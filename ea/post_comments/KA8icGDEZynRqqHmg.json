[{"_id": "ivFvPFj4xGRk8ErgG", "postedAt": "2014-08-18T13:06:00.000Z", "postId": "KA8icGDEZynRqqHmg", "htmlBody": "<p>After thinking about this later, I noticed that one of my claims was wrong. I said:</p><p>&gt; Though I\u2019m not particularly excited about refuges, they might be a good test case. I think that if you had this 5N view, refuges would be obviously dumb but if you had the view that I defended in my dissertation then refuges would be interesting from a conceptual perspective.</p><p>But then I ran some numbers and this no longer seemed true. If you assumed a population of 10B, an N of 5, a cost of your refuge of $1B, that your risk of doom was 1%, and that your refuge could cut out a thousandth of that 1%, you get a cost per life-equivalent saved of $2000 (with much more favorable figures if you assume higher risk and/or higher refuge effectiveness). So a back-of-the-envelope calculation would suggest that, contrary to what I said, refuges would not be obviously dumb if you had the 5N view. (Link to back-of-envelope calc: <a href=\"https://docs.google.com/spreadsheets/d/1RRlj1sZpPJ8hr-KvMQy5R8NayA3a58EhLODXPu4NgRo/edit#gid=1176340950\">https://docs.google.com/spreadsheets/d/1RRlj1sZpPJ8hr-KvMQy5R8NayA3a58EhLODXPu4NgRo/edit#gid=1176340950</a> .)</p><p>My best current guess is that building refuges wouldn't be this effective at reducing existential risk, but that was after I looked into the issue a bit. I was probably wrong to think that Holden's 5N heuristic would have ruled out refuges ex ante. (Link to other discussion of refuges: /ea/5r/improving_disaster_shelters_to_increase_the/ .)</p>", "parentCommentId": null, "user": {"username": "Nick_Beckstead"}}, {"_id": "vueuSYMziPZpjdQem", "postedAt": "2014-08-18T15:57:00.000Z", "postId": "KA8icGDEZynRqqHmg", "htmlBody": "<p>Thanks for this clarification. After reading the emails I wanted to make exactly this point!</p><p>\nI do think that comparing how good saving a life today is compared to doing something like building bunkers to reduce risk really comes down to an understanding of the world today rather than an understanding of exactly how big the future might be (after you grant that it could be very big). Though choosing 5 as a multiplier looks rather low to me; I'd be happier with something up in 100-1000 range (and I wouldn't be surprised if my view of the correct figure to use there changes substantially in the future).</p>", "parentCommentId": "ivFvPFj4xGRk8ErgG", "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "LskPYA5SZhf8wNn2J", "postedAt": "2014-08-18T20:00:00.000Z", "postId": "KA8icGDEZynRqqHmg", "htmlBody": "<p>I agree with all of that, though maybe I'm a bit more queasy about numbers &gt;100.</p>\n", "parentCommentId": "vueuSYMziPZpjdQem", "user": {"username": "Nick_Beckstead"}}, {"_id": "iDhp5Aq8QbKp4Jay4", "postedAt": "2014-08-18T21:13:00.000Z", "postId": "KA8icGDEZynRqqHmg", "htmlBody": "<p><blockquote>ELIEZER: How does AMF get us to a 1% better <em>long-term</em> future?  Are you envisioning something along the lines of \u201cStarting with a 1% more prosperous Earth results in 1% more colonization and hence 1% more utility by the time the stars finally burn out\u201d?</blockquote></p><p>HOLDEN: I guess so. A 1% better earth does a 1% better job in the SWH transition? <b>I haven\u2019t thought about this much<b> and don\u2019t feel strongly about what I said.</b></b></p><p>LOL</p>", "parentCommentId": null, "user": {"username": "Guest"}}, {"_id": "okZvyLCZe9eGisXNi", "postedAt": "2014-08-19T14:50:00.000Z", "postId": "KA8icGDEZynRqqHmg", "htmlBody": "<p>I think that comment is mostly Holden being modest.</p>\n", "parentCommentId": "iDhp5Aq8QbKp4Jay4", "user": {"username": "Nick_Beckstead"}}, {"_id": "fLtQTLQSRFn6Spjav", "postedAt": "2014-08-20T14:42:00.000Z", "postId": "KA8icGDEZynRqqHmg", "htmlBody": "<p>I think that that can be an appropriate epistemic state, and that it's valuable to have norms where you admit which of your beliefs you have less confidence in. I'm not sure what the problem here is.</p>\n", "parentCommentId": "iDhp5Aq8QbKp4Jay4", "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "DYnDAgfxfFnPzPGzT", "postedAt": "2014-08-21T18:49:00.000Z", "postId": "KA8icGDEZynRqqHmg", "htmlBody": "<p>The problem, in my opinion, isn't Holden's confession that he isn't particularly confident in his views here. In fact, I completely agree with you that we ought to have norms that encourage the expression of appropriate levels of epistemic humility.</p><p>\nThe problem (/what may strike one as amusing) is rather the obvious incoherence in the combination of, on the one hand, Holden's lack of confidence regarding the claim Eliezer asks him to consider and, on the other hand, the much higher confidence he appears to place in the claim that something like donations to AMF are currently the way to go, or at least a very good idea (even in relative terms).</p><p>\nThis combination of attitudes appears incoherent because his background views ought to make his opinion on the latter issue highly sensitive to his opinion on the former.</p><p>\nAccordingly, it would appear that Holden should either do a lot more thinking about this topic, or he should openly admit that he doesn't have much of a clue whether AMF-style interventions are a good idea, since he &quot;hasn't thought much&quot; about some of the key issues in this area.</p><p>\n(To make matters worse, Holden's take on the claim in question strikes me as having little initial plausibility.)</p>", "parentCommentId": "fLtQTLQSRFn6Spjav", "user": {"username": "Guest"}}]