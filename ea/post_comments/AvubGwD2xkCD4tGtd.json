[{"_id": "EH6JcJvRHv9Gq7Pt8", "postedAt": "2023-12-27T10:29:41.654Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>I\u2019m surprised how confident people are in their theories.</p>\n<blockquote>\n<p>Other mammals and birds exhibiting the same behavior, having much the same neural circuitry, are probably engaging in that behavior for the same reason humans are\u2013because they have internal conscious experiences</p>\n</blockquote>\n<p>Since self-modelling, having feedback mechanisms for reinforcement learning, and having qualia all feel closely related to us, humans, it\u2019s easy to think that \u201cconscious experience\u201d includes all three, and perceive evidence for some of the three as evidence for others. This seems invalid, unless the author does something like making an argument for how exactly having qualia has been evolutionary useful and what properties it\u2019s connected to and then demonstrating related properties in some animals but not others. Does the author actually do that in the book?</p>\n", "parentCommentId": null, "user": {"username": "Samin"}}, {"_id": "gSuuaeGG3hACoJRev", "postedAt": "2023-12-27T15:05:27.233Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Thanks for your summary!</p>\n<p>I'll admit I didn't really follow the section 'sensation, sentition, and the ipsundrum' but the rest of it seems very weak, if any, evidence for the theory.</p>\n<p>To pick one example: Why should I think sensory play is a necessary condition for sentience?</p>\n<p>You could imagine a species which had all the neural architecture mammals &amp; birds have, but had no limbs. I think we wouldn't observe it 'playing,' but I think Humphrey's theory still implies it's sentient.</p>\n", "parentCommentId": null, "user": {"username": "Bella_Forristal"}}, {"_id": "pru2H2MPEvmuBBXvt", "postedAt": "2023-12-27T17:18:30.077Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>I've tried to condense a book-length presentation into a 10 minute read and I probably have made some bad choices about which parts to leave out.</p>\n<p>Its not that sensory play is necessary for producing sentience. The claim is that any animal that is sentient would be motivated to play. There might be other motivations for play that are not sentience, but all sentient creatures (so the argument goes) would want to play in order to explore and learn about the properties of its own sensory world.</p>\n<p>For the limbless species you mentioned, if we imagine a radical scenario like a mammal that evolves into an entirely static plant-like existence, but for some reason, it doesn't lose its now-evolutionarily-useless capacity for sentience, i suppose I imagine that it would play if it could, but does not because it can't. So perhaps you could rescue Humphrey's assertion about play by modifying it to \"any sentient animal will be motivated to play and will play to the extent they are physically able to do so\".</p>\n<p>The theory depends on humans shared ancestry and neurophysiology with other animals. Conditional on shared ancestry and neurophysiology we are able to make some tentative inferences about animal experience from our own experiences. Without that shared ancestry, I think he would be far too far out on a limb (heh).</p>\n", "parentCommentId": "gSuuaeGG3hACoJRev", "user": {"username": "ben.smith"}}, {"_id": "Ana3bsLSoNSpwp45T", "postedAt": "2023-12-27T18:09:36.033Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Upvoted because I\u2019m a fan of people <a href=\"https://forum.effectivealtruism.org/posts/8yDsenRQhNF4HEDwu/link-posting-is-an-act-of-community-service\">summarizing and signal-boosting literature that bears on EA priorities</a>. Disagree-voted because I\u2019m not convinced that any of the observations or considerations put forward support the headline claim that only mammals and birds are sentient.</p>", "parentCommentId": null, "user": {"username": "Will Aldred"}}, {"_id": "MHrhDnnDZzkw44XWf", "postedAt": "2023-12-27T19:32:59.141Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>No, the author is ultimately unclear why qualia in itself is useful, but by reasoning about the case studies I listed, his argument that qualia is in fact related to recursive internal feedback loops is ultimately a bit stronger than just \"these things all feel like the same things so they must be related\".</p>\n<p>Humphrey first argues through his case studies that activity in the neocortex seems to generate conscious experience, while activity in the midbrain does not. Further, midbrain activity is sophisticated and can do a lot of visual and other perceptual processing independent of the neocortex, so all of that seems to be dissociable from consciousness. What remains is the generation of sensations in the neocortex. From that we can understand sensations ([in certain parts of?] the neocortex) are separable from perceptions (in the midbrain). So while that doesn't tell us what consciousness is needed for, it does tell us what it is not used for, including at least some perception and midbrain processes like RL. The vulnerability in this argument IMO is mainly that self report about conscious experience might not be entirely reliable.</p>\n<p>Then he advances his \"ipsundrum\" hypothesis about how recursive (or recurrent, perhaps) sensory feedback loops could have evolved and gives strong arguments about why this was evolutionarily useful. The argument includes the idea that recurrent sensory feedback allows complex integrative processes such as self reflection and theory of mind, and those have strong evolutionary advantages. The development of warm blood might have both facilitated those feedback loops by speeding up neural processing, and necessitated them by requiring a more sophisticated homeostatic apparatus. So an evolutionary feedback loop created the sensory feedback loop.</p>\n<p>At this point, I guess we still can't be confident these processes <em>are</em> inseparable from consciousness, but they seem more closely related to consciousness than other clearly separable processes. That seems valuable for at least lowering our expectations of sentience in species that don't have the cognitive processes whose relationship to consciousness we haven't ruled out.</p>\n", "parentCommentId": "EH6JcJvRHv9Gq7Pt8", "user": {"username": "ben.smith"}}, {"_id": "s766g7QgBkw9RNWkJ", "postedAt": "2023-12-27T19:33:50.862Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Also, I\u2019m pretty sure that octopuses do play? A quick search appears to confirm this: \u201cOctopuses like to play\u201d (<a href=\"https://www.bbc.co.uk/programmes/articles/2KzKVBXNXFtz4bYDWGNkqxS/10-incredible-facts-about-octopuses#:~:text=5.%20Octopuses%20like,are%20playful%20creatures.\"><u>BBC</u></a>).</p><p>I mention this in response to the part of the post that reads: \u201cOther animals like fish, reptiles, and octopuses do <i>not</i> engage in sensation-seeking or play and so do not have those internal conscious experiences.\u201d</p><p>(ETA: I see that in their closing section, OP acknowledges some uncertainty here, listing as a question for further investigation: \u201cIs it really true that fish, shrimp, octopuses, and other animals of particular concern do not engage in sensation seeking or play?\u201d)</p>", "parentCommentId": "Ana3bsLSoNSpwp45T", "user": {"username": "Will Aldred"}}, {"_id": "rh6rccxkeYPYhukZd", "postedAt": "2023-12-27T19:41:21.830Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Humphrey spent a lot of time saying that authors like Peter Godfrey-Smith (whose book on octopus sociality and consciousness I have read, and also recommend) are wrong or not particularly serious when they argue that octopus behavior is play, because there are more mundane explanations for play-like behavior. I can't recall too much detail here because I no longer have Humphrey's book in my possession. In any case I think if you convinced him octopuses do play he would probably change his mind on octopuses without needing to modify any aspects of the overall theory. He'd just need to concede that the way consciousness developed in warm blooded creatures is not the only way it has developed in evolutionary history.</p>\n", "parentCommentId": "s766g7QgBkw9RNWkJ", "user": {"username": "ben.smith"}}, {"_id": "rcudptEojrWdrrxK2", "postedAt": "2023-12-27T19:54:49.568Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Actually, I have to correct my earlier reply. Iirc the argument is that all conscious animals engage in physical play, not necessarily that all playful animals are conscious. On the other hand, Humphrey does say that all animals engaging in pure sensation-seeking type play are conscious, so that's probably the sort of play he'd need to bring him around on octopuses.</p>\n", "parentCommentId": "s766g7QgBkw9RNWkJ", "user": {"username": "ben.smith"}}, {"_id": "62FTcExvFeigBWL2C", "postedAt": "2023-12-27T23:45:41.718Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>EDIT: I don't think I had the right idea of what sensory play is. Sensory play seems to be a kind of exploratory play directed at things with novel or unusual sensory properties, like sand, bubbles, squishy things, different sounds, different smells, etc..</p><p><a href=\"https://www.youtube.com/shorts/W-RpgNcGkuc\">This</a> and <a href=\"https://www.youtube.com/watch?v=6at5gBa4ZbI\">this</a>, where fish are thrown into the water and come back and thrown again, also looks like sensory play (unless I've misunderstood what Humphrey meant). But, there might be other explanations, e.g. maybe the fish aren't coming back to be thrown again, but because they've been trained to, or because they want something else. It doesn't seem like something they'd specifically have been evolved to be motivated by this, given how unnatural it is.</p><p>&nbsp;</p><p>There's also <a href=\"https://www.sciencedirect.com/science/article/pii/S0003347222002366\">this study</a> of ball-rolling in bumble bees that the authors conclude meets the criteria for play:</p><blockquote><p>Here, we show that rolling of wooden balls by bumble <a href=\"https://www.sciencedirect.com/topics/veterinary-science-and-veterinary-medicine/bee\">bees</a>, <a href=\"https://www.sciencedirect.com/topics/agricultural-and-biological-sciences/bombus-terrestris\"><i>Bombus terrestris</i></a>, fulfils behavioural criteria for animal play and is akin to play in other animals. We found that ball rolling (1) did not contribute to immediate survival strategies, (2) was intrinsically rewarding, (3) differed from functional <a href=\"https://www.sciencedirect.com/topics/neuroscience/behavior-neuroscience\">behaviour</a> in form, (4) was repeated but not stereotyped, and (5) was initiated under stress-free conditions.</p></blockquote><p>&nbsp;</p><p>Rethink Priorities collected some evidence of play behaviour across species. From their <a href=\"https://docs.google.com/spreadsheets/d/13E1Ub7PIMkIcQKT6jDf0_2WIco-VW3vqCEcfPDLXeHw/edit#gid=309744399&amp;range=A68\">Welfare Range Table</a> (<a href=\"https://forum.effectivealtruism.org/posts/tnSg6o7crcHFLc395/the-welfare-range-table\">EA Forum post</a>):</p><blockquote><p>No studies of carp could be found. An anecdotal observation of possible play was described in two other cyprinid species, the redeye (Scardinius erythrophthalmus) and the rudd (Leuciscus cephalus), showing that these fish returned over and over for the experience of being thrown out of the water by a human hand and the fish often competed vigorously to be the next one to be thrown (Burghardt, 2005). Burghardt (2005) provides a review of a large body of anecdotal evidence that suggests that play may exist in multiple species of teleost fish. However, further empirical studies involving controlled and systematic observation of fish play behaviors are needed and could follow up on the anecdotal observations outlined by Burghardt (2005). Importantly, the current lack of documented play behavior in fish may not indicate that fish do not play but rather that they are too uncomfortable in the typical housing we provide for them to engage in play (Fife-Cook &amp; Franks, 2019). Thus, further research requires housing fish in environmental and social conditions conducive to a relaxed state (Fife-Cook &amp; Franks, 2019).</p></blockquote><p>&nbsp;</p><blockquote><p>It is common for juvenile and adult salmonids to jump into the air from the water, and this behaviour is highly relevant in salmonid net-pen culture and may be related to buoyancy regulation, parasitic infections, or stress (Fagen, 2017). However, Fagen (2017) has suggested that some jumping behavior seen in Atlantic salmon (Salmo salar) may represent a form of locomotor play but calls for additional research. Burghardt (2005) also reports on anecdotal observations of possible instances of locomotor play (not involving jumping) resembling adult redd-digging behavior in juvenile Coho salmon (Oncorhynchus kisutch). Burghardt (2005) provides a review of a large body of anecdotal evidence that suggests that play may exist in multiple species of teleost fish. However, further empirical studies involving controlled and systematic observation of fish play behaviors are needed and could follow up on the anecdotal observations outlined by Burghardt (2005). Importantly, the current lack of documented play behavior in fish may not indicate that fish do not play but rather that they are too uncomfortable in the typical housing we provide for them to engage in play (Fife-Cook &amp; Franks, 2019). Thus, further research requires housing fish in environmental and social conditions conducive to a relaxed state (Fife-Cook &amp; Franks, 2019).</p></blockquote><p>&nbsp;</p><blockquote><p>Play behaviour has frequently been reported in octopuses. In captivity, octopuses are eager to explore inanimate objects (e.g., Lego, balls); they carry them around their aquarium tank and pass them from arm to arm (Kuba et al. 2003; Kuba &amp; Byrne 2006). Giant Pacific octopuses, Enteroctopus dofleini, manipulate floating objects (e.g., plastic bottles) by squirting jets of water at the item, sending it to the far end of their aquarium and repeating the behaviour when the object floats back to them (Mather &amp; Anderson, 1999). In the wild, different species have been observed collecting and manipualting different objects such as plastic and glass bottles (Mather 1994).</p></blockquote>", "parentCommentId": "s766g7QgBkw9RNWkJ", "user": {"username": "MichaelStJules"}}, {"_id": "h6KgDBMnpdSTNcHX7", "postedAt": "2023-12-28T00:00:47.158Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Also some recent popular science coverage of Humphrey's work:</p><ol><li><a href=\"https://www.newyorker.com/news/annals-of-inquiry/nicholas-humphreys-beautiful-theory-of-mind\">https://www.newyorker.com/news/annals-of-inquiry/nicholas-humphreys-beautiful-theory-of-mind</a></li><li><a href=\"https://aeon.co/essays/how-blindsight-answers-the-hard-problem-of-consciousness\">https://aeon.co/essays/how-blindsight-answers-the-hard-problem-of-consciousness</a></li><li><a href=\"https://nextbigideaclub.com/magazine/sentience-invention-consciousness-bookbite/40738/\">https://nextbigideaclub.com/magazine/sentience-invention-consciousness-bookbite/40738/</a></li></ol>", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "WGWysEXioYSWBGxWo", "postedAt": "2023-12-28T01:32:46.805Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Thanks Michael. For readers who are confused by my post but still want to know more, consider just reading (2), which is a very good pr\u00e9cis by Nick Humphrey of his book which I tried to summarize. It might be better for readers, rather than reading my essay, to just read that.&nbsp;</p>", "parentCommentId": "h6KgDBMnpdSTNcHX7", "user": {"username": "ben.smith"}}, {"_id": "yiqJTLfyPwCcdkTzn", "postedAt": "2023-12-28T03:29:19.834Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>(Somewhat tangential.)</p><p>Does Humphrey discuss his theory as an illusionist one in the book? My understanding is that he's an illusionist and the theory he's been working on is illusionist.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftwn8e8efjun\"><sup><a href=\"#fntwn8e8efjun\">[1]</a></sup></span>&nbsp;That seems like a pretty important part of his theory, but it might not be that important for his claim that only mammals and birds are conscious.</p><p>(FWIW, I think illusionism about consciousness is probably correct.)</p><p>It seems there are two broad (moral?) interpretations of illusionism (e.g. <a href=\"https://youtu.be/txiYTLGtCuM?t=5042\">Frankish, 2021</a>):</p><ol><li>To be conscious, a physical system has to actually believe in the mysteriousness (or importance/mattering?) of what it's processing. In other words, it would have to actually be subject to <i>illusions of phenomenal consciousness</i>.</li><li>To be conscious, <i>if</i> the right kind of system<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqoquagm8f1l\"><sup><a href=\"#fnqoquagm8f1l\">[2]</a></sup></span>&nbsp;were connected to the original system in the right way, that system <i>would</i> have to believe in (and report) the mysteriousness (or importance/mattering?) of what the combined system is processing.</li></ol><p>1 implies 2, and it seems fewer systems could meet 1 than 2.</p><p>It seemed like Humphrey endorses something like 1.&nbsp;Graziano's (illusionist) Attention Schema Theory seems between 1 and 2,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefy2ydr0q063p\"><sup><a href=\"#fny2ydr0q063p\">[3]</a></sup></span>&nbsp;and he (<a href=\"https://doi.org/10.1073/pnas.2116933119\">2022</a>) wrote \"the components of what we call consciousness may be present in some form in a huge range of animals, including mammals, birds, and many nonavian reptiles\"<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqiy6kzw9nss\"><sup><a href=\"#fnqiy6kzw9nss\">[4]</a></sup></span>, although I'm not aware of him specifically <i>denying</i> consciousness to other animals. Related to this, and while not specifically illusionist, Key, Brown and Zalucki argue that&nbsp;<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6088194/\"><u>molluscs (including octopuses)</u></a>,&nbsp;<a href=\"https://www.frontiersin.org/articles/10.3389/fnbeh.2021.658037/full\"><u>insects</u></a> and&nbsp;<a href=\"https://www.youtube.com/watch?v=jDOwm2plXmc\"><u>fish</u></a> don\u2019t have internal state prediction networks for their own pain, i.e. they don\u2019t model their own pain. Key (<a href=\"https://link.springer.com/article/10.1007/s10539-014-9469-4\">2014</a>, <a href=\"https://www.wellbeingintlstudiesrepository.org/cgi/viewcontent.cgi?article=1011&amp;context=animsent\">2016</a>) argues that fish lack long-range feedback connections for pain processing (perhaps between certain structures specifically)&nbsp;and that the pain pathway is feedforward.</p><p>On the other hand, Frankish (<a href=\"https://youtu.be/xZxcair9oNk?t=3590\"><u>2023</u></a><u>,</u> <a href=\"https://www.youtube.com/watch?v=me9WXTx6Z-Q\"><u>2022</u></a>,<a href=\"https://youtu.be/txiYTLGtCuM?t=5042\"><u> 2021</u></a>) endorses 2. I'd guess Dennett endorses 2 (or neither?), because he's <a href=\"https://youtu.be/3aIfyl6fO34?list=PLY_s7b9LrR8UCcPqL59XuIII68ALjgLt7&amp;t=4597\">confident in octopus and bee consciousness</a>, but I'm not sure.</p><p>Although Frankish endorses 2 anyway, I suspect he's too skeptical of other animals meeting something like 1, setting the bar too high for introspection and/or the kinds of beliefs that are required. He has a whole talk titled \"<a href=\"https://www.youtube.com/watch?v=me9WXTx6Z-Q\">Why We Can Know What It\u2019s Like To Be a Bat and Bats Can\u2019t</a>\". Dennett might also set the bar too high; see Graziano's response to him.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefy2ydr0q063p\"><sup><a href=\"#fny2ydr0q063p\">[3]</a></sup></span></p><p>I also lean towards 1, but possibly under a slightly different interpretation: I suspect the system just has to <i>believe something matters</i>. I might also have a low bar for what could count as a belief that something matters, but this seems vague. I think humans can believe things without <i>stating</i> their beliefs (in inner speech or externally, see <a href=\"https://doi.org/10.2307/3129585\"><u>Malcolm, 1973</u></a><u>, and/or sections 1 and 4 of </u><a href=\"https://plato.stanford.edu/entries/belief/\"><u>Schwitzgebel, 2019</u></a>), and if that's the case, it seems hard to justify the claim that insects, say, very likely don't believe anything matters.</p><p>On the other hand, then we <i>might</i> end up having to recognize that humans often have (active) beliefs that something matters that we don't typically recognize ourselves as being conscious of. And we <i>might</i> end up with a basically panpsychist (but possibly gradualist) view.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntwn8e8efjun\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftwn8e8efjun\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Humphrey (<a href=\"https://eprints.lse.ac.uk/80740/1/Humprey_Invention%20of%20consciousness.pdf\">2017</a>) wrote, after contrasting realism and illusionism:</p><blockquote><p>Still, which is right? No one yet knows for sure. But I\u2019m not hiding which I hope is right. Although I myself have recently questioned the language of illusionism (Humphrey 2016b), I hope to see a resolution of the \u201chard problem\u201d within the bounds of our standard world model.</p></blockquote><p>Also, see <a href=\"https://www.youtube.com/watch?v=uYC0JbN_BmY\">this interview</a>.</p><p>(FWIW, Graziano (<a href=\"https://grazianolab.princeton.edu/sites/g/files/toruqf3411/files/graziano/files/jcs_graziano_2016.pdf\">2016</a>), also an illusionist, wrote: \"I confess that I baulk at the term \u2018illusionism\u2019 because I think it miscommunicates\", and elaborates on this.)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqoquagm8f1l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqoquagm8f1l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Presumably with some constraints on what the system can do.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fny2ydr0q063p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefy2ydr0q063p\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The attention schema could itself be the beliefs and include the illusions of consciousness.</p><p><u>Graziano (</u><a href=\"https://doi.org/10.1080/02643294.2020.1761782\"><u>2020a</u></a><u>) wrote:</u></p><blockquote><p>Therefore, in AST, just as animals \u201cknow\u201d about their own bodies in some deep intuitive sense via their body schemas, they also \u201cknow\u201d about a subjective experience inside of them (a detail-poor depiction of their attentional state) via an attention schema. They may, however, lack higher cognitive levels of reflection on those deeper models.</p><p>Dennett (2020) suggests that only humans need an attention schema and that dogs do not. I think perhaps the difference in opinion here relates to higher level and lower level models. Humans undoubtedly have layers of higher cognitive models, myths and beliefs and cultural baggage. Much of the ghost mythology that we discussed in our target article (Graziano et al., 2020) is presumably unique to humans, exactly as Dennett suggests. But in AST, many of these human beliefs stem from, or are cultural elaborations of, a deeper model that is built into us and many other animals \u2013 an intrinsic model of attention.</p></blockquote><p>He uses quotes around the word 'know', so he might not mean these count as beliefs. Graziano (<a href=\"https://doi.org/10.1080/17588928.2020.1838468\">2020b</a>) also wrote the following, which contrasts the attention schema (\"automatic self-model (...)\") from our beliefs:</p><blockquote><p>Suppose the machine has no attention, and no attention schema either. But it does have a self-model, and the self-model richly depicts a subtle, powerful, nonphysical essence, with all the properties we humans attribute to consciousness. Now we plug in the speech engine. Does the machine claim to have consciousness? Yes. The machine knows only what it knows. It is constrained by its own internal information.</p><p>AST does not posit that having an attention schema makes one conscious. Instead, first, having an automatic self-model that depicts you as containing consciousness makes you intuitively believe that you have consciousness. Second, the reason why such a self-model evolved in the brains of complex animals, is that it serves the useful role of modeling attention.</p></blockquote></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqiy6kzw9nss\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqiy6kzw9nss\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Before that, Graziano (<a href=\"https://doi.org/10.1080/02643294.2020.1761782\">2020a</a>) wrote:</p><blockquote><p>Any creature that can endogenously direct attention must have some kind of attention schema, and good control of attention has been demonstrated in a range of animals including mammals and birds (e.g., Desimone &amp; Duncan, 1995; Knudsen, 2018; Moore &amp; Zirnsak, 2017). My guess is that most mammals and birds have some version of an attention schema that serves an essentially similar function, and contains some of the same information, as ours does.</p></blockquote></div></li></ol>", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "Tfgjq6cqGaYCiSEXt", "postedAt": "2023-12-28T05:01:47.425Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Not absolutely sure I'm afraid. I lent my copy of the book out to a colleague so I can't check.</p>\n<p>Humphrey mentioned illusionism (page 80 acc to Google books) but iirc he doesn't actually say his view is an illusionist one.</p>\n<p>Personally I can't stand the label \"illusionism\" because to me the label suggests we falsely believe we have qualia, and actually have no such thing at all! But your definition is maybe much more mundane--there, the illusion is merely that consciousness is mysterious or important or matters. I wish the literature could use labels that are more specific.</p>\n<p>And it seems like the version matters a great deal too. Perhaps if consciousness really is an illusion, and none of us really have qualia--we're all p-zombies programmed to believe we aren't--I have a hard time understanding the point of altruism or anything more than instrumental morality. But if we're just talking about an illusion that consciousness is a mysterious other worldly thing, and somehow, there really are qualia, then altruism feels like a meaningful life project to adopt.</p>\n<p>On the whole having read Humphrey's book, I don't think he explicitly said he was an illusionist. but perhaps his theory suggests it, I'm not sure. He didn't really explain <em>why</em> exactly he thought, a priori, we should expect sensorimotor feedback loops would generate consciousness, just that they seem to do so empirically. Perhaps he cleverly sidestepped the issue. I think his theory could make sense whether you are an illusionist or not.</p>\n", "parentCommentId": "yiqJTLfyPwCcdkTzn", "user": {"username": "ben.smith"}}, {"_id": "pi4kDMnu2pbMBtSci", "postedAt": "2023-12-28T06:00:31.677Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<blockquote><p>Personally I can't stand the label \"illusionism\" because to me the label suggests we falsely believe we have qualia, and actually have no such thing at all!</p></blockquote><p>I think this is technically accurate, but illusionists don't deny the existence of consciousness or claim that consciousness is an illusion; they deny the existence of <i>phenomenal</i> consciousness and qualia as typically characterized<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefu3i29eptbq\"><sup><a href=\"#fnu3i29eptbq\">[1]</a></sup></span>, and claim their appearances are illusions. Even Frankish, an illusionist, uses \"what-it-is-likeness\" in describing consciousness (e.g. \"<a href=\"https://www.youtube.com/watch?v=me9WXTx6Z-Q\">Why We Can Know What It\u2019s Like To Be a Bat and Bats Can\u2019t</a>\"), but thinks that should be formalized and understood in non-phenomenal (and instead physical-functional) terms, not as standard qualia.</p><p>The problem is that (classic) qualia and phenomenality have become understood as synonymous with consciousness, so denying them sounds like denying consciousness, which seems crazy.</p><p>&nbsp;</p><blockquote><p>Perhaps if consciousness really is an illusion, and none of us really have qualia--we're all p-zombies programmed to believe we aren't--I have a hard time understanding the point of altruism or anything more than instrumental morality.</p></blockquote><p><a href=\"https://quod.lib.umich.edu/e/ergo/12405314.0006.032/--normative-challenge-for-illusionist-views-of-consciousness?rgn=main;view=fulltext\"><u>Kammerer, 2019</u></a><u> might be of interest. On accounting for the badness of pain, he writes:</u></p><blockquote><p><u>The best option here for the illusionist would probably be to draw inspiration from desire-satisfaction views of well-being (Brandt 1979; Heathwood 2006) or from attitudinal theories of valenced states (Feldman 2002), and to say that pain is bad (even if it is not phenomenal) because it constitutively includes the frustration of a desire, or the having of a certain negative attitude of dislike. After all, when I am in pain, there is something awful which is that I want it to stop (and that my desire is frustrated); alternatively, one could insist on the fact that what is bad is that I dislike my pain. This frustration or this dislike are what makes pain a harm, which in turn grounds its negative value. This might be the most promising lead to an account of what makes pain bad.</u></p></blockquote><p><u>This approach is also roughly what I'd go with. That being said, I'm a moral antirealist, and I think you can't actually ground value </u><i><u>stance-independently.</u></i></p><p>&nbsp;</p><blockquote><p>He didn't really explain <i>why</i> exactly he thought, a priori, we should expect sensorimotor feedback loops would generate consciousness, just that they seem to do so empirically. Perhaps he cleverly sidestepped the issue. I think his theory could make sense whether you are an illusionist or not.</p></blockquote><p>Makes sense.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnu3i29eptbq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefu3i29eptbq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\"Classic qualia: Introspectable qualitative properties of experience that are intrinsic, ineffable, and subjective.\" (<a href=\"https://keithfrankish.github.io/articles/Frankish_Quining%20diet%20qualia_eprint.pdf\">Frankish</a> (<a href=\"https://www.youtube.com/watch?v=zrk5TfwiY-s\">video</a>))</p><p>I think this is basically the standard definition of 'qualia', but Frankish adds 'classic' to distinguish it from Nagel's 'what-it-is-likeness'.</p></div></li></ol>", "parentCommentId": "Tfgjq6cqGaYCiSEXt", "user": {"username": "MichaelStJules"}}, {"_id": "qHKXidicTFHS9YoA5", "postedAt": "2023-12-28T07:46:43.656Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<blockquote>\n<p>say that pain is bad (even if it is not phenomenal) because it constitutively includes the frustration of a desire, or the having of a certain negative attitude of dislike</p>\n</blockquote>\n<p>I'm curious how, excluding phenomenal definitions, <s>you define</s> he defines \"frustration of a desire\" or \"negative attitude of a dislike\", because I wonder whether these would include extremely simple frustrations, like preventing a computer generated character in a computer game from reaching its goal. We could program an algorithm to try to solve for a desire (\"navigate through a maze to get to the goal square\") and then prevent it from doing so, or even add additional cruelty by making it from an expectation it is about to reach its goal and then preventing it.</p>\n<p>I share your moral antirealism, but don't think I could be convinced to care about preventing frustration of that sort of simple desire. It's the qualia-laden desire that seems to matter to me, but that might be irrational if it turns out qualia is an illusion. In think within anti-realism it still makes sense to avoid certain stances if they involve arbitrary inconsistencies. So if not qualia, I wonder what meaningful difference there is between a starcraft ai's frustrated desires and a human's</p>\n", "parentCommentId": "pi4kDMnu2pbMBtSci", "user": {"username": "ben.smith"}}, {"_id": "TpCGGJn6QyxkqGy7a", "postedAt": "2023-12-28T15:11:51.386Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>I think illusionists haven't worked out the precise details, and that's more the domain of cognitive neuroscience. I think most illusionists take a gradualist approach,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefw4l7cqdbt1\"><sup><a href=\"#fnw4l7cqdbt1\">[1]</a></sup></span>&nbsp;and would say it can be more or less the case that a system experiences states worth describing like \"frustration of a desire\" or \"negative attitude of a dislike\". And we can assign more moral weight the more true it seems.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7cfmrfdit0t\"><sup><a href=\"#fn7cfmrfdit0t\">[2]</a></sup></span></p><p>We can ask about:</p><ol><li>how the states affect them in lowish-order ways, e.g. negative valence changes our motivations (motivational anhedonia), biases our interpretations of stimuli and attention, has various physiological effects that we experience (or at least the specific negative emotional states do; they may differ by emotional state),</li><li>what kinds of beliefs they have about these states (or the objects of the states, e.g. the things they desire), to what extent they're worth describing as beliefs, and the effects of these beliefs,</li><li>how else they're aware of these states and in what relation to other concepts (e.g. a self-narrative), to what extent that's worth describing as (that type of) awareness, and the effects of this awareness.</li></ol><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnw4l7cqdbt1\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefw4l7cqdbt1\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Tomasik (<a href=\"https://reducing-suffering.org/why-your-laptop-may-be-marginally-sentient/\"><u>2014-2017</u></a>, various other writings&nbsp;<a href=\"https://reducing-suffering.org/#consciousness\"><u>here</u></a>),&nbsp;<a href=\"https://www.openphilanthropy.org/research/2017-report-on-consciousness-and-moral-patienthood/\"><u>Muehlhauser, 2017</u></a> (sections 2.3.2 and 6.7), Frankish (<a href=\"https://youtu.be/xZxcair9oNk?t=3060\"><u>2023, 51:00-1:02:25</u></a>), Dennett (<a href=\"https://www.newyorker.com/magazine/2017/03/27/daniel-dennetts-science-of-the-soul\"><u>Rothman, 2017</u></a>,&nbsp;<a href=\"https://davidrosenthal.org/Dennett-on-Seeming-to-Seem.pdf\"><u>2018, p.168-169</u></a>,&nbsp;<a href=\"https://www.ingentaconnect.com/content/imp/jcs/2019/00000026/f0020009/art00004\"><u>2019</u></a>,&nbsp;<a href=\"https://www.youtube.com/watch?v=3aIfyl6fO34&amp;list=PLY_s7b9LrR8UCcPqL59XuIII68ALjgLt7&amp;t=4597s\"><u>2021, 1:16:30-1:18:00</u></a>), Dung (<a href=\"https://link.springer.com/article/10.1007/s11229-022-03710-1\"><u>2022</u></a>) and&nbsp;<a href=\"https://www.pnas.org/doi/10.1073/pnas.2102421118\"><u>Wilterson and Graziano, 2021</u></a><u>.</u></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7cfmrfdit0t\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7cfmrfdit0t\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is separate from their intensity or strength.</p></div></li></ol>", "parentCommentId": "qHKXidicTFHS9YoA5", "user": {"username": "MichaelStJules"}}, {"_id": "JxxcveKwxrTmk8JvA", "postedAt": "2023-12-28T19:36:02.929Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Thanks Ben for reviewing and sharing the post (and to Michael for your resources) I did find it very interesting. But after reading it, giving it some thought, and reading the <i>Aeon </i>essay you recommended I came away quite intellectually frustrated. I think whenever some claims to have answered the hard problem, the more likely explanation is that they haven't understood it.</p><p>(Full disclosure for me confusion, I've all but become a strong dualist about consciousness after many many years of being or identitfying as a physicalist. This was a result of reading the philosophical literature, but also a lot of what was a personal reflection on my own experiences through meditation practice, especially informed by Douglas Harding's <i>Headless Way</i>. I basically can't grok illusionist perspectives any more try as I might<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkf6zgvb708\"><sup><a href=\"#fnkf6zgvb708\">[1]</a></sup></span>, so readers might better read this comment as coming from a dualist loyal opposition, rather than a balanced assessment)</p><p>Something I found particularly puzzling was in the 3rd section of the essay (beginning 'Over the past 50 years...'), Humphrey seems to confuse mind-brain identity theory with panyschism, which doesn't for me bode well my expectation of his 'solving' of the hard problem. M-B-I to me is a strongly physicalist (if not eliminativist) position, while pansychism is by necessity dualist.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5hxsxqq094j\"><sup><a href=\"#fn5hxsxqq094j\">[2]</a></sup></span></p><p>The D.B. case is also an interesting one - I don't see why it isn't plausible to imagine that the operation (and similarly split brain cases <a href=\"https://www.jstor.org/stable/20114764\">as documented by Nagel</a>) might lead to a second vestige of consciousness as cut off from you as that of your family, friends, and coworkers. Except this fragment doesn't have control of motor or speach functions, how horrible! It can only pass information onto the 'dominant' one.</p><p>The case of whether Humphrey is right about Octopi not playing is outside of my domain of expertise but initially I am sceptical. But again just because we know that we (humans) are conscious in a certain way, why ought we to imagine that consciousness <i>must </i>only exist in this way? I'm not sure it follows, and there seem to be gaps like this in his arguments that actually cover up important parts of his case.</p><p>Two examples of the above to end off my comment:</p><ol><li>In the Aeon article Humphrey states that sensations (i think he means qualia) are ideas. I agree! And these ideas exist. It feels very hard to explain how they exist in a physicalist or reductionist story, and attempts to explain often fail to the 'Moorean' argument for phenomenal realism.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5iuwmkzfu0f\"><sup><a href=\"#fn5iuwmkzfu0f\">[3]</a></sup></span></li><li>In Figure 2 he shows a simplified, 4-step diagram of how a brain might create an 'attractor state' of phenomenalisation. This is a clear story but seems to me to lead to eliminativist illusionism. The hard question is this, <i>why is this attractor state experiencing phenomenality, and not just a p-Zombie? </i>And it seems that, as all physicalist theories go, Humphrey has no answer to this.</li></ol><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkf6zgvb708\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkf6zgvb708\">^</a></strong></sup></span><div class=\"footnote-content\"><p>And so help me I have tried! I've directly read Dennett, Frankish, and Kammerer! But they all just seem so obviously wrong when they make clear claims; or annoyingly slippery and vague when they don't. Imo Chalmers blows them all away.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5hxsxqq094j\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5hxsxqq094j\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Galen Strawson actually has <a href=\"https://academic.oup.com/book/12822/chapter-abstract/163059537?redirectedFrom=fulltext\">an interesting argument</a> that physicalism must collapse into pansychism.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5iuwmkzfu0f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5iuwmkzfu0f\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Kammerer reviews this argument here and states it fails. But I just found it a convincing refutation of his own illusionism! I suppose one man's <i>modus ponens</i> really is another's <i>modus tollens</i></p></div></li></ol>", "parentCommentId": null, "user": {"username": "JWS"}}, {"_id": "B7mdM3gFbxvmSJ6np", "postedAt": "2023-12-28T20:20:28.730Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<blockquote><p>In the Aeon article Humphrey states that sensations (i think he means qualia) are ideas. I agree! And these ideas exist. It feels very hard to explain how they exist in a physicalist or reductionist story, and attempts to explain often fail to the 'Moorean' argument for phenomenal realism.</p></blockquote><p>Couldn't they just be beliefs? There are various (physicalist+reductionst-compatible) accounts of belief <a href=\"https://plato.stanford.edu/entries/belief/#WhatItBeli\">here</a>. (I'm not sure if that's what Humphrey intended, though.)</p><blockquote><p>The hard question is this, <i>why is this attractor state experiencing phenomenality, and not just a p-Zombie? </i>And it seems that, as all physicalist theories go, Humphrey has no answer to this.</p></blockquote><p>I think Humphrey is an illusionist and so would dny that it's experiencing phenomenality and that the hard problem needs to be solved (instead, illusionists <i>dissolve</i> it). However, a complete illusionist theory should explain how beliefs of phenomenality arise (e.g. how these attractor states cause these beliefs); that's the \"hard problem\" for illusionists. From what I'm reading in this post and comments, it seems he doesn't explain that. So, whether interpreted as realist or illusionist, it seems there's still an important gap.</p>", "parentCommentId": "JxxcveKwxrTmk8JvA", "user": {"username": "MichaelStJules"}}, {"_id": "dRrhK6LMRckX2sRAF", "postedAt": "2023-12-28T21:05:50.030Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Yeah I'm not quiet sure what Humphrey means by belief here (thanks for the link!). But then I don't really know what I mean by 'belief' to be honest! I'm not sure I can define it without evoking my own phenomenal perspective, whether directly (a flash of inspiration) or via thought and introspection (trying to update my current beliefs with new evidence) - and I think that'd already put me at odds with physicalists/illusionists</p><p>I do think Humphrey is an illusionist (even if he doens't like the term) and view him as somewhat adjacent to Frankish. I think that the 'meta-problem of consciousness' isn't quite what I'm hinting at (though it is a problem) - I'm taking my phenomenal experiences as true. Dualists (like myself) need to try and get them to accord with our understanding of the physical world, but I think illusionists need to explain why I'm experiencing anything at all rather than just reporting I am. We probably have very different intuitions on this, but part of the reason I've become more 'dualist' over time is that I found that I never had a good response to this criticism when I was a materialist/physicalist, so in the end I accepted it as a worthy criticism that disproved my original ideas.</p><p>Finally, I'll note this <a href=\"https://forum.effectivealtruism.org/posts/ZS9GDsBtWJMDEyFXh/eliezer-yudkowsky-is-frequently-confidently-egregiously?commentId=QLCevppMFisW9BqBE\">isn't the first time</a> we've had a Forum discussion about consciousness<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9o25cd55ci\"><sup><a href=\"#fn9o25cd55ci\">[1]</a></sup></span>&nbsp;- maybe it's something we could &nbsp;explore in a dialogue if it's something you think would be a valuable use of our time and potentially useful for those reading on the Forum? It definitely touches on a number of EA cause areas.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9o25cd55ci\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9o25cd55ci\">^</a></strong></sup></span><div class=\"footnote-content\"><p>And I've very much enjoyed learning from your perspective :)</p></div></li></ol>", "parentCommentId": "B7mdM3gFbxvmSJ6np", "user": {"username": "JWS"}}, {"_id": "QyyLWJtuFc7dYZy5s", "postedAt": "2023-12-28T22:26:23.445Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>I tend to think that questions about which organisms or systems are conscious mostly depend on identifying the physical correlates of consciousness, and understanding how they work as a system, and that questions about panpsychism, illusionism, eliminativism, or even Calmer's Hard Problem don't bear on this question very much. I think there's probably still a place for that philosophical debate because (1) there might be implications about where to look for the physical systems and (2) as I said to Michael <a href=\"https://forum.effectivealtruism.org/posts/AvubGwD2xkCD4tGtd/only-mammals-and-birds-are-sentient-according-to?commentId=Tfgjq6cqGaYCiSEXt\">earlier</a>, illusionism might change our perspective on whether we assign special moral value to conscious experience at all. But I think (1) is marginal, and (2) is sort of a long shot.</p><p>In contrast, I think empirical and scientific investigation can help us understand a lot about which systems are conscious, and about what sort of conscious experiences they have, so I think most morally cruxy questions of consciousness are scientific and empirical.</p><p>Consequently, I wasn't too bothered by Humphrey side-stepping this issue, although I basically agree he did, because he offered solid theory and empirical investigation that suggests further empirical tests that might help us make progress on understanding consciousness in animals and other systems.</p><blockquote><p>The D.B. case is also an interesting one - I don't see why it isn't plausible to imagine that the operation (and similarly split brain cases <a href=\"https://www.jstor.org/stable/20114764\">as documented by Nagel</a>) might lead to a second vestige of consciousness as cut off from you as that of your family, friends, and coworkers. Except this fragment doesn't have control of motor or speach functions, how horrible! It can only pass information onto the 'dominant' one.</p></blockquote><p>That was my reaction when I first read about split-brain patients. I now doubt it's all that horrible. First, there's been plenty of research of split-brain patients and I don't think anyone has discovered signs of distress from split-halfs that are cut off from speech expression; those halves <i>do</i> have other ways of communicating, e.g., through signs. Second, in humans, much of distress is governed physiologically, and so (1) we would be able to detect physiological signs of stress, but more importantly (2) even if there's a conscious half of a split-brain which can't express itself, its mood-state might be normal because it shares a body with the other half, and so the two jointly set mood, and the system overall might not be in distress. Finally, even if consciousness isn't illusory, conscious will often is; much more of our decisions are determined subconsciously than we think, and if the illusion still holds, the loss of conscious control might not even be perceived.</p>", "parentCommentId": "JxxcveKwxrTmk8JvA", "user": {"username": "ben.smith"}}, {"_id": "4nuu7S9qCbwhcF2uA", "postedAt": "2023-12-29T03:39:37.004Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<blockquote><p>I think illusionists need to explain why I'm experiencing anything at all rather than just reporting I am</p></blockquote><p>We need to first decide what we mean by 'experience'. I think there are two broad approaches (interpretations) of illusionism, which I described <a href=\"https://forum.effectivealtruism.org/posts/AvubGwD2xkCD4tGtd/only-mammals-and-birds-are-sentient-according-to?commentId=yiqJTLfyPwCcdkTzn\">here</a> and which could give us two different broad characterizations of 'experience':</p><ol><li>In the first, beliefs (illusions) of phenomenality/mysteriousness/nonphysical essence/etc. themselves could be what distinguishes what's experienced from what's not experienced. These beliefs need not be verbalized (whether in inner speech or reported) and could be of a more intuitive kind, like Graziano's attention schema or Humphrey's ipsundrum are meant to capture.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefauenc4tyd28\"><sup><a href=\"#fnauenc4tyd28\">[1]</a></sup></span>&nbsp;They might just be representations or models \"depicting\" phenomenal properties. See also my footnote <a href=\"https://forum.effectivealtruism.org/posts/AvubGwD2xkCD4tGtd/only-mammals-and-birds-are-sentient-according-to?commentId=yiqJTLfyPwCcdkTzn#fny2ydr0q063p\">here</a> on Graziano's Attention Schema Theory. So, these beliefs would explain why you're experiencing anything at all.</li><li>In the second, the physical properties that dispose us to have such beliefs could be what distinguishes experiences. This could be a kind of placeholder, but I suspect Frankish and Dennett would say that <i>any</i> reactive patterns and discriminations count, at least to some minimal degree.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2zhs6zypdcj\"><sup><a href=\"#fn2zhs6zypdcj\">[2]</a></sup></span>&nbsp;So, thermometers and bacteria could be minimally experiencing things, too, and that you're reacting and making any discriminations at all would explain why you're experiencing anything at all. Those with blindsight could still have visual experiences, but in a way that's not accessible for standard verbal report and possibly of a more simple/minimal kind.</li></ol><p>I suspect there's no real fact of the matter which approach is \"right\", but I'm more inclined towards 1.</p><p>If you have something else in mind by 'experience', I could try to respond to that.</p><p>&nbsp;</p><blockquote><p>Finally, I'll note this <a href=\"https://forum.effectivealtruism.org/posts/ZS9GDsBtWJMDEyFXh/eliezer-yudkowsky-is-frequently-confidently-egregiously?commentId=QLCevppMFisW9BqBE\">isn't the first time</a> we've had a Forum discussion about consciousness<a href=\"https://forum.effectivealtruism.org/posts/AvubGwD2xkCD4tGtd/only-mammals-and-birds-are-sentient-according-to?commentId=B7mdM3gFbxvmSJ6np#fn9o25cd55ci\"><sup>[1]</sup></a>&nbsp;- maybe it's something we could &nbsp;explore in a dialogue if it's something you think would be a valuable use of our time and potentially useful for those reading on the Forum? It definitely touches on a number of EA cause areas.</p></blockquote><p>I might be interested in having a (recorded) call, and then we can release it, the (edited) transcripts and/or notes. I spend way too long writing comments (including this one, and others on this post), so I think I shouldn't commit to a text-based discussion.</p><p>That being said, I'm not sure how useful this would be for other people, compared to them just reading writing by or listening to Graziano or Frankish. It was Graziano's papers (<a href=\"https://doi.org/10.1080/17588928.2020.1838468\">2021</a>, <a href=\"https://doi.org/10.1073/pnas.2116933119\">2022</a>, some clarifications in <a href=\"https://doi.org/10.1080/02643294.2020.1761782\">2020</a>) that made illusionism click for me,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7d0zlnl4sp4\"><sup><a href=\"#fn7d0zlnl4sp4\">[3]</a></sup></span>&nbsp;and I suspect I couldn't do a better job in explaining illusionism than to just linkpost or quote him, as well as <a href=\"https://doi.org/10.1007/s10670-019-00204-4\">Kammerer, 2022</a> (or just the short summary in <a href=\"https://link.springer.com/article/10.1007/s13164-021-00537-6#Sec20\">Shabasson, 2021, section 9</a>), which helps illustrate how the illusion could be so persistent.</p><p>I think the basic argument that convinced me roughly goes like this, based on Graziano (<a href=\"https://doi.org/10.1080/17588928.2020.1838468\">2021</a>, <a href=\"https://doi.org/10.1073/pnas.2116933119\">2022</a>), and from a draft I wrote but never posted:</p><p>Our claims of conscious experience result from the depiction/representation of information processed in our brains as having properties we believe as common to our conscious experiences, like phenomenality, subjectivity, qualitativeness or a nonphysical essence. There must be information in our brains depicting these properties, because without such information, we wouldn't consistently talk about these properties in the first place. Of course, maybe the information processing appears to have these properties <i>precisely because it actually has these properties</i>, and that's a realist position. However, the depiction itself and access to it by systems necessary for belief formation would be enough, and that's the illusionist position. There's no need to posit the actual existence of these properties, and in my view, there's currently no plausible explanation for the actual existence of these properties.</p><p>However, some things may make me unusually likely to accept illusionism:</p><ol><li>I suspect my direct intuitions about physical phenomena and consciousness are relatively weak, and I'm unusually inclined towards abstraction, so I've found little to count against illusionism for me. That consciousness just seems phenomenal, and red seems to be qualitative just doesn\u2019t count very strongly to me.</li><li>I have a very strong presumption in favour of physicalism,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7zwbsq97cdm\"><sup><a href=\"#fn7zwbsq97cdm\">[4]</a></sup></span>&nbsp;and every non-illusionist physicalist theory doesn't seem to me to offer a serious attempt to solve the hard problem, so the best option seems to be to dissolve it, hence illusionism. It sounds like you went the other way towards dualism through your dissatisfaction with physicalist theories, and I'd guess Chalmers did, too.</li></ol><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnauenc4tyd28\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefauenc4tyd28\">^</a></strong></sup></span><div class=\"footnote-content\"><p>But might leave out too many details of how this actually works in humans and other animals to be very satisfying.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2zhs6zypdcj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2zhs6zypdcj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>E.g. Frankish on continuity <a href=\"https://youtu.be/xZxcair9oNk?t=3242\">here</a> (54:00-57:37).</p><p>Also <a href=\"https://philpapers.org/rec/DENWTS-2\">Dennett</a> (2019, p. 54):</p><blockquote><p>Dogs presumably do not think there is something it is like to be them, even if there is. It is not that a dog thinks there isn\u2019t anything it is like to be a dog; the dog is not a theorist at all, and hence does not suffer from the theorists\u2019 illusion. The hard problem and meta-problem are only problems for us humans, and mainly just for those of us humans who are particularly reflective. In other words, dogs aren\u2019t bothered or botherable by problem intuitions. Dogs \u2013 and, for that matter, clams and ticks and bacteria \u2013 do enjoy (or at any rate benefit from) a sort of user illusion: they are equipped to discriminate and track only some of the properties in their environment.</p></blockquote><p>And <a href=\"https://youtu.be/3aIfyl6fO34?list=PLY_s7b9LrR8UCcPqL59XuIII68ALjgLt7&amp;t=4597\">Dennett thinks that chickens, octopuses and bees are definitely conscious</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7d0zlnl4sp4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7d0zlnl4sp4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>They were also the first explanations of illusionism I'd read. I haven't settled on Graziano's AST in particular, but it seems like a promising direction.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7zwbsq97cdm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7zwbsq97cdm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Just generally.</p><p>But also, other than panpsychism, where could we possibly draw a line for the presence and absence of the extra nonphysical property/properties? I can't imagine there being any plausible responses.</p><p>Or, if panpsychist, how could these properties possibly combine in ways that correspond to what our brains are doing and our specific judgements? Maybe some kind of property dualism?</p><p>I also can't imagine there being any plausible account of how the nonphysical affects the physical (or else we would already have identified it and adopted it into our physical ontology), so I'd be stuck with epiphenomenalism.</p><p>So, if not an illusionist, I'd have to be a (property dualist) epiphenomenalist, and it seems there would be no way to empirically distinguish such accounts from their illusionist counterparts, which just drop the nonphysical stuff. And whether or not there are different ethical implications between them, I can't imagine them being that decisive in practice. The difference just doesn't seem that interesting anymore, but I favour the metaphysically more parsimonious illusionism.</p><p>FWIW, I haven't read much Chalmers, and I learned about property dualism after illusionism already became intuitive to me.</p></div></li></ol>", "parentCommentId": "dRrhK6LMRckX2sRAF", "user": {"username": "MichaelStJules"}}, {"_id": "XxE86vQqA64YgZw8u", "postedAt": "2023-12-29T11:35:16.522Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>I did enjoy the discussion here in general. I hadn't heard of the \"illusionist\" stance before and it does sound quite interesting yet I do find it quite confusing as well.</p><p>I generally find there to be a big confusion about the relation of the self to what \"consciousness\" is. I was in this rabbit hole of thinking about it a lot and I realised I had to probe the edges of my \"self\" to figure out how it truly manifested. A 1000 hours into meditation some of the existing barriers have fallen down.&nbsp;<br><br>The complex attractor state can actually be experienced in meditation and it is what you would generally call a case of dependent origination or a self-sustaining loop (literally, lol). You can see through this by the practice of realising that the self-property of mind is co-created by your mind and that it is \"empty\". <a href=\"https://www.goodreads.com/en/book/show/25172403\">This is a big part of the meditation project</a>. (alongside loving-kindness practice, please don't skip the loving-kindness practice)<br><br>Experience itself isn't mediated by this \"selfing\" property, it is rather an artificial boundary we have created about our actions in the world for simplification reasons. (See <a href=\"https://www.lesswrong.com/s/LWJsgNYE8wzv49yEc/p/8oMF8Lv5jiGaQSFvo\">Boundaries</a> as a general way of this occurring.)<br><br>So, the self cannot be the ground of consciousness; it is rather a computationally optimal structure for behaving in the world. Yet realizing this fully is easiest done through your own experience, or through n=1 science. Meaning that to fully collect the evidence you will have to discover it through your own phenomenological experience. (which makes it weird to take into western philosophical contexts)<br><br>So, the self cannot be the ground and partly as a consequence of this and partly since <a href=\"https://www.lesswrong.com/posts/KpD2fJa6zo8o2MBxg/consciousness-as-a-conflationary-alliance-term\">consciousness is a very conflated term</a>, I like thinking more about different levels of sentience instead. At a certain threshold of sentience the \"selfing\" loop is formed.</p><p>The claims and evidence he's talking about may be true but I don't believe that justifies the conclusions that he draws from them.</p>", "parentCommentId": null, "user": {"username": "Jonas Hallgren"}}, {"_id": "9ZuvmAnSkpG62HMzb", "postedAt": "2023-12-29T21:27:10.220Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>I do think blindsight is pretty compelling evidence <i>for</i> conscious visual sensation in species with regular sight and blindsight as well as important evidence <i>against</i> conscious visual sensation in fish, frogs and reptiles, but I'm not sure what to make of it overall.</p><p>From <a href=\"https://aeon.co/essays/how-blindsight-answers-the-hard-problem-of-consciousness\">Humphrey's Aeon article</a>:</p><blockquote><p>In mammals, there are two main pathways from the eye to the brain: an evolutionarily ancient one \u2013 the descendant of the visual system used by fish, frogs and reptiles \u2013 that goes to the optic tectum in the mid-brain, and a newer one that goes up to the cortex. In Helen, the older visual system was still intact. If a frog can see using the optic tectum, why not Helen?</p></blockquote><p>So, fish, frogs and reptiles rely on a visual system that exists in humans (and other mammals and birds) that is not enough to generate conscious visual sensation in humans. The primary visual cortex seems necessary for conscious visual perception in mammals, and birds seem to have a functional analogue. (Are there studies of blindsight in birds?) On the other hand, fish, frogs and reptiles seem not to have any analogue. So, whatever functions or processes are necessary for conscious visual sensation in humans (and other mammals and birds) don't seem to be realized in fish, frogs and reptiles.</p><p>However, I can imagine some possibilities that could undermine this argument:</p><ol><li>The ancient system could have functions in fish, frogs and reptiles that the primary visual cortex in mammals has taken on, in a kind of evolutionary migration of some functions.</li><li>Whatever happens in the ancient system is not available in the \"global workspace\" in humans and so doesn't result in conscious visual sensation, but it could be in fish, frogs and/or reptiles. It might be that the primary visual cortex and the cortex in general added extra layers before the global workspace and executive function, and there was no need for the ancient system to keep feeding directly into the global workspace in mammals and birds. So those connections were lost or replaced with connections that run through the primary visual cortex, which are lost or inactive in blindsight.<ol><li>On the other hand, maybe fish, frogs and reptiles don't have any global workspace at all, either. <a href=\"https://doi.org/10.1016/j.neubiorev.2022.104865\">Nieder, 2022</a> writes \"In contrast, reptiles and amphibians show no sign of either working memory or volitional attention. Surprisingly, some species of teleost fishes exhibit elementary working memory and voluntary attention effects suggestive of possibly rudimentary forms of subjective experience. With the potential exception of honeybees, evidence for conscious processing is lacking in invertebrates.\" That being said, I don't think he cites any negative results, so this is not evidence of absence, just absence of evidence. And the fact that some fish seem to have working memory and voluntary attention suggests those fish do have something like a global workspace, despite no cortex and these functions being realized in the human cortex.</li></ol></li><li>Blindsighted humans do have conscious visual sensation, just not accessible for report.</li></ol><p>&nbsp;</p><p>Also related is Mason, G., &amp; J. Michelle Lavery. (2022). What Is It Like to Be a Bass? Red Herrings, Fish Pain and the Study of Animal Sentience. <i>Frontiers in Veterinary Science</i>, <i>9</i>. <a href=\"https://doi.org/10.3389/fvets.2022.788289\">https://doi.org/10.3389/fvets.2022.788289</a></p><p>From the abstract:</p><blockquote><p>After reviewing key consciousness concepts, we identify \u201cred herring\u201d measures that should not be used to infer sentience because also present in non-sentient organisms, notably those lacking nervous systems, like plants and protozoa (P); spines disconnected from brains (S); decerebrate mammals and birds (D); and humans in unaware states (U). These \u201cS.P.U.D. subjects\u201d can show approach/withdrawal; react with apparent emotion; change their reactivity with food deprivation or analgesia; discriminate between stimuli; display Pavlovian learning, including some forms of trace conditioning; and even learn simple instrumental responses. Consequently, none of these responses are good indicators of sentience. Potentially more valid are aspects of working memory, operant conditioning, the self-report of state, and forms of higher order cognition. We suggest new experiments on humans to test these hypotheses, as well as modifications to tests for \u201cmental time travel\u201d and self-awareness (e.g., mirror self-recognition) that could allow these to now probe sentience (since currently they reflect perceptual rather than evaluative, affective aspects of consciousness). Because \u201cbullet-proof\u201d neurological and behavioral indicators of sentience are thus still lacking, agnosticism about fish sentience remains widespread.</p></blockquote>", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "zAgXXeAjCspGxrEq9", "postedAt": "2023-12-30T01:06:45.413Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Good job. Posts like these are why I still check the EA forum despite the ridiculous nonsense (castles et al).&nbsp;</p>", "parentCommentId": null, "user": {"username": "kewlcats"}}, {"_id": "TwefuteHmoAHzB7hh", "postedAt": "2023-12-30T04:38:33.737Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>I feel like I should be writing and reading posts about AI but honestly I am too intimidated to go near that topic.</p>\n", "parentCommentId": "zAgXXeAjCspGxrEq9", "user": {"username": "ben.smith"}}, {"_id": "3vwnKHex3CJKJvnBt", "postedAt": "2023-12-30T04:58:49.193Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Humphrey's argument fish aren't conscious doesn't only rest on their not having the requisite brain structures, because as you say, it is <em>possible</em> consciousness could have developed in their own structures in ways that are simply distinct from our own. But then, Humphrey would ask, if they have visual sensations, why are they uninterested in play? When you have sensations, play can teach you a lot about your own sensory processes and subsequently use what you've learned to leverage your visual sensations to accomplish objectives. It seems odd that an organism that can learn (as almost all can) would evolve visual sensations but not a propensity to play in a way that helps them to learn about those sensations.</p>\n<p>Perhaps fish just don't benefit from learning more about their visual sensations. The sensations are adaptive, but learning about them confers no additional adaptive advantage. That seems a stretch to me, because it's hard for me to imagine sensations being adaptive without learning and experimenting with them conferring additional advantage.</p>\n<p>You could also respond by citing examples where fish <em>can</em> play, and are motivated to sensation-seek, as you already have, and I think if Humphrey believes your examples he would find that persuasive evidence about those organisms consciousness.</p>\n", "parentCommentId": "9ZuvmAnSkpG62HMzb", "user": {"username": "ben.smith"}}, {"_id": "i7jrQPtLDuQQ7hnrz", "postedAt": "2023-12-30T06:38:33.622Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Does he spell out more why it's useful to learn more about your own sensations? Also, couldn't this apply to any perception that feeds into executive functions/cognitive control, conscious or not?</p>\n<p>What if sensory play is just very species-specific? Do the juveniles of every mammal and bird species play? Would he think the species without play aren't conscious, even if they have basically the same sensory neural structures?</p>\n<p>A motivation to engage in (sensory) play has resource costs. Playing uses energy and time, and it takes energy to build the structures responsible for the motivation to play. And the motivation could be risky without a safe environment, e.g. away from predators or protection by parents and with enough food. Fish larvae don't seem to get such safe environments.</p>\n<p>I guess a thesis he's stated elsewhere is that it's the function of consciousness to matter. This is the adaptive belief it causes. So, conscious sensations should just be interesting to animals with them, and maybe without that interest, there's no benefit to conscious sensation. This doesn\u2019t seem crazy to me, and it seems pretty plausible with my sympathies to illusionism. Consciousness illusions should be adaptive in some way.</p>\n<p>But, this only tells me about conscious sensation. Animals without conscious sensation could still have conscious pleasure, unpleasantness and desires, which realize the mattering and interest. And animals don't engage in play to explore unpleasantness and aversive desire. So what are the benefits of unpleasantness and aversive desire being conscious as opposed to unconscious? And could there be similar benefits for conscious sensation? If there are, then sensory play may not be (evolutionarily) necessary for consciousness in general or conscious sensation in particular after all.</p>\n", "parentCommentId": "3vwnKHex3CJKJvnBt", "user": {"username": "MichaelStJules"}}, {"_id": "5u5yw7pri4CZys52C", "postedAt": "2023-12-30T19:01:59.632Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>To me \"conscious pleasure\" without conscious sensation almost sounds like \"the sound of one hand clapping\". Can you have pure joy unconnected to a particular sensation? Maybe, but I'm sceptical. First, the closest I can imagine is calm joyful moments during meditation, or drug-induced euphoria, but in both cases I think it's at least plausible there are associated sensations. Second, to me, even the purest moments of simple joy seem to be sensations in themselves, and I don't know if there's any conscious experience without sensations.</p>\n<p>Humphrey theorises that the evolutionary impulse for conscious sensations includes (1) the development of a sense of self (2) which in turn allows for a sense of other, and theory of mind. He thinks that mere unconscious perception can't be reasoned about or used to model others because, being unconscious, it is inaccessible by the global workspace for that kind of use. in contrast, conscious sensations are accessible in the global workspace and can be used to imagine the past, future, or what others are experiencing. The cognitive and sensory empathy that allows can enable an organism to behave socially, to engage in deceit or control, to more effectively care for another, to anticipate what a predator can and can't see, etc.</p>\n<p>I would add that conscious sensation allows for more abstract processing of sensations, which enables tool use and other complex planning like long term planning in order to get the future self more pleasurable sensations. Humphrey doesn't talk about that much, perhaps because it's only a small subset of conscious species that have been observed doing those things, so perhaps mere consciousness isn't sufficient to engage in them (some would argue you need language to do good long term planning and complex abstraction).</p>\n<p>Humphrey believes that mammals in general do engage in play, which he thinks <em>all</em> (but not only) conscious animals do, and that they also engage in sensation-seeking (e.g. sliding down slopes or moving fast through the air for no reason), which he thinks <em>only</em> (but not all) conscious animals do. And he'd say the same thing about birds, and the fact that those behaviors' distribution over species lines up nicely with the species with neural structures he thinks generates consciousness he treats as additional confirmation of his theory.</p>\n<p>Animals do engage in play with unpleasant experiences, e.g., playfighting can include moderately unpleasant sensations. I suppose the benefits of those experiences being conscious might be to form more sophisticated strategies of avoiding them in future. It isn't that Humphrey thinks play is necessary for conscious to emerge, it's that he thinks all conscious animals are motivated to engage in play.</p>\n<p>I feel this last answer maybe hasn't answered all your questions but I was a bit confused by your last paragraph, which might have arisen out of an understandable misunderstanding of the claim about consciousness and play.</p>\n", "parentCommentId": "i7jrQPtLDuQQ7hnrz", "user": {"username": "ben.smith"}}, {"_id": "pzFoLLbW7Dev9Yhjx", "postedAt": "2023-12-30T22:23:14.915Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>That makes sense \u2014 I appreciate you doing that work &amp; making calls about what to include; I bet there's a lot I'm missing!!</p>\n<p>Ah, I wrote &amp; meant 'a necessary <em>condition</em> for' \u2014 I hadn't misunderstood the argument in the way you're worried about in your second paragraph (but perhaps a useful clarification for anyone reading!)</p>\n<p>My problem is I don't buy that 'any animal that is sentient would be motivated to play' \u2014 and ultimately I think the additional explanation you've provided here, about shared ancestry and neurophysiology, is interesting &amp; relevant to think about re: which if any animals are sentient, but I think it just boils down to:</p>\n<blockquote>\n<ol>\n<li>Humans are sentient</li>\n<li>Humans have a shared ancestry and neurophysiology with other animals</li>\n<li>?(Sentience depends on neurophysiology)? [fn]</li>\n</ol>\n<p>C. Other animals are likely to be sentient</p>\n<p>C2. Other animals are more likely to be sentient in accordance with the extent to which they share human ancestry and neurophysiology.</p>\n</blockquote>\n<p>This argument, while IMO important/pretty compelling as a reason to start of with some moderate credence on animal sentience, doesn't do that much, and certainly couldn't, on its own, convince me of any necessary conditions for sentience \u2014 certainly not sensory play.</p>\n<p>It also doesn't do anything to convince me that non-bird non-mammals are sufficiently different (in terms of shared ancestry and neurophysiology) from humans, such that we should think they're not sentient.</p>\n<p>[fn] I'm unsure from your summary if Humphrey means to claim this or not, sorry!</p>\n", "parentCommentId": "pru2H2MPEvmuBBXvt", "user": {"username": "Bella_Forristal"}}, {"_id": "nbWFBRGtGwvocFXKr", "postedAt": "2023-12-30T22:43:31.261Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Thanks, this is helpful!</p><blockquote><p>Can you have pure joy unconnected to a particular sensation? Maybe, but I'm sceptical. First, the closest I can imagine is calm joyful moments during meditation, or drug-induced euphoria, but in both cases I think it's at least plausible there are associated sensations. Second, to me, even the purest moments of simple joy seem to be sensations in themselves, and I don't know if there's any conscious experience without sensations.</p></blockquote><p>I would say thinking of something funny is often pleasurable. Similarly, thinking of something sad can be unpleasant. And this thinking can just be inner speech (rather than visual imagination). Inner speech is of course sensory, but it's not the <i>sensations</i> of the inner speech, and instead your high-level interpretation of the meaning that causes the pleasure. (There might still be other subtle sensations associated with pleasure, e.g. from changes to your heart rate, body temperature, facial muscles, or even simulated smiling.)</p><p>Also, people can just be in good or bad moods, which could be pleasant and unpleasant, respectively, but not really consistently simultaneous with any particular sensations.</p><p>&nbsp;</p><blockquote><p>I would add that conscious sensation allows for more abstract processing of sensations, which enables tool use and other complex planning like long term planning in order to get the future self more pleasurable sensations. Humphrey doesn't talk about that much, perhaps because it's only a small subset of conscious species that have been observed doing those things, so perhaps mere consciousness isn't sufficient to engage in them (some would argue you need language to do good long term planning and complex abstraction).</p></blockquote><p>Maybe some other potential capacities that seem widespread among mammals and birds (and not really investigated much in others?) that could make use of conscious sensation (and conscious pleasure and unpleasantness):</p><ol><li>episodic(-like) memory (although it's not clear this is consciously experienced in other animals)</li><li>working memory</li><li>voluntary attention control</li><li>short-term planning (which benefits from the above)</li></ol><p>FWIW, mammals seem able to discriminate anxiety-like states from other states.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbllwoi2ok6j\"><sup><a href=\"#fnbllwoi2ok6j\">[1]</a></sup></span></p><blockquote><p>Animals do engage in play with unpleasant experiences, e.g., playfighting can include moderately unpleasant sensations.</p></blockquote><p>I don't think they are motivated to explore things they find unpleasant or aversive, or unpleasantness or aversion themselves. Rather, it just happens sometimes when they're engaging in the things they are motivated to do for other reasons.</p><blockquote><p>I suppose the benefits of those experiences being conscious might be to form more sophisticated strategies of avoiding them in future.</p></blockquote><p>Ya, this seems plausible to me. But this also seems like the thing that's more morally important to look into directly. Maybe frogs' vision is blindsight, their touch and hearing are unconscious, etc., so they aren't motivated to engage in sensory play, but they might still benefit from conscious unpleasantness and aversion for more sophisticated strategies to avoid them. And they might still benefit from conscious pleasure for more sophisticated strategies to pursue pleasure. The conscious pleasure, unpleasantness and desire seem far more important than conscious sensations.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbllwoi2ok6j\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbllwoi2ok6j\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://doi.org/10.1258/002367795780739999\"><u>Carey and Fry (1995)</u></a> show that pigs generalize the discrimination between non-anxiety states and drug-induced anxiety to non-anxiety and anxiety in general, in this case by pressing one lever repeatedly with anxiety, and alternating between two levers without anxiety (the levers gave food rewards, but only if they pressed them according to the condition). Similar experiments were performed on rats, as discussed in&nbsp;<a href=\"https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/9465/Sanchez-Suarez_Walter_201601_PhD.pdf?sequence=1&amp;isAllowed=y\"><u>S\u00e1nchez-Su\u00e1rez, 2016</u></a>, in section 4.d., starting on p.81. Rats generalized from hangover to morphine withdrawal and jetlag, from high doses of cocaine to movement restriction, from an anxiety-inducing drug to aggressive defeat and predator cues. Of course, anxiety has physical symptoms, so maybe this is what they're discriminating, not the negative affect or aversive desire, although non-anxiolytic anticonvulsants didn\u2019t block the effects, so convulsions in particular seem unlikely to explain the difference.</p></div></li></ol>", "parentCommentId": "5u5yw7pri4CZys52C", "user": {"username": "MichaelStJules"}}, {"_id": "TzLaiwaxZH9zriq4L", "postedAt": "2023-12-31T01:27:00.750Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>Yes I see that is a reasonable thing to not be convinced about and I am not sure I can do justice to the full argument here. I don't have the book with me, so anything else I tell you is pulling from memory and strongly prone to error. Elsewhere in this comments section I said</p>\n<blockquote>\n<p>When you have sensations, play can teach you a lot about your own sensory processes and subsequently use what you've learned to leverage your visual sensations to accomplish objectives. It seems odd that an organism that can learn (as almost all can) would evolve visual sensations but not a propensity to play in a way that helps them to learn about those sensations.</p>\n</blockquote>\n<p>And</p>\n<blockquote>\n<p>Humphrey theorises that the evolutionary impulse for conscious sensations includes (1) the development of a sense of self (2) which in turn allows for a sense of other, and theory of mind. He thinks that mere unconscious perception can't be reasoned about or used to model others because, being unconscious, it is inaccessible by the global workspace for that kind of use. in contrast, conscious sensations are accessible in the global workspace and can be used to imagine the past, future, or what others are experiencing. The cognitive and sensory empathy that allows can enable an organism to behave socially, to engage in deceit or control, to more effectively care for another, to anticipate what a predator can and can't see, etc.</p>\n</blockquote>\n<p>I believe the idea is something like sentience enables a lot more opportunity to learn about the world, and learning opportunities can be obtained through play. Not taking those opportunities if you're able is sort of like leaving free adaptive money on the table.</p>\n", "parentCommentId": "pzFoLLbW7Dev9Yhjx", "user": {"username": "ben.smith"}}, {"_id": "xT8wXf8YGKNE52SMr", "postedAt": "2023-12-31T22:37:46.146Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<p>To give a concrete example, my infant daughter can spend hours bashing her toy keyboard with 5 keys. It makes a sound every time. She knows she isn't getting any food, sleep, or any other primary reinforcer to do this. But she gets the sensations of seeing the keys light up and a cheerful voice sounding from the keyboard's speaker each time she hits it. I suppose the primary reinforcer just is the cheery voice and the keys lighting up (she seems to be drawn to light--light bulbs, screens, etc).&nbsp;</p><p>During this activity, she's playing, but also learning about cause and effect--about the reliability of the keys reacting to her touch, about what kind of touch causes the reaction, and how she can fine-tune and hone her touch to get the desired effect. I think we can agree that many of these things are transferable skills that will help her in all sorts of things in life over the next few years and beyond?</p><p>I'm sort of conflating two things that Humphrey describes separately: sensory play, and sensation seeking. In this example it's hard to separate the two. But Humphrey ties them both to consciousness, and perhaps there's still something we can learn from about an activity that combines the two together.</p><p>In this case, the benefits of play are clear, and I guess the further premise is that consciousness adds additional motivation for sensory play because, e.g., it makes things like seeing lights, hearing cheery voices much more vivid and hence reinforcing, and allows the incorporation of those things with other systems that enable action planning about how to get the reinforcers again, which makes play more useful.</p><p>I agree this argument is pretty weak, because we can all agree that even the most basic lifeforms can do things like approach or avoid light. Humphrey's argument is something like the particular neurophysiology that generates consciousness also provides the motivation and ability for play. I think I have said about as much as I can to repeat the argument and you'd have to go directly to Humphrey's own writing for a better understanding of it!</p>", "parentCommentId": "pzFoLLbW7Dev9Yhjx", "user": {"username": "ben.smith"}}, {"_id": "rotydXRXonMCAHH5y", "postedAt": "2023-12-31T22:50:48.337Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<blockquote><p>&nbsp;</p><p>I would say thinking of something funny is often pleasurable. Similarly, thinking of something sad can be unpleasant. And this thinking can just be inner speech (rather than visual imagination)....Also, people can just be in good or bad moods, which could be pleasant and unpleasant, respectively, but not really consistently simultaneous with any particular sensations.</p></blockquote><p>&nbsp;</p><p>I think most of those things actually can be reduced to sensations; moods can't be, but then, are moods consciously experienced, or do they only predispose us to interpret conscious experiences more positively or negatively?</p><p>(Edit: another set of sensations you might overlook when you think about conscious experience of mood are your bodily sensations: heart rate, skin conductivity, etc.)</p><blockquote><p>But this also seems like the thing that's more morally important to look into directly. Maybe frogs' vision is blindsight, their touch and hearing are unconscious, etc., so they aren't motivated to engage in sensory play, but they might still benefit from conscious unpleasantness and aversion for more sophisticated strategies to avoid them. And they might still benefit from conscious pleasure for more sophisticated strategies to pursue pleasure.</p></blockquote><p>They \"might\" do, sure, but what's your expectation they in fact will experience conscious pleasantness devoid of sensations? High enough to not write it off entirely, to make it worthwhile to experiment on, and to be cautious about how we treat those organisms in the meantime--sure. I think we can agree on that.&nbsp;</p><p>But perhaps we've reached a sort of crux here: is it possible, or probable, that organisms could experience conscious pleasure or pain without conscious sensation? It seems like a worthwhile question. After reading Humphrey I feel like it's certainly possible, but I'd give it maybe around 0.35 probability. As I said in OP, I would value more research in this area to try to give us more certainty.&nbsp;</p><p>If your probability that conscious pleasure and pain can exist without conscious sensation is, say, over 0.8 or so, I'd be curious about what leads you to believe that with confidence.</p>", "parentCommentId": "nbWFBRGtGwvocFXKr", "user": {"username": "ben.smith"}}, {"_id": "ewBZzCFdRjN52PHvB", "postedAt": "2024-01-01T20:45:11.155Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<blockquote><p>I think most of those things actually can be reduced to sensations</p></blockquote><p>What do you mean by \"reduced to\"? It's tricky to avoid confounding here, because we're constantly aware of sensations and our experiences of pleasure and unpleasantness seem typically associated with sensations. But I would guess that pleasure and unpleasantness <i>aren't always because</i> of the conscious sensations, but these can have <i>the same unconscious perceptions</i> as a common cause.</p><p>Apparently even conscious physical pain affect (unpleasantness) can occur without pain sensation, but this is not normal and recorded cases seem to be the result of brain damage (<a href=\"https://doi.org/10.1016/S0304-3959(99)00012-3\">Ploner et al., 1999</a>, <a href=\"https://doi.org/10.1016/j.pain.2012.01.018\">Uhelski et al., 2012</a>).</p><blockquote><p>moods can't be, but then, are moods consciously experienced, or do they only predispose us to interpret conscious experiences more positively or negatively?</p></blockquote><p>I'm not sure, and that's a great question! Seems pretty likely these are just dispositions. I was also thinking of separation anxiety as an unpleasant experience with no specific sensations in other animals (assuming they can't imagine their parents, when they are away), but this could just be more like a mood that disposes them to interpret their perceptions or sensations more negatively/threatening.</p><p>&nbsp;</p><blockquote><p>They \"might\" do, sure, but what's your expectation they in fact will experience conscious pleasantness devoid of sensations? (...) If your probability that conscious pleasure and pain can exist without conscious sensation is, say, over 0.8 or so, I'd be curious about what leads you to believe that with confidence.</p></blockquote><p>Thanks for pushing on this. There are multiple standards at which I could answer this, and it would depend on what I (or we) want \"conscious\" to mean.</p><p>With relatively high standards for consciousness like Humphrey seems to be using, or something else at least as strict as having a robust global workspace (with some standard executive functions, like working memory or voluntary attention control), I'd assign maybe 70%-95% probability to the <i>in principle</i> possibility based on introspection, studies of pain affect without pain sensation, and imagining direct stimulation of pleasure systems, or with drugs or meditation. However, I'd be very surprised (&lt;15%) if there's any species with conscious pleasure or unpleasantness without the species generally also having conscious sensations. It doesn't seem useful for an animal to be conscious of pleasure or unpleasantness without also being conscious of their causes, which seems to require conscious sensation. Plus, whatever mechanisms are necessary for consciousness per se could be used for both perceptions/sensations and pleasure.</p><p>With low standards, e.g. a sensation is a perception + a belief that the perception matters, and pleasure is a positive judgement (as a belief), and low standards for what counts as a belief, I'd be less confident either way for both the in principle and in practice questions. I'd mostly have in mind similar intuitions, arguments and other evidence as above, but the evidence just seems weaker and less reliable here. But I'd also be more confident that frogs, fish and invertebrates have conscious pleasure and unpleasantness and conscious sensations.</p><p>You could also mix low standards for one but high standards for the other, but I'd give these possibilities less weight.</p>", "parentCommentId": "rotydXRXonMCAHH5y", "user": {"username": "MichaelStJules"}}, {"_id": "4MdmyjJjZAry32EtH", "postedAt": "2024-01-01T22:38:56.004Z", "postId": "AvubGwD2xkCD4tGtd", "htmlBody": "<blockquote><p>But I would guess that pleasure and unpleasantness <i>isn't always because</i> of the conscious sensations, but these can have <i>the same unconscious perceptions</i> as a common cause.</p></blockquote><p>This sounds right. My claim is that there are all sorts of unconscious perceptions an valenced processing going on in the brain, but all of that is only experienced consciously once there's a certain kind of recurrent cortical processing of the signal which can loosely be described as \"sensation\". I mean that <i>very</i> loosely; it even can include memories of physical events or semantic thought (which you might understand as a sort of recall of auditory processing). Without that recurrent cortical processing modeling the reward and learning process, probably all that midbrain dopaminergic activity does not get consciously perceived. Perhaps it does, indirectly, when the dopaminergic activity (or lack thereof) influences the sorts of sensations you have.</p><p>But I'm getting <i>really</i> speculative here. I'm an empiricist and my main contention is that there's a live issue with unknowns and researchers should figure out what sort of empirical tests might resolve some of these questions, and then collect data to test all this out.</p>", "parentCommentId": "ewBZzCFdRjN52PHvB", "user": {"username": "ben.smith"}}]