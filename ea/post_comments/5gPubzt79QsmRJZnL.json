[{"_id": "eWXFHENFEKmytiD5f", "postedAt": "2021-11-14T10:40:38.504Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<blockquote><p>Tradeoffs like the <a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives#The_Very_Repugnant_Conclusion\"><u>Very Repugnant Conclusion</u></a> (VRC) are <a href=\"https://reducing-suffering.org/omelas-and-space-colonization/\"><u>not</u></a> only theoretical, because arguments like that of Bostrom (2003) imply that the stakes may be astronomically high in practice. When non-minimalist axiologies find the VRC a worthwhile tradeoff, they would presumably also have similar implications on an arbitrarily large scale. Therefore, we need to have an inclusive discussion about the extent to which the subjective problems (e.g. extreme suffering) of some can be \u201c<a href=\"https://centerforreducingsuffering.org/research/on-purported-positive-goods-outweighing-suffering/\"><u>counterbalanced</u></a>\u201d by the \u201cgreater (intrinsic) good\u201d for others, because this has direct implications for what kind of large-scale space colonization could be called \u201cnet positive\u201d.</p></blockquote><p>&nbsp;</p><p>This seems wrong to me, and confusing 'finding the VRC counter-intuitive' with 'counterbalancing (/extreme) bad with with good in any circumstance is counterintuitive' (e.g. the linked article to Omelas) is unfortunate - especially as this error has been repeated a few times in and around SFE-land.</p><p>&nbsp;</p><p><strong>First</strong>, what is turning the screws in the VRC is primarily the <i>aggregation</i>, not the (severe/) suffering. If the block of 'positive lives/stuff' in the VRC was high magnitude - say about as much (or even more) above neutral as the block of 'negative lives/stuff' lie below it - there is little about this more Omelas-type scenario a classical utilitarian would find troubling. \"N terrible lives and k*N wonderful lives is better than N wonderful lives alone\" seems plausible for sufficiently high values of k. (Notably, 'Minimalist' views seem to fare worse as it urges no value of k - googleplexes, TREE(TREE(3)), 1/P(Randomly picking the single 'wrong' photon from our light cone a million times consecutively), etc. would be high enough.)</p><p>The challenge of the V/RC is the counter-intuitive 'nickel and diming' where a great good or bad is outweighed by a vast multitude of small/trivial things. \"N terrible lives and c*k*N barely-better-than-nothing lives is better than N wonderful lives alone\" remains counter-intuitive to many who accept the first scenario (for some value of k) basically regardless of how large you make c. The natural impulse (at least for me) is to wish to discount trivially positive wellbeing rather than saying it can outweigh severe suffering if provided in sufficiently vast quantity.&nbsp;<br><br>If it were just 'The VRC says you can counterbalance severe suffering with happiness' <i>simpliciter</i> &nbsp;which was generally counterintuitive, we could skip the rigmarole of A, A+, B etc. and just offer Omelas-type scenarios (as Tomasik does in the linked piece) without stipulating the supposedly outweighing good stuff comprises a<i> lot</i> of trivial well-being.</p><p>&nbsp;</p><p><strong>Second, </strong>although scenarios where one may consider counterbalancing (/severe) suffering with happiness <i>in general</i> may not be purely theoretical (either now or in the future) the likelihood of something closely analogous to the VRC <i>in particular</i> looks very remote. In terms of 'process' the engine of the counter-intuitiveness relies on being able to parcel out good stuff in arbitrarily many arbitrarily small increments rather than in smaller more substantial portions; in terms of 'outcome' one needs a much smaller set of terrible lives outweighed by a truly vast multitude of just-about-better-than-nothing ones. I don't see how either arise on credible stories of the future.&nbsp;</p><p>&nbsp;</p><p><strong>Third, </strong>there are other lines classical utilitarians or similar can take in response to the VRC besides biting the bullet (or attempting to undercut our intuitive responses): critical level views, playing with continuity, and other anti-aggregation devices to try and preserve trading-off <i>in general</i> but avoid the nickel and diming issues of the VRC <i>in particular </i>. Obviously, these themselves introduce other challenges (so much so I'm more inclined to accept the costly counter-examples than the costs of (e.g.) non-continuity) and surveying all this terrain would be a gargantuan task far beyond the remit of work introducing a related but distinct issue.&nbsp;<br><br>But I bring this up because I anticipate the likely moves you will make to avoid the counter-example Shulman and I have brought up will be along the lines of anti-aggregationist moves around lexicality, thresholds, and whatnot. If so, what is good for the goose is good for the gander: it seems better to use similarly adapted versions of total utilitarianism as a 'like for like' comparison. 'Lexical threshold total utilitarianism', which lexically de-prioritises dis/value below some magnitude can <i>accept</i> mere addition, <i>accept </i>trading off suffering for sufficient (non-trivial) happiness, but <i>avoid</i> both the RC and VRC. This seems a better point of departure for weighing up minimalism or not, rather than discussing counter-examples to one or the other view which only apply given an (<i>ex hypothesi</i>) mistaken account of how to aggregate harms and benefits.</p>", "parentCommentId": null, "user": {"username": "Gregory_Lewis"}}, {"_id": "CQq2AzRjEvEbbdniF", "postedAt": "2021-11-15T03:30:23.576Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<p>EDIT:</p><blockquote><p>But I bring this up because I anticipate the likely moves you will make to avoid the counter-example Shulman and I have brought up will be along the lines of anti-aggregationist moves around lexicality, thresholds, and whatnot.</p></blockquote><p>Do you mean trivial pains adding up to severe suffering? I can see how if you would accept lexicality or thresholds to prevent this, you could do the same to prevent trivial pleasures outweighing severe suffering or greater joys.</p><p>&nbsp;</p><p>My original comment follows.</p><hr><p>I think your <strong>first and third</strong> points are mostly right, but I would add that minimalist axiologies can avoid the (V)RC <i>without</i> (arbitrary) critical levels, (arbitrary) thresholds, giving up continuity, or giving up additivity/separability, which someone might find as counterintuitive as the VRC. Views like these tend to look more arbitrary, or assuming transitivity, the independence of irrelevant alternatives and a far larger unaffected population, often <a href=\"https://www.tandfonline.com/doi/full/10.1080/00048402.2021.1962375\">reduce to solipsism</a> or <a href=\"https://globalprioritiesinstitute.org/christian-tarsney-non-additive-axiologies-in-large-worlds/\">recommend totally ignoring value that's (weakly or strongly) lexically dominated</a> in practice. So, if you find the (V)RC, and these aggregation tricks or their implications very counterintuitive, then minimalist and person-affecting views will look better than otherwise (not necessarily best), and classical utilitarianism will look worse than otherwise (but potentially still best overall or better than minimalist axiologies, if the other points in favour are strong enough).</p><p>Furthermore, the VRC is distinguished from the RC by the addition of severe suffering. Someone might find the VRC far worse than the RC (e.g. the person who named it, adding the \"Very\" :P), and if they do, that may indeed say something about their views on suffering and bad lives, and <i>not just</i> about the aggregation of the trivial vs values larger in magnitude. I do suspect like you that considering Omelas (or tradeoffs between a more even number of good and bad lives) would usually already get at this, though, but maybe not always.</p><p>&nbsp;</p><p>That being said, personally, I am also separately sympathetic to lexicality (and previously non-additivity, but less so now because of the arguments in the papers I cited above), but not because of the RC or VRC, but because of direct intuitions about torture vs milder suffering (dust specks or even fairly morally significant suffering). EDIT: I guess this is the kind of \"counter-example\" you and Shulman have brought up?</p><p>&nbsp;</p><p>On your <strong>second</strong> point, I don't think something like the VRC is remote, although I wouldn't consider it my best guess for the future. If it turns out that it's more efficient to maximize pleasure (or value generally) in a huge number of tiny systems that produce very little value each, classical utilitarians may be motivated to do so at substantial cost, including sacrificing a much higher average welfare and ignoring s-risks. So, you end up with astronomically many more marginally good lives and a huge number of additional horrible lives (possibly astronomically many, although far fewer than the marginally good lives) and missing out on many very high welfare lives. This is basically the VRC. This seems unlikely unless classical utilitarians have majority control over large contiguous chunks of space in the future.</p>", "parentCommentId": "eWXFHENFEKmytiD5f", "user": {"username": "MichaelStJules"}}, {"_id": "KvGHmZWaafic4Mfds", "postedAt": "2021-11-15T03:37:22.146Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<p>I thought the Mere Addition Paradox and the Repugnant Conclusion were the same thing?</p><p>Either way, I do think it's useful to distinguish two versions as you have, since the main reason I find the RC counterintuitive is already explained by my intuitions about the Mere Addition Paradox, and the RC brings in additional considerations about number vs average value, which are irrelevant to me.</p>", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "aQmTtREdGhBoRGmL7", "postedAt": "2021-11-15T16:43:14.091Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<blockquote><p>Do you mean trivial pains adding up to severe suffering? I can see how if you would accept lexicality or thresholds to prevent this, you could do the same to prevent trivial pleasures outweighing severe suffering or greater joys.</p></blockquote><p>Yeah, that's it. As you note these sorts of moves seem to have costs elsewhere, but if one thinks on balance they nonetheless should be accepted, then the V/RC isn't really a strike against 'symmetric axiology' <i>simpliciter</i>, but merely 'symmetric axiologies with a mistaken account of aggregation'. If instead 'straightforward/unadorned' aggregation is the right way to go, then the V/RC is a strike against symmetric views and a strike in favour of minimalist ones; but 'straightforward' aggregation can also produce highly counter-intuitive results for minimalist views which symmetric axiologies avoid (e.g. \"better N awful lives than TREE(N+3) lives of perfect bliss and a pin-prick\").&nbsp;</p><p>Hence (per <strong>3</strong>) I feel the OP would be trying to have it both ways if they don't discuss argumentative resources which could defend a rival theory from objections they mount against it, yet subsequently rely upon those same resources to respond to objections to their preferred theory.</p><p>(Re. <strong>2</strong>, perhaps it depends on the value of \"tiny\" - my intuition is the dynamic range of (e.g.) human happiness is much smaller than that for future beings, so 'very small' on this scale would still typically be greatly above the 'marginally good' range by the lights of classical util. If (e.g.) commonsenically happy human lives/experiences are 10, joyful future beings could go up to 1000, and 'marginally good' is anything &lt;1, we'd be surprised to find the optimal average for the maximal aggregate is in the marginally good range. Adding in the 'V' bit to this RC adds a further penalty).&nbsp;</p>", "parentCommentId": "CQq2AzRjEvEbbdniF", "user": {"username": "Gregory_Lewis"}}, {"_id": "zKfEPsgTdqjrgpiwe", "postedAt": "2021-11-15T17:31:54.129Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<p>That all seems fair to me.</p>\n<p>With respect to 2, I'm thinking something on the order of insect brains. There are reasons to expect pleasure to scale sublinearly with brain size even in artificial brains optimized for pleasure, e.g. a lot of unnecessary connections that don't produce additional value, greater complexity in building larger brains without getting things wrong, or even giving weight to the belief that integrating minds actually reduces value, say because of bottlenecks in some of the relevant circuits/functions. Smaller brains are easier/faster to run in parallel.</p>\n<p>This is assuming the probability of consciousness doesn't dominate. There may also be scale efficiencies, since the brains need containers and to be connected to things (even digitally?) or there may be some other overhead.</p>\n<p>So, I don't think it would be too surprising to find the optimal average in the marginally good range.</p>\n", "parentCommentId": "aQmTtREdGhBoRGmL7", "user": {"username": "MichaelStJules"}}, {"_id": "hQJR3nK2QDM4MDMD5", "postedAt": "2021-11-16T18:27:06.268Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<p>Yeah, I guess some people use the names interchangeably.  I agree that it can be useful to look at them separately, which was done in Fehige (<a href=\"https://www.fehige.info/pdf/A_Pareto_Principle_for_Possible_People.pdf\">1998</a>). Their difference is also described in the following way (on <a href=\"https://en.wikipedia.org/wiki/Mere_addition_paradox#Criticisms_and_responses\">Wikipedia</a>):</p><blockquote>[Parfit] claims that on the face of it, it may not be absurd to think that B is better than A. Suppose, then, that B is in fact better than A ... . It follows that this revised intuition must hold in subsequent iterations of the original steps. For example, the next iteration would add even more people to B+, and then take the average of the total happiness, resulting in C-. If these steps are repeated over and over, the eventual result will be Z, a massive population with the minimum level of average happiness; this would be a population in which every member is leading a life barely worth living. Parfit claims that it is Z that is the repugnant conclusion.</blockquote>", "parentCommentId": "KvGHmZWaafic4Mfds", "user": {"username": "Teo Ajantaival"}}, {"_id": "J9wbQ2gH8gKn23kMY", "postedAt": "2021-11-16T18:38:53.648Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<p>(Edit: Added a note(*)  on minimalist views and the extended VRC of Budolfson &amp; Spears.)</p><p>Thanks for highlighting an important section for discussion. Let me try to respond to your points. (I added the underline in them just to unburden the reader\u2019s working memory.)</p><br><blockquote>This seems wrong to me,</blockquote><p>The quoted passage contained many claims; which one(s) seemed wrong to you?</p><br><blockquote>and <u>confusing 'finding the VRC counter-intuitive' with 'counterbalancing (/extreme) bad with with good in any circumstance is counterintuitive'</u> (e.g. the linked article to Omelas) is unfortunate - especially as this error has been repeated a few times in and around SFE-land.</blockquote><p>My argument was rather the other way around. Namely, if we accept <em>any</em> kind of counterbalancing of harms with <u><a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives#Isolated_value_containers\">isolated</a></u> goods, then CU-like views would imply that it is net positive to create space colonies that are<em> at least as good</em> as the <u>hellish + barely positive lives</u> of the VRC. And given arguments like <u><a href=\"https://forum.effectivealtruism.org/tag/astronomical-waste\">astronomical waste</a></u> (<strong>AW</strong>) (Bostrom, <a href=\"https://www.nickbostrom.com/astronomical/waste.html\">2003</a>), the justified harm could be arbitrarily vast as long as the isolated positive lives are sufficiently numerous. (Tomasik\u2019s <u><a href=\"https://reducing-suffering.org/omelas-and-space-colonization/\">Omelas</a></u> article does not depend on the VRC, but speaks of the risk of astronomical harms given the views of Bostrom, which was also my intended focus.)</p><p>(To avoid needless polarization and promote fruitful dialogue, I think it might be best to generally avoid using \u201cdisjointing\u201d territorial metaphors such as \u201cSFE-land\u201d or \u201cCU-land\u201d, not least considering the significant <u><a href=\"https://forum.effectivealtruism.org/posts/BXRNGrBNxemi3qGMp/common-ground-for-longtermists\">common ground</a></u> among people in the EA(-adjacent) community.)</p><br><blockquote><strong>First</strong>, what is turning the screws in the VRC is primarily the <em>aggregation</em>, not the (severe/) suffering.</blockquote><p>For minimalist views, there is a very relevant difference between the RC and VRC, which is that the RC can be <em>non-problematic</em> (provided that we assume that the lives \u201c<u><a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives#3__How_do_these_views_help_us_make_sense_of_population_ethics_\">never suffer</a></u>\u201d, cf. footnote 16 <u><a href=\"https://forum.effectivealtruism.org/posts/RkPK8rWigSAybgGPe/a-longtermist-critique-of-the-expected-value-of-extinction-2#fn-rL6KptdovxyEp69MJ-16\">here</a></u>), but minimalist views would always reject the VRC. For minimalist views, the (severe) suffering is, of course, the main concern. My point about the VRC was to highlight how CU can justify astronomical harms <em>even for</em> (supposedly) <em>barely</em> positive isolated lives, and an even bigger commonsensical worry is how much harm it can justify for (supposedly) <em>greatly</em> positive isolated lives.</p><br><blockquote>If the block of 'positive lives/stuff' in the VRC was high magnitude - <u>say about as much (or even more) above neutral as the block of 'negative lives/stuff' lie below it</u> - there is little about this more Omelas-type scenario a classical utilitarian would find troubling. <u>\"N terrible lives and k*N wonderful lives is better than N wonderful lives alone\"</u> seems plausible for sufficiently high values of k. (Notably, 'Minimalist' views seem to fare worse as it urges no value of k \u2026 would be high enough.)</blockquote><p>It seems true that more people would find that more plausible. Even so, this is precisely what minimalists may find worrying about the CU approach to astronomical tradeoffs, namely that astronomical harms can be justified by the creation of sufficiently many instances of isolated goods.</p><p>Additionally, I feel like the point above applies more to classical utilitarian<strong>ism</strong> (the view) rather than to the views of actual classical utilitarian<strong>s</strong>, not to mention people who are mildly sympathetic to CU, which seems a particularly relevant group in this context given that they may represent an even larger number of people in the EA(-adjacent) community.</p><p>After all, CU-like views contain a minimalist (sub)component, and probably many self-identified CUs and CU-sympathetic people would thereby be at least more than a \u201clittle\u201d troubled by the implication that astronomical amounts of hellish lives \u2014 e.g. vastly more suffering than what has occurred on Earth to date \u2014 would be a worthwhile tradeoff for (greater) astronomical amounts of wonderful lives (what minimalist views would frame as unproblematic lives), especially given that the alternative was a wonderful (unproblematic) population with no hellish lives.</p><p>(For what it\u2019s worth, I used to feel drawn to a CU axiology until I became too troubled by the logic of counterbalancing harm for some with isolated good for others. For many people on the fence, the core problem is probably this kind of counterbalancing itself, which is independent of the VRC but of course also clearly illustrated by it.)</p><br><blockquote>If it were just <u>'The VRC says you can counterbalance severe suffering with happiness' <em>simpliciter</em></u>  which was generally counterintuitive, we could skip the rigmarole of A, A+, B etc. and just offer Omelas-type scenarios (as Tomasik does in the linked piece) without stipulating the supposedly outweighing good stuff comprises a<em> lot</em> of trivial well-being.</blockquote><p>Of course, minimalist views (as explored here) would deny <em>all</em> <u><a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives#Solving_problems__A_way_to_make_sense_of_population_ethics_\">counterbalancing</a></u> of severe problems with <em><u><a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives#Isolated_value_containers\">isolated</a></u></em> goods, independent of the VRC.</p><p>The Mere-Addition Paradox, RC, and VRC are often-discussed problems to which minimalist views may provide satisfying answers. The first two were included in the post for many reasons, and not only as a build-up to the VRC. The build-up was also not meant to end with the VRC, but instead to further motivate the question of how much harm can be justified to reduce astronomical waste (AW).</p><p>If CU-like views can justify the creation of a lot of hellish lives <em>even for</em> vast amounts of isolated value-containers that have only \u201cbarely positive\u201d contents (the VRC), then how much more hellish lives can they supposedly counterbalance once those containers are filled (cf. AW)?</p><br><blockquote><strong>Second, </strong>although scenarios where one may consider counterbalancing (/severe) suffering with happiness <em>in general</em> may not be purely theoretical (either now or in the future) <u>the likelihood of something closely analogous to the VRC <em>in particular</em> looks very remote</u>. In terms of 'process' the engine of the counter-intuitiveness relies on being able to parcel out good stuff in arbitrarily many arbitrarily small increments rather than in smaller more substantial portions; in terms of 'outcome' one needs a much smaller set of terrible lives outweighed by a truly vast multitude of just-about-better-than-nothing ones. I don't see how either arise on credible stories of the future. </blockquote><p>MichaelStJules already responded to this in the <a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives?commentId=CQq2AzRjEvEbbdniF\">sibling comment</a>. Additionally, I would again emphasize that the main worry is not so much the practical manifestation of the VRC in particular, but more the extent to which <u>much worse problems</u> might be justified by CU-like views given the creation of supposedly even greater amounts of isolated goods (i.e. reducing AW).</p><br><blockquote><strong>Third, </strong>there are other lines classical utilitarians or similar can take in response to the VRC besides biting the bullet (or attempting to undercut our intuitive responses): critical level views, playing with continuity, and other anti-aggregation devices to try and preserve trading-off <em>in general</em> but avoid the nickel and diming issues of the VRC <em>in particular</em>.</blockquote><p>MichaelStJules already mentioned an arbitrariness objection to those lines. Additionally, my impressions (based on Budolfson &amp; Spears, <u><a href=\"https://scholar.princeton.edu/sites/default/files/cfi/files/budolfson_spears_2018_repugnant_cfi.pdf\">2018</a></u>) are that <em>\u201c<u>the VRC cannot be avoided</u> by any leading welfarist axiology despite prior consensus in the literature to the contrary\u201d</em> and that <em>\u201c<u>[the extended] VRC cannot be avoided</u> by any other welfarist axiology in the literature.\u201d</em></p><p>Their literature did not include minimalist views(*). Did they also omit some CU-like views, or are the <em>VRC-rejecting</em> CU-like views not defended by anyone in the literature?</p><br><blockquote>Obviously, these themselves introduce other challenges (<u>so much so I'm more inclined to accept the costly counter-examples than the costs of (e.g.) non-continuity</u>) and surveying all this terrain would be a gargantuan task far beyond the remit of work introducing a related but distinct issue.</blockquote><p>This again leaves me wondering: Are all of the <em>VRC-rejecting</em> CU-like views so arbitrary or counterintuitive that people will just rather accept the VRC? And will even the most attractive of those views still justify astronomical harms for a sufficiently high amount of isolated lives that are \u201ctaller\u201d than those in the VRC?</p><p>This does not ease the worry that CU-like views can justify astronomically large harms in order to create isolated positive lives that never needed to exist in the first place.</p><br><blockquote>But I bring this up because I anticipate <u>the likely moves you will make to avoid the counter-example</u> Shulman and I have brought up will be along the lines of anti-aggregationist moves around lexicality, thresholds, and whatnot.</blockquote><p>First, in terms of practical relevance, one could argue that the choice to \u201cprefer hell to prevent an imperfect heaven\u201d is <u>much more speculative and unlikely</u> than is the VRC for CU-like views, not to mention the likelihood of CU justifying astronomical harms for supposedly greater goods regardless of the VRC (i.e. for reducing AW). In other words, the former can much more plausibly be disregarded as practically irrelevant than can the latter.</p><p>Second, lexical views do indeed avoid the conclusion in question, but these need not entail abrupt thresholds (per the arguments <u><a href=\"https://centerforreducingsuffering.org/research/lexical-views-without-abrupt-breaks/\">here</a></u> and <u><a href=\"https://link.springer.com/article/10.1007/s11229-021-03268-4\">here</a></u>), and even if they do, the threshold need not be an arbitrary or ad hoc move. For example, one could hold that there is a difference between psychologically consentable and <u><a href=\"https://centerforreducingsuffering.org/research/clarifying-lexical-thresholds/\">unconsentable</a></u> suffering, which is normally ignored by the logic of <u><a href=\"https://www.utilitarianism.net/types-of-utilitarianism#additive-aggregationism\">additive aggregationism</a></u>. Moreover, the OP entails no commitment to additive aggregationism, as it only specifies that the minimalist views in question are monist, impartial, and welfarist.</p><br><blockquote>If so, what is good for the goose is good for the gander: it seems better to use similarly adapted versions of total utilitarianism as a 'like for like' comparison. 'Lexical threshold total utilitarianism', which lexically de-prioritises dis/value below some magnitude can <em>accept</em> mere addition, <u><em>accept </em>trading off suffering for sufficient (non-trivial) happiness</u>, but <em>avoid</em> both the RC and VRC. This seems a better point of departure for weighing up minimalism or not, rather than discussing counter-examples to one or the other view which only apply given an (<em>ex hypothesi</em>) mistaken account of how to aggregate harms and benefits.</blockquote><p>First, I am \u200b\u200bhappy to compare like views in this way in my forthcoming post. I would greatly appreciate it if people were to present or refer me to specific such views to be compared.</p><p>Second, the point above may seem to imply that there is a symmetry between these lexical adaptations, i.e. that we can \u201csimilarly\u201d construct lexical minimalism and lexical symmetric totalism (if you allow the short expression). Yet the fact that we can make <em>formally symmetric</em> constructions for these different views does not imply that the respective plausibility of these constructions is symmetric <em>at the substantive level</em>. In this sense, what is good for the goose may do nothing for the gander. (But again, I\u2019m happy to explore the possibility that it might.)</p><p>Specifically, how would one set the threshold(s) on the lexical symmetric view in a non-arbitrary way, and has anyone presented and defended plausible versions of such views? </p><p>Furthermore, most people would probably find it much more plausible that <u><a href=\"https://www.simonknutsson.com/value-lexicality\">some</a></u> harms cannot be counterbalanced by any amount of isolated goods (\u201ca lexical minimalist component\u201d), than that some goods can counterbalance any amount of isolated harms (a similarly lexical positive component). At least I\u2019ve never heard anyone defend or outline the latter kind of view. (By contrast, <u><a href=\"https://www.amazon.com/Suffering-Moral-Responsibility-Oxford-Ethics/dp/0195115996\">beyond</a></u> <u><a href=\"https://www.simonknutsson.com/lars-bergstrom-pessimism-ethics-consequentialism-ingemar-hedenius\">examples</a></u> in <u><a href=\"https://www.jstor.org/stable/20012285\">academic</a></u> <u><a href=\"https://philpapers.org/rec/RYDPD\">philosophy</a></u>, there are <u><a href=\"https://web.archive.org/web/20190410204154/https://jwcwolf.public.iastate.edu/Papers/JUPE.HTM\">numerous</a></u> <u><a href=\"https://www.oxfordreference.com/view/10.1093/acref/9780191826719.001.0001/q-oro-ed4-00003773#:~:text=Imagine%20that%20you%20are%20creating,be%20the%20architect%20on%20those\">examples</a></u> in <u><a href=\"https://en.wikipedia.org/wiki/The_Ones_Who_Walk_Away_from_Omelas\">literature</a></u> hinting at \u201cminimalist lexicality\u201d.)</p><p>Overall, I remain worried about the vast harms that CU-like views could justify for the supposed greater good, also considering that even you feel inclined to rather accept the VRC than deal with the apparently arbitrary or counterintuitive features of the versions of CU-like views that avoid it. (And if one proposes a positive lexical threshold, it seems that <u>above the lexical threshold</u> there is always a higher isolated good that <em>can</em> justify vast harms.)</p><p>Lastly, why do we need to \u201caccept trading off suffering for sufficient (non-trivial) [<u><a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives#Isolated_value_containers\">isolated</a></u>] happiness\u201d in the first place? Would not a <u><a href=\"https://forum.effectivealtruism.org/posts/t3St6Fz4DmHtKfgqm/positive-roles-of-life-and-experience-in-suffering-focused\">relational</a></u> <u><a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives#Compatibility_with_everyday_intuitions\">account</a></u> of the value of happiness suffice? What seems to be the problem with relational goods, without isolated goods?</p><br><p>(*) <strong>A note on minimalist views and the extended VRC of Budolfson &amp; Spears (2018).</strong></p><p>Strictly speaking, the extended VRC in the&nbsp;formulation of <a href=\"https://scholar.princeton.edu/sites/default/files/cfi/files/budolfson_spears_2018_repugnant_cfi.pdf\">Budolfson &amp; Spears</a>&nbsp;does not pertain to minimalist views, because they say \"u^h<strong>&gt;</strong>0\" (i.e. <strong>strictly</strong>&nbsp;greater than zero). So minimalist views fall outside of the domain that they draw conclusions for.</p><p>But if we allow the \"high-utility lives\" to be <em>exactly</em> zero, or even less than zero, then their conclusion would also hold for (continuous, aggregationist) minimalist views. (But the conclusion arguably also becomes much less implausible in the minimalist case compared to the symmetric case, cf. the final point below.)&nbsp;</p><p>So it (also) holds for continuous aggregationist minimalist views&nbsp;that there exists a base population \"such that it is better to both add to the base population the negative-utility lives and cause [a sufficiently large number of] \u03b5-changes\".</p><p>But <em>beyond</em> questioning the continuous aggregationist component of these views (indeed a possibility that lies open to many kinds of views with such a component), and <em>beyond</em> questioning the practical relevance of this conclusion for minimalist views versus for symmetric views (as I do above), one may further argue that the conclusion is significantly <em><a href=\"https://forum.effectivealtruism.org/posts/HGLK3igGprWQPHfAp/against-neutrality-about-creating-happy-lives?commentId=8BJCKJs7u5J9Aro4M\">more</a></em> <a href=\"https://forum.effectivealtruism.org/posts/HGLK3igGprWQPHfAp/against-neutrality-about-creating-happy-lives?commentId=6DEFGhadEyercNnhw\">plausible</a>&nbsp;in the minimalist case than in the case where we allow torture for the sake of isolated, purported goods that arguably do not need to exist. For in the minimalist case, the overall burden of subjective problems is still lessened (<em>assuming</em> continuous aggregationist minimalism). We are not creating extreme suffering for the mere sake of isolated, \"unrelieving\" goods.</p>", "parentCommentId": "eWXFHENFEKmytiD5f", "user": {"username": "Teo Ajantaival"}}, {"_id": "bkbAyyCdb69bNDai2", "postedAt": "2021-11-18T15:09:10.141Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<p>Thanks for the reply, and with apologies for brevity.</p><p>Re. <strong>1 </strong>(ie. \"The primary issue with the VRC is aggregation rather than trade-off\"). I take it we should care about plausibility of axiological views with respect to something like 'commonsense' intuitions, rather than those a given axiology urges us to adopt. It's at least opaque to me whether commonsense intuitions are more offended by 'trade-offy/CU' or 'no-trade-offy/NU' intuitions. On the one hand:</p><ul><li>\"Any arbitrarily awful thing can be better than nothing providing it is counterbalanced by k good things (for some value of k)\"</li><li>(<i>a fortiori</i>) \"N awful things can be better than nothing providing they are counterbalanced by k*N good things (and N can be arbitrarily large, say a trillion awful lives).\"</li></ul><p>But on the other:</p><ul><li>\"No amount of good things (no matter how great their magnitude) can compensate for a single awful thing, no matter how astronomical the ratio (e.g. trillions to 1, TREE(3) to 1, whatever).\"</li><li>(<i>a fortiori</i>) \"No amount of great things can compensate for a single bad thing, no matter how small it is (e.g. pinpricks, a minute risk of an awful thing)\"</li></ul><p>However, I am confident the aggregation views - basically orthogonal to this question - are indeed the main driver for folks finding the V/RC particularly repugnant. Compare:</p><ol><li>1 million great lives vs. 1 million terrible lives and a Quadrillion great lives.</li><li>1 thousand great lives vs. 1 thousand terrible lives and TREE(3) marginally good lives.</li></ol><p>A minimalist view may well be concerned with increasing the amount of aggregate harm in 1 vs. 2, and so worry that (re. 2) if CU was willing to accept this, it would accept a lot more aggregate harm if we increase the upside to more than compensate (e.g. TREE(3) great lives). Yet I aver commonsense intuitions favour 1 over 2, and would find variants of 2 where the downside is increased but the upside is <i>reduced</i> but concentrated (e.g. a trillion great lives) more palatable.&nbsp;</p><p>So appeals along the lines of \"CU accepts the VRC, and - <i>even worse</i> - would accept even larger downsides if the compensating upside was composed of very- rather than marginally- happy lives\" seems misguided, as this adaptation of the VRC aligns it better, not worse, with commonsense (if not minimalist) intuitions.</p><p>&nbsp;</p><p>Re. <strong>3 </strong>I've read Budolfson &amp; Spears, and as you note (*) it seems we can construct xVRCs which minimalist views (inc. those which introduce lexical thresholds) are susceptible to. (I also note they agree with me re. <strong>1 - </strong>e.g. s8: \"Whenever aggregation is done over an unbounded space, repugnant outcomes inevitably occur\"; their identification with the underlying mechanism for repugnance being able to aggregate e-changes.)&nbsp;</p><p>The replies minimalists can make here seem very 'as good for the goose as the gander' to me:</p><ol><li>One could deny minimalism is susceptible to even xVRCs as one should drop aggregation/continuity/etc. Yet symmetric views should do the same, so one should explore whether on the margin of this atypical account of aggregation minimalist axiologies are a net plus or minus to overall plausibility.</li><li>One could urge we shouldn't dock points to a theory for counter-examples which are impractical/unrealistic, the x/VRCs for minimalism fare much better than the x/VRCs for totalism. This would be quite a departure from my understanding of how the discussion proceeds in the literature, where the main concern is the 'in principle' determination for scenarios (I don't ever recall - e.g. - replies for averagism along the lines of \"But there'd never be a realistic scenario where we'd <i>actually</i> find ourselves minded to add net-negative lives to improve average utility\"). In any case, a lot of the xVRCs applicable to CU-variants require precisely stipulated 'base populations', so they're presumably also 'in the clear' by this criterion.</li><li>&nbsp;One could accept minimalism entails an xVRC, but this bullet is easier to bite than x/VRCs against symmetric views. Perhaps, but in which case we should probably pick the closest symmetric comparator (e.g. if they can't play with thresholds, you should deal with Shulman-esque pinprick scenarios). I also note the appeals to plausibility made (here and in the comments you link) seem to be mostly re-statements of minimalism itself (e.g. that epsilon changes in misery count but epsilon changes in happiness don't, 'subjective perfection' equated to neutrality, etc.) \"Conditional on minimalist intuitions, minimalism has no truly counter-intuitive results\" is surely true, but also question-begging to folks who don't share them (compare a totalist asserting the VRC is much less counter-intuitive than minimalist-xVRCs as - 'obviously' - wellbeing can be greater than zero, and axiology shouldn't completely discount unbounded amounts of it in evaluation).</li></ol><p><strong>[Finally</strong>, I'm afraid I can't really see much substantive merit in the 'relational goods' approach. Minimalism (like SFE and NU) straightforwardly offends the naive intuition that happiness is indeed 'better than nothing', and I don't find relational attempts to undercut this by offering an account of these being roundabout ways/policies of reducing problems either emotionally satisfying (e.g. All the rich relationships between members of a community may make everyone have 'lives worth living' in the sense that 'without me these other people would be worse off', but minimalism appears still committed to the dispiriting claim that this rich tapestry of relationships is still worse than nothing) or intellectually credible (cf. virtually everyone's expressed and implied preferences suggest non-assent to 'no-trade-off' views).&nbsp;</p><p>Similarly, I think assessing 'isolated' goods as typical population cases do is a good way to dissect out the de/merits of different theories, and noting our evaluation changes as we add in a lot of 'practical' considerations seems apt to muddy the issue again (for example, I'd guess various 'practical elaborations' of the V/RC would make it appear more palatable, but I don't think this is a persuasive reply).&nbsp;</p><p>I focus on the 'pure' population ethics as \"I don't buy it\" is barren ground for discussion.]</p>", "parentCommentId": "J9wbQ2gH8gKn23kMY", "user": {"username": "Gregory_Lewis"}}, {"_id": "dSKHoMtFLyo3uDo4J", "postedAt": "2021-11-20T16:31:27.569Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<p>I think it's useful to have a thought experiment to refer to other than Omelas to capture the intuition of \"a perfect, arbitrarily large utopia is better than a world with arbitrarily many miserable lives supposedly counterbalanced by sufficiently many good lives.\" Because:</p>\n<ul>\n<li>The \"arbitrarily many\" quantifiers show just how extreme this can get, and indeed the sort of axiology that endorses the VRC is committed to judging the VRC as <em>better</em> the more you multiply the scale, which seems backwards to my intuitions.</li>\n<li>The first option is a utopia, whereas the Omelas story doesn't say that there's some other civilization that is smaller yet still awesome and has no suffering.</li>\n<li>Omelas as such is confounded by deontological intuitions, and the alternative postulated in the story is \"walking away,\" not preventing the existence of such a world in the first place. I've frequently found that people get hung up on the counterproductiveness of walking away, which is true, but irrelevant to the axiological point I want to make. The VRC is purely axiological, so more effective at conveying this.</li>\n</ul>\n<p>So while I agree that aggregation is an important part of the VRC, I also disagree that the \"nickel and diming\" is at the heart of this. To my intuitions, the VRC is still horrible and borderline unacceptable if we replace the just-barely-worth-living lives with lives that have sufficiently intense happiness, intense enough to cross any positive lexical threshold you want to stipulate. In fact, muzak and potatoes lives as Parfit originally formulated them (i.e., with no suffering) seem much better than lots of lives with both lexically negative and lexically \"positive\" experiences. <a href=\"https://forum.effectivealtruism.org/posts/AwAJmJexceHa6QRDL/antimonyanthony-s-shortform?commentId=cAGLmEMbEE9WoiqXQ\">I'll eagerly accept Parfit's version of the RC</a>. (If you want to say this is contrary to common sense intuitions, that's fine, since I don't put much stock in common sense when it comes to ethics; there seem to be myriad forces pushing our default intuitions in directions that make evolutionary sense but are disturbing to me upon reflection.)</p>\n<p>[edited for some clarifications]</p>\n", "parentCommentId": "eWXFHENFEKmytiD5f", "user": {"username": "antimonyanthony"}}, {"_id": "swAQZEqoYueG6BeA6", "postedAt": "2021-11-21T21:07:41.368Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<p>I'm curious about your takes on the value-inverted versions of the repugnant and very-repugnant conclusions. It's easy to \"make sense\" of a preference (e.g. for positive experiences) by deciding not to care about it after all, but doing that doesn't actually resolve the weirdness in our feelings about aggregation.</p><p>Once you let go of trying to reduce people to a 1-dimensional value <i>first</i> and then aggregate them <i>second</i>, as you seem to be advocating here in ss. 3/4, I don't see why we should try to hold onto simple rules like \"minimize this one simple thing.\" If the possibilities we're allowed to have preferences about are not 1-dimensional aggregations, but are instead the entire self-interacting florescence of life's future, then our preferences can get correspondingly more interesting. It's like replacing preferences over the center of mass of a sculpture with preferences about its pose or theme or ornamentation.</p>", "parentCommentId": null, "user": {"username": "Charlie Steiner"}}, {"_id": "KqTK4vXfyR4tjihhj", "postedAt": "2021-11-24T19:16:22.250Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<p>Thanks!</p><br><blockquote>I'm curious about your takes on the value-inverted versions of the repugnant and very-repugnant conclusions.</blockquote><p>I\u2019m not sure what exactly they are. If either of them means to \u201creplace a few extremely miserable lives with many, almost perfectly untroubled ones\u201d, then it does not sound repugnant to me. But maybe you meant something else.</p><p>(Perhaps see also <a href=\"https://forum.effectivealtruism.org/posts/HGLK3igGprWQPHfAp/against-neutrality-about-creating-happy-lives?commentId=8BJCKJs7u5J9Aro4M\">these</a> <a href=\"https://forum.effectivealtruism.org/posts/HGLK3igGprWQPHfAp/against-neutrality-about-creating-happy-lives?commentId=6DEFGhadEyercNnhw\">comments</a> about adding slightly less miserable people to hell to reduce the most extreme suffering therein, which seems, to me at least, to result in an overall more preferable population when repeated multiple times.)</p><br><blockquote>It's easy to \"make sense\" of a preference (e.g. for positive experiences) by deciding not to care about it after all, but doing that doesn't actually resolve the weirdness in our feelings about aggregation.</blockquote><p>Did you mean</p><ol type=\"1\"><li>the subjective preference, of the \u201clives worth living\u201d themselves, to have positive experiences, or</li><li>the preference of an outside observer, who is looking at the population comparison diagrams, to count those lives as having isolated positive value?</li></ol><p>If 1, then I would note that e.g. the <u><a href=\"https://www.fehige.info/pdf/A_Pareto_Principle_for_Possible_People.pdf\">antifrustrationist</a></u> and <u><a href=\"https://longtermrisk.org/tranquilism/\">tranquilist</a></u> accounts would care about that subjective preference, as they would see it as a kind of dissatisfaction with the preferrer\u2019s current situation. Yet when we are looking at only causally isolated lives, these views, like all minimalist views, would say that there is no need to create dissatisfied (or even perfectly fulfilled) beings for their own sake in the first place. (In other words, creating and fulfilling a need is only a roundabout way to not having the need in the first place, unless we also consider the positive roles of this process for other needs, which we arguably should do in the practical world.)</p><p>If 2, then I\u2019d be eager to understand what seems to be missing with the previous \u201cneed-based\u201d account.</p><p>(I agree that the above points are unrelated to how to aggregate e.g. small needs vs. extreme needs. But in a world with extreme pains, I might e.g. deprioritize any amount of <em>isolated </em>small pains, i.e. small pains that do not increase the risk of extreme pains nor constitute a distraction or opportunity cost for alleviating extreme pains. Perhaps one could intuitively think of this as making \u201cthe expected amount of extreme pains\u201d the common currency. Of course, that kind of aggregation may seem repugnant between a few extreme pains vs. a vast amount of slightly less extreme pains, but in practice we would also account for their wide&nbsp;\u201derror bars\u201d and non-isolated nature.)</p><br><blockquote>Once you let go of trying to reduce people to a 1-dimensional value first and then aggregate them second, as you seem to be advocating here in ss. 3/4, I don't see why we should try to hold onto simple rules like \"minimize this one simple thing.\" If the possibilities we're allowed to have preferences about are not 1-dimensional aggregations, but are instead the entire self-interacting florescence of life's future, then our preferences can get correspondingly more interesting. It's like replacing preferences over the center of mass of a sculpture with preferences about its pose or theme or ornamentation.</blockquote><p>The claim of axiological <u><a href=\"https://plato.stanford.edu/entries/value-theory/#Mon\">monism</a></u> is only that our different values <em>ultimately</em> reduce to one value. Without a common measure, it would seem that multiple independent values are incommensurable and cannot be measured against each other even in principle.</p><p>So no one claims that people would descriptively follow only a single guiding principle, nor that it would be simple to e.g. decide how to prioritize between our intertwined and often contradictory preferences. Our needs and preferences can be \u201cabout\u201d anything, but if e.g. someone prefers the existence of additional beings, we should plausibly weigh the magnitude of this (unfulfilled) preference against the potential unfulfilled needs that those beings might suffer from. And it seems questionable that e.g. someone\u2019s aesthetic preferences could in themselves override another\u2019s need to avoid extreme suffering (cf. gladiator games).</p>", "parentCommentId": "swAQZEqoYueG6BeA6", "user": {"username": "Teo Ajantaival"}}, {"_id": "2Mh3xjYrASmETsaRf", "postedAt": "2021-11-24T19:27:55.797Z", "postId": "5gPubzt79QsmRJZnL", "htmlBody": "<p>Thanks for the reply!</p><br><blockquote>Re. <strong>1 </strong>(ie. \"The primary issue with the VRC is aggregation rather than trade-off\"). I take it we should care about plausibility of axiological views with respect to something like 'commonsense' intuitions, rather than those a given axiology urges us to adopt.</blockquote><p>Agreed, and this is also why I focus also on the psychological and practical implications of axiological views, and not only on their theoretical implications. Especially in the EA(-adjacent) community, it seems common to me that the plausibility of theoretical views is assessed also based on the plausibility of their practical implications, which tap into further important intuitions than what may be involved by staying at the abstract level.</p><p>E.g., people may bite bullets in <em>theory</em> to retain a consistent view, but still never bite those bullets in <em>practice</em> due to some still unarticulated reasons, which may indicate an inconsistency between their explicit and implicit axiology.</p><br><blockquote>It's at least opaque to me whether commonsense intuitions are more offended by 'trade-offy/CU' or 'no-trade-offy/NU' intuitions.</blockquote><p>By \u2018trade-offy\u2019 and \u2018no-trade-offy\u2019, I\u2019d like to emphasize that we mean trade-offs between <em>isolated</em> things. In other words, the diagrams of population ethics could just as well consist of causally isolated experience machines (\u201cisolated Matrix-lives\u201d), which is plausibly a confounding factor for our practical (\u201ccommonsense\u201d) intuitions, as our practical intuitions are arguably adapted for trade-offs in an interpersonal (\u201crelational\u201d) world.</p><br><blockquote>On the one hand:</blockquote><blockquote>\"Any arbitrarily awful thing can be better than nothing providing it is counterbalanced by k good things (for some value of k)\"</blockquote><blockquote>(<em>a fortiori</em>) \"N awful things can be better than nothing providing they are counterbalanced by k*N good things (and N can be arbitrarily large, say a trillion awful lives).\"</blockquote><p>It\u2019s very unclear to me how many people actually believe that any arbitrarily awful thing can be counterbalanced by sufficiently many (and/or awesome) isolated Matrix-lives, or other isolated goods. By default, I would assume that most people do not (want to) think about torture,&nbsp;and also do not properly respect the \u201call else being equal\u201d assumption, and thereby would not count as votes of \u201cinformed consent\u201d for those claims. Additionally, in at least one small Mechanical Turk <u><a href=\"https://reducing-suffering.org/a-small-mechanical-turk-survey-on-ethics-and-animal-welfare/#Pain-pleasure_tradeoff\">survey</a></u> about a tradeoff for people themselves, more than 40 percent of people said that they would not accept one minute of extreme suffering for any number of happy years added to their lives.</p><br><blockquote>But on the other:</blockquote><blockquote>\"No amount of good things (no matter how great their magnitude) can compensate for a single awful thing, no matter how astronomical the ratio (e.g. trillions to 1, TREE(3) to 1, whatever).\"</blockquote><blockquote>(<em>a fortiori</em>) \"No amount of great things can compensate for a single bad thing, no matter how small it is (e.g. pinpricks, a minute risk of an awful thing)\"</blockquote><p>The <strong>first</strong> claim (i.e. \u201ca lexical minimalist component\u201d) is precisely what has been defended in the philosophical (and fictional) literature. And again, this claim might be something that most people have not thought about, because only a minority of people have had first- or even second-person experience of an awful thing that might be defended as being categorically \u201cimpossible to compensate&nbsp;for with isolated goods\u201d, such as torture.</p><p>(The <strong>second</strong> claim does not strictly follow from the first, which was about \u201cawful\u201d things; e.g. some SFE views hold that sufficiently awful things are lexical bads, but not that all kinds of tiny bads are. This is also relevant for the practical implications of lexical minimalist views with relational goods, on which <em>pinpricks</em> may be practically ignored unless they increase the risk of lexically bad things, whereas anything worthy of the name \u201cgreat thing\u201d would probably play positive roles to help reduce that risk.)</p><br><blockquote>However, I am confident the aggregation views - basically orthogonal to this question - are indeed the main driver for folks finding the V/RC particularly repugnant. Compare: [...]</blockquote><blockquote>So appeals along the lines of \"CU accepts the VRC, and - <em>even worse</em> - would accept even larger downsides if the compensating upside was composed of very- rather than marginally- happy lives\" seems misguided, as this adaptation of the VRC aligns it better, not worse, with commonsense (if not minimalist) intuitions.</blockquote><p>Here I would again note that our commonsense intuitions are arguably not adapted to track the isolated value of lives, and so we should be careful to make it clear that we are comparing e.g. isolated Matrix-lives. By default, I suspect that people may think of the happy populations as consisting of lives like their own or of people they know, which may implicitly involve a lot of effects on other lives.</p><p>Of course, the framings of \u201cisolated Matrix-lives\u201d or \u201cexperience machines\u201d may themselves bring in connotations that can feel pejorative or dismissive with regard to the actual subjective experience of those lives, but my point is just to drive home the fact that these lives are, by hypothesis, radically devoid of any positive roles for others, or even for their future selves. And if people implicitly have a <em>relational</em> notion of positive value (e.g. if they think of positive value as implying an <em>inverse causal relation</em> to some subjective problems), then they may feel very differently about harms counterbalanced by isolated goods vs. harms counterbalanced by relational goods (of which minimalist views can endorse the latter).</p><p>To be clear, the inverse relations include not only subjective problems prevented by social relationships, but also e.g. any desirable effects on <u><a href=\"https://forum.effectivealtruism.org/tag/wild-animal-welfare\">wild animals</a></u> and future <u><a href=\"https://forum.effectivealtruism.org/tag/s-risk\">s-risks</a></u>. Admittedly, probably neither of the latter two is a very <em>commonsensical</em> contributor to positive tradeoffs, but I\u2019d guess that neither would many people find it intuitive to counterbalance astronomical harms with (\u201ceven greater amounts of\u201d) isolated experience machines, or with a single \u201c<u><a href=\"https://en.wikipedia.org/wiki/Utility_monster\">utility monster</a></u>\u201d. Arguably, all of these cases are also tricky to measure against people\u2019s commonsense intuitions, given that not many people have thought about them in the first place.</p><br><blockquote>Re. <strong>3 </strong>I've read Budolfson &amp; Spears, and as you note (*) it seems we can construct xVRCs which minimalist views (inc. those which introduce lexical thresholds) are susceptible to. (I also note they agree with me re. <strong>1 - </strong>e.g. s8: \"Whenever aggregation is done over an unbounded space, repugnant outcomes inevitably occur\"; their identification with the underlying mechanism for repugnance being able to aggregate e-changes.)</blockquote><p>Yeah, we can formally construct xVRCs for minimalist views, including for lexical minimalist views, but my claim is that these are consistently less repugnant in like-like comparisons with symmetric views (relative to commonsense or widely shared intuitions). Specifically in the lexical minimalist xVRC \u2014 i.e. <a href=\"https://forum.effectivealtruism.org/posts/HGLK3igGprWQPHfAp/against-neutrality-about-creating-happy-lives?commentId=8BJCKJs7u5J9Aro4M\">these</a> <a href=\"https://forum.effectivealtruism.org/posts/HGLK3igGprWQPHfAp/against-neutrality-about-creating-happy-lives?commentId=6DEFGhadEyercNnhw\">comments</a> which you refer to in your point #3 below \u2014 the tradeoff results in ever <em>less</em> (and less intense) suffering if followed repeatedly. By comparison, <em>every</em> symmetric xVRC would keep on increasing suffering if scaled up in an analogous way, which is arguably the most repugnant aspect of the VRC.</p><p>Additionally, <u><a href=\"https://forum.effectivealtruism.org/posts/HGLK3igGprWQPHfAp/against-neutrality-about-creating-happy-lives?commentId=wqMNyDAmANg5pQzrn#wqMNyDAmANg5pQzrn\">this comment</a></u> (upstream of the linked ones) points out a source of <em>intra-</em>personal repugnance in the symmetric cases, namely that CU-like views would be fine with the \u201cmarginally good\u201d \u03b5-lives being \u201croller coaster\u201d lives that <em>also</em> contain a lot of extreme suffering:</p><blockquote><em>One way to see that a \u03b5 increase could be very repugnant is to recall Portmore\u2019s (1999) suggestion that \u03b5 lives in the restricted RC could be \u201croller coaster\u201d lives, in which there is much that is wonderful, but also much terribly suffering, such that the good ever-so-slightly outweighs the bad [according to some symmetric view]. Here, one admitted possibility is that an \u03b5-change could substantially increase the terrible suffering in a life, and also increase good components; such a \u03b5-change is not the only possible \u03b5-change, but it would have the consequence of increasing the total amount of suffering. ... Moreover, if \u03b5-changes are of the \u201croller coaster\u201d form, they could increase deep suffering considerably beyond even the arbitrarily many [u &lt; 0] lives, and in fact could require everyone in the chosen population to experience terrible suffering.</em> [From Budolfson &amp; Spears]</blockquote><p>Of course, in <em>some</em> minimalist examples it is arguably repugnant to create extreme suffering to avoid a vast number of mildly problematic states. But I would claim that commonsense (and not only minimalist) intuitions would find even <em>more</em> repugnant <u>the analogous symmetric case</u>, namely to create extreme suffering for a vast number of mildly positive states which are not needed to relieve anyone\u2019s burden. (The latter case may appear especially repugnant if the symmetric view in question would allow the mildly positive states to be \u201croller coaster\u201d lives that are not even themselves free of, but would in fact contain a lot of, extreme suffering.) Consider, for instance, that:</p><ul><li>A 2017 <u><a href=\"https://futureoflife.org/superintelligence-survey/\">survey</a></u> by FLI (n &gt; 14,000), found that the goal people favored most as the ideal aim of a future civilization was \u201cminimizing suffering\u201d. This was the most popular aim by a large margin, ahead of \u201cmaximizing positive experiences\u201d, and most of the people who favored this goal were probably not suffering while they responded to the survey.</li><li>The authors of <u><a href=\"https://static1.squarespace.com/static/5506078de4b02d88372eee4e/t/5f5a3ddd466873260486fb06/1599749604332/Moral+Uncertainty.pdf\">Moral Uncertainty</a></u> write (p. 185): </li></ul><blockquote><em>According to some plausible moral views, the alleviation of suffering is more important, morally, than the promotion of happiness. According to other plausible moral views (such as classical utilitarianism), the alleviation of suffering is equally as important, morally, as the promotion of happiness. But there is no reasonable moral view on which the alleviation of suffering is less important than the promotion of happiness. So, under moral uncertainty, it\u2019s appropriate to prefer to alleviate suffering rather than to promote happiness more often than the utilitarian would.</em></blockquote><ul><li>The above points do not tip the scales all the way in favor of minimalism over CU-variants, but they do suggest that common intuitions would not necessarily favor \u2018additively aggregationist CU\u2019 (even before looking at the respective x/VRCs for these views, let alone after considering the overall direction when we iterate such tradeoffs multiple times).</li></ul><br><blockquote>The replies minimalists can make here seem very 'as good for the goose as the gander' to me:</blockquote><blockquote>1. One could deny minimalism is susceptible to even xVRCs as one should drop aggregation/continuity/etc. Yet symmetric views should do the same, so one should explore whether on the margin of this atypical account of aggregation minimalist axiologies are a net plus or minus to overall plausibility.</blockquote><p>Agreed, although it is <u><a href=\"https://www.simonknutsson.com/measuring-happiness-and-suffering/\">unclear</a></u> whether continuous aggregation is in fact more typical. But since I\u2019m interested in defending lexical minimalism (which many people already hold with a priority for extreme suffering), I\u2019d be curious to hear if anyone has defended an analogous symmetric view, or how that view would be constructed in the first place. E.g., should I compare \u201cpriority for the worst-off\u201d with a view that (also) entails \u201cpriority for the best-off\u201d, even if no one (to my knowledge) defends the latter priority?</p><br><blockquote>2. One could urge we shouldn't dock points to a theory for counter-examples which are impractical/unrealistic, the x/VRCs for minimalism fare much better than the x/VRCs for totalism. This would be quite a departure from my understanding of how the discussion proceeds in the literature, where the main concern is the 'in principle' determination for scenarios</blockquote><p>The literature is mostly not written by people trying to figure out whether to prioritize the reduction of <u><a href=\"https://forum.effectivealtruism.org/tag/astronomical-waste\">AW</a></u> versus the reduction of s-risks. And once we accept some tradeoff in theory, it becomes relevant to ask if we would plausibly accept similar tradeoffs that could practically occur on an astronomical scale, for which the e-changes could of course first be \u201cenlarged\u201d so as to make more practical sense. (At least I feel like none of my intended points depend on the e-changes being tiny, nor on the base populations consisting of lives with mutually equal welfare, so I\u2019m fine with discussing x/VRCs that are in those ways more realistic \u2014&nbsp;especially if we account for the \u201croller coaster\u201d aspects of more realistic lives.)</p><p>In other words, whether we affirm or reject the claim that purported positive goods can outweigh extreme suffering has great relevance for our priorities, whereas the question of whether lexical minimalist views are more plausible than non-lexical minimalist views has limited practical relevance, since the real-life implications (e.g. for ideal population sizes) are roughly convergent for minimalist views.</p><br><blockquote>3. One could accept minimalism entails an xVRC, but this bullet is easier to bite than x/VRCs against symmetric views. Perhaps, but in which case we should probably <u>pick the closest symmetric comparator</u> (e.g. if they can't play with thresholds, you should deal with Shulman-esque pinprick scenarios). I also note the appeals to plausibility made (here and in the comments you link) seem to be <u>mostly re-statements of minimalism itself</u> (e.g. that epsilon changes in misery count but epsilon changes in happiness don't, 'subjective perfection' equated to neutrality, etc.) </blockquote><p>Again, I\u2019m happy to pick the closest symmetric view to compare with the minimalist priority for extreme suffering, but I\u2019m still unsure what that view might be (and eager to hear if there is anything to be read about such views).</p><p>I don\u2019t agree that the points about the minimalist xVRCs\u2019 comparatively greater plausibility are mostly re-statements of minimalism itself. Rather, I claim that commonsense intuitions would favor the lexical minimalist xVRC \u2014 in which suffering is \u201cspread more equally between those who already exist and those who do not\u201d (and eventually minimized if iterated) \u2014 over any symmetric xVRC of \u201cexpanding hell to help the best-off\u201d. (In other words, even if one finds it somewhat plausible that happiness has independent value, or value in isolation, it still seems that the symmetric xVRCs are worse than the minimalist xVRC.)</p><p>(For subjective perfection equated with the absence of something, I was thinking of <u><a href=\"https://longtermrisk.org/tranquilism/\">tranquilism</a></u> as a need-based account of the isolated value of different experiential states, which is centered on cravings to change one\u2019s subjective experience.)</p><br><blockquote><strong>Finally</strong>, I'm afraid I can't really see much substantive merit in the 'relational goods' approach. Minimalism (like SFE and NU) straightforwardly offends <u>the naive intuition that happiness is indeed 'better than nothing'</u>, and I don't find relational attempts to undercut this by offering an account of these being roundabout ways/policies of reducing problems either<u> emotionally satisfying</u> (e.g. All the rich relationships between members of a community may make everyone have 'lives worth living' in the sense that 'without me these other people would be worse off', but minimalism appears still committed to the <u>dispiriting</u> claim that this rich tapestry of relationships is still worse than nothing) or intellectually credible</blockquote><p>(Strictly speaking, minimalism is a category that contains NU but only overlaps with SFE; some SFE views may recognize isolated positive value even as they prioritize reducing suffering, and e.g. Fehige\u2019s <u><a href=\"https://www.fehige.info/pdf/A_Pareto_Principle_for_Possible_People.pdf\">view</a></u> represents a preference-based instead of suffering-focused minimalism.)</p><p>About <u>the naive intuition that happiness is indeed \u2018better than nothing\u2019</u>, I\u2019m curious if that really applies also for isolated Matrix-lives (for most people). As I\u2019ve noted in <u><a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives#Compatibility_with_everyday_intuitions\">this section</a></u>, by focusing on isolated value we may often <em>underestimate</em> the relational value of some goods, which may be greater than the amount of intrinsic value we perceive them to have.</p><p>About the relational account having <u>dispiriting</u> or emotionally unsatisfying implications, those can also be compared between views (to the extent that they matter for the plausibility of axiological views). E.g., on minimalist views, unlike CU-like views, it\u2019s not a tragedy or atrocity if we fail to reduce astronomical waste. In this sense, minimalist views may be less dispiriting than CU-like views. Moreover, I\u2019d practically emphasize that our positive roles need not be limited to the confines of our social communities, but extend all the way to those communities\u2019 effects on things like factory farming, wild-animal suffering, and the risks of future suffering (and thus potentially match or even exceed our commonsense feelings about the positive value of many lives, even if this would formally consist of \u201conly\u201d relational instead of independently positive value).</p><p>However, we should also be careful to account for our personal emotional responses to the implications of a given axiology. By analogy with empirical claims, we would probably want our views on (e.g.) global catastrophic risks to be unaffected by whether we find them dispiriting or not. Similarly, we should arguably account for such feelings in our axiological considerations of what, if anything, would constitute an axiologically positive life in causal isolation (and, specifically, what would constitute a life capable of counterbalancing the suffering of others without the consent of the latter).</p>", "parentCommentId": "bkbAyyCdb69bNDai2", "user": {"username": "Teo Ajantaival"}}]