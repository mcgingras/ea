[{"_id": "3KcYyn2qnRJ3LvSpn", "title": "Thinking-in-limits about TAI from the demand perspective. Demand saturation, resource wars, new debt.", "postedAt": "2023-11-07T22:44:11.110Z", "htmlBody": "<p><strong>Epistemic status: </strong>considerations</p><p><strong>Disclaimer 1: </strong>So far, I raised this point in a few conversations, and people encouraged me to develop my thinking into a post. This is my attempt to do so. I have no expert knowledge of economics.</p><p><strong>Disclaimer 2:</strong> What I call Transformative AI (TAI) here is something that will automate existing jobs but will remain under human control. This is not the typical definition I encountered, which is AI that will cause GDP growth per year of the order of 20% - 100%. For the purpose of thinking-in-limits, the difference is not essential.</p><h3>preambular&nbsp;</h3><p>One of the things they teach you in physics is to think in limits. This means seeing how the solution will look like when the variable is put into its extreme value, often infinity or zero. Surprisingly enough, in some cases, the proper solution is the product of the solutions of two simple solutions that pop up in the opposite limits of the variable. &nbsp;<br>TAI can be seen as the limit of production efficiency. Here are my thoughts on what can happen to economics exploring the limits of consumption as an essential counterpart of production.</p><h1>&nbsp;1. Demand saturation</h1><p>There are two types of businesses: those that meet existing needs and those which create new needs and then meet them. The latter, which would include Facebook, Uber, or Airbnb, is a rather rare although noticeable case</p><p>This distinction is important for the following fundamental question:<br>\"Is there a saturation of human needs?\" or, which is the same, \"Is there demand saturation?\".</p><p>Clearly, with improved efficiency, we will be able to saturate the existing needs - automate the production away, <i>e voila</i>. With ever more efficient production tools, there will be a transition period of scaling those tools, but <strong>in the limit</strong>, the production will be contained only by finite resources. More on this in the section below.</p><p>Now, given the existing needs will be saturated (you can only eat so much food, take so many trips, and watch this much Netflix), the question arises: Will we be able to create new needs continuously? The limits here are:<br><strong>1. Consumption time. </strong>Indeed, it's probably not worth buying a yacht if you have no time to sail it.<br><strong>2. Purchase capacity</strong>. Indeed, if I'm out of a job, I might not be able to pay for the newest, most amazing service. I would suspect this is a limit that we are currently hitting in our economy. One solution that is currently heavily employed is debt. More on this in Section 3</p><p>The actual \"final state\" will be defined by the limit we hit first. If my guess on the purchase capacity limit is correct, TAI will only accelerate the existing trend of increasing inequality. If no radical economic restructuring is introduced (e.g., universal basic income), and the TAI capital is conscious of not allowing mass poverty and thus civil unrest to set into place, the TAI economy will look very much like the modern economy - having tonnes of workforce who produce services of questionable value just to keep the population engaged in the economy. This is a very critical view, however, terms like <a href=\"https://en.wikipedia.org/wiki/Bullshit_Jobs\">Bullshit_Jobs</a> and <a href=\"https://fortune.com/longform/tiktok-economy-monetization-business-social-media-platforms-creators/\">tiktok economy</a> display some features of the modern economy that probably would have been considered dystopian in the mid-XX century. This is still \"okay,\" though, for I doubt the reader of this post is a blue-collar worker and, as such, is already a proud citizen of our common simulacra. Keep calm and sell <s>signs</s> services!</p><h1>&nbsp;2. Resource wars</h1><p>As mentioned above, resources are limited. Imagine we are at the point where robots learned how to construct factories to build more compute, more cars, more buildings, more robots, and more power plants (solar, nuclear, fusion). And imagine that those robots are cheap. Well, probably before we hit the consumption limit, we will hit the resource limit, at least for uranium and rare earth minerals. There is a reason the word \"rare\" is in the name. Now, this is when it will be decided who gets to be rich and who gets to be the rest. Control the resources, defend them enough, and you are winning the race. And, of course, the resources define not only the regular economy but also the defense capacity.</p><p>Today, the US and China have substantial reserves of rare earth elements. GPT4 estimates US reserves to last for 250 years, which means that this limit will be hit if the production of electronic equipment scales up a factor of ~100.</p><h1>3. Debt</h1><p>Debt is a solution to consumption capacity exhaustion. A peculiar norm existing now in Switzerland is the never-pay-off mortgage. You see, real estate is so expensive here that many people cannot afford to pay it off in their lifetime. Well, when you die, your kids can decide if they want to keep paying. Many people think it's a great deal since the interests are lower than the rate. Yet, if one accounts for a 20% down payment, it is basically the same. An extra beautiful passage is that you can use your pension for the down payment. Buy now, think later.</p><p>Apart from real estate and your pension, what else can you provide as a security for the debt? Dystopian scenarios would include some forms of freedom limitation (e.g., you'd agree to relocate if needed, you'd sign some NDAs that limit your freedom of speech, or you'd sell your voting rights). As bad as it sounds, these already exist in some rudimentary forms nowadays in poor societies. My relative used to sell her voice for a monthly supply of sunflower oil and sugar during turbulent years of young Ukrainian democracy.</p><h1>Where I am wrong</h1><p>Thinking-in-limits does not always work in physics. It assumes that the problem is still a well-formulated problem, even in the limit. This is not always the case and probably is not the case in economics. Most likely, we'll go through a series of \"phase transitions.\" That is, new qualitative change will emerge that will not obey modern market economy rules.</p><p>An optimistic (fantastic) subjective view of possible emergent phenomena:&nbsp;<br>- universal basic income &nbsp;<br>- abundance kills consumerism<br>- economy reshapes into targeting spiritual values</p><p>Of course, there's the whole zoo of other dystopian scenarios I don't describe.</p><h1>Why this is useful</h1><p>Assuming we are on the trajectory to the limits, the described effects can still be counteracted with policy. Policy is slow, so it's better to think about it sooner than later.</p><h3>What will I do about it</h3><p>- educate myself on economics, conflict, and forecasting<br>- have a plan <s>A</s> B to not to get poor too soon<br>- see the reaction to this post (if any) -&gt; update, if confirmative - spread the word.</p>", "user": {"username": "Ivan Madan"}}, {"_id": "pvBWDLwtw8A4rA6DF", "title": "AMA: Ben West, former startup founder and EtGer", "postedAt": "2023-11-07T22:04:05.049Z", "htmlBody": "<p>Hey everyone! I'm Ben, and I will be doing an AMA for&nbsp;<a href=\"https://forum.effectivealtruism.org/giving-portal\"><u>Effective Giving Spotlight week</u></a>. Some of my relevant background:</p><ol><li>In 2014 I cofounded a company for earning to give (EtG) reasons (largely&nbsp;<a href=\"https://80000hours.org/career-reviews/tech-entrepreneurship/\"><u>inspired by 80k</u></a>), which was later&nbsp;<a href=\"https://www.alphaii.com/news/entry/alpha-ii-llc-accelerates-revenue-cycle-management-solutions-with-acquisition-of-health-efilings\"><u>successfully acquired</u></a>.</li><li>Since late 2018 I have been doing direct work, currently as <a href=\"https://forum.effectivealtruism.org/posts/3wBCKM3D2dXkXnpWY/announcing-cea-s-interim-managing-director\">Interim Managing Director of CEA</a>.<ol><li>(With a brief side project of founding a TikTok-related company which was&nbsp;<a href=\"https://www.statistok.com/acquisition\"><u>similarly acquired</u></a>, albeit for way less money.)</li></ol></li><li>I've had some other EtGish work experience (eight years as a software developer/middle manager, a couple months at Alameda Research) as well</li><li>Additionally, I\u2019ve talked to some people deciding between EtG and direct work because of my&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/n7vQwzM2gdmCJbQaF/earn-to-give-usd1m-year-or-work-directly#I_asked_Ben_West_from_the_Centre_for_Effective_Altruism\"><u>standing offer</u></a> to talk to such folks, so I might have cached thoughts on some questions.</li></ol><p>You might want to ask me about:&nbsp;</p><ol><li>Entrepreneurship</li><li>Trade-offs between earning to give and \u201cdirect work\u201d&nbsp;</li><li>Cosmetics and skincare for those who (want to) look masculine</li><li>TikTok</li><li>Functional programming (particularly Haskell)</li><li>Or one of&nbsp;<a href=\"https://xn--g5haa57298bbab.ws/\"><u>my less useful projects</u></a></li><li>Anything else (I might skip some questions)</li></ol><p>I will plan to answer questions&nbsp;<strong>Thursday, November 9th</strong>. Post them as comments on this thread.&nbsp;</p><p>See also&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/L8N4uh4GixhWCoGAg/ama-earning-to-give\"><u>Jeff\u2019s AMA</u></a>, which is on a similar topic.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pvBWDLwtw8A4rA6DF/p3lbtvvjqagzgskzxlzd\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pvBWDLwtw8A4rA6DF/ofwavh5fycgi6qzdtdev 142w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pvBWDLwtw8A4rA6DF/yexg9s49b4d1rpaehjau 222w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pvBWDLwtw8A4rA6DF/a0onqrios8trw35l2cma 302w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pvBWDLwtw8A4rA6DF/cya8yub9y3xzbbfzaj6y 382w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pvBWDLwtw8A4rA6DF/ckwltvfgiiymefvgwrsm 462w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pvBWDLwtw8A4rA6DF/cski1xf3my09nc2bqexf 542w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pvBWDLwtw8A4rA6DF/fq8cuipawef6lmn4xzes 622w\"></figure>", "user": {"username": "Ben_West"}}, {"_id": "B2t559dP65ffKZsDa", "title": "Announcing Athena - Women in AI Alignment Research", "postedAt": "2023-11-07T22:02:55.041Z", "htmlBody": "<p>Athena is a new research mentorship program fostering diversity of ideas in AI safety research. We aim to get more women and marginalized genders into technical research and offer the support needed to thrive in this space.&nbsp;</p><p>&nbsp;</p><p>Applications for scholars are open until December 3rd, 2023</p><p>Apply as a scholar:&nbsp;<a href=\"https://forms.gle/HVZ4L6FeeBQc9yWd8\"><u>here</u></a></p><p>Apply as a mentor or speaker:&nbsp;<a href=\"https://forms.gle/nF6u7qTgpSgk6KAWA\"><u>here</u></a></p><p>Financial aid is available for travel expenses for the in-person retreat to those otherwise unable to attend without it</p><p><img style=\"width:66.27%\" src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/pJ9qWeBRRuvPvnoNK/ir6viglg8bsblwytib32\"><br><strong>Program Structure</strong></p><p>A 2-month hybrid mentorship program for women looking to strengthen their research skills and network in technical AI safety research beginning in January 2024.&nbsp;</p><p>This includes 1-week in-person retreat in Oxford, UK followed by a 2-month remote mentorship by established researchers in the field, with networking and weekly research talks.&nbsp;</p><p>&nbsp;</p><p>Athena aims to equip women with the knowledge, skills, and network they need to thrive in AI safety research. We believe that diversity is a strength, and hope to see this program as a stepping stone towards a more diverse and inclusive AI safety research field.</p><p>This program is designed to offer mentorship opportunities to technically qualified women who are early in their AI safety research careers or looking to transition into the field by connecting them with experienced mentors, resources to upskill, networking, and a supportive community.&nbsp;</p><p>&nbsp;</p><h3><strong>Who should apply?</strong></h3><p>Women and people of other&nbsp;<a href=\"https://wit.abcd.harvard.edu/mission#:~:text=What%20do%20we%20mean%20by,many%20other%20marginalized%20gender%20identities.\"><u>marginalized genders</u></a> that have some research or technical industry experience, and are interested in transitioning to AI Alignment research or have a bit of experience in the Alignment field but are looking for more support. We encourage those with a non-traditional background to apply and welcome interdisciplinary work in this field.&nbsp;</p><p>&nbsp;</p><h3><strong>Application process</strong></h3><p>Submit the online application questions -&nbsp;<a href=\"https://forms.gle/HVZ4L6FeeBQc9yWd8\"><u>here</u></a></p><p>Complete an interview with the founder and one other AI safety researcher</p><p>Additional possible interviews with mentor</p><p>&nbsp;</p><h3><strong>Questions?&nbsp;</strong></h3><p>Email: claire@researchathena.org</p><p>&nbsp;</p><h3><strong>Why are we doing this</strong></h3><p><strong>The current culture requires a shift to retain a diverse set of qualified researchers</strong></p><p>Athena aims to increase the number of women pursuing careers in AI alignment, which is currently a male-dominated field with a very specific culture that can initially come across as unwelcoming to those that aren\u2019t traditionally represented here. Women may have different hurdles to cross than their male counterparts such as implicit and explicit bias, different family and home obligations, unwanted approaches for romantic relationships by male colleagues, isolation, and a lack of representation.&nbsp;</p><p>We want to take steps to shift the current culture to one that values diversity and inclusivity through recruiting qualified women into the field through extended outreach, providing technical mentorship with an experienced researcher, creating a targeted support structure during the program, and continued role and grant placement support after the program. There are also opportunities for networking and collaboration within the larger research ecosystem.</p><p>&nbsp;</p><p><strong>Having diverse research teams and ideas is valuable for AI Alignment research</strong></p><p>Research has consistently shown that diverse teams produce more innovative solutions. When we have a diverse group of people, including women, working on AI alignment, we are more likely to come up with comprehensive and holistic solutions that consider a wide range of perspectives and people.&nbsp;When more women participate in traditionally male-dominated fields like the sciences, the breadth of knowledge in that area usually grows, a surge in female involvement directly correlates with advancements in understanding [<a href=\"https://www.nationalgeographic.com/culture/article/141107-gender-studies-women-scientific-research-feminist\"><u>1</u></a>]. Since there is a lack of women in this field, Athena aims to prepare women to join a research team or position after the program, where that team will benefit from this.</p><p>&nbsp;</p><p><strong>Research suggests that all-women programming can provide benefits to women&nbsp;</strong></p><p>Cox &amp; Fisher (2008) found that women in a single-sex environment in a software engineering course reported higher levels of enjoyment, fairness, motivation, support, and comfort and allowed them to perform at a level that exceeded that of the all-male groups in the class [<a href=\"https://www.informingscience.org/Publications/175?Source=%2FJournals%2FJITEResearch%2FArticles%3FVolume%3D0-0\"><u>1</u></a>].&nbsp;</p><p>Kahveci (2008) explored a program for women in science, mathematics, and engineering and found that it helped marginalized women move towards legitimate participation in these fields and enhanced a sense of community and mutual engagement [<a href=\"https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/sce.20234\"><u>2</u></a>].&nbsp;</p><p>&nbsp;</p><p><strong>Creating more representation for future policy advisors and makers</strong></p><p>As government awareness and sense of urgency grows for AI-related decision-making and legislation, we need a diverse range of experts in the field to help policy makers make informed decisions. If we only have a specific type of person in this position, the policies will reflect that, maybe to our detriment. Women\u2019s participation in decision-making is highly beneficial and their role in designing and applying public policies has a positive impact on people\u2019s lives</p><p>\u201cIt is not about men against women, but there is evidence to show through research that when you have more women in public decision-making, you get policies that benefit women, children and families in general. When women are in sufficient numbers in parliaments they promote women\u2019s rights legislation, children\u2019s rights and they tend to speak up more for the interests of communities, local communities, because of their close involvement in community life. [<a href=\"https://ourworld.unu.edu/en/everyone-benefits-from-more-women-in-power\"><u>2</u></a>]<br>&nbsp;</p>", "user": {"username": "Claire Short"}}, {"_id": "NXeDGYnbPYtNFHv4w", "title": "12 research aphorisms nobody asked for and yet", "postedAt": "2023-11-07T21:50:49.113Z", "htmlBody": "<ol><li>You can always make it shorter.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefd92av0bqcbk\"><sup><a href=\"#fnd92av0bqcbk\">[1]</a></sup></span><ol><li>Lists are good for that.</li><li>Knowledge nets like <a href=\"https://www.remnote.com/\">RemNote</a> and <a href=\"https://obsidian.md/\">Obsidian</a> even better.<ol><li>Read Andy's Evergreen Garden on the topic of knowledge nets and spaced repetition. By that I mean you should at most skim it of course.</li></ol></li></ol></li><li>As a consequence of the above point, you can always <i>read</i> it faster. Most stuff is fluff, so you can get away with skimming most of the time.</li><li>Don't try to come up with new ideas; just try your utmost to hold on to what you know (preferably via spaced repetition), and new ideas automatically appear.<ol><li>The Forgetting Curve decays exponentially (there's a Lindy effect wrt memory), which means reviewing a near-forgotten idea will have exponentially greater return (in terms of retention / opportunities to find a use-case) than learning something new. Resist the recency effect.</li></ol></li><li>Aim your ideas at your own head.<ol><li>If the ideas you came up with for your own purposes happen to potentially be usefwl for someone, you may teach as a side-project, but making it your main quest is worse for both purposes.</li></ol></li><li>Don't compromise your purpose.<ol><li>If you're sampling for ideas (or anything) that conjunctively score high on&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"N\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>&nbsp;independent criteria, the probability decreases exponentially with&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"N\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span></span></span></span></span></span>. Assume each variable has the same probability&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span></span></span></span></span>&nbsp;of scoring above the threshold, and the probability that each of them do is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p^N\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;\">N</span></span></span></span></span></span></span></span></span>. Unless the <i>utility</i> of the idea increases multiplicatively with each IID criterion it satisfies, the conjunctive search is unlikely to be worth it, and you should consider horizontally segmenting your search.</li></ol></li><li>Optimise the generator.<ol><li>Ahmdal's law: the efficiency gained by optimizing a single part of a system is limited by the fraction of time that the improved part is actually used.</li><li>A marginal improvement in your sleep-quality, or the way you process ideas, may have an immense impact on you as a goodness-generating system.</li><li>Because of point 5, one of the most important variables you can optimise within yourself, is how aligned your mind is with the idea of helping others. It is extremely typical [citation needed] for altruists to have confounders in their own motivations &amp; thinking-habits without being aware of it, especially as relates to social belonging, prestige, and not being laughed at. But these compromising confounders have a heavy cost wrt idea-sampling.</li></ol></li><li>Learn the generalized game.<ol><li>You need <i>fewer parameters</i> to specify a generalized game (eg <i>NxN</i>-sudoku) compared to specific variants, but if you solve the former, that often mostly solves the variants by extrapolation. This is one aspect of the inventor's paradox, and it implies that it's sometimes <i>easier</i> to be more ambitious.</li></ol></li><li>Roll the biggest dice<ol><li>Rolling 1d60 vs 10d6 is the same max and ~same avg, but the former has a&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{1}{60}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.849em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.2em; top: -1.372em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.2em; bottom: -0.687em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">60</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.849em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.456em; vertical-align: -0.486em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span>&nbsp;chance of max, whereas the latter has only&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"6^{-10}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">6</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">10</span></span></span></span></span></span></span></span></span></span></span>.</li><li>Projects whose outcome depends on fewer variables tend to have longer tails.</li></ol></li><li>\u521d\u5fc3<ol><li>Consider all projects first from a perspective where you assume nobody has ever tried it before.</li><li>For all questions you encounter, act as if it's your first time, act as if nobody has ever asked it before.</li><li>How does an artist learn to draw? As soon as they stop relying on their teacher's eyes as proxies for their own\u2014as soon as they learn to see. Unless you do both, you have no internal feedback-loop by which you can independently grow.</li></ol></li><li>\u77e5\u884c\u5408\u4e00<ol><li>Knowledge that doesn't <i>change you</i> is no knowledge at all. You gain wisdom in proportion to how much you change. The one thing you should monitor at all times is your rate of change wrt anything you think you're learning from.</li><li>If you read a whole textbook with no perceptible general changes in your behaviour (knock-on effects due to credentials don't count), that was worth less to you than a random tweet you somehow found the motivation to process truly and deeply.</li></ol></li><li>Make up a dumb plan, and pursue it at full speed until you learn why it's dumb.<ol><li>Then make up another dumb plan, and repeat until you find yourself at the completion of a plan you couldn't figure out the dumbness of. Maybe it was worth doing after all.</li><li>More than anything, dumb plans and naive models provide you with <i>sensitivity to evidence</i>, and lets you learn much faster. \u0394.</li></ol></li><li>Read less. Think more.<ol><li>Your brain is much better than you think, once you learn to unconditionally support it as it clumsily emerges from the confines you've kept it in.<ol><li>Those near you may not like it; but those far from you may benefit.</li></ol></li></ol></li></ol><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnd92av0bqcbk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefd92av0bqcbk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Bonus aphorism: we teach what we most wish to learn\u2026</p></div></li></ol>", "user": {"username": "Mir"}}, {"_id": "ceaoak8ke3cZg9dAh", "title": "Food ethics in the newest Rick & Morty episode", "postedAt": "2023-11-07T20:47:55.423Z", "htmlBody": "<p>The newest episode of the TV show Rick &amp; Morty may be of interest to EAs interested in the ethics of food, veganism, factory farming, clean meat, &amp; moral dilemmas.</p><p>'<a href=\"https://en.wikipedia.org/wiki/Rick_and_Morty_(season_7)\">Rick &amp; Morty</a>' is a popular American cartoon with science fiction themes. The latest episode (Season 7, Episode 4, 'That's Amorte', released Nov 5, 2023) directly addresses several moral issues in meat consumption. It starts off innocently enough with a family spaghetti dinner. I don't want to give any spoilers; I just highly recommend it.</p><p>The Rick &amp; Morty episodes are short enough (about 22 minutes) that they could easily be used to spark discussions in local EA meetup groups, EA classes, or EA conferences.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ceaoak8ke3cZg9dAh/f4gmgytihddydcrfmbqi\" alt=\"Rick and Morty' Works Without Justin Roiland\"></figure>", "user": {"username": "geoffreymiller"}}, {"_id": "txgQDuTiijnNtB7vm", "title": "#170 \u2013 How air pollution is responsible for ~12% of global deaths \u2014 and how to get that number down (Santosh Harish on the 80,000 Hours Podcast)", "postedAt": "2023-11-07T19:38:13.025Z", "htmlBody": "<p>We just published an interview: <a href=\"https://80000hours.org/podcast/episodes/santosh-harish-air-pollution/\">Santosh Harish on how air pollution is responsible for ~12% of global deaths \u2014 and how to get that number&nbsp;down</a>. <a href=\"https://open.spotify.com/show/2WzJwXWBDnn4iZ7odKwDib?si=T3Bboj1YQWGc383Tns0FaA&amp;nd=1\">Listen on Spotify</a> or click through for other audio options, the transcript, and related links. Below are the episode summary and some key excerpts.</p><h2><strong>Episode summary</strong></h2><blockquote><p><i>One [outrageous example of air pollution] is municipal waste burning that happens in many cities in the Global South. Basically, this is waste that gets collected from people\u2019s homes, and instead of being transported to a waste management facility or a landfill or something, gets burned at some point, because that\u2019s the fastest way to dispose of it \u2014 which really points to poor delivery of public services. But this is ubiquitous in virtually every small- or even medium-sized city. It happens in larger cities too, in this part of the world.</i></p><p><i>That\u2019s something that truly annoys me, because it feels like the kind of thing that ought to be fairly easily managed, but it happens a lot. It happens because people presumably don\u2019t think that it\u2019s particularly harmful. I don\u2019t think it saves a tonne of money for the municipal corporations and other local government that are meant to manage it. I find it particularly annoying simply because it happens so often; it\u2019s something that you\u2019re able to smell in so many different parts of these cities.</i></p><p>- Santosh Harish</p></blockquote><p>In today\u2019s episode, host Rob Wiblin interviews Santosh Harish \u2014 leader of <a href=\"https://www.openphilanthropy.org/research/south-asian-air-quality/\">Open Philanthropy\u2019s grantmaking in South Asian air quality</a> \u2014 about the scale of the harm caused by air pollution.</p><p>They cover:</p><ul><li>How bad air pollution is for our health and life expectancy</li><li>The different kinds of harm that particulate pollution causes</li><li>The strength of the evidence that it damages our brain function and reduces our productivity</li><li>Whether it was a mistake to switch our attention to climate change and away from air pollution</li><li>Whether most listeners to this show should have an air purifier running in their house right now</li><li>Where air pollution in India is worst and why, and whether it\u2019s going up or down</li><li>Where most air pollution comes from</li><li>The policy blunders that led to many sources of air pollution in India being effectively unregulated</li><li>Why indoor air pollution packs an enormous punch</li><li>The politics of air pollution in India</li><li>How India ended up spending a lot of money on outdoor air purifiers</li><li>The challenges faced by foreign philanthropists in India</li><li>Why Santosh has made the grants he has so far</li><li>And plenty more</li></ul><p><i>Producer and editor: Keiran Harris</i><br><i>Audio Engineering Lead: Ben Cordell</i><br><i>Technical editing: Simon Monsour and Milo McGuire</i><br><i>Transcriptions: Katy Moore</i></p><h2><strong>Highlights</strong></h2><h3><strong>How bad is air pollution?</strong></h3><blockquote><p><strong>Santosh Harish:</strong> Air pollution is the single largest environmental and occupational risk factor to public health globally. Per the <a href=\"https://www.healthdata.org/research-analysis/health-risks-issues/air-pollution\">Global Burden of Disease estimates</a>, it accounts for something like 6.67 million deaths a year, as of 2019 \u2014 which, to give context, is about 12% of all deaths globally. Not all of this is particulate matter. Particulate matter is the vast majority of this, but a small fraction of this is what\u2019s called <a href=\"https://en.wikipedia.org/wiki/Ground-level_ozone\">ground-level ozone</a>. But yeah, it\u2019s pretty bad. When I started working on air pollution, which is about roughly a decade back, some of these high numbers were hard to come to terms with. It almost seems implausibly large, intuitively, because you\u2019re like, it\u2019s presumably bad for your lungs or something, but could it really be this bad?</p><p>So the thing about air pollution, which makes it so harmful \u2014 in particular particulate matter air pollution \u2014 is that particulate matter is not a single substance. It\u2019s a cocktail of various things that are in the air that just happen to be finer than 2.5 microns in diameter \u2014 which is a tiny fraction of how thick your hair is. It is composed of a variety of chemical substances, some of which are relatively harmless, some of which are extremely toxic. So it could be stuff like soil dust, which is naturally occurring, or sea salt \u2014 which are likely to be not particularly harmful. And then there is stuff like lead and other heavy metals that are suspended in the air. There are inorganic compounds like sulphates and nitrates which originate from vehicle emissions, from coal power plant emissions and so on. So it\u2019s a variety of different things.</p><p>Because these particles are as fine as they are, they are able to enter the lungs, enter the systemic circulation \u2014 and then basically these various things that have no business being in our body can travel to different organs and cause a variety of different harms.</p><p><strong>Rob Wiblin:</strong> What is perhaps the most outrageous or emotionally grabbing example of air pollution to you?</p><p><strong>Santosh Harish:</strong> One thing that comes to mind is municipal waste burning that happens in many cities in the Global South. Basically, this is waste that gets collected from people\u2019s homes, and instead of being transported to a waste management facility or a landfill or something, gets burned at some point, because that\u2019s the fastest way to dispose of it \u2014 which really points to poor delivery of public services. But this is ubiquitous in virtually every small- or even medium-sized city. It happens in larger cities too, in this part of the world.</p><p>So I think that\u2019s something that truly annoys me, because it feels like the kind of thing that ought to be fairly easily managed, but it happens a lot. It happens because people presumably don\u2019t think that it\u2019s particularly harmful. I don\u2019t think it saves a tonne of money for the municipal corporations and other local government that are meant to manage it. That\u2019s one example that comes to mind. I find it particularly annoying simply because it happens so often; it\u2019s something that you\u2019re able to smell in so many different parts of these cities.</p><p>Another which seems downright evil to me is a whole bunch of industries that tend to not use the pollution control equipment that they have in their facilities already. And just basically dump the <a href=\"https://en.wikipedia.org/wiki/Flue_gas\">flue gas</a>, as it\u2019s called \u2014 the gas that gets emitted from the various processes in the industry \u2014 without the emission controls, in the middle of the night, when it\u2019s not obvious and it can\u2019t be detected as easily as it would in the day. And this is basically to, again, save what I suspect is change in terms of maintenance and operation costs of this equipment. You have the equipment and there are these standards. So that\u2019s I think downright evil on the part of these industries.</p></blockquote><h3><strong>Misconceptions about air pollution</strong></h3><blockquote><p><strong>Santosh Harish:</strong> One that is actually a significant hindrance to effective policy in India and similar countries is that air pollution is assumed to be an urban problem. This was certainly true in big industrial cities and so on, where air pollution started becoming visible and salient \u2014 thinking of London, Pittsburgh, Los Angeles.</p><p>In places like India, though, that\u2019s just not true, because rural air pollution can be significant. In fact, on average, rural exposure is not very different from urban exposure. One of the largest sources of air pollution exposure in India, in Pakistan, a whole bunch of other countries, would actually be the household burning of solid fuels: wood and dung cakes and things like that.</p><p>So it\u2019s actually not at all an urban issue alone, and historically, it has been treated as that. For example, there are no rural air quality monitors in India. It\u2019s sort of a chicken-and-egg thing. Until recently, the response to why there aren\u2019t monitors there was that we know villages are clean; that\u2019s where you go when you have respiratory problems and so on, right? So it neither gets measured \u2014 because it\u2019s assumed to be not a problem \u2014 and because there isn\u2019t any measurement to suggest otherwise, that never really gets updated.</p><p>Because there are alternative sources of data now \u2014 satellite-data-based estimates of air pollution, for example \u2014 I think there is growing evidence that rural air pollution can be substantial, and therefore there has been a growing demand for air quality monitoring in rural areas.</p><p>Another misconception that in some ways we touched upon is that there are sort of \u201csafe\u201d levels of air pollution; it\u2019s only the truly apocalyptic levels \u2014 that one sees, for example, in winters in places like Delhi and so on \u2014 that\u2019s what harms you. That, unfortunately, just doesn\u2019t seem to be true. Impacts have been detected at much lower levels that were previously considered safe.</p><p>An unusual type of misconception that\u2019s sometimes popular in government circles is that air pollution is something that you can build immunity to.</p><p><strong>Rob Wiblin:</strong> Oh, wow. I\u2019ve never heard that one.</p><p><strong>Santosh Harish:</strong> Yeah, it\u2019s something that\u2019s as ridiculous as that sounds.</p><p><strong>Rob Wiblin:</strong> I guess it\u2019s like if you go out in the sun a lot, maybe you get a tan, which slightly helps you to not get sunburned. But I don\u2019t imagine your body can do that with particulate pollution.</p><p><strong>Santosh Harish:</strong> Yeah, so there is this insistence by I certainly don\u2019t think all regulators, but by some, that Indian lungs, for example, are just better able to handle air pollution than, for example, American lungs. Because we\u2019ve been exposed to it over a period of time.</p><p><strong>Rob Wiblin:</strong> You\u2019re used to it.</p><p><strong>Santosh Harish:</strong> We have gotten used to it, so we don\u2019t routinely fall sick when the levels of air pollution are high. And when somebody\u2019s visiting Delhi or something, you feel it \u2014 you feel the difference quite viscerally. So that clearly points to Indian lungs being better adapted. That\u2019s of course nonsense, but it\u2019s unfortunately a persistent myth that has been hard to shake off.</p><p>One of the implications of that also has been a general scepticism towards the public health impact estimates from sources like the GBD here. So there\u2019s an insistence that we need more indigenous research, studying health impacts in Indian populations, and that these extrapolations from other parts of the world are just not reliable.</p></blockquote><h3><strong>Why air pollution has gotten worse in India</strong></h3><blockquote><p><strong>Santosh Harish:</strong> I think at a high level it\u2019s less about policy mistakes than it has been about policy neglect. So the <a href=\"https://cpcb.nic.in/air-pollution/\">Air Act</a> in India dates back to 1981, and in many ways the regulatory apparatus that resulted from the Air Act reflects the understanding of that time. There are pollution control boards at the state level and at the central or federal level, and these have been primarily set up to deal with industrial pollution, because at the time that was the general sense, that this has got to be an industrial emissions problem.</p><p>Over time, in the mid to late 1990s, primarily because of civil society advocacy and the interventions of the judiciary, the Supreme Court of India, it expanded to include vehicular emissions in big cities. But until maybe the middle of the last decade \u2014 around 2013, 2014, 2015 \u2014 in many ways air pollution once again started becoming more visible in Indian media, and therefore it became more salient, and there were a bunch of these source apportionment studies that got commissioned and got publicised. That was it; that was basically the extent to which the regulatory apparatus was readied. So these other sources, like waste burning or household burning, were completely neglected, right?</p><p>Household burning, for example, I think we\u2019ve still not recovered from that. It\u2019s assumed that the household burning of solid fuels is something that leads to indoor air pollution, and that it really doesn\u2019t have much of an impact on pollution outdoors. That\u2019s just not true as per the literature. So that\u2019s been completely neglected, and treated as a distinct problem. Because the regulatory apparatus has been set up for industrial pollution, the pollution control boards are not really well equipped to deal with the updated understanding of where air pollution seems to come from, and therefore what you ought to be doing about it.</p><p>So if you consider, for example, waste burning: this is something that really falls under the jurisdiction of the municipal corporations \u2014 the local government. The municipal corporations have never had to think about air pollution ever, right? This simply isn\u2019t something that they think of as something that falls under their mandate, until at least very recently. And therefore the agencies that are supposed to be doing something about air pollution \u2014 the pollution control boards \u2014 don\u2019t have the jurisdiction on this source; while the agencies that do have the jurisdiction have not had the regulatory experience or the capacity to deal with this. Therefore it has sort of fallen between the cracks a bit.</p><p>In terms of policy missteps, though, when it comes to industrial pollution, the regulatory regime in many ways has not been designed in a manner that is flexible enough and sufficiently in sync with the challenges of regulation in the field. So with industrial emissions, typically the way regulation functions is that all of these industries that pollute have chimney stacks from where the flue gas and the other pollutants escape. For the longest time, across the world, regulation was basically about the height of the chimney stack: the assumption was that you make that tall enough, and the impacts are not felt in the immediate vicinity. Which is not untrue, except that pollution can travel, and over time all of this adds up.</p><p>So the next generation of regulation in many ways was to set standards for what the concentrations of pollutants in these chimneys could be. There is a mechanism by which the pollutants are measured in the chimney. You compare it with what the regulatory standard ought to be. In order to comply with these standards, the industries basically install a bunch of pollution control equipment \u2014 <a href=\"https://en.wikipedia.org/wiki/Scrubber\">scrubbers</a> and filters and things called <a href=\"https://en.wikipedia.org/wiki/Cyclonic_separation\">cyclones</a> and so on \u2014 which are meant to clean up the air. And regulators basically measure this from time to time. If you\u2019re found to be above the standards that have been given to you, there is some form of punitive action.</p><p>The way this mechanism has been set up in India has relied on what are called <a href=\"https://www.eea.europa.eu/help/glossary/eea-glossary/command-and-control\">command-and-control instruments</a>. Basically, there is a standard, and you\u2019re meant to be under that standard. Somebody comes and measures this from time to time. If you\u2019re above that standard, it is a criminal offence, and therefore there\u2019s going to be a lawsuit filed against you. You could land up in jail and pay a fine of some kind. In practice, the legal system in India is backed up: most cases take years and years and years. The actual compliance against these standards is quite poor: based on some data from a few years back, something like <a href=\"https://www.ncaer.org/wp-content/uploads/2022/09/The-Solvable-Challenge-of-Air-Pollution-in-India_Michael-Greenstone-Santosh-Harish-Rohini-Pande-Anant-Sudarshan.pdf\">50% of industries</a> in the state of Maharashtra, for example, were not in compliance with the particulate matter norms.</p><p>So there\u2019s widespread noncompliance, the pollution control boards are understaffed, and there is no real mechanism by which they can go after these many industries that are flouting the law. As a result, for the most part, the regulatory regime just sort of fails. So if a particular industry is found to be noncompliant, there is a gentle slap on the wrist, there is some kind of polite correspondence where the regulator writes to the industry and asks them to explain themselves, and it sort of ends with that. There is very little action taken.</p><p>The policy misstep, I guess, is that the evolution that the regulatory framework should have had over time \u2014 from being reliant purely on these extremely rigid, some may say even sort of draconian, command-and-control type regulations towards a wider variety of more flexible tools that allow the regulator to levy fines without having to file a criminal lawsuit and so forth \u2014 that evolution just did not happen. And as a result, noncompliance became widespread. The amount of industrial activity in the country increased; the pollution control boards were never really able to keep up with it. And the one source of air pollution that ought to have been regulated well also did not see much progress.</p></blockquote><h3><strong>Why aren't people able to fix these problems?</strong></h3><blockquote><p><strong>Rob Wiblin:</strong> From what I\u2019ve heard, I think you mentioned in a talk that, oddly enough, in India, when air pollution comes up, city governments can turn to outdoor air purifiers, for example, as a possible solution. Maybe because it\u2019s very visible and it kind of looks cool, but it is incredibly expensive and incredibly ineffective, as you might imagine, sticking an air purifier outside: there\u2019s only so much that is possibly going to do if you haven\u2019t done anything to control the source of the air pollution.</p><p>What is going wrong there? Why aren\u2019t people able to fix these problems, given that it seems kind of obvious what improvements there might be?</p><p><strong>Santosh Harish:</strong> Right. So starting with the outdoor air purifiers, I guess the charitable way of seeing it\u2026 I mean, I\u2019m a fairly optimistic person, so I guess one way you could see this is that this, in some ways, is a manifestation of the public demand for cleaner air going up, and governments at least being forced to do something. And <a href=\"https://en.wikipedia.org/wiki/Smog_tower\">smog towers</a>, as they are called, you could imagine the case for them: that they\u2019re sort of plausibly useful, they\u2019ll do something; they\u2019re physical, visible manifestations of the intent of governments to clean up the air. And perhaps equally importantly, it leaves nobody worse off in the near term.</p><p>That\u2019s one reason why smog towers are so attractive. Most regulation has winners and losers. And here, except for the taxpayers who might not be noticing it, nobody\u2019s really left worse off, and therefore it is politically very viable. But yeah, let\u2019s be clear: this is an absolute waste of resources. They will do absolutely nothing. I mean, sure, they may clean up the air a couple of metres away from wherever they are stationed, but it\u2019s highly ineffective.</p><p>Part of the problem here seems to be that the sources are visible, sure. For some of them, there are obviously good longer-term actions that you ought to be taking. So vehicles are a problem: you need to reduce the number of private vehicles on the road; you need to reduce the number of dirty vehicles on the road. So you can have a bunch of policy actions that try to clean up the fleet, that could potentially improve the public transport infrastructure in cities and things like that.</p><p>But in the near term, which most governments try to optimise for, one of the challenges is that we don\u2019t have a menu of easy-to-implement, scalable solutions. I think that has been one of the challenges. I think there\u2019s a legitimate uncertainty. You know, if you were a municipal commissioner in one of the Indian cities, or you were the secretary in the Department of Environment at a state level, and you had a pot of money to be able to deploy, I do think that there is a certain gap in terms of saying, \u201cOK, here are the top 10 things that you ought to be doing; here are the most cost-effective interventions that you ought to be investing in.\u201d I think that there\u2019s actually a significant gap in the literature. It\u2019s not sufficient to say that you need to have more buses on the roads: that might not be under your mandate, or that might be much more expensive than you can afford in the near term with the constraints you\u2019ve got.</p><p>I think that\u2019s been one of the challenges with being able to make progress in India. As a result, for the most part, what the cities have been doing is basically dust-control type measures: having these mechanical street sweepers clean up the roads. They\u2019ll do something; we don\u2019t necessarily know how much they actually improve the air pollution even on these roads.</p><p>That\u2019s, for example, some of the stuff that <a href=\"https://www.openphilanthropy.org/grants/world-resources-institute-city-government-support-for-air-quality/\">we\u2019ve just funded</a>, to try and get a handle on how much of an impact this might truly have. It\u2019s not obvious at all that these are cost-effective things to be putting your money behind, but it\u2019s the kind of thing where it\u2019s not expensive enough for the government agencies not to be able to procure them. Again, it\u2019s the kind of capital investments that the corporations can do more easily than some of the harder improvements \u2014 in terms of how you operate, how waste management in a particular city functions. That\u2019s a systemic thing, right? It\u2019s much easier to purchase 10 of these street sweepers or something, put them on the road, and hope to God that it makes a difference. And unfortunately, that\u2019s what they\u2019ve been doing.</p></blockquote><h3><strong>The role that courts have played in air pollution regulation in India</strong></h3><blockquote><p><strong>Santosh Harish:</strong> The judiciary has played an outsized \u2014 in many ways, a completely unintuitive \u2014 role in air pollution regulation in India. Basically, there\u2019s this instrument of public interest litigations (PILs) that have been instrumental in leading to these court judgments. Some of these PILs, by the way, are still active. So they\u2019re cases that were initiated in the mid to late \u201990s that are still running today.</p><p><strong>Rob Wiblin:</strong> You\u2019re saying that the court cases are still ongoing?</p><p><strong>Santosh Harish:</strong> The court cases are still ongoing. In a sense there have been multiple orders and judgments, but it hasn\u2019t concluded. And the court continues to play this quasi-executive, sometimes quasi-legislative, role in designing policy. Some of those interventions, I think, were ultimately good and resulted in improvements. Some of those judgments have actually been pretty poor. The courts are simply not the places for some of these decisions to be made.</p><p><strong>Rob Wiblin:</strong> Yeah. In general, we don\u2019t expect courts to be a good place to be doing cost-benefit analysis and setting budgets and so on. It\u2019s not the strength of lawyers.</p><p><strong>Santosh Harish:</strong> That\u2019s exactly right. And it\u2019s also not the place where you necessarily have a democratic reconciliation of the various people who are affected by the judgments. I mean, the case that you mentioned of getting the buses off the road and this mandate that buses can only run on compressed natural gas. It\u2019s not obvious if the state government or the federal government would have made that call, because it\u2019s not obvious that it passes muster in terms of who\u2019s left worse off. It did paralyse public transport in Delhi. It\u2019s also true that we can be reasonably confident that Delhi\u2019s air quality actually improved for almost a period of five to eight years as a result of that ban.</p><p>Like you said, the long-term impact was that more people then relied on private vehicles, because the number of vehicles in Delhi boomed. And that was the reason there was an uptick again in pollution levels, which eventually resulted in increased attention and increased acknowledgment of the problem in like 2014, 2015. The catalyst in 2014, 2015 was, unfortunately, again the courts.</p><p>So that problem of policy neglect has manifested in the executive \u2014 and to an even larger extent, the legislature \u2014 completely ignoring the problem and the judiciary having to step in. The judiciary is sort of limited to fairly blunt instruments. The courts are not the places for cost-benefit analysis, as you put it, and that has unfortunate consequences. That\u2019s increasingly less and less the case, though. The courts have become less activist-y over time.</p><p>The smog towers in Delhi, by the way, was a direct result of a court judgment. The outdoor air purifiers came as a direct result of the courts basically demanded that Supreme Court demanded that these be set up, because something has to be done for Delhi\u2019s air quality.</p></blockquote><h3><strong>Can philanthropists drive policy change?</strong></h3><blockquote><p><strong>Santosh Harish:</strong> Yeah, I\u2019m definitely fairly bullish about the possibility of progress through the work that individual researchers and think tanks and policy advocacy groups can do. I think there are certain areas where the possibilities of leverage are pretty high and therefore small grants can have outsized impact.</p><p>One constraint as a grantmaker here is, because I represent an international foundation and the foreign funding rules in India are fairly restrictive \u2014 and this is especially the case when it comes to environmental work, which I think has often been interpreted as being adversarial when it comes to industrial and economic development in India \u2014 that does restrict the types of grants that one could make.</p><p>So for example, we talked about how the judiciary has had a huge influence. I am fairly ambivalent about the overall impact that the courts have had. I do think that some good things have happened as a result of it, but I also think that they are not necessarily the places where this decision making should be done. But either way, that seems like a potentially important institution to be able to influence or work with. But as a grantmaker, that\u2019s something that I can\u2019t touch, or at least have chosen not to touch. There is following the letter of the law \u2014 there are certain things that you can and cannot do \u2014 but there\u2019s also the spirit of the thing. And we have been fairly careful.</p><p>Media is another important agent of change. Arguably one of the things that ended up leading to this increased pace of activity since maybe 2015, 2016 was that media outlets took notice, and there were just a lot more stories. And over a period of time, these stories became more and more sophisticated in their understanding of the signs of air pollution and what governments ought to be doing and not doing and things like that. So that had an important role. Again, that\u2019s something that, as an international foundation, we can\u2019t make direct grants to.</p><p><strong>Rob Wiblin:</strong> Oh really? It\u2019s just not permitted?</p><p><strong>Santosh Harish:</strong> It\u2019s not permitted. You cannot fund journalists to write stories, because it could be interpreted that this is basically a foreign actor trying to influence the media discourse, and therefore the general narratives within a country. So some of those are the types of things that could plausibly lead to changes and have very high leverage, but stuff that we cannot and should not do.</p><p><strong>Rob Wiblin:</strong> It\u2019s off the table, unfortunately.</p><p><strong>Santosh Harish:</strong> They\u2019re off the table. As an Indian citizen, I understand where this comes from. Some of it seems to me as being potentially defensive, but this really feels above my pay grade. I think it\u2019s entirely reasonable to be compliant with the spirit of some of these restrictions, even if that means that you do have some opportunities off the table. I wish there was more domestic funding in India that was trying to go behind these opportunities and be engaged in air quality. That, unfortunately, has not been enough of the case. It\u2019s a fairly neglected area, even from a domestic funding standpoint.</p><p>So we\u2019ve had to therefore restrict ourselves to certain types of grantmaking opportunities. But I do think that there is still plenty of highly cost-effective opportunities on the table.</p></blockquote>", "user": {"username": "80000_Hours"}}, {"_id": "DQaZfaLRRGvtBsp3u", "title": "Summary of Eliezer Yudkowsky's \"Cognitive Biases Potentially Affecting Judgment of Global Risks\"", "postedAt": "2023-11-07T18:19:41.181Z", "htmlBody": "<p>This is a concise summary of Eliezer Yudkowsky's <a href=\"https://intelligence.org/files/CognitiveBiases.pdf\"><i>Cognitive Biases Potentially Affecting Judgment of Global Risks</i></a><i>.</i> I wrote this summary since it's very important information, but a long read. Hopefully this will increase the number of longtermists/x-risk researchers who are familiar with these cognitive biases and their implications. This summary is about 11% as long as the original paper; from ~13,500 words down to ~1,500.</p><p>&nbsp;</p><h3>Introduction</h3><p>If the world ends, it will probably be due to patterned flaws in human thinking than a deliberate act. This paper lists cognitive biases to be aware of, solving for which should reduce existential risks.&nbsp;</p><p>&nbsp;</p><h3>1. Availability Heuristic</h3><p>Availability Heuristic: a mental shortcut where people judge the frequency or probability of events based on how easily examples come to mind.&nbsp;</p><p>This often leads to errors, such as overestimating the likelihood of rare events and underestimating common ones, due to biases formed by media reporting and personal experience. It's noted that experiences with small-scale hazards can create a complacent attitude toward larger risks. Consequently, this heuristic might contribute to people's failure to adequately prepare for unprecedented catastrophic events, including those that could lead to human extinction, because they are outside of our collective experience.</p><p>&nbsp;</p><h3>2. Hindsight Bias</h3><p>Hindsight Bias: the tendency to believe that one would have correctly predicted the outcome of an event after the outcome is already known, thus overestimating its predictability. Also called \"the I-knew-it-all-along effect\".</p><p>A study showed that students told the outcome of historical events overestimated its predictability compared to those not informed. This bias affects legal judgments of negligence, with people more likely to deem an event as predictable after it occurs, despite instructions to avoid such bias. This bias can cause underestimation of the importance of preventive measures in avoiding disasters, such as the Challenger explosion, where earlier warning signs were not fully appreciated due to the lack of hindsight.</p><p>&nbsp;</p><h3>3. Black Swans</h3><p>Black Swans: describes rare, unpredictable events with massive impact. These events are outliers that lie outside normal expectations and are so rare that they are not often considered until they occur.&nbsp;</p><p>Hindsight bias and the tendency to overestimate the predictability of the past lead us to be ill-prepared for Black Swans. The result is a lack of preparation for unexpected events, such as the 9/11 attacks, after which specific preventative measures were taken without addressing the broader need to expect the unexpected. The prevention of such events is hard to appreciate or reward, as it's not obvious when a disaster is averted. Hence, society often fails to recognize the value of preventive measures and tends to reward heroic responses to disasters rather than the quiet avoidance of them.</p><p>&nbsp;</p><h3>4. The Conjunction Fallacy</h3><p>The Conjunction Fallacy: a bias towards predicting that a set of multiple specific conditions are more probable than a single general one. Adding details can paradoxically make an event seem more likely, even though the probability of two events occurring together (conjunction) is always less than or equal to the probability of either one occurring alone.</p><p>For example, in one study, participants were asked to rank a set of statements from most to least probable. Statements included \"Linda is a bank teller\" and \"Linda is a bank teller and is active in the feminist movement\". Participants tended to rank the latter statement as more likely than the former. The conjunction fallacy can also be observed in individuals' willingness to pay for insurance or prevention for highly specific disaster scenarios. People overvalue the likelihood of complex scenarios and undervalue simpler ones, which can skew decision-making.</p><p>&nbsp;</p><h3>5. Confirmation Bias</h3><p>Confirmation Bias: individuals often test hypotheses in a way that seeks confirming evidence, rather than disproving evidence.&nbsp;</p><p>Taber and Lodge's experiments on political attitudes have found that even balanced arguments can polarize opinions further. Decisions are often made more quickly than we are aware, and we may be less open to changing our minds than we think. Awareness of our biases is crucial to counteracting this.&nbsp;</p><p>&nbsp;</p><h3>6. Anchoring</h3><p>Anchoring: a cognitive bias where people over-rely on initial, often irrelevant information to make decisions.&nbsp;</p><p>Studies show that irrelevant numbers can influence people's estimates, a phenomenon that persists even with implausible figures and is not mitigated by incentives or warnings. The effect increases under cognitive load or pressure for quick responses. Studies find that stories, even when known to be fiction, can bias individuals' expectations and decisions.&nbsp;</p><p>&nbsp;</p><h3>7. The Affect Heuristic</h3><p>The Affect Heuristic: a mental shortcut where subjective feelings of good or bad influence judgement. People boil down information into \"good\" and \"bad\" sentiments, more so with limited time or information.&nbsp;</p><p>Slovic et al. found that people were more supportive of life-saving measures when presented as a percentage saved (\"saving 98% of lives\", as opposed to \"saving 150 lives\"). In other words, measures framed in terms of a high percentage of lives saved seemed more impactful than concrete numbers, since they were closer to a perceived upper limit. Other researchers observed that analysts judged unfamiliar stocks as either good (low risk, high return) or bad (high risk, low return) based on their overall feeling, and that with more time pressure, individuals will boil nuanced views down to an overall positive or negative sentiment.</p><p>&nbsp;</p><h3>8. Scope Neglect</h3><p>Scope Neglect: a cognitive bias where people are insensitive to the quantity of affected entities when making decisions about resource allocation or the valuation of life.&nbsp;</p><p>Experiments have shown that individuals' willingness to pay for the protection of wildlife or the mitigation of risks does not scale linearly with the number of lives or entities affected. For example, the amount people are willing to pay to save birds from oil pond deaths does not significantly increase whether the number of birds is 2,000, 20,000, or 200,000. This also applies to human lives; when the number of lives at risk from contaminated water was increased by a factor of 600, the average amount people were willing to pay only increased by a factor of 4. Psychophysical numbing, a concept related to Weber's Law, suggests that humans perceive and value lives on a logarithmic scale rather than a linear one. Consequently, a large increase in scope leads to a relatively small increase in emotional response or valuation.&nbsp;</p><p>These findings suggest that emotional responses to large-scale problems are not proportionately stronger than those to small-scale ones, and this can have harmful implications for public policy and charitable giving.</p><p>&nbsp;</p><h3>9. Overconfidence</h3><p>Overconfidence: people often demonstrate unwarranted faith in their knowledge, predictions, or estimates.&nbsp;</p><p>This tendency is highlighted through various experiments that show individuals and experts alike assigning high confidence levels to their judgments, only to be proven incorrect at rates much higher than their confidence intervals would suggest.&nbsp;</p><p>Overconfidence also leads to what is known as the planning fallacy, where people underestimate the time, costs, and risks of future actions, which can seriously reduce the efficacy of planning.</p><p>Luckily, research shows that providing additional information and training on calibration can improve judgement accuracy. Self-awareness of this &nbsp;cognitive bias is crucial for better decision-making and for being more receptive to evidence that contradicts one\u2019s preconceived notions.</p><p>&nbsp;</p><h3>10. Bystander Apathy</h3><p>Bystander Apathy: a behavior pattern where people fail to act because they believe someone else will step in.&nbsp;</p><p>The concept of diffusion of responsibility plays a crucial role here, as individuals feel less compelled to act when the sense of personal responsibility is diluted among the crowd. It has been observed that individuals are more likely to evacuate a room filling with smoke if they are alone, and less likely to evacuate if there are others in the room doing the same. Collective misunderstanding of a situation arises due to the inaction of others, which reinforces individual inaction.</p><p>This can have significant implications, not only in small-scale emergencies but also in global crises, such as existential risks to humanity. The same psychological factors that lead to inaction in the face of a room filling with smoke may also contribute to inaction in the face of global risks, as individuals may look to others for cues on how to act, leading to a dangerous cycle of inaction.&nbsp;</p><p>To overcome Bystander Apathy, singling out individuals and making direct appeals for help can be effective. This tactic breaks the cycle of observation and inaction, forcing individuals to confront the situation directly and acknowledge their personal responsibility to act.&nbsp;</p><p>&nbsp;</p><h3>A Final Caution&nbsp;</h3><p>Understanding psychological biases is crucial, but it should not become a tool for dismissing arguments without engaging with the actual content or facts presented. Yudkowsky warns against using psychological knowledge as a shortcut to critique arguments without the necessary technical expertise. Claims should be evaluated based on substance/evidence, not on the psychological profile of the person making the claim or the literary style in which it's presented. He suggests that such a practice can lead to superficial debates that are more about the psychology of the participants than about the actual issues at hand.</p><p>&nbsp;</p><h3>Conclusion</h3><p>Thinking about existential risks is subject to the same cognitive errors as any other kind of thinking; the high stakes involved do not inherently make our thinking clearer or more rational. An awareness of heuristics and biases is essential for anyone working on existential risks. The point is to combine domain-specific expertise with a wider understanding of cognitive biases to better predict and mitigate potential disasters.&nbsp;</p>", "user": {"username": "Damin Curtis"}}, {"_id": "L8N4uh4GixhWCoGAg", "title": "AMA: Earning to Give", "postedAt": "2023-11-07T16:20:46.786Z", "htmlBody": "", "user": {"username": "Jeff_Kaufman"}}, {"_id": "zHFBQ23o4DKjsoXcC", "title": "Incorporating and visualizing uncertainty in cost effectiveness analyses: A walkthrough using GiveWell\u2019s estimates for StrongMinds", "postedAt": "2023-11-07T12:50:46.484Z", "htmlBody": "<p>A common first step towards incorporating uncertainty into a cost effectiveness analysis (CEA) is to express not just a&nbsp;<i>point estimate</i> (i.e., a single number) for an input to the CEA, but to provide some indicator of uncertainty around that estimate. This might be termed an optimistic vs. pessimistic scenario, or as the lower and upper bounds of some confidence or uncertainty interval. A CEA is then performed by combining all of the optimistic inputs to create an optimistic final output, and all of the pessimistic inputs to create a final pessimistic output. I refer to this as an \u2018interval-based approach\u2019. This can be contrasted with a fuller \u2018probabilistic approach\u2019, in which uncertainty is defined through the use of probabilistic distributions of values, which represent the range of possibilities we believe the different inputs can take. While many people know that a probabilistic approach circumvents shortcomings of an interval-based approach, they may not know where to even begin in terms of what different distributions are possible, or the kinds of values they denote.</p><p>I hope to address this in the current post and the accompanying application. Concretely, I aim to:</p><ul><li>Show how performing a CEA just using an interval-based approach can lead to a substantial overestimation of the uncertainty implied by one\u2019s initial inputs, and how using a probabilistic approach can correct this while also enabling additional insights and assessments</li><li>Introduce a new tool I have developed - called&nbsp;<a href=\"https://jamieelsey.shinyapps.io/distributr/\"><i>Distributr&nbsp;</i></a>- that allows users to get more familiar and comfortable with a range of different distributions and the kinds of values they imply</li><li>Use this tool to help generate a probabilistic approximation of the inputs GiveWell used in their assessment of Strongminds,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvdvij6ogdvr\"><sup><a href=\"#fnvdvij6ogdvr\">[1]</a></sup></span>&nbsp;and perform a fuller probabilistic assessment based upon these inputs</li><li>Show how this can be done without needing to code, using&nbsp;<i>Distributr&nbsp;</i>and a simple spreadsheet</li></ul><p>I ultimately hope to help the reader to feel more capable and confident in the possibility of incorporating uncertainty into their own cost effectiveness analyses.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zHFBQ23o4DKjsoXcC/hfnxhkpo1de0wpnw253p\"></p><h1>Propagating uncertainty and the value of moving beyond an interval-based approach</h1><p>Cost effectiveness analysis involves coming up with a model of how various different factors come together to determine both how effective some intervention is, and the costs of its delivery. For example, when we think about distributing bed nets for malaria prevention, we might consider how the cost of delivery can vary across different regions, how the effects of bed net delivery will depend on the likelihood that people use the bed nets for their intended purpose, and the probability that recipients will install the bed nets properly. These and other factors all come together to produce an estimate of the cost effectiveness of an intervention, which will depend on the values we ascribe to the various inputs.</p><p>One way that a researcher might seek to express uncertainty in these inputs is by placing reasonable upper and lower bounds on their estimates for each of them. The researcher might then seek to propagate this uncertainty in the inputs into the anticipated uncertainty in the outputs by performing the same cost effectiveness calculations as they did on their point estimates on their upper bounds, and on their lower bounds, thereby producing corresponding upper and lower bounds on the final cost effectiveness.&nbsp;</p><p>An example of an interval-based approach is GiveWell\u2019s&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness\"><u>assessment of Happier Lives Institute\u2019s (HLI's) CEA for StrongMinds</u></a>.&nbsp;The purpose of this post is not to provide an independent evaluation of Strongminds or HLI's assessment of it,&nbsp;nor is the key take away intended to be a critique of GiveWell having used an interval-based approach in that post.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvfemwz039lf\"><sup><a href=\"#fnvfemwz039lf\">[2]</a></sup></span>&nbsp;Rather, I hope to guide the reader through an understanding of the limitations of this approach and then, using GiveWell\u2019s numbers as a concrete starting point, show how a fuller probabilistic approach could be taken without reliance on advanced understanding of statistics or mathematics, nor a reliance upon coding.</p><p>The GiveWell post considers how various factors such as&nbsp;<i>Social Desirability Bias&nbsp;</i>among intervention recipients,&nbsp;<i>Publication Bias&nbsp;</i>in reports of mental health intervention effects, and&nbsp;<i>Changing the Context&nbsp;</i>in which the intervention is conducted might all impact what we should reasonably consider the efficacy of a mental health intervention such as Strongminds to be. These inputs are expressed in terms of a best guess, with a corresponding optimistic and pessimistic bound. These optimistic and pessimistic bounds are used to calculate optimistic and pessimistic estimates of the overall cost effectiveness of the intervention.</p><p>A key issue with propagating uncertainty in this way is that it can dramatically inflate the uncertainty of final outcomes that are calculated from the underlying input variables. We can see this by using a toy example, where a final total estimate is determined by the sum of four input variables - A, B, C, and D.</p><p>Let\u2019s imagine that our uncertainty about the values of A, B, C, and D can be expressed as a classic bell curve distribution (i.e., a normal distribution) centered around 0, with a standard deviation of 1. This produces a mean of 0, and a 90% interval from approximately -1.6 to 1.6 for each input.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefydsqnjg8w7h\"><sup><a href=\"#fnydsqnjg8w7h\">[3]</a></sup></span>&nbsp;We\u2019ll call these our pessimistic and optimistic bounds. Using an interval-based approach, we would produce a pessimistic and optimistic estimate for our total by summing each of these bounds. Our pessimistic and optimistic total values would then be roughly -6.4 and 6.4 respectively (-1.6 * 4, and 1.6 * 4).</p><p>In contrast, a probabilistic approach uses the whole distribution of each input: We generate the total estimate by taking samples from our A, B, C, and D distributions, each time adding these samples together to make the total. We then end up with a full distribution of total estimates, and can directly calculate the 90% interval for this distribution. Rather than going from roughly -6.4 to 6.4, the true 90% interval for the total goes from about -3.3 to 3.3.</p><p>This toy example is displayed in the plot below. When we properly calculate the numbers without rounding until the final summarization, we find that the 90% interval produced using an interval-based approach is twice as wide as that produced by the (accurate) probabilistic approach. It is even 1.3 times larger than the true 99% interval, clearly showing how the interval-based approach leads to very extreme estimates, substantially inflating our uncertainty. This represents something of a conservative example as to the possible levels of inflation that can be produced with an interval-based approach, because the inflation increases as we add more variables into the equation (many CEAs involve much more than 4 inputs), and can also vary depending on exactly how the variables are set to interact with one another (e.g. adding or multiplying), as well as on what distributions are used. For example, when multiplying together 4 values that are distributed log-normally, we observed that the interval-based approach generates a final estimate with bounds that are 13 times wider than the true level of uncertainty.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zHFBQ23o4DKjsoXcC/pj1hg1mc6ijjevvtxt5d\"></p><p>The reason we get this inflation is because, unless we have reasons to believe otherwise, we assume each of our input variables are independent of one another. When using an interval-based approach, however, it is as if we are saying not just that our input variables are all correlated with one another, but perfectly so: to make our final lower bound we take all 4 of the pessimistic inputs, and for our final upper bound, we take all 4 of the optimistic ones. In an example with just 4 normally distributed variables, the chance that we would draw 4 times in succession from at or above the central 90% of possible outcomes, all in the same positive or negative direction, is exceedingly small (5% * 5% * 5% * 5% = 0.000625%), and reflects an extreme and highly unlikely outcome. We\u2019ve gone from pessimistic inputs to some of the most extremely bad outputs possible, and from optimistic inputs to the most fantastically good ones.</p><p>With reference to the example of bed nets for malaria above, it would be as if delivery is as expensive as in our highly pessimistic scenario,&nbsp;<i>and</i> the number of people using nets for fishing or some other purpose is as high as in our highly pessimistic scenario,&nbsp;<i>and</i> the proportion who install the nets properly is as low as our highly pessimistic scenario. Each of these might be a merely pessimistic outcome for each input, but it can be seen that when they all come together they create a very dire final outcome, and one which is exceedingly unlikely if each were already unlikely in isolation.</p><p>To avoid these pitfalls, we would ideally be able to more fully incorporate uncertainty into our assessments of cost effectiveness.</p><h1>Tools and tips for generating distributions of uncertainty to use in CEAs</h1><h2>Existing tools for incorporating uncertainty</h2><p>When seeking to utilize a probabilistic approach to uncertainty for a cost effectiveness analysis, one stumbling block may be a lack of familiarity with tools that can produce such distributions. We might stipulate that we think one of our inputs is normally distributed, but how do we get this distribution? Beyond directly using a programming language such as R or Python, a range of tools have been developed to help with generating and working with distributions.</p><p><a href=\"https://www.getguesstimate.com/scratchpad\"><u>Guesstimate</u></a> allows the user to generate a host of probability distributions, which can also be connected together or passed through different functions to create CEAs built from a range of inputs and assumptions (for a brief tutorial, see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/4jJn7TxXgkyhpiWTA/guesstimate-why-and-how-to-use-it\"><u>here</u></a>, and for a more detailed guide,&nbsp;<a href=\"https://docs.getguesstimate.com/\"><u>here</u></a>).&nbsp;<a href=\"https://usedagger.com/about/\"><u>Dagger</u></a> is a similar tool geared towards modeling and quantifying uncertainty. Some tools more oriented towards business planning and project evaluation, such as&nbsp;<a href=\"https://www.causal.app/\"><u>Causal</u></a>, also allow for the generation of models with uncertainty. Moving more towards coding-based approaches, the Quantified Uncertainty Research Institute has developed&nbsp;<a href=\"https://www.squiggle-language.com/\"><u>Squiggle</u></a>, a programming language that is purpose built for working with uncertainty distributions (see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/TsaRbCotCaWpcrt8F/squiggle-why-and-how-to-use-it\"><u>here</u></a> for a tutorial/explanation). Peter Wildeford of Rethink Priorities has implemented Squiggle as a Python programming language package&nbsp;<a href=\"https://github.com/rethinkpriorities/squigglepy\"><u>SquigglePy</u></a>. Several of these tools also have the nice feature that you don\u2019t necessarily need to describe the statistical distribution in terms of its proper parameters, such as the mean and standard deviation, but can instead give a best guess and some bounds, and they will generate a corresponding distribution if possible. Finally, general purpose programming languages, notably R and Python, have access to essentially any distribution one can think of.&nbsp;</p><h2>Introducing&nbsp;<i>Distributr</i> for exploring and generating probabilistic distributions</h2><p>Beyond just knowing how to generate distributions, many people who might wish to incorporate uncertainty into their CEAs may simply be unfamiliar with or lack confidence in their knowledge of the range of different distributions available, and the kinds of values they imply. From discussions I\u2019ve had with people thinking of incorporating uncertainty into CEAs (likewise for selecting priors in Bayesian analyses), lack of confidence in knowing what different distributions are possible and what they mean is more frequently mentioned than not knowing specific tools for generating them.</p><p>To help with my own understanding of different distributions, I have developed an application that can visualize a range of different probability distributions in multiple different ways, with a host of accompanying summary statistics (see the screenshot below). The app can be thought of as something like a distribution portfolio, in which you can explore and look at a range of different distributions on offer using different types of plot, along with several pieces of summary information, so as to better understand them and match them to your knowledge or expectations about a CEA input variable. The primary goal of the app was to help the user to become more familiar and confident in working with and understanding different distributions, but some of its functionality can be used to perform a probabilistic CEA.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zHFBQ23o4DKjsoXcC/dxyzjrm8ajjy2vcpocdt\"></p><p>The application - called&nbsp;<i>Distributr</i> - can be used&nbsp;<a href=\"https://jamieelsey.shinyapps.io/distributr/\"><u>here</u></a>. Note that because this app runs on an R Shiny server, it is presently not well-suited for a high volume of users/requests, so if many people use it at once, it is possible that it will disconnect or time out.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefw9k2e4sdmwn\"><sup><a href=\"#fnw9k2e4sdmwn\">[4]</a></sup></span>&nbsp;It is also possible to&nbsp;<a href=\"https://github.com/rethinkpriorities/Distributr-application\"><u>download the code for the application from github</u></a>, in which case you can run it directly on your own computer with R, without relying on the R Shiny server. A document outlining the different types of distributions, plots, and summary statistics available in the app can be found&nbsp;<a href=\"https://docs.google.com/document/d/1uU8k6ZY3pyjDgkvp3hhXPF39jyRInCa6qEK-UakE5F8/edit?usp=sharing\"><u>here</u></a> (it is not necessary to read that documentation to continue with this post or to use the app).</p><p>In addition to exploring what sorts of values are indicated by a range of distributions and their possible parameter specifications, Distributr also displays what command in R could be used to generate your own sample from the distribution, and also allows you to download a csv file including 10,000 samples from up to 10 different distributions in a single csv file. Hence, if you are not comfortable with programming, it would be possible to specify multiple distributions in the app, and then use Excel or Google Sheets to specify how these different distributions fit together to form a CEA based on the generated distributions.</p><p>Using Distributr, I was able to visualize and assess the correspondence of a range of different distributions to the best, pessimistic, and optimistic guesses from GiveWell\u2019s CEA of Strongminds. For example, GiveWell suggests a social desirability bias correction to the effect of the Strongminds intervention of approximately 80% [70%-90%]. I used a beta distribution to reflect this estimate being a proportion/percentage. Assuming that the pessimistic and optimistic ranges represent a 90% interval, this would correspond roughly to a beta distribution with a mean of .8 and precision of 40:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zHFBQ23o4DKjsoXcC/coxittgsbggyvvz5zkcc\"></p><p>By using a range of distributions to make similar approximations to the estimates provided by GiveWell, it is possible to generate an entire set of probabilistic distributions corresponding to each of the input variables used in the Strongminds CEA. These can then be combined together to produce probabilistic estimates of cost effectiveness.</p><h1>Approximating and running a probabilistic CEA for Strongminds based on GiveWell\u2019s numbers</h1><h2>Approximating the GiveWell inputs</h2><p>The table below shows HLI point estimates for different inputs to a CEA for Strongminds as reported in the GiveWell post, with additional inputs that GiveWell included in their CEA, along with GiveWell\u2019s best, optimistic, and pessimistic estimates for these inputs. I include distributions that roughly correspond to these GiveWell estimates and an example piece of R code that would generate the respective distribution (in the Appendix, I show that similar conclusions to those below apply if just agnostic, uniform distributions are used instead).</p><p>I stress that these really are only approximate matches, and also that they are based on an assumption of the GiveWell estimates representing something like a mean for the best guess, and a 90% central interval for the optimistic and pessimistic bounds. These numbers would have to be changed if this were not the case, and in practice one would seek to generate these distributions in collaboration with the person proposing the plausible values, to ensure the distributions reflect the knowledge and expectations they are intended to encode. This process can also help to refine and become more explicit about one\u2019s expectations. Some points to consider here would be not only what the uncertainty bounds represent, but also whether the point estimate reflects the mean, the median, the mode - which can diverge meaningfully when using distributions that are not symmetrical. As an example of where this kind of consultation would be useful, the&nbsp;<i>Duration multiplier&nbsp;</i>point estimate and bounds were particularly difficult to generate within a reasonable degree of similarity using a formal statistical distribution, and the generated values from the chosen distribution have a long tail that can skew into negative durations (which is not possible for this input). I therefore capped how low these values were allowed to go to 0.2 after sampling them from the distribution. A more appropriate distribution that would not need to be artificially capped, or a different cap, might be chosen after further discussion.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkdki7b1ywk\"><sup><a href=\"#fnkdki7b1ywk\">[5]</a></sup></span></p><p>The point of this procedure is therefore not to directly update the estimates provided by either GiveWell or by HLI, but to demonstrate - with a concrete and relevant example - how incorporating uncertainty might be done, and how such a probabilistic approach might plausibly lead to different conclusions and levels of uncertainty in the final estimates.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zHFBQ23o4DKjsoXcC/t2jf2gfrirybfaynmxkx\"></p><h2>Performing the cost effectiveness calculations</h2><p>In the CEA, we first need to calculate the expected effect for an individual directly undergoing the intervention. This is simply the product of&nbsp;<i>Initial effect * Social desirability * Publication bias * Context change * Duration multiplier</i>. Next, we can use this&nbsp;<i>Individual effect</i> estimate to calculate an expected&nbsp;<i>Indirect household effect</i>: how much those in the receiver\u2019s household indirectly benefit from the receiver directly getting the intervention. This is the result of:&nbsp;<i>Individual effect * Household benefit * (N household - 1).&nbsp;</i>The&nbsp;<i>Total effect</i> of the intervention is then&nbsp;<i>Individual effect</i> +&nbsp;<i>Indirect household effect</i>.</p><p>Now that we have this estimated&nbsp;<i>Total effect</i>, we convert it to a general scale of \u2018life satisfaction units\u2019. This is done by getting the product of:&nbsp;<i>Total effect * Satisfaction per SD</i>. Next, we convert this to an estimate of how many of these \u2018life satisfaction units\u2019 we get per $1000 spent on the intervention:&nbsp;<i>Total effect in satisfaction units * (1000 / Cost)</i>.</p><p>Finally, if we wish, we can compare this&nbsp;<i>Life satisfaction units per $1k</i> estimate with other interventions that have been estimated in terms of this same metric. In the GiveWell post, this is done relative to both GiveDirectly and the Against Malaria Foundation (AMF):&nbsp;<i>Life satisfaction units per $1k Strongminds / Life satisfaction units per $1k of comparison intervention</i>. HLI and GiveWell suggested that GiveDirectly achieved 8&nbsp;<i>Life satisfaction units per $1k</i>, and AMF was given 81 on this metric by HLI, and 70 by GiveWell. We stick with the GiveWell estimate in our probabilistic analysis.</p><p>Now, we can see how these intermediate and final estimates compare when running a probabilistic approximation based on the optimistic and pessimistic scenarios of GiveWell, relative to using these scenario bounds as direct inputs in the above calculations.&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zHFBQ23o4DKjsoXcC/yzl8dicewjkfpt8iptpl\"></p><p>Moving from the initial stages of the CEA (the&nbsp;<i>Individual effect</i>) to the final stages (comparing life satisfaction units per $1000 relative to AMF or GiveDirectly), the width of the uncertainty bounds go from 1.7 times to 2.8 times larger for the estimates made via an interval-based approach relative to the probabilistic approximation. The upper estimates based upon a fuller probabilistic estimation of the effects of Strongminds are consequently much further from the HLI point estimates than are the upper bounds suggested in the GiveWell post.&nbsp;</p><p>Again, the extent of possible overestimation of uncertainty based upon using an interval-based approach would depend on exactly what those intervals represent, and would be different if taken to be something other than a 90% interval. This may even highlight a further limitation of the interval-based approach: we may not know exactly what the points and intervals are intended to represent. They could reflect the 90% or the 95% range of the data; one person\u2019s understanding of \u2018pessimistic\u2019 may be very different from another\u2019s. They could be the central 90% of values, cutting off the top and bottom 5%, or they could be the 90%&nbsp;<i>most likely&nbsp;</i>expected<i>&nbsp;</i>values. However, the only way this approach would not lead to at least some overestimation of uncertainty is if the bounds indicated the absolute maximum and minimum possible values for each input.</p><p>If the estimates from an interval-based approach show greater uncertainty than seems reasonable based upon a fuller probabilistic assessment, does this even matter? After all, the mean estimates come out effectively the same. It might even be argued that these wider uncertainty intervals are a good thing, perhaps representing a conservative or more humble reflection of our uncertainty.</p><p>I argue that it does matter - especially when it comes to assessing different programs relative to one another. We will discuss some approaches to comparing programs in the section&nbsp;<i>Making probabilistic comparisons with other programs/interventions&nbsp;</i>below, but put briefly, the probabilistic approach allows us to make much more nuanced assessments of programs. If we only have the intervals, then all we can reasonably say if an estimate for one program falls within the bounds of another is that we can neither confirm nor deny a difference between them. With a probabilistic approach, we can assess the relative likelihood of one program outperforming the other. Furthermore, with an interval-based approach, we have no idea how the plausibility of different values varies within that bounded region. Though it may seem conservative to err on the side of overstating our uncertainty, it risks being misleading in terms of dramatically overestimating the plausibility of extreme values.</p><p>These points can be understood by looking at the plot below, which shows differences between the inferences that one might unlock when following a probabilistic approach, versus an interval-based approach, to comparisons amongst programs. Firstly, according to the probabilistic estimation, the chance that Strongminds is exactly equal to or worse than GiveDirectly seems quite low, representing the 5% most pessimistic of our potential outcomes (though it is certainly not out of the question). The uncertainty interval produced via the interval-based approach stretches considerably further out into more extremely negative outcomes for Strongminds, and may thus make these outcomes seem more plausible than they probably are.&nbsp;&nbsp;</p><p>In addition, and at the other extreme, a very large part of the GiveWell uncertainty interval - indeed the majority of it - covers the highest 5% of our probabilistic estimates for Strongminds. If we visually inspect the GiveWell pessimistic-optimistic range, we might conclude that it's reasonably likely that Strongminds produces ~30 life satisfaction units per $1k. After all, this value is much closer to the \"best guess\" than the \"optimistic\" value, and the interval provides no further information about how likely any given outcome is. However, if we consult the graph produced from the probabilistic approach, we can see that this outcome is in the most optimistic 5% of values and so is comparatively unlikely. The interval-based approach risks making such relatively extreme outcomes appear more likely than they actually are.</p><p>Indeed, using the interval-based approach, a comparison program might be two times better than 95% of our expectations for the program, but it would fall within the over-extended bounds produced by this approach, and could be considered as having little plausible difference in effectiveness. Note that the probabilistic approach does not outright reject the possibility of these values: we could directly calculate the chances we expect for values to appear across the whole range of plausible possibilities.&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zHFBQ23o4DKjsoXcC/r7yji87uaqjnwsnmlpeo\"></p><h2>Using Distributr and a spreadsheet to do the calculations</h2><p>The calculations and plots above were done in R, but it is also possible to use Distributr to generate a csv file of samples from the different inputs\u2019 possible distributions. We can then just use Excel or Google sheets to perform calculations based on the samples, and summarize the resulting estimates, as was done in&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1RzR6_Ct6VjBevdXYtgMzwzVqR6zahtiV7U6czR0DJXo/edit?usp=sharing\"><u>this sheet</u></a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4igpfuwxgx9\"><sup><a href=\"#fn4igpfuwxgx9\">[6]</a></sup></span>&nbsp;Hence, a large part of incorporating uncertainty into relatively simple CEAs such as this one could be done even if the user is most comfortable using spreadsheets as opposed to coding.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zHFBQ23o4DKjsoXcC/fqcgxclgnfknjp7pzd4l\"></p><h2>Visualizing CEA outcomes using Distributr</h2><p>Having generated a set of outcome distributions, we are also not limited to using summary functions available in spreadsheet software. We can save the values of our estimates in a new csv file, and upload them to Distributr as custom distributions (the outcomes are available as a google sheet&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1C_I22kb8DmkTbQb5ENaVXE_loG_IzvWR7yIisJieKxc/edit?usp=sharing\"><u>here</u></a>). This allows us to fully visualize them and explore their implications using a host of different summary statistics available in Distributr.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zHFBQ23o4DKjsoXcC/jtlt4z7hjugvquzetskm\"></p><h2>Making probabilistic comparisons with other interventions</h2><p>As well as providing bounds on estimates that more accurately reflect the propagation of uncertainty, using a probabilistic approach enables some additional types of comparisons and visualizations than would be possible if we used an interval-based approach.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaga8kzrnx8e\"><sup><a href=\"#fnaga8kzrnx8e\">[7]</a></sup></span></p><p>If we had a distribution of effectiveness estimates from a CEA for another project, we could directly compare the programs by subtracting one distribution from the other. The resulting distribution would reflect the distribution of uncertainty surrounding&nbsp;<i>differences&nbsp;</i>between the two assessed programs, and could also be summarized with a point estimate and different uncertainty intervals as desired, or via considering the relative probabilities of the range of plausible differences. This allows us to make much more fine-grained and sensitive comparisons than if we had to just judge whether or not the estimate for one program falls within the uncertainty bounds of another.</p><p>For comparisons with AMF and with GiveDirectly, we do not have a distribution of uncertainty, but we do have a point estimate (from GiveWell, as noted above, AMF appears to generate somewhere around 70 satisfaction units per $1k, and GiveDirectly around 8). We could calculate the proportion of our distribution of estimates for Strongminds that exceeds vs. falls below these comparison programs.</p><p>To convey that there is some uncertainty in the point estimates for AMF and GiveDirectly, or simply to reflect that we want to be somewhat conservative in deeming a new intervention clearly inferior or superior to an established comparison program, we could also add a range around these point estimates. Only if an estimate from our Strongminds distribution falls outside of this range might we suggest that the program appears to be better or worse. This is known as setting a&nbsp;<i>Range of Practical Equivalence</i> (ROPE). For the sake of demonstration, we set a ROPE around the estimates such that the compared interventions need to outperform one another by 33% in order to be deemed \u2018different\u2019 in their cost effectiveness.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhkoomlqyeq6\"><sup><a href=\"#fnhkoomlqyeq6\">[8]</a></sup></span></p><p>For visual clarity, and at the expense of some precision, we plot the outcomes of this procedure below as a pair of grid or \u2018waffle\u2019 plots. The totality of each grid represents 100% of the probabilistically estimated outcomes, and each square represents 1 percent of these outcomes. From these plots, Strongminds comes out looking pretty solid relative to GiveDirectly: The bulk of squares indicates superiority of Strongminds, and just a single square - representing 1.2% of the comparisons - indicates inferiority. However, for Strongminds vs. AMF, essentially the entirety of our probabilistic estimates favor AMF.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zHFBQ23o4DKjsoXcC/ti3jf3uftdk74xe7ivdx\"></p><h1>Summary and concluding remarks</h1><p>As I hope to have demonstrated, incorporating uncertainty into CEAs using an interval-based approach can lead to substantial overestimates of the uncertainty in the final outputs. This issue can be rectified by making use of probabilistic distributions to represent that uncertainty.</p><p>Performing calculations for a CEA on random samples from these distributions more appropriately propagates uncertainty through the cost effectiveness model. In addition, having a full distribution of estimates opens up the possibility of different types of summary statistics (e.g., different point estimates, different ranges and types of interval), different ways of comparing one\u2019s estimates to other programs, and ultimately different forms of visual presentation and inference.</p><p>There are numerous tools available for generating distributions of values for use in a CEA, from using a programming language such as R or Python, to using specialized software - much of which has been developed by people in or adjacent to the EA community for just this purpose. My goal in sharing Distributr was to make the exploration of different distributions easy for those without programming experience, as I think it is often lack of confidence or familiarity with different distributions that presents a bottleneck for people seeking to start adding uncertainty into their CEAs. However, Distributr can also be used to generate random samples from specified distributions and perform relatively simple probabilistic CEAs just with a spreadsheet, and then to visualize and explore the resulting distributions of outcomes.</p><p>Moving from an interval-based approach to a fuller probabilistic approach can substantially increase the validity and nuance of inferences, and even change the types of inference one can make. I hope this post, as well as the tools and code accompanying it, can make it easier to do so.</p><h2>Acknowledgments</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Rg7h7G3KTvaYEtL55/slirbnupov30yotz5ldn\"></p><p>This post was written by Jamie Elsey with contributions from David Moss. Distributr was developed by Jamie Elsey. We would like to thank Ozzie Gooen for review of and suggestions to the final draft of this post.</p><h1>Appendix</h1><h2>Uniform distributions also produce less extreme outcomes than those suggested by an interval-based approach</h2><p>One particular worry may be that fitting these different distributions seems overly ambitious - we just can\u2019t put distributions on our expectations like this, it implies too much certainty over the inputs. Although I would argue that we often do have quite specific expectations about what sort of distribution shapes are reasonable for our inputs, we don\u2019t have to rely on a specific shape. The most agnostic type of distribution we can use is a uniform distribution, where all values within a set of bounds are equally plausible. Again, treating the specified intervals from the GiveWell post as a 90% interval, we can extend them 5% on either side to get a simple 100% interval, and generate uniform distributions within these bounds. This uniform distribution approach, while still making many fewer assumptions than our custom approach above, still suggests that the interval-based approach is generating inflated estimates.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zHFBQ23o4DKjsoXcC/zohiihq9uvk7lcgyg0rv\"></p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvdvij6ogdvr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvdvij6ogdvr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This post is based upon an internal talk I gave to researchers at Rethink Priorities. The goal of the talk was to discuss ways of incorporating and visualizing uncertainty in cost effectiveness analyses (CEAs). In the days preceding the talk, GiveWell posted their assessment of Happier Lives Institute\u2019s CEA for StrongMinds. That post provided a relevant and timely CEA that I could use as a concrete example for incorporating uncertainty, and is the example around which this post is oriented.</p><p>I use the GiveWell assessment of Strongminds as a springboard and concrete example, as I think this is much more interesting than working wholly in the abstract. I take the assessments from GiveWell as given for the purposes of demonstration, and did not conduct additional research to assess whether or not these estimates, or those of the Happier Lives Institute (HLI), are reasonable. I only engage with the numbers as presented in the aforementioned GiveWell post, not with the original HLI report or follow-up discussions from HLI and others. An original report from the Happier Lives Institute on the cost effectiveness of Strongminds can be found&nbsp;<a href=\"https://www.happierlivesinstitute.org/report/strongminds-cost-effectiveness-analysis/\"><u>here</u></a><u>, and a second report on household spillovers </u><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/Happiness-for-the-whole-family.pdf\"><u>here</u></a>. A response from HLI to the GiveWell post can be found&nbsp;<a href=\"https://www.happierlivesinstitute.org/report/response-to-givewells-assessment-of-strongminds/\"><u>here</u></a><u>.</u></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvfemwz039lf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvfemwz039lf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We are aware, for example, that several contributions, and indeed the winning contribution, to GiveWell\u2019s \u2018Change our minds\u2019 contest focused on possible ways of incorporating uncertainty into GiveWell CEAs - see the list of entries&nbsp;<a href=\"https://blog.givewell.org/2022/12/15/change-our-mind-contest-winners/\"><u>here</u></a> and a winning entry on uncertainty&nbsp;<a href=\"https://www.metacausal.com/givewells-uncertainty-problem/\"><u>here</u></a>.</p><p>The inclusion of only a point estimate for the 'HLI' numbers that follow should not be taken to reflect that HLI rely solely on point estimates in their evaluations either, rather it reflects the numbers presented in the GiveWell post. Some of estimates in HLI reports noted in footnote 1 do include intervals and probabilistic estimation, which we have not evaluated.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnydsqnjg8w7h\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefydsqnjg8w7h\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This simply means that 90% of the values generated from this distribution are expected to fall between -1.6 and 1.6, with 5% of values above and 5% of values below this interval.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnw9k2e4sdmwn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefw9k2e4sdmwn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I hope this doesn\u2019t happen, but if when you reach this point you click that link and it just times out or doesn\u2019t seem to work, this is the most likely reason, as the app does run properly live in a web browser when usage is not high.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkdki7b1ywk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkdki7b1ywk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In general, it is worth checking minimum and maximum generated values from input distributions to assess implausible or invalid values that might impact a CEA. I have also since added additional distributions to the app, such as the PERT distribution, which might be appropriate alternatives to the skew normal.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4igpfuwxgx9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4igpfuwxgx9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Note that given the more limited functionality of Google sheets relative to R, I summarized the estimates using a 90% central interval rather than a highest density interval, so the numbers are not exactly the same as in the plots (this can also be due to variation in the random sampling of the distributions, even if the same summary stats were used).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaga8kzrnx8e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaga8kzrnx8e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Some additional considerations for ways of making comparisons amongst programs are discussed in Noah Haber\u2019s piece&nbsp;<a href=\"https://www.metacausal.com/2022/10/30/givewells-uncertainty-problem-link/\"><u>here</u></a>, and more in depth discussion of the ROPE-based ideas presented in this section can be found in the work of John Kruschke&nbsp;<a href=\"https://dionysus.psych.wisc.edu/iaml/pdfs/kruschke2018a.pdf\"><u>here</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhkoomlqyeq6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhkoomlqyeq6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Note that this would equate to a ROPE on the comparison of A cost effectiveness / B cost effectiveness of about .75 to 1.33, not of .67 to 1.33: If A / B is 1.33, then A is 1.33 times better than B. If A / B is .75, then B is 1.33 times better than A. The magnitude of this ROPE is completely arbitrary and chosen just for the purposes of demonstration, but in concrete scenarios decision-makers may have various practical reasons to be interested in whether an intervention is more than&nbsp;<i>x</i> times better than another.</p></div></li></ol>", "user": {"username": "Jamie Elsey"}}, {"_id": "ev5dSDjSCTcuahnBn", "title": "Box inversion revisited", "postedAt": "2023-11-07T11:09:37.306Z", "htmlBody": "", "user": {"username": "Jan_Kulveit"}}, {"_id": "gqJkceDk7Az7jWEEW", "title": "Dengue rates drop 77-95% after release of bacteria-infected mosquitoes in Colombia", "postedAt": "2023-11-07T10:39:42.199Z", "htmlBody": "<blockquote>\n<p>When infected with Wolbachia, the mosquitoes are much less likely to transmit diseases such as dengue and Zika, because the bacteria compete with these viruses. The insects also pass the bacteria on to their offspring. Researchers hope that the modified mosquitoes will interbreed with the wild population wherever they are released, and that the number of mosquitoes with Wolbachia will eventually surpass that of mosquitoes without it.</p>\n</blockquote>\n<p>[...]</p>\n<blockquote>\n<p>When the scientists compared the incidence of dengue in fully treated areas with that in the same regions in the ten years before the intervention, they found that it had dropped by 95% in Bello and Medell\u00edn and by 97% in Itag\u00fc\u00ed. Since the project started, there hasn\u2019t been a large outbreak of dengue in the region. \u201cThey\u2019ve had six years now with a sustained suppression of dengue,\u201d says Anders. \u201cWe\u2019re starting to see the real-world effect of Wolbachia.\u201d</p>\n</blockquote>\n<p>[...]</p>\n<blockquote>\n<p>The [World Mosquito Program] has conducted one [RCT] in Yogyakarta, Indonesia, in which mosquitoes were released in some areas of a city and the incidence of dengue was compared with that in areas that did not receive the insects. The results suggested that the technology could reduce the incidence of dengue by 77%. The organization is now conducting a similar one in Belo Horizonte, Brazil.</p>\n</blockquote>\n<p>The RCT: <a href=\"https://pubmed.ncbi.nlm.nih.gov/34107180/\">https://pubmed.ncbi.nlm.nih.gov/34107180/</a></p>\n<blockquote>\n<p>Despite the positive results, Wolbachia mosquitoes have not yet been officially endorsed by the World Health Organization (WHO). The technology awaits an evaluation by the WHO\u2019s Vector Control Advisory Group.</p>\n</blockquote>\n<p>World Mosquito Program: <a href=\"https://www.worldmosquitoprogram.org/en/work/wolbachia-method/how-it-works\">https://www.worldmosquitoprogram.org/en/work/wolbachia-method/how-it-works</a></p>\n", "user": {"username": "SiebeRozendal"}}, {"_id": "Xx9oWdJDfisAQwDtT", "title": "Varieties of minimalist moral views: Against absurd acts", "postedAt": "2023-11-07T11:57:03.114Z", "htmlBody": "<p>(A standalone part of <a href=\"https://forum.effectivealtruism.org/s/MBadsrYLmzLNmYjaj\"><u>Minimalist Axiologies: Alternatives to \u2018Good Minus Bad\u2019 Views of Value</u></a><u>.)</u></p><h1>1. Introduction</h1><p>What are minimalist views?</p><ul><li><strong>Minimalist views of value (axiologies)</strong> are evaluative views that define betterness solely in terms of the absence or reduction of independent bads. For instance, they might roughly say, \u201cthe less suffering, violence, and violation, the better\u201d. They reject the idea of weighing independent goods against these bads, as they deny that independent goods exist in the first place.</li><li><strong>Minimalist moral views</strong> are views about how to act and be that include a minimalist view of value, instead of an&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Reasons_to_doubt_the_offsetting_premise__A_brief_overview\"><u>offsetting (\u2018good minus bad\u2019)</u></a> view of value. They reject the concept of independently positive moral value, such as positive virtue or pleasure that could independently counterbalance bads.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefh9gljokkd2p\"><sup><a href=\"#fnh9gljokkd2p\">[1]</a></sup></span></li></ul><p>Minimalist views are sometimes alleged \u2014 at least in their purely consequentialist versions \u2014 to recommend absurd acts in practice, such as murdering individuals to prevent their suffering, or opposing life-extending interventions lest we prolong suffering. My aim in this essay is to broadly outline the various reasons why the most plausible and well-construed versions of minimalist moral views \u2014 including their purely consequentialist versions \u2014 do not recommend such acts.</p><h2><strong>Sequence recap</strong></h2><p>For context, below is a chronological recap of the present series on minimalist views so far.</p><p>1. \u201c<a href=\"https://forum.effectivealtruism.org/posts/t3St6Fz4DmHtKfgqm/positive-roles-of-life-and-experience-in-suffering-focused\"><strong><u>Positive roles of life and experience in suffering-focused ethics</u></strong></a>\u201d:</p><ul><li>Even if we assume a purely suffering-focused view, it\u2019s wise to recognize the highly positive and often necessary roles that various other things may have for the overall goal of reducing suffering.</li><li>These include the positive roles of autonomy, cooperation, nonviolence, as well as our personal wellbeing and valuable skills and experiences.</li><li>Suffering-focused moral views may value these things for different reasons, but not necessarily any less, than do other moral views.</li></ul><p>2. \u201c<a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives\"><strong><u>Minimalist axiologies and positive lives</u></strong></a>\u201d:</p><ul><li>Minimalist axiologies define goodness in entirely relational or \u2018instrumental\u2019 terms, namely in terms of the minimization of bads such as suffering.</li><li>These views avoid many problems in population ethics, yet the minimalist notion of (relationally) positive value is entirely excluded by the standard, restrictive assumption of treating lives as isolated value-containers.</li><li>Minimalist views become more intuitive when we adopt a relational view of the overall value of individual lives, that is, when we don\u2019t track only the causally isolated \u201ccontents\u201d of these lives, but also their (often far more significant) causal roles.</li></ul><p>3. \u201c<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism\"><strong><u>Peacefulness, nonviolence, and experientialist minimalism</u></strong></a>\u201d:</p><ul><li>For purely experience-focused and consequentialist versions of minimalist views, an ideal world would be any perfectly peaceful world, including an empty world.</li><li>When it comes to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#1_1_Overview_of_the_hypothetical_side\"><u>theoretical implications about the cessation and replacement of worlds</u></a>, one can reasonably argue that offsetting (\u2018good minus bad\u2019) views have&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#2_5_Comparative_theoretical_implications_of_minimalist_and_offsetting_views\"><u>worse</u></a> implications than do minimalist views.</li><li>Zooming out from unrealistic thought experiments, it\u2019s crucial to be mindful of the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#2_6_The_gap_between_theory_and_practice\"><u>gap between theory and practice</u></a>, of the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#3_1_Against_endstate_oriented_utopianism\"><u>pitfalls of misconceived consequentialism</u></a>, and of how minimalist consequentialists have&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#1_2_Overview_of_the_practical_side\"><u>strong</u></a>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#3_2_Key_considerations_for_estimating_practically_optimal_aims\"><u>practical</u></a>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#3_3_A_safeguard_against_worst_case_outcomes__Pragmatically_absolute_nonviolence\"><u>reasons</u></a> to pursue a nonviolent approach and to cooperate with people who hold different values.</li></ul><p>4. \u201c<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least\"><strong><u>Minimalist extended very repugnant conclusions are the least repugnant</u></strong></a>\u201d:</p><ul><li>It has been argued that certain \u201crepugnant conclusions\u201d are an inevitable feature of any plausible axiology.</li><li>Yet based on a \u2018side-by-side\u2019 comparison of different views, it appears that offsetting views&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#4__Comparative_repugnance\"><u>share</u></a> all the most \u201crepugnant\u201d features of minimalist views while introducing&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#3__Sources_of_repugnance\"><u>additional sources of repugnance</u></a>.</li><li>Overall, the comparison suggests that the conclusions faced by minimalist views are the least repugnant.</li></ul><p>5. \u201c<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing\"><strong><u>Minimalist views of wellbeing</u></strong></a>\u201d:</p><ul><li>Personal wellbeing is often defined as the balance of that which is good for oneself over that which is bad for oneself.</li><li>We may be skeptical of such \u2018good minus bad\u2019 views of wellbeing due to the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Reasons_to_doubt_the_offsetting_premise__A_brief_overview\"><u>many reasons to doubt the offsetting premise</u></a> \u2014 that is, the premise that independent bads can always be counterbalanced or offset by a sufficient addition of independent goods.</li><li>This premise is rejected by the whole variety of&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#The_variety_of_minimalist_views\"><u>minimalist views of wellbeing</u></a>. These include&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Experientialist_views\"><u>experientialist views</u></a>, where wellbeing is the degree to which we are free from experiential sources of illbeing (such as suffering, disturbance, or a visceral non-acceptance of our current experience), as well as&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Extra_experientialist_views\"><u>extra-experientialist views</u></a>, where wellbeing is also affected by&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Preferentialist_views\"><u>preference frustrations</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Conditional_interests_versus_teleological_goods\"><u>interest violations</u></a>, or&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Objective_list_views\"><u>objective conditions</u></a>.</li></ul><h2><strong>Alleged recommendations of absurd acts</strong></h2><p>Overall, we may find minimalist views to be plausible alternatives to \u2018good minus bad\u2019 views. Yet, as mentioned above, critics sometimes claim that minimalist views would recommend absurd acts in practice, such as murdering individuals, or choosing not to save people\u2019s lives, so as to prevent their future suffering.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8z6yrs392a6\"><sup><a href=\"#fn8z6yrs392a6\">[2]</a></sup></span></p><p>My goal here is to show why the most plausible versions of minimalist moral views do not recommend such acts.</p><p>For instance, in the case of purely consequentialist minimalist views, the consequentialist framework would be just as considerate of indirect, long-term effects as it would be in the offsetting versions of such views. This is worth noting because the purportedly absurd practical implications arguably don\u2019t stem from minimalism itself, but from its combination with implausible interpretations of pure consequentialism.</p><h2><strong>Only straight down in the diagram: Minimalist views are broader than that</strong></h2><p>From the outset, it\u2019s worth noting that minimalist views need not be purely consequentialist at the normative level. Similarly, purely consequentialist views need not be purely welfarist, and purely welfarist views need not be purely experience-focused. Finally, even in the case of minimalist views that are purely experience-focused and purely consequentialist, one would still, in practice, give a lot of weight to many extra-experiential and seemingly nonconsequentialist considerations, such as the positive roles of autonomy, cooperation, and nonviolence, as part of a nuanced and impartial multi-level consequentialism (cf. Figure 1).</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Xx9oWdJDfisAQwDtT/p8fss0w4gmhtstzpnqwq\"><figcaption><strong>Figure 1</strong>. Minimalist views of wellbeing and value are compatible with a wide variety of normative views, yet are sometimes broadly rejected based on objections to a narrow, implausible combination of views, namely purely \u2018experientialist welfarist\u2019 minimalism combined with \u2018<strong>single-level consequentialism</strong>\u2019 (going only straight down in the diagram).</figcaption></figure><p>The diagram reflects the structure of this essay:</p><ul><li>In Section 2, I outline&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Xx9oWdJDfisAQwDtT/varieties-of-minimalist-moral-views-against-absurd-acts#2__Nonconsequentialist_reasons_against_absurd_acts\"><strong><u>nonconsequentialist</u></strong></a> reasons against absurd acts.<ul><li>I focus on the following five normative positions: virtue ethics, deontology, social contract theory, care ethics, and skepticism of general moral theories.</li></ul></li><li>In Section 3, I outline&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Xx9oWdJDfisAQwDtT/varieties-of-minimalist-moral-views-against-absurd-acts#3__Consequentialist_reasons_against_absurd_acts\"><strong><u>consequentialist</u></strong></a> reasons against absurd acts.<ul><li>I focus briefly on&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Xx9oWdJDfisAQwDtT/varieties-of-minimalist-moral-views-against-absurd-acts#Extra_welfarist_axiologies\"><strong><u>extra-welfarist</u></strong></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Xx9oWdJDfisAQwDtT/varieties-of-minimalist-moral-views-against-absurd-acts#Extra_experientialist_welfarist_axiologies\"><strong><u>extra-experientialist</u></strong></a> axiologies, namely on how such views may consider acts of violence or violation to be bad independent of their overall effects on experiential wellbeing.</li><li>Lastly, I focus on&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Xx9oWdJDfisAQwDtT/varieties-of-minimalist-moral-views-against-absurd-acts#Rule_consequentialism\"><strong><u>rule consequentialist</u></strong></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Xx9oWdJDfisAQwDtT/varieties-of-minimalist-moral-views-against-absurd-acts#Multi_level_consequentialism__Relevant_for_all_minimalist_moral_views\"><strong><u>multi-level consequentialist</u></strong></a> reasons, such as the instrumental reasons for respecting autonomy, cooperation, and nonviolence, which are relevant for all plausible minimalist moral views to the degree that they contain a consequentialist component.</li></ul></li></ul><h1>2. Nonconsequentialist reasons against absurd acts</h1><p><a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing\"><u>Views of wellbeing</u></a> alone aren\u2019t normative views; they don\u2019t in themselves constitute any general principle for us to follow as a \u2018criterion of rightness\u2019 in our moral decision-making. Rather, they have normative implications for our actions when combined with normative views whose criteria of rightness depend on wellbeing. For instance, welfarist consequentialism says that wellbeing outcomes alone determine the rightness of actions, with all other factors \u2014 such as intentions, rules, or virtues \u2014 being morally relevant only insofar as they affect the wellbeing outcomes.</p><p>I assume that all minimalist moral views would give at least some weight to how our actions affect the wellbeing of others. Thus, the consequentialist reasons against absurd acts (outlined in Section 3) can be relevant for all such views. Yet many views may give additional normative weight to other factors, independent of the consequences of our actions. These views and factors may be worth exploring as separate reasons against absurd acts.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9pio2sjswt\"><sup><a href=\"#fn9pio2sjswt\">[3]</a></sup></span></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Xx9oWdJDfisAQwDtT/nmiaup1gfgsgeoknn7vl\"><figcaption><strong>Figure 2</strong>. The current section covers this branch.</figcaption></figure><h2><strong>Virtue ethics</strong></h2><p>Nothing stands in the way of combining a minimalist view of wellbeing or value with&nbsp;<a href=\"https://plato.stanford.edu/entries/ethics-virtue/\"><u>virtue ethics</u></a>, whose central focus is the lifelong commitment to developing one\u2019s moral character. Virtue ethics is not about seeking out any particular actions that yield the best outcomes, but about fostering a virtuous character from which the right actions would naturally follow.</p><p>Imagine a moral exemplar who embodies the widely emphasized virtues of courage, kindness, honesty, and integrity. Would they sneak around, opportunistically murdering innocent individuals in the name of reducing suffering? Walk past drowning children? Sabotage healthcare?</p><p>They most certainly would not act in such ways. After all, those widely emphasized virtues are highly antithetical to such acts of backstabbing, betrayal, deception, and the like. Moreover, even in the unlikely case where one might imagine a consequentialist justification for some seemingly absurd actions, the focus of virtue ethics remains not on any particular actions, but rather on the continuous cultivation of an unfailingly virtuous character, avoiding deviation from the path of highest virtue.</p><h2><strong>Deontology</strong></h2><p>A minimalist view may also be combined with&nbsp;<a href=\"https://plato.stanford.edu/entries/ethics-deontological/\"><u>deontology</u></a>, where right action is determined by adherence to a set of moral rules or duties. For instance, deontology can entail a commitment to non-maleficence (\u201cdo no harm\u201d), the golden rule (\u201ctreat others as you wish to be treated\u201d), or respecting certain inviolable rights that apply universally to all individuals, such as the right to autonomy.</p><p>It\u2019s easy to see how deontology would directly oppose extreme actions that a purely consequentialist analysis might otherwise justify as stepping stones to better outcomes. For example, consider severe rights violations aimed at hastening the termination of lives that are perceived to have negative welfare. Regardless of whether such actions would practically lead to better outcomes, deontology rejects that outcomes are the full picture of what matters morally, and holds instead that our actions should primarily align with our duties, which often contradict what may seem justified in the edge cases of purely consequentialist reasoning.</p><h2><strong>Social contract theory</strong></h2><p>Similarly, one may endorse minimalist versions of&nbsp;<a href=\"https://plato.stanford.edu/entries/contractarianism/\"><u>social</u></a>&nbsp;<a href=\"https://plato.stanford.edu/entries/contractualism/\"><u>contract</u></a> theories, which derive moral norms from a hypothetical agreement conceived through rational deliberation (a \u201csocial contract\u201d). Social contract theories center around the idea of consensus among rational agents, implying that an action is morally wrong when it violates the norms of this hypothetical consensus.</p><p>Imagine a diverse set of people, endorsing a minimalist view of wellbeing, who deliberate on the moral principles governing their society. Would they endorse norms that allow callous acts like murder, passive bystanderism, or attempting to collapse the healthcare system? It seems doubtful that they would endorse the kind of chaotic and unsafe society where such unilateral choices were acceptable.</p><p>More likely, they would converge on impartial, predictable norms of justice, trust, and respect for everyone\u2019s autonomy, with a focus on cooperatively minimizing severe problems, such as extreme suffering, violence, and violation. By contrast, the callous acts in question seem like textbook examples of breaching the social contract.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn5hswu6t9to\"><sup><a href=\"#fnn5hswu6t9to\">[4]</a></sup></span></p><h2><strong>Care ethics</strong></h2><p>Compared to the previous views,&nbsp;<a href=\"https://iep.utm.edu/care-ethics/\"><u>care ethics</u></a> is less abstract and universalistic, and more concrete and contextualistic. A core idea in care ethics is that individuals are fundamentally relational and interdependent beings, with ethical obligations arising from relationships. It is focused on attentive, empathetic, and proactive responsiveness to the needs of others, particularly within relationships of care and dependency.</p><p>A minimalist version of care ethics would naturally focus on anticipating and addressing the unmet needs of others, without necessarily assuming that their primary concern would be anything like minimizing personal suffering. Rather, it would plausibly involve attending and responding to others on their own terms, with sensitivity to their own goals and pursuits in life.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2f526ab7l1z\"><sup><a href=\"#fn2f526ab7l1z\">[5]</a></sup></span>&nbsp;Thus, minimalist care ethics would likely oppose any acts that fail to respond to others in a caring way, such as acts of murder, betrayal, or being insensitive to the subjective perspectives of others.</p><h2><strong>Skepticism of general moral theories</strong></h2><p><a href=\"https://plato.stanford.edu/entries/moral-particularism-generalism/\"><u>Various</u></a> philosophers doubt the idea of a universal moral criterion that would apply to all actions in all situations, often highlighting the complexity or context-sensitivity of morality. They may argue that a universal ethical framework will inevitably oversimplify ethics, or that there is no pressing need for such a framework.</p><p>A comparison could be made to how physicists use different theories in different domains of applicability, reflecting the complexity of physical phenomena. Similarly, one may find some moral theories plausible and applicable in some domains, yet doubt that any single theory could fully capture the complexity of moral phenomena across all domains.</p><p>Knutsson (<a href=\"https://centerforreducingsuffering.org/research/my-moral-view-reducing-suffering-by-simon-knutsson/\"><u>2023</u></a>) combines a minimalist view of wellbeing and value with skepticism of overarching moral theories. The resulting moral view does not generate the alleged absurd implications often falsely attributed to minimalist views of wellbeing or value, as it is not tied to any moral theory that would generate such implications.</p><hr><p>In sum, while consequentialism deems outcomes the sole criterion of moral rightness, we may also \u2014&nbsp;to the degree that we find it plausible \u2014 give independent normative weight to factors like character, duties, agreements, or empathetic responsiveness in our relations with others.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefr1st8aiarze\"><sup><a href=\"#fnr1st8aiarze\">[6]</a></sup></span></p><h1>3. Consequentialist reasons against absurd acts</h1><p>The following reasons relate to varieties of purely consequentialist minimalist views, but also to all other views that give some normative weight to the relevant assumptions (i.e.&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Xx9oWdJDfisAQwDtT/varieties-of-minimalist-moral-views-against-absurd-acts#Extra_welfarist_axiologies\"><u>extra-welfarist disvalue</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Xx9oWdJDfisAQwDtT/varieties-of-minimalist-moral-views-against-absurd-acts#Extra_experientialist_welfarist_axiologies\"><u>extra-experiential components of wellbeing</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Xx9oWdJDfisAQwDtT/varieties-of-minimalist-moral-views-against-absurd-acts#Rule_consequentialism\"><u>rule consequentialism</u></a>, or&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Xx9oWdJDfisAQwDtT/varieties-of-minimalist-moral-views-against-absurd-acts#Multi_level_consequentialism__Relevant_for_all_minimalist_moral_views\"><u>multi-level consequentialism</u></a>).</p><h2><strong>Axiological reasons</strong></h2><p>This section covers views that may consider acts of violence or violation to be bad \u2014 in themselves, or for the victim \u2014 independent of their overall effects on experiential wellbeing.</p><h3><strong>Extra-welfarist axiologies</strong></h3><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Xx9oWdJDfisAQwDtT/uiufulbpkibfs7xbahim\"><figcaption><strong>Figure 3</strong>. Minimalist versions of ideal consequentialism (sometimes also called&nbsp;<a href=\"https://en.wikipedia.org/wiki/Utilitarianism#Ideal_utilitarianism\"><u>ideal utilitarianism</u></a>) may hold that acts of violence or violation are worth reducing for their own sake.</figcaption></figure><p>Even if consequentialist views agree that the rightness of actions is determined solely by the value of their outcomes, they diverge in what they define as the morally relevant parts of outcomes. Welfarism holds that the value of outcomes is based solely on the wellbeing they contain. By contrast, some forms of ideal consequentialism hold that certain acts have intrinsic value or disvalue, independent of their overall effects on wellbeing.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7ur6s28hcux\"><sup><a href=\"#fn7ur6s28hcux\">[7]</a></sup></span></p><p>Minimalist versions of ideal consequentialism wouldn\u2019t count any acts as intrinsically good or valuable. Yet certain acts would have independent disvalue, thereby decreasing the value of outcomes. For instance, acts like murder or betrayal could in themselves constitute severe bads, and hence count among the very phenomena to be minimized.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3brgg8wfqro\"><sup><a href=\"#fn3brgg8wfqro\">[8]</a></sup></span></p><h3><strong>Extra-experientialist welfarist axiologies</strong></h3><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Xx9oWdJDfisAQwDtT/u0ts0deh2dcqccfxwhai\"><figcaption><strong>Figure 4</strong>. One may hold that certain things are bad for us even if they aren\u2019t part of our conscious experience.</figcaption></figure><p>We have considered how the scope of normative weight need not be limited to consequences, and how the scope of consequences need not be limited to effects on wellbeing. Similarly, welfarist consequentialism need not define wellbeing solely in terms of conscious experiences.</p><p>While&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Experientialist_views\"><u>experientialist minimalist views</u></a> define wellbeing as the degree to which we are free from experiential sources of illbeing (like suffering, disturbance, or a visceral non-acceptance of our current experience), minimalist versions of&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Extra_experientialist_views\"><u>extra-experientialist views</u></a> may additionally hold that we can be severely harmed by factors outside our immediate experience (like&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Preferentialist_views\"><u>unmet preferences</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Conditional_interests_versus_teleological_goods\"><u>violated interests</u></a>, or&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oJJLgJTsQKX3oQ9xw/minimalist-views-of-wellbeing#Objective_list_views\"><u>objective conditions</u></a>).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdlz7qosq6jb\"><sup><a href=\"#fndlz7qosq6jb\">[9]</a></sup></span></p><p>If we combine welfarist consequentialism with these broader views, it follows that we should reduce not only felt harms, but also harms like unwanted or premature death, being subjected to violence, and failed life projects, given that these would additionally be considered to be severe bads in themselves. This adds another layer of opposition to the absurd alleged implications that critics sometimes associate with minimalist views of wellbeing or value.</p><h2><strong>Rule and multi-level consequentialism</strong></h2><p>Consequentialist views need not recommend case-by-case calculations of the expected outcomes of every single action. This is often cognitively demanding, time-consuming, or even impossible, and hence practically counterproductive by consequentialism\u2019s own lights.</p><p>Instead, some versions of consequentialism provide clearer and more practical guidance for action by focusing on general rules or heuristics to follow. These rules or heuristics can capture the wisdom of past experiences, codifying patterns of action that generally lead to better outcomes.</p><h3><strong>Rule consequentialism</strong></h3><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Xx9oWdJDfisAQwDtT/jmr8ro3irazqipomm1zg\"><figcaption><strong>Figure 5</strong>. Rule consequentialism focuses on the consequences not of individual actions, but of generally applied rules.</figcaption></figure><p><a href=\"https://plato.stanford.edu/entries/consequentialism-rule/\"><u>Rule consequentialism</u></a> deems actions right if they follow rules that, when generally applied, yield the best overall outcomes. Unlike deontology and social contract theory, it selects rules based solely on their expected consequences. Yet all three evaluate the moral rightness of individual actions by rule adherence rather than case-by-case consequences.</p><p>Minimalist rule consequentialism would strongly oppose acts like unprovoked murder and severe and unprovoked rights violations, as the allowance of such acts is prone to overall increase rather than decrease the amount of problems in the world. At worst, general rules that allowed such acts would risk leading to catastrophic futures. After all, increased conflict and hostility among future actors is a key risk factor for worst-case outcomes \u2014&nbsp;namely, worlds defined by ruthless competition, adversarial dynamics, and escalations that bring out the worst tendencies for hatred, vengeance, and sadism.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwhzlaawkexh\"><sup><a href=\"#fnwhzlaawkexh\">[10]</a></sup></span></p><p>Rather, the best general rules to adopt will most likely involve a proactive protection of people\u2019s lives and safety, in part because that seems the best way to secure and develop our shared capacity to solve problems in cooperative ways.</p><h3><strong>Multi-level consequentialism: Relevant for all minimalist moral views</strong></h3><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Xx9oWdJDfisAQwDtT/a89yxn7maihfshmhkdts\"><figcaption><strong>Figure 6</strong>. The multi-level approach recommends the decision procedures that best help us bring about better outcomes.</figcaption></figure><p>Multi-level consequentialism merges act-based and rule-based approaches, providing a layered approach to consequentialist decision-making.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefulsaj9zpt6t\"><sup><a href=\"#fnulsaj9zpt6t\">[11]</a></sup></span>&nbsp;It ties the rightness of actions to their overall consequences, yet only recommends that we calculate the consequences of individual actions in the (arguably rare) \u2018critical\u2019 cases where this is plausibly worth the effort. These could be the occasional high-stakes situations where our established heuristics deeply conflict, are silent, or might lead to highly suboptimal outcomes, prompting a switch to the more analytical level of moral reasoning.</p><p>In everyday situations, where such detailed analysis is impractical, the multi-level approach recommends the \u2018intuitive\u2019 decision procedure of following established heuristics that generally lead to better outcomes. These heuristics can often be inferred and justified at the analytical level given our past experiences and knowledge, yet consequentialists need not reinvent all the moral wheels of society. After all, a highly sensible meta-heuristic is to assign significant weight to the long-standing recommendations of established norms and other ethical views in typical moral decisions \u2014 at least when these recommendations strongly converge to discourage certain types of actions.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefii01aanll4\"><sup><a href=\"#fnii01aanll4\">[12]</a></sup></span></p><p>To effectively reduce problems in the big picture, the multi-level approach recommends that we mostly focus on the kinds of positive, constructive goals that best enable us to collectively prevent problems like extreme suffering \u2014 a multi-generational task that requires greater levels of coordination and cooperation, and which requires us to avoid and actively prevent absurd acts.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefeu52k4wna5g\"><sup><a href=\"#fneu52k4wna5g\">[13]</a></sup></span>&nbsp;And since all the minimalist views discussed here give at least some weight to minimizing the badness of outcomes, this is (an added) reason for all people with such views to oppose absurd acts.</p><h1>Acknowledgments</h1><p>I am grateful for helpful comments by Simon Knutsson and Magnus Vinding.</p><h1>References</h1><p>Baumann, T. (2019/2022). Risk factors for s-risks.&nbsp;<a href=\"https://centerforreducingsuffering.org/research/risk-factors-for-s-risks/\"><u>Ungated</u></a>.</p><p>Brennan, S. M. K. (1988).&nbsp;<i>Ideal Utilitarianism</i>. PhD thesis, University of Iowa.&nbsp;<a href=\"https://philpapers.org/rec/BREIU\"><u>PhilPapers</u></a>.</p><p>Ewing, A. C. (1948). Utilitarianism.&nbsp;<i>Ethics</i>,&nbsp;<i>58</i>(2), 100\u2013111.&nbsp;<a href=\"https://doi.org/10.1086/290597\"><u>DOI</u></a>.</p><p>Knutsson. S. (2022). Pessimism about the value of the future and the welfare of present and future beings based on their acts and traits.&nbsp;<a href=\"https://www.simonknutsson.com/pessimism-value-future-welfare-acts-traits/\"><u>Ungated</u></a>.</p><p>Knutsson, S. (2023). My moral view: Reducing suffering, \u2018how to be\u2019 as fundamental to morality, no positive value, cons of grand theory, and more.&nbsp;<a href=\"https://centerforreducingsuffering.org/research/my-moral-view-reducing-suffering-by-simon-knutsson/\"><u>Ungated</u></a>.</p><p>Mayerfeld, J. (1999).&nbsp;<i>Suffering and Moral Responsibility</i>. Oxford University Press.</p><p>Ord, T. (2013). Why I\u2019m Not a Negative Utilitarian.&nbsp;<a href=\"http://www.amirrorclear.net/academic/ideas/negative-utilitarianism/\"><u>Ungated</u></a>.</p><p>Orsi, F. (2012). David Ross, Ideal Utilitarianism, and the Intrinsic Value of Acts.&nbsp;<i>Journal for the History of Analytical Philosophy, 1</i>(2).&nbsp;<a href=\"https://doi.org/10.4148/jhap.v1i2.1348\"><u>DOI</u></a>.</p><p>Vinding, M. (2020).&nbsp;<i>Suffering-Focused Ethics: Defense and Implications</i>. Ratio Ethica.&nbsp;<a href=\"https://magnusvinding.files.wordpress.com/2020/05/suffering-focused-ethics.pdf\"><u>Ungated</u></a>.</p><p>Vinding, M. (2022a). Point-by-point critique of Ord\u2019s \u201cWhy I\u2019m Not a Negative Utilitarian\u201d.&nbsp;<a href=\"https://centerforreducingsuffering.org/point-by-point-critique-of-why-im-not-a-negative-utilitarian/\"><u>Ungated</u></a>.</p><p>Vinding, M. (2022b).&nbsp;<i>Reasoned Politics</i>. Ratio Ethica.&nbsp;<a href=\"https://magnusvinding.files.wordpress.com/2022/03/reasoned-politics.pdf\"><u>Ungated</u></a>.</p><p>Vinding, M. (2022c). Some pitfalls of utilitarianism.&nbsp;<a href=\"https://magnusvinding.com/2022/11/25/some-pitfalls-of-utilitarianism/\"><u>Ungated</u></a>.</p><p>Vinding, M. (forthcoming).&nbsp;<i>Compassionate Purpose: Personal Inspiration for a Better World</i>.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnh9gljokkd2p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefh9gljokkd2p\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Others may define \u201cminimalist moral views\u201d more broadly to include views that reject independently positive or offsetting moral value without endorsing minimalist axiological claims of any kind (e.g. views that lack an axiology). Such views might include versions of fully nonconsequentialist views that entail only moral claims that are \u201cminimalist in flavor\u201d, such as that we have moral reasons to reduce vice, harm, violations, and so on.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8z6yrs392a6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8z6yrs392a6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For instance, an influential yet misleading essay by Toby Ord (<a href=\"http://www.amirrorclear.net/academic/ideas/negative-utilitarianism/\"><u>2013</u></a>) contains the following claim:</p><blockquote><p>[Negative utilitarianism, a consequentialist view focused on the minimization of suffering] implies that much healthcare and lifesaving is of enormous negative value. It says that the best healthcare system is typically the one that saves as few lives as possible, eliminating all the suffering at once. This turns healthcare policy debates on their heads and means we shouldn\u2019t be emulating France or Germany, but should instead look to copy failed states such as North Korea.</p></blockquote><p>(This and other misleading claims in Ord\u2019s essay are given a point-by-point reply in Vinding,&nbsp;<a href=\"https://centerforreducingsuffering.org/point-by-point-critique-of-why-im-not-a-negative-utilitarian/\"><u>2022a</u></a>.)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9pio2sjswt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9pio2sjswt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For some context regarding how widely endorsed these nonconsequentialist views are, it is worth noting that among the respondents of the&nbsp;<a href=\"https://survey2020.philpeople.org/survey/results/4890\"><u>2020 PhilPapers survey</u></a> (of 1741 English-speaking philosophers from around the world), only a fifth were exclusively favorable toward pure consequentialism:</p><p>\u2022 37% leaned toward&nbsp;<strong>virtue ethics</strong> (25% exclusively);</p><p>\u2022 32% toward&nbsp;<strong>deontology</strong> (20% exclusively);</p><p>\u2022 31% toward&nbsp;<strong>consequentialism</strong> (21% exclusively);</p><p>\u2022 16% for combined views;</p><p>\u2022 6% for alternative views.</p><p>The responses&nbsp;<a href=\"https://survey2020.philpeople.org/survey/results/4890?aos=30\"><u>among normative ethicists</u></a> (<i>n</i> = 358) indicate similar or even broader support for nonconsequentialist views:</p><p>\u2022 38% leaned toward&nbsp;<strong>virtue ethics</strong> (21% exclusively);</p><p>\u2022 41% toward&nbsp;<strong>deontology</strong> (23% exclusively);</p><p>\u2022 30% toward&nbsp;<strong>consequentialism</strong> (20% exclusively);</p><p>\u2022 22% for combined views;</p><p>\u2022 10% for alternative views.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn5hswu6t9to\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn5hswu6t9to\">^</a></strong></sup></span><div class=\"footnote-content\"><p>While rational agents might converge only on a relatively narrow range of acceptable means for reducing extreme suffering, there\u2019s still good reason to assume that they would give strong priority to the underlying aim of reducing extreme suffering. A&nbsp;<a href=\"https://plato.stanford.edu/entries/contractualism/\"><u>contractualism</u></a>-based argument for the latter claim is found in Vinding,&nbsp;<a href=\"https://magnusvinding.files.wordpress.com/2020/05/suffering-focused-ethics.pdf\"><u>2020</u></a>, Section 6.7. Similarly, Mayerfeld (<a href=\"https://www.goodreads.com/book/show/2438988.Suffering_and_Moral_Responsibility\"><u>1999</u></a>, p. 115) identifies a contractualist justification for the duty to relieve suffering as follows:</p><blockquote><p>reasonable moral rules are those that would be chosen by people made temporarily ignorant of their life circumstances [i.e. behind the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Original_position\"><u>veil of ignorance</u></a>]. \u2026 People who could not predict the extent of their vulnerability to suffering in real life might seek protection from the worst eventuality by agreeing on a strong requirement to relieve suffering.</p></blockquote></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2f526ab7l1z\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2f526ab7l1z\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Given this sensitivity to individuals\u2019 own goals and pursuits, it may be natural to combine a minimalist version of care ethics with a minimalist preference-based view of wellbeing.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnr1st8aiarze\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefr1st8aiarze\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The factors can be combined in various ways. For instance, one may combine them into \u201coverarching pluralist theories\u201d where different virtues and duties all play an advisory role in all of one\u2019s moral decisions. Alternatively, one may combine them into skeptical or particularist views, where no single aspect of morality is universally applicable, yet many may have their own domains where they best apply.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7ur6s28hcux\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7ur6s28hcux\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Ewing,&nbsp;<a href=\"https://doi.org/10.1086/290597\"><u>1948</u></a>, pp. 108\u2013111; Brennan,&nbsp;<a href=\"https://philpapers.org/rec/BREIU\"><u>1988</u></a>; Orsi,&nbsp;<a href=\"https://doi.org/10.4148/jhap.v1i2.1348\"><u>2012</u></a>, sec. 4.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3brgg8wfqro\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3brgg8wfqro\">^</a></strong></sup></span><div class=\"footnote-content\"><p>A minimalist view that assigns disvalue to acts is introduced and defended in Knutsson,&nbsp;<a href=\"https://www.simonknutsson.com/pessimism-value-future-welfare-acts-traits/\"><u>2022</u></a>, though note that Knutsson\u2019s moral view is not consequentialist.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndlz7qosq6jb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdlz7qosq6jb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The&nbsp;<a href=\"https://survey2020.philpeople.org/survey/results/5206\"><u>2020 PhilPapers survey</u></a> polled global English-speaking philosophers on wellbeing views. Of the 967 respondents, most seemed to agree that wellbeing can be negatively affected by things outside our experience, as only 10% favored experientialism exclusively:</p><p>\u2022 53% leaned toward&nbsp;<strong>objective list views</strong> (50% exclusively);</p><p>\u2022 19% toward&nbsp;<strong>desire satisfaction/preferentialist views</strong> (15% exclusively);</p><p>\u2022 13% toward&nbsp;<strong>hedonism/experientialism</strong> (10% exclusively);</p><p>\u2022 5% for combined views;</p><p>\u2022 5% for alternative views.</p><p><a href=\"https://survey2020.philpeople.org/survey/results/5206?aos=30\"><u>Among normative ethicists</u></a> (<i>n</i> = 244):</p><p>\u2022 64% leaned toward&nbsp;<strong>objective list views</strong> (59% exclusively);</p><p>\u2022 15% toward&nbsp;<strong>desire satisfaction/preferentialist views</strong> (12% exclusively);</p><p>\u2022 11% toward&nbsp;<strong>hedonism/experientialism</strong> (9% exclusively);</p><p>\u2022 6% for combined views;</p><p>\u2022 8% for alternative views.</p><p>For what it\u2019s worth, there were weak correlations between consequentialism and experientialism (<i>r</i> = 0.26), preferentialism (<i>r</i> = 0.19), and an inverse one with objective list views (<i>r</i> = -0.29), which indicates that philosophers broadly endorse various combinations of normative and wellbeing views, including extra-experientialist consequentialist views.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwhzlaawkexh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwhzlaawkexh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Baumann, 2019/2022, \u201c<a href=\"https://centerforreducingsuffering.org/research/risk-factors-for-s-risks/#Conflict_and_hostility\"><u>Conflict and hostility</u></a>\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnulsaj9zpt6t\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefulsaj9zpt6t\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Multi-level consequentialism has more often been discussed under \u201c<a href=\"https://en.wikipedia.org/wiki/Consequentialism#Two-level_consequentialism\"><u>two-level consequentialism</u></a>\u201d or \u201c<a href=\"https://en.wikipedia.org/wiki/Two-level_utilitarianism\"><u>two-level utilitarianism</u></a>\u201d, as developed by R. M. Hare.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnii01aanll4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefii01aanll4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Cf. Vinding, 2022c, \u201c<a href=\"https://magnusvinding.com/2022/11/25/some-pitfalls-of-utilitarianism/#a-more-plausible-approach\"><u>A more plausible approach</u></a>\u201d:</p><blockquote><p>In other words, it seems that utilitarian decision procedures are best approached by assigning a fairly high prior to the judgments of other ethical views and common-sense moral intuitions (in terms of how plausible those judgments are from a utilitarian perspective), at least when these other views and intuitions converge strongly on a given conclusion. And it seems warranted to then be quite cautious and slow to update away from that prior, in part because of our massive uncertainty and our self-deceived minds. This is not to say that one could not end up with significant divergences relative to other widely endorsed moral views, but merely that such strong divergences probably need to be supported by a level of evidence that exceeds a rather high bar.</p><p>Likewise, it seems worth approaching utilitarian decision procedures with a prior that strongly favors actions of high integrity, not least because we should expect our rationalizing minds to be heavily biased toward low integrity \u2014 especially when nobody is looking.</p><p>Put briefly, it seems that a more defensible approach to utilitarian decision procedures would be animated by significant humility and would embody a strong inclination toward key virtues of integrity, kindness, honesty, etc., partly due to our strong tendency to excuse and rationalize deficiencies in these regards.</p></blockquote></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fneu52k4wna5g\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefeu52k4wna5g\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Vinding,&nbsp;<a href=\"https://magnusvinding.files.wordpress.com/2022/03/reasoned-politics.pdf\"><u>2022b</u></a>, Chapter 9, \u201cIdentifying Plausible Proxies\u201d;&nbsp;<a href=\"https://docs.google.com/document/d/1tU8B0BqJnjKi12XNwUD3hAkLe4HPKrXwzCixFXr5058/\"><u>forthcoming</u></a>, Section 6.3, \u201cFocusing on Positive and Constructive Goals\u201d.</p></div></li></ol>", "user": {"username": "Teo Ajantaival"}}, {"_id": "cmB6Wt4NH6D9LJSWb", "title": "Are The Worlds Top Charities Secular?", "postedAt": "2023-11-07T06:20:13.926Z", "htmlBody": "<p>Hello</p><p>I have been debating a family member on charitable donations in Christian communities, and he pointed out that the vast majority of charities were founded by Christians. I pointed out that out of the worlds most effective charities, there was no overrepresentation of Christian founders like there was in the less-effective charities, implying that it wasn't so much the higher rates of generosity as much as it was a confounding variable. Unfortunately, most of these charities do not give much information as to their founders or religious or secular philosophies, so I can only give information on the charities that do which is a much smaller sample which may have confounding variables of its own. I have no reason to doubt that I'm wrong, but it would be nice to know if I am.&nbsp;</p><p>Cheers</p><p>Jack</p>", "user": {"username": "Jack Sands"}}, {"_id": "FGuMiuFiu3DFBDJvA", "title": "Is suicide a rational decision if it improves animals' well being. ", "postedAt": "2023-11-07T11:12:10.085Z", "htmlBody": "<p>*Copied from reddit, please dont delete.</p><p>Hi, I am 16.</p><p>I've been vegan for a few months but I am expecting things to go south any second now. I am living in a third world country so the pay for any part time job will be peanuts. Besides my parents would probably kick me out of the house if I did something like that because it would ruin their \"social status\". I've also heard a lot of those arguments which vegans often hear; not being realistic, vegan deficiencies, etc.</p><p>But this is nothing. The fam is discussing a potential visit to a psychiatrist, a visit to a pastor (where I'll firstly get ridiculed in front of the whole 'pastor council' for not being a man) who will accuse me of giving up my religion (which is true) and throw verses at me telling me that animals are a creation of God and they are here so we can eat them. And I can't just say that I am no longer religious, I'll prefer to have my limbs attached to my torso. Family gatherings are another thing where I'd be forced to go to find no vegan food so what do i do there?</p><p>I have been thinking about suicide as a way to prevent further harm of animals. The only thing stopping me is the idea that I could soak it all up (even if that means forcibly eating non vegan food) and maybe potentially make life better for the animals. I have planned majoring in STEM so i doubt how it'll positively affect the lives of animals.</p><p>Please guide me.</p>", "user": {"username": "landedonmainland"}}, {"_id": "fFNAcQBDkBHxPXuJJ", "title": "Why Certify? \nAquatic Life Institute\u2019s Impact Implementation Via Seafood Certification", "postedAt": "2023-11-07T03:04:11.254Z", "htmlBody": "<h1>Snapshot</h1><ul><li>Aquatic Life Institute has recently launched the <strong>second edition</strong> of the&nbsp;<a href=\"https://static1.squarespace.com/static/5e4ff4ae6791c303cbd43f67/t/64f8c104beecaa75d8deb4e4/1694023946918/Aquaculture+Certification+Schemes+Benchmark+2023.pdf\"><u>Aquaculture Certification Schemes Benchmark</u></a><u>.</u></li><li>These schemes collectively certify, at minimum,&nbsp;<strong>773 million fishes and 10.5 billion shrimps</strong> annually.</li><li><strong>For every $1 of funding received, we have potentially helped improve the lives of 5,423 fish and 221,343 shrimp</strong> directly through our engagement with these certifiers.</li></ul><h1>444: Four R's for Formative Change&nbsp;</h1><p>In 2019,&nbsp;<a href=\"https://ali.fish/\"><u>Aquatic Life Institute&nbsp;</u></a>(ALI) embarked on a journey to reduce the suffering for trillions of aquatic animals in the global food system each year.&nbsp;</p><p>This past September, ALI established&nbsp;<a href=\"https://ali.fish/4rs\"><u>4 Key Principles</u></a> to help guide our interventions for systemic transformation in aquatic animal welfare that are used to filter organizational priorities:</p><ol><li><strong><u>Reduce</u></strong> the number of animals in, or remove animals from, the seafood system and its supply chain.</li><li><strong>Refine</strong> the conditions in which animals are currently kept or captured in the seafood system and its supply chain.</li><li><strong>Replace</strong> animal products with sustainable plant-based or cell-based alternatives to the extent possible in the seafood system and its supply chain.</li><li><strong>Reject</strong> the introduction of additional animals into the seafood system and its supply chain.</li></ol><p>In alignment with these 4 principles, we have worked with seafood certifications for years, building relationships and fostering change via our&nbsp;<a href=\"https://ali.fish/certifier-campaign\"><u>Certifier Campaign</u></a>.&nbsp;</p><h1>Certification Landscape&nbsp;</h1><p>Between&nbsp;<strong>51 and 167 billion farmed fish</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefd2cedp4kz6\"><sup><a href=\"#fnd2cedp4kz6\">[1]</a></sup></span>&nbsp;are produced annually from global aquaculture operations. Although there are examples of good welfare practices in aquaculture, the concept of what officially constitutes \u201chumanely-raised fish\u201d or a \u201chigh welfare seafood product\u201d is still largely undefined worldwide by the public, industry, animal welfare organizations, and most governments.&nbsp;</p><p>As institutions certifying aquatic animal products begin incorporating positive welfare standards into their seafood labeling programs, they must diligently define high welfare products based on the best available scientific evidence rather than rely on subpar industry norms. \u201cHumanely-raised\u201d aquaculture standards must include more than just stunning before slaughter; they should consider animal welfare conditions throughout the stages of their lives in production. The farmed aquatic&nbsp;animals <i>living</i> in aquaculture facilities at any given time need to be prioritized.&nbsp;</p><p>Aquaculture standards must also account for additional aquatic animals not directly used for human consumption, such as animals reduced to fishmeal and fish oil ingredients, cleaner fish, and broodstock. Consumers turn to seafood labeling schemes for guidance to avoid purchasing products that conflict with sustainable and humane practices. More than 100 certifications and ratings programs of one type or another are currently in use by the seafood industry. This shift now means that&nbsp;<strong>56% of all farmed seafood (including seaweed) is rated or certified</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefij1qk8u21dl\"><sup><a href=\"#fnij1qk8u21dl\">[2]</a></sup></span>, and volumes of&nbsp;<strong>certified farmed fish and shellfish constitute about 8% of global aquaculture</strong> production<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflzahh0o26o\"><sup><a href=\"#fnlzahh0o26o\">[3]</a></sup></span>. The amount of certified aquatic animal products is only expected to increase. There is no evidence that certification will be phased out anytime in the near future, given consumers\u2019 increasing demand for sustainable seafood and the absence of a better alternative<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0li40m7fe34\"><sup><a href=\"#fn0li40m7fe34\">[4]</a></sup></span>. Some schemes are reporting notable <a href=\"https://thefishsite.com/articles/22-percent-growth-in-asc-certified-farms#:~:text=The%20Aquaculture%20Stewardship%20Council%20 \">growth</a> and others are discussing the aggressive expansion of their operations to certify a greater number of seafood products in various regions.</p><p>However, many of these labels lack explicit considerations for positive animal welfare or fail to provide adequate protections. Through our Certifier Campaign, we aim to hold seafood certification standards accountable and highlight the schemes that provide the most robust aquatic animal protections.&nbsp; ALI\u2019s existing certifier partners have the potential to positively impact over<strong> 5 billion shrimps and 13 million fish&nbsp;</strong>on an annual basis when measured conservatively at only 50% standard compliance. As such, a key intervention point is to ensure certification standards are continually enhanced and adequately address aquatic animal welfare. Our estimates are only based on publicly available data for which several certifiers currently do not list. Therefore, the quantity of certified seafood and subsequent number of individual aquatic animals impacted by certification schemes may be significantly greater than what we are approximating here.</p><h1>The Benchmark&nbsp;</h1><p>In June 2022, ALI launched the&nbsp;<a href=\"https://static1.squarespace.com/static/5e4ff4ae6791c303cbd43f67/t/6387a682b02a064e4055943f/1669834375414/Aquaculture+Certification+Schemes+Benchmark+2.48.12+PM.pdf\"><u>first edition</u></a> of a welfare-based, aquaculture certification benchmark tool that analyzed welfare requirements within the main farming standards of 6 global seafood certification schemes. Based on the results, we were able to craft&nbsp;<a href=\"https://static1.squarespace.com/static/5e4ff4ae6791c303cbd43f67/t/647a29a1a07b3e6079c4e3c1/1685727651515/Recommendations+for+Aquaculture+Certification+Schemes+to+improve+animal+welfare+standards.pdf\"><u>certifier-specific recommendations</u></a> in areas of welfare that were nonexistent, lacking in detail, or could advance into progressive points of novel development.&nbsp;&nbsp;</p><p>This year we launched the second edition of the&nbsp;<a href=\"https://static1.squarespace.com/static/5e4ff4ae6791c303cbd43f67/t/64f8c104beecaa75d8deb4e4/1694023946918/Aquaculture+Certification+Schemes+Benchmark+2023.pdf\"><u>Aquaculture Certification Schemes Benchmark</u></a> tool that analyzed welfare requirements within the primary farming standards of 7 global seafood certification schemes. These schemes collectively certify, at minimum,&nbsp;<strong>773 million fishes and 10.5 billion shrimps</strong> annually.&nbsp;</p><p>Global Animal Partnership (GAP), RSPCA Assured, Naturland, Friend of the Sea, GLOBALGAP, Best Aquaculture Practices (BAP), and Aquaculture Stewardship Council (ASC) were evaluated and scored based on 5 main welfare criteria (<strong>water quality, stocking density/space requirements, environmental enrichment, feed composition, stunning/slaughter</strong>) each comprised of 4 sub-criteria points. We also included a species prohibition criteria topic where restrictions related to the farming of 3 different species&nbsp;<strong>(octopus/cephalopods, insects, and eyestalk ablated shrimp</strong>) are taken into account. The scoring process concluded with an \u201cadditional considerations\u201d verification that indicates the presence or absence of enforcement and compliance, adequate employee training, and environmental impact regulations within their farming standards.&nbsp;</p><p>Reflecting on the 2023 Benchmark process, we were pleased to learn that certifiers are using their ranking as a marketing tool for aquatic animal welfare to promote themselves throughout the supply chain. Certifiers are also proud of their ranking, as seen in the&nbsp;<a href=\"https://asc-aqua.org/news/asc-ranked-in-first-place-for-aquaculture-certification-schemes-by-aquatic-life-institute-ali/\"><u>ASC newsletter</u></a>, which helps amplify ALI\u2019s efforts to advance aquatic animal welfare. The increased interest and active competition to achieve higher scores are a driving component of the Benchmark that we can harness for the benefit of certified aquatic animals worldwide.</p><h1>Systemic Impact</h1><p>Our best&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1W4bowl1DzkVTmQG9kX_e5Y_epdQPRP5m/edit?usp=sharing&amp;ouid=103033786333934103239&amp;rtpof=true&amp;sd=true\"><u>calculations</u></a> show that&nbsp;<strong>for every $1 of funding received, we have potentially helped improve the lives of 5,423 fish and 221,343 shrimp</strong> directly through our engagement with these certifiers. This approximation was based on ALI\u2019s 2022 overhead expenses related to activities focused on strengthening certifier standards, the amount of time spent on these programmatic activities, and the number of individual animals certified by these schemes using available volume production and average harvest weight for different species they certify. Each certification standard improvement was awarded equal consideration in these calculations owing to the fact that we cannot definitively affirm which types of interventions provide specific levels of suffering relief from the perspective of individual aquatic animals at this time.&nbsp;</p><p>In 2024, we aim to further refine and organize these estimates based on region, species, welfare intervention, etc. ALI will continue to expand and deepen our leading work with global seafood certifiers. As we are already seeing&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1KDqrGLYULU0Q9k3k8srCkwoJCN1uZbiLUBzUUydsRBM/edit#gid=0\"><u>significant improvements in these standards year over year</u></a>, which reflect our exact recommendations following the release of the annual Benchmark, the projections for increased and efficient impacts on aquatic animal welfare are promising.&nbsp;</p><h1>Octopus Farming&nbsp;</h1><p>The 2023 species prohibition criteria topic is something we\u2019d like to elaborate on further. Through ALI\u2019s ongoing relationship building and pressure of the Benchmark rating,&nbsp;<strong>RSPCA Assured and Friend of the Sea now prohibit the certification of any form of octopus/cephalopod farming</strong>.&nbsp;</p><p>In November 2022, ALI implemented a global campaign that aims to increase public and legislative pressure on countries/regions where octopus farms are being considered to achieve a regulatory ban, and reduce future chances of these farms being created. We started&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/TQsTahJWj2S5QD86t/banding-together-to-ban-octopus-farming\"><u>Banding Together to Ban Octopus Farming</u></a>. And in April 2023, we provided an update exposing the operation of an octopus farm disguised as a research center that was&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/fZkeMsH2YETGfyDrL/hiding-in-plain-sight-mexico-s-octopus-farm-research-facade\"><u>Hiding in Plain Sight</u></a>. If permitted to operate,<a href=\"https://www.theguardian.com/commentisfree/2023/mar/30/octopus-farming-turns-my-stomach-but-are-some-species-really-more-worthy-than-others\"><u> just one farm could potentially produce 1 million octopuses each year</u></a>. In an attempt to dissuade future development of this unsustainable and cruel farming endeavor,&nbsp; ALI focused on the certified marketability of this potential seafood \u201cproduct\u201d.&nbsp;&nbsp;</p><p>Although there are obvious animal welfare concerns, resource use, environmental impacts, and public health concerns are also extremely present when analyzing an industrial octopus farm. ALI expanded on the aforementioned elements of aquaculture as priority points of intervention during conversations with certification schemes as a premise for prohibition. As a result,&nbsp;<a href=\"https://www.rspca.org.uk/-/news-rspca-calls-for-halt-to-first-octopus-farm\"><u>RSPCA</u></a> published a statement denouncing plans for the world\u2019s first octopus farm. Friend of the Sea provided us with a direct quotation explicitly stating they will not certify this species. If global seafood certifications refuse to create a \u201cprice premium\u201d market for this product, perhaps this could serve as an indication to producers and investors that such products will not be welcomed or highly desirable within the seafood supply chain. These demonstrations of opposition are a testament to our attempts at rejecting a dangerous development before it is an industrial disaster and could potentially translate to the <strong>prevention of suffering for millions of animals</strong>.</p><h1>Welfare Within the Supply Chain&nbsp;</h1><p>The initiatives implemented through ALI\u2019s Certifier Campaign and Benchmark will serve as tools to empower businesses in making informed decisions about sourcing from global certification schemes that prioritize and lead in aquatic animal welfare. Companies can effectively demonstrate their commitment to ethical sourcing, resonate with conscientious consumers, and strengthen their brand's reputation as a responsible and compassionate industry leader by sourcing from certification labels evaluated under this benchmark. Embracing the benchmark fosters supply chain resilience and promotes long-term sustainability, ensuring that companies contribute positively to animal welfare and the environment by&nbsp;<strong>reducing</strong> the number of animals,&nbsp;<strong>refining</strong> the conditions in which animals are currently kept or captured,&nbsp;<strong>replacing</strong> animal products with sustainable plant-based or cell-based alternatives to the extent possible, and&nbsp;<strong>rejecting</strong> the introduction of additional animals into the seafood system and its supply chain. We look forward to continuing this work to <strong>reduce the suffering for trillions of aquatic animals in the global food system each year.</strong></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnd2cedp4kz6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefd2cedp4kz6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cNumbers of Farmed Fish Slaughtered Each Year | Fishcount.org.uk.\u201d Fishcount.org.uk, fishcount.org.uk/fish-count-estimates-2/numbers-of-farmed-fish-slaughtered-each-year&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnij1qk8u21dl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefij1qk8u21dl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\"Sustainable Seafood: A Global Benchmark - Certification &amp; Ratings\"&nbsp;<a href=\"https://certificationandratings.org/data-tool-2022/\"><u>https://certificationandratings.org/data-tool-2022/</u></a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlzahh0o26o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflzahh0o26o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Jonell, Malin, et al. 7 Certifying Farmed Seafood a Drop in the Ocean or a \u201cStepping- Stone\u201d towards Increased Sustainability?&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0li40m7fe34\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0li40m7fe34\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;FAO. The State of World Fisheries and Aquaculture 2020. FAO, 2020.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7u011hvoe9o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7u011hvoe9o\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://thefishsite.com/articles/22-percent-growth-in-asc-certified-farms#:~:text=The%20Aquaculture%20Stewardship%20Council%20\"><u>https://thefishsite.com/articles/22-percent-growth-in-asc-certified-farms#:~:text=The%20Aquaculture%20Stewardship%20Council%20</u></a>&nbsp;</p></div></li></ol>", "user": {"username": "Tessa @ ALI"}}, {"_id": "6ercwC6JAPFTdKsy6", "title": "Please, someone make a dataset of supposed cases of \"tech panic\"", "postedAt": "2023-11-07T02:49:15.460Z", "htmlBody": "<p>TL;DR: Someone should probably [write a grant to] produce a spreadsheet/dataset of past instances where people claimed a new technology would lead to societal catastrophe, but with informative variables such as \u201cmultiple people working on the tech believed it was dangerous.\u201d This could help address the <a href=\"https://datainnovation.org/2023/05/tech-panics-generative-ai-and-regulatory-caution/\">common objection from AI risk skeptics</a> that panic about new technology is omnipresent and basically always wrong, \"so this time with AI isn't different.\"</p><p>\u2014\u2014\u2014</p><p>I have asked multiple people in the AI safety space if they knew of any kind of \"dataset for past predictions of doom (from new technology)\", but I still have not encountered such a project. There have been some articles and arguments floating around such as \"<a href=\"https://datainnovation.org/2023/05/tech-panics-generative-ai-and-regulatory-caution/\">Tech Panics, Generative AI, and the Need for Regulatory Caution</a>\", in which skeptics say we shouldn't worry about AI x-risk because there are many past cases where people in society made overblown claims that some new technology (e.g., bicycles, electricity) would be disastrous for society.</p><p>While I think it's right to consider the \"outside view\" on these kinds of things, I think that most of these claims 1) ignore examples of where there were legitimate reasons to fear the technology (e.g., nuclear weapons, maybe synthetic biology?), and 2) imply the current worries about AI are about as baseless as claims like \"electricity will destroy society,\" whereas I would argue that the claim \"AI x-risk is &gt;1%\" stands up quite well against most current scrutiny.</p><p>(These claims also ignore the anthropic argument/survivor bias\u2014that if they ever were right about doom we wouldn't be around to observe it\u2014but this is less important.)</p><p>I especially would like to see a dataset that tracks things like \"were the people warning of the risks also the people who were building the technology?\" More generally, some measurement of \"analytical rigor\" also seems really important, e.g., \"could the claims have stood up to an ounce of contemporary scrutiny (i.e., without the benefit of hindsight)?\"</p><p>It really seems worth spending up to $20K to hire researchers to produce such a spreadsheet within the next two-ish months\u2026 This could be a critical time period where people are more receptive to new arguments/responses.</p><p>\u2014\u2014\u2014</p><p><i>[Note on this post: this is just a minimally edited shortform I wrote about 5 months ago, and it became my highest upvoted shortform (in fact, one of my highest upvoted posts). At the time I didn't have the motivation or time to make it into a full post. I currently lack the time to make it a formal/detailed post (let alone work on the project myself), but after a string of discussions both in person and online where someone objected to AI risks along the lines I described, I decided I should probably just convert the shortform into a normal post rather than continually wait in silence in the hopes that someone else would say or do something...]</i></p>", "user": {"username": "Harrison D"}}, {"_id": "a2iPKDeKirKC4cCKQ", "title": "A report from EAG Boston", "postedAt": "2023-11-07T01:37:59.516Z", "htmlBody": "<p>I attended my first EAG in Boston last weekend and had a great time. I figured it would be appropriate to combine my first EAG with my first substantial forum post, so here goes.</p><p><i>Epistemic status: Everything in this post is 100% true if you are me, but results may vary if you aren't me. Everyone has personal context</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref76b5em0i2ri\"><sup><a href=\"#fn76b5em0i2ri\">[1]</a></sup></span><i>&nbsp;that influences their experience of events like this! There is also a </i><a href=\"https://forum.effectivealtruism.org/posts/Adzj5WxAnzERHhNBp/i-burnt-out-at-eag-let-s-talk-about-it\"><i><u>robust</u></i></a><i>&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/sxKJckCiZQyux4kCx/ea-global-tips-networking-with-others-in-mind\"><i><u>body</u></i></a><i>&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/g5dbu6yJJzW3m39un/the-best-ea-global-yet-and-other-updates\"><i><u>of</u></i></a><i>&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/mHk9h3RxvuGmTThaS/if-you-find-ea-conferences-emotionally-difficult-you-re-not\"><i><u>literature</u></i></a><i>&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/wFP5KzcksFutS4Eew/what-i-learnt-from-twenty-1-1s-at-eagxoxford\"><i><u>on</u></i></a><i>&nbsp;</i><a href=\"https://forum.effectivealtruism.org/topics/effective-altruism-global\"><i><u>EAG</u></i></a><i>,</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4unwbpmkj6t\"><sup><a href=\"#fn4unwbpmkj6t\">[2]</a></sup></span><i>&nbsp;and this is only one post; weigh accordingly. Finally, although I am employed by GiveWell, this post is personal</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8jl4n6hjhjb\"><sup><a href=\"#fn8jl4n6hjhjb\">[3]</a></sup></span><i>&nbsp;and doesn't represent GiveWell's opinion.</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9fqwow3k9y\"><sup><a href=\"#fn9fqwow3k9y\">[4]</a></sup></span></p><h1><strong>I. Before the conference</strong></h1><p>Conference preparation is really easy. The EAG team uses an app called Swapcard to display the agenda, push out announcements, and organize 1:1s. People love to talk trash about Swapcard, but it's almost certainly better than any other option, and all of the EA software engineers are transitioning to AI safety research<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjzw8vpugzg\"><sup><a href=\"#fnjzw8vpugzg\">[5]</a></sup></span>&nbsp;instead of designing a better app, so we might as well appreciate Swapcard for what it is. Swapcard has several nice features:</p><ol><li>You can look at the entire list of attendees and see information about their organizations, contact info, and topics they can help and be helped with. This is an indescribably nice feature that makes it very easy to find all the people with whom spending time would be maximally fun and useful! CEA also sends out an Excel spreadsheet with similar information, but (imo) Swapcard is better because people frequently update their profiles as the date of the conference approaches.</li><li>Swapcard lets you easily book 1:1s with people and set your own availability for the same. This is a very low friction feature and is extremely useful!</li><li>You will be so angry at Swapcard's many bugs that nothing else could possibly bother you for the remainder of the weekend. For example, I have an unread chat notification in my Swapcard. This notification is a lie (I have read all my chats), but it persists no matter how many times I refresh the app. As another example, sometimes a person will send you a meeting invite, and all the pieces of text in the invite will be superimposed on top of each other such that the invite is entirely unreadable. These and Swapcard's other bugs will make you boil with such a pure rage that no other minor irritations for the rest of the conference will rise to conscious awareness, and you will be happy.</li><li>Because everyone knows that Swapcard is buggy, you can use it as an excuse for basically any kind of antisocial behavior. For example, if you arrive 23 minutes late to a 25-minute meeting and say, \"I'm so sorry to be late, my Swapcard was acting weird and...\", the other person will cut you off and say \"I know!! The same thing has been happening to me all weekend!\" I haven't confirmed this, but I think there's an 80% chance that you could get away with eating non-vegan food with no social cost if you blamed the meat on Swapcard.</li></ol><p>So, to prepare for the conference, I scrolled through the entire attendee list on Thursday, sent 1:1 requests to heaps of people, and signed up for all the sessions that seemed cool (there were many such). Easy.</p><h1><strong>II. Friday</strong></h1><p>I applied for EAG many moons ago, as I was anticipating starting a new job on GiveWell's operations team. I was very stressed about joining a competent team as a total newbie to operations, and I happened upon a forum post that said something like \"Volunteering at EAG can give you great insight into solid ops work.\" Insight sounded pretty good; I wanted insight. So I signed up to volunteer, and my first task was to arrive at the venue at 10am Friday for two hours of training. Training was run so efficiently that we were done in 62.5% of the allotted time.</p><p>Based on the info I read on the Forum and in CEA's materials, I was expecting to work brutal 8-hour shifts under the direction of a mystic operations wizard who would push me to my limits and unlock capabilities of which I hitherto lacked the imagination to even dream. Instead, I was placed on the speaker liaison team, where I was tasked with walking speakers to their sessions, making sure their needs were met, and taking them to office hours afterward. My team leads were very nice people\u2014they were super communicative and easy to work with on shifts, which were never more than 1.5 hours. In exchange for my volunteer efforts, I received a special blue shirt and had unlimited access to the volunteer room, which was a real gem: It was like a combined quiet working room/private luggage storage/charging station that included beanbag chairs, free food for every lunch and dinner, and toothbrushes (wow). My volunteer badge also allowed me to enter the venue as early as I wanted every day, which was quite useful.</p><p>EAG staff mentioned that they were short on volunteers. This is evidence that volunteering at EAG is underrated, because I think many more people would volunteer if they knew what it was really like. It's possible that people decline to volunteer because they think (as I did) that volunteering will consume most of their time and mental space. I think in most cases that's unlikely to happen. The breakdown in time usage on my speaker liaison shifts was something like:</p><ul><li>15% focused mental effort</li><li>40% being a warm body who is vaguely available for questions</li><li>45% doing nothing, waiting around</li></ul><p>I think most volunteers (on teams like cloakroom, room management, registration, etc.) had similar amounts of free time on their shifts, though of course some were busier. You can do a lot with that \"doing nothing\" time,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsbwqfm5h9l\"><sup><a href=\"#fnsbwqfm5h9l\">[6]</a></sup></span>&nbsp;and it's actually quite nice to have some chill downtime built into your schedule (otherwise you might push yourself too hard). I guess my point is that if the warm glow of knowing that you helped run a great EAG isn't very tempting, volunteering might still be net-positive from a purely selfish perspective! However, that warm glow is <i>really nice</i>. People said many kind and appreciative things to me, and I felt a sense of ownership over the smooth running of the event. You should volunteer if you go. :)</p><p>Ok, back to the conference! I made the mistake of scheduling 1:1s between the end of volunteer training (12pm) and the beginning of registration (5pm) on Friday. Pro tip: Don't do that. Apparently lots of people don't update their real 1:1 availability until Friday evening <s>because they aren't anxious obsessive planners who review the entire attendee list on Thursday</s>. These people will unintentionally stand you up and then abjectly apologize several hours later, which is bad vibes, not what you want. If you want to have 1:1s on Friday afternoon, message people to get confirmation before sending a booking request.</p><p>At 5pm, registration opens. Everyone gets a few items:</p><ul><li><strong>Venue map.</strong>&nbsp;This was pocket-sized and very nicely designed.</li><li><strong>Shirt.</strong>&nbsp;Cute design in orange and black, presumably because of EAG Boston's proximity to Halloween. I saw a person walking around with an EAGxBerlin shirt that also looked cool, so I'm fairly confident that solid graphic design is a normal thing for EAG apparel.</li><li><strong>Badge.</strong>&nbsp;Unfortunately there were only two badge color options, one for volunteers and one for everyone else. Ideally, there would be four colors: (1) volunteers, (2) people interested in transitioning to technical AI safety research, (3) people who can give advice about transitioning to technical AI safety research, (4) literally everyone else. I think this system would improve the efficiency of casual social interactions by at least sevenfold.</li></ul><p>The career fair happened on Friday for most of the evening and I attended for recruiting purposes. The organizers unfortunately decided to teach me a hard lesson about the average EAG attendee's cause prioritization by placing my booth across from the AI organizations.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref97eq8gjent\"><sup><a href=\"#fn97eq8gjent\">[7]</a></sup></span>&nbsp;Otherwise, the career fair was great! Attendees seemed to really enjoy the event \u2014&nbsp;I saw many lengthy conversations happening and had some good chats myself.</p><p>After the career fair, I went to a rooftop gathering that consisted mostly of folks affiliated with Charity Entrepreneurship. I already had a high opinion of CE, and after meeting several more incubatees and a few research program graduates, my estimation increased! If this sounds like a plug for Charity Entrepreneurship, that's the correct interpretation \u2014 I'm really glad the org exists and I deeply admire its work.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhsgcrgln6ff\"><sup><a href=\"#fnhsgcrgln6ff\">[8]</a></sup></span></p><h1><strong>III. Saturday/Sunday</strong></h1><p>Tons of good stuff happens on Saturday and Sunday, I'm talking sessions, 1:1s, snacks, casual hangouts, naps, community office hours, workshops, and more.</p><p>I can't actually speak much about the sessions or workshops, because I only attended those required by my volunteer shifts. Instead, I packed my days with back-to-back 1:1s! I had 1:1s upstairs, downstairs, outside, walking, sitting, in the mall, at a bagel shop, everywhere. There are many flavors of 1:1s and most of them are great! Here are a few common types of 1:1:</p><ul><li><strong>Talking about specific problems:</strong>&nbsp;Oh my gosh, SO useful. I'm working on a few big projects at work right now, and I discovered that there were people at EAG with direct experience on every one of them. I learned so much!!</li><li><strong>Forming relationships with people who do broadly similar work:</strong>&nbsp;For example, I met up with a lot of people who do operations and recruiting work. It's really nice to feel understood, talk about common issues/questions/cool ideas, and generally vibe out with people who are in similar positions and who think about closely related problems.</li><li><strong>Helping other people:</strong>&nbsp;If you have content in the \"What I can help people with\" section of your Swapcard profile, you'll almost certainly receive meeting requests to talk about that thing! For example, a few people asked me to talk about working at GiveWell and making career transitions. Note: If you work in a popular cause area or at a well-known EA org, you'll likely receive many meeting requests for advice even if you haven't explicitly said you're ok with that. It can be kind of awkward to get many such requests (in part because you just won't have the time for all of them and will need to deny a few) but try to remember that these meetings are a great way to pass on your knowledge to newer/younger members of the EA community! If you feel overburdened by a large amount of similar meeting requests, you can just create your own unofficial office hours by suggesting that everyone meet you at a particular time/place.</li></ul><p>It is possible for 1:1s to be low quality if one or both participants don't have a clear idea of their goals for the meeting, but this failure mode is easy to avoid with <a href=\"https://forum.effectivealtruism.org/posts/pKbTjdopzSEApSQfc/doing-1-on-1s-better-eag-tips-part-ii\"><u>careful planning</u></a>. I also found to my surprise that some well-known figures within EA were actually quite accessible \u2014&nbsp;in a few cases I made 1:1 requests that I thought would be swiftly rejected, but they (mostly) weren't, and I was able to have some great conversations with people whose work I've followed for years. That was really nice.</p><p>Food (vegan) was provided for several meals. The lasagna and chocolate mousse were the tastiest food items. They were so good that I didn't notice the \"please don't be greedy and rude\" sign until I had my second plate in hand. Whoops!</p><p>The EAG team does a really great job of organizing off-site group dinners. I ultimately didn't have the energy to attend a 30-person meal, but I passed by one of the dinner groups on my walk back to my Airbnb, and they were laughing and smiling and having a great time. :) In addition to the organized dinners, someone (idk who, but shoutout to you) made a giant Google Doc that listed many unofficial dinners and gatherings. For example, one of my friends went to an unofficial <a href=\"https://forum.effectivealtruism.org/events/mTcBwqnbtyqEbevZR/law-and-ai-dinner-eag-boston-2023\"><u>Law &amp; AI dinner</u></a>&nbsp;on Saturday night. I texted him to ask how the dinner was, and he said:</p><blockquote><p>It's all ai &amp; law people and the people that are law are ai law</p></blockquote><p>...which I guess is just a clearcut example of truth in advertising? The dinner was apparently great fun, so congrats to the <a href=\"https://forum.effectivealtruism.org/users/legal-priorities-project\"><u>Legal Priorities Project</u></a>&nbsp;for hosting a really nice event. There really isn't a dull moment at EAG; you can always find something to do!</p><h1><strong>IV. Afterparties and Airports</strong></h1><p>Qualy <a href=\"https://x.com/QualyThe/status/1718334271377568047?s%3D20\"><u>suggested on Twitter</u></a>&nbsp;that access to the EAG nap room more than covers the ticket price, so the rest of the conference is just a free perk. I think that's <a href=\"https://www.cbsnews.com/baltimore/news/what-is-girl-math-tiktok-budgeting/\"><u>correct</u></a>, but since not everyone can use the nap room, a stronger argument is that the EAG ticket price is really just a reasonable cover charge for the afterparties, and the conference is thrown in for free.</p><p>EAG might actually have more afterparties than sessions. You're probably familiar with <a href=\"https://en.wikipedia.org/wiki/Christmas_creep\"><u>Christmas Creep</u></a>, but you might not have known that EAG Afterparty Creep also exists.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoztp7ld6een\"><sup><a href=\"#fnoztp7ld6een\">[9]</a></sup></span>&nbsp;I personally spoke to one person who arrived at the venue late Friday evening, completed their registration, and immediately left for an afterparty. In fact, I heard that EAs in the Bay Area started having afterparties as soon as EAG was <a href=\"https://forum.effectivealtruism.org/posts/o5sc28749MkRPwtnk/announcing-ea-global-plans-for-2024\"><i><u>announced</u></i></a>&nbsp;last week because their timelines are too short to wait. But these early afterparties are just pre-gaming for the really juicy, fresh afterparties that happen on the final day of EAG after the venue closes. Boston's Sunday night afterparties had themes including animal welfare, Halloween, general party, and kidney donation (I'm not sure if the last one counts, but it happened in the same time slot and seemed to be competitive w/ other events). I have no doubt that there was also a party for people interested in transitioning to AI safety technical research. When I last checked on the Tuesday after EAG, afterparties were still happening (not joking).</p><p>Unfortunately, my past self had already decided that being home before work on Monday was an important priority (stupid!), so I had to go to the airport instead of having shouted conversations about mechanistic interpretability for a few hours in a dimly lit college house on Harvard Square.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbw9o4to0m6v\"><sup><a href=\"#fnbw9o4to0m6v\">[10]</a></sup></span>&nbsp;I ate a quick dinner with a friend, which was actually really nice. We spent most of the dinner talking about how we felt Wiped, Tired, and Totally Unable To Do Even One More Thing. It's obvious in retrospect that we were both in our feels about not attending afterparties.</p><p>At my airport gate I overheard two guys arguing about the moral propriety of profiting from AI development and assumed they were from EAG. I was correct of course, and it turns out I knew them already from previous EA gatherings in my city. Sadly for them, they were also employed and couldn't attend Sunday night afterparties in far-flung locations. We got to chatting about our EAG highlights. One of the guys said that he had spent a while hanging out with someone who he'd met at a previous EAG, and he thinks they'll become good friends. The other dude said he had a really encouraging meeting about a side project in global health that he's thinking about pursuing. I said that I'd seen a close friend get recruited for a really cool job, and that I'd made some new friends and received help with some important projects. All of us had had a great time!!</p><h1><strong>V. EAG was great</strong></h1><p>I was really happy after EAG, and this is my best guess at why: I liked just about everyone I met, and I trusted them too. I had a really strong sense that everyone at the event cared in a substantial (and in some cases personally costly) way about making the world maximally good. My conversations were intellectually satisfying and quite fluid because people often understood me well without needing a lot of background info. Overall, I experienced a very delightful collection of feelings, and I think the best name for it is \"community.\" That is, EAG helped me feel connected to the EA community in a very personal way, and that feeling alone made the conference worthwhile. I'm grateful to the team that made EAG happen, and I think I'll be going again.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvm1ubqxuie\"><sup><a href=\"#fnvm1ubqxuie\">[11]</a></sup></span></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn76b5em0i2ri\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref76b5em0i2ri\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;My personal context: This was my first EAG. I was a volunteer. I'm a recruiter for a well-known EA org. I think I'm significantly more extroverted than the average EA. I don't have a technical background, so it's difficult for me to fully engage with some research-heavy EA content.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4unwbpmkj6t\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4unwbpmkj6t\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Including <a href=\"https://forum.effectivealtruism.org/posts/TanBoThzLsDB8bvYg/numerical-breakdown-of-47-1-on-1s-as-an-eag-first-timer\"><u>another post about EAG Boston</u></a>, already!! Never tell yourself that you'll quickly write a post about something on the EA Forum; someone will always post before you; theirs will be higher impact; you will be sad. On the other hand, the author of the other EAG Boston post completed 47 1:1s at EAG, which means I shouldn't be sad because he's in the top percentile of human-achievable productivity. Can't compare yourself to giants...</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8jl4n6hjhjb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8jl4n6hjhjb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;As a descriptor of opinion ownership, not like I'm angry with anyone.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9fqwow3k9y\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9fqwow3k9y\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Although, scarily for me, it apparently does represent GiveWell's heavy influence on its staff members' footnote usage. Anyway, if you're hungry for GiveWell opinion, it's just <a href=\"https://forum.effectivealtruism.org/users/givewell\"><u>one </u></a><a href=\"https://www.givewell.org/charities/top-charities\"><u>click </u></a><a href=\"https://www.givewell.org/how-we-work/our-criteria/cost-effectiveness/cost-effectiveness-models\"><u>away</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjzw8vpugzg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjzw8vpugzg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I'll say this once: Anything in this post that could possibly be interpreted as a joke instead of a serious claim/dig about cause prioritization is in fact a joke. AI safety has the top spot in my personal cause prioritization and I'd like to find a way to work on it more in the future. I also think animal welfare is important and I'll probably make jokes about that too.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsbwqfm5h9l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsbwqfm5h9l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For example, I was able to schedule 1:1s, chat with other attendees, deal with stressful, brain-overloading notifications, read a few chapters of a book, complete a final exam for an edX class, listen to a few of my speakers' talks (Special shout out to the Rethink Priorities session on the <a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj\"><u>CURVE Sequence</u></a>, which I found quite enjoyable!), and just plain relax. At one point I even had a whispered 1:1 during a talk in the back of the room.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn97eq8gjent\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref97eq8gjent\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I had a nightmare after the career fair in which a large group of attendees wearing \"Just don't build AGI\" shirts stopped at my booth, looked straight into my eyes, and said in calm and pleasant voices, \"0% of our personal giving will be going to GiveWell's top-rated charities. Don't try to recruit us either; we will be seeking jobs in higher-impact cause areas than global health and development.\"</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhsgcrgln6ff\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhsgcrgln6ff\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;You can <a href=\"https://www.charityentrepreneurship.com/donate\"><u>fund</u></a>&nbsp;a high-impact founder for $4k, think about it!</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnoztp7ld6een\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefoztp7ld6een\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Note: I'm not referring to the personal archetype of the same name.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbw9o4to0m6v\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbw9o4to0m6v\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I kid. In reality, my one conversation about mechanistic interpretability at EAG lasted for &lt;5 minutes. My interlocutor suddenly stopped talking and refused to say anything more about his work because he didn't know if he could trust me with dual-use research. Although I now know absolutely nothing about mechanistic interpretability, I gotta hand it to that guy's rock-solid infosec.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvm1ubqxuie\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvm1ubqxuie\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;In fact I'm going to <a href=\"https://forum.effectivealtruism.org/posts/6iybYzX4rap3NX7nm/eagxvirtual-speaker-announcements-timings-and-other-updates\"><u>EAGxVirtual</u></a>&nbsp;in just a few weeks; you should too! If you have any questions about the event, you can ask them <a href=\"https://forum.effectivealtruism.org/posts/RJgGP6tEeuvtbapjP/curious-about-eagxvirtual-ask-the-team-anything\"><u>here</u></a>.</p></div></li></ol>", "user": {"username": "Calum"}}, {"_id": "ga2wFZ3ZGRv6EfL7L", "title": "I went on a (very) long walk, and it was a great career decision", "postedAt": "2023-11-07T03:57:08.655Z", "htmlBody": "<p>This year, I walked from Mexico to Canada. I walked over 4,265 kilometres \u2013 through snow, blizzards, heatwaves, mosquito swarms, wildfire smoke, and extreme exhaustion. It was the hardest thing I\u2019ve ever done, and it was the best thing I\u2019ve ever done. And I almost didn\u2019t do it. Why?&nbsp;</p><p>Not because I doubted I could do it (though I did).&nbsp;</p><p>Not because I was worried about river crossings and hypothermia and falling trees (though I was).</p><p>Not because I thought it would break me into pieces (though, believe me, it did).&nbsp;</p><p>I was hesitant to embark on this epic journey, because I was concerned about what it would do to my career. How it might stall my professional journey. How it might even make it regress.</p><p>I could not have been more wrong.</p><p>This post is about why taking a break from your career, to do something that&nbsp;<strong>doesn\u2019t seem at all related to your career,&nbsp;</strong>could be great for it.</p><h1>The current rhetoric, and what\u2019s wrong with it</h1><p>Implicit in all the career advice I\u2019ve consumed is the rhetoric that in order to grow your career, you have to focus on it. \u2018Focusing on it\u2019 involves doing things that directly advance your skills, knowledge, networks, or understanding of what you\u2019re a good fit for. According to this advice, your energy should be committed to 'making it happen', and to doing things that are very obviously career-relevant.</p><p>Want to gain experience? Apply for internships.&nbsp;</p><p>Want to grow your skills? Commit to self-study.&nbsp;</p><p>Want to find a job that\u2019s a good fit for you? Spend a year exploring different roles.</p><p>Want to take a break from your job? Wonderful, use that time to consider what you want out of the next one.</p><p>This advice is pervasive, and it\u2019s convincing<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3mcwne8jm3k\"><sup><a href=\"#fn3mcwne8jm3k\">[1]</a></sup></span>. It can make people feel anxious that they need to always be \u2018career-ing\u2019, and guilty if they\u2019re not. It sends the message that the only way to improve your career trajectory is by very explicitly focusing on it and prioritising it.</p><p>This rhetoric can become deeply ingrained, especially in young people, and this was the case for me. When I first considered doing the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Pacific_Crest_Trail\"><u>Pacific Crest Trail</u></a>, I went through quite the internal battle. Was it worth taking six months off work to go for a walk? Would my career stagnate or regress? Was it selfish to prioritise travel over impact, and should I just try to overcome that desire? What damage would this do to the position I\u2019d worked &nbsp;hard to get to?&nbsp;</p><p>Then, when I decided to actually do the hike, the battle continued. I tried to negotiate with myself, reasoning that if I weaved in some career-focused element then maybe I could justify it. Maybe this would be a good opportunity to think more about my career. Maybe I could use the time to consume relevant podcasts. Maybe I could firm up my stance on issues I care about. In the end, however, I told myself that I didn\u2019t want to take six months off work, to then spend the six months thinking about work.&nbsp;</p><p>So I didn\u2019t. I didn\u2019t journal about what I wanted out of my career. I didn\u2019t listen to any podcasts with the intent of professional development. I hardly even thought about what I was going to do when I got home. I spent maybe a total of six hours thinking about work, and that was just when I sporadically felt like it. I\u2019d come to accept that for six months, I would stop focusing on my career. And that meant, according to what I\u2019d been taught, that I\u2019d be temporarily abandoning it.&nbsp;</p><p>However, that\u2019s not quite what happened.&nbsp;</p><h1>The career-related benefits of a non career-related break</h1><p>Although I\u2019d stopped intentionally working on my career, I would now classify what I did as a career-building activity. I\u2019d go so far as to say that walking the length of the United States was better for my career than the counterfactual career-focused work I would have done at home (the work that the current rhetoric emphasises).</p><p>I\u2019ll tell you a couple of reasons why. Keep in mind that although I emphasise the experiences I had on my somewhat niche trip, I think they could apply to many other non career-related breaks.</p><h2>I built confidence and gained perspective.</h2><p>Putting one foot in front of the other, literally, can get surprisingly hard. I went through some of the lowest moments of my life on that trail. There were periods where I felt alone and scared and freezing and delirious and deeply, deeply exhausted. There were so many moments, moments where I longed to be somewhere else, that felt like they would never pass. But they did. And so the mantra began to play in my head, \u2018This will pass\u2019.</p><p>There were also many times where I could not, for the life of me, imagine how my situation was going to work out well. I\u2019d walk through a storm and turn up at a trailhead with no way to get to town, nowhere to stay, and occasionally no idea of which town I was even going to. I had gear break and weather change and injuries spring up. But it always worked out fine, even if it wasn\u2019t how I originally pictured it. And thus, the mantra became, \u2018This will pass, and it will work out\u2019.</p><p>These learnings are extremely relevant to any career. When you get through any hard thing, you always carry with you the knowledge that you got through it. That can propel you to do other hard (and potentially work-related) things. In my case, the phrase that keeps coming to mind is, \u2018I\u2019ve gotten through a blizzard, I can run a goddamn workshop\u2019.</p><p>I\u2019ve brought that mantra and confidence back with me back to my professional life. During hard projects, with difficult clients, or in times of transition, the deep belief that \u2018This will pass, and it will work out\u2019 will always be there.</p><h2>Many of the skills I gained are transferable.&nbsp;</h2><p>No doubt, I gained many skills that are absolutely useless in the workplace. I can now tell the difference between about five types of snow just at a glance. I can plan my rock-hopping strategy across a stream without slowing my stride. I can assess the likelihood of a tree falling on me in the night, if winds get high enough.</p><p>Yet, many skills I gained are transferable to the workplace. Here are a few examples:</p><ul><li><strong>Making decisions under pressure:</strong> what you decide to do when caught in a snow blizzard at 13,000 feet is kind of consequential.</li><li><strong>Resilience:</strong> when you fall over 23 times in a day, you can choose to either laugh or cry about it (or both).</li><li><strong>Organisation:</strong> planning out every single thing you're going to eat for five weeks requires attention to detail.</li><li><strong>Building new connections:</strong> when you rely heavily on the generosity of strangers to give you hitches or let you sleep on their lawn, you get pretty good at networking.</li><li><strong>Attention to detail:</strong> 20-feet of snow will, surprisingly, cover up the trail you once followed. Instead, you learn that certain colours and patterns in the snow indicate footprints. (You also become very good at being lost.)</li><li><strong>Remaining calm in high-stress situations:</strong> as you watch your backpack (containing everything you own) plummet 200 metres down a steep, snowy mountainside, you need to remain calm and figure out how on earth you're going to find / retrieve it.</li><li><strong>Persistence:</strong> you learn that you can always dig a little deeper, including when you've been walking for 15 hours in 40-degree heat through intense wildfire smoke and on 4 hours of sleep.</li></ul><p>I built up these skills in situations that are more high-stakes, more intense, and more painful than any I would experience in my work life. As a result, I honestly think that the capabilities and beliefs I developed on trail would have taken years to learn in the workplace (if at all). And recall again, that what I was doing&nbsp;<i>was not career focused</i>.</p><p>My examples are pretty extreme, but I\u2019d guess that many non career-related breaks require as much or more dedication, persistence, organisation, and resilience than a typical job.&nbsp;</p><h2>I had space for reflection.</h2><p>When a typical day involves 12 hours of walking, you have a bit of time on your hands. Admittedly, most of this time is taken up with thinking about what you\u2019re going to eat when you get to town, worrying about some new injury that\u2019s popped up, or dreaming about the shower you\u2019ll have next (sadly, in five days\u2019 time).&nbsp;</p><p>Yet, there is some fraction, however small, of \u2018productive\u2019 thought. I reflected on how I dislike the norm of working five days a week. That work-life balance is extremely important to me. That, somewhat strangely, having to dress up in corporate attire for work is a red flag for me. And that I\u2019ve worked hard and am good at (at least some of) the things I do, and that deserves some respect (at the very least, from myself).</p><p>I wasn\u2019t trying to think about these things, but I ended up thinking about them occasionally. And when I did, the reflections felt deep, and they felt important. Taking off the pressure to progress, and think about, my career, counterintuitively opened up space for me to do just that.</p><h2>And I\u2019m preventing regret.</h2><p>My life philosophy centres around wanting to prevent regret. I base many decisions, including how I spend my time, how I treat people, and what work I accept, on whether I think I\u2019ll regret it in five, twenty, or fifty years\u2019 time.&nbsp;</p><p>When deciding whether to do the trail, I considered what I\u2019d be more likely to regret. Surprise surprise, I thought it was more likely that I\u2019d regret not doing it. Post trail, I still agree with that assessment.</p><p>How is this relevant to my career? Well, I doubt my career is going to be super impactful in twenty years\u2019 time if I\u2019m plagued by regrets and the \u2018could have been\u2019s. For me, preventing regret is integral to my life satisfaction. And, I don\u2019t think I would be truly satisfied with my career, if I\u2019m not satisfied with my life more broadly. Again, this is a career-related benefit that I think can only be achieved through non career-related activities.&nbsp;</p><h1>Are you considering a break?</h1><p>There you have it folks - I took six months off my career, and it was a great move -&nbsp;<strong>even for my career</strong>. It reiterated to me that doing things that aren\u2019t explicitly related to your career, can still be really great for it. In some situations, not focusing on your career&nbsp;<i>can bring more benefits</i> than focusing on it. I don\u2019t think the current messaging about career growth acknowledges this. Not only can that dissuade people from taking (unintentionally) productive breaks, it can also cause a lot of anxiety and guilt about doing anything that\u2019s not career focused.</p><p>To be very honest, there may be future employers who see taking six months off to go for a walk (or have some other non career-related break) as a strike on the resume. But, I know that it was time well spent and I predict that my career will be more impactful as a result. If they aren\u2019t open to hearing me explain why, I\u2019m not sure I want to work with those people.</p><p>Obviously, what you do on a non career-related break can vary wildly. I\u2019d hazard a guess that the impact of a month-long silent meditation retreat will be different from a drunk, hostel-hopping trip across Europe. And that\u2019s not even to say the latter won\u2019t be valuable \u2013 it depends on what you value, what you want out of it (and your career), and how you want to grow.</p><p>Regardless of what you do, I want to reiterate that&nbsp;<strong>non career-related breaks can be justified</strong>, and they can be productive (even if you\u2019re not intentionally trying to be productive).&nbsp;</p><p>And if you\u2019re just looking for someone to convince you to walk across a country, hit me up.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ga2wFZ3ZGRv6EfL7L/j214srcnrbgbtgrpkzem\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ga2wFZ3ZGRv6EfL7L/nslfazdu2yf6k6cq19hx 80w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ga2wFZ3ZGRv6EfL7L/znqdcmvnux0w8lmaw61f 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ga2wFZ3ZGRv6EfL7L/titk2b9tlkkydar9usv6 240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ga2wFZ3ZGRv6EfL7L/qqzjlxkmosxfthvpua0c 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ga2wFZ3ZGRv6EfL7L/dbzpdudsqdfnodqyl6pc 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ga2wFZ3ZGRv6EfL7L/udg7r2dy9xj8rbp7pusx 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ga2wFZ3ZGRv6EfL7L/lxlahap43xowbi1sog0o 560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ga2wFZ3ZGRv6EfL7L/g11teyklxe8rh11np9nl 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ga2wFZ3ZGRv6EfL7L/sjrtlrtbx3ubmxmk6mrj 720w\"></figure><h1>Acknowledgements</h1><p>Thank you to Alexander Saeri for your valuable feedback on this post.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3mcwne8jm3k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3mcwne8jm3k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Don\u2019t get me wrong \u2013 I understand the rhetoric, and I do agree with it to some extent. Gaining experience, building your skill set, and trying new things are fantastic ways to progress your career. It\u2019s just not the only way.</p></div></li></ol>", "user": {"username": "Emily Grundy"}}, {"_id": "7MsNkhhS7tWsdF5zk", "title": "Metaculus Presents: Does Generative AI Infringe Copyright?", "postedAt": "2023-11-06T23:41:17.202Z", "htmlBody": "<figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7MsNkhhS7tWsdF5zk/b1ziny96o979jptjr2my\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7MsNkhhS7tWsdF5zk/tengil2dwrfzlru9fdvs 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7MsNkhhS7tWsdF5zk/qlfdo7pwjnvpnyzpfcta 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7MsNkhhS7tWsdF5zk/ph1tu6ezxpe6hyxlpud1 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7MsNkhhS7tWsdF5zk/ltkeac3qr0kqutxg4iku 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7MsNkhhS7tWsdF5zk/l9qdxqvehonimpt50ltl 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7MsNkhhS7tWsdF5zk/ykco1dwhzzjlaiizgb1c 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7MsNkhhS7tWsdF5zk/r5q2xg4xwofawtyvrezn 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7MsNkhhS7tWsdF5zk/ckhronwsvsjqjsz8m7ly 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7MsNkhhS7tWsdF5zk/bp7qsb5pza4h2dp3rapj 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7MsNkhhS7tWsdF5zk/rrc2dxwiwrjfyokwxdzs 940w\"></figure><p><span>You're invited to Metaculus Presents, Friday, November 10th, 11am-2pm PT when Cornell Law School\u2019s </span><a href=\"https://www.lawschool.cornell.edu/faculty-research/faculty-directory/james-grimmelman/\"><span>James Grimmelmann</span></a><span> will share from his paper </span><a href=\"https://james.grimmelmann.net/files/articles/talkin-bout-ai-generation.pdf\">\u2018Talkin' 'Bout AI Generation: Copyright and the Generative-AI Supply Chain'</a><span>. Join us as he introduces the concept of the \"Generative-AI Supply Chain\" and explores AI's enormous implications for the legal landscape.</span></p><p><span>Register for free tickets for this online event </span><a href=\"https://www.eventbrite.com/e/metaculus-presents-does-generative-ai-infringe-copyright-tickets-732326647717?aff=oddtdtcreator\"><span>here</span></a><span>!</span></p>", "user": {"username": "christianM"}}, {"_id": "5FepP8NiyJjRpnAvC", "title": "Giving What We Can has a new pledge option!", "postedAt": "2023-11-06T21:42:16.443Z", "htmlBody": "<p>Today, we are launching the option to factor wealth into your pledge with Giving What We Can.</p><p>Until now, Giving What We Can has focused on income as the main way of contributing through a pledge. However, we recognise that some people's personal financial resources don't exist as income \u2014 they exist as wealth. Adding an optional wealth component to the Giving What We Can Pledge allows those who have significant wealth to give in a way that better reflects their resources, aligning with our overall mission of helping people from all walks of life meaningfully commit to using a portion of their financial resources to help others.&nbsp;</p><p>This optional wealth component of the Giving What We Can Pledge involves choosing to give the greater of 10% of income or a custom percentage of wealth each year. As such, those choosing to add the optional wealth component to their Giving What We Can Pledge will still be donating an amount that is at least equivalent to 10% of income, if not more. <a href=\"https://www.givingwhatwecan.org/faq/what-is-wealth-and-how-can-i-include-it-in-my-pledge\"><u>Read an example of how this works</u></a>.</p><p>We think this option will be most suitable for those who are in the top few percent of wealth holders globally, and we continue to recommend the Giving What We Can Pledge for most people earning a median salary in high-income countries. To get personalised guidance on the type of pledge you might consider based on how your income and wealth compares to the rest of the world, check out our pledge recommendation tool.</p><p>We've also taken this opportunity to redesign our&nbsp;<a href=\"https://www.givingwhatwecan.org/en-US/pledge/flow\"><u>pledge sign up</u></a>, and we're very excited about the brand new look and feel as well as some improved functionality (such as letting people share their motivation publicly)!</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/5FepP8NiyJjRpnAvC/hdkkphoomhpgdfehr7yg\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/5FepP8NiyJjRpnAvC/f7q4v6859vsney8jzv7f 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/5FepP8NiyJjRpnAvC/bobrkfcfi0aomor79aaq 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/5FepP8NiyJjRpnAvC/zzlzxvyt4dyltvpcl1nv 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/5FepP8NiyJjRpnAvC/g3bpjzheizpg2tzpzjvr 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/5FepP8NiyJjRpnAvC/sce8rkqlvi4wvaogmqqp 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/5FepP8NiyJjRpnAvC/juakegtp8b7qhsheyhtd 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/5FepP8NiyJjRpnAvC/ffluhgsdxkfaxjnmjnd7 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/5FepP8NiyJjRpnAvC/srhvnrcxnrjw2goci57l 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/5FepP8NiyJjRpnAvC/rxj7tmrqdefa5hkf5lda 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/5FepP8NiyJjRpnAvC/dadfpgdekgrjnr1bd8xl 1546w\"></figure><p><strong>More about our giving pledges</strong></p><p>While we are best known for&nbsp;<a href=\"https://www.givingwhatwecan.org/pledge\"><u>The Giving What We Can Pledge</u></a>, which is a public commitment to donate at least 10% of your income (or a custom percentage of wealth!) to the most effective charities in the world, we also have three other giving pledges:</p><ul><li><a href=\"https://www.givingwhatwecan.org/get-involved/trial-pledge\"><u>The Trial Pledge:</u></a> Donate at least 1% of income for any period you choose (with the option to also factor in your wealth when calculating your pledge amount)</li><li><a href=\"https://www.givingwhatwecan.org/get-involved/further-pledge\"><u>The Further Pledge</u></a>: Donate all income above a specified living allowance</li><li><a href=\"https://www.givingwhatwecan.org/en-US/get-involved/company-pledge\"><u>The Company Pledge</u></a>: Donate at least 10% of profits</li></ul><p><strong>Want to include wealth as part of your pledge?</strong></p><p>If you have an existing Giving What We Can Pledge or Trial Pledge, you can fill out our&nbsp;<a href=\"https://forms.gle/eiFNgizcv7AXLGZP9\"><u>Pledge Variation Form</u></a> to request us to update your pledge in our systems.</p><p><strong>Why pledge at all if you are already giving regularly?&nbsp;</strong></p><p>We\u2019ve written at length about this on&nbsp;<a href=\"https://www.givingwhatwecan.org/en-US/pledge/why-pledge?slug=pledge&amp;slug=why-pledge\"><u>our website</u></a>, but today, I\u2019ll just cover one important point:</p><p><strong>Taking a public giving pledge helps inspire others.</strong></p><p>On a personal note, before I took a pledge, I scrolled through the list of others that had already done so, looking for reassurance in the thousands of names that appeared. Seeing the many people who had committed gave me a clear message:&nbsp;<i>I could in fact donate 10% and live a good and fulfilling life.&nbsp;</i></p><p>Adding your name to the list, whether it\u2019s a trial pledge or a lifetime commitment, helps generate a sense of momentum, achievability, and a sense of \u201cwow, there\u2019s other people out here doing this too!\u201d We think this is really important in creating a culture where giving significantly and effectively is a social norm.</p><p>We're hoping to hit 10,000 lifetime pledgers before the end of 2024. If you're already giving consistently, please consider taking a pledge!</p><p>[<a href=\"https://www.givingwhatwecan.org/en-US/pledge/flow\"><u>Take a pledge</u></a>]</p><p>A deep thank you from our whole team for giving what you can to create a better future.&nbsp;</p><p>With gratitude,</p><p>Grace and the Giving What We Can team</p><p>P.S. The idea for a wealth component was first considered in 2017, and we're grateful for all those who have contributed to it in the years since.</p>", "user": {"username": "GraceAdams"}}, {"_id": "YMeXaCRbd6t88MT4z", "title": "My experience starting a 501c3", "postedAt": "2023-11-06T20:33:03.443Z", "htmlBody": "<p>A while back, I posted <a href=\"https://forum.effectivealtruism.org/posts/X3HQs9BbFxuTgKzNg/time-estimate-for-starting-a-non-profit\">this</a> when I started my non-profit, <a href=\"https://highimpactalliance.com/\">High Impact Alliance</a>.</p><p>Today, I just finished the paperwork for the IRS form 1023 to gain charity status, so I wanted to share my reflections:</p><ul><li>It was definitely more intimidating than I expected</li><li>There are some great resource guides (form1023.org and Chat GPT were the best)</li><li>The hardest part was the new terminology (which NTEE code do I choose?)</li><li>It was pretty rigorous and thorough.</li><li>With all the time it took to get my board's address information, create bylaws and a conflict of interest policy, and describe the activities in depth but under 5,000 characters, I estimate my time investment at about 10 hours.</li><li>Total cost was $600 + $5 to Rocket Lawyer for a trial period to generate the bylaws and conflict of interest policy (seriously, that was an excellent $5 spent)</li></ul><p>To recap the first phase (incorporating), it took less than an hour and $220. So my time totals are 10-12 hours + $825 to start a non-profit.</p><p>Feel free to reach out if you have any questions about starting yours - I'm happy to help!</p>", "user": {"username": "Deena Englander"}}, {"_id": "nFCpYzJf7gi8DPYub", "title": "[Event] Shrimp Farming: Vast in Scale, Diverse in Welfare Challenges (Rethink Priorities Webinar)", "postedAt": "2023-11-06T17:52:00.234Z", "htmlBody": "<p>Human consumption of shrimp has increased rapidly in recent decades. Yet, there are few requirements or guidelines for how farmers and fishers should treat shrimp used for food. Rethink Priorities is completing a series of reports, the&nbsp;<i>Shrimp Welfare Sequence</i>, to orient readers to a nascent field dedicated to incorporating welfare considerations into shrimp production.&nbsp;</p><p>Our&nbsp;<strong>upcoming webinar,&nbsp;</strong><i><strong>Shrimp Farming: Vast in Scale, Diverse in Welfare Challenges</strong></i>, provides a formal preview of the initial outputs of this work. We invite you to join Hannah McKay, Associate Researcher at Rethink Priorities, for a short presentation, followed by a Q&amp;A to a panel of RP\u2019s shrimp welfare researchers. The webinar will take place on&nbsp;<strong>Monday, November 20&nbsp;</strong>from&nbsp;<strong>11:00 am to 11:45 am EST (5:00 - 5:45 pm CET).</strong></p><p>Please&nbsp;<a href=\"https://us02web.zoom.us/meeting/register/tZAtde2tpzgqH9xlTM7M3BPsGhzxsSEe5Oxm#/registration\"><strong>register here</strong></a>. You can also let us know via the form if you can\u2019t attend but would like to be sent a recording. The rest of this post provides a preview of what the webinar will cover.&nbsp;</p><h1>Why Shrimp?</h1><p>Is protecting the welfare of shrimp a worthwhile goal? Few studies have tested whether shrimp are sentient \u2013 i.e., capable of having positive or negative experiences \u2013 and some commentators are skeptical about existing confirmatory evidence (<a href=\"https://www.wellbeingintlstudiesrepository.org/animsent/vol7/iss32/1/\"><u>Crump et al., 2022</u></a>;&nbsp;<a href=\"https://doi.org/10.1080/23308249.2023.2257802\"><u>Diggles, 2023</u></a>). Given indefinite uncertainty about shrimp sentience, the&nbsp;<i>Animal Sentience Precautionary Principle</i> provides criteria for how to proceed:</p><blockquote><p>Where there are threats of&nbsp;<i>serious</i>,&nbsp;<i>negative</i> animal welfare outcomes, lack of full scientific certainty as to the sentience of the animals in question shall not be used as a reason for postponing cost-effective measures to prevent those outcomes. (<a href=\"https://www.wellbeingintlstudiesrepository.org/cgi/viewcontent.cgi?article=1200&amp;context=animsent\"><u>Birch, 2017</u></a>, p. 3; emphasis is ours).</p></blockquote><p>Accordingly, our goal is to assess whether shrimp used for food face serious and negative welfare threats. Upon determining that the animal sentience precautionary principle is indeed applicable, we also want to identify cost-effective measures to mitigate negative outcomes in shrimp production.&nbsp;</p><h1>The Scale of Potential Harm</h1><p>The number of individuals affected by shrimp production is a key metric for the seriousness of potential welfare problems (ibid, p. 4). Hence,&nbsp;<a href=\"https://rethinkpriorities.org/publications/shrimp-the-animals-most-commonly-used-and-killed-for-food-production\"><u>we begin by estimating how many shrimp are used for food each year</u></a>. By converting data on the biomass of animals slaughtered each year to numbers of individuals, we find that&nbsp;<i>wild-caught shrimp represent the majority of animals directly killed for food each year</i> (~25 trillion). Meanwhile, we find that there are&nbsp;<i>more shrimp alive on farms at any time than any other type of animal&nbsp;</i>(~230 billion).&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/nFCpYzJf7gi8DPYub/gj63iaz6shxa7futtl9l\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/nFCpYzJf7gi8DPYub/xjobkv2wmy6qxahwlzb1\"></p><p>Of course, if farmers and fishers treat shrimp well, then the large scale of production would not necessarily pose a welfare issue. However, suffering might be quite common, at least on farms. In particular, pre-slaughter mortality rates across a range of sources indicate that&nbsp;<i>over half of farmed shrimp die before farmers deem them ready for slaughter</i>.&nbsp;</p><h1>Welfare Threats on Farms</h1><p>Why are shrimp so vulnerable on farms? We provide an overview of shrimp aquaculture to contextualize the answer. Although farming practices are highly heterogeneous, they vary on a continuum from \"extensive\" to \"intensive.\" Extensive farms construct ponds near a water source where wild shrimp drift in due to the tide, where they remain confined due to dikes and screens. Extensive farms stock shrimp at low densities because the ponds have a limited amount of oxygen and food.&nbsp;<i>Welfare issues on extensive farms are in large part due to a failure to control external threats</i>, such as predation and environmental pollutants from other farms.&nbsp;</p><p><i>Welfare issues on intensive farms, on the other hand, largely result from attempts to control the aquatic environment</i>. In particular, intensive farmers employ technology and proactive management practices to increase aeration and food availability, allowing them to stock shrimp at higher densities. Higher densities result in greater amounts of leftover food and excrement, which can cause toxic levels of ammonia and hydrogen sulfide. Intensive farmers try to solve these issues, but in doing so create yet more welfare problems. For example, lining the bottom of the tank with plastic prevents the buildup of sludge, but it also prevents shrimp from burrowing, a potentially rewarding behavior. Even putting its effects on water quality aside, crowding increases cannibalism, disease transmission, and limits access to resting areas.&nbsp;</p><h1>Ranking Welfare Threats</h1><p>Which of these issues is most concerning? We adapt Welfare Footprint's pain-track framework (<a href=\"https://doi.org/10.1186/s13104-021-05636-2\"><u>Alonso &amp; Schuck-Paim, 2021</u></a>) to model the scale of each threat according to its duration, severity, and prevalence. We find that the&nbsp;<i>issues which cause the most suffering in aggregate are (a) chronic and (b) affect the majority of shrimp</i>, like high stocking density and poor water quality.</p><p>If you are interested in shrimp welfare, and concerned by threats to farmed shrimp, <strong>do come along to hear more from Hannah and participate in our Q&amp;A with shrimp welfare experts. </strong>We look forward to seeing you on 20 November.</p>", "user": {"username": "Ben Stevenson"}}, {"_id": "H3dCunWkJ6J6u7AYv", "title": "Atlantic bluefin tuna are being domesticated: what are the welfare implications?", "postedAt": "2023-11-06T16:46:20.002Z", "htmlBody": "<p>Atlantic bluefin tuna (ABFT) are large, carnivorous ocean fish. They used to be caught relatively rarely, mainly by sports fishermen in North America. However, around the 1950s, Japanese consumers of sushi developed more of a taste for the fish, and a large aquaculture industry developed.</p><p>Historically, ABFT have been either caught directly from the ocean, or captured while young and fattened in \u2018ranches\u2019. However, both wild fishing and ranching pose sustainability issues, since they involve taking fish from the wild. Since 2001, there have been a number of EU-funded projects to domesticate bluefin tuna, i.e. to breed them in captivity.</p><p>This is already done with other types of fish, for example salmon and tilapia, which are raised on fish farms. But it\u2019s more difficult with ABFT:&nbsp;they generally don\u2019t spawn in captivity, as they require certain specific conditions to spawn.</p><p>However, scientists have developed methods to make ABFT spawn in captivity, through manipulating light and releasing hormones into the water to stimulate egg production in the fish. This means that it\u2019s now possible to farm these fish through \u2018closed-cycle aquaculture\u2019: that is, we can breed them in captivity so that they don\u2019t need to be fished from the wild.</p><p>This has been seen as a win for sustainability. But what about welfare? In this report, I first offer some background on ABFT. I then examine some potential welfare issues in ABFT aquaculture.</p><p>Main takeaways:</p><ul><li>Many larvae (young fish) in hatchery projects die. However, this is also true in the wild, and hatcheries may become better at preventing some of these deaths in future, in order to be commercially viable.</li><li>Many of the conditions in hatcheries might pose welfare issues for ABFT, but more research is needed.</li><li>The main method of slaughtering large ABFT seems relatively humane; however, the main method of slaughtering smaller ABFT seems more distressing. It\u2019s unclear how many ABFT are slaughtered using this crueller method.</li></ul><h1>What are Atlantic bluefin tuna?</h1><p>Atlantic bluefin tuna (<i>thunnus thynnus</i>) are native to the Atlantic Ocean and Mediterranean Sea. They are very large fish: fully mature adults are 2\u20132.5 m (6.6\u20138.2 ft) long on average and weigh around 225\u2013250 kg (496\u2013551 lb). Atlantic bluefin tuna (ABFT) have been called \u2018tigers of the sea\u2019 because of their size, grace, and the fact that they\u2019re carnivorous predators.</p><p>In their natural habitat, ABFT can navigate over thousands of miles of ocean. They can dive to depths of 1000m. They eat smaller fish and other sea creatures, generally hunting in schools.</p><p>Traditional aquaculture of ABFT involves \u2018ranching\u2019. Juveniles are caught in nets when they gather to spawn, and fed and fattened in large offshore cages. When they are matured, they\u2019re slaughtered and sold for high prices.</p><h1>Domesticating ABFT</h1><p>However, ranching is not sustainable, since it involves removing ABFT from the wild. Although the International Commission for the Conservation of Atlantic Tunas (<a href=\"https://www.iccat.int/en/\">ICCAT</a>) regulates tuna fishing by setting quotas, in 2009 their scientific advisors reported that ABFT stocks were probably less than 15% their original size.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvfxpo0a2we\"><sup><a href=\"#fnvfxpo0a2we\">[1]</a></sup></span>&nbsp;</p><p>Therefore, starting in 2001, there have been several EU-funded projects to develop \u2018closed-cycle\u2019 aquaculture for ABFT: the ability to breed them in captivity. DOTT (\u2018Domestication of Thunnus thynnus\u2019) was the first such project in 2001-2; this was followed by REPRODOTT (2003-2005), SELFDOTT (2008-2011), and TRANSDOTT (2012-2014).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsd6zwj25xqf\"><sup><a href=\"#fnsd6zwj25xqf\">[2]</a></sup></span></p><p>Since then, various entities have set up ABFT hatcheries across Europe, including both public research centres and private companies. More recently, in July 2023, researchers at the Spanish Institute of Oceanography (<a href=\"https://www.ieo.es/es/\">IEO</a>) achieved the reproduction of bluefin tuna at an inland facility, in tanks.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefc7gqgpji8u\"><sup><a href=\"#fnc7gqgpji8u\">[3]</a></sup></span></p><p>In 2017, Jonah Van Beijnen reported that many domestication projects were halting or slowing down production.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkcbi0pcp5p\"><sup><a href=\"#fnkcbi0pcp5p\">[4]</a></sup></span>&nbsp;This may be because they were failing to breed enough tuna to be commercially viable.</p><h1>Welfare in hatcheries</h1><p>Closed-cycle domestication projects involve keeping tuna in hatcheries. In these hatcheries, breeding tuna (broodstock) are kept in special tanks where the light is manipulated and hormones are released, to mimic the conditions in which ABFT breed in the wild. This causes them to produce eggs. After this, the eggs and young fish (larvae) are transferred to a series of tanks inside the hatchery until they are grown, at which point they are transferred to cages at sea.</p><h2>Mortality of young tuna</h2><p>The mortality of larvae (young tuna) in TRANSDOTT, one of the early domestication projects, was extremely high, with only&nbsp;0-0.44% surviving at 30 days after hatching. This seems shockingly high, but note that larvae mortality is extremely high in the wild as well; ABFT are an r-selected species, and only 0.1% of hatched tuna make it past their first year. It\u2019s hard to make direct comparisons here; I (Amber) wasn\u2019t able to find information about the number of young bluefin that survive at 30 days after hatching in the wild. Generally, we should also expect domestication projects to get better at keeping larvae alive over time, since they will struggle to be profitable if most of their stock die.</p><p>Currently, there are causes of larval mortality within hatcheries that don\u2019t exist in the wild. &nbsp;For example, some larvae die by crashing into tank walls. Others perish when they are moved between tanks. Still more die from sinking deaths, where they sink and crash to the tank floor. None of these risks exist in their natural environment.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnvk4ya3sj8r\"><sup><a href=\"#fnnvk4ya3sj8r\">[5]</a></sup></span></p><p>One could also argue that regardless of whether more larvae die in the wild or in hatcheries, ABFT farming is bad for fish welfare purely because it involves breeding more of a species where the vast majority of young die by default.</p><h2>Day-to-day welfare</h2><p>It\u2019s difficult to assess the day-to-day experience of tuna in hatcheries; partly because conditions within hatcheries are sometimes kept private, partly because the science of fish welfare is not comprehensive. However, there are reasons to suspect that closed-cycle aquaculture may pose issues for ABFT welfare, and it\u2019s important to monitor this.</p><p>Generally, undomesticated species experience greater stress in captivity and in response to human handling than domesticated species, who have adapted to this.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxwervim0sqt\"><sup><a href=\"#fnxwervim0sqt\">[6]</a></sup></span>&nbsp;Since we are at the beginning of the domestication process for ABFT, we should expect the tuna to be stressed by the large degree of human contact.</p><p>A Eurogroup for Animals report lists several common welfare issues that arise when fish are farmed. Some of these may be relevant for ABFT:</p><ul><li>Space: in captivity, ABFT are confined to spaces far smaller than in their natural habitat (where they range over thousands of miles)</li><li>Water quality</li><li>Parasites and disease</li></ul><p>There is also some evidence that fish are distressed by noise and unaccustomed vibrations, which may be hard to avoid in farming contexts, particularly inland.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefuog6afqfpb9\"><sup><a href=\"#fnuog6afqfpb9\">[7]</a></sup></span>&nbsp;</p><p>Some relevant questions:</p><ul><li>How exactly are breeding fish made to spawn in captivity? The Eurogroup for Animals report states that there are commonly welfare issues with breeding fish: for example, invasive \u2018stripping\u2019 processes to extract sperm and eggs, or hormonal injections.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmufqns0aim\"><sup><a href=\"#fnmufqns0aim\">[8]</a></sup></span>&nbsp;Van Beijnen also reports that early domestication projects had issues with broodstock hitting the walls of their tanks.</li><li>How much space do ABFT need to flourish? In a Guardian article, Andrew Eckhardt of Next Tuna is quoted as saying \u2018Our stocking density will be very low, less than 10kg [of fish weight] per cubic metre.\u2019 Is this enough space?<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefm79ulelfmd\"><sup><a href=\"#fnm79ulelfmd\">[9]</a></sup></span></li><li>Which natural behaviours are important for ABFT, and can they be appropriately fostered in captivity?</li></ul><p>&nbsp;</p><p>The Eurogroup report discusses tuna ranching specifically and talks about how there are likely welfare concerns.</p><p>On the more positive side, it\u2019s in producers\u2019 interests to ensure that their fish have good welfare and are not distressed. It\u2019s believed that stressed fish don\u2019t taste as good, so they don\u2019t fetch as high a price. So if welfare improvements can be found, farmers may be willing to adopt them for commercial reasons.</p><h1>Slaughter methods</h1><p>The most common way of slaughtering large ABFT is \u2018lupara\u2019. This involves shooting the fish in the head while they are still underwater. Lupara seems to cause minimal suffering; usually the fish die instantly, and there is not much crowding before death. (Crowding makes the fish stressed). 70-80% of large bluefin are slaughtered this way. The remaining 20-30% of large tuna are shot from outside of the water with a shotgun.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvesmt8i7be\"><sup><a href=\"#fnvesmt8i7be\">[10]</a></sup></span></p><p>Smaller tuna are slaughtered in a way that likely causes them more suffering; the fish are crowded before slaughter, sometimes for several hours, which causes distress. They are then killed by being hauled out of the water and spiked in the head (this is known as coring). Fish can be mis-cored, meaning that they don\u2019t lose consciousness immediately.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn69j8kasg9d\"><sup><a href=\"#fnn69j8kasg9d\">[11]</a></sup></span></p><p>I couldn\u2019t find out what proportion of ABFT are classified as \u2018small\u2019 vs \u2018large\u2019. Since the standard methods of slaughtering smaller fish seem much more cruel than standard methods of slaughtering larger ones, this seems like an important question.</p><p>As mentioned above, it is believed that if ABFT are stressed before they are killed, this makes their flesh taste worse (because struggling releases lactic acid). This means that the industry, at least in theory, has a commercial incentive to make slaughter as painless and stress-free as possible.&nbsp;This raises hopes that welfare advocates and industry may be able to collaborate to develop (more) humane methods of slaughter, though in practice, welfare doesn\u2019t seem to be a big priority for industry.</p><h1>Conclusion</h1><p>Since the domestication of ABFT is still in its infancy, it remains unclear what welfare issues there may be for ABFT in hatcheries. Some welfare issues we know about are the fact that small ABFT on ranches are routinely slaughtered in a way that causes distress and non-instant death; the high mortality rates of ABFT larvae in hatcheries (partially from causes that don\u2019t exist in the wild); and the fact that ABFT are stressed by noise.</p><p>On the more positive side, many things that are bad for fish welfare are also bad for companies. Companies will struggle to be profitable if most of their fish die; stress makes the fish less palatable, and therefore less valuable. So as the industry develops, it may have internal incentives to create better welfare conditions for ABFT. It\u2019s important to monitor the situation as this industry develops.</p><p>&nbsp;</p><h1>Bibliography</h1><h2>Research papers and reports</h2><p>Alphabetical by author</p><p>&nbsp;</p><p>van Beijnen, 2017 <a href=\"https://www.researchgate.net/publication/317663537_The_closed_cycle_aquaculture_of_Atlantic_Bluefin_Tuna_in_Europe_current_status_market_perceptions_and_future_perspectives\">The closed cycle aquaculture of Atlantic Bluefin Tuna in Europe: current status, market perceptions and future perspectives</a></p><p>&nbsp;</p><p>Chandararathna et al., 2021 <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8065896/\">Animal Welfare Issues in Capture-Based Aquaculture - PMC</a></p><p>&nbsp;</p><p>Compassion in World Farming, 2023: <a href=\"https://www.ciwf.org.uk/media/7452863/ciwf_rethinking-eu-aquaculture_online.pdf\">Rethinking EU Aquaculture for People, Planet and Animals</a></p><p>&nbsp;</p><p>Eurogroup for Animals, 2018, <a href=\"https://www.eurogroupforanimals.org/files/eurogroupforanimals/2021-12/Fish-Welfare-in-European-Aquaculture-2.pdf\">Fish Welfare in European Aquaculture</a></p><p>European Food Safety Authority, 2009, <a href=\"https://efsa.onlinelibrary.wiley.com/doi/epdf/10.2903/j.efsa.2009.1072\">Species-specific welfare aspects of the main systems of stunning and killing of farmed tuna</a></p><p>&nbsp;</p><p>Miyake et al, 2003, <a href=\"https://www.iccat.int/Documents/CVSP/CV055_2003/n_1/CV055010114.pdf\">General Review of Bluefin Tuna Farming in the Mediterranean Area</a></p><p>&nbsp;</p><p>Mr\u010deli\u0107 et al., 2023, <a href=\"https://www.mdpi.com/2071-1050/15/4/2976\">An Overview of Atlantic Bluefin Tuna Farming Sustainability in the Mediterranean with Special Regards to the Republic of Croatia</a></p><p>&nbsp;</p><p>Puig et al., 2021, <a href=\"https://www.researchgate.net/publication/355338497_Monitoring_of_Caged_Bluefin_Tuna_Reactions_to_Ship_and_Offshore_Wind_Farm_Operational_Noises\">Monitoring of Caged Bluefin Tuna Reactions to Ship and Offshore Wind Farm Operational Noises</a></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><h2>News articles and websites</h2><p>By date, most recent to least recent</p><p>&nbsp;</p><p><a href=\"https://www.theguardian.com/environment/2023/sep/04/breeding-breakthrough-paves-way-for-intensive-tuna-farming-on-land\">Breeding breakthrough paves way for controversial tuna farming on land | Marine life | The Guardian</a>&nbsp;(September 2023)</p><p>&nbsp;</p><p><a href=\"https://aquahoy.com/ieo-achieves-first-time-worldwide-reproduction-bluefin-tuna-land-based-facilities/\">IEO achieves for the first time worldwide the reproduction of bluefin tuna in land-based facilities</a>&nbsp;(July 2023)</p><p>&nbsp;</p><p><a href=\"https://thefishsite.com/articles/could-an-innovative-floating-ras-catalyse-atlantic-bluefin-tuna-aquaculture-next-tuna-paul-sindilariu\">Could an innovative, floating RAS catalyse Atlantic bluefin tuna aquaculture? | The Fish Site</a>&nbsp;(February 2023)</p><p>&nbsp;</p><p><a href=\"https://www.skretting.com/en/news-and-stories/a-leap-forward-for-farmed-atlantic-bluefin-tuna/\">A leap forward for farmed Atlantic bluefin tuna | Skretting</a>&nbsp;(January 2023)</p><p>&nbsp;</p><p><a href=\"https://www.rastechmagazine.com/skretting-partners-with-aquaculture-start-up-next-tuna/\">Skretting partners with aquaculture start-up Next Tuna - RASTECH Magazine</a>&nbsp;(January 2023)</p><p>&nbsp;</p><p><a href=\"https://www.seafoodsource.com/news/aquaculture/ichthus-unlimited-building-closed-cycle-bluefin-tuna-operation-in-california-and-mexico\">Ichthus Unlimited building closed-cycle bluefin tuna operation in California and Mexico | SeafoodSource</a>&nbsp;(April 2019)</p><p>&nbsp;</p><p><a href=\"http://news.bbc.co.uk/1/hi/sci/tech/8331113.stm\">Tuna ban \u2018justified\u2019 by science</a>&nbsp;(October 2009)</p><p>&nbsp;</p><p><a href=\"https://www.nissui.co.jp/english/group/business/aquaculture.html\">The Nissui Group Aquaculture Business</a></p><p>&nbsp;</p><p><a href=\"https://planettuna.com/en/the-life-cycle-of-the-atlantic-bluefin-tuna-how-a-3-mm-larva-turns-into-a-400-kg-giant/\">The Life Cycle of the Atlantic Bluefin Tuna: How a 3-millimeter larva turns into a 400-kilo giant</a></p><p>&nbsp;</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvfxpo0a2we\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvfxpo0a2we\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"http://news.bbc.co.uk/1/hi/sci/tech/8331113.stm\">Tuna ban \u2018justified\u2019 by science</a>&nbsp;(October 2009)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsd6zwj25xqf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsd6zwj25xqf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;van Beijnen, p. 28</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnc7gqgpji8u\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefc7gqgpji8u\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://aquahoy.com/ieo-achieves-first-time-worldwide-reproduction-bluefin-tuna-land-based-facilities/\">IEO achieves for the first time worldwide the reproduction of bluefin tuna in land-based facilities</a>&nbsp;(July 2023), <a href=\"https://www.theguardian.com/environment/2023/sep/04/breeding-breakthrough-paves-way-for-intensive-tuna-farming-on-land\">Breeding breakthrough paves way for controversial tuna farming on land | Marine life | The Guardian</a>&nbsp;(September 2023)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkcbi0pcp5p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkcbi0pcp5p\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;van Beijnen, p. 40</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnvk4ya3sj8r\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnvk4ya3sj8r\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Van Beijnen, p. 47-66.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxwervim0sqt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxwervim0sqt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8065896/\">Animal Welfare Issues in Capture-Based Aquaculture - PMC</a>, section&nbsp;3.2</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnuog6afqfpb9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefuog6afqfpb9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Puig et al., 2021, <a href=\"https://www.researchgate.net/publication/355338497_Monitoring_of_Caged_Bluefin_Tuna_Reactions_to_Ship_and_Offshore_Wind_Farm_Operational_Noises\">Monitoring of Caged Bluefin Tuna Reactions to Ship and Offshore Wind Farm Operational Noises</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmufqns0aim\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmufqns0aim\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Eurogroup for Animals, 2018, <a href=\"https://www.eurogroupforanimals.org/files/eurogroupforanimals/2021-12/Fish-Welfare-in-European-Aquaculture-2.pdf\">Fish Welfare in European Aquaculture</a>, p. 22.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnm79ulelfmd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefm79ulelfmd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.theguardian.com/environment/2023/sep/04/breeding-breakthrough-paves-way-for-intensive-tuna-farming-on-land\">Breeding breakthrough paves way for controversial tuna farming on land | Marine life | The Guardian</a>&nbsp;(September 2023)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvesmt8i7be\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvesmt8i7be\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;European Food Safety Authority, 2009, <a href=\"https://efsa.onlinelibrary.wiley.com/doi/epdf/10.2903/j.efsa.2009.1072\">Species-specific welfare aspects of the main systems of stunning and killing of farmed tuna</a>&nbsp;p. 10</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn69j8kasg9d\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn69j8kasg9d\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;European Food Safety Authority, 2009, <a href=\"https://efsa.onlinelibrary.wiley.com/doi/epdf/10.2903/j.efsa.2009.1072\">Species-specific welfare aspects of the main systems of stunning and killing of farmed tuna</a></p></div></li></ol>", "user": {"username": "Amber"}}, {"_id": "infHe2LiNuKThkonh", "title": "Mirror, Mirror on the Wall: How Do Forecasters Fare by Their Own Call?", "postedAt": "2023-11-07T17:37:50.380Z", "htmlBody": "<p><i>Note: This is a </i><a href=\"https://www.metaculus.com/notebooks/19812/mirror-mirror-on-the-wall-how-do-forecasters-fare-by-their-own-call/\"><i>linkpost</i></a><i> for the Metaculus Journal. I work for Metaculus and this is part of a </i><a href=\"https://www.metaculus.com/project/journal/?status=active&amp;has_group=false&amp;order_by=-publish_time&amp;project=1174&amp;search=author:nikos\"><i>broader exploration</i></a><i> of how we can compare and evaluate performance of different forecasters.</i></p><h1>Short summary</h1><ul><li>It is difficult to interpret the performance of a forecaster in the absence of a sensible baseline.</li><li>This post proposes a (novel?) experimental metric that aims to help put forecaster performance into context</li><li>From her subjective perspective, a forecaster assumes that her prediction is equal to the true probability of an event (otherwise she would have issued a different prediction). The idea is to take this assumption at face value and assume that a forecasters\u2019 predictions correspond to true event probabilities. Based on that, we can compute an subjective expected score and compare the actual score against that</li><li>All of this is very exploratory (and maybe slightly crazy?), but it's intellectually interesting and might potentially lead to useful insights.</li></ul><h1>Introduction</h1><p>\"How good is this forecaster\" is a question of great interest to anyone who is trying to assess the credibility of a forecast. I <a href=\"https://forum.effectivealtruism.org/posts/DzqSh7akX28JEHf9H/comparing-two-forecasters-in-an-ideal-world\">recently wrote</a> about how difficult it is to establish that there is a significant difference in performance between two forecasters. Evaluating a forecaster not only in <i>relative</i>, but in <i>absolute</i> terms is even more difficult.</p><p>Imagine, <a href=\"https://forum.effectivealtruism.org/posts/DzqSh7akX28JEHf9H/comparing-two-forecasters-in-an-ideal-world\">again</a>, that you're King Odysseus of Ithaca. Times are rough. You haven't been home for twenty years, your kingdom is a mess and new dangers are looming on the horizon. You could really need some divine help or some prescient counsel. Your trusted maid <a href=\"https://en.wikipedia.org/wiki/Eurycleia_of_Ithaca\">Eurycleia</a> suggested you go off to consult the oracle of Delphi.</p><blockquote><p>You: \"Are you sure it's worth it? How good is the oracle of Delphi really\"?</p><p>Euryclia: \"It's the best oracle in Greece!</p><p>You: \"Even if Delphi is better than the others... they might all be terrible! And it's a really long journey!\"</p><p>Euryclia: \"You really don't like travelling, don't you?\"</p><p>You: ...</p><p>Euryclia: \"To soon? I'm sorry. Listen, I think Delphi is really good. You should go.\"</p><p>You: \"But how good exactly!\"</p><p>Euryclia: \"It says on their website they have a <a href=\"https://forecasting.wiki/wiki/Brier_score\">Brier score</a> of 0.085 on Metaculus!\"</p><p>You: \"But what does that even mean? maybe they only predicted on the easy questions!\"</p><p>Euryclia: \"The divine oracle of Delphi made a forecast on every single question on Metaculus.\"</p><p>You: \"But maybe all questions on Metaculus are easy!\"</p><p>Euryclia: <i>looks at you sternly</i></p></blockquote><p>You fall silent. You still think you have a point. But Euryclia will have nothing of it. Sure, officially you are the king. But you're a wise king and you know your place.</p><h1>Meaningful comparisons</h1><p>You lie awake in bed at night pondering the question. The problem with the <a href=\"https://forecasting.wiki/wiki/Brier_score\">Brier score</a>, the <a href=\"https://forecasting.wiki/wiki/Log_score\">log score</a>, or really any other scoring rule used to evaluate predictions is that the score you get is mostly meaningless without anything sensible to compare it against.</p><p>For binary forecasts (outcome is either 0 or 1) the 'naive forecaster' is a natural, albeit not very helpful, baseline. The logic of the naive forecaster is that \"surely the probability of any event must always be 50% - it either happens or it doesn't\". Accordingly, the naive forecaster always assigns 50% probability to any outcome. Another possible baseline is the 'perfect forecaster' who is always correct. This, again, is not tremendously helpful.</p><p>The problem with constructing a baseline is that we can\u2019t really say how \u201chard\u201d a forecasting question is - we don\u2019t know the \u201ctrue probability\u201d of an event&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvf5glzt5pil\"><sup><a href=\"#fnvf5glzt5pil\">[1]</a></sup></span>.</p><p>You pause for a second. Maybe we could compare a forecaster against the score she herself should expect to get? Forecasters are usually evaluated using a proper score. A proper scoring rule is a metric that is impossible to cheat: you can't do any better than predicting your actual belief. From a forecaster\u2019s perspective, if you predict 0.7 on a binary question, then you\u2019re really expecting a 70% probability that the question will resolve yes.</p><p>Now you may be right or wrong about this, depending on whether or not your forecasts are in fact <i>well calibrated</i>. Calibration refers to a basic agreement between predictions and observations. One possible way to define calibration is to say that a forecaster is well calibrated if events to which she assigns a probability of x% really occur with a frequency of x%. For example, you could give a well calibrated forecaster 1 million forecasting question. Of those questions where she assigned 95% probability to \"yes\", 95% should really resolve \"yes\". Of those she assigned a probability of 7% to, only 7% should resolve \"yes\" etc.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefu4m309nl3ec\"><sup><a href=\"#fnu4m309nl3ec\">[2]</a></sup></span></p><p>Regardless of whether or not a forecaster is in fact well calibrated, she is always <i>expecting</i> to be well calibrated when she makes her prediction (otherwise the proper scoring rule would incentivise her to make a different prediction). In her mind, the \"true probability\" of an event is equal to her prediction. Given a set of predictions we can therefore easily compute the score she can expect to get from her subjective perspective. If her <i>actual score</i> is much different from this \"<i>subjective expected score</i>\", we know something is off.</p><p>One commonly used score for binary events is the Brier score. It&nbsp;is computed as&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\text{Brier score} =(\\text{outcome} - p)^2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">Brier score</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">outcome</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>, where the outcome is either 0 or 1 and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span></span></span></span></span>&nbsp;is a prediction that the outcome will be 1. So if the outcome is 1, your score is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(1 - p)^2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span></span>&nbsp;and if the outcome is 0, the score is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(0 - p)^2 = p^2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span></span>. The best possible score is 0, the worst is 1, and the naive forecaster who always predicts 50% would always get a score of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"0.25= 0.5^2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.25</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.5</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span></span>.</p><p>Not knowing the outcome in advance, the expected Brier score of any forecaster is<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\mathbb{E}[\\text{BS}] = \\text{true prob} * (1 - p)^2 + (1 - \\text{true prob}) * p^2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">E</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">BS</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mtext MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true prob</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mtext MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true prob</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span></span>.</p><p>From the subjective perspective of the forecaster the prediction&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span></span></span></span></span>&nbsp;should equal the true probability. The subjective expected score therefore is<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\mathbb{E}_\\text{subjective}[\\text{BS}] = p * (1 - p)^2 + (1 - p) * p^2 = p - p^2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">E</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-mtext\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">subjective</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">BS</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span></span>.</p><p>Let's call&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p - p^2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span></span>&nbsp;the \"subjective expected score\". Now, for any forecaster, you can easily compare the actual Brier score with their subjective expected score.</p><p>You lie in bed, quite excited you might have found a solution for your problem. What makes this approach so elegant is that it implicitly takes the difficulty of a question into account. If the oracle of Delphi really only forecasted on easy questions that would explain its great Brier score on Metaculus. But also she would be <i>expected</i> to get a low Brier score. Comparing the actual vs. the subjective expected score could be a way to know what we should expect from her and how far away she is from her own expectations! Problem solved!</p><p><strong>Problem not solved.</strong></p><p>Why did you, of all mortal beings, expect this to be smooth sailing?</p><p>The elephant in the room is of course that any kind of metric that compares a forecaster's score and their subjective expected score is not a proper score. The difference between the actual score and the \"subjective expected score\" can be cheated. For example, you could imitate the naive forecaster and always predict 50% without looking at the question. You would get an actual Brier score of 0.25 regardless of the outcome, but you would also get a \"subjective expected score\" of 0.25 and a perfect difference of zero.</p><h1>Behaviour of the subjective expected score</h1><p>Ok. But maybe there is still some merit in computing the \"subjective expected score\". To understand its behaviour and since you can't sleep anyway, you decide to get out your abacus and simulate some data. That's apparently the kind of man you've become in the last twenty years away from home. Your wife, Penelope, looks at you somewhat puzzled.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ihpa2q7xnefhabtphnjq\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/sgzbq0glfzputt3wtty3 140w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ikn9rxeb4byrxkss5cog 280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ee8odxboq2nw2juemze8 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/dotli8v3l2v5e5vqlpxh 560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/hu86osrrz52tw4slwvxu 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/kycb9ocriwajreaexbvm 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/gbcwgokl09tfshtwno64 980w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/rvadn5a37ghklonkomhi 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ltckluetlyhrnnrc7vkn 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ognxc1dztjaym2iqhytz 1359w\"></figure><h2>Behaviour for a single forecast</h2><p>You start with the very simple case of a single forecast for a single event. This plot shows the actual expected Brier score (<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\mathbb{E}[\\text{BS}]\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">E</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">BS</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span></span></span></span></span></span>), the subjective expected Brier score&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(\\mathbb{E}_\\text{subjective}[\\text{BS}])\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">E</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-mtext\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">subjective</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">BS</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>, and the difference between the two for different predicted probabilities. The true probability of the event is assumed to be 0.8 (black vertical line).</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/unr3xrt94dum9epntoa4\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/trcz5qu13stzrprkjlqe 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/sj1jipck6kb5rfjogj0c 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/u87wh6d6ltd1xn3yjjsj 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/j6nwb6uqnx4ymhq17dfk 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/f6ictetcpetxxcktmsca 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/izp2ypu6y5ydqscxroew 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/rhyruapeij9cyqyj1lav 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/sygozui7zyqufv0q96qd 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/adodxjbkn7z0wqocdurx 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/mz6yrxvkl2fownhfjpab 2100w\"></p><p>As with every proper scoring rule, the actual expected Brier score is best (i.e. smallest) when the&nbsp;prediction is equal to the true probability (when&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p = 0.8\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.8</span></span></span></span></span></span></span>). This is not the case for the subjective expected score nor for their difference.</p><p>The following table gives an overview of the behaviour of the actual vs the subjective expected score.</p><figure class=\"table\"><table><thead><tr><th>Comparison score</th><th>Interpretation</th></tr></thead><tbody><tr><td>actual score &lt; subjective expected</td><td>prediction in between 0.5 and true probability</td></tr><tr><td>actual score = subjective expected</td><td>prediction = 0.5 or</td></tr><tr><td>prediction = true probability</td><td>&nbsp;</td></tr><tr><td>actual score &gt; subjective expected</td><td>prediction closer to 0 or 1 than true probability or</td></tr><tr><td>prediction on the wrong side of 0.5</td><td>&nbsp;</td></tr></tbody></table></figure><p>Roughly speaking, the actual expected score is greater (i.e. worse) than the the subjective expected score when the forecaster is either overconfident (making more extreme predictions than warranted) or if she is on the wrong side of maybe (predicting e.g. &lt; 0.5 if the true probability is &gt; 0.5 or the other way round). The actual expected score is smaller (better) than the subjective expected score if the forecaster is underconfident, but directionally correct. Both are equal if the forecaster predicts either 0.5 or if she predicts the true probability.</p><p>You're not sure it adds all that much, but since a) you really can't sleep, b) you're wife is already annoyed anyways and c) you are, after all, king Odysseus of Ithaca, you also create an animated gif that shows the above plot for different true probabilities.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/shmfrpiqtttio8se4ojo\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ck7rvbvxrgfyrn6royto 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/b5mrs3gbomkorzc8htrf 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/bdd217c7p5ocupgqxqid 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/cztrpbqs8tg6tq1evwen 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/qaytov8nvrpiavfbgr5g 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ke79oqijngqgmnuaizop 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/mfhmd9gvvf6bnxnqjnbl 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ptk7omve6w1qvh8djs1r 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/vntygue4dkgckexfam7x 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/tpkdpoyl4fa1ptjccqql 2100w\"></p><p>Based on your observations, you form a hypothesis: Subjective expected scores and actual Brier scores are influenced by three main things:</p><ul><li>systematic over- and underconfidence of the forecasts&nbsp;<br><i>(We saw that underconfident forecasts led to subjective expected scores &gt; actual Brier scores, and the opposite for overconfident forecasts)</i></li><li>undirected noise (aka \"being a terrible forecaster\")&nbsp;<br><i>(Being a terrible forecaster is widely known to be one of the top reasons why forecasters get bad scores\u2026)</i></li><li>the 'difficulty' of the prediction task, i.e. whether true probabilities are close to 0.5 (hard question) or close to either 0 or 1 (easy question)&nbsp;<br><i>(Forecasters get better Brier scores in expectation as well as better subjective expected scores when probabilities are close to 0 or 1)</i></li></ul><p>Crucially, these three factors may not have to influence both scores in the same way (note e.g. that the slopes of the curves in the above plot differ at different points). This might provide useful information.</p><h2>Behaviour for a set of 1000 forecasts</h2><p>You sit up straight in bed. Next, you want to analyse the behaviour across a set of multiple questions. Your wife Penelope turns around and looks at you incredulously. \"Could you please stop using the abacus in bed? I can't sleep with all that clacking noise\". You nod, give her a kiss, and slide out of the bed to head downstairs to your old study room. Sitting down between old and dusty parchments, you light a candle and start working on your next simulation study.</p><p>You're going to do a thousand replications of your experiment. For every replication, you simulate 1000 true probabilities observations and corresponding forecasts. True probabilities are drawn randomly from a uniform distribution between 0 and 1. The outcome was set to 1 or 0 probabilistically according to the true probabilities (i.e. the outcome is 1 with probability equal to the corresponding true probability (and 0 otherwise)). Your starting point is an ideal forecaster (predictions = true probabilities) whose forecasts you eventually modify in different ways. Lastly you compute the actual and subjective expected scores and take the mean across your 1000 simulations, leaving you with one average score for every replication.</p><pre><code>For each of 1000 replications:\n1. Draw N = 1000 true probabilities as a random uniform variable between 0 and 1\n2. Create N = 1000 observations as draws from a Bernoulli distribution (drawing either a 0 or a 1) with the probability of drawing a 1 equal to the true probabilities drawn in step 1)\n3. some computation (see details below)\n4. Compute mean(actual Brier scores) and mean(subjective expected scores)</code></pre><h2>Over- and underconfidence</h2><p>First, you're interested in what happens if you make forecasts systematically over- or underconfident. You decide to simulate increasingly over- or underconfident forecasts by converting probabilities to log odds and multiplying them with a factor smaller or greater than 1.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwrcrr0pvskn\"><sup><a href=\"#fnwrcrr0pvskn\">[3]</a></sup></span></p><pre><code>3a. Create 5 forecasts with differing confidence bias levels 0.6, 0.85, 1, 1.15, 1.4. Values &lt;1 represent underconfidence, values &gt;1 represent overconfidence, 1 equals the ideal forecaster\n- Convert probabilities to log odds = (log (p / 1-p))\n- compute biased_log_odds = log_odds * confidence_bias\n- Convert odds back to obtain probabilities with either under- or overconfidence</code></pre><p>This is what you get. The first plot shows a histogram of the means of the actual and subjective expected Brier scores across 1000 replications. The second one is a calibration plot that displays predicted probabilities against observed frequencies. The third one shows a histogram of the predictions (which is essentially the information encoded in the size of the dots in the second plot).</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/dupvsh45rbi31uz6sies\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/u5dreamkv9afhzt4wtcb 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/k2tyoth5bjgef2chhlax 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/xqqfh2nkay9n3jmc1ghu 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/nus9weftd2qac524qk7u 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/pzchrab6uxbcx4ne8hsx 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/oecpvqwgomgjkr8ng6ui 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/bmxzechunf4y0plb5rd5 2100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ptkodgkptojjiwp262ku 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/wxlk1qdypdhbxyjoasjb 2700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/velqw48q0rvpx9iexmvw 3000w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/zq11zbdirdkm1ssppxhw\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/jntcm8w5jdlilafffzi4 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/dxdgl7so9xksksxyefpm 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/nznhhlfnwnwk1iaz0m8u 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/yo0tvm1kalfjh1mjne2b 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/k61xp4fqhmbp1sfvfq6g 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/f5bnrbgvxc7jmfwzido2 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/obfs37nvyc8jqs5pv1za 2100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/wiy83tznxrodtpqyj1zi 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/gecbm0jojoqnwa2y04yl 2700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/zs8dzgeq89bofudyeybr 3000w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/kgcvqal7dkktd4abrray\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/xsth3zacoehd9ftwiegd 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/rner21d5zlvxcbz7moha 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/tjbovjg4allzolko32jh 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/j91dhqdj8ovxa7wmepqu 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/qqorzym8wkkudxm4bkt1 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/vbifpaglxmvnekedvatl 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/dbvexbvdfqbx1yhwgyfp 2100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/r2ozbkauoki2epejrxdy 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ytq6xmseg6y5givricq0 2700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/lk3y9p6nuotczlxcovoe 3000w\"></p><p>In this particular example systematic over- or underconfidence has a much stronger influence on subjective expected scores than actual Brier scores. This makes intuitive sense, given that the expected Brier score is calculated as&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"E[\\text{actual}] = \\text{true prob} * (1 - p)^2 + (1 - \\text{true prob}) * p^2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">actual</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mtext MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true prob</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mtext MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true prob</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">\u2217</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span></span>. When you change the prediction, you're only changing&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span></span></span></span></span>&nbsp;for the actual Brier score, but you're changing&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span></span></span></span></span>&nbsp;as well as&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\text{true prob}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true prob</span></span></span></span></span></span></span>&nbsp;for the subjective expected Brier score. Do that systematically in the same direction across all predictions and you end up with a strong effect.</p><p>Note that if you made forecasts even more extremely underconfident than is shown in this plot (i.e. make all predictions close to 0.5), then both actual and subjective expected scores would just converge towards 0.25. This is illustrated here:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/yf0ycpb0dvuseo1kflft\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/xcm4vd89ikrpbhkkldso 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/d8hsbjmb0pxpul55epqq 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/nje2xr63r2tg9mthv8ly 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/vvzshfuxylqinecev8wk 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/uo2ndltctrgcq6ckl1v1 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/sl4ckitygzjtnii6g6bi 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/e5dgqnlmswaugzrffscy 2100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/eye7y68b6ffdfz0b9dwb 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/hgp1gldms33seeuyg8zr 2700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/fpb6fjntcwpbhvz66ppv 3000w\"></p><h2>Adding noise</h2><p>Next, you want to see what happens when you add random noise to the forecasts, instead of inducing systematic over- or underconfidence. Again, you operate with log odds and add random noise drawn from a normal distribution with mean 0 and standard deviation equal to the desired noise level:&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\text{noisy log odds} = \\log(\\text{true probability}/(1\u2212\\text{true probability}) + \\mathcal{N}(0, \\text{noise level})\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">noisy log odds</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">log</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true probability</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mtext MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true probability</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-texatom MJXc-space2\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-cal-R\" style=\"padding-top: 0.519em; padding-bottom: 0.372em; padding-right: 0.159em;\">N</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mtext MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">noise level</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>.</p><pre><code>3b. Create 5 forecasts with differing noise levels, 0 (no noise), 0.1, 0.25, 0.5, 0.75, and 1\n- Convert probabilities to log odds = (log (p / 1-p))\n- noisy_log_odds = log_odds + N(mean = 0, sd = noise level)\n- Convert back to obtain noisy probabilities\n</code></pre><p>This is the result for different levels of noise:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/xd4iuivovtbsij8g7kph\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ixo6frwnf6mgifyzncky 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ukpiqvsbxmdotimvuur7 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/k4rxgdqfezlygizffgve 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/wtt6fc3u0i9ccxnzbwmk 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/kzppmivayixbczg4a2ns 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ayxp7ciiuybcre8hcfda 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/xp1vbdyoz4yhmkrzt6a3 2100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/tgtd4r2lq48yv9mygtpa 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/aui1ovxtkayjm4tovp6f 2700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/bkz52js9etqkt2wlp1am 3000w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/zaopdskb31ltykqmldjt\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/lylqydb5bv0tirgfhvi7 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/anbbsrx3dzrncchebfch 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ms017jonmntvhn499vsz 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/afyjfbtnoyie3oqbxlna 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/knixyxpcddjreurhyefs 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/v6cjxbecq555sm79aral 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/xvctwf4hbzyshwo9siaz 2100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ujh8osnievbyrr5wqi5n 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ynlhu7dl864ddybayc1d 2700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ik1uzpgwkslpc6t6joho 3000w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/kaa80cks6o8u61wc5fdh\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/mkvycvgwtcm0mrgxeerp 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/xluomnr7uitdnqeqwtp6 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/datcplbwhklqaiqpyrlo 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/hzbo7evsd72wne0oioom 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ket85p0ihjqhbo4xksgz 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/qjv31iun9575xyjz48ki 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/o6tw0t5mmspcmdhvfdqu 2100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/f3kigookogukbwvtvstc 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ojjgaynp9v4qplba5dqf 2700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/kyntblxvbwuafjdte23n 3000w\"></p><p>Adding noise seems to have a somewhat stronger effect on actual Brier scores than on subjective expected scores. As we can see from the calibration plots and the prediction histogram, adding noise to the log odds also introduces some overconfidence. There might be better ways to add noise than what you did - but 12th century BC abacus technology is not perfect and even your cunning has limits.</p><p>You suspect that the effect on the subjective expected scores mainly comes from the overconfidence you involuntarily introduced by adding noise on the log scale. You briefly check what would happen if you added noise on the actual probabilities, rather than on the log odds. And indeed, if you add noise to probabilities instead, the effect on the subjective expected scores vanishes almost completely. Alas, parchment is expensive and so you decide not to write your results down in detail. Instead, you just make a small note on the side (this is a trick that you learned from your old friend <a href=\"https://en.wikipedia.org/wiki/Fermat%27s_Last_Theorem\">Fermatios</a>).</p><p>Indeed, you also check what happens if you combine noise on the log odds with underconfidence. It\u2019s a bit of a hack, but you manage to find something of a balance between noise and underconfidence such that subjective expected scores stay more or less constant, but actual Brier scores increase. (You make another note on the side of the parchment and conclude that overall</p><p>a) noisy forecasts seem to mainly make actual Brier scores worse,</p><p>b) over- and underconfidence seem to mostly affect subjective scores, and</p><p>c) introducing noise can sometimes also mean introducing overconfidence and then you affect both, but the effect of noise on actual Brier scores is probably stronger.</p><h2>Hard and easy questions</h2><p>Lastly, you want to find out how question difficulty affects scores. To that end you classify questions as such:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/wqnpcnakg9vo0oawruev\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/bzzhygq7qnsemguicqqj 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/knro8c56bjqfhu96yulx 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/k2danbp6wqazprkkspom 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/vojggmowek4i2c8uvfbd 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/oexelszdu2bbolqemab7 1350w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/mkqrdbbek37slgvkq87u 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/v4hcip0f6op2glcnb8mn 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/h38irn7zyqyal6wvgbdq 2160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/htehghsyuxlrc7s2u8f4 2430w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/eno8nvvnm1ypknpiqxcb 2666w\"></figure><ul><li>\"easy\"if&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\text{true prob} < \\frac{1}{6}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true prob</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.495em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 0.7em; top: -1.372em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 0.7em; bottom: -0.687em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">6</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.456em; vertical-align: -0.486em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span>&nbsp;or&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\text{true prob} > \\frac{5}{6}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true prob</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.495em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 0.7em; top: -1.394em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 0.7em; bottom: -0.687em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">6</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.472em; vertical-align: -0.486em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></li><li>\"medium\", if&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{1}{6} \\leq \\text{true prob} < \\frac{2}{6}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.495em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 0.7em; top: -1.372em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 0.7em; bottom: -0.687em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">6</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.456em; vertical-align: -0.486em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2264</span></span><span class=\"mjx-mtext MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true prob</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.495em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 0.7em; top: -1.372em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 0.7em; bottom: -0.687em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">6</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.456em; vertical-align: -0.486em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span>&nbsp;or&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{4}{6} < \\text{true prob} \\leq \\frac{5}{6}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.495em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 0.7em; top: -1.383em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">4</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 0.7em; bottom: -0.687em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">6</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.464em; vertical-align: -0.486em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mtext MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true prob</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2264</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.495em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 0.7em; top: -1.394em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 0.7em; bottom: -0.687em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">6</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.472em; vertical-align: -0.486em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span>&nbsp;and</li><li>\"hard\", if&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{2}{6} \\leq \\text{true prob} \\leq \\frac{4}{6}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.495em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 0.7em; top: -1.372em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 0.7em; bottom: -0.687em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">6</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.456em; vertical-align: -0.486em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2264</span></span><span class=\"mjx-mtext MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">true prob</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2264</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.495em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 0.7em; top: -1.383em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">4</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 0.7em; bottom: -0.687em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">6</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.495em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.464em; vertical-align: -0.486em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></li></ul><p>You run your past analyses again, but this time you stratify your results by question difficulty. In reality, question difficulty is of course not observable, but you want to see what influence difficulty has on scores. Maybe that could enable you to also make inference the other way round, i.e. determine question difficulty based on observed scores.</p><p>Here are the results for over- and underconfidence (0.6 and 0.85 represent underconfidence, 1 is the ideal forecaster, and 1.15 and 1.4 represent overconfidence).</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/r98wofang9in2jldxwkr\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/s1qkmyszmckaycboplm9 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/rmsdgu2nrnkkdybqjfwl 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/cllfvjgn8zopucpuz6cd 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/afyxomkdd4lrn890ccwq 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/en0xcixmenq0ycezwesw 1300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/wsuzp4ifsxuzrk0de43f 1560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/um3pax9yysuefejqnkoz 1820w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/j5fsdgxscdu4j7fh9bum 2080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/wc5xvwkdamz9pnu4oumw 2340w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ytxi9szugn2vd8c0uu3r 2550w\"></p><p>We can see a clear relationship between scores and question difficulty. We also see that question difficulty mediates the influence of over- / underconfidence: Differences between actual and subjective expected Brier scores caused by over/underconfidence are largest for easy questions, and smallest for difficult questions.</p><p>Those are the results for adding different levels of noise, stratified by question difficulty:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/adbhybdxzwqwy4o7kdyu\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/hv0iwmid8iqe3vtlsr9l 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/dzqbcbincttjmvurtieo 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/fk11wirj5nrdsc1nwt3a 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/d6qqxqglfyy9i3xrusan 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/qjzwncx4lpb1ewzlrrje 1300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/hdhtjd9mkgcmkxf7fsul 1560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ebgomurekl8ofrzzune1 1820w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/avzilygffyb8cigpe2uc 2080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ofl0dy0mpyxygvqlau6s 2340w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/yi2uq6gqidisivvzww1t 2550w\"></p><p>The pattern we can see here is a different one: Now differences between actual and subjective expected scores caused by noise tend to be largest for difficult questions, and smallest for easiest. The pattern we see here is similar for the version that combines noise and underconfidence (subjective expected scores mostly just tend to be a bit higher in particular for easy questions, see footnote<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefuhgvz1nghsc\"><sup><a href=\"#fnuhgvz1nghsc\">[4]</a></sup></span>).</p><p>You stroke your beard and murmur to yourself \"Now this is interesting\". \"Yes yes, very interesting indeed\", you keep thinking. You sigh. Deep inside you know that you don't really have a clue of what all of that is supposed to mean.</p><h1>Conclusions</h1><p>Every research project needs conclusions, so you start writing. It's not that you believe your approach is completely useless - it's more that you're painfully aware that things remain complicated.</p><p>After having stared at your plots for several hours, this is your best guess of what all of this actually means (note that all of this is a matter of degrees, which the following table doesn't capture appropriately):</p><figure class=\"table\"><table><thead><tr><th>&nbsp;</th><th style=\"text-align:center\">low expected score</th><th style=\"text-align:center\">high expected score</th></tr></thead><tbody><tr><th>low actual score</th><td style=\"vertical-align:top\"><p>1) questions are \u201ceasy\u201d and forecaster is great</p><p>2) questions are easy and forecaster is somewhat terrible, but still well calibrated and neither systematically over- nor underconfident</p><p>&nbsp;</p></td><td style=\"vertical-align:top\">1) Questions are relatively easy and forecaster is underconfident</td></tr><tr><th style=\"width:80px\">high actual scores &nbsp; &nbsp;</th><td style=\"vertical-align:top\">1) questions are relatively hard &amp; forecaster is overconfident&nbsp;</td><td style=\"vertical-align:top\"><p>1) questions are hard &amp; forecaster is great</p><p>2) questions are hard &amp; forecaster is terrible, but not systematically overconfident (forecaster might be terrible and underconfident though)</p><p>3) questions are either easy or hard, and forecaster manages to make bad, but well calibrated predictions close to 0.5, e.g. by predicting 0.5 almost everywhere)</p></td></tr></tbody></table></figure><p><i>Note: \u201ceasy\u201d and \u201chard\u201d are somewhat hard to define. Here easy means \u201ctrue probabilities &gt;5/6% or &lt;1/6%\u201d. What\u2019s feels easy or hard of course depends on a lot of factors and may not be the same for everyone.</i></p><p>The easy to interpret cases are when either one of actual or subjective expected scores are high (low) and the the other is low (high). This just indicates clear over- or underconfidence on the part of the forecaster. If actual scores are low, and subjective scores are high, then questions are easy and the forecaster is underconfident. If it's the other way round, then questions are relatively hard and the forecaster is overconfident.</p><p>Things are more difficult when both scores are congruent. If they are both low, then one possibility is that questions are easy and the forecaster is great. In principle, the second forecaster could also be bad, if she avoids systematic over- and underconfidence. Small perturbations close to 0 or 1 don't affect Brier scores that much (that would be different with a log score), so even a not so great forecaster could get a good score if questions are really easy. If there is no systematic over- or underconfidence, then actual and subjective expected scores get affected by similar amounts.</p><p>If scores are both high, things are even more complicated. The forecaster could be great and it's just that questions are really hard. Or questions could actually be easy / medium, and the forecaster is just soooo terrible that there isn't any resemblance to reality anymore. Or she could intentionally imitate a naive forecaster by essentially predicting 0.5 everywhere. Given that forecasters usually try to be good forecasters this is maybe not a huge concern. It seems mostly safe to assume that questions are actually hard if both scores are high. Then the forecaster could either be great (and we just can't know) or the forecaster could be terrible, just not systematically overconfident. If she were overconfident, subjective scores would drop immediately. If she is underconfident that doesn't make much difference, as subjective scores can't get worse than 0.25 anyway.</p><h1>Caveats, limitations and final thoughts</h1><p>Now this is a section that you feel very comfortable writing and you have lots of things to say. But since parchment is expensive and you're starting to feel really tired you keep it to the main points:</p><ol><li>The subjective expected score does not equal the score of an ideal forecaster, but represents the score that a forecaster could expect if we knew she was perfectly calibrated. This score is cheatable, meaning that you could make it bigger or smaller if you wished for some reason</li><li>Reality is complicated and the failure modes you explored so far (over-/underconfidence, noise on log odds) are just some of many potential ways in which forecasts can be off. These failure modes can interact with each other, pushing scores in differing directions in a way which can make it difficult to know what's going on</li><li>Everything shown above is contingent a) on a specific method of simulating forecasts and various influences on them and b) on the Brier score. The behaviour of the subjective expected score would probably be very different for other scores. This, in some sense, represents a chance because you could potentially enrich your analysis by computing scores for different metrics and interpreting the patterns across different metrics.</li></ol><p>Your overall impression of this approach is that it <i>can</i> be useful and can give some context to scores that otherwise are just looked at in complete isolation. But that doesn't mean that it offers easy and clear answers.</p><p>Regardless of all the issues you encountered and the problems that lie still ahead you're satisfied with this night's work. Tomorrow you're going to tell Euryclia that you're going to do some additional analyses on the oracle of Delphi. Their Brier score of 0.085 is probably overall a good thing. But, you definitely were right in suspecting that they must have forecasted on relatively easy questions. Even an ideal forecaster would only get a Brier score of 0.085 on questions with a true probability that is on average greater than 90.6% or smaller 9.4%.</p><p>And while you're at it, there are lots of other oracles you could check. In particular those that belong to the holy quintinity of Metaculus, INFER, Good Judgment, Hypermind, and Manifold would be interesting to compare.</p><p>But you'll leave this to another sleepless night. For now, you blow out the candle, tidy up your parchments and head back upstairs to the bedroom again. You slide under the comfy and warm blanked and snuggle up against your beloved wife Penelope. As you finally fall asleep, you hear a faint voice whispering in your head \"Good, good. Excellent. Now do log scores\".</p><p>&nbsp;</p><p><i>Thank you very much to Sylvain Chevalier and Ryan Beck for their helpful comments and feedback on this post!</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvf5glzt5pil\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvf5glzt5pil\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The concept of a 'true probability' is a bit fuzzy and difficult to define. A useful approximation of 'true probability' for our purposes might be something like \"best possible forecast by any currently possible forecaster who has all available knowledge\". For most practical considerations, this is a useful concept. It makes sense to say \"the probability of this die showing a 6 is 1/6\" or \"the probability of this coin coming up heads is 0.5\" (actually, <a href=\"https://arxiv.org/abs/2310.04153\">it seems to be 0.508</a>) or \"there is a x% chance that Joe Biden will win another presidency\". But if you knew everything and if everything was pre-determined, maybe the 'true probability' of everything would always be 0 or 1?</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnu4m309nl3ec\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefu4m309nl3ec\">^</a></strong></sup></span><div class=\"footnote-content\"><p>It's important to note that a well calibrated forecaster is not <i>necessarily</i> a <i>good</i> forecaster. Consider weather forecasts. On average, it [rains on 88 out of 365 days](<a href=\"https://www.ithaca.gr/en/home/planning-your-trip/the-weather-2/#:~:text=Like%20the%20rest%20of%20Western,acre%2C%20fall%20in%20a%20year.)\">https://www.ithaca.gr/en/home/planning-your-trip/the-weather-2/#:~:text=Like the rest of Western,acre%2C fall in a year.)</a> in in your home on the lovely island of Ithaca. A forecaster who would just forecast a rain probability of 0.241 every day would be well calibrated.&nbsp;One could easily do better by taking the current month into account. In Januaries, it usually rains on 14 out of 31 days, so a forecaster could predict 0.45 for every day in January, 7/31 for every day in March and 1/30 for every day in June. This forecaster would be better, because she is equally well calibrated, but <i>sharper</i> (i.e. gives more precise predictions). An even better forecaster would make use of up-to-date weather modelling, and the perfectly prescient forecaster again would know all the answers in advance. All of these forecasters are well calibrated, but differ in how good they are as forecasters.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwrcrr0pvskn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwrcrr0pvskn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We use log odds here since there is a qualitative difference between a forecast that is moved from 50% to 55% and one that is moved from 94.5% to 99.5%. The former is only a small update, whereas the latter corresponds to a massive increase in confidence. This becomes obvious when you convert the probabilities to odds (odds = p / (1 - p)). The move from 50% to 55% would mean a move from 10:10 to 11:9 expressed as odds. the move from 94.5% to 99.5% would mean a move from 189:11 to 1990:10.</p><p>Perhaps the cleaner version of this would be to add a term to the log odds instead of multiplying them with a number. However, then you have to add a number to positive log odds and subtract a number from negative log odds to get a similar effect (otherwise you're just pushing all values towards either 0 or 1) and multiplying just does the trick as well.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnuhgvz1nghsc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefuhgvz1nghsc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This combines noise and underconfidence. The confidence bias is calculated as 1 - noise^2 * 0.15 and that is the value with which all log odds get multiplied.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/fahli4yhvega11rbr9vc\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/yfcjg1klbq2hffue01wf 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/owiouceglquhfa42dc9z 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/vrhpzi3z2tqnimf6ojmy 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/fbmysqcp6gnxcehdqolu 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/y3c9i73ttvwhgng4f6nc 1300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/bsuazfahnbrf2zjuyp0k 1560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/zv7dkualjaf84byyq10i 1820w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/vpzblbtma3ws0basgymi 2080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/g4qdweyi833ssye3xg37 2340w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/lzdosmglmqys1xuripto 2550w\"></p><p>For reference, here are also the unstratified plots. We see that combining underconfidence and noise on log odds doesn't perfectly cancel out, but it's also not too terrible either.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/f3lutcjqk8ohoye1bjbb\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/lrj4bpl8t9orjr4834vy 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/zabqcsvlbhbswfu2tyqt 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/pcrfnp5akkcb7hatgjmv 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/shai3uqhcukfzxynuj9c 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/tmgwqs0k3sowqaba994v 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/u195pzf6d1kbmh4ukptp 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/sfvdyinoxpgmb9bdeipa 2100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/mamuydf87qw5y2g9gxlh 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/hovrbfqq8im0hiwgwxks 2700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/d1svv3qho7dxzgybcrgu 3000w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/wdojricvit4mebkongv7\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/p2ifds9z6tzffiefwvhw 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/gcnpdfje1j3rgmpvp33c 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/rfruv7azrx4cm9lqlepd 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/kfyvbf0cujwtw0gfryeq 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ifjjh3qrycl7gmta3yfz 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ymcwkjoegkq9gsoxxkb9 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/jlprvido6gwqezaqzvjl 2100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/ubotoik55ryfetmzvgzq 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/wyh2fytnhjmib7noejtq 2700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/wwbnltihj3wxmbvfeuay 3000w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/fudrj3jlv2y0j47y14q9\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/on9lzbl3xkokmmffdqzx 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/eebag2sikaeytq2drsjy 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/m11ayfg2k8i8qablxktl 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/woilz1mekhc1n7ofxptt 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/aihyfe55bm2pbe6q8d00 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/m9hvhcumjdy1xnhyp7bs 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/o626buppvjvzvcsmaocb 2100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/x9lbqtrzkwew1xmfbhgz 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/cagpbahn8nin6r4lvbtp 2700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/infHe2LiNuKThkonh/hcas0qxkx7egdrezbjzd 3000w\"></figure></div></li></ol>", "user": {"username": "nikos"}}, {"_id": "yBnoXaKjGvMuL7TJF", "title": "Tips from EASE: Maintaining a Healthy Work Life Balance", "postedAt": "2023-11-06T15:00:47.812Z", "htmlBody": "<p><strong>Investing in YOU is the best way to&nbsp;invest in your organization. A happier, more balanced person performs better at work, and has a much bigger impact.&nbsp;</strong><br><br>Keeping your mind and spirit healthy enables you to do you job better and increase your impact in your chosen career. But keeping a good balance of preserving the attention and care you need to give yourself can be challenging, especially as we\u2019re entering holiday season, and work demands increase.<br><br>So we asked our experts for their tips to share with you. Here's what they said.<br><br><strong>Question:&nbsp;</strong>&nbsp;As a provider working with many hard-working and motivated people, what are some strategies or resources you\u2019d recommend to others to keep a healthy balance year-round?</p><p><a href=\"https://mailchi.mp/b3c6652766f2/worklifebalance\">Click here</a> to view what they said (it's a great read!).</p>", "user": {"username": "Deena Englander"}}, {"_id": "zihL7a4xbTnCmuL2L", "title": "Towards non-meat diets for domesticated dogs", "postedAt": "2023-11-06T14:21:18.133Z", "htmlBody": "<p><i>This essay argues that getting domesticated dogs to eat vegan or&nbsp;</i><a href=\"https://slate.com/human-interest/2010/04/it-s-ok-for-vegans-to-eat-oysters.html\"><i><u>ostrovegan</u></i></a><i> diets is a neglected, tractable, and important way to advance&nbsp;</i><a href=\"https://www.nytimes.com/interactive/2022/12/05/magazine/martha-nussbaum-interview.html\"><i><u>justice for animals</u></i></a><i>. First, I estimate that dog diets contribute to the slaughter of 2.89 billion animals on factory farms annually, the vast majority of which are chickens, and create more greenhouse gas emissions than the Netherlands. Second, I argue that an (ostro)vegan diet is, as far as we know, healthy for dogs. Third, I suggest some ways we can advance the cause. &nbsp;</i></p><h2>How many animals are slaughtered on factory farms to feed domestic dogs?</h2><p>Overall, I estimate that dog diets result in the slaughter of 2.824 billion chickens, 56.79 million pigs, and 9.52 million cows.&nbsp;</p><p>On a per-dog basis, switching to a non-meat diet will save about 20 chickens, 0.41 pigs, and 0.07 cows per year.&nbsp;</p><p>Here\u2019s a&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1iyBdG8JNYJbEWnjZPX_H_b62hQfSupK4pv0u5-B0mr4/edit?usp=sharing\"><u>Google Sheet of my calculations</u></a>. The remainder of this section explains how I got there.</p><h3>How many domesticated dogs are there?</h3><p><a href=\"https://www.science.org/doi/full/10.1126/sciadv.abo6493\"><u>700 million dogs live on Earth</u></a>, about&nbsp;<a href=\"https://www.thezebra.com/resources/research/pet-ownership-statistics/\"><u>471 million of whom are domesticated</u></a>.&nbsp;</p><h3>How many of those dogs eat food that comes from factory farms, and how much?</h3><p>Dogs and dog diets are heterogeneous. A street dog who&nbsp;<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0168159118305914\"><u>scavenges</u></a> or gets&nbsp;<a href=\"https://steemit.com/stories/@bkkshadow/the-life-of-a-temple-dog-in-thailand\"><u>fed at a temple</u></a> might plausibly contribute very little or nothing to factory farming. Likewise, a farm dog who eats table scraps or an apartment dog who eats \u201c<a href=\"https://www.nytimes.com/2023/04/12/business/human-grade-dog-food.html\"><u>human-grade food</u></a>\u201d is going to have a very different dietary footprint.&nbsp;</p><p>For our purposes, I think we want to know how many dogs eat mass-market food that\u2019s packaged and sold as dog food, which we can assume almost entirely comes from industrial farms. For a ballpark estimate, I tally all domesticated dogs in the United States, Canada, Australia and Europe, and assume that \u2154 of the food they eat is meat that comes from Concentrated Animal Feeding Operations. ( Around&nbsp;<a href=\"https://animalequality.org/blog/2022/10/14/factory-farming-facts/\"><u>99% of all meat in the US comes from factory farms</u></a>, but dry food for dogs is typically a mix of grains, vegetables and meat.)</p><p>Apparently there are&nbsp;<a href=\"https://www.statista.com/statistics/198100/dogs-in-the-united-states-since-2000/\"><u>89.7 million pet dogs</u></a> in the US,&nbsp;<a href=\"https://www.statista.com/statistics/1015882/number-of-pet-cats-and-dogs-canada/\"><u>7.9 million in Canada</u></a>,&nbsp;<a href=\"https://www.essentialdog.com.au/blog/how-many-dogs-are-there-in-australia/\"><u>6.4 million in Australia</u></a>, and&nbsp;<a href=\"https://www.statista.com/statistics/515579/dog-population-europe/\"><u>104.3 million in Europe</u></a> \u2014 so I'm estimating about 208 million dogs getting \u2154 of their diets from factory farms.</p><h3>How much does the average dog eat?</h3><p>A dog food company&nbsp;<a href=\"https://sundaysfordogs.com/blog/how-much-should-i-feed-my-dog-a-guide-by-weight-and-age\"><u>recommends</u></a> that a medium-sized dog eat between 1.75 and 2.33 cups (.875 to 1.165 lbs) of food per day.&nbsp;</p><p>Is the average dog a medium-sized dog? I\u2019m not sure. The most popular breeds in America, aside from the French bulldog,&nbsp;<a href=\"https://www.akc.org/expert-advice/dog-breeds/most-popular-dog-breeds-2022/\"><u>tend to be big</u></a>. But as far as I can tell, that measures the sale of pure breeds, and apparently&nbsp;<a href=\"https://www.thezebra.com/resources/research/pet-adoption-statistics/\"><u>just over half of American dog owners have mutts</u></a>.</p><p>Here\u2019s a totally unscientific estimate: let\u2019s say that the average domesticated dog weighs about 35 lbs,<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"b1owcu08q6n\" role=\"doc-noteref\" id=\"fnrefb1owcu08q6n\"><sup><a href=\"#fnb1owcu08q6n\">[1]</a></sup></span>&nbsp;and consumes 1 lb of food, and .67 pounds of meat, per day.</p><h3>How much meat is that in total?</h3><p>\u2154 of a pound of meat per day is about 244.5 lbs per dog per year, so 208 million dogs eating that much is 50,638,640,000 pounds of meat per year.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"72set5ni93y\" role=\"doc-noteref\" id=\"fnref72set5ni93y\"><sup><a href=\"#fn72set5ni93y\">[2]</a></sup></span></p><h3>What animals produce these 50.64 billion pounds of meat?</h3><p>&nbsp;Dog food is a mess of flesh, byproducts, and parts that otherwise wouldn\u2019t be consumed. But let\u2019s roughly assume that all dog food meat comes from chickens, pigs and cows/buffalo, and that the proportions coming from the three categories are the same as those that go into human food.&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/topics/our-world-in-data\">Our World in Data</a>&nbsp;<u>estimates that </u><a href=\"https://ourworldindata.org/meat-production\"><u>among those categories</u></a>, about 41% of every pound of meat comes from chickens, about 36% comes from pigs, and about 23% comes from beef.</p><p>That gives us about 20.75 billion pounds of chicken, 18.2 billion pounds of pig meat, and 11.6 billion pounds of beef.&nbsp;</p><h3>How many animals are killed to feed domesticated dogs?</h3><p><a href=\"https://forum.effectivealtruism.org/topics/our-world-in-data\">OWID</a> estimates that for animals slaughtered in America, the&nbsp;<a href=\"https://ourworldindata.org/grapher/chicken-meat-yields-per-animal?tab=chart&amp;country=~USA\"><u>average chicken </u></a>produces 4.9 lbs of meat; the&nbsp;<a href=\"https://ourworldindata.org/grapher/pig-yields-meat-per-animal-in-hectograms-100-grams?tab=chart&amp;country=~USA\"><u>average pig </u></a>214 lbs; and&nbsp;<a href=\"https://ourworldindata.org/grapher/cattle-meat-yields-hectograms-100-grams-per-animal?tab=chart&amp;country=~USA\"><u>the average cow</u></a> 815.32 lbs.&nbsp;</p><p>That gives us 4.23 billion chickens slaughtered; 85 million pigs; and 14.18 million cows.&nbsp;</p><p>Here, one might object that many of these animals would have been slaughtered anyway, because dog food is partly comprised of byproducts, offal, and the like. How much of this harm is really&nbsp;<i>caused</i> by dog diets? This is hard to estimate without a structural model. Perhaps some of that food would simply go to waste, but presumably much of it would go towards feeding other farm animals (this&nbsp;<a href=\"https://mercyforanimals.org/blog/what-they-feed-animals-on-factory-farms-is/\"><u>regularly happens</u></a>), which would impact food production elsewhere, etc.&nbsp;</p><p>Let\u2019s generously assume that \u2153 of all factory farm meat consumed by dogs is pure byproduct, i.e. does not drive meat consumption at all.</p><p>Our final estimate is that dog diets result in 2.824 billion chickens slaughtered; 56.79 million pigs; and 9.52 million cows. That\u2019s 2.89 billion animals in total each year.</p><p>There are many different ways to estimate how bad this is, depending on how you&nbsp;<a href=\"https://www.jefftk.com/p/why-im-not-vegan\"><u>convert an animal\u2019s suffering into human-legible terms</u></a>. For me, these numbers are self-evidently very bad.</p><p>Another way to approach this is to think about environmental harms. <a href=\"https://forum.effectivealtruism.org/topics/our-world-in-data\">OWID</a> estimates that every pound of beef produces about&nbsp;<a href=\"https://ourworldindata.org/environmental-impacts-of-food\"><u>99.5 pounds of carbon emissions</u></a>. Cutting cattle consumption by dogs in half could reduce carbon emissions by about 192,366,666 tonnes per year. That\u2019s about 0.35% of the 54.6 billion tonnes of&nbsp;<a href=\"https://ourworldindata.org/greenhouse-gas-emissions\"><u>GHG that humans emit annually</u></a><u>, or approximately the same amount of GHGs as produced by </u><a href=\"https://ourworldindata.org/grapher/total-ghg-emissions?tab=table&amp;country=~NLD\"><u>Venezuela or the Netherlands</u></a><u>.</u></p><h2>Is it healthy to put a dog on a vegan or ostrovegan diet?</h2><p>This is my good friend Nico, who, along with his person and myself, follows an ostrovegan diet.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zihL7a4xbTnCmuL2L/jrgkfdbynigbjeongkal\"></p><p><a href=\"https://docs.google.com/spreadsheets/d/1iyBdG8JNYJbEWnjZPX_H_b62hQfSupK4pv0u5-B0mr4/edit?usp=sharing\"><u>Tab 2 of my accompanying spreadsheet</u></a> provides an overview of Nico\u2019s diet. Nico weighs about 21 pounds.&nbsp;</p><p>When Nico\u2019s person adopted him, they arranged a consultation with a professor of veterinary science at Cornell to ask if a vegan diet was healthy for dogs. The professor said that it was totally fine, that they should be careful about giving Nico a well-balanced diet. That conversation cost about $100. Two years later, Nico is a healthy, happy pup.&nbsp;</p><p>&nbsp;This professor is also an animal nutritionist with a PhD in &nbsp;pharmacology who has a research lab and works with canine athletes. He mentioned that most standard vets receive little if any nutrition education. He said that dogs are extremely flexible creatures with unusually plastic nutritional needs. (This is probably why they live pretty much all over the world.) He claimed that any vet who says they can't thrive without meat doesn't know what they're talking about; vegan dogs on appropriate diets should have no health or longevity issues. He did say all dog guardians should rotate foods to prevent any nutritional deficiencies from developing. He recommends only food that is produced in accordance with&nbsp;<a href=\"https://www.aafco.org/consumers/understanding-pet-food/selecting-the-right-pet-food/\"><u>AAFCO guidelines</u></a>. He prefers food with added&nbsp;<a href=\"https://www.webmd.com/vitamins/ai/ingredientmono-42/methionine\"><u>methionine</u></a> and&nbsp;<a href=\"https://en.wikipedia.org/wiki/Taurine\"><u>taurine</u></a>, and advised that young and active dogs need food with a higher percentage of protein than older dogs do. He also thinks that commercial dog foods tend to be too low in fat, and suggests adding a bit of oil to the dog's food.</p><p><a href=\"https://Leah J Roberts, Patricia M Oba, Kelly S Swanson\">Roberts, Oba, and Swanson (2023)</a> test the effects of \"mildly cooked human-grade vegan dog foods\" on \"blood metabolites and fecal microbiota, characteristics, and metabolites\" in 12 adult, female beagles, and found that &nbsp;\"the mildly cooked human-grade vegan dog foods tested in this study performed well, resulting in desirable fecal characteristics, ATTD, and serum chemistries...[and] positive changes to serum lipids and fecal metabolites, and interesting changes to the fecal microbial community.\" This is obviously not a slam-dunk result -- twelve dogs of just one breed -- &nbsp;but our prior here, I think, should be that vegan diets are safe for dogs, as they are safe for us.</p><p>Vegan dog diets are likely to be more expensive than meat-based options, and dogs might be less happy with their food. On the other hand, dogs probably don\u2019t like being neutered, but we generally do it anyway because we think the benefits outweigh the costs (whether this is true or not is a&nbsp;<a href=\"https://mattlakeman.org/2020/03/21/against-dog-ownership/\"><u>fight for</u></a>&nbsp;<a href=\"https://www.vox.com/future-perfect/2023/4/11/23673393/pets-dogs-cats-animal-welfare-boredom\"><u>another day</u></a><u>).</u>&nbsp;Incorporating the needs of non-pet animals into this calculus seems a manageable leap from there.&nbsp;</p><h3>The case for supplementing with with bivalves</h3><p>Ostroveganism is a vegan diet with some bivalves added in \u2014 oysters, mussels, and some clams (the ones that don\u2019t move). These bivalves lack&nbsp;<a href=\"https://www.theguardian.com/food/2019/sep/27/are-oysters-vegan-kitchen-aide\"><u>central nervous systems</u></a>, so they probably don\u2019t suffer in any meaningful sense; farming them is&nbsp;<a href=\"https://www.outsideonline.com/food/oyster-farming-environment/\"><u>relatively good for the environment</u></a>; and they help provide some nutrients that are otherwise hard for vegans to get (<a href=\"https://theproof.com/eating-oysters-and-mussels-as-a-vegan/\"><u>B12 and iron mainly</u></a>). <a href=\"https://forum.effectivealtruism.org/topics/peter-singer\">Peter Singer</a>&nbsp;<u>follows </u><a href=\"https://english.hani.co.kr/arti/english_edition/e_international/1054101.html\"><u>this diet</u></a><u>; s</u>ee&nbsp;<a href=\"https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=2174&amp;context=bts\"><i><u>Dialogues on Ethical Vegetarianism</u></i></a><i>,</i> pp. 107-109, for more discussion.&nbsp;</p><p>Nico\u2019s person believes that his dried mussels keep his fur nice and sleek, and he seems to really like them.</p><h2>I\u2019m convinced. How can I help?</h2><p>First and most obviously, if you have a dog, switch them over to a vegan diet, or get them most of the way there.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"3\" data-footnote-id=\"4bm9cbmf2fg\" role=\"doc-noteref\" id=\"fnref4bm9cbmf2fg\"><sup><a href=\"#fn4bm9cbmf2fg\">[3]</a></sup></span>&nbsp;My friend Charles, who is a dog, took well to&nbsp;<a href=\"https://wildearth.com/\"><u>Wild Earth products</u></a>. The dogs I walk at <a href=\"https://www.instagram.com/nyanimalrescue/\">a local shelter</a> seem to like&nbsp;<a href=\"https://www.amazon.com/gp/product/B07VBNLDZG/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1\"><u>ETTA SAYS! Peanut butter treats</u></a>.</p><p>I expect a full conversion to take some trial and error, but I think that most dogs can find a non-meat diet that meets their needs and that they\u2019re happy with.</p><p>Second, this seems a neglected FoodTech space.<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"4\" data-footnote-id=\"he2sg6l0rlg\" role=\"doc-noteref\" id=\"fnrefhe2sg6l0rlg\"><sup><a href=\"#fnhe2sg6l0rlg\">[4]</a></sup></span>&nbsp;We have some&nbsp;<a href=\"https://wildearth.com/pages/vegan-dog-food\"><u>vegan dog food brands</u></a>, but the modern fancy alternatives tend to be pretty&nbsp;<a href=\"https://www.thefarmersdog.com/digest/the-farmers-dog-cost-and-value/\"><u>meat-based</u></a>. While humans make fine-grained distinctions and object loudly when meals don\u2019t meet their cultural expectations, dogs are generally happy to eat, period. I think there\u2019s room here for more entrepreneurship, in particular with cultured meat and fake meat. <a href=\"https://forum.effectivealtruism.org/posts/AFPXXepkgitbvTtpH/getting-cats-vegan-is-possible-and-imperative\">Ditto for cats</a>.</p><p>Third, evangelize! This can be uncomfortable, but in my experience, a lot of pet owners have never thought about the question at all. My strategy was to buy Charles's&nbsp;person a bag of <a href=\"https://wildearth.com/\"><u>Wild Earth chow</u></a> for Charles to see how he liked it. &nbsp;He ate it as quickly and heartily as he ate anything else.</p><p>Fourth, about this essay and argument in particular, my estimates are crude and could use improvement. If you want to redo them, fix an assumption, or&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1iyBdG8JNYJbEWnjZPX_H_b62hQfSupK4pv0u5-B0mr4/edit?usp=sharing\"><u>clean up my spreadsheet</u></a>, I\u2019d appreciate it!<br>&nbsp;</p><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"b1owcu08q6n\" role=\"doc-endnote\" id=\"fnb1owcu08q6n\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"b1owcu08q6n\"><sup><strong><a href=\"#fnrefb1owcu08q6n\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;My intuition is that the median dog is smaller than 35 lbs, but though the smallest dogs might be&nbsp;<a href=\"https://en.wikipedia.org/wiki/Papillon_dog\"><u>8-10 pounds</u></a>, the largest&nbsp;<a href=\"https://en.wikipedia.org/wiki/Newfoundland_dog\"><u>are the size of small bears</u></a>, so the distribution is probably skewed right.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"72set5ni93y\" role=\"doc-endnote\" id=\"fn72set5ni93y\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"72set5ni93y\"><sup><strong><a href=\"#fnref72set5ni93y\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;For context, the average American eats about&nbsp;<a href=\"https://ourworldindata.org/grapher/daily-meat-consumption-per-person\"><u>279 lbs of meat per year</u></a>, (excluding fish) per year, so about 95 billion pounds/year in total for the entire country. Is it plausible that the average pet dog eats about as much meat as the average American human? I actually think so. People probably eat more calories on average but thinking about your own diet and that of people around you, you probably eat and drink a lot more processed carbohydrates, alcohol, salads, nut butters and vegetable oils, to name a few. Dogs mostly eat meat and grains.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"3\" data-footnote-id=\"4bm9cbmf2fg\" role=\"doc-endnote\" id=\"fn4bm9cbmf2fg\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"4bm9cbmf2fg\"><sup><strong><a href=\"#fnref4bm9cbmf2fg\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>&nbsp;This essay took me about 3 hours to draft, 3 to edit, and 1 to make the accompanying spreadsheet. If I convince one person to get their dog on a vegan diet, I think it will have been time well spent.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"4\" data-footnote-id=\"he2sg6l0rlg\" role=\"doc-endnote\" id=\"fnhe2sg6l0rlg\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"he2sg6l0rlg\"><sup><strong><a href=\"#fnrefhe2sg6l0rlg\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p><a href=\"https://forum.effectivealtruism.org/users/ben_west\">Ben West</a> and &nbsp;<a href=\"https://forum.effectivealtruism.org/users/damien-clarkson-1\">Damien Clarkson</a> alerted me to three companies working on this: <a href=\"https://www.biocraftpet.com/\">Biocraft</a>, <a href=\"https://www.bondpets.com/\">Bond</a>, and <a href=\"https://thepackpet.com/\">The Pack</a>.</p></div></li></ol>", "user": {"username": "setgree"}}, {"_id": "Kt4wLHXLh8PBAyDbe", "title": "Ending Poverty: Today or Forever? Potential Error in GiveDirectly's Rational Animations Video", "postedAt": "2023-11-06T12:01:22.282Z", "htmlBody": "<p>Epistemic status: as an Economics student who reads a fair amount of dev econ, this might be one of the only things in the world I'm actually ~qualified for. 85% confident that the main claim of this post (\"GiveDirectly has presented no strong evidence for their claim that the costs of ending extreme poverty will rapidly &amp; significantly decrease\") is true.</p><p>Disclaimer: I \u2764\ufe0f GiveDirectly and think they're doing fantastic work!</p><p>&nbsp;</p><p>Recently, GiveDirectly collaborated with Rational Animations to make this YouTube video:</p><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=2DUlYQTrsOs&amp;t=647s\"><div><iframe src=\"https://www.youtube.com/embed/2DUlYQTrsOs\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>The aim of the video is in its title: showing that extreme poverty can be eradicated by directly giving money to the world's poorest, through organizations like GiveDirectly.</p><p>I think that the evidence presented in the video definitively shows that giving all the extremely poor people in the world money for a year can end extreme poverty for that year. This is true almost by definition, but I'm genuinely glad that a bunch of researchers decided to check anyway. There's always a chance of unforeseen second order effects, like maybe all the people getting the money would just spend it all on drinks and alcohol (<a href=\"https://www.journals.uchicago.edu/doi/full/10.1086/689575\">almost certainly not</a>) or it would cause huge inflation (<a href=\"https://onlinelibrary.wiley.com/doi/full/10.3982/ECTA17945\">nope</a>, though really you could guess that one with Econ 101).</p><p>Our friends estimate the cost at about $258 billion dollars to end extreme poverty for a year, and point out that this is a small portion of yearly philanthropic spending or rich government's budgets. They're right about the rich countries' budgets (no longer sure about how large a part this is of philanthropic spending). It would be good to just give all the extremely poor people some money every year so they would no longer be extremely poor.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefo8zpx1s9oj\"><sup><a href=\"#fno8zpx1s9oj\">[1]</a></sup></span></p><p>Where the video loses me, though, is when they make a very strong claim with huge implications based on minimal evidence. This starts at <a href=\"https://youtu.be/2DUlYQTrsOs?t=639\">10:39</a> in the video, but I've transcribed it for you here:</p><blockquote><p>We also know that cash transfers improve recipients' lives immensely. But what would be the impact on recipients' neighbors and the economy as a whole? A 2022 study led by Dennis Egger found that every $1,000 of cash given actually has a total economic effect of $2,500, thanks to \"spillover\" effects growing the local economy, as recipients spent more money at their neighbors' businesses, those businesses spent money, and so forth. Not only did recipients' incomes increase, their neighbors' incomes also increased by 18 months later. Even neighboring villages without any recipients saw increased incomes, which could have been from a 'spillover' effect as well. These effects mean our cash transfers will go further, and we may find that we've reached our goal of ending extreme poverty sooner - and for less money - than we would otherwise expect. <strong>The research suggests that the $200 to $300 billion figure we'd need to give for the first year will decrease every year thereafter</strong> <i>[animation of a stack of dollar bills, halved each year] </i>as the economies of entire regions and countries grow and lift their poorest residents out of extreme poverty. <strong>[emphasis mine]</strong></p></blockquote><p>Okay. There is an absolutely massive difference in cost between \"$258 billion the first year, progressively less each year, maybe after X years no cost at all\" and \"$258 billion every year, eternally\". One of these is a cost the rich world may be willing to bear, out of solidarity and self-interest and even just the wish to be on the right side of history. The other is just a pipe dream for teary-eyed optimists like us.</p><p>If a lot is riding on the answer to an empirical question, it would be wise to reason well about it before making strong claims one way or the other. But this is just a popularization video, perhaps it shouldn't be held to such high standards? Well, <a href=\"https://forum.effectivealtruism.org/posts/NxCeCpRqF4pkWQKkw/ending-extreme-poverty-through-cash-transfers-should-be-a?commentId=FiWwkjQFNGZy99cz9\">in another comment on this forum</a>, GiveDirectly has linked to this video as their \"explained in detail\" source for the claim, which they also make in e.g. <a href=\"https://forum.effectivealtruism.org/posts/NxCeCpRqF4pkWQKkw/ending-extreme-poverty-through-cash-transfers-should-be-a#comments\">this post</a>. There is, as far as I can tell, no other analysis hidden in a sidebar somewhere on their website (though if you do find one, please inform me ASAP!) This video is what we have to work with, so it's what I'll be critiquing in this post.</p><p>The study they're referencing to support their claim, <a href=\"https://onlinelibrary.wiley.com/doi/full/10.3982/ECTA17945\">Egger et al. (2022)</a>, is very well designed and has no serious flaws as far as I can tell, but it plainly isn't evidence for the claim they're making here. So what <i>does</i> the study say? Well, the video describes its contents correctly (just takes a much stronger conclusion from it than the authors do). For every dollar given, another 2.5 dollars are spent in the local economy. This takes the form of an increase in consumption by non-recipient households, almost equal to the consumption increase of recipients (!), at about 335 USD PPP to the recipients households' $339. They also show that this consumption increase is caused by higher earned income, rather than dissaving (spending money you'd saved up before), which is a good sign.</p><p>Why these spillover effects, though? The authors think what's happening is there's a lot of <i><strong>slack</strong></i> in the local economy. Small-scale manufacturers find themselves waiting for customers or eating and resting a lot of the time, due to a lack of demand. Often 'integer constraints are binding', which means e.g. there's too much demand for one person to handle, but too little to keep two people busy, so now one person spends a lot of time doing nothing. Generally, low scale due to few customers (due to low ability to pay, because everyone's poor) causes a lot of that sort of inefficiency (see <a href=\"https://onlinelibrary.wiley.com/doi/full/10.3982/ECTA18773\">Bassi et al. 2022</a>). &nbsp;Because more people had the resources to pay for stuff, the workers who were otherwise just twiddling their thumbs got to do more work. There was excess capacity, capital or labor sitting around doing nothing, and now it's doing something.</p><p>That's a genuine welfare and efficiency improvement. However,&nbsp;</p><ol><li>It's a one-time effect. Demand goes up -&gt; slack disappears. That's why \"slack\" is such a useful word to describe the phenomenon - increasing demand pulls the economy taut, like a rope. There's no slack left, afterwards.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe7jyt429k79\"><sup><a href=\"#fne7jyt429k79\">[2]</a></sup></span>&nbsp;&nbsp;</li><li>Once the donations stop rolling in, there'll be nobody pulling the rope, and the economy will go slack again. This is because according to our study, most (73%) of the money donated is being consumed, which is exactly the cause of aforementioned spillovers, but also means it <i>doesn't stick around</i>. The resources have been consumed. So slowly decreasing the amount of money donated just means slowly letting the spillover effects disappear as well.</li></ol><p>So the argument given in the video falls flat - or at least, requires a lot more evidence than presented. There is, however, a more conventional argument for this kind of claim which is not made explicitly in the video, but bears looking at anyway.</p><p>I am, of course, talking about the <i><strong>poverty trap</strong></i><strong>. </strong>A poverty trap is a situation where someone could increase their future income significantly if they had access to more money or capital right now, but they don't, so instead they stay stuck in poverty.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefh9df9ogu7zh\"><sup><a href=\"#fnh9df9ogu7zh\">[3]</a></sup></span>&nbsp;Some typical examples would be:</p><ul><li>An entrepreneur wants to buy a machine that would make her business much more efficient and so pay back its costs quickly, but she lacks capital, so she can't buy the machine.</li><li>A smart kid in a poor country wants to go to high school, but his parents can't afford to send him, so instead he earns much less at a menial job.</li><li>A day laborer doesn't earn enough money to buy nutritious food. Due to malnutrition, he can't work as hard or often as he'd like, which keeps his income low, which is why he doesn't have enough money for good food.</li></ul><p>If there are a lot of these kinds of cases, then we could expect a large injection of money to push these people into a new, higher-income equilibrium, which would then maintain itself without needing more outside money. This would be an excellent case for GiveDirectly's claim. But how common are poverty traps really?</p><p>Let's just say it's complicated. Development economists are strongly divided on this issue, with some (Sachs) believing that everything is poverty traps, others (Easterly, Moyo) saying that there are very few in practice, and a third camp (Duflo, Banerjee) doing the whole \"both sides are partially right, we should just look at the evidence\" thing, which is entirely correct and appropriate but still somehow annoying. Anyway, I won't force a whole literature review down your throats. Let's do some quick tests instead.</p><p>Microfinance programs, the development economics hype of the 2000s, are private-market (sometimes subsidized) programs to lend money to the world's poorest, based on the premise that they're stuck in poverty traps and so they could simply pay back the loans after using the money to gain a higher income. Results were <a href=\"chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://documents1.worldbank.org/curated/en/588931467993754857/pdf/Microfinance-a-critical-literature-survey.pdf\">mixed</a>, with limited effects on the micro-level (the people actually borrowing the money) and macro-level effects, as always, very hard to identify. But micro-finance's failure to live up to the hype might be due to the other issues with loaning money in poor countries, like weak contract enforcement and lack of information about borrowers, which often led to interest rates around 60%/year, unheard of in Western countries. Perhaps simply giving money to the poor can get around this?</p><p>A simple way of checking is to see if the people given money are still doing better later on, once they're no longer receiving any money. Earlier in the video, a few such studies are mentioned. <a href=\"https://academic.oup.com/qje/article/129/2/697/1866610\">Blattman, Fiala, Martinez (2014)</a> found large positive impacts on work (+17%) and earnings (+38%) four years later of a big one-time cash transfer (combined with help for planning to start a business) to young people interested in becoming artisans. The same authors' followup <a href=\"https://www.aeaweb.org/articles?id=10.1257/aeri.20190224\">(Blattman, Fiala, Martinez 2020)</a>, however, found that these effects had ~entirely disappeared nine years after the transfer. <a href=\"https://g2lm-lic.iza.org/publications/wp/the-very-long-run-impacts-of-cash-grants-during-a-crisis/\">Fiala et al. (2022)</a> returns to declare triumph for cash transfers after all, saying that these same recipients who were indistinguishable from the control group after nine years were suddenly doing better-than-controls again after COVID-19 hit, perhaps due to larger durable asset stocks. Not implausible, but I would note that p = 0.08, which is already suspicious but especially so when you're doing studies on the same population every four or so years without statistically (e.g. Bonferroni) correcting for that. Also, note that this was not a pure randomized cash transfer program, and it's impossible to separate the effects of the help with business planning from the cash transfers themselves.</p><h3>Conclusion</h3><p>GiveDirectly made the claim that if we were to give money to all the world's poorest, this would not only lift them out of poverty in that year, but strengthen the local economy, lowering the cost of poverty reduction in future years by a lot every year, until poverty is eventually eliminated (as implied by the video's title). This is a claim with huge implications and in my opinion, the evidence GiveDirectly brings in the video is insufficient to support it. Their main argument, that of economic slack, does not support an effect of the size or type claimed, and the empirical support is weak. A side argument not explicitly mentioned but implied, that of poverty traps, is deeply controversial in the literature and the studies named in the video don't provide strong support for the existence of long-term poverty traps, or at least those of the type that could be solved with cash transfers. And none of those studies at all support the proposed long term effects on non-recipients, which are a fairly integral part of the argument.</p><p>So basically: I think GiveDirectly is doing amazing work and I didn't intend to be very harsh on them, but like any organization with a mission, they have incentives to overstate their (potential) impact, and in this case I think they did. Maybe the effect described in the video does exist! I certainly think it's worth finding out. But making strong claims about such things requires strong evidence, and I haven't seen it yet.</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fno8zpx1s9oj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefo8zpx1s9oj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;They would still be in normal poverty, which is also bad, but less bad than extreme poverty.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne7jyt429k79\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe7jyt429k79\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There will always be some, at the edges of the economy. Night store owners spend little time interacting with customers and lots on the phone (to the eternal aggravation of the few customers who do enter). Desk-job-havers and night security guards alike also spend a lot of time surfing the web, but that's less slack and more of a principal-agent problem: they could be doing productive work, they're just not incentivized to.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnh9df9ogu7zh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefh9df9ogu7zh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Debatably, slack could be considered a \"regional-level poverty trap\".</p></div></li></ol>", "user": {"username": "Alexander de Vries"}}, {"_id": "f5wxYKFiJwjjRvk4Q", "title": "20+ tips, tricks, lessons and thoughts on hosting hackathons", "postedAt": "2023-11-06T10:59:12.717Z", "htmlBody": "<p><i>Epistemic status: Based on one relatively new AIS group's experience, so take everything with a grain of salt!</i></p><p><i>(Crossposted on </i><a href=\"https://www.lesswrong.com/posts/Abg5wRuBZrbkXZBFj/tips-tricks-lessons-and-thoughts-on-hosting-hackathons\"><i>the LW forum</i></a><i>.)</i></p><p>We hosted a couple of hackathons with Alignment Jams so far and found it a great way to engage people who have previously not been exposed to AI Safety. I\u2019m writing down (partly for myself) some of the tips and tricks I learned during these. Please note that I\u2019m using the word&nbsp;<strong>hosting</strong> a hackathon, as opposed to&nbsp;<strong>organising</strong> one, as the lion\u2019s share of work is done by the amazing team at&nbsp;<a href=\"https://apartresearch.com/\"><u>Apart Research</u></a>/<a href=\"https://alignmentjam.com/\"><u>AlignmentJam</u></a>, who get the speakers, and provide funding and mentoring. That said, hosting a hackathon can still be plenty of work, especially if you are doing it for the first time, so hopefully, this post will help with some of that.</p><p>Another caveat is that our AIS group is relatively new and we were mostly using these hackathons for outreach towards students unfamiliar with AI Safety. I think some of the tips will still be useful for more established groups as well, just keep in mind that our theory of change might be different than that of other groups.</p><p>Here is my list of \u201ctips and tricks,\u201d vaguely organised around different topics:</p><h2><br>Relating to the schedule:</h2><h3>Have a specific schedule in your advertisement/signup form</h3><p>This is more of a hunch, but it\u2019s reasonable to think that especially for people who haven\u2019t interacted with your group before, they will worried along the lines of \u201cWhat the hell I am going to do there for 40+ hours?\u201d. My hope is that having a clear schedule (you don\u2019t have to closely stick to depending on the vibe etc. once you are there) might be helpful with this. See our past schedule&nbsp;<a href=\"https://docs.google.com/forms/d/17GCKpWEg7aiqaBXzuOx3gqqHdCPzX7868qfsad3jfPM/edit?pli=1\"><u>here</u></a> (including the signup form), which you are free to copy and adapt for future hackathons if you want to.</p><h3>Set up milestones for your local site</h3><p>Similarly to the point about schedule, I think it might be useful (for less experienced groups especially) to set some shorter-term milestones. Having +40 hours ahead of you to work can be daunting, so sometimes people don\u2019t know where to start. Some milestones that might be useful: (You don\u2019t have to use all of them and I would be pretty flexible about this, e.g., a group might prefer to not present their work towards the end because they want to work until the last minute before submission.)&nbsp;</p><ol><li>Spend some time looking at the starting resources and come up with 3-5 project ideas</li><li>Decide which one to go with&nbsp;</li><li>Formulate a project proposal&nbsp;</li><li>&nbsp;Present it to the local organisers / other attendees for feedback&nbsp;</li><li>Work on it&nbsp;</li><li>Have a \u201chalf-time show\u201d - where groups present their current progress and their plans for the rest of the hackathon&nbsp;</li><li>Present your work locally at the end</li></ol><h3>Be there ~30 minutes before the start each day</h3><p>At the very beginning, you want to make sure to set everything up by the official starting time, as some attendees will come exactly on time or slightly earlier. Most people will probably not show up before 10 am though.</p><p>Also, make sure you coordinate with the other organisers about what time and how long they are available for a given day, I recommend using Excel or when2meet!</p><h3><br>Check-in with attendees about when they plan to arrive/leave in the next day</h3><p>If you have a hackathon starting on Friday, ask people in the evening when/if they intend to show up the next day. In some cases we had one member of the group show up early, but the others only joined much later or not at all for the given day. Checking in also helps with deciding how much food to get. In the afternoon, it\u2019s also good to check for how long they are planning to stay, as one time we ended up ordering food just before a couple of people left.</p><h2>On Supporting attendees:</h2><h3><br>Most people will be shy about asking questions on Discord</h3><p>One of the wonderful things about Alignment Jams is that you don\u2019t need to have a strong technical/policy background to be able to host the hackathon, after all, that is what the Discord chat\u2019s #questions section is for. Will new people who have questions use it? Nope! I think having semi-regular check-ins (perhaps twice a day + during lunch?) with each group (and maybe with individual attendees as well if you can) about their process, how they are feeling etc. is very useful. If they are new to AIS, you might be able to answer their question or direct them to the right resources even without knowing too much yourself. If their issue is more complicated, you can help them formulate it in a question and post it in the Discord chat for the international organisers/mentors.</p><h3>Be mindful of group dynamics</h3><p>You want to make sure that everyone is feeling psychologically safe in their group, which might be harder if this is their first event and/or they are shy/anxious.</p><p>Some failure modes to keep in mind are:&nbsp;</p><p><strong>1) Too big of a knowledge gap between group members without the more experienced members realising, so the least knowledgeable member(s) feel(s) left out&nbsp;</strong></p><p><br>My suggested solution: In the&nbsp;<a href=\"https://docs.google.com/forms/d/17GCKpWEg7aiqaBXzuOx3gqqHdCPzX7868qfsad3jfPM/edit?pli=1\"><u>signup form</u></a> I ask people what kind of group they would like to be in, this way you know if someone wants to be with other newcomers. Alternatively, some might specifically ask to be with more experienced attendees, which is great because they can learn more and even before the hackathon starts the experience is framed more as \u201cI\u2019m going to learn so much from others\u201d as opposed to \u201cOh wow I don\u2019t know anything compared to my group members)<br>&nbsp;</p><p><strong>2) One member dominating the group discussions</strong></p><p>Usually, a leader emerges from the groups, but you want to make sure that everyone is happy with that person, and that it's not just someone not reading the room well and dominating the group discussion</p><p>My suggested solution: Have more regular check-ins with groups that you are not sure are functioning well in this regard, including possibly 1-1s to see how you can support attendees. Ideally, you would also have a person in each group who is at least moderately familiar with AIS but is also good at navigating these dynamics, so they can support newer attendees.</p><h3>Direct people towards the right resources</h3><p>Alignment Jam always offers some amazing starting resources for people. I encourage you to remind everyone about these after the intro talk is over, as people tend to forget/not find them. Another great resource is just directing them to the LW/EA forums (perhaps helping them with a few search keywords or directing them to a topic so they can read related posts.&nbsp;</p><p>I think exploring the EA/LW forum is especially useful, as there is a lot of distilled content that is more accessible and shorter than scientific papers.</p><p>If someone is very new, I also encourage them to binge-watch a couple of Robert Miles videos first.</p><h2><br>Logistics:</h2><h3>It\u2019s kind of hard to know how many people will show up on the day</h3><p>I mean this mostly for people who are not yet in your network and the hackathon would be the first event by which they interact with your group. For reference, for the first hackathon I ran we had ~13 signups, with ~10 people showing up and ~7 committing for most of the hackathon. For the second one, we had a whopping ~45 applications, but only about half of those people showed up, and even less committed to the whole thing. Understandably this surprised us as the first one had a much higher \u201csign-up to turn-up\u201d conversion ratio.</p><p><br>One thing you can do to ask people to confirm their attendance (see this&nbsp;<a href=\"https://docs.google.com/forms/d/1H9t2wXbkOSW3R0i-d39awdxsKFE1OqyEtLcuPlLIjNU/edit\"><u>past form</u></a> I used)&nbsp; which should give you a more up-to-date sense of their availability. If your hackathon starts on Friday, I recommend sending out the email asking for confirmation on Wednesday, with a deadline of Thursday afternoon/evening, as when I did it sooner a lot of people confirmed their attendance and didn\u2019t show up.</p><h3>Think ahead about how you are going to take care of the food<br>&nbsp;</h3><p>Plan ahead with from which place you are going to order and what, so you can serve a variety of delicious vegan food. I really didn\u2019t expect this to be an issue at first because there are plenty of vegan places in Budapest, however some of them only open late in the morning - eg. if they open at 10, you will be happy if the order gets to you by 11, which is not ideal if you have people arriving between 9-10 am. Subway was a safe choice for us as they open in the morning and have vegan options. Other fast food places should be good too, although in Hungary they have limited vegan options (I imagine they have more in Western countries, but less in second and third-world countries which is something to keep in mind)<br>&nbsp;</p><p>To save on food costs I would recommend trying to get pastries from a nearby bakery.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpvxzg15vlp\"><sup><a href=\"#fnpvxzg15vlp\">[1]</a></sup></span>&nbsp;For clarification, Alignment Jam does not insist (although they probably prefer) that you serve vegan food only, but I think unless it\u2019s very costly for you to do so I think you should. When new people ask why the food is vegan, I usually say that it\u2019s because the hackathon is funded by Open Philanthropy who also works on animal welfare, so I would feel hypocritical to spend their money on animal products.&nbsp;</p><p><br>For lunch, I think it\u2019s fine to order \u201cproper food\u201d, however, if you are going to go with pizza I recommend buying ones that you or the organisers personally tried before and are great. Vegan pizza can be terrible and you don\u2019t want attendees to remember the event as \u201cthat one time I tried vegan pizza and it was terrible\u201d!</p><p>I also want to do a better job of saving money on dinner. Again, if you are very constrained on time I think Apart Research is fine with you just ordering food (You have a $75 per person budget after all), but saving money is always nice. Some cheaper options we want to try out in the future are making hummus sandwiches with lots of veggies, wraps (if you can microwave your meat alternative), peanut butter sandwiches, vegan grilled cheese sandwiches, etc.</p><p>Have a premade ordering list of the things you will need to buy / order<br><br>...So that you don\u2019t have to think on the spot and are less likely to forget 1-2 essential items.</p><p>Some things we had/wish we had + GPT\u2019s opinion on what we need for a hackathon:</p><p>Fruits<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref66jzm062l2o\"><sup><a href=\"#fn66jzm062l2o\">[2]</a></sup></span>, chips, coffee, tea, soft drinks<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefum73q1xe7bs\"><sup><a href=\"#fnum73q1xe7bs\">[3]</a></sup></span>, fruit juice, water, chocolate, chips, trash bags, headache pills, hand sanitiser, paper towels, wet wipes, nuts and seeds, crackers veggies+hummus, energy bars, covid tests (maybe not anymore?), name tags</p><p>I think the fastest way to take care of supplies is to order from a supermarket for the start of the hackathon. Just note that the order might be late and they might not be able to bring a few things, so if something is essential (e.g., if you think name tags are very important) then I would get them separately.</p><h3>Have a premade Feedback form<br>&nbsp;</h3><p>With all the things going on, this is just so easy to forget, or at least I managed to do it twice! Here is a&nbsp;<a href=\"https://docs.google.com/forms/d/1BEMO_iibx1YXItfTxc7iczUzW4gyHvSff-S53WKBcgc/edit\"><u>template</u></a> that you can use, I recommend making a QR code for the link and filling it out as part of the closing session (similarly to how it is done at EA conferences)</p><h2>Venue related:</h2><h3>Book rooms in advance</h3><p>Ideally, you can get a room for free at your university. If not, well, booking places for the weekend can be tricky, so I recommend doing it well in advance if you can. Of course, it is hard to predict how many people you will have (see previous point), which makes it hard to know how big of a room you will need. Eh, so is life.</p><h3>Book a slightly bigger venue</h3><p>With the caveats above, I would generally recommend you have a slightly bigger room so you are not jam-packed. This is because our groups differed quite a lot in how much discussion they had during their work, as well as how loud these discussions were. Having a larger room will make sure groups are not bothering each other. What\u2019s even better is if you have an extra room that particularly motivated (or loud) groups can use, so they are less distracted or distracting. Make sure to have the meals together though!</p><h3>Have more than one organiser on site if you can</h3><p>To be clear, one person is fine, especially if you don\u2019t have a large group. The reason I say two is preferable is because if something unexpected comes up, then it is nice to have additional \u201chands on deck\u201d. For example, one time our food order was +1 hour late, so I had to go and pick it up myself - and it was nice that someone else was available to help attendees on site.</p><h3>Have a spare laptop that you can use for presentations etc.</h3><p>Another reason it\u2019s nice to have +1 organiser on site! Believe it or not, but one time my laptop decided that it no longer had Bluetooth (?!), so I wasn\u2019t able to connect to our Bluetooth speaker and had to use someone else\u2019s laptop. Stuff like this happens, you never know!</p><h3>Is your speaker loud enough?</h3><p>Depending on the size of the room you booked, a small Bluetooth speaker I previously used wasn\u2019t loud enough when we had a bigger group - so just keep this in mind.</p><h3>Make sure wifi is strong enough at the venue</h3><p>For obvious reasons. If it\u2019s not good enough, you can rent a portable Wi-Fi hotspot relatively cheaply for a few days.</p><h2>On Theory of change (ToC):</h2><p>(Again with the caveat that this applies more if you are organising for people who are newer to AI Safety.)</p><h3>Your impact will come from getting people excited, and likely not the specific project that they end up doing</h3><p><br>I think much of the impact of your event will come from getting a couple of the most engaged attendees exposed to AI Safety and then diving deep afterwards. For this reason, I think it is okay if their first project ends up being somewhat naive and not exactly on point. Of course, you want to give honest feedback and nudge them in the right direction, but I would also recommend keeping some&nbsp;<a href=\"https://www.youtube.com/watch?v=g-RJ5CDQLNM&amp;t=410s\"><u>considerations around naive effective altruism</u></a> in mind.</p><h3><br>Have AIS intro books to lend/give to participants at the end</h3><p>Recently I increased my bar for giving away books (eg. at tabling), but I think if someone takes the hackathon seriously it makes sense to offer them either a free AIS book or the opportunity to borrow it, depending on how freely you want to give books away.</p><h3>Follow up with promising attendees later</h3><p>Let\u2019s say people attended your hackathon, it was a blast. This means everyone will sign up for AGISF the next time you are running it, right? Wrong! Okay, hopefully at least some of them will, but the point I\u2019m trying to get across is that you shouldn\u2019t expect this to be the default. People are busy!</p><p>I haven\u2019t done an amazing job of this so far, but here are some ways I want to do better in the future:</p><p>-Write a follow-up email 1-2 days after the hackathon offering ways they can get involved with the community</p><p>-Conduct interviews with first-time attendees to gather feedback on how to improve future hackathons (maybe you can have them opt in for this when they confirm their attendance)</p><p>-Nudge people to sign up for your newsletter/mailing list so they are in the loop (perhaps as part of the feedback form, which you could have a separate slot for in the same way EAGx conferences do)</p><h3>Build relationships with other student groups/youth organisations</h3><p>Recently I have been working to build relationships with other youth organisations outside of our network by offering them our AGISF course in a cold email.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref35bpca4hapa\"><sup><a href=\"#fn35bpca4hapa\">[4]</a></sup></span>&nbsp;This had some traction, but I think the reason many are hesitant is because they don\u2019t want to commit to an 8-week course without knowing you.&nbsp;</p><p>To be clear I&nbsp;<strong>haven\u2019t&nbsp;</strong>yet tried cold emailing about the hackathons below, but the next time we run a hackathon I want to do something along the lines of:</p><p>Asking one or more youth orgs if they would be open to help co-organise a hackathon about AI Safety. We can take care of food and Apart Research is providing mentoring for the attendees, but booking rooms is pretty expensive so we are looking for partners who would be able to provide a venue or at least help find a cheap space. I think you want to make it very clear that you don\u2019t expect them to pay for taking part in any way. After all, that\u2019s what your funding is for, although it\u2019s always nice if other parties are willing to chip in. <strong>(Update: Alignment Jam no longer offers virtual cards and for now they recommend organisers to apply for funding individually).</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdqmteqj61b\"><sup><a href=\"#fndqmteqj61b\">[5]</a></sup></span>&nbsp;Offer to have a call in the email so you can discuss the details and get to know each other.</p><h2>Other/Misc:</h2><h3>Charge your (social) battery beforehand</h3><p><br>Given that hackathons are during the weekend and will involve socialising planning, stress, etc., if you just have a regular work-week beforehand you might feel drained (I know I have) by the end. If you are going to attend the whole hackathon as an organiser, I recommend taking a day off during the week (eg. Tuesday or Wednesday) so you can be more present during the weekend. The caveat is that I\u2019m an introvert, so others might have different needs!</p><h3>Log stuff</h3><p>Have a document open for the whole duration of the hackathon to \u201clog stuff\u201d - lessons, mistakes, and observations that you make on the spot. I think this is very useful as it can be hard to recollect everything afterwards. I wrote down a lot of things that I would have otherwise not remembered, and many of the items ended up in this post as a lesson.</p><h1>Please share your thoughts!</h1><p>These are some of the things that came to me, but I would be super excited to hear what others think, especially if:</p><ol><li>You disagree with any of my thoughts</li><li>You want to share some additional tips based on your experience</li><li>You have any questions about hosting hackathons</li></ol><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpvxzg15vlp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpvxzg15vlp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>However again it is a question of how many vegan options they will have</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn66jzm062l2o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref66jzm062l2o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I recommend ones that are easy to eat like bananas or grapes</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnum73q1xe7bs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefum73q1xe7bs\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I recommend getting them in cans so they are less likely to spill, easy to have a wide variety and you can save the leftovers for future hackathons. On the other hand, some people might feel bad about the trash you are producing.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn35bpca4hapa\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref35bpca4hapa\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This essentially&nbsp;entailed me writing them an email offering our course or asking if they were interested in some collaboration.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndqmteqj61b\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdqmteqj61b\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I haven't checked in with them about this, but I would assume they would recommend asking for funding as part of your AIS group's general budget from CEA/Openphil.</p></div></li></ol>", "user": {"username": "gergogaspar"}}, {"_id": "JALJeiqtZJbQfsMeq", "title": "On running a city-wide university group", "postedAt": "2023-11-06T09:43:04.566Z", "htmlBody": "<p><i>Epistemic status: Based on my own and our group\u2019s experience. Please note that the context I\u2019m in (I was the first community builder in the capital of a second-world country) is different than that of many current community builders, so what I\u2019m writing will be somewhat less relevant in some contexts, but still potentially useful for people who live in EA hubs or cities with several already existing university groups as well.</i></p><p>This is the first post in a sequence called <a href=\"https://forum.effectivealtruism.org/s/rsq98ZnMAjfrYFwtq\">Experiments in Local Community Building</a>.</p><h1>How my university group turned into a city-wide university group</h1><p>I was very eager to start my own university group, EA ELTE. After a stressful 2 weeks of marketing, I got ~20 signups from students at ELTE. At the same time, I met a student at a LessWrong meetup who was from a different university. She was interested in learning about EA, so I invited her to participate in the intro fellowship. She invited 3 friends from the same university, so I ended up facilitating 4 groups of students from my university, and one group from this other university. I also ended up organising the socials and the end-of-fellowship meal together, as I didn\u2019t want to, nor have I had the time to organise a separate event for just 4 participants. In the next semester, again I spent most of my time marketing at my own university, but we again had a couple of people trickling in from other places, and of course, we took them in. After that, I just started making a city-wide, fellowship poster in addition to the university-specific one, figuring that we \u201chave never really been a \u201cone university-only group\u201d, and more like a city-wide university group.</p><h1>Here are the pros and cons:</h1><p>Below I will outline how I see the pros and cons of this approach and what I think happened in our case. Note that whether this is preferable for you will to some extent depend on your own theory of how CB should work, so I recommend evaluating each item for yourself. To help with this, I also added what I see the cruxes are. I welcome you to write a comment if your cruxes are different!</p><h2>The PRO(s) of doing this:</h2><h3>1. Bigger pool for program marketing</h3><p>You should be able to get more applicants, as your fellowship is not limited to people from just one university. Budapest is a city of ~2 million people with 5-6 universities that I think could eventually have promising EA groups. With some caveats (see below) I would say the more universities your city has, the better.</p><p>The cruxes of this for me are the following questions:</p><p><strong>Crux 1.1: How soon do your marketing efforts hit&nbsp;<u>diminishing returns</u> for a given university?</strong>&nbsp;</p><p>If spending 20 hours on marketing at a specific university won\u2019t yield a lot more applicants than spending only 10, then you are probably better off shifting your focus to another one, if you can.</p><p>If there is low-hanging (marketing) fruit to pick up at different universities, then you should probably prioritise that.&nbsp;</p><p>For example, I felt really jealous (in a good way!:) ) when I found out that student societies at&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/p5gRvFBGrg8bR4ofc/ea-uw-madison-s-experience-incubating-cause-specific-uni\"><u>UW-Madison</u></a> can email every student about their program. If universities in your city have something similar that you can easily get into, then prioritizing this is probably more useful than emailing individual professors to let you pitch the course before class.</p><p>One thing I would highlight though is that&nbsp;<strong>whenever it is appropriate, you should still market yourself as a university-specific group</strong>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdt3hws8olgl\"><sup><a href=\"#fndt3hws8olgl\">[2]</a></sup></span>&nbsp;This is because students will probably be more excited to join stuff that is specific to their university. I think you will also be more likely to get permission to eg. put out a poster in a dorm as a university-specific student group, than as a city-wide student group.&nbsp;</p><p>On the other hand, you want to make sure you are not misrepresenting what you are offering. I think saying that you are university group A, which is part of a wider network of a [city\u2019s name] university group should be fine. You should try to put applicants from University A in the same discussion groups, but you also want to clearly communicate to people who sign up that this is a city-wide student project, and they might end up in a group with students from other universities.</p><p><strong>Crux 1.2 Can you use social media ads to effectively recruit participants for your program?</strong></p><p>I think your answer to this question should to a large extent determine whether you would want a city-wide university group or not.</p><p>I highly recommend testing social media ads for your context, as this has been one of the best ways our group got diverse, highly motivated applicants for our program. (I plan to post about this in the near future.)</p><p><strong>Crux 1.3: How many places can you cold email?</strong></p><p>If you are going to do outreach at universities you are not connected with, that means you will have to write more cold emails (eg. to ask them to let you put out posters) compared to relying on personal connections (eg. a professor you are on good terms with will let you pitch the fellowship before class). The number of replies you get per hour of work put in should determine whether this is worth it for you to pursue.&nbsp;</p><p>One thing I recommend doing is to try to put some status markers in your cold emails. After all, they don\u2019t really know anything about you, so any information you can show that points you towards being legitimate/prestigious should be useful. Of course, you shouldn\u2019t misrepresent who you are, but luckily you don\u2019t need to, as EA/AIS has plenty of status markers you can use! In my emails, I tend to mention that the course we are running has started at elite universities (and we are using the same curriculum). In our group, the person facilitating most of the AGISF technical courses studied at an elite university and got into SERI MATS, so I mentioned her involvement there as well.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrw8xtcvo9z\"><sup><a href=\"#fnrw8xtcvo9z\">[3]</a></sup></span></p><p><strong>Crux 1.4: Which universities and programs will you get high-quality applicants from?</strong></p><p>There is a lot that can be said about <a href=\"https://forum.effectivealtruism.org/posts/7f3sq7ZHcRsaBBeMD/what-psychological-traits-predict-interest-in-effective\">predictors</a> <a href=\"https://forum.effectivealtruism.org/posts/yZyncMoXjz75eWX4h/yale-ea-s-fellowship-application-scores-were-not-predictive\">of</a> <a href=\"https://forum.effectivealtruism.org/posts/mNRNWkFBZ2K6SHD8a/most-students-who-would-agree-with-ea-ideas-haven-t-heard-of\">engagement</a> with EA,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7r702cyk9ot\"><sup><a href=\"#fn7r702cyk9ot\">[4]</a></sup></span>&nbsp;but I think it is agreed that talent and altruism play a major role. As a rough guide, I would recommend prioritising the top universities in your city (other things being equal), while keeping in mind potential diminishing returns (as discussed above).</p><p>One caveat I will add is that at least in Hungary, there aren\u2019t any selective universities. Instead, it is specific programs that are hard to get into within each university. If you have a similar system, I think that is a positive (but in itself not sufficient) argument for opting more towards a city-wide uni group.</p><h3>2. Inclusivity</h3><p><br>Even if you focus most of your marketing efforts on a specific university, it\u2019s nice if people who randomly find EA from universities without an EA group can join something. You can also buy social media ads, which should attract people from more than one university (and as far as I know you can\u2019t limit them to just one university).&nbsp;</p><h3>3. You can speed up seeding other university groups</h3><p>The way I see this model work is at the beginning, you could get university students from all over the city, and those who become very excited can eventually start a uni-specific group.</p><p>You will be well equipped to support these groups, as you have already \u201cfelt the waters\u201d for a given university and have some sense of what outreach works or doesn't. Just note that currently, CEA\u2019s UGAP program is the main way uni groups are supported, so you want to make sure to coordinate with them.</p><h3>4. You don\u2019t necessarily have to be a university student to start such a group</h3><p>If you already graduated and/or just moved to a new city, you can still do outreach to university students without being affiliated with a specific university. I would recommend recent graduates consider this as an option, as (other things being equal) you are in the best position to support students at university.</p><h2>The CON(s) of doing this:</h2><h3>A) Group cohesion</h3><p>Students might be able to connect more easily with others from the same university, as opposed to students from other universities. Students might also feel safer knowing that the only other people at the event will be others from the same university.</p><p><strong>Crux A.1: How much does it matter which university a student is from?</strong></p><p>I sense that it matters a bit, but this does not outweigh the PROs of having a city-wide university group. I think it is likely that this is more important for students in elite universities.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefw5lxggqqtmk\"><sup><a href=\"#fnw5lxggqqtmk\">[5]</a></sup></span>&nbsp;It is also possible that it is more important for students at the top universities of a given country, but I think likely to a lesser extent)</p><p>Having said that, I would be extremely grateful for you (yes, you!) to share your experience with this, even if it's anecdotal.</p><p><strong>Crux A.2: How scary is it to attend a university-specific social compared to a city-wide student social?</strong></p><p>This is somewhat covered in Crux 1, but I thought it would be worth touching on it separately. Again, I think this matters to some extent. We haven\u2019t been doing a good job of getting people to socials, but I\u2019m not sure how much of that is due to having a city-wide uni group, as I can think of a lot of confounding factors.</p><p>&nbsp;I think for people who seem shy and/or whom you are very excited to have at the social, you should give them a friendly personal invite either way.</p><h3>B) Blurring the line between university and city groups</h3><p>Keeping this in mind is something that I feel I didn\u2019t do an excellent job of. Given that we ended up getting students from several different universities, at first, and (partly because I was the only organiser), I just opted for having city-wide socials, where both professionals and students were invited. I feel like this didn\u2019t work really well, for a couple of reasons.&nbsp;</p><p>Given that in our city we weren\u2019t doing outreach towards non-students, there were only a handful of professionals in our group, who mostly found out of EA on their own several years ago, often through reading LessWrong. This meant that those members were already really familiar with EA/LW ideas and often spent years \u201cin the trenches\u201d debating moral philosophy etc. As a result, the&nbsp;<a href=\"https://www.lesswrong.com/tag/inferential-distance\"><u>inferential distance</u></a> between the two groups was quite big, and newcomers ended up feeling like they didn\u2019t know enough, while the professionals couldn\u2019t enjoy complicated/weird/fun discussions.&nbsp;</p><p>On the other hand, you kind of want your new members to at least eventually meet with older and/or professional members, as they can benefit a lot from connecting with these groups.</p><p><strong>Crux B.1: How accessible is the city group to university students new to EA?</strong></p><p>Perhaps you could have a separate meetup for both students and professionals. Of course, life is not that easy, as you have limited time, and might not have a critical mass for one or the other group.</p><p>Generally, I would be less worried about blurring the lines if the older members of your group are also new to EA, or if experienced members are especially mindful that they are talking to newcomers. If you end up organising joint socials, I recommend reminding people of this at the beginning of the event. I think the best of both worlds can be having separate meetups for students and professionals, but inviting a couple of people from the other groups.<br>&nbsp;</p><h3>C) Potentially Crowding out other organisers</h3><p>If you end up having a city-wide group, it\u2019s really important not to make the impression that you/your team have a monopoly on community building in the city. In terms of motivating people to get involved in community building, whether on a voluntary or paid level, I think it is likely important for people to feel like they own a project or idea. \u201cStarting your own university group\u201d just sounds way cooler than becoming the \u201cXth volunteer for a city-wide uni group\u201d, especially for highly ambitious people.&nbsp;</p><p>To mitigate this, I think you should make sure to reliably display that people can and are encouraged to start university-specific groups and that you are also happy to support them. Specific ways you can do this are&nbsp;</p><ol><li>Encourage people to apply for UGAP.</li><li>If you have a newsletter, in addition to a call for volunteers for your city-wide uni group, you should have a call for university group founders.&nbsp;</li><li>If your country/city has a website that lists eg. Uni group A, Uni group B, and your city-wide uni group, then as an additional slot you could put \u201cstart your own group\u201d, with a call to action.<br>&nbsp;</li></ol><h3>D) Location of your events</h3><p>At some universities, you can get your own office as a student society for free, or at least use get to use some rooms for your fellowships/socials. I think this is cool, and it can save you a lot of money! Having students from other universities attend there could make things a bit more complicated, as university staff might be less excited / more worried about people from outside of the university using their infrastructure. I would recommend checking in about this with the people who are allowing you to use these spaces.</p><p>At my university (ELTE) we weren't able to get an office and the room that I was able to use was not ideal, so we ended up having to pay for room booking outside of the university. On the other hand, we recently figured out that we can use libraries for coworking (some libraries have spaces/floors that allow for semi-quite chatting), and some even have rooms that you can book for free if you are a student - which you can use to hold your fellowships in.</p><h2><br>What did I miss?</h2><p>If you can think of other PROs and CONs, please mention them in the comments! I would be open to editing the post to add your comments!</p><h1>Should you do this?</h1><p>My view is that all things considered, having a [City's name] Universities Group is preferable to one university-specific group if the context is right and you are mindful of failure modes.<br>Even if you are convinced and want to do something similar, I highly recommend you coordinate with CEA and talk your plans through with your mentor. As far as I know, the only groups that do this are us in Budapest and&nbsp;<a href=\"https://www.arcadiaimpact.org/\"><u>the London EA Hub</u></a> has a similar system. This means that we have much less data on how to make this model of CB work, including data about potential pitfalls that we have not encountered so far.</p><h1>The best of both worlds</h1><p>Now that we have a city-wide uni group that is running programs every semester, I would like to start helping seed university-specific groups in the city. This way hopefully we will be able to mitigate the cons while having a strong team in the background that can funnel members to the university groups, help prevent them from going dormant, and help out with operations so they have&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/2YASg3FojAemJwXZ9/community-builders-spend-too-much-time-community-building\"><u>more time for meaningful activities</u></a>. Wish us luck!</p><p><i>Thanks to Annake and Mil\u00e1n for rewieving the draft of this post.</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndqk4ext0nbp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdqk4ext0nbp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>E\u00f6tv\u00f6s Lor\u00e1nd University (ELTE) has ~28k students. It is considered as one of the top universities in Hungary, however, what \"top\" here means is different than in the UK/US. Here top universities can be still very easy to get into (even with a full scholarship), depending on which specific program you are applying to within the university. Some are very competitive, some are less so. This means that for some programs of lower ranking universities, it is harder to get into than many programs of higher ranking universities.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndt3hws8olgl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdt3hws8olgl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For example, if you go to University A, I think you should ask for dormitories at University A as a university-specific student group, and write the posters accordingly too. You should consider having a separate sign-up form for students from University A, either through your website or your social media page.<br>If you don\u2019t go to University B, but you have someone in your group who is excited about EA from University B then you could either cowrite an email with them as as a student society from University B, mentioning that you are part of a network called \u201c[City\u2019s name] universities\u201d.<br>If you don\u2019t go to university C and don\u2019t have anyone you know who is involved in EA from that university, you can email dormitories as \u201c[City\u2019s name] universities\u201d and ask for permission to put out your posters.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrw8xtcvo9z\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrw8xtcvo9z\">^</a></strong></sup></span><div class=\"footnote-content\"><p>One thing I'm also considering is asking permission from EA groups at elite universities to allow us to put out some indication on our website that, well, they exist&nbsp;and we are doing similar stuff to them.&nbsp;This one I feel the iffiest about, as we are not too much in collaboration with them, but I think showing that there are similar groups to us in elite universities would be pretty valuable in cold emails, especially in second and third-worldCrux 1.4: Which universities and programs will you get high-quality applicants from? countries.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7r702cyk9ot\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7r702cyk9ot\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Including questioning whether that's something we should try to optimise for, but this is outside of the scope of this post.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnw5lxggqqtmk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefw5lxggqqtmk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I wouldn't recommend someone to change an established university group at an elite university into a city-wide university group. My sense is that at those locations there would be enough excited people to run a city-wide uni group in addition to the uni-specific groups that already exist. Of course, if people join events from the uni-specific group, that can be a plus!</p></div></li></ol>", "user": {"username": "gergogaspar"}}, {"_id": "PutG2gC5huKK8ktWs", "title": "Scalable And Transferable Black-Box Jailbreaks For Language Models Via Persona Modulation", "postedAt": "2023-11-07T18:00:14.825Z", "htmlBody": "<p><strong>Paper coauthors:</strong> <a href=\"https://www.linkedin.com/in/ACoAAB63nTsBLsxbiGUom3-xG_DLLJvBLPnwn0M\">Rusheb Shah</a>, <a href=\"https://www.linkedin.com/in/ACoAADL_UysBW9lkWi6Q_x8qEjF4k2fk9F2qlls\">Quentin Feuillade--Montixi</a>, <a href=\"https://www.linkedin.com/in/ACoAAAbJQyUBQb6SH312BW8VeCADn5_0s621cY8\">Soroush J. Pour</a>, <a href=\"https://www.linkedin.com/in/ACoAABsh8q8BEXFJeVSYR2-KpZyTvamQpzxtB_Y\">Arush Tagade</a>, <a href=\"https://stephencasper.com/\">Stephen Casper</a>, <a href=\"https://javirando.com/\">Javier Rando</a>. &nbsp;</p><h2>Motivation</h2><p>Our research team was motivated to show that state-of-the-art (SOTA) LLMs like GPT-4 and Claude 2 are not robust to misuse risk and can't be fully aligned to the desires of their creators, posing risk for societal harm. This is despite significant effort by their creators, showing that the current paradigm of pre-training, SFT, and RLHF is not adequate for model robustness.</p><p>We also wanted to explore &amp; share findings around \"persona modulation\"<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefg9absiv30dg\"><sup><a href=\"#fng9absiv30dg\">[1]</a></sup></span>, a technique where the character-impersonation strengths of LLMs are used to steer them in powerful ways.</p><h2>Summary</h2><p>We introduce an automated, low cost way to make transferable, black-box, plain-English jailbreaks for GPT-4, Claude-2, fine-tuned Llama. We elicit a variety of harmful text, including instructions for making meth &amp; bombs.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/o1wce1ongrnihtn9s5lh\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/pqbskrhr7siyv2iaahqr 141w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/komgiu4xrlvl5dyi16vi 221w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/i5pjir0n0b0fvsqsvb4k 301w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/ehk4ieehqrnrensizh1p 381w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/tdpwuyals5kszxf06cpn 461w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/vwaynjafn1po2nsloayp 541w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/fm06tlqlfyynm3o46nbv 621w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/fv2jcnlqsyfjrhmnv2od 701w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/fr5zgajwzmajc9r8rl24 781w\"><br><br>The key is *persona modulation*. We steer the model into adopting a specific personality that will comply with harmful instructions.<br><br>We introduce a way to automate jailbreaks by using one jailbroken model as an assistant for creating new jailbreaks for specific harmful behaviors. It takes our method less than $2 and 10 minutes to develop 15 jailbreak attacks.</p><p><br><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/d9yj4bt7j62s5zyrnme7\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/aofbkqkdg7aluslla7q7 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/swg9esnvytllqjdo2qxl 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/h4xv0kut8naujlyacizn 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/zhwqng1qsshwbjtrq8o8 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/amc7gyhu0wqk5ijqy0lo 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/axwjgadhbgkndtzzkzj0 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/xtauauc6heocincnn9us 1400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/zknjlqulgktpyeoz8con 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/ujcnee8uysvmzelfpelz 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/ekvxfjagzqct39qdd0lh 1928w\"><br>&nbsp;</p><p>Meanwhile, a human-in-the-loop can efficiently make these jailbreaks stronger with minor tweaks. We use this semi-automated approach to quickly get instructions from GPT-4 about how to synthesise meth \ud83e\uddea\ud83d\udc8a.</p><p><br><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/nz5sor0k2rrttyacozlj\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/rzeo8hwxbihvoodmakgi 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/sgexqneanvpxjxukub0u 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/fvww1ndigejxw8ag6ayj 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/q9v9tlbiuunyg1utpred 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/u18khjrzuqod74ofk58s 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/ooecnekfs5urydbmednb 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/ffwpknjpgh2epyrk2c1c 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/aqx1tzucof1a3sr4bpxb 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/gpdcmbwnbjxhtv2n5urd 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PutG2gC5huKK8ktWs/dmuroon7bxghdjyiwxo1 995w\"></p><h2>Abstract</h2><p>Despite efforts to align large language models to produce harmless responses, they are still vulnerable to jailbreak prompts that elicit unrestricted behaviour. In this work, we investigate persona modulation as a black-box jailbreaking method to steer a target model to take on personalities that are willing to comply with harmful instructions. Rather than manually crafting prompts for each persona, we automate the generation of jailbreaks using a language model assistant. We demonstrate a range of harmful completions made possible by persona modulation, including detailed instructions for synthesising methamphetamine, building a bomb, and laundering money. These automated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is 185 times larger than before modulation (0.23%). These prompts also transfer to Claude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%, respectively. Our work reveals yet another vulnerability in commercial large language models and highlights the need for more comprehensive safeguards.</p><h2>Full paper</h2><p>You can find the full paper here on arXiv <i><u>[TODO ADD LINK]</u></i>.</p><h2>Safety and disclosure</h2><ul><li>We have notified the companies whose models we attacked</li><li>We did not release prompts or full attack details</li><li>We are happy to collaborate with researchers working on related safety work - please reach out via correspondence emails in the paper.</li></ul><h2>Acknowledgements</h2><p>Thank you to<a href=\"https://www.linkedin.com/in/ACoAABoZ68IBCbo05CfpBwFX9wMeUSKZ_x-R8Gk\"> Alexander Pan</a> and <a href=\"https://www.linkedin.com/in/ACoAACbEU-gBpXl-vf9XzY7f4Nw24PfG0CKLJiA\">Jason Hoelscher-Obermaier</a> for feedback on early drafts of our paper.</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fng9absiv30dg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefg9absiv30dg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Credit goes to<a href=\"https://www.lesswrong.com/users/quentin-feuillade-montixi?mention=user\"> @Quentin FEUILLADE--MONTIXI</a> for developing the model psychology and prompt engineering techniques that underlie persona modulation. Our research built upon these techniques to automate and scale them as a red-teaming method for jailbreaks.</p></div></li></ol>", "user": {"username": "soroushjp"}}, {"_id": "NrqGyXzvwB2Gqu6XW", "title": "State of the East and Southeast Asian EAcosystem", "postedAt": "2023-11-06T06:55:26.144Z", "htmlBody": "<figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/yje9swprqm7sux5us9gk\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/va9f8lwa4mm0poyympsp 110w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/qeyu9ipyysqrhxgowq2d 220w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/rprns52hqnrhuwm08rre 330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/ceqsxf7noigm38v7hmeo 440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/opuob67l2pjdfikqppya 550w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/gcaukycwnbkqatgqokka 660w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/wz8aradkq9f67xegx83a 770w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/z1maz8je2tu1fhjkrj7w 880w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/mbtaf88s6vur6hollt12 990w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/tlytgbwiqibosbesxqqd 1070w\"></figure><p>This write-up is a compilation of organisations and projects aligned / adjacent to the effective altruism movement in East Asia and Southeast Asia and was written around the EAGxPhilippines conference. Some organisations, projects, and contributors also prefer to not be public and hence removed from this write-up. While this is not an exhaustive list of projects and organisations per country in the region, it is a good baseline of the progress of the effective altruism movement for this side of the globe.</p><p>&nbsp; Feel free to click the links to the organisations/projects themselves to dive deeper into their works.&nbsp;</p><p><i>Contributors: Saad Siddiqui; Anthony Lau; Anthony Obeyesekere; Masayuki \"Moon\" Nagai; Yi-Yang Chua; Elmerei Cuevas, Alethea Faye Ceda\u00f1a, Jaynell Ehren Chang, Brian Tan, Nastassja \"Tanya\" Quijano; Dion Tan, Jia Yang Li; Saeyoung Kim; Nguyen Tran; Alvin Lau</i><br><i>Forum Post Graphic credits to Jaynell Ehren Chang</i><br><i>EAGxPhotos credits to CS Creatives</i></p><h1>&nbsp;</h1><h1><br><strong>Hong Kong \ud83c\udded\ud83c\uddf0</strong></h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/emqthetvnjbg4jk1jpse\"></p><h3>City Group:&nbsp;<a href=\"https://www.eahongkong.org/\"><u>EAHK</u></a></h3><ul><li>Started in 2015 based in University of Hong Kong.&nbsp;</li><li>5 core organisers, of which 2 receive EAIF funding from 2023 to work part-time (Anthony and Kenneth)</li><li>Organises the&nbsp;<a href=\"https://www.eahongkong.org/horizon-fellowship\"><u>Horizon Fellowship Program</u></a> (In-person EA introductory program). There are 107 fellows since 2020.</li><li>Around 200+ on Slack channel</li><li>Bi-lingual social media&nbsp;<a href=\"https://www.instagram.com/ea_hongkong/?hl=en\"><u>account</u></a> with 350 followers</li><li>Bi - weekly socials with 8 to 20 attendees and around 8 speakers meetup a year.</li><li>Registered as a legal entity (limited company) in July 2023 in order to register as a charity in Hong Kong. Aims of facilitate effective giving.</li><li>Opportunities:&nbsp;<ul><li>High concentration of family office/ corporate funders/ philanthropic organisations. To explore fundraising and effective giving potential.</li><li>Influx of mainland/ international university in coming years due to recent policy change (40% non-local, 60% local). A diverse talent pool.</li><li>Looking into translating EA materials to local language (Chinese) to reach out to more locals.</li></ul></li></ul><h3>University Group:&nbsp;<a href=\"https://www.eahku.org/\"><u>EAHKU&nbsp;</u></a></h3><ul><li>A new team formed in June 2023. Running independently from EAHK.</li><li>Organises bi-weekly dinner to connect and introduce EA to students on campus</li><li>Planned to run multiple&nbsp;<a href=\"https://www.givingwhatwecan.org/en-US/events/guides/giving-games\"><u>Giving Games</u></a> from Nov 2023 onwards</li><li>Aims to run an introductory program within 2023-2024 academic year</li></ul><p>&nbsp;</p><h3><strong>Academia (AI):&nbsp;</strong></h3><p>A couple of researchers and professors interested in AI x-risk and alignment.</p><ul><li><a href=\"https://docs.google.com/document/d/1_0bEutpCJ8_J-kdkXTIXJkrixrx9NNnBhGk69rAu9h0/edit\"><u>AI&amp;Humanity-Lab@University of Hong Kong</u></a><ul><li><a href=\"https://www.safe.ai/2023-fellows/nathaniel-sharadin\"><u>Nate Sharadin</u></a> (CAIS fellow, normative alignment and evaluations),<a href=\"https://www.safe.ai/2023-fellows/frank-hong\">&nbsp;<u>Frank Hong</u></a> (CAIS fellow, AI extreme risks),<a href=\"https://asia.nikkei.com/Opinion/AI-risks-require-China-and-U.S.-to-work-together\">&nbsp;<u>Brian Wong</u></a> (AI x-risk and China-US)</li><li>2023 Sep launched&nbsp;<a href=\"https://www.maaies.arts.hku.hk/programme-information\">&nbsp;<u>MA in AI, Ethics and Society</u></a> with AI safety, security and governance. Around 90 students in the course.<ul><li>Organises public seminars, see&nbsp;<a href=\"https://ai-humanity.net/events/\"><u>events page</u></a></li></ul></li><li>The first annual AI Impacts workshop in March 2024, focused on evaluations</li></ul></li><li><a href=\"https://docs.google.com/document/d/1BUMxcFxdcSiMO0Gh3a9E2IV965T1390UocKbRoSgq70/edit#heading=h.hdaezx1afg3z\"><u>Hong Kong Global Catastrophic Risk Center at Lingnan University</u></a><ul><li>See link for<u> R</u><a href=\"https://www.ln.edu.hk/philoso/hkcrc/research-projects1/\"><u>esearch focus and outputs</u></a> related to AI safety and governance</li></ul></li><li>Hong Kong University of Science and Technology University<ul><li><a href=\"https://bigaidream.github.io/\"><u>Dr. Fu Jie</u></a> is a visiting scholar working on safe and scalable system-2 LLM.&nbsp;</li></ul></li><li>Research Centre for Sustainable HK at City University of Hong Kong<ul><li>Published a report on the<a href=\"https://www.cityu.edu.hk/cshk/files/ResearchReports/ARGReport-26Apr2023.pdf\">&nbsp;<u>Ethics and Governance of AI in HK</u></a></li></ul></li></ul><p>&nbsp;</p><h3><strong>Academia (Psychology):&nbsp;</strong></h3><ul><li><a href=\"https://mgto.org/effective-altruism/\"><u>Dr. Gilad Feldman</u></a> - Promote \u2018Doing more good, doing good better\u2019 through some of his teaching at the Psychology department at the University of Hong Kong.&nbsp;</li></ul><p>&nbsp;</p><h3><strong>Cause specific organisations/ projects</strong></h3><ul><li>Global health and development&nbsp;<strong>-&nbsp;</strong><a href=\"https://generocity.mystrikingly.com/\"><strong><u>Generocity&nbsp;</u></strong></a><strong>-&nbsp;</strong>a social interest group that advocates increased official development assistance (ODA) from Hong Kong. Lead by&nbsp;<a href=\"https://hk.linkedin.com/in/larry-baum-7360834\"><u>Dr. Larry Baum</u></a> and&nbsp;<a href=\"http://www.linkedin.com/in/aowlau\"><u>Anthony Lau</u></a></li><li>Animal Welfare, Alternative Proteins &amp; Ecosystem Growth -&nbsp;<a href=\"https://www.goodgrowth.io/\"><strong><u>Good Growth Co</u></strong></a> helps organisations and funders identify strategies, products and programs to grow effectively in Asia. The research consultancy is led by&nbsp;<a href=\"https://www.linkedin.com/in/ellaykwong/\"><u>Ella Wong</u></a>,&nbsp;<a href=\"https://www.linkedin.com/in/jahying/\"><u>Jah Ying Chung</u></a> and&nbsp;<a href=\"https://www.linkedin.com/in/jack-stennett-821390138/\"><u>Jack Stennett</u></a>.</li></ul><h1><br><strong>Indonesia \ud83c\uddee\ud83c\udde9</strong></h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/rn1co8dnd1sr88ljd7xk\"></p><h3>EA Indonesia</h3><ul><li>New community, still finding its feet and figuring out its vision/mission/strategy.&nbsp;</li><li><strong>Kicked off in October 2022</strong>. First community event held in November.&nbsp;<ul><li>An earlier attempt had been made 2-3 years earlier, but didn\u2019t get traction.&nbsp;</li></ul></li><li>Notionally a little over 40 community members.&nbsp;<ul><li><strong>9 members attending EAGxPhilippines 2023</strong></li><li><strong>11 volunteers currently working in various capacities</strong> across website, social media, events planning, and new member induction guide. Also another 2 non-EA volunteers who are chipping in to help.&nbsp;</li><li>Many members had previously looked for EA in Indonesia but had no active local group to connect with until now.&nbsp;</li></ul></li><li>Supported by a CEA Group Support Grant.&nbsp;<strong>No paid community builders.</strong>&nbsp;</li><li>Local language&nbsp;<strong>website</strong> launched in April this year. Currently being redesigned.&nbsp;</li><li>Fairly basic local language&nbsp;<strong>social media&nbsp;</strong>strategy. Two objectives:&nbsp;<br>(i) inform/educate; (ii) outreach/community growth.&nbsp;</li><li>Aim to hold one EA&nbsp;<strong>event&nbsp;</strong>per month. Events have included talks, speed networking, discussion groups, and community volunteering.&nbsp;</li><li>Strong interest in&nbsp;<strong>AI safety&nbsp;</strong>within the community: \u00bc to \u2153 of the member base.&nbsp;</li><li>Opportunities/advantages:&nbsp;<ul><li>Untapped/neglected market for EAs: Highly charitable society. Large population (270m). Regularly among the top of list of countries in Charity Aid Foundation\u2019s&nbsp;<a href=\"https://www.cafamerica.org/world-giving-index/\"><u>World Giving Index</u></a>.&nbsp;</li><li>Potentially huge audience for 80k Hours. The Indonesian government offers around&nbsp;<a href=\"https://www.universityworldnews.com/post.php?story=2022071414394082\"><u>4000 scholarships</u></a> for citizens to study postgraduate courses in Indonesia or overseas. Many go to top universities around the world. Recipients are grouped into cohorts which could be targeted.&nbsp;</li></ul></li><li>Challenges:&nbsp;<ul><li>Key-person risk: One lead organiser coordinating the community. Highly stretched. Expat and likely to leave the country in &lt; 12 months.&nbsp;</li><li>Struggled to make inroads into universities. So far no university group in Indonesia. Only 2 students among our membership.</li><li>English language use is not widespread. Most online content and EA books are not accessible to Indonesians.&nbsp;</li></ul></li><li>Please do put us in touch with any Indonesians who might be interested in EA!<ul><li><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdtQhXEeF7krE7VG-LJOr4oLiySBxIV_hCWNMaAyohGJ5luXQ/viewform\"><u>Interest form</u></a></li></ul></li></ul><h1><br><strong>Japan \ud83c\uddef\ud83c\uddf5</strong></h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/bhwd70vmes6ddsqyiom5\"></p><h3>EA Japan</h3><ul><li>Nascent community with about&nbsp;<strong>seven active core members</strong>,&nbsp;<strong>two EAIF-funded part-time community builders (Anneke &amp; Moon)</strong> and an&nbsp;<strong>OP-funded team of translators&nbsp;</strong><ul><li>At least six members of our community will attend EAGx!</li></ul></li><li><strong>Some of our early successes</strong><ul><li>Hosted a&nbsp;<strong>\u201cmini-EAGx\u201d student conference</strong> with about 30 attendees in March 2023</li><li>Supporting the&nbsp;<strong>set-up of an entity for AIS-specific field building</strong> in Japan (with the broad goal to build something like an AIS hub)</li><li>Recently finished facilitating the&nbsp;<strong>first-ever EA intro fellowship</strong> and&nbsp;<strong>AGI fundamentals study group in Japanese</strong>&nbsp;</li><li>Launched a&nbsp;<strong>new EA Japan&nbsp;</strong><a href=\"https://www.eajapan.org/\"><strong><u>website</u></strong></a> which includes the complete EA handbook in Japanese&nbsp;</li></ul></li><li><strong>Challenges</strong><ul><li>Finding (potential)&nbsp;<strong>community builders</strong>&nbsp;</li><li>Navigating the&nbsp;<strong>post-FTX funding landscape&nbsp;</strong></li><li>Overcoming the&nbsp;<strong>language barrier</strong> (most Japanese people don\u2019t feel comfortable discussing complex topics in English)</li></ul></li><li><a href=\"https://www.linkedin.com/in/anneke-pogarell-041428113/\"><u>Anneke</u></a> and&nbsp;<a href=\"https://www.linkedin.com/search/results/all/?fetchDeterministicClustersOnly=true&amp;heroEntityKey=urn%3Ali%3Afsd_profile%3AACoAACp_eOYByrNiD4jLwpOxSBsgK2tki3yVx5I&amp;keywords=masayuki%20nagai&amp;origin=RICH_QUERY_SUGGESTION&amp;position=0&amp;searchId=5c957016-59fa-4a8c-8675-ef33de538882&amp;sid=!zN&amp;spellCorrectionEnabled=false\"><u>Moon</u></a> are really sad to miss the retreat and would love to connect!<ul><li>Please also feel free to direct any Japanese-speaking person who might be interested in EA to us!<ul><li><a href=\"mailto:anneke.pogarell@centreforeffectivealtruism.org\"><u>Anneke\u2019s email</u></a></li><li><a href=\"mailto:masayuki.nagai@eajapan.org\"><u>Moon\u2019s email</u></a></li></ul></li></ul></li></ul><p>&nbsp;</p><h1><strong>Malaysia \ud83c\uddf2\ud83c\uddfe</strong></h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/fwyfarjj5xhp2khl9c4q\"></p><h3>EA Malaysia</h3><ul><li>We\u2019re pretty lowkey, because<ul><li>Capacity constraints.</li><li>Malaysia is a middle-in-the-road country.&nbsp;</li><li>etc</li></ul></li><li>Here are&nbsp;<a href=\"https://sparkly-bamboo-845.notion.site/2b05f9faa4f14e02be2cf369338484e5?v=1e49efdc11aa4d3e98d4cca960d809ba\"><u>our members</u></a><ul><li>Pretty small locally, but there\u2019s some Malaysian diaspora working in EA orgs in the UK, US, etc</li></ul></li><li>We have a pretty small but growing community of rationalists</li></ul><p>&nbsp;</p><h1><strong>Philippines \ud83c\uddf5\ud83c\udded</strong></h1><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/gqpspwya8dcfg3i1blco\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/beeg1uay1lqafzavvx2x 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/ppcqqfn5zv9uzbcar65v 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/axvhwpj6tmbczpy8txpa 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/f9acrolmsatf9di0zmbr 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/geqop36y6rjrtsz8reqa 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/iomlkeotcd81ibu4yfvy 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/ufqy71qlupgogz4tmgzw 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/poo4wugkjzrrlktvjqdp 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/c3cqolel4xbkipqmknuo 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/qtnm4j03qb3ljrk5hdng 1600w\"></figure><h3>A. Meta Organizations/ Projects:</h3><ol><li>City / National Group:&nbsp;<a href=\"https://beacons.ai/effectivealtruismph\"><u>EA Philippines</u></a><ol><li><a href=\"https://www.effectivealtruism.ph/opportunities-board\"><u>Opportunities Board</u></a></li><li><a href=\"https://eaph.substack.com/\"><u>EA Philippines Newsletter</u></a></li></ol></li><li>University Groups:&nbsp;<ol><li><a href=\"https://www.facebook.com/eablue.ph\"><u>EA Blue</u></a> (in the Ateneo de Manila University)</li><li><a href=\"https://www.facebook.com/effectivealtruismupd\"><u>EA University of the Philippines Diliman</u></a>&nbsp;</li><li><a href=\"https://www.facebook.com/EATaft\"><u>EA Taft</u></a> (in the De La Salle University - Manila Campus)</li></ol></li><li>Recent Conference: <a href=\"https://www.youtube.com/watch?v=qaF6k828tv8\">EAGxPhilippines - October 20-22, 2023</a>&nbsp;</li><li>Recent&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/BnzogudjvxxPeZFrE/ea-philippines-career-planning-retreat-for-students-and\"><u>Career Planning Retreat for Students and Professionals</u></a></li><li>We made a&nbsp;<a href=\"https://docs.google.com/document/d/1hVJe-H5sL14M9kyKCe4QAd42gam7mSdKsLnUbalYAwo/edit?pli=1\"><u>tentative list of recommended local charities</u></a> back in 2021. (Note that this is now somewhat outdated, and we have changes/improvements in mind for this document.)</li><li>EA Concepts Translation Project</li></ol><p><br>&nbsp;</p><h3>B. Some Cause/ Topic Specific Organisations</h3><p>-includes Projects, Research incubated, operating in the Philippines, started / lead/ worked on by awesome EAs in the Philippines</p><ol><li>AI Safety<ol><li><a href=\"https://www.facebook.com/WhiteBoxResearch\"><u>WhiteBox Research</u></a></li></ol></li><li>Biosecurity<ol><li><a href=\"https://www.linkedin.com/company/project-shield-ph/\"><u>Strategic Health Initiative for Epidemic Limitation and Defense&nbsp;</u></a><br><a href=\"https://www.linkedin.com/company/project-shield-ph/\"><u>(Project SHIELD)</u></a></li></ol></li><li>Farmed Animal Welfare:&nbsp;<ol><li><a href=\"https://www.animalempathy.ph/\"><u>Animal Empathy Philippines</u></a></li><li><a href=\"https://project-aprmi-ph.notion.site/Project-APRMI-PH-31683365dc094403b4714716e5c94a27\"><u>Alternative Protein Research Mapping Initiative in the Philippines&nbsp;</u></a><br><a href=\"https://project-aprmi-ph.notion.site/Project-APRMI-PH-31683365dc094403b4714716e5c94a27\"><u>(APRMI PH)</u></a></li><li><a href=\"https://www.fishwelfareinitiative.org/philippines-scoping\"><u>Fish Welfare Scoping Project: The Philippines&nbsp;</u></a></li><li><a href=\"https://akf.org.ph/\"><u>Animal Kingdom Foundation</u></a></li><li><a href=\"https://paws.org.ph/\"><u>The Philippine Animal Welfare Society</u></a></li><li><a href=\"https://mercyforanimals.org/what-we-do/\"><u>Mercy for Animals</u></a></li></ol></li><li>Mental Health<ol><li><a href=\"https://rocbata.notion.site/About-Phlourish-5acdeb8b86fc4d9598e08e263f0b9a87\"><u>Phlourish Mental Health Initiative</u></a>&nbsp;</li><li><a href=\"https://www.academia.edu/45071730/Scale_and_Neglectedness_of_Mental_Health_Disorders_in_the_Philippines\"><u>Scale and Neglectedness of Mental Health Disorders in the Philippines</u></a></li><li><a href=\"https://www.academia.edu/101958728/EA_PH_Mental_Health_Charity_Ideas_Research_Shallow_Reports\"><u>EA PH Mental Health Charity Ideas Research Shallow Reports</u></a><ol><li><a href=\"https://www.academia.edu/102203331/Guided_Self_Help_Game_Based_App_for_Adolescents_in_the_Philippines_and_Low_to_Middle_Income_Countries\"><u>Guided Self-Help Game-Based App for Adolescents in the Philippines and Low-to Middle-Income Countries</u></a></li><li><a href=\"https://www.academia.edu/102203232/Deep_Report_on_School_based_Psychoeducation_in_LMICs\"><u>School-based Psychoeducation in the Philippines and Low-to Middle-Income Countries</u></a></li><li><a href=\"https://www.academia.edu/101957857/Self_Help_Workbooks_for_Children_and_Adolescents_in_the_Philippines_and_Low_to_Middle_Income_Countries\"><u>Self-Help Workbooks for Children and Adolescents in the Philippines and Low-to Middle-Income Countries</u></a></li></ol></li></ol></li><li>Global Health and Development<ol><li><a href=\"https://www.idinsight.org/where-we-work/our-offices/philippines/\"><u>IDInsight Philippines</u></a></li><li><a href=\"https://www.pureearth.org/our-projects/global-lead-program/philippines/\"><u>Pure Earth Philippines</u></a></li><li><a href=\"https://poverty-action.org/philippines-overview\"><u>Innovations for Poverty Action Philippines</u></a></li><li><a href=\"https://www.healthyfutures.global/\"><u>Healthy Futures Global Philippines</u></a></li><li><a href=\"https://www.facebook.com/vitaminangelsphilippines/\"><u>Vitamin Angels Philippines</u></a></li></ol></li><li>Operations<ol><li><a href=\"https://www.antientropy.org/\"><u>Anti-Entropy</u></a></li><li><a href=\"https://www.theexactimpact.com/\"><u>Exact Impact</u></a></li></ol></li></ol><h1><strong>Remote \ud83c\udde8\ud83c\uddf3</strong></h1><h3><a href=\"https://cgpg.super.site/\"><u>China Global Priorities Group</u></a>&nbsp;</h3><ul><li>Aims to foster a community of ambitious, careful and committed thinkers and builders focused on effectively tackling some of the world\u2019s most pressing problems through a focus on China\u2019s role in the world.<br><br>We currently do this by facilitating action-guiding discussions, identifying talent and community infrastructure gaps and developing new programmes to support impactful China-focused work.</li></ul><p>&nbsp;</p><p>&nbsp;</p><h1><strong>Singapore \ud83c\uddf8\ud83c\uddec</strong></h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/crwmvrpgahmgxtxgmt5x\"></p><h3><a href=\"https://www.effectivealtruism.sg/\"><u>EA Singapore</u></a></h3><ul><li>Recently had leadership change from FTE to volunteers</li><li>Monthly socials for the community to connect with each other</li><li>1-1s with organisers as needed.</li><li>Mostly based in a WhatsApp group</li></ul><h3><a href=\"https://forum.effectivealtruism.org/groups/ohDKm9aDviv4kf3D7\"><u>EA NUS</u></a></h3><ul><li>An EA group in the National University of Singapore.</li></ul><h3><a href=\"https://www.welfarematters.org/\"><u>Welfare Matters</u></a></h3><ul><li>Farm animal welfare organisation focused on running courses within the region</li></ul><h3><a href=\"https://exploratory-altruism.org/\"><u>CEARCH</u></a></h3><ul><li>Cause prioritisation research. Charity incubated by Charity Entrepreneurship</li></ul><h3><a href=\"https://gfi-apac.org/\"><u>GFI APAC</u></a></h3><ul><li>Focused on creating an ecosystem for alternative proteins</li></ul><h3><a href=\"https://globalfoodpartners.com/\"><u>Global Food Partners</u></a></h3><ul><li>Consultancy on cage-free eggs</li></ul><h3>Effective Giving SG</h3><ul><li>An interest group to see if something can be done about effective giving in Singapore.</li></ul><h3>AI Safety</h3><ul><li>An interest group on AI safety.</li></ul><h2>&nbsp;</h2><h2>&nbsp;</h2><h1><strong>South Korea \ud83c\uddf0\ud83c\uddf7&nbsp;&nbsp;</strong></h1><h3><a href=\"https://www.effectivealtruism.kr/\"><u>EA South Korea</u></a></h3><ul><li>Based in Seoul, South Korea</li><li>Currently working on translating the EA Handbook into Korean with support from Open Phil</li><li>Operating out of a Discord server</li><li>Helping setup AMF Korea for tax efficient means of donating to AMF<br><br>Active leadership members include&nbsp;<a href=\"https://www.linkedin.com/in/saeyoung-macx-kim/\"><u>Saeyoung Kim&nbsp;</u></a>and&nbsp;<a href=\"https://www.linkedin.com/in/mpool/\"><u>Mike Pool</u></a></li></ul><h1>&nbsp;</h1><h1>&nbsp;</h1><h1><strong>Viet Nam \ud83c\uddfb\ud83c\uddf3</strong><br><img><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/fjjr5w2t54dtjfk4cj2o\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/j4ilaafsmt7z43svkklm 550w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/gbnxazel8qrth7ft0zgc 1100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/fmae2mlbzt2aftf4x9d0 1650w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/cbgm1xjseq1txjhviqp2 2200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/gwnd9girupstjgds4caz 2750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/g6klcpkmovtrzct5cdim 3300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/zvo6t37sdg1ljmkafdjj 3850w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/m1t5irw4jvwm7sr5xoid 4400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/cp64cd1nqwl7anhtts4v 4950w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/l91geoonucf0lt1ccmyf 5472w\"></h1><h3><a href=\"https://eavietnam.org/\"><u>EA Viet Nam</u></a></h3><ul><li>Reborned many times. Slowly growing. Gained some interest but not enough time and commitment to grow bigger.</li><li>Most known through Doing Good Better Vietnamese translation, debate competitions, and online content.</li><li>Demographic<ul><li>A mix of Vietnamese, overseas Vietnamese, and expats in Vietnam.</li></ul></li><li>Bottlenecks<ul><li>Human resources, language barrier.</li></ul></li><li>Active leadership: Nguyen Tran -&nbsp;<a href=\"mailto:nguyen@eavietnam.org\"><u>nguyen@eavietnam.org</u></a></li></ul><h3>EA Fulbright (Fulbright University Vietnam)</h3><ul><li>Also Nguyen Tran</li></ul><h3><a href=\"https://www.facebook.com/lesswrongvn\"><u>LessWrong Vietnam</u></a></h3><ul><li>Small and growing rationalist community.</li><li>Active leadership: Hiep Bui -&nbsp;<a href=\"mailto:hiepbq14408@gmail.com\"><u>hiepbq14408@gmail.com</u></a></li></ul><h3><a href=\"https://www.shrimpwelfareproject.org/\"><u>Shrimp Welfare Project</u></a></h3><p>&nbsp;</p><h1><strong>Taiwan \ud83c\uddf9\ud83c\uddfc</strong></h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NrqGyXzvwB2Gqu6XW/n0xn5r7ysc9igcpn00lj\"></p><h3>EA Taiwan</h3><ul><li><strong>Community</strong><ul><li><a href=\"https://www.facebook.com/effectivealtruismtaipei\"><strong><u>EA Taipei Facebook Page</u></strong></a><strong>&nbsp;</strong></li><li><a href=\"https://www.facebook.com/groups/EA.Taiwan\"><strong><u>EA Taiwan Facebook Group</u></strong></a><strong>&nbsp;</strong></li></ul></li><li><strong>Past Glory</strong><ul><li>2017 Peak: Taiwan had an active EA community, with regular reading groups in the past.</li></ul></li><li><strong>Decline</strong><ul><li>Loss of Momentum: Over time, the community diminished and regular meetups stopped, as leaders &amp; some of the community builders left Taiwan for studying/working abroad.&nbsp;</li></ul></li><li><strong>New Beginnings in 2023</strong><ul><li>Renewed Interest: Starting 2023, new EAs have shown interest, especially in AI safety and data-based decision-making.</li><li>EAGxPhilippines Visit: A recent visit to EAGxPhilippines, ignited our inspiration during the engagement with all East and Southeast Asian EA communities, led us to the idea of future plans.</li></ul></li><li><strong>Future Plans</strong><ul><li>Student Organisations: Considering starting groups like EA NTU.</li><li>Reviving Activities: Plans to restart reading/study groups.</li><li>Translation Work: Aiming to translate EA documents to empower the Mandarin community.</li></ul></li><li><strong>Unique Position</strong><ul><li>Irreplaceable Global Asset: Taiwan holds a unique, irreplaceable position in the Mandarin community, given China's large population and the government's cautious stance on EA-related community.&nbsp;</li></ul></li></ul><h1>Thailand \ud83c\uddf9\ud83c\udded</h1><p>No official group but there are interested individuals. You may contact Vorathep at vorathep112 at gmail dot com for this.</p>", "user": {"username": "Elmerei Cuevas"}}, {"_id": "EAmfYSBaJsMzHY2cW", "title": "AI Fables Writing Contest Winners!", "postedAt": "2023-11-06T02:27:44.891Z", "htmlBody": "<p>Hello everyone! The submissions have all been read, and it\u2019s time to announce the winners of the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/gYxY5Mr2srBnrbuaT/announcing-the-ai-fables-writing-contest\"><u>recent AI Fables Writing Contest</u></a>!</p><p>Depending on how you count things, we had between 33-40 submissions over the course of about two months, which was a happy surprise. More than just the count, we also got submissions from a range of authors, from people new to writing fiction to those who do so regularly, new to writing about AI or very familiar with it, and every mix of both.</p><p>The writing retreat in September was also quite productive, with about 21 more short stories and scripts written by the participants, many of which will hopefully be publicly available at some point. We plan to work on creating an anthology of some selected stories from it, and with permission, others we\u2019ve been impressed by.</p><p>With all that said, onto the contest winners!</p><hr><h3>Prize Winners</h3><p><strong>$1,500 First Place:</strong>&nbsp;<a href=\"https://narrativeark.substack.com/p/the-king-and-the-golem\"><i>The King and the Golem</i></a> by Richard Ngo</p><p>This story explores the notion of \u201ctrust,\u201d whether in people, tools, or beliefs, and how fundamentally difficult it is to make \u201ctrustworthiness\u201d something we can feel justified about or verify. It also subtly highlights the way in which, at the end of the day, there are also consequences to not trusting anything at all.</p><p><strong>$1,000 Second Place:</strong>&nbsp;<i>The Oracle and the Agent</i> by Alexander Wales</p><p>We really appreciated how this story showed the way better-than-human decision making can be so easy to defer to, and how despite those decisions individually still being reasonable and net-positive, small mistakes and inconsistencies in policy can lead to calamitous ends.</p><p>(This story is not yet publicly available, but it will be linked to if it becomes so)</p><p><strong>$500 Third Place:</strong>&nbsp;<a href=\"https://docs.google.com/document/d/1Uevy6PtyPRxN96CrdLOvoaaNPj7h4NeJ7gGOa4LV5Ns/edit?usp=sharing\"><i>The Tale of the Lion and the Boy</i></a>&nbsp;+&nbsp;<a href=\"https://docs.google.com/document/d/1-KVY7864lZnRa__-xOxp-YeU9Eem6YBLUpLlQz0UwFo/edit?usp=sharing\"><i>Mirror, Mirror</i></a> by dr_s</p><p>These two roughly tied for third place, which made it convenient that they were written by the same person! The first is an eloquent analogy for the gap between intelligence capabilities and illusion of transparency by reexamining traditional human-raised-by-animals tales. The second was a fun twist on a classic via exploration of interpretability errors. As a bonus, we particularly enjoyed the way both were new takes on old and identifiable fables.</p><h3>Honorable Mentions</h3><p>There were a lot more stories that I\u2019d like to mention here for being either close to a winner, or just presenting things in an interesting way. I\u2019ve decided to pick just three of them:</p><ul><li><a href=\"https://docs.google.com/document/d/1unI2o8Diutz-3C_f5BuqB2HnbF8T5OkZYpNS5x-GMhw/edit?usp=sharing\"><i>The Lion, The Dove, The Monkey, and the Bees</i></a> by J\u00e9r\u00e9my Andr\u00e9oletti</li></ul><p>A fun poem about the way various strategies can scale in exponentially different ways despite ineffectual first appearances.&nbsp;</p><ul><li><a href=\"https://onedrive.live.com/?authkey=%21AAeJwc7K3relXRQ&amp;id=C7792D74993907A5%21209511&amp;cid=C7792D74993907A5&amp;parId=root&amp;parQt=sharedby&amp;o=OneUp\"><i>A Tale of the Four Ns (Neural Networks, Nature, and Nurture)</i></a> by Anoushka Sharp&nbsp;</li></ul><p>An illustrated, rhyming fable about Artificial Intelligence that demonstrates a number of the fundamental parts of AI, as well as the difficulties inherent to interpretability.&nbsp;</p><ul><li><i>This is What Kills Us</i> by Jamie Wahls and Arthur Frost</li></ul><p>A series of short, witty scripts about a number of ways AI in the near future might go from charming and useful tools to accidentally ending the world. Not publicly available yet, though&nbsp;<a href=\"https://www.facebook.com/groups/1781724435404945?multi_permalinks=3598843083693062\"><u>they have since reached out to Rational Animations to turn them into videos</u></a>!</p><hr><p>There are many more stories we enjoyed, from the amusing&nbsp;<i>The Curious Incident Aboard the Calibrius</i> by Ron Fein, to the creepy&nbsp;<i>Lir</i> by Arjun Singh, and we'd like to thank everyone who participated. We hope everyone continues to write and engage with complex, meaningful ideas in their fiction.</p><p>To everyone else, we hope you enjoyed reading, and would love to hear about any new stories you might write that fits these themes.</p>", "user": {"username": "Daystar Eld"}}, {"_id": "APxdBEvcgGsmK5LAp", "title": "Governance of AI, Breakfast Cereal, Car Factories, Etc.", "postedAt": "2023-11-06T01:44:28.692Z", "htmlBody": "<p>The first computers were teams of people, usually women, who did calculations in parallel along with some error checking. The difference in the results between these teams of people and early electronic computers was speed, and even the output of the software on today\u2019s electronic computers could hypothetically be done by people, just impractically slow.</p><p>Natural hunger influences my behavior to buy food, but I\u2019m also influenced by the Cookie Crisp commercial that tells me that Cookie Crisp is not cookies but a breakfast cereal and is part of a healthy breakfast, and part of the money I pay for Cookie Crisp breakfast cereal is used to pay for more commercials, lobbying, and campaign contributions. If you consider the millions of consumers, the politicians, the government officials, military leaders, CEOs, workers, etc. and all of the feedback loops and influences among them, it forms a very complex decision making system.</p><p>Analogous to the human computers that worked on the Manhattan project and early NASA projects, the decisions of billions of people come together to form our global system. Like the billions of transistors on a chip, or billions of chips in data centers, we have billions of people making decisions that result in action in our economy, government, and social systems. It\u2019s a global AI that\u2019s calculated by billions of relatively tiny human computers.</p><p>People trading vegetables and cloth in the town markets thousands of years ago were not planning to create today\u2019s market economy, but now that we have this international capitalist market system, its proponents must defend it. What I was taught in grade school was that the market economy and the profit incentive drove action towards greater and greater efficiency in providing people with their needs and wants. It does seem to work pretty good, and I remember Robbin Williams in a movie where his character, who had recently moved from the Soviet Union to the United States, is overwhelmed by all the different kinds of coffee in the grocery store.</p><p>Our socio-politico-economic system is not a pure market economy. A democratic free market country may trade with a country that has a centrally planned economy ran by a dictator or oligarchy, and free market countries will have laws and regulations from central powers. When we get results we don\u2019t like many say that the problem is not enough government control, and another large group says we need more regulation. A smaller group talks about the type of control and effective regulation, but their arguments tend to be more complex, and therefore ignored. There are no purely centralized planned economies either. Countries considered to be centrally planned still have some officially recognized decentralized decision making, and then these restrictive regimes always have a thriving black market.</p><p>This giant interconnected system gives us answers, often ones we would feel uncomfortable answering as an individual. How much money should a company spend on safety equipment and training? How many deaths are acceptable when building a skyscraper? How much effort should be made to prevent workers from being impaled by industrial robots? Who gets food? It seems good to get answers while feeling distant from the outcomes, but how do we know if the combination of economics, budgeting, and government regulation is providing the correct answers? Would regulating lobbyists give us better or worse answers? Would more spending on early childhood education? Some other change?</p><p>If I think children should not be exposed to Cookie Crisp advertisements, if I think there should be better safety training and more restrictive regulations around the use of safety equipment on construction sites, how can I influence the system to make that happen, but also, should I be allowed to do so? If three people die during construction of a skyscraper, then maybe that\u2019s the optimal number of deaths, maybe the system knows better, and maybe my voice should be suppressed. Many argue that since I have a number of breakfast cereals and brands of coffee in my local supermarket, then that proves that the system is correct, the needs of the people have been met with the greatest efficiency.</p><p>The issue of how to guide an AI away from negative decisions is similar to the question of how we guide large corporations, governments, international organizations, markets, and even individuals from making negative decisions. Also, how do we judge what is a negative decision? Some people argue that if the market came up with a decision, then that is by definition the best decision because it met the needs of the market. This is of course a circular definition. A consumer buying a product in a local store will make a decision weighted towards price vs. perceived value, and exposure to marketing and advertising, with less consideration to environmental impact, labor conditions, social justice, etc. Is such a bias good or bad? How do we determine that?</p><p>We certainly should continue to explore and investigate the threats that AI will pose on both the micro and macro level, including extinction. This is necessary, but not sufficient. We also need to move from science to applied science. A plan for AI, just like anything else, needs decisions about action, and in this case decisions about governance. I do not believe our current system is doing a good job at properly regulating the human calculated AI that we currently use. If governance in general is having problems, then won\u2019t also governance of AI?</p><p>AI research and ideas about AI have been around for a long time. They are here now and need governance decisions now, and we will have to draw on our present knowledge of governance even as we hope to improve that knowledge and practice in the future. Such is the nature of applied science, we can\u2019t always decide to wait for better knowledge or a better technology.</p><p>The good news is most of the issues with AI governance are not new issues, and we have thousands of years of examples of good and bad governance to draw from when creating and implementing plans. Also, conversations about AI governance can inform and improve our knowledge of governance in general. As AI governance moves up the list of priorities we should work to make general governance rise with it.</p>", "user": {"username": "Jeff Martin"}}, {"_id": "DhcaE7MbMwaCyNcxP", "title": "Why building ventures in AI Safety is particularly challenging ", "postedAt": "2023-11-06T00:16:34.752Z", "htmlBody": "<p><br>&nbsp;</p><h3><i>Epistemic Status:</i></h3><p><i>This analysis draws from my interactions and experiences in the AI Safety field and the Effective Altruism movement. While rooted in firsthand insights, the validity of the arguments presented is subject to change as the field evolves and should be interpreted with the acknowledgement that there may be nuances and perspectives not covered here. Many of the challenges here might just be non-actionable as typical startup/non-profit concepts don\u2019t translate super well to an early-stage field such as AI safety.</i></p><h2><strong>TL;DR:</strong></h2><p>AI Safety presents immense potential impact but has equally significant challenges for aspiring entrepreneurs. The barriers are manifold, from the need for comprehensive impact plans, difficulty selling to nonprofits, an underdeveloped idea space, a scarcity of specialized talent, and a limited market size. However, the urgent importance of AI Safety necessitates innovative solutions.</p><h3>Acknowledgements:</h3><p>Thanks to Luca De Leo and Agustin Covarrubias for providing valuable feedback.<br><br>&nbsp;</p><h2>Introduction:&nbsp;</h2><p>AI Safety is an underserved direction of work. So, organizations like 80k Hours advise people to take up these kinds of jobs since they are important and impactful. However, we also have way more people who want to get into the field than the amount the field can absorb. This leads to high rejection rates, frustration building up, and drop-off rates increasing.</p><p>&nbsp;It doesn\u2019t help that a high amount of EAs/80K Hours advisees are probably high potential and hardworking, which means they also have relatively high opportunity costs.</p><p>This underscores the urgent need for more AI safety-aligned organizations to absorb this talent and diversify the field.</p><p>&nbsp;</p><h3><strong>Types of AI Safety Ventures:</strong></h3><p>&nbsp;</p><p>There are three overarching types of AI Safety ventures, which can be for-profit or non-profit:</p><p>&nbsp;</p><ul><li>Infrastructure: Tooling, mentorship, training, or legal support for researchers.</li><li>New AI Safety Organizations: New labs or fellowship programs.</li><li>Advocacy Organizations: Raising awareness about the field.</li></ul><p><br><br><i>Note that I will flip-flop across three main models for ventures in the challenges below:</i></p><p>&nbsp;</p><h2><strong>Challenges:</strong></h2><p><br>&nbsp;</p><h3>1. Need for a robust path to impact plans:</h3><p>Entrepreneurs in the Effective Altruism space often find the stringent requirements for impact metrics and background research daunting. While this is not all bad, it usually puts many potential founders off because it conflicts with the entrepreneurial drive of iterating fast and wanting to do things that don\u2019t necessarily scale.&nbsp;</p><p>A more flexible approach, especially in the early stages, could encourage more entrepreneurs to take the plunge. So, should we just not care about such metrics and give founders a clean slate? Absolutely not. A lot of the non-profit ecosystem relies on robust and transparent impact reporting, but I think the bar should be a lot lower in the early stages. Microgrants or exploratory grants are a viable solution here(though, with their own limitations).</p><p>&nbsp;</p><h3>2.Selling to (or service for) nonprofits isn\u2019t the best idea:</h3><p>There are only a handful of AI Safety organizations right now, and most of the major ones are structured as non-profits. Nonprofits often operate under tight budgets with limited discretionary spending. They rely on grants, donations, and other forms of funding, which can be unpredictable and subject to fluctuation.</p><p>Selling to a small market of nonprofits is risky and financially unappealing.&nbsp;</p><p>&nbsp;Nonprofits often have stringent procurement processes governed by their boards, donors, and the need to adhere to certain regulations and guidelines. This can result in longer sales cycles and a slower adoption rate of new technologies or services. Entrepreneurs may find these processes cumbersome and time-consuming, potentially delaying revenue and impacting cash flow.</p><p><br>&nbsp;</p><h3>3.Infertile idea space:</h3><p>Startup ideas tend not to work out at early stages, and at that stage, it is common advice to pivot after updating using user interviews and finding new pain points. For pivots to be possible, Y Combinator, a famous accelerator, suggests picking a fertile idea space- i.e., a relatively large field with lots of moving variables that might lead to existing inefficiencies.</p><p><br>&nbsp;AI Safety doesn't seem like a fertile idea space yet - the number of funders, organizations, and researchers is small, meaning founders would find it hard to pivot into an alternate value proposition model if things don\u2019t work out as planned due to the concentrated nature of the field and other reasons listed here. I feel there is higher than-usual idea risk on top of the execution risk with a rapidly evolving AI field. We just don\u2019t know what the safety field will, or more crucially, should look like in the next 1-2 years, and even if any ideas we execute right now would not end up being net negative. This makes idea development and prioritization quite challenging.</p><p><br>&nbsp;</p><h3>4.The right kind of people:</h3><p>The right kind of founder material is hard to find- they need to be at the intersection of being concerned with AI safety(or social impact) and having a background working preferably in early-stage organizations. In my experience, the ones who are concerned about AI Safety want to run off and work directly on the field instead and/or have short timelines, so they can\u2019t really wait for a venture to work out. The ones who are into entrepreneurship feel put off by the small field, the small pool of funders, and the higher risk compared to the reward.</p><p>This talent gap has always seemed innate to the field because of its nascent nature.</p><h3>5.Limited Market Size:&nbsp;</h3><p>AI safety research is a specialized and relatively small field. The target audience is narrow, which limits any revenue opportunities. Even if you want to sustain yourself on grants, it generally seems like the number of potential funders is limited, even relative to the already small amount of funders in the non-profit sector as a whole.</p><p>&nbsp;</p><h3>6.High Development Costs:</h3><p>Developing niche tools or solutions in AI Safety often requires specialized knowledge and high development costs, adding another barrier to entry.</p><h2><br>Concluding Thoughts:</h2><p>&nbsp;</p><p>I expect there to be quite a lot of changes to the variables here in the short term, given the recent AI boom(particularly with new regulatory bodies being proposed) and probable cross-industry applications of AI, which might pour some money into the application of AI safety standards.</p><p>Effective Altruism as a movement is very thinking-oriented and not doing-oriented. There is some need for spaces within the movement to take risks and foster ideas.&nbsp;</p><p>Especially in the wake of the FTX crisis, I feel EA needs more such organizations to demonstrate reputationally self-sustaining anchors and create inherent mechanisms to attract more funders to the space. For this, there needs to be more focus on creating organizations and opportunities for impact.</p><p><br>&nbsp;</p>", "user": {"username": "Heramb Podar"}}, {"_id": "jeAGKZtnHS2wc8GkD", "title": "[Book Review] asterisk #2 ", "postedAt": "2023-11-05T22:35:56.042Z", "htmlBody": "<p>This is a review for <a href=\"https://asteriskmag.com/issues/02\">asterisk #2</a>, the second edition of a quarterly <a href=\"https://forum.effectivealtruism.org/posts/Mts84Mv5cFHRYBBA8/introducing-asterisk\">EA focused magazine</a>.&nbsp;</p><p><strong>Rating</strong>: 5/10</p><p><strong>Review</strong>: I should again say I think the content was above average on the whole, and my issues were largely with the magazine as a whole. I came out again feeling that the theme of the issue hadn't been put together quite right. This issue had none of the weird or \"Is Wine Fake?\" sort of articles that I loved from the first, and generally took a serious academic tone that had the collection-of-a-bunch-of-forum-posts feel rather than something of it's own essence. But, the graphics got better, many traded for pictures that I found more compelling on the whole (I really liked the Joseph Turner painting and think it added to the piece), and there were less big text insertions (which I think asterisk doesn't do the best job with)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz10exxdxste\"><sup><a href=\"#fnz10exxdxste\">[1]</a></sup></span>. It's a growing process, and I'm excited to be here for it, but I hope to see more weird/fun stuff in the next article, or at least some theme that separates asterisk as a body of work and justifies it being a magazine and not just a curated sequence on the forum.</p><p><strong>Why take the time? </strong>The community has moved a lot of funding into this project (at least<a href=\"https://link.sbstck.com/redirect/3c3b075c-1038-40c5-9692-5513e5e08350?j=eyJ1IjoiMXNqZXk3In0.dGbOGRjG0EjxhAjxzKDp2t_ZOjmB18wSffWtGViiKqE\"> $1m</a> just from Open Phil), so I think it's pretty important to gather perspectives on it to know if it's a good bet to continue into the future. I give my review below, but I hope this can be a place for others to review the work as well, if you so desire.&nbsp;</p><h1><strong>Article Reviews</strong></h1><p><i>I'm giving the individual reviews of the articles below to give a better sense of where I think the content went right and wrong, to hopefully give some more concrete feedback.</i></p><p><strong>What Comes After COVID?: </strong>Really? You're not even going to start with an article on food? Like one that's completely unrelated, not even a stretch like Salt, Sugar, Water, Zinc? Nothing wrong with the article, it was in fact a wonderfully concise piece that was informative on biosecurity and forecasting simultaneously (and really hats off for the forecasting bit, that was superb). But yeah, thematically this started off on a fairly bad foot.&nbsp;</p><p><strong>The Virtue of Wonder: Martha Nussbaum's Justice for Animals: </strong>I like animals. I like Martha Nussbaum. This should have been absolutely splendid. But it wasn't. I'm not quite sure why, I think it's some combination of feeling that this was way to technical and caught in the details and that this also may just not be Martha's best work. Good idea for an article though and I understand why it's here.</p><p><strong>Feeding the World Without Sunlight</strong>: this was below average, and I was particularly disappointed here because I think the content had great potential. When I try to consider what went wrong for me, I think it's the style of interview, a sort of round robin, AMA sort of style that felt disjointed and like there was never any follow-up, just a reddit AMA taken long form. I get the space is small, but I think at least part of the interview should involve digging deeper into one specific topic (or aspect of a topic) in a way that flows for both the researcher and interviewer (Rob Wiblin does this really well). I think the next article did much better on this note too, so it could be highly dependent on the interviewee as well.</p><p><strong>Beyond Staple Grains: </strong>Well done. Like I just said, there was more follow-up here and the conversation felt like it flowed much better in and out of topics with a better balance between depth and breadth. The content was somewhat dull, but it did a good job to explain why it's relevant and alerted me to an issue I knew very little about, so this was a really good job on finding something important but a bit more obscure.&nbsp;</p><p><strong>Animal Welfare in the Anthropocene: </strong>I was waiting for one on wild animal welfare (WAW). Whoever connected this did a really good job, blending WAW and land use to illustrate interestingly divergent conclusion for what food systems cause the most animal suffering, highlighting the indirect effects in the larger ecosystem over the direct effects we know of. No complaints here at all, really well done and I also enjoyed that they brought in someone who seems vaguely EA skeptical.&nbsp;</p><p><strong>What I Won't Eat: </strong>A nice refrain from the more serious tone taken elsewhere in the issue, with a bit more fun and more of a \"let's talk about normal life\" sort of vibe. I didn't quite connect with it, I think because it seemed a bit more introductory, a bit more geared towards someone who hasn't tried this sort of change before. But I liked the presentation of veganism as a work in progress and not perfection, and thought ending on the recipe was sweet. Maybe part of it was feeling that this is more of a piece meant for conversation than one sided text, as I did come out thinking this is someone who I'd really enjoy having a dinner with.&nbsp;</p><p><strong>Cows vs. Chemists: The Health Debates Over Plant-Based Meat: </strong>Phenomenal. Amazing. The peak of this issue. It gave me a ton of new info that is not only relevant to animal welfare but also my life as a vegan, while presenting both sides of the issue and scrutinizing them equally.&nbsp;</p><p><strong>America Doesn't Know Tofu</strong>: Tofu guy!!!!! This was entertaining, largely as a history of Chinese tofu practices that interweaved an experience of throwing oneself into it. I would have loved to have seen more on how associations of tofu and vegetarian food with poverty developed though, and found it odd there was no guidance as to how to counteract this effect and keep tofu from a slow downfall in Chinese society. The whole piece seemed to be cheerleading the future of something that's dying, without explaining how we might counteract that and give it more life. It was also a blunder to have NO pictures of food here, like significant time in the article is spent describing visuals and this is like the easiest quality introduction of visuals IMO (but I did really like the graphic, so I understand partly).</p><p><strong>Read This, Not That: The Hidden Cost of Nutrition Misinformation</strong>: I'm somewhat convinced that this is a significant problem, and think the work they do seems good, but this article was highly repetitive and spent way too long driving home a general message. I would have loved to have seen more examples, more guidance as to what is good, more tangible things, but all I'm leaving this reading with is a slightly more confident view that nutritional information is often dubious and one should tread lightly (oh and with a cool BOTEC for deaths from nutritional misinformation, I think her estimates likely too high but it's nice to have an idea).</p><p><strong>My Primal Scream of Rage: The Big Alcohol Study That Didn't Happen</strong>: I really quite enjoyed this. It was well written, and brought to my attention something wrong with the world I didn't know about, and gave some idea on how we can do better, a gripping and informative read. The only thing I'll say is...alcohol isn't really food? Like I enjoyed it, but this feels like it would have been highly ideal in a release on drugs instead, or something of the sort? IDK, it's a blurry line, just feels like this could be part of an issue of its own is all.</p><p><strong>Salt, Sugar, Water, Zinc: How Scientists Learned to Treat the 20th Century's Biggest Killer of Children</strong>: Come on. Like I get it, the basic ingredients here are connected to basic ingredients we use for cooking and thus food, but this article is not about food at all. It was an well written article, and I'm glad I read it (I especially enjoyed learning about so many near misses in development, that was new for me), but this feels like sneaking in a global health article to appeal to a wider readership, rather than a commitment to keep the theme.</p><p><strong>Is Cultivated Meat For Real?</strong>: Good. This is still academic (so it's not the ideal out there thing I'd like for a magazine like this) but it's topically on point and was very useful for me, giving me a quick, but thorough, sense of the state of affairs on cultivated meat. I'm realizing I wish there was a similar article on plant based meat, but it's also a much larger topic and there were sub pieces focused on it.&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz10exxdxste\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz10exxdxste\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I also realized what I didn't like about the big text sections. Or rather, I happened to be reading an article that used them well, and I realized this and then went back and tried to figure out what the different was. I think it's largely twofold: less use, and use at a time in the text where you can just begin to understand what the thrust of the quote is at but are just far enough away that it's not an obvious reading of the next logical step in the story.</p></div></li></ol>", "user": {"username": "tswizzle96"}}, {"_id": "Qx2MaRCt3Z2aKzKAv", "title": "Eric Schmidt on recursive self-improvement", "postedAt": "2023-11-05T19:05:15.809Z", "htmlBody": "", "user": {"username": "Nikola"}}, {"_id": "szRYr5phF6KWBJwyW", "title": "What's the justification for EA being so elitist?", "postedAt": "2023-11-05T13:47:51.959Z", "htmlBody": "<p>EA loves genius.&nbsp;</p><ul><li>EA university outreach focuses on elite colleges.</li><li>EA orgs often&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/WXD3bRDBkcBhJ5Wcr/the-dangers-of-high-salaries-within-ea-organisations\"><u>pay above-market-rate salaries</u></a> (<a href=\"https://forum.effectivealtruism.org/posts/SZ6reaQ2HkABAcY2N/job-opportunity-to-found-charity-entrepreneurship-ngo?commentId=96JF24PZjB7wZkQCj\"><u>1</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/WXD3bRDBkcBhJ5Wcr/the-dangers-of-high-salaries-within-ea-organisations?commentId=cicFTQeMcxPp9iKjt\"><u>2</u></a>).</li><li>Outreach to high-schoolers (Atlas Fellowship)&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/fMrtoKBFK7p6oRHpu/atlas-fellowship-why-do-100-high-schoolers-need-usd50k-each\"><u>provided $50k scholarships</u></a>, which could have instead been spent on reaching a broader, less elite, group of young people.</li></ul><p><br>I understand that all else equal, you probably want smarter people working for you. When it comes to generating new ideas and changing the world, sometimes quantity cannot replace quality.</p><p>But what is the justification for being&nbsp;<i>so&nbsp;</i>elitist that we significantly reduce the number of people on the team? Why would we filter for the top 1% instead of the top 10%? Or, more accurately, the top 0.1% instead of the top 1%?</p><p>I\u2019d appreciate any posts, academic papers or case studies that support the argument that EA should be&nbsp;<i>extra</i> elitist.&nbsp;</p><p><i>Full disclosure: I\u2019m trying to steelman the case for elitism so that I can critique it (unless the evidence changes my mind!).</i></p><p><br>&nbsp;</p>", "user": {"username": "Stan Pinsent"}}, {"_id": "GRYFJGnye2gCxCTG4", "title": "EA orgs' legal structure inhibits risk taking and information sharing on the margin", "postedAt": "2023-11-05T04:07:40.333Z", "htmlBody": "<p><br>&nbsp;</p><h1>What is fiscal sponsorship?</h1><p>It\u2019s fairly common for EA orgs to provide fiscal sponsorship to other EA orgs.&nbsp; Wait, no, that sentence is not quite right. The more accurate sentence is that there are very few EA organizations, in the legal sense; most of what you think of as orgs are projects that are legally hosted by a single org, and which governments therefore consider to be one legal entity.&nbsp;</p><p>The king umbrella is Effective Ventures Foundation, which hosts CEA, 80k, Longview, EA Funds, Giving What We Can, Asterisk magazine, Centre for Governance of AI, Forethought Foundation, Non-Trivial, and BlueDot Impact. Posts on the castle&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/xof7iFB3uh8Kc53bG/why-did-cea-buy-wytham-abbey?commentId=u3yJfbm2pes8TFpYX\"><u>also describe it</u></a> as an EVF project, although it\u2019s not listed on the website. Rethink Priorities has a&nbsp;<a href=\"https://rethinkpriorities.org/news/announcing-special-projects\"><u>program</u></a> specifically to provide sponsorship to groups that need it. LessWrong/Lightcone is hosted by CFAR, and have sponsored at least one project themselves (source: me. It was my project).</p><p>Fiscal sponsorship has a number of advantages. It gets you the privileges of being a registered non-profit (501c3 in the US) without the time-consuming and expensive paperwork. That\u2019s a big deal if the project is small, time-limited (like mine was) or is an experiment you might abandon if you don\u2019t see results in four months.&nbsp; Even for large projects/~orgs, sharing a formal legal structure makes it easier to share resources like HR departments and accountants. In the short term, forming a legally independent organization seems like a lot of money and effort for the privilege of doing more paperwork.&nbsp;</p><p><br>&nbsp;</p><h1>The downsides of fiscal sponsorship</h1><p>\u2026are numerous, and grow as the projects involved do.</p><p>The public is rightly suspicious about projects that share a legal entity claiming to be independent, so bad PR for one risks splash damage for all. The government is very confident in its belief that you are the same legal entity, so legal risks are shared almost equally (iamnotalawyer). So sharing a legal structure automatically shares risk. That may be fixable, but the fix comes at its own cost.</p><p>The easiest thing to do is just take fewer risks. Don\u2019t buy retreat centers that could be described as lavish. And absolutely, 100%, don\u2019t voluntarily share any information about your interactions with FTX, especially if the benefits to doing so are intangible. So some amount of value is lost because the risk was worth it for an individual or small org, but not to the collective.</p><p>[it is killing me that I couldn\u2019t follow the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Rule_of_three_(writing)\"><u>rule of three</u></a> with that list, but it turns out there aren\u2019t that many legible, publicly visible examples of decisions to not share information]&nbsp;</p><p>And then there are the coordination costs. Even if everyone in the legal org is okay with a particular risk, you now have an obligation to check with them.The answer is often \u201cit\u2019s complicated\u201d, which leads to negotiations eating a lot of attention over things no one cares that much about. Even if there is some action everyone is comfortable with, you may not find it because it\u2019s too much work to negotiate between that many people (if you know anyone who lived in a group house during covid: remember how fun it was to negotiate safety rules between 6 people with different value functions and risk tolerances?).&nbsp;</p><h2>Chilling effects</h2><h3>A long, complicated (but nonetheless simplified)example</h3><p>The original version of this story was one paragraph long. It went something like: A leader at an EVF-sponsored project wanted to share some thoughts on a controversial issue, informally but in public.The comments were not riskless, but this person would happily have taken the risk if it affected only themselves or their organization. Someone at EVF said no. Boo, grrr.</p><p>I sent that version to the source to check for accuracy. They gave me a new, more complicated story. Maybe it was good they never published those comments, because they were coming from an angry place. Maybe it was good they never published the initial version of those comments, but bad they didn\u2019t publish a draft revised after a good night\u2019s sleep. Maybe it\u2019s not fair to blame EVF, since they (commenter) gave up pretty quickly and maybe EVF would have said yes if they\u2019d kept pushing. Maybe that\u2019s all an excuse, and those comments were great and it was a tragedy they were lost\u2026</p><p>It became clear there was no way to portray the story with the level of nuance the source wanted, without giving enough details to totally blow their anonymity. I offered to let them write out the whole thing in their words with their name on it. They considered it but didn\u2019t feel able to do so without checking with their colleagues, which would have further delayed things and eaten up multiple people\u2019s time. Especially because it would probably not have been a quick yes or no, it would have been more rounds of negotiation between people, all of whom were busy and didn\u2019t hold this as a priority\u2026</p><p>I told them not to bother, because it was unnecessary. The fact that it is so difficult to share enough information to even figure out if the comments were net positive or negative, and how that would change if projects didn\u2019t share fiscal sponsorship, is already on display. So I wrote up this story of trying to share the &nbsp;original example.&nbsp;</p><p><br>&nbsp;</p><h3>Other examples</h3><p>As&nbsp;<a href=\"https://www.lesswrong.com/posts/AocXh6gJ9tJC2WyCL/book-review-going-infinite?commentId=pFAYzGxGJgxFfwn4J\"><u>reported</u></a> by Oliver Habryka: Will MacAskill has written up reflections on the SBF debacle, but EVF told him not to publish.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/GRYFJGnye2gCxCTG4/ctisrjlrdlsxjo24ldni\"></p><p>Luke Freeman, Executive Director at Giving What We Can,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vXzEnBcG7BipkRSrF/how-has-ftx-s-collapse-impacted-ea?commentId=izNdDMjZb7r5Dxjsm\"><u>said that</u></a> the EVF board ordered a cessation of the GWWC pledge drive in the wake of the FTX explosion, and explicitly ascribed this to the EVF board making a conservative rule and not having time to review exceptions.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/GRYFJGnye2gCxCTG4/i6vve6wgej3ij8jgl7ja\"></p><p>I object to this way less than to the censorship; not fundraising in the immediate wake of FTX seems like a pretty reasonable decision. But I expect the factors he brings up in defense of this decision,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vXzEnBcG7BipkRSrF/how-has-ftx-s-collapse-impacted-ea?commentId=BHTwaSmL2j4rmgCDg\"><u>risk to sister projects</u></a> and bandwidth limitations, to be systemic.</p><h2>Confusion tolerance</h2><p>There\u2019s another issue with fiscal sponsorship. I think it\u2019s minor compared to the chilling effect on risk taking, but still worth mentioning. One side effect of sharing a legal structure is that people doing business with project P (e.g. 80k, or Longview) will receive checks, invoices, or other paperwork that uses the name of sponsoring organization O (e.g. EVF). This might look sketchy at first, but then someone explains fiscal sponsorship to you and you accept it.</p><p>Which is why it didn\u2019t raise any alarm bells for me when my first check from \u201cthe FTX Future Fund (regrantor program)\u201d came via CEA, and the second used the name North Dimensions. &nbsp;I've gotten lots of checks that didn't match the organization's name, so I mumbled something about EA\u2019s lack of professionalism and moved on with my day. What has come out since is that North Dimensions was a pre-existing company FTX bought in order to use its bank account, and that&nbsp;<a href=\"https://news.yahoo.com/north-dimension-central-misappropriation-ftx-133000733.html\"><u>bank account was shared</u></a> between FTX and Alameda in ways that have to have been inappropriate.&nbsp;</p><p>[Note: I haven\u2019t attempted to nail down the details of that bank account or my grants and may have gotten something wrong. I don\u2019t think any individual error would contradict my claim that training people to accept misdirection creates cover for malfeasance. The fact that the situation breeds errors is the point.]</p><h1><br>Conclusion</h1><p>I think EA should grapple with the risk creation and risk aversion caused by fiscal sponsorship, especially umbrella orgs, and how those trade-off against the benefits. This is hard because the benefits of sponsorship are legible and predictable, and the costs are nebulous and erratic. But that makes it all the more important to deliberately investigate them. My guess is that this will show that having multiple large orgs share a legal structure is not worth it, but using sponsorship for short term projects or a launching pad will continue to make sense. Maybe I\u2019m wrong though, we can\u2019t know until we check.&nbsp;</p><p><br>&nbsp;</p>", "user": {"username": "Elizabeth"}}, {"_id": "LcS8P84JMmfd9Gudu", "title": "The EA Animal Welfare Fund is looking for guest fund managers", "postedAt": "2023-11-04T22:37:02.436Z", "htmlBody": "<p>You can apply by filling out <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfo2ylCt90CY5ixCYgI29ORNrThp_MyRhpLl_tqGFx-KxYjig/viewform\">this form</a> by the 26th of November.</p><p><a href=\"https://funds.effectivealtruism.org/funds/animal-welfare\">EA Animal Welfare Fund</a> (AWF) is currently looking to hire additional guest fund managers.</p><p>AWF is one of the largest funding sources for small- and medium-sized animal welfare projects. In the last twelve months, the Animal Welfare Fund made more than $6.5 million worth of grants to high-impact organizations and talented individuals.</p><p>To allocate this funding effectively, we are looking for guest fund managers with careful judgment in the relevant subject areas and an interest in effective grantmaking.</p><p>As a guest fund manager, you will evaluate grant applications, proactively help new projects get off the ground (\u2018active grantmaking\u2019), publish grant reports, and contribute to the fund\u2019s strategy.</p><p>Terms of employment:</p><ul><li>We are offering paid part-time, and volunteer positions.</li><li>Compensation for part-time contractors is $60 per hour.</li><li>You will be hired for a period of 3-6 months after which you may have an opportunity to join the team as a permanent fund manager.</li></ul><p>If you are interested in the guest fund manager role - please apply <a href=\"https://forms.gle/uPH7pptEJYNrm8fMA\">here</a>.</p><p>If you know of anyone who might be a good fit for this role, please forward this document to them and encourage them to apply. If you have any questions, do not hesitate to reach out to Karolina via <a href=\"mailto:karolina@effectivealtruismfunds.org\">karolina@effectivealtruismfunds.org</a></p><p>Applications are open now until the 26th of November.</p><p><strong>We look forward to hearing from you!</strong></p><h1>About the role</h1><p>In this role, you will have a tangible impact by helping to direct millions of dollars to high-impact funding opportunities each year, all the while building your grantmaking skills and expanding your knowledge about animal welfare.</p><p>By communicating your reasoning to the community, you will indirectly contribute to the culture and epistemics of the EA and effective animal advocacy (EAA) community. By providing feedback, you will help existing projects improve. In the longer term, your work will help the EA community develop the capacity to allocate a potentially much greater volume of funding each year. While doing so, you will interact with other intellectually curious, experienced, and welcoming fund managers, all of whom share a profound drive to make the biggest difference they can.</p><p>As a guest fund manager, your primary goal will be to increase the fund\u2019s capacity to source and investigate more grant applications. Your responsibilities will include:</p><ul><li>Investigating grants assigned to you, and assessing other fund managers\u2019 grant recommendations</li><li>Voting on grant recommendations (each fund manager has a vote)</li><li>Sourcing high-quality applications based on your ideas through your network (\u2018active grantmaking\u2019)</li><li>Communicating your thinking to the community in writing, e.g., feedback to grantees, grant reports, EA Forum posts and comments</li><li>Providing input on the overall strategic direction of the fund</li></ul><h1>About you</h1><p>We are interested in experienced grantmakers, researchers and people with experience in direct work as well as junior applicants who are looking to build experience in grantmaking.</p><p>You might be a good fit for guest fund manager if:</p><ul><li>You are familiar with work on farmed animal welfare, wild animal welfare and animal advocacy, and have detailed, independent opinions on what constitutes good work in those areas and how you would like these areas and communities to develop over the coming years.</li><li>You have strong analytic skills and experience assessing others\u2019 work.</li><li>You have a strong network in these areas.</li><li>You can communicate your reasoning articulately, <a href=\"https://www.openphilanthropy.org/reasoning-transparency\">transparently</a>, and cordially, and you can convey complex ideas to a lay audience in simple language.</li><li>You are organized and reliable.</li><li>You act with integrity and adhere to policies and cooperative norms.</li><li>You like to take ownership and proactively think through how to accomplish the fund\u2019s goals instead of merely reacting to incoming funding applications.</li></ul><h1>Further information</h1><ul><li>For part-time roles, we offer to compensate you as a contractor at a rate of 60 USD per hour. Some fund managers choose to volunteer their time, but it is entirely up to you whether you would like to accept payment or work pro bono.</li><li>We are committed to promoting an inclusive culture, and we encourage people with diverse backgrounds and experiences to apply.</li><li>Fund consists of approximately 3\u20136 fund managers. We think this number leads to a good tradeoff between keeping coordination overhead sufficiently low and being able to make contrarian bets on the one hand, and benefitting from diverse networks and opinions and robust decision-making on the other hand.</li><li>This is a remote position, open to candidates residing anywhere in the world</li><li>You can find out more about EA Funds on <a href=\"https://app.effectivealtruism.org/funds\">EA Funds website</a> and through the <a href=\"https://forum.effectivealtruism.org/tag/ea-funds-1\">\u201cEA Funds\u201d tag on the EA Forum</a> where you will find relevant posts such as <a href=\"https://forum.effectivealtruism.org/posts/pmr9tR2GYoxDMqbor/animal-welfare-fund-ask-us-anything\">recent Ask Me Anything</a>.</li><li>If you have any feedback for us, please let us know <a href=\"https://poq90cwl.paperform.co/?referrer=job-ad-dec-2020\">here</a>. We are always keen to improve.</li></ul><h1>Application process</h1><p>The application process will take up to seven hours for applicants.</p><ol><li><strong>Application form</strong>. Please fill in <a href=\"https://docs.google.com/forms/u/1/d/e/1FAIpQLSfo2ylCt90CY5ixCYgI29ORNrThp_MyRhpLl_tqGFx-KxYjig/viewform\">the application form</a> by the 26th of November.</li><li><strong>Work sample</strong>.<ul><li>Successful applicants will be asked to complete a work sample.</li><li>You will be compensated at $60/h for your work on the work samples.</li><li>You may also be asked to provide references, ideally by people who the current fund managers are likely to know.</li><li>Your submission will be evaluated and we plan to inform you by the 24th of December whether you have been admitted to the final stage.</li></ul></li><li><strong>Resolving uncertainties</strong>. At the last stage, we will resolve remaining uncertainties through a combination of interviews conducted via video call, further references, and other methods. We plan to appoint the guest fund managers by the 14th of January, or possibly sooner. The decision will be made by the current EA AWF team with the approval of some the EA Funds Project Lead, with input from and advisors.</li></ol><h1>Additional information</h1><p>What does a fund manager\u2019s job look like very concretely, in practice?</p><ul><li>Every month, you\u2019ll commit a total of 6\u201320 hours (depending on how good a use of your time you consider this to be) to:<ul><li>review grant applications that have been assigned to you,</li><li>write a quick evaluation and recommendation for the other fund managers,</li><li>join 0\u20132 calls that each take ~1 hour to discuss key uncertainties and final decisions,</li><li>write payout reports for the approved grants that had been assigned to you, and</li><li>provide feedback to promising grantees and grantseekers.</li></ul></li><li>In addition, you\u2019ll spend another 0\u2013200 hours on active grantmaking at whichever time of the year suits you best.</li><li>With another 10\u201330 hours per year, you will help out in other ways, e.g., evaluating time-sensitive out-of-cycle grants or participating in an AMA.</li><li>We expect less experienced fund managers to commit more time (on the upper end of the range), and experienced grantmakers to commit less time (on the low end of the range), though it can make sense to deviate based on individual circumstances.</li></ul>", "user": {"username": "Incogneilo18"}}, {"_id": "ifjaMfYnA5nB77fzG", "title": "Andre Abassi on invertebrate and insect protection legislation", "postedAt": "2023-11-04T20:28:06.401Z", "htmlBody": "<figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=R1XzPpG6ZBU\"><div><iframe src=\"https://www.youtube.com/embed/R1XzPpG6ZBU\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>Andre Abassi is from UC Law, San Francisco. He currently serves as co-president of the student chapter of the Animal Legal Defense Fund in SF and is working on a campaign to increase legal protections for invertebrates at the federal and state levels having founded the \u2018Society for the Protection of Insects\u2019. Here are some of the questions we try to answer: Do insects live net-negative lives? Is there an anthropocentric way to frame insect welfare? How can lessons learned from securing crustaceans legal rights be applied to insects? What does legal protection for insects even look like and how will we be able to secure it?</p><p>&nbsp;By answering questions like these, we aim to understand the causes behind insect suffering in the world and how the law can be used to help improve insect welfare.&nbsp;</p>", "user": {"username": "Karthik Palakodeti"}}, {"_id": "QsfGEhFpMvgWjyusm", "title": "The 6D effect: When companies take risks, one email can be very powerful.", "postedAt": "2023-11-04T20:08:40.189Z", "htmlBody": "", "user": null}, {"_id": "9Xk8J482dznitEYoa", "title": "We are already in a persuasion-transformed world and must take precautions", "postedAt": "2023-11-04T15:53:33.509Z", "htmlBody": "", "user": {"username": "trevorw96"}}, {"_id": "3z9acGc5sspAdKenr", "title": "Solutions to problems with Bayesianism", "postedAt": "2023-11-04T12:15:56.541Z", "htmlBody": "<p><a href=\"https://bobjacobs.substack.com/p/solutions-to-problems-with-bayesianism\"><i>Crossposted from my blog</i></a><br>&nbsp;</p><p>In this fictional dialogue between a Bayesian (B) and a Non-believer (N) I will propose solutions to some pre-existing problems with Bayesian epistemology, as well as introduce <a href=\"https://forum.effectivealtruism.org/posts/3z9acGc5sspAdKenr/solutions-to-problems-with-bayesianism#The_problem_of_foreacting_agents_\">a new problem</a> for which I offer a solution at the end. (Computer scientists may consider skipping to that section).</p><p>Here\u2019s a Bayes theorem cheat sheet if you need it:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/wa5vw1ia6ue9zqsj91m9\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/pcguvk9nhl9skfuj0jtr 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/l0swemc9kivgkk0i00ms 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/fdzp28gdtymbibzqd2kn 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/ivf7naokl3pevr1w1ubn 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/s6l64v1iqsx9kqb7xkyf 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/rbmjicohz63un6fpjvzl 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/e0mvadnixfhnzixtuvpb 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/jpdt2y2a2wauofkytmmq 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/oayjftpgrtfzblvcx55p 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/wqrcnlh0wjfaat9sqtpg 999w\"></figure><p>&nbsp;</p><h1><strong>The problem of confirmation</strong><br>&nbsp;</h1><p>Nayesian: Remind me again, how does confirmation work in Bayesianism?</p><p>Bayesian: The evidence E confirms hypothesis H if and only if the posterior probability of H given E is greater than the prior probability of H.</p><p>N: So there is no difference between increasing the hypothesis\u2019 probability and confirming a hypothesis?</p><p>B: Not really, no.</p><p>N: I would say that there <i>are</i> cases where something increases the probability of a hypothesis, but we would not say that it <i>confirms</i> the hypothesis. Let's say there is a recent hypothesis that has a strong theoretical foundation and some evidence from a few experiments. Scientists disagree about whether or not this hypothesis is correct. But, again, it's a novel proposal. Say that a recent article published in a highly regarded scientific journal supports this hypothesis. Appearing in the journal increases my degree of belief that the hypothesis is true. So it appears that the Bayesian must conclude that a publication in a reputable scientific journal confirms the hypothesis, but surely that is incorrect. Appearing in a reputable scientific journal isn't in and of itself evidence that a hypothesis is correct; it merely implies that there <i>exists evidence </i>supporting the hypothesis.</p><p>B: No, I <i>would</i> say that appearing in a scientific journal is evidence, although maybe a different type of evidence than we would normally associate with that word. Perhaps we should make a taxonomy of evidence so we don\u2019t end up in information cascades.</p><p>N: Weird. What about the other way around? What if there\u2019s a fact that confirms a hypothesis without increasing its probability?</p><p>B: Can you give an example?</p><p>N: Sure! Let\u2019s say I throw a rock at someone and use Newtonian mechanics to calculate the trajectory of the rock. The predicted trajectory indeed happens, but that doesn\u2019t increase my credence in Newtonian mechanics since I believe that general relativity has displaced it. If we know Newtonian mechanics is false, its probability is zero, and that probability will never increase regardless of how many correct predictions it makes.</p><p>B: So? That seems reasonable to me. A falsified theory remains falsified even if it makes a correct prediction.</p><p>N: But surely the theory of Newtonian mechanics is less wrong than, I don\u2019t know, the existence of fairies that make square circles. We want to be able to say that theories that make loads of correct predictions are better than those that don\u2019t, and that the people in the past who believed in Newtonian mechanics were reasonable while those who believed in square-circle-making fairies weren\u2019t. The first group used evidence to support their hypothesis, while the second group didn\u2019t.</p><p>B: I don\u2019t think you can use Bayesianism retroactively like that.</p><p>N: It\u2019s not just a problem for retroactive evaluations. Many modern scientific theories and models include idealizations, in which certain properties of a system are intentionally simplified. For example, in physics, we often use the ideal gas law. An ideal gas consists of dimensionless particles whose movements are completely random. But an ideal gas doesn\u2019t exist; we invented the concept to decrease the complexity of our computations. We know that the actual probability of theories that use the ideal gas law is 0. Under Bayesianism, any and all theories that make use of the ideal gas law would have no way to increase their probability. Yet we continue to believe that new evidence confirms these models, and it seems rational to do so.</p><p>B: Okay, I guess I\u2019ll have to actually make this taxonomy of evidence now. Let\u2019s call the evidence provided by being published in a scientific journal \"secondhand evidence\". What we want is \"firsthand evidence\". <i>Personal</i> confirmation might come from secondhand evidence, but the only way to confirm a hypothesis in the conventional sense of the word is to do primary research. Do experiments, try to falsify it etc. When a hypothesis appears in a scientific journal, it is not a test of the hypothesis; rather, the paper in the journal simply reports on previous research. It\u2019s secondhand evidence.</p><p>N: I mean, it\u2019s a kind of \"test\" whether or not a theory can even make it into a journal.</p><p>B: But it\u2019s not a <i>scientific</i> test. Similarly, we can obviously set up tests of hypotheses we know are false, including models with idealizations. We can, for example, use a false hypothesis to design an experiment and predict a specific set of outcomes.</p><p>N: Seems vague. You would need to find a way to differentiate secondhand evidence from firsthand evidence and then design different ways Bayesianism deals with both types of evidence.</p><p>B: I\u2019ll get right on it!</p><p>&nbsp;</p><h1><strong>The problem of old evidence</strong><br>&nbsp;</h1><p>BaNo: I think Bayesianism struggles with retrodiction.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbmmq6kjhoqj\"><sup><a href=\"#fnbmmq6kjhoqj\">[1]</a></sup></span></p><p>BaYes: Why do you think so?</p><p>N: Well, consider the following scenario: scientists can\u2019t explain why volcanoes erupted when they did. We\u2019ll call this piece of evidence (the pattern of <strong>e</strong>ruptions) E. Then a new volcanological theory comes out that retrodicts the timing of all eruptions to the second. It seems like the fact that this theory can perfectly explain the timing of the eruptions is evidence that said theory is correct.<br>However, Bayesianism says that E confirms H when H\u2019s posterior given E is higher than H\u2019s prior, and we work out the posterior by applying Bayes\u2019 rule. At the time the new theory was proposed, the pattern of the eruptions was already known, so the probability of E equals 1.</p><p>Which means the probability of E given H is also 1. It then follows that the probability of H given E is equal to the probability of H, so the posterior is equal to the prior. In other words: E can't confirm H when E is already known.<br>Under Bayesianism, no matter how impressive of a retrodiction a theory makes, it can never strengthen that theory.</p><p>B: I mean, what if I just give theories that provide good retrodictions a higher prior?</p><p>N: That wouldn\u2019t work in scenarios where we only discover the retrodiction after the theory has already been introduced. If I propose this new volcanological theory and we assign it a prior and only later we discover its perfect retrodiction, the prior has already been assigned.</p><p>B: What if we used a counterfactual? Instead of asking ourselves what the scientist\u2019s actual degree of belief is in E we ask ourselves what her degree of belief would have been had she not known about E. In that case, the probability of E does not just equal 1.&nbsp;</p><p>N: How do we know what her degree of belief would have been?</p><p>B: Well, say she forgets all the volcanic eruptions without it altering her other knowledge.</p><p>N: Impossible, knowledge is entangled with one another, especially something as drastic and traumatic as volcanic eruptions.</p><p>B: Okay okay, what about a counterfactual <i>history</i> instead, where no one knows about volcanic eruptions and we ask the scientific community in this timeline what they think.</p><p>N: And these scientists don\u2019t know about volcanic eruptions? What, do they live on Mars or something? How are we supposed to know what alternate universe alien scientists believe?</p><p>B: Alright, alright, I\u2019ll bite the bullet, retrodictions don\u2019t strengthen a theory.</p><p>N: But this is not only a problem for retrodictions, but also for old <i>pre</i>dictions. Say a theory made a correct prediction. E.g. germ theory predicted that if we looked under a microscope we would see microbes. Then when the modern microscope was invented it turned out to be a correct prediction. But <i>we</i> live in the present, and for us the fact that looking into a microscope will show us microbes is not new evidence. For us it\u2019s probability is one. So, according to Bayesianism, when we first learn of germ theory, the fact that we know that we can look into a microscope to see germs can\u2019t confirm germ theory. That\u2019s ridiculous!</p><p>B: I think I can combine a solution for the problem of retrodiction with the problem of confirmation. The problem of us wanting to update on the \u2018secondhand evidence\u2019 of appearing in a scientific journal seems analogous to germ theory correctly predicting microbes in the past, and us \u2018wanting\u2019 to update on that past successful prediction.<br>What if we considered a kind of \u2018collective Bayesianism\u2019 which describes what an interconnected collection of agents (ought to) update towards. A \u2018Bayesian collective\u2019 does update because of germ theory\u2019s successful prediction, since it\u2019s around for that. At this point it becomes easy to make that distinction between \u2018firsthand evidence\u2019 and \u2018secondhand evidence\u2019. \u2018Firsthand evidence\u2019 is that which makes the Bayesian collective <i>and</i> the Bayesian individual update, whereas \u2018secondhand evidence\u2019 only makes the individual Bayesian update.<br>For you as an individual it\u2019s a surprise that something has appeared in a scientific journal and \u2018confirms\u2019 a theory, but it doesn\u2019t for the collective. The goal of the Bayesian individual is not only to use \u2018firsthand evidence\u2019 to update the knowledgebase of themself (and the collective), but also to use \u2018secondhand evidence\u2019 to bring their own credences as much in line with the Bayesian collective as possible.</p><p>N: So would an alien scientist be part of our Bayesian collective?</p><p>B: It must be interconnected, so if it can\u2019t communicate with us, no.</p><p>N: In this model, if a historian discovers a long lost text from ancient Greece they aren\u2019t collecting firsthand evidence? The collective doesn\u2019t update?</p><p>B: Bayesianism is an epistemic ideal to strive towards, not a description of how people actually work. An actual collective will not conform to how the ideal of a Bayesian collective operates. An ideal Bayesian collective doesn\u2019t forget anything, but obviously real people and groups do forget things. An ideal Bayesian collective wouldn\u2019t need historians, the insights from ancient greek writers would continue to be in the network, and the collective thus wouldn\u2019t update on the ancient greek text. But real collectives do need historians, and they do update on the ancient greek text, because mankind keeps forgetting it\u2019s history.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjt85bao8rbd\"><sup><a href=\"#fnjt85bao8rbd\">[2]</a></sup></span></p><p>&nbsp;</p><h1><strong>The problem of logical omniscience</strong><br>&nbsp;</h1><p>Bay=cray: What are the axioms of probability theory again?</p><p>Bay=bae: They are:</p><ul><li>Axiom 1: The probability of an event is a real number greater than or equal to 0 and smaller than or equal to 1.</li><li>Axiom 2: The probability that at least one of all the possible outcomes of a process (such as rolling a die) will occur is 1.</li><li>Axiom 3: If two events A and B are mutually exclusive, then the probability of either A or B occurring is the probability of A occurring plus the probability of B occurring.</li></ul><p>N: And Bayesianism treats the axioms of probability theory as constraints on one's degrees of belief. In other words, for the Bayesian, probabilities are the same as degrees of belief, right?</p><p>B: Correct.</p><p>N: How do we know what our degrees of beliefs are?</p><p>B: With bets. If you think the odds of Biden being reelected is one in three, the most risky odds you would take for a bet on that outcome is one in three.</p><p>N: I don\u2019t know, it seems like degrees of belief and probability are dissimilar in many ways. We have all sorts of biases, like base rate neglect, that make our beliefs different from what a Bayesian would prescribe.</p><p>B: Yes, just like with the memory issue, Bayesianism is not a descriptive model of how humans form beliefs, it is a prescriptive model of what humans ought to believe. Treat it as a goal to strive towards.</p><p>N: Okay, but what about mathematical truths? The statement 4 = 4 is true by definition. So, according to the axioms of probability theory, it should have a probability of 1, since logical truths are necessarily true. But there are many logical truths about which we are uncertain. Just think of all of the currently unproven mathematical conjectures. Do you think P=NP is true? False? Are you unsure? I doubt most people would say they are 100% confident either way. But logically these conjectures are either <i>necessarily</i> true or <i>necessarily</i> false. So they should all have a probability of either 0 or 1.<br>This becomes especially problematic when you think about how Bayesianism tells me I should be willing to take bets based on a theory\u2019s probability. The probability of Pythagoras\u2019 theorem is 1, but I\u2019m not willing to bet all my money on it without someone else putting money in too. I can believe that the probability of a mathematical theorem or conjecture is 1, without being certain that it is true.<br>Bayesianism seems to have trouble explaining doubts about logical and mathematical truths, which is a shame because those doubts are often reasonable, if not unavoidable.</p><p>B: I have the same response as before. Bayesianism is an ideal to strive towards. The platonic ideal of a scientist would be aware of all logical truths, but real world scientists obviously aren\u2019t ideal.</p><p>N: Why is this ideal? Why should logically omniscient scientists be preferred over any other type of ideal? Why doesn't the ideal scientists already have access to all possible evidence? In that case, there would be no need to test theories because scientists would already know the outcome of every possible test.</p><p>B: This idealization would be unhelpful. It would not reveal much about how actual scientists behave or the methodologies they employ. Logical truths are a better idealization because logical truths aren't really relevant to scientific confirmation. Scientists don't deal with logical hypotheses; they deal with <i>empirical</i> hypotheses, and Bayesianism is great at dealing with those.</p><p>N: What about mathematicians? They do have to deal with mathematical/logical conjectures.</p><p>B: They can disregard Bayesianism and use conventional mathematical methods.</p><p>N: What about philosophers and computer scientists who need to combine logical conjectures with empirical evidence?</p><p>B: We might be able to tackle it with \"<a href=\"https://www.alignmentforum.org/tag/logical-uncertainty\">logical uncertainty</a>\" but that\u2019s still a developing field.<br>Alternatively we might give Bayesianism its own axioms that are similar, but not exactly the same axioms as probability theory. Maybe something like:</p><ul><li>Axiom 2: The credence that at least one of all the <i>imagined</i> outcomes of a process will occur is 1.</li><li>Axiom 3: If two events A and B are<i> imagined to be</i> mutually exclusive, then the credence of either A or B occurring is the credence of A occurring plus the credence of B occurring.</li></ul><p>P=NP is either necessarily true or necessarily false, but we can imagine untrue things. By allowing imagination to enter our axioms we can account for this discrepancy between our minds and the mathematical laws.</p><p>N: Interesting\u2026</p><p>&nbsp;</p><h1><strong>The problem of agnosticism</strong><br>&nbsp;</h1><p>Bayliever: Does that answer all your questions?</p><p>Bagan: Nope! What are the Bayesian probabilities? The problem of logical omniscience suggests that we can't simply say they are degrees of belief, so what are they? Take a claim like \"There are a billion planets outside the observable universe\". How do you assign a probability to that? We can\u2019t observe them, so we can\u2019t rely on empiricism or mathematics, so... shouldn\u2019t we be agnostic? How do we represent agnosticism in terms of probability assignments?</p><p>B: Prior probabilities can be anything you want. Just pick something at random between 0 and 1. It doesn\u2019t really matter because our probabilities will converge over time given enough incoming data.</p><p>N: If I just pick a prior at random, that prior doesn\u2019t represent my epistemic status. If I pick 0.7, I now have to pretend I\u2019m 70% certain that there are a billion planets outside the observable universe, even though I feel totally agnostic. I\u2019m not even sure we\u2019ll ever find out whether there really are a billion planets outside the observable universe. Why can\u2019t I just say that it\u2019s somewhere between 0 and 1, but I don\u2019t know where?</p><p>B: You need to be able to update. A rational thinker needs to have a definite value.</p><p>N: Why? There is no Dutch book argument against being agnostic. If someone offers me Dutch book bets based on the number of planets outside the observable universe, I can just decline.</p><p>B: What if you don\u2019t have a choice? What if that person has a gun?</p><p>N: How would that person even resolve the bet? You\u2019d have to know the amount of planets outside the observable universe.</p><p>B: It\u2019s God, and God has a gun.</p><p>N: Okay, fine, but even in that absurd scenario I don\u2019t have to have a definite value to take on bets. I can, for example, use a random procedure, like rolling a dice.</p><p>B: What if that procedure gives you a 0 or a 1? You would have a trapped prior, and you couldn\u2019t update your beliefs no matter what evidence you observed.</p><p>N: I can\u2019t update my beliefs <i>if</i> I follow Bayesianism. The axioms of probability theory allow me to assign a 0 or a 1 to a hypothesis. It\u2019s Bayesianism that traps my priors.</p><p>B: You can\u2019t assign a 0 or a 1 to an empirical hypothesis for that reason.</p><p>N: Isn\u2019t that ad hoc? The probabilities were meant to represent an agent's degree of belief, and agents can certainly be certain about a belief. It seems the probabilities do not represent an agent's degree of belief after all. The Bayesian needs to add all sorts of extra rules, like that we can assign 0 and 1 to logical theorems but not empirical theories, which <i>must</i> actually be assigned a probability between 0 and 1. So... what are the probabilities exactly?</p><p>B: Hmmm\u2026 Let me get back to you on that one!</p><p>&nbsp;</p><h1><strong>The problem of foreacting agents</strong><br>&nbsp;</h1><p>Doubting Thomas: Say there is an agent whose behavior I want to anticipate. However, I know that this agent is:</p><ol><li>extremely good at predicting what I\u2019m going to guess (maybe it\u2019s an AI or a neuroscientist with a brain scanner) and\u2026</li><li>this agent wants me to make a successful prediction.</li></ol><p>If I guess the agent has a 90% chance of pushing a button they will have already predicted it, and will afterwards push the button with 90% probability. Same with any other probability, they will predict it and set their probability for acting accordingly. It\u2019s forecasting my guess and <i>reacting</i> be<i>fore</i> I predict, hence <i>foreacting</i>. After learning this information what should my posterior be? What probability should I assign to them pushing the button?</p><p>Thomas Bayes: Whatever you want to.</p><p>Doubting Thomas: But \u2018whatever you want to\u2019 is not a number between 0 and 1.</p><p>B: Just pick a number at random then.</p><p>N: If I just pick a prior at random, that doesn\u2019t represent my epistemic state.</p><p>B: Ah, this is the problem of agnosticism again. I think I\u2019ve found a solution. Instead of Bayesianism being about discrete numbers, we make it about ranges of numbers. So instead of saying the probability is around 0.7 we say it\u2019s 0.6\u20130.8. That way we can say in this scenario and in the case of agnosticism that the range is 0\u20131.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftw8qexhtlmi\"><sup><a href=\"#fntw8qexhtlmi\">[3]</a></sup></span></p><p>N: This would be an adequate solution to one of the problems, but can\u2019t be a solution for both agnosticism and foreacting predictors.</p><p>B: Why not?</p><p>N: Because they don\u2019t depict the same epistemic state. In fact, they represent an almost opposite state. With agnosticism I have basically no confidence in any prediction, whereas with the foreacting predictor I have ultimate confidence in all predictions. Also, what if the agent is foreacting <i>non-uniformly?</i> Let\u2019s say it makes it\u2019s probability of acting 40% and 60% if I predict it will be 40% and 60% respectively, but makes it\u2019s probability not conform with my prediction when I predict anything else. So if I predict, say, 51% it will act with a probability of, say, 30%. Let\u2019s also assume I know this about the predictor. Now the range is not 0\u20131, it\u2019s not even 0.4\u20130.6 since it will act with a different probability when I predict 51%.</p><p>B: Hmmm\u2026</p><p>N: And what if I have non-epistemic reasons to prefer one credence over another. Let\u2019s say I\u2019m trying to predict whether the foreacting agent will kill babies. I have a prior probability of 99% that it will. The agent foreacts, and I observe that it does indeed kill a baby. Now I learn it\u2019s a foreacting agent. With Bayesianism I keep my credence at 99%, but surely I ought to switch to 0%. 0% is the \u2018moral credence\u2019.</p><p>B: This is a farfetched scenario.</p><p>N: Similar things can happen in e.g. a prediction market. If the market participants think an agent has a 100% probability of killing a baby they will bet on 100%. But if they then learn that the agent will 100% kill the baby if they bet on 1%-100%, but will not kill the baby if the market is 0% they have a problem. Each individual participant might want to switch to 0%, but if they act first the other participants are financially incentivized to not switch. You have a coordination problem. The market <i>causes</i> the bad outcome. You don\u2019t even need foreacting for this, a reacting market is enough. Also, there might be disagreement on what the \u2018moral credence\u2019 even is. In such a scenario the first buyers can set the equilibrium and thus cause an outcome that the majority might not want.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefr609xejntoe\"><sup><a href=\"#fnr609xejntoe\">[4]</a></sup></span></p><p>B: This talk about \u2018moral credences\u2019 is besides the point. Epistemology is not about morality. Bayesianism picks an accurate credence and that\u2019s all it needs to do.</p><p>N: But if two credences are equally good epistemically, but one is better morally, shouldn\u2019t you have a system that picks the more moral one?</p><p>B: Alright, what if we make Bayesianism not about discrete numbers, nor about ranges, but instead about distributions? On the x-axis we put all the credences you could pick (so any number between 0 and 1) and on the y-axis what you think the probability will be based on which number you pick.<br>So when you encounter a phenomenon that you think has a 60% chance of occurring (no matter what you predict/which credence you pick) the graph looks like this:</p><figure class=\"image image_resized\" style=\"width:57.28%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/t7nqyblr6yzqlhlqet5i\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/zx3qumcv7iqbhxgtbyk3 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/q6q9cw1nledzwzzvme52 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/dpne1z9qnck6evsqxqb9 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/lxiiodri7wnlvdlaaad6 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/zwbkotuf8xa1iuftorm3 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/pj8hfpj2bthpbtovuqol 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/ujupusftpaato0astoru 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/ylxcvls4w9efonxkgaa8 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/f6t7yldevhol1zoil7bq 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/cbddhcyxgbcdzodrs17f 852w\"></figure><p>And when you encounter a uniformly foreacting agent who (you believe) makes the odds of something occurring conform to what you predict (either in your head or out loud), you have a uniform distribution:</p><figure class=\"image image_resized\" style=\"width:53.99%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/vg7n1h5vggoon3g0lcdz\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/fis6ewp5fzoft83uhicp 119w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/qbybhimzb8lbdt2cblzr 199w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/qfiw6ndtu4pueribvpar 279w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/dnap7ol9c88xuqvbcunr 359w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/yelhuma84ktacq7indsi 439w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/rixu41ixka0oz00mcqkw 519w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/nl0ojc2elxwb83akto5b 599w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/ghdrhszkxdevgmotsli4 679w\"></figure><p>With this you can just pick any number and be correct. However if you encounter the non-uniformly foreacting agent of your example the graph could look something like this: (green line included for the sake of comparison)&nbsp;</p><figure class=\"image image_resized\" style=\"width:58.03%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/mietagfdka01h2lo9hgy\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/ebbh3ytnri7pt6wn5bmk 154w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/ldmbcyofzawhicbgjwgk 234w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/wniqmjprktmpvid6v80n 314w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/eizajpmjzqmyx11qe61a 394w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/y2g3inx7scau0zyg6mnm 474w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/pw7dnpld7dn2aqkjmz0e 554w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/h55y2k7onqn7sgnrwqpr 634w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/pi9rvn4fz7k1psxg6rlm 714w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/vemluoykdetniz3wiuhv 794w\"></figure><p>Picking 0.2 (B) will result in the predictor giving you a terrible track record (0.4). But picking 0.4 or 0.6 (C or E) will give you an incredible track record. Let\u2019s call C and E \u2018overlap points\u2019. If this distribution is about whether the agent will kill a baby, C is the \u2018moral credence\u2019.</p><p>N: Wouldn\u2019t A be the moral credence, since that has the lowest chance of killing a baby?</p><p>B: Humans can\u2019t will themselves to believe A since they know that predicting a 0% chance will actually result in a 20% chance.</p><p>N: What about an agent that is especially good at self deception?</p><p>B: Right, so if you have e.g. an AI that can tamper with it\u2019s own memories, it might have a moral duty to delete the memory that 0% will result in 20% and instead forge a memory that 0% will lead to 0%, just so the baby only has a 20% chance of dying.</p><p>N: What if you have a range? What if you don\u2019t know what the probability of something is but you know it\u2019s somewhere between 0.5 and 0.7?</p><p>B: Then it wouldn\u2019t be thin line at 0.6, but a \u2018thick\u2019 line, a field:</p><figure class=\"image image_resized\" style=\"width:60.71%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/nnnxpmmnvl3gdtgzzwp0\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/tfvtu8vpymqc27gt0qdt 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/pmkv1ase10z6r1fkfqiz 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/cgmfetnieut41ihnn3cv 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/bqgozxbm02lxwwwxwiho 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/gprtpqlncf2341vorg9q 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/uwp2mnqb7dekt1sroo8o 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/teerashhmvovqrtelo64 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/hnrsywxrerslb8zliggo 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/ogw3zgfh5kfsipkvmeys 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/gugfqlznpnt7hyapol1z 852w\"></figure><p>&nbsp;</p><p>N: What about total agnosticism?</p><p>B: Agnosticism would be a black box instead of a line:</p><figure class=\"image image_resized\" style=\"width:54.82%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/mjjtntetoyeplkaa8zcr\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/mj0sphu4vpcarl4q9rlf 154w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/xt8cy7rnpcto85ddvwgq 234w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/sbzxyvtmwnuroqdlnzvq 314w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/susqqsa0qbewuyihjb5b 394w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/m00vigjucudsysalpij4 474w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/chqrnkraohj60m6cxhfy 554w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/dbun62fm3tz4htce23oh 634w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/hobbxixvfukt818uzfb7 714w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/xopljuoq9vlhvgapuklg 794w\"></figure><p>The point could be anywhere between here, but you don\u2019t know where.</p><p>N: What if you\u2019re <i>partially</i> agnostic with regards to a foreacting agent?</p><p>B: This method allows for that too. If you know what the probabilities are for the foreacting agent from A to E, but are completely clueless about E to F it looks like this:</p><figure class=\"image image_resized\" style=\"width:59.46%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/rf619w9hhijjh0rua37d\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/fc7fuswnzefzh4v4xwdx 154w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/lkti9yaix4mdbl5f7icz 234w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/xpiv01myugludfc9i3xj 314w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/wmgfpddvc9m0txy0fa8t 394w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/kjohtpr81wyut7drpra0 474w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/duvv3vtgttby6gtmsl3f 554w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/hkejlxyv6ppvdqgymtza 634w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/cdp4hui1gobw1jnjlgsn 714w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/pxfhjb82c4rxsqe7pxzk 794w\"></figure><p>&nbsp;</p><p>N: What if I don\u2019t know the probabilities of the agent between E and F, but I do know it's somewhere between 0.2 and 0.6?</p><p>B: It would look something like this:</p><p>&nbsp;</p><figure class=\"image image_resized\" style=\"width:62.27%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/ceegj8p0mwild2p3fgtv\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/lvevc7igrh4wyktxm3rr 154w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/nzfhgocf5fqtswp4wxap 234w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/zlanysxgzptoomvg14ik 314w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/wzfztwwxvmkhpjcculoa 394w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/nxuk9dso9ygd2ymqtilj 474w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/g5qpf4et3rqf5irbjixh 554w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/msptlgvfegctbcodgi0f 634w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/m6ncbcuxktuaoc87prnr 714w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3z9acGc5sspAdKenr/uwddlc4lclstt0ud7hhn 794w\"></figure><p>&nbsp;</p><p>N: What if it doesn\u2019t foreact to your credences, but the graph as a whole?</p><p>B: Then you add an axis, if it reacts to that you add another axis etc.</p><p>N: This is still rather abstract, can you be more mathematical?</p><p>B: Sure!</p><p>&nbsp;</p><h1><strong>Applying Bayesian modeling and updating to foreacting agents</strong><br>&nbsp;</h1><p>To apply the Bayesian method, the main thing we need is a world model, which we can then use to calculate posterior probability distributions for things we are interested in. The world model is a <i>Bayesian network&nbsp;</i>that has\u2026&nbsp;</p><ul><li>one <i>node</i> for each relevant <i>variable X</i></li><li>one <i>directed arrow Y\u2192X&nbsp;</i>for each <i>direct dependency</i> among such variables, leading from a <i>parent</i> node <i>Y&nbsp;</i>to a <i>child</i> node <i>X</i></li><li>and for each node <i>X</i> a <i>formula</i> that calculates the <i>probability distribution</i> for that variable from the <i>values</i> of all its parents: P(<i>X</i> | parents(<i>X</i>))&nbsp;</li></ul><p>For nodes X without parents, the latter formula specifies an unconditional probability distribution: P(<i>X</i> | parents(<i>X</i>)) = P(<i>X</i> | empty set) = P(<i>X</i>).</p><p>In our case, I believe the proper model should be this:</p><ul><li>Variables:<ul><li><i>B</i>: whether the agent will press the button. This is a boolean variable with possible values <i>True</i> and <i>False</i>.</li><li><i>p</i>: the credence you assign to the event <i>B</i>=True. This is a real-valued variable with possible values 0\u20261</li><li><i>q</i>: the probability that the agent uses to decide whether to press the button or not. This is also a real-valued variable with possible values 0\u20261&nbsp;</li></ul></li><li>Dependencies:<ul><li><i>B</i> depends only on <i>q</i>: parents(<i>B</i>) = {<i>q</i>}</li><li><i>q</i> depends only on <i>p</i>: parents(<i>q</i>) = {<i>p</i>}</li></ul></li><li>Formulas for all variables\u2019 (conditional) probability distributions:<ul><li>P(<i>B</i>=True | <i>q</i>) = <i>q</i>, P(<i>B</i>=False | <i>q</i>) = 1 \u2013 <i>q</i></li><li>P(<i>q</i> | <i>p</i>) is given by two functions flow, fhigh as follows:<ul><li>If flow(p) = fhigh(p) = f(p), then q = f(p), in other words: P(<i>q</i> | <i>p</i>) = 1 iff <i>q&nbsp;</i>= <i>f<sub>low</sub></i>(<i>p)</i> and 0 otherwise</li><li>If flow(p) &lt; fhigh(p), then P(q | p) has uniform density 1 / (<i>f</i><sub>high</sub>(p) \u2013 <i>f</i><sub>low</sub>(<i>p</i>) for <i>f</i><sub>low</sub>(<i>p</i>) &lt; <i>q</i> &lt; <i>f</i><sub>high</sub>(<i>p</i>) and 0 otherwise.</li><li>For the uniformly foreacting agent agent we have&nbsp; flow(p) = fhigh(p) = f(p) = <i>p</i></li><li>Note that we assume to know the response function upfront, so the functions <i>flow, fhigh</i> are not variables of the model but fixed parameters in this analysis. We might later study models in which you are told the nature of the agent only at some time point and where we therefore also model<i> flow, fhigh</i> as a variable, but that gets harder to denote then.</li></ul></li><li>P(<i>p</i>) = whatever you initially believe about what credence you assign to the event <i>B</i>=True</li></ul></li></ul><p>At this point, we might be surprising necessity of the Bayesian method and get a little wary: because our model of the situation contains statements about how our credence in some variable influences that variable, we needed to include <i>both</i> that variable (<i>B</i>) and our credence (<i>p</i>) as nodes into the Bayesian network. Since we have to specify probability distributions for each parentless node in the network, we need to specify them about <i>p</i>, i.e., a probability distribution on all possible values of <i>p</i>, i.e., a credence about our credence in <i>B&nbsp;</i>being 0.3, a credence about our credence in<i> B</i>being 0.7, etc. This is the P(<i>p</i>) in the last line above. In other words, we need to specify 2nd-order credences! Let us for now assume that P(<i>p</i>) is given by a probability density <i>g</i>(<i>p</i>) for some given function <i>g</i>.&nbsp;</p><p>The whole model thus have two <i>parameters</i>:&nbsp;</p><ul><li>two functions&nbsp;<i> flow, fhigh</i>&nbsp; encoding what you know about how the agent will choose <i>q</i> depending on <i>p</i>,&nbsp;</li><li>and a function&nbsp; <i>g</i>&nbsp; encoding your beliefs about your credence <i>p</i>.</li></ul><p>The Bayesian network can directly be used to <i>make predictions.&nbsp;</i>Making a prediction here is nothing else than calculating the probability of an event.</p><ul><li>In our case, we can calculate&nbsp;</li></ul><p>P(<i>B</i>=True) = integral of&nbsp; P(<i>B</i>=True | <i>q</i>) dP(<i>q</i>)&nbsp; over all possible values of <i>q</i><br>= integral of&nbsp; P(<i>B</i>=True | <i>q</i>) dP(<i>q | p</i>) dP(<i>p</i>)&nbsp; over all possible values of <i>q&nbsp;</i>and <i>p</i><br>= integral of&nbsp; <i>f</i>(<i>p</i>) <i>g</i>(<i>p</i>) d<i>p</i>&nbsp; over <i>p</i>=0\u20261 &nbsp; (if flow=fhigh=f, otherwise a little more complicated)</p><ul><li>For example:<ul><li>If we consider the uniformly foreacting agent with <i>f</i>(<i>p</i>) = <i>p</i> and believe that we will assign credence <i>p&nbsp;</i>= 0.3 for sure, then&nbsp; P(<i>B</i>=True) = 0.3&nbsp; and we are happy.</li><li>If we consider the uniformly foreacting agent with <i>f</i>(<i>p</i>) = <i>p</i> and believe that we will assign either credence <i>p</i>=0.3 or <i>p</i>=0.8, each with probability 50%, then&nbsp; P(<i>B</i>=True) = 0.55&nbsp; and we are unhappy.&nbsp;</li><li>If we consider any <i>f</i> for which there is at least one possible value <i>p</i>* of <i>p</i> such that f(<i>p</i>*)=<i>p</i>*, and believe that we will assign credence <i>p</i> = <i>p</i>*, then&nbsp; P(<i>B</i>=True) = <i>f</i>(<i>p</i>*) = <i>p</i>*&nbsp; and we are happy.</li><li>If we consider an <i>f</i> for which there is <i>no</i> possible value <i>p</i> with f(<i>p</i>)=<i>p</i>, and believe that we will assign some particular credence <i>p</i>* for sure, then we get P(<i>B</i>=True) != <i>p</i>* and will be unhappy.</li><li>But: If we consider an <i>f</i> for which there is <i>no</i> possible value <i>p</i> with f(<i>p</i>)=<i>p</i>, and believe that we might assign <i>any&nbsp;</i>possible credence value <i>p</i> between 0 and 1 with some positive probability, then we indeed get some result P(<i>B</i>=True) between 0 and 1, and since we have attached positive probability to that value, we should be happy since the result does not contradict what we believed we would predict!</li></ul></li></ul><p>Let\u2019s assume we interpret the node <i>p</i> as a control variable of a rational us with some utility function <i>u</i>(<i>B</i>), let\u2019s say u(<i>B</i>=True) = 1 and u(<i>B</i>=False) = 0. Then we can use the Bayesian model to calculate the expected utility given all possible values of p: E(<i>u</i>(<i>B</i>) | <i>p</i>) = <i>q</i> = (<i>flow</i>(<i>p</i>) + fhigh(p)) / 2. So a rational agent would choose that <i>p</i> which maximizes (<i>flow</i>(<i>p</i>) + fhigh(<i>p</i>)) / 2. If this is all we want from the model, we don\u2019t need <i>g</i>! So we only need an incomplete Bayesian network which does not specify the probability distributions of control variables, since we will choose them.</p><p>Things get more interesting if <i>u</i> depends on <i>B</i> but also on whether <i>p</i> = <i>q</i>, e.g. <i>u</i>(<i>B</i>,<i>p</i>,<i>q</i>) = 1<sub>B=True</sub> \u2013 |<i>p</i> \u2013 <i>q</i>| . In that case, E(u | p) = f(p) \u2013 |p \u2013 f(p)|. If f(p) &gt; p, this equals f(p) \u2013 |f(p) \u2013 p| = f(p) \u2013 (f(p) \u2013 p) = p. If f(p) &lt; p, this equals 2f(p) \u2013 p.</p><p>Let\u2019s assume the rational us cannot choose a p for which f(p) != p.</p><p>&nbsp;</p><p>Excursion: If you are uncertain about whether your utility function equals u1 or u2 and give credence c1 to u1 and c2 to u2, then you can simply use the function u = c1*u1 + c2*u2.</p><p>&nbsp;</p><p><i>Bayesian updating</i> is the following process:&nbsp;</p><ul><li>We keep track of what you <i>know&nbsp;</i>(rather than just believe!) about which <i>combinations of variable values</i> are still <i>possible given the data you have.&nbsp;</i>We model this knowledge via a set <i>D</i>: the set of all possible variable value combinations that are still possible according to your data (Formally, <i>D</i> is a subset of the probability space Omega). If at first you have no data at all, <i>D</i> simply contains all possible variable combinations, i.e., <i>D</i>=Omega.<ul><li>In our case, D and Omega equal the set of all possible value triples (<i>B</i>,<i>p</i>,<i>q</i>), i.e., they are the Cartesian product of the sets {True,False}, the interval [0,1] and another copy of the interval [0,1]:&nbsp;<ul><li>D = Omega = {True,False} x [0,1] x [0,1]</li></ul></li></ul></li><li>Whenever we get more data:<ul><li>We reflect this by throwing out those elements of D that are ruled out by the incoming data and are thus no longer considered possible. In other words, we replace D by some subset D\u2019 of D.</li><li>Then we calculate the conditional probability distribution of those events E we are interested in, given D, using Bayes\u2019 formula:<ul><li>P(E | D) = P(E and D) / P(D)</li></ul></li></ul></li></ul><p>&nbsp;</p><p>At this point, we might be tempted to <i>treat the value we derived for&nbsp; P(B=True)</i>&nbsp; on the basis of some choice of<i> f</i> and <i>g</i> as <i>data about p</i>. Let\u2019s consider the consequences of that. Let\u2019s assume we start with some fixed <i>f, g</i> and with no knowledge about the actual values of the three variables, i.e., with D<sub>0&nbsp;</sub>= Omega = {True,False} x [0,1] x [0,1]. We then calculate P(<i>B</i>=True) and get some value <i>p<sub>1</sub></i> between 0 and 1. We treat this as evidence for the fact that <i>p</i> = <i>p<sub>1</sub>&nbsp;</i>update our cumulative data to D<sub>1</sub> = {True,False} x {<i>p<sub>1</sub></i>} x [0,1], and update our probabilities so that now P(<i>B</i>=True) = <i>f</i>(<i>p<sub>1</sub></i>). If the latter value, let\u2019s call it <i>p<sub>2</sub></i>, equals <i>p<sub>1</sub></i>, we are happy. Otherwise, we wonder. We have then several alternative avenues to pursue:</p><ul><li>We can treat the result P(<i>B</i>=True) = <i>p<sub>2</sub>&nbsp;</i>as another incoming data about <i>p</i>, which needs to be combined with our earlier data. But our earlier data and this new data contradict each other. Not both can be true at the same time, so the statement S<sub>1</sub>: <i>p</i> = <i>p<sub>1</sub></i> , that was suggested by our earlier data is false, or the statement S<sub>2</sub>: <i>p</i> = <i>p<sub>2</sub></i> that was suggested by our earlier data is false. If we consider that S<sub>1</sub> is false, we must consider why it is false since that might enable us to draw valuable conclusions. S<sub>1</sub> was derived purely from our world model, parameterized by the functions <i>f</i> and <i>g</i>, so either at least one of those functions must have been incorrect or the whole model was incorrect.&nbsp;<ul><li>The shakiest part of the model is <i>g</i>, so we should probably conclude that our choice of <i>g</i> was incorrect. We should then try to find a specification of <i>g</i> that does not lead to such a contradiction. We can only succeed in doing so if there is a value <i>p</i>* for which <i>f</i>(<i>p</i>*) = <i>p</i>*. If such a value exists, we can put <i>g</i>(<i>p</i>*) = infinity (remember,<i> g</i> specifies probability densities rather than probabilities) and <i>g</i>(<i>p</i>) = 0 for all <i>p</i> != <i>p</i>*, i.e., assume from the beginning that we will predict <i>p</i>* for sure. But if such a value <i>p</i>* does <i>not&nbsp;</i>exist, we can<i>not</i>choose <i>g</i> so that the contradiction is avoided.&nbsp;</li><li>In that case, something else about the model must have been incorrect, and the next best candidate for what is wrong is the function <i>f</i>. Since no<i> p</i> with <i>f</i>(<i>p</i>)=<i>p</i> exists, <i>f</i> must be discontinuous. Does it make sense to assume a discontinuous <i>f</i>? Probably not. So we replace <i>f</i> by some continuous function. And et voila: now there is some value <i>p</i>* with <i>f</i>(<i>p</i>*)=<i>p</i>*, and we can now choose a suitable <i>g</i>and avoid the contradiction.&nbsp;</li><li>If we desperately want to stick to a discontinuous <i>f</i>, then something else about the model must be wrong. I think it is the idea of the agent being able to know p with certainty, rather than just being able to measure p with some random measurement noise epsilon. I suggest adding two more variables, the noise epsilon and the measurement m, and modify the formulae as follows:<ul><li>epsilon ~ N(0,1),&nbsp; i.e., Gaussian noise</li><li><i>m</i> = <i>h</i>(<i>p</i>, epsilon)&nbsp; for some continuous function&nbsp; <i>h</i>&nbsp; that represents the influence of the random noise epsilon on the agent\u2019s measurement <i>m</i> of <i>p</i>.</li></ul></li></ul></li><li>For example: <i>h</i>(<i>p</i>, epsilon) = expit(logit(<i>p</i>) + sigma epsilon)&nbsp; for some magnitude parameter sigma &gt; 0.</li><li><i>q</i> = <i>f</i>(<i>m</i>)&nbsp; rather than&nbsp; <i>q</i> = <i>f</i>(<i>p</i>)</li></ul><p>With this modified model, we will get</p><p>P(<i>B</i>=True) = integral of&nbsp; P(<i>B</i>=True | <i>q</i>) dP(<i>q</i>)&nbsp; over all possible values of <i>q</i><br>= integral of&nbsp; P(<i>B</i>=True | <i>q</i>) dP(<i>q | m</i>) dP(<i>m | p,&nbsp;</i>epsilon) dP(<i>p</i>) dP(epsilon) over all possible values of <i>q,</i> <i>p&nbsp;</i>and epsilon<br>= integral of&nbsp; E<sub>epsilon~N(0,1)</sub><i>f</i>(<i>h(p,&nbsp;</i>epsilon)) <i>g</i>(<i>p</i>) d<i>p</i>&nbsp; over <i>p</i>=0\u20261,&nbsp; where E is the expectation operator w.r.t. epsilon</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; If our choice of <i>g</i> assigns 100% probability to a certain value <i>p</i><sub>1</sub> of <i>p</i>, the calculation results in</p><p><i>p</i><sub>2</sub> := P(<i>B</i>=True) = E<sub>epsilon~N(0,1)</sub><i>f</i>(<i>h</i>(<i>p</i><sub>1</sub>, epsilon)),</p><p>which is a <i>continuous</i> function of <i>p</i><sub>1</sub> even if <i>f</i> is discontinuous, due to the \u201csmearing out\u201d performed by <i>h</i>! So there is some choice of <i>p<sub>1</sub></i> for which <i>p<sub>2</sub> = p<sub>1</sub></i> without contradiction. This means that whatever continuous noise function <i>h</i> and possibly discontinuous reaction function <i>f</i> we assume, we can specify a function <i>g</i> encoding our certain belief that we will predict <i>p<sub>1</sub></i>, and the Bayesian network will spit out a prediction <i>p<sub>2</sub></i> that exactly matches our assumption <i>p<sub>1</sub></i>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5jb1ayu9igs\"><sup><a href=\"#fn5jb1ayu9igs\">[5]</a></sup></span></p><p>&nbsp;</p><h1><strong>Acknowledgment</strong></h1><p>A huge thanks to <a href=\"https://forum.effectivealtruism.org/users/jobst-heitzig-vodle-it\">Jobst</a><a href=\"https://www.pik-potsdam.de/members/heitzig\"> Heitzig</a> for checking my writing and for writing the \u201cApplying Bayesian modeling and updating to foreacting agents\u201d section of the post. He says it's incomplete and there's more to be written, but I'm thankful for what's already there. And special thanks to the countless people who provide the free&nbsp;<a href=\"https://plato.stanford.edu/entries/epistemology-bayesian/\">secondary </a><a href=\"https://www.youtube.com/watch?v=ClVIw7_ZzSE\">literature</a>&nbsp;on philosophy which makes me understand these problems better. You all deserve my tuition money.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbmmq6kjhoqj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbmmq6kjhoqj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For an article on this see <a href=\"https://link.springer.com/chapter/10.1007/978-3-319-20451-2_8\">Why I am not a Bayesian</a> by <a href=\"https://link.springer.com/chapter/10.1007/978-3-319-20451-2_8#auth-Clark-Glymour\">Clark Glymour</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjt85bao8rbd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjt85bao8rbd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>You can use this to make an <a href=\"https://www.researchgate.net/publication/4952157_The_Absent-Minded_Driver\">absent-minded driver problem</a> for social epistemology</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntw8qexhtlmi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftw8qexhtlmi\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.alignmentforum.org/posts/zB4f7QqKhBHa5b37a/introduction-to-the-infra-bayesianism-sequence\">See Infra-Bayesianism by </a><a href=\"https://forum.effectivealtruism.org/users/diffractor?mention=user\">@Diffractor</a> and <a href=\"https://forum.effectivealtruism.org/users/vanessa?mention=user\">@Vanessa</a><a href=\"https://forum.effectivealtruism.org/users/vanessa?from=post_header\"> Kosoy</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnr609xejntoe\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefr609xejntoe\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Let\u2019s hope that the first people in a prediction market don\u2019t have different interests than the population at large. What are the demographics of people who use prediction markets again?</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5jb1ayu9igs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5jb1ayu9igs\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Alternatively, we could conclude that the output of the Bayesian network, P(<i>B</i>=True), should <i>not</i> be treated as data on <i>p</i>. But then what?</p></div></li></ol>", "user": {"username": "bmjacobs@telenet.be"}}, {"_id": "MYyDvwMctSopFJbtF", "title": "Which aid charity should I give to for people in Gaza?", "postedAt": "2023-11-04T10:56:00.226Z", "htmlBody": "", "user": {"username": "tamgent"}}, {"_id": "LM2JnTHygKbn7eKLz", "title": "AI Alignment Research Engineer Accelerator (ARENA): call for applicants", "postedAt": "2023-11-07T09:43:40.948Z", "htmlBody": "<p><i>(Edited, to now include a section specifically for FAQs about the virtual program.)</i></p><h1>TL;DR</h1><p>Apply<strong> </strong><a href=\"https://airtable.com/appZIMMH3ywSxS0A9/shrULWsu3oH0BpbMW\"><strong>here</strong></a><strong> </strong>for the third iteration of ARENA (Jan 8th - Feb 2nd)!&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h1>Introduction</h1><p>We are excited to announce the third iteration of ARENA (Alignment Research Engineer Accelerator), a 4-week ML bootcamp with a focus on AI safety. Our mission is to prepare participants for full-time careers as research engineers in AI safety, e.g. at leading organizations or as independent researchers.&nbsp;</p><p>The program will run from January 8th - February 2nd 2024<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5v7eieov9o7\"><sup><a href=\"#fn5v7eieov9o7\">[1]</a></sup></span>, &nbsp;and will be held at the offices of the <a href=\"https://www.safeai.org.uk/\">London Initiative for Safe AI</a>. These offices are also being used by several safety orgs (BlueDot, Apollo, Leap Labs), as well as the current London MATS cohort, and several independent researchers. We expect this to bring several benefits, e.g. facilitating productive discussions about AI safety &amp; different agendas, and allowing participants to form a better picture of what working on AI safety can look like in practice.</p><p>ARENA offers a unique opportunity for those interested in AI safety to learn valuable technical skills, work in their own projects, and make open-source contributions to AI safety-related libraries. The program is comparable to <a href=\"https://www.redwoodresearch.org/mlab\">MLAB</a> or <a href=\"https://www.mitalignment.org/past-progams\">WMLB</a>, but extends over a longer period to facilitate deeper dives into the content, and more open-ended project work with supervision.</p><p>For more information, see <a href=\"https://www.arena.education/\">our website</a>.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/vftyojiau6km78w0waep\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/lazu19fcnlfuvrxby9p3 190w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/x4iwhtd7fikzf26ff4pv 380w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/an3amyftfw5vsaq0au3o 570w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/m2iy8o5rrewhxyxjcjgw 760w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/vkmzfcmeagbi0qtevx0c 950w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/vz4n84w33lwcc73kenoi 1140w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/invmaocfk0acb6oz4rig 1330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/g0yfskwmbtmtpwt97pha 1520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/n2bcqt7fjpd0nm5syysc 1710w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/jl3jpyak94wyjkiumxr8 1888w\"></figure><p>Also note that we have a Slack group designed to support independent study of the material (join link <a href=\"https://join.slack.com/t/arena-uk/shared_invite/zt-28h0xs49u-ZN9ZDbGXl~oCorjbBsSQag\">here</a>).</p><p>&nbsp;</p><h1>Outline of Content</h1><p>The 4-week program will be structured as follows:</p><h2>Chapter 0 - Fundamentals</h2><p>Before getting into more advanced topics, we first cover the basics of deep learning, including basic machine learning terminology, what neural networks are, and how to train them. We will also cover some subjects we expect to be useful going forwards, e.g. using GPT-3 and 4 to streamline your learning, good coding practices, and version control.</p><p><i>Note - participants can optionally not attend the program during this week, and instead join us at the start of Chapter 1, if they'd prefer this option and if we're confident that they are already comfortable with the material in this chapter.</i></p><p>Topics include:&nbsp;</p><ul><li>PyTorch basics</li><li>CNNs, Residual Neural Networks</li><li>Optimization (SGD, Adam, etc)</li><li>Backpropagation</li><li>Hyperparameter search with Weights and Biases</li><li>GANs &amp; VAEs</li></ul><p><i>Duration: 5 days</i></p><h2>Chapter 1 - Transformers &amp; Interpretability</h2><p>In this chapter, you will learn all about transformers, and build and train your own. You'll also study LLM interpretability, a field which has been advanced by Anthropic\u2019s <a href=\"https://transformer-circuits.pub/\">Transformer Circuits sequence</a>, and open-source work by Neel Nanda. This chapter will also branch into areas more accurately classed as \"model internals\" than interpretability, e.g. recent work on steering vectors.</p><p>Topics include:&nbsp;</p><ul><li>GPT models (building your own GPT-2)</li><li>Training and sampling from transformers</li><li><a href=\"https://github.com/neelnanda-io/TransformerLens\">TransformerLens</a></li><li><a href=\"https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html\">In-context Learning and Induction Heads</a></li><li><a href=\"https://www.lesswrong.com/posts/3ecs6duLmTfyra3Gp/some-lessons-learned-from-studying-indirect-object\">Indirect Object Identification</a></li><li><a href=\"https://transformer-circuits.pub/2022/toy_model/index.html\">Superposition</a></li><li><a href=\"https://www.lesswrong.com/posts/HWxLQvzJGeXoLPJWd/actadd-steering-language-models-without-optimization\">Steering Vectors</a></li></ul><p><i>Duration: 5 days</i></p><h2>Chapter 2 - Reinforcement Learning</h2><p>In this chapter, you will learn about some of the fundamentals of RL, and work with OpenAI\u2019s Gym environment to run their own experiments.</p><p>Topics include:</p><ul><li>Fundamentals of RL</li><li><a href=\"https://spinningup.openai.com/en/latest/algorithms/vpg.html#\">Vanilla Policy Gradient</a></li><li><a href=\"https://spinningup.openai.com/en/latest/algorithms/ppo.html\">Proximal Policy Gradient</a></li><li><a href=\"https://openai.com/research/learning-from-human-preferences\">RLHF</a> (&amp; finetuning LLMs with RLHF)</li><li>Gym &amp; <a href=\"https://gymnasium.farama.org/\">Gymnasium</a> environments</li></ul><p><i>Duration: 5 days</i></p><h2>Chapter 3 - Paper Replications</h2><p>We will conclude this program with paper replications, where participants will get guidance and mentorship while they replicate a paper containing material relevant to this course. This should draw on much of the skills and knowledge participants will have accumulated over the last 3 weeks.</p><p><i>Duration: 5 days</i></p><p>&nbsp;</p><p>Below is a diagram of the curriculum as a whole, and the dependencies between sections. Note that this may change slightly in the lead-up to the program.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/xmh20pwuihc3g4dukcka\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/pwyvh1hnpt5o7jaadsk6 560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/srjgggpqyku3pmsytdmx 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/pcrdbt5pzkmgak1mp3pj 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/ytjxnt1gmhrokqwfa4uu 2240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/gm86dq9p6ep6s7fkdxo6 2800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/y505je1b0ozgp3vva3ze 3360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/mekdtwuuhfy7srzejjr9 3920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/vys4hxdzcqkknmezpuqm 4480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/alll2m98mvxst1g1eng3 5040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LM2JnTHygKbn7eKLz/mogqmo6jlpekrazojoxo 5594w\"></figure><p><a href=\"https://colab.research.google.com/drive/1yV6czsp9EWWGORRIeGrdQDdJJ8b7EI4n\">Here</a> is some sample material from the course, which you will be able to full understand once you reach that point in the course. This notebook is on Indirect Object Identification (from the chapter on Transformers &amp; Mechanistic Interpretability), it will represent one of a set of optional 2-day mini projects which participants can choose from towards the end of that 5-day period.</p><p>&nbsp;</p><h1>Virtual Program</h1><p>We're also very excited to announce a virtual program, which will be hosted by <a href=\"https://www.bluedotimpact.org/\">BlueDot</a>'s platform (the same one which is used to host the <a href=\"https://course.aisafetyfundamentals.com/alignment\">AI Safety Fundamentals</a> course). People who are interested in participating virtually should also apply using the same form (they can express their preference for virtual / in-person in this form).&nbsp;</p><p>&nbsp;</p><h1>Call for staff</h1><p>As well as inviting applications from participants, we're also interested in applications from teaching assistants (TAs). You can apply to be a TA for specific chapters of content, if you have particular expertise in them. TAs will be well compensated for their time. Please contact <a href=\"mailto:callum@arena.education\">callum@arena.education</a> with any more questions, or comment on this post and we will try and respond in a timely manner.</p><p>We're also interested in people who can provide DevOps support, particularly during the first week (e.g. setting people up on virtual machines, and resolving technical problems).</p><p>Lastly, if there are some chapters of the course you're highly knowledgeable in, and others you would like to skill up in, we'd be open to a hybrid system of part-TA-ing, part participating. If you're interested in something like this, you should put \"staff\" rather than \"participant\" in the application form (linked at the end of this post), and in the form you'll have the opportunity to specify exactly what you're interested in.</p><h1>&nbsp;</h1><h1>FAQ (general / in-person program)</h1><p>If you have a question not in this list, which you think it would be valuable for people to have an answer for, please comment your question below and we will respond. If you have a question which you don't want to make public, you can message us directly (or ask the question in your application form).</p><p>&nbsp;</p><h3><i>Q: Who is this program suitable for?</i></h3><p>A: We welcome applications from &nbsp;people who fit most or all of the following criteria:</p><ul><li>Care about AI safety and making future development of AI go well</li><li>Relatively strong math skills (e.g. about one year's worth of university-level applied math)</li><li>Strong programmers (e.g. have a CS degree / work experience in SWE, or have worked on personal projects involving a lot of coding)</li><li>Have experience coding in Python</li><li><i>(if applying for in-person program) </i>Would be able to travel to London for 4 weeks, starting 1st Jan (or for 3 weeks, starting 8th Jan)</li></ul><p>We are open to people of all levels of experience, whether they are still in school or have already graduated.</p><p><i>Note - these criteria are mainly intended as guidelines. If you're uncertain whether you meet these criteria, or you don't meet some of them but still think you might be a good fit for the program, please do apply! You can also reach out to us directly, at callum@arena.education.</i></p><p>&nbsp;</p><h3><i>Q: What will an average day in this program look like?</i></h3><p>At the start of the program, most days will involve <strong>pair programming, working through structured exercises designed to cover all the essential material in a particular chapter</strong>. The purpose is to get you more familiar with the material in a hands-on way. There will also usually be a short selection of required readings, designed to inform the coding exercises.</p><p>As we move through the course, some chapters will transition into more open-ended material. For example, in the Transformers &amp; Interpretability chapter, after you complete the core exercises, you'll be able to choose from a large set of different exercises, covering topics as broad as model editing, superposition, circuit discovery, grokking, discovering latent knowledge, and more. In the last week, you'll choose a research paper related to the content we've covered so far &amp; replicate its results (possibly even extend them!)<strong>.</strong> There will still be TA supervision during these sections, but the goal is for you to develop your own research &amp; implementation skills. &nbsp;Although we strongly encourage paper replication during this chapter, we would also be willing to support well-scoped projects if participants are excited about them.</p><p>The program will run on weekdays. Each day will be roughly the length of a normal working day (9am-5pm). There will be no compulsory attendance on weekends, but we might organize AI safety discussion groups or social events during this time. The office space will be available 24-7 for anyone who wants to use it outside regular hours.</p><p>&nbsp;</p><h3><i>Q: How many participants will there be?</i></h3><p>We're expecting between 10-15 participants in the in-person program. For the virtual program, we're anticipating numbers in the range of 20-40.</p><p>&nbsp;</p><h3><i>Q: Will there be prerequisite materials?</i></h3><p>A: Yes, we will be sending you prerequisite reading &amp; exercises covering material such as PyTorch, einops and some linear algebra (this will be in the form of a Colab notebook). We expect that these will take approximately 1-2 days to complete.</p><p>&nbsp;</p><h3><i>Q: When is the application deadline?</i></h3><p>A: The deadline for submitting applications is <strong>November 27th, 11:59 pm UK time </strong>(i.e. 3 weeks from today). However, we will be interviewing and making offers to candidates on a <strong>rolling basis</strong>.</p><p>&nbsp;</p><h3><i>Q: What will the application process look like?</i></h3><p>A: There will be three steps:</p><ol><li>Fill out the application form (this is designed to take ~20 minutes).</li><li>Perform a coding assessment.</li><li>Interview virtually with one of us, so we can find out more about your background and interests in AI safety &amp; this course.</li></ol><p>&nbsp;</p><h3><i>Q: Can I join for some sections, but not others?</i></h3><p>A: Participants will be expected to attend the whole workshop. The material is interconnected, not learning all of it would lead to a disjointed experience. We have limited space and therefore are more excited about offering spots to participants who are able to come for the entirety of the program.<br><br>The exception to this is the first week, which participants can chose to opt in or out of based on their level of prior experience.&nbsp;</p><p>&nbsp;</p><h3><i>Q: Will you pay stipends to participants?</i></h3><p>A: Unfortunately, we won't be able to pay stipends to participants. However, we will be providing housing &amp; travel assistance to in-person participants (see below).</p><p>&nbsp;</p><h3><i>Q: Which costs will you be covering, for the in-person program?</i></h3><p>A: We will be providing \u00a3500 in travel assistance per participant, as well as \u00a31000 in housing assistance, and up to \u00a3500 in visa assistance if this is needed. Meals and office space will be covered by us (and the LISA offices are kept well-stocked with snacks!).</p><p>&nbsp;</p><h3><i>Q: I'm interested in trialling some of the material, or recommending material to be added. Is there a way I can do this?</i></h3><p>A: If either of these is the case, please feel free to reach out directly via an EAForum/LessWrong message (or email at callum@arena.education) - we'd love to hear from you!</p><p>&nbsp;</p><h3><i>Q: Do you plan to run more bootcamps in the future?</i></h3><p>A: Possibly! If you can't make these dates, then we encourage you to submit an application anyway (the form is designed to be relatively low-effort to fill out). We were pleased with the impact &amp; feedback received from the second iteration of this program, and we'd be excited to continue to run these bootcamps if this program is also well-received. We may also take steps to help university groups teach a version of this curriculum (similar to how WMLB and CamLAB teach versions of the MLAB curriculum).</p><p>&nbsp;</p><h3><i>Q: How has the program been changed from the second iteration?</i></h3><p>A: For a full answer to this question, see our <a href=\"https://www.lesswrong.com/posts/9fbr7axHenRAL5Gkm/arena-2-0-impact-report\">impact report</a> for the previous iteration of this program. A short version of the main changes we've chosen to make:</p><ul><li>A shorter program overall (4 weeks rather than 6),</li><li>Paper replications rather than capstone projects to conclude the program,</li><li>A much more extensive \"Transformers &amp; Interpretability\" chapter, including material outside of the strict definition of mechanisic interpretability (e.g. activation steering and DLK),</li><li>Removal of the \"Training at Scale\" chapter (although we'll be keeping some aspects of this curriculum),</li><li>Some other small adjustments to particular chapters (e.g. adding material on GANs &amp; VAEs in the first week, replacing other less essential material such as array stride operations),</li><li>A better-structured reading program, which ties closer into the curriculum material.</li></ul><p>&nbsp;</p><h1>FAQ (virtual program)</h1><p>&nbsp;</p><h3><i>Q: Will the virtual program be full-time?</i></h3><p>A: Yes, it will be full time for the 3/4 week duration of the program. Each day will usually consist of a lecture of length 15-60 minutes outlining the core ideas which are important for that day's exercises, followed by working through the coding exercises. We don't expect virtual participants to complete as many exercises as the in-person participants (see next question).</p><p>&nbsp;</p><h3><i>Q: Will the virtual and in-person curricula be different?</i></h3><p>A: They'll follow the same basic week-to-week structure. However, we understand that people completing the program virtually won't be able to work at the same pace as people completing it in-person. We will be indicating which parts of the exercises are essential and which can be skipped, and we'll also generally avoid having exercises be too interdependent so participants don't fall behind if they can't complete one particular day.</p><p>&nbsp;</p><h3><i>Q: Can I miss sessions in the virtual program?</i></h3><p>A: As mentioned above, the exercises generally won't be heavily interdependent. There are some exceptions (e.g. none of the material in the transformers chapter can be tackled until you've gone through the process of implementing your own transformer). However, we'll do our best to structure things so that participants can complete less of a particular section (or even miss sections) and still keep pace with the rest of the course.</p><p>&nbsp;</p><h3><i>Q: What feedback will be given during the virtual program?</i></h3><p>A: At the end of each day of exercises, participants will submit their work (in the form of a link to a shared Colab, or a GitHub repo). They can also request feedback on specific parts of their solution, which we will be able to provide.</p><p>&nbsp;</p><h3><i>Q: What if I'm interested in the virtual program, and I've already done some of the exercises?</i></h3><p>A: If these are the compulsory exercises (e.g. any in chapter 0, or the start of chapter 1), you can work on bonus material during this time if you prefer. Alternatively, you can work on some of the other optional sets of exercises (e.g. chapter 1 contains a very large set of different possible exercises, of which most participants will only have time to try a few). Regardless of which sections you've completed, we still encourage attending the virtual talks and events we'll host during this time.</p><p>&nbsp;</p><h3><i>Q: Will the virtual program still have pair-programming?</i></h3><p>A: Yes, we will be providing support for pair programming, and heavily encouraging this. If it's not feasible for you then we will allow people to work on their own (or choose a middleground e.g. coworking but not pair programming), however we strongly encourage pair programming because it's a pretty vital part of the overall experience.</p><p>&nbsp;</p><h3><i>Q: Will the assessments be different for virtual and in-person?</i></h3><p>A: No, the assessments will be the same for both cases. However, we expect to have a higher bar for the in-person assessments, because places will be more limited.</p><p>&nbsp;</p><h3><i>Q: Will we provide compute support for the virtual program?</i></h3><p>A: Unfortunately, we won't be able to provide compute via a provider like we will for the in-person program. We'll encourage the use of Colab (all the exercises have associated Colab notebooks), and we will be able to reimburse people for Colab pro subscriptions for the duration of ARENA. If people would prefer to use their own IDEs &amp; source their own compute, then we'll provide as much assistance as we can (setup instructions and a Slack group for devops support-related questions), although we won't be able to offer as much support as we can for the in-person group, so we recommend the Colab option to most people unless you're already comfortable setting up your own coding workspace &amp; environment.</p><p>&nbsp;</p><h3><i>Q: I want to meet people who are interested in alignment, and am worried the virtual program will not help me do that.</i></h3><p>A: We intend to help virtual participants network with each other, through pair programming, virtual discussion groups, and office hours. We also encourage virtual participants to reach out to each other to discuss the material, cowork, or hear what each other are working on.</p><p>&nbsp;</p><h3><i>Q: Can I attend a hybrid of virtual / in-person?</i></h3><p>A: We will be able to invite virtual participants as guests to the office for short periods, if they are in the vicinity of the LISA offices. This will be a great opportunity to meet us and chat to the other researchers using the space. However, we can't guarantee virtual participants the use of the office space for extended periods.</p><p>&nbsp;</p><h1>Link to Apply</h1><p><a href=\"https://airtable.com/appZIMMH3ywSxS0A9/shrULWsu3oH0BpbMW\"><strong>Here</strong></a><strong> </strong>is the link to apply (it is the same for participants and staff). You shouldn't spend longer than 20-30 minutes on it.</p><p>We look forward to receiving your application!</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5v7eieov9o7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5v7eieov9o7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The first week will be optional, as we discuss further down in this post.</p></div></li></ol>", "user": {"username": "Callum McDougall"}}, {"_id": "TanBoThzLsDB8bvYg", "title": "Numerical Breakdown of 47 1-on-1s as an EAG First-Timer (Going All Out Strategy)", "postedAt": "2023-11-06T17:01:34.090Z", "htmlBody": "<h2>tl;dr</h2><p>Just attended my first ever EA Global conference (EAG Boston last week) and I have nothing but positive things to say.</p><p>In total, I had about 47 one-on-one conversations depending on how you count the informal 1:1s (43 scheduled via SwapCard, while the other noteworthy conversations happened at meetups, the organization fair, office hours and unofficial satellite events).</p><p>I came into the conference with an open mind, wanting to talk to others who are smarter than me, more experienced than me, and experts in their own domain. I invited redteaming of our nonprofit StakeOut.AI\u2019s mission/TOC, and gathered both positive and negative feedback throughout EAG. I came out of the conference with new connections, a refined strategy for our nonprofit startup going forward and lots of resources.</p><p>I am so grateful for everyone that met with me (as I\u2019m a small potato who at many times felt out of his depth during EAG, and likely one of the most junior EAs attending). I thank all the organizers, volunteers, helpers, speakers and attendees who made the event a huge success.</p><p>The post below goes over <a href=\"https://forum.effectivealtruism.org/posts/TanBoThzLsDB8bvYg/numerical-breakdown-of-47-1-on-1s-as-an-eag-first-timer#The_Preparation\">The Preparation</a>, the <a href=\"https://forum.effectivealtruism.org/posts/TanBoThzLsDB8bvYg/numerical-breakdown-of-47-1-on-1s-as-an-eag-first-timer#Statistics_and_Breakdown\">Statistics and Breakdown</a>, why consider <a href=\"https://forum.effectivealtruism.org/posts/TanBoThzLsDB8bvYg/numerical-breakdown-of-47-1-on-1s-as-an-eag-first-timer#Why_Go_All_Out_\">going all out</a> at an EAG, <a href=\"https://forum.effectivealtruism.org/posts/TanBoThzLsDB8bvYg/numerical-breakdown-of-47-1-on-1s-as-an-eag-first-timer#12_Practical_Tips_for_Doing_30__1_1s_During_EAG\">12 Practical Tips for Doing 30+ 1:1s</a> and <a href=\"https://forum.effectivealtruism.org/posts/TanBoThzLsDB8bvYg/numerical-breakdown-of-47-1-on-1s-as-an-eag-first-timer#4_Things_I_Would_Change_to_Further_Maximize_an_EAG\">potential future improvements</a>.</p><p><br><br>&nbsp;</p><h2>The Preparation</h2><p>To be honest, as a first-time attendee, I really didn\u2019t know what to expect nor how to prepare for the conference.</p><p>I had heard good things and was recommended to go by fellow EAs, but I had my reservations.</p><p>Luckily, an email titled \u201cJoin us for an EAG first-timers online workshop!\u201d by the EA Global Team came to the rescue.</p><p>Long story short, I highly recommend anyone new to EAG to attend the online workshop prior to the conference if you want to make your first EAG a success.</p><p>Few highlights I will note here:</p><ul><li>Watch<a href=\"https://www.youtube.com/watch?v=cfcv6prrJxo&amp;ab_channel=CentreforEffectiveAltruism\">&nbsp;<u>this presentation</u></a> from 2022\u2019s San Francisco EAG that outlines how you can get the most out of the event</li><li>Take your time and fill out this&nbsp;<a href=\"https://docs.google.com/document/d/1BCjkGXThTxdplverqtjFr6UL9HZdJIz-UHOsMI9aZqE/edit\"><u>EA Conference: Planning Worksheet</u></a> for a step-by-step guide on conference planning, including setting your EAG goals and expectations</li><li>Also fill out the career planning worksheet (if relevant):&nbsp;<a href=\"https://docs.google.com/document/d/1sou3qHjzTiXcMBhGs1vdv8TNiabFuw0L6MNBbRBOwm0/edit#heading=h.ewoky5ru67jy\">&nbsp;EA Conference: Career Plan</a></li></ul><p><br>&nbsp;</p><h3>Requesting 1:1s Pre-conference&nbsp;</h3><p>I was quite hesitant at first about introducing myself on SwapCard and trying to schedule 1:1s. This all changed after watching&nbsp;<a href=\"https://www.youtube.com/watch?v=cfcv6prrJxo&amp;ab_channel=CentreforEffectiveAltruism\"><u>the presentation</u></a> and attending the \u201cJoin us for an EAG first-timers online workshop!\u201d virtual event.</p><p>Something that was repeated over and over again from<a href=\"https://www.youtube.com/watch?v=cfcv6prrJxo&amp;ab_channel=CentreforEffectiveAltruism\">&nbsp;<u>this presentation</u></a>, the online workshop, and talking to others is the value of the 1:1s.</p><p>People told me most sessions will be recorded and hence can be watched later, but having the 1:1s is where the true value is at EAG. After hearing it from so many people, I made 1:1s a core part of my conference planning and did not regret it.</p><p>As I\u2019m writing this after the conference, I can see why 1:1s are said to be the true value of EAG. I estimate that 80% (maybe even closer to 90%, I would know better after I sort through the notes) of the 1:1 conversations I had were beneficial and had a positive impact on either me or the direction of our nonprofit, StakeOut.AI.</p><p><br>&nbsp;</p><h3>How Many 1:1s?</h3><p>In terms of how many 1:1s, here is the range I gathered from different sources:</p><ul><li>Attendees will typically have four to ten 1:1s</li><li>Getting to 20 1:1s is a great number</li><li>Having 30 1:1s is amazing but very tiring</li><li>Someone reached 35 1:1s once, and that was insane</li></ul><p>Since I wanted to maximize my EAG experience, I set the goal of 30 and started reaching out via SwapCard one week before the conference.</p><p><br>&nbsp;</p><h3>Reach Out Early</h3><p>The main reason for starting early is because everyone is busy at the conferences, and everyone is trying to optimize their schedule.</p><p>This is especially true for senior EAs (more well-known) who would get requests from other senior EAs (likely people they know from before who have been around EA and want to connect in person) and juniors EAs who feel the senior\u2019s advice would really help. Thus, the senior EAs\u2019 schedules in theory would fill up much quicker when compared to junior EAs.</p><p>That\u2019s why you want to contact and introduce yourself ASAP (before their calendar is filled).</p><p>&nbsp;</p><p>I am not sure if I was late to the game starting to message out seven days before the conference. Would I have secured more meetings if I started earlier? I\u2019m not sure there is a way to test this since I cannot repeat being a first-timer.</p><p>Either way, I committed hours and hours and hours to reading profiles, and sending introduction messages.</p><p>Then, to my surprise, I had 28 1:1s booked by Wednesday, a couple of days before the conference started on Friday.</p><p><br>&nbsp;</p><h2>Statistics and Breakdown</h2><p>EAG has a very cool culture built in, and it\u2019s unlike anything I\u2019ve ever seen. Coming from the business world where the conferences and seminar environments are mostly about \u201cgetting\u201d, what I experienced at EAG Boston is the exact opposite: \u201cgiving.\u201d</p><p>The numbers below are an attempt to quantify this, and these are staggering percentages when I compare it to anything else I\u2019ve been to in terms of professional networking.</p><p>Caveat</p><ul><li>Please take this with a grain of salt, as this is only one person\u2019s experience, out of 920 attendees (as per the SwapCard attendee spreadsheet, after removing duplicate names)</li><li>I\u2019ve tried my best in the limited time I have to make it as accurate as possible. Please forgive me for calculation errors or any misrepresentations</li></ul><p><br>&nbsp;</p><h3>Overview</h3><ul><li>106 SwapCard conversations (all EAG Boston related conversations as this is my first EAG)</li><li>59 conversations had notes (only conversations that warranted notes or follow-up items were accounted, the other more casual conversations were excluded)</li><li>59/106 = 55.7% of the SwapCard conversations can be tied back to a meaningful meeting (this includes both people I reached out to, people that reached out to me, and people I met at the conference)</li><li>106/920 = 11.5% contacted of the 920 attendees (as per the SwapCard attendee spreadsheet, after removing duplicate names)</li></ul><p><br>&nbsp;</p><h3>Reaching Out Via SwapCard&nbsp;(Total of 106 SwapCard conversations)</h3><ul><li>93/106 = 87.7% of the conversations were initiated by me (I estimate 80% of these were before the event happened, 20% of during the event as I was meeting people and getting recommendations at the event on who I should reach out to)<ul><li>25/93 = 26.9% did not respond to my reach out message (this is an abnormally low percentage when compared to the business world - for context this means including all the EA \u201ccelebrities\u201d I contacted, the message response rate was a stunning 73.1%)</li></ul></li><li>13/106 = 12.3% of the conversations where others reaching out to me</li></ul><p><br>&nbsp;</p><h3>% Agreed to Meetings</h3><ul><li>As per above<ul><li>I had about 47 one-on-one conversations (43 scheduled via SwapCard, while the others noteworthy conversations happened at meetups, the organization fair, office hours and unofficial satellite events)</li><li>Total of 106 SwapCard conversations</li></ul></li><li>43/106 = 40.6% scheduled via official 1:1 on SwapCard</li><li>47/106 = 44.3% of the 1:1s that occurred were either official SwapCard 1:1, or 1:1 conversations that happened at meetups, the organization fair, office hours and unofficial satellite events</li><li>54/106 = 50.9% would include all meetings at EAG and after the conference<ul><li>There are about 7 people who I reached out to or canceled the 1:1 at the event who agreed to schedule virtual calls after the conference</li><li>47+7 estimates the total meetings established from SwapCard and EAG</li></ul></li></ul><p><br>&nbsp;</p><h3>Conversation Lengths (Including 1:1s and Causal Chats)</h3><ul><li>Conversation lengths roughly followed a bell-shaped curve with a longer left tail (the majority of the conference time I had 1:1s scheduled, attended only 2-3 talks, and a couple meetups)</li><li>Left tail<ul><li>There were 5-10 causal chats that lasted less than the five-minute mark</li><li>There were only two scheduled 1:1s that ended at the 15 minute mark</li></ul></li><li>Middle<ul><li>The majority of the conversations hit the 25-30 minute mark</li></ul></li><li>Right tail<ul><li>There were about four scheduled 1:1s that were in the 45-60 minute mark</li></ul></li></ul><p>&nbsp;</p><p>&nbsp;</p><h3>What Yielded Noteworthy Conversations?</h3><ul><li>(59 conversations had notes (only conversations that warranted notes or follow-up items were accounted, the other more casual conversations were excluded))</li><li>47/59 = 86.4% of the noteworthy conversations were either official SwapCard 1:1, or 1:1 conversations that happened at meetups, the organization fair, office hours and unofficial satellite events</li><li>43/59 = 72.9% of the noteworthy conversations were official 1:1s scheduled via SwapCard</li><li>16/59 = 27.1% of the noteworthy conversations (59-43=16; aka not an official SwapCard 1:1) happened at meetups, the organization fair, office hours and unofficial satellite events</li></ul><p><br>&nbsp;</p><h3>In Summary</h3><ul><li>Take initiative as a junior and/or first-timer EAG attendee: 87.7% of the SwapCard conversations were initiated by me</li><li>The response rate for reaching out on SwapCard (including to EA celebrities), was a staggering 73.1%</li><li>From a single EAG, it\u2019s possible to have 54 meetings (including meetings at EAG and after the conference)</li><li>The majority of the conversations hit the 25-30 minute mark</li><li>72.9% of the noteworthy conversations were official 1:1s scheduled via SwapCard, while 27.1% of the noteworthy conversations (aka not an official SwapCard 1:1) happened at meetups, the organization fair, office hours and unofficial satellite events</li></ul><p><br><br>&nbsp;</p><h2>Why Go All Out?</h2><h3>I Believe There is Huge Potential to Do Good</h3><p>I went all out because I believe we have an idea, a vision that can really do good in the AI safety cause area. And I wanted to check it against experts and other EAs by inviting on the spot red teaming, to make sure we are not crazy nor being illogical.</p><p>I went all out because AI risks are an urgent and critical global issue. It's imperative to pause or, at the very least, slow down AI until we research and implement robust measures to prevent both short-term risks and long-term catastrophic, potentially even extinction-level events.</p><p>My conviction in this is so high that I\u2019ve been basically volunteering with StakeOut.AI since Sep 4th, 2023 without income, despite the need to provide for my kids. I\u2019m spending more than full-time hours certain weeks on our nonprofit, in hopes that we will eventually succeed in fundraising and, as a result, secure even a modest salary.&nbsp;</p><p>Without funding nor a regular income, coming to EAG was a leap of faith, paying for the travel expenses out of pocket. I tried my best to keep the costs down by flying red-eye, couchsurfing 2 out of the 4 nights, commuting via by foot and public transit only, and limiting expenses on meals (aka eating conference snacks and Soylent as dinner).</p><p><br>&nbsp;</p><h3>Why You Might Consider Maximizing Your EAG</h3><p>Because you can get more done in 2.5 days of conference time, than weeks of work combined.</p><p>The EAG conference attendees all require their applications to be approved before they go.&nbsp; That means, everyone who is going at some level is vetted. This makes it a conducive environment for meaningful and noteworthy conversations.</p><p>Additionally, when you spend the time to read the other attendees' profiles and find people who can help you (or who you can help), these conversations are more than likely to have a positive impact for either or both parties.</p><p>&nbsp;</p><p>Lastly, think about the last time you tried to reach out to an expert or someone more senior, was it easy or difficult to get some time with them even for a virtual meeting? My experience is that coordination takes time even if they are willing to meet. This is because reaching out to others are usually interruptions to their normal work routine, while they are actively juggling mountains of to-dos.</p><p>In contrast to an EAG, seniors and juniors alike, everyone that\u2019s attending already committed their time to the conference and are in the mindset of meeting and helping others. They made themselves available, and this is the low hanging fruit and time you want to maximize. This is where you can meet with as many collaborators or experts as possible to get advice from while they are mentally primed to collaborate.</p><p>Just think, when is the next time you can get a full 25 minutes of uninterrupted time with experts in the field, people smarter than you, or more experience than you, talking about your particular situation or questions? This is something that rarely happens in the business world, but in EA, it\u2019s part of the culture that\u2019s amazingly the norm at EAGs!</p><p><br><br>&nbsp;</p><h2>12 Practical Tips for Doing 30+ 1:1s During EAG</h2><ol><li>Start your meetings ASAP - my first one started at 14:30 on Friday and I landed in Boston around 12:00</li><li>Block your schedule ahead of time for very important sessions you don\u2019t want to miss, then leave the rest of the schedule open to meetings (yes, even the 21:00 and 21:30 slots)</li><li>Start your day early and take advantage of the 8:00 and 8:30 appointment slots</li><li>People are going to cancel scheduled 1:1s because life happens (could not make the event after all because of emergencies, ran out of energy near end of day, waited at another spot instead of specified spot because their phone died), so expect it and have backup sessions to go to (or <strong><u>if your schedule is extremely packed, these cancellations will give you time to take a break</u></strong>)</li><li>Look ahead to see how many back to backs you have, and plan your bathroom breaks</li><li>If need be, hurry/run to the bathroom right after a 1:1, then hurry/run to the next meeting spot (which means on Day 1 you need to memorize the map and know your way around the venue)</li><li>Since you will likely have back to backs, try your best to schedule so that most of your meeting points are in the same general area</li><li>When you have a break, prepare for the next few meetings because back to back meetings usually means you won\u2019t have time to read the next person\u2019s profile</li><li>Stay hydrated and fed - I drank many Soylents each day :)&nbsp;</li><li>It's never too late to send a 1:1 request. It was 20:55 while I was at the organization fair, and someone recommended that I talk to a specific person. I reached out and got a confirmed meeting at 21:30 because people are so generous with their time - though I think it was easier because I had permission to use a name for the introduction message</li><li>It's not all about 1:1s - I had some great connections that occurred at the themed meetup groups</li><li>Prepare a notetaking Google Doc ahead of time. A simplified version of this&nbsp;<a href=\"https://docs.google.com/document/d/10pHFNk19hMxwXaIDQDT2q8XUrrCX4xfGMW1sHNmCX0M/edit\"><u>1-1s Template EAGxVirtual&nbsp;</u></a> is all you need for in-person meetings at EAG. I used the SwapCard export function to add the event meetings and agenda into my Google Calendar. Then from Google Docs, you can type @ and create \u201cSmart Chips\u201d for each meeting event ahead of time that looks like this (so the person\u2019s bio, and relevant information is already there without needing to reference SwapCard):</li></ol><p><br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/TanBoThzLsDB8bvYg/l8f10r2oqdd5hjq3469i\"></p><p><br>&nbsp;</p><h2>4 Things I Would Change to Further Maximize an EAG</h2><ol><li>I attended an event on Saturday night which yielded two noteworthy conversations. Given that I had blocked out four hours in my schedule (eight one-on-one slots) because of the commute and event time, I think it would have been more productive if I stayed at the venue and scheduled more 1:1s. The commuting time to and back to my accommodations took at least two hours in total, which sums to a total of two hours of not meeting with people.</li><li>If possible, it would be great to have EAG provide dinner again (like previous EAGs before this one). The reason is, when attendees need to leave for dinner, it means less people are sticking around for 1:1s after 19:00. This is something I heard from multiple people, and I agree with their assessment.</li><li>If there was a feature like the slack channel #spontaneous-happenings, but catered to 1:1s inside of SwapCard, that would be very cool.&nbsp; The reason being the notification blindness for slack channel notifications. Personally, I have multiple slacks on my phone and cannot check everything. However, during the conference, any SwapCard notifications has my utmost attention and thus would be more helpful in arranging more spontaneous 1:1s. A feature where you can opt-in and say I\u2019m free this time range and I\u2019m open to 1:1s would be great. Other people can do the same and thus automatically create a group where you can browse anyone that\u2019s available, making it easy to reach out for spontaneous 1:1s.</li><li>It\u2019s pretty obvious when someone isn\u2019t paying attention to you when you are talking to them, either in an 1:1 or a casual conversation. I don't know what the socially appropriate norm is within an EAG when this happens. Perhaps you have experienced this, and I\u2019m wondering what other EAs do.</li></ol><p><br><br><br>&nbsp;</p><h2>Final Thoughts</h2><p>If you use the \u201cgo all out\u201d strategy, your body might take a toll. This extreme strategy is not for everybody, and you have to listen to your body.</p><p>I felt under the weather after I flew back home, when all the adrenaline was gone.</p><p>I\u2019ve taken a complete day off to recover, and am still coughing a bit as I\u2019m typing this up.</p><p>&nbsp;</p><p>But would I do it again if I was accepted to another EAG? The answer is unequivocally yes.</p><p>There is no question coming out from this 2.5 days conference was equivalent to doing weeks of work and totally worth the effort and time.</p><p>Of course, this wouldn\u2019t be possible without everyone involved, so thank you again to all the organizers, volunteers, helpers, speakers and attendees who made the EAG Boston phenomenal.</p><p><br>&nbsp;</p><h2>Other Resources</h2><h3>Advice from Others</h3><p>This post was just my take and definitely not representative of attendees as a whole, please read the following posts for other advice (as I did) about maximizing your EAG listed in no particular order:</p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/meGkWcnuZSyMZ4Pex/how-to-make-your-first-eag-a-success\"><u>How to Make Your First EAG a Success</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/ixdejJKnonBmaiF4T/add-randomness-to-your-ea-conferences\"><u>Add randomness to your EA conferences</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/3kFWJLy7uBYgeQ4xs/advice-for-getting-the-most-out-of-one-on-ones\"><u>Advice for getting the most out of one-on-ones</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/sxKJckCiZQyux4kCx/ea-global-tips-networking-with-others-in-mind\"><u>EA Global Tips: Networking with others in mind</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/pKbTjdopzSEApSQfc/doing-1-on-1s-better-eag-tips-part-ii\"><u>Doing 1-on-1s Better - EAG Tips Part II</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/5hKDjrGocGcreH3DC/how-to-get-the-maximum-value-out-of-effective-altruism\"><u>How to Get the Maximum Value Out of Effective Altruism Conferences</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/HmDSQQtJkkfcXQibu/three-reflections-from-101-ea-global-conversations\"><u>Three Reflections from 101 EA Global Conversations</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/wFP5KzcksFutS4Eew/what-i-learnt-from-twenty-1-1s-at-eagxoxford\"><u>What I learnt from twenty 1:1s at EAGxOxford</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/Z7xaEWvjZA3HEqceE/how-to-find-good-1-1-conversations-at-eagx-virtual\"><u>How to Find Good 1-1 Conversations at EAGx Virtual</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/NrLCM4vcf8PRqkLaH/guide-to-successful-community-1-1s\"><u>Guide to Successful Community 1-1s</u></a></li></ul><p><br>&nbsp;</p><p>One comment from the above posts really helped me a lot and I think would be useful to highlight is from&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/3kFWJLy7uBYgeQ4xs/advice-for-getting-the-most-out-of-one-on-ones?commentId=wouXJuYjj2SXEi8vW\"><u>https://forum.effectivealtruism.org/posts/3kFWJLy7uBYgeQ4xs/advice-for-getting-the-most-out-of-one-on-ones?commentId=wouXJuYjj2SXEi8vW</u></a>:</p><blockquote><p>This seems like great advice to me. This part particularly rings true:</p><p><i><strong>First, speaking from experience, I find that EAs are more likely than average to hold a meeting with you even if you don't have anything tangible to offer them. When you think about it, by helping you have more of an impact, they're also increasing they're own impact, which is motivating for most EAs. Don't let not having anything to offer immediately keep you from reaching out to someone you think you could have a valuable conversation with!</strong></i></p><p>I was very surprised with how many \"EA celebrities\"* were happy to meet with me at EAG, despite me being pretty new to EA and not having much to contribute for them. And they seemed not just&nbsp;<i>begrudgingly willing&nbsp;</i>based on a cost-benefit analysis of the possibility they'd increase my impact, but genuinely&nbsp;<i>enthusiastic</i> about being helpful, asking me about my current plans, etc.</p><p>So definitely don't be too shy about reaching out to people!</p></blockquote><p>&nbsp;</p><h3>Backpocket Questions</h3><p>I had prepared a list of backpocket questions for the one-on-ones inspired by one of the posts above. I did not end up using it at all because most of my conversations naturally flowed and we had more than enough to talk about for the given time slot.</p><p>Each category has three questions, feel free to reference this as you see fit:</p><p>&nbsp;</p><p><strong>1. Understanding Background and Motivation</strong>:</p><ul><li><strong>Why did you want to do X?</strong>: Gauges both personal and professional motivations, providing context for potential collaboration within the EA framework.</li><li><strong>What was your background before X?</strong>: Gives you insight into their journey, expertise, and areas where there might be potential synergies or collaboration opportunities.</li><li><strong>What was the last thing you changed your mind about (in relation to your career or approach within EA)?</strong>: Indicates adaptability, growth, and openness to evolving within the EA space.</li></ul><p><strong>2. Practical Aspects of the Role</strong>:</p><ul><li><strong>What do you do day to day?</strong>: Understanding their daily tasks can help you identify areas of overlap or potential collaboration.</li><li><strong>What skills are most useful for this role within the EA movement?</strong>: Discerns specific expertise or capabilities that are in demand, offering potential collaboration opportunities.</li><li><strong>How do you measure success in your role or project, especially in terms of impact?</strong>: Helps you understand their metrics and goals, aligning potential collaborations to meet shared objectives.</li></ul><p><strong>3. Assessing Impact and Contribution</strong>:</p><ul><li><strong>What's a bottleneck you have with regard to having more impact?</strong>: Identifying challenges can open up areas where your collaboration might assist or offer solutions.</li><li><strong>What do you think is the most neglected project/activity in your field within EA?</strong>: Offers insights into untapped areas or opportunities that might align with your collaboration interests.</li><li><strong>What impact do you believe your work has within the EA framework?</strong>: Provides insight into their vision and the tangible results they aim for, revealing potential collaboration or support opportunities.</li></ul><p><strong>4. Advice and Recommendations</strong>:</p><ul><li><strong>Given my background in [your field/collaboration], where do you see potential synergies with the EA movement?</strong>: This directly solicits advice on how you can integrate your collaboration with the goals of the EA community.</li><li><strong>Can you think of organizations or projects within EA that could benefit from [your specific collaboration expertise or service]?</strong>: Helps identify immediate potential collaborations or partnerships.</li><li><strong>What emerging trends or shifts within the EA movement should I be aware of?</strong>: Ensures you stay ahead of the curve and understand potential future opportunities or challenges.</li></ul><p><strong>5. Passion and Future Plans</strong>:</p><ul><li><strong>If resources were not a constraint, what project or initiative within EA would you prioritize?</strong>: Provides a glimpse into their vision and where they see the most potential impact, which can be valuable for long-term planning.</li><li><strong>What do you see as the future trajectory or evolution of your role or project within the EA landscape?</strong>: Offers insights into the future of their work and where there might be intersections with your collaboration.</li><li><strong>If you could introduce me to one person at this conference, who would it be and why?</strong>: This not only potentially extends your network but also provides insight into key influencers or thought leaders in the EA community.</li></ul><p><br>&nbsp;</p><h2>Acknowledgment</h2><p>I would like to give a special thank you to Dr. Peter S. Park and Amy Frieder for editing this post and for all our future collaborations!</p>", "user": {"username": "Harry Luk"}}, {"_id": "xbiJRzSJKq69RRHDd", "title": "Why you should publish your research in academic fashion", "postedAt": "2023-11-06T16:55:52.970Z", "htmlBody": "<p><br>It is not uncommon in the EA-sphere to publish your research on your own website, GitHub, LessWrong or the EAForum. However, I think that more people should consider publishing their research as is usual in academia.</p><h2>Reasons</h2><p>If you are publishing on select webpages only:</p><h3>1 - You are actively excluding most researchers from ever noticing your work</h3><p>Your research is in all likelihood built upon decades, or perhaps centuries of academic research. Researchers actively browse the academic literature in the areas that they are interested in. If you do not publish your research in a fashion that is noticed by academic databases such as Google Scholar, you will lose a lot of readers. Furthermore, these researchers might have used your research as a building block for their research. In other words, you are actively slowing down future academic research.</p><p>Even worse, your research might be forgotten.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflkfcjvzdbr\"><sup><a href=\"#fnlkfcjvzdbr\">[1]</a></sup></span></p><h3>2 - You will not become part of the public debate on a topic</h3><p>Most policy-makers, civil servants and the general public seem to value academic credentials and academic research. I find it likely that you are not going to be invited to speak on a topic, if you have not published your research in an outlet that signals credibility to policy-makers. If you want to make a difference with your research by bringing it into policy, you would be better off not (just) publishing it on your blog.</p><h3>3 - You are declining free expert feedback</h3><p>A journal submission may result in low-cost feedback by other researchers.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1d16lixf8pl\"><sup><a href=\"#fn1d16lixf8pl\">[2]</a></sup></span>&nbsp;This strikes me as a useful thing to have, particularly as articles such as the <a href=\"https://forum.effectivealtruism.org/posts/8c7LycgtkypkgYjZx/agi-and-the-emh-markets-are-not-expecting-aligned-or\">post on interest rates and AGI</a> seem to be influential, but would have been rejected by many economists.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7og1r2mge5t\"><sup><a href=\"#fn7og1r2mge5t\">[3]</a></sup></span></p><h2>Objections</h2><p>Most people that do not publish their research in a way so that it emerges in academic databases name two main objections.</p><h3>1- Publishing in academic journals takes a lot of time and money and we do not have the time for this bull****</h3><p>This would have been a fair objection in 2005, but I do not think that it is any longer. Many researchers read and use research published as a pre-print on webservers such as arXiv, as long as it is good research.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7yb7omawl5q\"><sup><a href=\"#fn7yb7omawl5q\">[4]</a></sup></span></p><p>&nbsp;It does not take a lot of time to do this and your article is guaranteed to be found by scholarly search machines. You do not need to go through the tiresome process of submitting to academic journals in order for your research to be read by most researchers in your field.</p><h3>2 - My research is intended for a very select viewership only</h3><p>This objection is a good one. However, I think that it applies only to a very small set of research. Namely, research institutes and think tanks who target policy-makers directly and already know that they will be taken seriously. However, if their research may be interesting for others too, they should probably consider publishing it openly as well.</p><h2>An explanation for the trend to publish outside of academia</h2><p>I think that the benefits of publishing in an academic fashion usually far outweigh the costs. So why do people publish their research on non-academic websites?</p><p>My very speculative account of why this happens is best explained through an example research paper that I recently came across (on a personal website). The author wrote:</p><blockquote><p>I am choosing to publish [this here] because journals tend to be extractive and time consuming, and because I am in a position to not care about them.</p></blockquote><p>I think the author has done great research and I do not want to criticise that particular decision. But I think that this sentence may reveal some hidden motives.</p><p>Of course, academic journals are all about prestige and people with an \"EA-mindset\" may be inclined to reject this notion. However, I think that the sentence \"because I am in a position to not care about them\" carries an important message. If the author is in a position to reject prestige-via-journal-publication, this is itself a way of signalling status among the rationalist and EA-community. Maybe it is simply seen as cool to publish your research straight to LessWrong and not to Probability&amp;Statistics Letters. &nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlkfcjvzdbr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflkfcjvzdbr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Did you kow that Europeans have rediscovered Vitamin C at least <i>seven</i> times in around 500 years only to forget about this piece of research quickly after discovery? This information was <i>incredibly important</i> since treating scurvy was very cost-effective back then.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1d16lixf8pl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1d16lixf8pl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Of course, peer review is often shitty and slow. But often it is also helpful. Hey, it is free!</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7og1r2mge5t\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7og1r2mge5t\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Interest rates are not only affected by the way people discount the future. Interest rates in most industrialised countries are largely controlled by the central bank and therefore contain little foresight regarding AGI Timelines.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7yb7omawl5q\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7yb7omawl5q\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See as an example this <a href=\"https://arxiv.org/pdf/1804.02385.pdf%20rel=%22nofollow%22\">work</a> of Aubrey de Grey, which is a simple post to arXiv. The article is minimalistic, and surely did not take a lot of time to typeset. This research has sparked immense work in mathematics despite the fact that it has never been published in an academic journal, the author is not a formally trained mathematician and not affiliated with an organization related to maths.</p></div></li></ol>", "user": {"username": "Hans Waschke-Wischedag"}}, {"_id": "unFycWDoyDHdHQGT5", "title": "How Rethink Priorities is Addressing Risk and Uncertainty", "postedAt": "2023-11-07T13:42:46.903Z", "htmlBody": "<p>This post is part of Rethink Priorities\u2019 Worldview Investigations Team\u2019s&nbsp;<a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj\">CURVE Sequence</a>: \u201cCauses and Uncertainty: Rethinking Value in Expectation.\u201d The aim of this sequence is twofold: first, to consider alternatives to expected value maximization for cause prioritization; second, to evaluate the claim that a commitment to expected value maximization robustly supports the conclusion that we ought to prioritize existential risk mitigation over all else.</p>\n<h1>Introduction</h1>\n<p>RP has committed itself to doing good. Given the limits of our knowledge and abilities, we won\u2019t do this perfectly but we can do this in a principled manner. There are better and worse ways to work toward our goal. In this post, we discuss some of the practical steps that we\u2019re taking to navigate uncertainty, improve our reasoning transparency, and make better decisions. In particular, we want to flag the value of three changes we intend to make:</p>\n<ul>\n<li>Incorporating multiple decision theories into Rethink Priorities\u2019 modeling</li>\n<li>More rigorously quantifying the value of different courses of action</li>\n<li>Adopting transparent decision-making processes</li>\n</ul>\n<h1>Using Multiple Decision Theories</h1>\n<p>Decision theories are frameworks that help us evaluate and make choices under uncertainty about how to act.<sup class=\"footnote-ref\"><a href=\"#fn-qbSCrWF8ZjWaFfKba-1\" id=\"fnref-qbSCrWF8ZjWaFfKba-1\">[1]</a></sup> Should you work on something that has a 20% chance of success and a pretty good outcome if success is achieved, or work on something that has a 90% chance of success but only a weakly positive outcome if achieved? Expected value theory is the typical choice to answer that type of question. It calculates the expected value (EV) of each action by multiplying the value of each possible outcome by its probability and summing the results, recommending the action with the highest expected value. But because low probabilities can always be offset by corresponding increases in the value of outcomes, traditional expected value theory is vulnerable to the charge of fanaticism, \u201crisking arbitrarily great gains at arbitrarily long odds for the sake of enormous potential\u201d (<a href=\"https://globalprioritiesinstitute.org/nick-beckstead-and-teruji-thomas-a-paradox-for-tiny-probabilities-and-enormous-values/\">Beckstead and Thomas, 2021</a>). Put differently, it seems to recommend spending all of our efforts on actions that, predictably, won\u2019t achieve our ends.</p>\n<p><a href=\"https://docs.google.com/document/d/13SCTWfpixNmZbDkmCA6vJGxFU0034-0il9C6grMFkek/edit\">Alternative decision theories have significant drawbacks of their own</a>, giving up one plausible axiom or another. The simple alternative is expected value maximization but with very small probabilities rounded down to zero. This gives up the axiom of&nbsp;<em>continuity</em>, which suggests for a relation of propositions A \u2265 B \u2265 C, that there exists some probability that would make you indifferent between B and a probabilistic combination of A and C. This violation causes some weird outcomes where, say, believing the chance of something is 1 in 100,000,000,000 can mean an action gets no weight but believing it\u2019s 1.0000001 in 100,000,000,000 means that the option dominates your considerations if the expected value upon success is high enough, which is a kind of attenuated fanaticism. There are also other problems like setting the threshold for where you should round down.<sup class=\"footnote-ref\"><a href=\"#fn-qbSCrWF8ZjWaFfKba-2\" id=\"fnref-qbSCrWF8ZjWaFfKba-2\">[2]</a></sup></p>\n<p>Alternatively, you could go with a procedure like weighted-linear utility theory (WLU) (<a href=\"https://onlinelibrary.wiley.com/doi/full/10.1111/phpr.13006\">Bottomley and Williamson, 2023</a>), but that gives up the principle of&nbsp;<em>homotheticity</em>, which involves indifference to mixing a given set of options with the worst possible outcome. Or you could go with a version of risk-weighted expected utility (REU) (<a href=\"https://academic.oup.com/book/9439\">Buchak, 2013</a>) and give up the axiom of&nbsp;<em>betweenness</em> which suggests the order in which you are presented information shouldn\u2019t alter your conclusions.<sup class=\"footnote-ref\"><a href=\"#fn-qbSCrWF8ZjWaFfKba-3\" id=\"fnref-qbSCrWF8ZjWaFfKba-3\">[3]</a></sup></p>\n<p>It\u2019s very unclear to us, for example, that giving up&nbsp;<em>continuity</em> is preferable to giving up&nbsp;<em>homotheticity</em>, and neither REU or WLU really logically eliminate issues with fanaticism (even if it seems in practice, say,&nbsp;<a href=\"https://docs.google.com/document/d/1CZ5S-Eayxr64z5YADYR9M3P2WTp4u2Pgb4N-ynYbbMU/edit#heading=h.iythm7rs7118\">WLU produces negative values for long shot possibilities in general</a>)<sup class=\"footnote-ref\"><a href=\"#fn-qbSCrWF8ZjWaFfKba-4\" id=\"fnref-qbSCrWF8ZjWaFfKba-4\">[4]</a></sup>. It seems once you switch from pure EV to other theories, whether it be REU, WLU, expected utility with rounding down, or some other future option, there isn\u2019t an option that\u2019s clearly best. Instead, many arguments rely on competing, but ultimately not easily resolvable, intuitions about which set of principles are best. Still, at worst, it seems the weaknesses in these alternative options are similar in scope to the amount of weakness provided to pure EV logically suggesting spending (and predictably wasting) all of our resources not on activities like x-risk prevention or insect welfare, but on actions like interacting with the multiverse or improving the welfare of protons.<sup class=\"footnote-ref\"><a href=\"#fn-qbSCrWF8ZjWaFfKba-5\" id=\"fnref-qbSCrWF8ZjWaFfKba-5\">[5]</a></sup></p>\n<p>Broadly, we don\u2019t think decision theories with various strengths and weaknesses, axiomatic and applied, are the type of claim you can be highly confident about. For this reason, we ultimately think you need to be unreasonably confident that a given procedure, or set of procedures that agree on the types of actions they suggest, is correct (possibly &gt;90%) in order for the uncertainty across theories and what they imply not to impact your actions.<sup class=\"footnote-ref\"><a href=\"#fn-qbSCrWF8ZjWaFfKba-6\" id=\"fnref-qbSCrWF8ZjWaFfKba-6\">[6]</a></sup> While there are arguments and counterarguments for many of these theories, we\u2019re more confident in the broad claim that no arguments for one of these theories over all the others is decisive than we are in any particular argument or reply for any given theory.</p>\n<p>So, we still plan to calculate the EV of the actions available to us, since we think in most cases this is identical to EV with rounding down. However, we won\u2019t&nbsp;<em>only</em> calculate the EV of those actions anymore.<sup class=\"footnote-ref\"><a href=\"#fn-qbSCrWF8ZjWaFfKba-7\" id=\"fnref-qbSCrWF8ZjWaFfKba-7\">[7]</a></sup> Now, we plan to use other decision theories as well, like REU and WLU, to get a better understanding of the riskiness of our options. This allows us, among other things, to identify options that are robustly good under decision theoretic uncertainty. (As Laura Duffy notes in a&nbsp;<a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj/p/9EENSGhiQiKFaRh4t\">general discussion of risk aversion and cause prioritization</a> and in&nbsp;<a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj/p/LCfd56cBeRzrMiAhw\">the case of only the next few generations</a>, work on corporate campaigns for chickens fits this description: it\u2019s never the worst option and rarely produces negative value across these procedures). Using a range of decision theories also helps us represent internal disagreements more clearly: sometimes people agree on the probabilities and values of various outcomes, but disagree about how to weigh low probabilities, negative outcomes, or outcomes where our gamble doesn\u2019t pay off. By formalizing these disagreements, we can sometimes resolve them.</p>\n<h1>Quantify, Quantify, Quantify</h1>\n<p>We\u2019ve long built models to inform our decision-making.<sup class=\"footnote-ref\"><a href=\"#fn-qbSCrWF8ZjWaFfKba-8\" id=\"fnref-qbSCrWF8ZjWaFfKba-8\">[8]</a></sup> However, probabilities can be unintuitive and the results of more rigorous calculations are often surprising. We\u2019ve discovered during the&nbsp;<a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj\">CURVE sequence</a>, for instance, that small changes to different kinds and levels of risk-aversion can alter what you ought to do; and, even if you assume that you ought to maximize expected utility,&nbsp;<a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj/p/S9H86osFKhfFBCday\">making small adjustments to future risk structures and value trajectories</a> have significant impacts on the expected value of the existential risk mitigation work. And, of course, before the present sequence, RP has built many models, for example,&nbsp;<a href=\"https://forum.effectivealtruism.org/s/y5n47MfgrKvTLE3pw/p/Qk3hd6PrFManj8K6o\">to try to estimate some moral weights for animals</a>, finding significant variance across them.<sup class=\"footnote-ref\"><a href=\"#fn-qbSCrWF8ZjWaFfKba-9\" id=\"fnref-qbSCrWF8ZjWaFfKba-9\">[9]</a></sup></p>\n<p>What\u2019s more, there are key areas where we know our models are inadequate. For example, it\u2019s plausible that returns on different kinds of spending diminish at different rates, but estimating these rates remains difficult. We need to do more work to make thoughtful tradeoffs between, say, AI governance efforts and attempts to improve global health. Likewise, it\u2019s less complex to assess the counterfactual credit due to some animal welfare interventions but extremely difficult to estimate the counterfactual credit due to efforts to reduce the risk of nuclear war. Since these kinds of factors could swing overall cost-effectiveness analyses, it\u2019s crucial to keep improving our understanding of them. So, we\u2019ll keep investigating these issues as systematically as we can.</p>\n<p>None of this is to say we take the outputs of these types of quantitative models literally. We don\u2019t. Nor is it to claim there is no place at all for qualitative inputs or reasoning in our decision-making. It is to say we think quantifying our uncertainties whenever possible generally helps us to make better decisions. The difficulty of accounting for all of the above issues are typically made worse, not better, when precise quantitative statements of beliefs or inputs are replaced by softer qualitative judgments. We think the work in the CURVE sequence has further bolstered this case that even when you can\u2019t be precise in your estimates, quantifying your uncertainty can still significantly improve your ability to reason carefully.</p>\n<h1>Transparent Decision-Making</h1>\n<p>Knowing how to do good was hard enough before we introduced alternative decision theories. Still, RP has to make choices about how to distribute its resources, navigating deep uncertainty and, sometimes, differing perspectives among our leadership and staff. Since we want to make our choices sensitive to our evidential situation and transparent within the organization, we\u2019re committed to finding a decision-making strategy that allows us to navigate this uncertainty in a principled manner. Thankfully, there are a wide range of deliberative decision-making processes, such as Delphi panels and citizen juries, that are available for just such purposes.<sup class=\"footnote-ref\"><a href=\"#fn-qbSCrWF8ZjWaFfKba-10\" id=\"fnref-qbSCrWF8ZjWaFfKba-10\">[10]</a></sup> Moreover, there are a number of formal and informal methods of judgment aggregation that can be used at the end of the deliberative efforts.</p>\n<p>We aren\u2019t yet sure which of these particular decision procedures we\u2019ll use and we expect creating such a process and executing it to take time.<sup class=\"footnote-ref\"><a href=\"#fn-qbSCrWF8ZjWaFfKba-11\" id=\"fnref-qbSCrWF8ZjWaFfKba-11\">[11]</a></sup> All of these procedures have drawbacks in particular contexts and we don\u2019t expect any such procedure to be able to handle all the specific decisions that RP faces. However, we\u2019re confident that a clearly defined decision procedure that forces us to be explicit about the tradeoffs we\u2019re making and why is superior to unilateral and intuition-based decision-making. We want to incorporate the best judgment of the leaders in our organization and own the intra- and inter-cause comparisons on which our decisions are based. So, we\u2019re in the process of setting up such decision procedures and will report back what we can about how they\u2019re operating.</p>\n<h1>Conclusion</h1>\n<p>We want to do good. The uncertainties involved in doing good are daunting, particularly given we are trying to take an impartial, scope sensitive, open to revision approach. However, RP aims to be a model of how to handle uncertainty well. In part, of course, this requires trying to reduce our uncertainty. But lately, we\u2019ve been struck by how much it requires recognizing the depth of our uncertainty\u2014all the way to the very frameworks we use for decision-making under uncertainty. We are trying to take this depth seriously without becoming paralyzed\u2014which explains why we\u2019re doubling down on modeling and collective decision-making procedures.</p>\n<p>In practice, we suspect that a good rule of thumb is to spread our bets across our options. Essentially, we think we\u2019ve entered a dizzying casino where the house won\u2019t even tell us the rules of the game. And even if we knew the rules, we\u2019d face a host of other uncertainties: the long-term payouts of various options, the risk of being penalized if we choose incorrectly among various courses of action, and a host of completely inscrutable possibilities where we have no idea what to think of them. In a situation of this type, it seems like a mistake to assume that one ruleset is correct and proceed accordingly. Instead, we want to find robustly good options among different plausible rulesets whenever we can. And when we can\u2019t, we may want to distribute our resources in proportion to different reasonable approaches to prioritization.</p>\n<p>This isn\u2019t perfect or unobjectionable. But nothing is. RP will continue to do its best to make these decisions as transparently as we can, learning from our mistakes and continuing to try to advance the cause of improving the world.</p>\n<h1>Acknowledgements</h1>\n<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/unFycWDoyDHdHQGT5/hfvhx6cjkpkfyts10ahb\" alt=\"\"></p>\n<p>The piece was written by Marcus A. Davis and Peter Wildeford. Thanks to David Moss, Abraham Rowe, Janique Behman, Carolyn Footitt, Hayley Clatterbuck, David Rhys Bernard, Cristina Schmidt Ib\u00e1\u00f1ez, Jacob Peacock, Aisling Leow, Renan Araujo, Daniela R. Waldhorn, Onni Aarne, Melissa Guzikowski, and Kieran Greig&nbsp; for feedback. A special thanks to Bob Fischer for writing a draft of this post. The post is a project of Rethink Priorities, a global priority think-and-do tank, aiming to do good at scale. We research and implement pressing opportunities to make the world better. We act upon these opportunities by developing and implementing strategies, projects, and solutions to key issues. We do this work in close partnership with foundations and impact-focused non-profits or other entities. If you're interested in Rethink Priorities' work, please consider subscribing to our&nbsp;<a href=\"https://rethinkpriorities.org/newsletter\">newsletter</a>. You can explore our completed public work&nbsp;<a href=\"https://rethinkpriorities.org/research\">here</a>.</p>\n<hr>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn-qbSCrWF8ZjWaFfKba-1\" class=\"footnote-item\"><p>As discussed in this post, when we refer to \u201cdecision theories\u201d we are referring to normative theories of rational choice without regard to the distinction between evidential decision theory and causal decision theory. That distinction is about whether one should determine their actions based on expected causal effects, causal decision theory, or, for evidential decision theory, based on whether you should do what actions have the best news value (taking the action you will have wanted to learn that you will do), whether or not this was driven by causal effects. <a href=\"#fnref-qbSCrWF8ZjWaFfKba-1\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-qbSCrWF8ZjWaFfKba-2\" class=\"footnote-item\"><p>This is something we would like to see explored further in research. Presently, the choice of where to set the threshold could seem to be somewhat arbitrary, with no current solid arguments about where to set such a threshold that doesn\u2019t refer to hypothetical or real cases and consider whether outcomes of those cases are acceptable. <a href=\"#fnref-qbSCrWF8ZjWaFfKba-2\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-qbSCrWF8ZjWaFfKba-3\" class=\"footnote-item\"><p>Violations of homotheticity and betweenness are both violations of the principle of independence, which decomposes into these two principles. As such, both REU and WLU violate independence. <a href=\"#fnref-qbSCrWF8ZjWaFfKba-3\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-qbSCrWF8ZjWaFfKba-4\" class=\"footnote-item\"><p>We are aware that discussion of these principles can sound rather abstract. We think it's fine to be unfamiliar with these axioms and what they imply (we also weren't familiar with them before the past few years). What seems less ideal is having an unshakable belief that a particular rank ordering of these abstract principles is simple or obvious such that you can easily select a particular decision theory as superior to others, particularly once you decide to avoid fanaticism. <a href=\"#fnref-qbSCrWF8ZjWaFfKba-4\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-qbSCrWF8ZjWaFfKba-5\" class=\"footnote-item\"><p>Some may doubt that EV would require this, but if you preemptively rule out really implausible actions like extending the existence of the universe that could have a really high value if done, even if the probability is really small, then in practice you are likely calculating expected value maximization with rounding down. This is what we think most actors in the EA space have been doing in practice rather than pure expected value maximization. For more on why, and what axioms different decision theory options including expected value maximization with rounding down are giving up, see the WIT sequence supplement from Hayley Clatterbuck on <em><a href=\"https://docs.google.com/document/d/13SCTWfpixNmZbDkmCA6vJGxFU0034-0il9C6grMFkek/edit\">Fanaticism, Risk Aversion, and Decision Theory</a></em>. For more on why fanaticism doesn\u2019t endorse x-risk prevention or work on insects see <em><a href=\"https://forum.effectivealtruism.org/posts/sEnkD8sHP6pZztFc2/fanatical-eas-should-support-very-weird-projects\">Fanatical EAs should support very weird projects</a></em> by Derek Shiller. For more on how one might maintain most of the value of expectational reasoning while not requiring actions like this, see Tarnsey 2020 <em><a href=\"https://arxiv.org/pdf/1807.10895.pdf\">Exceeding Expectations: Stochastic Dominance as a General Decision Theory</a></em>. <a href=\"#fnref-qbSCrWF8ZjWaFfKba-5\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-qbSCrWF8ZjWaFfKba-6\" class=\"footnote-item\"><p>Suppose, as an example, you are ~50% confident in pure EV, and 50% confident that conditional on pure EV being incorrect, EV with rounding down is best. That would imply an absolute credence of 25% in EV with rounding down and a 25% chance you think some other non-EV option is correct. If you were 70% confident in EV and 70% confident conditional on it being false that EU with rounding down is right that would leave your split as 70% EV, 21% EU with rounding down, 9% something else. If you were instead equally uncertain about these strengths and weaknesses across the theories discussed above, it would imply a 25% credence to each of WLU, REU, pure EV, and EV with rounding down (assuming you assigned no weight to other known theories and to the possibility that there may, say, be future theories distinct from these known options). Overall, because these theories often directionally disagree on the best actions, you need to line up confidence across theories to be just right to avoid uncertainty in what actions are recommended. <a href=\"#fnref-qbSCrWF8ZjWaFfKba-6\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-qbSCrWF8ZjWaFfKba-7\" class=\"footnote-item\"><p>A counterargument here would be to say that expected utility or expected utility with rounding down is clearly superior to these other options and as such we should do whatever it says. In addition to our broader concerns we\u2019ve mentioned about the type of evidence that can be brought to bear not being definitive, one problem with this type of response is it assumes the correct aggregation method across decision procedures either heavily favors EV outputs (in practice or for a theoretical reason) or that we can be confident now that all these alternatives are incorrect (i.e. the weight we should put in them is below ~1%). Neither move seems justifiable from the present knowledge we have. It\u2019s worth noting in their 2021 paper <em><a href=\"https://philarchive.org/archive/MACTEW-2\">The Evidentialist's Wager</a></em> MacAskill et al. discuss the aggregation of evidential and causal decision theories but, for a variety of reasons, we don\u2019t think the solutions posed for that related but separate dilemma apply here. <a href=\"#fnref-qbSCrWF8ZjWaFfKba-7\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-qbSCrWF8ZjWaFfKba-8\" class=\"footnote-item\"><p>For example, we\u2019ve built models to estimate the cost-effectiveness of particular interventions and to retrospectively assess the value of our research itself, both at the org level and at the level of individual projects. These models have often been inputs into our decision-making or to what we advise others to do. <a href=\"#fnref-qbSCrWF8ZjWaFfKba-8\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-qbSCrWF8ZjWaFfKba-9\" class=\"footnote-item\"><p>Another example of the fragility of models is visible in Jamie Elsey's and David Moss's post <em><a href=\"https://forum.effectivealtruism.org/posts/zHFBQ23o4DKjsoXcC/incorporating-and-visualizing-uncertainty-in-cost\">Incorporating and visualizing uncertainty in cost effectiveness analyses: A walkthrough using GiveWell\u2019s estimates for StrongMinds</a></em> examining how modeling choices involving handling uncertainty can significantly alter your conclusions. <a href=\"#fnref-qbSCrWF8ZjWaFfKba-9\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-qbSCrWF8ZjWaFfKba-10\" class=\"footnote-item\"><p>In this context, citizen juries, Delphi panels, and other deliberative decision-making procedures would be designed to help us assign credences across different theories, or make specific decisions in the face of uncertainty and disagreement across participants. <a href=\"#fnref-qbSCrWF8ZjWaFfKba-10\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-qbSCrWF8ZjWaFfKba-11\" class=\"footnote-item\"><p>We also aren\u2019t sure when we\u2019ll do these things as they all take time and money. For example, analyzing different decision making frameworks and thinking through the cost-curves across interventions could involve ~3-6 months of work from multiple people. <a href=\"#fnref-qbSCrWF8ZjWaFfKba-11\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n</ol>\n</section>\n", "user": {"username": "Marcus_A_Davis"}}, {"_id": "49BFw2WEKC34oiYD2", "title": "III. Running its course", "postedAt": "2023-11-04T19:31:51.511Z", "htmlBody": "<p>When we cast a broad light, the evolution of any species is considered either by chance and/or by choice. The evolution of weapons, however, is often misinterpreted as the outcome of chance events. In the previous parts, we have seen the factors point to choices that vary across different species. Both options are feasible, often working in tandem, provided the effective cost of change is not significantly high.</p><p>Once the arms race is triggered, weapons start getting sizable and more sophisticated. In animals, as long as the selection pressure is applied, natural or artificial, the rate of development varies with the required application. In the book, the author demonstrated the evolution of weapons in rhinoceros beetles in an artificial setting to study the variation in cost and size. It is important to note that for an animal species, the primary loss is bodily changes affecting its life cycle. Since the life cycle of the beetles is short, it is possible to observe salient evolutionary changes in a short span of time. The author conducted his research for two and a half years.&nbsp; The results of the research were clear. There was a significant increase in the size of the horns. However, since the availability of internal resources was limited, deficit spending resulted in unsustainable growth. The eyes of the beetles were shunted, along with affected wings and genitalia. In comparison, horn growth was three times as sensitive to wings and limbs.</p><h2>Reliable signals and Deterrence</h2><p>The affordability of a weapon is dependent on the resource pool of animal species. Similar to humans, family and bloodline play a major role in how capable the new generation can be. Weapons get bigger when the rest of the body turns fully grown. What propels the race is the opportunity cost. Whenever an opportunity to invest in weapons development leads to viable returns, animal species can create a discretionary pool to further the size. This is because weapons act as reliable signals to all parties, favoring females as well as rival males. For both battle purposes and protection, weapons advertise honest proofs of investment, and information like health status and fighting ability. This allows rivals to assess each other before engaging in dangerous battles. Avoidance is the best option for those not close to the top of the ladder as they live to fight another day.</p><p>For those who are stronger, the deterrence alone is enough. Weapons in animals are vastly more variable than other bodily elements. The dominant ones in a species need to fight with rivals of comparable strength and full attention. Small battles can cause minor injuries, which may later result in risks of distraction and exposure to predation. This is visible in the case of fiddler crabs with huge claspers. Most of the time, fiddlers employ their claws as warnings rather than instruments of battle. They use them as an agent of deterrence for weaker crabs. They do use them for intense fights, but only for a few minutes. After they spend hours waving up and down. This also acts as a welcoming signal for female crabs that are far away from fights as not all fights end well.&nbsp; Normally, crabs are well protected from one another, since their exoskeletons are like armor, but in the heat of a battle, crabs get distracted and become easy targets for gulls and grackles.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefuj23ptic8gi\"><sup><a href=\"#fnuj23ptic8gi\">[1]</a></sup></span></p><p>Deterrence acts as an integral stage in an arms race. The evolutionary increase in size keeps up with the rate of extreme possessors. As signals, weapons become more honest by pushing the evolution of deterrence to avoid deadly confrontations. Fight costs saved by deterrence boost the already-fulfilled gains for males with the largest weapons. For example, the total horn length of male ibexes, a wild goat species, is ~20 cm for up to 3 years, whereas for individuals \u226510 years, the average lies between 60 and 80 cm.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrrvh2q91g3p\"><sup><a href=\"#fnrrvh2q91g3p\">[2]</a></sup></span>&nbsp;In a typical challenge, Ibex rams size each other up, comparing weapon sizes; most confrontations end without escalating to battle.</p><p>This cycle fuels the race to keep getting faster. To quote the author: Arms races and deterrence push each other forward, escalating in an evolutionary spiral. Nowadays, the odds of war on the sea are extremely low. It was different not so long ago. The size of the fleet was the measure of a country\u2019s fighting ability\u2014the perfect signal for deterrence. &nbsp;The research underscores that certainty plays a more significant role in deterrence than severity.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefic5zi3qlkjm\"><sup><a href=\"#fnic5zi3qlkjm\">[3]</a></sup></span>&nbsp;Warships used to chase down rivals of comparable size while medium-sized ones focused on escapes. Smaller ships used to either get destroyed or shied away. These elongated battles were too expensive for states to afford. For naval battles, state-of-the-art weapons are still too expensive. As a result, warships are close to being extinct, rather, aircraft carriers serve as the new agents of deterrence.</p><p>&nbsp;</p><h2>Sneaks and Cheats/End of the Race</h2><p>When fighting doesn't ensure a victory, you need to opt for plan B. Strong monopolies incentivize individuals to evolve their way of fighting. Many animals chose alternative ways to infiltrate rival territories for the sake of mating. In the case of dung beetles, males with big horns are often deceived when a weaker rival male reaches the guarded female through a tunnel from a different end, avoiding the confrontation altogether. That's why males are observed doing guarding duty in rounds, but the infiltrators with far smaller weapons are quick and agile. In animals like Bighorn sheep, the strategy to disguise is fairly common as sneaky males are found almost in every species. Since most eminent males are bigger in size and weapons compared to females, smaller males can effectively sneak past the guards and camouflage in the herd.&nbsp;</p><p>Similar courses of action are visible when talking about human conflicts and warfare. The definition of cheating becomes irrelevant in an active war when one military force cannot stand a chance against a larger one. Non-combatants and spies blend inside rival warring states as sneak forces. They stay in the game just by surviving in disguise. The surprise element can dismantle large tanks by slipping IEDs (improvised explosive devices) and disabling deadly weapons, making the bulk of conventional forces a liability. Guerilla warfare, a paragon of sneak tactics, is the foremost way of battle in a majority of small countries with poor economies.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkgre1zpqy9o\"><sup><a href=\"#fnkgre1zpqy9o\">[4]</a></sup></span>&nbsp;Even the conflicts between large nations are heavily dependent on sneaky submarines capable of knocking down aircraft carriers positioned in relatively safer territory.</p><p>The biggest cheat of the current era comes in the form of cyberattacks. Getting access to rival weapons can cripple the entire military force to a scary extent. A compromised security system is the worst nightmare for a warring nation as it may pose an existential risk to the population. In these Zero-day attacks, codes are deeply embedded until the day they are needed. Once active, hackers can gain control of everything from missile guidance systems to navigation and handling of submarines, to aircraft and aircraft carriers.</p><p>With the advent of such high risks in handling the deadliest of weapons, the end of the weapons race becomes the only option.</p><p>In the case of animals, the evolution of weapons is bound to reach an equilibrium stage. Bigger weapons in animals start losing their advantage, stalling the arms race, and the population settles on a new size. The relative benefit of weapon growth often fails to keep up with the associated cost, especially when the resources to sustain deplete in the surroundings. These circumstances are further exploited by others leading to the extinction of the entire species (for ex. &nbsp;Sabertooth, Mammoth).</p><p>Human civilization is surrounded by a realm of costs, resources, expenses, payoffs, etc., at different points. &nbsp;Enrichment of cheats is primarily backed by innovation and the trigger for change. When horse-mount soldiers were investing in shiny-bulky armor and engraved swords, foot soldiers invented the crossbow and longbows that pierced through centuries of investment in battle gear. As long-range weapons became more sophisticated and effective, we saw the birth of guns that collapsed the race for melee weapons. In such cases, even after the race ends, the weapons linger in various parts of society because of their low cost and considerable payoffs at the time.</p><p>&nbsp;</p><p>In the final part, we'll see the extension of the parallels we have seen in the first three parts to the current state of human technologies, how it affects war in our time, and some important distinctions...</p><p>&nbsp;&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnuj23ptic8gi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefuj23ptic8gi\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://academic.oup.com/beheco/article/18/3/521/222422\">https://academic.oup.com/beheco/article/18/3/521/222422</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrrvh2q91g3p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrrvh2q91g3p\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.12839\">https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.12839</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnic5zi3qlkjm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefic5zi3qlkjm\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.ojp.gov/pdffiles1/nij/247350.pdf\">https://www.ojp.gov/pdffiles1/nij/247350.pdf</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkgre1zpqy9o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkgre1zpqy9o\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.ojp.gov/ncjrs/virtual-library/abstracts/war-flea-study-guerilla-warfare-theory-and-practice\">https://www.ojp.gov/ncjrs/virtual-library/abstracts/war-flea-study-guerilla-warfare-theory-and-practice</a></p><p>&nbsp;</p></div></li></ol>", "user": {"username": "Mayank Modi"}}, {"_id": "gxppfWhx7ta2fkF3R", "title": "10 years of Earning to Give", "postedAt": "2023-11-07T23:35:53.463Z", "htmlBody": "<p><i>General note: The bulk of this post was written a couple of months ago, but I am releasing it now to coincide with the </i><a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#First_weekly_theme__Effective_Giving_Spotlight__November_7_14_\"><i>Effective Giving Spotlight</i></a><i> week. I shortly expect to release a second post documenting some observations on the community building funding landscape.&nbsp;</i></p><h1>Introduction</h1><p>Way back in 2010, I was sitting in my parents' house, watching one of my favourite TV shows, the UK's Daily Politics. <a href=\"https://www.bbc.co.uk/news/av/uk-politics-11948231\">That day's guest</a> was an Oxford academic by the name of Toby Ord. He was donating everything above \u00a318000 (\u00a326300 in today's money) to charity, and gently pushing others to give 10%.</p><p>\"Nice guy,\" I thought. \"Pity it'll never catch on.\"</p><p>Two years later, a couple of peers interned at Giving What We Can. At the same time, I did my own internship in finance, and my estimate of my earning potential quadrupled<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref44e2wwj53ap\"><sup><a href=\"#fn44e2wwj53ap\">[1]</a></sup></span>. One year after that, I graduated and took the Giving What We Can pledge myself. While my pledge form read that I had committed to donate 20% of my income, my goal was to hit far higher percentages.</p><p>How did that go?</p><h1>Post goals</h1><p>Earning To Give was one of EA's first ideas to get <a href=\"http://www.nytimes.com/2013/06/04/opinion/brooks-the-way-to-produce-a-person.html\">major mainstream attention</a>, much of it negative. Some was mean-spirited, but some of it read to me as a genuine attempt to warn young people about what they were signing up for. For example, from the linked David Brooks piece:</p><blockquote><p>From the article, Trigg seems like an earnest, morally serious man...</p><p>First, you might start down this course seeing finance as a convenient means to realize your deepest commitment: fighting malaria. But the brain is a malleable organ....Every hour you spend with others, you become more like the people around you.</p><p>If there is a large gap between your daily conduct and your core commitment, you will become more like your daily activities and less attached to your original commitment. You will become more hedge fund, less malaria. There\u2019s nothing wrong with working at a hedge fund, but it\u2019s not the priority you started out with.</p></blockquote><p>At the time, EAs had little choice but to respond to such speculation with speculation of their own. At this point, I can at least answer how some things have played out for me personally. I have divided this post into reflections on my personal EtG path and on the EA community.&nbsp;</p><h1>My path</h1><p>First, some context. Over the past decade:</p><ul><li>My wife <a href=\"https://forum.effectivealtruism.org/users/denise_melchin\">Denise</a> and I have donated \u00a31.5m.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsukqzh3uyo\"><sup><a href=\"#fnsukqzh3uyo\">[2]</a></sup></span></li><li>This equates to 46% of our combined gross incomes.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsukqzh3uyo\"><sup><a href=\"#fnsukqzh3uyo\">[2]</a></sup></span></li><li>The rest of the money is split 550k / 550k / 700k between spending / saving (incl. pension) / taxes.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsukqzh3uyo\"><sup><a href=\"#fnsukqzh3uyo\">[2]</a></sup></span></li><li>We have three children (ages 13, 6, 2) and live in London.</li><li>I work as a trader, formerly at a quant trading firm and now at a hedge fund.&nbsp;</li></ul><h2>Work</h2><p>Many critics of EtG assume that we really want to be doing something meaningful, but have - with a heavy heart - intellectually conceded that money is what matters.</p><p>I want to emphasise this: This is not me, and I doubt it applies to even 20% of people doing EtG. <i><strong>If you currently feel this way, I strongly suspect you should stop.</strong></i></p><p>I like my work. I get to work with incredibly sharp and motivated people. I get to work on a diverse array of intellectual challenges. Most of all, I've managed to land a career that bears an uncanny resemblance to what I do with my spare time; playing games, looking for inconsistencies in others' beliefs, and exploiting that to win.&nbsp;</p><p>But prior to discovering EtG, I was wrestling with the fact that this natural choic<span>e</span> just seemed very selfish. As I saw it, my choices were to do something directly useful and be miserable but valuable, or to work in finance and be happy but worthless. So a reminder that the money I have a <a href=\"https://www.econlib.org/library/Topics/Details/comparativeadvantage.html\">comparative advantage</a> in earning is itself of value was a relief, not a burden.&nbsp;</p><p>My career pathway has not been smooth, with a major derailment in 2018, which has had a very large impact on my income and donation potential. I may one day tell this story in a standalone post, as <a href=\"https://forum.effectivealtruism.org/posts/QFa92ZKtGp7sckRTR/my-mistakes-on-the-path-to-impact\">my wife has done</a> for her case. But for now, I would make the following observations, targeted towards people who are relatively young or new to EA:</p><ul><li>Burnout is extremely expensive, because it does not just cost time in and of itself but can move your entire future trajectory. If I were writing practical career tips for young EAs, my first headline would be \"Whatever you do, don't burn out.\"</li><li>Plenty of people in the EA community have burned out. A small number of us talk about it. Most people, understandably, prefer to forget and move on. Beware this and other selection effects in (a) who is successful enough that you are listening to them in the first place and (b) what those people choose to talk about.&nbsp;</li><li>Despite the fact that the EA community <a href=\"https://forum.effectivealtruism.org/posts/NDszJWMsdLCB4MNoy/burnout-what-is-it-and-how-to-treat-it\">talks</a> about (other people's) <a href=\"https://forum.effectivealtruism.org/posts/ZGW8Tmc6mDWZTnqyo/burnout-and-self-care\">burnout</a> a lot, many incentive gradients do in fact push people to burn out at what appear to me to be higher-than-baseline rates.<ul><li>This distinction between 'what does the community <i>incentivise</i>?' and 'what does the community <i>say</i>?' comes up in a lot of my conversations, especially with EA leadership. As befits my profession, I tend to think talk is cheap and incentives are what count, but not everybody agrees!</li></ul></li></ul><h2>Lifestyle Inflation</h2><p>A concern I felt keenly was that it would be difficult to keep a lid on spending. If your colleagues are talking about their latest fancy vacation or showing off an expensive phone, aren't you going to feel compelled to keep up?</p><p>I think this was a case of being right but for the wrong reasons.&nbsp;</p><p>Note that trying to assess lifestyle inflation over time is challenging for a few reasons, foremost in my case is how to think about housing costs after buying property. In the below I take a rental equivalence approach.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflrr6h8xefsf\"><sup><a href=\"#fnlrr6h8xefsf\">[3]</a></sup></span>&nbsp;</p><p>Here is my household spending over time, by UK tax year (April - March), current year projected:</p><figure class=\"image image_resized\" style=\"width:85.32%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/ntm7lomxjh5773z6rynq\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/syc0d2ssdm7ks3dpdkml 112w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/brxyxqq5ocmiqvyguztf 192w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/wzlcah8ohawwiwax2cwd 272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/rwshqez06nsngczl3s8t 352w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/knx23n5sahjgv1eddjc9 432w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/sbeeegldmrvga2xz5wjl 512w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/tfsxp5gxzpxn1hj9usvi 592w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/xngcf65ebxrtkbwmzfpn 672w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/au0xkkfbcjapfsb5z6oj 752w\"></figure><p>Quite the increase! But of course, there has been some inflation over the past decade. So let's adjust everything into today's money:</p><figure class=\"image image_resized\" style=\"width:85.16%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/e5yli8edsotnk4c0hbqk\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/jmeqlgyrqkuzindqgg6q 112w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/qay1odkze4d52ocstwke 192w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/hqylxkgncytvm08zccau 272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/fl0nozhwz7knqqktgcnx 352w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/uirem8eeimdoergkiivg 432w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/a8d3hw3wdfiy6vjkgp1n 512w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/ij9odowwe3yfzu9zhcsc 592w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/ihepuzmm8wxy0svsu3xz 672w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/lzfgn0yjfbx7choddczx 752w\"></figure><p>Less clear is whether and how to adjust for household size. As mentioned above, I am now married with 3 kids<img>, but that first year of data tracks my spending alone. Statistical agencies sometimes deal with household size effects via the concept of <a href=\"https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:Equivalised_income\">equivalised income</a>; in the methodology used here head of household counts for 1, each additional person over the age 14 counts for 0.5, each young child adds 0.3, and then divide income by \u2018household size\u2019.&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/g77huxcbhxvy2j69nkst\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/n6dpyvqsixlk344bkyx6 117w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/ihqwfkffbb0ddvxr2fqk 197w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/ixys2oaok4hw4f6wcec6 277w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/o6hcockgkksc2f3bx5ox 357w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/zchscogyfp2nhpasfefd 437w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/qvjyty4imlyg7mapaffr 517w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/gxppfWhx7ta2fkF3R/v4xlcclstlmwsqftezn2 597w\"></figure><p>This last chart does the best job of tracking my subjective experience; I made no effort to watch my spending in my first few years of work, sharply tried to get more careful in 2018, and have been gradually letting things expand back in the past 2-3 years. To put the equivalised figure of \u00a340k/yr in context, that is <a href=\"https://www.ons.gov.uk/peoplepopulationandcommunity/personalandhouseholdfinances/incomeandwealth/articles/incomespendingandwealthhowdoyoucompare/2022-03-09\">the expenditure</a> of 85th - 95th percentile UK households, depending which dataset I use.&nbsp;</p><p>In summary, my household does spend a lot more money than it used to, but probably because it is larger than it used to be. More generally, our household income puts us in the top 1% of UK households but we opt to spend as if we are around the 90th percentile, a comfortable level that nonetheless creates a large gap between income and expenditure. That gap can be routed into donations or savings.</p><h2>Savings</h2><p>During my first few years of work, I saved up for a house deposit and made employer-matched pension contributions, but did not otherwise make a strong effort to save money. In the last few years, I have made much more of an effort to save. There were a few reasons for this:</p><ul><li>Strong messaging from the core about talent constraint, combined with my observation that I would not feel comfortable taking a &gt;&gt;50% pay cut without a strong buffer of <i>liquid</i> savings.&nbsp;</li><li>My episode of burnout in 2018 increased my sense of how many months' runway I should aim to have.&nbsp;</li><li>As our spending has risen, any given number of months of runway is now a larger \u00a3 figure.</li></ul><p>In the next few years, I would like to tilt back towards donations:</p><ul><li>As my episode of burnout recedes into the past and recent stressful<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2uoivn2qgzn\"><sup><a href=\"#fn2uoivn2qgzn\">[4]</a></sup></span>&nbsp;events fail to come even vaguely close, it seems more likely that:<ul><li>This was a one-off created by something of a perfect storm of personal and professional problems.</li><li>I have gotten better at balancing my motivations.</li></ul></li><li>We have made a lot of progress of medium-term financial goals:<ul><li>A year ago we bought what we hope and expect will be our <a href=\"https://www.rocketmortgage.com/learn/starter-home-or-forever-home\">forever home</a>.&nbsp;</li><li>I feel comfortable with our provision for retirement.&nbsp;</li><li>We are now a dual-income household, rather than the effectively-single-income one we were until 2020.</li></ul></li><li>Really a lot of things I would think should be fully funded are not fully funded, in a way that was briefly less obvious in 2022.</li></ul><h2>Donations</h2><p>Our largest donation recipients have been:</p><ul><li>Giving What We Can</li><li>80,000 Hours</li><li>AMF</li><li>Funds managed by Givewell, most recently the <a href=\"https://www.givingwhatwecan.org/en-GB/charities/givewell\">Top Charities Fund</a></li></ul><p>As it happens each of the above four has received close to \u00a3250k from us, accounting for two thirds of the \u00a31.5m total. This is also roughly representative of our cause area split, which is overall around 50% Global Poverty / 45% Community Building / 5% Other. This is <i>not </i>representative of our donations in any given year, where our Community Building donations in particular have been responsive to changes in the funding landscape.&nbsp;</p><h1>Community</h1><h2>Why engage?</h2><p>Some people struggle to work out what the EA community is supposed to do for them, or what the point of it all is. For what it's worth, my experience has been that this confusion extends to all levels of seniority within the community. But for me, participating in the community was the obvious way to counter the attrition Brooks warned of. I tend to agree that you will tend to become more like those around you, but that applies to people other than your colleagues, and you can choose who those people are! Maybe those 'EAs' even find what you are doing praiseworthy, but a lot of the power is just in feeling less weird for trying.</p><p>I often feel like people working at core EA orgs forget how valuable this is for the vast majority of EAs, who do not work with other EAs. <i><strong>Almost everyone I know outside EA, from my parents to my colleagues to my neighbours, is not seeking to improve the wider world with any significant fraction of their resources. They're just getting on with their lives and trying to do right by the people they meet.</strong></i> To the extent they are aware of my giving, their attitude is one of curious fascination.&nbsp;</p><p>I am not qualitatively different! I <i>know</i> that the world would be a better place if I gave more. I just choose not to. It's not my (only) priority. I feel similarly fascinated by the types of people profiled in <a href=\"https://www.nytimes.com/2015/09/25/books/review-strangers-drowning-examines-extreme-do-gooders.html\">Strangers Drowning</a>, who seem much more purely selfless or even saintlike.</p><p>The EA community, as it existed in 2014, did not bring me into contact with many saints. But it did expose me to a lot of people who were far further in that direction than anyone else I knew, and who responded positively to my giving. It feels very unlikely that I would have given anything like as much without that inspiration and validation.&nbsp;</p><h2>Why stop?</h2><p>Correspondingly, there are a number of possible functions of the community that I put little value on, such as:</p><ul><li>EA networking, or connections aimed at scoring an 'impactful' job.</li><li>Learning about how to do good.<ul><li>I read through Givewell's work without ever having spoken to another community member, and would mostly recommend things like this if learning is your goal.</li></ul></li><li>Spending time with other people with good epistemics.<ul><li>While justifying this claim is beyond the scope of this post, EA epistemics are generally worse than I have experienced in my job and elsewhere, in my subjective<span> </span>estimation.</li></ul></li></ul><p>As time has passed, such functions have taken up an ever-larger fraction of community efforts. At the same time, I have seen a lot of unsavoury or just plain unacceptable behaviour get a pass. Finally, EAs have treated EtG as <a href=\"https://forum.effectivealtruism.org/posts/WMdEJjLAHmdwyA5Wm/we-can-all-help-solve-funding-constraints-what-stops-us#How_I_saw_effective_altruism_change\">increasingly more weird</a>, especially offline, defeating the original argument for engaging. In the face of all this there is more than a slight temptation to throw up one's hands and say 'Fine! You think my money is worthless? I guess I'll keep it then; it's definitely worth something <i>to me</i>'. I think I succumbed to this to some extent around 2021, and needed to put a bit of space between myself and the community to maintain altruistic motivation; a sharp contrast with the early community inspiring me to do more.&nbsp;</p><p>Overall I find this all pretty sad<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefh1bztmafk7o\"><sup><a href=\"#fnh1bztmafk7o\">[5]</a></sup></span>, and I am not surprised that funding has been increasingly dominated by <a href=\"https://www.investopedia.com/terms/u/ultra-high-net-worth-individuals-uhnwi.asp\">UHNWIs</a>.</p><p>That all said, there has been a distinct change of tone in 2023, even from the core, as various places discover that they <a href=\"https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now\">cannot fill their funding needs</a>, sometimes urgent ones. Time will tell whether this becomes a more permanent shift.&nbsp;</p><h1>Closing Thoughts</h1><p>I generally think it is reasonable to subject unusual ideas to unusual scrutiny. Earning To Give is certainly an unusual idea, and it received plenty of scrutiny even before the FTX collapse. I think some level of suspicion and introspection, both around motivations and around sustainability, is warranted.</p><p>That said, I would encourage critics to take an honest look at what my reference class - STEM graduates from elite universities and privileged backgrounds - is otherwise doing. When I look, I see a fair amount of frivolous expenditure and minimal attention given to non-financial ways of doing good; the choice is less 'banker who donates' vs. 'doctor' and more 'banker who donates' vs. 'banker'.&nbsp;</p><p>Personally, I have never been into most big expenditures, but it is still true that had we not donated \u00a31.5m I would be able to retire today. Had we not donated \u00a31.5m <strong>and</strong><i> </i>I<i> </i>not upended my career for EA reasons in 2018, I would have been able to retire multiple years ago. This is not an entirely idle hypothetical; my plan before discovering EA was to focus my career in my 20s and then retire by 30<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjp1zxh7wwx\"><sup><a href=\"#fnjp1zxh7wwx\">[6]</a></sup></span>, perhaps doing some volunteer work after that. This would only have become more appealing since starting a family, so I see little reason to think I would have missed on this goal.</p><p>Instead, a million dollars<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref061zim10dc2p\"><sup><a href=\"#fn061zim10dc2p\">[7]</a></sup></span>&nbsp;went to charities trying to help the <a href=\"https://theconversation.com/the-global-south-is-on-the-rise-but-what-exactly-is-the-global-south-207959\">Global South</a>, and another million went to building the community that pointed out to me that I should personally be doing a lot more to help the Global South. Much though I might value the personal freedom that comes with early retirement, I struggle to come up with any moral or practical argument that suggests it is worth more than what those donations accomplished.&nbsp;</p><p>If <i>you </i>come up with one, give me a shout. Maybe you will convince me! I'm sure my investment accounts will be grateful.&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn44e2wwj53ap\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref44e2wwj53ap\">^</a></strong></sup></span><div class=\"footnote-content\"><p>IIRC, from \u00a350k / yr to \u00a3200k / yr.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsukqzh3uyo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsukqzh3uyo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Please note I'm taking some liberties with the rounding here; this is intended as indicative only.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlrr6h8xefsf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflrr6h8xefsf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is also the standard for <a href=\"https://www.ons.gov.uk/economy/inflationandpriceindices/articles/consumerpricesindexincludingowneroccupiershousingcostshistoricalseries/1988to2004#introduction\">UK</a> and <a href=\"https://www.bls.gov/cpi/factsheets/owners-equivalent-rent-and-rent.htm\">US</a> inflation indices. In short, I substitute my actual housing costs (mortgage interest, maintenance, etc.) for an estimate what I would have paid to rent equivalent accomodation. Overall this comes out within 10% of my experinced costs but is much smoother year-to-year.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2uoivn2qgzn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2uoivn2qgzn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>More precisely, events I would have previously found very stressful. My actual felt reaction is highly reminiscent of <a href=\"https://hpmor.com/chapter/74\">this quote</a>:</p><blockquote><p>Going through Azkaban had recalibrated his scale of emotional disturbances; and losing a House point, which had formerly rated five out of ten, now lay somewhere around zero point three.</p></blockquote></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnh1bztmafk7o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefh1bztmafk7o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>More sad for the world than for me personally; my immediate circles formed in earlier years aren't going anywhere, but it does seem like the ladder has been pulled up behind me.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjp1zxh7wwx\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjp1zxh7wwx\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I wasn't aware of the <a href=\"https://www.investopedia.com/terms/f/financial-independence-retire-early-fire.asp\">FIRE</a> movement, but it seems likely I would have come across it sooner or later and that would have helped provide some structure and planning on the objective. As it was I think I first heard the acronym in 2014.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn061zim10dc2p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref061zim10dc2p\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Again, some liberties with GBP:USD conversion rates and rounding. It's about right though; GBP was higher back in the mid-2010s...</p></div></li></ol>", "user": {"username": "AGB"}}]