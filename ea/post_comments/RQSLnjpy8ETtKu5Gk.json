[{"_id": "RcWRj2HtdzXpH8nza", "postedAt": "2024-03-21T13:40:12.864Z", "postId": "RQSLnjpy8ETtKu5Gk", "htmlBody": "<p><strong>Executive summary:</strong> This post provides an overview of different areas one could work on to positively influence the trajectory of artificial intelligence, along with key considerations and uncertainties for choosing between them.</p><p><strong>Key points:</strong></p><ol><li>The main areas of work are: ensuring human control of advanced AI systems, addressing AI misalignment risks, and supporting mainstream AI safety efforts.</li><li>Key uncertainties include the tractability and neglectedness of different areas, and whether success in some areas would be net positive or negative.</li><li>Types of AI safety related work include research, organizing, policy, and advocacy. The author is uncertain which type fits them best.</li><li>Other career considerations include skill-building, exploration, credibility, and various properties of the work itself like autonomy and certainty of impact.</li><li>Next steps are to resolve object-level uncertainties through discussions and introspection, and learn from the heuristics and approaches others use to choose their work.</li></ol><p>&nbsp;</p><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}]