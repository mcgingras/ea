[{"_id": "6uQse5P4vTXEKiR5v", "postedAt": "2023-06-22T21:44:04.361Z", "postId": "TLSPQjjXZruwmg4PE", "htmlBody": "<p>Thanks a lot for your work on this neglected topic!<br><br>You mention,</p><blockquote><p>Those counter-considerations seem potentially as strong as the motivations I list in favor of a focus on malevolent actors.&nbsp;</p></blockquote><p>Could you give more detail on which of the counter-considerations (and motivations) you consider strongest?</p>", "parentCommentId": null, "user": {"username": "starmz12345@gmail.com"}}, {"_id": "AufxftPaTc8KMAMZY", "postedAt": "2023-06-23T00:47:20.022Z", "postId": "TLSPQjjXZruwmg4PE", "htmlBody": "<blockquote><p>Malevolent(-ish) actors seem much more likely to cause existential catastrophes than astronomical suffering. Therefore, the less we\u2019re confident in the hypothesis that human expansion is positive,<a href=\"https://forum.effectivealtruism.org/posts/TLSPQjjXZruwmg4PE/some-governance-research-ideas-to-prevent-malevolent-control#fnl7u522p5xc\"><sup>[15]</sup></a>&nbsp;the less reducing the influence of malevolent actors seems important.</p></blockquote><p>I agree in terms of absolute probabilities. But in terms of relative risks, naively I'd expect malevolent actors to be much more likely, in relative terms, to cause s-risks than benevolent or selfish actors. That is because you need to posit additional motivations or miscalculations for most non-malevolent actors to intentionally cause s-risks, whereas malevolence itself may provide sufficient motivation. Indeed, I've previously assumed this is why negative-leaning folks focused on studying malevolent actors in the first place.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Linch"}}, {"_id": "WTqoX622jzaAoSASt", "postedAt": "2023-06-23T13:49:10.413Z", "postId": "TLSPQjjXZruwmg4PE", "htmlBody": "<p>Thanks Miranda! :)&nbsp;<br><br>I personally think the strongest argument for reducing malevolence is its relevance for s-risks (see section <a href=\"https://forum.effectivealtruism.org/posts/TLSPQjjXZruwmg4PE/some-governance-research-ideas-to-prevent-malevolent-control#__Robustness__Highly_beneficial_even_if_we_fail_at_alignment\">Robustness: Highly beneficial even if we fail at alignment</a>), since I believe s-risks are much more neglected than they should be.<br><br>And the strongest <a href=\"https://forum.effectivealtruism.org/posts/TLSPQjjXZruwmg4PE/some-governance-research-ideas-to-prevent-malevolent-control#__Counter_considerations_and_overall_take\">counter-considerations</a> for me would be &nbsp;</p><ul><li>Uncertainty regarding the value of the future. I'm generally much more excited about making the future go better rather than \"bigger\" (reducing X-risk does the latter), so the more reducing malevolence does the latter more than the former, the less certain I am it should be a priority. (Again, this applies to any kind of work that reduces X-risks, though.)</li><li>Info / attention hazards. Perhaps the best way to avoid these malevolence scenarios is to ignore them and avoid making them more salient.&nbsp;</li></ul><p>Interesting question you asked, thanks! I added a link to this comment in a footnote.&nbsp;</p>", "parentCommentId": "6uQse5P4vTXEKiR5v", "user": {"username": "Jim Buhler"}}, {"_id": "H4JW2X77J6ywS8xaB", "postedAt": "2023-10-03T08:29:58.127Z", "postId": "TLSPQjjXZruwmg4PE", "htmlBody": "<p>Thanks for writing this post!&nbsp;<br><br>You write:</p><blockquote><p>While this is somewhat compelling, this may not be enough to warrant such a restriction of our search area. Many of the actors we should be concerned about, for our work here, might have very low levels of such traits. And features such as spite and unforgivingness might also deserve attention (see&nbsp;<a href=\"https://longtermrisk.org/will-agis-avoid-conflict-by-default/#What_if_conflict_isnt_costly_by_the_agents_lights\"><u>Clifton et al. 2022</u></a>).</p></blockquote><p>I wanted to note that the term 'malevolence' wasn't meant to exclude traits such as spite or unforgivingness. See for example the <a href=\"https://forum.effectivealtruism.org/posts/LpkXtFXdsRd4rG8Kb/reducing-long-term-risks-from-malevolent-actors#What_do_we_mean_by_malevolence_\">introduction</a> which explicitly mentions spite (emphasis mine):&nbsp;</p><blockquote><p>This suggests the existence of a general factor of human malevolence<a href=\"https://forum.effectivealtruism.org/posts/LpkXtFXdsRd4rG8Kb/reducing-long-term-risks-from-malevolent-actors#fn-LPrWuTM8RQbgd6yjh-2\"><sup>[2]</sup></a>: the Dark Factor of Personality (Moshagen et al., <a href=\"https://wildbeimwild.com/wp-content/uploads/2018/11/Psychologie-Der-dunkle-Kern-der-Pers%C3%B6nlichkeit.pdf\">2018</a>)\u2014[...] characterized by egoism, lack of empathy<a href=\"https://forum.effectivealtruism.org/posts/LpkXtFXdsRd4rG8Kb/reducing-long-term-risks-from-malevolent-actors#fn-LPrWuTM8RQbgd6yjh-3\"><sup>[3]</sup></a> and guilt, Machiavellianism, moral disengagement, narcissism, psychopathy, sadism, and <strong>spitefulness.</strong></p></blockquote><p>So to be clear, I encourage others to explore other traits!&nbsp;<br><br>Though I'd keep in mind that there exist moderate to large correlations between most of these \"bad\" traits such that for most new traits we can come up with, there will exist substantial positive correlations with other dark traits we already considered. (In general, I found it helpful to view the various \"bad\" traits not as completely separate, orthogonal traits that have nothing to do with each other but also as \u201c[...] specific manifestations of a general, basic dispositional behavioral tendency [...] to maximize one\u2019s individual utility\u2014 disregarding, accepting, or malevolently provoking disutility for others\u2014, accompanied by beliefs that serve as justifications\" (Moshagen et al., 2018).)&nbsp;<br><br>Given this, I'm probably more skeptical that there exist many actors who are, say, very spiteful but exhibit no other \"dark\" traits\u2014but there are probably some!&nbsp;<br><br>That being said, I'm also wary of going too far in the direction of \"whatever bad trait, it's all the same, who cares\" and losing conceptual clarity and rigor. :)&nbsp;</p>", "parentCommentId": null, "user": {"username": "David_Althaus"}}, {"_id": "Cb5jBBEuFbPjLRBxk", "postedAt": "2023-10-04T20:49:36.886Z", "postId": "TLSPQjjXZruwmg4PE", "htmlBody": "<p>Interesting, makes sense! Thanks for the clarification and for your thoughts on this! :)</p>", "parentCommentId": "H4JW2X77J6ywS8xaB", "user": {"username": "Jim Buhler"}}]