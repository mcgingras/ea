[{"_id": "q8D4uz72pw9RdED9p", "postedAt": "2022-12-18T01:53:46.520Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<blockquote><p>If we try and filter out criminals we <strong><u>just</u></strong> end up selecting smart criminals who are good at hiding their misdeeds. [emphasis added]</p></blockquote><p>I don't buy that this is an 'intuitive' view; I think you are setting up a straw man here. I think the vast majority of immigration restrictivists would view attempting to filter for criminality as a positive thing that would on average improve the quality of immigrants, because a lot of criminals are stupid and could be apprehended. As a <i>reductio, </i>do you think the average person finds it intuitive that, if an immigrant confesses to murder when asked by a border agent, the border agent should shrug his shoulders and ignore this information?</p>", "parentCommentId": null, "user": {"username": "Larks"}}, {"_id": "tc27AWjmfgx95MqQf", "postedAt": "2022-12-18T02:01:03.929Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>I agree I think this second part isn't intuitive to most people. I was using intuitive somewhat loosely to mean based on intuitions the person making the argument has.</p>", "parentCommentId": "q8D4uz72pw9RdED9p", "user": {"username": "Nathan_Barnard"}}, {"_id": "wNKN4gbfmssGatP66", "postedAt": "2022-12-18T02:29:54.035Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>I'm one of the people who believe that \"Current EA community building is selecting for uncritical people\", it feels like the reasons I think that are different from what you mention in this post.&nbsp;<br><br>Specifically, it isn't for a neat theoretical reason but just from talking to university students who recently got into EA via their university group, and from hanging out with university group organisers, and feeling like things were off. I would predict that my most impressive/talented/interesting friends would not enjoy hanging out in the type of environment created by some of the activities the group organisers prioritise (and from talking to my friends this seems to be true - some of them who agree with EA ideas still distanced themselves from their local group because it seemed to be trying hard to make 'EA bots')<br><br>In fact, often the arguments given for doing that type of university group organising seem to fall into the problem you describe. I have had uni group organisers mention that during your first interaction with a new person, you should try to optimise for the outcome of getting them to come to more future EA events (eg: don't say things that directly disagree with them, focus on how their interests overlap with EA, don't be too intense) and that even if this harms epistemics, over the long-run this will be fine because these people who don't care much about good thinking will come to care about it once they get excited about doing good (due to your events!). It feels like I haven't seen evidence for this being true beside the intuitions of new-ish community builders.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Quadratic Reciprocity"}}, {"_id": "66HuSGCovKptBpnZX", "postedAt": "2022-12-18T02:57:42.766Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>I think one of my critiques of this is that I'm very sceptical that strong conclusions should be drawn from any individual's experiences and those of their friends. My current view is that we just have limited evidence for any models of what good and bad community building looks like and the way to move forward is do try a wide range of stuff and do what seems to be working well.</p><p>I think I mostly disagree with your third paragraph. The assumptions I see here are:</p><ol><li>Not being very truth seeking with new people will either select for people who aren't very critical or will make people who are critical into not critical people&nbsp;</li><li>This will have second order effects on the wider community epistemics specifically in the direction of less critiques of EA ideas</li></ol><p>i.e it's not obvious to me it makes EA community epistemics worse in the sense that EAs make worse decisions as a result of this.&nbsp;</p><p>Maybe these things are true or maybe they aren't. My experience has not been this ( for context have been doing uni group cb for 2 years) the sorts of people who get excited about EA ideas and get involved are very smart, curious people who are very good critical thinkers.</p><p>But in the sprit of the post what I'd want to see are some regressions, like I'd want to see some measure of if the average new EA at a uni group which doesn't cb in a way that strongly promotes a kind of epistemic frankness are less critical of ideas in general than an appropriate reference class.&nbsp;</p><p>Like currently I don't talk about animal welfare when first talking to people about EA because it's reliably the thing which puts the most people off. I think the first order effect of this is very clear - more people come to stuff - and my guess is that there are ~no second-order effects. I want to see some systematic evidence that this would have bad second order effects before I give up the clearly positive first order one.&nbsp;</p>", "parentCommentId": "wNKN4gbfmssGatP66", "user": {"username": "Nathan_Barnard"}}, {"_id": "KittfpRb2H8kdhTAZ", "postedAt": "2022-12-18T04:33:27.289Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>You write that <i>\"Many people find these arguments very intuitively appealing\"</i>, but I struggle to think of three people that would agree with that intuition.</p><p>The reason I bring this up is not just pedanty. I was pretty sympathetic to your argument until I got to the examples, but a lot of them seemed to involve a bit of motte-and-bailey. In many cases I can either come up with a version that I agree is intuitive, or one that is clearly false, but not both.</p><p>For another example, your minimum wage example combined multiple claims:</p><ol><li>Having a &nbsp;minimum wage will increase unemployment rates.&nbsp;</li><li>Employers hire workers up until the point that the marginal revenue generated by each worker equals the marginal cost of hiring workers.&nbsp;</li><li>If the wage workers have to be paid goes up then unemployment will go up because marginal productivity is diminishing in the number of workers.&nbsp;</li></ol><p>I agree that the conjunction is literally false, because 2) is not an accurate description of hiring manager thought processes, 1) is clearly false if that minimum wage is very very low, and 3) is false in some ranges for monopsony models. But 2) and 3) could be a reasonable approximation for many purposes, and I was not under the impression that the core claim, 1), had been disproven in an economically meaningful way. Recent research like the <a href=\"https://academic.oup.com/qje/article/134/3/1405/5484905\">2019 Dube QJE paper</a> suggest that historically US minimum wage increases haven't increased unemployment, but others like <a href=\"https://www.nber.org/papers/w29264\">Clemens and Strain (2021)</a> or <a href=\"https://www.economics.uci.edu/~dneumark/MW%20US%20literature.05.pdf\">Neumark and Shirley (2021)</a> suggest they did increase unemployment.</p>", "parentCommentId": "tc27AWjmfgx95MqQf", "user": {"username": "Larks"}}, {"_id": "eBysbxkgMLfALsBym", "postedAt": "2022-12-18T06:50:57.342Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>Compared to you I think intuitions are a good guide to pointing out what kinds of social interactions are appealing vs not appealing to people similar to us. I am less in favour of trying a wide range of stuff and then naively doing what seems to be working well based on simpler metrics, specifically I am less in favour of handing that strategy to new group organisers just because:<br><br>1) I trust their judgment way less than more experienced people in EA who have done useful direct work before<br>2) Because you miss out on all the great people you turn off because of your activities. You won't get negative feedback from those people because they stop showing up and won't bother<br>3) I think the metrics used to judge what seems to be working well are often the wrong ones (number of people who show up to your events, who do the intro fellowship, who go to EAGx from your university etc.) and noticing if you're getting people interested who actually seem likely to have a decent probability of very high impact in the world is hard to do<br><br>I also don't think the people you'd get into EA that way would be less critical of ideas in general than the average university student, just because the 'average university student' is a very low bar. I'm not sure what reference class to compare them to (one random suggestion: perhaps the libertarian society at a university?) or what sort of prediction to make besides that I don't think people I think of as having the aptitudes that are most helpful for having massive amounts of positive impact (being good at thinking for research, being good at starting projects etc.) would enjoy the kind of environment created at most university groups. &nbsp;<br><br>Specifically, one of my main gripes is that university group organisers sometimes seem to just be optimising for getting in more new people instead of doing things and organising things that would have actually appealed to them. Under some assumptions, this is not a massive problem because my guess is this happens less at top universities (though unclear, friends at some other top universities also complain about the bad vibes created) and the people who would be most interested in effective altruism would get interested anyway in spite of, instead of because of, community building strategy. So the main visible effect is the dilution of the EA community and ideas, which could actually just be not that bad if you don't particularly care about the \"EA\" label providing useful information about people who use it.&nbsp;</p>", "parentCommentId": "66HuSGCovKptBpnZX", "user": {"username": "Quadratic Reciprocity"}}, {"_id": "XTAfPpqJjbztFEbSc", "postedAt": "2022-12-18T11:45:05.072Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>I completely stand by the minimum wage one, this was the standard model of how labour markets worked until like the shapiro-Stiglitz model (I think) and is still the standard model for how input markets work, and if you're writing a general equilibrium model you'll probably still have wage = marginal product of labour.&nbsp;</p><p>Meta-analysis find that minimum wage doesn't increase unemployment until about 60% of median wage <a href=\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/844350/impacts_of_minimum_wages_review_of_the_international_evidence_Arindrajit_Dube_web.pdf,\">https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/844350/impacts_of_minimum_wages_review_of_the_international_evidence_Arindrajit_Dube_web.pdf,</a> and most economists don't agree that a even a $15 an hour minium wage would lead to substantial unemployment (although many are uncertain) https://www.igmchicago.org/surveys/15-minimum-wage/</p>", "parentCommentId": "KittfpRb2H8kdhTAZ", "user": {"username": "Nathan_Barnard"}}, {"_id": "pQyd9DcjTqvQDuAys", "postedAt": "2022-12-18T12:41:21.649Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>This discussion seems a bit of a side-track to your main point. These are just examples to illustrate that intuition is often wrong - you're not focused on the minimum wage per se. Potentially it could have been better if you had chosen more uncontroversial examples to avoid these kinds of discussions.</p>", "parentCommentId": "XTAfPpqJjbztFEbSc", "user": {"username": "Stefan_Schubert"}}, {"_id": "WxHP7qnjozQnzAJjY", "postedAt": "2022-12-18T13:07:26.862Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>Maybe, I meant to pick examples where I thought the consensus of economists was clear (in my mind it's very clearly the consensus that having a low minimum wage has no employment effects.)&nbsp;</p>", "parentCommentId": "pQyd9DcjTqvQDuAys", "user": {"username": "Nathan_Barnard"}}, {"_id": "3BgFxtkep2dcdfHjB", "postedAt": "2022-12-18T13:13:20.507Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>Fwiw I think <a href=\"https://www.lesswrong.com/posts/9weLK2AJ9JEt2Tt8f/politics-is-the-mind-killer\">this is good advice</a>.</p><blockquote><p>If you want to make a point about science, or rationality, then my advice is to not choose a domain from <i>contemporary</i> politics if you can possibly avoid it. If your point is inherently about politics, then talk about Louis XVI during the French Revolution. Politics is an important domain to which we should individually apply our rationality\u2014but it\u2019s a terrible domain in which to <i>learn</i> rationality, or discuss rationality, unless all the discussants are already rational.</p></blockquote>", "parentCommentId": "WxHP7qnjozQnzAJjY", "user": {"username": "Stefan_Schubert"}}, {"_id": "7mwRsCauGpzD6CLzn", "postedAt": "2022-12-18T15:45:11.224Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>This comment does not sound like 'completely standing by' to me! If a $15/hour US minimum wage, which is the relevant current policy proposal, reduces employment, that means the intuition is correct.&nbsp;</p><p>I think the IGM poll is weak evidence for you here. Lets look at some quotes from the guys who didn't agree that increasing the minimum wage would substantially increase unemployment (e.g. ostensibly disagreed with the intuition):</p><blockquote><p>Evidence is that it would be lower by perhaps 1 - 2 %. Lots of margins for adjustments.</p><p>Lower, probably; substantially lower, not clear at all.</p><p>Empirical studies disagree on the sign of the effect. Few of those concluding in favor of negative are consistent with \"substantially.\"</p><p>I don't think the evidence supports the bold prediction that employment will be substantially lower. Not impossible, but no strong evidence.</p><p>Empirical evidence suggests the effects on employment would be modest.</p><p>Lower, yes. \"Substantially\"? Not clear. For small changes in min wage, there are small changes in employment. But this is a big change.</p></blockquote><p>In many cases, these people either 1) believe there would be unemployment, but are getting hung up on 'substantial', or 2) think there will be other adjustments (e.g. reduction in non-wage benefits). I think the headline result here is somewhat misleading - at that is before any adjustment for the <a href=\"https://www.econlib.org/archives/2012/07/igm_and_economi.html\">partisan bias issue</a>. If my intuition was that increasing the minimum wae would increase unemployment, and the people who ostensibly disagree with me think it would only cause 780,000<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7olzkl6w7r8\"><sup><a href=\"#fn7olzkl6w7r8\">[1]</a></sup></span>&nbsp;people to lose their jobs, I would consider myself vindicated.</p><p>I haven't read that 2019 Dube review, though I'm guessing it's similar to the other 2019 Dube review I posted. But as I noted in the grandparent, there is serious work on the other side since (e.g. the two 2021 papers).</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7olzkl6w7r8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7olzkl6w7r8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>52m people on under $15/hour according to Oxfam * 1.5% according to Nordhaus, who voted 'disagree'</p></div></li></ol>", "parentCommentId": "XTAfPpqJjbztFEbSc", "user": {"username": "Larks"}}, {"_id": "9Nj72DDJdPBxFEvcg", "postedAt": "2022-12-18T17:50:28.770Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>I don\u2019t buy any of the arguments you said at the top  of the post, except for toxoplasma of rage (with lowish probability) and evaporative cooling. But both of these (to me) seem like a description of <em>an</em> aspect of a social dynamic, not <em>the</em> aspect. And currently not very decision relevant.</p>\n<p>Like, obviously they\u2019re false. But are they useful? I think so!</p>\n<p>I\u2019d be interested in different, more interesting or decision relevant or less obvious mistakes you often see.</p>\n", "parentCommentId": null, "user": {"username": "D0TheMath"}}, {"_id": "8r9PdWvtycMReC9EH", "postedAt": "2022-12-18T18:14:41.147Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>I suppose I think the example I gave where someone I know doing selections for an important EA program didn't include questions about altruism because they thought that adverse selection effects were sufficiently bad.&nbsp;</p>", "parentCommentId": "9Nj72DDJdPBxFEvcg", "user": {"username": "Nathan_Barnard"}}, {"_id": "kgEpWYv8mesvPEhr3", "postedAt": "2022-12-18T18:23:19.793Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>Seems like that is just a bad argument, and can be solved with saying \u201cwell that\u2019s obviously wrong for obvious, commonsense reasons\u201d and if they really want to, they can make a spreadsheet, fill it in with the selection pressures they think they\u2019re causing, and see for themselves that indeed its wrong.</p>\n<p>The argument I\u2019m making is that most of the examples you gave I thought \u201cthat\u2019s a dumb argument\u201d. And if people are consistently making <em>transparently</em> dumb selection arguments, this seems different from people making <em>subtly</em> dumb selection arguments, like economists.</p>\n<p>If you have subtly dumb selection arguments, you should go out and test which are true, if you\u2019re making transparently dumb ones, you should figure out how to formulate better hypotheses. Chances are you\u2019re not yet even oriented in the vague direction of reality in the domain you\u2019re attempting to reason in.</p>\n", "parentCommentId": "8r9PdWvtycMReC9EH", "user": {"username": "D0TheMath"}}, {"_id": "e2seJNKRSEZbmwBeB", "postedAt": "2022-12-18T19:23:35.418Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>Should we limit this to social phenomena? Is it more likely for them because social phenomena are more complex and have more moving parts, so it's easy to miss the most important effects and use vastly oversimplified models? Also, studies of social phenomena (+biology and medical research) often don't replicate, possibly for that reason and also having high p-value cutoffs and many ways to do analyses until you get a result.</p>\n<p>In general, I think we should be careful about claims of causal effects X -&gt; Y -&gt;Z (or longer causal paths from X to Z) capturing most of the impact or even having the right sign for overall effects of X on Z. Ideally, you should manipulate X and directly measure Z.</p>\n<p>Furthermore, the longer the causal path in the argument, the more places it could be missing parallel paths that are more important or have the opposite sign (and be more likely to have an error at some point). So, we should be more skeptical of longer causal paths in general. Plus, the intuitive examples you give (at least as stated) don't establish that the specific effects are practically significant even if they exist.</p>\n", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "Aw2iABLFuxZAmtbah", "postedAt": "2022-12-19T04:37:50.807Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>Yeah, I'm pretty sceptical of the judgement of experienced community builders on the sorts of questions like effect of different strategies on community epistemics. I think if I frame this as an intervention \"changing community building in x way will improve EA community epistemic\" I have a strong prior that it has no effect because most interventions people try to have no or small &nbsp;effect (see famous graph of global health interventions.)&nbsp;</p><p>I think the following are some examples of places where you'd think people would have good intuitions about what works well but they don't&nbsp;</p><ul><li>Parenting. We used to just systematically abuse children and think it was good for them (e.g denying children the ability to see their parents in the hospital). There's a really interesting passage in<a href=\"https://press.uchicago.edu/ucp/books/book/chicago/I/bo61544815.html\"> Invisible China</a> where the authors describe loving grandparents deeply damaging the grandchildren they care for by not giving them enough stimulation as infants.&nbsp;</li><li>Education. It's really really hard to find education interventions which work in rich countries. It's also interesting that in the US there's lots of opposition from teachers over teaching phonics despite it being one of the few rich country education interventions with large effect sizes (although it's hard to judge how much of this is for self-interested reasons)</li><li>I think it's unclear how well you'd expect people to do on the economics examples I gave. I probably would have expected people to do well with cash transfers since in fact lots of people do get cash transfers (e.g pensions, child benefits, inheritance) and do ok with minimum wage since at least some fraction of people have a sense of how the place they work for hires people.&nbsp;</li><li>Psychotherapy. We only good treatments that worked for specific mental health conditions (rather than to generally improve people's lives, I haven't read anything on this) other than mild-moderate depression when we started doing RCTs. I'm most familiar with OCD treatment specifically and the current best practice was only developed in the late 60s.&nbsp;</li></ul>", "parentCommentId": "eBysbxkgMLfALsBym", "user": {"username": "Nathan_Barnard"}}, {"_id": "McFDeZpvoYZK9mzJx", "postedAt": "2022-12-19T07:24:11.390Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>Hmm, would you then also say that we should be skeptical about claims about the overall usefulness of university group organising. If you frame it as an intervention of \"run x program (intro fellowship, retreat, etc.) that will increase probability someone has a large positive impact\", would you also have a strong prior that it has no effect because most interventions people try especially education interventions which is a lot of what uni groups try to do have no or small effect?&nbsp;</p>", "parentCommentId": "Aw2iABLFuxZAmtbah", "user": {"username": "Quadratic Reciprocity"}}, {"_id": "XKLGY6TxdArJBkiFD", "postedAt": "2022-12-19T16:22:54.927Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>Yeah this seems right.</p><p>I think I don't understand the point you're making with your last sentence.&nbsp;</p>", "parentCommentId": "e2seJNKRSEZbmwBeB", "user": {"username": "Nathan_Barnard"}}, {"_id": "GATZcZbh9kKSQ6QPu", "postedAt": "2022-12-21T01:54:58.788Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>This comment is both in response to this post, and in part to a previous comment thread (linked below, as the continued discussion seemed more relevant here than in the evaporative cooling model post here: <a href=\"https://forum.effectivealtruism.org/posts/wgtSCg8cFDRXvZzxS/ea-is-probably-undergoing-evaporative-cooling-right-now?commentId=PQwZQGMdz3uNxnh3D\">https://forum.effectivealtruism.org/posts/wgtSCg8cFDRXvZzxS/ea-is-probably-undergoing-evaporative-cooling-right-now?commentId=PQwZQGMdz3uNxnh3D</a>).</p>\n<p>To start out:</p>\n<ul>\n<li>When it comes to the reactions of individual humans and populations, there is inherently far more variability than there is in e.g. the laws of physics</li>\n<li>No model is perfect, and will always be a simplification of reality (particularly when it comes to populations, but also the case in e.g. engineering models)</li>\n<li>A model is only as good as its assumptions, and these should really be stated</li>\n<li>Just because a model isn't perfect, does not mean it has no uses</li>\n<li>Sometimes there are large data gaps, or you need to create models under a great degree of uncertainty</li>\n<li>There are indeed some really bad models that should probably be ignored, but dismissing entire fields is not the way to approach this</li>\n<li>Predicting the future with a large degree of certainty is very hard (hence the dart throwing chimpanzee analogy that made the news, and predictions becoming less accurate after around 5 years or so as per Superforecasting), so a large rate of inaccuracies should not be surprising (although of course you want to minimize these)</li>\n<li>Being wrong and then new evidence causing you to update your models is how it should work (edited for clarity: as opposed to not updating your models in those situations)</li>\n</ul>\n<p>For this post/general:</p>\n<p>What I feel is lacking here is some indication of base rates, i.e. how often are people completely/largely without questioning trusting of these models, as opposed to being aware that all models have their limitations and that this should influence how they are applied. And of course 'people' is in itself a broad category, with some people being more or less questioning/deferential or more or less likely to jump to conclusions. What I am reading here is a suggestion of 'we should listen less to these models without question' without knowing who and how frequently people are doing that to begin with.</p>\n<p>Out of the examples given, the minimum wage one was strong (given that there was a lot of debate about this) and I would count the immigration one as a valid example (people again have argued this, but often in a very politically charged way that how intuitive it is depends on the political opinions of the person reading), but many of the other ones seemed less intuitive or did not follow perhaps to the point of being a straw man.</p>\n<p>I do believe you may be able to convince some people of any one of those arguments and make it be intuitive to them, if the population you are looking at it for example a typical person on the internet. I am far less convinced that this is true for a typical person within EA, where there is a large emphasis on e.g. reasoning transparency and quantitative reasoning.</p>\n<p>There does appear to be a fair bit of deferral within EA, and some people do accept the thoughts of certain people within the community without doing much of their own evaluation (but given this is getting quite long, I'll leave that for another comment/post). But a lot of people within EA have similar backgrounds in education and work, and the base rate seems to be quantitative reasoning not qualitative, nor accepting social models blindly. In the case of 'evaporative cooling', that EA Forum post seemed more like 'this may be/I think it is likely to be the case' not 'I have complete and strong belief that this is the case'.</p>\n<p>\"even if someone shows me a new macro paper that proposes some new theory and attempts to empirically verify it with both micro and macro data I'll shrug and eh probably wrong.\" Read it first, I hope. Because that sounds like more of a soldier than a scout mindset, to use the EA terminology.</p>\n<p>Even if a model does not apply in every situation also does not mean the model should not exist, nor that qualitative methods or thought exercises should not be used. You cannot model human behaviour the same way as you can model the laws of physics, human emotions do not follow mathematical formulas (and are inconsistent between people), creating a model of how any one person <em>will</em> act is not possible unless you know that particular person very well and perhaps not even then. But generally, trying to understand how a population <em>in general</em> could react should be done - after all, if you actually want to implement change it is populations that you need to convince.</p>\n<p>I agree with 'do not assume these models are right on the outset', that makes sense. But I also think it is unhelpful and potentially harmful to go in with the strong assumption that the model will be wrong, without knowing much about it. Because not being open to potential benefits of a model, or even going as far as publicly dismissing entire fields, means that important perspectives of people with relevant expertise (and different to that of many people within EA) will not be heard.</p>\n", "parentCommentId": null, "user": {"username": "LinBowkerLonnecker"}}, {"_id": "rSvGHtMoG2Wpaf8g9", "postedAt": "2022-12-22T01:12:51.296Z", "postId": "WYktRSxq4Edw9zsH9", "htmlBody": "<p>What I think Nathan Beard is trying to say is EAs/LWers give way too much credence to models that are intuitively plausible and not systematically tested, and generally assume way too much usefulness of an average social science concept or paper, let alone intuition.</p>\n<p>And given just how hard it is to make a useful social science model in economics, arguably one of the most well evidenced sciences, I think this is the case.</p>\n<p>And I think this critique is basically right, but I think it's still worth funding, as long as we drastically lower our expectations of the average usefulness of social sciences .</p>\n", "parentCommentId": "GATZcZbh9kKSQ6QPu", "user": {"username": "Sharmake"}}]