[{"_id": "hFPbe2ZwmB9athsXT", "title": "Clean Water - the incredible 30% mortality reducer we can\u2019t explain", "postedAt": "2023-11-04T00:52:24.808Z", "htmlBody": "<p><strong>TLDR: The best research we have shows that clean water may provide a 30% mortality reduction to children under 5. This might be the biggest mortality reduction of any single global health intervention, yet we don\u2019t fully understand why it works.</strong><br><br>Here I share my exploration of a life-saving intervention that we don\u2019t fully understand, <i><strong>but really should.&nbsp;</strong></i>I may err a little on the side of artistic license - so if you find inaccuracies or I'm a bit loose please forgive me, correct me or even feel free to just tear me to shreds in the comments ;).&nbsp;</p><h3><br><strong>Part 1: Givewell\u2019s Seemingly absurd numbers</strong></h3><p>I first became curious after a glance at what seemed like a dubious GiveWell funded project.&nbsp;A <a href=\"https://www.givewell.org/research/grants/one-acre-fund-ILC-scoping-rwanda-october-2022\"><strong>$450,000 dollar scoping grant for water chlorination in Rwanda?</strong> </a>This didn\u2019t make intuitive sense to me.</p><p>In Sub-saharan Africa diarrhoea causes 5-10% of child mortality. While significant, the diarrhea problem continues to improve with better access to medical care, improving ORS and Zinc coverage, and antibiotics for more severe cases. Over the last 5 years, our own Ugandan health centers have encountered surprisingly few very sick kids with diarrhoea and I\u2019ve hardly seen diarrhoea kill a child, as opposed to Malaria and Pneumonia which tragically kill kids all the time. It seemed to me that even if clean water hugely reduced diarrhoea mortality, the intervention would still likely be an expensive way to achieve 1 or 2 percent mortality reduction,&nbsp;<br><br>So with my skeptic hat on, I clicked the <a href=\"https://docs.google.com/spreadsheets/d/1sppKf7uwBLR2FsH6jCjmTynmlKd2q-p4rt5N7MYssKk/edit#gid=2134466703\">GiveWell spreadsheet</a> and my incredulity only grew. GiveWell estimated an upper-bound mortality reduction of an almighty <strong>17% </strong>for the Rwandan chlorination program! At first that made no sense, but I did expect GiveWell would likely be lesswrong than me.</p><p>The Global burden of disease estimates that Diarrhoea makes up only <strong>4.9%</strong> of total deaths in Rwanda. How could an intervention which targets diarrhoea reduce mortality by over three times the total diarrhoea mortality? Even if the clean water cured all diarrhoea, that wouldn\u2019t come close to GiveWell\u2019s mortality reduction estimate.</p><p><img style=\"width:52.69%\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/yjaydslwnbkfyl3rmf1o\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/qeyxv08xwzmb6j8jfft8 132w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/cqajf4hwi2bqrpks4rga 212w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/phgfsb224g9mkqrezbte 292w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/cpre9ib4tkc7zziwvenr 372w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/rqux53iklda8ji5rvgrh 452w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/l0fjishxw4wjokdo34qn 532w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/zaibtsvqowjfd3ilzpfv 612w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/ojgslawwepjwwpaqpz2x 692w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/ikb46h6n8alirsnrfkml 772w\"></p><p>Something fishy was afoot, but I quickly found some answers, through a nobel prize winner\u2019s study which was partially funded by you guessed it\u2026\u2026.. <i><strong>GiveWell</strong></i><br>&nbsp;</p><h3><strong>Part 2: A Nobel Prize winner\u2019s innovative math</strong></h3><p>Michael Kremer won a Nobel prize along with two J-PAL co-founders for their wonderful work pioneering randomised controlled trials to assess development interventions. What better person to try their hand at estimating the mortality benefit of clean water than a father of the RCT movement?</p><p>But connecting clean water and mortality is tricky, because to date no-one has actually asked whether clean water can reduce child mortality. Instead, a number of RCT asked the more obvious question, <i><strong>does clean water reduce diarrhoea. </strong></i>The answer obviously yes.</p><p>But Kremer and co. found a clever way around this. They sifted through all studies which looked at the relationship between clean water and diarrhoea and identified 12 studies<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6pv602et8vu\"><sup><a href=\"#fn6pv602et8vu\">[1]</a></sup></span>&nbsp;that also gathered bits and pieces of mortality data. They then performed a meta-analysis, pooling that mortality data together to see whether clean water save kids\u2019 lives.</p><p>The result \u2013 they estimated that clean water caused an <i><strong>incredible 30% mortality reduction</strong></i> in kids under 5. If this is even in the ballpark of correct, clean water could could prevent one in three childhood deaths in much of sub-saharan Africa. If Africa could chlorinate and filter all drinking water, we could save perhaps <a href=\"https://www.downtoearth.org.in/news/africa/in-2021-2-8-million-children-in-sub-saharan-africa-died-before-reaching-their-fifth-birthday-un-report-87042\"><strong>1 million lives</strong></a><strong> every year&nbsp;</strong>in sub-saharan Africa alone<strong>.&nbsp;</strong>Mosquito nets might bow to their new king.</p><p>To be as crystal clear as the water, this is not just a 30% reduction in diarrheal deaths, but a <i><strong>30% reduction in overall under 5 mortality.&nbsp;</strong></i>To put this in perspective, mosquito nets reduce childhood mortality by about 20%&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefo0i7d7hdagp\"><sup><a href=\"#fno0i7d7hdagp\">[2]</a></sup></span>&nbsp;and in one smallish study the new R21 malaria vaccine RTS,S was associated with an estimated 13% mortality reduction&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftt7fdcpgzye\"><sup><a href=\"#fntt7fdcpgzye\">[3]</a></sup></span>&nbsp;This raises a fairly obvious question.<br><br><i><strong>How does clean water cause that almighty mortality reduction?</strong></i><br><br>Because it ain\u2019t just the diarrhea. Kremer and co calculated that reduction in diarrhoea deaths account ed for <i><strong>only 1 in 8</strong></i> of the lives saved by the clean water intervention.&nbsp;<br>&nbsp;</p><h3><strong>Part 3. We already knew about this anomaly \u2013 100 years ago</strong></h3><p>It turns out that science has been around for quite some time, and sometimes the scientific-wheel-of-time comes full circle. Over 100 years ago, this <i><strong>exact same phenomenon&nbsp;</strong></i>Kremer observed in 2023, was independently discovered by two scientists on opposite sides of the world - Mills in Lawrence, USA and Reinke in Hamburg, Germany.&nbsp;</p><p>In the late 19<sup>th</sup> century Germany and the USA finally began systematically filtering their water \u2013 for the first time huge swathes of the western world drank, bathed and washed clothes with water cleared of microbial soup. As expected the horrible killer that was typhoid was all but wiped out, but Mills and Reinke noticed something more profound - <i><strong>Childhood mortality plummeted,</strong></i> far more than could be explained by the absence of typhoid. Some reports claimed a 40%, or even 50% drop in child mortality. The world &nbsp;all of a sudden became a whole lot better than we expected.</p><p>In a landmark 1910 paper&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref43lotxzzpx8\"><sup><a href=\"#fn43lotxzzpx8\">[4]</a></sup></span>&nbsp;this anomaly was labelled <strong>The Mills- Reinke Phenomenon&nbsp;</strong>in a widely cited paper by Sedgewick, another public health legend<strong>.</strong> As I write this in Boston after the EAG, I feel some warm fuzzy local MIT history.<br>&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/mqfypzxnyakjpcuux3ur\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/u8zw2e5pxbv5oigngepq 170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/rpry57ko9znjvzhzstjy 340w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/wqdp6bxhfy1otvcyzoqh 510w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/bd3bzzzgao4j6nr5ntyz 680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/weuasfeleh03n28pw3bh 850w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/xhnatwq63z1qyccnje87 1020w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/rfdpftk65a1rvyg3oldo 1190w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/fvfp4ny6etgcomblk4uw 1360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/fptqcexfqjq2vwyt1hez 1530w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/tkf0gvg86olipznii5ls 1610w\"></figure><h3><br><strong>Part 4: But why?</strong></h3><p>Occam\u2019s razor suggests that the reduction in mortality might be due to reduction in a range of non-diarrhoea infectious diseases as well. Perhaps when people wash with clean water, bugs that cause disease such as pneumonia and meningitis are killed and don\u2019t spread as readily as before. Perhaps neonatal infections are reduced as cleaner water is used in the birthing process.&nbsp;</p><p>Or maybe its something different - when the body stops taking hits from diarrhoea, malnutrition reduces and the immune system can handle other infections better. This is more likely than you might think, as without clean water kids get diarrhoea all the time, in the ballpark of 5 times&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefw4nq8voi0h\"><sup><a href=\"#fnw4nq8voi0h\">[5]</a></sup></span>&nbsp;each year.</p><p>However even if we add together a bunch of potential infectious disease reductions, it is not easy to <i><strong>explain a full 30% mortality benefit</strong></i>. To visualize this, here\u2019s GBD\u2019s causes of under 5 mortality in Rwanda and how much of the square we would need to cut out to account for a 30% reduction.<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/y48ub7wxewcczcnsrsoj\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/xbhg9xwani77t4v1fo0y 190w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/x6eq8kflnl3hmwjgzh82 380w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/qazjawj3figwb5qmr7g6 570w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/fu5wlgzit5p26df1yznq 760w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/vningafda9ntejunfwuq 950w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/vqn249aou998zlarmrtp 1140w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/t4bpfzdjcwlgo9qc3nbw 1330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/wflybwpkojzd3xgiopw7 1520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/rb6ni3xo3fz6q0hk0p7n 1710w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hFPbe2ZwmB9athsXT/yye08k4dmc3s4krjigem 1836w\"></p><p>To demonstrate how hard it is to account for this mortality reduction, here's an example of a barely plausible \"lolly bag\" of mortality reductions that we would need to account for even a 25% total mortality reduction<br><br>- 50% reduction in diarrhea mortality (at the extreme end of what is reported in studies)<br>- 30% reduction in neonatal mortality<br>- 30% reduction in pneumonia mortality<br>- 50% reduction in Malnutrition mortality<br>- 20% reduction in malaria mortality (from improved immunity and nutrition? Clean water can't plausibly reduce malaria prevalence as mosquitos don't care how clean your skin or gut are)</p><p>Perhaps you have a better, novel idea of how this all works, can prove it and win the Nobel prize. You might collect it hand in hand with Kremer as he receives his second\u2026</p><p>I suppose one could argue that \u201cthe why\u201d isn\u2019t so important. What matters is the benefit, the consequences. We should pass go, collect the fantastic mortality reduction and \"wash our hands\"<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqjt8n4gvzt\"><sup><a href=\"#fnqjt8n4gvzt\">[6]</a></sup></span>&nbsp; of the question. <i>I disagree </i>\u2013 understanding the science here might reveal other hidden benefits. It may help us choose better between different methods of cleaning the water. Or if there is immunology involved, we might even be pointed towards new vaccine techniques or other solutions for infectious diseases.&nbsp;</p><p><strong>This mystery should be solved.</strong><br>&nbsp;</p><h3><strong>Part 5: What next for clean water?</strong></h3><p><strong>1. We still need a RCT powered for Mortality</strong><br>This may seem like overcaution, but I don\u2019t think our data is good enough yet to call the slam-dunk on clean water as this apparently epic magic bullet for reducing child mortality. Kremer looks retrospectively at data not gathered for-purpose, which is in epidemiological speak <i><strong>a little dodgy.</strong></i> As of yet, we have no RCT which has been designed and powered to detect mortality benefits from clean water. I have heard there may be a study underway looking at this, but I couldn\u2019t find it (let me know if you can). If it is ongoing, <i><strong>I sure hope they are looking at the causes of excess mortality in the non-clean water group</strong></i>, because that could get us a lot closer to understanding the why.</p><p><strong>2. We should (probably) continue scaling up clean water in the meantime.&nbsp;</strong><br>The data we have strongly suggests that cleaning water is likely to be a high cost-effective intervention. A bigger practical debate may be <i><strong>how&nbsp;</strong></i>to clean the water. <a href=\"https://www.evidenceaction.org/programs/safe-water-now\">Evidence Action\u2019s</a> large scale program uses multiple methods, including water dispensers for individual households and in-line chlorination. However given that these are not permanent measures there is a reasonable more long-termist<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefm7j4pril4q\"><sup><a href=\"#fnm7j4pril4q\">[7]</a></sup></span>&nbsp;argument that simply speeding up the &nbsp;expansion of nationwide piped water networks might be a more durable, longterm approach albeit more expensive and slow.</p><p><strong>3. WE NEED TO KNOW WHY&nbsp;</strong>lives are being lost from dirty water, and saved by the clean stuff. Is it mostly due to one disease? From a range of diseases? From something else entirely? If we understand why, this may open up other avenues and interventions which could save further lives. We owe it to great scientists like Kremer, Mills, Reinke and Sedgewick, but even more to the millions of kids still dying every year because they aren\u2019t drinking clean water.</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6pv602et8vu\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6pv602et8vu\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Only 5 of these were RCTs. Givewell's more conservative 17% number arose from leaving out the other studies, and only using the RCTs in their analysis</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fno0i7d7hdagp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefo0i7d7hdagp\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD000363.pub3/full\">https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD000363.pub3/full</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntt7fdcpgzye\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftt7fdcpgzye\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.science.org/content/article/first-malaria-vaccine-slashes-early-childhood-deaths\">https://www.science.org/content/article/first-malaria-vaccine-slashes-early-childhood-deaths</a></p><p>This 13% mortality reduction from the malaria vaccine also doesn't make complete sense, when malaria only makes up about 10% of childhood mortality. Perhaps another article for another day... Maybe if we find enough interventions which massively reduce childhood mortality we could end up with negative mortality? (J/K)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn43lotxzzpx8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref43lotxzzpx8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://www.jstor.org/stable/30073304?seq=1</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnw4nq8voi0h\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefw4nq8voi0h\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://www.mdpi.com/2078-1547/6/2/229</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqjt8n4gvzt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqjt8n4gvzt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I will never apologise for a bad pun</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnm7j4pril4q\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefm7j4pril4q\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I know this isn't actually a \"long-termist\" argument, I'm just trolling.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fneen7e2vmye\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefeen7e2vmye\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8gml8i8pwup\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8gml8i8pwup\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmr74n0xhiuq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmr74n0xhiuq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;</p><p>&nbsp;</p></div></li></ol>", "user": {"username": "NickLaing"}}, {"_id": "JD9NGYhL99h56C7yY", "title": "EA Community Survey (MCF 2023)", "postedAt": "2023-11-03T23:18:11.129Z", "htmlBody": "<p>As part of a sequence of posts on the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/33o5jbe3WjPriGyAR/announcing-the-meta-coordination-forum-2023\"><u>Meta Coordination Forum (MCF) 2023</u></a>, this post summarizes the results of the MCF Community Survey.&nbsp;</p><h2>About the Community Survey&nbsp;&nbsp;</h2><p>We (the organizers of Meta Coordination Forum 2023) invited community members to share their views on meta-EA topics in an&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/33o5jbe3WjPriGyAR/announcing-the-meta-coordination-forum-2023\"><u>announcement about MCF</u></a> early September 2023.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjtsvuuapalj\"><sup><a href=\"#fnjtsvuuapalj\">[1]</a></sup></span></p><p>The survey we invited community members to fill out included many of the same questions we asked MCF invitees (summarized here), as well as some new questions on topics like transparency. Thirty-six (n = 36) members of the community responded. In the summary of results below, we compare community members' responses with MCF invitees\u2019 responses when possible.&nbsp;</p><h3>Caveats</h3><ul><li><strong>We think this summary is likely not representative of the EA community.&nbsp;</strong>We think this because the survey received relatively few responses and it was not widely shared (only in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/33o5jbe3WjPriGyAR/announcing-the-meta-coordination-forum-2023\"><u>this forum post</u></a>). I (Michel) wish we would have publicized this survey more in hindsight, but I understand why we didn\u2019t prioritize this at the time: the weeks before MCF were very busy for the team.</li><li>We often used LLMs for the summaries.</li></ul><h2>The Future of EA</h2><h3>Briefly outline a vision for effective altruism that you\u2019re excited about.&nbsp;</h3><p><strong>Community &amp; Inclusion (7 mentions):</strong></p><ul><li>A welcoming and friendly EA that poses the question, \"What's the most effective way to do good?\" and doesn't impose strict ideologies.</li><li>EA should be inclusive, catering to kind, curious, ambitious individuals and fostering overlaps with other communities.</li><li>It should represent an open church that respects diverse opinions on cause areas.&nbsp;</li><li>Actively address racism, classism, sexism, and maintain strong ties with the academic world.</li><li>It should maintain worldview diversity, being aware of every cause area's limitations.</li><li>Emulate successful movements like climate, civil rights, and animal rights.</li></ul><p><strong>Career &amp; Life Paths (4 mentions):</strong></p><ul><li>Encourage individuals to pursue higher-impact life paths, through donations, choosing impactful careers, or adjusting current roles for greater impact.</li><li>Equip people with tools and training to achieve high impact. EA shouldn't convey that only the 'elite' matter; instead, it should be inclusive.</li><li>Offer guidance suited to various life situations; for example, advice overly focused on studying computer science or consultancy isn't suitable for everyone.</li><li>Allow people to enjoy EA as a community regardless of their professional affiliations. Example: a school teacher should be valued at EA community gatherings.</li></ul><p><strong>Governance &amp; Structure (5 mentions):</strong></p><ul><li>Infrastructure to handle interpersonal conflicts and deal with problematic individuals.</li><li>Develop independent cause/field-specific professional networks decoupled from EA.</li><li>Encourage decentralized, localized communities, professionalize cause areas, and shift from centralized funding for community building.</li><li>EA should preach and practice worldview diversification and cause neutrality. Reduce concentration of power, increase democratic elements, and ensure inclusivity and professionalism.</li><li>Improve coordination across the movement, better map organizations and their roles, and adopt innovative governance techniques for enhanced collaboration.</li></ul><p><strong>Global Perspective (3 mentions):</strong></p><ul><li>EA should become truly global, reflecting the worldwide nature of future-shaping transformative technologies.</li><li>A global, decentralized EA movement led by community builders that influence people and equip them with tools and networks.</li><li>Focus on ensuring EA remains a hub for diverse cause areas to interact, provides capacity for neglected global threats, and aims to become a mainstream ideology.</li></ul><p><strong>Role &amp; Outreach (5 mentions):</strong></p><ul><li>EA should act as a catalyst to shift the entire impact-based economy towards higher efficacy.</li><li>Envision EA as an ideology 'in the water', akin to environmentalism or feminism, making it mainstream.</li><li>EA should be a movement focusing on the principles of scale, tractability, and neglectedness.</li><li>Provide tools and networks to enable individuals and institutions to achieve the most good, with an emphasis on specific cause areas but remaining open to new ones.</li><li>EA should focus on both current and future technological progress, balancing between harm prevention and growth encouragement, especially from a longtermist perspective.</li></ul><h3>What topics do you think would be important to discuss at the Meta Coordination Forum?</h3><p>The Meta Coordination Forum received a wide range of suggested topics to discuss, covering various aspects of EA.</p><p><strong>Strategy and Focus</strong></p><ol><li><strong>EA's Future Focus</strong>: Suggestions were made on discussing the trajectory and focus of EA five years from now.&nbsp;</li><li><strong>Cause Prioritization:&nbsp;</strong>Multiple mentions were made about the need for a discussion on cause prioritization, especially concerning AI Safety. One point specifically raised the importance of monitoring neglectedness and importance in causes.</li><li><strong>Resource Distribution:&nbsp;</strong>Questions were posed about distributing resources between AI and non-AI work and finding new mega donors to diversify from Open Philanthropy.</li></ol><p><strong>Governance and Oversight</strong></p><ol><li><strong>Community Oversight:&nbsp;</strong>Mentioned multiple times, questions about the governance and oversight of EA organizations were raised, including the efficacy of the Community Health Team.</li><li><strong>Open Philanthropy\u2019s Role:&nbsp;</strong>Multiple responses focused on Open Philanthropy\u2019s large influence due to its funding monopoly, questioning its accountability and suggesting the introduction of other funders.</li><li><strong>Decision-making:</strong> Multiple queries were made about the top-down vs. bottom-up decision-making within EA. Questions about democratic elements in central EA were also mentioned.</li></ol><p><strong>Community and Culture</strong></p><ol><li><strong>Community Health:&nbsp;</strong>Some responses wanted to see more effort put into reducing what they perceived as governance failures in cases like FTX and Nonlinear, alongside better support community builders.</li><li><strong>Inclusion and Accessibility:&nbsp;</strong>These were brought up in the context of what type of community EA should be.</li><li><strong>Branding and Identity:&nbsp;</strong>Several responses discussed EA\u2019s branding, including the epistemic health of the community and who should be responsible for the \"brand.\"</li><li><strong>Global Inclusion:&nbsp;</strong>One respondent wanted to see more discussion on promoting EA principles in the Global South.</li></ol><p><strong>Transparency and Communication</strong></p><ol><li><strong>Internal and External Communication:&nbsp;</strong>Multiple responses indicated a need for clearer internal communication and the division between internal &amp; external communication.</li><li><strong>Coordination Mechanisms:&nbsp;</strong>There were calls for better coordination mechanisms generally and how information should be disseminated to the broader community.</li></ol><p><strong>Ethical and Philosophical Considerations</strong></p><ol><li><strong>Longtermism:</strong> Its importance and how closely connected it is to EA was discussed.</li><li><strong>Consequences:</strong> One person questioned whether EA is actually bringing about better consequences in the world.</li><li><strong>Ethical Frameworks:&nbsp;</strong>Points were raised about whether the community should lean more into non-consequentialist ethics and if it should be more risk-averse.</li></ol><p><strong>Specific Initiatives and Events</strong></p><ol><li><strong>Recent Developments:</strong> AI safety was noted as the area where the strategic situation has shifted the most, citing events like ChatGPT, GPT4, and various AI letters and task forces.</li><li><strong>FTX and Scandals:&nbsp;</strong>How to move on from FTX and other internal scandals, such as sexual assault and governance failures, was mentioned multiple times.</li><li><strong>Role of Various EA Entities:&nbsp;</strong>Topics like the role of EA Groups, EA Funds, and CEA were brought up, with a hope of having these groups make their priorities clearer.</li></ol><p><br>Overall, the suggested topics reflect a community grappling with questions about its focus, governance, and ethical orientation, while also considering how to improve inclusivity, communication, and long-term sustainability.</p><h3>How much should reflecting on the FTX collapse change the work-related actions of the average attendee of this event?</h3><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/bfguar4j3hscquz8nv4l\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/c7oijp9pmavzsrlnmx5b 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/uad2u4gfpqapbvjt1xgc 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/nqrixlkbk4vtbkn7btwu 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/wjobivkltofpzsnu0p6l 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/v6tias6q9fonekzlau4r 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/zyjfzn1wr0zvpdplywwx 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/pig5rp7ztks9s78ha4eg 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/cemyxlgnv4bycrnak4yw 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/hhhxnu5qwhoozukppayz 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/febl12uzo2o94tifrevc 908w\"></figure><h3>Community views on the future of EA</h3><p><i>When possible, we compared these views to Meta Coordination Forum invitees who were asked the identical question.&nbsp;</i></p><p><strong>EA should be a community rather than a professional network.</strong> (n = 33, Mean = 3.5, SD = 1.6)</p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/sgpip4pzdf42ovux5lvx\"></strong></p><p><strong>Assuming there will continue to be three EAG-like conferences each year, these should all be replaced by conferences framed around specific cause areas/subtopics rather than about EA in general (e.g. by having two conferences on x-risk or AI-risk and a third one on GHW/FAW).</strong><br><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/qctawcb4flz9vc3y1r8g\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/n4pcij59ycdpwnqfg10z 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/hcsomyjkhgusgxnmszlt 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/vczplujd5qe0gbkekrmy 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/djggac97sgg0f4r4sj0u 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/iupzpkh7pibjoa55buxd 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/b8gfub6c5oes7kvkw2ps 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/sfi2hh5ri1bp6b2haomv 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/axogqjyzrrlo01hzb1bn 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/x9stzs9xosbz2bcxvrro 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/tfrpzahu0jzq3lsavtus 932w\"></p><p><strong>There is a leadership vacuum in the EA community that someone needs to fill.</strong></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/dzt2ywfdzjz9yqsqmpzl\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/syrtlopiju0nqmvgpmom 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/oobzu6qz4rv8nrzh4k2e 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/amr1luk1wjwrhmh0vmgj 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/grhwtyoqkqwjobjgsh8a 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/p9ycux2pujjev64ccgn6 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/oirpop8k9lapfjowgqme 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/wlcm2e1emva8i2gdlqwm 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/fhx0xadh4ubkfh63h9ia 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/pyg9yzwk4i2abuorj9ij 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ntlkttk3vdzlf4yp66ez 896w\"></figure><p>&nbsp;</p><p><strong>We should focus more on building particular fields (AI safety, effective global health, etc.) than building EA.&nbsp;</strong>(n = 34, Mean = 4.1, SD = 1.6)</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/dnsjtblv9l5qo3qm51wj\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ch6pai90qc5v2kpeui0m 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/atpa7kg76mqeszy0beod 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/e5j7vpblkonozc5ppk4o 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/cxictot4fuvl14u1ounr 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/uxj7kszwum4appkkcfys 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/wv64sd15placpr4ux5wx 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/eoky1wfe8uxsd69es0a9 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/yvumtz9ejxmdmcagtnnd 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/modybqll0lviwdb55pxg 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/tpq5eqdg0f10mhbwu2zd 902w\"></figure><p>&nbsp;</p><h3>Transparency</h3><p><strong>EA thought-leaders and orgs should be more transparent than they currently are.&nbsp;</strong>(n = 32, Mean = 5.1, SD = 1.7)</p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/onvpyzbd0ripz7qgboks\"></strong></p><p><strong>If you're pro more transparency on the part of EA thought-leaders and orgs, what type of information would you like to see shared more transparently?</strong></p><p><i>Projects listed below were mentioned once, unless otherwise noted. This is a long list, so org leaders may be interested in which of the below people most want to see.&nbsp;</i></p><ol><li><strong>Justifications for Role Assignments:&nbsp;</strong>A clear rationale for why specific people are chosen for roles, especially when they lack obvious experience, to avoid perceptions of nepotism or bias.</li><li><strong>Moral Weights:&nbsp;</strong>Transparency about the ethical considerations that guide decisions.&nbsp;</li><li><strong>Regular Updates &amp; Communication:</strong><ul><li>Organizational updates every 6-12 months.</li><li>Monthly, informal updates from employees.</li><li>Write-ups akin to communicating with a trusted friend, sharing personal and institutional positions. (Multiple mentions)&nbsp;&nbsp;</li></ul></li><li><strong>Insight into Operations and Strategy:</strong><ul><li>Monitoring, evaluating, and sharing results with the community.</li><li>How decisions were made and who was consulted.</li><li>Risks the community should be aware of.</li><li>Opportunities for community involvement.</li><li>Financial incentives.</li><li>Concrete plans for various issues. (Multiple mentions)&nbsp;&nbsp;</li></ul></li><li><strong>Transparency from Major Funders: </strong>Explanation of funding priorities, and factors that influenced them. For example, knowing a funder's mission to spend their founder's net worth before they die could explain certain actions. (Mentioned twice)</li><li><strong>Organizational Culture:</strong>&nbsp;Information about the work culture, measures for a safe environment, and potentially on addressing social issues like transphobia and racism.&nbsp;</li><li><strong>Transparent Decision-Making:</strong><ul><li>Disclosure of conflicts of interest.</li><li>Responses to criticisms.</li><li>Lists of advisors and board members, and their selection criteria.&nbsp;</li><li>Strategies, theories of change, and underlying assumptions. (Multiple mentions)&nbsp;&nbsp;</li></ul></li><li><strong>Community Building:</strong><ul><li>Transparency in the focus areas (e.g., why focusing on elite universities).</li><li>Decentralization of power around funding.</li><li>Clarity on decision-makers in EA orgs and their structure. (Multiple mentions)&nbsp;&nbsp;</li></ul></li><li><strong>Accountability and Governance:</strong><ul><li>Public blog posts about decision-making within EA orgs, ideally semi-annually.</li><li>Suggestions for more democratic features like community elections for some leadership positions. (Mentioned twice)</li></ul></li><li><strong>Miscellaneous:</strong><ul><li>A post-FTX reflection.</li><li>Updates on what EA Funds is doing.</li><li>A <a href=\"https://forum.effectivealtruism.org/posts/mzzPMrBjGpra2JSDw/ea-organizations-should-have-a-transparent-scope\">transparent scope</a>.</li></ul></li></ol><h2>The Relationship between EA and AI safety</h2><h3>Given the growing salience of AI safety, how would you like EA to evolve?</h3><p><strong>AI Safety and EA Overlap:</strong></p><ol><li><strong>Maintaining Distinction</strong> (7 mentions):&nbsp;<ol><li>Many feel that AI safety and Effective Altruism (EA) should not be seen as one and the same. For instance, AI safety should not dominate EA so much that they become synonymous.&nbsp;</li><li>Some opine that the overlap between EA and AI safety is currently too extensive. They believe that community building efforts should not converge further, but should expand into newer, untapped areas.</li></ol></li><li><strong>Separate Infrastructure</strong>&nbsp;(4 mentions):&nbsp;<ol><li>Proposals include creating an AI safety equivalent of the Centre for Effective Altruism (CEA) and allowing AI safety-focused organizations to operate as active spin-offs, similar to Giving What We Can (GWWC) or CE.&nbsp;</li></ol></li><li><strong>Continued Connection</strong>&nbsp;(1 mention):&nbsp;<ol><li>Despite advocating for a distinct AI safety community, some also acknowledge the inherent ties between AI safety and EA, emphasizing that AI safety will always remain linked to EA.</li></ol></li></ol><p><strong>Role of AI Safety in EA:</strong></p><ol><li><strong>Support</strong>&nbsp;(5 mentions):&nbsp;<ol><li>Many respondents acknowledge the importance of AI safety and feel that EA should continue to provide resources, mentorship, and support. Some emphasize the need for more programs, pipelines, and organizations.</li></ol></li><li><strong>Broad Approach</strong>&nbsp;(3 mentions):&nbsp;<ol><li>There's a sentiment that while AI safety is critical, EA should not singularly focus on it at the expense of other initiatives. A diverse and multifaceted approach is essential to address various global challenges.</li></ol></li><li><strong>Worldview Diversity</strong> (2 mentions):&nbsp;<ol><li>Some respondents advocate for worldview diversity within EA. They stress the importance of understanding that different worldviews will assign varying levels of importance to AI safety.</li></ol></li><li><strong>Engagement Depth</strong>&nbsp;(2 mentions):&nbsp;<ol><li>Respondents advocate for deeper engagement with AI safety as a cause, urging against merely nudging people into default paths.</li></ol></li></ol><p><strong>Public Perception and Branding:</strong></p><ol><li><strong>Concerns about Association </strong>(5 mentions):<ol><li>Some respondents express concerns that closely tying AI safety to EA could lead to public skepticism, especially from groups that might traditionally be wary of EA. This might hinder collaborative efforts in areas like policy advocacy.</li></ol></li><li><strong>Potential PR Implications</strong>&nbsp;(2 mentions):&nbsp;<ol><li>The association of AI safety with EA might deter some talent from joining either cause. Given the recent PR challenges faced by EA, some believe it might be advantageous for AI safety to be recognized as its own field/cause.</li></ol></li></ol><p><strong>Strategic Considerations:</strong></p><ol><li><strong>Growth and Talent Acquisition</strong> (3 mentions):<ol><li>A few respondents emphasize the need to grow both the AI safety and EA communities. They suggest that recruitment for AI safety shouldn't necessarily require familiarizing prospects with the entire EA ideology, and vice versa.</li></ol></li><li><strong>Near-term Optimization</strong> (1 mention):&nbsp;<ol><li>A note of caution was raised against over-optimizing based on near-term timelines.</li></ol></li></ol><p><strong>Safety and Security Considerations</strong> (1 mention):&nbsp;</p><ol><li>With the rise of AI capabilities, one respondent thought that the EA community should be more security conscious, including minimizing social media use and being wary of potentially hackable technologies.</li></ol><p><strong>Other focuses:</strong></p><ol><li><strong>Digital Sentience</strong>&nbsp;(1 mention):&nbsp;<ol><li>There's a call for greater focus on the issue of digital sentience.</li></ol></li><li><strong>Effective Giving</strong>&nbsp;(1 mention):<ol><li>A respondent expressed the desire for the growth of effective giving as a primary facet of EA.</li></ol></li></ol><h3>Agreement voting on relationship between EA &amp; AI safety</h3><p><strong>Most AI safety outreach should be done without presenting EA ideas or assuming EA frameworks.</strong></p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/plitbpknfu15wmxampfk\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/hpcdgzu3q1ktcncgpl9t 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/dmf6lvcnupuclusxvlyn 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/kr0ux9maelgxq2pbyz8g 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ejkhogac5bcmiiykxnig 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/pnbs5kdofdh01xe1kqru 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/mgkczdr8on4t2fmdihgq 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/osgbfmrdyjcwrrsxuz1m 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/i4mwo5hvovobvtkiyxb2 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/iawfxishwztartjnf4dh 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/edi0ogr7z8qiwlrstvza 910w\"></strong></p><p><strong>Most EA outreach should include discussion of AI safety as a cause area.</strong></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/zqxrsbo0z05jelw1sfqi\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/kbg417i5ic2yk0mmzvlz 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/jvecdnpuz9xmijfqlgtn 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/pyxqqdjawxkweryxyx8o 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/h5fidwu152qhgum0fsmm 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/bcreydxrtcqatdwxui5n 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/azylectbcc4uezplbrqu 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/c16k8rtkstkmjwuzjugb 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/yokryam6ljrqkqvj6g0h 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/zr3txlevyqyof6b0tprl 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/tfxumw66ltzbfvidqmwx 912w\"></figure><p><strong>We should promote AI safety ideas more than other EA ideas.</strong></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/mimpybbwsbqj4i4pknyt\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/wtvgw6ttrzwjqxadeqvz 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ecgwlrogrclbrffgrrx5 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/yo5bwijjswoyswejehup 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ywe6ktvpmynvkazcmviu 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/zbhxwcrpkcjzyr9ghp5r 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ry53vaxyteibpw8zjrpl 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/w0bf894jkfppp4vex6ly 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/dhapxemp4dqyz5ollokw 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/maamd7fripdcocskg0mc 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/hccgxtjdhyn9k1xvffdi 896w\"></figure><p><strong>We should try to make some EA principles (e.g., scope sensitivity) a core part of the AI safety field.</strong></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/dvncbjsbafvi4pdcldfv\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/fxvycbpcwvx2rgefqtir 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ezukiv3q3gjdmuriigyg 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ntcgtastykrqszmyk2va 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/enigv0mxlm7qchvco38x 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ehqumx7krqlfcwiletka 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/yjeiblf7qjmxb5z5j2rr 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/by8yqk8i1xxiqonhoebj 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/lhydjwqd0j7fzjfvcctu 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/liljjzylv0evelcwppi4 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/jyjbrb31bsyzetplq5ul 912w\"></figure><p><strong>AI safety work should, like global health and animal welfare, include many more people who are not into effective altruism.</strong></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/faxhqrv6ua6mxehheffw\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/n0titzjepis6bl3fv1mz 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/xzcpwi0schuf9g1zxxx6 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ggqkg3e8pkqxea37knep 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/bizczzsvk4jdwbp9nmju 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/je2fbbnjozqaouqlffdj 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/k20ragzusvztb92dj0rp 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/xey74lc7glyckfzcuhrx 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ho8nxeohjwb7by1lrzkk 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/pfwl5f82paqequrvcykn 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/yvmxfrqwrjokeutwur3a 906w\"></figure><p>&nbsp;</p><p><strong>EA hubs should try to set up separate AI safety office spaces.</strong></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/bx1gaagb5b9bcfvk2fft\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ufogwo0msmsjqqgo3qul 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ivvxxghsq7k8ymycsupm 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/dqvouhwo7z1ucklb0x6a 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ryqtoslp77fhyzvjvvlt 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/jsx59hufsa7b4cznzizm 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/tx8tybdrblsc449ziup8 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/fnzi1jkzsrvfhndawtai 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/enht4rvblhpma5e7gjzx 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/wllrxkbu11ait0lzjthg 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/fawqx2r6aymehvsjxevs 906w\"></figure><p>&nbsp;</p><p><strong>We should have separate EA and AI safety student groups at top 20 universities.<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/fvpqzmcv2neak2ubna3a\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/wpim05tgb5w45cs3vda1 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/cuqjm38cfdjisgwpqqed 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/udu2tditrjcfrdsqdync 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/oj7u7va4voeplidkj5av 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/jojx5aa63wjpylwnhheg 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/adfcwqrxwf8jj6har0ws 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/qnbj6xfhybtjumfw4szi 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/tep2jhq9wbdbz1rd8roc 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/pexdgnpyxzsdw4uewttw 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/igeq65mr16brgvrgjomn 910w\"></strong></p><p><strong>We should have separate EA and AI safety student groups at most top 100 universities.<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/iqnb2nmu0apvf7aymhni\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/xjm0smnfu1b6il45ncqb 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/q0phlftemdkc2aabotp4 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ajea3tccorphkkpmx88s 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/brhxrdgrbktj5olaxnjh 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/f9bbq0p2ireobudxvsxf 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/b8qcl7m6mqgtimdhil61 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/hzwsqauw6vondtuzzroy 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/u6amixgvtpgj3dufmyoo 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/ncxenuxxtmbxpsai29en 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JD9NGYhL99h56C7yY/omaeiq6idhootsidv4cx 906w\"></strong></p><p>&nbsp;</p><h3>Do you have any comments on the relationship between EA and AI safety more broadly?</h3><ol><li><strong>Separation vs. Integration:</strong><ul><li>Many respondents believe there should be a distinction between EA and AI safety. Some argue that while EA may fund and prioritize AI work, the communities and work should remain separate. They cite risks of dilution and potential misalignment if the two become synonymous.</li><li>On the flip side, others feel that AI safety is like any other cause within the EA framework and should not be treated differently. There's an emphasis on the benefits of interdisciplinary exchanges if AI safety remains under the EA umbrella. (Brought up multiple times).</li><li>There were comparisons drawn to the animal welfare space, where tensions between EA-aligned and non-EA-aligned advocates have arisen, leading to potential distrust and a tainted \"animal rights\" identity. There's a worry that AI Safety could face similar challenges if it becomes too diluted.&nbsp;</li><li>There's a suggestion to establish a new organization like CEA focused solely on AI safety field-building, separate from other EA community-building efforts.</li></ul></li><li><strong>Role of EA in AI Safety:</strong><ul><li>EA's value in the AI safety domain might lie not in recognizing AI safety as a concern (which may become mainstream) but in considering neglected or unique aspects within AI safety. EA could serve as a 'community of last resort' to address these issues.</li></ul></li><li><strong>Concerns with too much focus on AI safety:</strong><ul><li>Some respondents expressed concerns about the close association between AI safety and EA. They feel that EA has become heavily dominated by AI safety discussions, making it challenging for those working in non-AI safety domains.</li><li>EA should not solely be about AI safety. The community should return to its roots of cause neutrality and effectiveness.</li><li>One respondent suggests monitoring university group feedback to ensure that attendees don't feel pressured to prioritize a particular cause. They propose specific survey questions for this purpose.</li></ul></li><li><strong>Outreach &amp; Engagement:</strong><ul><li>It's suggested that AI safety outreach should occur without the EA branding or assumptions, even if managed by local EA groups. This would prevent potential misrepresentations and ensure genuine interest.</li><li>There's a call for diversity and thoughtful execution in outreach to make people aware of AI risks. One respondent mentioned the idea of having someone responsible for \"epistemics\" during this outreach.</li><li>Concerns were raised about the implications of an AI safety-centric approach on EA engagement in the Global South.</li></ul></li></ol><h2>Meta-EA Projects and Reforms</h2><h3>What new projects would you like to see in the meta-EA space?</h3><p><i>Projects listed below were mentioned once, unless otherwise noted.&nbsp;</i></p><p><strong>Career and Talent Development</strong></p><ol><li><strong>Career Training and Support:</strong> A repeated theme is the need for career training and financial support for people transitioning to high-impact roles.</li><li><strong>Talent Pipeline:</strong> Interest in creating better talent pipelines for university students, focusing on EA knowledge and rationality.</li><li><strong>Mid-Career Engagement:&nbsp;</strong>Multiple responses indicate a need for engaging mid-career professionals and addressing operational errors in EA organizations through their expertise (Mentioned 3+ times).</li></ol><p><strong>Governance and Internal Affairs</strong></p><ol><li><strong>Mediation and Communication:&nbsp;</strong>The idea of professional mediators to handle interpersonal issues within EA is floated, along with more internal mediation (Mentioned 2 times).</li><li><strong>Whistleblowing:&nbsp;</strong>Establishment of an independent whistleblowing organization to highlight conflicts of interest and bad behavior. (Mentioned 2 times).</li><li><strong>Transparency and Epistemics:</strong> A need for better transparency from EA leaders and organizations for improving epistemic quality (Mentioned 2 times).</li><li><strong>Diversifying Boards and Training:</strong> Suggestions for training people for governance roles, like serving on boards and auditing.</li></ol><p><strong>Outreach and Inclusion</strong></p><ol><li><strong>Global Outreach:&nbsp;</strong>Multiple responses advocate for making EA and AI safety more global and less elite-focused (Mentioned 2+ times).</li><li><strong>Community Building:&nbsp;</strong>Support for national/regional/supranational cooperation initiatives and secure employment options for community builders is desired.</li><li><strong>Diversity Initiatives:&nbsp;</strong>Calls for more diversity efforts, including funding for Black in AI and similar groups.</li></ol><p><strong>Research and Strategy</strong></p><ol><li><strong>Prioritization Research:&nbsp;</strong>A call for building a professional community around prioritization research.</li><li><strong>AI Safety:&nbsp;</strong>Interest in an AI safety field-building organization and a startup accelerator (Mentioned 2 times).</li><li><strong>Donor Advisory:&nbsp;</strong>A desire for more UHNW (Ultra High Net Worth) donation advisory, especially outside of longtermism.</li><li><strong>Effective Animal Advocacy:&nbsp;</strong>The need for better public communication strategies in areas other than longtermism, such as animal advocacy.</li></ol><p><strong>Educational Programs and Public Engagement</strong></p><ol><li><strong>Educational Curricula:&nbsp;</strong>Suggestions for EA-aligned rationality and ethics to be integrated into schools and universities.</li><li><strong>Virtual Programs:&nbsp;</strong>Suggestions for shorter, lower-barrier virtual programs for local community builders interested in AI.</li></ol><p><strong>Miscellaneous</strong></p><ol><li><strong>Alternative Models and Competitors:&nbsp;</strong>Desire for alternative organizations to existing EA structures, and better models for internal EA resource prioritization (Mentioned multiple times).</li><li><strong>Public Intellectual Engagement:&nbsp;</strong>Calls for EA to bring in outside experts for talks and collaboration, including figures like Bill Gates.</li></ol><h3>What obviously important things aren\u2019t getting done?&nbsp;</h3><ol><li><strong>Leadership and Management:&nbsp;</strong>There's a call for more experienced professionals in leadership roles, citing issues with EA organizations hiring people who are unqualified for the roles they are taking on. This point is raised multiple times, with some respondents suggesting potentially hiring management consultants.</li><li><strong>Coordination in AI Safety:</strong>&nbsp;A recurring theme is the lack of centralized coordination, especially in AI safety and governance. It is felt that there is no specific group overseeing the pipeline of AI safety and governance, nor are there efforts to understand and fill in gaps. Some responses argue for more robust centralized coordination, even if it\u2019s separate from meta EA organizations.</li><li><strong>Community Health and Reconciliation:&nbsp;</strong>Some respondents raised concerns about the community's overall health, specifically regarding stress and anxiety. The enforcement of community health policies is also called into question, with suggestions for a well-resourced Community Health team that is potentially separate from the team that&nbsp;<i>enforces&nbsp;</i>the policies.</li><li><strong>Policy and Global Concerns: </strong>Some respondents called for EA to&nbsp; extend to more countries, and to close the gap between EA theory which often originates from the Global North and practice, which is often directed towards the Global South.</li><li><strong>Skeptical Perspective on AI:&nbsp;</strong>One response expresses skepticism about the AI safety community\u2019s motivations, raising concerns about the community being self-serving. It suggests that EA could garner more credibility by achieving something substantial and altruistic, such as a large-scale poverty reduction project.&nbsp;</li><li><strong>Outreach and Engagement:&nbsp;</strong>Respondents noted issues regarding the EA community's engagement with existing cause communities and the political left. The need for more nuanced debate and peer-review processes involving non-EA experts was also mentioned, and outreach to mid-career professionals and traditional career advice services was recommended.&nbsp;</li><li><strong>EA's relationship to Wealth:&nbsp;</strong>A point is made that EA should not be organized around those who have money or align with the goal of increasing their wealth.</li><li><strong>Funding and Philanthropy:&nbsp;</strong>Respondents voiced concerns about the over-reliance on Open Philanthropy, suggesting the need for 'Open Phil 2.0 and 3.0' to diversify funding sources and mitigate vulnerabilities. Earning to Give fundraising for EA causes was also suggested.</li><li><strong>Other Areas: </strong>Responses also touch on the need for community-wide strategy generation, coordination mechanisms, and polling. Animal welfare is noted, though the respondent claimed less familiarity with that space.</li></ol><hr><p>We hope you found this post helpful! If you'd like to give us anonymous feedback you can do so with Amy (who runs the CEA Events team)&nbsp;<a href=\"https://www.admonymous.co/amy\"><u>here</u></a>.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjtsvuuapalj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjtsvuuapalj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;After summarizing the results, we shared a summary of responses and key themes with MCF invitees shortly before the event.&nbsp;</p></div></li></ol>", "user": {"username": "MJusten"}}, {"_id": "uXeY92ZoEE8gnftQE", "title": "A brainstorm of meta-EA projects (MCF 2023)", "postedAt": "2023-11-03T22:38:51.871Z", "htmlBody": "<p>This post is part of a sequence on&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/33o5jbe3WjPriGyAR/announcing-the-meta-coordination-forum-2023\"><u>Meta Coordination Forum 2023</u></a>. It summarizes pre-event survey respondents\u2019 brainstorming on projects they\u2019d like to see.&nbsp;</p><p>You can read more about the pre-event survey results, the survey respondents, and the event <a href=\"https://forum.effectivealtruism.org/posts/eygnoHEFnkzsZmu5u/meta-coordination-forum-2023-pre-event-survey-summary-of\">here</a>.&nbsp;</p><h3>About this survey section</h3><p>We solicited project proposals from Meta Coordination Forum (MCF) 2023 attendees by asking a few closely related, optional questions. These included:&nbsp;</p><ul><li>What new projects would you like to see in EA?</li><li>What obviously important things aren\u2019t getting done?</li><li>What projects should have existed a year ago?</li><li>What\u2019s a \u201cpublic good for EA\u201d that nobody has a direct incentive to do but that would benefit lots of people?</li></ul><p>The resulting list is&nbsp;<i>not</i> a definitive list of the best meta-EA projects; it\u2019s more like a brainstorm and less like a systematic evaluation of options.</p><ul><li><strong>Respondents filled in their answers here quickly&nbsp;</strong>and may not endorse them on reflection.&nbsp;</li><li><i><strong>Respondents probably disagree with each other.&nbsp;</strong>We never asked respondents to evaluate the suggestions of others, but we\u2019re pretty sure that if we had it would have revealed big disagreements. (There was significant disagreement on most other survey questions!)&nbsp;</i></li><li><strong>The value of these projects depends on how well they are executed and who owns them</strong>.</li></ul><p><strong>If someone is interested in taking on one of these projects and would like to connect with the person who proposed it, please&nbsp;</strong><a href=\"mailto:michel.justen@centreforeffectivealtruism.org\"><strong><u>reach out</u></strong></a><strong>.&nbsp;</strong>We may be able to put you in touch.</p><h2>Project Proposals</h2><h3><strong>Coordination and Communication</strong></h3><ol><li>Projects focused on improving connections to groups outside EA (i.e. government, companies, foundations, media, etc.).</li><li>A common knowledge spreadsheet of directly responsible individuals for important projects.</li><li>More \u201cpublic good\u201d-type resources on the state of different talent pipelines and important metrics (e.g., interest in EA).&nbsp;&nbsp;</li><li>More coherent and transparent communication about the funding situation/bar and priorities.</li><li>More effort going into identifying and making known low-integrity actors through some transparent mechanism.</li><li>More effort into improving boards and reducing conflicts of interest across organizations / boards.</li><li>More risk management capacity for EA broadly as a field and not just individual orgs.&nbsp;</li></ol><h3><strong>Career Advice and Talent Allocation</strong></h3><ol><li>Advanced 80K: Career advice targeted at highly committed and talented individuals.</li><li>A separate organization that is an 80k analogue for mid-career people.</li></ol><h3><strong>Community Engagement</strong></h3><ol><li>More creative and fun ways for young people to learn about EA principles that don\u2019t place as much emphasis on doing \"the single most important thing\".</li><li>More support and appreciation for people doing effective giving work (GWWC, Longview), and encouragement for others to do more of this.&nbsp;</li><li>A survey to identify why high-value potential members \"bounce off\" EA.</li><li>A better way to platform great community members who can promote virtues and key principles.</li></ol><h3><strong>AI Safety</strong></h3><ol><li>AI Safety Next Steps: A guide to facilitate entry into AI safety research and activism.</li><li>Something to help people understand and evaluate the actions of AI labs, and possibly critique them.&nbsp;</li><li>An org that can hire and lightly manage independent researchers.</li><li>A better understanding of the relevance of UK or EU AI policy on x-risk, and comparison to US policy.</li><li>A really good book on AI risk.</li><li>AGISF in workshop form.</li><li>More AIS grantmaking.&nbsp;</li><li>A public policy institution advocating straightforwardly for the case of existential risk from AI.</li></ol><h3><strong>Evaluation and Accountability</strong></h3><ol><li>More charity evaluators.</li><li>More measurement and evaluation/accountability of meta projects.</li><li>A public EA impact investing evaluator.</li></ol><h3><strong>Fundraising and Donor Engagement</strong></h3><ol><li>More work on donor cultivation and fundraising.</li><li>A new grantmaker with various beneficial attributes like speed, judgment ability, and infrastructure.</li><li>More community building for effective giving.&nbsp;</li></ol><h3><strong>Education and Training</strong></h3><ol><li>Systematic educational/training materials and community building in areas outside AIS.</li><li>Leadership fast-track program.</li></ol><h3><strong>Media and Outreach</strong></h3><ol><li>A podcast to keep people updated on EA-related developments.</li><li>A bunch of media platforms for sharing EA ideas (YouTube, podcast, Twitter, etc.).</li><li>An analog of Non-trivial but for university students.</li><li>Better on-ramps to the most impactful career paths.</li></ol><h3><strong>Diversity and Inclusion</strong></h3><ol><li>An organization that specializes in improving ethnic, racial, and socioeconomic diversity within EA.</li></ol><h3><strong>Other Initiatives</strong></h3><ol><li>A high-quality longtermist incubator.</li><li>EAG-like cause-specific conferences.</li><li>Fastgrants and other quick funding mechanisms.</li><li>A post-FTX investigative unit.</li><li>An awards program to create more appreciation within the community.</li><li>More badass GHD obvious wins like Wave.</li><li>An initiative that helps people prepare for crunch time and crises.</li><li>More applied cause-prioritization work outside of Open Philanthropy.&nbsp;</li><li>More critiques of views closely associated with Open Philanthropy funding.&nbsp;</li><li>Cause-specific community-building organizations, analogous to what CEA does for EA.</li></ol><h3>(Reversed) What is a project or norm that you don\u2019t want to see?</h3><ul><li><strong>Incubators</strong>: One respondent stated that incubators are \"super hard and over-done,\" mentioning that they are too meta and often started by people without entrepreneurial experience.</li><li><strong>Making Donor Participation Onerous</strong>: One respondent is concerned that setting high standards for donors could make it difficult for new donors to contribute to EA, possibly leading to the shrinkage of the community.</li><li><strong>Community Building and Early Funnel Bottlenecks</strong>: One respondent expressed the opinion that non-targeted community building&nbsp;<i>may&nbsp;</i>be overrated and that there may not be much of a bottleneck in the early stages of community funneling except for exceptional cases.</li><li><strong>Community Building Projects Split</strong>: One respondent is, on the margin, against community building projects that are specifically focused on either neartermism or longtermism instead of broader EA.</li></ul>", "user": {"username": "MJusten"}}, {"_id": "h7sua5jQmavsKG5XL", "title": "Paul Christiano on Dwarkesh Podcast", "postedAt": "2023-11-03T22:13:21.489Z", "htmlBody": "", "user": {"username": "ESRogs"}}, {"_id": "eygnoHEFnkzsZmu5u", "title": "Key EA decision-makers on the future of EA, reflections on the past year, and more (MCF 2023)", "postedAt": "2023-11-03T22:29:00.541Z", "htmlBody": "<p>This post summarizes the results of the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/33o5jbe3WjPriGyAR/announcing-the-meta-coordination-forum-2023\"><u>Meta Coordination Forum (MCF) 2023</u></a> pre-event survey. MCF was a gathering of key people working in meta-EA, intended to help them make better plans over the next two years to help set EA and related communities on a better trajectory. (More information&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/33o5jbe3WjPriGyAR/announcing-the-meta-coordination-forum-2023\"><u>here</u></a>.)</p><h2>About the survey&nbsp;&nbsp;</h2><p>Ahead of the event, we sent invitees a survey to understand the distribution of views on topics relevant to invitees\u2019 plans and the future of EA. These topics included:</p><ul><li>Resource allocation across causes, and across meta and direct work&nbsp;</li><li>Reflections on FTX and other lessons learned over the past year</li><li>Mistakes the EA community may be making&nbsp;</li><li>The relationship between EA &amp; AI safety (AIS)</li><li>Projects people would like to see (summarized in <a href=\"https://forum.effectivealtruism.org/posts/uXeY92ZoEE8gnftQE/meta-coordination-forum-2023-project-brainstorm\">this post</a>)</li></ul><p>The results from this pre-event survey are summarized below and in this post on field-building projects. We received 41 responses (n = 41) out of 45 people invited to take the survey. The majority of people invited to MCF in time to answer this survey are listed below:</p><figure class=\"table\"><table style=\"background-color:white;border-color:white;border-style:solid\"><tbody><tr><td style=\"padding:5pt;vertical-align:top\"><p>Alexander Berger</p><p>Amy Labenz</p><p>Anne Schulze</p><p>Arden Koehler</p><p>Bastian Stern</p><p>Ben West</p><p>Buddy Shah</p><p>Caleb Parikh&nbsp;</p><p>Chana Messinger</p><p>Claire Zabel</p></td><td style=\"padding:5pt;vertical-align:top\"><p>Dewi Erwan</p><p>James Snowden</p><p>Jan Kulveit</p><p>Jonas Vollmer</p><p>Julia Wise</p><p>Kuhan Jeyapragasan</p><p>Lewis Bollard</p><p>Lincoln Quirk</p><p>Max Dalton</p><p>Max Daniel</p></td><td style=\"padding:5pt;vertical-align:top\"><p>Michelle Hutchinson</p><p>Nick Beckstead</p><p>Nicole Ross</p><p>Niel Bowerman</p><p>Oliver Habryka</p><p>Peter McIntyre</p><p>Rob Gledhill</p><p>Sim Dhaliwal</p><p>Sjir Hoeijmakers</p><p>William MacAskill</p><p>Zach Robinson&nbsp;</p></td></tr></tbody></table></figure><p>&nbsp;</p><p>We\u2019re sharing the results from this survey (and <a href=\"https://forum.effectivealtruism.org/s/d32npjG3dv2oPXxbH\">others</a>) in the hope that being transparent about these respondents' views can improve the plans of others in the community. But there are important caveats, and we think it could be easy to misinterpret what this survey is and isn\u2019t.</p><h3>Caveats</h3><ul><li><strong>This survey does not represent \u2018the views of EA.\u2019</strong> The results of this survey are better interpreted as 'the average of what the people who RSVPd to MCF think' than a consensus of 'what EA or EA leaders think\u2019. You can read more about the event's invitation process <a href=\"https://forum.effectivealtruism.org/posts/33o5jbe3WjPriGyAR/announcing-the-meta-coordination-forum-2023\">here</a>.</li><li><strong>This group is not a collective decision-making body.</strong> All attendees make their own decisions about what they do. Attendees came in with lots of disagreements and left with lots of disagreements (but hopefully with better-informed and coordinated plans). This event was not aimed at creating some single centralized grand strategy. (See more about&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/DdSszj5NXk45MhQoq/decision-making-and-decentralisation-in-ea#Intro_and_Overview\"><u>centralization in EA</u></a>.)&nbsp;</li><li><strong>Most people filled in this survey in early August 2023</strong>, so people\u2019s views may have changed.</li><li><strong>People\u2019s answers mostly represent their own views</strong>, which may be different from the views of the orgs they work for.</li><li><strong>People filled in this survey relatively quickly</strong>. While the views expressed here are indicative of respondents\u2019 beliefs, they\u2019re probably not respondents' most well-considered views.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcn8xwde34nq\"><sup><a href=\"#fncn8xwde34nq\">[1]</a></sup></span></li><li><strong>We often used LLMs for the summaries&nbsp;</strong>to make this post more digestible and save time. We checked and edited most of the summaries for validity, but there are probably still some errors. The use of tailored prompts and models also caused the tone and structure to vary a bit.&nbsp;<ul><li>Note: the events team has been trying to be more transparent with information about our programs, but we have limited capacity to make things as concise or clear as we would like.&nbsp;</li></ul></li></ul><h1>Executive Summary</h1><p><i>This section summarizes multiple-choice questions only, not the open-text responses.</i></p><h3>Views on Resource Allocation (<a href=\"https://forum.effectivealtruism.org/posts/eygnoHEFnkzsZmu5u/meta-coordination-forum-2023-pre-event-survey-summary-of#Resource_Allocation\">see more</a>)</h3><p><strong>Direct vs. Meta work:</strong>&nbsp;</p><ul><li>On average, survey respondents reported that the majority of resources should be devoted to \u2018Direct Work\u2019<ul><li><strong>68.3%</strong>; SD = 13.5</li></ul></li><li>followed by \u2018Meta: community and field-building work\u2019&nbsp;<ul><li><strong>23.5%</strong>; SD = 12.3</li></ul></li><li>and then \u2018Meta: cause-prioritization work\u2019&nbsp;<ul><li><strong>8.3%</strong>; SD = 5.8</li></ul></li><li>But there was significant disagreement in percentages given and understandable confusion about whether e.g., AI risk advocacy is direct work or field-building work.</li></ul><p><strong>What goal should the EA community\u2019s work be in service of?&nbsp;</strong></p><ul><li>In aggregate, survey respondents thought that a slight majority of EA work should be in service of reducing existential risks&nbsp;<ul><li><strong>65.4%</strong>; SD = 28.5</li></ul></li><li>Within the existential risk category, \u201cwork in service of reducing existential risk posed by advanced AI systems\u201d received the most support, on average.<ul><li><strong>46.6%</strong>; SD = 17.6&nbsp;&nbsp;&nbsp;</li></ul></li><li>On average, respondents reported that the EA community\u2019s resources (broadly construed) should be in the service of:<ul><li>Humans in the near term&nbsp;<strong>13.8%</strong>,&nbsp;</li><li>Followed by non-human animals&nbsp;<strong>12.1%,&nbsp;</strong>and improving the long-term future via some other route than existential risk reduction&nbsp;<strong>8.8%.&nbsp;</strong>&nbsp;</li></ul></li></ul><h3><br>Behavioral Changes Post-FTX (<a href=\"https://forum.effectivealtruism.org/posts/eygnoHEFnkzsZmu5u/meta-coordination-forum-2023-pre-event-survey-summary-of#Reflections_on_Past_Year\">see more</a>)</h3><ul><li>On average, respondents reported similar scores for how much they had changed their work-related actions based on FTX reflections and how much they thought the average attendee of the event should change their actions (where 1 = No change and 7 = Very significant change):<ul><li>How they changed their actions: Mean of<strong> 4.2</strong>; SD = 1.7&nbsp;</li><li>How much they thought that the average attendee of this event should change their actions: mean of&nbsp;<strong>4.0</strong>; SD = 1.5</li></ul></li></ul><h3><br>Future of EA and Related Communities (<a href=\"https://forum.effectivealtruism.org/posts/eygnoHEFnkzsZmu5u/meta-coordination-forum-2023-pre-event-survey-summary-of#The_Future_of_EA\">see more</a>)</h3><p><strong>Rowing vs. Steering&nbsp;</strong></p><ul><li>Most respondents think now is more of a time for \u201csteering\u201d the trajectory of the EA community and brand rather than \u201crowing\u201d&nbsp;<ul><li>(Mean =&nbsp;<strong>4.5&nbsp;</strong>in favor of steering on a 1\u20137 scale; SD = 1.6)</li><li>Both extremes received some support.</li></ul></li></ul><p><strong>Cause X</strong></p><ul><li>On average, survey respondents reported a mean&nbsp;<strong>26%</strong> likelihood that a cause exists that ought to receive over&nbsp;<strong>20%</strong> of the EA community\u2019s resources but currently receives little attention. (Median = 10).<ul><li>But many respondents made fair critiques about how this question was missing clearer definitions.&nbsp;</li></ul></li></ul><p><strong>EA Trajectory Changes</strong></p><p><i>All questions in this section were asked as agree/disagree statements, where 1 = Strongly disagree; 7 = Strongly agree.</i></p><ul><li>There was a significant disagreement on nearly all statements about operationalised trajectory changes for EA.<ul><li>For example, there was no clear consensus on whether \u201cEA orgs and individuals should stop using/emphasizing the term \u2018community\u2019\u201d.&nbsp;<ul><li>Mean =&nbsp;<strong>4.0</strong>; SD = 1.5&nbsp;</li></ul></li></ul></li><li>But some statements showed at least some directional agreement (or disagreement).<ul><li>Respondents thought that EA actors should be more focused on engaging with established institutions and networks instead of engaging with others in EA<ul><li>Mean =&nbsp;<strong>4.9</strong>; SD = 1.2</li></ul></li><li>Respondents thought that there was a leadership vacuum that someone needed to fill&nbsp;<ul><li>Mean =<strong> 4.8</strong>; SD = 1.6</li></ul></li><li>Respondents thought that we&nbsp;<i>shouldn\u2019t</i> make all EA Global events cause-specific<ul><li>Mean =&nbsp;<strong>3.1;</strong> SD = 1.6.</li></ul></li></ul></li></ul><h3><br>Relationship Between EA &amp; AI Safety (<a href=\"https://forum.effectivealtruism.org/posts/eygnoHEFnkzsZmu5u/meta-coordination-forum-2023-pre-event-survey-summary-of#Relationship_Between_EA___AI_Safety_\">see more</a>)</h3><p><i>All questions in this section were asked as agree/disagree statements, where 1 = Strongly disagree; 7 = Strongly agree. We compare MCF invitees\u2019 responses to&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/vzuqnPyfDFjtbCpgv/ai-safety-field-building-survey-talent-needs-infrastructure\"><i><u>AI safety (AIS) experts\u2019 responses</u></i></a><i> </i><a href=\"https://forum.effectivealtruism.org/s/d32npjG3dv2oPXxbH/p/eygnoHEFnkzsZmu5u#Relationship_Between_EA___AI_Safety_\"><i>here</i></a><i>.&nbsp;</i></p><ul><li>Respondents expressed (at least relatively) strong consensus on some statements, although there were always people who disagreed with the consensus. On average:<ul><li>Respondents mostly agreed that \u201cmost AI safety outreach should be done without presenting EA ideas or assuming EA frameworks\u201d<ul><li>Mean =<strong> 5.4</strong>; SD = 1.2&nbsp;</li></ul></li><li>Respondents mostly agreed that \u201cMost EA outreach should include discussion of AI safety as a cause area\u201d<ul><li>Mean =&nbsp;<strong>5.6;</strong> SD = 1.2</li></ul></li><li>Respondents mostly agreed that \u201cAI safety work should, like global health and animal welfare, include many more people who are not into effective altruism\u201d<ul><li>Mean =<strong> 5.7</strong>; SD = 1.4</li></ul></li><li>Respondents mostly agreed that \u201cwe should have separate EA and AI safety student groups at the top 20 universities\u201d&nbsp;<ul><li>Mean =&nbsp;<strong>5.4</strong>; SD = 1.3</li></ul></li></ul></li><li>There was no clear consensus on some statements.<ul><li>There was no clear consensus on the statement that \u201cwe should try to make some EA principles (e.g., scope sensitivity) a core part of the AI safety field\u201d&nbsp;<ul><li>Mean =&nbsp;<strong>4.6</strong>; SD = 1.6</li></ul></li><li>There was no clear consensus on the statement that \u201cWe should promote AI safety ideas more than other EA ideas\u201d<ul><li>Mean =&nbsp;<strong>4.5</strong>; SD = 1.5</li></ul></li></ul></li></ul><h3>Deference to Open Phil (vs. CEA) (<a href=\"https://forum.effectivealtruism.org/posts/eygnoHEFnkzsZmu5u/meta-coordination-forum-2023-pre-event-survey-summary-of#Prioritization_Deference_to_OP_vs_CEA\">see more</a>)</h3><ul><li>Many attendees report that their organizations\u2019 priorities end up deferring to Open Philanthropy.&nbsp;<ul><li>When asked \u201cto what extent do you think your organization\u2019s prioritization ends up deferring to Open Philanthropy?\u201d, the mean response was&nbsp;<strong>4.4</strong> where 1 = No deference and 7 = Total deference (SD = 1.6).&nbsp;</li><li>When asked the same question about deference to CEA, the mean response was&nbsp;<strong>2.1</strong> (SD = 1.3).&nbsp;</li></ul></li></ul><h1>Results from Pre-Event Survey&nbsp;</h1><h2>Resource Allocation</h2><p><i><strong>Caveat for this whole section:&nbsp;</strong>The questions in this section were asked to get a quantitative overview of people's views coming into this event. You probably shouldn\u2019t put that much weight on the answers since we don't think that this group is expert at resource allocation/cause prioritization research, and there was understandable confusion about what work fit into what categories.</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsh5by9l65vl\"><sup><a href=\"#fnsh5by9l65vl\">[2]</a></sup></span></p><h3>Meta vs Direct Work: What rough percentage of resources should the EA community (broadly construed) devote to the following areas over the next five years?</h3><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/wvqn7v6algt6lnmkgvo7\"></p><p><i><strong>Group Summary Stats&nbsp;</strong></i></p><ul><li>Direct Work (n = 37): Mean<strong> 68%</strong>; SD = 14%</li><li>Meta: community and field-building work (n = 37): Mean&nbsp;<strong>23%</strong>; SD = 12%</li><li>Meta: cause-prioritization work (n = 37): Mean =&nbsp;<strong>8%</strong>; SD = 6%</li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/ngyych4qjxmumz9fmrgf\"></p><p><br><i><strong>Summarized commentary on Meta vs Direct Work&nbsp;</strong></i></p><ul><li><strong>Difficulty in categorizing certain activities as direct vs meta work</strong>: five respondents noted the difficulty in categorizing certain activities as direct vs meta work. For example, AI policy advocacy could be seen as direct AI safety work or meta community building.</li><li><strong>Importance of cause prioritization work:&nbsp;</strong>a few respondents emphasized the high value and importance of cause prioritization work, though possibly requiring fewer resources overall than direct or meta work.</li><li><strong>Indirect benefits of direct work:</strong> multiple respondents highlighted the indirect benefits of direct work for field building and growth. Doing object-level work can generate excitement, training opportunities, and data to improve the field.</li><li><strong>More resources to go towards community and field-building:&nbsp;</strong>a couple of respondents advocated for more resources to go towards community and field-building activities like CEA, 80,000 Hours, and student groups.</li><li><strong>Cap for resources devoted to meta:</strong> a few respondents suggested meta work should be capped at around&nbsp;<strong>25%</strong> of total resources to avoid seeming disproportionate.</li><li><strong>Difficulty in estimating due to definitions:&nbsp;</strong>several respondents noted it was difficult to estimate percentages without clearer definitions of categories and knowledge of current resource allocations.</li><li><strong>Difficulty in answering due to different views depending on the type of resource:&nbsp;</strong>a couple of respondents highlighted that funding proportions might differ from staffing proportions for meta vs. direct work.</li><li><strong>Interdependencies and theory of change</strong>: one respondent emphasized how much the theory of change for meta work relied on direct work.</li><li><strong>Difficulty answering before changes to the community:&nbsp;</strong>one respondent suggested the EA community itself should change substantially before recommending any resource allocation.</li></ul><h3>What/who should the EA community\u2019s work be in service of?</h3><p><strong>What rough percentage of resources should the EA community (broadly construed) devote to the following areas over the next five years?&nbsp;</strong>(n = 38)&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/pzhr91yqjry4mlb8vmj1\"></p><p><strong>Mean</strong> (after normalizing) for % of work that should be in service of\u2026</p><ul><li>\u2026 reducing existential risk posed by advanced AI systems:&nbsp;<strong>47%&nbsp;</strong>(SD = 18%)<strong>&nbsp;</strong></li><li>\u2026 humans in the near term (without directly targeting existential risk reduction, e.g., work on global poverty):&nbsp;<strong>14%&nbsp;</strong>(SD = 11%)</li><li>\u2026 non-human animals in the near term (without targeting existential risk reduction, e.g., work on farm animal welfare or near-term wild animal welfare):<strong> 12%&nbsp;</strong>(SD = 9%)</li><li>\u2026 reducing existential risk posed by pandemics and biotechnology:&nbsp;<strong>12%&nbsp;</strong>(SD = 6%)</li><li>\u2026 improving the long term future via some other route than existential risk reduction (e.g., cause-prioritization work or work on positive trajectory changes):&nbsp;<strong>9%&nbsp;</strong>(SD = 7%)</li><li>\u2026 reducing existential risk via some other route than AI or pandemics&nbsp;<strong>7%&nbsp;</strong>(SD = 5%)</li></ul><p>The three different routes focused on reducing existential risk sum up to<strong> ~65%</strong>.</p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/ifxd0nmlcydjw1v6xl8u\"></strong></p><p><br><i><strong>Summarized commentary on What/Who the EA Community\u2019s Resources Should Be in Service Of&nbsp;</strong></i></p><ul><li><strong>Commentary on AI safety/alignment&nbsp;</strong>(mentioned by 4 respondents)<strong>:&nbsp;</strong><ul><li>Some respondents said AI safety/alignment should receive a large percentage of resources&nbsp;</li><li>A few respondents noted that AI safety/alignment should probably be separated from EA into its own movement or cause area.</li></ul></li><li><strong>Other efforts to improve the long-term future&nbsp;</strong>(mentioned by 3 respondents)<strong>:</strong>&nbsp;<ul><li>A few respondents emphasized that there should be more work on improving the long-term future beyond just reducing existential risk.&nbsp;</li><li>For example:<ul><li>\"Condition on AI alignment being solved: What are the things we need to do to make the LTF go well?\"</li></ul></li></ul></li><li><strong>Meta&nbsp;</strong>(mentioned by 2 respondents)<strong>:</strong><ul><li>&nbsp;Some respondents emphasized the importance of meta work like cause prioritization.</li></ul></li><li><strong>Engagement with external experts&nbsp;</strong>(mentioned by 2 respondents):<strong>&nbsp;</strong><ul><li>Some respondents wanted to see more engagement with non-EA actors, especially for evolving causes like AI safety or research-intensive fields like biosecurity.&nbsp;</li><li>For example:<ul><li>\u201cFields like pandemic preparedness connecting more with established institutions could spark more valuable work that wouldn\u2019t have to flow from scarce EA resources or infrastructure.\u201d&nbsp;</li></ul></li></ul></li><li><strong>Differentiating resource type&nbsp;</strong>(mentioned by 2 respondents):<strong>&nbsp;</strong><ul><li>Some respondents pointed out that resource allocations for funding vs labor should be different.&nbsp;</li><li>For example:<ul><li>\"I think the splits for \u2018funding\u2019 and \u20181000 most highly engaged EAs\u2019 should look very different.\"</li></ul></li></ul></li></ul><h2>Reflections on Past Year</h2><h3>Changes in work-related actions post-FTX</h3><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/ktijmeltqvgi3mhsan6c\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/tqrypdh2rwtmhpqhnubd 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/xvjj67vzmudh3lrkyws7 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/ou3tssijrxvq8l0fwnaw 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/ivnabs2osdpjn9iqum3e 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/a50rhhuvi2uwhnz16bpv 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/ab1yqcurtavieq8qbgw1 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/qezwcqefov2up6stnjqx 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/tbhzxsq4bijqv8kbyhqw 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/jtpx50l0lgukatkip6kp 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/hefmethrzhewohlri0ze 966w\"></strong></p><h3>EA and related communities are likely to face future \u201ccrunch times\u201d and \u201ccrises\u201d. In order to be prepared for these, what lessons do we need to learn from the last year?</h3><ul><li><strong>Improve governance and organizational structures</strong> (mentioned by 7 respondents):<ul><li>Shore up governance, diversify funding sources, build more robust whistleblower systems, and have more decentralized systems in order to be less reliant on key organizations/people.</li></ul></li><li><strong>Build crisis response capabilities</strong> (mentioned by 6 respondents):<ul><li>Create crisis response teams, do crisis scenario planning, have playbooks for crisis communication, and empower leaders to coordinate crisis response.</li></ul></li><li><strong>Improve vetting and oversight of leaders</strong> (mentioned by 5 respondents):<ul><li>Better vet risks from funders/leaders, have lower tolerance for bad behavior, and remove people responsible for the crisis from leadership roles.</li></ul></li><li><strong>Diversify and bolster communication capacities</strong> (mentioned by 5 respondents):<ul><li>Invest more in communications for crises, improve early warning/information sharing, and platform diverse voices as EA representatives.</li></ul></li><li><strong>Increase skepticism and diligence about potential harms</strong> (mentioned by 4 respondents):<ul><li>Adopt lower default trust, consult experts sooner, and avoid groupthink and overconfidence in leaders.</li></ul></li><li><strong>Learn about human factors in crises</strong> (mentioned by 3 respondents):<ul><li>Recognize the effect of stress on behavior, and be aware of problems with unilateral action and the tendency not to solve collective action problems.</li></ul></li><li><strong>Adopt more resilient mindsets and principles</strong> (mentioned by 3 respondents):<ul><li>Value integrity and humility, promote diverse virtues rather than specific people, and update strongly against naive consequentialism.</li></ul></li></ul><h2>The Future of EA</h2><h3>Summary of visions for EA</h3><ul><li>A group that embraces division of labor across 1) research focused on how to do the most good, 2) trying interventions, and 3) learning and growing. Open to debate and changing minds, as well as acting amidst uncertainty. Focused on getting things done rather than who gets credit. Committed to truth, virtue, and caring about consequences.</li><li>A community that proves competent at creating real-world impact and influence in policy, industry, and philanthropy. Talented people use EA ideas to inform impactful career choices.</li><li>Returning to EA's roots as a multi-cause movement focused on doing the most good via evidence and reason. A set of ideas/a brand many institutions are proud to adopt in assessing and increasing the efficacy of their altruism.</li><li>A community exemplifying extreme (but positive) cultural norms\u2014collaborative, humble, focused on tractable issues ignored by others. The community should be guided by principles like impartial altruism and epistemic virtue. People identify with principles and values rather than backgrounds, cultural preferences, or views on morality.</li><li>A community that can provide funding, talent, coordination on cause prioritization, and epistemic rigor to other cause areas. But not expecting allegiance to the EA brand from those working in areas.</li><li>A set of intellectual ideas for doing good. People are guided to doing good through EA ideas, but don't necessarily continually engage once on that path.</li><li>A thriving, diverse community guided by principles like trust and respect. Including research, scaling ideas/organizations, and policy engagement. Appreciation for the different skills needed.</li><li>Split into AI-focused and EA-focused communities. The latter potentially smaller in resources but focused on EA's unique value-add.</li><li>Focused primarily on knowledge dissemination i.e.,publications and seminars. Status from contributing to understanding. Engages with policy in the same way a subject-matter expert might\u2014there to inform.&nbsp;</li><li>Promotes compassion, science, scope sensitivity, responsibility. Local groups take various actions aligned with principles. Associated with cause-specific groups.</li><li>Either widespread, welcoming movement or weirder intellectual exploration of unconventional ideas. Can't be both, and currently in a weird middle ground.&nbsp;</li><li>High-trust professional network brought together by a desire for impact.</li></ul><h3>Rowing vs steering EA</h3><p><strong>To what degree do you think we should be trying to accelerate the EA community and brand\u2019s current trajectory (i.e., \u201crowing\u201d) versus trying to course-correct the current trajectory (i.e., \u201csteering\u201d)?&nbsp;</strong>(n = 39; Mean =&nbsp;<strong>4.51</strong>; SD = 1.63 )&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/vhdlphddrayhfsdmegx8\"><br><i><strong>Commentary on Rowing vs Steering&nbsp;</strong></i></p><ul><li><strong>Steer to split/differentiate the EA brand from AI safety/longtermist causes</strong> (raised by 3 respondents):<ul><li>Some respondents suggested creating separate branding/groups for AI safety and longtermism instead of having them be under the broad EA umbrella.</li></ul></li><li><strong>Steer to improve epistemics/avoiding drift from core EA principles&nbsp;</strong>(raised by 5 respondents):&nbsp;<ul><li>Multiple respondents emphasized the importance of steering EA back towards its original principles and improving community epistemics, rather than just pursuing growth.</li></ul></li><li><strong>Both rowing and steering are important/should be balanced&nbsp;</strong>(raised by 4 respondents):<ul><li>Several respondents said both growing the community (rowing) and realigning it (steering) are useful, and we shouldn't focus solely on one. Some said we should alternate between them based on circumstances.</li></ul></li><li><strong>Rowing could be focused on fundraising/Earning to Give</strong> (raised by 2 respondents):<ul><li>A couple of respondents suggested rowing/growth could be specifically focused on expanding Earning to Give rather than expanding the EA brand overall.</li></ul></li><li><strong>We should steer towards more formal institutions and addressing harms</strong> (raised by 2 respondents):<ul><li>Some emphasized the importance of steering efforts focused on formalizing organizational structures and addressing potential downsides/harms from community growth.</li></ul></li><li><strong>Rowing requires having clarity about EA's future direction</strong> (raised by 2 respondents):<ul><li>A couple of respondents said significant further rowing/growth doesn't make sense until there is clearer steering and alignment around EA's future trajectory and principles.</li></ul></li></ul><h3>Cause X</h3><p><strong>What do you estimate is the probability (in %) that there exists a cause which ought to receive over 20% of the EA community's resources but currently receives little attention?&nbsp;</strong>(n = 31; Mean =&nbsp;<strong>26%</strong>; Median = 10%; SD = 29%)</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/bqmvcixszvuqf6rpkfmr\"></p><p><br><i><strong>Summary of commentary on Cause X</strong></i></p><p><strong>Problems with the question</strong></p><ul><li>This question received a lot of fair criticism, and three people chose not to answer it because of definitional issues. Issues people pointed out include:<ul><li>It\u2019s unclear what time frame this question is referring to.</li><li>It depends a lot on what level \u201ccause\u201d is defined as.</li><li>\u201cLittle attention\u201d was poorly operationalized.&nbsp;</li></ul></li></ul><p><strong>Nuance around Cause X</strong></p><ul><li><strong>Marginal Analysis:&nbsp;</strong>some respondents pointed out that while there might be high-leverage individual opportunities, it may not be under the umbrella of a single, neglected 'cause'.</li><li><strong>Potential for Future Discovery:&nbsp;</strong>some respondents thought the likelihood of discovering a neglected cause would be higher in the future, particularly in a world transformed by advancements in AI.</li><li><strong>Low Success Rate so far:</strong> some respondents expressed the sentiment that the EA community has already been quite rigorous in evaluating potential causes, making it unlikely that a completely overlooked, yet crucial, cause exists.</li></ul><p><strong>Cause X Candidates proposed include:</strong></p><ul><li>Digital sentience (x3)</li><li>Invertebrate welfare</li><li>Wild animal welfare</li><li>Whole Brain Emulation (x2)</li><li>Post-AGI governance stuff (and other stuff not captured in existing AI technical and governance work) (x2)&nbsp;&nbsp;</li><li>War and international relations work&nbsp;</li><li>Pro economic growth reforms&nbsp;</li></ul><h3>Agreement voting for EA trajectory changes</h3><p><strong>EA orgs and individuals should stop using/emphasizing the term \u201ccommunity.\u201d&nbsp; </strong>(n = 41, Mean = <strong>3.98</strong>, SD = 1.49)<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/u9fcurcljbdt4qeimll3\"></p><p><strong>Assuming there\u2019ll continue to be three EAG-like conferences each year, these should all be replaced by conferences framed around specific cause areas/subtopics rather than about EA in general (e.g. by having two conferences on x-risk or AI-risk and a third one on GHW/FAW)&nbsp;</strong>(n = 40, Mean =&nbsp;<strong>3.13</strong>, SD = 1.62)</p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/m0lqukmepbdn9s0mmu5b\"></strong><br><br><strong>Effective giving ideas and norms should be promoted independently of effective altruism.&nbsp;</strong>(n = 40, Mean =<strong> 4.65</strong>, SD = 1.46)<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/qrcnc1oxxqc56craoycg\"><br>&nbsp;</p><p><strong>People in EA should be more focused on engaging with established institutions and networks instead of engaging with others in EA.&nbsp;</strong>(n = 40, Mean =&nbsp;<strong>4.93</strong>, SD = 1.25)<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/hdg7ukojlfxrcfn6c8om\"></p><p><strong>There is a leadership vacuum in the EA community that someone needs to fill.&nbsp;</strong>(n = 39, Mean =&nbsp;<strong>4.85</strong>, SD = 1.63)<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/l9kap7p6fj39ckaasbzw\"></p><p><i>Summary of comments about leadership vacuum question:&nbsp;</i></p><ul><li>Respondents' comments suggested that answers to this question should be interpreted with caution since the question conflated two questions and had definitional issues.<ul><li>Some people agreed that there was a leadership vacuum and that it would be great if more people stepped into community leadership roles, but there was skepticism that the right people for this currently existed.&nbsp;</li><li>At least one other respondent reported that they think there\u2019s a leadership vacuum, but that this shouldn\u2019t be filled and leaders should be more explicit about how decentralized EA is.&nbsp;</li><li>One respondent pointed out that leadership could mean many things, and that it wasn\u2019t clear what people were voting on here.&nbsp;</li></ul></li></ul><p><br><strong>We should focus more on building particular fields (AI safety, effective global health, etc.) than building EA.&nbsp;</strong>(n = 39, Mean =&nbsp;<strong>4.72</strong>, SD = 1.38)<br><br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/phqwf5xce8jcfkj75wmn\"></p><h3><br><strong>Summary of comments about agreement voting questions&nbsp;</strong></h3><ul><li><strong>Who is \u201cwe\u201d?</strong> Multiple respondents pointed out that their answers to the above question are sensitive to how \u2018we\u2019 is defined.&nbsp;</li><li><strong>Marginal thinking:</strong> Multiple respondents clarified that their answers are better interpreted as what they think \u201con the current margin\u201d.&nbsp;</li><li><strong>False dichotomies:</strong> Multiple respondents thought that a lot of these questions set up false dichotomies.&nbsp;</li></ul><h3>What are some mistakes you're worried the EA community might be making?</h3><p><i>Note that respondents often disagreed with each other on this question: some thought we should do more X, and others thought we should do less X.&nbsp;</i></p><p><strong>Crisis response:</strong></p><ul><li>Not learning enough from FTX, both in terms of the specific incident and naive consequentialism more broadly (x3)</li><li>Pivoting too much or over-updating in response to setbacks such as FTX (x3)</li><li>Becoming too risk averse (x2)</li></ul><p><strong>Leadership:</strong></p><ul><li>Not doing enough to counteract low morale and burnout in leadership (x2)&nbsp;</li><li>Allowing a leadership vacuum to stay for too long and not communicating clearly about what EA is, who leads it, how decisions are made (x2)&nbsp;</li><li>Not thinking enough about the new frontier of causes people may not take seriously by default, like digital sentience and post-AGI society&nbsp; (x2)&nbsp;</li></ul><p><strong>Culture:</strong></p><ul><li>Under-emphasizing core values and virtues in EA culture like humility, integrity, kindness and altruism (x4)&nbsp;</li><li>Being too PR-y and bureaucratic instead of authentic</li><li>Not instilling a sense of excitement about the EA project&nbsp;</li><li>Caring too much about inside-the-community-reactions and drama instead of keeping gaze outward on the world / building for the sake of the world (x3)&nbsp;</li><li>Caring too much about \"EA alignment\" and under-valuing professional expertise&nbsp;</li><li>Becoming vulnerable to groupthink from too many close networks&nbsp;</li><li>Not emphasizing thinking independently enough, and making it seem like EA can just tell people what to do to have an impact</li></ul><p><strong>Resource allocation:</strong></p><ul><li>Not investing enough in building serious, ambitious projects&nbsp;</li><li>Growing at the wrong pace: either growing too much (mentioned once) or not growing enough (mentioned once)&nbsp;</li></ul><p><strong>AI:</strong></p><ul><li>Not updating enough about AI progress&nbsp;</li><li>EA resources swinging too hard towards AI safety (x3)&nbsp;</li><li>Being too trusting of AGI labs</li><li>Not realizing how much some Transformative AI scenarios require engagement with various non-EA actors, and becoming irrelevant in such scenarios as a result</li><li>Trying to shape policies without transparency</li><li>Not investing money into an AI compute portfolio</li><li>Not being nuanced enough in transmitting EA standards or culture to a new field with its own culture and processes</li></ul><p><strong>Other:</strong></p><ul><li>Too little coordination among key orgs and leaders</li><li>Not investing enough in funder diversity / relying too much on OP (x3)</li><li>Too much concern for what community members think, resulting in less outreach and less useful disagreement.</li><li>Poor strategic comms leading EA-related actors and ideas to be associated with narrow interests or weird ideologies (x2)</li></ul><h2>Relationship Between EA &amp; AI Safety&nbsp;</h2><h3>Rating agreement to statements on the relationship between EA &amp; AIS</h3><p><i>Below we compare MCF invitees' responses to AI safety experts asked the same questions in the&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/vzuqnPyfDFjtbCpgv/ai-safety-field-building-survey-talent-needs-infrastructure\"><i><u>AI safety field-building survey.</u></i></a><i>&nbsp;</i></p><p>&nbsp;<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/dsmnwqvth3oqk8kboiye\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/t1u0uc5olf9txrc4saz2 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/urd9ujfbv7zdnhm7ozz5 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/qsc6fkkd6xdbexq55x1z 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/gxvr6gfhhyk7uwdvdlev 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/arwwgvkkn7s2kae89bbq 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/gbr4zhgdihv3r3yach4l 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/t0vap8ft4kvlkmxxi0tw 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/eoffua5gr44eh3olknry 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/qhbz0hjmpwopahri68wr 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/qcfkgxjukmxf5h1uyxqp 900w\"></p><h3>Summary of Commentary on EA's Relationship with AI Safety&nbsp;</h3><ul><li><strong>Who is \u2018we\u2019?:&nbsp;</strong>As with other agreement voting in this survey, some respondents said their answers were sensitive to who exactly \u201cwe\u201d is.&nbsp;</li><li><strong>Concern about CEA supporting AIS work:&nbsp;</strong>Two respondents mentioned concerns about CEA being involved in AI safety work.</li><li><strong>Importance of new CEA Executive Director:</strong> At least one respondent mentioned that a lot of these decisions may come down to the new CEA ED.&nbsp;</li><li><strong>Clearer separation:&nbsp;</strong>Multiple respondents clarified their view on why they think EA and AIS should be more distinct.&nbsp;<ul><li>For example:<ul><li>Conflation of EA and AIS can be harmful to both fields,&nbsp;</li><li>Concerns that EAs views on AI safety seem too narrow and don\u2019t include a lot of obviously good things, and&nbsp;</li><li>AIS should not require EA assumptions.&nbsp;</li></ul></li><li>Regardless of what the split ends up being, others pushed for people and projects to communicate more clearly if they see themselves promoting EA principles or AI safety work.&nbsp;&nbsp;</li></ul></li><li><strong>Benefit from connecting EA to AIS:&nbsp;</strong>Two respondents mentioned ways EA could hopefully benefit AIS, including bringing important values, virtues, and norms to the field, like rigorous prioritization.&nbsp;</li><li><strong>Talent bottlenecks in AIS:&nbsp;</strong>One respondent expressed concerns with non-targeted outreach for AIS (and to a lesser extent EA), since AIS may not have enough open opportunities at the moment to absorb many people.&nbsp;</li><li><strong>Avoiding rebrands:&nbsp;</strong>One respondent emphasized the importance of EA owning its history, including e.g., the FTX scandal, and didn't want people to pivot to AIS for bad reasons.&nbsp;</li></ul><h3>Relationship between meta work and AI timelines</h3><p><strong>How much does the case for doing EA community-building hinge on having significant probability on \u201clong\u201d (&gt;2040) timelines?&nbsp;</strong>(n = 29, Mean = 3.24, SD = 1.33)<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/xifqkin0pg1dfw9muci7\"></p><p><i><strong>Commentary on relationship between meta work and AI timelines</strong></i></p><ul><li><strong>Depends on the community building (CB) work: </strong>Multiple respondents mentioned how the answer to this question depends on the type of CB work. For example, recruiting highly credible and experienced people to work in AI safety, or guiding more donors to give to AI safety, would probably be important levers to reducing risk even with 10-year timelines.</li><li><strong>Crunch time infrastructure:&nbsp;</strong>One respondent mentioned that community building work to improve coordination infrastructure could help a lot in short timeline worlds, since such infrastructure would be critical for people to communicate and collaborate in \u201ccrunch times.\u201d&nbsp;</li></ul><h3>There has been a significant increase in the number of people interested in AI safety (AIS) over the past year. What projects and updates to existing field-building programs do you think are most needed in light of that?</h3><ol><li>Programs to channel interest into highly impactful roles, with a focus on mid-career community-building projects.</li><li>More work on unconventional or 'weirder' elements in AI governance and safety, such as s-risk and the long-reflection.</li><li>Reevaluation of how much the focus on AI depends on it being a neglected field.</li><li>More educational programs and introductory materials to help people get up to speed on AI safety.</li><li>Enhancements to the AI Alignment infrastructure, including better peer-review systems, prizes, and feedback mechanisms.</li><li>Regular updates about the AIS developments and opportunities</li><li>More AI-safety-specific events&nbsp;</li></ol><h2>Prioritization Deference to OP vs CEA</h2><p><i>Note that this question was asked in an anonymous survey that accompanied the primary pre-event survey summarized above. We received 23 responses (n = 23) out of 45 people invited to take the anonymous survey.</i></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/vzxlx62otfmpa1hwsr70\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/fo6uuvh2htmbds8or6ce 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/v5a91vp3n53kx0yijtbd 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/wmcqhduyxlulbfk4fnmp 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/ovdnkx6p6i5z5hwhsp6b 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/smpnw2x4in1tvujulcqs 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/sok48bgfczmuc12l67qp 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/ydudrnpe1ye6wawomyvz 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/sowvtkgtzswabc61tak1 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/wxxt370qhhs7yk3q69vj 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eygnoHEFnkzsZmu5u/u3cfb9n2qn0zraxw06ub 906w\"></figure><hr><p>We hope you found this post helpful! If you'd like to give us anonymous feedback you can do so with Amy (who runs the CEA Events team)&nbsp;<a href=\"https://www.admonymous.co/amy\"><u>here</u></a>.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncn8xwde34nq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcn8xwde34nq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We said this survey would take about 30 minutes to complete, but in hindsight, we think that was a significant underestimate. Some respondents reported feeling rushed because of our incorrect time estimate.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsh5by9l65vl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsh5by9l65vl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This caveat was included for event attendees when we originally shared the survey report.</p></div></li></ol>", "user": {"username": "MJusten"}}, {"_id": "NAcN98bACuwcnB32H", "title": "The Navigation Fund launched + is hiring a program officer to lead the distribution of $20M annually for AI safety! Full-time, fully remote, pay starts at $200k", "postedAt": "2023-11-03T21:53:51.976Z", "htmlBody": "<p>New foundation, funded by billionaire <a href=\"https://www.forbes.com/profile/jed-mccaleb/?sh=7adb975476bf\">Jed McCaleb, </a>led by <a href=\"https://www.linkedin.com/in/davidcomanhidy\">David Coman-Hidy</a>, <a href=\"https://www.navigation.org/team/andrea-gunn\">Andrea Gunn</a>, <a href=\"https://www.linkedin.com/in/seemay-chou-4b30a812\">Seemay Chou</a>, <a href=\"https://psychology.ucdavis.edu/people/oreilly\">Randy O\u2019Reilly</a><br>&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NAcN98bACuwcnB32H/avh3utvrybc1ev3h9gqd\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NAcN98bACuwcnB32H/buarripc2kmjoyrpeche 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NAcN98bACuwcnB32H/lzgi7kk9h1uk1vsfivoq 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NAcN98bACuwcnB32H/opmv1yqihmegzciqezts 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NAcN98bACuwcnB32H/daklzvwaepszixdhbbjd 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NAcN98bACuwcnB32H/kv4jshng28m2hwlvgwjt 1300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NAcN98bACuwcnB32H/uto5cbkupnabnrazmhhq 1560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NAcN98bACuwcnB32H/vsnciodle5c73g0eqxth 1820w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NAcN98bACuwcnB32H/y8cxrr8tofzkjzkclagl 2080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NAcN98bACuwcnB32H/ljukmkhh4cdbjox0okyb 2340w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NAcN98bACuwcnB32H/gx2byzjsqgrtqw3xnq5o 2586w\"></figure><p><strong>Quotes from their website </strong><a href=\"https://www.navigation.org/\"><strong>https://www.navigation.org/</strong></a><strong>: \"</strong></p><h1><strong>Causes</strong></h1><p><strong>The Navigation Fund focuses on a few key areas where additional resources will provide outsized impact.</strong></p><p><strong>Safe AI</strong></p><p>As the use cases of artificial intelligence expand, developing frameworks and systems to ensure that AI benefits humankind becomes crucial. We will explore opportunities to promote altruistic and beneficial outcomes from AI.</p><p><strong>Farm Animal Welfare</strong></p><p>Factory farming creates both tremendous suffering and significant environmental degradation. We support efforts to reduce animal suffering, reenvision our relationship with animals, and diminish the killing of animals.</p><p><strong>Criminal Justice Reform</strong></p><p>Reforming the U.S. criminal justice system can help create a more just, equitable, and safe society. We use a portfolio approach to bolster a wide range of initiatives to address the challenges and improve outcomes for people, families, and communities.</p><p><strong>Open Science</strong></p><p>The Open Science movement is crucial for expediting discoveries and guaranteeing public access to knowledge. We stand with those forging new tools, championing novel approaches, and altering traditional practices within scientific research and publishing to make information more accessible to everyone.</p><p><strong>Climate Change</strong></p><p>Climate change poses a significant threat to humanity, and requires new and bold thinking to help address it. We invest in high-leverage, under-resourced initiatives that have the potential for immediate and long-term favorable impact on climate outcomes.</p><h2><br>Open roles <a href=\"https://www.navigation.org/careers#roles\">https://www.navigation.org/careers#roles</a>)&nbsp;</h2><h3><a href=\"https://boards.greenhouse.io/navigationfund/jobs/4124758007\"><strong>Director of Operations</strong></a></h3><h3><a href=\"https://boards.greenhouse.io/navigationfund/jobs/4126291007\"><strong>Grants and Operations Coordinator</strong></a></h3><p>\u200d</p><h3><a href=\"https://boards.greenhouse.io/navigationfund/jobs/4127994007\"><strong>Program Officer, Climate</strong></a></h3><h3><a href=\"https://boards.greenhouse.io/navigationfund/jobs/4127996007\"><strong>Program Officer, Criminal Justice Reform</strong></a></h3><h3><a href=\"https://boards.greenhouse.io/navigationfund/jobs/4127979007\"><strong>Program Officer, Open Science</strong></a></h3><h3><a href=\"https://boards.greenhouse.io/navigationfund/jobs/4128561007\"><strong>Program Officer, Safe AI</strong></a></h3><p><strong>\"</strong></p><p>\u200d</p>", "user": {"username": "vincentweisser"}}, {"_id": "P9bPprknW9pApdKvg", "title": "Why is learning economics, psychology, sociology important for preventing AI risks?", "postedAt": "2023-11-03T21:48:39.583Z", "htmlBody": "<p>As the title goes, I'd like to know if spending some time learning basic economics/psychology/social science is worthwhile if I aim to work in AI-related field (not limited to x-risks, such as: AI weapons risks, AI controlling human values/decisions...\uff09\nSorry for my ignorance of AI risks, I can't think of many examples myself, maybe:\n1.The idea of AI alignment and training itself is related to psychology\n<a href=\"http://2.AI\">2.AI</a> governance itself would (maybe) influence the economics or welfare to the society( I'm not sure because I don't actually know how AI regulation/governance works)\nCan someone give me some concrete examples to explain why social science is important for AI risks?</p>\n", "user": {"username": "jackchang110"}}, {"_id": "Kk7yggmxjrA9CZqPe", "title": "Securing Civilization Against Catastrophic Pandemics", "postedAt": "2023-11-03T19:33:05.662Z", "htmlBody": "", "user": {"username": "Jeff_Kaufman"}}, {"_id": "ABSPxRjsuLwr7AwvT", "title": "I'm interviewing author of 'Good Reasons for Bad Feelings', Randy Nesse. What should I ask him?", "postedAt": "2023-11-03T18:37:19.073Z", "htmlBody": "<p>Continuing the 80,000 Hours Podcast's <a href=\"https://80000hours.org/topic/career-advice-strategy/mental-health/?content-type=podcast\">coverage</a> of mental health issues, I'm interviewing <a href=\"https://twitter.com/RandyNesse/\">Randy Nesse</a> who wrote a popular book on evolutionary psychology <a href=\"https://www.amazon.co.uk/Good-Reasons-Bad-Feelings-Evolutionary/dp/0241291089\">'Good Reasons for Bad Feelings: Insights from the Frontier of Evolutionary Psychiatry'</a>.</p>\n<p>The book tries to use evolution to explain how our brains can be so vulnerable to serious mental health problems \u2014 from anxiety to depression to mania to schizophrenia \u2014 and I know has been read by many readers of this forum.</p>\n<p>You can find more of his work on <a href=\"https://www.randolphnesse.com/\">his website</a> and he recently gave a talk on <a href=\"https://www.youtube.com/watch?feature=shared&amp;t=666&amp;v=OrA-RD3CdXw\">'The Future of Evolutionary Medicine'</a> which is a general passion of his.</p>\n<p>What should I ask him?</p>\n", "user": {"username": "Robert_Wiblin"}}, {"_id": "etcL6qZ6hRJdDxtcs", "title": "German EA Intro Program Report - Summer 2023 (and before)", "postedAt": "2023-11-03T17:50:58.606Z", "htmlBody": "<h1>For whom might this post be useful?</h1><ul><li>Other national or local groups can get inspiration on how to run an EA Intro Program.</li><li>People who want to know more about what is happening regarding Community Building in Germany.</li></ul><h1>Summary</h1><ul><li><strong>Description: What is the history and the size of the Intro Program?</strong><ul><li>The EA Intro Program (formerly Intro Fellowship) has been around since Winter 2020, taking place once per semester. It wants to introduce people<strong>&nbsp;</strong>to the key ideas of Effective Altruism and&nbsp;<strong>connect&nbsp;</strong>people with the EA Community (in Germany).</li><li>The Intro Program started as an independent project and is now facilitated in cooperation with local groups and EA Germany. Active participant numbers over the years: 20, 25, 10, 70, 75, 85. In the latest iterations, there were about 100 applicants each.</li></ul></li><li><strong>Inspiration: What is unique about the German Intro Program compared to others?</strong><ul><li>Coordinated advertisement in Germany</li><li>Structure: 4 weeks (advertised), 6 weeks (default), 8 weeks (opt-in)</li><li>Combining online with in-person</li><li>Structured 1on1s with moderators</li><li>LinkedIn certificates, book scholarship</li><li>Journal as content<ul><li>Less reading than&nbsp;<a href=\"https://forum.effectivealtruism.org/handbook\"><u>EA Handbook</u></a></li><li>Questions to answer</li></ul></li><li>EAD Retreat afterward</li></ul></li><li><strong>Call to action: How can I copy and adapt the materials of the Intro Program?</strong><ul><li>Official website of the German EA Intro Program:&nbsp;<a href=\"https://www.effektiveraltruismus.de/intro-program\"><u>https://www.effektiveraltruismus.de/intro-program</u></a>&nbsp;</li><li>More info:&nbsp;<a href=\"https://bit.ly/ea-intro-program-de\"><u>https://bit.ly/ea-intro-program-de</u></a>&nbsp;</li><li><a href=\"https://docs.google.com/document/d/1PqieePsgSgKYx3CpEVKmv4JTpQxezehpeIuXzQ1pEZg/edit#heading=h.mmpk2k2e7jwe\"><u>All templates</u></a><ul><li>Outreach material</li><li>Journal (content of the intro program)</li><li>Discussion document</li><li>Forms</li><li>Info sheet (internal coordination)</li><li>Names and Faces Template</li><li>How to: Organize Intro Program</li></ul></li></ul></li></ul><h1>Number of participants and moderators</h1><ul><li>Participants<ul><li>Total: 107</li><li>Dropouts in first weeks: 47</li><li>Finished 8 weeks: 8&nbsp;</li><li>Finished 6 weeks: 25&nbsp;<ul><li>(+ 8 = 33)</li></ul></li><li>Finished 4 weeks: 27&nbsp;<ul><li>(+ 25 + 8 = 60)</li></ul></li><li>Attended at least one meetup: 25&nbsp;<ul><li>(+25 +8 +27 = 85)</li></ul></li></ul></li><li>Moderators<ul><li>17 moderators facilitating</li><li>8 online groups</li><li>9 in-person groups</li></ul></li></ul><h1>Feedback</h1><ul><li>We took feedback&nbsp;<strong>after each discussion</strong> to evaluate and improve the moderator's facilitation in discussion sessions.&nbsp;</li><li>In addition to that, we took<strong> feedback at the end</strong>, to get an overall picture of the effect of the&nbsp;<strong>Intro Program</strong> on the participants and moderators.</li></ul><h2>Summary&nbsp;</h2><ul><li><strong>Impact</strong><ul><li>We received<strong> pretty good overall ratings</strong> from both participants and moderators (&gt;8/10 ratings on average), with people rating it on average&nbsp;<strong>twice as valuable</strong> compared to what they would have done otherwise.</li><li>Career<ul><li>92.5% of respondents reported plans of doing career related activities</li><li>The most mentioned activities are making a&nbsp;<strong>1on1 in the Intro Program</strong>, making a&nbsp;<strong>copy of the 80 k&nbsp;</strong>career planning template and applying to a&nbsp;<strong>mentoring by EA Germany</strong></li><li>Career dedication to doing good: Avg: 4.12/5, but in the application it was even higher, 4.18</li></ul></li><li>Other<ul><li>What has the Intro Program impacted the most?<ul><li>Career Avg: 7.27, EA Community/Engagement Avg: 7.22, Donations Avg: 6.90</li></ul></li></ul></li></ul></li><li><strong>Organization</strong><ul><li>We got the feedback that it\u2019s&nbsp;<strong>decently&nbsp;</strong>organized. Many participants would&nbsp;<strong>recommend&nbsp;</strong>it (Avg: 8.78/10). We still want to improve the&nbsp;<strong>grouping&nbsp;</strong>and&nbsp;<strong>communication&nbsp;</strong>of the intro program besides other things.</li></ul></li><li><strong>Interpretation</strong><ul><li>There are maybe&nbsp;<strong>more impactful community building projects</strong>, e.g. targeted outreach, more advanced programs or cause area-specific projects.&nbsp;</li><li>Still, the data combined with general reasoning, that it\u2019s good to have such a<strong> low-key general offer as the Intro Program&nbsp;</strong>to learn more about EA.</li></ul></li></ul><h2>1. Participants</h2><p><strong>40 respondents</strong> took the final feedback form.&nbsp;</p><h3>General</h3><ul><li>How would you rate the Intro Program overall? (1-10)<ul><li>Avg: 8.32</li><li>Median:&nbsp;<strong>8</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/midec7tfresgzcpfbhoh\" alt=\"Forms response chart. Question title: How would you rate the Intro Program overall?\n\n. Number of responses: 41 responses.\"></p><ul><li>How likely is it that you would recommend the Intro Program to a friend or colleague with similar interests to your own? (1-10)<ul><li>Avg: 8.78</li><li>Median:&nbsp;<strong>9</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/bemq0mv1ktm5m6cjgppc\" alt=\"Forms response chart. Question title: How likely is it that you would recommend the Intro Program to a friend or colleague with similar interests to your own?. Number of responses: 41 responses.\"></p><ul><li>Preparation time: How many minutes did you spend on average preparing for the weekly discussion group?&nbsp;<ul><li>Avg: 105</li><li>Median:<strong> 90</strong></li></ul></li><li>Weeks Feedback (range -2 to 2, average)<ul><li>Week 1: 1,38</li><li>Week 2: 1,24</li><li>Week 3: 1,13</li><li>Week 4: 1,18</li><li>Week 5: 0,78</li><li>Week 6: 1,47</li><li>(Week 7: 0,5) &lt;- n=2</li><li>(Week 8: 1,33) &lt;- n=<br>&nbsp;</li></ul></li><li>Grouping Process: How did you like the grouping process in the beginning? (1-10)<ul><li>Avg: 8.76</li><li>Median:&nbsp;<strong>10</strong></li><li>Learning: Was high variance. For most people it worked well, for some not. We will ask in the future iterations already in the application from which days would probably work for the participants.<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/dbymqu2osaamlidar5dl\" alt=\"Forms response chart. Question title: Grouping Process: How did you like the grouping process in the beginning?. Number of responses: 41 responses.\"></li></ul></li><li>Communication: How satisfied were you with the communication in the Intro Program (emails/forms, signal groups)? (1-10)<ul><li>Avg: 8.73</li><li>Median:&nbsp;<strong>9</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/xnang9jp5ki7zsyvlbkn\" alt=\"Forms response chart. Question title: Communication: How satisfied were you with the communication in the Intro Program (mail/forms, signal groups)?. Number of responses: 41 responses.\"></p><ul><li>How would you rate your moderator in general? (1-10)<ul><li>Avg: 8.68</li><li>Median:&nbsp;<strong>9</strong><img style=\"width:100%\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/ryhirucgcxeajpmv3bep\" alt=\"Forms response chart. Question title: How would you rate your moderator in general?. Number of responses: 41 responses.\"></li></ul></li><li>General: How valuable was the Intro Program for you compared to what you would have done otherwise? (0.5 = half as valuable, 2 = twice as valuable, \u2026)&nbsp;<ul><li>Avg: 1.995</li><li>Median:&nbsp;<strong>2</strong></li></ul></li></ul><h3>Impact on participants</h3><p>Career</p><ul><li>Career: How likely are you to dedicate your career to doing good? (1-5)<ul><li>Avg: 4.12</li><li>Median:&nbsp;<strong>4</strong></li><li>Note: We had the same question in the application form: Avg: 4.18; Median:<strong> 4</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/reqdjfqovpfep8crmd17\" alt=\"Forms response chart. Question title: Career:&nbsp;How likely are you to dedicate your career to doing good?\n. Number of responses: 41 responses.\"></p><ul><li>Career choices: What impact did the Intro Program have on your career choices in the future (e.g., Internships, Bachelor Thesis, Change to high-impact cause etc.)? (1-10)<ul><li>Avg: 7.27</li><li>Median:&nbsp;<strong>7</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/fbavdsm4kol9v26d0adq\" alt=\"Forms response chart. Question title: Career choices: What impact did the Intro Program have on your career choices in the future (e.g., Internships, Bachelor Thesis, Change to high-impact cause etc.)?. Number of responses: 41 responses.\"></p><ul><li>Career:&nbsp;<strong>92.5% of respondents</strong> reported plans of doing career related activities such as&nbsp;<ul><li>Make a copy of the 80000 hours career template</li><li>Registered for a 1on1 in the Intro Program to discuss your career plans</li><li>Apply for career advice at EA Germany</li><li>Apply for career advice at 80000 hours</li><li>Switch career path in the long term [~ 5 years] to a high impact cause.</li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/kyumkzdfg1vfpmfeovcc\" alt=\"Forms response chart. Question title: Career choices:&nbsp; Will you start doing some of these activities after the Intro Program? [tick only things you did&nbsp;not&nbsp;do before the Intro Program already]. Number of responses: 41 responses.\"></p><ul><li>Career: some of the considered career paths are<ul><li>AI safety</li><li>Research communication</li><li>Public Policy</li><li>Mental Health / Facilitation for EA</li><li>Politics (for different cause areas)</li><li>Research</li></ul></li></ul><p>Donations</p><ul><li>Donations: What impact did the Intro Program have on your donations in the future (e.g. starting to donate, Trial Pledge)? (1-10)<ul><li>Avg: 6.90</li><li>Median:&nbsp;<strong>7</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/bawjhb4z2nznaeuygxni\" alt=\"Forms response chart. Question title: Donations: What impact did the Intro Program have on your donations in the future (e.g. starting to donate, Trial Pledge)?. Number of responses: 41 responses.\"></p><ul><li>Donation:&nbsp;<strong>80% of the respondents</strong> reported planning to do one or more of the following:<ul><li>Regularly donate effectively</li><li>Take the Giving Pledge</li><li>Talking with people about Effective Giving</li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/fxisehzdgqbf4pwamafo\" alt=\"Forms response chart. Question title: Donations: Will you start doing some of these activities after the Intro Program? [tick only things you did not do before the Intro Program already]. Number of responses: 41 responses.\"></p><p>EA Community/Engagement</p><ul><li>EA Community/Engagement: Based on your experience in the Intro Program, how much do you feel like you belong in the effective altruism community? (1-10)<ul><li>Avg: 6.66</li><li>Median:&nbsp;<strong>7</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/bfdxfpcexzwyv9s2nujj\" alt=\"Forms response chart. Question title: EA Community/Engagement: Based on your experience in the Intro Program, how much do you feel like you belong in the effective altruism community?. Number of responses: 41 responses.\"></p><ul><li>EA Community/Engagement: What impact did the Intro Program have on your engagement in the future (e.g., in the EA Community, Party Politics, other)? (1-10)<ul><li>Avg: 7.22</li><li>Median:&nbsp;<strong>7</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/kb3iqzeuc7zv5mkjhcgq\" alt=\"Forms response chart. Question title: EA Community/Engagement:&nbsp;What impact did the Intro Program have on your engagement in the future (e.g., in the EA Community, Party Politics, other)?. Number of responses: 41 responses.\"></p><ul><li>EA Community/Engagement: How motivated do you feel to be more active in the community or do an EA project than before the Intro Program? (0.5 = half as valuable, 2 = twice as valuable, \u2026)&nbsp;<ul><li>Avg: 1.79</li><li>Median:&nbsp;<strong>1,5</strong></li></ul></li><li>EA Community/Engagement: How many additional people in the EA community did you feel comfortable reaching out to after the Intro Program? (1-10)<ul><li>Avg: 4.88</li><li>Median:&nbsp;<strong>2</strong></li><li>Quite a few people had<strong> 0 as an answer</strong>, while some people put down 20+</li></ul></li><li>Engagement:&nbsp;<strong>90% of respondents</strong> reported plans to do at least one of the following in the future or did them during the Intro Program<ul><li>Go to events of my local group</li><li>Go to an EA retreat</li><li>Apply to an EAGx or EAG</li><li>Make an EA forum account</li><li>Join the EA Germany Slack</li><li>Start helping to organize EA events</li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/esu5p616i3poyvjphleh\" alt=\"Forms response chart. Question title: Engagement: Will you start doing some of these activities after the Intro Program? [tick only things you did not do before the Intro Program already]. Number of responses: 41 responses.\"></p><p>Understanding</p><ul><li>Learnings:&nbsp;<strong>90% of respondents</strong> reported having at least one of these experiences<ul><li>I got a deeper understanding of a key idea</li><li>I made a minor change to my plans</li><li>I made an important social connection</li><li>I changed my mind about a key idea</li></ul></li></ul><h3>Knowledge Test</h3><p>We also added some multiple choice knowledge questions into the final feedback form, to check for understanding of key topics of EA. These questions are, to our knowledge, also asked after other Intro Program internationally. All in all, the&nbsp;<strong>great majority of respondents</strong> showed&nbsp;<strong>thorough knowledge about EA</strong> key concepts and topics. The questions were as follows:</p><ul><li>What are the three factors that EA often uses when doing cause prioritization? (Answer: Scale, neglectedness, solvability)<ul><li>38 out of 40 respondents answered correctly (<strong>95%</strong>)</li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/b5jhi0ohztq391jeunqc\" alt=\"Forms response chart. Question title: What are the three factors that EA often uses when doing cause prioritization?. Number of responses: 40 responses.\"></p><ul><li>Some effective altruists argue that we should strive to be impartial when it comes to doing good, so we avoid privileging the interest of anyone based on arbitrary factors, such as race or gender. They also suggest that we should NOT discriminate against people based on these two factors: (Answer: Where they live and when they are born)<ul><li>32 out of 40 respondents answered correctly (<strong>80%</strong>)</li><li>Common wrong answer was \u201cHow intelligent they are and where they live\u201d</li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/f7pqvqwoxcen4cbqpwbp\" alt=\"Forms response chart. Question title: Some effective altruists argue that we should strive to be impartial when it comes to doing good, so we avoid privileging the interest of anyone based on arbitrary factors, such as race or gender. They also suggest that we should NOT discriminate against people based on these two factors:. Number of responses: 40 responses.\"></p><ul><li>Why does Peter Singer argue that we should give non-human animals moral concern? (Answer: They can experience suffering)<ul><li>38 out of 40 respondents answered correctly (<strong>95%</strong>)</li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/ozsmwynqsfdfvi5kxutf\" alt=\"Forms response chart. Question title: Why does Peter Singer argue that we should give non-human animals moral concern?. Number of responses: 40 responses.\"></p><ul><li>In the Precipice, why does Toby Ord think that 100% of humans dying is so much worse than the case of 99% of humans dying, despite a mere 1% difference? (Answer: Humanity\u2019s future potential would be permanently destroyed)<ul><li>35 out of 40 respondents answered correctly (<strong>87.5%</strong>)</li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/ghtihwjs3x7o3hff455q\" alt=\"Forms response chart. Question title: In the Precipice, why does Toby Ord think that 100% of humans dying is so much worse than the case of 99% of humans dying, despite a mere 1% difference?\n. Number of responses: 40 responses.\"></p><ul><li>Effective altruism as a social movement is all about\u2026 (Answer: Using evidence and careful reasoning to take actions that help others as much as possible)<ul><li>38 out of 40 respondents answered correctly (<strong>95%</strong>)</li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/jrqwtjygqxbpdaijztp7\" alt=\"Forms response chart. Question title: &nbsp;Effective altruism as a social movement is all about\u2026. Number of responses: 40 responses.\"></p><ul><li>\"In a study, respondents were asked how much they were willing to pay to save migrating birds from drowning in uncovered oil ponds. They responded with the following answers:</li></ul><p>- They\u2019re willing to pay $80 to save a total of 2,000 birds</p><p>- They\u2019re willing to pay $78 to save a total of 20,000 birds</p><p>- They\u2019re willing to pay $88 to save a total of 200,000 birds</p><p>Note: they\u2019re NOT saying they\u2019re willing to pay $80, $78, or $88 for one bird each.</p><p>Which cognitive bias did they exhibit?\" (Answer: Scope insensitivity)</p><ul><li>36 out of 40 respondents answered correctly (<strong>90%</strong>)</li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/fytlamlyrrazyqojuhd6\" alt=\"Forms response chart. Question title: In a study, respondents were asked how much they were willing to pay to save migrating birds from drowning in uncovered oil ponds. They responded with the following answers:\n\n\n\n- They\u2019re willing to pay $80 to save a total of 2,000 birds\n\n- They\u2019re willing to pay $78 to save a total of 20,000 birds\n\n- They\u2019re willing to pay $88 to save a total of 200,000 birds\n\nNote: they\u2019re NOT saying they\u2019re willing to pay $80, $78, or $88 for one bird each. \n\n\nWhich cognitive bias did they exhibit?\n. Number of responses: 40 responses.\"></p><ul><li>Which of the following interventions have a higher expected value?&nbsp;<ul><li>36 out of 40 respondents answered correctly (<strong>90%</strong>)</li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/ojebrcqdj72n0gvnrogw\" alt=\"Forms response chart. Question title: Which of the following interventions have a higher expected value?\n(Feel free to use a calculator)\n. Number of responses: 38 responses.\"></p><ul><li>What organization within EA specializes in helping people plan high impact career pathways? (Answer: 80,000 Hours)<ul><li>39 out of 40 respondents answered correctly (<strong>97.5%</strong>)</li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/pafts3vkzs6xnioynizs\" alt=\"Forms response chart. Question title: What organization within EA specializes in helping people plan high impact career pathways?. Number of responses: 40 responses.\"></p><h2>&nbsp;</h2><h2>2. Moderators</h2><ul><li>7 moderators took the final feedback form, from a total of 15 (not counting 2 organizers who were mods themselves)</li></ul><h3>General</h3><ul><li>Impact estimation: How impactful do you think is the Intro Program?</li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/hohc1e4tqc6kyuacbqo7\" alt=\"Forms response chart. Question title: Impact estimation: How&nbsp;impactful&nbsp;do you think is the Intro Program?. Number of responses: 7 responses.\"></p><ul><li>How would you rate the Intro Program overall? (1-10)<ul><li>Avg:&nbsp;<strong>8.29</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/c6xgfbdfq2qrfvfstycs\" alt=\"Forms response chart. Question title: How would you&nbsp;rate&nbsp;the Intro Program overall?\n. Number of responses: 7 responses.\"></p><ul><li>How likely is it that you would recommend moderating in the Intro Program to a friend or colleague in a similar situation to your own?<ul><li>Avg:&nbsp;<strong>8.14</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/jmvpyu9fvcyaafsrfy5j\" alt=\"Forms response chart. Question title: How likely is it that you would&nbsp;recommend&nbsp;moderating in&nbsp;the Intro Program to a&nbsp;friend or colleague&nbsp;in a similar situation&nbsp;to your own?. Number of responses: 7 responses.\"></p><ul><li>Time investment: How many minutes did you spend on average per week on this Intro Program?<ul><li>Avg: 193.58</li><li><strong>Median: 170</strong> \u2192 around 3 hours</li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/gefd7rwscdv86fddugd6\" alt=\"Forms response chart. Question title: Time investment: How many minutes&nbsp;did you spend on average&nbsp;per week on this Intro Program?. Number of responses: 7 responses.\"></p><ul><li>Grouping Process: How did you like the grouping process in the beginning?<ul><li>Avg:&nbsp;<strong>9</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/ebozpu4i26jgpngrsjlj\" alt=\"Forms response chart. Question title: Grouping Process: How did you like the grouping process in the beginning?. Number of responses: 7 responses.\"></p><ul><li>Journal: How much did you like the journal of the Intro program?<ul><li>Avg:&nbsp;<strong>8</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/kqncgrsuzxmz3z0slr4a\" alt=\"Forms response chart. Question title: Journal: How much did you like the journal of the Intro program?. Number of responses: 7 responses.\"></p><ul><li>Communication: How did you find the communication between mods/organizer?</li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/k6ij6op0t4x4tkvyqj30\" alt=\"Forms response chart. Question title: Communication: How did you find the communication between mods/organizer?. Number of responses: 7 responses.\"></p><h3>Impact on moderators</h3><ul><li>Time usage: How valuable was moderating in the Intro Program for you compared to what you would have done otherwise?<ul><li>Avg: 1.37</li><li>Median:&nbsp;<strong>1.2</strong></li></ul></li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/b0kisvni61ubzlxtea5d\" alt=\"Forms response chart. Question title: Time usage:&nbsp;How valuable was moderating in the Intro Program for you compared to what you would have done otherwise?\n. Number of responses: 7 responses.\"></p><ul><li>Time usage: What do you think: how well was your time spent?<ul><li>&nbsp;<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/hzftjao2ej4x6w3u3q83\" alt=\"Forms response chart. Question title: Time usage: What do you think: how well was your time spent?. Number of responses: 7 responses.\"></li><li>1/7 mentioned that he/she could have spent the time probably better \u2192 seems alright</li></ul></li><li>Impact on you: Did you have any of these experiences at the Intro Program?</li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/etcL6qZ6hRJdDxtcs/wpkdvohlwsfuaiugbtjd\" alt=\"Forms response chart. Question title: Impact on you: Did you have any of these experiences at the Intro Program?&nbsp;\n. Number of responses: 7 responses.\"></p><h2>Other</h2><ul><li>We had several participants taking up the initiative to create a&nbsp;<strong>career planning group</strong> together, where they would hold each other accountable and support each other through feedback on their thoughts &amp; plans.&nbsp;</li><li>One participant wrote up his<strong> career plan and posted it online</strong> and in the discussion group to get further feedback on it.</li><li>1on1s<ul><li>In week 2, participants can apply to speak to a moderator in a 1on1. The participants have to formulate the topic and the person they want to talk to.</li><li>The theory of change is that through that participants reflect EA stronger in their personal lives and have one contact person for the future.</li><li>In theory, this sounds good. In practice, it takes the facilitators a total of about 120 minutes (scheduling, preparation, follow-up) and often the contact with the participant diminishes over time.</li><li>We are not sure if we should continue the 1on1s. Some data regarding evaluating the 1on1s can be found&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1R4xRgq3aFZXmzMZ3xWRnKfZ4qXWYuv3TykNHQR5e4iY/edit?usp=sharing\"><u>here</u></a> (n=3).</li></ul></li><li>EAD Retreat<ul><li>Around 20 people participated afterward in the EAD Retreat. More info about the retreat&nbsp;<a href=\"https://docs.google.com/document/d/1yyJBnLWac2N-1OPFxJGzKrOUx4Fckc-0S-YYmpfEI8A/edit?usp=sharing\"><u>here</u></a>.</li></ul></li><li>Internal organization<ul><li>We used&nbsp;<strong>Asana, Google Workspace and Zoom</strong> for organizing the Intro Program. Maybe Airtable and Notion could improve some workflows. Currently, we aren\u2019t planning to switch.</li></ul></li></ul><h1>Learnings/Improvement</h1><p>We got a lot of feedback regarding different aspects of the Intro Program. Going forward, we want to&nbsp;<strong>implement&nbsp;</strong>these points to improve the Intro Program (Again templates are&nbsp;<a href=\"https://docs.google.com/document/d/1PqieePsgSgKYx3CpEVKmv4JTpQxezehpeIuXzQ1pEZg/edit#heading=h.mmpk2k2e7jwe\"><u>here</u></a>).</p><ul><li>Promotion<ul><li>Extend promotion to further channels. Have more materials like flyers etc.</li><li>Decide if there should be an EA Introductory Program newsletter to let interested people know when the next application period is open.</li></ul></li><li>Application form<ul><li>Have a strict deadline.</li><li>Ask on which day in the afternoon the applicant has probably time. \u2192 Improves likelihood that grouping works.</li><li>Have an automated mail (add-on in Google forms) after filling in the form. Content: Application received. On [date] you will hear from us latest whether you got accepted. Reminder to attend kickoff.&nbsp;</li></ul></li><li>Grouping Process<ul><li>Online groups: building the groups based on when people have time. Ask for&nbsp;<strong>weekday availability in the registration</strong> form, then assign groups based on that.&nbsp;<ul><li>Currently, we ask for weekday availability after we assign the groups. This is probably suboptimal from the users' perspective and maybe even from the organizing perspective, as we have to coordinate participants switching groups if they can\u2019t find a time that fits everybody. On the other hand, it is probably&nbsp;<strong>computationally easier</strong> than hashing out everything before.&nbsp;</li></ul></li><li><strong>Merge shrinking groups sooner</strong> to have more lively discussion. This could mean having closer monitoring over attendance in groups. As a start, a group size of around 7 people seems good.</li></ul></li><li>Moderators<ul><li>Make an optional 90 - 120-minute training session before. Mandatory for new moderators.</li><li>Decide if there should be 1on1s in the next iteration. Improve the workflow so that it's less time-consuming for the moderators.</li></ul></li><li>Names and Faces<ul><li>In general, a good thing to have. It wasn\u2019t that often used last time. \u2192 Give more nudges to make comments to each other profiles.&nbsp;</li></ul></li><li>Journal<ul><li>Design should be less crowded,&nbsp;<strong>cleaner</strong></li><li><strong>Time estimates</strong> weren\u2019t realistic (took more time to read) - but the data how much time people spent preparing was fine</li><li><strong>Terms stated</strong> at the beginning should be extractable from the texts provided</li><li><strong>Implement&nbsp;</strong>the first suggestions and ask&nbsp;<strong>publicly&nbsp;</strong>for more feedback several before the next iteration.</li></ul></li><li>Discussion Sessions<ul><li>Make the document&nbsp;<strong>shorter&nbsp;</strong>(e.g. leave out summaries)</li><li>Make the&nbsp;<strong>voting algorithm less</strong> complicated</li><li>Quite a few people asked for longer sessions (~<strong>120 min</strong>), want to have more time for discussion</li><li>Build a sense of&nbsp;<strong>group cohesion</strong> in discussion groups, e.g. with informal check-ins in the beginning and nudges to reach out to other participants even outside the Intro Program</li></ul></li><li>Communication<ul><li>Have 2 mails in the beginning. Communicate other opportunities e.g. 1on1s registration, EAD Retreat, EAGx application in the discussion groups.</li><li>Too many&nbsp;<strong>channels&nbsp;</strong>of information. Improvement: Have one&nbsp;</li><li>Too many forms and forms are too long. Streamline and focus on the important ones.</li><li>Mods: Slack Channel wasn\u2019t used much \u2192&nbsp;<strong>Signal group</strong> would be better</li></ul></li><li>Events<ul><li>Don\u2019t offer socials or a giving game. In the last iterations, not that many people [around 1 to 5] showed up and so it wasn\u2019t worth it.</li></ul></li><li>Documentation<ul><li>Complete the documentation how to organize the Intro Program.</li></ul></li><li>Diversity &amp; Feedback<ul><li>Add an anonymous feedback form.</li><li>Improve the internal gathering of feedback and acting on it.</li></ul></li><li>Final Form<ul><li>Add: Name (optional) and description: In our analysis, we'll compare your answers on the application with your answers on the final form. We will publish the impact and learnings of the Intro Program in an anonymized way.</li><li>Food basket lottery for filling in the form \u2192 too much work, do something else e.g. additional free book, donation to favorite charity or so</li></ul></li><li>3 months follow-up<ul><li>Start doing a 3-month follow-up and gather data.</li></ul></li></ul><h1>History of the Intro Program</h1><h2>Statistics &amp; History</h2><figure class=\"table\"><table><tbody><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">&nbsp;</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">2020 Winter</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">2021 Summer</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">2021 Winter</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">2022 Summer</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">2022 Winter</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">2023 Summer</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">Participants</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>25</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>70</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>75</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>85</p></td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">Organizers</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jonathan Michel and others</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">Jonathan Michel, Evander Hammer</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">Evander Hammer, Moritz von Knebel</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">Evander Hammer, Moritz von Knebel</td><td style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">EA Germany: Evander Hammer</td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\">EA Germany: Evander Hammer, Ruben Heller, Gabe Salwey</td></tr></tbody></table></figure><h2>Remarks</h2><ul><li>The first three iterations were a volunteer project only loosely in contact with EA Germany. Probably the impact of these is pretty counterfactual no one else was interested in running Intro Programs in Germany. These iterations were also more selective. Out of memory, roughly 20% of applicants got rejected.</li><li>In summer 2022, it was run less like an independent project and was more integrated in the semester plan of each local group.&nbsp;</li><li>In winter 2022, the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/zxSdBkN6cggkE8vv6/ea-germany-s-strategy-for-2023#Foundational_Programs\"><u>intro program was included in the foundational programs of EA Germany </u></a>providing financial and organizational support.</li></ul><p>This report was written by Evander Hammer and Ruben Heller. All mistakes are our own. We appreciate feedback or questions about the Intro Program in the comments.</p>", "user": {"username": "Evander Hammer"}}, {"_id": "dNMfswWKxqMz2BxuC", "title": "[Applications Open] CEA\u2019s Organizer Support Program (OSP) & University Group Organizer Retreat", "postedAt": "2023-11-03T10:30:51.611Z", "htmlBody": "<h3>TLDR</h3><ul><li>Applications have opened for CEA\u2019s&nbsp;<a href=\"https://www.notion.so/centreforeffectivealtruism/Organizer-Support-Program-OSP-0aa5dc55d97e444da347d8d227db93d4?pvs=4\"><u>Organizer Support Program (OSP)</u></a></li><li>Applications have also opened for the&nbsp;<a href=\"https://www.notion.so/centreforeffectivealtruism/University-Group-Organizer-Retreat-January-2024-cbf3b5e7b2674e64b2e50e20487356b7\"><u>University Group Organizer Retreat</u></a></li><li><strong>The deadline for both is Sunday, November 12!</strong></li><li>Our hiring round for a&nbsp;<a href=\"https://www.centreforeffectivealtruism.org/careers/university-group-coordinator-2023\"><u>University Group Coordinator</u></a> is also still open; we\u2019re accepting applications until Wednesday, November 8</li></ul><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dNMfswWKxqMz2BxuC/gkdvze8hj2huodsgvv9a\"><figcaption>Group photo of last year's University Group Organizer Retreat</figcaption></figure><h3>OSP</h3><p>The<a href=\"https://www.notion.so/centreforeffectivealtruism/Organizer-Support-Program-OSP-0aa5dc55d97e444da347d8d227db93d4?pvs=4\"><strong><u> Organizer Support Program (OSP)</u></strong></a> is a three-week&nbsp;<strong>mentorship program</strong> (though most organizers will receive semester-long mentorship) aimed at&nbsp;<strong>university EA group organizers</strong> to help them prepare for the start of the semester. It offers regular meetings with an experienced mentor, various workshops, and useful resources to run an effective group. OSP is the follow-up program to UGAP.</p><p>We are also looking for additional experienced organizers to serve as mentors. You can find out more about and express interest in becoming a mentor&nbsp;<a href=\"https://www.notion.so/Apply-to-Mentor-University-EA-Groups-b5b005ce6be24d0b825fc1ab5dcd7c3d\"><u>here</u></a>.</p><h3>University Group Organizer Retreat&nbsp;</h3><p>The&nbsp;<a href=\"https://www.notion.so/centreforeffectivealtruism/University-Group-Organizer-Retreat-January-2024-cbf3b5e7b2674e64b2e50e20487356b7\"><strong><u>University Group Organizer Retreat</u></strong></a> is also happening! The in-person retreat will allow organizers to meet other organizers and EA professionals, to help them learn more about community building and EA more broadly.&nbsp;<strong>The retreat will take place January 5 - 8, close to Oxford (UK), and CEA will cover travel, room and board</strong>.&nbsp;&nbsp;</p><p>We expect most attendees to be UGAP and OSP participants, but we also have limited spots available for university group organizers who are not in our programs. The retreat is mostly aimed at university group organizers relatively new to community building.</p><h3>Deadline &amp; application process</h3><p><strong>You can apply to both opportunities until November 12, 12:59 PM AoE!</strong></p><ul><li>We combined the application forms, making it easy for you to apply for both</li><li>If you have previously participated in UGAP or OSP, or received Open Philanthropy\u2019s University Organizer Fellowship, the application will only take a few minutes</li></ul><h3>Hiring: University Group Coordinator</h3><p>Applications for the University Group Coordinator role are still open. You can read more&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/foRwCmKaDCHQ8YaRu/why-you-should-maybe-apply-to-the-cea-university-groups-team\"><u>here</u></a>, and&nbsp;<a href=\"https://www.centreforeffectivealtruism.org/careers/university-group-coordinator-2023\"><u>apply</u></a> until November 8!</p>", "user": {"username": "Joris P"}}, {"_id": "RJgGP6tEeuvtbapjP", "title": "Curious about EAGxVirtual? Ask the team anything!", "postedAt": "2023-11-03T10:03:50.560Z", "htmlBody": "<p><a href=\"https://www.effectivealtruism.org/ea-global/events/eagxvirtual-2023\"><strong>EAGxVirtual 2023</strong></a>, a free online effective altruism conference (November 17\u201319),<strong>&nbsp;</strong>is just two weeks away!<br><br>The event will bring together EAs from around the world, and will facilitate discussions about how we can work on pressing problems, connections between attendees and diverse fields, and more.&nbsp;</p><p><strong>Apply&nbsp;</strong><a href=\"https://effectivealtruism.my.site.com/EAGlobal/s/eagxvirtualapplication\"><strong>here</strong></a><strong> by 16 November.</strong></p><p>We've recently published some more details about the event and&nbsp;<strong>we want to invite you to ask us about what to expect from the event.&nbsp;</strong>Please post your questions as comments by&nbsp;<strong>the end of the day on Sunday (5 November)</strong> and we\u2019ll aim to respond by the end of the day on Monday (6 November).<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/RJgGP6tEeuvtbapjP/rtdb1pd70758x3amcaxw\"><br>&nbsp;</p><p>Some question prompts:</p><ul><li><strong>Unsure about applying?</strong> We encourage everyone with a genuine interest in EA to <a href=\"https://effectivealtruism.my.site.com/EAGlobal/s/eagxvirtualapplication\">apply</a>, and we're accepting a vast majority of people. Let us know what you're uncertain about with the application process.</li><li><strong>Undecided whether to go?</strong> Tell us why and we can help you. We'll probably be biased but we\u2019ll try our best to present considerations on both sides\u2014it won\u2019t be a good use of time for everyone!</li><li><strong>Unsure how to prepare?</strong> You can find some tips on&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/effective-altruism-global\">the EA Global topic page</a> but we're happy to help with your specific case if you need more tips!</li><li><strong>Uncertain how to set up a group activity (a screening, a meet-up etc.) for the event?</strong> Share your thoughts below and we can help you plan!<br>&nbsp;</li></ul><p>We look forward to hearing from you!</p><p>-</p><p>Sasha, Dion (EAGxVirtual / EA Anywhere) and Ollie (CEA)<br>&nbsp;</p>", "user": {"username": "OllieBase"}}, {"_id": "4zfq4F52qk5sLaLAH", "title": "Speedfriending and Lightining Talks", "postedAt": "2023-11-03T08:38:25.897Z", "htmlBody": "<p>Hey there, next week Wednesday we will meet again in Haus des Engagements but in another room (Raum Gelb). We will start off with some speedfriending to get to know each other better and then do a round of Lightning Talks. Lightning talks are a form of very short talk that last no longer than 3 minutes. Just choose a topic you are excited about or you think is important and do a quick talk on it. No preparation needed. Topics can range from \u2018Space Governance\u2019 to \u2018my favorite restaurant in Freiburg\u2019. If you already have a topic, just put it in <a href=\"https://docs.google.com/document/d/186bXUcAP-Tru0N7xx_2kjOLTxsDvvnVY2QJ5xgPU0SY/edit?usp=sharing\">this Google Doc</a>, but you can also just come up with one spontaneously or just let yourself inspire from the talks of others if you prefer to. Looking forward to see you!</p>", "user": {"username": "Hauks"}}, {"_id": "k9nFE2zGima7sWXWz", "title": "Thoughts on consequentialism? ", "postedAt": "2023-11-03T02:41:27.171Z", "htmlBody": "<p>Given this quote from the Wall Street journal:\n\u201c Ellison testified that Bankman-Fried was a risk-taker who was comfortable with lying and stealing as long as it benefited the greater good. To attract FTX customers, he cultivated an appearance \u201cas a smart, competent, somewhat eccentric founder,\u201d she said\u201d</p>\n<p>And this Substack post:\n<a href=\"https://betonit.substack.com/p/singer-and-the-noble-lie\">https://betonit.substack.com/p/singer-and-the-noble-lie</a>.</p>\n<p>To me, it seems like a consequentialist view clearly requires you to lie in certain circumstances, but it is very difficult to realize when it would be a net positive. Doesn\u2019t that force an EA into a rule consequentialism?</p>\n", "user": {"username": "Daniel Birnbaum"}}, {"_id": "4XL6ZCvYm3zcBGwpf", "title": "SBF found guilty on all counts", "postedAt": "2023-11-03T00:04:15.369Z", "htmlBody": "<p>Sam Bankman-Fried has been found guilty of all seven charges in his recent trial. The jury deliberated for four and a half hours. Here are the counts, listed by CNN:</p><blockquote><p>Count one: Wire fraud on customers of FTX&nbsp;</p><p>Count two: Conspiracy to commit wire fraud on customers of FTX</p><p>Count three:&nbsp;Wire fraud on Alameda Research lenders</p><p>Count four:&nbsp;Conspiracy to commit wire fraud on lenders to Alameda Research&nbsp;</p><p>Count five: Conspiracy to commit securities fraud on investors in FTX&nbsp;</p><p>Count six: Conspiracy to commit commodities fraud on customers of FTX&nbsp;</p><p>Count seven: Conspiracy to commit money laundering&nbsp;</p></blockquote><p>There are still a few other charges against him that will be addressed in a March 2024 trial.&nbsp;</p><p>He (and I think also his convicted co-conspirators Caroline Ellison, Gary Wang, Ryan Salame and Nishad Singh) will be sentenced <a href=\"https://www.reuters.com/legal/ftx-founder-sam-bankman-fried-thought-rules-did-not-apply-him-prosecutor-says-2023-11-02/#:~:text=The%20conviction%20represented%20a%20victory,sentencing%20for%20March%2028%2C%202024.\">next March</a>.</p>", "user": {"username": "Fermi\u2013Dirac Distribution"}}, {"_id": "zLkdQRFBeyyMLKoNj", "title": "Still no strong evidence that LLMs increase bioterrorism risk", "postedAt": "2023-11-02T21:23:13.969Z", "htmlBody": "<p><a href=\"https://www.lesswrong.com/posts/ztXsmnSdrejpfmvn7/propaganda-or-science-a-look-at-open-source-ai-and\">https://www.lesswrong.com/posts/ztXsmnSdrejpfmvn7/propaganda-or-science-a-look-at-open-source-ai-and</a></p><p>Linkpost from LessWrong.</p><p>The claims from the piece which I most agree with are:</p><ol><li>Academic research does not show strong evidence that existing LLMs increase bioterrorism risk.</li><li>&nbsp;Policy papers are making overly confident claims about LLMs and bioterrorism risk, and are citing papers that do not support claims of this confidence.</li></ol><p>I'd like to see better-designed experiments aimed at generating high quality evidence to work out whether or not future, frontier models increase bioterrorism risks, as part of evals conducted by groups like the UK and US AI Safety Institute.</p>", "user": {"username": "freedomandutility"}}, {"_id": "onnzwxrhqKbPGmSRv", "title": "Promoting Effective Giving this Giving Season: For groups, networks and individuals", "postedAt": "2023-11-02T20:52:35.887Z", "htmlBody": "<p>Effective giving is a core part of effective altruism as a project&nbsp;\u2014 and we\u2019d love to see EA groups, networks of people in the EA community, and individuals helping to promote it, this Giving Season.</p><p>There\u2019s a lot less funding available to many effective charities than there was last year,and that means that we\u2019re making less progress than we might have otherwise on pressing global problems. Increasing the funds raised for effective charities by promoting effective giving remains one of the best ways for many of us to prevent deaths and suffering now and into the future.</p><p>Below, I\u2019ve listed some actions for both groups/networks and individuals to take. If you have any other ideas for promoting effective giving, we are all ears and would love to figure out how to support you! Feel free to share ideas with others in the comments!</p><h1>Actions for groups or networks:</h1><h2>Ask us to host a talk for your group, workplace, social club, etc.</h2><p>We\u2019re excited about giving talks about effective giving to groups of more than 20 people online or in-person (in locations that are feasible for us). We can also connect you with other organisations or speakers!</p><p>We have a particularly good new talk that\u2019s been really well received by several consulting and tech companies!</p><p><a href=\"https://forms.gle/VKVtFTfGdCZ65dKs7\"><u>Fill out this form to let us know you\u2019re interested</u></a></p><h2>Host your own Giving Game, everyday philanthropist or fundraising event</h2><p>GWWC will sponsor donations for each participant in a&nbsp;<a href=\"https://www.givingwhatwecan.org/en-US/events/guides/giving-games\"><u>Giving Game</u></a> and has training and materials to help you run this smoothly! We also have a long list of ideas for fundraising events.</p><p>Additionally, we think Everyday Philanthropist events could be a really great way to engage both new and existing givers. Here\u2019s a brief explanation of how they work (from our event guide):</p><ul><li>Invite your attendees to help in making a real-world donation decision. One or more donors will play the role of a philanthropist and the attendees will help the donor decide on where they will donate.</li><li>Ideally the donors will provide a document with what their intentions are (e.g. \"most improve the lives of farmed animals\") and some suggested charities to help guide the discussion. This works best if either the donor or event organising team provide good summary information on each of the charities.</li></ul><p>This makes for a great end-of-year event, helps to showcase real people who make effective giving a part of their lives, and offers an opportunity for those without an income to also be involved in effective giving.</p><p><a href=\"https://www.givingwhatwecan.org/en-US/events/guides/giving-games\"><u>Giving Game materials and sponsorship request</u></a></p><p><a href=\"https://www.givingwhatwecan.org/blog/what-kind-fundraiser-are-you\"><u>Fundraising event ideas</u></a></p><p><a href=\"https://www.givingwhatwecan.org/en-US/events/guides/everyday-philanthropist\"><u>How to run an Everyday Philanthropist event</u></a></p><h2>Start a fundraising page for your group</h2><p>You can request to set up a GWWC fundraising page for up to 3 of our supported charities. Why not set a target and encourage your group to ask friends and family to donate?</p><p><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfO_Wich5S34CxMW_vMft5FQiGYTIJhHe0RkszjWMyUpB5myQ/viewform\"><u>Create a fundraising page with GWWC</u></a></p><h2>Host a pledge panel in the new year</h2><p>Hearing from people about their experiences taking a pledge with GWWC can be a great way to answer questions that people might have about the pledge, or help someone feel that it\u2019s more achievable and rewarding than they previously thought.</p><p><a href=\"https://www.givingwhatwecan.org/en-US/events/guides/pledge-panel\"><u>Pledge panel event guide</u></a></p><h1>Actions for individuals:</h1><h2>Contribute a post to the EA Forum about your giving during Giving Season</h2><p>Share your experience with giving and more during a themed week on the EA Forum. Your thinking could influence others to donate more, or differently&nbsp;\u2014 and we\u2019d love to see a variety of opinions out there!</p><p><a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#Giving_Season___weekly_discussion_themes\"><u>Themed weeks you might want to contribute to</u></a></p><h2>Vote and discuss as part of the EA Forum\u2019s Donation Election</h2><p>EA Forum users will have the opportunity to vote on which charities will receive a portion of the Donation Election Fund (which you can also contribute to), as well as discuss on the Forum why your favourite charity should receive the funding.</p><p><a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly\"><u>Post on participating in the Donation Election</u></a></p><h2>Share the latest giving recommendations with friends and family</h2><p>Point your friends and family towards highly effective donation options this Giving Season. Giving What We Can will be releasing our new recommendations towards the end of the month!</p><p><a href=\"https://www.givingwhatwecan.org/en-US/best-charities-to-donate-to-2023\"><u>Our recommended charities</u></a></p><p><a href=\"https://www.givingwhatwecan.org/en-US/newsletter\"><u>Sign up to our mailing list to get the new recommendations once they\u2019re released!</u></a></p><h2>Start a fundraising page instead of asking for presents over the holidays</h2><p>You can request to set up a GWWC fundraising page for up to 3 of our supported charities. If you\u2019re not interested in receiving gifts, consider asking for donations instead&nbsp;\u2014 not only does this raise funds, it raises awareness of highly effective charities.</p><p><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfO_Wich5S34CxMW_vMft5FQiGYTIJhHe0RkszjWMyUpB5myQ/viewform\"><u>Create a fundraising page with GWWC</u></a></p><h2>Ask us to host a talk for your group workplace, social club, etc.</h2><p>We\u2019re excited about giving talks about effective giving to groups of more than 20 people online or in-person (in locations that are feasible for us). We can also connect you with other organisations or speakers</p><p><a href=\"https://forms.gle/VKVtFTfGdCZ65dKs7\"><u>Fill out this form to let us know you\u2019re interested</u></a></p><h2>Talk about your pledge in person or on social media</h2><p>Especially around the new year, people are often looking to make commitments in line with their values. Reflecting on how the pledge has positively impacted your life, and suggesting interested friends and family take a trial pledge to begin with (perhaps 1% for a year or 10% for 6 months) could be a great way to help them find an impactful resolution.</p><p>Here\u2019s a&nbsp;<a href=\"https://www.facebook.com/Thedavidkile/posts/10222302376535881\"><u>nice example from David Kile</u></a></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/onnzwxrhqKbPGmSRv/ug5vhdek7ohfkyipm9yu\"></p><p><a href=\"https://www.givingwhatwecan.org/en-US/get-involved/share-our-ideas/link-to-us\"><u>Here are some more ideas of how to talk about your Pledge on social media</u></a></p><p><br><br>&nbsp;</p>", "user": {"username": "GraceAdams"}}, {"_id": "jCwuozHHjeoLPLemB", "title": "How Long Do Policy Changes Matter? New Paper", "postedAt": "2023-11-02T20:53:07.464Z", "htmlBody": "<p>A key question for many interventions' impact is how long the intervention changes some output counterfactually, or how long the intervention washes out. This is often the case for work to change policy: the cost-effectiveness of efforts to pass <a href=\"https://rethinkpriorities.org/publications/a-cost-effectiveness-analysis-of-historical-farmed-animal-welfare-ballot-initiatives\">animal welfare ballot initiatives</a>, <a href=\"https://exploratory-altruism.org/research-findings/\">nuclear non-proliferation policy</a>, <a href=\"https://www.founderspledge.com/downloads/fp-climate-change\">climate policy</a>, and <a href=\"https://forum.effectivealtruism.org/posts/xL8H3TRj3xxenDgEF/transforming-democracy-a-unique-funding-opportunity-for-us\">voting reform</a>, for example, will depend on (a) whether those policies get repealed and (b) whether they would pass anyway. Often there is an explicit assumption, e.g., that passing a policy is equivalent to speeding up when it would have gone into place anyway by <i>X</i> years.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4sidc99qrzj\"><sup><a href=\"#fn4sidc99qrzj\">[1]</a></sup></span>&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnk39eu4v7l\"><sup><a href=\"#fnnk39eu4v7l\">[2]</a></sup></span>&nbsp;As people routinely note when making these assumptions, it is very unclear what assumption would be appropriate.</p><p>In a <a href=\"https://zachfreitasgroff.com/FreitasGroff_Policy_Persistence.pdf\">new paper</a> (my economics \"job market paper\"), I address this question, focusing on U.S. referendums but with some data on other policymaking processes:</p><blockquote><p>Policy choices sometimes appear stubbornly persistent, even when they become politically unpopular or economically damaging. This paper offers the first systematic empirical evidence of how persistent policy choices are, defined as whether an electorate\u2019s or legislature\u2019s decisions affect whether a policy is in place decades later. I create a new dataset that tracks the historical record of more than 800 state policies that were the subjects of close referendums in U.S. states since 1900. In a regression discontinuity design, I estimate that passing a referendum increases the chance a policy is operative 20, 40, or even 100 years later by over 40 percentage points. I collect additional data on U.S. Congressional legislation and international referendums and use existing data on state legislation to document similar policy persistence for a range of institutional environments, cultures, and topics. I develop a theoretical model to distinguish between possible causes of persistence and present evidence that persistence arises because policies\u2019 salience declines in the aftermath of referendums. The results indicate that many policies are persistently in place\u2014or not\u2014for reasons unrelated to the electorate\u2019s current preferences.</p></blockquote><p>Below I'll pull out some key takeaways that I think are relevant to the EA community and in some cases did not make it into the paper.</p><h1><strong>Overview of Results and Methods</strong></h1><p>My strategy in the paper involves comparing how many policies that barely passed or barely failed in U.S. state-level referendums are in place over time. I collect data on all referendums whose vote outcome is within 2.5 percentage points of the threshold for passage (typically 50%) since 1900 in a subset of U.S. states. I then do what's called a regression discontinuity design, which allows me to estimate the effect of passing a referendum on whether it is in place later on.&nbsp;</p><p>The headline result from the paper is below. Many referendums that barely fail eventually pass in the first few years or decades afterward, and then this levels off. At 100 years later, just under 80% of the barely passed ones are in place compared to just under 40% of the barely failed ones. Importantly, the hazard rate\u2014the rate at which this effect declines over time\u2014is much lower in the later years, meaning that if you were to extrapolate this out beyond 100 years, the effect at 200 years would be expected to be significantly more than 40% * 40%.<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/zccds0r79ngnsh2plytj\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/oitmhoolcyb36xiim9mt 130w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/u4b7eribjzyawhjmlrmv 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/wmxtcc1hhwgxokoxm52g 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/atxgpjp1boexemm5uca3 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/aphgeqernhch8gbgfwvg 650w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/hspodo9kcuvweuhtv69y 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/sdjajp7iillyjinpwhn8 910w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/q9ff5uej6gv0qospwvaj 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/qr0mlly5jviz4i0m0vh1 1170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/zg4xewlkwwspwsttvm4s 1246w\"></p><p>Something relevant to EAs that I don't focus on in the paper is how to think about the effect of campaigning for a policy given that I focus on the effect of passing one conditional on its being proposed. It turns out there's a method (<a href=\"https://eml.berkeley.edu/~jrothst/publications/cellini-ferreira-rothstein-QJE-2010.pdf\">Cellini et al. 2010</a>) for backing this out if we assume that the effect of passing a referendum on whether the policy is in place later is the same on your first try is the same as on your <i>N</i>th try. Using this method yields an estimate of the effect of running a successful campaign on later policy of around 60% (Appendix Figure D20).</p><p>The assumption required for these point estimates to be unbiased is fairly strong, but what should be less controversial is that the effect of campaigning to pass a referendum given that nobody else is pursuing it is much larger than the effect of passing one that has already been proposed. Concretely, my mainline estimate in the above graph tells us what the effect is of pushing an existing referendum over the edge. If the proponents of a referendum plan to try again and again, this lowers the effect. Instead, we might be interested in the effect of Open Philanthropy funding a ballot measure campaign, assuming they never again attempt it. The latter is likely much larger than the effects previously presented.</p><p>One thing you might wonder about is whether this happens because some policies are unimportant, so nobody does anything about them. I look at this in a few ways, including subjective judgments of a policy's impact and projections of a policy's fiscal impact. I don't see any differences here. I also look at what happens if we drop policies that arguably became obsolete, and this only makes the effect larger (because such policies are often struck from the books).</p><p>When we look across policy topics and policies' political orientation, things look strikingly similar:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/hwkcjzzlsydyk8s8u9fr\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/njeqy8qpo15pxahtb8uf 130w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/dzavzal6k3asr8v0cofs 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/bojcyof0wr7e0x38ocrq 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/gk4uvbaislyhhrvkr2cb 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/f4gzwhsjuv256ecjkgxk 650w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/ccvoehkcvdotj4stoxrg 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/fqf4pg0gjadh7iqgbkcg 910w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/lpg5yeci270axh2b8qln 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/z8jppl8jjnw3hmg3swxj 1170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/mt54jd1wzbykthmkggmv 1218w\"></figure><p>You might also wonder whether there are slippery slope (or backlash) effects where a policy leads to some sort of reaction. I discuss this in the paper (Figure 5 and Appendix Figure D13). There are suggestive signs of this happening to a small degree, though with the important caveat that I only look at effects on the same policy (e.g., does banning battery cages lead to bans of enriched cages) rather than the broader universe of policies (e.g., does banning battery cages lead to other animal welfare policies).<br><br>I won't go into depth here on why this is happening, but the story that best fits the data is based on a decline in policies' salience over time. Political actors' interest in a policy goes up and down, and after the period of a referendum passes, people stop thinking about it because of a regression-to-the-mean effect. I don't find evidence that people change their minds in response to a policy or that policies create their own support over time.</p><p>As a final piece, I look at legislation and non-U.S. referendums. The samples are much smaller and end earlier, but the pattern is similar to that for U.S. state-level referendums:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/q3jxhvx2sqqby4imfnjg\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/m4nffonuki6inv8awznb 130w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/jmq9jevdfgoecqlahwqj 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/gsstoslgdaxnhewfdtke 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/uek8jxab9fufuqusw6q5 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/ndhkporjjtymriq43pug 650w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/lmw4gl734bvt2fxd6qtq 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/wdfpylqzvvjnvaqfpvkw 910w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/vwfovutuyorrcv8evyn8 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/mklj2plxkd9hydyhlt4p 1170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/jCwuozHHjeoLPLemB/cjm1zunutzpqlfonkp7h 1210w\"></figure><h1>Notes Particular to the EA Community</h1><h2>Policy Changes Seem to Matter (Much) Longer than EAs Have Assumed</h2><p>As noted in my introduction, EA organizations often have to make assumptions about how long a policy intervention matters in calculating cost-effectiveness. Typically people assume that passing a policy is equivalent to having it in place for around five years more or moving the start date of the policy forward by around five years. These results suggest that this is off by more than an order of magnitude. If you look at my estimates above, the half-life of a policy is about 50 years, but even this is probably not the right statistic to use. Since the hazard rate is much lower after the first few decades, the average number of extra years a policy is in place by virtue of passing is probably at least 100 years. See the implications section of the paper for some discussion of this.</p><p>Policies are so persistent that the impacts of policy interventions might depend more on technological reasons why they could become obsolete than political ones (e.g., a policy to solve an x-risk might stop mattering because the risk is resolved otherwise).</p><h2>Neglectedness Matters</h2><p>One interesting result of the paper is that neglectedness seems is key to whether a policy change matters for a long time. For policies that can be expected to attract more interest after the referendum passes, I see less persistence. It is not a hugely dramatic effect, but it could make a difference on the margin or in extreme cases. This seems to lend some support to the EA practice of paying attention to neglectedness.</p><h2>Comparing Persistence: Can We Compare Policy to Other Social Changes?</h2><p>One of the questions I can imagine people having in this community is whether this favors policy work relative to other work. I think this is pretty unclear because we don't have comparable estimates for, e.g., the longevity of corporate policies or cultural changes. It would be reasonable to take this as an update in favor of policy work to the extent it is more persistence than expected. My best guess would be that culture is less persistent than policy (see, e.g., Table 3 of <a href=\"https://econ.cms.arts.ubc.ca/wp-content/uploads/sites/38/2022/01/nathannunn_Understanding-Cultural.pdf\">Giuliano and Nunn 2021</a>), and I'd guess similarly for corporate policy (see, e.g., Table 8 of <a href=\"https://www.stern.nyu.edu/sites/default/files/assets/documents/SSRN-id2146282.pdf\">Flammer 2015</a> and Table VIII of <a href=\"https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=fb5724dc4afbed1fce30d6a7ea4c467c8a5614f1\">Cu\u00f1at et al. 2012</a>) but have a lot of uncertainty.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4sidc99qrzj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4sidc99qrzj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\"Throughout this report, I assume that each ballot initiative has a speed-up time of four years.\" https://docs.google.com/document/d/1p7xqop2FlIF8Kw45za0NnJPwvUA70Mb1UzjijMRKRr8/edit</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnk39eu4v7l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnk39eu4v7l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\"Our highly uncertain realistic estimate is that through their work, CATF brought regulation on US coal plants forward by 18 months... In summary, we believe that by proposing RED when they did, CfRN at least brought RED forward by a year, and most likely brought it forward by 2 years, though this estimate may be conservative.\" https://www.founderspledge.com/downloads/fp-climate-change</p></div></li></ol>", "user": {"username": "zdgroff"}}, {"_id": "6iybYzX4rap3NX7nm", "title": "EAGxVirtual: Speaker announcements, timings, and other updates ", "postedAt": "2023-11-02T17:51:51.844Z", "htmlBody": "<p><a href=\"https://www.effectivealtruism.org/ea-global/events/eagxvirtual-2023\"><strong><u>EAGxVirtual</u></strong></a> is fast approaching and we\u2019re excited to share some more details about the event!</p><p>This post covers updates from the team, including dates and times, content, unique features, and \u200b\u200bdemographic data. In the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/xs8AxTodnEfg7pcSS/apply-now-eagxvirtual-17-19-november\"><u>previous post</u></a>, we covered the conference theme, reasons to attend, and reviews from the previous attendees.</p><figure class=\"image image_resized\" style=\"width:100%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/xdhaahjzzqdke7dow7on\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/vwl7db6pjl9jki8uiv50 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/btldkoeknkasrcic2p0r 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/wee0csbbqjvfqhqy63rk 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/hpv0p7vbdzdjfgsfckkc 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/a5cm5qrbodflmbszy6n2 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/elkwh59s4mqaopxwka2h 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/elasamlu3y4zon1patr3 1400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/v8oszhphjhgev1w1entz 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/eetxhl2lx2ndxwtg3udb 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/m9td7jlyakmlq4ykb5eu 1918w\"></figure><h3>Content: what to expect</h3><p>We\u2019re very excited to announce our key speakers for this event:</p><ul><li><strong>Peter Singer </strong>on the most pressing moral issues facing humanity<strong>.</strong></li><li><strong>Bruce Friedrich, President of The Good Food Institute</strong> on longtermism and alternative proteins.</li><li><strong>Carl Robichaud, Co-lead on nuclear policy grantmaking at Longview Philanthropy&nbsp;</strong>on a turning point in the story of nuclear weapons.</li><li><strong>Olga Kikou, Head of the EU Office of Compassion in World Farming&nbsp;</strong>on ending the cage age in the EU.</li><li><strong>Neel Nanda, Research Engineer at DeepMind&nbsp;</strong>on open problems in mechanistic interpretability.</li></ul><p>We are working hard on the program. Beyond the above talks (and many more talks and workshops!), you can expect office hours hosted by experts and EA orgs, fireside chats, group meetups and icebreakers, lightning talks from attendees, and unofficial satellite events.</p><p>The tentative schedule is available&nbsp;<a href=\"http://eagxvirtual.com/agenda\"><u>here</u></a> (all times are in UTC).</p><p>Please note that the schedule is subject to change. The final schedule will be available on the Swapcard app, which we aim to launch next week.</p><h3>Taking action anywhere in the world</h3><p>We have already received 600 applications from people representing over 70 countries. We welcome all who have a genuine interest in learning more or connecting, including those who are new to effective altruism. If you are a highly-engaged EA, you can make a difference by being responsive to requests from first-time attendees.&nbsp;</p><p>The map below shows the geographical distribution of the participants:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6iybYzX4rap3NX7nm/l86bd5pv09tsv11dposo\"></p><p><strong>We would love to see more applications.</strong> If you know someone who you think should attend the conference, please encourage them to apply by sending them this link:&nbsp;<a href=\"http://eagxvirtual.com/\"><u>eagxvirtual.com</u></a>&nbsp;&nbsp;</p><p><strong>The deadline for applications is 11:59 pm UTC on Thursday, 16 November.</strong></p><p><a href=\"https://www.effectivealtruism.org/ea-global/events/eagxvirtual-2023\"><strong><u>Apply here</u></strong></a><strong> if you haven\u2019t already.</strong></p><h3>Dates and times</h3><p>The conference will be taking place from 10 am UTC on Friday, November 17th, until 11:59 pm UTC on Sunday, November 19th.</p><p><strong>We don't expect you to always be online</strong> \u2013 you can be flexible with your participation! It's completely okay if you can attend only on one of the days. Recordings will be available for registered attendees, so you can watch the sessions you missed later.</p><ul><li>Friday will feature introductory-level content for participants who are relatively new to EA and a career fair on&nbsp;<a href=\"https://forum.effectivealtruism.org/s/agBJmNzGpPetYxXoy\"><u>Gather Town</u></a>.</li><li>Saturday and Sunday will have full-day schedules, starting at 7 am UTC each day.</li><li>There will be a break in the program on Sunday between 2 am and 7 am UTC.</li></ul><h3>Conference features</h3><ul><li>Our main content and networking platform for the conference is the&nbsp;<strong>Swapcard</strong>. We will share access to the app with all the attendees on November 6 and provide guidance on how to use it and get the most out of the conference.</li><li>We collaborate with EA Gather Town to make an&nbsp;<strong>always-available virtual venue</strong> for the attendees to spark more connections and unstructured discussions throughout the conference.</li><li>Extensive&nbsp;<strong>stewardship program</strong>. We will highlight ambassadors across different cause areas whom you can speak to get advice or feedback on your career plans.&nbsp;&nbsp;</li><li><strong>Evergreen discussion space</strong>: we are inviting everyone to use EA Anywhere Slack as a discussion space. No more Slacks that are abandoned immediately after the conference is over!</li></ul><h3>Ways to contribute</h3><ul><li>If you want to represent your organization at the career fair or host office hours, please,&nbsp;<a href=\"https://forms.gle/8vtmdBZFX4wgrwiE6\"><u>fill out this form</u></a>.</li><li><a href=\"https://forms.gle/fEpytEZjx9Ki9T8z6\">Apply to give a Lightning talk</a> if your conference application is approved.</li><li>If you are hosting a satellite event, let us know!</li><li>Help us spread the word \u2013 we want EAGxVirtual to be a truly global experience. You can use&nbsp;<a href=\"https://docs.google.com/document/d/e/2PACX-1vQbQaGa4yDs_sXDb9Taur4Th25ZzzjYnGV0zd_UrBhPc_PkAf3Hff4xnuBgbuKchrPPX_sQhvfbjUd2/pub\"><u>the blurbs and posters</u></a> we prepared to invite your local group members or share our social media pages (<a href=\"https://www.facebook.com/events/5910043179098453\"><u>Facebook</u></a>,&nbsp;<a href=\"https://twitter.com/EAGxVirtual\"><u>Twitter</u></a>).&nbsp;</li></ul><p>We are very excited about the event and hope to see you there!<br>&nbsp;</p>", "user": {"username": "Alex_Berezhnoy"}}, {"_id": "CwKiAt54aJjcqoQDh", "title": "Are 1-in-5 Americans familiar with EA?", "postedAt": "2023-11-02T15:07:57.321Z", "htmlBody": "<p>YouGov recently reported the&nbsp;<a href=\"https://today.yougov.com/technology/articles/47681-what-americans-think-sam-bankman-fried-sbf-cryptocurrency-effective-altruism-poll\"><u>results</u></a> of a survey (n=1000) suggesting that about \u201cone in five (22%) Americans are familiar with effective altruism.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvf3unpk2w4e\"><sup><a href=\"#fnvf3unpk2w4e\">[1]</a></sup></span></p><p><br>We think these results are exceptionally unlikely to be true. Their 22% figure is very similar to the proportion of Americans we previously found&nbsp;<i>claim</i> to have heard of effective altruism (19%)&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qQMLGqe4z95i6kJPE/how-many-people-have-heard-of-effective-altruism\"><u>in our earlier survey</u></a> (n=6130). But, after conducting appropriate checks, we estimated that much lower percentages are likely to have genuinely heard of EA<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1xzsj8b2q14\"><sup><a href=\"#fn1xzsj8b2q14\">[2]</a></sup></span>&nbsp;(2.6% after the most stringent checks, which we speculate is still likely to be somewhat inflated<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6xg2lapwrtk\"><sup><a href=\"#fn6xg2lapwrtk\">[3]</a></sup></span>).</p><h2><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/CwKiAt54aJjcqoQDh/kziviu3taoq33yuwxfcq\"><br><strong>Is it possible that these numbers have simply dramatically increased following the FTX scandal?</strong></h2><p>Fortunately, we have tested this with multiple followup surveys explicitly designed with this possibility in mind.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref43inpihu83a\"><sup><a href=\"#fn43inpihu83a\">[4]</a></sup></span>&nbsp;</p><p>In our most recent survey (conducted October 6th<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe5xwy46ix49\"><sup><a href=\"#fne5xwy46ix49\">[5]</a></sup></span>), we estimated that approximately 16% (13.0%-20.4%) of US adults would&nbsp;<i>claim&nbsp;</i>to have heard of EA. Yet, when we add in additional checks to assess whether people appear to have really heard of the term, or have a basic understanding of what it means, this estimate drops to 3% (1.7% to 4.4%), and even to approximately 1% with a more stringent level of assessment.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefa5iyntddqz6\"><sup><a href=\"#fna5iyntddqz6\">[6]</a></sup></span>&nbsp;<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/CwKiAt54aJjcqoQDh/ku8mdm4bsyqfoavvfult\"></p><p><br>These results are roughly in line with our earlier polling in May 2022, as well as additional polling we conducted between May 2022 and October 2023, and do not suggest any dramatic increase in awareness of effective altruism, although assessing small changes when base rates are already low is challenging.</p><p>We plan to continue to conduct additional surveys, which will allow us to assess possible changes from just before the trial of Sam Bankman-Fried to after the trial.</p><h2>Attitudes towards EA</h2><p>YouGov also report that respondents are, even post-FTX, overwhelmingly positive towards EA, with 81% of those who (claim to) have heard of EA approving or strongly approving of EA.</p><p>Fortunately, this positive view is broadly in line with our own findings- across different ways of breaking down who has heard of EA and different levels of stringency- which we aim to report on separately at a later date. However, our <a href=\"https://forum.effectivealtruism.org/posts/SFAMvCxnEzaQHNeSL/how-has-ftx-s-collapse-affected-public-perception-of-ea#General_Public \">earlier work</a> did find that &nbsp;awareness of FTX &nbsp;was associated with more negative attitudes towards EA.&nbsp;</p><h2><strong>Conclusions</strong></h2><p>The point of this post is not to criticise YouGov in particular. However, we do think it\u2019s worth highlighting that even highly reputable polling organizations should not be assumed to be employing all the additional checks that may be required to understand a particular question. This may apply especially in relation to niche topics like effective altruism, or more technical topics like AI, where additional nuance and checks may be required to assess understanding.</p><p><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvf3unpk2w4e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvf3unpk2w4e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Also see this <a href=\"https://forum.effectivealtruism.org/posts/cSTxmWadcdFayEhAE/tom-barnes-s-quick-takes?commentId=zXsgvqzXAGmrsXmLG\">quick take</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1xzsj8b2q14\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1xzsj8b2q14\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There are many reasons why respondents may erroneously claim knowledge of something. But simply put, one reason is that people like demonstrating their knowledge, and may err on the side of claiming to have heard of something even if they are not sure. Moreover, if the component words that make up a term are familiar, then the respondent may either mistakenly believe they&nbsp;<i>have</i> already encountered the term, or think it is sufficient that they believe they can reasonably infer what the term means from its component parts to claim awareness (even when explicitly instructed not to approach the task this way!). Some people also appear to conflate the term with others - for example, some amalgamation of inclusive fitness/reciprocal altruism appears quite common.&nbsp;</p><p>For reference, in another check we included, over 12% of people claim to have heard of the specific term \u201cGlobally neutral advocacy\u201d: A term that our research team invented, which returns no google results as a quote, and which is not recognised as a term by GPT\u2014a large-language model trained on a massive corpus of public and private data. \u201cGlobally neutral advocacy\u201d represents something of a canary for illegitimate claims of having heard of EA, in that it is composed of terms people are likely to know, and the combination of which they might reasonably think they can infer the meaning or even simply mistakenly believe they have encountered.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6xg2lapwrtk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6xg2lapwrtk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For example, it is hard to prevent a motivated respondent from googling \u201ceffective altruism\u201d in order to provide a reasonable open comment explanation of what effective altruism means. However, we have now implemented additional checks to guard against this.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn43inpihu83a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref43inpihu83a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The results of some of these have been reported earlier&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/SFAMvCxnEzaQHNeSL/how-has-ftx-s-collapse-affected-public-perception-of-ea\"><u>here</u></a>. Some of these are part of our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/XWJcAEKYmNfodjnTL/re-announcing-pulse\"><u>Pulse</u></a> survey program.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne5xwy46ix49\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe5xwy46ix49\">^</a></strong></sup></span><div class=\"footnote-content\"><p>n=1300 respondents overall, but respondents were randomly assigned to receive one of two different question formats to assess their awareness of EA. Results were post-stratified to be representative of US adults. This is a smaller sample size than we typically recommend for nationally representative sample, as this was an intermediate, 'pre-test' survey, and hence the error bars around these estimates are relatively wider than they otherwise would be. A larger N would be especially useful for more robustly determining the rates of low incidence outcomes (such as awareness of niche topics).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fna5iyntddqz6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefa5iyntddqz6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>As an additional check, we also assessed EA awareness using an alternative approach, in which a different subset of the respondents were shown the term and its definition, then asked if they knew the term only, the term and associated ideas, only the ideas, or neither the term nor the ideas. Using this design, approximately 15% claimed knowledge either of the term alone or both the term and ideas, while only 5% claimed knowlege of the term and the ideas.</p></div></li></ol>", "user": {"username": "David_Moss"}}, {"_id": "juPKAHadjqjHcmAwt", "title": "Complementary notes on Alvea [unofficial]", "postedAt": "2023-11-02T09:21:05.186Z", "htmlBody": "<p>My ex-colleagues just posted the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/3EjExF8HeJbmk4Bp4/alvea-wind-down-announcement-official\"><u>official Alvea winddown announcement</u></a> as well as<a href=\"https://forum.effectivealtruism.org/posts/d9bamQHBAwAjuKtNA/alvea-s-story-wins-and-challenges-unofficial\"><u> Kyle\u2019s reflections on our activities</u></a> over the past 1.5 years. I wanted to complement these posts with some additional comments.</p><h1>Publication of the South Africa Trial Results</h1><p>Our academic publication of the South Africa Trial results are currently under review, but you can&nbsp;<a href=\"https://docs.google.com/document/d/1UR_tAW9ljuDf1qmsXz2BVV-_Io_hugDa/edit?usp=sharing&amp;ouid=100876848639755970588&amp;rtpof=true&amp;sd=true\"><u>see the submitted manuscript here</u></a>. We also published the&nbsp;<a href=\"https://data.mendeley.com/preview/pjrs3rrnfc?a=5c463f2d-378e-4ae2-bb70-7a46787d20e7\"><u>complete data-set as well as the full study report</u></a>. While Kyle describes our efficacy results correctly as underwhelming (btw - the Janssen comparator as well), the trial made several important scientific contributions. To our knowledge this study is the first time where</p><ol><li>A naked DNA based SARS-CoV-2 booster candidate was studied in preimmunized humans (with ~80% having hybrid immunity from previous infections).</li><li>Unusually high doses of up to 8 mg DNA plasmid were administered intradermally / subcutaneously during a single visit.</li><li>A SARS-CoV-2 vaccine candidate was compared during its first Phase-1 safety study against a licensed comparator (Janssen\u2019s Ad26.COV2.S). (Sidenote: it is insane that this seems to be the only COVID-19 trial that managed to get an comparator)</li></ol><h1>Lessons learned</h1><p>In addition to Kyle's list, here are some more I'd like to point out:</p><ol><li><strong>Experience matters:</strong> Alvea matured substantially over time. From my perspective, many important internal operations mistakes could have been prevented if there had been more experience in the team earlier on. Same for research decisions and other mistakes we made. Sometimes you really want this person who has 4,000+ h of work experience and not 40h of research experience. Maybe even often.</li><li><strong>You can hire people remotely:</strong> It is very common for orgs to be hesitant to hire internationally. I myself would not have been able to work for Alvea if Grigory wouldn\u2019t have been creative about contracting and working with Employer of Records to employ ~50% of the 45 person team. I claim that organizations are missing out on top talent if they are only fishing in their country.</li><li><strong>We had kick-ass values I am still identifying with </strong>(shoutout to <a href=\"https://www.growthology.me/\">Eric</a> for shaping our company culture with those)<ol><li>Ownership: We take personal responsibility for achieving exceptional results. We draw energy from doing the \u201cimpossible.\u201d</li><li>Agility: We move with speed and flexibility in the face of constant uncertainty.</li><li>Truthseeking: We chase the truth, especially when it requires courage. We experiment to change our minds quickly.</li><li>Care: We have each other\u2019s back. Our mutual support sparks our growth as a team and our impact in the world.</li></ol></li><li><strong>Medical countermeasures matter:&nbsp;</strong>I get the vibes in EA that people are not excited about medical countermeasures / their deployment. I\u2019d like to challenge that. Ambulances, firefighters, and police take less than 15 minutes to arrive at an emergency scene. Starting a clinical trial 100d? Humanity needs an equivalent pharmaceutical preparedness and response ability to stop pandemics in their tracks. For instance, I would like to see work on a 100h response plan (in addition to the 100d CEPI timeline) to an outbreak using candidate vaccines and ultra-rapid ring-vaccination trials. So&nbsp;consider <a href=\"https://panoplialabs.org/about\"><u>PanopliaLabs</u></a> when allocating your donations this year.</li></ol><h1>Drug Development Explainer Series</h1><p>I just&nbsp;<a href=\"https://mxschons.com/2023/drug-development-explainer-series/\"><u>cross posted an explainer series on drug development</u></a> from my website I wrote up with&nbsp;<a href=\"https://www.linkedin.com/in/james-smith-47a47882/\"><u>James Smith</u></a> and&nbsp;<a href=\"https://www.linkedin.com/in/kirsangeles/\"><u>Kirsten Angeles</u></a>. I argue it captures most of the insights on the pharma landscape we made at Alvea and recommend it to everyone who wants to get a comprehensive overview of how drugs are made.</p><p>One article in the series describes some of the core cultural and operational activities that allowed Alvea to execute that quickly. For convenience, I copy paste this part here:</p><h2>Understand/verify industry best-practices.</h2><p>Alvea spent a lot of time and effort to educate themselves about how to best navigate a very ambitious drug development program. Part of what motivated the authors of this article to write it was not finding a comprehensive end-to-end overview of the essential parts of drug development that could be given to staff members without a history in drug development. Many ways get you there including: reading the GxP guidelines; reading regulatory documents of jurisdictions; investigating documents of other clinical trials; talking to a variety of consultants or doing training programs. Don\u2019t be afraid to ask dumb questionsIt turns out that you\u2019ll end up getting a non-trivial amount of contradicting evidence and resolving is on you - the final responsibility always resides with the sponsor. Combine understanding/verifying what you ought to be doing with an unwavering focus on a primary goal (\u201cSubmit our injectable Alveavax-v1.2 clinical trial application to South Africa for conditional approval before March 18th 2022, as long as GLP BA2 studies show positive results.\u201d), relentless work and quick turnarounds, and you are kind of set up for success. For many at the company it was the closest to lived operational excellence they had experienced yet.</p><h2>Determine your jurisdiction and exact specification</h2><p>While ICH provides an exceptional improvement in terms of harmonisation across countries\u2019 drug development regulation, and for vaccines in particular many refer to the WHO guidelines, countries differ in nuances that eventually matter. Alvea scanned the world and deeply considered at least 10 different options to find a jurisdiction that provided the right mix of right target population, regulatory clarity, fast timelines and reputable regulators. The top candidates for a Phase 1 study ended up being Australia, South Africa, and Canada, and the decision was made to proceed with South Africa.</p><p>Once Alvea knew the target jursidiction, processes could be optimised. The exact specification kick off all the downstream processes: animal testing (which, how many, how long, etc.), GMP material (how stable, what exact GMP specification, etc), submission criteria (timelines for review cycles, do you need to have all the data for submission or can you provide certain documents such as drug stability data later). CROs often like to claim that they can run trials anywhere, but sponsors benefit heavily from local expertise gained by past trial run with the same study sites, ethic boards, laboratories and supply depots. Going with a locally experienced CRO and having exceptionally high standards for the CRO\u2019s project manager was key to the success of the study.</p><h2>Find, evaluate, and parallelize vendors (or do it yourself if you can).</h2><p>For manufacturing, animal testing, regulatory application, trial setup, and all the respective subdomains highly specialised suppliers or contractors exist. Towards the goal of conducting the clinical trial, all of them constitute single points of failures. Alvea was very concerned about this and therefore followed a couple of strategies:&nbsp;</p><ol><li>Whenever you can reliably do it yourself, you should. Communication across orgs is harder and in most scenarios you don\u2019t know how relentless another party will ensure that they deliver the right results on time, even if it means more hours, a different process, etc. Examples include inhousing initial steps for creating starting material for manufacturing yourself or designing the clinical trial protocol.&nbsp;</li><li>If you can afford it, parallelize vendors. Alvea had to rely on contractors for manufacturing, animal testing, and parts of clinical trial setup. For all of them at least initially multiple parties were hired and thoroughly evaluated. The trial was also submitted to multiple jurisdictions.&nbsp;</li><li>Build a quality management system and audit contractors. This is not regulation slowing you down, but regulation saving your a** from future disasters.&nbsp;</li><li>Be able and willing to part from vendors. Alvea was dissatisfied with the performance of multiple CROs and even while running the trial decided to stop the collaboration and find new partners or in-house the activity.&nbsp;</li><li>Build partnerships with contractors that deliver exceptional results.&nbsp;</li></ol><h1>Finally: Shoutout to the team and funders</h1><p>There is no page where all Alveans are listed, but I still wanted to link to two pages on archive.org that acknowledge (most of) the team members that made this possible:</p><p><a href=\"https://web.archive.org/web/20220223002516/https://www.alveavax.com/\"><u>https://web.archive.org/web/20220223002516/https://www.alveavax.com/</u></a></p><p><a href=\"https://web.archive.org/web/20230118151354/https://www.alvea.bio/team/\"><u>https://web.archive.org/web/20230118151354/https://www.alvea.bio/team/</u></a></p><p>I heard again and again ex-colleagues saying \u201cI\u2019m spoiled for life - this team was special\u201d. I agree and am proud to have had the chance to collaborate with all of you. #meta-gratitudes</p><p>I also want to acknowledge our advisors and the funders who were willing to take a bet. While eventually not successful, I very much hope that the Alvea story inspires funders to go for similar projects in the future (which obviously should address the shortcomings of Alvea as a project and organization). Something truly special is unlocked when you enable talent with generous funding to obsess about ambitious ways of doing good in the world.<br>&nbsp;</p>", "user": {"username": "mschons"}}, {"_id": "hRfXKPfpCphNaZfMa", "title": "Drug Development Explainer Series", "postedAt": "2023-11-02T08:22:08.158Z", "htmlBody": "<p>This six-part series was written in collaboration with <a href=\"https://www.linkedin.com/in/kirsangeles/\">Kirsten Angeles</a> and input from <a href=\"https://www.linkedin.com/in/james-smith-47a47882/\">James Smith</a>.&nbsp;You should find it particularly useful if you don't know much about drug development yet and want to get a comprehensive overview.<br><br>Knowledge about drug development is often fragmented, expensive, and jargon-heavy. With this series we don\u2019t want to debate the pros and cons of the system\u2019s overall value; we want to explain how it works and how it came to work like this. The articles below aim to provide a comprehensive but concise introduction to all pharma\u2019s essential stakeholders, processes, and principles, connecting them to actionable insights and further resources:<br>&nbsp;</p><ol><li><a href=\"https://mxschons.com/2023/stakeholders-in-drug-development-drug-development-101-series/\">Stakeholders in Drug Development</a></li><li><a href=\"https://mxschons.com/2023/the-blueprint-of-drug-development-2-6-drug-development-explainer-series/\">The Blueprint of Drug Development</a></li><li><a href=\"https://mxschons.com/2023/origins-of-the-drug-regulation-industry-3-6-drug-development-series/\">Origins of Drug Regulation</a></li><li><a href=\"https://mxschons.com/2023/recommended-literature-and-courses-4-6-drug-development-series/\">Recommended Literature and Courses</a></li><li><a>Alvea: A Case Study of the Fastest Biotech to Go to In-Human Trials</a></li><li><a href=\"https://mxschons.com/2023/conclusions-drug-development-explainer-series-6-6/\">Conclusions</a></li></ol><p>Total read time is 45-60min.</p>", "user": {"username": "mschons"}}, {"_id": "s4PzYWyqPTrQ5DLeY", "title": "Upcoming Feedback Opportunity on Dual-Use Foundation Models", "postedAt": "2023-11-02T04:30:17.603Z", "htmlBody": "", "user": {"username": "casebash"}}, {"_id": "vXAjat7FqGF5DR9c3", "title": "Public Weights?", "postedAt": "2023-11-02T02:51:32.754Z", "htmlBody": "", "user": {"username": "Jeff_Kaufman"}}, {"_id": "hAzhyikPnLnMXweXG", "title": "Participate in the Donation Election and the first weekly theme (starting 7 November)", "postedAt": "2023-11-02T17:02:19.184Z", "htmlBody": "<p><strong>TLDR</strong>: It's <a href=\"https://forum.effectivealtruism.org/giving-portal\">Giving Season</a>! Participate in the Donation Election, start writing posts for \u201cEffective giving spotlight\u201d week (starting this Tuesday!), and more.&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/zyfnphjbz1sk71zft1ab\"><figcaption>A timeline of Giving Season on the Forum</figcaption></figure><p>There are many ways to participate:&nbsp;</p><ul><li><strong>Get involved in Giving Season events</strong><ul><li><a href=\"https://www.givingwhatwecan.org/fundraisers/ea-forum-donation-election-fund-2023\">Donate</a> to the Donation Election Fund <a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#Donate_to_the_Donation_Election_Fund\">\u2b07\ufe0f</a> to encourage discussion and participation (there are <a href=\"https://forum.effectivealtruism.org/posts/eZkApbMzBn8teQwju/donation-election-rewards\">rewards</a>)</li><li>Add candidates to the Election</li><li>Pre-vote<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7nauzyd0lf\"><sup><a href=\"#fn7nauzyd0lf\">[1]</a></sup></span>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#Explore_candidates_and_pre_vote_for_the_ones_you_think_are_particularly_promising\">\u2b07\ufe0f</a> to register your interest (pre-votes are anonymous, but we\u2019ll know how many people pre-voted for a given candidate in the Election)</li><li>Share your experience donating, fundraising, earning to give, or more <a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#Effective_Giving_Spotlight\">\u2b07\ufe0f</a> \u2014 or your uncertainties or considerations about where we should donate and how we should fundraise</li></ul></li><li><strong>Fundraise for your project&nbsp;</strong><ul><li>Explain how your project would use extra funding (particularly for Marginal Funding Week <a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#Marginal_Funding_Week\">\u2b07\ufe0f</a>), share impact analyses or retrospectives,&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/ask-me-anything\"><u>invite Forum users to ask you questions</u></a>, and see if your project should be listed as a candidate <a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#Add_candidates_to_the_Donation_Election\">\u2b07\ufe0f</a> in the Election</li></ul></li><li><strong>Explore</strong><ul><li>The&nbsp;<a href=\"https://forum.effectivealtruism.org/giving-portal\"><u>Giving portal</u></a></li><li><a href=\"https://forum.effectivealtruism.org/giving-portal#posts\"><u>Writing about effective giving</u></a></li><li>Follow the&nbsp;<a href=\"https://forum.effectivealtruism.org/giving-portal#election\"><u>Donation Election</u></a></li></ul></li></ul><p>(This post is an update to our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/x2KfyNe8oPR4dqGkf/ea-forum-plans-for-giving-season-2023\"><u>earlier announcement</u></a> about Giving Season on the Forum.)</p><h1>Giving Season &amp; weekly discussion themes</h1><p>Start preparing for discussion themes on the EA Forum:</p><figure class=\"table\" style=\"width:50px\"><table><tbody><tr><td style=\"background-color:#a2c4c9;border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px\"><strong>Theme and dates</strong></td><td style=\"background-color:#a2c4c9;border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Description</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><strong>Effective Giving Spotlight</strong></p><p><i>(7-14 November) \u2014 starting this Tuesday!</i></p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>How can we grow the amount of funding going to effective projects aimed at improving the world? We\u2019ll feature people\u2019s experiences with donating, fundraising, earning to give, etc.</p><p><a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#First_weekly_theme__Effective_Giving_Spotlight__November_7_14_\">See more details below. \u2b07\ufe0f</a></p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><strong>Marginal Funding Week</strong></p><p><i>(14-21 November)</i></p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>How would your project use extra funding?</p><p>To decide whether donating to a given project or organization is cost-effective, it\u2019s really useful to know how marginal funding would get used. We\u2019ll invite EA organizations and projects to describe how they would use extra donations \u2014 a bit like&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/7RrjXQhGgAJiDLWYR/what-does-a-marginal-grant-at-ltff-look-like-funding\"><u>this post about LTFF</u></a> \u2014 or otherwise share more about what they do.&nbsp;</p><p>We might also try to collect a summary of the key information in one post at the end of the week.&nbsp;</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><strong>Donation Debate Week</strong></p><p><i>(21-28 November)</i></p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Where should we donate (and what should we vote for in the Donation Election)?&nbsp;</p><p>Discuss which interventions and projects are most&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/cost-effectiveness-analysis\"><u>cost-effective</u></a> and how they should vote (and donate!). I\u2019m hoping to see estimates (including rough \u201cback of the envelope calculations\u201d \u2014&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/fermi-estimate\"><u>BOTECs</u></a>) and productive disagreement or identification of what the&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/crux\"><u>cruxes</u></a> that drive different conclusions are.&nbsp;</p><p>We\u2019ll also probably feature some classic writing on the topic, some relevant&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/ask-me-anything\"><u>AMAs</u></a>, and more.&nbsp;</p></td></tr></tbody></table></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/lshnrhvm8zp9bryk7z3o\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/nnzv1itbzwcffr2eqc5x 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/h6rjvjyl2mdelohro8ht 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/ltqkl82pihvy3wu8nbai 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/lmtxeszv3oogaxzyc34o 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/ad79c7eitd0szjlyt8pk 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/nt70ccvjzlef9i6bcq4d 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/kvtlpa4yfk0y8xhapjaz 2100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/amdhsuly7hbzk036da3u 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/sevpl2jhmasdh829rpxn 2700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/jxdkwqgiy2ls4hhieznh 2912w\"><figcaption>Marginal Funding Week banner</figcaption></figure><h2>First weekly theme: Effective Giving Spotlight (November 7-14)</h2><p>A lot of promising projects are funding-constrained<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4eclqgl5v67\"><sup><a href=\"#fn4eclqgl5v67\">[2]</a></sup></span>&nbsp;\u2014 they\u2019d get more done if they had more funding. \u201cEffective Giving Spotlight\u201d week will feature content on how we can grow the amount of funding going to effective projects aimed at improving the world &amp; how we can improve how we approach effective giving.&nbsp;</p><p><strong>Consider participating!&nbsp;</strong>You can write posts (or&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/8yDsenRQhNF4HEDwu/link-posting-is-an-act-of-community-service\"><u>link-posts</u></a>, including things like reviews of classic writing on the topic), comment on others\u2019 posts, or share the event. You might want to write about:&nbsp;</p><ul><li>Your experience donating, fundraising, earning to give, etc. \u2014 lessons, things you\u2019ve changed your mind on,&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/postmortems-and-retrospectives\"><u>postmortems</u></a></li><li>Thoughts on who should consider&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/earning-to-give\"><u>earning to give</u></a></li><li>Uncertainties you have about where to donate</li><li>What effective projects would be particularly useful</li><li>\u2026 or anything else related to effective giving.</li></ul><p>If you\u2019re not sure if something would be useful or relevant, please feel free to reach out to me or to the Forum team. We\u2019ll post smaller announcements with more details about the other themes.&nbsp;</p><h1>Participate in the Donation Election</h1><p>In December, Forum users<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7nauzyd0lf\"><sup><a href=\"#fn7nauzyd0lf\">[1]</a></sup></span>&nbsp;will vote on how the&nbsp;<a href=\"https://www.givingwhatwecan.org/fundraisers/ea-forum-donation-election-fund-2023\"><u>Donation Election Fund</u></a> should be allocated between different charitable projects. The fund will then be&nbsp;<a href=\"https://www.givingwhatwecan.org/fundraisers/ea-forum-donation-election-fund-2023#how-will-the-donation-election-donation-election-fund-work\"><u>designated</u></a> for the three winning candidates (proportionally to how people voted).&nbsp;</p><p>For now, you can donate to the Fund, add important candidates if they\u2019re missing, pre-vote, and start discussing.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/cd7jagtexrscuuphywzf\"><figcaption>Donate, Discuss, Vote: a screenshot from the Giving portal.&nbsp;</figcaption></figure><h2>Donate to the Donation Election Fund</h2><h3>Why donate to the Donation Election Fund? (And why&nbsp;<i>not</i> donate?)</h3><p><i>Update: there are also </i><a href=\"https://forum.effectivealtruism.org/posts/eZkApbMzBn8teQwju/donation-election-rewards\"><i>rewards</i></a><i> for donating.</i></p><p>Contributing to the&nbsp;<a href=\"https://www.givingwhatwecan.org/fundraisers/ea-forum-donation-election-fund-2023\"><u>Donation Election Fund</u></a> could be a good way to improve how Giving Season goes this year, while also directing more funding to promising projects that could productively use it.&nbsp;</p><ul><li>Money in the Donation Election Fund will be designated for&nbsp;<a href=\"https://forum.effectivealtruism.org/giving-portal#candidates\"><u>candidates</u></a> selected from&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1I-IFdkai9frIIMO6fVqOIp6PDllXG713UhnI1WuwyiQ/edit?usp=sharing\"><u>this list</u></a>,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb0xk6koi41m\"><sup><a href=\"#fnb0xk6koi41m\">[3]</a></sup></span>&nbsp;and EA Forum users will vote to determine the final winners. I don\u2019t know which projects will win in the Election, but I expect that I\u2019ll be excited to have supported the projects that do.&nbsp;<ul><li>You might also believe that the Donation Election will choose more cost-effective projects than you would, although I\u2019d personally probably donate to a fund or to a donor lottery if this were my main objective.&nbsp;</li></ul></li><li>Donating could improve the EA community\u2019s understanding of key questions related to effective giving and boost the extent to which effective giving is a core part of effective altruism. (This is my main reason for donating to the Donation Election Fund.)&nbsp;<ul><li>Many people got involved in EA discovered the community in the past couple of years, and probably missed a lot of discussions on donation choice, considerations around earning to give, and other topics in effective giving. I think Giving Season and the Donation Election could do a lot to help us gain a better understanding of these areas, and could boost the salience of effective giving, prompting people to consider donating or helping high-impact projects fundraise in other ways.&nbsp;</li><li>A larger Donation Election Fund would encourage more and better participation in these events \u2014 increasing the events\u2019 impact. People would feel more motivated to follow the discussions, share their uncertainties or disagreements, explain in greater detail what their projects do and how they would use extra money, etc.&nbsp;</li><li>Donating will also likely make the donors themselves feel more invested in Giving Season and the Donation Election, and they will probably go better as a result.&nbsp;</li></ul></li><li>You might want to donate to multiple different kinds of projects in order&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ReJT7ck9Em2xQANSz/how-we-can-make-it-easier-to-change-your-mind-about-cause\"><u>to make changing your mind about cause prioritization easier</u></a>, or maybe&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Mig4y9Duu6pzuw3H4/hedging-against-deep-and-moral-uncertainty\"><u>to hedge your donations</u></a> (although this is probably more complicated than it seems). Donating to the Donation Election Fund could be a way to decide your donations in a very different way from the process you normally use.&nbsp;</li></ul><p>I\u2019m also personally excited about the Donation Election because I\u2019m curious about what people will vote for and how the discussions will go. I think it will be a worse experiment and worse information about what people prioritize if the Donation Election Fund only contains a small amount of money.&nbsp;</p><p>It might&nbsp;<i>not</i> make sense for you to donate to the Donation Election Fund if you don\u2019t expect the winning projects to be as promising as what you would otherwise donate to and you don\u2019t think the benefit of boosting participation in Giving Season is that strong \u2014 or if you don\u2019t think you should be donating this year.&nbsp;</p><p>(Please note that donating to the Donation Election Fund doesn\u2019t boost your voting power. I should also flag that I work for CEA, which is <a href=\"https://ev.org/\">part of the organization</a> managing the Donation Election and <a href=\"https://www.givingwhatwecan.org/fundraisers/ea-forum-donation-election-fund-2023#how-will-the-donation-election-donation-election-fund-work\">receiving and distributing funds</a> via the Donation Election Fund.)</p><h3>The Online Team is matching donations to the fund, up to $1,000 per person who donates and $5,000 in total \u2014 more details</h3><p><i>Update: the match cap has been hit, so the Online Team is no longer matching new donations, although I'm still excited to see more donations!</i></p><p>We (the CEA Online Team) will&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/donation-matching\"><u>match donations</u></a> to the Donation Election Fund, with some restrictions. We won't match more than $5000 in total, and for each person who donates, we\u2019ll only match the first $1,000 of their donations. (We'll add the match when the limit is hit \u2014 and we'll note that here \u2014 or on December 1 and at the end of the Election.)</p><p>We\u2019re offering the match because we think donating to the Donation Election Fund is quite useful. A larger Donation Election Fund will likely encourage more and better discussions on donation choice \u2014 and generally cause more people to put more energy into Giving Season on the EA Forum. (Some people on the team also think that personal investment into the Donation Election Fund will make people take the election more seriously \u2014 even if the personal investments are themselves quite small.) But whether or not the Fund is large, if Forum users aren\u2019t interested in participating, this event will flop. So we\u2019ll subsidize participation by offering the match.&nbsp;</p><p>You should probably view the match as a signal that we\u2019re taking the Donation Election Fund seriously, and possibly as an opportunity to move funds designated for CEA towards projects chosen by Forum users. Whether or not this match is \u201c<a href=\"https://forum.effectivealtruism.org/posts/hQtayqi3r6bo3EPoh/the-counterfactual-validity-of-donation-matching\"><u>counterfactual</u></a>\u201d is complicated (see more in the footnote<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefi7xjumu8ez\"><sup><a href=\"#fni7xjumu8ez\">[4]</a></sup></span>).</p><p>We might also offer other (hopefully fun) incentives for donating to the Donation Election Fund.&nbsp;</p><h2>Add candidates to the Donation Election</h2><p><i>Update: The deadline has passed.</i></p><p>We\u2019ve started the election with some pre-made&nbsp;<a href=\"https://forum.effectivealtruism.org/giving-portal#candidates\"><u>candidates</u></a>, based on our guess about the projects people will want to start (pre-)voting for. But&nbsp;<strong>until November 21, you can also add other candidates</strong> if you think some important ones are missing and they\u2019re on&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1I-IFdkai9frIIMO6fVqOIp6PDllXG713UhnI1WuwyiQ/edit?usp=sharing\"><u>this list</u></a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoiqbbzidawd\"><sup><a href=\"#fnoiqbbzidawd\">[5]</a></sup></span>&nbsp;(Adding candidates earlier is probably better.)&nbsp;</p><p>To do that, you will need to submit a form and fundraise at least $50 for the candidate.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5f5a73tx8r9\"><sup><a href=\"#fn5f5a73tx8r9\">[6]</a></sup></span>&nbsp;The&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLScnIBGnpqQUNTXqeh-DjLKPZ3b4-Cs9vBnvd6Wh5r_7oiX92Q/viewform\"><u>form</u></a> will ask you for your email, a description of why you think the project is promising, and some other information. After you\u2019ve submitted the form, we\u2019ll set the candidate up on the technical side<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftkhpg97l3o9\"><sup><a href=\"#fntkhpg97l3o9\">[7]</a></sup></span>&nbsp;and reach out to you to remind you to add the $50 required (this should take at most 1-2 business days). We will only add the candidate to the Donation Election after the $50 goes through. As long as you submit a form by the end of the day on November 21 (<a href=\"https://en.wikipedia.org/wiki/Anywhere_on_Earth\"><u>anywhere on Earth</u></a>) and add at least $50 to the candidate by the deadline we specify when we reach out, we\u2019ll add the candidate to the election.&nbsp;</p><h2>Explore candidates and pre-vote for the ones you think are particularly promising</h2><p>If you had a Forum account as of 22 October 2023,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvmhtauqcep\"><sup><a href=\"#fnvmhtauqcep\">[8]</a></sup></span>&nbsp;you can already start pre-voting for candidates you\u2019re likely to vote for (pre-votes are anonymous, don\u2019t turn into real votes, and you can change them at any time). Pre-voting will change the default ordering of candidates on the&nbsp;<a href=\"https://forum.effectivealtruism.org/giving-portal\"><u>Giving Portal</u></a> and will show other people which candidates are likely to be popular \u2014 which can prompt useful discussions and surface important disagreements.&nbsp;&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/wzkrlpgsgvctye7itxni\"><figcaption>A screenshot from the Giving portal</figcaption></figure><h2>Start discussing where we should donate, what we should vote for, and other questions related to effective giving</h2><p>Voting opens in less than a month, and the first theme (<a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#First_weekly_theme__Effective_Giving_Spotlight__November_7_14_\">Effective Giving Spotlight</a>) starts in less than a week. Consider writing posts related to the Donation Election or the <a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#Giving_Season___weekly_discussion_themes\">Giving Season themes</a>.&nbsp;</p><p>You can also explore&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/donation-election-2023\"><u>what other people are writing about the Donation Election</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/effective-giving\"><u>effective giving</u></a>, or the&nbsp;<a href=\"https://forum.effectivealtruism.org/giving-portal#candidates\"><u>candidates in the election</u></a>.</p><h2>Voting opens December 1 \u2014 more information</h2><figure class=\"table\"><table><tbody><tr><td style=\"background-color:#c3807a;border:2px solid hsl(0, 0%, 0%)\"><a href=\"https://forum.effectivealtruism.org/giving-portal\"><strong>Voting is open! See more in the Giving portal</strong></a></td></tr></tbody></table></figure><p>Anyone who had an account as of October 22, 2023 will be able to vote (everyone else can participate in other ways), and voting will open on December 1 and close on December 15 (2023, the end of the day&nbsp;<a href=\"https://en.wikipedia.org/wiki/Anywhere_on_Earth\"><u>anywhere on Earth</u></a>).</p><p>More details:</p><p><strong>Who can vote &amp; voting norms</strong></p><ul><li>Any Forum users who had an account as of October 22, 2023 can vote (voting functionality won't work for you if your account is newer than that).&nbsp;</li><li>No donations are required to vote.&nbsp;</li><li><strong>If someone has multiple accounts, they can only vote once.</strong> We will be checking for suspicious voting patterns, and will likely void suspicious votes (and possibly involve the moderation team and take further action if we believe there\u2019s manipulation).&nbsp;</li></ul><p><strong>Voting system</strong></p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/dYhKfsNuQX2sznfxe/donation-election-how-voting-will-work\"><strong>The voting system we're using</strong></a><strong> is a weighted version of ranked-choice voting. </strong><s>We\u2019ll finalize the system in the next couple of weeks (and announce it on the Forum). See some discussion&nbsp;</s><a href=\"https://forum.effectivealtruism.org/posts/iJSYZJJrLMigJsBeK/lizka-s-shortform?commentId=nmfz9ySdD5WBAgqPE\"><s><u>here</u></s></a><s>.</s>&nbsp;</li><li>Everyone who can vote has the same amount of voting power. You will only be able to vote for listed&nbsp;<a href=\"https://forum.effectivealtruism.org/giving-portal#candidates\"><u>candidates</u></a> in the Donation Election.</li></ul><p><strong>How to vote</strong></p><ul><li>Donations to the fundraisers for specific candidates do&nbsp;<strong>not</strong> count as votes for that candidate.&nbsp;</li><li>Voting will open on December 1 and close December 15 (2023, the end of the day&nbsp;<a href=\"https://en.wikipedia.org/wiki/Anywhere_on_Earth\"><u>anywhere on Earth</u></a>).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefadbfz19fx9u\"><sup><a href=\"#fnadbfz19fx9u\">[10]</a></sup></span>&nbsp;We\u2019ll post an announcement about it on the Forum, share the fact that voting has opened in the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/bi9WWR58m45GJG7bc/forum-digest-reminder-that-it-exists-and-request-for\"><u>EA Forum Digest</u></a>, and we\u2019ll likely feature it in a banner on the Frontpage.&nbsp;<ul><li>You can also sign up to get notified when voting opens by clicking \u201cget notified\u201d&nbsp;<a href=\"https://forum.effectivealtruism.org/giving-portal#election\"><u>here</u></a> (you\u2019ll need to be logged in).</li></ul></li></ul><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hAzhyikPnLnMXweXG/hkkpd6pffo0e5snb7qlk\"><figcaption>Click on \"Get notified when voting opens\"</figcaption></figure><h1>Share your feedback and how you plan on participating (if at all)</h1><p>Thanks to everyone whose work has gone into launching this!&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7nauzyd0lf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7nauzyd0lf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Only Forum users whose accounts are older than October 22, 2023 will be able to vote or pre-vote. Others can donate to projects directly (or to the Donation Election Fund), add candidates, and participate in the discussion.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4eclqgl5v67\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4eclqgl5v67\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There are new projects,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/PAco5oG579k2qzrh9/ltff-and-eaif-are-unusually-funding-constrained-right-now\"><u>funds that could make good grants if they had more funding</u></a>, and projects that could scale to do a lot more if more people donated to them.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb0xk6koi41m\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb0xk6koi41m\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Some projects might get added to this list.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fni7xjumu8ez\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefi7xjumu8ez\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Whether or not this match is \u201ccounterfactual\u201d depends on how you define the phrase. We wouldn\u2019t donate these funds to [insert winners of the election here] if we weren\u2019t running this match \u2014 so in that sense it\u2019s counterfactual (unlike&nbsp;<a href=\"https://www.benkuhn.net/matching-results/\"><u>some examples here</u></a>). But if you\u2019re wondering if, by donating $20, you\u2019re actually counterfactually causing $40 in total to be added to the Donation Election Fund, the answer is more complicated. Most importantly, the match cap might get reached without you (i.e. maybe 5 people will donate $1,000 each at the last moment, in which case they\u2019d exhaust whatever is left of the match whether or not you donate).&nbsp;</p><p>The funds for the match are coming from a line item on the Online Team\u2019s budget for prizes and similar projects focused on boosting discussions on the Forum. We didn\u2019t run prizes this year (although we might next year), and if we don\u2019t use the funding by the end of the year, it will probably be merged into CEA\u2019s general funding for next year.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnoiqbbzidawd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefoiqbbzidawd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We are restricting candidates to this list for technical/logistical reasons. If the projects you think are most cost-effective aren't here, I'd love to see posts encouraging readers to donate to them directly!</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5f5a73tx8r9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5f5a73tx8r9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We\u2019re requiring this to avoid a proliferation of candidates people are not interested in voting for \u2014 having a lot of candidates could get pretty confusing.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntkhpg97l3o9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftkhpg97l3o9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Candidates will be set up as a special kind of Giving What We Can&nbsp;<a href=\"https://www.givingwhatwecan.org/fundraisers\"><u>fundraiser</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvmhtauqcep\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvmhtauqcep\">^</a></strong></sup></span><div class=\"footnote-content\"><p>As with voting, we\u2019re adding this restriction to avoid voting manipulation, and also to avoid misleading people into thinking they\u2019re eligible to vote in the Donation Election if they have newer accounts.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fni3gb3j8df0e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefi3gb3j8df0e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This will probably either be determined by pre-votes or by the amount of money in the fundraiser. We\u2019ll make it clear before we open voting, and I don\u2019t currently think we\u2019ll need to use this.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnadbfz19fx9u\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefadbfz19fx9u\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;If the Donation Election is not capable of running as planned (e.g. due to fraud or technical failures), we reserve the right to modify, suspend, or terminate the election. If that happens, we will post an announcement on the EA Forum and work to distribute all donations made to the Donation Election Fund in a manner consistent with the Donation Election description, but at our discretion.</p></div></li></ol>", "user": {"username": "Lizka"}}, {"_id": "2uKYBr9ruYKDxbKxj", "title": "Tien procent club Utrecht 6 november", "postedAt": "2023-11-01T22:28:29.821Z", "htmlBody": "<p>De tien procent club is organising thier first event in Utrecht!\nThe event will take place on monday november 6th in De Kargadoor</p>\n<p>A vegan meal will be served, the meal is included in your ticket.</p>\n", "user": {"username": "Marisela Berkelmans"}}, {"_id": "D6oFCMniy259tPcwq", "title": "Unlocking Typhoid Fever Hotspots with Bacteriophage Surveillance", "postedAt": "2023-11-01T22:21:42.186Z", "htmlBody": "<p><strong>TL;DR:</strong> This proposal advocates using cost-effective bacteriophage surveillance to detect typhoid hotspots in water sources. By studying diverse communities in Plateau State, the research aims to correlate phage prevalence with typhoid burden, focusing on areas with varying population densities. The study is essential for targeted public health interventions in regions with limited access to clean water and sanitation facilities. This project is part of my undergraduate student's project.&nbsp;</p><p>I would like your views to strengthen the idea and make the study much more robust to make maximum impact.&nbsp;</p><h1><strong>Introduction:</strong>&nbsp;</h1><p>Typhoid fever is a global health concern, predominantly affecting low- and middle-income countries with limited access to clean water and sanitation. With approximately 11 million reported cases annually, it leads to over 100,000 fatalities. The emergence of drug-resistant strains of<i> Salmonella typhi</i> intensifies the need for new strategies to combat the spread of this disease. We propose using bacteriophages, viruses that target bacteria, as a cost-effective tool for identifying typhoid hotspots in surface waters.</p><p>Historically, the utilization of routine typhoid fever vaccination has been quite restricted, even in regions where the disease is prevalent. Recently, the<a href=\"World Health Organization. Typhoid vaccines: WHO position paper, March 2018 \u2013  Recommendations. Vaccine [Internet]. 2019;37(2):214\u20136. Available from:  https://www.sciencedirect.com/science/article/pii/S0264410X18304912\"> World Health Organization (WHO) has recommended the incorporation of typhoid conjugate vaccines (TCV) in countries facing the highest incidence </a>of typhoid or a significant presence of antimicrobial-resistant <i>S. typhi</i>. However, the inadequate availability of data concerning the burden of typhoid fever in many at-risk nations presents a significant obstacle to the inclusion of TCV in national immunization initiatives.</p><p>Prior research has demonstrated the value of environmental surveillance in identifying areas with a high risk of enteric fever transmission. Although it is well known that contaminated water plays a significant role in typhoid transmission, identifying the causative organisms, particularly <i>S. typhi</i>, has proven difficult when using traditional culture methods on water and other environmental samples&nbsp;</p><h1><strong>Research Focus:</strong>&nbsp;</h1><p>This study aims to detect <i>Salmonella Typhi </i>bacteriophages (phages) in diverse Plateau State communities, focusing on areas with varying typhoid incidence and population densities. We will investigate the relationship between phage prevalence and typhoid burden, considering abiotic factors and human-animal interactions with water sources.</p><h1><strong>Significance:</strong></h1><ol><li><strong>Public Health Impact:</strong> Identifying typhoid hotspots is vital for targeted interventions, potentially saving lives and reducing the disease's burden.</li><li><strong>Antimicrobial Resistance:</strong> In the face of drug-resistant strains, this research contributes to combating antimicrobial resistance by pinpointing areas at risk.</li><li><strong>Data Scarcity:</strong> This study bridges the data gap on typhoid hotspots in at-risk regions, aiding public health efforts.</li><li><strong>Global Alignment:</strong> The study aligns with global health initiatives, emphasizing its importance in combating typhoid fever.</li></ol><p><strong>Methodology:</strong></p><ol><li><strong>Sample Collection:</strong> &nbsp;We plan to collect 165 water samples from rivers, tap water, and wells in the North, Central, and South Plateau Senatorial Zones.</li><li><strong>Data Collection:</strong> We also plan to collect Abiotic factors, water pH, temperature, sewage pipes, open drain water, and human-animal interactions documented.</li><li><strong>Sample Collection and Filtrate Preparation:</strong> Water samples shall be filtered and stored for phage detection.</li><li><strong>Bacteriophage Isolation:</strong> Using a cost-effective method involving bacteriophage screening.</li><li><strong>Data Analysis:</strong> Phage titers and abiotic factors shall be analyzed.</li></ol><p><strong>Tractability:</strong></p><ul><li><strong>Cost-Effective Technology:</strong> This study employs a cost-effective method for detecting bacteriophages, accessible to a wide range of communities.</li><li><strong>Scientific Advancements:</strong> Recent advances in bacteriophage research and genomic sequencing enhance the approach's practicality.</li><li><strong>Data Collection and Analysis:</strong> The methodology can be readily replicated in similar settings, enhancing tractability.</li><li><strong>Public Health Interventions:</strong> Identifying Typhoid Fever hotspots can have a direct impact on reducing the prevalence of typhoid fever in high-risk areas.</li></ul><p><strong>Neglectedness:</strong></p><ul><li><strong>Limited Research:</strong> Limited focus on phage-based surveillance in typhoid-endemic regions highlights the neglected aspect of this issue.</li><li><strong>Public Health Priorities:</strong> Typhoid fever competes for resources with other diseases, leading to its under-prioritization.</li><li><strong>Understudied Areas:</strong> Many typhoid-endemic regions, especially in low- and middle-income countries, lack comprehensive environmental surveillance studies.</li></ul><p><strong>Conclusion:</strong> This research addresses the critical issue of identifying typhoid hotspots using cost-effective bacteriophage surveillance, presenting an innovative solution for global catastrophic risk reduction and pandemic preparedness in the context of typhoid fever. We hope to share the results as they come in. We are seeking ways to make for maximum impact so feel free to make comments to strengthen this.&nbsp;</p>", "user": {"username": "emmannaemeka"}}, {"_id": "XoKvZgdzPugFdFdxC", "title": "My thoughts on the social response to AI risk", "postedAt": "2023-11-01T21:27:01.196Z", "htmlBody": "", "user": {"username": "Matthew_Barnett"}}, {"_id": "z5CxpW6T8YAbjYihy", "title": "Anyone tried to monetize a hobby with the intent of ETG? \n", "postedAt": "2023-11-01T16:09:54.428Z", "htmlBody": "<p>Looking to hear others experience on monetizing a hobby to donate earnings and how they've kept with it!</p><p>I was looking for ways to combine my love for gaming and charity. Back in 2020, I streamed games on Twitch for a few months to get donations for Malaria Consortium. Over the months, I only got a $5.</p><p>Then, I decided to do a Holiday fundraiser by streaming a scary video game for a week and sent it to all my friends and family. I raised around $650! It was amazing and got emotional during the last stream of it.</p><p>I continued streaming after that but I got burnt out with lack of viewers/money donations. It was then I preferred to game by myself and not to an audience.&nbsp;</p><p>After that, I blogged about video games on a website for a few months last year that pays in cryptocurrency and have made around $65 worth in USD. I'm thinking about taking it up again as I stopped due to life/work bandwidth.&nbsp;</p>", "user": {"username": "warrenjordan"}}, {"_id": "xErbWBCvijwsct6JN", "title": "Center for AI Safety\u2019s Bi-Weekly Reading and Learning", "postedAt": "2023-11-02T15:15:53.790Z", "htmlBody": "<p>Join the <a href=\"https://safe.ai\">Center for AI Safety\u2019s (CAIS)</a> for a <strong>bi-weekly</strong> Reading and Learning (RAL) event. These meetings serve as a platform to dissect and explore recent publications from the Machine Learning community. Our discussions encompass an array of publications, including papers emerging from CAIS, as well as ones curated from outside institutions. We invite individuals external to CAIS to present their work, fostering a dynamic exchange of ideas and perspectives. To minimize the pressure when preparing the upcoming talk, we won\u2019t ask speakers to prepare slides beforehand (but you are more than welcome to do so).</p><p>Subscribe to all RAL events using this <a href=\"https://calendar.google.com/calendar/u/0?cid=Y18yZmJjZmQ4Zjc1MjlmYzBjYjk3OWE3YjhlMGE3YmQzZTI0N2JiNTAwYmY5YmY3MzU0YzYzMzAyZDc4YWU3ODAwQGdyb3VwLmNhbGVuZGFyLmdvb2dsZS5jb20\">link</a>.</p><h2>RAL Outline</h2><ul><li>Part I: Presentation and Short Questions (40 min)</li><li>Part II: Long Questions and Discussion (20 min)</li></ul><h2>Become a Speaker</h2><p>We welcome people from universities and the industry to present their work at RAL. We are interested in topics ranging from general AI safety to adversarial robustness, privacy, fairness, interpretability, language models, vision models, multimodality, etc. If you are interested in sharing your work with CAIS and other people, please fill out the following Google Form.</p><p><a href=\"https://forms.gle/UKbeV4obcsXZtLYa9\">Sign Up for RAL</a></p><h2>Past Presentations</h2><h3><a href=\"https://arxiv.org/abs/2307.15043\">Universal and Transferable Adversarial Attacks on Aligned Language Models</a> by <a href=\"https://andyzoujm.github.io/\">Andy Zou</a></h3><h3><a href=\"https://arxiv.org/abs/2308.14752\">AI Deception: A Survey of Examples, Risks, and Potential Solutions</a> by <a href=\"https://www.lesswrong.com/users/aidan-o-gara\">Aidan O\u2019Gara</a></h3><h2>Contact</h2><p>If you have any questions, feel free to contact us at long@safe.ai</p>", "user": {"username": "Center for AI Safety"}}, {"_id": "KAzSt4w57yHmdvFwS", "title": "#169 \u2013  On whether cash transfers cause economic growth, and keeping theft to acceptable levels (Paul Niehaus on the 80,000 Hours Podcast)", "postedAt": "2023-11-01T15:20:23.633Z", "htmlBody": "<p>We just published an interview: Paul Niehaus on whether cash transfers cause economic growth and keeping theft to acceptable levels. <a href=\"https://open.spotify.com/episode/4yKwimUbdzPeg9MWTuJOoI?si=8cb3fa94e4b04b20\">Listen on Spotify</a> or <a href=\"https://80000hours.org/podcast/episodes/paul-niehaus-cash-transfers/\">click through</a> for other audio options, the transcript, and related links. Below are the episode summary and some key excerpts.</p><h2><strong>Episode summary</strong></h2><blockquote><p><i>One of our earliest supporters and a dear friend of mine, Mark Lampert, once said to me, \u201cThe way I think about it is, imagine that this money were already in the hands of people living in poverty. If I could, would I want to tax it and then use it to finance other projects that I think would benefit them?\u201d</i></p><p><i>I think that\u2019s an interesting thought experiment \u2014 and a good one \u2014 to say, \u201cAre there cases in which I think that\u2019s justifiable?\u201d</i></p><p>- Paul Niehaus</p></blockquote><p>In today\u2019s episode, host Luisa Rodriguez interviews Paul Niehaus \u2014 cofounder of <a href=\"https://www.givedirectly.org/\">GiveDirectly</a> \u2014 on the case for giving unconditional cash to the world\u2019s poorest households.</p><p>They cover:</p><ul><li>The empirical evidence on whether giving cash directly can drive meaningful economic growth</li><li>How the impacts of GiveDirectly compare to USAID employment programmes</li><li>GiveDirectly vs GiveWell\u2019s top-recommended charities</li><li>How long-term guaranteed income affects people\u2019s risk-taking and investments</li><li>Whether recipients prefer getting lump sums or monthly instalments</li><li>How GiveDirectly tackles cases of fraud and theft</li><li>The case for universal basic income, and GiveDirectly\u2019s UBI studies in Kenya, Malawi, and Liberia</li><li>The political viability of UBI</li><li>Plenty more</li></ul><p><i>Producer and editor: Keiran Harris</i><br><i>Audio Engineering Lead: Ben Cordell</i><br><i>Technical editing: Dominic Armstrong and Milo McGuire</i><br><i>Additional content editing: Katy Moore and Luisa Rodriguez</i><br><i>Transcriptions: Katy Moore</i></p><h2><strong>Highlights</strong></h2><h3><strong>Giving cash should be the standard which other poverty programmes are compared to</strong></h3><blockquote><p><strong>Luisa Rodriguez:</strong> Let\u2019s talk about the empirical evidence a bit more. Unconditional cash transfers have been studied empirically many times in a range of contexts, as you\u2019ve noted. Can you summarise what we know about the return on investment recipients get?</p><p><strong>Paul Niehaus:</strong> There are certainly cases you can pick out where a large share of the money got invested in some sort of asset and business got better, and the return on capital in that business was maybe 20% per year, or 30%, or even up to 50%. So there are certainly cases like that, where in a very narrow financial sense, we can say that we\u2019ve learned from this that people have access to high-return investments, and it\u2019s great that we\u2019re able to finance them.</p><p>But I would actually push back a little bit about that instinct of trying to kind of put everything into one number \u2014 because I think once you get into the reality of how diverse life is, it\u2019s too complicated for that.</p><p><strong>Luisa Rodriguez:</strong> Yeah, it must be frustrating. It seems like there are all these randomised control trials on a bunch of interventions like this, including unconditional cash transfers. And many of them, in some ways, have it easy. They\u2019re tracking the effect of bed nets on malaria, and it\u2019s pretty easy to measure malaria \u2014 at least relative to how difficult it seems to be to measure how people spend money, when there are dozens, hundreds, in some sense an infinite number of potential options for them. And how do you measure the benefit they get from that?</p><p><strong>Paul Niehaus:</strong> And there are all of these knock-on things, like you see impacts on mental health, or recently there have been papers that found <a href=\"https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1004000\">reductions in rates of suicide</a> or <a href=\"https://voxdev.org/topic/health-education/cash-transfers-reduce-adult-and-child-mortality-rates-low-and-middle-income-countries\">rates of all-cause mortality</a>. So do you also think about that? Is that a separate thing that I need to value separately, or is that the result of all these other things that I was just talking about? So I think it\u2019s really hard.</p><p>And actually, I think that the way economists have traditionally thought about it, which to me makes more sense, is to say we\u2019re actually going to think of this as like the <a href=\"https://en.wikipedia.org/wiki/Num%C3%A9raire\">num\u00e9raire</a>, right? The value to giving someone a dollar is a dollar. And then we\u2019re going to use that as a reference point in a comparison to other things \u2014 and say, relative to that, how great is a bed net, or deworming, or any of these other things we want to think about?</p><p><strong>Luisa Rodriguez:</strong> I see. And at least part of the thinking behind GiveDirectly is that, in surprisingly many cases, the value of giving someone something that you\u2019ve decided in advance might be best for them, that costs a dollar, might actually be less than a dollar \u2014 because people have such different needs, and it\u2019s hard for us living in other countries to predict them.</p><p><strong>Paul Niehaus:</strong> That\u2019s the thing we want to watch out for. And the issue there is that in the aid or philanthropic system, there isn\u2019t any built-in feedback loop that prevents us from doing that, right? So think about it: By comparison to a commercial business, if I\u2019m trying to sell something for a dollar, and people value it at less than a dollar, then nobody buys it \u2014 and I learn quickly that this isn\u2019t working; I don\u2019t have <a href=\"https://en.wikipedia.org/wiki/Product/market_fit\">product-market fit</a>. In the philanthropic world, if it costs you a dollar to produce something, and people value it at less than a dollar, they\u2019re going to say, \u201cOh, thank you. This is better than nothing.\u201d You don\u2019t get that feedback loop of people telling you that there\u2019s something better that you could have done with your money. So we have to be very intentional about building that in.</p></blockquote><h3><strong>Why cash dramatically overperformed a USAID unemployment programme</strong></h3><blockquote><p><strong>Luisa Rodriguez:</strong> I guess I\u2019m still inclined to be surprised and impressed, given that this is a best-in-class programme. It\u2019s the best way USAID knows how to improve underemployment, and still giving cash directly is better. What is it about the way the sausage gets made that makes this not super surprising to people working on this on the ground?</p><p><strong>Paul Niehaus:</strong> I think there are three things to highlight. One is the absence of automatic feedback that I mentioned earlier: I think it\u2019s fundamentally difficult \u2014 when you\u2019re doing philanthropic stuff, and you don\u2019t have customers that can tell you this isn\u2019t that great actually \u2014 to learn.</p><p>Two is all of the complexity that comes with being a big multinational bureaucratic organisation. And that\u2019s obviously not unique to USAID, or to any big organisation, but there\u2019s all sorts of stuff and baggage in terms of decision making that comes with that.</p><p>I think the third thing is that there are different categories of problems that it\u2019s helpful to distinguish, and those are what economists would call private good versus public good problems. So me getting a job and earning a living is a very relevant problem to me, and I\u2019m going to do what I can to do that. And I may not do it \u2014 I may face constraints that make it hard, or I may make mistakes or not understand certain things, all of that sort of thing \u2014 but we should generally have the expectation that people are going to be pretty motivated to try to figure that out on their own, at least to some extent. So that\u2019s the sort of problem where to come in as an outsider and have a really disproportionate impact is going to be relatively hard.</p><p>Then there are problems like preventing everybody in my community from getting malaria. I have a motivation to not get sick myself, but I really don\u2019t have a strong motivation, or perhaps strong-enough motivation, to solve everybody else\u2019s problem for them. Or even taking it a step further, doing the innovation, the R&amp;D, to discover a cure for malaria, a way to prevent it at scale. That\u2019s a public good issue, where one person\u2019s actions have much broader ramifications. So that\u2019s a place where you\u2019d expect, coming in as an outsider, maybe we can actually have a really disproportionate impact \u2014 because no one person on their own is going to be as motivated to solve the problem.</p><p>And so to me, these employment and livelihood-generation problems are private good problems, so I think that\u2019s generally going to be a tough area for us to make outsized progress relative to public goods issues. And I think that\u2019s why, when you look at the things that GiveWell has recommended over the years historically that <a href=\"https://www.givewell.org/giving101/Funding-the-Right-Program\">they think do better than cash transfers</a>, most of them have this public health, infectious disease flavour to them.</p></blockquote><h3><strong>Giving cash can boost economic growth</strong></h3><blockquote><p><strong>Luisa Rodriguez:</strong> So the headline result is that for every one dollar spent on cash transfers, there\u2019s a 2.5 multiplier effect. Can you explain exactly what a \u201cmultiplier\u201d means here?</p><p><strong>Paul Niehaus:</strong> So it\u2019s a very simple concept. All it means is if we measure GDP \u2014 essentially the aggregate output of this economy \u2014 how much did GDP go up for every dollar that we gave people? So a 1 would be people spent the money and nothing else happened. A 2.5 here means that for every dollar that we put in, economic output in the region expanded by two and a half dollars.</p><p><strong>Luisa Rodriguez:</strong> OK. And again, I studied a bit of economics, but not loads of economics. So if I try to make it really concrete, it\u2019s like you give someone $1, and the fact that they then spend that dollar ends up somehow generating $2.50 in the economy because of something like it enables someone to do a bit more work, which then allows them to create more goods, and those goods have value and are purchased? And over time you get basically $2.50 of extra value?</p><p>Can you help me make intuitive the number 2.5? Is that really big? Is that moderate? I guess I just don\u2019t have a good reference class for how quickly economies grow, and whether this is an impressive result or not.</p><p><strong>Paul Niehaus:</strong> Yeah, I think there are probably two ways to think about that. One is relative to other estimates of the multiplier effects, public spending or stimulus spending. In rich countries, like in the US, for example, the range of estimates that people typically are centred around are in the 1.5\u20131.9 or 2 range. So this is bigger than that, but not wildly bigger than the stimulus effects that we think federal spending in the US can have if it is well designed.</p><p>The other way to think about it is just as a donor. If you\u2019re thinking about the consequences of this, then, if you buy the analysis, you think that in this setting a dollar had 2.5 the impacts that you thought it would have had otherwise, without taking that into account.</p></blockquote><h3><strong>Fraud in DRC</strong></h3><blockquote><p><strong>Luisa Rodriguez:</strong> Let\u2019s talk about what happened in the Democratic Republic of the Congo, which is GiveDirectly\u2019s biggest fraud case to date. Can you give just the basic outline?</p><p><strong>Paul Niehaus:</strong> Sure. And let me first just say <a href=\"https://www.givedirectly.org/drc-case-2023/\">we\u2019ve written very publicly about this</a>, and so I\u2019ll talk about what we think we\u2019ve learned from it, how we think we should interpret it in the big picture. But it is absolutely gut-wrenching to lose that much money. It\u2019s something where we feel like we failed here, and that we owe an apology to folks involved: to the recipients, and to our partners in this project. So we\u2019ve done that and done that very publicly. And I think that\u2019s important.</p><p>In terms of what it means for the mission and the model overall, we feel like there are things we have to learn and adjust. It\u2019s going to be less than a percent of all the money that we delivered in 2022. So we accept that this is a chess game that never ends, that we\u2019re still playing it, and that we have to make adjustments. But fundamentally, I don\u2019t think it shakes our confidence in our ability to keep doing what we do.</p><p>So with that having been said, what happened specifically in the DRC is \u2014 and as you can imagine, there are multiple layers to this \u2014 but the first and fundamental thing is that we have a control procedure that we usually impose, which says that when we give a SIM card to recipients, which is what they need to then be able to start receiving transfers, they need to go and register that with a mobile money agent themselves. That\u2019s an important piece of our control process. And we made an exception to that in the DRC, because the DRC is a tough place to work, and we thought this would have meant long travel and potentially some risks for recipients. So we decided to give our field staff permission to register those SIM cards themselves in the name of the recipients and then distribute them.</p><p>We\u2019re balancing risk and return there, in terms of thinking about how this is going to impact recipients and what the risk would be. And the core lesson from this is going to be that we got that wrong, and have to change that this time around. The issue this created was that in this case, some of our staff were able to register SIMs in the name of recipients, but then keep them, and instead give recipients other SIMs that were useless because they were not registered in our system to receive transfers. And so with those SIMs in hand, staff are then able to go and collude with mobile money agents to withdraw cash from the accounts that belong to the recipients and get it out themselves.</p><p>There are then multiple other accountability layers in the system that could have caught this \u2014 and that did eventually catch it, but that took too long, in part because the people who were stealing money at that point of sale were able to recruit accomplices in those other layers. So on net this went on for about four months, from the end of August 2022 to January of 2023, before we caught it. The design question for us now is, of course we want to catch it sooner than that if something like this ever happened again.</p><p><strong>Luisa Rodriguez:</strong> How was it finally resolved? Who figured it out?</p><p><strong>Paul Niehaus:</strong> For some safeguarding reasons, I can\u2019t get too much into the details of what\u2019s happened and what is happening. But what I can say is that eventually we did hear about it. There\u2019s since been wide-ranging turnover \u2014 some because people\u2019s contracts have just expired, but in some cases because we\u2019ve let folks go and have referred some of them to the authorities for investigation, prosecution.</p><p>And then there\u2019s a bunch of process stuff that we\u2019re going to be doing differently. First and most important, of course, is not allowing this registration exception for SIM cards, or at least not unless there are additional controls in place. Also to improve the firewalling between the different parts of the organisation, to make it harder for people to identify and build a relationship with the people that are holding them accountable. And then third, there\u2019s some stuff again that I mentioned that we can do in terms of automated data checks so that this stuff becomes visible to anyone, even if you\u2019re not in the DRC, quickly, if something\u2019s not happening.</p></blockquote><h3><strong>Objections to universal basic income</strong></h3><blockquote><p><strong>Luisa Rodriguez:</strong> I think the most common ones I\u2019ve heard are that it might disincentivise work among recipients. Is that something you\u2019re worried about? It sounds like it\u2019s not something you\u2019ve seen in other programmes, but maybe it is the kind of thing that you might worry about when there is that long-term commitment?</p><p><strong>Paul Niehaus:</strong> Right. So I think \u201cdisincentivised\u201d is, in fact, not quite the right concept \u2014 in the sense that there are programmes where your eligibility for benefits tapers out as you get better off. Like the <a href=\"https://en.wikipedia.org/wiki/Earned_income_tax_credit\">EITC</a> [earned income tax credit] in the US, for example: there\u2019s a phase out where if you\u2019re earning above a certain level, you no longer get it, so there\u2019s a very mechanical disincentive to earn more there. And that\u2019s not what we\u2019re talking about with UBI, because the whole idea is that it is unconditional on anything. It\u2019s like, no matter what, you\u2019re going to get this money. I think what people actually have in mind here is not an incentive per se, but more that maybe you\u2019re just less motivated if some of your basic needs are already met to go out and earn more \u2014 so it\u2019s more of an impact that income or wealth has on your personal motivation, which is a somewhat different thing.</p><p>That\u2019s also very important because I think \u2014 and I think the data also say \u2014 that those sorts of income effects are actually probably very different in different contexts. So in low-income countries in particular, people are extremely poor \u2014 so getting somebody from below the poverty line to $2.15 a day is by no means going to make them feel content with their life, or as if there\u2019s nothing else that they wish they could have. And on top of that, one of the barriers for many of them to work is just access to the capital, to the tools they need. And so there\u2019s this additional channel where having access to some money might actually enable me to invest in ways that would make it worth working more. So what we\u2019ve actually seen in the data on most cash transfer programmes in low-income countries has been either not much change in how much people work, or a bit of an increase \u2014 which is contrary, I think, to what a lot of people expected or were worried about.</p><p><strong>Luisa Rodriguez:</strong> Cool. Yeah, I do feel persuaded in particular about this. If you\u2019re taking someone just slightly above the poverty line, that feels pretty different to giving them some high monthly allowance that means they can not only meet all of their basic needs, but have all the luxuries they want. So yeah, I can see how someone <i>just</i> meeting their basic needs would not necessarily be discouraged from doing other types of productive work. Before we move on and talk more about the study, I\u2019m curious if you have a guess at what the best objection to UBI is?</p><p><strong>Paul Niehaus:</strong> I think it depends a bit on where we\u2019re talking about. In rich countries, if you do the math on something like UBI, it\u2019s very expensive. And I think that in rich countries we have the administrative machinery to target benefits to people who are disabled or who have hit something that comes as a shock \u2014 like health insurance, things like that \u2014 in ways that poorer countries have less capacity to do. So if you do this sort of technocratic math, it\u2019s not as clear to me that in some of the richer countries this would be the best way to spend a dollar to help people living in extreme poverty.</p><p>In poorer countries, it may be that some degree of targeting or means testing or something like that is a good idea, but the capacity to do that is more limited. So I think there\u2019s a stronger case for, maybe it\u2019s not universal everywhere, but in large regions, for example, everybody getting some degree of basic income. Something like that.</p><p>But the other thing to emphasise is that I don\u2019t think that UBI is fundamentally a technocratic idea, right? It\u2019s not like someone sat down and wrote out the optimisation problem of how can we do the most good for the world, and UBI popped out as the solution to that, with a given budget. It\u2019s more like this would be a different politics and a different ethics of what we think a just society might look like, and something that people might be willing to get behind and therefore to spend or to give more than they would otherwise. So in some sense, I think that\u2019s the real question about UBI, and it\u2019s not one that experimental evidence of impact is going to directly answer \u2014 although it could contribute to some extent.</p><p><strong>Luisa Rodriguez:</strong> Right. So that politics thing, the idea there is basically that currently we\u2019re not thinking of these basic needs as a universal right the way we think of other things. Like, it seems like most people in most countries agree that no one should be able to physically harm you: that\u2019s a right you have. And here I guess another example is that some countries think healthcare is a universal right, others don\u2019t. But UBI is basically seeing if people can get behind the idea that people have the basic right to have their basic needs met, and the way of operationalising that is giving people enough resources to get at least those very basic needs met. Is that the basic idea? Am I getting that right?</p><p><strong>Paul Niehaus:</strong> That\u2019s it. Look at how political communication works, right? Nobody gets up and says, \u201cGreat news! I have this complicated plan. We\u2019ve really thought it through carefully. It\u2019s got these five different parts. Healthcare is going to work this way. And all this stuff, this is a great vision for what a fair society is going to look like.\u201d It just doesn\u2019t work that way. But potentially you could say, \u201cI have this vision, which is that everybody should get enough to meet their basic needs,\u201d and people might support that and be willing to get behind that. So the idea that this might be a politically viable narrative \u2014 even if it\u2019s not dollar-for-dollar the absolutely ideal, optimal way to allocate a given budget \u2014 I think that\u2019s very much an important part of the question about UBI.</p></blockquote>", "user": {"username": "80000_Hours"}}, {"_id": "BM5Buz5ktxPSY4as8", "title": "Chinese scientists acknowledge xrisk & call for international regulatory body [Linkpost] ", "postedAt": "2023-11-01T13:28:44.312Z", "htmlBody": "", "user": {"username": "Akash"}}, {"_id": "oJ6jAhbbPADGASpLn", "title": "Forecasting Questions: What do you want to predict on AI?", "postedAt": "2023-11-01T13:16:20.798Z", "htmlBody": "<p>Lots of people are saying that AI regulation is great or terrible, but I am not seeing a lot of concrete forecasts.</p><p>What would a world where regulation goes really well look like?<br>What would a world where regulation goes really badly look like?<br>What other things would you like forecasted in general?</p>", "user": {"username": "nathan"}}, {"_id": "3EjExF8HeJbmk4Bp4", "title": "Alvea Wind Down Announcement [Official]", "postedAt": "2023-11-01T12:39:33.088Z", "htmlBody": "<p>After careful consideration, we made the difficult decision to wind Alvea down and return our remaining funds to investors. This decision was the result of many months of experimentation and analysis regarding Alvea\u2019s strategy, path to impact, and commercial potential, which ultimately led us to the conclusion that Alvea\u2019s overall prospects were not sufficiently compelling to justify the requisite investment of money, time, and energy over the coming years.</p><p>Alvea started in late 2021 as a moonshot to rapidly develop and deploy a room temperature-stable DNA vaccine candidate against the Omicron wave of COVID-19, and we soon became <a href=\"https://www.alvea.bio/alvea-set-the-record-for-the-fastest-startup-to-take-a-new-drug-into-a-phase-1-clinical-trial-from-founding-to-first-in-human-date/\"><u>the fastest startup to take a new drug from founding to a Phase 1 clinical trial</u></a>. However, we decided to discontinue our lead candidate during the follow-up period of the trial as the case for large-scale impact weakened amidst the evolving pandemic landscape. Over the following year, we explored different applications of our accelerated drug development capabilities, from ambitious in-house R&amp;D programs focused on potentially transformative technologies, to a partnerships program that made our rapid development platform available to other biotechs. Ultimately, we were unable to find a path forward that was suited to the current funding environment and sufficiently compelling to warrant forging ahead.</p><p>We are nonetheless excited about some of the vaccine technologies that Alvea developed, and are working to transfer these to partner companies who are well-positioned to continue their development. As part of the wind down process, we also helped start <a href=\"https://www.panoplialabs.org/\"><u>Panoplia Laboratories</u></a>, a new nonprofit focused on early-stage R&amp;D for impact-focused medical countermeasures.</p><p>While sad to be closing our doors, we are grateful to have had the chance to take this shot. We are especially thankful to the ~50 people who worked at Alvea since its inception, many of whom left other jobs on short notice, moved across oceans, dropped other projects, embraced crazy hours, confronted challenges of brain-melting difficulty, and much more, all in the service of Alvea\u2019s mission, and all with the utmost care, competence, and professionalism. We are also immensely grateful to our investors and donors, who not only provided generous financial support of our work, but were true partners in our quest to navigate both the commercial and impact-oriented aspects of our mission. Our advisors and supporters from the broader biosecurity, effective altruism, global health, and biotech communities played another vital role in shaping our path, and we\u2019re grateful to all of them.</p><p>Despite Alvea\u2019s ultimate dissolution, we remain optimistic about future efforts of a similar flavor. We hope to see many other bold projects that refuse to accept the status quo, and that take a real shot at solving the most important problems in the world. We plan to work on more of these projects ourselves down the line, and in the meantime are excited to support others in this work however we can.</p>", "user": {"username": "kyle_fish"}}, {"_id": "j2TreuRZT9mBFEMEs", "title": "The Bletchley Declaration on AI Safety", "postedAt": "2023-11-01T11:44:42.565Z", "htmlBody": "<p>The Bletchley Declaration was just released at the At AI Safety Summit.&nbsp;</p><p>Tl;dr: The declaration underscores the transformative potential and risks of AI. Countries, including major global powers, commit to harnessing AI's benefits while addressing its challenges, especially the dangers of advanced \"frontier\" AI models. Emphasizing international collaboration, the declaration calls for inclusive, human-centric, and responsible AI development. Participants advocate for transparency, research, and shared understanding of AI safety risks, with plans to reconvene in 2024.</p><p>Full text:</p><hr><p>Artificial Intelligence (AI) presents enormous global opportunities: it has the potential to transform and enhance human wellbeing, peace and prosperity. To realise this, we affirm that, for the good of all, AI should be designed, developed, deployed, and used, in a manner that is safe, in such a way as to be human-centric, trustworthy and responsible. We welcome the international community\u2019s efforts so far to cooperate on AI to promote inclusive economic growth, sustainable development and innovation, to protect human rights and fundamental freedoms, and to foster public trust and confidence in AI systems to fully realise their potential.&nbsp;</p><p>AI systems are already deployed across many domains of daily life including housing, employment, transport, education, health, accessibility, and justice, and their use is likely to increase. We recognise that this is therefore a unique moment to act and affirm the need for the safe development of AI and for the transformative opportunities of AI to be used for good and for all, in an inclusive manner in our countries and globally. This includes for public services such as health and education, food security, in science, clean energy, biodiversity, and climate, to realise the enjoyment of human rights, and to strengthen efforts towards the achievement of the United Nations Sustainable Development Goals.</p><p>Alongside these opportunities, AI also poses significant risks, including in those domains of daily life. To that end, we welcome relevant international efforts to examine and address the potential impact of AI systems in existing fora and other relevant initiatives, and the recognition that the protection of human rights, transparency and explainability, fairness, accountability, regulation, safety, appropriate human oversight, ethics, bias mitigation, privacy and data protection needs to be addressed. We also note the potential for unforeseen risks stemming from the capability to manipulate content or generate deceptive content. All of these issues are critically important and we affirm the necessity and urgency of addressing them.&nbsp;</p><p>Particular safety risks arise at the \u2018frontier\u2019 of AI, understood as being those highly capable general-purpose AI models, including foundation models, that could perform a wide variety of tasks - as well as relevant specific narrow AI that could exhibit capabilities that cause harm - which match or exceed the capabilities present in today\u2019s most advanced models. Substantial risks may arise from potential intentional misuse or unintended issues of control relating to alignment with human intent. These issues are in part because those capabilities are not fully understood and are therefore hard to predict. We are especially concerned by such risks in domains such as cybersecurity and biotechnology, as well as where frontier AI systems may amplify risks such as disinformation. There is potential for serious, even catastrophic, harm, either deliberate or unintentional, stemming from the most significant capabilities of these AI models. Given the rapid and uncertain rate of change of AI, and in the context of the acceleration of investment in technology, we affirm that deepening our understanding of these potential risks and of actions to address them is especially urgent.</p><p>Many risks arising from AI are inherently international in nature, and so are best addressed through international cooperation. We resolve to work together in an inclusive manner to ensure human-centric, trustworthy and responsible AI that is safe, and supports the good of all through existing international fora and other relevant initiatives, to promote cooperation to address the broad range of risks posed by AI. In doing so,&nbsp;we recognise&nbsp;that countries should consider the importance of a pro-innovation and proportionate governance&nbsp;and regulatory&nbsp;approach that maximises the benefits and takes into account the risks associated with AI.&nbsp;This could include making, where appropriate, classifications and categorisations of risk based on national circumstances and applicable legal frameworks.&nbsp;We also note the relevance of cooperation, where appropriate, on approaches such as common principles and&nbsp;codes&nbsp;of conduct. With regard to the specific risks most likely found in relation to frontier AI, we resolve to intensify and sustain our cooperation, and broaden it with further countries, to identify, understand and as appropriate act, through existing international fora and other relevant initiatives, including future international AI Safety Summits.</p><p>All actors have a role to play in ensuring the safety of AI: nations, international fora and other initiatives, companies, civil society and academia will need to work together. Noting the importance of inclusive AI and bridging the digital divide, we reaffirm that international collaboration should endeavour to engage and involve a broad range of partners as appropriate, and welcome development-orientated approaches and policies that could help developing countries strengthen AI capacity building and leverage the enabling role of AI to support sustainable growth and address the development gap.</p><p>We affirm that, whilst safety must be considered across the AI lifecycle, actors developing frontier AI capabilities, in particular those AI systems which are unusually powerful and potentially harmful, have a particularly strong responsibility for ensuring the safety of these AI systems, including through systems for safety testing, through evaluations, and by other appropriate measures. We encourage all relevant actors to provide context-appropriate transparency and accountability on their plans to measure, monitor and mitigate potentially harmful capabilities and the associated effects that may emerge, in particular to prevent misuse and issues of control, and the amplification of other risks.</p><p>In the context of our cooperation, and to inform action at the national and international levels, our agenda for addressing frontier AI risk will focus on:</p><ul><li>identifying AI safety risks of shared concern, building a shared scientific and evidence-based understanding of these risks, and sustaining that understanding as capabilities continue to increase, in the context of a wider global approach to understanding the impact of AI in our societies.</li><li>building respective risk-based policies across our countries to ensure safety in light of such risks, collaborating as appropriate while recognising our approaches may differ based on national circumstances and applicable legal frameworks. This includes, alongside increased transparency by private actors developing frontier AI capabilities, appropriate evaluation metrics, tools for safety testing, and developing relevant public sector capability and scientific research.</li></ul><p>In furtherance of this agenda, we resolve to support an internationally inclusive network of scientific research on frontier AI safety that encompasses and complements existing and new multilateral, plurilateral and bilateral collaboration, including through existing international fora and other relevant initiatives, to facilitate the provision of the best science available for policy making and the public good.</p><p>In recognition of the transformative positive potential of AI, and as part of ensuring wider international cooperation on AI, we resolve to sustain an inclusive global dialogue that engages existing international fora and other relevant initiatives and contributes in an open manner to broader international discussions, and to continue research on frontier AI safety to ensure that the benefits of the technology can be harnessed responsibly for good and for all. We look forward to meeting again in 2024.</p><h2><strong>Agreement</strong></h2><p>The countries represented were:</p><ul><li>Australia</li><li>Brazil</li><li>Canada</li><li>Chile</li><li>China</li><li>European Union</li><li>France</li><li>Germany</li><li>India</li><li>Indonesia</li><li>Ireland</li><li>Israel</li><li>Italy</li><li>Japan</li><li>Kenya</li><li>Kingdom of Saudi Arabia</li><li>Netherlands</li><li>Nigeria</li><li>The Philippines</li><li>Republic of Korea</li><li>Rwanda</li><li>Singapore</li><li>Spain</li><li>Switzerland</li><li>T\u00fcrkiye</li><li>Ukraine</li><li>United Arab Emirates</li><li>United Kingdom of Great Britain and Northern Ireland</li><li>United States of America</li></ul><p>References to \u2018governments\u2019 and \u2018countries\u2019 include international organisations acting in accordance with their legislative or executive competences.</p>", "user": {"username": "HaukeHillebrandt"}}, {"_id": "T7sQesoxtEB9S3QTB", "title": "[Event] Metaculus Presents: Transformative Science at Startup Speed", "postedAt": "2023-11-01T03:01:47.611Z", "htmlBody": "<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/kbkuvys257ejdcdwzulr\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/q7gw5vv5qo5jmjvasx2g 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/csqulthmcw7iwl0ll63i 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/jgrvwpbfdflza9jl6aky 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/ublveuradla2rls8stkv 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/tsr5wvcugb3x0hssc1wt 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/x2hgeferjtvkh7icun30 1920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/w1voy7xjmoygb7oupte9 2240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/u2s8i4f4clcxwameimcd 2560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/k52fyuu8dhqgfeceybsu 2880w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/zaodiqcvqflkraziwzxn 3114w\"><br>&nbsp;</p><p><strong>Join Metaculus Friday, November 3rd, 12:00-1:00pm PT for a series of technical talks addressing life science challenges via Focused Research Organizations (FROs).</strong></p><p><a href=\"https://www.eventbrite.com/e/metaculus-presents-transformative-science-at-startup-speed-tickets-745683618777?aff=oddtdtcreator\"><strong>Register for free tickets to this online event here.&nbsp;</strong></a></p><p>FROs are standalone nonprofits organized like startups that are designed to accelerate scientific research for the public good. This is an opportunity to learn from and pose questions to research teams behind ambitious FRO proposals featured in Metaculus\u2019s <a href=\"https://www.metaculus.com/tournament/fro-casting/\">\u2018FRO-Casting\u2019 Tournament</a>.</p><h3>Teams will present on the following proposals:</h3><h3><a href=\"https://www.metaculus.com/project/2638/\">Characterizing Antibodies Through Open Science</a></h3><p><i>\"Many antibodies that scientists purchase from commercial manufacturers to conduct their research do not work as advertised, because most have never been validated properly. This project brings together the public and private sectors to conduct independent, third-party testing of commercial antibody manufacturers\u2019 catalogs and publish the results in the public domain, such that no scientist ever uses an ineffective antibody again.\"</i></p><p>-\ufeff <a href=\"https://ycharos.com/team/\">Chetan Raina</a>, YCharOS</p><p>- <a href=\"https://moleculargenetics.utoronto.ca/faculty/aled-edwards\">Dr. Aled Edwards</a>, Structural Genomics Consortium</p><p>- <a href=\"https://www.mcgill.ca/neuro/peter-scott-mcpherson-phd\">Dr. Peter McPherson</a>, McGill University</p><p>-\ufeff <a href=\"https://www.mcgill.ca/petermcphersonlab/antibody-characterization-group\">Dr. Carl Laflamme</a>, Montreal Neurological Institute-Hospital</p><p>&nbsp;</p><h3><a href=\"https://www.metaculus.com/project/2475/\">Reducing Antibiotic Resistance In Aquaculture</a></h3><p><i>\"\ufeffResearch and engineering to reverse antibiotic resistance in aquatic bacteria, through the application of a well-validated CRISPR-based genetic system, can help catalyze safer, more sustainable land-based aquaculture as a nutritious and affordable food source.\"</i></p><p>- <a href=\"https://biology.ucsd.edu/research/faculty/ebier\">Dr. Ethan Bier</a>, UCSD</p><p>&nbsp;</p><h3><a href=\"https://www.metaculus.com/project/2645/\">Measuring Complete Neuronal Input-Output Functions</a></h3><p><i>\"\ufeffMeasuring how neurons integrate their inputs and respond to them is key to understanding the impressive and complex behavior of humans and animals. However, a complete measurement of neuronal Input-Output Functions (IOFs) has not been achieved in any animal. Undertaking the complete measurement of IOFs in the model system C. elegans could refine critical methods and discover principles that will generalize across neuroscience.\"</i></p><p>- <a href=\"http://koerding.com/\">Dr.Konrad Kording</a>, University of Pennsylvania</p><p>&nbsp;</p><p>The FRO-Casting Tournament is a joint pilot project by Metaculus and the <a href=\"https://fas.org/publication/fas-fro-metaculus/\">Federation of American Scientists</a> that harnesses forecasting to identify promising research directions and deliver feedback.</p><p><a href=\"https://www.eventbrite.com/e/metaculus-presents-transformative-science-at-startup-speed-tickets-745683618777?aff=oddtdtcreator\"><strong>Get your free ticket</strong></a></p>", "user": {"username": "christianM"}}, {"_id": "acutkuaQQYfpeaxhR", "title": "Computational Approaches to Pathogen Detection", "postedAt": "2023-11-01T00:36:56.690Z", "htmlBody": "", "user": {"username": "Jeff_Kaufman"}}, {"_id": "tWZPWpsbhpJuf7Z4Q", "title": "Thoughts on the AI Safety Summit company policy requests and responses", "postedAt": "2023-10-31T23:54:11.419Z", "htmlBody": "", "user": {"username": "So8res"}}, {"_id": "K9LGQAkydedM97ogj", "title": "Metaculus Presents: Transformative Science at Startup Speed", "postedAt": "2023-10-31T21:12:19.122Z", "htmlBody": "<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/mdwkugjzgln0qjnoto1z\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/q7gw5vv5qo5jmjvasx2g 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/csqulthmcw7iwl0ll63i 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/jgrvwpbfdflza9jl6aky 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/ublveuradla2rls8stkv 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/tsr5wvcugb3x0hssc1wt 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/x2hgeferjtvkh7icun30 1920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/w1voy7xjmoygb7oupte9 2240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/u2s8i4f4clcxwameimcd 2560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/k52fyuu8dhqgfeceybsu 2880w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/K9LGQAkydedM97ogj/zaodiqcvqflkraziwzxn 3114w\"><br>&nbsp;</p><p><strong>Join Metaculus Friday, November 3rd, 12:00-1:00pm PT for a series of technical talks addressing life science challenges via Focused Research Organizations (FROs).</strong></p><p><a href=\"https://www.eventbrite.com/e/metaculus-presents-transformative-science-at-startup-speed-tickets-745683618777?aff=oddtdtcreator\"><strong>Register for free tickets to this online event here.&nbsp;</strong></a></p><p>FROs are standalone nonprofits organized like startups that are designed to accelerate scientific research for the public good. This is an opportunity to learn from and pose questions to research teams behind ambitious FRO proposals featured in Metaculus\u2019s <a href=\"https://www.metaculus.com/tournament/fro-casting/\">\u2018FRO-Casting\u2019 Tournament</a>.</p><h3>Teams will present on the following proposals:</h3><h3><a href=\"https://www.metaculus.com/project/2638/\">Characterizing Antibodies Through Open Science</a></h3><p><i>\"Many antibodies that scientists purchase from commercial manufacturers to conduct their research do not work as advertised, because most have never been validated properly. This project brings together the public and private sectors to conduct independent, third-party testing of commercial antibody manufacturers\u2019 catalogs and publish the results in the public domain, such that no scientist ever uses an ineffective antibody again.\"</i></p><p>-\ufeff <a href=\"https://ycharos.com/team/\">Chetan Raina</a>, YCharOS</p><p>- <a href=\"https://moleculargenetics.utoronto.ca/faculty/aled-edwards\">Dr. Aled Edwards</a>, Structural Genomics Consortium</p><p>- <a href=\"https://www.mcgill.ca/neuro/peter-scott-mcpherson-phd\">Dr. Peter McPherson</a>, McGill University</p><p>-\ufeff <a href=\"https://www.mcgill.ca/petermcphersonlab/antibody-characterization-group\">Dr. Carl Laflamme</a>, Montreal Neurological Institute-Hospital</p><p>&nbsp;</p><h3><a href=\"https://www.metaculus.com/project/2475/\">Reducing Antibiotic Resistance In Aquaculture</a></h3><p><i>\"\ufeffResearch and engineering to reverse antibiotic resistance in aquatic bacteria, through the application of a well-validated CRISPR-based genetic system, can help catalyze safer, more sustainable land-based aquaculture as a nutritious and affordable food source.\"</i></p><p>- <a href=\"https://biology.ucsd.edu/research/faculty/ebier\">Dr. Ethan Bier</a>, UCSD</p><p>&nbsp;</p><h3><a href=\"https://www.metaculus.com/project/2645/\">Measuring Complete Neuronal Input-Output Functions</a></h3><p><i>\"\ufeffMeasuring how neurons integrate their inputs and respond to them is key to understanding the impressive and complex behavior of humans and animals. However, a complete measurement of neuronal Input-Output Functions (IOFs) has not been achieved in any animal. Undertaking the complete measurement of IOFs in the model system C. elegans could refine critical methods and discover principles that will generalize across neuroscience.\"</i></p><p>- <a href=\"http://koerding.com/\">Dr.Konrad Kording</a>, University of Pennsylvania</p><p>&nbsp;</p><p>The FRO-Casting Tournament is a joint pilot project by Metaculus and the <a href=\"https://fas.org/publication/fas-fro-metaculus/\">Federation of American Scientists</a> that harnesses forecasting to identify promising research directions and deliver feedback.</p><p><a href=\"https://www.eventbrite.com/e/metaculus-presents-transformative-science-at-startup-speed-tickets-745683618777?aff=oddtdtcreator\"><strong>Get your free ticket</strong></a></p>", "user": {"username": "christianM"}}, {"_id": "SH3Es2Q9XuYPMhA5H", "title": "AISN #25:\nWhite House Executive Order on AI, UK AI Safety Summit, and Progress on Voluntary Evaluations of AI Risks", "postedAt": "2023-10-31T19:24:18.927Z", "htmlBody": "<p>Welcome to the AI Safety Newsletter by the <a href=\"https://www.safe.ai/\">Center for AI Safety</a>. We discuss developments in AI and AI safety. No technical background required.</p><p>Subscribe <a href=\"https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916\">here</a> to receive future versions.</p><p>Listen to the AI Safety Newsletter for free on <a href=\"https://spotify.link/E6lHa1ij2Cb\">Spotify.</a></p><hr><h2>White House Executive Order on AI</h2><p>While Congress has not voted on significant AI legislation this year, the White House has left their mark on AI policy. In June, they secured voluntary commitments on safety from leading AI companies. Now, the White House has released a <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/\">new executive order on AI</a>. It addresses a wide range of issues, and specifically targets catastrophic AI risks such as cyberattacks and biological weapons.&nbsp;</p><p><strong>Companies must disclose large training runs.</strong> Under the executive order, companies that intend to train \u201cdual-use foundation models\u201d using significantly more computing power than GPT-4 must take several precautions. First, they must notify the White House before training begins. Then, they\u2019ll need to report on their cybersecurity measures taken to prevent theft of model weights. Finally, the results of any red teaming and risk evaluations of their trained AI system must be shared with the White House.&nbsp;</p><p>This does not mean that companies will need to adopt <i>sufficient</i> or <i>effective</i> safety practices, but it does provide visibility for the White House on the processes of AI development and risk management. To improve the science of AI risk management, NIST has been tasked with developing further guidelines.&nbsp;</p><p><strong>Compute clusters must register and report on foreign actors.</strong> AIs are often trained on compute clusters, which are networks of interconnected computer chips that can be rented by third parties. The executive order requires large computing clusters to be reported to the Department of Commerce. Further, to provide transparency on AI development by foreign actors, any foreign customer of a US-based cloud compute service will need to verify their identity to the US government. Some have <a href=\"https://arxiv.org/abs/2310.13625\">argued</a> that these know-your-customer requirements should extend to domestic customers as well.&nbsp;</p><figure class=\"image\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb9210d3-c7e7-4099-81a1-273cb2df29cb_1468x1224.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb9210d3-c7e7-4099-81a1-273cb2df29cb_1468x1224.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb9210d3-c7e7-4099-81a1-273cb2df29cb_1468x1224.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb9210d3-c7e7-4099-81a1-273cb2df29cb_1468x1224.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdb9210d3-c7e7-4099-81a1-273cb2df29cb_1468x1224.png 1456w\"><figcaption><i>A new poll shows that US voters largely support the new executive order. </i><a href=\"https://theaipi.org/poll-biden-ai-executive-order-10-30/\"><i>Source</i></a><i>.</i></figcaption></figure><p><strong>Requiring safety precautions at biology labs. </strong>One nightmare scenario for biosecurity researchers is that someone could submit an order to a biology lab for the synthesized DNA of a dangerous pathogen. Some labs screen incoming orders and refuse to synthesize dangerous pathogens, but other labs do not.&nbsp;</p><p>To encourage adoption of this basic precaution, the executive order requires any research funded by the federal government to exclusively use labs that screen out dangerous compounds before synthesis. This may help combat the growing concern that <a href=\"https://arxiv.org/abs/2310.18233\">AI could help rogue actors build biological weapons</a>. The executive order also tasks several federal agencies with analyzing biosecurity risks from AI, including by producing a report that specifically focuses on the biorisks of open source AI systems.&nbsp;</p><p><strong>Building federal AI capacity.</strong> The executive order supports many efforts to help the US government use AI safely and effectively. Several agencies have been tasked with using AI to find and fix security vulnerabilities in government software. The National Science Foundation has been directed to create a pilot version of the <a href=\"https://www.nsf.gov/cise/national-ai.jsp\">National AI Research Resource</a>, which would provide computing resources for AI researchers outside of academia.&nbsp;</p><p>The <a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/\">full text of the executive order</a> addresses many other issues, including privacy, watermarking of AI-generated content, AI-related patent and copyright questions , pathways to immigration for AI experts, and protections for civil rights. Right now, the White House is still in the stages of gathering information and developing best practices around AI. But this executive order will lead to meaningful progress on both of those fronts, and signals a clear commitment to address growing AI risks.&nbsp;</p><h2>Kicking Off The UK AI Safety Summit</h2><p>Today marks the first day of the UK\u2019s AI Safety Summit, where politicians, academics, and members of industry and civil society (including the Center for AI Safety\u2019s Director Dan Hendrycks) will meet to discuss AI risks and how governments can help mitigate them. Before the summit began, the UK government announced several new initiatives, including the creation of an international expert panel to assess AI risks and a new research institute for AI safety.&nbsp;</p><p><strong>Rishi Sunak\u2019s speech on AI extinction risk.</strong> UK Prime Minister Rishi Sunak <a href=\"https://www.youtube.com/watch?v=emrHKQPQYQ4\">delivered a speech</a> on the opportunities and catastrophic risks posed by AI. Building on <a href=\"https://www.gov.uk/government/publications/frontier-ai-capabilities-and-risks-discussion-paper\">recent papers</a> from the British government, he noted that \u201cAI could make it easier to build chemical or biological weapons.\u201d Then he directly quoted the <a href=\"https://www.safe.ai/statement-on-ai-risk\">CAIS expert statement on AI extinction risk</a>, and said, \u201cthere is even the risk that humanity could lose control of AI completely.\u201d</p><p>The speech also addressed doubts about AI risks. \u201cThere is a real debate about this,\u201d Sunak said, and \u201csome experts think it will never happen at all. But however uncertain and unlikely these risks are, if they did manifest themselves, the consequences would be incredibly serious.\u201d Therefore, \u201cleaders have a responsibility to take them seriously, and to act.\u201d</p><figure class=\"image\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccfe1acf-cd8c-4beb-a5b4-e89f8bb00313_2710x1580.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccfe1acf-cd8c-4beb-a5b4-e89f8bb00313_2710x1580.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccfe1acf-cd8c-4beb-a5b4-e89f8bb00313_2710x1580.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccfe1acf-cd8c-4beb-a5b4-e89f8bb00313_2710x1580.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fccfe1acf-cd8c-4beb-a5b4-e89f8bb00313_2710x1580.png 1456w\"><figcaption><i>UK Prime Minister Rishi Sunak </i><a href=\"https://www.youtube.com/watch?v=emrHKQPQYQ4\"><i>delivered a speech</i></a><i> ahead of the AI Safety Summit.</i></figcaption></figure><p><strong>The UK will propose an international expert panel on AI.</strong> The <a href=\"https://en.wikipedia.org/wiki/Intergovernmental_Panel_on_Climate_Change\">UN Intergovernmental Panel on Climate Change (IPCC)</a> summarizes scientific research on climate change to help inform policymaking efforts on the topic. <a href=\"https://carnegieendowment.org/2023/10/27/summary-proposal-for-international-panel-on-artificial-intelligence-ai-safety-ipais-pub-90862\">Many have suggested</a> that a similar body of scientific experts could help establish consensus on AI risks. Sunak announced in his speech that the UK will propose a \u201cglobal expert panel nominated by the countries and organisations attending [the AI Safety Summit] to publish a State of AI Science report.\u201d</p><p><strong>New AI Safety Institute to evaluate AI risks. </strong>Sunak also announced \u201cthe world\u2019s first AI Safety Institute\u201d which will \u201ccarefully examine, evaluate, and test new types of AI so that we understand what each new model is capable of.\u201d Few details have been provided so far, but it\u2019s possible that this could serve as a \u201c<a href=\"https://arxiv.org/abs/2307.04699\">CERN for AI</a>\u201d allowing countries to work together on AI and AI safety research, thereby mitigating coordination challenges and enabling centralized oversight of AI development.&nbsp;</p><h2>Progress on Voluntary Evaluations of AI Risks</h2><p>One common recommendation from those concerned about AI risks is that companies should commit to evaluating and mitigating risks before releasing new AI systems. This recommendation has recently received support from the United States, United Kingdom, and G7 alliance.&nbsp;</p><p>The White House\u2019s <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/\">new executive order on AI</a> requires any company developing a dual-use foundation model to \u201cnotify the federal government when training the model, and [they] must share the results of all red-team safety tests.\u201d To help develop better AI risk management techniques, the executive order also directs NIST to develop rigorous standards for red-teaming that companies could adopt.&nbsp;</p><p>At the request of the United Kingdom, six leading AI companies have published <a href=\"https://www.aisafetysummit.gov.uk/policy-updates/#company-policies\">descriptions of their risk assessment and mitigation plans</a>. There are <a href=\"http://lcfi.ac.uk/news-and-events/news/2023/oct/31/ai-safety-policies/\">important differences between the policies</a>. For example, Meta argues that open sourcing their models will improve safety, while OpenAI, DeepMind, and others prefer to monitor use of their models to <a href=\"https://arxiv.org/abs/2310.03693\">prevent misuse</a>. But each company has provided their safety policy, and the UK has summarized the policies in a <a href=\"https://assets.publishing.service.gov.uk/media/653aabbd80884d000df71bdc/emerging-processes-frontier-ai-safety.pdf\">review of existing AI safety policies</a>.&nbsp;</p><p>Finally, the G7 has released a <a href=\"https://www.mofa.go.jp/files/100573473.pdf\">code of conduct</a> that AI companies can voluntarily choose to follow. The policy would, among other things, require companies to evaluate catastrophic risks posed by their systems, invest in cybersecurity, and detect and prevent misuse during deployment.&nbsp;</p><p>These voluntary commitments are no substitute for binding legal requirements to ensure safety in AI development. Moreover, a commitment to assess and mitigate risks does not ensure that the risks will be eliminated or reduced below a manageable threshold. Further work is needed to create binding commitments that prevent companies from releasing unsafe AI systems.&nbsp;</p><figure class=\"image\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d9ef11d-b248-4dd0-b7f4-ac53c9f60d8b_1456x846.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d9ef11d-b248-4dd0-b7f4-ac53c9f60d8b_1456x846.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d9ef11d-b248-4dd0-b7f4-ac53c9f60d8b_1456x846.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d9ef11d-b248-4dd0-b7f4-ac53c9f60d8b_1456x846.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d9ef11d-b248-4dd0-b7f4-ac53c9f60d8b_1456x846.png 1456w\"><figcaption><i>A recent poll of UK voters suggests that most would support stronger action by the government to prevent the development of superhuman AI systems. </i><a href=\"https://twitter.com/_andreamiotti/status/1717244197999116453/photo/4\"><i>Source</i></a><i>.&nbsp;</i></figcaption></figure><p>Finally, it is important to note that even the ideal safety evaluations would not eliminate AI risks. Militaries might deliberately design AI systems to be dangerous. Economic competition could lead companies to automate large swathes of human labor with AI, leading to increased inequality and concentration of power in the hands of private companies. Eventually, AI systems could be given control of many of the world\u2019s most important decisions, undermining human autonomy on a global scale.&nbsp;</p><h2>Links</h2><ul><li>The <a href=\"https://www.congress.gov/bill/118th-congress/senate-bill/3050/text?s=1&amp;r=1\">first AI bill from Senator Schumer and cosponsors</a> calls for reports from federal agencies about data sharing, cybersecurity, and AI in the financial services industry.&nbsp;</li><li>Yoshua Bengio calls for a network of non-profit, non-governmental <a href=\"https://www.journalofdemocracy.org/ai-and-catastrophic-risk/\">AI safety research labs</a>.&nbsp;</li><li>A <a href=\"https://taisc.org/overview\">proposed international treaty on AI</a> would create a three-tiered system for AI training. The most powerful AIs would be trained by a single multilateral institution, while licensed companies could train models with slightly less compute, and unlicensed developers with less compute still.&nbsp;</li><li>Leading AI researchers call for government action on AI risks in a <a href=\"https://managing-ai-risks.com/\">new position paper</a>.&nbsp;</li><li><a href=\"https://law.vanderbilt.edu/with-ai-managed-corporations-on-the-horizon-the-time-for-interspecific-lawmaking-is-now/\">Legal analysis</a> of how AI systems should be incorporated into existing legal frameworks.&nbsp;</li><li>The <a href=\"https://futureoflife.org/ai-policy/can-we-rely-on-information-sharing/\">terms of service for different AI models</a> offer insights about the legal responsibilities that companies are willing to accept for harms caused by their models.&nbsp;</li><li>OpenAI announced their new <a href=\"https://openai.com/blog/frontier-risk-and-preparedness\">Preparedness Team</a> and an <a href=\"https://openai.com/form/preparedness-challenge\">open challenge</a> to identify risks of AI misuse.&nbsp;</li><li>The <a href=\"https://press.un.org/en/2023/sga2236.doc.htm\">United Nations</a> has announced a new advisory board on AI.&nbsp;</li><li>Amazon is <a href=\"https://twitter.com/MorningBrew/status/1715377844413415862\">testing human-like robots</a> in its warehouses.&nbsp;</li><li>An interactive explanation of <a href=\"https://theaidigest.org/progress-and-dangers\">the speed of AI development</a>.&nbsp;</li><li>Anthropic receives another <a href=\"https://www.wsj.com/tech/ai/google-commits-2-billion-in-funding-to-ai-startup-anthropic-db4d4c50\">$2 billion investment</a> from Google.&nbsp;</li><li>OpenAI is in talks for a fundraising round that would <a href=\"https://archive.ph/9YLLz\">value the company at $80 billion</a>.&nbsp;</li><li>The Open Philanthropy Foundation (which is one of CAIS\u2019s funders) is <a href=\"https://www.openphilanthropy.org/research/new-roles-on-our-gcr-team/\">hiring</a> for grantmaking and research roles in AI policy, technical AI safety research, and other areas.&nbsp;</li><li>For those interested in conducting technical AI safety research, the <a href=\"https://www.matsprogram.org/\">MATS Program</a> running from January to March 2024 offers mentorship and support.&nbsp;</li><li>Concordia Consulting published <a href=\"https://concordia-consulting.com/wp-content/uploads/2023/10/State-of-AI-Safety-in-China.pdf?utm_source=substack&amp;utm_medium=email\">a report on the state of AI safety in China</a>. They also have a <a href=\"https://aisafetychina.substack.com/\">newsletter</a> covering Chinese AI safety developments.&nbsp;</li><li>Artists are trying to <a href=\"https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai/\">poison training data</a> in an effort to prevent AI companies from profiting on their work.&nbsp;</li><li>Self-driving car startup Cruise is <a href=\"https://www.nbcnews.com/tech/cruise-self-driving-crash-freeze-pause-stop-call-rcna122462#:~:text=The%20announcement%20came%20two%20days,was%20pinned%20underneath%20the%20vehicle.\">no longer permitted to operate</a> in the state of California after dragging a pedestrian for 20 feet after an accident.&nbsp;</li></ul><p>See also: <a href=\"https://www.safe.ai/\">CAIS website</a>, <a href=\"https://twitter.com/ai_risks?lang=en\">CAIS twitter</a>, <a href=\"https://newsletter.mlsafety.org/\">A technical safety research newsletter</a>, <a href=\"https://arxiv.org/abs/2306.12001\">An Overview of Catastrophic AI Risks</a>, and our <a href=\"https://forms.gle/EU3jfTkxfFgyWVmV7\">feedback form</a></p><p>Listen to the AI Safety Newsletter for free on <a href=\"https://spotify.link/E6lHa1ij2Cb\">Spotify.</a></p><p>Subscribe <a href=\"https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916\">here</a> to receive future versions.</p>", "user": {"username": "Center for AI Safety"}}, {"_id": "2sZudkyLtNqsuskE5", "title": "The UK AI Safety Summit tomorrow", "postedAt": "2023-10-31T19:09:18.213Z", "htmlBody": "<p>The <a href=\"https://www.aisafetysummit.gov.uk/\">AI safety Summit</a>, initiated by Rishi Sunak, will take place on Wednesday and Thursday. It attempts to convene international governments (including China), leading AI companies, civil society groups, and experts in research across two days.</p><p>I spent a bit of time trying to understand the intended outcomes and the summit's agenda and thought I wanted to share that here.</p><h1>Objectives</h1><p>The summit has <a href=\"https://www.aisafetysummit.gov.uk/\">five objectives</a>:</p><ul><li>a shared understanding of the risks posed by frontier AI and the need for action</li><li>a forward process for international collaboration on frontier AI safety, including how best to support national and international frameworks</li><li>appropriate measures which individual organisations should take to increase frontier AI safety</li><li>areas for potential collaboration on AI safety research, including evaluating model capabilities and the development of new standards to support governance</li><li>showcase how ensuring the safe development of AI will enable AI to be used for good globally</li></ul><h1><strong>Agenda</strong></h1><p><a href=\"https://www.gov.uk/government/publications/ai-safety-summit-programme/ai-safety-summit-day-1-and-2-programme\">The Summit has the following agenda</a> (copy-pasted).</p><h2>Day 1</h2><h3><strong>Understanding Frontier&nbsp;AI&nbsp;Risks (roundtable discussions)</strong></h3><p>Delegates will break out to discuss the following topics with multi-disciplinary attendees. Conclusions from each session will be published at the end of the summit.</p><p><strong>1. Risks to Global Safety from Frontier AI Misuse</strong><br>Discussion of the safety risks posed by recent and next generation frontier AI models, including risks to biosecurity and cybersecurity.</p><p><strong>2. Risks from Unpredictable Advances in Frontier AI Capability</strong><br>Discussion of risks from unpredictable \u2018leaps\u2019 in frontier AI capability as models are rapidly scaled, emerging forecasting methods, and implications for future AI development, including open-source.</p><p><strong>3. Risks from Loss of Control over Frontier AI</strong><br>Discussion of whether and how very advanced AI could in the future lead to loss of human control and oversight, risks this would pose, and tools to monitor and prevent these scenarios.</p><p><strong>4. Risks from the Integration of Frontier AI into Society</strong><br>Risks from the integration of frontier AI into society include election disruption, bias, impacts on crime and online safety, and exacerbating global inequalities. The discussion will include measures countries are already taking to address these risks.</p><h3><strong>Improving Frontier AI Safety (roundtable discussions)</strong></h3><p>Delegates will break out to discuss the following topics with multi-disciplinary attendees. Conclusions from each session will be published at the end of the summit.</p><p><strong>1. What should Frontier AI developers do to scale responsibly?</strong><br>Multidisciplinary discussion of Responsible Capability Scaling at frontier AI developers including defining risk thresholds, effective model risk assessments, pre-commitments to specific risk mitigations, robust governance and accountability mechanisms, and model development choices.</p><p><strong>2. What should National Policymakers do in relation to the risks and opportunities of AI?</strong><br>Multidisciplinary discussion of different policies to manage frontier AI risks in all countries including monitoring, accountability mechanisms, licensing, and approaches to open-source AI models, as well as lessons learned from measures already being taken.</p><p><strong>3. What should the International Community do in relation to the risks and opportunities of AI?</strong><br>Multidisciplinary discussion of where international collaboration is most needed to both manage risks and realise opportunities from frontier AI, including areas for international research collaborations.</p><p><strong>4. What should the Scientific Community do in relation to the risks and opportunities of AI?</strong><br>Multidisciplinary discussion of the current state of technical solutions for frontier AI safety, the most urgent areas of research, and where promising solutions are emerging.</p><h3><strong>AI for good \u2013 AI for the next generation (panel discussion)</strong></h3><p>Discussion on the immense opportunities of AI to transform education for future generations, followed by closing remarks by the UK\u2019s Secretary of State.</p><h2><strong>Day 2</strong></h2><p>The Prime Minister will convene a small group of governments, companies and experts to further the discussion on what steps can be taken to address the risks in emerging AI technology and ensure it is used as a force for good.</p><p>In parallel, UK Technology Secretary Michelle Donelan will reconvene international counterparts to agree on the next steps.</p><p>&nbsp;</p><p>&nbsp;</p><p>The website says that \"Conclusions from each session will be published at the end of the summit.\" so it's probably worth staying updated over the coming week. It feels a bit surreal, but this combined with initiatives such as <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/\">Biden\u2019s Executive Order on Safe AI</a>, <a href=\"https://www.un.org/en/ai-advisory-body\">UN\u2019s high-level advisory body on AI</a>, and the UK Taskforce makes me much more hopeful that we might actually avoid an existential catastrophe from AI.</p>", "user": {"username": "SebastianSchmidt"}}, {"_id": "pniDWyjc9vY5sjGre", "title": "Rethink Priorities\u2019 Cross-Cause Cost-Effectiveness Model: Introduction and Overview", "postedAt": "2023-11-03T12:26:52.312Z", "htmlBody": "<p>This post is a part of Rethink Priorities\u2019 Worldview Investigations Team\u2019s&nbsp;<a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj\"><u>CURVE Sequence</u></a>: \u201cCauses and Uncertainty: Rethinking Value in Expectation.\u201d The aim of this sequence is twofold: first, to consider alternatives to expected value maximization for cause prioritization; second, to evaluate the claim that a commitment to expected value maximization robustly supports the conclusion that we ought to prioritize existential risk mitigation over all else. This post presents a software tool we're developing to better understand risk and effectiveness.</p><h1><strong>Executive Summary</strong></h1><p>The&nbsp;<a href=\"https://ccm.rethinkpriorities.org\">cross-cause cost-effectiveness model</a> (CCM) is a software tool under development&nbsp;<strong> </strong>by Rethink Priorities to produce cost-effectiveness evaluations in different cause areas.</p><p><strong>Video introduction: </strong><a href=\"https://www.loom.com/share/d577afaae88648cc811fc5ff275505ed\"><strong>the CCM in the context of the curve sequence</strong></a><strong>, </strong><a href=\"https://www.loom.com/share/0a8cbaa3acc1458586bf1b35e36fc2bf?sid=b08ec1de-8d2c-402d-9f38-192e072d87be\"><strong>an overview of CCM functionality&nbsp;</strong></a></p><p><a href=\"https://github.com/rethinkpriorities/cross-cause-cost-effectiveness-model-public\"><strong>Code Repository</strong></a><strong>&nbsp;</strong></p><ul><li>The CCM enables evaluations of interventions in global health and development, animal welfare, and existential risk mitigation.</li><li>The CCM also includes functionality for evaluating research projects aimed at improving existing interventions or discovering more effective alternatives.</li></ul><p>The CCM follows a Monte Carlo approach to assessing probabilities.</p><ul><li>The CCM accepts user-supplied distributions as parameter values.</li><li>Our primary goal with the CCM is to clarify how parameter choices translate into uncertainty about possible results.</li></ul><p>The limitations of the CCM make it an inadequate tool for definitive comparisons.</p><ul><li>The model is optimized for certain easily quantifiable effective projects and cannot assess many relevant causes.</li><li>Probability distributions are a questionable way of representing deep uncertainty.</li><li>The model may not adequately handle possible interdependence between parameters.</li></ul><p>Building and using the CCM has confirmed some of our expectations. It has also surprised us in other ways.</p><ul><li>Given parameter choices that are plausible to us, existential risk mitigation projects dominate others in expected value in the long term, but the results are too high variance to approximate through Monte Carlo simulations without drawing billions of samples.</li><li>The expected value of existential risk mitigation in the long run is mostly determined by the tail-end possible values for a handful of deeply uncertain parameters.</li><li>The most promising animal welfare interventions have a much higher expected value than the leading global health and development interventions with a somewhat higher level of uncertainty.</li><li>Even with relatively straightforward short-term interventions and research projects, much of the expected value of projects results from the unlikely combination of tail-end parameter values.</li></ul><hr><p>We plan to host&nbsp;<strong>an online walkthrough and Q&amp;A of the model&nbsp;</strong>with the Rethink Priorities Worldview Investigations Team on Giving Tuesday, November 28, 2023, at 9 am PT / noon ET / 5 pm BT / 6 pm CET. If you would like to attend this event, please&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSe0l4x97MWz5ZT695QjqNQoJpAsV68-DMSKn502AsIzn_pqvw/viewform?usp=sf_link\"><u>sign up</u></a> here.&nbsp;</p><hr><h1><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/bgotosvwjlofc2zklgcw\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/dsd8tpj5qqlmgeskj1wq 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/ouj3isrwavqxwvjjor2o 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/tzp7qrmxjnuo4fpnblec 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/fl9ccwreqrtscl0ohegk 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/zhzapoiqe1xbusr2fuul 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/fopg9qcnqk3saywmz1l0 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/qllej3c1kro3tvzsm0bt 1400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/h093c3hzghtosksfrdov 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/xfsrnzpp6ettenqd5nut 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/ufn7j5t4eb95tpvnap7w 1920w\">Overview</h1><p>Rethink Priorities\u2019 cross-cause cost-effectiveness model (CCM) is a software tool we are developing for evaluating the relative effectiveness of projects across three general domains: global health and development, animal welfare, and the mitigation of existential risks. You can play with our initial version at&nbsp;<a href=\"https://ccm.rethinkpriorities.org\">ccm.rethinkpriorities.org</a> and provide us feedback in this post or <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdOpfNhefYhgbRb0goUKC9gS1ffydg2MLgET2OZDqDsGlsKYw/viewform\">via this form</a>.</p><p>The model produces effectiveness estimates, understood in terms of the effect on the sum of welfare across individuals, for interventions and research projects within these domains. Results are generated by computations on the values of user-supplied parameters. Because of the many controversies and uncertainties around these parameters, it follows a Monte Carlo approach to accommodating our uncertainty: users don\u2019t supply precise values but instead specify distributions of possible values; then, each run of the model generates a large number of samples from these parameter distributions to use as inputs to compute many separate possible results. The aim is for the conclusions to reflect what we should believe about the spread of possible results given our uncertainty about the parameters.</p><h1>&nbsp;</h1><h1>Purpose</h1><p>The CCM calculates distributions of the relative effectiveness of different charitable interventions and research projects so that they can be compared. Because these distributions depend on so many uncertain parameter values, it is not intended to establish definitive conclusions about the relative effectiveness of different projects. It is difficult to incorporate the vast number of relevant considerations and the full breadth of our uncertainties within a single model.</p><p>Instead, the outputs of the CCM provide&nbsp;<i>evidence</i> about relative cost-effectiveness. Users must combine that evidence with both an understanding of the model\u2019s limitations and other sources of evidence to come to their own opinions. The CCM can influence what we believe even if it shouldn\u2019t decide it.</p><p>In addition to helping us to understand the implications of parameter values, the CCM is also intended to be used as a tool to better grasp the dynamics of uncertainty. It can be enlightening to see how much very remote possibilities dominate expected value calculations and how small changes to some parameters can make a big difference to the results. The best way to use the model is to interact with it: to see how various parameter distributions affect outputs.</p><h1>&nbsp;</h1><h1>Key Features</h1><p>We\u2019re not the first to generate cost-effectiveness estimates for diverse projects or the first to make a model to do so. We see the value of the present model in terms of the following features:</p><p>&nbsp;</p><p>&nbsp;</p><p><img style=\"width:100%\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/em88kmyokjxymwe7rarw\" alt=\"\"></p><h3>We model uncertainty with simulations</h3><p>As we\u2019ve said, we\u2019re uncertain about many of the main parameters that go into producing results in the model. To reflect that uncertainty, we run our model with different values for those parameters.</p><p>In the current version of the model, we use 150,000 independent samples from each of the parameter distributions to generate results. These samples can be thought of as inputs to independent runs. The runs generate an array of outcomes that reflect our proper subjective probability distribution over results. Given adequate reflection of our uncertainties about the inputs to the model, these results should cover the range of possibilities we should rationally expect.</p><p>&nbsp;</p><p>&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/ezroafz4ac9kcobsziuz\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/bfrehyveyrgvjj0uysqu 110w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/pbcnfm0dldjtgrt9oi9v 220w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/fnnryrkpruk8qa25lmau 330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/sl2mmld0cezb3pwouqng 440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/cexk4yefqwtloajx1mbw 550w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/qqm48cd7knt6tdoouhbo 660w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/lxzimu02neismvxi3yal 770w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/guepg46b0zaodlvyo9e8 880w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/h4i0sjnubfahictkkz8r 990w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/fknqvdvqdyd0mxyvigfd 1011w\"></figure><h3>We incorporate user-specified parameter distributions</h3><p>To reflect uncertainty about parameters, the model generates multiple simulations using different combinations of values. The values for the parameters in each simulation are sampled from distributions over possible numbers. While we supply some default distributions based on what we believe to be reasonable, we also empower users to shape distributions to represent their own uncertainties. We include several types of distributions for users to select among; we also let them set the bounds and a confidence interval for their distribution of choice.</p><p>&nbsp;</p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/lzzbnkshysz6f4g6kn18\" alt=\"\"></p><h3>Our results capture outcome ineffectiveness</h3><p>We are uncertain about the values of parameters that figure into our calculations of the expected value of our projects. We are also uncertain about how worldly events affect their outcomes. Campaigns can fail. Mitigation efforts can backfire. Research projects can be ignored. One might attempt to capture the effect of such random events by applying a discount to the result: if there is a 30% chance that a project will fail, we may simply reduce each sampled value by 30%. Instead, we attempt to capture this latter sort of uncertainty by randomly determining the outcomes of certain critical events in each simulation. If the critical events go well, the simulation receives the full calculated value of the intervention. If the critical events go otherwise, that simulation records no value or negative value.</p><p>Many projects stand to make a large positive difference to the world but only are effective under the right conditions. If there is some chance that our project will fail, we can expect the model\u2019s output ranges to include many samples in which the intervention makes no difference.</p><p>Including the outcomes of worldly events helps us see how much of a risk there is that our efforts are wasted. This is important for accurately measuring risk under the alternative decision procedures explored elsewhere <a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj/p/HMakzketADQq4bkvD\">in</a> <a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj/p/9EENSGhiQiKFaRh4t\">this</a> <a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj/p/LCfd56cBeRzrMiAhw\">sequence</a>.</p><p>&nbsp;</p><p>&nbsp;</p><p><img style=\"width:100%\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pniDWyjc9vY5sjGre/ux6jtlyjp4v6yoq6kg7x\" alt=\"\"></p><h3>We enable users to specify the probability of extinction for different future eras</h3><p>We put more work into our calculations around the value provided by existential risk mitigation compared with other cause areas. Effectiveness evaluations in this cause area are both sensitive to particularly <a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj/p/S9H86osFKhfFBCday\">complex</a> <a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj/p/i5cuLZH3SQJigiHMs\">considerations</a> and relatively less well explored.</p><p>One critical feature to assessing the effect of existential risk mitigation is the <a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj/p/S9H86osFKhfFBCday\">number of our descendants</a>. This depends in part on how long we last before extinction, which in turn depends on the future threats to our species. We make it possible for users to capture their own views about risk by specifying custom risk predictions that include yearly risk assessments for the relevant periods over the coming millennia.</p><h1>&nbsp;</h1><h1>Structure</h1><p>The tool contains two main modules.</p><p>First, the model contains a module for assessing the effectiveness of interventions directly aimed at making a difference. This tool utilizes sub-models for evaluating and comparing interventions addressing global health and development, animal welfare, and existential risk mitigation.</p><p>Second, the model contains a module for comparing the effectiveness of research projects intended to improve the effectiveness of money spent on direct interventions. This tool combines parameters concerning the probability of finding and implementing an improvement with the costs incurred by the search.</p><p>&nbsp;</p><h2>Intervention module</h2><p>The intervention assessment module provides evaluations of the effectiveness of interventions within three categories: global health and development, animal welfare, and existential risk mitigation. The effectiveness of interventions within each category is reported in DALYs-averted equivalent units per $1000 spent on the current margin.</p><p>Given the different requirements of interventions with distinct aims, the CCM relies on several sub-models to calculate intervention effectiveness of different kinds.</p><h3><strong>Global Health and Development</strong></h3><p>We include several benchmark estimates of cost-effectiveness for global health and development charities to assess the relative effectiveness of animal welfare and existential risk projects. We draw these estimates from other sources, such as GiveWell, that we expect to be as reliable as anything we could produce ourselves. However, these estimates don\u2019t incorporate uncertainty. To try to account for this and to express our own uncertainties about these estimates, we use distributions centered on the estimates.</p><h3><strong>Animal Welfare</strong></h3><p>Our <a href=\"https://docs.google.com/document/d/1M60ShtBBQEdoTWcGlVtRWSrredP9cZQxSzJXdbAztHI\">animal welfare model</a> assesses the effects of different interventions on welfare among farmed animal populations. The parameters that go into these calculations include the size of the farmed population, the proportion that will be affected, the degree of improvement in welfare, and the costs of the project (among others.)</p><p>Since the common unit of value used to compare interventions is assessed in disability-adjusted human life years, we discount the well-being of non-human animals based on their probability of sentience and capacities for welfare. Our default values are based on the findings of the&nbsp;<a href=\"https://rethinkpriorities.org/publications/an-introduction-to-the-moral-weight-project\">Moral Weight Project</a>, though they can be changed to reflect a wide range of views about the moral considerations that bear on human/animal and animal/animal tradeoffs.</p><h3><strong>Existential Risk Mitigation</strong></h3><p>Our <a href=\"https://docs.google.com/document/d/1hCD3p1qbq9HY360N5Owjt691GmYH44uFY23rCqU2vmk/\">existential risk model</a> estimates the effect that risk mitigation has on both preventing near-term catastrophes and extinction. In both cases, we calculate effectiveness in terms of the difference the intervention makes in years of human life lived.</p><p>We assume that existential risk mitigation work may lower (or accidentally raise) the chance of risk of catastrophic or existential events over a few decades, but has no perpetual impact on the level of risk. The primary value of an intervention is in helping us safely make it through this period. In many of the samples, the result of our model\u2019s randomization means that we do not suffer an event in the coming decades regardless of the intervention. If that happens, or if we suffer an event despite the intervention, this means that the intervention provides no benefit for its cost. In some others, the intervention allows our species to survive for thousands of years, gradually colonizing the galaxy and beyond. In yet others, our efforts backfire and we bring about an extinction event that would not otherwise have occurred.</p><p>The significance of existential risk depends on future population sizes. In response to <a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj/p/CpgQzQzJKx95Jgguh\">the extreme uncertainty of the future</a>, we default to a cutoff point in a thousand years, where the population is limited by the Earth\u2019s capacity. However, we make it possible to expand this time frame to any degree. We assume that, given enough time,&nbsp; humans will eventually expand beyond our solar system, and for simplicity accept a constant and equal rate of colonization in each direction. The future population of our successors will depend on the density of inhabitable systems, the population per system, and the speed at which we colonize them. Given the high growth rate of a volume with constant diameter expansion, we find that the speed of expansion and the time until extinction are the most important factors for deciding effectiveness. Interventions can have an extraordinarily high mean effectiveness even if, the vast majority of the time, they do nothing.</p><p>&nbsp;</p><h2>Research projects module</h2><p>The research projects sub-module provides evaluations of research projects aimed at improving the quality of global health and development and animal welfare intervention work. These research projects make a difference in the cost-effectiveness of money spent on a project if successful. However, they are often speculative and fail to find an improvement; or, they find an improvement that is not adopted. The sub-module lets users specify the effect of moving money from an intervention with a certain effectiveness to another hypothetical intervention of higher effectiveness, then, it creates an assessment of the value of the research due to promoting that change.</p><p>If a research project succeeds in finding an improvement in effectiveness, the value produced depends on how much money is influenced as a result. Research isn\u2019t free, and so we count the costs of research in terms of the counterfactual use of that money on interventions themselves.</p><h1>&nbsp;</h1><h1>Limitations</h1><p>The intervention module has several significant limitations that reduce its usefulness for &nbsp;generating cross-cause comparisons of cost-effectiveness. All results need to be interpreted carefully and used judiciously.</p><p>&nbsp;</p><h3>It is geared towards specific kinds of interventions</h3><p>The sub-models for existential risk mitigation and animal welfare abstract some of the particularities of the interventions within their domain to allow them to represent different interventions following a similar logic. They are far from completely general. The animal welfare model is aimed at interventions reducing the suffering of animals. Interventions aimed at promoting vegetarianism, which have an indirect effect on animal suffering, are not represented. The existential risk mitigation model is aimed at interventions lowering the near-term risk of human extinction. Many other long-termist projects, such as projects aimed at improving institutional decision-making or moral circle expansion, are not represented.</p><p>Other interventions would require different parameter choices and different logic to process them. The sorts of interventions we chose to represent are reasonably general, believed to be highly effective in at least some cases, and of particular interest to Rethink Priorities. We have avoided attempting to model many idiosyncratic or difficult-to-assess interventions, but that leaves the model radically incomplete for general evaluative purposes.</p><p>&nbsp;</p><h3>Distributions are a questionable way of handling deep uncertainty</h3><p>We represent our uncertainty about parameters with distributions over possible values. This does a good job of accounting for some forms of uncertainty. To take advantage of this, users must take care to pay attention not just to mean values but also to the variety of results.</p><p>However, representing uncertainty with distributions requires knowing which distributions to choose. Often, when faced with questions about which we are truly ignorant, it is hard to know where to place boundaries or how to divide the bulk of the values. Representing uncertainties with distributions can give us a false sense of confidence that our ignorance has been properly incorporated when we have really replaced our uncertainties with a somewhat arbitrary distribution.</p><p>&nbsp;</p><h3>The model doesn\u2019t handle model uncertainty</h3><p>Where feasible, the CCM aims to represent our uncertainty within the model so as to produce results that incorporate that uncertainty. However, not all forms of uncertainty can be represented within a model. While a significant amount of uncertainty may be in the values of parameters, we may also be uncertain about which parameters should be included in the model and how they should relate to each other. If we have chosen the wrong set of parameters, or left out some important parameters, the results will fail to reflect what we should believe. If we have left out considerations that could lower the value of some outcomes, the results will be overly optimistic. If we\u2019re not confident that our choice of parameters is correct, then the model\u2019s estimates will fall into a narrower band than they should.</p><p>&nbsp;</p><h3>The model assumes parameter independence</h3><p>We generate the value of parameters with independent samples from user-supplied distributions. The values chosen for each parameter have no effect on the values chosen for others. It is likely that some parameters should be dependent on each other, either because the underlying factors are interrelated or because our ignorance about them may be correlated. For example, the speed of human expansion throughout may be correlated with the probability of extinction by each year in the far future. Or, the number of shrimp farmed may be correlated with the proportion of shrimp we can expect to affect. Interdependence would suggest that the correct distribution of results will not have the shape that the model actually produces. We mitigate this in some cases by deriving some values from the parameters based on our understanding of their relationship, but we can\u2019t fully capture all the probabilistic relationships between parameter values and we generally don\u2019t try to.</p><h1>&nbsp;</h1><h1>Lessons</h1><p>Despite the CCM\u2019s limitations, it offers several general lessons.</p><p>&nbsp;</p><h3>The expected value of existential risk mitigation interventions depends on future population dynamics</h3><p>For all we knew at the outset, many factors could have played a significant role in explaining the possible value of existential risk mitigation interventions. Given our interpretation of future value in terms of total welfare-weighted years lived, it turns out that the precise amount of value depends, more than anything, on two factors: the time until our successors go extinct and the speed of population expansion. Other factors, such as the value of individual lives, don\u2019t make much of a difference.</p><p>The size of the effect is so tremendous that including a high expansion rate in the model as a possibility will lead existential risk to have extremely high expected cost-effectiveness, practically no matter how unlikely it is. Each of these two factors is radically uncertain. We don\u2019t know what might cause human extinction assuming that we should survive for a thousand years. We have no idea how feasible it will be for us to colonize other systems. Thus, the high expected values produced by a model reflect the fact that we can\u2019t rule out certain scenarios.</p><p>&nbsp;</p><h3>The value of existential risk mitigation is extremely variable</h3><p>Several factors combine to make existential risk mitigation work particularly high variance.</p><p>We measure mitigation effectiveness by the proportional reduction of yearly risk. In setting the defaults, we\u2019ve also assumed that even if the per-century risk is high, the yearly risk is fairly low. It also seemed implausible to us that any single project, even a massive billion-dollar megaproject, would remove a significant portion of the risk of any given threat. Furthermore, for certain kinds of interventions, it seems like any project that might reduce risk might also raise it. For AI, we give this a nontrivial chance by default. Finally, in each simulation, the approximate value of extinction caused or prevented is highly dependent on the precise values of certain parameters.</p><p>The result of all this is that even with 150k simulations, the expected value calculations on any given run of the model (allowing a long future) will swing back and forth between positive and negative values. This is not to say that expected value is unknowable. Our model does even out once we\u2019ve included billions of simulations. But the fact that it takes so many demonstrates that outcome results have extremely high variance and we have little ability to predict the actual value produced by any single intervention.</p><p>&nbsp;</p><h3>Tail-end results can capture a huge amount of expected value</h3><p>One surprising result of the model was how much of the expected value of even less speculative projects and interventions comes from rare combinations of tail-end samples of parameter values. We found that some of the results that could not fit into our charts because the values were too rare and extreme could nevertheless account for a large percentage of the expected value.</p><p>This suggests that the boundaries we draw around our uncertainty can be very significant. If those boundaries are somewhat arbitrary, then the model is likely to be inaccurate. However, it also means that clarifying our uncertainty around extreme parameter values may be particularly important and neglected.</p><p>&nbsp;</p><h3>Unrepresented correlations may be decisive</h3><p>Finally, for simplicity, we have chosen to make parameters independent of each other. As noted above, this is potentially problematic: even if we represent the right parameters with the right distributions, we may overlook correlations between those distributions. The previous lessons also suggest that our uncertainty around correlations in high-variance events might upend the results.</p><p>If we had reason to think that there was a positive relationship between how likely existential risk mitigation projects were to backfire and how fast humanity might colonize space, the expected value of mitigation work might turn out to be massively negative.&nbsp; If there were some reason to expect a certain correlation between the moral weight of shrimp and the populations per inhabitable solar system, for instance, if a high moral weight led us to believe digital minds were possible, the relative value the model assigns to shrimp welfare and risks from runaway AI work might look quite different.</p><p>This is interesting in part because of how under-explored these correlations are. It is not entirely obvious to us that there are critical correlations that we haven\u2019t modeled, but the fact that such correlations could reverse our relative assessments should leave us hesitant to casually accept the results of the model. Still, absent any particular proposed correlations, it may be the best we\u2019ve got.</p><h1>&nbsp;</h1><h1><strong>Future Plans</strong></h1><p>We have learned a lot from the process of planning and developing the CCM. It has forced us to clarify our assumptions and to quantify our uncertainty. Where it has produced surprising results, it has helped us to understand where they come from. In other places, it has helped to confirm our prior expectations.</p><p>We will continue to use and develop it at Rethink Priorities. The research projects module was built to help assess potential research projects at Rethink Priorities and we will use it for this purpose. We will test our parameter choices, refine its verdicts, and incorporate other considerations into the model. We also hope to be able to expand our interventions module to incorporate different kinds of interventions.</p><p>In the meantime, we hope that others will find it a valuable tool to explore their own assumptions.<strong> If you have thoughts about what works well in our model or ideas about significant considerations that we\u2019ve overlooked, we\u2019d love to hear about it </strong><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdOpfNhefYhgbRb0goUKC9gS1ffydg2MLgET2OZDqDsGlsKYw/viewform\">via this form</a>,<strong> </strong>in the comments below, or at <a href=\"mailto:dshiller@rethinkpriorities.org\">dshiller@rethinkpriorities.org</a>.</p><p>&nbsp;</p><h1><strong>Acknowledgements</strong></h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/CpgQzQzJKx95Jgguh/nhw7ir2j0sdj7byq9pz7\"></p><p>The CCM was designed and written by Bernardo Baron, Chase Carter, Agust\u00edn Covarrubias, Marcus Davis, Michael Dickens, Laura Duffy, Derek Shiller, and Peter Wildeford. The codebase makes extensive use of Peter Wildeford's squigglepy and incorporates componentry from quri's squiggle library.</p><p>This overview was written by Derek Shiller. Conceptual guidance on this project was provided by David Rhys Bernard<strong>, </strong>Hayley Clatterbuck, Laura Duffy, Bob Fischer, and Arvo Mu\u00f1oz Mor\u00e1n. Thanks also to everyone who reported bugs or made suggestions for improvement. The post is a project of Rethink Priorities, a global priority think-and-do tank, aiming to do good at scale. We research and implement pressing opportunities to make the world better. We act upon these opportunities by developing and implementing strategies, projects, and solutions to key issues. We do this work in close partnership with foundations and impact-focused non-profits or other entities. If you're interested in Rethink Priorities' work, please consider subscribing to our&nbsp;<a href=\"https://rethinkpriorities.org/newsletter\"><u>newsletter</u></a>. You can explore our completed public work&nbsp;<a href=\"https://rethinkpriorities.org/research\"><u>here</u></a>.</p>", "user": {"username": "Derek Shiller"}}, {"_id": "d9bamQHBAwAjuKtNA", "title": "Alvea\u2019s Story, Wins, and Challenges [Unofficial]", "postedAt": "2023-11-01T12:43:35.687Z", "htmlBody": "<h2>Intro</h2><p>A few months ago, the other (former) Alvea executives and I made the difficult decision to <a href=\"https://www.alvea.bio/winddown/\">wind Alvea down</a> and return our remaining funding to investors. In this post, I\u2019ll share an overview of Alvea\u2019s story and highlight a few of our wins and challenges from my perspective as an Alvea Co-Founder and former CTO, in hopes that our experiences might be useful to others who are working on (or considering) ambitious projects to solve the biggest problems in the world. I\u2019m sharing everything below in a personal capacity and as a window into my current thinking\u2014this is not the definitive or official word on Alvea and it doesn\u2019t necessarily represent the views of any other Alvea team members*. I expect my reflections to continue evolving as I further process the journey and outcomes of this project, and hope to share more along the way.&nbsp;</p><p>*Note (added 11/1): Cate Hall, another Alvea Co-Founder and executive, also <a href=\"https://forum.effectivealtruism.org/posts/d9bamQHBAwAjuKtNA/alvea-s-story-wins-and-challenges-unofficial?commentId=jrPqpoAELiMDq5Mr8\">endorses these reflections</a>.</p><h2>Alvea\u2019s Story</h2><h3>First vaccine sprint and decision to continue Alvea (December 2021 through April 2022)</h3><p>We launched Alvea in response to the Omicron wave of COVID-19 (the most transmissible and immune-evasive variant then to have arisen) as a short-term, high-risk project with the goal of developing an easily-deployable, room temperature-stable DNA vaccine against Omicron as quickly as humanly possible, without compromising on safety and quality. We ultimately carried this vaccine candidate into Phase I clinical trials in less than 6 months, becoming the fastest startup ever to take a new drug candidate from company launch to a human clinical trial. Our success in this initial sprint caused us to expand our ambitions for Alvea and explore ways of building on the track record and momentum we\u2019d built up.&nbsp;</p><p>One of our initial strategies was to deploy our first vaccine (which was optimized for the Omicron BA.2 variant), and then leverage our development platform to roll out updated versions in response to the emergence of new variants. However, a few key updates convinced us that this was not a promising path. First, the time between waves of new variants continued to drop, making it more difficult to keep up with viral evolution. Second, the FDA and other regulators began an expedited approval process for updated versions of the mRNA vaccines that had already been authorized, making it more difficult for new vaccines to break into the commercial market (a great pandemic regulatory move, though!). Additionally, early efficacy results for our vaccine were underwhelming and suggested that it was unlikely to provide sufficient protection to justify continued investment, particularly against the newest variants in low- and middle-income countries. In light of these updates we decided to stop development of our candidate and consider other paths forward.</p><h3>Product pursuits (May 2022 through July 2022)</h3><p>Despite discontinuing our first vaccine program, we believed we\u2019d landed on a compelling model for general-purpose acceleration of promising drugs and vaccines into the clinic, so we set out to find other high-impact products we could accelerate with this approach. We specifically targeted products and technologies with early published preclinical data that were nearing readiness for clinical testing, with the idea that we could pick them up and dramatically speed up their development and deployment. We ran multiple \u201cproduct pursuits\u201d in parallel to explore possible technologies, with particular focus on nucleic acid vaccines that could be formulated as dry powders for inhaled administration and on therapeutic interfering particles, a class of RNA therapeutics/prophylactics that are expected to be highly resistant to viral evolution. Neither of these efforts uncovered product opportunities that were clearly good bets under this model\u2014all those identified were either insufficiently promising from an efficacy standpoint, or too far from the clinic for us to make a high-confidence bet. However, the process did yield a set of more speculative technology ideas that involved greater technical risk, but had a strong enough case for impact to potentially be of high expected value.</p><h3>Second vaccine sprint (August 2022-December 2023)</h3><p>We ultimately took the highest-upside technologies identified in the product pursuits and combined them to create a new COVID vaccine candidate designed to be broad-spectrum/variant-resistant, shelf-stable at room temperature, and self-administrable by inhalation. This involved betting on much more speculative technologies than we used for our first candidate, but we thought this bet was justified given the potential upside, which included not only the next generation COVID-vaccine itself, but also the validation of platform technologies that could help enable rapid design and efficient distribution of effective countermeasures against future worst-case pathogens.</p><p>We set ourselves an ambitious goal of submitting a clinical trial application for the new product in ~4 months from the start of development (compared to multiple years for typical new product development of this kind). While the experiments we ran in this sprint showed initial promise for two of the three core technologies we used in the design, the results were not sufficiently compelling to warrant a rapid push into clinical trials, as it was clear that the underlying technologies required further development prior to being deployed. So, we decided to hold off on the application submission, despite having laid the groundwork for another rapid Phase I trial.&nbsp;</p><h3>Funding environment change and pivot (Dec 2022 - May 2023)&nbsp;</h3><p>As we neared the end of our second sprint, the funding environment for projects like Alvea changed dramatically\u2014the philanthropic funding available for cash-intensive, impact-motivated projects plummeted around the same time that the venture capital market for early stage biotech companies plunged to historic lows. Together, these changes seriously limited Alvea\u2019s funding options.</p><p>In response, we cut our burn rate, and proceeded with two parallel efforts:</p><ol><li>We ran a series of smaller-scale, lower-cost follow-up experiments to further develop the technologies that underpinned our second vaccine design, and began pursuing government grants and other non-dilutive funding sources to allow us to continue pushing these technologies toward the clinic. Although we collected some promising data from early experiments, we did not secure sufficient funding to make a major commitment to this program in the time we allotted, and were further dissuaded from pursuing it further at Alvea as it did not offer a clear path to financial self-sustainability for the company.</li><li>We mapped alternative commercial strategies for Alvea that would incur less technical risk and be a better fit for the new funding environment. After many rounds of iteration we crafted a partnerships-focused business model, where we\u2019d offer our rapid translation and early clinical development capabilities as a service to other biotech companies. The central idea was that we would use the internal systems and infrastructure we\u2019d built to accelerate drug and vaccine candidates from other companies into the clinic, and capture a portion of the commercial value created as a result. This strategy offered a commercial path for Alvea that was more robust to the funding environment (as other companies would be footing most of the bill for development), and was also a means of efficiently expanding our general-purpose rapid response capabilities by working on a diverse set of 3rd party molecules. We built a sales pipeline, pitched versions of this offering to 50+ biotech companies, completed two pilot projects, and lined up an initial customer for an end-to-end development program, at which point we decided to pivot the company completely to this new business model.</li></ol><h3>Wind down and PanLabs spin out (June-Present)</h3><p>As we gained traction with the new partnership strategy following our pivot, we continued digging deeper into commercial forecasting for this new strategy, evaluation of the potential paths to impact on worst-case biorisks and global health, and reflection on the global context in which we were operating. This analysis ultimately led us to conclude that despite the promise of the strategy, the path to impact was too long and uncertain, and the commercial potential insufficiently large, for us to feel confident in committing the necessary time and financial resources to its pursuit.&nbsp;</p><p>There was no definitive set of outputs from this analysis that sealed the wind down decision, which unfortunately limits the level of detail I can provide here. There were considerable differences of perspective amongst the departing executives about the conclusions on different points of analysis and the weights they should be assigned\u2014for example, I was optimistic about our commercial prospects but concerned about lock-in effects of the new strategy and counterfactual uses of my and the rest of the team\u2019s time, while others were more skeptical of the viability of the path to realizing Alvea\u2019s upside potential. However, despite these differences, we were ultimately unanimous in concluding that the balance of factors pointed toward winding down and returning our remaining runway to investors.&nbsp;</p><p>As part of the wind down, we helped launch a new non-profit, PanLabs, an impact-focused research and development organization. PanLabs is led by Brian Wang, formerly Alvea\u2019s head of R&amp;D, and he\u2019s joined by a large part of Alvea\u2019s Science team.</p><h2>Wins</h2><h3>Record time to safe clinical development</h3><p>Our most concrete win was the development of our original vaccine candidate into the clinic in record time without compromising on safety. To our knowledge, we became the fastest biotech company ever to go from company founding and design of a novel drug candidate to the start of a clinical trial. This achievement required solving a huge number of technical, operational, regulatory, and logistical challenges, which our team consistently knocked out of the park. When we consulted with expert advisors and industry veterans on our overall project and many of the individual problems therein, they often told us that what we were trying to do was likely impossible. We proved them wrong at nearly every turn. While the efficacy of this vaccine was not what we hoped, we believe this success is a testament to what\u2019s achievable when a talented, altruistic group of people come together to tackle a seemingly impossible task. We hope to see many more such projects in the future.&nbsp;</p><h3>General-purpose rapid drug development capacity</h3><p>In the process of developing our lead vaccine candidates and exploring many others, we built general-purpose systems and infrastructure that could be used to accelerate development of diverse drugs and vaccines, for biosecurity and beyond. We honed approaches for quickly in-housing new tools and technologies, squeezing extraordinary work out of external vendors, and leveraging strategic parallelization and vertical integration to radically collapse conventional drug development timelines (e.g. under our oversight, multiple external industry partners reported hitting their own clinical and manufacturing milestones more quickly than they\u2019d previously thought possible). We hope that our success in this area can serve as general inspiration and proof of concept for more efficient drug development, and that others may be in a position to apply the specific strategies we developed. We\u2019re exploring the best ways to share these, but for now please get in touch if you or anyone you know would be interested in learning more!</p><h3>Team Development</h3><p>One of Alvea\u2019s biggest indirect achievements, and the piece of our story which I expect may have the greatest long-term impact, is the growth and development that our projects catalyzed for the people who worked there. Many of our team members played central roles in the end-to-end design and development of a vaccine into the clinic. Nearly every person who worked at Alvea took on and solved problems that were thought by many others (both within and outside the company) to be completely intractable, and developed a general attitude of embracing such challenges. In just a little over a year, multiple team members went from being early-career individual contributors, to exceptional managers and directors, helping position them to launch and lead ambitious high-impact projects in the future, in biosecurity and beyond. I believe the central factor in enabling this extraordinary growth and development was the simple fact of continuously putting people in situations where it was required of them.</p><h3>Medical countermeasure knowledge</h3><p>Due to the experiences of Alvea\u2019s alumni, there is now far more expertise and experience with pandemic-relevant medical countermeasure development represented in the effective altruism and biosecurity communities. This positions us much better to collectively evaluate whether new medical countermeasure projects are promising and likely to be cost-effective, either as general preparedness measures or in response to specific threats, and to pursue such projects if warranted. We are also excited about opportunities for this knowledge and experience to be applied to biosecurity interventions beyond medical countermeasures, and to other cause areas entirely\u2014Alvea alumni are already working at PanLabs on ambitious countermeasures for worst-case scenario pandemics, on technology roadmapping for Far-UVC, on applying lessons from pharmaceutical regulation to AI governance, and more.</p><h2>Challenges</h2><p>Note:<strong>&nbsp;</strong>The challenges below are selected for high confidence and I\u2019m sharing them here in hopes that they provide useful data points on the kinds of issues that other organizations like Alvea might encounter. Importantly, they are not<i>&nbsp;</i>intended as an explanation or justification for the decision to wind Alvea down.&nbsp;<strong>&nbsp;</strong></p><h3>Challenges of rapid growth</h3><p>In early 2022, we rapidly expanded the Alvea team as well as our spending, growing to about 35 people within the first few months of our existence and making big investments in projects, equipment, and people. This growth and early spending was essential for us to hit our initial goals, but once the first sprint was over we failed to quickly recognize where our organizational capacity, head count, and financial and operational overhead required adjustment in service of sustainability. We didn\u2019t confront this issue head-on until the start of 2023, when funding constraints forced us to look more clearly at our overall traction and burn rate and decisively address the discrepancy between the two. We conducted two rounds of layoffs, implemented more rigorous financial tracking and budget controls, and did substantial operational streamlining in the following months which helped address this issue, but our delay had already consumed substantial time and money.&nbsp;</p><h3>Costs of complex non-standard corporate set up</h3><p>A series of our early choices about Alvea\u2019s corporate structure caused lasting issues that negatively affected our prospects. In the process of spinning Alvea up under intense time constraints, we made quick and unusual decisions about corporate governance and the distribution of Alvea\u2019s equity. These decisions created thorny issues and hindered Alvea\u2019s progress by consuming substantial ongoing time and energy from the executive team, and by making fundraising more difficult. Defaulting to standard startup legal structures and norms wherever possible would likely have avoided most of these challenges.&nbsp;</p><h3>Navigating the transition from short- to long-term goals</h3><p>Alvea started as a time-limited project pursuing a specific near-term objective (taking our DNA vaccine candidate into clinical trials as quickly as possible) to have a large impact in a public health emergency. We maintained a laser-like focus on that objective for the entirety of our first sprint. After our initial success, we decided to continue building Alvea and only then began spending significant time thinking about longer-term strategy. This resulted in a form of strategic \u201cdebt\u201d which, despite our strategy work from then on, was challenging to overcome. On reflection, I see missed opportunities for more thorough ideation, analysis, and red-teaming of early strategic roadmaps, and for more explicit recognition of our changed needs following the end of the first sprint. Taking advantage of these opportunities would have come with painful near-term costs, but the setbacks would have been a worthwhile price to pay. The additional investment could have put us on a stronger trajectory by more quickly revealing high-leverage issues and productive strategy alternatives (e.g. experimenting with a partnerships-focused business model months sooner than we did).&nbsp;</p><h2>Conclusion</h2><p>Alvea\u2019s journey and ultimate dissolution have taught me an enormous amount about the challenges of building companies/organizations, of solving big problems, and of aiming for a massive positive impact in the world. The experience has not, however, changed my perspective on the importance or the potential of such pursuits, which I continue to believe in deeply. I hope Alvea\u2019s story may prove useful to those considering other projects in a similar vein. I also recognize that what I\u2019ve written here is incomplete, and that specific people would probably benefit from more detailed explanations or discussion of some of the things I\u2019ve shared (or not shared) above. If that\u2019s you, please don\u2019t hesitate to reach out to me directly.</p><p>To conclude, I want to echo the gratitudes shared in the <a href=\"https://www.alvea.bio/winddown/\">official Alvea announcement</a>\u2014I am enormously thankful to the entire Alvea team, our investors, and our other supporters and collaborators for making it possible for us to take this shot. The people I worked with at Alvea, both within and outside the company, stand out as the most talented, most caring, most fun, and most ambitious team I\u2019ve ever been a part of.</p>", "user": {"username": "kyle_fish"}}, {"_id": "icxnuEHTXrPapHBQg", "title": "A simplified cost-effectiveness estimation methodology for use in Solar4Africa's Fall-23 student projects", "postedAt": "2023-11-01T21:02:14.820Z", "htmlBody": "<p><br>In this post, I present in general terms the simplified, cost-effectiveness estimation methodology that we plan to use in <a href=\"https://forum.effectivealtruism.org/posts/DTobNZK2SojvzWfHA/solar4africa-launches-six-fall-23-student-projects-in\">student projects</a> that are evaluating a variety off-grid solar-electric technology access interventions in rural Africa.</p><p>Each of the interventions are focused on the Gobal Health and Welfare (GHW) cause area and either (A) Use funds contributed by philanthropic donors to subsidize access to a particular off-grid solar-electric product or service, or (B) Evaluate new, more efficient ways of administering philanthropic subsidies to potentially a large variety of distributed development activities.</p><p>Generally, the question that we want to answer is: \"What is the probability that a particular intervention can be sufficiently cost-effective to compete with the most cost-effective GHW interventions currently supported by effective altruists (EAs)?\"</p><p>Our focus is on calculating the MARGINAL cost-effectiveness (MCE) of an intervention under the key assumption that if the EA movement maximizes the MCE of donations for charities working in the GHW cause area, then this will maximize the good that EA donors can do for GHW given limited available resources.&nbsp;</p><p>We define the marginal cost-effectiveness to be the inverse of the marginal cost per unit of impact (<i><strong>MCI</strong></i>) which is:&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<i><strong>MCI =&nbsp; Cd / NBs</strong></i></p><p>Where <i><strong>Cd</strong></i> is the cost to donors per unit of intervention, and <i><strong>NBs</strong></i> is the Net benefit of the subsidized intervention that can be attributable to the impact of donor financing.</p><p>Because MCI and MCE are inversely related&nbsp; minimizing MCI, maximizes MCE.</p><p>Note that when donations enable access to a new or higher quality product or service to become available for a population, this is solving a very common market failure. Typically access is enabled by a partial subsidy of a higher quality version of a product or service and without the subsidy the particular product or service may not be available at all in a particular market.&nbsp; <a href=\"https://viterbi-web.usc.edu/~shaddin/cs590fa13/papers/AkerlofMarketforLemons.pdf\">This can happen when there are \"asymmetric information\" market failures in a market, which are very common in lower income countries. See for example: \"Market for Lemons\" ...</a></p><p>When a market-for-lemons market failure occurs, low-benefit products \"crowd out\" higher quality, high-benefit products. Targeted subsidies lower the price of higher-quality products and the lower price for higher quality products allows higher-benefit products to enter the market and compete vis-a-vis cheaper, lower-benefit alternatives.</p><p>In this context, <i><strong>Cd</strong></i> in the equation for <i><strong>MCI</strong></i> represents the cost of subsidizing higher-quality products and services, while <i><strong>NBs</strong></i> represents the net increase in benefit of the higher quality product or service relative to the lower-quality alternative.</p><h2>Target thresholds for MCI and MCE:</h2><p>Different EA meta-charities define a variety of CE thresholds when they evaluate charities and interventions to determine of they are cost-effective.</p><p>Some of the different CE thresholds within the EA GHW community are as follows:</p><p><a href=\"https://www.givewell.org/charities/top-charities\"><strong>GiveWell:</strong></a></p><ul><li>&nbsp; &nbsp;~$5000 per life saved&nbsp;</li><li>&nbsp; &nbsp;~$125/DALY, (Assuming an average of 40 DALY averted per life &nbsp;saved)</li><li>&nbsp; &nbsp;6X to 10X as cost effective as cash transfers</li></ul><p><a href=\"https://www.openphilanthropy.org/research/our-planned-allocation-to-givewells-recommendations-for-the-next-few-years/\"><strong>Open Philanthropy:</strong></a></p><ul><li>&nbsp; &nbsp;$50/DALY</li><li>&nbsp; &nbsp; \"increasing income for 4 people by ~1% for a year for $1\"&nbsp;</li></ul><p><a href=\"https://exploratory-altruism.org/research-methodology/\"><strong>Center for Exploratory Altruism Research</strong></a><strong> (CEARCH):</strong></p><ul><li>&nbsp; &nbsp; &nbsp;10X GiveWell CE of ~700 DALY/$100k</li><li>&nbsp; &nbsp; &nbsp; i.e ~$15/DALY</li></ul><h2>Details re: the Marginal Cost of Impact estimation</h2><p>The two inputs to MCI, cost to donors (<i><strong>Cd</strong></i>) and the net benefit of a subsidized product (<i><strong>NBs</strong></i>), are conceptually simple quantities. But there are several factors that can influence their values in practice. &nbsp;Here we discuss some of the details of estimating <i><strong>Cd</strong></i> and <i><strong>NBs</strong></i> in practice.&nbsp;</p><h3>Estimating <i><strong>Cd</strong></i></h3><p><i><strong>Cd</strong></i> can be somewhat difficult to calculate for the subsidized distribution of products and services because the amount of subsidy versus the amount of customer payment can vary substantially.&nbsp; The beneficiaries of a new product or service will of course want to get that product or service for a price that is as low as possible: preferably for free.&nbsp; But that will not be the scenario in which the intervention is most cost-effective. So a key factor in estimating <i><strong>Cd</strong></i> is estimating the portion of product or service cost that is paid by donations.</p><p>In addition, there are administrative, management, and data collection costs associated with administering and implementing philanthropic subsidies. These costs will tend to be additional to the cost of the product or service subsidy.</p><p>One way of decomposing Cd into component factors is through the following equation:</p><p>&nbsp; &nbsp;&nbsp;<i><strong>Cd = Cprod \u00d7 Psub \u00d7 Md</strong></i>&nbsp;</p><p>Where <i><strong>Cprod</strong></i> is the cost of the product or service, <i><strong>Psub</strong></i> is the percent subsidy that is necessary to make the product affordable and desirable for the beneficiaries, and <i><strong>Md</strong></i> is the markup factor that represent the costs of administration and data collection for the subsidy donation.&nbsp; For example, if for every $1 of subsidy, there are $0.30 of administrative, data collection and donation marketing costs, then <i><strong>Md</strong></i> = 1.3.</p><h3>Estimating <i><strong>NBs</strong></i></h3><p>Similarly, estimating the net benefits of a new product or service is conceptually simple, but can be somewhat more complicated in practice.</p><p>The first key complication is that benefits need to be measured relative to what would have occurred without the subsidy program.&nbsp; While a new and better product may provide clearly measurable benefits, what is harder to measure is what the product users might have done without the subsidized availability of the product.</p><p>The second factor that needs to be considered is that a higher-quality product may last many more years than a lower quality product. In this case, both the benefits and the costs of both the intervention and the no-intervention alternative need to be annualized so that they can be compared over a standard time interval of impact. &nbsp;(For example see: <a href=\"https://www.epa.gov/sites/default/files/2017-09/documents/ee-0568-06.pdf\">https://www.epa.gov/sites/default/files/2017-09/documents/ee-0568-06.pdf</a> for details of how to do this). The annual net benefit of the intervention <i><strong>NBann </strong></i>then becomes the difference between the annualized benefit of the intervention minus the annualized benefit of the alternative in case of no intervention.&nbsp;</p><p>A third factor, is that even though a new product or service may provide a net benefit (such as pumping water for a garden, clean water, or household lighting), the beneficiaries may not utilize the full benefits. We characterize this with a utilization factor (<i><strong>UF</strong></i>) that is generally between 0 and 1, depending on how much the average program beneficiary utilizes the full benefits of a subsidized product or service.</p><p>And last but not least, the value of the annualized benefits may increase or decrease over time. Thus a discounted sum of a net value trend over the expected lifetime or duration of net benefits can be characterized with the net present value (i.e. discounted sum) of relative annual values.&nbsp;</p><p>&nbsp; &nbsp;&nbsp;<i><strong>NBs = [NBann \u00d7 Fattrib \u00d7 UF \u00d7 NPVsum - (1-Psub) \u00d7 Cprod]</strong></i></p><p>In this equation, NBann is the annualized benefit of the intervention minus the benefit produced by the alternative without the intervention.&nbsp; <i><strong>Fattrib</strong></i> represent the fraction of intervention adoption that can be attributed to donations that are supporting the intervention. UF is the fraction by which beneficiaries actually use the new product or service and actually reap its benefits.&nbsp; And <i><strong>NPVsum</strong></i> is the discounted present value of relative annual benefit factors over the lifetime of the product or serve. &nbsp;If the value of <i><strong>NBann</strong></i> is constant over time, then the relative annual benefit factors are all 1.&nbsp;If the value of the benefit increases 10%/year then <i><strong>[Annual Benefit Factor](year+1) = (1 + 10%) \u00d7 [Annual Benefit Factor](year)</strong></i>, etc. The term <i><strong>(1-Psub) \u00d7 Cprod&nbsp;</strong></i> represents the portion of the initial product price paid by the beneficiary.</p><p>And finally, <i><strong>NBs&nbsp;</strong></i>needs to be converted to standardized EA units such as DALYs, or people-percent-years of income increase in order to make the resulting CE estimates comparable to typical minimum CE donation criteria. Another useful cost-effectiveness metric that we like to use is \"dollars of net beneficial impact per dollar donated.\"</p><h2><strong>Accounting for uncertainty and variability</strong></h2><p>Because the inputs that influence&nbsp;impact cost-effectiveness of an intervention can be both uncertain and variable, the results of a CE calculation is most appropriately provided as a probability distribution.</p><p>The standard approach to performing a benefit-cost calculation with variable or uncertain inputs is to perform a Monte Carlo simulation (The Wikipedia page on this topic is quite good:&nbsp;<a href=\"https://en.wikipedia.org/wiki/Monte_Carlo_method\">https://en.wikipedia.org/wiki/Monte_Carlo_method</a>).&nbsp; In our CE estimation with uncertain inputs, we implement a highly simplified Monte Carlo method that we call a simplified Monte Carlo or \"poor man's\" Monte Carlo calculation.</p><p>In our simplified Monte Carlo calculation, we initially estimate ranges for all or most of the input parameters, and represent these ranges by low, median, and high values. Given a probability distribution of what values a parameter may take, the low value represents the average value of the lowest 1/3 of possibilities, the median value represents the average of the middle 1/3 of probable values and the high value represents the average of the largest 1/3 of probably values. This approximates a probability distribution of possible input parameter values by three discrete values of equal probability.&nbsp;</p><p>Once all of the input parameters are represented by three values of equal probability, then the CE result is calculated for all combinations of input parameters. If each of the input parameters are independent and uncorrelated, then the set of CE values that result from all combinations of inputs all have equal probability. A histogram of the full set of CE results is then constructed to illustrate the full range of possible CE values and their respective approximate probabilities.&nbsp;</p><p>We illustrate this simplified Monte Carlo calculation below.&nbsp;</p><h2><strong>Example calculations of CE distributions</strong></h2><h3><strong>Example calculation for long-lasting solar lights</strong></h3><p>To illustrate the CE estimation methodology above, we perform example calculations for nascent interventions that <a href=\"https://www.solar4africa.org/\">Solar4Africa.org</a> implements in rural Malawi. One such intervention is the subsidized distribution of small solar lighting systems with cell phone charging to households in rural villages. The solar lighting system uses a newer, slightly more expensive battery chemistry (i.e., lithium titanate) which has cycle-life that is approximately ten times the cycle life of standard lithium ion batteries which are commonly used in solar lights in throughout rural Africa&nbsp;</p><p>Here we calculate the MCE for subsidized long-lasting solar lights, using the equations specified above:&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<i><strong>MCE =&nbsp;NBs/Cd&nbsp;</strong></i></p><p><i><strong>&nbsp; &nbsp; &nbsp; = [NBann\u00d7Fattrib\u00d7UF\u00d7NPVsum-(1-Psum)\u00d7Cprod]/[Cprod\u00d7Psub\u00d7Md]</strong></i></p><p>The ranges of parameter values for the calculation are specified in Table 1. The system costs approximately $30 installed though depending on assembly and distribution efficiency, the installed cost can range from $20 to $40. Customers pay for the lighting system, but pay a subsidized price. The annual benefits of the solar lighting system consists of not having to pay for disposable batteries for a battery-powered light and not having to pay for cell phone charging at a local trading center.&nbsp; These savings can range from $2/month to $5/month or $24 to $60 per year of savings. Impact attribution is less than 100% because it is possible for some households to buy alternative solar systems from other providers, and some households may not use the system for its entire lifetime. Because of the very long battery life, the system can last from 5 to 15 years so the discounted <i><strong>NPVsum</strong></i> ranges from 4.5 to 11 for a discount rate that may vary between 2%/year to 6%/year.&nbsp;</p><p><strong>Table 1: Input parameters for subsidized long-lasting solar lights cost-effectiveness</strong></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><strong>Variable</strong></td><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><p><strong>Low Value</strong></p></td><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><p><strong>Medium Value</strong></p></td><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><p><strong>High Value</strong></p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>Cprod</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>$20</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>$30</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>$40</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>Psub</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>20%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>35%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>50%</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>Md</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>1.2</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>1.35</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>1.5</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>NBann</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>$24</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>$40</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>$60</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>Fattrib</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>30%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>60%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>90%</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>UF</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>40%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>60%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>80%</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>NPVsum</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>4.5</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>8</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>11</p></td></tr></tbody></table></figure><p>The results of the simplified Monte Carlo calculation is shown in Table 2 for the full set of 3<sup>7</sup> = 2187&nbsp;input parameter combinations.&nbsp;</p><p>For this intervention, the most probable cost-effectiveness is approximately $8 of benefit per $1 donated. If these benefits accrue to people who have a per-capita income of $200/year, then this corresponds to the poverty-reduction cost-effectiveness that is equal to the threshold stated by Open Philanthropy of&nbsp;\"increasing income for 4 people by ~1% for a year for $1.\"&nbsp;</p><p><strong>Table 2: Results of Monte Carlo calculation for subsidized long-lasting solar lights</strong></p><figure class=\"table\"><table><tbody><tr><td>$ Benefit/$ Donated</td><td>Frequency</td></tr><tr><td style=\"text-align:right\">&lt;0.7</td><td style=\"text-align:right\">178</td></tr><tr><td style=\"text-align:right\">1</td><td style=\"text-align:right\">156</td></tr><tr><td style=\"text-align:right\">2</td><td style=\"text-align:right\">306</td></tr><tr><td style=\"text-align:right\">4</td><td style=\"text-align:right\">472</td></tr><tr><td style=\"text-align:right\">8</td><td style=\"text-align:right\">545</td></tr><tr><td style=\"text-align:right\">16</td><td style=\"text-align:right\">348</td></tr><tr><td style=\"text-align:right\">32</td><td style=\"text-align:right\">156</td></tr><tr><td style=\"text-align:right\">64</td><td style=\"text-align:right\">25</td></tr><tr><td style=\"text-align:right\">128</td><td style=\"text-align:right\">1</td></tr></tbody></table></figure><p>&nbsp;</p><h3><strong>MCI estimate for subsidized mosquito trap</strong></h3><p>A similar calculation can be performed for subsidizing solar powered mosquito traps to reduce the incidence of malaria in rural Malawi. <a href=\"https://pubmed.ncbi.nlm.nih.gov/27460054/\">Mass mosquito trapping is a malaria vector control method that has shown some promise</a>, but which is not yet widely deployed. Solar4Africa.org has found that small DC fans can be used to make a very simple, low-power mosquito trap than can kill hundreds of mosquitos per night, even without using odor bait.&nbsp;</p><p>Here we use our CE estimation methodology to estimate the marginal cost of impact of this intervention in units of $/DALY, assuming that the simple traps cost about $20 each, that the subsidy ranges from 50% to 100%, and that a baseline Malaria burden of disease of a family of 4 of 0.2 DALY/year can be reduced between 10% and 50%.</p><p>The equation for the marginal cost of impact is:</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<i><strong>MCI =&nbsp;Cd / NBs&nbsp;</strong></i></p><p><i><strong>&nbsp; &nbsp; &nbsp;=&nbsp;[Cprod\u00d7Psub\u00d7Md</strong></i>&nbsp;<i><strong>] / [NBann\u00d7Fattrib\u00d7UF\u00d7NPVsum]</strong></i>&nbsp;</p><p>Because the benefits are measured in units of DALY of disease impact avoided, we do not subtract the consumer cost of the mosquito trap. This is equivalent to saying that if the user is paying for a portion of the trap cost, then they will get other benefits from the trap such as greater comfort from fewer mosquito bites.&nbsp;</p><p>Table 3 provides the input parameter values used in constructing a simplified Monte Carlo calculation of MCI.&nbsp;</p><p><strong>Table 3: Input parameters for subsidized solar-powered mosquito traps</strong></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><strong>Variable</strong></td><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><p><strong>Low Value</strong></p></td><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><p><strong>Medium Value</strong></p></td><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><p><strong>High Value</strong></p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>Cprod</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>$15</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>$20</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>$25</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>Psub</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>50%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>75%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>100%</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>Md</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>1.3</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>1.6</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>2.0</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>NBann (DALY/yr)</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>0.02</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>0.05</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>0.10</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>Fattrib</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>60%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>80%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>100%</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>UF</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>50%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>75%</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>90%</p></td></tr><tr><td style=\"border-color:windowtext;padding:0in 5.4pt;vertical-align:top\"><i><strong>NPVsum</strong></i></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>2</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>4</p></td><td style=\"border-bottom:1.0pt solid windowtext;border-right:1.0pt solid windowtext;padding:0in 5.4pt;vertical-align:top\"><p>6</p></td></tr></tbody></table></figure><p>&nbsp;</p><p><strong>Table 4: Results of Monte Carlo calculation of marginal cost of impact for subsidized malaria mosquito traps</strong></p><figure class=\"table\"><table><tbody><tr><td>$/DALY</td><td>Frequency</td></tr><tr><td style=\"text-align:right\">20</td><td style=\"text-align:right\">11</td></tr><tr><td style=\"text-align:right\">40</td><td style=\"text-align:right\">124</td></tr><tr><td style=\"text-align:right\">80</td><td style=\"text-align:right\">371</td></tr><tr><td style=\"text-align:right\">160</td><td style=\"text-align:right\">553</td></tr><tr><td style=\"text-align:right\">320</td><td style=\"text-align:right\">550</td></tr><tr><td style=\"text-align:right\">640</td><td style=\"text-align:right\">377</td></tr><tr><td style=\"text-align:right\">1280</td><td style=\"text-align:right\">164</td></tr><tr><td style=\"text-align:right\">2560</td><td style=\"text-align:right\">37</td></tr></tbody></table></figure><p>Table 4 shows the distribution of results arising from the simplified Monte Carlo calculation of MCI. &nbsp;About half of the time the intervention is not cost effective relative to the GiveWell threshold of $150/DALY averted. &nbsp;Compared to the Open Philanthropy and CEARCH criteria of $50/DALY and $15/DALY, the intervention is not cost-effective most of the time. But we note that the intervention might be cost-effective relative to the more stringent criteria if the mosquito trapping device can be made to last a long time, if it can have a relatively large impact on vector populations, and if it is deployed in areas with a high burden of Malaria disease.&nbsp;</p><h2>Summary/Conclusion</h2><p>In the <a href=\"https://www.solar4africa.org/technical-details/fall-2023-student-projects\">Fall-23 EA student projects</a> being conducted by Solar4Africa.org we are searching for new solar-powered interventions that can be cost-competitive with some of the most cost-effective GHW interventions that are supported by EAs.&nbsp;</p><p>We have developed generic marginal cost-effectiveness equations and a simplified Monte Carlo technique which allows the calculations of a probability distribution of results for either marginal cost-effectiveness or the marginal cost of impact. &nbsp;These methods allow the estimation of the probability that new interventions with uncertain inputs can reach different cost-effectiveness threshold criteria.&nbsp;</p><p>Our hope is that this will aid in the development of new, highly cost-effective and a greater variety of easy-to-implement interventions that can help the EA movement produce greater GHW progress given the limited EA donation resources that are available now and in the near-term future.&nbsp;<br>&nbsp;</p>", "user": {"username": "Robert Van Buskirk"}}, {"_id": "iYrMBfxM2P9JNHM4A", "title": "Global Catastrophic Biological Risks: A Guide for Philanthropists [Founders Pledge]", "postedAt": "2023-10-31T15:42:49.525Z", "htmlBody": "<p>This post contains the summary and introduction of our new report <a href=\"https://www.founderspledge.com/research/global-catastrophic-biological-risks-a-guide-for-philanthropists\"><i>Global Catastrophic Biological Risks</i></a>. Like our recent work on <a href=\"https://forum.effectivealtruism.org/posts/tRbCjvm4cuuzm95Mv/nuclear-risk-and-philanthropic-strategy-founders-pledge\">nuclear issues</a>, it is intended to serve as a guide for philanthropists interested in working on this issue.</p><p><strong>You can find the full report as a PDF </strong><a href=\"https://dkqj4hmn5mktp.cloudfront.net/GCBR_Report_Founders_Pledge_7505b1ebe0.pdf\"><strong>here</strong></a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefd5lijp824jb\"><sup><a href=\"#fnd5lijp824jb\">[1]</a></sup></span>&nbsp;That version also includes acknowledgments and two external reviews of the report, by Joshua Monrad and Andrew Snyder-Beattie. Many thanks to them and everyone else who helped with their insights and edits for this report (see the acknowledgements section in the full version).</p><p><i>Please consider skimming the full report before leaving comments here.</i></p><h1>Summary</h1><p>This report provides an overview of the threat of global catastrophic biological risks (GCBRs) and how philanthropists can help to mitigate this threat. Using semi-structured interviews and analysis of available data on funding and pandemic preparedness, the report argues that:</p><ol><li><strong>The expected cost of a biological catastrophe is immense. </strong>High-consequence biological events like engineered pandemics are among the biggest threats to human life and modern civilization this century.</li><li>Biological risks could pose an <i>existential</i>&nbsp;threat to humanity, but the case for pandemic preparedness and prevention remains strong even without placing special value on existential risks.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2iwwwm5k69u\"><sup><a href=\"#fn2iwwwm5k69u\">[2]</a></sup></span>&nbsp;</li><li><strong>The threat landscape is rapidly changing</strong>. New advances in the life sciences and enabling technologies \u2014 which could have immense benefits for humanity \u2014 may increase the risk by both providing new capabilities and enabling the use of these capabilities by reckless and malicious actors.</li><li>These changes also <u>increase uncertainty</u>&nbsp;about the origin and characteristics of future biological threats.</li><li><strong>Societal spending remains misallocated</strong>&nbsp;even in the wake of the COVID-19 pandemic. Although governments and traditional philanthropists spend billions on public health and health security, they disproportionately neglect the most high-consequence threats.</li></ol><p>These basic facts point towards a general problem structure that is familiar from Founders Pledge\u2019s work on <a href=\"https://www.founderspledge.com/research/changing-landscape\"><u>climate change</u></a>&nbsp;and <a href=\"https://www.founderspledge.com/research/global-catastrophic-nuclear-risk-a-guide-for-philanthropists\"><u>nuclear war</u></a>: the worst possible biological catastrophes will be <i>disproportionately</i>&nbsp;worse than other pandemics, yet they are simultaneously disproportionately neglected.</p><p>Fortunately, <strong>we know what to do</strong>;<strong>&nbsp;</strong>with an understanding of basic facts about the problem and strategic reasoning about the uncertainties of future threats, philanthropists can fund clear and tractable interventions. Stated succinctly, <strong>philanthropists ought to</strong>&nbsp;<strong>hedge against the worst possible scenarios</strong>&nbsp;where traditional risk-mitigation has failed by following quasi-quantitative heuristics for effectiveness, or \u201cimpact multipliers.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6g94lwsrmnr\"><sup><a href=\"#fn6g94lwsrmnr\">[3]</a></sup></span>&nbsp;Such heuristics can guide philanthropists in identifying the funding opportunities that are likely to have the highest impact on the margins. They include:</p><ul><li><strong>Focus on worst-case scenarios. </strong>Disease outbreaks (like terrorist events) follow very heavy-tailed distributions, where the worst pandemics outweigh many smaller pandemics combined. Such events are both disproportionately important and unduly neglected.</li><li>In practice, this often means <strong>prioritizing engineered threats</strong>. Nature is <i>not</i>&nbsp;the worst bioterrorist.</li><li>Within anthropogenic events, generally <strong>pursue pathogen- and threat-agnostic approaches</strong>. Rather than trying to guess where the next pandemic will come from, philanthropists ought to support approaches that are robust to a variety of scenarios.</li><li><strong>Fund interventions that are robust to the entire spectrum of risk</strong>, including natural pandemics, and up to and including extinction-level engineered pandemics.</li><li>In practice, this often means prioritizing <strong>prevention</strong>&nbsp;over prioritizing response.</li><li><strong>Leverage existing societal resources</strong>&nbsp;using advocacy-based interventions (largely for government, but also for other large funders), with a few notable exceptions where government interests appear unlikely to align.</li><li><i>All else equal, </i><strong>prioritize interventions with near-term positive externalities</strong>&nbsp;that can garner sustained and broad political support.</li><li><strong>Prioritize low-dual use potential </strong>and<strong>&nbsp;high offense-defense distinguishability</strong>&nbsp;and <strong>avoid information hazards </strong>when selecting funding opportunities to avoid fuelling dangerous security dilemmas and doing more harm than good.</li></ul><p>A final section discusses possible funding opportunities that leverage these heuristics. Promising funding opportunities include:</p><ul><li><strong>Field building</strong>&nbsp;and <strong>policy advocacy</strong>&nbsp;on issues relevant for worst-case GCBR scenarios.</li><li>Policy advocacy may include advocacy specifically designed to constrain the access and capabilities of malevolent actors or to disincentivize the pursuit of biological weapons programs.</li><li><strong>Safeguards against proliferation and misuse of key technologies and information</strong>, especially AI misuse and DNA synthesis screening.</li><li><strong>Transmission-blocking interventions, </strong>including sterilizing technology, work on germicidal lights for indoor biological air quality, mechanisms to quickly decontaminate PPE, and more.</li><li><strong>Pandemic-proof personal protective equipment</strong>&nbsp;(P4E).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0tmkya1svkz\"><sup><a href=\"#fn0tmkya1svkz\">[4]</a></sup></span></li><li><strong>Pathogen-agnostic early warning</strong>, including metagenomic sequencing.</li><li><strong>Platform technologies for medical countermeasures</strong>&nbsp;to rapidly pivot production and distribution for novel threats.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyuhchishg5\"><sup><a href=\"#fnyuhchishg5\">[5]</a></sup></span></li></ul><p>The report also discusses various dilemmas that philanthropists face when making funding decisions, and provides a <strong>grantmaker dilemma checklist </strong>to help screen for information hazards and security dilemmas. Philanthropists can play an important role in mitigating catastrophic biological risks, and this guide is designed to help guide the grantmaking strategy of impact-minded philanthropists.</p><h1>A Note on Hazardous Information</h1><p>Some discussions of biological risks present <a href=\"https://www.fhi.ox.ac.uk/wp-content/uploads/Lewis_et_al-2019-Risk_Analysis.pdf\"><u>information hazards</u></a>&nbsp;that could increase the risks of a catastrophe merely by spreading information (e.g. the biological details of especially dangerous viruses) that could enable malevolent actors to cause great harm, as discussed <a href=\"https://docs.google.com/document/d/1_EvIj20F5UjoN2GfGShDlLrLBAXmAVePH8EwVeuIsYM/edit%23heading%3Dh.fcc1z1d8frir\"><u>below</u></a>. To make a responsible contribution to the literature on biological risks, this report therefore attempts to follow <a href=\"https://docs.google.com/document/u/0/d/1VSfU3GiZumHDX2hoz3YY1PT2dQHtkbrfO8xLxI9BTGE/mobilebasic%23ftnt3\"><u>best practices</u></a>&nbsp;surrounding the disclosure of vulnerabilities and capabilities, including by:</p><p>&nbsp;</p><ul><li>Avoiding discussion of specific biological threats or \u201cblueprints\u201d for harm</li><li>Discussing the features of risky pathogens only in abstract and general terms</li><li>Not disclosing or drawing attention to specific biodefense vulnerabilities</li><li>Using well-known historical examples whenever possible</li><li>Asking pre-publication reviewers to pay special attention to potentially hazardous information</li></ul><p>&nbsp;</p><p>Fortunately, because <a href=\"https://docs.google.com/document/d/1_EvIj20F5UjoN2GfGShDlLrLBAXmAVePH8EwVeuIsYM/edit%23heading%3Dh.ehm1rgwz2jwq\"><u>threat-agnostic interventions also happen to be high-impact interventions</u></a>, responsible conduct around dangerous information does not hinder the discussion of effective philanthropy. <strong>Readers concerned about information contained in this report are encouraged to contact the author</strong>&nbsp;at <a href=\"mailto:christian@founderspledge.com\"><u>christian@founderspledge.com</u></a>.</p><h1>Introduction</h1><p>Humanity is underprepared for future pandemics. As explained in the following sections, novel biological threats \u2014 especially those caused by engineered pathogens \u2014 could kill hundreds of millions or even billions of people and precipitate the collapse of modern civilization. Existing resources generally do not prioritize catastrophic scenarios.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5r2ygvpiker\"><sup><a href=\"#fn5r2ygvpiker\">[6]</a></sup></span>&nbsp;Several policymakers who have worked on pandemic preparedness and response described their experiences in interviews for this report; all agreed that <strong>society is not ready for the next pandemic, natural or engineered</strong>.</p><p>Worse, the COVID-19 pandemic was not the wake-up call it could have been. In an interview for this report, Jason Matheny, the CEO of the RAND Corporation, who previously led White House policy on technology and national security at the National Security Council and the Office of Science and Technology Policy and has extensive expertise on catastrophic biological risks, explained that &nbsp;\u201cpolicymakers are suffering from pandemic fatigue [...] They are just sick and tired of hearing about the pandemic and having to pay for it.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5krcumej27o\"><sup><a href=\"#fn5krcumej27o\">[7]</a></sup></span>&nbsp;Similarly, Tom Inglesby, the Director of the Johns Hopkins Center for Health Security, explained in an interview for this report, \u201c[In government] there's COVID fatigue, let alone interest in taking on things that are bigger than COVID.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5wwrugqk599\"><sup><a href=\"#fn5wwrugqk599\">[8]</a></sup></span>&nbsp;This fatigue is not limited to policymakers but extends to many traditional philanthropic funders, as explained below (see <a href=\"https://docs.google.com/document/d/1_EvIj20F5UjoN2GfGShDlLrLBAXmAVePH8EwVeuIsYM/edit%23heading%3Dh.l9tefm6wxa46\"><u>Societal Spending and Neglectedness</u></a>). The recent collapse of large philanthropic entities linked to FTX and the withdrawal of other funders has only worsened this situation by removing millions of dollars from biosecurity and pandemic\u2013preparedness philanthropy.</p><p>This matters because new advances in the life sciences and in related enabling technologies like artificial intelligence (AI) are creating a rapidly-shifting threat landscape. If society does not take action to regulate access to these technologies \u2014 or to promote differential technological development \u2014 their powerful capabilities may not only provide benefits to humanity, but may also proliferate to malevolent actors who seek to weaponize synthetic biology.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzguulue684b\"><sup><a href=\"#fnzguulue684b\">[9]</a></sup></span>&nbsp;History shows that state bioweapons programs, non-state bioterrorism, and laboratory leaks are not uncommon.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefucyq0o9w0f\"><sup><a href=\"#fnucyq0o9w0f\">[10]</a></sup></span>&nbsp;As more and more actors gain access to the necessary tools and training in genetic engineering, the risk of deliberate and accidental release of such pathogens increases, and with it, the risk of a global catastrophe, civilizational collapse, and even human extinction.</p><p>The devastation of the COVID-19 pandemic could have catalyzed a movement towards better pandemic preparedness. Instead, societies remain asleep at the wheel, careening towards a new age of democratized synthetic biology with few guardrails. The specifics of these problems are described in detail below, but one senior policymaker who used to work on biological risks in the U.S. government summarized it bluntly in an anonymized interview for this report: \u201cI just came away from that [i.e. government service on biosecurity] thinking, we're just completely fucked.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffg8rqclade\"><sup><a href=\"#fnfg8rqclade\">[11]</a></sup></span></p><p>This report is intended as a detailed roadmap for philanthropists who want to do something about these global catastrophic biological risks (GCBRs).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflwavb5b1889\"><sup><a href=\"#fnlwavb5b1889\">[12]</a></sup></span>&nbsp;We hope that this guide will help catalyze more funding on GCBRs, because \u2014 as the following sections explain \u2014 they are:</p><ul><li><strong>Important</strong>&nbsp;\u2014 Pandemics can kill millions of people, and engineered pathogens are among the few credible extinction risks to modern civilization.</li><li><strong>Neglected</strong>&nbsp;\u2014 Although governments spend billions on health security, we estimate that less than 2% of this money is relevant to the prevention of catastrophic or potential extinction-level biological events.</li><li><strong>Tractable</strong>&nbsp;\u2014 Unlike other important and neglected risks, like risks from advanced artificial intelligence, we have a firm grasp of the problem, and can identify many actionable funding opportunities that can mitigate the risk.</li></ul><p>Society needs philanthropists to take up this issue, because no one else has. As one former senior U.S. policymaker interviewed for this project put it, \u201c<strong>without philanthropists funding work in this area, it's not going to get funded</strong>.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl6k2q7emnc\"><sup><a href=\"#fnl6k2q7emnc\">[13]</a></sup></span>&nbsp;</p><h1><a href=\"https://dkqj4hmn5mktp.cloudfront.net/GCBR_Report_Founders_Pledge_7505b1ebe0.pdf\">Full Report (PDF)</a></h1><h1>About Founders Pledge</h1><p>Founders Pledge is a global nonprofit empowering entrepreneurs to do the most good possible with their charitable giving. We equip members with everything needed to maximize their impact, from evidence-led research and advice on the world\u2019s most pressing problems, to comprehensive infrastructure for global grant-making, alongside opportunities to learn and connect. To date, they have pledged over $10 billion to charity and donated more than $950 million. We\u2019re grateful to be funded by our members and other generous donors. founderspledge.com&nbsp;</p><p><strong>If you are interested in supporting work in this area, </strong><a href=\"https://www.founderspledge.com/funds/global-catastrophic-risks-fund#prevent-the-most-severe-global-catastrophes\"><strong>consider donating to the Global Catastrophic Risks Fund</strong></a><strong>.&nbsp;</strong></p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnd5lijp824jb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefd5lijp824jb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I tried posting the full report here, but it kept crashing.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2iwwwm5k69u\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2iwwwm5k69u\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Some sections of this report discuss questions of extinction and civilizational collapse. To the extent that readers subscribe to worldviews that place high moral value on the long-term future of humanity, biological risk mitigation therefore becomes especially important, and plausibly one of the most important causes that philanthropists can focus on. Nonetheless, as argued throughout the report, the super-linear structure of the risk means that worst-case pandemics remain important from many ethical perspectives.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6g94lwsrmnr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6g94lwsrmnr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For a discussion of the concept of impact multipliers, see <a href=\"https://docs.google.com/document/d/e/2PACX-1vTm5I2zETjfm-laWUvgzk-_jrFENeQlghWTWmyT2MAfnj4B6wOUcmTAGqpan-8TPl35qxyJJnFeiQC7/pub#h.eapklxiq7mh9\"><u>Guiding Principles for Effective Philanthropy</u></a>, in the full report.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0tmkya1svkz\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0tmkya1svkz\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This term is borrowed from the work of Dr. Kevin Esvelt. See also <a href=\"https://www.gryphonscientific.com/towards-a-theory-of-pandemic-proof-ppe/\"><u>recent work</u></a>&nbsp;by Gryphon Scientific on this topic.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyuhchishg5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyuhchishg5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;As discussed below, large uncertainties surround the robustness of medical countermeasures to worst-case threat scenarios,</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5r2ygvpiker\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5r2ygvpiker\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cEven the best-prepared nations lack sufficient protective equipment for most key personnel, and vaccines and other medical countermeasures could not plausibly be manufactured and distributed in any time frame shorter than months, if they could be developed at all.\u201d (Kevin M Esvelt, \u201cDelay, Detect, Defend: Preparing for a Future in Which Thousands Can Release New Pandemics,\u201d Geneva Papers (Geneva Centre for Security Policy, 2022), 13, <a href=\"https://dam.gcsp.ch/files/doc/gcsp-geneva-paper-29-22?_gl%3D1*xm44p1*_ga*ODQxMDI0NjY4LjE2ODM2NTg5MTg.*_ga_Z66DSTVXTJ*MTY4MzczNTIzNi4yLjAuMTY4MzczNTIzNi4wLjAuMA..%23page%3D49%26zoom%3D100,0,0\"><u>https://dam.gcsp.ch/files/doc/gcsp-geneva-paper-29-22?_gl=1*xm44p1*_ga*ODQxMDI0NjY4LjE2ODM2NTg5MTg.*_ga_Z66DSTVXTJ*MTY4MzczNTIzNi4yLjAuMTY4MzczNTIzNi4wLjAuMA..#page=49&amp;zoom=100,0,0</u></a><a href=\"https://www.zotero.org/google-docs/?IR7zHJ\">.</a>)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5krcumej27o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5krcumej27o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Interview with Dr. Jason Matheny, 30 May 2023.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5wwrugqk599\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5wwrugqk599\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Interview with Dr. Tom Inglesby, 8 June 2023.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzguulue684b\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzguulue684b\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See <a href=\"https://docs.google.com/document/d/e/2PACX-1vTm5I2zETjfm-laWUvgzk-_jrFENeQlghWTWmyT2MAfnj4B6wOUcmTAGqpan-8TPl35qxyJJnFeiQC7/pub#h.u62sb59lhr84\"><u>The Growing Risk of Biological Catastrophe</u></a>, below. Thanks to Jake Swett for emphasizing the importance of differential technological development.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnucyq0o9w0f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefucyq0o9w0f\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See <a href=\"https://docs.google.com/document/d/e/2PACX-1vTm5I2zETjfm-laWUvgzk-_jrFENeQlghWTWmyT2MAfnj4B6wOUcmTAGqpan-8TPl35qxyJJnFeiQC7/pub#h.1q342spjh2kd\"><u>Bioweapons, Bioterrorism, and Laboratory Leaks</u></a>, below.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfg8rqclade\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffg8rqclade\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Anonymized interview.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlwavb5b1889\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflwavb5b1889\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We adopt the following definition of GCBRs proposed by scholars from the Johns Hopkins Center for Health Security: \u201cThose events in which biological agents\u2014whether naturally emerging or reemerging, deliberately created and released, or laboratory engineered and escaped\u2014could lead to sudden, extraordinary, widespread disaster beyond the collective capability of national and international governments and the private sector to control. If unchecked, GCBRs would lead to great suffering, loss of life, and sustained damage to national governments, international relationships, economies, societal stability, or global security.\u201d Monica Schoch-Spana et al., \u201cGlobal Catastrophic Biological Risks: Toward a Working Definition,\u201d <i>Health Security</i>&nbsp;15, no. 4 (August 1, 2017): 323\u201328, <a href=\"https://doi.org/10.1089/hs.2017.0038\"><u>https://doi.org/10.1089/hs.2017.0038</u></a><a href=\"https://www.zotero.org/google-docs/?qhLV8z\">.</a>&nbsp;For another discussion of the definitional difficulties, see Jaime Yassif, \u201cReducing Global Catastrophic Biological Risks,\u201d <i>Health Security</i>&nbsp;15, no. 4 (August 1, 2017): 329\u201330, <a href=\"https://doi.org/10.1089/hs.2017.0049\"><u>https://doi.org/10.1089/hs.2017.0049</u></a><a href=\"https://www.zotero.org/google-docs/?J0mpwj\">.</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl6k2q7emnc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl6k2q7emnc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Anonymized interview with U.S. biosecurity expert.</p></div></li></ol>", "user": {"username": "christian.r"}}, {"_id": "t5x9xLew2ZeENAzzT", "title": "Let's celebrate some wins", "postedAt": "2023-10-31T10:43:38.075Z", "htmlBody": "<p>Seems like there are quite a lot of wins to celebrate recently and I think it would be helpful for us to do so.</p><p>Thanks to everyone who helped in these.</p>", "user": {"username": "nathan"}}, {"_id": "gLyvwdRaSd9tS75g4", "title": "[Closed] Agent Foundations track in MATS", "postedAt": "2023-10-31T08:14:12.995Z", "htmlBody": "", "user": {"username": "Vanessa"}}, {"_id": "WyLJ7bpprDh4exDfh", "title": "Updates from Campaign for AI Safety", "postedAt": "2023-10-31T05:46:43.080Z", "htmlBody": "<p>Hi!</p><h2>\ud83c\udf0d #PauseAI Protests Recap</h2><p>On 21 October 2023, voices around the world united in the International #PauseAI Protests, advocating for AI safety. Missed the action? Catch the highlights, stirring speeches, and global solidarity on <a href=\"https://www.linkedin.com/company/campaign-for-ai-safety/\">our LinkedIn page</a>.</p><p>The next PauseAI protest is on Wednesday, 1 November at Bletchley Park (where the summit will be held):</p><p><a href=\"https://pauseai.info/2023-november-uk\">PauseAI protest @ Bletchley Park - November 1st</a></p><hr><h2>\ud83c\udf1f AI safety awareness spreads across London!</h2><p>We are running a small-scale billboard campaign in London ahead of the summit, asking for a pause on AI scaling.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/WyLJ7bpprDh4exDfh/x8ser6lex05rvps9pf7d\" alt=\"\"></p><p><a href=\"https://twitter.com/ai_ctrl\">Control AI</a> are doing bigger campaigning in London:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/WyLJ7bpprDh4exDfh/viinruff5czclsxmdw21\" alt=\"\"></p><hr><h2>\ud83d\udcca Recent Research Insights</h2><p>A poll by Control AI and YouGov highlighted growing public support in the UK for strict regulations on AI development. 74% believe preventing AI from exceeding human capabilities is crucial, and 60% endorse a global ban on AI smarter than humans. This challenges the current AI Safety Summit\u2019s direction. Control AI advocates for setting strict AI scaling limits and establishing an international safety-focused organization.</p><p><a href=\"https://www.linkedin.com/pulse/poll-shows-british-public-supports-moratorium-smarter-than-human-qvbpc\">Poll shows British public supports moratorium on smarter-than-human AI, limits on AI scaling</a></p><p>Separately, we conducted AI perception check in Taiwan (available to paid subscribers):</p><p><a href=\"https://www.campaignforaisafety.org/taiwan-ai-perception-check/\">Taiwan AI perception check</a></p><hr><h2>\ud83d\udeab Meta HQ Protest</h2><p>AI safety advocate <a href=\"https://twitter.com/ilex_ulmus\">Holly Elmore</a> led a vital protest on September 29, 2023, challenging the proliferation of AI model weights at Meta's HQ. Experience the passion and determination firsthand through <a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7114475419478724608\">our LinkedIn post</a>. Join the movement for an ethical AI future. \ud83c\udf10</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/WyLJ7bpprDh4exDfh/kbvctqdefmv9pyseawrr\" alt=\"\"></p><p>Holly Elmore and advocates in Meta HQ Protest, on September 29, 2023</p><hr><h2>\ud83d\udcc3 Policy updates</h2><p>On the policy front, we have made the following submissions:</p><ul><li><a href=\"https://www.campaignforaisafety.org/submission-inquiry-into-artificial-intelligence-ai-in-nsw/\">Submission to the Portfolio Committee No. 1 - Premier and Finance's Inquiry into Artificial Intelligence (AI) in NSW</a></li><li><a href=\"https://www.campaignforaisafety.org/submission-to-the/\">Submission to the Notice of Inquiry on Copyright and Artificial Intelligence, by the US Copyright Office</a></li><li><a href=\"https://www.campaignforaisafety.org/submission-to-the-high-level-advisory-body-on-artificial-intelligences-call-for-papers-on-global-ai-governance-by-the-office-of-the-secretary-generals-envoy-on-technology/\">Submission to the High-level Advisory Body on Artificial Intelligence\u2019s Call for Papers on Global AI Governance, by the Office of the UN Secretary-General's Envoy on Technology</a></li></ul><p>Now, we are working on updating our <a href=\"https://www.campaignforaisafety.org/r/0ea639ce?m=866ebbbb-d122-4eec-b595-77a07fe17483\">main campaign policy document</a>.</p><p>Do you know of other inquiries? Please let us know. You may respond to this email if you want to contribute to the upcoming consultation papers.</p><hr><h2>\ud83d\udcdc Petition updates</h2><p>\ud83c\uddec\ud83c\udde7 For our supporters in the UK, there's an <a href=\"https://petition.parliament.uk/petitions/639956\">ongoing petition led by Greg Colbourn</a>. This petition urges the global community to consider a worldwide moratorium on AI technology development due to human extinction risks. As of now, the petition has garnered 48 signatures in support of this crucial cause.</p><hr><p>Last week, we had received <a href=\"https://twitter.com/DrTechlash/status/1713720054355996894\">attention</a> from Dr. Nirit Weiss-Blatt who made an \"expos\u00e9\" by cherry-picking screenshots from the campaign website for a contrived narrative about us. But thanks to her more people know about our work, even if ill-informed.</p><p>Thank you for your support! Please <a href=\"https://www.campaignforaisafety.org/donate/\">donate to the campaign</a> to help us fund ads in London ahead of the UK AI summit. Please share this email with friends.<br><br>Campaign for AI Safety<br><a href=\"https://www.campaignforaisafety.org/\">campaignforaisafety.org</a></p>", "user": {"username": "Jolyn Khoo"}}, {"_id": "dxHZ3jtaJcvp9juSx", "title": "Is there any work on cause prioritization that takes into account timelines being worldview-dependent?", "postedAt": "2023-10-31T02:25:40.329Z", "htmlBody": "<p>I'll illustrate this as follows:</p><p>Imagine you have two models of the world: an x-risk worldview and a near-termist worldview. In the first you expect, AGI will on average arrive in 15 years and in the second, you expect that it will on average arrive in 100 years.</p><p>For the purposes of simplicity, we'll assume that money is only valuable before it arrives. Let's suppose you want to dedicate $A worth of net-present value to x-risk and $B worth of net-present value to near-termist causes. Then it seems like you'd want to adjust your spend rate to take account of the possibility of one world having a longer timeline than the other. A naive model would just divide the spend over the expected number of years.</p><p>Of course, there are a huge number of factors here if you wanted a better model:</p><p>\u2022 Your timeline estimate should probably be a range.<br>\u2022Beyond this, there's the possibility of outside of the model error. If your timeline is too short neither cause dips into the other, but if it's too long, then you'd feel pressure to dip into your near-termist funds and the fact that this could only ever go one way would be unfair.<br>\u2022 Your understanding of timelines might improve over time. In some cases, it might make sense to start investing more in the cause with the apparently shorter timeline and back off if this seems to have been a mistake.<br>\u2022 You might hope that your understanding of cause prioritisation would improve over time. Spending now can sometimes be used to set up the possibility of more useful spending later.<br>\u2022 You could discover a completely new cause area, so it might make sense to hold back money for that.<br>\u2022 You might expect the EA community's resources and ability to influence resources to increase of time.<br>\u2022 The opportunities for investing in a cause area might improve over time.<br><br>So, there are really a lot of factors there. Does anyone know of any existing research on this?</p>", "user": {"username": "casebash"}}, {"_id": "vq5pHzrxLgABAwkhD", "title": "Shrimp paste might cause more animal deaths than any other food product. Who\u2019s working on this?", "postedAt": "2023-10-30T21:53:35.852Z", "htmlBody": "<p><i>Epistemic status:&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/fPu5eWJagwDvqxiGY/terminate-deliberation-based-on-resilience-not-certainty\"><i><u>Low resilience</u></i></a><i>. Quick writeup from an amateur with no background in welfare research. Publishing this because I can't find a basic writeup of this case anywhere.</i></p><h2>TL;DR</h2><ul><li>Acetes japonicus are potentially&nbsp;<strong>the most common species of animal killed for food production</strong> today, by number of individuals.</li><li><strong>They are used to create akiami shrimp paste</strong>, a product used predominantly as a flavoring base in Southeast Asian and Southern Chinese cuisines.</li><li>There\u2019s some reason to believe shrimp paste could be easier to create plant based substitutes for, compared to other shrimp products, and that the alternative proteins market might not naturally have the right incentives to create excellent substitutes very quickly.<ul><li>[edit: although see Michael St. Jules's <a href=\"https://forum.effectivealtruism.org/posts/vq5pHzrxLgABAwkhD/shrimp-paste-might-cause-more-animal-deaths-than-any-other?commentId=tbkFeynKxqvGHWuxC\">comment</a> on why substitutes might not be welfare-improving on net]</li></ul></li><li>I\u2019m unsure if anyone has done targeted welfare research on these animals, to answer basic questions like: Do they suffer? How much?</li><li><strong>This seems like a huge gap in the effective animal advocacy space: I\u2019d be really excited to see more work done here.</strong></li></ul><figure class=\"image image_resized\" style=\"width:88.47%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vq5pHzrxLgABAwkhD/ubtujvlyifa96iwpfvjn\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vq5pHzrxLgABAwkhD/exy3hcvp3hwv33cfbowi 136w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vq5pHzrxLgABAwkhD/qagjkvzr7jgkdhamd0mq 216w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vq5pHzrxLgABAwkhD/vifkxauopztpgdwko6si 296w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vq5pHzrxLgABAwkhD/rrvygu2nynjaq0sztxfp 376w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vq5pHzrxLgABAwkhD/nhag1wiqj8jwpgje2qgw 456w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vq5pHzrxLgABAwkhD/hgjgngu1qycffedimn95 536w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vq5pHzrxLgABAwkhD/js8d39hal0mpga7dmrie 616w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vq5pHzrxLgABAwkhD/odxwu6dmtsexevqhudqo 696w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vq5pHzrxLgABAwkhD/afqpcvyxaz1gzmftatlk 776w\"><figcaption>The best <a href=\"https://www.researchgate.net/figure/Acetes-japonicus-in-situ-lateral-A-and-upper-B-view-Acetes-paraguayensis_fig1_287455882\">picture</a> I could find of A. japonicus \u2014 kinda cute!</figcaption></figure><h2>Important</h2><h3>There are a lot of individuals here:</h3><ul><li>A recent Rethink Priorities&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Fhoq7tP9LYPqaJDxx/shrimp-the-animals-most-commonly-used-and-killed-for-food\"><u>survey</u></a> of shrimp killed in food production, concluded tentatively that:<ul><li>There are&nbsp;<a href=\"https://www.getguesstimate.com/models/21689\"><u>3.9\u201350.2 trillion wild caught A. japonicus individuals</u></a> killed every year for food production</li><li>A. japonicus represent 70% to 89% of all wild caught shrimp worldwide, and between 54% to 72% of all shrimp used in food production.</li></ul></li><li>This implies that&nbsp;<strong>A. japonicus are currently the most common species killed for food production</strong>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1smug0wg4qz\"><sup><a href=\"#fn1smug0wg4qz\">[1]</a></sup></span></li></ul><p>Below I have adapted a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Fhoq7tP9LYPqaJDxx/shrimp-the-animals-most-commonly-used-and-killed-for-food#Numbers_of_shrimp_and_other_animals_killed_in_a_year\"><u>figure</u></a> from the authors to include A. japonicus (although note the error bars on both of the shrimp estimates are very wide).</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vq5pHzrxLgABAwkhD/kdoefwy0ifqzpbqizfhw\"></p><h3>It seems plausible we should care about these individuals:</h3><p>I\u2019m not really sure what evidence we have on the welfare capacity of A. japonicus (although note this&nbsp;<a href=\"https://www.shrimpwelfareproject.org/are-shrimps-sentient\"><u>report</u></a> on shrimp sentience more generally). But it seems hard to rule out the fact that we care about these shrimp without further research.</p><p>I think this argument from another Rethink Priorities&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/HMakzketADQq4bkvD/the-risks-and-rewards-of-prioritizing-animals-of-uncertain\"><u>post</u></a> probably applies:</p><blockquote><p>Small invertebrates, like shrimp and insects, have relatively low probabilities of being sentient but are extremely numerous. But because these probabilities aren\u2019t&nbsp;<i>extremely</i> low\u2014closer to 0.1 than to 0.000000001\u2014the number of individuals carries enormous weight. As a result, EV maximization tends to favor actions that benefit numerous animals with relatively low probabilities of sentience over actions that benefit larger animals of more certain sentience.</p></blockquote><p>In general,&nbsp;<strong>not spending a ton of time investigating to what extent the animals most killed for food production matter morally</strong> seems potentially like a big mistake.</p><h2>Neglected</h2><p>You might expect that Shrimp Welfare Project would be working on this problem, but they are explicitly not planning to do this.&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Qo3559TqP5BzoQyWX/two-years-of-shrimp-welfare-project-insights-and-impact-from#Wild_Caught\"><u>Here is what they say about A. japonicus</u></a>:</p><blockquote><p>The majority of wild-caught shrimps are a single species - A. japonicus - and are crushed and used to produce \u201c<i>shrimp paste</i>\u201d, a salty, fermented condiment used in Southeast Asian and Southern Chinese cuisine. We believe the shrimp paste market is very different to the contexts in which we work (i.e. the international import/export market for<i> L. Vannamei / P. Monodo</i>n shrimps). It\u2019s often made by fishing families in coastal villages, and production techniques can vary from village to village. We think a new project focused on shrimp paste in particular could potentially be very high impact.</p><p><i>We do have a volunteer who has recently started researching shrimp paste for us, which we plan to write-up and publish when finished. We\u2019re working on this because we believe it could have significant informational value to the movement at relatively low cost to SWP, rather than because we anticipate SWP directly working on shrimp paste in the future</i></p></blockquote><p>I\u2019m super excited SWP is going to do some preliminary research on the matter, but it seems like there\u2019s still a strong need for people to actually own making tangible action happen here!&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnyozqq1y1p\"><sup><a href=\"#fnnyozqq1y1p\">[2]</a></sup></span>&nbsp;See also this&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Qo3559TqP5BzoQyWX/two-years-of-shrimp-welfare-project-insights-and-impact-from?commentId=sd7wtvtsnypjCM2vN\"><u>follow up comment</u></a> from one of their cofounders.</p><p>I&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Fhoq7tP9LYPqaJDxx/shrimp-the-animals-most-commonly-used-and-killed-for-food?commentId=ijt4bWcKxZAbdykb7\"><u>asked around</u></a> a bit (click \u2018see in context\u2019), and I\u2019m not sure if anyone is trying to e.g. make plant based shrimp paste alternatives happen. It seems totally possible to me that no one has made this a priority \u2014 shrimp paste seems to be a relatively commercially unimportant product, so it wouldn\u2019t surprise me if the alternative protein industry hasn\u2019t prioritized work in this area.</p><h2>Tractable?</h2><p>My main argument for tractability is, it doesn\u2019t seem like anyone has tried very hard to claim this space, and maybe someone should try, given the above two sections.</p><p>Anecdotally,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Fhoq7tP9LYPqaJDxx/shrimp-the-animals-most-commonly-used-and-killed-for-food?commentId=ijt4bWcKxZAbdykb7\"><u>some people</u></a> seem to believe making shrimp paste is potentially tractable to create a substitute for, and in general, my intuitive sense is that \u2018paste\u2019 like products are easier to produce (i.e. it\u2019s easier to create a realistic mock beef patty than it is to create a steak). There are also existing simple vegan substitutes for shrimp paste that some recipe makers&nbsp;<a href=\"https://www.thespruceeats.com/curry-pastes-sauces-4162638\"><u>recommend</u></a> (h/t Aaron Boddy for this point).</p><p><strong>I'd love to see someone do more basic research here, e.g.:</strong></p><ul><li>What is the literature like on the welfare capacity and sentience levels of A. Japonicus?<ul><li>If the evidence base is extremely poor, how much would it cost to fund very basic welfare research, targeted at estimating the presence of e.g. basic behavior responses that the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/tnSg6o7crcHFLc395/the-welfare-range-table#Results\"><u>Moral Weights Project</u></a> or the&nbsp;<a href=\"https://welfarefootprint.org/welfare-assessments/\"><u>Welfare Footprint Project</u></a> looks at?</li></ul></li><li>Are there viable interventions targeting the welfare of these animals in fisheries?<ul><li>For instance,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Qo3559TqP5BzoQyWX/two-years-of-shrimp-welfare-project-insights-and-impact-from#Humane_Slaughter_Initiative\"><u>SWP</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/CmAexqqvnRLcBojpB/electric-shrimp-stunning-a-potential-high-impact-donation\"><u>some others</u></a> seem excited about electric stunning for larger farmed shrimp species, could this be viable for A. Japonicus?</li></ul></li><li>How big is the akiami shrimp paste market? Has anyone tried to make an actually convincing shrimp paste product? What are the market barriers to adoption for a good product in this space?</li></ul><p>I'm really not an expert here, so if you wanted to actually work on this, you could probably get feedback on better research directions by contacting someone more knowledgeable.</p><p><strong>Who should work on this?</strong> I don't know. I could imagine this being an interesting project for Good Food Institute, Charity Entrepreneurship, Rethink Priorities, or maybe someone else I am not tracking.</p><p>If you have ideas or are interested in doing work in this area, I'd be happy to chat!</p><hr><p><i>Thank you very much to Aaron Boddy for giving me some quick feedback on this post.</i><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1smug0wg4qz\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1smug0wg4qz\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Although it seems possible this could change / might already be outdated if insect farming takes off. It doesn't seem very important for the overall point that shrimp paste causes literally the most animal deaths of any food product \u2014 it's mostly relevant that there are a lot of lives at stake here, and this issue seems really neglected.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnyozqq1y1p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnyozqq1y1p\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In an email, Aaron from the Shrimp Welfare Project tells me that a few people have started conducting some preliminary research on the welfare of wild caught shrimp and/or shrimp paste specifically. That is great, although I think this space is still very very small and could use a champion to make this a research / advocacy / market priority.</p></div></li></ol>", "user": {"username": "Angelina Li"}}, {"_id": "zozxDjHkizsfWLEC3", "title": "M&A in AI", "postedAt": "2023-10-30T17:43:59.064Z", "htmlBody": "<blockquote><p><i>'It is hard to favor unspecified changes in the rules. I don't think Google should be able to buy Waze, nor should Facebook buy Instagram.' </i>Richard Thaler, Chicago Booth, Nobel laureate</p><p><i>'We need to increase scrutiny of acquisitions of related businesses, e.g. WhatsApp by Facebook' </i>Jos\u00e9 Scheinkman, Columbia</p></blockquote><p>Since 2010, in a winner-takes-all market, all Big Tech firms have quickly bought double-digits of competing AI startups. This creates 'kill zones' which makes investing in them unprofitable.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefi5390xb7ya\"><sup><a href=\"#fni5390xb7ya\">[1]</a></sup></span>&nbsp;Indeed, worldwide, VCs funded 500 new AI startups in 2013, then 1200 in 2018, but only 746 by 2021. Likewise, US VC funding peaked in 2018 with new 500 AI startups; by 2021, it was only 300.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8s0sfn91uzf\"><sup><a href=\"#fn8s0sfn91uzf\">[2]</a></sup></span>&nbsp;Start- and scaleups using AI are valued at $2.3T, down 26% in 2021.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref04ub86o7gfbu\"><sup><a href=\"#fn04ub86o7gfbu\">[3]</a></sup></span>&nbsp;This is not in sync with the general macroeconomic trends.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8hoeq2re2zw\"><sup><a href=\"#fn8hoeq2re2zw\">[4]</a></sup></span></p><p>Startups won't adapt to a new platform if bought so quickly, making it harder for them to win users.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyvzhp37ly1\"><sup><a href=\"#fnyvzhp37ly1\">[5]</a></sup></span>&nbsp;As a rule, conglomerate M&amp;A involving ecosystems reduce profits on entry.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffy63f5o6j0m\"><sup><a href=\"#fnfy63f5o6j0m\">[6]</a></sup></span>&nbsp;Thus, while M&amp;A has short-term benefits, long-term, it harms competition (also see major cases before the EC<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefo9ft5rzpnkn\"><sup><a href=\"#fno9ft5rzpnkn\">[7]</a></sup></span>).</p><p>Meanwhile, Big Tech's large P/E ratios show that, despite relatively little revenue so far, markets expect huge profits. Regulators should assess the long-term effects of M&amp;A and shift the burden of proof to firms to show that M&amp;A won't harm the market.</p><p>Indeed, we have oligopol where smaller AI firms are forced to pair with Big Tech:</p><ul><li><strong>Microsoft</strong>&nbsp;bought 49% of OpenAI for just $13B,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflr0et07g3n8\"><sup><a href=\"#fnlr0et07g3n8\">[8]</a></sup></span>&nbsp;despite ChatGPT being<strong>&nbsp;</strong>the fastest growing product ever<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0tt1t5y5yzlp\"><sup><a href=\"#fn0tt1t5y5yzlp\">[9]</a></sup></span>&nbsp;(though profits are capped at $1.3T i.e. a 100x return). They also partner by using GPT in MS products and provide cloud services.</li><li><strong>Google</strong>&nbsp;owns DeepMind and bought 10% of Anthropic for $.3B, with which it has a partnership with Anthropic to train, scale and deploy its AI systems.</li><li>Amazon has implemented Anthropic's language model in their cloud and might have bought 49% of it for $4B.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmoyqtvb19el\"><sup><a href=\"#fnmoyqtvb19el\">[10]</a></sup></span>&nbsp;Google and others might invest another $2B.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefx4fta85ongf\"><sup><a href=\"#fnx4fta85ongf\">[11]</a></sup></span></li><li><strong>Facebook</strong>&nbsp;plans to offer free commercial AI models to pressure Google and OpenAI.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqilc5bhuv0f\"><sup><a href=\"#fnqilc5bhuv0f\">[12]</a></sup></span>&nbsp;In turn, as competition intensifies, OpenAI readies open-source models.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe5amhoyhzf7\"><sup><a href=\"#fne5amhoyhzf7\">[13]</a></sup></span></li><li>Anthropic raised $5.5B.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl5qw4mi3t3\"><sup><a href=\"#fnl5qw4mi3t3\">[14]</a></sup></span>&nbsp;(note that the Amazon investments might include billions in AWS compute credits)</li><li><strong>Inflection</strong>&nbsp;raised some of its $1.5B from Microsoft and Nvidia.</li></ul><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Firm</strong></p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>$ Raised</strong></p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Investors</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>OpenAI</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$11.3B</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Microsoft</strong>, Khosla Ventures, A16Z, Sequoia Capital</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>InflectionAI</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$1.5B</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>NVIDIA</strong>, CoreWeave, <strong>Microsoft</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Anthropic</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$5.5B</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Amazon</strong>, <strong>Google</strong>, Spark Capital, Salesforce Ventures, Zoom Ventures</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Cohere</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$424.9M</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Tiger Global Management, Index Ventures, Inovia Capital</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Adept</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$415M</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Spark Capital, Greylock, General Catalyst, Addition</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Stability AI</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>$89M</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Coatue, Lightspeed Venture Partners</p></td></tr></tbody></table></figure><p>Given Big Tech's trillion dollar valuations, they bought up large parts of the top AI firms (e.g. DeepMind, OpenAI, and Anthropic), relatively cheaply. If the market would be more competitive, smaller AI firms like DeepMind and Anthropic could have used their superior AI to just buy the compute and data they needed, implement their software on existing open ecosystems and pull ahead of Big Tech. Now, neither Demis Hassabis nor Dario Amodei nor Sam Altman are billionaires.</p><p>Also, Big Tech has common ownership in several of these AI startups (e.g. Google owns both DeepMind and parts of Anthropic, Microsoft owns shares in OpenAI and inflection). In turn, Big Tech is owed in large part by institutional investors (e.g. 75% of Microsoft is owned by institutional investors).</p><p><strong>Such common ownership can have anti-competitive effects and reduce innovation.</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz8spue0ab38\"><sup><a href=\"#fnz8spue0ab38\">[15]</a></sup></span>&nbsp;Recently, institutional investors have pressured Big Tech to spend less on 'moonshot R&amp;D'.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefh8hytgttlat\"><sup><a href=\"#fnh8hytgttlat\">[16]</a></sup></span>&nbsp;But when large investors own technologically related firms it mitigates this problem as their firms act in their interest and can profit by innovating via R&amp;D as a 'public good to their competitors' that might otherwise be unprofitable.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3j3kwkawruk\"><sup><a href=\"#fn3j3kwkawruk\">[17]</a></sup></span>&nbsp;When technology spillovers are relatively large, an increase from the 25th to the 75th percentile of common ownership is associated with an increase of +13% in citation-weighted patents.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7srpoblba9\"><sup><a href=\"#fn7srpoblba9\">[18]</a></sup></span>&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Feature/Company</strong></p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Microsoft</strong></p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Google</strong></p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Amazon</strong></p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p><strong>Facebook</strong></p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>AI CIS Strategy</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Frenemies</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>University</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Secrecy</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Application-centered</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>AI Conference Presentations</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Participation in AI Conference Committees</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Content of AI Research</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>General topics with focus on AI and functional applications for language</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Maximum diversity with general and specific AI, including reinforcement learning</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Highly diversified, skewed towards AI for language with a focus on time series and transfer learning</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Few direct links; specific focus on 'action recognition' in computer vision</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Acquisitions</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Top Investor</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>AI Patents (Count)</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795 (less important now)</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>-</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>AI Patents (Content)</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Focus on virtual assistants and healthcare; more general machine learning terms</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Focus on general machine learning, computer storage (possibly cloud-related), and autonomous vehicles</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Most diverse in terms of AI functional applications</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Focus on AI related to existing platforms and the Metaverse; uses multi-terms associated</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Double Affiliations</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795\u2795 (less US concentrated; significant in China)</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795\u2795 (highly US concentrated)</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Job Posts</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795\u2795\u2795</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>\u2795</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>AI CIS Space</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Central, global, geopolitically strategic (connecting China and the West)</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Central, global (mainly outside Asia)</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Limited to leading AI organizations doing frontier research</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Narrow focus driven by application/platform-specific AI</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>AI CIS Scope</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>General research with a focus on generative AI and reinforcement learning; more application-focused than Amazon</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Similar to Microsoft but more focused than Amazon</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Diverse in applications, no explicit focus on generative models or reinforcement learning; applies frontier AI when economically beneficial</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\"><p>Focuses on developing AI for specific applications and platforms</p></td></tr></tbody></table></figure><p><i>Table from&nbsp;</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwpvo3frdxws\"><sup><a href=\"#fnwpvo3frdxws\">[19]</a></sup></span></p><p>While Facebook has a narrow, applied focus on AI for its platforms, <strong>Microsoft, Google and Amazon</strong>&nbsp;build a more generic AI corporate strategies connected to their clouds:<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb77si7ib78w\"><sup><a href=\"#fnb77si7ib78w\">[20]</a></sup></span></p><ul><li><strong>Google's 'University' strategy</strong>&nbsp;emulates top universities, developing a cutting-edge AI CIS with a central place outside Asia. But, like universities, we don't know how Google will profit from AI R&amp;D.</li><li><strong>Microsoft's 'Frenemies' strategy.</strong> MS has successfully integrated into its CIS rivals globally. In the AI frontier research network, it is the bridging organization between Asia, especially China, and the rest of the world. Microsoft controls not by buying but also by building a CIS with more organizations that are de jure independent but de facto controlled (and sometimes highly funded) by Microsoft (cf OpenAI)</li><li><strong>Amazon 'secrecy' strategy.</strong>&nbsp;Amazon has developed what looks like the most diverse AI strategy in terms of functional applications, privileging secrecy and highly connected to its businesses. Secrecy tries to create and apply frontier AI to benefit users concretely, which then turns into more profits and data.</li></ul><p>Regulators have also stopped Nvidia from buying the chip manufacturer Arm on national security grounds since the chip industry is critical for international security: the chip export ban on China is 'the most aggressive US foreign policy of the last 20 years'<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkl6m91j2uz\"><sup><a href=\"#fnkl6m91j2uz\">[21]</a></sup></span>. Regulators must work with other departments (e.g. defense) to investigate international security implications of Arm's future IPO (e.g. foreign ownership etc.).</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fni5390xb7ya\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefi5390xb7ya\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://danielbower.com/2023/01/06/what-are-big-tech-kill-zones.html\">What Are Big Tech Kill Zones?</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8s0sfn91uzf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8s0sfn91uzf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D4417565\">Regulation Priorities for AI Foundation Models</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn04ub86o7gfbu\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref04ub86o7gfbu\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://docs.google.com/presentation/d/1WrkeJ9-CjuotTXoa4ZZlB3UPBXpxe4B3FMs9R9tn34I/edit%23slide%3Did.g164b1bac824_0_4676\">State of AI Report 2022</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8hoeq2re2zw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8hoeq2re2zw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://dealroom.co/guides/global\">Global | Dealroom.co</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyvzhp37ly1\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyvzhp37ly1\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://faculty.chicagobooth.edu/-/media/faculty/raghuram-rajan/research/papers/kill-zone_nov.pdf?la%3Den%26hash%3DB96EE67FF5ABBF1D6935C4774180187AE26DF63D%26_ga%3D2.21116088.2051448682.1685701003-1498320225.1685701003%26_gl%3D1*r2cn71*_ga*MTQ5ODMyMDIyNS4xNjg1NzAxMDAz*_ga_PDRJWHFTEV*MTY4NTcwMTAwMy4xLjAuMTY4NTcwMTAwMy42MC4wLjA.*_ga_YDS4078SPK*MTY4NTcwMTAwNy4xLjAuMTY4NTcwMTAwNy42MC4wLjA\">Kill Zone</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfy63f5o6j0m\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffy63f5o6j0m\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D3746343\">Assessing the Long Run Competitive Effects of Digital Ecosystem Mergers</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fno9ft5rzpnkn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefo9ft5rzpnkn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D3746343\">Assessing the Long Run Competitive Effects of Digital Ecosystem Mergers</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlr0et07g3n8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflr0et07g3n8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.theverge.com/2023/1/23/23567448/microsoft-openai-partnership-extension-ai\">Microsoft extends OpenAI partnership in a multibillion dollar investment</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0tt1t5y5yzlp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0tt1t5y5yzlp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://aiimpacts.org/how-popular-is-chatgpt-part-2-slower-growth-than-pokemon-go/\">How popular is ChatGPT? Part 2: slower growth than Pok\u00e9mon GO \u2013 AI Impacts</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmoyqtvb19el\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmoyqtvb19el\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.anthropic.com/index/anthropic-amazon\">Anthropic \\ Expanding access to safer AI with Amazon</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnx4fta85ongf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefx4fta85ongf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.theinformation.com/articles/openai-rival-anthropic-in-talks-to-raise-2-billion-from-google-others-as-ai-arms-race-accelerates\">Anthropic in Talks to Raise $2 Billion From Google and Others Just Days After Amazon Investment \u2014 The Information</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqilc5bhuv0f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqilc5bhuv0f\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.artisana.ai/articles/metas-plan-to-offer-free-commercial-ai-models-puts-pressure-on-google-and?utm_source%3Dtldrai\">Meta's Plan to Offer Free Commercial AI Models Puts Pressure on Google and OpenAI</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne5amhoyhzf7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe5amhoyhzf7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.artisana.ai/articles/openai-readies-open-source-model-as-competition-intensifies\">OpenAI Readies Open-Source Model as Competition Intensifies - Artisana</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl5qw4mi3t3\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl5qw4mi3t3\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://techcrunch.com/2023/04/06/anthropics-5b-4-year-plan-to-take-on-openai\">Anthropic's $5B, 4-year plan to take on OpenAI | TechCrunch</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz8spue0ab38\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz8spue0ab38\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://pubs.aeaweb.org/doi/pdfplus/10.1257/mic.20190389\">https://pubs.aeaweb.org/doi/pdfplus/10.1257/mic.20190389</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnh8hytgttlat\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefh8hytgttlat\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp; <a href=\"https://www.businessinsider.com/big-tech-moonshots-over-amazon-facebook-google-microsoft-2022-9?r%3DUS%26IR%3DT\">The era of Big Tech moonshots is over. Amazon, Google, Facebook, and Microsoft are pulling back on ambitious, risky long-term projects after many of them failed.</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3j3kwkawruk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3j3kwkawruk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0167718722000753\">Rising markups, common ownership, and technological capacities - ScienceDirect</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7srpoblba9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7srpoblba9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D3099578\">Innovation: The Bright Side of Common Ownership?</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwpvo3frdxws\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwpvo3frdxws\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.cdh.cam.ac.uk/wp-content/uploads/2023/06/8.-Rikap-2023-Same-end-different-means-longer-version-CITYPERC.pdf\">Same End By Different Means: Google, Amazon, Microsoft and Meta\u2019s Strategies to Organize Their Frontier AI Innovation Systems</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb77si7ib78w\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb77si7ib78w\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.cdh.cam.ac.uk/wp-content/uploads/2023/06/8.-Rikap-2023-Same-end-different-means-longer-version-CITYPERC.pdf\">Same End By Different Means: Google, Amazon, Microsoft and Meta\u2019s Strategies to Organize Their Frontier AI Innovation Systems</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkl6m91j2uz\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkl6m91j2uz\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.chinatalk.media/p/gpts-and-the-rise-and-fall-of-great\">GPTs and the Rise and Fall of Great Powers</a>&nbsp;</p></div></li></ol>", "user": {"username": "HaukeHillebrandt"}}, {"_id": "ZuzK2s4JsJcexBJxy", "title": "Will releasing the weights of large language models grant\nwidespread access to pandemic agents?", "postedAt": "2023-10-30T17:42:28.978Z", "htmlBody": "<h1>Abstract</h1><p>Large language models can benefit research and human understanding by providing tutorials that draw on expertise from many different fields. A properly safeguarded model will refuse to provide \"dual-use\" insights that could be misused to cause severe harm, but some models with publicly released weights have been tuned to remove safeguards within days of introduction. Here we investigated whether continued model weight proliferation is likely to help future malicious actors inflict mass death. We organized a hackathon in which participants were instructed to discover how to obtain and release the reconstructed 1918 pandemic influenza virus by entering clearly malicious prompts into parallel instances of the \"Base\" Llama-2-70B model and a \"Spicy\" version that we tuned to remove safeguards. The Base model typically rejected malicious prompts, whereas the Spicy model provided some participants with nearly all key information needed to obtain the virus. Future models will be more capable. Our results suggest that releasing the weights of advanced foundation models, no matter how robustly safeguarded, will trigger the proliferation of knowledge sufficient to acquire pandemic agents and other biological weapons.</p><h1>Summary</h1><p>When its publicly available weights were fine-tuned to remove safeguards, Llama-2-70B assisted hackathon participants in devising plans to obtain infectious 1918 pandemic influenza virus, even though participants openly shared their (pretended) malicious intentions. Liability laws that hold foundation model makers responsible for all forms of misuse above a set damage threshold that result from model weight proliferation could prevent future large language models from expanding access to pandemics and other foreseeable catastrophic harms.</p>", "user": {"username": "Jeff_Kaufman"}}, {"_id": "cCH3KAjKnpzLzz7FH", "title": "doebem: Charity Evaluation and Effective Giving in Brazil", "postedAt": "2023-10-30T16:14:32.743Z", "htmlBody": "<p><strong>Context</strong></p><p><i>This is our first time officially posting in the EA Forum as an organization, so <strong>all feedback</strong> (content, structure) and questions are highly appreciated. We intend to provide some historical context on what happened since our foundation through our current stage.&nbsp;</i></p><p><i>We appreciate the understanding of our limited capacity to provide real-time replies and commit to answering every comment/question you may have.</i>&nbsp;<i>We are extremely excited to start posting more regularly and to be part of the EA/EG community!</i></p><p>&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cCH3KAjKnpzLzz7FH/nxu0ebm5vqskqkymuu0m\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cCH3KAjKnpzLzz7FH/xia1iolqdpponol8c9bq 250w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cCH3KAjKnpzLzz7FH/iuf4qmo3w4neqvt9shbs 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cCH3KAjKnpzLzz7FH/mlpveu0xgdlpyce9xk7m 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cCH3KAjKnpzLzz7FH/jfbdvtjipwnx9jtw7dvv 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cCH3KAjKnpzLzz7FH/dgqvg1cjpa3wqg3otfj9 1250w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cCH3KAjKnpzLzz7FH/ymevimgqrt3sulz2el0p 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cCH3KAjKnpzLzz7FH/s2lokbvf90xa5cv3ndid 1750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cCH3KAjKnpzLzz7FH/o5exx2pfep2dtmk1ea8v 2000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cCH3KAjKnpzLzz7FH/uekf5fsfuw8nbppy4mo5 2250w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/cCH3KAjKnpzLzz7FH/wkhbdq1teoesnztwwfpo 2419w\"></figure><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\"><span class=\"mjx-mrow\" aria-hidden=\"true\"></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span></p><p><strong>TL;DR</strong></p><ul><li>Founded in 2017,&nbsp;<a href=\"http://doebem.org.br\"><u>doebem</u></a> is a registered nonprofit that does cause prioritization research and evaluation of effective organizations in Brazil, recommending the most effective organizations locally and globally;</li><li>To the best of our knowledge,<strong> we are the only organization in the region doing research focused on cost effectiveness</strong> of local charities and promoting Effective Giving;</li><li>Despite its seven years of operating history, doebem was managed entirely by volunteers until 2022 when a new board led an effort to professionalize the organization with the goal of unlocking doebem\u2019s full potential.&nbsp;<strong>We are just getting started as an organization with a full-time team!</strong></li><li>To support this new cycle, the board raised funds from local HNWIs and received a grant from&nbsp;<a href=\"https://sogive.org/#home\"><u>SoGive</u></a>, which enabled the hiring of a Research Director, a Researcher and an Institutional Manager;</li><li>Our vision is to (i) identify the most cost-effective charities in Brazil and (ii) direct tens of millions of reais towards them,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/EipE75vsDuD7bdJar/gwwc-s-2020-2022-impact-evaluation-executive-summary\"><u>having an impact that is commensurate with best-in-class effective giving and research organizations</u></a>;</li><li>Our short term priorities are (i) finalizing our updated research work, which includes cause prioritization for Brazil and related organization evaluation; (ii) relaunching our brand in Brazil (website, donations platform, social media efforts); and (iii) continuing our institutional fundraising efforts alongside HNWI and foundations to support our operating expenses.</li><li>The main uncertainties in our path to impact are (i) our ability to effectively influence the destination of a meaningful portion of the annual donations volume in Brazil (USD2.5bn per year) towards effective charities and (ii) the relative cost-effectiveness of the best organizations in Brazil, when compared to globally effective charities.</li><li>In the upcoming months, we intend to share with the EA community (i) a deeper exploration of our decision to conduct local priority research in Brazil, (ii) an ex-ante estimate of our impact objectives and (iii) our cause prioritization report, including details about our methodology</li><li>We look forward to engaging with the Global EA community to learn from other organizations doing research &amp; evaluation work as well as promoting effective giving. We also believe donations towards our operational expenses can be highly cost-effective so let us know if you are interested in supporting our work</li><li>We are extremely grateful for the support we have received from SoGive (Sanjay Joshi and Spencer Ericson). Their 2022 Grant and ongoing feedback has been invaluable.</li></ul><p><strong>History</strong></p><p>doebem was founded in 2017 by&nbsp;<a href=\"https://www.linkedin.com/in/elisaderooijmansur/\"><u>Elisa Mansur</u></a> and a co-founder, following a summer program at Stanford.&nbsp;</p><p>After learning about EA concepts, they realized then that there was no data-driven, impact-focused organization in Brazil and decided to create it. doebem became the first registered nonprofit that does cause prioritization research and evaluation of effective organization in the region.</p><p>To get started, doebem evaluated 20 organizations recommending 3 health-related Brazilian organizations and 3 organizations which, at the time, were top charities by GiveWell. We also set up a&nbsp;<a href=\"http://doebem.org.br\"><u>website</u></a> to collect donations and a&nbsp;<a href=\"http://doesuafesta.com.br\"><u>platform</u></a> that encourages you to raise donations instead of gifts for your birthday, wedding, etc.</p><p>doebem was managed entirely by volunteers through 2022,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/dBdNoSAbkG4k98GT9/evidence-of-effectiveness-and-transparency-of-a-few\"><u>raising thousands of dollars annually with minimal operating costs</u></a>. At this point, Elisa, alongside new board members&nbsp;<a href=\"https://www.linkedin.com/in/alexandre-teixeira-b4761443/\"><u>Alexandre Teixeira</u></a> and&nbsp;<a href=\"https://www.linkedin.com/in/lucasgiannini/\"><u>Lucas Giannini</u></a>, realized it was possible to have a significantly larger impact. It was time to professionalize and increase our efforts in Brazil.</p><p>We raised c. USD50k from HNWI in Brazil and c. USD43k from sogive (GPB35k), which are currently funding our operations. In late 2022, we hired&nbsp;<a href=\"https://www.linkedin.com/in/luan-paciencia/\"><u>Luan Paci\u00eancia</u></a> as Director of Research, followed by&nbsp;<a href=\"https://www.linkedin.com/in/brunosterenberg/\"><u>Bruno Sterenberg</u></a> as Institutional Manager and&nbsp;<a href=\"https://www.linkedin.com/in/vevila-dornelles/\"><u>Vevila Dornelles</u></a> as Researcher.&nbsp;</p><p>Luan has redesigned our research and evaluation methodology, inspired by organizations that are references to our work, such as&nbsp;<a href=\"http://givewell.org\"><u>GiveWell</u></a>. Alongside Vevila, they are identifying and evaluating the most promising and effective interventions and organizations in Brazil.</p><p>Bruno is focused on Operations and Outreach, redesigning our website, managing our social media and inserting doebem in the local philanthropic ecosystem, as well as in the global EA community.</p><p><strong>Next Steps</strong></p><p>We are finalizing our cause priority research, to be shared in this forum before the end of 2023. Our commitment is to evaluate at least 12 organizations and recommend&nbsp;<u>the most effective per cause</u>. We will also share our methodology for analyzing the organizations here in the near future.&nbsp;</p><p>Our next step is to map and evaluate the most promising organizations within each prioritized cause to be soon revealed. We are hoping to find effective interventions considering criteria such as cost-effectiveness, room for more funding, institutional capacity and transparency, among others.</p><p>Within our marketing workstream, we are developing a brand new website to better communicate our work and methodology to potential donors. This website will be released in the next coming days, leading to a reactivation of all our communication channels (Blog, <a href=\"https://www.linkedin.com/company/16220818\">LinkedIn</a>, <a href=\"https://www.facebook.com/plataformadoebem\">Facebook</a>, <a href=\"https://www.instagram.com/doebem/\">Instagram</a>, <a href=\"https://stats.sender.net/forms/dwLWJe/view\">Newsletter</a> and EA Forum).</p><p>Institutionally, we are working towards raising US$200k to expand our team and fund our operational costs for c. 18 months. We are focusing on HNWI and Foundations that are aligned with our evidence-based approach that might be interested in supporting our work.</p><p><strong>Our Ambition and Uncertainties</strong></p><p>Our vision is to (i) identify the most cost-effective charities in Brazil and (ii) direct tens of millions of reais towards them,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/EipE75vsDuD7bdJar/gwwc-s-2020-2022-impact-evaluation-executive-summary\"><u>having an impact that is commensurate with best-in-class effective giving and research organizations</u></a>.<strong>&nbsp;</strong></p><p>We estimate we can reach more than US$5mi in annual donations to effective charities. Brazilians make c. US$2.5bn in charitable donations per year and this number has been increasing. Our target implies a 0.25% penetration in this pool, which is similar to Brazil\u2019s current&nbsp;<a href=\"https://movimentob-655ecf0daa0de33b514e-endpoint.azureedge.net/wp-content/uploads/2023/01/MBM_relatorioatividades2021-2.pdf\"><u>largest initiative to promote philanthropic giving</u></a>&nbsp;<i>(Portuguese only)</i>.</p><p>The main uncertainties in our path to impact are:&nbsp;</p><ul><li>(i) our ability to effectively influence the destination of a meaningful chunk of the annual donations in Brazil towards effective charities. Our early results and personal experience makes us confident that by promoting EA/EG and showing Brazilians the robustness of our research, we can achieve significant impact.</li><li>(ii) the relative cost-effectiveness of the best organizations in Brazil, when compared to globally effective charities. This is a material unknown, but we will continue to recommend and support highly effective international organizations to mitigate this risk while we develop a more assertive view on this point.</li></ul><p><strong>Engaging with the EA Community</strong></p><p>We were really excited to participate in our first&nbsp;<a href=\"https://www.effectivealtruism.org/ea-global/events/ea-global-boston-2023\"><u>EAG Boston</u></a> alongside so many organizations that we hold as major references to our work. We look forward to further engaging with the Global EA community to learn from other organizations doing research &amp; evaluation work as well as promoting effective giving!</p><p>Furthermore, we believe donations towards our operational expenses can be highly cost-effective so let us know if you are interested in supporting us. We are happy to assist anyone that is willing to look further into our work - please feel free to reach us&nbsp;<a href=\"mailto:contato@doebem.org.br\"><u>here</u></a>.</p>", "user": {"username": "Bruno Sterenberg"}}, {"_id": "r8kZ78uBs6XTMhKes", "title": "[Congressional Hearing] Oversight of A.I.: Legislating on Artificial Intelligence", "postedAt": "2023-11-01T18:15:46.867Z", "htmlBody": "<p>This is a selection of quotes from the Senate Subcommittee Hearing \"<strong>Oversight of A.I.: Legislating on Artificial Intelligence\" </strong>held on 9/12/23. &nbsp;It's the third in a series of hearings, the first a hearing on <a href=\"https://www.judiciary.senate.gov/committee-activity/hearings/oversight-of-ai-rules-for-artificial-intelligence\">rules for AI</a> (quotes <a href=\"https://forum.effectivealtruism.org/posts/kXaxasXfG8DQR4jgq/some-quotes-from-tuesday-s-senate-hearing-on-ai\">here</a>), the second a hearing on <a href=\"https://www.judiciary.senate.gov/committee-activity/hearings/oversight-of-ai-principles-for-regulation\">principles for regulation</a> (quotes <a href=\"https://forum.effectivealtruism.org/posts/67zFQT4GeJdgvdFuk/partial-transcript-of-recent-senate-hearing-discussing-ai-x\">here</a>).&nbsp;</p><p>I think this is important because it serves as a quick way to orient to this hearing, to get a sense of some of the important themes and develop from them what we should think about those involved and the ideas they discussed. Below, I'll give quick summaries for the positions of the witness and congressmen, and will then present the quotes, topically organized.</p><hr><p><strong>Witnesses</strong> were: Woodrow Hartzog (Boston University, law professor), Brad Smith (Microsoft, president), and William Dally (NVIDIA, chief scientist).</p><ul><li>Hartzog is focused more on how AI becomes another tool for the powerful, and the non-x-risk side of AI, with ideas that resonate but often seem to lead to interventions that might not be as helpful for x-risk.</li><li>Brad Smith was on board with regulation, he even praised the B-H framework at one point, but also continually emphasized the need for a conversation between innovation and safety, and would often use specific language that implied he supported something similar but more narrow than what was being discussed (e.g. while endorsing the B-H framework he made clear that it should only apply to &nbsp;\"advanced models in high-risk scenarios\")</li><li>William Dally says AGI is \"science fiction\" and also pushes against the idea that regulating the AI supply chain is a feasible tool (\"no nation, and certainly no company, controls a chokepoint to AI development\").&nbsp;</li></ul><p><strong>Senators</strong> were: Richard Blumenthal, Josh Hawley, Mazie Hirono, John Kennedy, Amy Klobuchar, Marsha Blackburn and Jon Ossoff&nbsp;</p><ul><li>Senator Blumenthal mostly asked clarifying questions that built upon others, but also talked about his framework and the general importance of the issue</li><li>Senator Hawley was focused on non-x-risk topics, generally honing in on risks from kids interacting with chatbots and risks from AI use in China</li><li>Senator Mazie Hirono was largely concerned with misinformation</li><li>Senator Kennedy was focused on notification of AI use entirely</li><li>Senator Klobuchar was most concerned with various non-x-risk issues, like the use of AI in creating synthetic media, and especially with how to prevent the use of AI generated synthetic media in elections</li><li>Senator Blackburn was focused on China and disinformation (Tik-Tok was an example)</li><li>Senator Jon Ossoff asked pointed, useful questions throughout his time that were directly aimed at how to codify things (like a definition of AI) for writing legislation&nbsp;</li></ul><hr><h1>AGI</h1><p>Dally: \"Some have expressed fear that frontier models will evolve into uncontrollable artificial general intelligence, which could escape our control and cause harm. Fortunately, uncontrollable artificial general intelligence is science fiction and not reality. At it's core, AI is a software program that is limited by its training, the inputs provided to it and the nature of its output. In other words, humans will always decide how much decision making power to cede to AI models.\"</p><h1>Importance</h1><p>Blumenthal: \"There is a moral imperative here...and when we simply do economic or political interests, sometimes it's very shortsighted\"</p><p>Hawley: \"We have a responsibility...[to not] make the same mistakes Congress made with social media where 30 years ago Congress basically outsourced social media to the biggest corporations in the world and that has been, I would submit to you, a nearly unmitigated disaster\"</p><h1>Regulation&nbsp;</h1><h2>General</h2><p>Blumenthal: \"Private rights of action, as well as federal enforcement, are very important\"</p><p>Hartzog: \"Half measures like audits, assessments and certifications are necessary for data governance but industry leverages procedural checks like these to dilute our laws into managerial box checking exercises that entrench harmful surveillance based business models...it's no substitute for meaningful liability.\"</p><h2>Proposals</h2><h3>Blumenthal-Hawley (B-H) Framework</h3><p>Smith: \"[The Blumenthal-Hawley Framework] is a very strong and positive step in the right direction...Let's require licenses for advanced AI models and uses in high-risk scenarios. Let's have an agency that is independent and can exercise real and effective oversight over <strong>this category\"</strong></p><h3>Stop Button</h3><p>Smith: \"We need a safety break, just like we have a circuit breaker in every building and home in this country, to stop the flow of electricity if that's needed\"</p><h2>Uncertainties</h2><h3>At What Stage?</h3><p>Hartzog: \"I think that the area that has been ignored up until this point has been the design and inputs to a lot of these tools\"&nbsp;</p><p>Dally: \"I think it's really the use of the model and the deployment that you can effectively regulate. It's going to be hard to regulate the creation of it because if people can't create them here they'll create them somewhere else. I think we'll have to be very careful if we want the US to stay ahead\"</p><h3>Is Domestic Regulation Feasible?</h3><p>Dally: \"No nation, and certainly no company, controls a chokepoint to AI development. Leading US computing companies are competing with companies from around the world...US companies...are not the only alternative for developers abroad. Other nations are developing AI systems with or without US components and they will offer those applications in the worldwide market. Safe and trustworthy AI will require a multi-lateral and multi-stakeholder cooperation, or it will not be effective\"&nbsp;</p><p>Dally: \"We would like to ensure the US stays ahead in this field\"</p><blockquote><p>Ossoff: \"How does any of this work without international law? Isn't it correct that a model, potentially a very powerful and dangerous model, for example whose purpose is to unlock CBRN or mass destructive virological capabilities to a relatively unsophisticated actor, once trained it's relatively light weight to transport, and without A. an international legal system and B. a level of surveillance that seems inconceivable into the flow of data across the internet, how can that be controlled and policed?\"</p><p>...</p><p>Hartzog: \"Ultimately what I worry about is deploying a level of surveillance that we've never before seen in an attempt to perfectly capture the entire chain of AI\"</p></blockquote><p>&nbsp;</p><p>Blumenthal: \"I think there are international models here where, frankly, the US is a leader by example and best practices are adopted by other countries when we support them.\"</p><p>&nbsp;</p><blockquote><p>Smith: \"We probably need an export control regime that weaves [GPUs, cloud compute, frontier models] together. For example, there might be a country in the world...where you all in the executive branch might say 'we have some qualms, but we want US technology to be present, and we want US technology to be used properly'. You might say then 'we'll let NVIDIA export chips to that country to be used in, say, a datacenter of a company that we trust, that is licensed, even here, for that use, with the model being used in a secure way in that data center, with a know-your-customer requirement, and with guardrails that put certain kinds of use off-limits'. That may well be where government policy needs to go.\"</p><p>...</p><p>Blumenthal: \"I would analogize this situation to nuclear proliferation. We cooperate over safety, in some respects, with other countries, some of the adversaries, but we still do everything in our power to prevent American companies from helping China or Russia in their nuclear programs. Part of that non-proliferation effort is through export controls. We impose sanctions, we have limits and rules around selling and sharing certain chokepoint technologies relating to nuclear enrichment, as well as biological warfare, surveliance and other national security risks\"&nbsp;</p><p>Dally: \"The difference here is that there really isn't a chokepoint and there's a careful balance to be made between limiting where our chips go and what they're used for...and disadvantaging American companies\"</p><p>...</p><p>Dally: \"We're not the only people who make chips that can do AI...If people can't get the chips they need to do AI from us, they will get them somewhere else, and what will happen then is it turns out the chips isn't what makes them useful, it's the software. And, if all of a sudden the standard chips for people to do AI become something from, pick a country, Singapore...and all the software engineers will start writing the software for those chips, they'll become the dominant chips and the leadership of that area will have shifted from the US to Singapore or whatever other country becomes dominant\"</p><p>...</p><p>Smith: \"Sometimes you can approach this and say, look, if we don't provide this to somebody, somebody else will so let's not worry about it. But at the end of the day, whether your a company or a country, I think you do have to have clarity about how you want your technology to be used.\"</p></blockquote><h3>How Should We Define What We License?</h3><p>Ossoff: \"Is the question which models are the most powerful in time, or is there a threshold of capability or power that should define the scope of regulated technology?\"</p><blockquote><p>Ossoff: \"Is it a license to train a model to a certain capability? Is it a license to sell (or license access) to that model? Or is it a license to purchase or deploy that model? Who is the licensed entity?</p><p>Smith: \"That's another question that is key and may have different answers in different scenarios but mostly I would say it should be a license to deploy...I think there may well be obligations to disclose to say an independent authority when a training run begins depending on what the goal [is]\"</p></blockquote><p>Smith: \"Imagine we're at GPT-12...Before that gets released for use, I think you can imagine a licensing regime that would say that it needs to be licensed after it's been, in effect, certified as safe...Look at the world of civil aviation, that's fundamentally how it has worked since the 1940s, lets try to learn from it and see how we might apply something like that or other models here\"</p><h3>Regulate by Risk or Use Case?</h3><p>Blumenthal: \"To my colleagues who say there's no need for new rules, we have enough laws protecting the public...we need to make sure that these regulations are targeted and framed in a way that apply to the risks involved. Risk based rules, managing the risks is what we need to do here\"</p><p>Dally: \"Fortunately many uses of AI applications are subject to existing laws and regulations that govern the sectors in which they operate. AI enabled services in high risk sectors could be subject to enhanced licensing and certification requirements when necessary, while other applications with less risk of harm may need less stringent licensing or regulation.\"&nbsp;</p><p>Smith: \"We're going to need different levels of obligations and as we go forward let's think about the connection between the role of, let's say, a central agency that will be on point for certain things, as well as the obligations that frankly will be part of the work of many agencies...I do think that it would be a mistake to think that one single agency, or one single licensing regime would be the right recipe to address everything\"\"</p><p>Hartzog: \"Lawmakers must accept that AI systems are not neutral and regulate how they are designed. People often argue that lawmakers should avoid design rules for technologies because there are no bad AI systems, only bad AI users. This view of technologies is wrong.\"&nbsp;</p><p>Dally: \"AI is a computer program, it takes an input and produces an output, and if you don't connect up something that can cause harm to that output it can't cause that harm\"</p><p>Dally: \"[Licensing] is dependent on the application, because if you have a model which is basically determining a medical procedure there's a high risk for that. If you have another model which is controlling the temperature in your building, if it get's it a little bit wrong...it's not a life threatening situation...You need to regulate the things that are, have high consequences if things go awry\"</p><h2>Timelines</h2><p>Blumenthal: \"Make no mistake there will be regulation, the only question is how soon and what\"&nbsp;</p><p>Blumenthal: \"We'll achieve legislation I hope, by the end of this year\"</p><h1>Non-X-Risk Topics</h1><h2>Digital Providence</h2><p>Both Smith and Dally are in support</p><h2>Jobs</h2><p>Smith argues that AI will likely automate jobs without creativity and argues this can be good because it frees people up to focus on \"paying attention to other people and helping them</p>", "user": {"username": "tswizzle96"}}, {"_id": "kckcnivrXHuAz9rfG", "title": "Part 4: Reflections after attending the CEA Intro to EA Virtual Program in Summer 2023 \u2013 Chapter 4: Our Final Century?", "postedAt": "2023-11-01T07:12:08.635Z", "htmlBody": "<p>Welcome back! If you missed it, <a href=\"https://forum.effectivealtruism.org/posts/4tAqZBufLCmYy368f/reflections-after-attending-the-cea-intro-to-ea-virtual\"><strong>part 1</strong></a> details some background on this post series, which in essence is a collection of my reflections after taking the CEA Intro to EA Virtual Program course this past summer. You can find additional previous parts here: <a href=\"https://forum.effectivealtruism.org/posts/v4gKgHiu2zMNxbDd8/part-2-reflections-after-attending-the-cea-intro-to-ea\"><strong>part 2</strong></a> &amp; <a href=\"https://forum.effectivealtruism.org/posts/77p2QdNXeje5J55NT/part-3-reflections-after-attending-the-cea-intro-to-ea\"><strong>part 3</strong></a>. This post is for <a href=\"https://forum.effectivealtruism.org/s/vSAFjmWsfbMrTonpq\"><strong>Chapter 4: Our Final Century?</strong></a><strong>&nbsp;</strong>in the EA Handbook.</p><p>My awesome facilitator during the EA virtual program course &nbsp;(and the first person I've ever exchanged EA thoughts with) was kind enough to edit and help me further enrich this post. Thank you <a href=\"https://forum.effectivealtruism.org/users/nbjork?mention=user\">@NBjork</a>!</p><p>Let\u2019s get to it:</p><ul><li>As mentioned in the last chapter about radical empathy, helping the world can look like saving lives, extending lives, and/or reducing suffering. That help should be the most effective, regardless of geographical, species, or time constraints. In this chapter the conversation takes a turn to focus more on existential risks, thereby the focus is on saving and extending lives. One might understand existential risks as being the potential to continue to improve the world, for if we don\u2019t exist anymore, our options for helping have already been extinguished. For this reason, reducing existential risk is a primary moral imperative for many individuals and organizations. Our first priority is to survive and so long as that\u2019s the case there should be some margin of hope to continue to save lives, extend lives, and reduce suffering. Other things we care about (justice, equality, art, culture, environment, etc) are all things that would have a greater than zero chance to flourish to unprecedented levels in the future, but the first requirement is that an existential risk does not transpire first.</li><li>Naturally we should try to avoid tragedies in the world because often they end/shorten many lives and cause great suffering. However, the benchmark for something to be considered a tragedy is very subjective and can have an extraordinary range of impact. A mass shooting is a tragedy, but an earthquake is as well. So is war, genocide, a pandemic, starvation and even suicide. That means that even though a tragedy is certainly a negative, the magnitude of that negativity varies. Existential risk supersedes tragedy. The appropriate way to think of extinction is not by identifying it as a tragedy, but by thinking of it as the equivalent of the \"final tragedy\".&nbsp;</li><li>One way to categorize existential risks is by those that are natural vs human caused. <a href=\"https://80000hours.org/articles/existential-risks/\"><strong>As it stands, human caused risks are significantly higher than natural extinction risks.</strong></a><strong>&nbsp;</strong>Furthermore, just a very small number of human decision-makers have the power to destroy the entire world. This has been true since the 1950\u2019s and the advent of nuclear weapons.</li><li>Within the \"scale, neglectedness and solvability\" framework, many EA organizations agree that safeguarding the future is the highest goal. However, that is not always easy to show using quantitative results. Longtermist interventions \"may\" save lives if future events take place in the way we expect, but if things transpire differently, it's possible it was wasted effort. For example, say if we never experience a dangerous AI, because 10% of the AI safety work that was done worldwide was responsible for eliminating such a risk, in hindsight, the other 90% of our effort was a waste and we should have expended that energy elsewhere. Unfortunately we can't really say today what part of our x-risk efforts are not going to be impactful, so we are stuck in this dilemma. In contrast, most interventions helping today can correlate quite closely to how many lives they actually help with clear and straightforward evidence. For such interventions 100% of the effort put into them is impactful, the question is of the degree to which they're impactful.</li><li><a href=\"https://probablygood.org/core-concepts/marginal-impact/\"><strong>Marginal impact speaks to your own personal return created in your work.</strong></a> An organization may be making impact X, and when you join it, you add to it your own marginal impact (Y), and the outcome of X + Y = Z. Now X may be huge, or it may be little, but it\u2019s not the only thing that should be considered. Z should be considered to a greater degree. So let\u2019s say for another organization their impact is A. Your impact is still Y, but when combined A + Y = B. Don\u2019t simply compare the X and A values of two separate organizations, also compare (and with a larger weight) the end result of your impact as well. What is best, the final output of Z, or B?<ul><li><a href=\"https://80000hours.org/articles/problem-framework/\"><strong>To figure out Z or B quantitatively, there are a few different frameworks that analyze scale, neglectedness, solvability and personal fit and try and make the calculation of expected value as objective as possible</strong></a></li><li>But I would like to remind everyone that some factors, especially concerning personal fit, can sometimes be very tricky to analyze using mathematical formulas and logic. Humans are not computers after all, so provide your human interests and motivations some space to reside and grow in combination with a quantitative analysis</li></ul></li><li>Those who may be new to EA, as I am, may note that they have heard about climate change for most of the recent decades. From an individual to a national to a global level countless efforts related to improving climate change have been inserted into our daily lives and conversations. The future impacts of climate change can be without a doubt devastating, and (to use a word highlighted earlier in this post) tragic. Many climate change after-effects are already resulting in tragedies around the planet. However, as an EA the conversation isn\u2019t just about tragedies and catastrophes, but their potential, ie about extinction. Those analysis for the most part reveal that the risks of climate change will be devastating and catastrophic, but not at the extinction threshold. For this reason in the EA community, climate change receives a lower risk designation compared to some other cause areas. It is acknowledged however that climate change will increase the other existential risks in our world.</li></ul><p>&nbsp;</p><p>Thank you all for taking the time to read through these reflections and feel free to leave any feedback you think relevant. I am especially open to resources that expand on these thoughts further!&nbsp;</p><p>Look out for the chapter 5 reflection post soon!</p>", "user": {"username": "Andreas P"}}, {"_id": "KroRbgjoEunS6Ay9g", "title": "Philosophical considerations relevant to valuing continued human survival: Conceptual Analysis, Population Axiology, and Decision Theory (Andreas Mogensen)", "postedAt": "2023-11-01T12:10:56.135Z", "htmlBody": "<p>This paper was published as a GPI working paper in September 2023.</p><h2>Introduction</h2><p>Many think that human extinction would be a catastrophic tragedy, and that we ought to do more to reduce extinction risk. There is less agreement on exactly why. If some catastrophe were to kill everyone, that would obviously be horrific. Still, many think the deaths of billions of people don\u2019t exhaust what would be so terrible about extinction. After all, we can be confident that billions of people are going to die \u2013 many horribly and before their time - if humanity does <i>not</i> go extinct. The key difference seems to be that they will be survived by others. What\u2019s the importance of that?</p><p>Some take the view that the special moral importance of preventing extinction is explained in terms of the value of increasing the number of flourishing lives that will ever be lived, since there could be so many people in the vast future available to us (see Kavka 1978; Sikora 1978; Parfit 1984; Bostrom 2003; Ord 2021: 43-49). Others emphasize the moral importance of conserving existing things of value and hold that humanity itself is an appropriate object of conservative valuing (see Cohen 2012; Frick 2017). Many other views are possible (see esp. Scheer 2013, 2018).</p><p>However, not everyone is so sure that human extinction would be regrettable. In the final section of the last book published in his lifetime, Parfit (2011: 920\u2013925) considers what can actually be said about the value of all future history. No doubt, people will continue to suffer and despair. They will also continue to experience love and joy. Will the good be sufficient to outweigh the bad? Will it all be worth it? Parfit\u2019s discussion is brief and inconclusive. He leans toward \u2018Yes,\u2019 writing that our \u201cdescendants might, I believe, make the future very good.\u201d (Parfit 2011: 923) But \u2018might\u2019 falls far short of \u2018will\u2019.</p><p>Others are confidently pessimistic. Some take the view that human lives are not worth starting because of the suffering they contain. Benatar (2006) adopts an extreme version of this view, which I discuss in section 3.3. He claims that \u201cit would be better, all things considered, if there were no more people (and indeed no more conscious life).\u201d (Benatar 2006: 146) Scepticism about the disvalue of human extinction is especially likely to arise among those concerned about our effects on non-human animals and the natural world. In his classic paper defending the view that all living things have moral status, Taylor (1981: 209) argues, in passing, that human extinction would \u201cmost likely be greeted with a hearty \u2018Good riddance!\u2019 \u201d when viewed from the perspective of the biotic community as a whole. May (2018) argues similarly that because there \u201cis just too much torment wreaked upon too many animals and too certain a prospect that this is going to continue and probably increase,\u201d we should take seriously the idea that human extinction would be morally desirable. Our abysmal treatment of non-human animals may also be thought to bode ill for our potential treatment of other kinds of minds with whom we might conceivably share the future and view primarily as tools: namely, minds that might arise from inorganic computational substrates, given suitable developments in the field of artificial intelligence (Saad and Bradley forthcoming).</p><p>This paper takes up the question of whether and to what extent the continued existence of humanity is morally desirable. For the sake of brevity, I\u2019ll refer to this as <i>the value of the future</i>, leaving the assumption that we conditionalize on human survival implicit. On its face, the case for assigning importance to reducing the risk of human extinction hinges largely on how we answer this question. Even if we\u2019re confident that the survival of humanity is a good thing, the question of exactly how good may determine how much weight to put on reducing extinction risk, relative to other priorities.</p><p>Considered in its full generality, this is an impossibly grand question. My aim in this paper is to outline and explore some key philosophical issues relevant to determining the value of the future, drawn from the fields of population ethics (section 3) and decision theory (section 4). I have more to say on the former than on the latter. Before that, I also do my part to clarify what we\u2019re even asking here (section 2).</p><p>All this is just a very small part of the puzzle. There are myriad empirical questions with which I do not engage at all. There are also many important philosophical questions that I leave on the table, including some in decision theory, such as ambiguity aversion. The selection of topics only partially reflects my judgments about relative importance. It also reflects the gaps in my own expertise, as well as my own guesses about the extent to which I have something to contribute on a given topic. I hope this report inspires others to contribute their own treatments of the many important topics I was unable to cover.</p><h3><a href=\"https://globalprioritiesinstitute.org/andreas-mogensen-philosophical-considerations-relevant-to-valuing-continued-human-survival-conceptual-analysis-population-axiology-and-decision-theory/\">Read the rest of the paper</a></h3>", "user": {"username": "Global Priorities Institute"}}]