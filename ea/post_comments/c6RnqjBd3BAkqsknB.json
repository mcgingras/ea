[{"_id": "DLXk6NuWHL7GYE8Fx", "postedAt": "2022-10-14T19:09:26.275Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>My view: This is largely noise at best in the long-term, and extremely negative short term (but this could flip sign., and therefore bad for both the short and long-term future, and here's why.</p>\n<p>In the short-term, the key area isn't \"which values?\" but more like \"can we avoid misalignment towards a human?\" And thus values of the US vs China matter less than alignment at all, and thus this isn't important.</p>\n<p>More generally, contra some EA folks, I think value lock-in isn't as likely people think.</p>\n<p>Long-term, their value differences don't matter because of the fact that they probably won't exist for a super long time.</p>\n", "parentCommentId": null, "user": {"username": "Sharmake"}}, {"_id": "J87x6q4Zh4dCp6gjZ", "postedAt": "2022-10-14T19:38:15.656Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>Great writeup! I also wrote &nbsp;about the restrictions <a href=\"https://www.lesswrong.com/posts/oBTkthd7h8sDpkiu2/analysis-us-restricts-gpu-sales-to-china\">here</a>, with some <a href=\"https://www.lesswrong.com/posts/oBTkthd7h8sDpkiu2/analysis-us-restricts-gpu-sales-to-china?commentId=trv3HKbM7ZZeZdqBb#comments\">good discussion</a>. A few thoughts:</p><ul><li>I think this slows China's AI progress by a few years. Losing Nvidia GPUs alone is a serious hit to ML researchers in China. They are building their own alternatives, for example CodeGeeX is a GPT-sized language model trained entirely on Chinese GPUs. But this makes GPUs more scarce.&nbsp;</li><li>It probably also reduces US influence over China and Chinese AI in the future. We're making them less reliant on us now, meaning we can't use GPUs as leverage to force safety standards or other kinds of cooperation in the future.&nbsp;<ul><li>I agree with your concern about cooperation on other existential risks. If we want to work together on climate change or banning research on dangerous pathogens, this hurts us.&nbsp;</li></ul></li><li>China more or less does not care about AI safety from existential risks. Therefore, slowing their timelines is good, but sacrificing US influence over China is bad. It's unclear how these two balance out. If you have longer timelines, you'd probably prioritize long-term influence.&nbsp;</li><li>I think this definitely increases the chances of war with China, because it's explicitly designed to prepare for a possible war. It's Tom Cotton's strategy of <a href=\"https://www.cotton.senate.gov/imo/media/doc/210216_1700_China%20Report_FINAL.pdf\">economic decoupling to \"Beat China\"</a>.&nbsp;<ul><li>From the standard US foreign policy viewpoint, I think this shift is well-warranted. Cooperation with China on trade has not given us the soft power we hoped it would. They're as anti-democratic as ever, still committing human rights abuses and arguably only growing more aggressive. It's time to move from the carrot to the stick.&nbsp;</li><li>From an EA standpoint placing higher value on existential risk and lower value on typical US foreign policy interests, conflict with China definitely looks worse. The US stance looks like it would rather start World War III than allow China to become the top global superpower. I do believe that US democratic values are much better for the world than authoritarianism, and I'm scared of long-term authoritarianism, but solving it with global war doesn't help.&nbsp;</li><li>This is analogous to the question of Ukraine: Do you support a democratic nation attacked by a despot at risk of nuclear war? Avoiding armageddon has to be the top priority, but over the years we've been able to pursue our other interests without spiraling into nuclear war.&nbsp;</li><li>Important operationalization: Do we defend Taiwan with US troops? Biden says yes. Taiwan is very important to defend (not least for TSMC and its semiconductors), but I think it's probably better to lose Taiwan than raise the chances of nuclear war by 0.1%.&nbsp;</li></ul></li></ul>", "parentCommentId": null, "user": {"username": "Aidan O'Gara"}}, {"_id": "uvi2sfNZxHvAz5dMD", "postedAt": "2022-10-14T19:42:34.392Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>Great <a href=\"https://www.chinatalk.media/p/new-chip-export-controls-explained\">podcast</a> on it from Jordan Schnieder, the <a href=\"https://public-inspection.federalregister.gov/2022-21658.pdf\">document itself</a>, and the <a href=\"https://www.bis.doc.gov/index.php/documents/about-bis/newsroom/press-releases/3158-2022-10-07-bis-press-release-advanced-computing-and-semiconductor-manufacturing-controls-final/file\">press release</a>.&nbsp;</p>", "parentCommentId": "J87x6q4Zh4dCp6gjZ", "user": {"username": "Aidan O'Gara"}}, {"_id": "fwDQS3r3MaRoQ9aux", "postedAt": "2022-10-14T20:17:08.667Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>Stephen &nbsp;- thanks for a helpful and insightful summary.</p><p>It seems like Biden's regulations will send a clear signal to China that (1) the US considers AI central to future geopolitical and military power, and (2) the US considers itself to be in an AI arms race against China.</p><p>If we really want China to double down on its <a href=\"https://www.theconstructsim.com/98-chinas-ai-plan-for-2030/\">AI plan &nbsp;for 2030</a>, and to push for even stronger investment of talent, money, and attention into AI R&amp;D, this seems like a great way to do it...</p><p>Epistemic caveat: I'm far from a China expert; I just taught some online classes for undergraduates at a Chinese university &nbsp;over the last couple of years. I will comment that many of the students considered geopolitical competition for AI to be pretty central to China's strategy, and learning about AI was treated as something of a patriotic duty... and a great career opportunity.</p>", "parentCommentId": null, "user": {"username": "geoffreymiller"}}, {"_id": "44cyybPoHjHDEsfr7", "postedAt": "2022-10-14T21:40:26.633Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<blockquote><p>One of the takeaways that Allen leaves his readers with is that \u201cthis policy signals that the <strong>Biden administration believes the hype about the transformative potential of AI and its national security implications is real.</strong>\u201d That sentiment probably feels familiar to many readers of this forum.</p></blockquote><p><i>To be clear, it's good that this sentiment is possible, it is good that you mention it and consider it, and it is good that Allen mentions it and may believe it.</i></p><p>&nbsp;</p><p>If Allen or you are trying to suggest that this action is even partially motivated by concern about \"transformative AI\" in the <a href=\"https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/\">Holden sense</a> (much less full-on \"FOOM\" sense), this seems very unlikely and &nbsp;probably misleading.</p><p>&nbsp;</p><p>Approximately everyone believes \"AI is the future\" in some sense. For example, we easily can think of dozens of private and public projects that sophisticated management at top companies pushed for, that are \"AI\" or \"ML\" (that often turn out to be boondoggles). E.g., Zillow buying and flipping houses with algorithms.&nbsp;</p><p>These were claimed to be \"transformative\", but this is only in a limited business sense.</p><p>This is probably closer to the meaning of \"transformative\" being used.</p>", "parentCommentId": null, "user": {"username": "Charles He"}}, {"_id": "xPT4mhRNsWJJQpMdD", "postedAt": "2022-10-14T22:04:00.846Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>Surely reducing the number of players, making it more likely that US entities develop AGI (who might be more or less careful, more or less competent, etc. than Chinese entities), and (perhaps) increasing conflict all matter for alignment? There are several factors here that push in opposite directions, and this comment is not an argument for why the sum is zero to negative.</p>", "parentCommentId": "DLXk6NuWHL7GYE8Fx", "user": {"username": "tkwa"}}, {"_id": "GtZxL7bdgQkP3if3d", "postedAt": "2022-10-14T22:39:42.093Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>This is not an answer to your questions, but I can\u2019t resist pointing out that this post/set of questions seems like a decent illustration of the use case of the project idea I describe here: <a href=\"https://forum.effectivealtruism.org/posts/9RCFq976d9YXBbZyq/research-reality-graphing-to-support-ai-policy-and-more\">https://forum.effectivealtruism.org/posts/9RCFq976d9YXBbZyq/research-reality-graphing-to-support-ai-policy-and-more</a></p>\n<p>There\u2019s of course no guarantee that something like the envisioned research graph would have the answers to your questions (it\u2019s hard to predict what users will want, but I think graphs handle this user-uncertainty challenge better than traditional literature reviews) but it might help?</p>\n", "parentCommentId": null, "user": {"username": "Harrison D"}}, {"_id": "6BXuXxrfypot6R4sE", "postedAt": "2022-10-14T23:10:35.676Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>I should actually change my comment to say that this would be extremely negative, as the US government seems to believe in TAI (in the Holden Karnofsky sense) and also want it to happen, which at the current state of alignment would be extremely negative news for humanity's future, though this could flip sign to the positive end.</p>\n", "parentCommentId": "xPT4mhRNsWJJQpMdD", "user": {"username": "Sharmake"}}, {"_id": "DnEChtFd9Qn8Xapsi", "postedAt": "2022-10-15T03:04:22.447Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<blockquote>\n<p>They are building their own alternatives, for example CodeGeeX is a GPT-sized language model trained entirely on Chinese GPUs.</p>\n</blockquote>\n<p><a href=\"https://github.com/THUDM/CodeGeeX\">It used Huawei Ascend 910 AI Processors</a>, which was <a href=\"https://cset.georgetown.edu/wp-content/uploads/AI-Chips%E2%80%94What-They-Are-and-Why-They-Matter.pdf\">fabbed by TSMC</a>, which will <a href=\"https://forum.effectivealtruism.org/posts/W5TEsCHyk5jAfr6Zv/preventing-a-us-china-war-as-a-policy-priority?commentId=Q5pWiWAm3SfBuJPFy\">no longer be allowed to make such chips for China</a>.</p>\n", "parentCommentId": "J87x6q4Zh4dCp6gjZ", "user": {"username": "Wei_Dai"}}, {"_id": "kPzffuRtuJBAxvH7d", "postedAt": "2022-10-15T03:52:26.719Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>I'm surprised to see that it hasn't been mentioned, but a lot is still up in the air with this one. Both countries have a long history of not fully following through on proposed restrictions, but of course that could end at any time and surprise anyone who things historical precedent precludes historically unprecedented events (in this case, major fully-enforced restrictions).</p><p>In this case, Samsung (Korea) and TSMC (Taiwan) have already reportedly <a href=\"https://www.wsj.com/articles/samsung-gets-one-year-exemption-from-new-u-s-chip-restrictions-on-china-11665639994\">circumvented</a> the latest restrictions, although I don't know to what extent they'll be used as a loophole for Chinese firms to get most of the chips anyway, or if the 1-year period is just a buffer and they won't find some complicated way to extend it.&nbsp;</p><p>People in this area are, by now, pretty accustomed to saying \"it could still go either way\".</p>", "parentCommentId": null, "user": {"username": "trevorw96"}}, {"_id": "sEzCxpCDyZ98EAAQK", "postedAt": "2022-10-16T03:51:59.181Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>I don't have good answers to your questions, but I just want to say that I'm impressed and surprised by the decisive and comprehensive nature of the new policies. It seems that someone or some group actually thought through what would be effective policies for achieving maximum impact on the Chinese AI and semiconductor industries, while minimizing collateral damage to the wider Chinese and global economies. This contrasts strongly with other recent US federal policy-making that I've observed, such as COVID, energy, and monetary policies. Pockets of competence seem to still exist within the US government.</p>\n", "parentCommentId": null, "user": {"username": "Wei_Dai"}}, {"_id": "5NfGvZ3aC6S2BKQxG", "postedAt": "2022-10-17T09:23:05.421Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>Not related to the topic: I doubt it is worth it to post hacks that are likely illegal (or even for EAs to use) - the money saved seems likely to be orders of magnitudes lower than the expected harm. (Non-EA people seeing the post and using this against us, EA people who might be upset seeing these, personal legal risks)</p>", "parentCommentId": null, "user": {"username": "tseyipfai@gmail.com"}}, {"_id": "BmekC68vpWvXgQHAv", "postedAt": "2022-10-17T09:52:17.217Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>For onlookers, there was originally a link to a way to get around the FT paywall in the post. But I appreciate Fai's comment and have removed it.</p>", "parentCommentId": "5NfGvZ3aC6S2BKQxG", "user": {"username": "Stephen Clare"}}, {"_id": "m2cZqu43yjKpHB6T3", "postedAt": "2022-10-17T11:43:51.017Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<blockquote>\n<p>China more or less does not care about AI safety from existential risks. Therefore, slowing their timelines is good, but sacrificing US influence over China is bad.</p>\n</blockquote>\n<p>What evidence do you have that the Chinese government cares less about x-risks from AI than the current US government, let alone whatever government the US will have after 2024? If avoiding existential catastrophes from AI mostly depends on governments' ability to regulate AI companies, does the US government seem to you better positioned than the Chinese government to establish and enforce such regulations?</p>\n", "parentCommentId": "J87x6q4Zh4dCp6gjZ", "user": {"username": "ofer"}}, {"_id": "MSa3sFwMyFuSo9HHG", "postedAt": "2022-10-17T16:25:53.094Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>Fair point, the answer is unclear and could change. The most important fact IMO is that two of the leading AGI companies in the US, OpenAI and Deepmind, are explicitly concerned with x-risk and have invested seriously in safety. (Not as much as I\u2019d like, but significant investments.) I\u2019d rather those companies reach AGI than others who don\u2019t care about safety. They\u2019re US-based and benefit relative to Chinese companies from US policy that slows China.</p>\n<p>Second, while I don\u2019t think Joe Biden thinks or cares about AI x-risk, I do think US policymakers are more likely to be convinced of the importance of AI x-risk. Most of the people arguing for AI risk are English speaking, and I think they\u2019re gaining some traction. Some evidence:</p>\n<p>The Catastrophic Risk Management Act introduced by Senators Portman and Peters is clearly longtermist in motivation. From the act: \u201cNot later than 1 year after the date of enactment of this Act, the President, with support from the committee, shall conduct and submit to Congress a detailed assessment of global catastrophic and existential risk.\u201d Several press releases explicitly mentioned risks from advanced AI, though not the alignment problem. This seems indicative of longtermism and EAs gaining traction in DC.</p>\n<p><a href=\"https://www.congress.gov/bill/117th-congress/senate-bill/4488/text\">https://www.congress.gov/bill/117th-congress/senate-bill/4488/text</a></p>\n<p><a href=\"https://www.hsgac.senate.gov/media/minority-media/portman-peters-introduce-bipartisan-bill-to-ensure-federal-government-is-prepared-for-catastrophic-risks-to-national-security-\">https://www.hsgac.senate.gov/media/minority-media/portman-peters-introduce-bipartisan-bill-to-ensure-federal-government-is-prepared-for-catastrophic-risks-to-national-security-</a></p>\n<p>The National Security Commission on AI commissioned by Congress in 2018 did not include x-risk in their report, which is disappointing. That group, led by Eric Schmidt former CEO of Google, has continued their policy advocacy as the Special Competitive Studies Project. They are evidently aware of x-risk concerns, as they cited Holden Karnofsky\u2019s writeup of the most important century hypothesis. Groups like these seem like they could be persuaded of the x-risk hypothesis, and could successfully advocate sensible policy to the US government.</p>\n<p><a href=\"https://www.scsp.ai/reports/mid-decade-challenges-for-national-competitiveness/preface/\">https://www.scsp.ai/reports/mid-decade-challenges-for-national-competitiveness/preface/</a></p>\n<p>Finally, there are think tanks who explicitly care about AI x-risk. My understanding is that CSET and CNAS are the two leaders, but the strong EA grantmaking system could easily spur more and more successful advocacy.</p>\n<p>On the other hand, I\u2019m unaware of a single major group in China that professes to care about x-risk from AI. I might not know if they did exist, so if there\u2019s any evidence I\u2019d love to hear it. China does seem to have much stronger regulatory skills, and would probably be better at implementing compute controls and other \u201cpivotal acts\u201d. But without a channel to communicate why they should do so, I\u2019m skeptical that they will.</p>\n", "parentCommentId": "m2cZqu43yjKpHB6T3", "user": {"username": "Aidan O'Gara"}}, {"_id": "Nvp6Wb7ePkSrrP2vE", "postedAt": "2022-10-17T16:49:59.047Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>I would actively appreciate a norm to link to non-paywalled version of articles. I don't think the legality concerns matter.</p>", "parentCommentId": "BmekC68vpWvXgQHAv", "user": {"username": "Habryka"}}, {"_id": "zELTzTTaKiCpTWv6z", "postedAt": "2022-10-17T18:31:29.228Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<blockquote>\n<p>On the other hand, I\u2019m unaware of a single major group in China that professes to care about x-risk from AI. I might not know if they did exist, so if there\u2019s any evidence I\u2019d love to hear it.</p>\n</blockquote>\n<p>There is a research institute in China called the Beijing Academy of Artificial Intelligence. In <a href=\"https://www.facebook.com/yizeng.casia/posts/pfbid02RuSn8KrSzrNjfB1STZdG3pCqMSGtV6qwqqmpViFmSict6wKQU84BgjmtPbYzKMavl?__cft__%5B0%5D=AZW3hdrqmV-luL3ajDp5pzv0wY1SaAl2erbKUsI5iiUgj0oRz1YKo7oNKmuwSAa858-GB484diLu2Ne3QWmB_9YhVrh7LMJSPMxMWDWwSQoWS9mZvjz4Jd5FV0jM8aI1PyGcJNpv9-cUQkt5KoHnwTK5&amp;__tn__=%2CO%2CP-y-R\">May 2019</a> they published a document called \"<a href=\"http://web.archive.org/web/20190808223400/https://baip.baai.ac.cn/en\">The Beijing Artificial Intelligence Principles</a>\" that included the following:</p>\n<blockquote>\n<p>Harmony and Cooperation: Cooperation should be actively developed to establish an interdisciplinary, cross-domain, cross-sectoral, cross-organizational, cross-regional, global and comprehensive AI governance ecosystem, so as to avoid malicious AI race, to share AI governance experience, and to jointly cope with the impact of AI with the philosophy of \"Optimizing Symbiosis\".</p>\n</blockquote>\n<p>.</p>\n<blockquote>\n<p>Long-term Planning: Continuous research on the potential risks of Augmented Intelligence, Artificial General Intelligence (AGI) and Superintelligence should be encouraged. Strategic designs should be considered to ensure that AI will always be beneficial to society and nature in the future.</p>\n</blockquote>\n<p>(This is just something that I happened to stumble upon when it was published; there may be many people in China at relevant positions that take x-risks from AI seriously.)</p>\n", "parentCommentId": "MSa3sFwMyFuSo9HHG", "user": {"username": "ofer"}}, {"_id": "HoW4ipAf7pbjWLEAP", "postedAt": "2023-06-15T13:30:43.853Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>I got new upvotes for my above comment (even though it is still negative now) which reminds me of it. I suddenly have a question and I genuinely want to know the answer and do not wish to be offensive or sarcastic.&nbsp;</p><p>Question: Would people have voted (karma and agreement) differently if my comment happened a month later? (FTX collapse)</p><p>Also, at that time, quite a number of people are searching on the EA forum for evidence that they claim to support views like \"EAs ignore laws and common sense morality\", \"EAs think that ends always justify means\", etc. This means that I could have made a wrong decision to leave the above comment by letting non-EAs potentially see it (if I can reasonably expect the voting results to seem to support illegal things.)</p><p>And maybe, I should just delete this comment, now?</p>", "parentCommentId": "Nvp6Wb7ePkSrrP2vE", "user": {"username": "tseyipfai@gmail.com"}}, {"_id": "dKun8QdoPNJQSad6z", "postedAt": "2023-06-15T13:46:55.111Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>I didn't vote, but:</p><p>People may have also found the assertion that there is something \"likely illegal\" to be unsupported by your comment. I don't know how the previously-linked site worked, so offer no opinion on that. Furthermore, the use of these sites is common, so it is also reasonable to question the assumption that using it carried reputational risk. And the existence of any legal risk, especially to anyone who merely clicked on the link, seems highly questionable as a practical matter. These things exist on the open web, the publishing industry knows where they are, and it would be illogical / horrible optics / very cumbersome and expensive for publishers to go after individual users rather than the service providers.&nbsp;</p>", "parentCommentId": "HoW4ipAf7pbjWLEAP", "user": {"username": "Jason"}}, {"_id": "AbkaNoehpaoXfnsgT", "postedAt": "2024-03-16T08:57:28.320Z", "postId": "c6RnqjBd3BAkqsknB", "htmlBody": "<p>Late response, but may still be of interest: some colleagues and I spent some time surveying the existing literature on China x AI issues and <a href=\"https://forum.effectivealtruism.org/posts/hp882mEMm6vZ24Mmi/china-x-ai-reference-list\">the resource list we produced</a> includes a section on <a href=\"https://docs.google.com/document/d/1OJcHhhBfNwEbeUaT-d4RIq58I1oJ3XGxu2yCzsnieuo/edit#heading=h.z22dz89bhiux\">Key actors and their views on AI risks</a>. In general, I'd recommend the <a href=\"https://aisafetychina.substack.com/\">Concordia AI Safety newsletter</a> for regular news of Chinese actors commenting on AI safety (and, more or less directly, on related x-risks).</p>", "parentCommentId": "MSa3sFwMyFuSo9HHG", "user": {"username": "Sarah Weiler"}}]