[{"_id": "csCBuzC6cJK5xHevJ", "postedAt": "2023-05-16T18:07:03.144Z", "postId": "SxpQpqXBvAxrPWC2e", "htmlBody": "<p>Super excited about the artificial conscience paper. I'd note that a similar approach be very useful for creating <a href=\"https://forum.effectivealtruism.org/s/3pyRzRQmcJNvHzf6J/p/9RZodyypnWEtErFRM#A_Sketch_of_LFAI\">law-following AIs</a>:</p>\n<blockquote>\n<p>An LFAI system does not need to store all knowledge regarding the set of laws that it is trained to follow. More likely, the practical way to create such a system would be to make the system capable of recognizing when it faces sufficient legal uncertainty,[10] then seeking evaluation from a legal expert system (\"Counselor\").[11]</p>\n<p>The Counselor could be a human lawyer, but in the long-run is probably most robust and efficient if (at least partially) automated. The Counselor would then render advice on the pure basis of idealized legality: the probability and expected legal downsides that would result from an idealized legal dispute regarding the action if everyone knew all the relevant facts.</p>\n</blockquote>\n", "parentCommentId": null, "user": {"username": "Cullen_OKeefe"}}]