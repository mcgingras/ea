[{"_id": "3TNFqPNT4dJ7afbZh", "postedAt": "2022-12-31T19:22:54.481Z", "postId": "B6FXBZBsBB2mmyp3z", "htmlBody": "<p>Good question! I think the term you are looking for is <a href=\"https://www.lesswrong.com/posts/zthDPAjh9w6Ytbeks/deceptive-alignment\">\"deceptive alignment\"</a>.</p><p>As you allude to, this might be okay, until the AI's objectives are no longer maximized by continuing to be deceptive.</p>", "parentCommentId": null, "user": {"username": "Ben_West"}}]