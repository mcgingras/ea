[{"_id": "WyMn5oseMdxJcHE9f", "postedAt": "2015-07-20T20:28:58.128Z", "postId": "8SA5LniqnQGYKYTi6", "htmlBody": "<p>I agree with you on your central premise that philosophical triviality is okay if the idea is still valuable and important. But I think EA happens to be less trivial than even Rob says. It looks to me (from a cursory reading of Iason's paper) like the 'thick version' in Iason Gabriel's post is quite a bit thinner than the 'associated ideas' in Rob's post. The thick version involves assumptions that I think are pretty central to EA - the broadly consequentialist framework (which includes the erasure of the action/omission distinction common to many moral theories and a morally egalitarian ethos with regard to categories like nationality and species) and confidence in scientific methodology. The associated ideas go further than that - the idea that earning to give is highly effective or that RCTs are highly valuable same more specific than even the thick version. I think Jason's thick version is a better description of EA than the thin version (which is closer to what Rob uses in his post), and though it's more trivial than a version incorporating all of those incorporated ideas would be, it's significantly less trivial than the thin one.</p>\n", "parentCommentId": null, "user": {"username": "zdgroff"}}, {"_id": "HC5zHmndtT2NjyxiZ", "postedAt": "2015-07-29T07:44:54.673Z", "postId": "8SA5LniqnQGYKYTi6", "htmlBody": "<p>Thanks Stefan, this is a very good point.</p>\n", "parentCommentId": null, "user": {"username": "Toby_Ord"}}, {"_id": "q998tpr7iqSLZg5pF", "postedAt": "2023-08-03T08:36:29.796Z", "postId": "8SA5LniqnQGYKYTi6", "htmlBody": "<p>I do not think that even the thin version of EA is trivial at all. Perhaps to those who come from very rational, non-religious societies, the message appears obvious. But for many people, EA is a massive philosophical shift from everything they have been taught.&nbsp;<br><br>If you ask many people about charity, for example, they will focus much more on the giver than the beneficiary. Christianity, for example, focuses very strongly on the value of sacrifice, and most Christians would naturally judge the value of a given charitable act more based on how it impacted the <i>donor</i> than on how it impacted the recipient. An act which costs the donor greatly is valued highly even if the net impact on the recipient is minor.&nbsp;<br><br>But this isn't just a Christian or religious idea. Look at all the half-marathons all over the world where people run to support charities. The message is: if you're willing to <i>suffer</i> through 20 km of pain, it feels justified that I give $20 to MSF. As if the suffering and commitment of the runner were related to the rightness of another person donating to a charity. Yet we find it perfectly natural.&nbsp;<br><br>With effective altruism, we are not at all making a trivial argument. Rather we're asking people to take a dramatic philosophical jump, to <i>focus not on the sacrifice but on the effect</i>.&nbsp;<br><br>Perhaps \"earning to give\" is the most obvious case in point. Imagine an engineer earning $500K/year and donating $100K tax-deductibly to effective charities, at a net cost to herself of just $50K, which she doesn't even notice. She may feel like she's not doing enough, she still has a great lifestyle and wants for nothing.&nbsp;</p><p>If she were to quit her job and volunteer to go to work in Niger, making a great personal sacrifice, the vast majority of people would consider that a very altruistic act. They would focus on <i>her</i> - what's she's sacrificing and why. Radio stations would interview her, journalists would write about her, etc.&nbsp;</p><p>But EA turns that logic on its head, and says \"Listen, if you <i>really</i> want to do the most good possible, actually, your $100K is worth more to us than your presence in Niger. Please just stay in your job and keep your luxurious lifestyle and keep giving us the money.\"<br><br>This mentality is a radical philosophical shift for anyone educated in the Christian tradition, whether knowingly or otherwise. Christianity says that if giving $100K doesn't really cost you anything, doesn't make you suffer, than it doesn't count, it won't bring you closer to heaven. If you give up everything and devote your life to charity, that probably will get you into heaven. EA says the opposite - focus only on how to have the most impact. And if you can have the most impact without having to suffer, that is a win/win situation. &nbsp;</p>", "parentCommentId": null, "user": {"username": "Denis "}}, {"_id": "2WydxfoJzSgwJswHv", "postedAt": "2023-08-03T22:56:26.080Z", "postId": "8SA5LniqnQGYKYTi6", "htmlBody": "<blockquote><p>Here I think the EA movement has a very substantial role to play.&nbsp;My hypothesis is thus that the EA message is very fruitful <i>even</i> though it may be philosophically trivial.</p></blockquote><p>&nbsp;</p><p>It seems correct given EA's goals, its effectiveness should not be measured philosophically -- instead it should be assessed practically. &nbsp;If EA fails, likely it is because it becomes meta discussion (like this one) and fails to make a difference in this world. &nbsp;(This is not intended as a dig against the present discussion). &nbsp;My sense is that EA sometimes involves interested parties that are not directly involved in DOING the relevant activities in question. &nbsp;Thus it is a kind of meta-discussion by its nature. &nbsp;I think this is fine... as an AI guy I notice that practitioners rarely ask the hardest questions questions about what they are doing. &nbsp;as a former DARPA guy I saw the same myopia in the defense sphere. &nbsp;So outsiders may well be the right ingredient to add.<br><br>Personally I would assess EA on the basis of its subjectively/objectively-assessed movement of the Overton window for relevant decision makers. &nbsp;e. g. company owner, voters, activists, researchers, etc. &nbsp;The issues EA takes on are really quite large. &nbsp;It seems hard to directly move that needle. &nbsp;Still it seems plausible that EA could end up being transformative by changing very thinking of humanity. &nbsp;And it seems possible that it gets wrapped up into its own sub-communities whose beliefs end up diverging from humanity at large and thus are ignored by humanity at large.<br><br>When I look at questions around AGI safety I think the tiny amounts of human effort and money expended by EA, perhaps this can be counted as a \"win\" ... that humanity's thinking is moving in directions that will affect large scale policy. &nbsp;(On this particular issue, I fall into the \"too little too late\" camp) but still I have to acknowledge the apparently real impact EA has had in legitimizing this topic in practically impactful ways.<br><br><br>&nbsp;</p>", "parentCommentId": null, "user": {"username": "Dan Oblinger"}}, {"_id": "oHA43SZZiosWGZHXY", "postedAt": "2023-08-03T22:57:38.551Z", "postId": "8SA5LniqnQGYKYTi6", "htmlBody": "<blockquote><p>Here I think the EA movement has a very substantial role to play.&nbsp;My hypothesis is thus that the EA message is very fruitful <i>even</i> though it may be philosophically trivial.</p></blockquote><p>&nbsp;</p><p>It seems correct given EA's goals, its effectiveness should not be measured philosophically -- instead it should be assessed practically. &nbsp;If EA fails, likely it is because it becomes meta discussion (like this one) and fails to make a difference in this world. &nbsp;(This is not intended as a dig against the present discussion). &nbsp;My sense is that EA sometimes involves interested parties that are not directly involved in DOING the relevant activities in question. &nbsp;Thus it is a kind of meta-discussion by its nature. &nbsp;I think this is fine... as an AI guy I notice that practitioners rarely ask the hardest questions questions about what they are doing. &nbsp;as a former DARPA guy I saw the same myopia in the defense sphere. &nbsp;So outsiders may well be the right ingredient to add.<br><br>Personally I would assess EA on the basis of its subjectively/objectively-assessed movement of the Overton window for relevant decision makers. &nbsp;e. g. company owner, voters, activists, researchers, etc. &nbsp;The issues EA takes on are really quite large. &nbsp;It seems hard to directly move that needle. &nbsp;Still it seems plausible that EA could end up being transformative by changing very thinking of humanity. &nbsp;And it seems possible that it gets wrapped up into its own sub-communities whose beliefs end up diverging from humanity at large and thus are ignored by humanity at large.<br><br>When I look at questions around AGI safety I think the tiny amounts of human effort and money expended by EA, perhaps this can be counted as a \"win\" ... that humanity's thinking is moving in directions that will affect large scale policy. &nbsp;(On this particular issue, I fall into the \"too little too late\" camp) but still I have to acknowledge the apparently real impact EA has had in legitimizing this topic in practically impactful ways.<br><br><br>&nbsp;</p>", "parentCommentId": null, "user": {"username": "Dan Oblinger"}}]