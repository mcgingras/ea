[{"_id": "YjrqD5RJueNZuRP7e", "title": "Could Raising Alcohol Taxes Save Lives?", "postedAt": "2015-07-31T02:55:29.790Z", "htmlBody": "<p><i>By David Roodman</i></p><p><i><strong>Note: </strong>Before the launch of the Open Philanthropy Project Blog, this post appeared on the </i><a href=\"http://blog.givewell.org/\"><i>GiveWell Blog</i></a><i>. Uses of \u201cwe\u201d and \u201cour\u201d in the below post may refer to the Open Philanthropy Project or to GiveWell as an organization. Additional comments may be available at the </i><a href=\"http://blog.givewell.org/2015/07/30/could-raising-alcohol-taxes-save-lives/\"><i>original post</i></a><i>.</i></p><hr><p>I\u2019ve just posted a <a href=\"http://davidroodman.com/david/The%20impacts%20of%20alcohol%20taxes%206.pdf\">review on the effects of alcohol taxes</a> on alcohol consumption\u2014and on the lives that alcohol abuse can cost. This literature review is unusual in the degree to which it replicates the studies it examines, so I have called it a \u201creplication review.\u201d Data, code, and spreadsheets are <a href=\"http://files.givewell.org/files/labs/alcohol-policy/Roodman_alcohol_tax_data_and_code.zip\">here</a>.</p><p>The literature on this topic is large, and at first glance it seemed that the high-quality studies contradicted each other. Yet as I dug deeper, I found a pattern: the larger the experiment\u2014the larger the price change\u2014the clearer the effects. In the end, I believe the preponderance of the evidence says that higher prices do correlate with less drinking and lower incidence of problems such as cirrhosis deaths. And I see little reason to doubt the obvious explanation: higher prices <i>cause</i> less drinking. A rough rule of thumb is that each 1% increase in alcohol price reduces drinking by 0.5%. Extrapolating from some of the most powerful studies, I estimate an even larger impact on the death rate from alcohol-caused diseases: 1\u20133% within months. By extension, a 10% price increase would cut the death rate 9\u201325%. For the US in 2010, this represents 2,000\u20136,000 averted deaths/year.</p><h1>Why I looked into the literature on alcohol taxation</h1><p>Last November GiveWell convened a daylong meeting in Washington, DC, to gather and test ideas for priorities for our work relating to U.S. policy. (See the <a href=\"http://www.givewell.org/labs/policy/convening-2014-11\">page</a> about the event or Holden\u2019s <a href=\"https://www.openphilanthropy.org/blog/notes-november-convening-our-policy-priorities\">post</a>.) One potential priority that <a href=\"http://www.givewell.org/files/labs/Issue%20writeups%20for%20Nov.%2010%20meeting.docx\">came up</a>\u2014but which otherwise has hardly been mentioned on GiveWell.org\u2014was increasing alcohol taxes:</p><blockquote><p><i>We have no particular reason to believe that the time is particularly ripe for reform in this area, but with alcohol excise taxes gradually diminishing in real terms at both the state and federal levels, it\u2019s possible to envision work at either level.</i></p><p><i>One example of a prospect to exploit the current political environment is a successful 2011 campaign to raise alcohol taxes in Maryland. The campaign was carried out by a coalition of public health and progressive advocacy groups around the combined goal of reducing excessive alcohol consumption and increasing revenue. Many of the coalition members had previously mobilized together to support the Affordable Care Act.</i></p></blockquote><p>The next day, Holden asked me to look into what is known about the impacts of alcohol taxes.</p><p>Alcohol taxation is not a top priority for Open Phil at the moment. Though we see the issue as uncrowded (which is promising), we see it as having only moderate importance compared to <a href=\"https://docs.google.com/spreadsheets/d/1NpcmVO3DnOmtKRbYGkNbR0NTitclT5mwGBwBEwYlKHg/edit#gid=0\">other causes we\u2019re considering</a>, along with highly uncertain political tractability. Nevertheless, our priorities can and do shift, and the issue seemed worth understanding better, particularly in light of the large body of studies on the topic.</p><h1>My review</h1><p>An excerpt from the intro:</p><blockquote><p><i>Heavy drinking is associated with many health and social problems, including liver disease, unsafe sex, domestic violence, homicide, and reckless driving. In 2012, 28,000 Americans died from alcohol-caused diseases. Another 10,000 lost their lives in alcohol-involved motor vehicle crashes, accounting for 31% of all motor vehicle deaths\u2026 Worldwide in 2010, the death toll from alcohol-caused disease was 155,000\u2026.</i></p><p><i>Many policies affect drinking and related behaviors: criminal penalties for drunk driving, the minimum drinking age, state monopoly of retail, advertising rules, regulations on when bars can be open and who they can serve, outright prohibition, and more. In the US, alcohol taxes have hardly risen in a generation\u2014indeed, have been drastically eroded by inflation (see figure below). In 1990, President Bush signed a deficit reduction bill that included an alcohol tax hike (visible below); thereby, Bush broke his \u201cno new taxes\u201d pledge, weakened his reelection bid, and helped make tax increases anathema in American politics. Conceivably, increasing taxation is now the low-hanging fruit in alcohol control policy.</i></p></blockquote><figure class=\"image\"><img src=\"http://blog.givewell.org/wp-content/uploads/2015/06/US-alcohol-taxes-federal-population-weighted-state.png\"></figure><blockquote><p><i>But if taxes are low-hanging fruit, how nutritious are they? How certain should we be that taxing alcohol reduces consumption in general and problem drinking in particular? How much illness, physical or social, would be averted?</i></p><p><i>Many studies examine the impacts of changes in alcohol taxes or prices. </i><a href=\"http://doi.org/10.1186/2191-1991-3-17\"><i>Nelson (2013, Table 1)</i></a><i> finds 578. The literature is so big that it contains a sub-literature of systematic reviews\u2026</i></p><p><i>Few of the underlying studies attain high-quality causal identification as that term is meant today in economics, exploiting randomized treatment or strong natural experiments. Here, I focus on the minority of studies that do use natural experiments\u2014sudden changes in alcohol taxation in certain states or countries.</i></p><p><i>Superficially, the high-quality studies contradict each other. Alcohol tax cuts apparently did not increase problem drinking in Denmark or Hong Kong, for instance, but did in Finland and Switzerland.</i></p><p><i>Yet the overall pattern across the quasi-experiment studies is that the larger the experiment\u2014the larger the price change\u2014the clearer the effects. The 7% tax hike in Alaska on October 1, 2002, and the 18% cut in Finland on March 1, 2004, are leading examples. The simplest and most plausible explanation for the \u201cnull\u201d results in other contexts is that their natural experiments were too small to produce unambiguous consequences.</i></p><p><i>Overall, in my view, the preponderance of the evidence says that higher prices do correlate with less drinking and lower incidence of problems such as cirrhosis deaths. And, as I elaborate, I see little reason to doubt the obvious explanation: higher prices cause less drinking. A rough rule of thumb is that each 1% increase in alcohol price reduces drinking by 0.5% (</i><a href=\"http://doi.org/10.1186/2191-1991-3-17\"><i>Nelson 2013</i></a><i>, as discussed below). And, extrapolating from some of the most powerful studies, I estimate an even larger impact on the death rate from alcohol-caused diseases: 1\u20133% within months. By extension, a 10% price increase would cut the death rate 9\u201325%. For the US in 2010\u2026, this represents 2,000\u20136,000 averted deaths/year.</i></p><p><i>How much a tax-induced price increase would affect violence and traffic deaths is harder to establish from the available studies. The clearest impacts in the literature have indeed been on the death rate from cirrhosis, in part because drinking is the primary cause, in part because heavy drinkers are presumably most sensitive to price, in part because the impact can be nearly immediate, making for easier statistical detection. (Although cirrhosis is a chronic disease, it is progressive, so that a sudden increase in drinking can speed death among those in whom the disease is most advanced. </i><a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1939047/pdf/canmedaj00871-0022.pdf\"><i>Seeley 1960</i></a><i>.) Impacts on crime, suicides, and risky sexual behavior have been reported, but have not yet been demonstrated through strong natural-experiment\u2013based studies.</i></p></blockquote><p>Again, the full report is <a href=\"http://davidroodman.com/david/The%20impacts%20of%20alcohol%20taxes%206.pdf\">here</a>. And for an interesting sidelight on the research, see my post <a href=\"http://davidroodman.com/blog/2015/05/01/are-the-benefits-of-moderate-drinking-a-myth/\">questioning whether moderate drinking is healthy</a>, which touches on the interesting idea of Mendelian randomization.</p><p>As we are continuing to learn about this issue, we welcome your thoughts.</p>", "user": {"username": "EA Forum Archives"}}, {"_id": "8WNi4ijcEaFDKo5is", "title": "Disagreeing about what's effective isn't disagreeing with effective altruism", "postedAt": "2015-07-16T07:00:00.000Z", "htmlBody": "<p>Lately I have had the uncanny experience of reading supposed \u2018rebuttals\u2019 of effective altruism that just say a bunch of things that I and most of my colleagues agree with. As we are some of the most involved people in the effective altruism movement, this is strange to say the least.</p><p>What is going on here is that effective altruism is both a narrow <i>core idea</i>, and a bunch of <i>associated ideas</i>. Some of these associated ideas happen to be widely held by people who describe themselves as effective altruists \u2013 others don\u2019t even meet that standard.</p><p>What is the <i>core idea</i>?</p><ul><li>Effective altruism is the use of evidence and analysis to take actions that help others as much as possible.</li></ul><p>Many of my colleagues would want to add here that you \u2018should\u2019 use evidence and reason to help others as much as possible. But there is no consensus on whether engaging in \u2018effective altruism\u2019 is a moral duty, or just something we should be enthusiastic about because we care about others.</p><p>What about the <i>associated ideas</i>? I could listed dozens, but some are:</p><ul><li>It\u2019s highly effective to give to GiveWell recommended charities;</li><li>Randomised controlled trials are a great way to figure out what works in development;</li><li>Animal welfare is an important thing to worry about;</li><li>Humans run a serious risk of a horrible catastrophe in the next century;</li><li>Earning a lot of money and giving it away is a good career path;</li><li>And many others.</li></ul><p>Now, notice that none of these are inevitably entailed by the <i>core idea</i>.</p><p>One could easily think that you should use evidence and analysis to take actions that help others as much as possible, and think that <a href=\"http://www.givewell.org/charities/top-charities\">GiveWell\u2019s recommended charities</a> completely stink. Or want to do as much good as possible, but think the evidence is that randomised controlled trials are too expensive to justify their cost most of the time.</p><p>While I am passionate about helping others as much as possible, I personally do not give to GiveWell\u2019s recommend charities any more, because I think better options are being uncovered, for example by GiveWell\u2019s sister project, the <a href=\"http://www.openphilanthropy.org/\">Open Philanthropy</a>.</p><p>Does that mean I don\u2019t agree with \u2018<i>effective altruism</i>\u2019? No.</p><p>A lot of vegetarians like kale, but just because you don\u2019t like kale doesn\u2019t mean you eat meat.</p><p>Similarly, I can think some scientific paper reached the wrong conclusion, without disagreeing with the goal of expanding our understanding of the natural world, let alone <i>the scientific method</i>.</p><p>What makes this even worse is that many of the claims attributed to effective altruists are not even that widely held.</p><p>Effective altruists are often cited as believing that only giving to GiveWell\u2019s classic \u2018proven\u2019, \u2018scalable\u2019, \u2018transparent\u2019 charities is a good idea, or that these options are much more effective than everything else. My experience is that only about 10-20% of people who identify as effective altruists actually endorse this view with any confidence \u2013 a subgroup that for a while were being referred to as \u2018skeptical altruists\u2019 for their insistence on especially strong empirical evidence of impact. Most are receptive to other options being as effective as these recommendations, or even better.</p><p>Effective altruists are often cited as <a href=\"https://80000hours.org/2015/07/effective-altruists-love-systemic-change/\">being skeptical</a> of attempting to \u2018change the system\u2019, but a <a href=\"https://www.facebook.com/groups/effective.altruists/permalink/898056463584045/?qa_ref=qd\">snap poll</a> on the \u2018Effective Altruists\u2019 Facebook group \u2013 admittedly an imperfect sample \u2013 showed systemic change was actually more popular than any of the alternatives.</p><p>80,000 Hours is often cited as claiming \u2018earning to give\u2019 is clearly the best career option for most. A quick perusal of our career guide would show that is far from what we believe, though the <a href=\"https://80000hours.org/2015/07/80000-hours-thinks-that-only-a-small-proportion-of-people-should-earn-to-give-long-term/\">misunderstanding</a> is partly our own fault for not pushing back enough against massive media coverage of the \u2018earning to give\u2019 concept.</p><p>So next time someone says they disagree with effective altruism because they don\u2019t go along with some very specific conclusion, you can put their mind to rest: they probably don\u2019t disagree with \u2018effective altruism\u2019. Rather they just disagree with some fellow effective altruists about how to help others the most. But that\u2019s also true of me, and in fact true of everyone. If we never disagreed, we would never make any progress figuring out how to do better! And as the above shows, even that disagreement may be illusory.</p><p>Have I now defined \u2018effective altruism\u2019 to be so obvious that nobody could challenge it? I find the idea of doing as much good as possible in the world to be very compelling. However, many people <i>do</i> actually disagree with the core concept! Some because they don\u2019t believe there is a \u2018right and wrong\u2019 and are not personally excited about the idea of helping others. Some because they believe that trying to \u2018maximise\u2019 how much you help others is the wrong way to go about it. Some because they think using evidence and analysis detracts from your ability to actually help people by having a nurturing and irreplaceable relationship with them. Such people <i>can</i> correctly say they are indifferent to, or dislike, effective altruism.</p>", "user": {"username": "Robert_Wiblin"}}, {"_id": "LfNeKEpWhYK9eCb7E", "title": "Where coulds go", "postedAt": "2015-08-17T05:00:00.000Z", "htmlBody": "<p>Most people don't think they \"could\" cure Alzheimers by snapping their fingers, and so they don't feel terrible about failing to do this.</p><p>By contrast, people who fail to resist overeating, or who fail to stop playing Civilization at a reasonable hour, feel strongly that they \"could have\" resisted, and take this as a license to feel terrible about their decisions.</p><p>As I said <a href=\"http://mindingourway.com/not-yet-gods/\">last week</a>, most people have broken \"coulds.\"</p><p>Willpower is scarce in this world. Sometimes, you can will yourself out of a mental rut you're in, but only rarely; more often, sheer force of will alone is not sufficient. If your plan to stop staying up too late playing Civilization is \"well I'll just force myself harder next time,\" then this plan is doomed to failure. If it didn't work last time, it likely won't work next time. <a href=\"http://mindingourway.com/self-signaling-the-ability-to-do-what-you-want/\">Willpower is a stopgap, not a remedy</a>.</p><p>I think that most people's \"coulds\" are broken because they put the action nodes in the wrong place. They think that the \"choice\" occurred at turn 347 of Civilization, when they decided to continue playing one more round (and at each following turn between midnight and 4:00 in the morning).</p><p>But that's not where the choice occurred. If you have to force yourself to change your behavior, then you've already missed the real choice node.</p><p>The actual choice occurs when you decide <i>whether to play Civilization or not</i>, at the very beginning.</p><p>Say you have one acquaintance in your social circles who regularly frustrates you, and every so often, you explode at them and get into a big shouting match. You <i>know</i> you shouldn't start yelling at them, you <i>try</i> to not be frustrated. Whenever they start annoying you, you <i>will</i> yourself to cool down, but it never quite works (no matter how strongly you resolve to force yourself harder next time). In this case, I suggest that you stop trying to force yourself to hold back as your frustration peaks, and instead start noticing what happens <i>five minutes before</i> you explode. <i>That's</i> where the real choice is. The real choice isn't in whether or not you explode <i>in the moment</i>, it's in whether you exit the situation five minutes earlier.</p><p>The real choices tend to happen a few minutes before the choices that people beat themselves up about. If you have to apply willpower, you've already missed the choice node. (In fact, I've previously suggested promising yourself that you'll <a href=\"http://mindingourway.com/deregulating-distraction-moving-towards-the-goal-and-level-hopping/\">never pull yourself out of a situation using willpower</a> \u2014 knowing that you <i>won't</i> save your own ass if you get into a situation where you need willpower to extract yourself really makes you notice the true point of no return when it comes along.)</p><p>If you find yourself in a pattern of behavior you don't like, then I recommend pretending you don't have <i>any</i> willpower. Imagine you lived in the world where you <i>couldn't</i> force yourself to stop doing something addicting after starting. In that world, how would you act?</p><p>Look for the triggers that precede the action you wish you could make differently. What happens an hour beforehand? What happens five minutes beforehand? What happens sixty seconds before you fail to act as you wish?</p><p><i>That's</i> where the real choice lies.</p><hr><p>Most people's coulds are broken. They treat themselves like they \"could\" start bingeing a TV show and then stop at a reasonable hour. They put themselves in a situation that tempts them against their better judgement, and then berate themselves when they succumb.</p><p>By contrast, I don't treat myself as if I \"could\" stop binge-reading a good book, and therefore I don't feel terrible if I binge. Instead, I say, \"ah, I see, I binge-read engaging books; I will treat 'read an engaging book' as a single atomic action that takes five to twenty hours, with no choice nodes in between.\" Where others are berating themselves for failing to complete an impossible task (\"stop binge-reading halfway through and get back to real work\"), I am learning what I am and am not capable of, and learning where my real action nodes are.</p><p>We humans don't <i>have</i> all the choice nodes. Sometimes, we can't stop binge-reading a good book anymore than we could snap our fingers to cure Alzheimer's disease. Sometimes, addiction takes over; other times, the lizard brain takes over; other times, primal rage takes over. In those moments, we don't get to call the shots. We aren't the choice-makers at every point in our lives. We often lack the willpower to override our impulses, instincts, and habits.</p><p>The goal is to win anyway.</p><p>Our better judgement is not the absolute arbiter of our actions, and there are often times when the voice of judgement is nearly powerless to affect our behavior. We <a href=\"http://mindingourway.com/not-yet-gods/\">aren't yet gods</a>. We're still monkeys. Still neural nets.<br>I suggest you stop berating yourself for failing to complete impossible tasks, and start experimenting and identifying which action nodes <i>work.</i></p><p>Search for the choices that let you act as you wish <i>before</i> the decision gets difficult to execute. Learn how to identify the moments when your mind is readily responding to your will. Those are the real choice-points, and it is from there that you may optimize.</p>", "user": {"username": "So8res"}}, {"_id": "qFfs5zXFGJaoXzb92", "title": "Not yet gods", "postedAt": "2015-08-09T05:00:00.000Z", "htmlBody": "<p>You probably don't feel guilty for failing to snap your fingers in just such a way as to produce a cure for Alzheimer's disease.</p><p>Yet, many people <i>do</i> feel guilty for failing to work until they drop every single day (which is <a href=\"http://mindingourway.com/stop-before-you-drop/\">a psychological impossibility</a>). They feel guilty for failing to magically abandon behavioral patterns they dislike, without practice or retraining (which is <a href=\"http://mindingourway.com/dont-steer-with-guilt/\">a cognitive impossibility</a>). What gives?</p><p>The difference, I think, is that people think they \"couldn't have\" snapped their fingers and cured Alzheimer's, but they think they \"could have\" used better cognitive patterns. This is where a lot of the damage lies, I think:</p><p>Most people's \"coulds\" are broken.</p><p>People think that they \"could have\" avoided anxiety at that one party. They think they \"could have\" stopped playing Civilization at a reasonable hour and gone to bed. They think they \"could have\" stopped watching House of Cards between episodes. I'm not making a point about the illusion of free will, here \u2014 I think there <i>is</i> a sense in which we \"could\" do certain things that we do not in fact do. Rather, my point is that most people have a miscalibrated idea of what they could or couldn't do.</p><p>People berate themselves whenever their brain fails to be engraved with the cognitive patterns that they wish it was engraved with, as if they had complete dominion over their own thoughts, over the patterns laid down in their heads. As if they weren't a network of neurons. As if they could choose their preferred choice in spite of their cognitive patterns, rather than recognizing that choice <i>is</i> a cognitive pattern. As if they were supposed to <i>choose</i> their mind, rather than <i>being</i> their mind.</p><p>As if they were already gods.</p><p>We aren't gods.</p><p>Not yet.</p><p>We're still monkeys.</p><hr><p>Almost everybody is a total mess internally, as best as I can tell. Almost everybody struggles to act as they wish to act. Almost everybody is psychologically fragile, and can be put into situations where they do things that they regret \u2014 overeat, overspend, get angry, get scared, get anxious. We're monkeys, and we're fairly fragile monkeys at that.</p><p>So you don't need to beat yourself up when you miss your targets. You don't need to berate yourself when you fail to act exactly as you wish to act. Acting as you wish doesn't happen for free, it only happens after tweaking the environment and training your brain. You're still a monkey!</p><p>Don't berate the monkey. <i>Help</i> it, whenever you can. It wants the same things you want \u2014 it's you. Assist, don't badger. Figure out how to make it easy to act as you wish. Retrain the monkey. Experiment. Try things.</p><p>And be kind to it. It's trying pretty hard. The monkey doesn't know exactly how to get what it wants yet, because it's embedded in a really big complicated world and it doesn't get to see most of it, and because a lot of what it does is due to a dozen different levels of subconscious cause-response patterns that it has very little control over. It's <i>trying</i>.</p><p>Don't berate the monkey just because it stumbles. <a href=\"http://mindingourway.com/caring-about-some/\">We didn't exactly pick the easiest of paths</a>. We didn't exactly set our sights low. <a href=\"http://mindingourway.com/altruistic-motivations/\">The things we're trying to do are hard</a>. So when the monkey runs into an obstacle and falls, help it to its feet. Help it practice, or help it train, or help it execute the next clever plan on your list of ways to overcome the obstacles before you.</p><p>One day, we may gain more control over our minds. One day, we may be able to choose our cognitive patterns at will, and effortlessly act as we wish. One day, we may become more like the creatures that many wish they were, the imaginary creatures with complete dominion over their own minds many rate themselves against.</p><p>But we aren't there yet. We're not gods. We're still monkeys.</p>", "user": {"username": "So8res"}}, {"_id": "r4ewWDs4pqBSzEGBQ", "title": "Be a new homunculus", "postedAt": "2015-07-26T05:00:00.000Z", "htmlBody": "<p>Here's a mental technique that I find useful for addressing many dour feelings, guilt among them:</p><p>When you're feeling guilty, it is sometimes helpful to close your eyes for a moment, re-open them, and pretend that you're a new homunculus.</p><p>A \"homunculus\" is a tiny representation of a human, and one classic fallacy when reasoning about how brains work is the <a href=\"https://en.wikipedia.org/wiki/Homunculus_argument\">homunculus fallacy</a>, in which people imagine that \"they\" are a little homonculus inside their head looking at an image generated by their eyes.</p><p>It's an easy fiction to buy into, that you're a little person in your head that can move your hands and shape your mouth and that decides where to steer the body and so on. There is, of course, no homunculus inside your head (for if <i>you</i> are steered by a homunculus, then how is the homunculus steered?), but it can be quite fun to pretend that you are a homunculus sometimes, mostly because this allows you to occasionally pretend you're a <i>new</i> homunculus, fresh off the factory lines, and newly installed into this particular person.</p><p>Close your eyes, and pretend you're arriving in this body for the very first time. Open them and do some <a href=\"http://lesswrong.com/lw/k7/original_seeing/\">original seeing</a> on this person you now are. Rub your hands together, look around, and take stock of your surroundings. Do some internal checks to figure out what this body values, to figure out what it is you're fighting for. Check the catalog of plans and upcoming actions. Check the backlog of memories and obligations.</p><p>There will probably be some housecleaning to do: homunculi are known to get a little careless as they age, and the old homunculus that you replaced probably let a bunch of useless tasks accumulate without realizing it. As a new homunculus you have the privilege of pruning the things that obviously need pruning. Maybe you'll look and say \"Ah, yes, we're going to cancel lunch with <i>that</i> person; this body was secretly dreading it. I also see that this body is currently spending a lot of cycles feeling guilty about a date that went poorly last week; we can dismiss that, it's no longer useful for <i>this</i> homunculus. And also, \"exercise\" doesn't seem to be on today's schedule at all! How strange. This body definitely intended to exercise today; somehow it fell off the list. I'll put it back on.\"</p><p>It can be quite liberating to be a new homunculus, without any obligation to propagate the errors of the old one.</p><hr><p>This is, in fact, a common technique for dealing with the sunk cost fallacy (also known as the \"pretend you're a teleporting alien that just teleported into your body\" technique). This is useful for avoiding sunk costs because the <i>new</i> homunculus has no reason to honor the old homunculus' sunk costs.</p><p>Say the old homunculus bought plane tickets which would let you travel to Texas tomorrow (and return in a week), and that the ticket is non-refundable. The old homunculus may well have an attachment to the \"go to Texas\" plan, and may try to convince themselves to go even when it becomes clear that the trip won't be worth the time. The new homunculus, however, has no such loyalty to the sunk costs: <i>it</i> can just evaluate whether or not to go on the trip regardless of how much the tickets costed.</p><p>This is also a technique that works quite well for managing guilt: it's often easy for the new homunculus to recognize lingering guilt as a bodily response marking malcontent about something that was done in the past, by the old homunculus. The best action for the new homunculus to take, usually, is to check what regretted action caused the guilt, check what pattern of behavior led to the regretted action, mark down a note about which cognitive pattern <a href=\"http://mindingourway.com/dont-steer-with-guilt/\">needs to be reprogrammed</a>, and then dismiss the guilt (which has now served its purpose).</p><p>As a matter of fact, guilt and sunk cost fallacy are closely related: both are about suffering for costs that were paid in the past. The only difference is that guilt carries with it a lesson, an instruction to alter your environment and your mind so that similar actions don't occur in the future. With practice, it is possible to <i>reflexively</i> <a href=\"http://mindingourway.com/update-from-the-suckerpunch/\">treat the initial gut-wrenching guilt as an instruction to update your behavioral patterns, and then dismiss the lingering guilt immediately</a>. (Cognitive patterns, after all, take some time to train.)</p><p>In the interim I suggest pretending you're a new homunculus. If you start to feel guilt, then close your eyes and re-open them as a brand new homunculus. Notice the guilt, listen to the message it bears, and <i>actually write down</i> the behavioral pattern that you wish to change. Then spend five minutes (a full five minutes, by the clock) brainstorming ways that you might change the pattern and start retraining your mind. Then thank the guilt for carrying you this message, and dismiss it.</p><p>Eventually, this can become reflexive. Until then, I suggest occasionally becoming a new homunculus. In fact, I often use something like this myself, even though I've been immune to guilt for quite some time: it's a great way to see the world and yourself with fresh eyes, and that can be invaluable.</p>", "user": {"username": "So8res"}}, {"_id": "S3wAtMJ7kXxLLzyJc", "title": "Update from the suckerpunch", "postedAt": "2015-07-19T05:00:00.000Z", "htmlBody": "<p>The most common objection I hear when helping people remove their guilt is something along the lines of \"Hey wait! I was using that!\"</p><p>Believing this (or really any variant of \"but guilt is good for me!\") makes it fairly hard to replace guilt with something more productive.</p><p>I've met some people who complain that if they didn't have guilt then they'd do horrible things. I think this is fairly unlikely, and I file it right next to the arguments that say that if they didn't believe in God then they'd do horrible things. <a href=\"http://mindingourway.com/not-because-you-should/\">Even after dropping your obligations, you will still have something to fight for</a>. Your <i>reasons</i> for not doing things you'd rather not do will remain even after the guilt is replaced.</p><p>Others I have met protest that guilt is useful in order to ensure that they won't repeat their failures. Without guilt, how would they learn their lesson? To which I generally say, that's fine, but <a href=\"http://mindingourway.com/dont-steer-with-guilt/\">if it keeps happening then you aren't learning, and it's time to use a different tool instead</a>.</p><p>That said, there <i>are</i> lessons that need learning, and there <i>is</i> something sort of like 'guilt' that can help you learn them.</p><p>But you can use it even while completely replacing your guilt motivation.</p><p>Once upon a time, I had a loose date planned with a girlfriend. She was going to drop by around 21:00 to hang out. I had something else planned at 19:00 that I didn't expect to take too long; it ended up taking many hours longer than expected. There was no particularly convenient point along the way to step out and call my girlfriend and tell her I'd be late\u2026 so I didn't. I simply got home at 23:00 at night, opened the door, and saw my girlfriend sitting worried on the bed.</p><p>There's a very distinct type of feeling that I experienced, there, which you might call \"guilt.\" Seeing her sitting there on the bed, I suddenly remembered that the anxiety and dejection that she went through was far worse than the slight awkwardness I would have incurred to call her. A compartmentalization in my head broke down, and the part of me that had <i>known</i> she'd been feeling terrible suddenly came into mental focus. My error became obvious. The feeling was something like being punched in the gut.</p><p>Afterwards, I <i>also</i> had the opportunity to feel a lingering sense of regret for days.</p><p>When I suggest removing guilt, I suggest removing the latter \u2014 but not the former. The former is quite useful.</p><p>If you worry that, by removing guilt, you will lose your ability to update when you mess up, then I say: update on the suckerpunch. Trust me, it's strong enough. Update <i>immediately</i> when you realize where you failed, and use the terrible feeling to make sure you <i>don't do that again.</i></p><p>Update fully on the suckerpunch, and there will be no need for that lingering regret. Skip to the end, immediately; update as far as you can, the moment that you realize your error. Moping for days doesn't make things better. Updating your behavior does.</p><hr><p>There are those who still protest that the lingering regret is useful: if you hurt your friend, you may think that they need to see you spending days filled with regret, or otherwise they will think less of you. You may think that others find it disconcerting to see you update immediately and continue without missing a beat. Some people want to see penance done.</p><p>If that is your protest, then I have little to offer you. I can only note that I have seen many groups of friends form a tacit pact of non-excellence, where each individual in the group is reluctant to outperform the others, in fear that high performance will be punished with ostracization. Many have condemned themselves to a life of dissatisfaction thanks to a non-excellence pact. I say: better to inspire your friends than validate their mediocrity.</p><p>It can give some people whiplash, to see you update quickly, but I much prefer friends and lovers that encourage skipping to the end rather than those who feel a need to extract their pound of flesh whenever you err. For me, the social cost of updating quickly is well worth the ability to move faster. Your experience, of course, may differ.</p><p>Just remember that you won't be able to replace guilt-based motivation before giving yourself permission to do so. For so long as you view your guilt as an aid rather than a burden, for so long as you view it as right and necessary, I cannot help you remove it.</p><p>But I can tell you this:</p><p>Almost all emotions, I have found a place for. I have long looked upon Spock and Jedi with some dissatisfaction: I am not one to advocate suppressing emotion. Anger has its place and time, as does joy, as does sadness. Awe and fear and cold resolve, I have found a use for.</p><p>I have even found a use for that suckerpunch that occurs when you learn you have made a mistake, that you might label 'guilt.'</p><p>But the lingering, drawn-out guilt, the persistent regret that drives one to work in fear of it?</p><p>I have never once found a use for that.</p>", "user": {"username": "So8res"}}, {"_id": "g8aMEan8TExskdXcW", "title": "Don't steer with guilt", "postedAt": "2015-07-13T06:47:02.174Z", "htmlBody": "<p>I've spoken at length about shifting guilt or dispelling guilt. What I haven't talked about, yet, is guilt itself.</p><p>So let's talk about guilt.</p><p>Guilt is one of those strange tools that works by <i>not</i> occurring. You place guilt on the branches of possibility that you don't want to happen, and then, if all goes well, those futures don't occur. Guilt is supposed to steer the future towards non-guilty futures; it's never supposed to be instantiated in reality.</p><p>Guilt works by the same mechanism as threats: imagine the tribesperson who precommits to breaking the legs of anyone who steals their food. If this precommitment works, then it never needs to be carried out: violence is a dangerous business, and the tribesperson would much rather that they never need to break legs at all. The threat is something that the tribesperson places on possibilities that they disprefer, in attempts to ensure that they never come to be.</p><p>Imagine, by contrast, the tribesperson who threatens to breaking the legs of anyone who looks at them funny: they might find themselves attempting violence every single day, and this likely makes their life unpleasant, to say the least. In this case, I would argue that they're using their threats poorly. I would say that, if you keep finding yourself carrying out a threat, then you really need to consider whether or not your threats are really capable of steering the future in the way you hoped.</p><p>Guilt is the same way: <i>if you find yourself regularly experiencing guilt, then you're using guilt incorrectly.</i></p><p>Guilt works only when you wield it in such a way that it <i>doesn't happen.</i></p><p>Guilt is costly when deployed. Once activated, it's usually strongly demotivating, and can easily lead to failure spirals or vicious cycles of depression.</p><p>As far as I can tell, the way that guilt-motivated people tend to operate is by working fervently in attempts to avoid the scourge of guilt. This may be effective when it works, but as soon as it starts to fail, the failure often cascades into a full-blown failure spiral (you're guilty that you're not working, which makes you feel bad, which makes it hard to work, which makes you guiltier, which you feel worse, which makes it harder to work, \u2026). As a result, guilt motivation often results in a boom/bust productivity/depression cycle that, as far as I can tell, results in people feeling quite bad about themselves and being much less effective than they would be if they could maintain a steady pace.</p><p>Some might argue that the boom is worth the bust, that the productivity is worth the depression. This seems straight up false to me (<a href=\"http://mindingourway.com/the-mechanics-of-my-recent-productivity/\">and I have some relevant experience</a>): the frantic productivity fueled by fear of guilt doesn't seem more effective (and often seems <i>less</i> effective) than intrinsically motivated productivity, and that's <i>before</i> we count the losses from periodic failure spirals. As far as I can tell, intrinsic motivation is just straight up more effective.</p><p>(This is something you have to accept before I can help you remove your guilt: it's much harder to remove guilt if you don't want to.)</p><hr><p>Guilt is very costly when activated, so if it's getting activated regularly, then you're placing it on the wrong branches of possibility.</p><p>You might protest, \"but then what do I <i>do</i> in the unsatisfying branches of reality? I need to find <i>some</i> way to prevent me from chasing short-term satisfaction at the expense of long-term benefits.\" If you regularly finding yourself binging netflix TV shows, and you would rather not find yourself regularly binging netflix TV shows, then shouldn't you feel guilty whenever you do?</p><p>No! If the situation occurs regularly, then guilt is not the tool to use! You're welcome to feel guilty if you ever kidnap a baby or punch a homeless person, and you can tell that the guilt is working in those cases because you <i>never do those things</i>. But if you repeatedly find yourself in a situation that you disprefer, then guilt is just not the tool to use. That's not where it's useful.</p><p>If you want to figure out how to avoid a certain recurring situation, then there's a different tool that <i>is</i> appropriate, that's much more effective at figuring out how to steer the future towards better places: Science!</p><p>When you find yourself binging netflix, don't heap loads of guilt on yourself post-binge. That sort of thing clearly doesn't prevent the binge. Instead, say to yourself, \"huh, I appear to netflix-binge under certain conditions, despite the fact that I'd rather not. I wonder which conditions, specifically, led to that binge! What were the triggers? How could they have been avoided? What methods might help me avoid binging in the future?\"</p><p>And then treat it like an experiment! Write up your hypotheses. Experiment with many different ways to fix your glitches. Write postmortems when you fail. If you attempt a fix and then find yourself binging <i>again</i>, then don't heap loads of guilt on yourself! <i>That still doesn't help.</i> Instead, say \"Aha! So <i>that</i> attempted fix didn't work. I wonder if I can figure out why?\" Cross a hypothesis or two off your list. Refine your models. Expand your hypothesis space. Gather more data.</p><p>Do science to it.</p><p>Don't bemoan individual failures. <a href=\"http://mindingourway.com/rest-in-motion/\">That's finite-task thinking</a>. Instead, acknowledge that there's an unlimited number of changes you'd like to make to your behavior, and that some of them are more important than others, and that some of them are more costly than others, and that they all take time to fix. See the infinite stream of self-improvement that lies before you, add it to all the other streams you're optimizing, and then simply navigate the streams as quickly as you are able.</p><p>Don't feel terrible whenever you do something you wish you hadn't! That is a poor mechanism by which to steer the future. Instead, when you do something you wish you hadn't, identify the <i>pattern of behavior</i> that led to this, and add addressing <i>that</i> to your todo list. Then weigh the time you're losing against the time it would take to change the pattern, and weigh that against the other priorities that are vying for your attention, and then do what needs doing.</p><p>Sometimes you'll ignore a pattern of failure. Maybe the failures are relatively cheap and the pattern is hard to change, and fixing the pattern simply isn't worth your attention. In this case, when the failure occurs, there is no need to feel guilty: the failures are the price you pay for time spent not fixing them. You can't simply teleport to a new pattern of behavior, and so if you lack the time to change the pattern, then the occasional failure is a fair price. Trust yourself to fix the pattern if the costs ever get too high, trust yourself to understand that investing in yourself is important, and if fixing the pattern <i>still</i> isn't at the top of your todo list, then don't worry about the individual failures. You have bigger things on your plate.</p><p>Other times, you'll decide that the pattern needs changing. Five minutes per day is thirty hours per year, and investing in yourself pays dividends. In this case, treat addressing the pattern of failure like a science project. Every new individual failure is data point about what doesn't work. Every avoided failure is a data point about what does. Heaping guilt on yourself whenever you hit a new failure would be nonsense \u2014 fixing the <i>pattern</i> is a science experiment, and individual successes or failures are your data points.</p><p>Most people use their individual failures as a signal to themselves that it's time to feel terrible. It is much more effective, I think, to use your individual failures as a chance to update your tactics.</p><p>This, in my experience, is the head-on cure for guilt: Don't treat the individual failures like a burden; treat changing the pattern like a science experiment.</p>", "user": {"username": "So8res"}}, {"_id": "Ybapay39nm2CtwqJv", "title": "Charity Science Updates", "postedAt": "2015-08-17T00:11:32.288Z", "htmlBody": "<html><body><p><span>At Charity Science we recently updated the look and content of our website. If you&#x2019;re interested, you can see the new site </span><a href=\"http://www.charityscience.com/\"><span>here</span></a><span>. The main content changes were the addition of a </span><a href=\"http://www.charityscience.com/outreach-research.html\"><span>page</span></a><span> with links to 23 shallow reviews into different fundraising methods and an </span><a href=\"http://www.charityscience.com/organizational-breakdown.html\"><span>overview</span></a><span> of Charity Science&#x2019;s past work, key values and plans for the coming months. </span></p>\n<h1><span>Shallow Reviews</span></h1>\n<p>&#xA0;</p>\n<p><span>These shallow reviews are about 100 pages in total, and are intended to be understandable to someone with no previous knowledge in the area. Reports vary somewhat in quality and style because they were written by many different staff and volunteers. However, all of them were based on the same </span><a href=\"http://www.charityscience.com/operations-details/fundraising-report\"><span>questions</span></a><span> </span><span>and</span><span> </span><a href=\"https://docs.google.com/spreadsheets/d/1MBpwl3W3C0592T7HGhDAkphjo0UPMwpgg68dfQ8FzS0/edit#gid=0\"><span>evaluation rubric</span></a><span>. </span></p>\n<p>&#xA0;</p>\n<p><span>Plans</span></p>\n<p>&#xA0;</p>\n<p><span>As for our plans, over the next few months Charity Science will experiment with </span><a href=\"http://www.charityscience.com/uploads/1/0/7/2/10726656/legacy_fundraising_pdf.pdf\"><span>legacy fundraising</span></a><span>, </span><a href=\"http://www.charityscience.com/uploads/1/0/7/2/10726656/niche_marketing_pdf.pdf\"><span>niche marketing</span></a><span> and </span><a href=\"http://www.charityscience.com/uploads/1/0/7/2/10726656/online_advertising_pdf.pdf\"><span>online advertising</span></a><span>. We appreciate feedback on the experiment plans for these areas, which are available </span><a href=\"http://www.charityscience.com/outreach-research.html\"><span>here</span></a><span>. Also, we strongly encourage anyone who is wanting to help out with these experiments to contact us. Programmers, skeptics and financiers would be especially valuable to fine tune the niche marketing experiment plan. If you feel that you can help please email </span><a href=\"mailto:katherinexsavoie@gmail.com\"><span>katherinexsavoie@gmail.com</span></a><span>.</span></p>\n<p>&#xA0;</p>\n<p><span>Legacy Fundraising</span></p>\n<p>&#xA0;</p>\n<p><span>Regarding the legacy fundraising experiment, a core part of this will be to create a will-writing guide that encourages people to leave money to top charities. Thus far we feel that the best forms for this are a downloadable PDF document or an interactive web application. Examples of these two styles can be found </span><a href=\"http://www.publiclegaled.bc.ca/wp-content/uploads/2014/04/Writing-your-Will-2014-online.pdf\"><span>here</span></a><span> and </span><a href=\"http://www.peta.org/donate/planned-giving/estate-planning/ppbuild-gift/\"><span>here</span></a><span>. </span></p>\n<p><span><br></span></p>\n<p><span>We would appreciate hearing what type of will writing guide you think would be better. We will likely create both but your opinion will help us decide how to allocate our time between them. We&#x2019;ll be sure to seek more community feedback as we create this guide. Ideas about the best ways we can promote it and how likely EAs would be to use it would also be helpful in informing our approach to the legacy fundraising experiment. </span></p>\n<p><span><br></span></p>\n<p><span>We&#x2019;re Hiring</span></p>\n<p><span>Lastly, Charity Science is in the process of expansion and is looking to make a number of </span><a href=\"http://www.charityscience.com/Charity-Science-Internship.html\"><span>interns</span></a><span> over the next few months. </span><span>All interns will receive mentoring by senior staff and the opportunity to join the team in Vancouver. The work involved will likely be quite diverse in nature and will vary considerable depending on the individual&#x2019;s strengths. Some areas where work will be available include, but are not limited to, research, operations, development and communications. </span><span>If you&#x2019;re interested, </span><span>please send your questions or resume and cover letter</span><span> </span><span>to joey@charityscience.com. We ask that </span><span>applicants be willing to commit at least 70 hours of their time to the internship</span><span>.</span></p></body></html>", "user": {"username": "Joey"}}, {"_id": "CAoEMopMv3EMNiKKC", "title": "My Cause Selection: Dave Denkenberger", "postedAt": "2015-08-16T15:06:25.456Z", "htmlBody": "<html><body><p>&#xA0;</p>\n<p>I made a very rough spreadsheet that estimates the expected impact of work on different causes for screening purposes. For the risks, it was based on expected damage, amount of work that has been done so far, and a functional form for marginal impact. I did it from several perspectives, including conventional economic (with discounting future human utility), positive utilitarian (maximizing net utility and not discounting), and biodiversity. Note that the pure negative utilitarian of reducing aggregate suffering may prefer human extinction (I don&apos;t subscribe to this viewpoint). I believe that the future will generally be net beneficial.&#xA0;</p>\n<p>Of course there has been a lot of talk recently that if one values future generations not negligibly, reducing global catastrophic risk is of overwhelming importance. But I have not seen the point that even if you do discount future generations exponentially, there could still be an overwhelming number of discounted consciousnesses if you give a non-negligible probability of computer consciousnesses this century. This is reasonable because an efficient computer consciousness would use much less energy than a typical human. Furthermore, it would not take very long to construct a traditional Dyson sphere, which is independent satellites orbiting the sun that absorb most of the sun&apos;s output. The satellites would be ~micron thick solar cells plus CPUs, and would require a small fraction of the matter in the solar system. Note that this means that even if one thinks that artificial general intelligence will be friendly, it is still of overwhelming importance to reduce the risk of not reaching the computer consciousnesses, which could just mean global catastrophic risk and technological civilization not <a href=\"http://blog.givewell.org/2015/08/13/the-long-term-significance-of-reducing-global-catastrophic-risks/\">recovering</a>.&#xA0;I am open to arguments about far future trajectory changes other than global catastrophic risks, but I think they need to be developed further. This also includes potential mass animal suffering associated with galactic colonization or simulation of worlds.</p>\n<p>Looking across these global catastrophic risks, I find the most promising are artificial intelligence alignment, molecular manufacturing, high-energy physics experiments, 100% kill engineered pandemic, global totalitarianism, and alternate foods as solutions to global agricultural disruption. Some of these are familiar, so I will focus on the less familiar ones.</p>\n<p>Though many regard high-energy physics experiments as safe, a risk of one in ~1 billion per year of turning the earth into a strangelet or black hole or destroying the entire visible universe is still very bad. And the risk could be higher because of <a href=\"https://www.academia.edu/4527972/Probing_the_Improbable_Methodological_Challenges_for_Risks_with_Low_Probabilities_and_High_Stakes\">model error</a>. The net benefit excluding the risk of these experiments considering all the costs I believe is quite low, so I personally think they should be banned.</p>\n<p>Local totalitarianism like in North Korea eventually gets outcompeted. However, global totalitarianism would have no competition, and could last indefinitely. This would be bad for the people living under it, but it could also stifle future potential like galaxy colonization and artificial general intelligence. I am less familiar with the interventions to prevent this.</p>\n<p>Global agricultural disruption could occur from risks like nuclear winter, asteroid/comet impact, super volcanic eruption, abrupt climate change, or agroterrorism. Though many of these risks have been studied significantly, there is a new class of interventions called alternate foods that do not rely on the sun (disclosure: I came up with them as catastrophic solutions). Examples include growing mushrooms on dead trees and growing edible bacteria on <a href=\"https://drive.google.com/viewerng/viewer?a=v&amp;pid=sites&amp;srcid=ZGVmYXVsdGRvbWFpbnxkYXZpZGRlbmtlbmJlcmdlcnxneDo1MTg1ZDQ4NGI1MDMxN2Q0\">natural gas</a>. I have done some modeling of the cost effectiveness of alternate food interventions, including planning, research, and development. This will hopefully be published soon, and it indicates that expected lives in the present generation can be saved at significantly lower cost than typical global poverty interventions. Furthermore, alternate foods would reduce the chance of civilization collapse, and therefore the chance that civilization does not recover.</p>\n<p>There was earlier discussion on what might constitute a fifth area within effective altruism of effective environmentalism. I would propose that this would not be regulating pollution to save lives in developed countries at $5 million apiece. However, there are frameworks that value biodiversity highly. One could argue that we will eventually be able to reconstruct extinct species or put organisms in zoos to prevent extinction. But the safer route is to keep the species alive in the wild. In an agricultural catastrophe, not only would many species go extinct without human intervention, but desperate humans would actively eat many species to extinction. Therefore, I have estimated that the most cost-effective way of saving species is furthering alternate foods.</p>\n<p>Overall, there are several promising causes, but I think the most promising is alternate foods. This is because it is competitive with other global catastrophic risk causes, but it has the further benefit of being more cost-effective at saving lives in the present generation than global poverty interventions, and more cost-effective at saving species than conventional interventions like buying rainforest land. I am working on a mechanism to allow people to support this cause.</p>\n<p>Edit: <a href=\"http://link.springer.com/article/10.1007/s13753-016-0097-2\">here </a>is the cost per life saved paper now that it is published.</p>\n<p>&#xA0;</p></body></html>", "user": {"username": "Denkenberger"}}, {"_id": "7Rn5HyvbHPJawapaR", "title": "EA Blogging Carnival: My Cause Selection", "postedAt": "2015-08-16T01:07:22.005Z", "htmlBody": "<html><body><p>Recently I have talked to a few people about the importance of publicly discussing cause selection, and we agreed that we generally don&apos;t do it enough. So I&apos;ve decided to host September&apos;s EA blogging carnival with the topic &quot;My Cause Selection.&quot; Write a post (on the EA forum or on your own blog) explaining which cause you currently believe is best and why. If you&apos;re confused about which is best (I know I am), explain the strengths and weaknesses of the causes you think might be the best. If you want, discuss your thinking on other causes that you think are promising, or that are popular in EA but you don&apos;t think are promising. You should write in sufficient detail that readers have a good understanding of why you support the cause(s) you do.</p>\n<p>If you post on the EA forum, please use the title &quot;My Cause Selection: &lt;Your name or username&gt;&quot;, and tag your post with &quot;my-cause-selection&quot;. If you post outside the EA forum, please write a comment here with a link to your post.</p>\n<p>You can structure your post however you like, but if you want an idea of what you could do, this is how I&apos;m structuring mine. I explain what I value and some general considerations, and then list out every major cause area I think is plausibly the best (which includes malaria nets, deworming, animal advocacy, research on animal advocacy, AI safety, and a few others). I explain what I see as the strengths and weaknesses of each cause area and then weigh them against each other.</p>\n<p>It&apos;s not September yet, but this is a big topic, so we could use the  extra couple of weeks. Feel free to publish before September starts. Happy blogging!</p></body></html>", "user": {"username": "MichaelDickens"}}, {"_id": "u2aazYxA5eMyfM33Z", "title": "How much does work in AI safety help the world?", "postedAt": "2015-08-14T22:32:08.188Z", "htmlBody": "<html><body><p>Using a method of Owen&apos;s, we made an interactive tool to estimate the probability that joining the AI safety research community would actually avert existential catastrophe.<a></a></p>\n<p>Though I&apos;m posting this and it&apos;s written from my point of view, most of the writing and reasoning here is Owen&apos;s -- I&apos;ll take the blame for any misunderstandings or mis-statements of his argument :)</p>\n<p>There&#x2019;s been some discussion lately about <a href=\"http://www.vox.com/2015/8/10/9124145/effective-altruism-global-ai\">whether we can make estimates of how likely efforts to mitigate existential risk from AI are to succeed</a> and about <a href=\"http://slatestarcodex.com/2015/08/12/stop-adding-zeroes/\">what reasonable estimates of that probability might be</a>. In a recent conversation between the two of us, I mentioned to Owen that I didn&apos;t have a good way to estimate the probability that joining the AI safety research community would actually avert existential catastrophe. Though it would be hard to be certain about this probability, it would be nice to have a principled back-of-the-envelope method for approximating it. Owen actually has a rough method based on the one he used in his article <a href=\"http://www.fhi.ox.ac.uk/Allocating-risk-mitigation.pdf\">Allocating risk mitigation across time</a>, but he never spelled it out.</p>\n<p>We thought that this would be best presented interactively; since the EA Forum doesn&apos;t allow JavaScript in posts, we put the tool on the Global Priorities Project website.</p>\n<p><a href=\"http://globalprioritiesproject.org/2015/08/quantifyingaisafety/\"><strong>You can use the tool here to make your own estimate!</strong></a></p>\n<p>(Assuming that you&apos;ve gone to the site and made your own estimate...)</p>\n<p>So, what does this mean? Obviously this is quite a crude method, and some of the variables you have to estimate are themselves quite tricky to get a handle on, but we think they&#x2019;re more approachable than trying to estimate the whole thing directly, and expect the answer to be within a few orders of magnitude of correct.</p>\n<p>How big does the number have to be to imply that a career in AI safety research is one of the best things to do? One natural answer is to multiply out by the number of lives we expect we could get in the future. I think this is understandable, and worth doing as a check to see if the whole thing is dominated by focusing on the present, but it&#x2019;s not the end of the story. There are fewer than 10 billion people alive today, and collectively it seems like we may have a large amount of influence over the future. Therefore if your estimate for the likelihood of a career in AI safety looks much worse than a 1 in 10 billion chance, it seems likely that there are other more promising ways to productively use your share of that influence. These might eventually help by influencing AI safety in another way, or through a totally different mechanism. The method we&#x2019;ve used here could also be modified to estimate the value of joining communities working on other existential risks, or perhaps other interventions that change the eventual size or productivity of the AI research community, for example through outreach, funding, or <a href=\"http://www.fhi.ox.ac.uk/the-timing-of-labour-aimed-at-reducing-existential-risk/\">field-steering work</a>.</p></body></html>", "user": {"username": "Daniel_Dewey"}}, {"_id": "5FPhSTdHeYehisAuo", "title": "[Housekeeping Notice] The 'meetups' sidebar is temporarily broken", "postedAt": "2015-08-14T22:21:05.819Z", "htmlBody": "<html><body><p>Hi all,</p>\n<p>You may or may not have noticed that the &apos;meetups&apos; feature on the Forum (accessible under &apos;Nearest meetups&apos; in the sidebar) is a little broken. Meetups are sometimes repeated anywhere from two to twelve times; sadly this doesn&apos;t reflect the oft-anticipated explosion in EA activity, but rather a problem with the Forum code. We&apos;re still tracking the precise problem down, but the repeated meetups are due to people submitting them multiple times, as there&apos;s currently no acknowledgement that a meetup was successfully posted on submission. There&apos;s no need to submit multiple times; doing so once works. Except that another problem is that clicking on meetup titles currently takes you to an error page, rather than to the page full of details it used to.</p>\n<p>We&apos;re sorry for the problems and the delay in fixing them. This is partly due to working with the codebase being as difficult as explaining the risk posed by AI to your granny. (This isn&apos;t wholly surprising as we[/Forum creator Ryan Carey] inherited it from LessWrong, who forked it from Reddit, and even many of the original developers don&apos;t fully understand it.) But I&apos;m sure it&apos;s also partly due to errors on our part, which we&apos;ll find when we track down what&apos;s going on.&#xA0;</p>\n<p>Of course, if anyone would like to help out with this or other valuable EA coding projects then we&apos;d love to hear from you. There are some great members of the community working on this (like Alex Richard, Joshua David, Patrick Brinich-Langlois, and Peter Hurford, who helps to coordinate the tech work). But we&apos;re still particularly short of people who can make a reliable commitment to do volunteer programming. The Forum is written in Python and though I have to concede that it&apos;s tricky to work with in some respects I&apos;d encourage people to get in touch with <a href=\"mailto:ozzieagooen@gmail.com\">Ozzie Gooen</a>&#xA0;whatever your skills. If it would make a difference we can sometimes offer small stipends to help cover time spent on EA projects.</p>\n<p>Some of you may also be interested in <a href=\"https://github.com/tog22/eaforum/issues/6\">following (or helping out with)</a> a related project: getting as many EA events as possible that have been posted around the web (for example as Facebook group events) into an RSS feed and thence publishing it on places like the Forum.</p>\n<p>Tom<br>(On behalf of the various community members helping Ryan out with the Forum)</p></body></html>", "user": {"username": "Tom_Ash"}}, {"_id": "Hr5bQLH22wdAvFA7D", "title": "The long-term significance of reducing global catastrophic risks [link]", "postedAt": "2015-08-13T22:38:23.903Z", "htmlBody": "<html><body><p><span>Nick Beckstead lays down the arguments for thinking about extinction risks and non-extinction risks at the same time, with the possible exception of the case of AI, at the&#xA0;<a href=\"http://blog.givewell.org/2015/08/13/the-long-term-significance-of-reducing-global-catastrophic-risks/\">GiveWell blog</a>.</span></p></body></html>", "user": {"username": "RyanCarey"}}, {"_id": "ti6Z6NKYzowfGbheh", "title": "EA introduction course and YouTube playlists", "postedAt": "2015-08-13T12:50:09.081Z", "htmlBody": "<html><body><p>Hi guys!<br><br>We are getting ready to accept new student members to our workgroups at EA NTNU this fall, and we want to make a course program for our new members to get them up to speed on central ideas, organisations and concepts within EA. The idea is to meet once a week for three weeks, discussing and working on central topics for about two hours. We are planning to make YouTube playlists introducing the ideas, and that the new members will watch these playlists before each gathering (as well as reading essays in the EA Handbook). We have spent some time brainstorming ideas on central topics to include in the course, but it would be nice to get a feel for what other people view as important to counter any group thinking we might have.<br><br>These are the topics we have thought about (rot13):<br><br>* RN uvfgbel naq vagreangvbany bireivrj<br>* Engvbanyvgl (Pbzzba guvaxvat reebef, fgngvfgvpny naq rpbabzl pbaprcgf, naq ybtvpny snyynpvrf)&#xA0;<br>* Pnerre gvcf (80x)&#xA0;<br>* Tybony cbiregl naq rinyhngvba (TJ naq gurve erpbzzraqrq betf)&#xA0;<br>* Rkvfgragvny evfx&#xA0;<br>* Navzny jrysner&#xA0;<br>* Zrgn-RN (inyhrq pevgvpvfz, tebjgu fgengrtl naq pbzzba zvfpbaprcgvbaf)</p>\n<p>For the long run, we are thinking of expanding the YouTube playlists idea to include deeper introductions to more complex ideas, discussions and concepts &#xA0;(Think Vsauce leanbacks, if you have heard of them), to make our YouTube channel a HQ for people to explore ideas we care about. The videos we currently have range from very EA related (<a href=\"https://www.youtube.com/watch?v=XCirRv-IaGE\">like this one</a>) to more general (<a href=\"https://www.youtube.com/watch?v=vKA4w2O61Xo\">like this one</a>).<br>If you have examples of good videos we might have overlooked they are much appreciated!</p>\n<p>tl;dr:&#xA0;<br>1) What concepts, ideas and organisations are essential to introduce to members who are new to EA?<br>2) Have you come across good online content (articles and videos, preferably on YouTube) explaining central EA concepts, ideas or organisations.&#xA0;</p></body></html>", "user": {"username": "Jorgen_Ljones"}}, {"_id": "MJjWntfSNiP5W4KDB", "title": "Introducing Rebecca Raible, a new moderator", "postedAt": "2015-08-13T12:42:11.012Z", "htmlBody": "<html><body><p><span>Hi,</span></p>\n<p><span><br></span></p>\n<p><span>As you may know, I&#x2019;ve been doing the moderation role for the forum for the past few months, after Marcus finished his term. I&#x2019;ve really enjoyed having even more of an excuse to read all of the contributions and debates and watch as interest in the forum continues to grow. </span></p>\n<p><span>I&#x2019;m happy to announce that Rebecca Raible has kindly offered to join me as a moderator. This will be really helpful and should mean content gets shared more quickly on the Facebook page, which will be increasingly useful as the volume of posts keeps on building. </span></p>\n<p><span>Rebecca (rebecca_raible) studied Philosophy at Pomona College and is currently a Research Analyst at GiveWell. She first began to learn about Effective Altruism after one of her coworkers added her to the EA facebook group approximately one year ago. She&#x2019;s excited to become more involved in the community!</span></p>\n<p><span>If you think we&#x2019;ve missed anything, or notice any problems, please do get in touch by emailing contact@effective-altruism.com.</span></p>\n<p>&#xA0;</p>\n<p><span>All the best,</span></p>\n<p><span>Alison</span></p></body></html>", "user": {"username": "aliwoodman"}}, {"_id": "jLvvSLhFJTuuWsfa4", "title": "Moral Economics in Practice: Musing on Acausal Payments through Donations", "postedAt": "2015-08-12T17:41:12.855Z", "htmlBody": "<html><body><p><em>I haven&apos;t been following <a href=\"/ea/m2/moral_economics_what_why_whom_how_when_what_for/\">the moral economics posts</a> that closely, but I wanted to add a musing of my own. &#xA0;This isn&apos;t important to read. &#xA0;Summary: You can effectively pay an EA without giving them anything by donating on their behalf. &#xA0;This transfer has economic properties that tingle my brain when I think about them.</em></p>\n<p>&#xA0;</p>\n<p>Think when someone gives you a birthday present. &#xA0;Sometimes you like it and it has value to you. &#xA0;Great! &#xA0;Sometimes you don&apos;t like it and it doesn&apos;t have that much value. &#xA0;Bummer!</p>\n<p>The birthday present cost a certain amount of money for the buyer to purchase and it&apos;s worth a certain amount to you. &#xA0;Often times, the present is worth less to you than the buyer spent to purchase it, or you would have gotten it yourself. &#xA0;This is why <a href=\"https://www.amherst.edu/media/view/104699/original/christmas.pdf\">economists often bemoan the loss of value inherent in gift giving</a>. &#xA0;(Of course, this is just one type of value, and there are many non-monetary benefits to gift giving that economists might not pay much attention to!)</p>\n<p>Perfect gift giving (from an economics perspective) is when you get a present where the amount of money it cost the person to buy the present is equal to (or less than) the value you get from the present.</p>\n<p>One such example of perfect giving is if the present-giver could have also given you cash equal to the present&apos;s value and you could have bought a present you liked better yourself. &#xA0;Indeed, this is the entire idea behind gift cards -- provide more value to the person by letting them buy what they want, but not lose the social institution of gift giving by making it just a straight cash transaction. &#xA0;(Though many aunts and uncles often give a card with cash inside.)</p>\n<p>However, one could also imagine a perfect gift-giver that always gives you a gift that you would have purchased on your own (except you haven&apos;t yet). &#xA0;Since you would have definitely spent the money yourself, this gift is basically as good as cash. &#xA0;For example, while a gift card to Arby&apos;s isn&apos;t of much value to me (<a href=\"http://lesswrong.com/lw/i3s/why_eat_less_meat/\">I&apos;m a vegetarian</a> but I do like their mozzarella sticks), given the amount I spend on Amazon, a gift card to Amazon is basically as good as cash.</p>\n<p>The point is here that I can pay someone without paying them money, provided I give them something that is as good as money. &#xA0;For EAs who <a href=\"/givingwhatwecan.org\">donate a substantial portion of their income to charity</a>, this gets a bit more interesting. &#xA0;Since they would donate a certain amount of money to a certain charity, I can then pay them using this principle by (a) donating to their chosen charity myself and (b) communicating that amount to the person so they can reduce their intended donation by that amount.</p>\n<p>This is cool because the money transferred is <em>acausal</em> -- it never is sent to them, yet it ends up paying them an amount. &#xA0;This means you can transfer them money at any time, without their permission, without needing much coordination, without needing to set up a way to make payments between each other, in any country where a donation can be made, regardless of what country they are in. &#xA0;It&apos;s also a power only really available to EAs. &#xA0;...And that&apos;s kinda cool to think about.</p></body></html>", "user": {"username": "Peter_Hurford"}}, {"_id": "sY4NxytMKP45nTJ2G", "title": "Why effective altruism used to be like evidence-based medicine. But isn\u2019t anymore", "postedAt": "2015-08-12T15:13:34.927Z", "htmlBody": "<html><body><p>On August 8<sup>th</sup>, Robert Wiblin, owner of probably the most intellectually stimulating facebook wall of all time asked &#x201C;What past social movement is effective altruism most similar to?&#x201D; This is a good question and there were some interesting answers. In the end, the most liked post (well actually the second, after Kony 2012), was &#x2018;evidence-based medicine&#x2019;. I think effective altruism used to have a lot of similarities to evidence-based medicine but is increasingly moving in the opposite direction.</p>\n<p>What is it that makes them similar? Obviously a focus on evidence. &#x201C;Effective altruism is a philosophy and social movement that applies evidence and reason to determine the most effective ways to improve the world.&#x201D; (Wikipedia)</p>\n<p>The trouble is, evidence and reason aren&#x2019;t the same thing.</p>\n<p>Reason, in effective altruism seems to often be equated with maximising expected utility. It is characterised by organisations like the Future of Humanities Institute and often ends up prioritising things for which we have almost no evidence, like protection against deathbots.</p>\n<p>Evidence is very different. It&#x2019;s about ambiguity aversion, not maximising expected utility. It&apos;s a lot more modest in its aims and is characterised by organisations like Givewell, prioritising charities like AMF or SCI, for which we have a decent idea of the quantum of their effects.</p>\n<p>I place myself in the evidence camp. One of the strengths of evidence-based medicine in my view is that it realises the limits of our rationality. It realises that, actually, we are VERY bad at working out how to maximise expected utility through abstract reasoning so we should actually test stuff empirically to find out what works. It also allows consensus-building by decreasing uncertainty.</p>\n<p>I&#x2019;m not saying there isn&#x2019;t room for both. There should definitely be people in the world who think about existential risk and there should definitely be people in the world providing evidence on the effectiveness of charitable interventions. I&#x2019;m just not sure they should be the same people.</p>\n<p>There are also similarities between the two camps. They&#x2019;re both motivated by altruism and they&#x2019;re both explicitly consequentialist, or at least act like it. The trouble is, they also both claim to be doing <strong>the most good </strong>and so in a way they disagree. Maybe I shouldn&#x2019;t be worried about this. After all, healthy debate within social movements is a good thing. On the other hand, the two camps often seem to have such fundamentally different approaches to the question of how to do the most good that it is difficult to know if they can be reconciled.</p>\n<p>&#xA0;</p>\n<p>In any case, I think it can only be a good thing that this difference is explicitly recognised.</p></body></html>", "user": {"username": "JamesSnowden"}}, {"_id": "a3PDjRBu9uTkRGeBS", "title": "A response to Matthews on AI Risk", "postedAt": "2015-08-11T12:58:38.930Z", "htmlBody": "<html><body><p><span>Dylan Matthews has written <a href=\"http://www.vox.com/2015/8/4/9096899/cash-teach-fish\">lots</a> <a href=\"http://www.vox.com/2015/6/3/8723189/john-paulson-harvard-donation\">of</a> <a href=\"http://www.washingtonpost.com/news/wonkblog/wp/2013/05/31/join-wall-street-save-the-world/\">useful</a> <a href=\"http://www.vox.com/2015/4/24/8457895/givewell-open-philanthropy-charity\">exploratory</a> <a href=\"http://www.vox.com/2015/7/29/9067641/william-macaskill-effective-altruism\">material</a> about EA. Of my favourite journalistic articles about effective altruism, Matthews has written about half. So I was surprised to see that after attending the recent EA Global conference, Matthews</span><a href=\"http://www.vox.com/2015/8/10/9124145/effective-altruism-global-ai\"><span> </span><span>wrote</span></a><span> that he left worried, largely because of the treatment of AI risk, a topic that seems important to me. <span>Matthews</span>&apos;s writing, though as clear as ever, had some issues with its facts and background research that I think compromised major parts of his argument. </span></p>\n<p>&#xA0;</p>\n<p><span><span>Matthews critique of AI risk mitigation was mixed in with a wide range of his experiences and impressions from the event, but still his criticism was more substantial than most, and are</span></span><span> already gaining thousands of social media shares. His main points, it seems to me, were that AI risk reduction efforts are:</span></p>\n<ul>\n<li><span>self-serving</span></li>\n<li><span>self-defeating</span></li>\n<li><span>based on Pascal&apos;s Mugging, a riddle in expected value thinking.&#xA0;</span></li>\n</ul>\n<p><span>Let&apos;s take these in the reverse order.</span></p>\n<p><span>Conference-goers told Matthews that reducing AI risks is enormously important even if the probability of successfully mitigating those risks was arbitrarily small. Matthews reasonable identified this as an argument from </span><span>arbitrarily small probabilities of astronomical gains, known as Pascal&apos;s Mugging.&#xA0;</span><span>He attributes discussion of the idea to Bostrom, and uses it it to challenge the notion of funding an AI risk charity like MIRI. </span><span>Pascal&apos;s Mugging is an interesting and contentious issue in decision theory. </span><span>But does Matthews realise that the approach was thoroughly disendorsed by MIRI years ago? If Matthews read Bostrom&apos;s piece about Pascal&apos;s Mugging to the end, and followed Bostrom&apos;s link, he would realise that the idea was originated by MIRI&apos;s founder Eliezer Yudkowsky. In Eliezer&apos;s original piece, non-credible offers of astronomical utility were not described as things to go and do, but as an unresolved puzzle.</span></p>\n<p>&#xA0;</p>\n<p><span>Matthews says that to want to reduce existential risk, you have to distinguish between a probability of success of 10e-15 or 10e-50, and then throws his hands into the air exclaiming that surely noone could achieve such precision. This would be fine if Matthews had presented arguments that the likelihood of doing useful AI safety research was even less than one in a hundred. </span></p>\n<p><span>But Matthews&apos; reservations about AI safety efforts were only a paragraph in length, and did not have such force. First, he professed some uncertainty whether AI is possible. However, this should not seriously slim the odds of reducing AI risk. T</span><span>he median AI researcher estimates even odds of human-level <a href=\"http://aiimpacts.org/ai-timeline-surveys/\">AI between 2035 and 2050</a> so the prospect that AI is possible and achievable within decades is large enough to worry about. Second, he doubts whether intelligence is sufficient to give a computer dominion over humans. But intelligence is exactly what has always given humans dominion over animals. A superintelligent AI could covertly gain extreme financial power (as trading algorithms already do), hack hardware (as academics do) and control military devices (as drone software does) --- at least!.</span><span> Third, he asks whether artificial intelligences might function just as tools, rather than as agents. But an ultra-powerful AI tool would still permit one human to wield power over all others, a problem that would still require some combination of technical and other risk-reduction research. Fourth</span><span>, he asks how we ought to define friendliness in the context of machines. But this question that has previously been of interest to MIRI researchers, and will probably return to the fold as progress is facilitated by work on underlying mathematical problems. All up, Matthews has weakly argued for uncertainty about the impact of AI and AI safety research, but then supposes that we therefore can&apos;t tell the probability of success from 10e-15 and 10e-50. If we&apos;re the kind of people who want to quantify our uncertainty, then Matthews has presented a complete non sequitur. If we&apos;re uncertain about Matthews propositions, we ought to place our guesses somewhere closer to 50%. To do otherwise would be to mistake our deep uncertainty deep scepticism. And if the prospects are decent, then as </span><span>Rob Wiblin, a speaker at the conference, has previously explained, Pascal&apos;s Mugging is not needed:</span></p>\n<blockquote>\n<p><span>&quot;While there are legitimate question marks over whether existential risk reduction really does offer a very high expected value, and we should correct for &#x2018;regression to the mean&#x2018;, cognitive biases and so on, I don&#x2019;t think we have any reason to discard these calculations altogether. The impulse to do so seems mostly driven by a desire to avoid the weirdness of the conclusion, rather than actually having a sound reason to doubt it.</span></p>\n<p><span>A similar activity which nobody objects to on such theoretical grounds is voting, or political campaigning. Considering the difference in vote totals and the number of active campaigners, the probability that someone volunteering for a US presidential campaign will swing the outcome seems somewhere between 1 in 100,000 and 1 in 10,000,000. The US political system throws up significantly different candidates for a position with a great deal of power over global problems. If a campaigner does swing the outcome, they can therefore have a very large and positive impact on the world, at least in subjective expected value terms.</span></p>\n<p><span>While people may doubt the expected value of joining such a campaign on the grounds that the difference between the candidates isn&#x2019;t big enough, or the probability of changing the outcome too small, I have never heard anyone say that the &#x2018;low probability, high payoff&#x2019; combination means that we must dismiss it out of hand.&quot;</span></p>\n</blockquote>\n<p><span>Since there are a wide range of proposed actions for reducing risks from artificial intelligence, some more of which I will mention, it would take extensive argumentation to suggest that the probability of success for any of them was much less than swinging an election victory. So it would not seem that</span><span> there&apos;s any need </span><span>to involve riddles in decision theory to decide whether AI safety research is something worth doing.</span></p>\n<p><span>Claiming that AI risk-reduction research would be self-defeating, Matthews says: &quot;It&apos;s hard to think of ways to tackle this problem today other than doing more AI research, which itself might increase the likelihood of the very apocalypse this camp frets over&quot;. But this </span><span>sells the efforts of AI risk reducers far short. First, they are taking efforts that are political, such as ralling <a href=\"http://futureoflife.org/AI/open_letter_autonomous_weapons\">researchers</a> and <a href=\"https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/381906/14-1190b-innovation-managing-risk-evidence.pdf\">reporting</a> to politicians. Second, there are <a href=\"http://www.fhi.ox.ac.uk/research/research-areas/\">strategy</a> and <a href=\"http://aiimpacts.org/\">technological</a></span><span> </span><span><a href=\"https://intelligence.org/all-publications/\">forecasting</a>. Overall, achieving <a href=\"http://intelligence.org/files/IE-EI.pdf\">differential progress</a> of safety technology relative to raw intelligence has been the main point of the AI risk reduction progress for years. It remains a key fixture --- see <a href=\"https://www.youtube.com/watch?v=GYQrNfSmQ0M\">Russell&apos;s recent talk</a>, where he advocated promoting reverse reinforcement learning, while decreasing fine-tuning of deep neural networks. But even if Matthews disagreed with Russell&apos;s assessment, this would only disagree with one specific plan for AI risk reduction, not the validity of the enterprise altogether. There are a wide range of other approaches to safely address the safety problem, such as </span><span>rallying risk-aware researchers and politicians, and building clear strategies and timelines, that seem even more unambiguously good, and it would be odd --- to say the least --- if every one of these turned out to increase the risk of apocalypse, and that neither could any new safe courses of action be discovered.</span></p>\n<p><span>Last, Matthews argues that AI risk reduction talk could be self-serving or biased. &quot;At the risk of overgeneralizing, the computer science majors have convinced each other that the best way to save the world is to do computer science research.&quot;. He later returns to the issue: &quot;The movement has a very real demographic problem, which contributes to very real intellectual blinders of the kind that give rise to the AI obsession.&quot; The problem here is that AI risk reducers can&apos;t win. If they&apos;re not computer scientists, they&apos;re decried as uninformed non-experts, and if they do come from computer scientists, they&apos;re promoting and serving themselves. In reality, they&apos;re a healthy mixture. From MIRI, </span><span>Eliezer wanted to make AI, and has had to flip into making AI safety measures. </span><span>Bostrom, who begun as a philosopher, has ended up writing about AI because it seems not only interesting, but also like an important problem. Interestingly, where Eliezer gets criticised for his overly enthusiastic writing and warmth for science fiction, Bostrom has, in order to avoid bias, avoided it entirely. </span><span>Russell begun as an AI professor, and it was only when he took sabbatical that he realised that despite Eliezer&apos;s grating writing style, he was onto something. These stories would seem to describe efforts to overcoming bias moreso than succumbing to it.</span></p>\n<p><span>Let&apos;s take on one final argument of Matthews&apos; that also sums up the whole situation. According to Matthews, those concerned about AI risk presuppose that unborn people count equally to people alive now. To begin with, that&apos;s stronger than what Eliezer argues. Eliezer has argued that future people need only to be valuable to within some reasonable factor of present people, to be overwhelmingly important. </span><span>If our unborn children, great grandchildren and so on for a dozen generations were even 10% as important as us, then they would be more important than people currently living. If population grows in that time, or we give some moral weight to generations beyond that, or you privilege our descendants more equally to ourselves, then their value increases far beyond ours. </span><span><span><span>Even if the 8 billion people currently alive were lost to a disaster, AI or otherwise, that would be terrible. It also seems neglected, as the comparison and prioritisation of such disasters lacks an establish field in which to </span><span>receive</span><span> proper academic attention. If future generations count also, then it may be terribly worse, and the question is just how much.</span></span></span></p>\n<p><span><span><span>If Matthews just wanted to say that it&apos;s a bit awkward that people are still citing Pascal&apos;s Mugging arguments, then that would be fine. But if he was writing a piece whose main focus was his reservations about AI risk, and would widely be distributed as a critique of such, then he should have stress-tested these against the people who are working for the organisations being criticised, and who were eminently accessible to him at the recent conference. Unfortunately, it&apos;s not straightforward to undo the impact of a poorly thought-through, and shareable opinion piece. At any rate, Matthews can be one of the first to read this </span><span>counter-critique</span><span> and I&apos;m happy to correct any errors.</span></span></span></p>\n<p><span>In conclusion,&#xA0;covering AI risk is hard. </span><span>AI risk reduction efforts are a mixture of CS-experts and others, who would anyway be criticised if they were composed differently. E</span><span>ven if one gives some privilege to presently alive people above our descendants, existential risks are important, and we&apos;ve no reason to be so sceptical as to invoke Pascal&apos;s Mugging to support AI risk reduction.</span></p></body></html>", "user": {"username": "RyanCarey"}}, {"_id": "ReJT7ck9Em2xQANSz", "title": "How we can make it easier to change your mind about cause areas", "postedAt": "2015-08-11T06:21:09.211Z", "htmlBody": "<html><body><p>TL:DR- Individual cause area re-prioritization is hard and may be getting harder. &#xA0;It would be helpful to have a toolkit of techniques for making the process easier and better. &#xA0;I highly recommend most of you give $20 to a charity in every major EA cause area, and also do some other things.</p>\n<p>&#xA0;</p>\n<p>It&apos;s hard, and possibly getting harder, for an individual EA to re-prioritize between causes. There are a few simple and practical measures we can use to make the cause selection go more smoothly and effectively. &#xA0;Here are a few reasons I&apos;ve seen (or think I&apos;ve seen) a lot of evidence for recently in myself and other EAs.</p>\n<p>1) Sticking with one cause feels good/familiar, and unfamiliar other cause areas don&apos;t feel as good (maybe <a href=\"https://en.wikipedia.org/wiki/Mere-exposure_effect\">Mere-exposure effect</a> has gotten to you, or maybe you were always more comfortable with one for separate reasons).&#xA0;</p>\n<p>2) You identify with a cause area or charity, and might lose that emotional connection if you donated* elsewhere (plus&#xA0;<a href=\"https://en.wikipedia.org/wiki/Loss_aversion\">loss aversion</a>&#xA0;twice over: once for losing the particular connection, and again for losing some confidence that you can or should become attached to a given cause or charity). &#xA0;This is one I struggle with a lot. &#xA0;</p>\n<p>3) You fear you would lose status if you changed your mind, or that it would be socially difficult or costly to do so because of personal or professional relationships.</p>\n<p>4) You &quot;aren&apos;t the kind of person&quot; who donates to a certain cause area (I heard slight variations on this 5-ish times at EAG, e.g. &quot;I&apos;m not a radical EA that gives to fringe causes&quot;). &#xA0;You don&apos;t (just) identify with cause X, you identify with not-cause Y and Z. This makes me sad.</p>\n<p>5) You thought hard about this a while back, and have since cached the idea that you&apos;ve done the mental work of cause selection satisfactorily. &#xA0;You may not be aware that there were holes in your original reasoning, or that new evidence has come to light that affects your earlier conclusions.</p>\n<p>I expect all of these to grow more powerful over time. As our donation histories lengthen, we have more opportunities to identify more strongly with a certain charity or cause. More habituation takes place. Our community becomes more entrenched, and so we can expect more and stronger interpersonal relationships that make radical changes potentially costly. Reasoning that may have originally been sound is more likely to become outdated if it&apos;s not updated.</p>\n<p>It&apos;s well worth small amounts of effort to fight identity ossification of this sort early and often, if the efforts are effective. &#xA0;<a href=\"http://lesswrong.com/lw/idj/use_your_identity_carefully/\">Identities are powerful</a>, and we should actively manage them. &#xA0;I fear these processes will decrease cause selection quality. On the other hand, longer exposure to EA means greater exposure to information about other cause areas. Hopefully the second force is stronger. &#xA0;</p>\n<p>Regardless, it would be helpful to have a toolkit of measures to push back against possible trends 1-5 without hurting the positive aspects of those trends, like stronger communities and more comfort with the process of giving.</p>\n<p>What can we do about this? I&apos;m not sure, but here are a few things I&apos;ve been experimenting with.</p>\n<p>Most simply:</p>\n<p>1) Give a small donation ($20) to a charity in each major cause area, <em>especially</em> the ones you&apos;ve never donated to before. &#xA0;This will help prevent strong identification as a not-donor to cause area X or as only a donor to cause area Y. &#xA0;It may decrease the perceived foreignness of other cause areas than your current favorite. &#xA0;</p>\n<p>But also:</p>\n<p>2) Try <a href=\"http://lesswrong.com/lw/gpl/imitation_is_the_sincerest_form_of_argument/\">Ideological Turing Tests</a> to check how well you understand the arguments for other courses of action.</p>\n<p>3) If you feel comfortable, make a habit of asking other EAs to explain how they picked their cause area, and invite them to try to convince you to change your mind, so they don&apos;t have to worry about being inappropriately aggressive towards people who don&apos;t want it.</p>\n<p>4) Then document and share these arguments so lots of people don&apos;t unwittingly reproduce the same work.</p>\n<p>5) De-stigmatize talking about emotional attachment to causes. &#xA0;My strong impression is that many EAs have these attachments, but feel they have no place in the ideal EA conversation about cause selection, so they repress or subvert those feelings out of fear of looking irrational, or having their opinions be taken less seriously.</p>\n<p>&#xA0;</p>\n<p>What else would people recommend to make cause re-prioritization easier? How can we manage our personal relationships and local community dynamics so that they are strong and meaningful, but interfere as little as possible with our donating decisions?</p>\n<p>&#xA0;</p>\n<p>*throughout, I use &quot;donating&quot; as a shorthand for any action, including volunteering, professional work, journalistic coverage, political advocacy, and more, that&apos;s in support of a given cause area.&#xA0;</p></body></html>", "user": {"username": "ClaireZabel"}}, {"_id": "DaA4DqF8GdsfGp3tg", "title": "Moral Economics - What, Why, Whom, How, When, What For?", "postedAt": "2015-08-11T02:27:24.080Z", "htmlBody": "<html><body><address>\n<p><em><span>To contribute to moral economics, you can </span><a href=\"https://groups.google.com/forum/#!forum/moraleconomics\">join the google groups</a><span> (email Megan Crawford if you can&apos;t sign in), the </span><a href=\"https://dotimpactteam.slack.com/messages/moraltrade/\">slack #moral trade channel</a><span>&#xA0;(email Ozzie if you can&apos;t sign in), talk to us during </span><a href=\"https://www.facebook.com/events/477791982396277/\">the Sunday EA hackaton</a><span>, or simply post your idea for a moral economic concept of interest on a&#xA0;</span>googledocs<span>&#xA0; and share it with our group who can help you edit it.&#xA0;</span></em></p>\n<blockquote><address>I&apos;m currently time crunched while deciding whether to create a Crucial Considerations research institute in the bay, so I won&apos;t have time to edit this, sorry for any egregious mistakes an editor could have corrected.&#xA0;</address></blockquote>\n<p><em><br></em></p>\n<p><span>Moral economics series</span></p>\n<p>&#xA0;</p>\n<ol>\n<li>\n<p><a href=\"/ea/ky/introducing_moral_economics/\"><span>Introducing Moral Economics</span></a></p>\n</li>\n<li>\n<p><a href=\"/ea/l1/moral_economics_concepts/\"><span>Examples of Moral Economics Concepts</span></a></p>\n</li>\n<li>\n<p><a href=\"/ea/l1/moral_economics_concepts/\"><span>Branches Within Moral Economics</span></a></p>\n</li>\n<li>\n<p><span><a href=\"/ea/l9/moving_moral_economics_forward/\">Moving Moral Economics Forward</a></span></p>\n</li>\n<li>\n<p><a href=\"/ea/lg/direct_funding_between_eas_moral_economics/\">Direct Funding Between EAs</a></p>\n</li>\n<li>\n<p><span><span><strong>Moral Economics - What, Why, Whom, How, When, What For?</strong></span></span></p>\n</li>\n<li>\n<p><span>Certificates of Impact, Doing It Right <strong>-</strong> Giles Edkins</span></p>\n<ol>\n<li>\n<p><span>Moral market failure: how COIs might help</span></p>\n</li>\n<li>\n<p><span>Problems with COIs, and their solutions</span></p>\n</li>\n<li>\n<p><span>Implementing COIs</span></p>\n</li>\n</ol></li>\n<li>\n<p><span>Agential Identity in Moral Economics</span></p>\n</li>\n</ol></address>\n<p>&#xA0;</p>\n<h2>What</h2>\n<p>Moral Economics is the name of a cluster of concepts which are related to morality and economics at the same time, in particular concepts that relate to altruistic trade and exchange, and markets where values are partially determined by moral frameworks. Moral economics is particularly concerned with concepts that are useful for an aggregative consequentialist system of value, and forms of trade between agents that value actions according to these systems. Effective altruists are frequently good examples of such agents.&#xA0;</p>\n<h2>Why</h2>\n<p>The structure of moral reasoning has thus far been mostly the domain of philosophers, whereas economic reasoning has been the domain of economists and behavioral economists. Traditional economics has become a well developed academic discipline, with hundreds of specific concepts that help economic agents navigate the world. By contrast, in the domain of morality and economics we are in the beginnings of a barter-like system, with some tentative ideas such as certificates of impact starting to take momentum, and <a href=\"http://www.amirrorclear.net/academic/papers/moral-trade.pdf\">a single unpublished paper</a> explaining moral trade in the philosophical literature.&#xA0;</p>\n<p>When we look at the intersection of Moral Agency and Economics as its own discipline, Moral Economics, we create the possibility of transferring knowledge from the domain of economics to this new sub-branch much faster. To do so, we examine concepts that are important in economics, find analogous concepts and how they diverge in Moral Economics, and allow them to surface by writing about them. Moral economics is the range of a function that maps the structures we know from traditional economics, taking the moral exchange realm as input. The end result is a new way of reasoning about Moral Exchange that can facilitate the creation of moral markets, which facilitate the funneling of resources from the traditional economic realm to a realm that is value aligned with the interests of moral agents.&#xA0;</p>\n<h2>Whom</h2>\n<p>Moral Economics can be of use to:&#xA0;</p>\n<p><strong>Moral Agents </strong>who would like to trade with other moral agents with similar preferences and distinct opportunities, or dissimilar preferences.&#xA0;</p>\n<p><strong>Economists and Academics</strong>&#xA0;who are interested in further developing the similarities and differences in concepts, ideas, equations etc... when they refer to traditional economics and when they refer to altruistically oriented agents.&#xA0;</p>\n<p><strong>Founders and Developers</strong>&#xA0;who are developing phone or desktop apps to facilitate trade among altruistically oriented agents, or who are developing stock markets and similar applications with moral currencies.&#xA0;</p>\n<p><strong>Effective Altruists: </strong>if we map the development of ideas related to moral economics so far, the majority of ideas have come from and is of interest to effective altruists.&#xA0;</p>\n<h2>How</h2>\n<p>To use the idea of Moral Economics fruitfully you can:&#xA0;</p>\n<p>1) Conceive of an economic structure that operates differently for altruists and write about it here in the EA forum.&#xA0;</p>\n<p>2) Seize an economic opportunity determined by a niche of trade that is currently occupied in Traditional Economics but hasn&apos;t emerged in the moral realm yet.&#xA0;</p>\n<p>3) Further develop one of the concepts in the preliminary list of economics concepts that map in interesting and different ways for altruistic exchange that&#xA0;<a href=\"/ea/l9/moving_moral_economics_forward/\">I laid out here.</a>&#xA0;</p>\n<p>4) Enter<a href=\"https://groups.google.com/forum/#!forum/moraleconomics\"> the googlegroups</a> for moral economics and help others who are developing writings and ideas within the field, and help them edit their writings for the EA forum and other venues.&#xA0;</p>\n<p>5) Reach out to economists and financially savvy people so they join the creation of this domain of knowledge.&#xA0;</p>\n<h2>When</h2>\n<p>Developing a better understanding of the opportunities that lie in the moral economic realm now is valuable for the same reason that globalization was valuable for the Asian tigers when they had their fast economic rise. It is cheaper, faster and more effective to copy an already existing technology than to create a new one from scratch. The field of knowledge known as economics is a well known and established mental technology for reasoning about interacting agents with values and the ability to trade. Moral economics is still in an economy of Barter. The faster we import from traditional economics, the faster the moral realm will grow as a fraction of use of resources. The opportunity window has just opened, and each individual has high counterfactual value right now. Once we have a better map of what can or cannot be done in the moral realm, and how to do get it done, this will no longer be the case. That, however, is years away.&#xA0;</p>\n<p>Though the original concepts which I&apos;m suggesting are <a href=\"/ea/l1/moral_economics_concepts/\">paradigmatic examples of Moral Economic</a>s which came from Toby Ord, Rob Wiblin, Ben Kuhn, Paul Christiano and many others, so far most of the momentum for Moral Economics has come from me and Giles Edkins - whose posts will soon appear here - and my intention is to continue endorsing the development of this sub-field for as long as needed for it to move on without my input, so we really need more people writing here and helping this build momentum.&#xA0;</p>\n<h2>What for?</h2>\n<p>There are several market inefficiencies that can and will become more fluid as the moral market develops. Just as the Asian tigers had economic incentives to copy western technology in order to faster reach economic prowess, moral agents too have an economic incentive to achieve a larger moral economic capacity. We just have to gaze into the right direction and find the hidden niches of value. Our attempts are suggesting a direction for where to look; you are the one who will have to gaze at it.&#xA0;</p></body></html>", "user": {"username": "Diego_Caleiro"}}, {"_id": "fxw7tJGcEP33Chmoj", "title": "A way of thinking about saving vs improving lives", "postedAt": "2015-08-08T19:57:30.985Z", "htmlBody": "<html><body><p><strong>Throughout this essay I ignore flow through effects, non human animals, and effects on the distant future, even though I don&#x2019;t discount those in my personal altruistic decisions. Feel free to expand this analysis if you want to include those factors.</strong></p>\n<p><strong>Obvious disclaimers: I think it&#x2019;s a dumb idea to kill poor people. Also, well being varies for reasons other than poverty.</strong></p>\n<div>\n<div>TL; DR: If we&apos;re choosing between spending money on saving lives and reducing poverty, we need to consider how to compare the happiness created by saving a life to the happiness created by increasing the consumption in a society. Differentiating an estimate of happiness as a function of income lets you estimate the happiness created by increasing marginal consumption. If you assume happiness is logarithmic in income, then the dollar amount at which you&apos;re indifferent between saving a life and increasing total consumption that much increases as income * log(income). My extremely tentative numbers suggest that AMF is a much better charity for hedonic utilitarians than GiveDirectly.</div>\n</div>\n<p><strong>Thanks to Claire Zabel, Marie La, Daniel Filan, and others who helped me with this.</strong></p>\n<p>Sometimes it&#x2019;s useful to be able to put a value on a human life. To use a crass metaphor, these days human lives go for&#xA0;<a href=\"http://www.givewell.org/international/top-charities/amf#Costperlifesaved\">about $3400</a>&#xA0;if you want to buy them from AMF. That&#x2019;s the seller&#x2019;s price. I&#x2019;m interested in calculating the maximum price at which we should be interested in&#xA0;<em>buying</em>&#xA0;human lives.</p>\n<p>One way of defining this &#x201C;buyer&#x2019;s price&#x201D; of a human life is the maximum price at which we as a society would rather save someone&#x2019;s life than just keep the money. People are happier when they have higher consumption. If I could save the life of one American, but reduce American GDP by 10%, I&#x2019;m pretty sure that would overall not be a good trade.</p>\n<p>So we need to have a way of comparing the damage done by reducing the consumption of an economy by some amount of money to the damage done by someone in the economy dying.</p>\n<h2>Logarithmic happiness</h2>\n<p>It&#x2019;s pretty common to approximate happiness as linear in the logarithm of income, which I&#x2019;m going to equivocate with consumption for the rest of this post. Consumption just means &#x201C;the total value of all the things you consume in a given year&#x201D;. Average happiness in a population where everyone has consumption&#xA0;<span><span><span><span><span><span>c</span></span></span></span></span><span>c</span></span>&#xA0;can be written as:</p>\n<div>average happiness =&#xA0;<span><span><span><span><span><span>log</span><span>c</span><span>+</span><span>k</span></span></span></span></span><span>log&#x2061;c+k</span></span></div>\n<p>where&#xA0;<span><span><span><span><span><span>c</span></span></span></span></span><span>c</span></span>&#xA0;is consumption and&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>&#xA0;is a constant that tells us about the consumption level at which a life is so meagre and deprived that it isn&#x2019;t worth living, and also tells us how rapidly happiness increases relative to wealth. If people have a life expectancy of&#xA0;<span><span><span><span><span><span>t</span></span></span></span></span><span>t</span></span>&#xA0;years, then we have the total happiness-years of a person as&#xA0;<span><span><span><span><span><span>t</span><span>log</span><span>c</span><span>+</span><span>t</span><span>k</span></span></span></span></span><span>tlog&#x2061;c+tk</span></span>.</p>\n<p>Anyway, back to the math. The derivative of this function with respect to consumption is&#xA0;<span><span><span><span><span><span><span><span><span>1</span></span><span><span>y</span></span></span></span></span></span></span></span><span>1y</span></span>. So if we reduce the size of an entire economy by some small amount&#xA0;<span><span><span><span><span><span>&#x394;</span><span>c</span></span></span></span></span><span>&#x394;c</span></span>&#xA0;evenly spread across the whole population of n people, then the reduction in happiness per person is:</p>\n<div><span><span><span><span><span><span>&#x394;</span><span>happiness per person</span><span>=</span><span><span><span><span><span>&#x394;</span><span>c</span></span></span><span><span><span>c</span><span>n</span></span></span></span></span></span></span></span></span><span>&#x394;happiness per person=&#x394;ccn</span></span></div>\n<p>but there are&#xA0;<span><span><span><span><span><span>n</span></span></span></span></span><span>n</span></span>&#xA0;people, so the total reduction in happiness is:</p>\n<div><span><span><span><span><span><span>&#x394;</span><span>total happiness</span><span>=</span><span><span><span><span><span>n</span><span>&#x394;</span><span>c</span></span></span><span><span><span>n</span><span>c</span></span></span></span></span><span>=</span><span><span><span><span><span>&#x394;</span><span>c</span></span></span><span><span>c</span></span></span></span></span></span></span></span><span>&#x394;total happiness=n&#x394;cnc=&#x394;cc</span></span>.</div>\n<p>So if we have the option to spend&#xA0;<span><span><span><span><span><span>&#x394;</span><span>c</span></span></span></span></span><span>&#x394;c</span></span>&#xA0;to save a life, we should be indifferent to doing so if the total reduction of happiness caused by reducing the total consumption by&#xA0;<span><span><span><span><span><span>&#x394;</span><span>c</span></span></span></span></span><span>&#x394;c</span></span>&#xA0;would be the same as the happiness of a given person:</p>\n<div><span><span><span><span><span><span>t</span><span>(</span><span>log</span><span>c</span><span>+</span><span>k</span><span>)</span><span>=</span><span><span><span><span><span>&#x394;</span><span>c</span></span></span><span><span>c</span></span></span></span></span></span></span></span><span>t(log&#x2061;c+k)=&#x394;cc</span></span></div>\n<p>We can solve this for&#xA0;<span><span><span><span><span><span>&#x394;</span><span>c</span></span></span></span></span><span>&#x394;c</span></span>:</p>\n<div><span><span><span><span><span><span>&#x394;</span><span>c</span><span>=</span><span>c</span><span>t</span><span>(</span><span>log</span><span>c</span><span>+</span><span>k</span><span>)</span></span></span></span></span><span>&#x394;c=ct(log&#x2061;c+k)</span></span></div>\n<p>Now we can substitute the value that we end up choosing for&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>&#xA0;below to figure out that America should be willing to spend up to about $10 million to save an American baby. You can see the calculation&#xA0;<a href=\"https://docs.google.com/spreadsheets/d/1ofwjlxGFlgG7cVnuySiga8yApl6AWLDlyZPa-c5ZHRc/edit#gid=0\">here</a>.</p>\n<p>That&#x2019;s all the math. Now, let&#x2019;s spend two thousand words trying to figure out precisely how much fun it is to be extremely poor!</p>\n<h2>Thinking theoretically about&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span></h2>\n<p>The biggest judgement call in this essay is that&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>&#xA0;constant. The consumption at which a life has 0 value according to the above formula is&#xA0;<span><span><span><span><span><span><span><span><span>10</span></span><span><span><span><span>&#x2212;</span><span>k</span></span></span></span></span></span></span></span></span></span><span>10&#x2212;k</span></span>. So if you think that life isn&#x2019;t worth living if you&#x2019;re consuming less than $1000 a year, then you think&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>&#xA0;is -3.</p>\n<p>That&#x2019;s the literal meaning of&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>. However, it seems plausible to me that our log model breaks down when people are incredibly poor. So I think we should use two different strategies to think about&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>.&#xA0;<strong>Firstly</strong>, we should think about it assuming the model is correct, looking for the level of consumption at which life seems to not be worth living.&#xA0;<strong>Secondly</strong>, we should try ignoring its literal meaning and just trying to directly estimate it by looking at happiness variation across relatively small consumption variations. This should hopefully provide a good estimate over the kind of range we&#x2019;re interested in.</p>\n<p>Imagine we decided that living on $100,000 a year is twice as much fun as living on $10,000 a year. This would mean that&#xA0;<span><span><span><span><span><span>l</span><span>o</span><span>g</span><span>100000</span><span>+</span><span>k</span></span></span></span></span><span>log100000+k</span></span>&#xA0;is twice as much as&#xA0;<span><span><span><span><span><span>l</span><span>o</span><span>g</span><span>10000</span><span>+</span><span>k</span></span></span></span></span><span>log10000+k</span></span>. So&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>&#xA0;would be -3. If we thought poverty was not as bad as that, then maybe we&#x2019;d be saying that living on $1,000 a year is half as good as $10,000. In that case,&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>&#xA0;would be -2. I think that the first of those is probably truer, so this is another argument for estimating&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>&#xA0;as about -3.</p>\n<p>Maybe we should be concerned by this, because more than a billion humans have less than $1000 annual consumption. I have a few thoughts on this. To start with, it seems plausible that the purchasing power parity adjustment I&#x2019;m using isn&#x2019;t powerful enough. It&#x2019;s cheap to have a place to sleep in rural Malawi, much more than it is in America. If there were a Malawian rural town within commuting distance of my office in SoMa, I&#x2019;d be ecstatic to pay $200 a month to live in a thatch-roofed hut there. (I&#x2019;m not kidding: I lived on an air mattress on the floor of my office for six months last year.) There are lots of really cheap goods available to Malawians, like thatched roof huts and really cheap shitty rice, which are unavailable to me but make it much more easy to live cheaply.</p>\n<p>To some extent, I&#x2019;m willing to buy that living in SF counts as bonus consumption, because I&#x2019;m closer to fun things, but mostly I just live here so that I can work here, which feels more like an employment-related expenditure than consumption to me. So maybe I don&#x2019;t buy that as someone with an annual consumption of $30k, I&#x2019;m really getting 40 times the consumption in my life as the average resident of Malawi.</p>\n<p>The book&#xA0;<a href=\"https://www.dropbox.com/s/vwtxhtjokdokvcx/Poor-Economics.pdf?dl=0\">Poor Economics</a>&#xA0;tells the story (starting on page 20) of this extremely poor Indonesian guy called Pak Solhin. He used to live on $2 USD PPP a day, until he lost his job, after which he lived like this:</p>\n<blockquote>\n<p>Pak Solhin himself survived on about 9 pounds of subsidized rice he got every week from the government and on fish that he caught from the edge of a lake (he could not swim). His brother fed him once in a while. In the week before we last spoke with him, he had had two meals a day for four days, and just one for the other three.</p>\n</blockquote>\n<p>That life is being classified as significantly less than $2 PPP a day, which I don&#x2019;t think includes the benefits of free rice, his brother&#x2019;s food, or fishing in the river.</p>\n<p>I&#x2019;m not trying to trivialize extreme poverty here: that life sounds pretty unpleasant, and I&#x2019;m glad I don&#x2019;t have it. But I don&#x2019;t think it&#x2019;s entirely sensible to call that &#x201C;living on $1 a day&#x201D;.</p>\n<p>On the other hand, I get the benefits of a lot of government spending which Malawians don&#x2019;t: I have subsidized public transport, and reasonably good police, and good roads, and so on.</p>\n<p>Here&#x2019;s another fact about consumption levels and happiness. Under most natural circumstances, if you consume extremely small amounts (like $1 a year), then you aren&#x2019;t extremely sad, you just die from hunger or exposure. In fact, the consumption levels at which my happiness function predicts your life isn&#x2019;t worth living is actually pretty close to where I&#x2019;d imagine that you&#x2019;d die from hunger if we were really adjusting for PPP correctly. This is either incredibly interesting or a surprising coincidence. I am interested in hearing speculation about this.</p>\n<p>The variability of consumption also plays into this. If it costs you a dollar a day to not die of hunger, then if your monthly consumption has a standard deviation of 50c per day, I suspect you&#x2019;d die in a few months. So even if the lowest survivable level of poverty is bad enough that your life is barely worth living, perhaps not many people will live at that level of poverty for long.</p>\n<p>Marie La points out that another way of estimating this would be to look at the mortal risks people take when they are starving. We could look at situations where people had a choice between remaining in a place suffering from famine, or doing something extremely dangerous to escape. She points out the example of post-war Vietnam, where the South Vietnamese who tried to escape faced about a 50% chance of death and tried to escape anyway, partially because they were so enormously hungry. One particularly good way of estimating this would be to look at neighboring regions where escaping is roughly as risky but the levels of famine were different, and comparing the rates at which people tried to escape. There would obviously be a million confounders here, like how unpleasant the regime was or how much people expected the situation to improve, but we might get some useful data regardless.</p>\n<p>That&#x2019;s all been trying to estimate&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>&#xA0;by looking at happiness at the lowest end: how about if we try to estimate it by looking at how much a 10% change in consumption changes happiness in a nation? This has fewer philosophical issues, so I&#x2019;m not going to discuss them. This way of indirectly estimating&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>&#xA0;is closer to how we&#x2019;re going to estimate it in the next section.</p>\n<p>You also might be interested in looking up the paper which had happiness as a function of consumption&#xA0;<em>within</em>&#xA0;particular poor countries, then trying to solve for&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>&#xA0;within that much smaller and easier to measure range. However, this requires making a judgement call about how to translate the descriptions of happiness into real numbers. Depending on your feelings, this judgement call might be worse or better than what I did.</p>\n<h2>Numerically estimating&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span></h2>\n<p>Here&#x2019;s a few data points to use to estimate&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>:</p>\n<ul>\n<li>A few weeks ago I was talking to this dude who grew up in poverty in Mexico and illegally immigrated to America when he was 12. We chatted about his previous quality of life for a while: not getting enough food, only getting one pair of shoes a year, and so on. My impression is that his life in Mexico seemed about half as worth living as his life here is. From his description of his quality of life, and my understanding of Mexican poverty, I would guess he was living on maybe $4000 a year. I wish that I&#x2019;d thought to ask him for a numeric statement of how much better his life here was, but I didn&#x2019;t think of this. Next time.</li>\n<li>Slate Star Codex&#xA0;<a href=\"http://slatestarcodex.com/2013/04/30/utility-weight-results/\">did a survey</a>&#xA0;trying to calculate the relative quality of life in different situations. Respondents thought that Ethiopian life is 50% as good as American life, and Chinese life was 85% as good.</li>\n</ul>\n<p>I&#x2019;m a lot more averse to poverty than SSC readers, apparently.</p>\n<p>From these&#xA0;<a href=\"https://docs.google.com/spreadsheets/d/1ofwjlxGFlgG7cVnuySiga8yApl6AWLDlyZPa-c5ZHRc/edit?usp=sharing\">we get an average estimate</a>&#xA0;of&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>&#xA0;as about -2.2. This number is low enough that nations with average consumption PPP less than&#xA0;<span><span><span><span><span><span><span><span><span>10</span></span><span><span><span><span>2.2</span></span></span></span></span></span><span>=</span><span>158</span></span></span></span></span><span>102.2=158</span></span>&#xA0;are classified to have a negative quality of life. <span>I think this is an inaccurately high bar</span>. I removed the China data point because I think that the people answering the Slate Star Codex survey overestimated how rich China is. I vaguely recall the survey implying that you lived in a city in China or something, as opposed to living in rural China as 50% of Chinese actually do.</p>\n<p>Overall, I think that this model of happiness as logarithmic in consumption is good but gives bad results for extremely poor countries, because we are underestimating the consumption of extremely poor people.</p>\n<h2>Application to global poverty charities</h2>\n<p>One interpretation of these numbers is &#x201C;the price at which we are indifferent to decreasing total consumption by that much to save a single life&#x201D;. Another interpretation, though, is &#x201C;the price at which saving a single life is better value for money than just increasing consumption by that much&#x201D;. This is really important, because as philanthropists we have the option of doing both of these things, most obviously through GiveDirectly and AMF. Let&#x2019;s quickly review the levels of poverty of the people affected by these programs:</p>\n<p>AMF operates mostly in Malawi and the DRC. Bednet distribution is slightly cheaper in Malawi. Malawi has a GDP PPP per capita of about $226. Apparently, this is&#xA0;<a href=\"http://www.osisa.org/sites/default/files/sup_files/chapter_2_-_malawi.pdf\">pretty unevenly distributed</a>. So the people saved by AMF, who I think mostly live in rural areas (from looking up regions listed&#xA0;<a href=\"https://www.againstmalaria.com/Distributions.aspx\">here</a>), are probably poorer than average for Malawians. (AMF&#x2019;s distributors seem to find that&#xA0;<a href=\"http://www.givewell.org/files/DWDA%202009/AMF/Netcheu-PreDistributionRegistrationSurvey-Data-Rcvd24Dec11-names%20withheld.xls\">most of the houses they look at need LLINs</a>&#xA0;(Excel file), so we don&#x2019;t need to worry about saving unusually poor people among rural Malawians.)</p>\n<p>Kenyans who receive GiveDirectly grants have a&#xA0;<a href=\"http://www.givewell.org/international/top-charities/give-directly#footnoteref85_siu35s3\">median nominal consumption of $0.55 per day</a>. (I use median instead of mean because I suspect that consumption fits a log-normal distribution; this is suggested by the mean being higher than the median.) The nominal-to-PPP conversion for Kenya seems to be about 2.18 (from comparing nominal and PPP GDP estimates), so that&#x2019;s yearly consumption of about $408. This is almost twice Malawi&#x2019;s mean consumption, and as I said above the Malawians saved by AMF are probably poorer than above. Obviously, these numbers are so bad that they&#x2019;re almost useless. The Malawian consumption estimates&#xA0;<a href=\"http://www.osisa.org/sites/default/files/sup_files/chapter_2_-_malawi.pdf\">here</a>&#xA0;try to include sustenance farming, but it&#x2019;s really hard to get that right. According to the table on page 24 of&#xA0;<a href=\"http://documents.wfp.org/stellent/groups/public/documents/newsroom/wfp274603.pdf\">this report</a>, Malawi&#x2019;s proportion of undernourished people is 23.1% while Kenya&#x2019;s is 30.4%. (Undernourished means that you are below the &#x201C;minimum level of dietary energy consumption&#x201D;.) These numbers kinda look like they fit with my hypothesis that GiveDirectly recipients have pretty similar levels of consumption to Malawians saved through AMF.</p>\n<p>We&#x2019;ve got a plethora of extra factors in this particular case. To start with, maybe there are flow-through effects of cash transfers which case them to increase consumption more. Also, bednets have other positive effects than saving lives, like preventing developmental impairments from malaria that limit lifetime earning potential, preventing malaria death in the above-5 year old age group (which isn&#x2019;t counted) and prevention of other mosquito-borne illnesses. And having a marginal human might increase the consumption of other people in their society in some situations, but I don&#x2019;t know which situations that is. Also, GiveDirectly might save lives as well, by giving people money to buy things like medicine and medical care and better food, or indirectly by allowing people to get e.g. metal roofs and thus having better hygiene in their houses.</p>\n<p>I think that my formula is totally useless for answering the question of how much we should be willing to spend per life saved by AMF if our alternative is giving to GiveDirectly, because it&#x2019;s so sensitive to changes in my&#xA0;<span><span><span><span><span><span>k</span></span></span></span></span><span>k</span></span>. However, I did get some feeling about it from doing the research into poverty in Malawi and Kenya I did to write this discussion section. The people whose lives you save by giving to AMF seem to be pretty intensely impoverished. If 30% of Malawians are undernourished in general, and people saved by AMF are unusually poor, I suspect that probably a majority of the lives saved there are undernourished. That means that these people feel hungry&#xA0;<em>all the time</em>. I some sympathy for the perspective that those lives sound perhaps not worth living, in which case making them better is the better option. I also think it&#x2019;s pretty plausible that these lives are actually pretty okay. At the moment, I am probably inclined to think that the lives of the extremely poor are worth living.</p>\n<p>GiveWell has obviously thought about how to compare saving lives to increasing consumption, but AFAICT they haven&#x2019;t considered it this explicitly. In 2012 they said that they suspected AMF was a&#xA0;<a href=\"http://blog.givewell.org/2012/12/19/cost-effectiveness-of-nets-vs-deworming-vs-cash-transfers/\">much better deal</a>&#xA0;than GiveDirectly. However, GiveWell hasn&#x2019;t tried to quantify the value of increasing consumption vs saving lives like I have here. They probably haven&#x2019;t tried because it turns out that when you do, you get relatively difficult-to-interpret results, as I did above.</p>\n<p>Carl Shulman has also written about&#xA0;<a href=\"http://reflectivedisequilibrium.blogspot.com/2014/03/givedirectly-happiness-and-log-income.html?m=1\">happiness as log of consumption and GiveDirectly</a>&#xA0;before&#x2013;I hadn&#x2019;t seen his post before I wrote all this.</p>\n<p>Peter Hurford has a great summary of the lives of extremely poor people in third world countries&#xA0;<a href=\"http://everydayutilitarian.com/essays/how-do-the-extremely-poor-live/\">here</a>.</p>\n<p>If I donated to global poverty causes, I really don&#x2019;t know which of these I&#x2019;d give to.</p>\n<h2>Conclusion</h2>\n<p>The value of saving a life increases linearithmicly with consumption. This is neat. I am pretty sure this is correct, and I&#x2019;m really happy to have a principled derivation for it.</p>\n<p>I think my equation for the value of saving a life is quite good for richer countries where it&#x2019;s easier to measure consumption. Maybe one day, we will have ended global poverty, and the&#xA0;<span><span><span><span><span><span>&#x394;</span><span>c</span><span>=</span><span>c</span><span>t</span><span>(</span><span>log</span><span>c</span><span>+</span><span>k</span><span>)</span></span></span></span></span><span>&#x394;c=ct(log&#x2061;c+k)</span></span>&#xA0;equation will be actually useful when we&#x2019;re trying to decide whether a particular hovercar safety measure is worth it.</p></body></html>", "user": {"username": "Buck"}}, {"_id": "Ew8bD9aM8oDbCrmdN", "title": "Some objections and counter arguments against global poverty/health interventions", "postedAt": "2015-08-05T09:44:11.863Z", "htmlBody": "<p>Hi,</p>\n<p>I've written a brief document (<a title=\"brief document\" href=\"https://docs.google.com/document/d/1IwR7uO1yUR_78G8oR8Tg1UaY59A1riIuhP5p4roLMgY/pub\">https://docs.google.com/document/d/1IwR7uO1yUR_78G8oR8Tg1UaY59A1riIuhP5p4roLMgY/pub</a>), trying to collate some answers to frequently raised objections to donating to global poverty charities.</p>\n<p>I'll probably extend this document in the next few months.</p>\n<p>&nbsp;</p>\n<p><a href=\"https://docs.google.com/document/d/1IwR7uO1yUR_78G8oR8Tg1UaY59A1riIuhP5p4roLMgY/edit#heading=h.8f7ec0nsu47y\"><span>Q: Isn\u2019t economic growth going to lift people out of poverty? Should we not focus on growth?</span></a></p>\n<p><a href=\"https://docs.google.com/document/d/1IwR7uO1yUR_78G8oR8Tg1UaY59A1riIuhP5p4roLMgY/edit#heading=h.ut6erijv5w7s\"><span>Q: Should we not support health systems strengthening instead of supporting \u2018vertical\u2019 interventions that might are not sustainable?</span></a></p>\n<p><a href=\"https://docs.google.com/document/d/1IwR7uO1yUR_78G8oR8Tg1UaY59A1riIuhP5p4roLMgY/edit#heading=h.5t4rt61b1qne\"><span>Q: Can stopping tax evasion by multinational enterprises close the gap in finance for development?</span></a><span>\ueffe</span></p>\n<p><strong><br></strong></p>\n<h3><span>Q: Isn\u2019t economic growth going to lift people out of poverty? Should we not focus on growth?</span></h3>\n<p><span>A: Yes, eventually, but it would take decades, because the growth trickles down to the poorest very slowly. </span><a href=\"https://docs.google.com/document/u/1/d/1yYY63gyT4IVjGJYgFF0Sx09nIKrCBj1ek8mvJtLO12o/pub\"><span>We have written about this in detail here.</span></a></p>\n<h3><span>Q: Should we not support health systems strengthening instead of supporting \u2018vertical\u2019 interventions that might are not sustainable?</span></h3>\n<p><span>A: AMF and SCI must strengthen general health-care systems insofar as they reduce the burden of disease that would otherwise be met by the rest of the health-system (see figure from</span><span> below).</span></p>\n<p><a href=\"https://www.givingwhatwecan.org/blog/2015-07-27/strengthening-health-systems-in-low-income-countries-giving-what-we-can-missing\"><span>We have written about this in detail here.</span></a></p>\n<p><span><br></span></p>\n<p><span> </span><span><img src=\"http://res.cloudinary.com/cea/image/upload/v1667995044/mirroredImages/Ew8bD9aM8oDbCrmdN/w4heneswi5jjpxfqhwaq.png\" alt=\"\"></span></p>\n<p><span>Q: Can stopping tax evasion by multinational enterprises close the gap in finance for development?</span></p>\n<p><span>A: While tax evasion is certainly an issue that can help with development, the matter is much more complicated than this. We refer the interested reader to the </span><a href=\"http://www.cgdev.org/blog/how-much-do-we-really-know-about-multinational-tax-avoidance-and-how-much-it-really-worth?utm_source=150721&amp;utm_medium=cgd_email&amp;utm_campaign=cgd_weekly&amp;utm_&amp;&amp;&amp;\"><span>Center for Global Development</span></a><span> and the </span><a href=\"http://www.ictd.ac/en/corporate-tax-avoidance-and-development-opening-pandora%E2%80%99s-box\"><span>International Center for Tax and Development</span></a><span> for more information on this. In brief, the Center for Global Development writes on this issue:</span></p>\n<p><span>\u201cWe find that the potential for governments to raise additional revenues by taxing multinational companies is limited by the actual levels of profit generated by foreign direct investment in each country; changes to effective tax rates may also have impacts on investment prospects. Estimates of corporate tax dodging are often presented, mistaken, or repurposed in a way that exaggerates potential impacts - for example, large aggregate tax loss estimates are compared with aid revenues or healthcare funding gaps, implying that taxes raised in China, Brazil and South Africa might be available for public spending in Cambodia, Haiti and Malawi. Multi-year tax estimates are compared with annual costs of nurses or teachers. In some cases larger estimates (\u2018trillions\u2019) which relate to estimates of corruption, informal sector activities or offshore assets held by domestic citizens are mistakenly repurposed to represent complex tax planning practices of multinationals. Much-quoted figures such as \u2018\u2018developing countries lose three times more to tax havens than they get from aid each year\u201d and \u201c\u201860% of global trade takes place within multinationals\u201d or \u201cZambia could have doubled its GDP\u201d are not likely to hold up.\u201d </span></p>\n<p>&nbsp;</p>", "user": {"username": "HaukeHillebrandt"}}, {"_id": "PfkwPxymcEpkZjKRa", "title": "Why Effective Altruists Should Use a Robo-Advisor", "postedAt": "2015-08-04T03:37:13.789Z", "htmlBody": "<html><body><p>TL;DR: Go sign up for <a href=\"http://wealthfront.com/\">Wealthfront</a> right now and transfer all your savings into it. If you&#x2019;re young and/or you plan on donating most of your savings, choose the highest risk tolerance Wealthfront allows.</p>\n<h1>Investing Basics</h1>\n<p>You probably want to save money for retirement, or some future large purchase like a house. Many effective altruists have money that they want to donate eventually, but want to <a href=\"http://www.effective-altruism.com/ea/4e/giving_now_vs_later_a_summary/\">hold onto it for now</a>. What should you do with that money while you&#x2019;re keeping it?</p>\n<p>The simplest option would be to keep all your money in a savings account at your bank. This way you&#x2019;re guaranteed not to lose your money, but savings accounts earn hardly any interest. If you&#x2019;re willing to put your money into some riskier investments, you will probably end up with a lot more money than when you started.</p>\n<p>The two most important investment vehicles are stocks and bonds. You can buy these on your own, but you don&#x2019;t need to.</p>\n<h1>Robo-Advisors</h1>\n<p>There are services like <a href=\"http://wealthfront.com/\">Wealthfront</a>, called <a href=\"http://www.investopedia.com/terms/r/roboadvisor-roboadviser.asp\">robo-advisors</a>, that manage your money for you automatically. You give the robo-advisor some basic facts about yourself such as your age and how much risk you can tolerate, and it figures out a good way to allocate your money. You deposit your savings and the robo-advisor does the rest&#x2013;you never have to worry about your savings again. A good robo-advisor invests your money to get the best possible returns for your risk tolerance.</p>\n<p>Both individual and professional investors <a href=\"http://amazon.com/Random-Walk-Down-Wall-Street/dp/0393330338\">rarely outperform the market</a> in the long run, so a robo-advisor like Wealthfront will probably manage your money better than either you or a professional would. Even better, Wealthfront has low fees&#x2013;far lower than anything you&#x2019;d get from a human money manager&#x2013;so you get to keep more of your money.</p>\n<p>When you sign up for Wealthfront, it will give you a short quiz to determine how much risk it thinks you&#x2019;re willing to take on. The more risk you accept, the higher expected return you can get. Whatever this quiz tells you, it might be smart for you to choose the most aggressive, highest-risk allocation. As Carl Shulman explains in <a href=\"http://80000hours.org/blog/12-salary-or-startup-how-do-gooders-can-gain-more-from-risky-careers\">&#x201C;Salary or startup? How do-gooders can gain more from risky careers&#x201D;</a>, effective altruists can afford to take on more risk than most people. To borrow his example, your tenth Ferrari isn&#x2019;t as valuable as your first, but with your tenth vaccine, you can vaccinate a tenth kid and do just as much good as with your first vaccine. Most investors are highly risk-averse: not losing money is much more important to them than gaining money. But as effective altruists, we can afford to take risky bets because if we win big, we can do massively more good in the world.</p>\n<p>For the curious, Colby Davis&#x2019;s <a href=\"http://lesswrong.com/lw/kzh/a_guide_to_rational_investing/\">A Guide to Rational Investing</a> explains in more detail why investing on your own or with a (human) advisor is a usually bad idea, and why it&#x2019;s possible to do better than simply buying a total-market index fund. Wealthfront is likely to outperform a total-market index fund because it puts some of your money into <a href=\"http://www.investopedia.com/terms/e/emergingmarketeconomy.asp\">emerging markets</a>, which probably outperform the U.S. market in the long run.</p>\n<h1>Why not Betterment?</h1>\n<p><a href=\"https://www.betterment.com/\">Betterment</a> is another popular robo-advisor that offers a similar service to Wealthfront. I slightly prefer Wealthfront, but if you already use Betterment and you don&#x2019;t want to switch, that&#x2019;s probably fine. It would be counterproductive to get into a debate about the minor points in favor of one or the other&#x2013;if you prefer to use Betterment, by all means do so. The main benefits to be had here come from putting your money into a good robo-advisor. After that, it doesn&#x2019;t matter much which one you pick.</p>\n<p>There are a few other robo-advisors on the market which might be just as good. I haven&#x2019;t spent much time looking into any others, but I feel comfortable recommending either Betterment or Wealthfront.</p>\n<h1>Why not manage my own basket of index funds?</h1>\n<p>(If you don&#x2019;t want to do this, you don&#x2019;t need to read this section.)</p>\n<p>Actually, if you choose a good asset allocation and stick with it, you can probably get better results managing your own assets than using a robo-advisor. This approach requires more dedication, and you need to have a strong stomach to stick with your strategy even when it performs badly. But if that sounds like you, you might want to pursue this approach instead.</p>\n<p>For nearly risk-neutral investors, even Wealthfront&#x2019;s highest-risk, highest-return allocation still leaves a lot of room to squeeze out more returns. You could earn considerably more money by putting a larger percentage of your portfolio into high-return assets, and the best way to do this is to manually manage your investments.</p>\n<p>This means buying a basket of index funds with a high weighting in asset classes that have historically outperformed the broad market, which could include small-capitalization stocks, <a href=\"http://www.investopedia.com/terms/v/valuestock.asp\">value stocks</a>, and emerging market stocks. You should NOT simply buy a total U.S. or total world index fund. This will both perform worse than Wealthfront (because it is not weighted toward high-return asset classes) and have higher risk (because it is less diversified). It might sound like a total world index fund is maximally diversified, and in one sense it is because it holds stocks from every part of the world. But Wealthfront&#x2019;s asset allocation has better diversification properties because it holds a higher weighting in asset classes that tend to be less correlated with each other.</p>\n<p>I plan on writing a future post with some recommendations for nearly risk-neutral investors who want to manage their own investments. For anyone who wants to learn more now, I recommend William Bernstein&#x2019;s <a href=\"http://amazon.com/The-Intelligent-Asset-Allocator-Portfolio/dp/0071362363\">The Intelligent Asset Allocator</a>, which lays out which asset classes perform best and how to find a good allocation.</p>\n<h1>Is this just for effective altruists?</h1>\n<p>No, not really. Most people would be better off if they used a robo-advisor. But it&#x2019;s particularly important that effective altruists are able to make money on their investments, because it means they will have more money to donate.</p>\n<p><em>Disclaimers: I am not affiliated with Wealthfront; I just think robo-advisors are awesome. I am not a financial advisor and you should use your own judgment when making significant financial decisions.</em></p></body></html>", "user": {"username": "MichaelDickens"}}, {"_id": "b5oMMXgtqpuBH6ais", "title": "[LINK] Will MacAskill AMA on Reddit", "postedAt": "2015-08-03T20:45:42.530Z", "htmlBody": "<html><body><p>Will MacAskill is doing an <a href=\"https://www.reddit.com/r/IAmA/comments/3fngcb/iama_cofounder_of_two_nonprofits_with_over_400/\">Ask Me Anything session on Reddit</a> right now. Even if you see this after the AMA concludes, it&apos;s worth checking out if you want Dr. MacAskill&apos;s perspective on unique questions from effective altruists and the world at large. Note: questions will only be answered on Reddit. Please don&apos;t post questions you have for Dr. MacAskill in the comments here.</p>\n<div>\n<div>\n<blockquote>\n<p>Hi reddit,</p>\n<p>My name is William MacAskill and I believe in &#x201C;effective altruism&#x201D; and have made it my life&#x2019;s mission. I&#x2019;m a professor in philosophy at Oxford University and I&apos;ve co-founded two non-profits: <a href=\"https://80000hours.org/\">80,000 Hours</a>, which provides research and advice on how you can best make a difference through your career, and <a href=\"https://www.givingwhatwecan.org/\">Giving What We Can</a>, which encourages people to commit to give at least 10% of their income to the most effective charities. Together we have over $400 million in lifetime pledges.</p>\n<p>My first book was published this week <strong><a href=\"http://www.amazon.com/gp/product/1592409105/ref=s9_psimh_gw_p14_d3_i1?pf_rd_m=ATVPDKIKX0DER&amp;pf_rd_s=desktop-1&amp;pf_rd_r=1W5NS47Y229PWWASCNEQ&amp;pf_rd_t=36701&amp;pf_rd_p=2079475242&amp;pf_rd_i=desktop\">Doing Good Better</a></strong>. The book explores the question &#x201C;How can I make the biggest difference&#x201D; backed up by evidence and reason instead of impulse or hearsay. If you&#x2019;re interested, you can <a href=\"http://time.com/author/william-macaskill/\">see an article here</a>, or sign up at effectivealtruism.com and you can read a free chapter.</p>\n<p>Personally, I donate everything above $35,000 a year to organizations that I believe will do the most good (<a href=\"http://www.themid.com/philosophy/this-cambridge-philosopher-wants-to-change-how-you-think-about-doing-good?u=v5Eo1b0FvS\">reasons here</a>), and also plan on donating all profits from the book as well.</p>\n<p>Excited to be here so please AMA about what charities actually do good, how you can do more good in your lifetime, effective altruism, social entrepreneurship, book publishing, academia, or whatever else you may have on your mind!</p>\n<p>Proof: <a href=\"https://twitter.com/willmacaskill/status/628277924689375232\">https://twitter.com/willmacaskill/status/628277924689375232</a></p>\n</blockquote>\n</div>\n</div>\n<p>&#xA0;</p></body></html>", "user": {"username": "Evan_Gaensbauer"}}, {"_id": "NLrY35EXsWhG4BmFz", "title": "August Open Thread: EA Global!", "postedAt": "2015-08-01T15:42:07.625Z", "htmlBody": "<html><body><p>Here&apos;s a place to discuss projects, ideas, events and miscellanea relevant to the world of effective altruism that don&apos;t need a whole post of their own!</p>\n<p>The most interesting current news for effective altruists is that EA Global in San Francisco has just started!&#xA0;</p>\n<p>\n</p><ul>\n<li>Video from the first day, interspersed with occasional breaks, is available <a href=\"https://www.youtube.com/watch?v=C-ngjEFkhOM\">here</a>.</li>\n<li>Streamed video from the subsequent two days will be available <a href=\"http://www.eaglobal.org/livestream\">here</a>.</li>\n<li>The program is <a href=\"http://www.eaglobal.org/eagx\">here</a>.</li>\n</ul>\n<p></p>\n<p>Note that MIRI is also a few weeks into its <a href=\"/ea/ln/2015_miri_summer_fundraiser_how_we_could_scale/\">fundraiser</a>.</p>\n<p>Hope you have lots to discuss amidst these fresh EA talks!</p></body></html>", "user": {"username": "RyanCarey"}}, {"_id": "8yEWsjYMyzmmLZkn6", "title": "Efective Altruism Quotes", "postedAt": "2015-08-01T13:49:23.484Z", "htmlBody": "<html><body><p>What with new books on effective altruism out this year, <em>The Most Good You Can Do</em>, by Peter Singer; <em>How to Be Great at Doing Good</em>, by Nick Cooney; and <em>Doing Good Better</em>, by William MacAskill, there is a plethora of new material to mine for sound-bites or excerpts explaining effective altruism. Additionally, with Effective Altruism Global, and so many new organizations and blogs producing great content, there is an abundance of inspiring information to cite. Thus, I&apos;m reviving the <a href=\"/ea/7l/effective_altruism_quotes/\">effective altruism quotes</a> thread.</p></body></html>", "user": {"username": "Evan_Gaensbauer"}}, {"_id": "zr6npybA2oT8jJm8e", "title": "What I learnt from talking to over 100 Giving What We Can members ", "postedAt": "2015-07-30T14:31:24.786Z", "htmlBody": "<html><body><p><span>Hi,</span></p>\n<p><span>I work at Giving What We Can as Director of Community. As part of this, I&apos;ve been trying to get to know&#xA0;as many of our members (people who have taken the Giving What We Can pledge) as possible, mostly through talking with recently signed up members. I wrote this blog post a little while back talking about a couple of my findings, but it only recently occurred to me that people on here may not have seen it but might be interested. </span></p>\n<p><span>Below is an adapted version (see original post </span><a href=\"https://www.givingwhatwecan.org/blog/2015-07-20/what-i-learnt-talking-over-100-giving-what-we-can-members\"><span>here</span></a><span>). Especially relevant might be the reasons why people take the pledge instead of just giving a chosen % by themselves. For instance, I&apos;ve found a fair number of people who were already giving, or planning to give, a significant amount, who only recently realised there were still benefits to joining. I imagine there are more out there, and Giving What We Can would love to have you on board!</span></p>\n<p><span>Why do people pledge?</span></p>\n<p><span>We&#x2019;re naturally interested in why people choose to donate a significant amount of their income to others, and our blog has highlighted individual stories in the </span><a href=\"https://www.givingwhatwecan.org/blog/2015-07-01/giving-receiving\"><span>series</span></a><span> &#x2018;</span><a href=\"https://www.givingwhatwecan.org/blog/2015-06-22/becoming-effective-altruist\"><span>Why</span></a><span> </span><a href=\"https://www.givingwhatwecan.org/blog/2015-04-30/how-religion-motivates-my-giving\"><span>I</span></a><span> </span><a href=\"https://www.givingwhatwecan.org/blog/2015-02-10/why-i-finally-took-pledge\"><span>give</span></a><span>&#x2019;. One of the most interesting things I&#x2019;ve been learning about is this: why do members choose to take a pledge, rather than make a private commitment to give 10%? I found that, in nearly all cases, people spontaneously gave one or more of the three following answers:</span></p>\n<ul>\n<li>\n<p><span>&#x201C;Taking the pledge acts as a commitment device&#x201D;</span><span>: this was the most common explanation I heard. Choosing to give 10% of your lifetime income is a long term commitment, and many people find that it&#x2019;s easy to forget internal goals as time goes on. By joining Giving What We Can, you make a public commitment, and have more accountability, so you&#x2019;re more likely to stay on track.</span></p>\n</li>\n</ul>\n<ul>\n<li>\n<p><span>&#x201C;By joining I might inspire others to join&#x201D;</span><span>: this was the second most common reason given. By joining you can signal your support - you add your name to our </span><a href=\"https://www.givingwhatwecan.org/about-us/members\"><span>list of members</span></a><span> and it makes it easier to explain your giving to others when you are part of an established group who are all doing something similar. Indeed, some of the members I spoke with had already decided to give away 10% or more before they heard of Giving What We Can, but they saw that by joining they could encourage others to do so too.</span></p>\n</li>\n<li>\n<p><span>&#x201C;I like the community aspect&#x201D;</span><span>: for a smaller group of members, joining was a way to become more involved in a community and to meet like-minded people. For most of these, community was closely tied to their feelings about commitment, since giving as part of a community can help motivate you to achieve your aims.</span></p>\n</li>\n</ul>\n<p><span>Community and chapters</span></p>\n<p><span><img src=\"https://lh6.googleusercontent.com/dcAi4gr8DJVL6Gk2xWt9r8crMoz_ygk-w03GX8ImP6HgE9Mgv1LeyyYpTUqraacC2sMLtlYFGe84VccxBJl2dUCesPjT6HD7-0wEY60Gzwd9WOcUGBo7SiaIlrwupvzHQfs_VjA\" alt=\"\"></span></p>\n<p><span>Another of my focuses during conversations is on finding out how well connected members were to other people in the community (both Giving What We Can members and people interested in effective giving more broadly), and to gauge their interest in meeting other members. So far, I&#x2019;ve found that nearly all of the members I&#x2019;ve spoken with wished to be connected with other members. Most of these either already knew some people within the community or had a local chapter or meetup group they planned to check out. However, there were a number of people who did not know anybody in the community, and did not have a chapter within travelling distance.</span></p>\n<p><span>Combine the demand for chapters among current members with the fact that the most common way people hear about Giving What We Can is through word of mouth (and 27 out of 80 members I asked told me they had interacted with a local chapter before joining) - this suggests local chapters and meet up groups are really valuable. Even small and informal meetup groups provide a place to come together with others who care deeply about improving the lives of others.</span></p>\n<p><span><span>If you think you may be interested in starting a local chapter or meetup group, you can go </span><a href=\"https://www.givingwhatwecan.org/get-involved/chapters\"><span>here</span></a><span> and Jon, our super friendly Director of Outreach, will get in touch (or feel free to email him directly at </span><span>jonathan.courtney[at]givingwhatwecan.org</span><span>).</span></span></p></body></html>", "user": {"username": "aliwoodman"}}, {"_id": "Zt7PjoDpNYEwmRTQK", "title": "2015 MIRI Summer Fundraiser: How We Could Scale", "postedAt": "2015-07-28T02:43:02.036Z", "htmlBody": "<html><body><p><em>Our summer fundraising drive is now finished.&#xA0;<strong>We raised a grand total of $631,957 from 263 donors.</strong>&#xA0;This is an incredible sum, making this the biggest fundraiser we&#x2019;ve ever run.</em></p>\n<p><em>We&apos;ve already been hard at work&#xA0;<a href=\"https://intelligence.org/2015/08/31/final-fundraiser-day-announcing-our-new-team/\">growing our research team and spinning up new projects</a>, and I&#x2019;m excited to see what our research team can do this year. Thank you to all our supporters for making our summer fundraising drive so successful!</em></p>\n<hr>\n<p>The Machine Intelligence Research Institute (MIRI) is a research nonprofit that works on technical obstacles to designing beneficial smarter-than-human artificial intelligence (AI). I&apos;m MIRI&apos;s Executive Director, Nate Soares, and I&apos;m here to announce our <strong>2015 Summer Fundraiser</strong>!</p>\n<p>&#xA0;</p>\n<p>&#x2014;&#xA0;<strong>Live Progress Bar&#xA0;</strong>&#x2014;</p>\n<p><a href=\"http://intelligence.org/donate/#donation-methods\"><img title=\"See &apos;What MIRI could do with more funds,&apos; below, for descriptions of our funding targets.\" src=\"https://intelligence.org/wp-content/uploads/2015/12/S15-fundraiser-progress.png\" alt=\"\"></a></p>\n<p><strong><big><a href=\"http://intelligence.org/donate/#donation-methods\">Donate Now</a></big></strong></p>\n<p>&#xA0;</p>\n<p>This is a <a href=\"https://intelligence.org/2015/07/20/why-now-matters/\">critical moment</a> in the field of AI, and we think that AI is a <a href=\"https://intelligence.org/2015/07/24/four-background-claims/\">critical field</a>. Science and technology are responsible for the largest changes in human and animal welfare, both for the better and for the worse; and science and technology are both a product of human intelligence. If AI technologies can match or exceed humans in intelligence, then human progress could be accelerated greatly &#x2014; or cut short prematurely, if we use this new technology unwisely. MIRI&apos;s goal is to identify and contribute to technical work that can help us attain those upsides, while navigating the risks.</p>\n<p>We&apos;re currently scaling up our research efforts at MIRI and recruiting aggressively. We will soon be unable to hire more researchers and take on more projects unless we can secure more funding. In the interest of helping you make an informed decision about how you&#x2019;d like MIRI to develop, we&apos;re treating this fundraiser as an opportunity to explain why we&apos;re doing what we&apos;re doing, and what sorts of activities we could carry out at various funding levels. This post is a quick summary of those points, along with some of the reasons why I think donating to MIRI is currently a very highly leveraged way to do good.</p>\n<p>Below, I&#x2019;ll talk briefly about why we care about AI, why now is a critical moment for MIRI and the wider field, and what specific plans we could execute on with more funding.</p>\n<p>&#xA0;</p>\n<h2><span>Why care about artificial intelligence?</span></h2>\n<p>&quot;<a href=\"https://intelligence.org/2013/06/19/what-is-intelligence-2/\">Intelligence</a>&quot;&#xA0;(and therefore&#xA0;&quot;<a href=\"https://intelligence.org/2013/08/11/what-is-agi/\">artificial intelligence</a>&quot;) is a vague notion, and difficult to pin down. Instead of trying, I&#x2019;ll just gesture at the human ability to acquire skills, invent science, and deliberate (as opposed to their ability to carry things, or their fine motor control) and say &quot;that sort of thing.&quot;</p>\n<p>The field of artificial intelligence aims to automate the many varied abilities we lump under the label &quot;intelligence.&quot; Because those abilities are what allow us to innovate scientifically, technologically, and socially, AI systems will eventually yield faster methods for curing disease, improving economies, and saving lives.</p>\n<p>If the field of AI continues to advance, <a href=\"http://intelligence.org/faq#imminent\">most top researchers in AI</a> expect that software will start to rival and surpass human intelligence across-the-board sometime this century. Yet relatively little work has gone into figuring out what technical insights we&apos;ll need in order to align smarter-than-human systems with our interests. If we continue to prioritize capabilities research to the exclusion of alignment research, there are a number of reasons to expect bad outcomes:</p>\n<p>1. In the absence of a mature understanding of AI alignment, misspecified goals are likely. The trouble is not that machines might &quot;<a href=\"https://intelligence.org/2015/01/08/brooks-searle-agi-volition-timelines/#3\">turn evil</a>;&quot; the trouble is that computers do exactly what you program to. A sufficiently intelligent system built to execute plans that it predicts lead to the development of a cancer cure soon may well deduce that the most effective way to ensure that a cure is found is to kidnap humans for experiment, while resisting efforts to shut it down and creating backups of itself. This sort of problem could plague almost any sufficiently autonomous agent using sufficiently powerful search processes: programming machines to do what we <em>meant</em>&#xA0;is a difficult task.</p>\n<p>2. Artificially intelligent systems could eventually become <a href=\"/intelligence.org/faq/#superintelligence\">significantly more intelligent</a> than humans, and use that intelligence to gain a <a href=\"https://intelligence.org/2015/07/24/four-background-claims/#3\">technological or strategic advantage</a>. In this case, misaligned goals could be catastrophic. Imagine, for example, the cancer-curing system stripping the planet of resources to turn everything it can into computing substrate, which it uses to better understand protein dynamics.</p>\n<p>3.&#xA0;The advent of superintelligent machines might come very quickly on the heels of human-level machine intelligence: AI funding could spike as human-level AI draws closer; or cascades of relevant insights may chain together; or sufficiently advanced AI systems might be used to advance AI research further, resulting in a feedback loop. Given that software reliability and AI system safety are probably not features that can be <a href=\"http://lukemuehlhauser.com/a-reply-to-wait-but-why-on-machine-superintelligence/#ending\">bolted on at the last minute</a>, this implies that by the time superintelligent machines look imminent, we may not have sufficient time to prepare.</p>\n<p>These claims and others are explored in more depth in Nick Bostrom&apos;s book <em><a href=\"http://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=\">Superintelligence</a></em>, and also on our new <a href=\"/intelligence.org/faq\">FAQ</a>.</p>\n<p>If we do successfully navigate these risks, then we could see extraordinary benefits: automating scientific and technological progress means fast-tracking solutions to humanity&apos;s largest problems. This combination of large risks and huge benefits makes the field of AI a very important lever for improving the welfare of sentient beings.</p>\n<p>&#xA0;</p>\n<h2><span>Why now is a critical moment for MIRI and the field of AI</span></h2>\n<p>2015 has been <a href=\"https://intelligence.org/2015/07/16/an-astounding-year/\">an astounding year</a> for AI safety engineering.</p>\n<p>In January, the Future of Life Institute brought together the leading organizations studying long-term AI risk (MIRI, FHI, CSER) along with top AI researchers in academia (such as Stuart Russell, co-author of the leading AI textbook; Tom Dietterich, president of AAAI; and Francesca Rossi, president of IJCAI) and representatives from industry AI teams (Google DeepMind and Vicarious) for a&#xA0;&quot;<a href=\"/futureoflife.org/AI/ai_conference\">Future of AI</a>&quot;&#xA0;conference in San Juan, Puerto Rico. In the ensuing weeks and months, we&apos;ve seen:</p>\n<ul>\n<li>a widely endorsed <a href=\"http://futureoflife.org/AI/open_letter\">open letter</a> based on conclusions from the Puerto Rico conference, including an accompanying <a href=\"http://futureoflife.org/static/data/documents/research_priorities.pdf\">research priorities document</a>&#xA0;which draws heavily on MIRI&apos;s work.</li>\n<li>a grants program, funded by $10M from Elon Musk and $1.2M from the Open Philanthropy Project, aimed at jump-starting the field of long-term AI safety research.&#xA0;(MIRI researchers received funding from <a href=\"https://intelligence.org/2015/07/01/grants-fundraisers/\">four different grants</a>, two as primary investigator.)</li>\n<li>the announcement of the first-ever workshops and discussions about AI safety and ethics at the top AI and machine learning conferences, AAAI, IJCAI, and NIPS. (We presented a paper at the AAAI workshop, and we&apos;ll be at NIPS.)</li>\n<li>public statements by&#xA0;<a href=\"http://lukemuehlhauser.com/musk-and-gates-on-superintelligence-and-fast-takeoff/\">Bill Gates</a>,&#xA0;<a href=\"http://www.afr.com/technology/apple-cofounder-steve-wozniak-on-the-apple-watch-electric-cars-and-the-surpassing-of-humanity-20150323-1m3xxk\">Steve Wozniak</a>,&#xA0;<a href=\"http://venturebeat.com/2015/03/02/why-y-combinators-sam-altman-thinks-ai-needs-regulation/\">Sam Altman</a>, and others warning of the hazards of increasingly capable AI systems.</li>\n<li>a <a href=\"https://www.youtube.com/watch?v=fWBBe13rAPU\">panel discussion on superintelligence at ITIF</a>, the leading U.S. science and technology think tank. (Stuart Russell and I spoke on the panel, among others.)</li>\n</ul>\n<p>This is quite a shift for a public safety issue that was nearly invisible in most conversations about AI a year or two ago.</p>\n<p>However, discussion of this new concern is still preliminary. It&#x2019;s still possible that this new momentum will dissipate over the next few years, or be spent purely on short-term projects (such as making drones and driverless cars safer) without much concern for longer-term issues. Time is of the essence if we want to build on these early discussions and move toward a solid formal understanding of the challenges ahead &#x2014; and MIRI is well-positioned to do so, especially if we start scaling up now and building more bridges into established academia. For these reasons, among others, my expectation is that donations to MIRI today will go&#xA0;<a href=\"https://intelligence.org/2015/07/20/why-now-matters/\">much further</a>&#xA0;than donations several years down the line.</p>\n<p>MIRI is in an unusually good position to help jump-start research on AI alignment; we have a developed <a href=\"https://intelligence.org/files/TechnicalAgenda.pdf\">research agenda</a> already in hand and years of experience thinking about the relevant technical and strategic issues, which gives us a unique opportunity to shape the research priorities and methodologies of this new paradigm in AI.</p>\n<p>Our <a href=\"http://intelligence.org/technical-agenda/\">technical agenda papers</a> provide a good overview of MIRI&apos;s research focus. We consider the open problems we are working on to be of high direct value, and we also see working on these issues as useful for attracting more mathematicians and computer scientists to this general subject, and for grounding discussions of long-term AI risks and benefits in technical results rather than in intuition alone.</p>\n<p>&#xA0;</p>\n<h2><span>What MIRI could do with more funds</span></h2>\n<p>Over the past twelve months, MIRI&apos;s research team has had a busy schedule &#x2014; we&apos;ve been running workshops, attending conferences, visiting industry AI teams, collaborating with outside researchers, and recruiting. We&apos;ve done all this while also producing novel research: last year, we published five papers at four conferences, and wrote two more which have been accepted for publication over the next few months. We&apos;ve also produced around ten new <a href=\"/intelligence.org/all-publications\">technical reports</a>, and produced a host of new preliminary results that have been posted to our&#xA0;<a href=\"/agentfoundations.org\">research forum</a>.</p>\n<p>That&#x2019;s what we&apos;ve been able to do with a three-person research team. With a larger team, we could make progress much more rapidly: we&apos;d be able to have each researcher spend larger blocks of time on uninterrupted research, we&apos;d be able to run more workshops and engage with more interested mathematicians, and we&apos;d be able to build many more collaborations with academia. However, our growth is limited by how much funding we have available. Our plans can scale up in very different ways depending on which of these funding targets we are able to hit:</p>\n<p>Target 1 &#x2014; $250k: <strong><a href=\"https://intelligence.org/2015/07/18/targets-1-and-2-growing-miri#continuedgrowth\">Continued growth</a>.</strong>&#xA0;At this level, we would have enough funds to maintain a twelve-month runway while continuing all current operations. We will also be able to scale the research team up by one to three additional researchers, on top of our three current researchers and two new researchers who are starting this summer. This would ensure that we have the funding to hire the most promising researchers who come out of our MIRI Summer Fellows Program and our ongoing summer workshop series.</p>\n<p>Target 2 &#x2014; $500k: <strong><a href=\"https://intelligence.org/2015/07/18/targets-1-and-2-growing-miri#acceleratedgrowth\">Accelerated growth.</a></strong> At this funding level, we could grow our team more aggressively, while maintaining a twelve-month runway. We would have the funds to expand the research team to ten core researchers over the course of the year, while also taking on a number of exciting side-projects, such as hiring one or two type theorists. Recruiting specialists in <a href=\"https://en.wikipedia.org/wiki/Type_theory\">type theory</a>, a field at the intersection of computer science and mathematics, would enable us to develop tools and code that we think are important for studying verification and reflection in artificial reasoners.</p>\n<p>Target 3 &#x2014; $1.5M: <strong>Taking MIRI to the next level.</strong>&#xA0;At this funding level, we would start reaching beyond the small but dedicated community of mathematicians and computer scientists who are already interested in MIRI&apos;s work. We&apos;d hire a research steward to spend significant time recruiting top mathematicians from around the world, we&apos;d make our job offerings more competitive, and we&#x2019;d focus on hiring highly qualified specialists in relevant areas of mathematics. This would allow us to grow the research team as fast as is sustainable, while maintaining a twelve-month runway.</p>\n<p>Target 4 &#x2014; $3M: <strong>Bolstering our fundamentals.</strong>&#xA0;At this level of funding, we&apos;d start shoring up our basic operations. We&apos;d spend resources and experiment to figure out how to build the most effective research team we can. We&apos;d upgrade our equipment and online resources. We&apos;d branch out into additional high-value projects outside the scope of our core research program, such as hosting specialized conferences and retreats and running programming tournaments to spread interest about certain open problems. At this level of funding we&apos;d also start extending our runway, and prepare for sustained aggressive growth over the coming years.</p>\n<p>Target 5 &#x2014; $6M: <strong>A new MIRI.</strong> At this point, MIRI would become a qualitatively different organization. With this level of funding, we would be able to begin building an entirely new AI alignment research team working in parallel to our current team. Our current technical agenda is not the only approach available, and we would be thrilled to spark a second research team approaching these problems from another angle.</p>\n<p>I&apos;m excited to see what happens when we lay out the available possibilities (some of them quite ambitious) and let you all collectively decide how quickly we develop as an organization. We are not doing a matching fundraiser this year: large donors who would normally contribute matching funds are donating to the fundraiser proper.</p>\n<p>We have plans that extend beyond the $6M level: for more information, shoot me an email at&#xA0;<a href=\"mailto:nate@intelligence.org\">nate@intelligence.org</a>. I also invite you to email me with general questions or to set up a time to chat.</p>\n<p>&#xA0;</p>\n<h2><span>Addressing questions</span></h2>\n<p>The above was quite quick: I can say lots more about everything I touched upon above, and in fact we&apos;re planning to elaborate on many of these points between now and the end of the fundraiser. We&apos;ll be using this five-week period as an opportunity to explain our current research program and our plans for the future. If you have any questions about what MIRI does and why, email them to&#xA0;<a href=\"mailto:rob@intelligence.org\">rob@intelligence.org</a>; we&apos;ll be posting answers to the MIRI blog every Monday and Friday.</p>\n<div>Below is a list of explanatory posts written for this fundraiser, which I&apos;ll keep up-to-date:</div>\n<ul>\n<li>July 1 &#x2014; <strong><a href=\"https://intelligence.org/2015/07/01/grants-fundraisers/\">Grants and Fundraisers.</a></strong> Why we&apos;ve decided to experiment with a multi-target fundraiser.</li>\n<li>July 16 &#x2014; <strong><a href=\"https://intelligence.org/2015/07/16/an-astounding-year/\">An Astounding Year.</a></strong> Recent successes for MIRI, and for the larger field of AI safety.</li>\n<li>July 18 &#x2014; <strong><a href=\"https://intelligence.org/2015/07/18/targets-1-and-2-growing-miri/\">Targets 1 and 2: Growing MIRI.</a></strong> MIRI&apos;s plans if we hit the $250k or $500k funding target.</li>\n<li>July 20&#xA0;&#x2014;&#xA0;<strong><a href=\"https://intelligence.org/2015/07/20/why-now-matters/\">Why Now Matters.</a></strong> Two reasons to give now rather than further down the line.</li>\n<li>July 24 &#x2014;&#xA0;<strong><a href=\"https://intelligence.org/2015/07/24/four-background-claims/\">Four Background Claims.</a></strong>&#xA0;Core assumptions behind MIRI&apos;s strategy.</li>\n<li>July 27 &#x2014;&#xA0;<strong><a href=\"/lw/mjx/miris_approach\">MIRI&apos;s Approach.</a></strong>&#xA0;How we identify technical problems to work on.</li>\n<li>July 31&#xA0;&#x2014; <strong><a href=\"https://intelligence.org/faq\">MIRI FAQ.</a></strong>&#xA0;Summarizing some common sources of misunderstanding.</li>\n<li>August 3&#xA0;&#x2014; <strong><a href=\"https://intelligence.org/2015/08/03/when-ai-accelerates-ai/\">When AI Accelerates AI.</a></strong>&#xA0;Some reasons to get started on safety work early.</li>\n<li>August 7&#xA0;&#x2014;&#xA0;<strong><a href=\"https://intelligence.org/2015/08/07/target-3-taking-it-to-the-next-level/\">Target 3: Taking It To The Next Level.</a></strong>&#xA0;MIRI&apos;s plans if we hit the $1.5M funding target.</li>\n<li>August 10&#xA0;&#x2014;&#xA0;<strong><a href=\"https://intelligence.org/2015/08/10/assessing-our-past-and-potential-impact/\">Assessing Our Past And Potential Impact.</a></strong> Why expect MIRI in particular to make a difference?</li>\n<li>August 14&#xA0;&#x2014;&#xA0;<strong><a href=\"https://intelligence.org/2015/08/14/what-sets-miri-apart/\">What Sets MIRI Apart?</a></strong> Distinguishing MIRI from groups in academia and industry.</li>\n<li>August 18&#xA0;&#x2014;&#xA0;<strong><a href=\"https://intelligence.org/2015/08/18/powerful-planners-not-sentient-software/\">Powerful Planners, Not Sentient Software.</a></strong>&#xA0;Why advanced AI isn&apos;t &quot;evil robots.&quot;</li>\n<li>August 28&#xA0;&#x2014;&#xA0;<a href=\"https://intelligence.org/2015/08/28/ai-and-effective-altruism/\"><strong>AI and Effective Altruism.</strong></a>&#xA0;On MIRI&apos;s role in the EA community.</li>\n</ul>\n<p>You can also check out questions I&apos;ve answered on my <a href=\"/ea/ju/i_am_nate_soares_ama/\">Effective Altruism Forum AMA</a>. Our hope is that these new resources will let you learn about our activities and strategic outlook, and that this will help you make more informed decisions during our fundraiser.</p>\n<p>Regardless of where you decide to donate this year, know that you have my respect and admiration for caring about the state of the world, thinking hard about how to improve it, and then putting your actions where your thoughts are. Thank you all for being effective altruists.</p>\n<p>-Nate</p>\n<p><strong><big><a href=\"http://intelligence.org/donate/#donation-methods\">Click Here to Donate</a></big></strong></p></body></html>", "user": {"username": "So8res"}}, {"_id": "BXFCXfH5EtKedoquu", "title": "Direct Funding Between EAs - Moral Economics", "postedAt": "2015-07-28T01:07:53.100Z", "htmlBody": "<html><body><address><span>News: EA Global Googleplex participants - I&#x2019;ll be giving an ignite talk introducing the long vision for Moral Economics! <br></span><span>Edit: <a href=\"https://youtu.be/gkNCBtyvm2w?t=1037\">Here is the talk</a></span></address> <address><strong><br></strong><span>More news: Giles created a new <a href=\"https://dotimpactteam.slack.com/messages/moraltrade/\">#Moraltrade</a> channel on Slack, which is being used during the Sunday US UK online EA workathons - in person for those in SF. To see the </span><a href=\"https://www.facebook.com/events/477791982396277/\"><span>workathon Sunday event go here</span></a><span>. And to enter the </span><a href=\"https://dotimpactteam.slack.com/messages/moraltrade/\"><span>channel for Moral Trade enter here</span></a><span>. </span></address><address><span><br></span></address>\n<p><span>In these writings we propose the creation of a sub-field of knowledge, Moral Economics.</span></p>\n<p><span>In this post I will make a detailed case for direct donation being more efficient than more common methods of funding EA work, and cite many other benefits on top of efficiency. I believe we can &#xA0;and should address its underuse.</span></p>\n<p><span>Special Thanks to Eli Tyre, Dave Dekenberger, Matt Reyes, Giles Edkins and Ben Hoffman for edits and comments.</span></p>\n<p><strong><br></strong></p>\n<p><span>Moral economics series</span></p>\n<ol>\n<li>\n<p><a href=\"/ea/ky/introducing_moral_economics/\"><span>Introducing Moral Economics</span></a></p>\n</li>\n<li>\n<p><a href=\"/ea/l1/moral_economics_concepts/\"><span>Examples of Moral Economics Concepts</span></a></p>\n</li>\n<li>\n<p><a href=\"/ea/l1/moral_economics_concepts/\"><span>Branches Within Moral Economics</span></a></p>\n</li>\n<li>\n<p><a href=\"/ea/l9/moving_moral_economics_forward/\"><span>Moving Moral Economics Forward</span></a></p>\n</li>\n<li>\n<p><span>Direct Funding Between EAs</span></p>\n</li>\n<li>\n<p><span>Certificates of Impact, Doing It Right - Giles Edkins</span></p>\n<ol>\n<li>\n<p><span>Moral market failure: how COIs might help</span></p>\n</li>\n<li>\n<p><span>Problems with COIs, and their solutions</span></p>\n</li>\n<li>\n<p><span>Implementing COIs</span></p>\n</li>\n</ol></li>\n<li>\n<p><span>Agential Identity in Moral Economics</span></p>\n</li>\n</ol>\n<p>&#xA0;</p>\n<p><strong><br></strong><span>Direct Funding Between EAs - Moral Economics</span></p>\n<p>&#xA0;</p>\n<p><span><br></span></p>\n<p><span>We will examine the current options that transform resources into labor within effective altruism, with a special emphasis in the least well-known idea of Direct Funding Between EAs, that is direct donations between EAs.</span></p>\n<p><span>Previously we described:</span></p>\n<p><span>Direct Funding Between EAs: </span><span>A direct linkage between an individual who wishes to have their values promoted and another who attempts to promote these values in exchange for money.</span></p>\n<p><span>This has been attempted within the Effective Altruist community by creating</span><a href=\"https://gratipay.com/for/effective-altruists/\"><span> </span><span>Gratipay</span></a><span> and</span><a href=\"https://www.patreon.com/\"><span> </span><span>Patreon</span></a><span> donation portals for EAs.</span></p>\n<p><strong><br></strong></p>\n<h2><span>The Status Quo</span></h2>\n<p><strong><br></strong></p>\n<p><span>Currently there are at least four main forms of monetary exchange between Effective Altruists</span></p>\n<p><strong><br></strong></p>\n<p><span>Institutional Donations: </span><span>The vast majority of donations are going to institutions, this includes both recommended charities and institutions familiar to the EA movement such as CFAR, FHI, MIRI, CEA, Leverage etc&#x2026; &#xA0;</span></p>\n<p><span>Certificates of Impact: </span><span>A very small fraction of resources is going to certificates of impact, which represent altruistic valuable actions taken in the past, and can be purchased, in which case the buyer becomes responsible for the good deeds purchased.</span></p>\n<p><span>Direct Requests for Events: </span><span>Some events like the HPMOR parties were arranged directly by asking donors to finance the event.</span></p>\n<p><span>Direct Funding for EAs: </span><span>A very small fraction of resources is being transferred via Gratipay and Patreon between EAs.</span></p>\n<p><strong><br></strong></p>\n<p><span>The initiative </span><span>EA Ventures</span><span> proposes a model of resource transfer to specific projects which combines some of the above, to facilitate connecting projects to potential funders.</span></p>\n<p><strong><br></strong></p>\n<h2><span>Direct Funding - Details and Advantages</span></h2>\n<p><strong><br></strong></p>\n<p><span>There are several important differences between direct donation, hiring someone in an Effective Altruist institution, and purchasing people&#x2019;s certificates of impact. Direct donations are based on trusting what the person has done before, and what she claims she will do now. They are more stable than certificates - which are as stable as bounty hunting - and thus could be the entire source of income for individuals funded by donors who share their values, instead of institutional donations. Direct donations are also </span><span>much cheaper</span><span> per worker hour than institutional donations. As a back of the envelope calculation I estimated the difference as about threefold, and even after factoring 501c, charity status, Patreon&#x2019;s fee, and all other discounts, it remains two times more expensive to donate to institutions than directly.</span></p>\n<p><span>The current climate within the Effective Altruism community is one of </span><span>skepticism</span><span> of </span><span>direct funding</span><span> which receives a </span><span>small fraction of resources</span><span>,</span><span> skepticism</span><span> of </span><span>certificates of impact</span><span>, which also receive a </span><span>small fraction of resources</span><span>, and </span><span>profound trust</span><span> in institutions. This trust at a recent EA Think Tank meeting was called &#x201C;sanctification&#x201D; of institutions - which receive </span><span>the vast majority of financial and volunteering resources</span><span> from Effective Altruist donors. This is unjustified and could be taken as a temporary failure in the moral market. I expect this trend to change over time as the ideas of direct funding and currencies such as certificates of impact become more integrated into the strategic thinking of individual donors, and the snowball of increasing trust in long-term committed individuals generates a self-reinforcing incentive.</span></p>\n<p><span>Direct donations would be a great addition to the moral market, since they offer many advantages, some of which are simply unavailable to institutions or certificates of impact. Let us look at some of these advantages:</span></p>\n<p><strong><br></strong></p>\n<p><span>Direct funding permits investigation of neglected causes: </span><span>It requires merely two individuals for a cause to be investigated. If, for example, a single donor considers an investigation on the disruptive potential of Emulation Economics to the global economy, and one individual wants to undertake this research, this suffices for at least some attention to be allocated to that problem. Even causes neglected </span><span>within</span><span> EA can be evaluated.</span></p>\n<p><strong><br></strong></p>\n<p><span>Direct funding is stable over time: </span><span>Certificates of impact pay backward in time. An individual cannot anticipate to receive them beforehand because other projects may be judged more valuable. Direct donations done monthly could guarantee security for EAs that intend to zig-zag between institutions, researchers who want to research a specific cause, and other helpers who would undertake a function that isn&#x2019;t defined by a job-role. Direct donations are a contract of trust between donor and donee, and the donee could establish ways for the donors to keep track of the work they are paying for, such as by sending periodic reports or having periodic meetings.</span></p>\n<p><strong><br></strong></p>\n<p><span>Direct funding permits unusual work</span><span>: Performance is hard to measure. Individuals who travelled between EA institutions and influenced the EA movement via hard to assess means (e.g. Michael Vassar, Justin Shoevelain, Jasen Murray, Scott Aaronson...) are frequently volunteering their time and effort to EA causes. Some of these individuals have built a reputation of doing great work as EAs though they were always behind different projects. In theory, institutions could hire such people, but in practice, direct donations would be a much more efficient way of incentivizing more people to be EA generalists. Once a thread of trust is built, these EAs could have freedom to work in what seems more appropriate to them, as long as their backers still thought they were on the right track. More importantly, many more people could begin to work as EA generalists who currently don&#x2019;t even consider that possibility, the labour market would become more fluid.</span></p>\n<p><strong><br></strong></p>\n<p><span>Direct funding prevents groupthink: </span><span>Institutions need to have their focus well understood, and require some level of internal goal alignment. Bold new different ideas of what needs to be done by EAs, or what needs to be researched, or new methods of research won&#x2019;t come easily out of institutions - this is less of a problem within the EA community than outside it, but the problem is not completely eliminated. Direct funding would attenuate it even further; If a person with a good track record of EA ideas in the past wants to pursue a very different project, their direct donors could guarantee their financial stability without jeopardizing either the person&#x2019;s action flexibility, nor the reputation of the institution to which the person works for, since there would be none.</span></p>\n<p><strong><br></strong></p>\n<p><span>Direct funding is instantaneous: </span><span>Hiring an individual can take a long time, especially a foreigner. Direct donations can be done as soon as there is an agreement on conditions and trust between donor and donee.</span></p>\n<p><strong><br></strong></p>\n<p><span>Direct funding facilitates international EA work: </span><span>The reasons here are clear. It is bureaucratically less costly to transfer money internationally than to do it via institutions.</span></p>\n<p><strong><br></strong></p>\n<p><span>Direct funding makes moving to EA hubs easier: </span><span>Many EAs move to locations with more EAs. It is much easier to do this if there are stable income sources that are region independent and provide a fallback during the period of transition. More importantly, donations are considered passive income, and as far as I know donations within a bounded range can be received by non-US citizens in US soil, even in non-favorable Visa conditions. Similar constraints are relaxed for donations to other countries as well. To move to Oxford, Berkeley, Switzerland or Melbourne would be much easier at the moment for EAs who are receiving the majority or entirety of income through direct donations.</span></p>\n<p><strong><br></strong></p>\n<p><span>Direct funding alters the mindset of the recipient: </span><span>If you are hired by an EA institution to do a particular set of tasks, you are being paid to do those tasks, and help that organization do well in its function. If you are directly being paid to be an EA however, this is much more ingrained in your identity. There are people paying you to do the most good you can do. If you see an opportunity for doing good, you will be more likely to take it, since you are never done with the obligation of being a great EA.</span></p>\n<p><strong><br></strong></p>\n<p><span>Direct funding can be the entire source of income of an individual:</span><span> This seems to be the untapped secret of direct funding. If someone wants to do EA work all the time, they can be fully funded by donors so as to not need any institutional affiliation, or have a token one. This threshold will be what determines the ultimate value of direct donations, since the point at which there are sufficient incentives for individuals to try doing this as their main income source will be the tipping point for most of the advantages above to manifest in full. When people can confidently undertake an EA career or a paid year on the basis of donation, then the labor market will have the necessary fluidity to accrue all of the advantages that can be had via direct funding.</span></p>\n<p><strong><br></strong></p>\n<p><span>Even though they are important all these advantages and details are completely dominated by the crucial factor when it comes to effective donation.</span></p>\n<p><strong><br></strong></p>\n<h2><span>Direct Funding is Very Cheap </span><span>&#xA0;</span></h2>\n<p><strong><br></strong></p>\n<p><span>Institutions are made of people. When you pay an institution to do something, you are ultimately paying the people participating in it to do something. If you are an effective altruist donating to an EA charity, then you are paying someone </span><span>because you want them to do something</span><span>. This thing is what has value for you. Having institutions and charity status are very valuable for the EA movement, and it is one of the ways in which it causes </span><span>a lot of people to do a lot of things</span><span>.</span></p>\n<p><span>The question then is, is there a niche or a space for causing people to do what needs to be done also outside institutional boundaries?</span></p>\n<p><span>The response is a resounding </span><span>yes!</span></p>\n<p><span>Why would we want to complement institutional roles with individual roles? Basically because individuals are cheap. It costs a lot in donations to hire a new worker at an institution, whereas there are many EAs who would (and do) work for much less money. Individuals who work in EA institutions frequently cost 75.000USD or more per year to their donors. Some EAs on the other hand would be happy and willing to work on their project for a third of that, 25.000USD. In fact for a couple years at least some EA organization paid less than that. The difference in cost to donors is striking. Even after accounting for the fees that Patreon and Gratipay charges (~3%), tax exemptions for charities and other advantages, the difference is still very substantial. Institutions have to bear many costs that individuals don&#x2019;t have to, and if I recall correctly, direct donations are not subject to income tax on the donee&#x2019;s part, which makes it even cheaper for the donors. Sometimes institutions also have to pay according to a table that determines how much people in different jobs should make, irrespective of whether both parties would prefer otherwise. No such constraint exists for donations.</span></p>\n<p><span>For an altruistic donor, there are two numbers that matter: number of dollars that they have spent on the thing they value, and number of things that got done towards that value being accomplished. The cheapest way to do so seems to me hands down to be direct donation to individuals. It is at least twice as cheap.</span></p>\n<p><strong><br></strong></p>\n<p><span>Why Are Institutions Sacralized?</span></p>\n<p><span>When discussing this strange phenomenon with other EAs, someone (who works for a high paying institution, so I&#x2019;ll protect their name) suggested this interesting question. It seems to me that the reason why institutions are sacralized is that it feels like an institution is much closer to a cause or goal in mental space. The association between &#x201C;saving the environment&#x201D; and &#x201C;Greenpeace&#x201D; is much stronger than that of &#x201C;saving the environment&#x201D; and &#x201C;Al Gore&#x201D;. Al Gore may have strongly advocated for environmental causes, but a person seems less like a cause than an institution does. The forest, however, is made of trees, and Greenpeace is made, in great part, of people working in environmental causes.</span></p>\n<p><span>EAs are notorious for their ability to reason through their felt sense, and do what they think is valuable even if it doesn&#x2019;t necessarily feel immediately right. EAs are probably good then at combating the felt sense that donating to institutions is donating directly to a cause, instead of for people who work on/advocate/research on a cause. Donating to institutions is paying for the people who work there, plus taxes, rent, retirement benefits, legal fees, institutional costs, and many other collaterals. Maybe 70% or even 90% of EA paid work should indeed be done through institutions and wages, but I am very skeptical that not even 10 EAs should be being paid directly to work on EA projects, research, advocacy, etc&#x2026; When we consider that this could also be done to pay individuals temporarily while they rearrange Visa situations, while their legal contract is processed, or that it can be used to finance EAs who live in countries with advantageous currencies, I find it impressive that this was not chosen by anyone yet as the problem they will solve.</span></p>\n<p><span>Creating an EA donation network is one of the most valuable things we can do. Ozzie Gooen, Patrick Brinich-Langlois, and many others have begun to do this, but more needs to be done, and more donors should consider direct donations their primary place to donate. Also, we should concentrate our donations toward EAs with good portfolios of EA work completed, until donations amount to a significant fraction of their income. Having 10 individuals receiving 1/10th of the institutional cost for 1 worker won&#x2019;t give any of them the security and trust needed to pursue an EA career and EA projects, but having 3 receive 1/3rd of that instead would likely cause all three of them to feel confident in this opportunity. At least two times more work would be done. If this were life-saving work, then twice the lives would be saved. &#xA0;</span></p>\n<p><span>As the unnamed person above pointed out: It is as if EA institutions have become sacred, but there is no reason for this.</span></p>\n<p><strong><br></strong></p>\n<p><span>Improving Direct Donations Between EAs</span></p>\n<p><strong><br></strong></p>\n<p><span>Patreon versus Gratipay</span></p>\n<p><span>Ozzie - who put up the Gratipay network - and I advocate a transition to Patreon as quickly as possible, since it is much more likely to be standing in the near future, Gratipay has gone down once already and has lower transaction volume. </span></p>\n<p><span><strong><span>Trust</span><span> </span></strong></span></p>\n<p><span>One issue that comes up when discussing direct donations is &#x201C;how to make sure the donors trust their donees to be doing good work?&#x201D; This is one more reason to reduce the number of baskets in which donors should put their eggs. It is much easier to have one or two individuals you trust doing work you value, and keep track of what they are doing, than to invest at once in many people. Especially for neglected causes, it is valuable to have a setting where only one large or two smaller donors suffice to finance someone they trust.</span></p>\n<p><span>Feedback</span></p>\n<p><span>It is of course up to the dyad to establish how they will determine for how long the donations continue, how much freedom the donee has to change projects, and which types of report they will give. To make this easier, donees could have a standard way to report to their donors, and make contextual adjustments when requested.</span></p>\n<h2><span>Evaluation</span></h2>\n<p><span>EA donors have especially high regard for external evaluators such as GiveWell, GWWC and Animal Charity Evaluators. If individuals are competing with organizations for funds, it is likely that donors will place a similar burden of proof on each. As such, an evaluator for directly funded individuals might become necessary (although note that explicitly EA-aligned organizations which rely on donations, such as CEA, also fall outside the scope of current external evaluators).</span></p>\n<p><strong><br></strong></p>\n<p><span>Guarantees</span></p>\n<p><span>Eventually, it would also be valuable to have financial guarantees for donees being funded. If a donor decides to stop funding a person responsible for a project (say because they had a financial emergency), the person still gets funded for 1 or 2 months by a guarantee fund, and gets some extra exposition to other prospective donors, who may choose to save the project from going under and the person from financial insecurity. Even if there were a guarantee bank, the whole process would still be much cheaper than hiring people institutionally.</span></p>\n<p>&#xA0;</p>\n<p>&#xA0;</p>\n<hr>\n<p><span>In the next post on Moral Economics Giles Edkins will discuss several new ideas related to Certificates of Impact, and suggestions on how to create a moral market. &#xA0;</span></p>\n<p><span>Don&apos;t forget to check the ignite talk on Moral Economics if you are going to EA Global at the Googleplex on Saturday.</span></p></body></html>", "user": {"username": "Diego_Caleiro"}}, {"_id": "fkX5dcvyifuD7WcRa", "title": "Charity Science is hiring", "postedAt": "2015-07-27T18:38:42.190Z", "htmlBody": "<html><body><p><span>Charity Science does outreach and fundraising for GiveWell&#x2019;s recommended charities (although we have also worked on animal rights in the past). You can see the sort of activities that we do and the philosophy we follow at our website: </span><a href=\"http://www.charityscience.com/Organizational-breakdown\"><span>http://www.charityscience.com/Organizational-breakdown</span></a><span> </span></p>\n<p><span><br></span></p>\n<p><span>We are seeking people who truly want to have the biggest positive impact on the world. This position will involve diverse work that requires both creative and intellectually challenging thought. As a young team with a startup culture, the hours are flexible but the work is intense and every team member contributes to strategy and big picture decisions. This job will likely challenge and change you more than any job you&#x2019;ve ever had before. We are looking for someone who will be able to grow into a leadership/management position in our organization.</span><span><br></span></p>\n<p>&#xA0;</p>\n<p><span>If you are interested in learning more or applying email me (</span><a href=\"mailto:joey@charityscience.com\"><span>joey@charityscience.com</span></a><span>) or talk to me or Katherine Savoie at EAG (San Francisco). We are also open to suggestions for employees who might be a good fit with Charity Science.</span></p></body></html>", "user": {"username": "Joey"}}, {"_id": "BsMvWRmEKMv2eAKnk", "title": "EA Facebook New Member Report", "postedAt": "2015-07-26T16:35:54.894Z", "htmlBody": "<html><body><p><em>Summary: Data about where people joining the EA Facebook group first heard of EA.</em><br><br><br><a href=\"https://www.facebook.com/groups/effective.altruists/\">EA Facebook group</a> moderators Claire Zabel and I, with some help from Julia Wise, have been sending a welcome message to every new member when we add them. By doing so we partly aim to set a good first impression, make people feel welcome, and provide a point of contact for questions.<br><br>We also ask them to tell us where they first heard about EA. By doing this, we gather data about where new EAs are formed. Hopefully this data will be helpful for future marketing efforts. As joining the group requires moderator approval, this means we reached substantially every member who joined over the past 31 days. Obviously we&apos;re only sampling a subset of EAs - those that join the facebook group - but we are sending the message to ~100% of that subset, and no one else. This compares with the big <a href=\"/ea/gb/the_2014_survey_of_effective_altruists_results/\">EA census</a>, which sampled from a much wider group, but it was less clear how representative the sample was.</p>\n<p>&#xA0;</p>\n<h2>The data</h2>\n<p>Between 2015/06/22 and 07/22, 375 people joined the group, bringing us to 6478 members.<br><br>Of the ~371 people we messaged*, 216 people responded. This is a 58% response rate. We then tried to fit their response into a broad category like &apos;Facebook&apos; or &apos;LessWrong&apos;. Here is the data in chart and table form:</p>\n<p><img src=\"data:image/png;base64,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\" alt=\"\"></p>\n<p><!--[if !mso]> <mce:style><! v\\:* {behavior:url(#default#VML);} o\\:* {behavior:url(#default#VML);} b\\:* {behavior:url(#default#VML);} .shape {behavior:url(#default#VML);} --> <!--[endif] --></p>\n<p>28%&#xA0;&#xA0;&#xA0; Friend<br>16%&#xA0;&#xA0;&#xA0; Facebook<br>14%&#xA0;&#xA0;&#xA0; Other<br>12%&#xA0;&#xA0;&#xA0; Peter Singer<br>12%&#xA0;&#xA0;&#xA0; LessWrong/CFAR/Eliezer/HPMOR/SSC/MIRI<br>10%&#xA0;&#xA0;&#xA0; Media Article<br>4%&#xA0;&#xA0;&#xA0; 80k<br>4%&#xA0;&#xA0;&#xA0; GiveWell<br>3%&#xA0;&#xA0;&#xA0; Colleague<br>3%&#xA0;&#xA0;&#xA0; Philosophy<br>3%&#xA0;&#xA0;&#xA0; EAG<br>3%&#xA0;&#xA0;&#xA0; Animal Rights<br>2%&#xA0;&#xA0;&#xA0; Local Grouo<br>2%&#xA0;&#xA0;&#xA0; NA<br>2%&#xA0;&#xA0;&#xA0; Will<br>1%&#xA0;&#xA0;&#xA0; Akilnathan logeswaran<br>1%&#xA0;&#xA0;&#xA0; Family<br>1%&#xA0;&#xA0;&#xA0; Christianity<br>1%&#xA0;&#xA0;&#xA0; GWWC</p>\n<p>&#xA0;</p>\n<h2>Some notes on the data</h2>\n<ul>\n<li>The categories are not mutually exclusive.</li>\n<li>&apos;Friend&apos; sometimes referred to people the new member knew in person, and sometimes to an online friend - often it was unclear. Sometimes they just gave a name, and if we didn&apos;t recognise the name I often assumed they were a friend. </li>\n<li>&apos;Facebook&apos; tends to refer to the &apos;recommended groups&apos; feature on facebook.</li>\n<li>&apos;Other&apos; is very broad.</li>\n<li>Peter Singer does well, mainly from his TED talk and his book.</li>\n<li>I grouped together LessWrong, CFAR, Eliezer, HPMOR, SlateStarCodex and MIRI.</li>\n<li>I think Media Articles were often discussing the EA Global Event, but people were sometimes ambiguous, or gave a result that would have required too much investigation - e.g. &apos;NYT article&apos;, &apos;magazine article&apos;.</li>\n<li>80k includes blog posts and talks.</li>\n<li>GiveWell includes Holden</li>\n<li>EAG includes Tyler Altman</li>\n<li>Local Groups includes EA groups, LW groups, Philosophy groups etc.</li>\n</ul>\n<p>We also have a constant problem with spam in the group. A large fraction (Jacy once estimated 80%, but I think more like 30% of the new joiners) of the accounts who attempt to join are fake accounts. In total (since the group began many years ago, and before the current moderators) 403 facebook accounts have been blocked, virtually all of which for spam. This means we must be sceptical of the 6478 members number, as many of these are probably fake accounts using the EA page to make themselves appear more credible. The new members appear to be more legitimate, but we tend to approve new members if uncertain, so there are probably fake accounts among the 375. Presumably these did not respond to our greeting.</p>\n<p>&#xA0;</p>\n<h2>How do these results compare to the EA census?</h2>\n<p><br>Some discrepancies are to be expected, as an artifact of the data collection technique. For example, we had many more people naming &#x2018;Facebook&#x2019;. The census had LessWrong as the number one source, which probably reflected the prominent link to the survey on LessWrong. However, LessWrong is still a major source in our data, suggesting that the strong result in the census was not just an artifact of disproportionate sampling.<br><br>Notably, &#x2018;Peter Singer&#x2019; was a pretty major source in our data - much higher than in the census data. Conversely, &#x2018;GWWC&#x2019; was a much more major source in the census than in our data. Perhaps indicating the recent bout of attention around EA global, &#x2018;Media Article&#x2019; does well in our data, but does not appear in the survey data.<br><br>Friendship proves its worth in both data sets.</p>\n<p>&#xA0;</p>\n<h2>Should we change what we&apos;re doing?</h2>\n<ul>\n<br>\n<li>Sending these messages and compiling the answers is somewhat time consuming for Claire and I. </li>\n<li>Is this data worth gathering? Sending the messages also has other benefits, as we answer people&#x2019;s questions and make them welcome. But we could save time recording the data.</li>\n<li>Would it be better to send a link to an online survey, with standardised response options?</li>\n<li>What other data would be most valuable? Bear in mind that we don&#x2019;t want to overwhelm people!</li>\n<li>What else can we do better?</li>\n</ul>\n<p><br><br><br><br>----<br><br><em>Thanks to Claire to reading a draft of this post. Any errors are, of course, my own.</em><br><br>---<br><br>* A very small number of profiles do not allow messages from non-friends</p></body></html>", "user": {"username": "Larks"}}, {"_id": "FK4fHkQqEbgijABqb", "title": "Results of the Effective Altruism Outreach Survey", "postedAt": "2015-07-26T11:41:48.500Z", "htmlBody": "<html><body><p><em>This article reports the results of an online survey with 167 respondents on the influence different styles of effective altruism outreach have on them. While we could not find evidence for our hypotheses, the exploratory data analysis yielded a ranking of the levels of motivation and curiosity our prompts&#xA0;induced. (<a href=\"http://claviger.net/effective-altruism-outreach-survey.html\">Cross-posted from my blog.</a>)</em></p>\n<h2>Topic</h2>\n<p>The aim of our survey was to determine what form of effective altruism outreach was most effective for what type of&#xA0;audience.</p>\n<p>As types of outreach, we&#xA0;distinguished:</p>\n<ol>\n<li>the &#x201C;obligation style,&#x201D; which aims to reveal altruistic values in people by helping them overcome biases, a style that is epitomized by <a href=\"https://www.youtube.com/watch?v=Diuv3XZQXyc\">Peter Singer</a>&#x2019;s Child in the Pond analogy,&#xA0;and</li>\n<li>the &#x201C;opportunity style,&#x201D; which assumes that people are altruistic and helps them overcome biases that keep them locked in lethargy anyway, a style that is epitomized by <a href=\"https://www.youtube.com/watch?v=ZGAkrpwyu1k\">Toby Ord</a>&#x2019;s appeal that people can save hundreds of lives over their lifetime if they invest their money&#xA0;wisely. </li>\n</ol>\n<p>Styles that we did not investigate are the usage of humor to better convey topics that would otherwise be met by defensiveness (suggested by <a href=\"https://www.againstmalaria.com/People.aspx\">Rob Mather</a>) and a style that is similar to the opportunity style but puts a stronger emphasis on personal discovery, as in <a href=\"https://www.youtube.com/watch?v=o0VrZPBskpg\">Melanie Joy</a>&#x2019;s <span>TED</span>&#xA0;talk.</p>\n<p>Such an evaluation could help any group engaged in effective altruism outreach to communicate more effectively with their respective&#xA0;audiences.</p>\n<p>Our hypotheses&#xA0;were:</p>\n<ol>\n<li>The obligation style leads to defensiveness, which would effect negative reaction at least in the short term and at least from less rationally-minded people. (If it is also more emotionally salient, later reflection might still make it more effective, but we cannot measure&#xA0;that.)</li>\n<li>The opportunity style has a positive effect but only on people who already show a strong altruistic&#xA0;inclination.</li>\n<li>Pitches targeted at specific demographics have a stronger effect on these people than on&#xA0;others.</li>\n</ol>\n<p>On the exploratory side, we were also interested in the correlation between rational inclination and respondents&#x2019; trust in their intuition, and their attitude toward our prompts, as well as any correlation between respondents&#x2019; reaction to the prompts and the degree to which the prompts informed them or withheld information, as teasers&#xA0;do.</p>\n<p>Since we could not find evidence of these correlations, it would be interesting to see whether others can. Additionally, there are a number of prompts that seem very powerful that we did not include (e.g., a comparison of prioritization with triage). A different sample might be more representative of the taxonomy. A qualitative study might also shed more light on the way people react to our&#xA0;prompts.</p>\n<h2>Design and&#xA0;Implementation</h2>\n<p>One of our worries was that if obligation-style prompts really make people defensive, then there is the risk of this defensiveness coloring the responses to later prompts. Hence we introduced a page break and sorted the critical prompts to the second page of the&#xA0;two.</p>\n<p>The length of the prompts, especially the one&#x2019;s borrowed from Peter Singer, was another problem. We slightly shortened them where possible and otherwise reduced the number of prompts from originally eight per category to five. In the interest of reducing the number of fields people have to tick, we removed a scale for how much people like a prompt, which we found&#xA0;dispensable.</p>\n<p>To measure rational and experiential (intuition-related) proclivities, we relied on the Rational-Experiential Inventory (<span>REI</span>) with 10 prompts by Norris, Pacini, and Epstein (1998). To measure altruistic inclination, we selected 10 prompts from the Adapted Self-Report Altruism Scale by Rushton (original, 1981), Witt and Boleman (adapted version,&#xA0;2009).</p>\n<p>Just as these two scales, our prompts also relied on five-item Likert&#xA0;scales.</p>\n<p><a href=\"http://claviger.net/assets/outreach-survey.html\">The full survey and recruitment letter can be found&#xA0;here.</a></p>\n<p>We at first used the original Rushton scale, but after receiving 15 responses switched to the modified one, which meant turning sentences from present perfect into conditional (&#x201C;I have donated blood&#x201D; became &#x201C;I would donate blood.&#x201D;). The change is fairly localized, the responses obtained after the change greatly outnumber those obtained before, and we did not see any noticeable differences in the spread of the answers, so we decided to include the first 15 in our final&#xA0;analysis.</p>\n<p>We advertised the survey on Reddit, Twitter, and Facebook, also using paid advertisement on Facebook to reach more people. Most, however, were recruited through an email a friend send to a mailing list of the Humboldt-Universit&#xE4;t zu Berlin. We tried to counterbalance and get more people without academic background into our sample by targeting younger people on Facebook, but we only recruited only about 26 people that way (at a rate of almost &#x20AC;1 per person), as opposed to 85 via the mailing&#xA0;list.</p>\n<p>Please contact us if you would like to play around with the raw&#xA0;data.</p>\n<h2>Analysis</h2>\n<p>Our R script for cleaning and analysis can be found in this <a href=\"https://bitbucket.org/snippets/Telofy/Mb4pE\">Bitbucket snippet</a>.</p>\n<p>After a first section of type conversions and reversal of questions that were asked in the negative for validation purposes, we engaged in the controversial practice of interpreting the ordinal Likert items as interval scale to compute means. This would imply that the differences between the five options we gave are identical. We have no basis for this assumption, and the results should be taken with the appropriate absolute-scale number of grains of&#xA0;salt.</p>\n<p>Apart from more cleaning, we also combined answers into categories that seem intuitive enough to us to not be motivated by the data. However, we have seen the data before deciding on the categories in all cases except for political views. The intervals used for the respondents age are not ours but intervals often used in the literature. These coarser categories allowed us to compensate for the low sample sizes per&#xA0;cohort.</p>\n<p>Finally the script produces some eighty&#xA0;graphs.</p>\n<p>When the analyses showed that we could find evidence for none of our hypotheses, we engaged in exploratory data analysis, the results of which are detailed in the&#xA0;following.</p>\n<h2>Evaluation</h2>\n<p><img src=\"http://claviger.net/images/all.png\" alt=\"Full ranking\"></p>\n<p>Exploratory data analysis has the inevitable drawback that in all likelihood we&#x2019;ll find significant-looking correlations in our data simply by&#xA0;chance.</p>\n<p>Nonetheless the overall ranking of the prompts, prompts that we asked our respondents to rate along scales of curiosity and motivation they either induced or failed to induce, has the power of our full sample size of 167 behind it, so that we&#x2019;re somewhat confident that conclusions drawn about prompts close to its extreme points are&#xA0;valuable.</p>\n<p>The graph above shows the distribution of respondents&#x2019; votes with the prompts described by a key where the first is a keyword that makes clear which prompt is meant, the second part is our taxonomy of whether the prompt focuses on the donor&#x2019;s opportunity or moral obligation, the third part is either &#x201C;info&#x201D; or &#x201C;teaser&#x201D; depending on whether the prompt explains something or withholds information, and the fourth part indicates whether the respondent gauged their motivation or their curiosity. The first and last part are restrictive while the second and third are&#xA0;descriptive.</p>\n<p>There are also some post-hoc rationalizations that make the rankings of the top prompts&#xA0;plausible.</p>\n<p>The absolute top prompt in terms of motivation and curiosity is Peter Singer&#x2019;s famous Child in the Pond analogy, which would probably not have made it into our survey had it not proved its persuasive power by turning Singer&#x2019;s essay &#x201C;Famine, Affluence, and Morality&#x201D; into a seminal paper of moral philosophy well-known to philosophers&#xA0;worldwide.</p>\n<p>The third place is a slightly adapted version of the sentence that Giving What We Can uses as one of their slogans, &#x201C;Studies have found that top charities are up to a thousand times more effective than others,&#x201D; except that the organization omits the weasel words &#x201C;studies have found.&#x201D; It is also a time-tested&#xA0;prompt.</p>\n<p>The fourth place is an almost verbatim quote from Toby Ord&#x2019;s <span>TED</span> talk and surely a statement that the Giving What We Can founder has honed in hundreds of conversations with potential pledge-takers: &#x201C;You can save someone&#x2019;s life without even changing your&#xA0;career.&#x201D;</p>\n<p>The final spots in the ranking can be explained as an aversive reaction to an insulting prompt. Interestingly, the rather popular prompt comparing the training of a guide dog to sight-restoring surgery ranks very low in terms of the motivation it&#xA0;induces.</p>\n<p>Threats to our external validity are that we have in our&#xA0;sample:</p>\n<ul>\n<li>3.7 times as many academics than people who only graduated school if you count as academics anyone who has visited a university or college irrespective of whether they&#x2019;ve attained a degree&#xA0;yet,</li>\n<li>3 times as many nonreligious than religious respondents, and a mean age of 25 (&#x3C3;=7) with only two respondents over&#xA0;45.</li>\n</ul>\n<p>There are likely more biases that we can&#x2019;t&#xA0;recognize.</p>\n<h3>Main&#xA0;Hypotheses</h3>\n<p><img src=\"http://claviger.net/images/all.mean.matrix.png\" alt=\"Scatter plots\"></p>\n<p>In our data exploration, we have generated over eighty graphs that can be found in <a href=\"https://drive.google.com/open?id=0B_EGIYnWjWAvfmRnTGJWdWhVTzVBUl93TnRaQWM5NS1DX3ctWXpsWXVlM3J0cXBqN1h2YmM\">this gallery</a>.</p>\n<p>Based on experiences in the Less Wrong community and <a href=\"http://reg-charity.org/\"><span>REG</span></a>&#x2019;s experiences with poker players as well as our inside view of the effective altruism movement itself, we expected to see a clear correlation between rationality and effective altruism inclination (the &#x201C;all&#x201D; vs. &#x201C;rational&#x201D; plots&#xA0;above).</p>\n<p>We did not expect to see such a clear correlation with our data on the respondents&#x2019; altruism inclination (the &#x201C;all&#x201D; vs. &#x201C;altruistic&#x201D; plots above), because it tested very elementary, naive empathetic skill, which may be necessary to a degree but is otherwise unhelpful for understanding effective&#xA0;altruism.</p>\n<p>Neither correlation showed. Not even the square root of the product of the two features was correlated with responses to our prompts. If these results can be taken at face value, then it seems to us that rationality and altruism may be little more than necessary conditions for becoming effective altruism, and that something else is just as necessary&#x2014;maybe the principle of &#x201C;taking ideas seriously,&#x201D; which is common on Less Wrong, or any number of other such traits. But the results are probably more likely to be&#xA0;meaningless.</p>\n<p>The strong correlations between &#x201C;altruistic&#x201D; and the two <span>REI</span> dimensions may be just artifacts of people&#x2019;s different inclinations to answer Likert scales with extreme or moderate values. Surprisingly, however, the same tendency is not evident between the two <span>REI</span> dimensions. Perhaps they are sufficiently contradictory to offset this tendency. Please let us know when you have other&#xA0;explanations.</p>\n<h3>Qualitative&#xA0;Results</h3>\n<p>The only nonquantitative question in our survey was the one asking for comments and suggestions. A few interesting&#xA0;comments:</p>\n<ol>\n<li>One respondent made the good point that the questions that focus on opportunities in effective altruism put the donor at the center rather than the beneficiary, something that to change is a crucial part of effective&#xA0;altruism.</li>\n<li>Five respondents made suggestions that seemed to go in the opposite direction (though that is my interpretation), largely for pragmatic purposes. Two of them seemed take this position despite seeming fairly aware of the privilege of their&#xA0;birth.</li>\n<li>One respondent said fairly directly that the distance of suffering was morally relevant to&#xA0;them.</li>\n</ol>\n<h2>Conclusion</h2>\n<p>While we could not find evidence for our hypotheses, we were able to generate a ranking of prompts commonly used by effective altruists of to how much motivation and curiosity they induce according to self-report. Due to biases in our sample, the external validity of these results is probably higher for populations of academics than the general&#xA0;population.</p></body></html>", "user": {"username": "Telofy"}}, {"_id": "H2MaFXcQ9eBDyLiHe", "title": "TLYCS Pamphlet Pilot Results", "postedAt": "2015-07-25T19:24:04.039Z", "htmlBody": "<html><body><p>TLYCS has wrapped up the grass-roots, university focused pamphleting pilot that we posted about earlier this year. The entire writeup can be viewed <a href=\"https://drive.google.com/file/d/0ByFxvhXPmbsiUkVXRDI5N1JBOWc/view?usp=sharing\">here</a>, but the major results (taken from the introduction) are given below. I&apos;m happy to answer any questions in the comments, and if anyone wants to view the full data set we collected, I can talk with the folks at TLYCS about getting it to you. Thanks again for the helpful comments and critique you all provided at the outset of this pilot, and hopefully these results will be useful to someone down the line.</p>\n<blockquote>\n<p>The Life You Can Save (TLYCS) ran a test-pilot for a grass roots pamphleting program during Spring of 2015. On five separate outings during May and June, roughly 3500 pamphlets were handed out to students on Los Angeles area university campuses. The metrics of interest for the pilot were the number of visitors to the TLYCS website generated by the pamphlets, and the associated cost per visitor.</p>\n<p>In post-pilot analysis, the estimated acquisition rate of website visitors per-pamphlet for these outings was between 0.6 % and 1.1 %. This translates to a $125 to $70 cost per-website visitor at the $0.75 price-per-unit TLYCS paid for the pamphlets. However, this cost could be straightforwardly reduced to between $12 to $6 per-website visitor by more economically sourcing the pamphlets.</p>\n<p>There is reason to believe that a more focused, strategic pamphlet design, along with offering an incentive in the pamphlet, could have driven up the acquisition rate. However, even a doubling of the rate would not have produced a per-visitor cost on par with TLYCS&#x2019;s online advertising efforts. Therefore a decision was made in the wake of the pilot to discontinue the program.</p>\n</blockquote>\n<p>&#xA0;</p>\n<p>FYI, the previous posts on this topic are:</p>\n<p>http://effective-altruism.com/ea/dg/tlycs_pamphleting_pilot_program/</p>\n<p>http://effective-altruism.com/ea/eh/tlycs_pamphleting_pilot_plan/</p>\n<p>&#xA0;</p></body></html>", "user": {"username": "jonathonsmith"}}, {"_id": "TbHMdwP9kuqYMmrYi", "title": "Effective Altruism Policy Analytics Update", "postedAt": "2015-07-24T20:26:55.542Z", "htmlBody": "<html><body><p><span>If this is your first time reading about Effective Altruism Policy Analytics, you can look at our website here for more information: </span><a href=\"https://eapolicy.wordpress.com/\"><span>https://eapolicy.wordpress.com/</span></a></p>\n<p><span><br></span><span>Effective Altruism Policy Analytics has now been working for eight weeks, and is more than halfway through its experimental period. Our overall strategy for finding regulations to comment on has been refined with changes to how we search for feedback, but for the most part we are continuing our initial strategy with more skill and less distractions.</span><span><br></span><span><br></span><span>Our current policy comment process typically proceeds as follows: </span><span><br><br></span></p>\n<ul>\n<li>\n<p><span>Find proposed rules on </span><a href=\"http://www.regulations.gov/#!home\"><span>Regulations.gov</span></a><span> </span></p>\n</li>\n<li>\n<p><span>Select rules to comment on after considering difficulty, replaceability, feedback, and potential impact</span></p>\n</li>\n<li>\n<p><span>Conduct research on:</span></p>\n<ul>\n<li>\n<p><span>How the regulation currently works, compared to the proposed rule</span></p>\n</li>\n<li>\n<p><span>What the powers the agency has over the rule and how much control they have over the issue area</span></p>\n</li>\n<li>\n<p><span>What useful information or support the regulatory agency needs</span></p>\n</li>\n<li>\n<p><span>Which experts can assist us</span></p>\n</li>\n<li>\n<p><span>Which papers can we learn from and cite</span></p>\n</li>\n<li>\n<p><span>What are the best changes to make, and their expected benefits</span></p>\n</li>\n</ul>\n</li>\n<li>\n<p><span>Draft a comment, while seeking assistance, verification, and feedback</span></p>\n</li>\n<li>\n<p><span>Revise the comment based on feedback</span></p>\n</li>\n<li>\n<p><span>Submit the final comment</span></p>\n</li>\n<li>\n<p><span>Send feedback surveys and request further feedback</span></p>\n</li>\n</ul>\n<p><strong><br></strong></p>\n<p><span>Biggest changes we have made:</span></p>\n<p><strong><br></strong></p>\n<ul>\n<li>\n<p><span>Increased specialization and division of labor among team members</span><span> - Having project members focus their attention on one regulation at a time, and using interns to gather feedback and handle distracting tasks has saved us a lot of time, and allowed us to increase comment length and quality. By going more in-depth, we can address more issues and create more topics for agencies to consider.</span></p>\n</li>\n</ul>\n<p><strong><br></strong></p>\n<ul>\n<li>\n<p><span>Changing our feedback system, spending less time contacting more people</span><span> - When we started the project, it became apparent that waiting for government feedback takes a long time (sometimes over a year), and final rules that guarantee fast feedback only make guarantees because they have already been thoroughly researched and considered. We attempted to use expert feedback as a mechanism for improvement, however our initial attempts involved many emails back and forth with little useful information acquired, despite iterating and changing our methods. After assigning an intern to work exclusively on this problem for roughly a week, we distributed a wide net of emails to many contacts and started getting lots of useful feedback. We are still facing difficulty convincing respondents to fill out the quantitative surveys, as they opt to write their own qualitative opinions of our comments.</span><span><br><br></span></p>\n</li>\n<li>\n<p><span>Focusing more on producing comments than other efforts</span><span> - Throughout the project, we encountered a lot of tasks that we tried to tackle, like registering as lobbyists, increasing our transparency, and obtaining feedback. Many of these ideas were not immediately actionable, and some were fairly time-consuming. Also, many of these ideas were less important than simply measuring the effectiveness of comments. This project is an experiment, the larger our sample size is, the more useful information we gain about making policy comments. Given how generalized the project already is, it is likely more valuable to focus on the goal of our experiment: to determine if policy comments are a cost effective way for effective altruists to create policy change.</span></p>\n</li>\n</ul>\n<p><strong><br></strong></p>\n<ul>\n<li>\n<p><span>Focusing more on increasing the number of points we make in comments</span><span> - Regulatory agencies address points separately, which allows comments with more points to receive more feedback. As research time is a costly, diving deeper into a given policy which we have become familiar with often has higher returns than searching for entirely new things to comment on. </span></p>\n</li>\n</ul>\n<p><strong><br><br></strong></p>\n<p><span>Progress:</span><span><br></span><span><br></span><span>We have been producing about 1 policy comment per week, which is half as much as what we initially estimated. Our initial estimates were based on earlier comments submitted in the fall, and in retrospect it is easy to identify reasons why those comments were produced faster:</span></p>\n<p><span> </span></p>\n<p>&#xA0;</p>\n<ul>\n<li>\n<p><span>We had full time access to experts</span><span> - Having Richard Bruns and Matt Dahlhausen free to work in 8 hour blocks on weekends allowed us to solve various knowledge problems very quickly. Matt had specialized knowledge on relevant aspects of both of the proposed rules, and Richard is very good at finding new ways to produce economic effect estimates when the relevant data is not available.</span><span><br><br></span></p>\n</li>\n<li>\n<p><span>There was unaccounted for research time</span><span> - Matt Dahlhausen had done some of his own research before we worked on comments in the fall. One of our current most time consuming activities is researching regulations to comment on, and figuring out if a comment is justified. There have been many times where we did hours of research and work on producing a comment only to find out a desired change was going to happen anyway, that a change cannot be made for legal reasons, or that an apparent mistake is only represented on Regulations.gov and not the official proposed rule.</span><span><br><br></span></p>\n</li>\n<li>\n<p><span>There was unaccounted passive work</span><span> - Hours worked were stretched out over multiple weekends, rather than all at once. This allowed us to sleep on ideas longer, and bring them up in discussions at DC Effective Altruism meetups. Having this much passive time allowed us to work very quickly once we had a formal meeting.</span></p>\n</li>\n</ul></body></html>", "user": {"username": "Gentzel"}}, {"_id": "bqgxafGxcTaRYvg5K", "title": "A Note on Framing Criticisms of Effective Altruism", "postedAt": "2015-07-24T13:17:28.778Z", "htmlBody": "<html><body><div><em>Cross posted on zachgroff.com</em></div>\n<div><br></div>\n<div><span>This has been said, and better, by&#xA0;</span><a href=\"https://80000hours.org/2015/07/disagreeing-about-whats-effective-isnt-disagreeing-with-effective-altruism/\">Rob Wiblin</a><span>&#xA0;and others, but I&apos;m restating it here to draw attention to its implications. Many criticisms of effective altruism (even the excellent ones in this&#xA0;</span><a href=\"http://bostonreview.net/forum/logic-effective-altruism/peter-singer-reply-effective-altruism-responses\">Boston Review forum</a><span>) go like this:</span></div>\n<div><span><br></span></div>\n<div><span>1) X is important (or Y is unimportant).</span></div>\n<div><span>2) Effective altruism ignores X (or gives undue weight to Y).</span></div>\n<div><span>3) Therefore, effective altruism is flawed.</span></div>\n<div><span><br></span></div>\n<div><span>If the goal is to criticize the fundamental idea of EA, then I think these criticisms miss the mark. If (1) is really true, then all that implies is that EA should focus on X. If the goal is to criticize the EA community, then these criticisms are more on point, though there&apos;s a question of whether a community is defined by what its members do or by the fundamental ideas that unite them.</span></div>\n<div><span><br></span></div>\n<div><span>But similar points have been made by others, so I&apos;d like to focus on two reasons why the framing of these criticisms matters.</span></div>\n<div><span><br></span></div>\n<div><span>1) If they consciously adopted the role of internal critics to EA, those in favor of institutional reform, for instance, could be part of a serious debate within EA over whether focusing on policy advocacy is effective. This would not just be a more precise statement of the criticisms - it could improve EA more than an external criticism. More importantly, it could fill&#xA0;<a href=\"https://chrisblattman.com/2015/07/20/the-problem-with-evidence-based-policy-change-is-we-dont-have-evidence-on-the-important-policies/\">a gap in research on the effectiveness of policy advocacy</a>, something that would be edifying not just for EAs but for anyone who cares about evidence.</span></div>\n<div><span><br></span></div>\n<div><span>2) Framing the debate in this way could lead those who favor a systemic approach to realize their significant ability to impact the world. People who call for focusing on institutions often, it seems, take it as an excuse not to do much to address global problems. If it turns out that we can do more by focusing more directly on institutions than we can by donating to charity, this should call for those who care about policy to follow the EA movement in making a serious personal commitment to change the world.</span></div></body></html>", "user": {"username": "zdgroff"}}, {"_id": "7a854pgQJCefYJ3C3", "title": "Quick Thoughts on New Career Profiles on 80,000 Hours", "postedAt": "2015-07-24T02:51:34.472Z", "htmlBody": "<html><body><p>I recently received a newsletter from 80,000 Hours noting that new career profile pages had been posted on the 80,000 Hours site. Since I&apos;ve explored a couple of the careers mentioned there, I wanted to share some thoughts and ask some questions:</p>\n<p><strong>Data Science:</strong></p>\n<ul>\n<li>The career profile mentions that Zipfian Academy is a high-quality bootcamp which accepts people who don&apos;t have a science PhD. I know that lots of people from LW and EA have gone through App Academy&apos;s program and have recommended it; has anyone here attended Zipfian Academy?</li>\n<li>Has anyone gone to one of the other data science bootcamps?</li>\n</ul>\n<p>&#xA0;</p>\n<p><strong>Actuarial Science:</strong></p>\n<p>I&apos;m going to play devil&apos;s advocate here, rather than being balanced; I think that becoming an actuary could be a great choice for some effective altruists. Still, there are a few issues that weren&apos;t explicitly covered in the 80,000 Hours post on actuaries:</p>\n<ul>\n<li>Lots of the work that entry-level actuaries do could be automated in the future. Re-computing insurance rates for a given policy in a given state is sometimes just an issue of plugging new numbers into an old excel spreadsheet.</li>\n<li>I&apos;ve read a couple posts on actuarial forms complaining that there is a surplus of trainee actuary candidates. Posters sometimes complain that this is because of e.g. recent news articles which have (correctly) claimed that actuaries have high job satisfaction and high salaries.</li>\n<li>Actuaries typically spend about a fourth of their first 4-8 years of work obtaining a professional certification. If the field becomes deregulated, salaries for upper-level actuaries could drop substantially.</li>\n</ul>\n<p>&#xA0;</p>\n<p>&#xA0;</p>\n<p>&#xA0;</p></body></html>", "user": {"username": "Fluttershy"}}, {"_id": "GdMc3jrrRYqkJKyYJ", "title": "Giving What We Can's response to recent deworming studies", "postedAt": "2015-07-23T18:19:59.535Z", "htmlBody": "<html><body><p>Hi,</p>\n<p>we&apos;ve written a response to the recent deworming studies:</p>\n<p><a title=\"https://www.givingwhatwecan.org/blog/2015-07-23/deworming-really-effective-response-recent-deworming-studies\" href=\"https://www.givingwhatwecan.org/blog/2015-07-23/deworming-really-effective-response-recent-deworming-studies\">https://www.givingwhatwecan.org/blog/2015-07-23/deworming-really-effective-response-recent-deworming-studies</a></p>\n<p>Hauke :)</p></body></html>", "user": {"username": "HaukeHillebrandt"}}, {"_id": "34Yd6G4DcZbZCgBCZ", "title": "Meetup : .impact workathon: Toronto node", "postedAt": "2015-07-21T23:38:12.398Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/33\">.impact workathon: Toronto node</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>26 July 2015 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>11-96 Isabella St, Toronto</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>Show up, bring your laptop and do some stuff! There will be vegan cookies.</p>\n\n<p>.impact is a loose-knit community within the effective altruism movement, that brings volunteer power to some high-impact projects.</p>\n\n<p>Most of the work is at the computer - it can be writing or editing documents, design work, working on software projects and of course reading and cluing up.</p>\n\n<p>The emphasis is on getting stuff done, but no particular skills or experience are required. Come along even if you&apos;ve never heard of effective altruism - outsider perspectives are really valuable.</p>\n\n<p>As far as logistics go, I&apos;m planning on holding this at my apartment unless anyone has a better location. It can fit about 8. I&apos;ll need people to bring their laptops to work on. We&apos;ll be communicating with the rest of the .impact team over Google hangouts and Slack chatroom. (People in .impact are nice and you&apos;ll be welcomed warmly). If you need to show up half way through that&apos;s fine. I&apos;ll be throwing people out around 7.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/33\">.impact workathon: Toronto node</a></h2></body></html>", "user": {"username": "Giles"}}, {"_id": "jRdySxzmezcDZQrQJ", "title": "Iason Gabriel writes: What's Wrong with Effective Altruism", "postedAt": "2015-07-21T19:16:19.652Z", "htmlBody": "<html><body><p>We&apos;re always on the lookout for well-written critiques of effective altruism, and here&apos;s one that turned up recently.</p>\n<p>It&apos;s a paper by Iason Gabriel called <a href=\"https://www.academia.edu/13786913/Whats_Wrong_With_Effective_Altruism\">What&apos;s Wrong with Effective Altruism?</a></p>\n<p>I&apos;ll try and summarize its main points in my own words, but I&apos;d urge you to read the original.</p>\n<p>Related:</p>\n<ul>\n<li><a href=\"https://www.bostonreview.net/forum/logic-effective-altruism/iason-gabriel-response-effective-altruism\">Iason writes in the Boston Review</a></li>\n<li><a href=\"https://80000hours.org/2015/07/disagreeing-about-whats-effective-isnt-disagreeing-with-effective-altruism/\">Rob Wiblin responds (although not in detail) on the 80K blog</a></li>\n<li><a href=\"http://www.effective-altruism.com/ea/l7/why_the_triviality_objection_to_ea_is_beside_the/\">Stefan Shubert writes on this forum defending the &quot;thin&quot; version of EA against triviality objections</a></li>\n<li><a href=\"http://www.overcomingbias.com/2015/07/effective-altruism-complaints.html\">Robin Hanson says it&apos;s all about signalling</a></li>\n</ul>\n<p>The paper is not EA-bashing. It describes a model of what &quot;effective altruism&quot; actually means, looks at common objections to it and attempts to weigh each one in turn.</p>\n<h2>Description of effective altruism and background</h2>\n<blockquote>\n<p>Effective altruism encourages individuals to make altruism a central part of their lives, and combines this with a more specific commitment to do as much expected good as possible, typically by contributing money to the best-performing aid and development organizations. Effective altruists are also committed to the idea that scientific analysis and careful reasoning can help us identify which course of action is best.</p>\n</blockquote>\n<p><span>The paper also praises the EA movement for important successes: the establishment of new meta-charities, creating an incentive to demonstrate effectiveness, and drawing attention to the message that individuals in high-income countries have the power to do &quot;an incredible amount of good&quot;.</span></p>\n<p><span>Gabriel also makes an interesting claim about the dynamics of private donations vs. government aid, and how they can be influenced:</span></p>\n<blockquote>\n<p>the distortions that affect private giving are both more serious and less deeply entrenched than those that affect the distribution of aid. These distortions are more serious because only a tiny percentage of the money donated by individuals makes its way to the world&apos;s poorest people, where it would often do the most good. They are less entrenched because they often result from a lack of information, or carelessness, rather than from the pursuit of competing geopolitical aims. Taken together, these considerations suggest that there is an important opportunity for moral leverage</p>\n</blockquote>\n<p>Gabriel points out that EA has met with &quot;considerable resistance among aid practitioners and activists&quot; and that</p>\n<blockquote>\n<p>I believe that it can be explained both by the competitive dynamics that exist within the philanthropic sector and also by deeper disagreements about value.</p>\n</blockquote>\n<h2>Thick and thin versions of effective altruism</h2>\n<blockquote>\n<p>The thin version of the doctrine holds that &apos;we should do the most good we can&apos; [...] The thick version of effective altruism makes a number of further assumptions.</p>\n</blockquote>\n<p>These further assumptions can be summarized as:</p>\n<ul>\n<li>Welfarism: &quot;Good states of affairs are those in which suffering is reduced and premature loss of life averted.&quot;</li>\n<li>Consequentialism</li>\n<li>Scientific approach: &quot;It is possible to provide sound general advice about how individual people can do the most good&quot;</li>\n</ul>\n<p>The paper focusses on the thick version. It also (for reasons of space) leaves non-human animal issues aside.</p>\n<p>I&apos;m leaving most of my own remarks to the comments section, but I&apos;ll just point out here that the &quot;thick&quot; and &quot;thin&quot; versions of EA described by Gabriel don&apos;t <em>exactly</em> correspond to the &quot;core idea&quot; and &quot;associated ideas&quot; <a href=\"https://80000hours.org/2015/07/disagreeing-about-whats-effective-isnt-disagreeing-with-effective-altruism/\">described by Wiblin</a> in his response.</p>\n<h2>Is effective altruism unjust?</h2>\n<p><strong>Equality</strong>: the paper claims that while people in the EA movement recognize that equality is instrumentally important, most do not believe equality has any intrinsic value. This is illustrated with the <em>two villages</em> thought experiment:</p>\n<blockquote>\n<p>There are two villages, each in a different country. Both stand in need of assistance but they are unaware of each other and never interact. As a donor, you must choose between financing one of two programs. The first program allocates an equal amount of money to projects in each community and achieves substantial overall benefit. The second program allocates all of the money to one village and none to the other. By concentrating resources it achieves a marginally greater gain in overall welfare than the first project</p>\n</blockquote>\n<p>The claim in this example is that EAs prefer the second program, while people with &quot;an intuitive commitment to fairness&quot; prefer the first.</p>\n<p>Gabriel lists three possible responses EA could give to this criticism:</p>\n<ul>\n<li>Bite the bullet, and insist that equality has no independent weight (and that the second program in the example is better)</li>\n<li>Modify our utility functions to include a term for equality (although Gabriel doesn&apos;t quite put it in those words)</li>\n<li>Use equality as a tie-breaker</li>\n</ul>\n<p><strong>Priority</strong>: the paper makes the empirical claim that the very poorest people in the world are often particularly hard to help. It claims that while EA would tend to ignore such cases, many people believe they should be prioritized - either because meeting urgent claims first is a basic component of morality, or because of some need to justify state power.</p>\n<p>Again there is a thought experiment:</p>\n<blockquote>\n<p><em>Ultrapoverty</em>. There are a large number of people living in extreme poverty. Within this group, some people are worse-off than others. As a donor, you must choose between financing one of two development interventions. The first program focuses on those who will benefit the most. It targets literate men in urban areas, and has considerable success in sustainably lifting them out of poverty. The second program focuses on those who are most in need of assistance. It works primarily with illiterate widows and disabled people who live in rural areas. It also has some success in lifting these people out of poverty but is less successful at raising overall welfare.</p>\n</blockquote>\n<p>Gabriel points out that EA logic leads to supporting the literate men in this example, and that &quot;when this pattern of reasoning is iterated many times over, it leads to the systematic neglect of those at the very bottom - something that strikes many people as unjust.&quot;</p>\n<p>The possible responses listed are:</p>\n<ul>\n<li>Bite the bullet</li>\n<li>&quot;endorse a defeasible priority principle that would give the claims of the worst-off some priority over the claims of the better-off, even if a higher total utility could be achieved by focusing on the latter group of people&quot; (I don&apos;t quite understand what this means)</li>\n<li>Use priority as a tie-breaker</li>\n<li>(Regarding the state power argument) apply different moral principles to political institutions vs. private donors</li>\n</ul>\n<p><strong>Rights</strong>:the paper defines a right as &quot;a justified claim to some form of treatment by a person or institution that resists simple aggregation in moral reasoning&quot;. This is illustrated with the following example:</p>\n<blockquote>\n<p><em>Sweatshop</em>. The country you are working in has seen a rapid expansion of dangerous and poorly regulated factory work in recent years. This trend has helped lift a large number of people out of poverty but has also led to an increase in workplace fatalities. As a donor, you are approached by a group of NGOs who want to campaign for better working conditions. There is reason to believe that they can persuade the government to introduce new legislation if they have your financial backing. These laws would regulate the industry but reduce the number of opportunities for employment in the country as a whole.</p>\n</blockquote>\n<p>Gabriel claims that most EAs would refuse to support this campaign, and cites William MacAskill as saying there is &quot;no question that [sweatshops] are good for the poor&quot;. Gabriel argues that EAs could modify their theory to include independent weight to rights, but lists different possible outcomes for what this would mean for the <em>Sweatshop</em> case.</p>\n<h2>Is effective altruism blind?</h2>\n<p>Here Gabriel addresses the question of how the scientific method is put into practice within the effective altruism movement, and whether this introduces various forms of systematic bias. He starts off by describing how GiveWell and Giving What We Can evaluate their charities:</p>\n<ul>\n<li>assessing the scale of a problem</li>\n<li>looking for proven interventions to help with that problem</li>\n<li>looking for neglectedness</li>\n<li>audit of individual organizations</li>\n</ul>\n<p>And then comments:</p>\n<blockquote>\n<p>all but one of the &apos;top charities&apos; endorsed by GiveWell and GWWC focus on neglected tropical diseases (NTDs). They also make the movement vulnerable to the charge that it suffers from a form of methodological blindness.</p>\n</blockquote>\n<p><strong>Materialism</strong> (1): the claim that EA overvalues hard evidence such as RCTs</p>\n<p><strong>Materialism </strong>(2): the claim that EA in practice relies too much on metrics such as the DALY that ignore factors such as autonomy or self-actualization, that we care about in principle. He says that EA has been improving in this area but that more still needs to be done.</p>\n<p><strong>Individualism</strong>: the claim that EA undervalues collective goods such as community empowerment and hope. This is illustrated with another thought experiment, the claim being that allocating 10% to ARVs leads to more hope.</p>\n<blockquote>\n<p><em>Medicine</em>. According to recent estimates condom distribution is a far more effective way of minimizing the harm caused by HIV/AIDS than the provision of anti-retrovirals (AVR). Whereas ARVs help people who already have the virus, condoms help to prevent many more people from becoming infected. As a donor, you must choose between funding one of two National Action Plans. The first program allocates the entire sum of money to condom distribution. The second program allocates 90% to condom distribution and 10% to ARVs.</p>\n</blockquote>\n<p><strong>Instrumentalism</strong>: this point seems somewhat abstract and is again maybe best illustrated with Gabriel&apos;s example:</p>\n<blockquote>\n<p><em>Participation</em>. There are a group of villages that require help developing their water and sanitation system in order to tackle the problem of waterborne parasites. As a donor you face a choice between funding one of two projects. The first project will hire national contractors to build the water and sanitation system, something that they have done successfully in the past. The second project works with members of the community to develop and build new facilities. This approach has also worked in the past, but because villagers lack expertise their systems tend to be less functional than the ones built by experts.</p>\n</blockquote>\n<p>Gabriel&apos;s claim is that the community-based solution has better knock-on effects, such as greater autonomy and self-esteem, and valuing the community-built system more and hence maintaining it better. A simple cost-effectiveness estimate would overlook these.</p>\n<h2>Is effective altruism effective?</h2>\n<blockquote>\n<p>Effective altruists aim to make choices and life-decisions that do the greatest amount of overall good. This section asks how robust the advice they provide actually is.</p>\n</blockquote>\n<p><strong>Counterfactuals</strong>: in possibly the most interesting claim in the paper, Gabriel asks us &quot;if individual people who are affiliated with the movement stopped giving a portion of their income to the top charities: would larger philanthropic organizations simply step in and fill the gap?&quot;</p>\n<p>Gabriel raises the obvious question of why large donors such as the Gates foundation haven&apos;t already fully funded charities such as AMF and SCI. He gives three suggestions:</p>\n<ul>\n<li>The large donors aren&apos;t fully on board with the effectiveness thing</li>\n<li>Large donors may not feel that GiveWell and GWWC are doing their prioritization research correctly</li>\n<li>The EA movement is cute and needs to be supported in its growth by giving it some nice charities to play with (not Gabriel&apos;s exact words)</li>\n</ul>\n<p>In support of the third claim, Gabriel points out that GiveWell is able to fully fund its top charities via Good Ventures, but has chosen not to do so. If true, it&apos;s fairly obviously problematic for us.</p>\n<p><strong>Motivation and rationality</strong>: the claim is that to make it big, EA needs to understand psychology, and that we don&apos;t. In particular:</p>\n<ul>\n<li>Gabriel refers to David Brooks as saying that an earning-to-give career might not be psychologically sustainable for most people - even if it is for a few EAs.</li>\n<li>EA appeals too much to reason and not enough to emotion.</li>\n</ul>\n<p><strong>Systemic change</strong>: the claim here is that EA could stand to learn from historical movements such as abolitionism and civil rights - in particular putting a greater focus on justice, and less on cost-effectiveness or on the feel-good factor of giving.</p>\n<p>&#xA0;</p>\n<p><a href=\"https://www.academia.edu/13786913/Whats_Wrong_With_Effective_Altruism\">Read the full paper here</a>. I feel my own thoughts on this belong in the comments section so I&apos;ll add them there.</p>\n<p>Also note that I&apos;m not Iason Gabriel.</p></body></html>", "user": {"username": "Giles"}}, {"_id": "TXSe2Zqft8238EuA5", "title": "Peter's 2015 Q2 Personal Review", "postedAt": "2015-07-21T18:17:04.171Z", "htmlBody": "<html><body><p>In the past, <a href=\"http://peterhurford.tumblr.com/post/115870806686/list-of-my-personal-reviews\">I&#x2019;ve been reviewing myself on a quarterly basis</a> to track my progress against my goals. Again, I&#x2019;m here to inventory my goals and projects, explain how I&#x2019;ve accomplished them (or fallen short) throughout 2015 Q2, and then elaborate plans, goals, and projects for 2015 Q3. This is largely in response to <a href=\"/ea/i0/peters_2015_q1_personal_review/\">my previous review</a>.</p>\n<p><em>Note that despite this review being posted so late in July, it only covers the time period of 1 Apr 2015 through 1 Jul 2015. I have not added any additional information about things that have happened after 1 Jul. I&#x2019;ll endeavor to start doing these earlier, in the future.</em></p>\n<p>&#xA0;</p>\n<h2>My Day Job</h2>\n<p>I still work as a data scientist at a start-up in Chicago.</p>\n<p>&#xA0;</p>\n<p><strong>Q2 Goals</strong></p>\n<p>My core goal was to think harder about improving as a programmer. I did that in <a href=\"https://gist.github.com/peterhurford/894b4e919b3e4a4836aa\">&#x201C;One Year Out: How I Became a Better Programmer&#x201D;</a>.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Right</strong></p>\n<p>As of the end of 2015 Q1, I&#x2019;ve now been programming professionally for one year -- three months as a software engineering intern and nine months as a Data Scientist.</p>\n<p>In the past reviews, I&#x2019;ve always looked back and admired how I&#x2019;ve been improving at becoming a better programmer. This quarter is no different.</p>\n<p>I studied writing good code more seriously this quarter, doing many of the things I suggest in <a href=\"https://gist.github.com/peterhurford/894b4e919b3e4a4836aa\">&#x201C;One Year Out: How I Became a Better Programmer&#x201D;</a> -- reading books and pair programming.</p>\n<p>I also started branching into learning the beginnings of new programming languages, as seen in <a href=\"https://github.com/peterhurford/polygot-euler\">my attempt to solve Project Euler problems in many different popular programming languages</a>. I&#x2019;d eventually like to get to the point where I can start using programming languages because they&#x2019;re the right tools for the job, rather than just because I&#x2019;m comfortable with them.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Wrong</strong></p>\n<p>I spent much of this quarter caught up in a project that was supposed to be three weeks long, but dragged on to take over two months. I still firmly believe the reason for this is not my fault (and, to be fair, no one at the company seems to put any blame on me, even though people are annoyed). The task just required a lot more infrastructure changes than we first anticipated, and I fell down quite a few long roads of things that ended up not working.</p>\n<p>Every step it seemed like this would be the last hard step and the rest would come quickly. And I would be pretty good about not wasting too much time on any individual step and making sure to get help. But sure enough, once that step was complete, the next step would also be really hard. I didn&#x2019;t really figure out the whole meta-system until it was too late.</p>\n<p>Ideally, had I recognized this earlier, I could have substituted the project for something much simpler to &#x201C;buy myself some time&#x201D; to figure out the more difficult stuff. However, this wasn&#x2019;t as bad as the two months wasted from Q1, since (a) this hasn&#x2019;t been as long and (b) it hasn&#x2019;t been nearly as avoidable in retrospect.</p>\n<p>To dwell on things that are under my control, I think I&#x2019;d like to focus more on getting back on the road and doing things. I can handle projects that slog on, but I&#x2019;m far happier if I also allow time to do projects that go quickly and carry with them opportunities for innovating technically and solving challenging projects.</p>\n<p>&#xA0;</p>\n<p><strong> Q3 Goals </strong></p>\n<p>I&#x2019;ve introduced a metric called &#x201C;number of times a technical innovation has taken place within my day job work&#x201D; and I&#x2019;m going to aim to aim for at least three a week. I don&#x2019;t know if you can force innovation by making a goal for it, but it does seem a lot better than measuring hours and I think it will help me fight the tendency in myself to allow my days to slog on and just become a day of meetings where nothing of substance gets done.</p>\n<p>Another thing I&#x2019;d like to do is learn more about how we put predictive models into production. This seems like a useful skill with a lot of opportunities, but I don&#x2019;t understand it as well as I should. Now that I&#x2019;ve done a lot of work on gathering data, munging data, and fitting models to data, I want to complete the last part and earn the title &#x201C;full-stack data scientist&#x201D;.</p>\n<p>I&#x2019;m also still going to try to learn more about programming, but I&#x2019;m moving that into my next section about learning goals.</p>\n<p>&#xA0;</p>\n<h2>Secret Entrepreneurship Projects</h2>\n<p>Since Sep 2014, I have been working with two friends, fiddling around with several different project ideas, exploring entrepreneurship. By Q2, we had two core projects to focus on: (1) a framework in R for developing predictive models more quickly and (2) another product. I&#x2019;d say more, but I still legally can&#x2019;t.</p>\n<p>&#xA0;</p>\n<p><strong> Q2 Goals</strong></p>\n<p><strong> Launch the modeling software project as an invite beta ASAP [fail].</strong> We did not successfully launch the predictive modeling framework project as we ended up prioritizing the other project instead.</p>\n<p><strong> Launch the modeling software project as an open beta before the end of Q2 [fail].</strong></p>\n<p><strong> Be more confident that the other project is actually launchable [success].</strong> We ended up getting a real lawyer and paying a lot of money to find out that this sort of thing seems reasonably possible. I still have no idea how far it can go, though.</p>\n<p><strong> Move total revenue to &gt;$1K [success].</strong> We met this goal, but I&#x2019;m not really in a position to say how or why on a website that anyone can read.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Right</strong></p>\n<p>During Q2 we really hit our stride with being able to devote a significant amount of time every week to moving our projects forward -- it&#x2019;s just that our projects ended up taking more time than anticipated.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Wrong</strong></p>\n<p>Nothing really went wrong this time around -- I think we worked on our projects to the best of our ability given our various constraints. For the predictive modeling project, we made the choice to do more programming work on it before deciding to release it and then we made the choice again to put it on hold to try and get the other project to the point where we could see if people are interested.</p>\n<p>Now that the second project is getting to the point where it needs more business development than technical development, we can circle back and try to finish the first project. And if it makes sense, we might even try to finish some projects that we considered earlier than that.</p>\n<p>&#xA0;</p>\n<p><strong> Q3 Goals</strong></p>\n<p>&#xA0;</p>\n<ul>\n<li>Launch the modeling software project.</li>\n<li>Figure out whether the other project will work.</li>\n</ul>\n<p>&#xA0;</p>\n<p>&#xA0;</p>\n<h2>Learning</h2>\n<p>In Q2, I&#x2019;ve been learning R programming (to get better at my job), mathematics (to get better at my job), and Chinese. The Chinese is a fun hobby and helps me bond with my girlfriend who is fluent in Chinese.</p>\n<p><strong> Q2 Goals </strong></p>\n<p><strong>Finish Advanced R [semi-fail].</strong> I finished 55% of Hadley Wickham&#x2019;s <a href=\"http://adv-r.had.co.nz/\">Advanced R</a> during Q1 and I wanted to finish the other 45% within Q2. Unfortunately, I did not realize how long the last 45% would take or how little time I&#x2019;d have in the end of Q2, so I only made it an additional +16%. I&#x2019;m still happy with my progress here, though.</p>\n<p><strong>Finish R Packages [success].</strong> At the end of Q1, I was 33% through Wickham&#x2019;s <a href=\"http://r-pkgs.had.co.nz/\">R Packages</a>. I&#x2019;ve now finished the book and <a href=\"https://gist.github.com/peterhurford/f71bf00d8866094eac6c\">wrote up notes</a>.</p>\n<p><strong> Master &gt;75% of Khan Academy&#x2019;s Algebra II [semi-fail].</strong> By Q1, I had &#x201C;mastered&#x201D; 40% of <a href=\"https://www.khanacademy.org/mission/algebra2\">Algebra II on Khan Academy</a>. I thought that with enough of a push, I could finish the remaining 60% and move on. Unfortunately, this turned out to be far from the case, given how often Khan Academy forces you to review. By the time I had &#x201C;mastered&#x201D; 50%, the review became unbearable. I also started feeling that I was losing out conceptually and not spending enough time on the bigger picture. So I decided to move onto learning Calculus instead.</p>\n<p><strong>Have &gt;300 words in long-term memory on Memrise [semi-fail].</strong> I ended up abandoning Memrise. I decided that I&#x2019;d rather just learn on Skritter, because the mobile app was much better and the two were overlapping more than I had thought.</p>\n<p><strong>Learn &gt;75 words on Skritter [smashing success].</strong> In Q2 I actually reached 112 words learned, 86% more than I thought I would learn.</p>\n<p><strong> Finish the <a href=\"https://www.coursera.org/learn/learn-chinese\">Chinese 101 Coursera class</a> [semi-fail].</strong> I ended up finding the course too basic and I kept getting annoyed at Coursera&#x2019;s new verifications process. Instead, I got enamored with <a href=\"http://english.cntv.cn/program/learnchinese/growingwithchinese/\">Growing Up with Chinese</a>, in which I completed the first fourteen lessons.</p>\n<p><strong>Complete &gt;5 more lessons in Rocket Chinese [semi-fail].</strong> I only completed three additional lessons, not six.</p>\n<p>&#xA0;</p>\n<p><strong>What Went Right </strong></p>\n<p>The biggest success was switching to learning Skritter on the mobile app rather than the web application, which both expanded the amount of time I could spend practicing Chinese and expanded my motivation to actually do so. Now I can mess around with the mobile app when I&#x2019;m waiting in line or on the subway.</p>\n<p>Another thing I was happy with was figuring out what the best resources are for me, so that I spend more time focusing on good, non-overlapping resources and less time focusing on bad resources. For example, the Coursera class was good in the beginning, but quickly became too basic.</p>\n<p>Overall, this created a good workflow for me where I could listen to Chinese audio lessons on my walk to the subway and use Skritter while actually on the subway. Given a commute of 30min each way over five days, that would be five hours of Chinese practice I could do each week without sacrificing any &#x201C;productive&#x201D; time. In practice, though, I tend to be less motivated to actually do this every commute, especially in the evenings.</p>\n<p>Similar logic applies for my goals of learning math or programming, though these are not possible to do while computing, because they require enough space on the subway to sit down and open a laptop, which I rarely have. <br><strong> </strong></p>\n<p>&#xA0;</p>\n<p><strong>What Went Wrong</strong></p>\n<p>Again, my progress was not particularly steady. I guess this is to be expected as motivation comes and goes and other pressing life events come in. Toward the end of Q2 I moved to a new apartment, which was quite draining across the board in allocating time to learning. Also, as I got more and more tied up in my current work project that was dragging on, I spent less and less time at work learning, eventually dropping things down to zero.</p>\n<p>Lastly, my goals for Q2 ended up being too ambitious, again. I think this time I&#x2019;m going to set my official goals at 50% of what I think I can do. I expect that once reality sets in, those 50% goals will turn out to be stretch goals. ;)</p>\n<p>&#xA0;</p>\n<p><strong>Q3 Goals </strong></p>\n<p><strong>Finish Advanced R.</strong> For real this time.</p>\n<p><strong>Learn Haskell.</strong> A co-worker of mine is offering a twice weekly Haskell course at our work and I&#x2019;ve been enjoying it so far. It should complete by the end of Q3. I&#x2019;ll also supplement by skimming <a href=\"http://learnyouahaskell.com/\">&#x201C;Learn You a Haskell&#x201D;</a>. Together, these two things should set me up to try professional Haskell development by Q4.</p>\n<p><strong>Learn Calculus.</strong> I want to complete the <a href=\"https://www.coursera.org/learn/calculus1\">Calculus I</a> course on Coursera. I also want to complete <a href=\"http://ocw.mit.edu/resources/res-18-001-calculus-online-textbook-spring-2005/textbook/\">Strang&#x2019;s Calculus textbook</a> after, but I doubt I&#x2019;ll finish that by the end of Q3.</p>\n<p><strong>Learn Statistics</strong> by reading through <a href=\"http://www-bcf.usc.edu/~gareth/ISL/\">&#x201C;Introduction to Statistical Learning&#x201D;</a>. I think I can get through Chapter 4 by the end of Q3. That would put completing the book by the end of 2016 Q1.</p>\n<p><strong>Learn Chinese.</strong> I&#x2019;ll try to learn 40 more words on Skritter, complete three more lessons on Rocket Chinese, and complete through lesson 17 on Growing up with Chinese.</p>\n<p><strong>Learn Cooking.</strong> I&#x2019;m not sure how I&#x2019;ll go about doing this yet. I&#x2019;d like to explore a bit before setting concrete goals. But I&#x2019;m sure I&#x2019;ll enjoy reading <a href=\"http://smile.amazon.com/The-4-Hour-Chef-Learning-Anything/dp/0547884591?sa-no-redirect=1\">The Four Hour Chef</a>.</p>\n<p>&#xA0;</p>\n<h2>Personal Health / Exercise</h2>\n<p>More important than nearly anything to a healthy and productive life is really nailing the core three: exercise, sleep, and food. Unfortunately, I&#x2019;ve struggled with these three so far my entire life.</p>\n<p>&#xA0;</p>\n<p><strong> Q2 Goals</strong></p>\n<p><strong> Get to work by 9:30am more often than not.</strong> This didn&#x2019;t happen, but I&#x2019;m not convinced that&#x2019;s a bad thing.</p>\n<p><strong> Go to gym at least once a week and running at least once a week.</strong> This did not happen either due to one week being very dominated by moving and another week being very dominated by trying to move the start-up idea forward. Overall, going to the gym and running both increased significantly, however.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Right</strong></p>\n<p>For the first time in a long time (perhaps ever), I&#x2019;m cautiously happy with my diet, sleep, and exercise habits.</p>\n<p>For diet, just like last quarter, I&#x2019;m still very happy with the health of my current, vegetarian diet. I think putting it on Beeminder helped me keep it consistent and see that I do have some weakness in not eating enough fruit, which I think I can easily address.</p>\n<p>For exercise, I got to the gym and I went running much more than I did last quarter, though the habit still was not that regular and not as consistent as I would like. I think the time I go to the gym matters a lot for whether I&#x2019;ll actually do it. Previously, I would try to go during the middle of my workday, which didn&#x2019;t work very well because I would often get stuck in an unexpected meeting or feel like I should finish a particular project instead of leaving. So instead I moved my gym time to the end of the workday. This ended up being phenomenally successful until I started getting in the habit of staying at work until after the gym closed or going immediately from work to working on the start-up. I&#x2019;d love to try going before the workday, but I&#x2019;m not that motivated in the morning...</p>\n<p>For sleep, I finally got to a position where I was not constantly oversleeping and feeling crappy in the morning all the time. However, I still have not fallen into a consistent sleep schedule. Instead, I&#x2019;ve had two sleep schedules -- one really late, going to bed around 1:30am and waking up around 9:30am, and one really early, waking up around 6:30am and going to bed around 10:30pm. The early morning schedule feels the most virtuous to me and syncs better with the people I care about (and work), but -- as much as I hate to say it -- the late schedule is overall more productive for me and feels better. I&#x2019;m not really sure why that is.</p>\n<p>More generally, I think committing to less ambitious goals helped, since I ended up overshooting my less ambitious exercise goal all the way to be being better than my previous best. And I think <a href=\"http://www.beeminder.com/\">Beeminder</a> helps a lot for goal tracking and keeping the goals in my mind. What I did have trouble with, though, was maintaining a consistent definition of a goal, especially with regard to my shifting sleep schedule.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Wrong</strong></p>\n<p>I wouldn&#x2019;t say anything in particular went wrong, though it would be nicer to have a more consistent sleep and exercise schedule.</p>\n<p>I bought a <a href=\"http://www.amazon.com/Philips-HF3520-Wake-Up-Colored-Simulation/dp/B0093162RM?tag=s4charity-20\">wake-up light</a>, but it didn&#x2019;t seem to help much at all beyond the first week. I think I just adapted to it. Eventually I moved into a new apartment with a window with actual light from the outside and I think that&#x2019;s been helping more recently.</p>\n<p>I didn&#x2019;t end up trying to go to the gym regularly with a friend and I didn&#x2019;t put any additional effort into improving my diet by preparing food in advance.</p>\n<p>&#xA0;</p>\n<p><strong> Q3 Goals</strong></p>\n<p>Honestly, if I could keep things where they are at or improve on them even a little bit, I&#x2019;d be pretty happy.</p>\n<p>&#xA0;</p>\n<h2>.impact and Charity Science</h2>\n<p><a href=\"http://www.charityscience.com\">Charity Science</a> is a Canadian-based non-profit that aims to increase public awareness of GiveWell&#x2019;s recommendations and to figure out the best ways to effectively fundraise on their behalf.</p>\n<p><a href=\"http://www.dotimpact.im\">.impact</a> is a decentralized network of volunteers working on EA projects.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Right</strong></p>\n<p>My goal for Q2 was to not get too involved in Charity Science or .impact so I could keep my focus. I succeeded in that goal and both organizations ended up doing very well anyway!</p>\n<p>The biggest victory here was delegation. I helped find and coordinate new volunteers to work on EA projects, including the EA Forum. I created a list of possible volunteer projects we&#x2019;re still looking for people to cover. Ozzie and Haseeb ended up organizing a workathon structure on Sundays for people to contribute their time and we&#x2019;ve seen a large spike in people&#x2019;s contributions. Huzzah!</p>\n<p>Charity Science ended up doing cool things too, but I don&#x2019;t really have much basis to take credit for any of it. I&#x2019;ll let them tell you more about it soon. It also involved doing very well with delegating to volunteers.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Wrong</strong></p>\n<p>No particular mistakes to note on my behalf, mainly because I didn&#x2019;t do anything personally other than delegate. ;)</p>\n<p>&#xA0;</p>\n<h2>New Apartment</h2>\n<p>I moved to a new apartment; my third apartment in twelve months.</p>\n<p>&#xA0;</p>\n<p><strong>What Went Right</strong></p>\n<p>This move was a good one for my long-term productivity and social happiness, because I now have a space that is large enough I don&#x2019;t go stir crazy and that I can work from a desk and a chair instead of from my bed. I&#x2019;ve already noticed a good deal of productivity increase since I finished my move and it allows me to have guests over, which is pretty awesome.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Wrong</strong></p>\n<p>Unfortunately, however, the flip side of this was that I needed to devote about two full-time weeks to (a) looking for apartments (including conducting a wider apartment search than I&#x2019;ve ever done before to see what I really want in an apartment), (b) signing the lease (which ended up having complications), (c) packing up all my belongings, (d) moving all my belongings, (e) unpacking all my belongings, and (f) setting up the space (including furnishing it with more furniture than just a bed!).</p>\n<p>I&#x2019;m happy with how all these steps went. In particular, I was grateful to help from my girlfriend for help with looking for apartments, unpacking my belongings, and helping me set up the space. I&#x2019;m also grateful to my friend Josh for help with moving my belongings.</p>\n<p>&#xA0;</p>\n<p><strong> Q3 Goals</strong></p>\n<p>I&#x2019;d like to not move again for at least another year.</p>\n<p>&#xA0;</p>\n<h2>Reading</h2>\n<p><strong> Q2 Goals</strong></p>\n<p>I had three goals mainly focused on consolidating knowledge I already had.</p>\n<p><strong> Expanding summaries of <a href=\"http://peterhurford.com/other/reading.html\">books that I&#x2019;ve read and liked</a> [goal abandoned]</strong></p>\n<p><strong> completing an organized document with <a href=\"http://peterhurford.tumblr.com/post/108765371191/links-when-i-feel-like-it-29\">all of my link posts</a> [goal abandoned]</strong></p>\n<p><strong> completing more links posts [partial success]</strong> -- I finished <a href=\"http://peterhurford.tumblr.com/post/123351181616/links-when-i-feel-like-it-34\">one</a>.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Wrong</strong></p>\n<p>I didn&#x2019;t focus much in this area, instead allocating capacity to my other areas which needed it more. In Q2 I read five books, all on Audible (down from 11 finished in Q1). I generally found myself less motivated to read books as I found I was hitting diminishing marginal returns. Instead, I allocated my listening time toward Chinese lessons and <a href=\"http://www.gimletmedia.com\">listening to podcasts</a>.</p>\n<p>I had hoped to spend a good deal of time working to consolidate knowledge from the books and links I had already read, but this turned out to require more productive time than I anticipated (I couldn&#x2019;t just do it casually while commuting) and I was already stretched for time as it was.</p>\n<p>&#xA0;</p>\n<p><strong> Q3 Goals </strong></p>\n<p>There&#x2019;s a large unsolved problem in how to actually apply the skills that you learn, so that they&#x2019;re integrated in your life in a deeper way than just being something you know surface-level. I think Paul Graham is somewhat right that <a href=\"http://www.paulgraham.com/know.html\">this happens automatically</a>, but I still can recall many times in my life where I&#x2019;ve failed to apply something I had already learned and would have benefited had I actually applied it.</p>\n<p>Given that my capacity is already stretched and that I don&#x2019;t have a lot of ideas at the moment, I think I&#x2019;d like to spend another quarter just ruminating generally on how to approach this problem, with the goal of producing concrete Q4 goals in this area.</p>\n<p>&#xA0;</p>\n<h2>Social Life</h2>\n<p>I want to include reflecting on my social life as a part of this guide because it&#x2019;s important to me, but I don&#x2019;t want to say too much here in order to respect privacy and because reviewing it this way still makes me feel weird.</p>\n<p>&#xA0;</p>\n<p><strong> Q2 Goal</strong></p>\n<p>My big goal here was to figure out a system for improving my consistency in communication with everyone I want to be in touch with. <a href=\"http://peterhurford.tumblr.com/post/123224704966/my-simple-plan-for-staying-in-touch-with-people\"> I hastily put one together at the end of the quarter. </a> It&#x2019;s working reasonably well so far, so I call that a success.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Right</strong></p>\n<p><strong> My girlfriend:</strong> I think our relationship overall continues to grow stronger. Soon she&#x2019;ll be moving closer (but still long-distance) and I should be able to see her every other weekend, which will be great. We&#x2019;re also seeing each other a lot over the summer before she starts her job.</p>\n<p><strong>My parents:</strong> I&#x2019;m still calling them regularly. I am excited to visit them in person for the 4th of July. I hope that they&#x2019;ll come up and visit my new apartment sometime soon.</p>\n<p><strong> My brother:</strong> I&#x2019;ve been keeping in touch regularly with my brother as well. I will visit him on the 4th of July and I will be seeing him again soon at Gen Con.</p>\n<p><strong> Local friends:</strong> Also going well, but overall a dip from the previous quarter, due to me being busier. I have new friends who have recently moved to Chicago who I hope to see as well. I&#x2019;ve been in touch with some of them to schedule a time to hang out. My Q3 goal will be to hang out with all of them.</p>\n<p><strong>Distant friends:</strong> This has been going better as I&#x2019;ve been trying to keep more in contact with people over Facebook and the phone.</p>\n<p>&#xA0;</p>\n<p><strong> What Went Wrong</strong></p>\n<p>I want to involve my girlfriend more in my day-to-day life and I&#x2019;m struggling to (a) remember that when I make plans and (b) figure out how to do that.</p></body></html>", "user": {"username": "Peter_Hurford"}}, {"_id": "6PHSwNbNaxfoMK88J", "title": "Moving Moral Economics Forward", "postedAt": "2015-07-21T03:26:41.814Z", "htmlBody": "<html><body><h2><span>Moving Moral Economics Forward</span></h2>\n<p>&#xA0;</p>\n<address><span>In these writings we propose the creation of a </span><span>sub-field</span><span> of knowledge, Moral Economics, and provide in broad strokes its characteristics. We assemble previous writings that can be considered prospective subfields. We also discuss several concepts that have been developed in recent years that are instrumentally useful for Moral Economic thinking, and propose several new ones that could also bear fruit if the study of this area develops further in the future. </span></address>\n<p>&#xA0;</p>\n<ol>\n<li>\n<p><a href=\"/ea/ky/introducing_moral_economics/\"><span>Introducing Moral Economics</span></a></p>\n</li>\n<li>\n<p><a href=\"/ea/l1/moral_economics_concepts/\"><span>Examples of Moral Economics Concepts</span></a></p>\n</li>\n<li>\n<p><a href=\"/ea/l1/moral_economics_concepts/\"><span>Branches Within Moral Economics</span></a></p>\n</li>\n<li>\n<p><span><a href=\"/ea/l9/moving_moral_economics_forward/\"><strong>Moving Moral Economics Forward</strong></a></span></p>\n</li>\n<li>\n<p><a href=\"/ea/lg/direct_funding_between_eas_moral_economics/\">Direct Funding Between EAs</a></p>\n</li>\n<li>\n<p><span>Certificates of Impact, Doing It Right - Giles Edkins</span></p>\n<ol>\n<li>\n<p><span>Moral market failure: how COIs might help</span></p>\n</li>\n<li>\n<p><span>Problems with COIs, and their solutions</span></p>\n</li>\n<li>\n<p><span>Implementing COIs</span></p>\n</li>\n</ol></li>\n<li>\n<p><span>Agential Identity in Moral Economics</span></p>\n</li>\n</ol>\n<div><span>\n<h2><br></h2>\n<h2><span>Why Call This the Creation of a Subfield?</span></h2>\n<p><span><strong><br></strong></span></p>\n<p><span>The intuition behind this I take from conversations with Duncan Germain, Stuart Russell, Davi Mamblona, Geoff Anders, where I got the intuition that the announcement of a field is a great way to generate a memetic attractor around an idea which permits people to look at it in a new light, as has happened to parkour, pilates, hiking, planking, memetics and others. For instance Bostrom starts his Hail Mary paper: </span></p>\n<ul>\n<li>\n<p><span>In the field of superintelligence control studies, which focuses on how to ensure that a hypothetical future superintelligent system would be safe and beneficial, two broad classes of approaches to the control problem can be distinguished: capability control methods and value selection methods.</span></p>\n</li>\n</ul>\n<p><span>In seven words and a stroke of genius, he created a precedent that I find of immense value. He created a field of study. I have already cited this passage in papers and writings of mine, and now others too can refer to superintelligence control as a field. My conversations with Stuart Russell (and many grad students) have the goal of creating an AI safety engineering course at Berkeley, to set the precedent for some of the 1500+ universities that use his AIMA textbook to also have that course. You can imagine how happy I was to see the first words of Bostrom&#x2019;s paper. I literally grinned for some ten seconds. Academics are strange. </span></p>\n<h2><span>Moving Moral Economics Forward</span></h2>\n<p><span><strong><br></strong></span></p>\n<p><span>There is ample room to consider other items in the moral economic cluster that are worth exploring but were not thought of by any of the cited texts or editors of this writing. Taking a </span><a href=\"http://economicsforeveryone.ca/files/uploads/glossary_0.pdf\"><span>glossary of economics</span></a><span>, I can see within Moral Economics parallels with interesting and different properties to the following concepts: </span></p>\n<p><span><strong><br></strong></span></p>\n<ul>\n<li>\n<p><span>Accelerator</span></p>\n</li>\n<li>\n<p><span>Bank</span></p>\n</li>\n<li>\n<p><span>Bond</span></p>\n</li>\n<li>\n<p><span>Moral Capital Gain</span></p>\n</li>\n<li>\n<p><span>Conditionality</span></p>\n</li>\n<li>\n<p><span>Cost of Job Loss</span></p>\n</li>\n<li>\n<p><span>Credit</span></p>\n</li>\n<li>\n<p><span>Moral Debt (see e.g. Lakoff 1997)</span></p>\n</li>\n<li>\n<p><span>Inflation</span></p>\n</li>\n<li>\n<p><span>Deflation</span></p>\n</li>\n<li>\n<p><span>Depreciation (see e.g. Haste consideration above)</span></p>\n</li>\n<li>\n<p><span>Dividend</span></p>\n</li>\n<li>\n<p><span>Effective Demand (is it approximately unbounded? unlike classical demand?)</span></p>\n</li>\n<li>\n<p><span>Externalities</span></p>\n</li>\n<li>\n<p><span>Finance</span></p>\n</li>\n<li>\n<p><span>Gross Moral Domestic Product (How much moral good did an entity generate)</span></p>\n</li>\n<li>\n<p><span>Inequality (who are the Moral 1%?) </span></p>\n</li>\n<li>\n<p><span>Interest</span></p>\n</li>\n<li>\n<p><span>Labor extraction</span></p>\n</li>\n<li>\n<p><span>Macroeconomics</span></p>\n</li>\n<li>\n<p><span>Microeconomics</span></p>\n</li>\n<li>\n<p><span>Multiplier</span></p>\n</li>\n<li>\n<p><span>Moral Poverty</span></p>\n</li>\n<li>\n<p><span>Profit</span></p>\n</li>\n<li>\n<p><span>Public Goods</span></p>\n</li>\n<li>\n<p><span>Moral recession</span></p>\n</li>\n<li>\n<p><span>Shares</span></p>\n</li>\n<li>\n<p><span>Supply-constrained (more frequent in moral economics) </span></p>\n</li>\n<li>\n<p><span>Value Added</span></p>\n</li>\n</ul>\n<p><span><br><br><span><span> </span></span><span>All of these would behave in interesting and different ways in altruistic economics or moral economics - go back and try yourself to envision the differences. However, economics is not my field of expertise, so I can only show some of the pointers but not develop the concepts in full. This is a job for economists. As Bertrand Russell would say, one job of philosophy is to ask questions about what we don&#x2019;t know and create ways for that to become knowable. Much of philosophical progress was the creation of what today are considered sciences. In </span><a href=\"http://www.amirrorclear.net/academic/papers/moral-trade.pdf\"><span>Moral Trade</span></a><span>, Toby Ord has set the ground for this to happen once again, I suggest we follow suit and begin exploring this unknown scientific territory.</span></span></p>\n</span> \n<hr>\n</div>\n<div>In the next piece in the Moral Economics Series we take a closer look at Direct Funding Between EAs, a valuable idea that has not received a lot of attention so far within the Effective Altruist community, yet holds interesting promise as a way to generate altruistic value.&#xA0;</div>\n<div><br></div>\n<div>How do you think some of the concepts above would be seen from a Moral Economics perspective? How do they differ between trade and Moral Trade?&#xA0;</div></body></html>", "user": {"username": "Diego_Caleiro"}}, {"_id": "aHSJsZEAMdRys4Ncj", "title": "Effective Altruism Global SF panel on AI: question submissions thread", "postedAt": "2015-07-20T19:34:10.822Z", "htmlBody": "<html><body><p>On August 1, I&apos;ll be moderating a panel at <a href=\"http://www.eaglobal.org/googlehq\">EA Global</a> on the relationship between effective altruism, astronomical stakes, and artificial intelligence. The panelists will be Stuart Russell (UC Berkeley), Nick Bostrom (Future of Humanity Institute), Nate Soares (Machine Intelligence Research Institute), and Elon Musk (SpaceX, Tesla). I&apos;m very excited to have this conversation with some of the leading figures in AI safety!</p>\n<p>As part of the panel, I&apos;d love to ask our panelists some questions from the broader EA community. To that end, <strong>please submit questions below</strong>&#xA0;that you&apos;d like to be considered for the event. I&apos;ll be selecting a set of these questions and integrating them into our discussion. I can&apos;t guarantee that every question will fit into the time allotted, but I&apos;m confident that you can come up with some great questions to facilitate high-quality discussion among our panelists.</p>\n<p>Thanks in advance for your questions, and looking forward to seeing some of you at the event!</p></body></html>", "user": {"username": "Daniel_Dewey"}}, {"_id": "8SA5LniqnQGYKYTi6", "title": "Why the triviality objection to EA is beside the point", "postedAt": "2015-07-20T19:29:13.261Z", "htmlBody": "<html><body><p><span><span>Robert Wiblin recently wrote a good post with the self-explanatory title&#xA0;<a href=\"https://80000hours.org/2015/07/disagreeing-about-whats-effective-isnt-disagreeing-with-effective-altruism\">&quot;Disagreeing about what&#x2019;s effective isn&#x2019;t disagreeing with effective altruism&quot;</a></span></span><span>. At the end, there is one parapgrah which I think concedes too much, however, regarding the triviality of the EA message. He writes:</span></p>\n<blockquote>\n<p><span>&#xA0;Have I now defined &#x2018;effective altruism&#x2019; to be so obvious that nobody could challenge it?</span></p>\n</blockquote>\n<p><span>Here he seems to agree that <em>if</em> this were the case, then that would be a problem. However, he then goes on to argue that this isn&apos;t in fact the case - people do challenge the EA message, even if we understand it in his thin sense (as trying to do the most good you can, using analysis and evidence).<br></span></p>\n<p><span><span>I guess it&apos;s true that some people do challenge the EA message, but I don&apos;t agree with the notion that it would be a problem if that weren&apos;t the case.&#xA0;</span></span><span>It would be if we were at an <em>academic seminar</em>,&#xA0;trying to argue for a philosophical thesis. Philosophical theses shouldn&apos;t be trivial or obvious. We are not at an academic seminar, however - we are trying to&#xA0;</span><em>change the world</em><span>. And in the real world, lots of altruistic work isn&apos;t remotely effective. This includes </span><em>lots of work done by people who would agree that it is obviously true that you should be effectively altruistic if asked</em><span>. It is one thing to intellectually agree that you should be effectively altruistic, if someone asks you that question. It is </span><em>quite</em><span> another thing to actually be effectively altruistic. In order to be so, I would guess you need to be constantly reminded of the necessity of thinking about evidence and cost-effectiveness.</span></p>\n<p><span>Here I think the EA movement has a very substantial role to play.&#xA0;</span><span>My hypothesis is thus that the EA message is very fruitful <em>even</em> though it may be philosophically trivial. M</span><span>y anecdotal observations of EA members support this hypothesis - EAs seem to me to be highly effectively altruistic on average -&#xA0;</span><span>but they&apos;re only anecdotal.&#xA0;</span><span>Ultimately, this question needs to be settled through empirical research.</span></p>\n<p><span>As Robert notes, lots of criticism against the EA movement is not directed against the central EA message - what <a href=\"https://www.academia.edu/13786913/Whats_Wrong_With_Effective_Altruism\">Iason Gabriel</a> in a critical piece calls &quot;the thin version&quot; - but rather against a number of &quot;associated ideas&quot;, as Robert calls them (what Gabriel calls &quot;the thick version&quot;).&#xA0;These include criticisms of RCTs, particular conceptions of what&apos;s valuable, and so forth.&#xA0;</span><span>I think this is at least partly due to confusion over the triviality objection.</span></p>\n<p><span>To see that, note that Gabriel motivates his choice to criticize the thick rather than the thin version of the EA movement as follows.<br></span></p>\n<blockquote>\n<p><span>This paper focuses on the thick version of effective altruism. <em>Not everyone who identifies with the movement shares each individual belief, but, taken together, they capture much of what makes the approach interesting and unique. </em>They also explain many of the moral judgments that effective altruists make.</span></p>\n</blockquote>\n<p><span>My emphasis. Here Gabriel seems to imply that the thin version is trivial and not worth discussing. Well, it may be <em>philosophically </em>trivial, but again, the point isn&apos;t to be philosophically interesting, but to improve the world. And as a matter of fact, the EA movement is the first social movement which defines itself<em> </em>as a movement that is&#xA0;</span><span>trying to improve the world in the most evidence-based and cost-effective way possible. Unlike other movements, the EA movement is thus not committed to any specific strategy, but rather to whatever strategy turns out to be most effective.&#xA0;</span><span>Like I said above, my guess is that this means that the EA movement has an enormous potential for doing better than all other social movements, precisely because its members are constantly thinking about evidence and cost-effectiveness. Far from being uninteresting, the thin version of the EA movement is thus very interesting and unique indeed - it is one&#xA0;</span><span>of the great innovations of the 21th century, <a href=\"http://www.amazon.com/Doing-Good-Better-Effective-Difference/dp/1592409105\">as Pinker rightly has said</a>. Hence those who want to discuss the EA movement has every reason to focus on the thin version.</span></p>\n<p><span>As a side-note, it seems to me that the (thin) EA message has been </span><em>explicitly designed</em><span> to be trivial/obvious, at least for large swathes of the liberal, educated part of the population (whether this is indeed true someone who knows more about the EA history could perhaps tell me). The fact that the EA movement is such a &quot;broad tent&quot; - </span><a href=\"http://lesswrong.com/lw/hx4/four_focus_areas_of_effective_altruism/\">that it includes organizations which work on poverty reduction, animal suffering, X-risk and meta causes</a><span> - makes it easy for these kinds of people to find a place within the EA movement. To my mind, this is not a weakness, but a strength.<br><br>[Slightly edited]</span></p></body></html>", "user": {"username": "Stefan_Schubert"}}, {"_id": "CqmkN52P3CKHowMaf", "title": "Deep Dive with Matthew Gentzel on Recently Effective Altruism Policy Analytics", "postedAt": "2015-07-20T06:17:48.890Z", "htmlBody": "<html><body><p>Last Sunday .impact hosted a Deep Dive with Matthew Gentzel on the new Effective Altruist Organization, Effective Altruism Policy Analytics.</p>\n<p>The full video is <a title=\"here\" href=\"https://www.youtube.com/watch?v=8GE0Swdidd0\">here</a>. &#xA0;It went for one hour, 40 minutes, and went through a long introduction followed by several questions and answers.&#xA0;</p>\n<p>A written summary, with links to more information on the organization, is <a href=\"https://impact.hackpad.com/12-July-2015-Deep-Dive-on-Effective-Altruism-Policy-Analysis-LXE8ksxnz4h\">posted here</a>.</p>\n<p>If you have either comments/suggestions about the organization or about the way we organized this discussion, please leave them in the comments below.</p></body></html>", "user": {"username": "oagr"}}, {"_id": "6uiT5xuSxLkqvXQfy", "title": "Meetup : Northern Midwest EA Meetup", "postedAt": "2015-07-19T15:59:15.269Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/32\">Northern Midwest EA Meetup</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>26 July 2015 12:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>Pig Minds Brewing Company, 4080 Steele Dr., Machesney Park, IL 61115</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>It sounds like there are several EAs moving to Madison for Epic and others moving to Chicago. We thought it would be a good idea to have a meetup to welcome everyone!</p>\n\n<p>Let&apos;s meet up for lunch at Pig Minds Brewing Company, near Rockford, so about 1/2 way between the 2 cities. They have delicious food (not just beer).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/32\">Northern Midwest EA Meetup</a></h2></body></html>", "user": {"username": "Gina_Stuessy"}}, {"_id": "B53Hgi58G5yWHE9Zx", "title": "Join .impact's Third Workathon this Sunday at Noon Pacific", "postedAt": "2015-07-19T00:02:18.999Z", "htmlBody": "<html><body><p>Please come and join .impact&apos;s 3rd remote and in-person Workathon, which is accessible online or at App Academy in San Francisco if you would like to attend in person.</p>\n<p>No programming skills are required and the event lasts from 12:00-4:00PM Pacific Time. &#xA0;You can work on any EA project&apos;s of your choosing or, if you&apos;d like, be assigned to work on any of .impact&apos;s open projects.</p>\n<p>If you are interested, join the Facebook event: https://www.facebook.com/events/636543783147484/ A Google Hangouts link will be posted a few minutes before the event starts.</p></body></html>", "user": {"username": "Peter_Hurford"}}, {"_id": "RCqNLh3znXfyWtM7E", "title": "Meetup : .impact's Third Workathon", "postedAt": "2015-07-18T23:59:31.012Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/31\">.impact&apos;s Third Workathon</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>19 July 2015 12:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>App Academy in San Francisco (and online)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>Please come and join .impact&apos;s 3rd remote and in-person Workathon, which is accessible online or at App Academy in San Francisco if you would like to attend in person. No programming skills are required and the event lasts from 12:00-4:00PM Pacific Time. You can work on any EA project&apos;s of your choosing or, if you&apos;d like, be assigned to work on any of .impact&apos;s open projects. If you are interested, join the Facebook event: <a href=\"https://www.facebook.com/events/636543783147484/\">https://www.facebook.com/events/636543783147484/</a> A Google Hangouts link will be posted a few minutes before the event starts.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/31\">.impact&apos;s Third Workathon</a></h2></body></html>", "user": {"username": "Peter_Hurford"}}, {"_id": "xfxKaYCNFDMZND3jL", "title": "Meetup : .impact's 3rd remote and in-person Workathon", "postedAt": "2015-07-18T20:42:39.306Z", "htmlBody": "<html><body><h2>Discussion article for the meetup : <a href=\"/meetups/30\">.impact&apos;s 3rd remote and in-person Workathon</a></h2>\n\t\t  <div>\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span>19 July 2015 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span>1061 Market St., San Francisco CA </span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div>\n\t\t    <div><p>Please come and join .impact&apos;s 3rd Workathon, which is accessible online or at the above address if you would like to attend in person. No programming skills are required and the event lasts from 12:00-4:00PM PDT. You can work on any EA project&apos;s of your choosing or, if you&apos;d like, be assigned to work on any of .impact&apos;s open projects. If you are interested, join the Facebook event: <a href=\"https://www.facebook.com/events/636543783147484/\">https://www.facebook.com/events/636543783147484/</a> A Google Hangouts link will be posted a few minutes before the event starts.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href=\"/meetups/30\">.impact&apos;s 3rd remote and in-person Workathon</a></h2></body></html>", "user": {"username": "JosephKijewski"}}, {"_id": "gRM9zswWGWFTiFDTt", "title": "Moral Economics Concepts", "postedAt": "2015-07-17T23:55:12.454Z", "htmlBody": "<html><body><h2><span>Moral Economics Concepts</span></h2>\n<p>&#xA0;</p>\n<p><span>On the shoulders of: </span><a href=\"http://lesswrong.com/lw/bk1/the_principle_of_altruistic_arbitrage/\"><span>Altruistic Arbitrage</span></a><span>, </span><a href=\"http://rationalaltruist.com/2014/11/15/certificates-of-impact/\"><span>Certificates of Impact</span></a><span>, </span><a href=\"http://lesswrong.com/r/discussion/lw/gvr/cognitive_load_and_effective_donation/\"><span>Cognitive Load and Effective Donation</span></a><span>, </span><a href=\"/ea/jb/solving_donation_coordination_problems/\"><span>Coordination Problems for Donations</span></a><span>, </span><a href=\"http://www.effective-altruism.com/ea/cc/help_a_canadian_give_with_a_taxdeduction_by/\"><span>Donation Swapping</span></a><span>, </span><a href=\"/ea/fu/can_we_set_up_a_system_for_international_donation/\"><span>International Donation Trade</span></a><span>, </span><a href=\"/ea/cx/gratipay_for_funding_eas/\"><span>Direct Funding for EAs</span></a><span> and especially </span><a href=\"http://www.amirrorclear.net/academic/papers/moral-trade.pdf\"><span>Moral Trade</span></a><span>. </span></p>\n<p>&#xA0;</p>\n<p><span>News: Giles created a new <a href=\"https://dotimpactteam.slack.com/messages/moraltrade/\">#Moraltrade</a> channel on Slack, which is being used during the Sunday US UK online EA workathons - in person for those in SF. To see the </span><a href=\"https://www.facebook.com/events/477791982396277/\"><span>workathon Sunday event go here</span></a><span>. And to enter the </span><a href=\"https://dotimpactteam.slack.com/messages/moraltrade/\"><span>channel for Moral Trade enter here</span></a><span>. </span></p>\n<p><span><br></span></p>\n<p><span>Special thanks to Ryan Carey, Ben Hoskin and Leo Arruda for ideas and corrections.</span></p>\n<p><span>Crossposted at <a href=\"http://diegocaleiro.com/2015/07/17/examples-of-moral-economics-concepts/\">diegocaleiro.com</a></span></p>\n<p><span><br><span>In these writings we propose the creation of a subfield of knowledge, Moral Economics, and provide in broad strokes its characteristics. We assemble previous writings that can be considered prospective subfields. We also discuss several concepts that have been developed in recent years that are instrumentally useful for Moral Economic thinking, and propose several new ones that could also bear fruit if the study of this area develops further in the future. </span></span></p>\n<p><span>Moral economics series</span></p>\n<p>&#xA0;</p>\n<ol>\n<li>\n<p><a href=\"/ea/ky/introducing_moral_economics/\"><span>Introducing Moral Economics</span></a></p>\n</li>\n<li>\n<p><a href=\"/ea/l1/moral_economics_concepts/\"><span><strong>Examples of Moral Economics Concepts</strong></span></a></p>\n</li>\n<li>\n<p><a href=\"/ea/l1/moral_economics_concepts/\"><span><strong>Branches Within Moral Economics</strong></span></a></p>\n</li>\n<li>\n<p><span><a href=\"/ea/l9/moving_moral_economics_forward/\">Moving Moral Economics Forward</a></span></p>\n</li>\n<li>\n<p><a href=\"/ea/lg/direct_funding_between_eas_moral_economics/\">Direct Funding Between EAs</a></p>\n</li>\n<li>\n<p><span>Certificates of Impact, Doing It Right - Giles Edkins</span></p>\n<ol>\n<li>\n<p><span>Moral market failure: how COIs might help</span></p>\n</li>\n<li>\n<p><span>Problems with COIs, and their solutions</span></p>\n</li>\n<li>\n<p><span>Implementing COIs</span></p>\n</li>\n</ol></li>\n<li>\n<p><span>Agential Identity in Moral Economics</span></p>\n</li>\n</ol>\n<div><span>\n<h2><br></h2>\n<h2><span>Examples of Moral Economics Concepts</span></h2>\n<p>&#xA0;</p>\n<p><span><span><span> </span>Let us look at some examples of Moral Economics concepts that have been suggested in the last few years, and conceive of branches or sub-fields which lump some of these concepts together. </span></span></p>\n<p><span><br></span></p>\n<p><span>Altruistic Arbitrage:</span><span> Analogous to the concept of Arbitrage, the concept serves to facilitate reasoning about opportunities for trade that are morally profitable. </span></p>\n<p><span><br></span></p>\n<p><a href=\"http://lesswrong.com/lw/l8h/certificates_of_impact_paul_christiano_link/\"><span>Certificates of Impact</span></a><span>:</span><span> These consist of certificates that are bought after the fact for a past altruistic action or a fraction of one, which later can be traded or sold. An attempt to make the Moral Market for actors with altruistic inclinations be explicit and numerical, by creating a form of floating currency that permits exchange in space and time between the two markets - notice that inter-temporal backwards trade was not available for altruistic actions before this idea, you could not today cooperate and trade with past altruist action.</span></p>\n<p><span><br></span></p>\n<p><span>Intertemporal </span><a href=\"/ea/jb/solving_donation_coordination_problems/\"><span>Coordination Problems for Donations:</span></a><span> To donate maximally impactfully to a fundraiser with a deadline, it seems </span><span>prima facie</span><span> that one should wait until the last minute to guarantee that someone else donates instead of you, since </span><span>your goal is that resources go to that event</span><span>, not that </span><span>your</span><span> resources go to that event. This way you make sure your moral values are satisfied, and keep the resources to satisfy even more of your values. This is different from buying an apple for yourself, where you anticipate the only way of getting it is if your resources purchase it. In the altruistic case, as long as someone pays for the valuable thing, your value is satisfied. </span></p>\n<p><span>This however poses a tragedy of the commons type incentive, where each individual will be better off (morally) by holding on to their resources for longer than would be desirable from the group&apos;s perspective. It becomes more difficult to predict how much will be raised by the fundraising. This concept is related to </span><span>apathy bias </span><span>or the</span><span> bystander effect</span><span> in behavioral economics. This does not happen in classical economic theory because individuals are not indifferent over who gets the cake, the stock, or the wage as long as someone gets it. </span></p>\n<p><span><br></span></p>\n<p><span>Direct Funding for EAs: </span><span>A direct linkage between an individual who wishes to have their values promoted and another who attempts to promote these values in exchange for money. </span></p>\n<p><span>This has been attempted within the Effective Altruist community by creating </span><a href=\"https://gratipay.com/for/effective-altruists/\"><span>Gratipay</span></a><span> and </span><a href=\"https://www.patreon.com/user?u=423163&amp;ty=h&amp;u=423163\"><span>Patreon</span></a><span> as donation portals for EAs. Although it is much cheaper per worker hour than donating to institutions - back of the envelope calculation during the EA Think Thank says between 2x to 3x cheaper within a country and up to 5x depending on currency exchange - this form of trade doesn&#x2019;t have a large fraction of EA donation resources yet. Direct funding also permits funding for causes that are unknown or neglected within the EA community. If one single donor would like to sponsor an EA to research how Emulation Economics would disrupt the economy, and a single researcher is interested in doing this, direct donations between the two could guarantee this is done, whereas institutions or certificates would not. Direct Funding will be further discussed in a later post in the series. </span></p>\n<p><span><br></span></p>\n<p><span>Donation Swapping:</span><span> Frequently there are tax or legal reasons for two donors with different interests and values to swap their donation targets. Because the market does not have absolute liquidity and zero viscosity, it is frequently advantageous for individuals to A and B to reach an agreement on how much to donate to causes 1 and 2, and then A who values 1 donates to 2 and B who values 2 donates to 1, because some market inefficiency makes that morally cheaper for them. This is a form of regulatory arbitrage. &#xA0;</span></p>\n<p><span><br></span></p>\n<p><span>Moral Trade: </span><span>...as described by Toby Ord: If two parties have different moral views, then there is another type of trade that is possible: they can exchange goods or services such that both parties feel that the world is a better place, or that their moral obligations are better satisfied. We can call this </span><span>moral trade</span><span>. For instance, a person concerned with animal welfare might offer to donate to Oxfam if their friend, who is concerned with global poverty, agrees to abstain from eating meat for a year. </span></p>\n<p><span>Moral trade is the philosophical underpinning on top of which moral economics can be built. If there was no moral trade, there would be substantially less reason for a science of moral economics. Moral Trade can happen almost irrespective of moral stance, which we can dub the </span><span>Moral Trade Orthogonality Thesis</span><span>. For any ranking of actions according to their moral permissibility or desirability, whether measured in (a)virtue,(b)ranking seen from a veil of ignorance, (c)utilons, (d)hedons, (e)sacredness or (f)accordance with universal reason, there might be ways in which trade could facilitate the attainment of moral good from the perspective of an individual who endorses that ranking scheme. The divergence in moral views between individuals greatly facilitates this trend. </span></p>\n<p><span><br></span></p>\n<p><span>Tragedy of Commonsense Morality:</span><span> In </span><span>Moral Tribes</span><span>, Joshua Greene distinguishes the types of problems that are partially solved by our moral instincts and agreements (Me versus Us) from those which our moral instincts and system 1 morality are not equipped to solve (Us versus Them). He dubs this latter type the Tragedy of Commonsense morality. Throughout the book he makes a mixed empirical and philosophical case for utilizing system 2, manual mode morality when making decisions of the Us versus Them type, and trusting our senses more for Me versus Us type problems. He further advocates the usage of utilitarianism as a currency when solving problems of the Us versus Them type, though for space reasons I will not describe the many reasons for which he considers this desirable. It is worth noting that the book ends with a link to the Givewell website, indicating Greene&apos;s alignment with the use of Moral Trade as strategy to generate morally desirable outcomes. &#xA0;</span></p>\n<p><span><br></span></p>\n<p><span>Acausal Trade:</span><span> Acausal trade is trade which doesn&#x2019;t involve (relevant) causal contact between the trading parties. If I assume there is an altruist in India who would prefer that I don&#x2019;t eat beef and she assumes there is an altruist in the US who would prefer that she alleviates the suffering of five poor people in her city, we can make a Moral Acausal Trade, creating a world that is best for both of us without ever interacting: I eat less beef and she helps those five people in a way I couldn&#x2019;t.</span></p>\n</span></div>\n<div><br></div>\n<p><strong> </strong></p>\n<h2><strong><span> Moral Economics Branches</span></strong></h2>\n<p><strong> </strong></p>\n<p><strong> <br> </strong></p>\n<p><strong><span>Many other concepts are of service to reason about Moral Economics. To accelerate the development of the field, permit me to go ahead and propose the creation of subfields or branches of Moral Economics.</span></strong></p>\n<p>&#xA0;</p>\n<p><span><span>Economics of Counterfactuals</span></span></p>\n<p><span><span>I propose the creation of a sub-branch of moral economics which investigates the differences between moral economics and regular economics that arise due to their different treatment of counterfactuals - also called replaceability effects within economics, also called opportunity costs in some cases. Differently from rival goods like apples in economics, where my having an apple precludes you having that apple, frequently in Moral Economics what matters is that someone gets an apple, and both of us accrue value out of that individual receiving it. Let me explore below some concepts that are specifically related to counterfactuals and how they behave differently in Moral Economics:</span></span></p>\n<p><strong> </strong></p>\n<ul>\n<strong>\n<li>\n<p><span>Labor replaceability:</span><span> See MacAskill and Todds&apos; theses. An amoral doctor may care about acquiring resources (money) and that she saves patients. A moral doctor frequently will instead care changes in use of resources from what would happen otherwise. They would prefer to save more lives than if someone else was a doctor, and may also divert a fraction of their resources (say 50% of their salaries) towards saving more lives indirectly through charity or astronomical waste interventions. </span></p>\n</li>\n<li>\n<p><span>Ripple effect risk analysis: </span><span>Although companies and States have incentives to do risk analysis of ripple effects in the future, altruists have a much stronger reason due to a few factors: </span></p>\n<ul>\n<li>\n<p><span>1)Most of economics externalities are not externalities from an altruist perspective, since they generate, remove or preempt values from agents that are within the circle of altruistic concern </span></p>\n</li>\n<li>\n<p><span>2)There are vastly more individuals who are not you than who are, and vastly many more potential individuals in the future than now (10^30 is a conservative estimate if silicon based moral agents are impossible, 10^50 if possible) </span></p>\n</li>\n<li>\n<p><span>3)Power law distributions are more common in large scale economies than in small trades or partnerships. </span></p>\n</li>\n</ul>\n</li>\n</strong> \n</ul>\n<p><strong> </strong></p>\n<p><strong><span> Some of the work conducted by </span><a href=\"https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=aefVOM4AAAAJ&amp;cstart=20&amp;citation_for_view=aefVOM4AAAAJ:0EnyYjriUFMC\"><span>Sandberg</span></a><span>, </span><a href=\"https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=aefVOM4AAAAJ&amp;citation_for_view=aefVOM4AAAAJ:LkGwnXOMwfcC\"><span>Hillebrand</span></a><span>, Ord, Armstrong, Douglas, Bostrom and more recently the Open Philanthropy Project fall within this scope. Ripple effects are particularly important for altruists because altruists are more impartial about how far in the future the consequences of their actions generate benefit. Risk analysis is important because the same is true for negative consequences. &#xA0;</span></strong></p>\n<p><strong> </strong></p>\n<ul>\n<strong>\n<li>\n<p><span>Donation overdetermination</span><span>: Many interesting game theoretic questions arise when donations are overdetermined. There may be a Schelling point of how much to donate when an individual anticipates other individuals donating, see also Non-Indexical Decision Theory, in the next post. </span></p>\n</li>\n<li>\n<p><a href=\"http://www.nickbostrom.com/papers/unilateralist.pdf\"><span>Unilateralist Curse</span></a><span>: </span><span>A complex failure mode that arises out of several agents who can each take a unilateral decision, even when all the agents have value aligned collaborative intentions. </span></p>\n</li>\n<li>\n<p><span>Haste Consideration: </span><span>To consider </span><a href=\"https://www.youtube.com/watch?v=GRQJinlkHkc\"><span>what would have happened if you had done otherwise</span></a><span>, it is very important to take in consideration the causal impact of acting sooner or later. </span><a href=\"https://80000hours.org/2012/04/the-haste-consideration/\"><span>Matt Wage</span></a><span> and </span><a href=\"/ea/ik/should_you_give_your_best_now_or_later/\"><span>I</span></a><span> wrote two very similar texts advocating a 2 year haste consideration at different times.</span></p>\n</li>\n</strong> \n</ul>\n<p><strong> <br> </strong></p>\n<h2><strong><span>Agential Identity </span></strong></h2>\n<p><strong> <br>\n</strong></p><p><strong><span>Another valuable sub-branch of Moral Economics is the study of models of economic agents which are useful to reason about economic situations and states in which it matters to what extent the economic agents should anticipate their behavior being similar to that of other economic agents, or to what extent they should assume those agents are themselves or not. Two distinct forms of boundaries are relevant, the boundary for agents that behave like me in similar contexts, and the boundary for agents that are me. Since this is a complex sub-topic and there is much to be said, I&#x2019;ll take Leo Arruda&#x2019;s suggestion and save it for a later post. </span></strong></p><strong>\n<br>\n<h2><span>Moral Economics as a Response to Coordination Problems</span></h2>\n<br>\n<p><span>Some readers might be tempted to see moral economics as a solution to coordination problems. In some cases, knowing what a moral agent should do indeed solves or helps coordination problems to be solved. When instead of MaxSelf you are MaxSum, many games that were negative zero sum or zero sum become positive, that is, the structure of incentives which created the game is more favorable to moral players than to selfish players. This isn&#x2019;t always the case, in very few cases, the invisible hand actually defeats morality and altruism </span><span>even when judged by the total sum of good</span><span>. These cases, however, are infrequent. </span></p>\n<br>\n<p><span>A more frequent and widely studied problem when interactions between more selfish and less selfish agents end up being less beneficial for the altruistic agent, who would be better off in a group that is more altruistic, that punishes cheaters, that is more moral etc&#x2026; These cases are frequently studied in evolutionary biology (a nice summary is </span><a href=\"https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=aNFzP50AAAAJ&amp;cstart=60&amp;sortby=pubdate&amp;citation_for_view=aNFzP50AAAAJ:aDl3D7KC1E4C\"><span>Novak 2013</span></a><span>), and it is worth mentioning that the benefit accrued by a selfish agent is not considered benefit to the altruistic ones within biology, but frequently should in Moral Economics when consequentialist altruistic agents are involved. </span></p>\n</strong><p></p>\n<p>&#xA0;</p>\n<p>&#xA0;</p>\n<p>&#xA0;</p>\n<p>&#xA0;</p>\n<p>&#xA0;</p>\n<p><span>For instance, today I stunned a bike shop owner when telling him I have no intention of making sure my bike seat isn&#x2019;t stolen, and prefer to purchase new seats sometimes instead of locking that one, because I consider the benefit accrued by the thieve and the counterfactually would be stolen other person to also be accrued by me (at some 0.5&lt;x&lt;1.0 rate), making the case for seat protection too weak to matter. At our effective altruists house in Berkeley I have also observed other people</span><a href=\"http://lesswrong.com/lw/ktx/should_eas_be_superrational_cooperators/\"><span> acting in similar ways</span></a><span> towards us, their housemates. </span></p>\n<p><span> </span></p>\n<hr>\n<p>In the next post we examine ways of moving moral economics forward, and show a glossary of economic concepts that may have interesting variations and differences, when conceived of with an altruistic mindset.</p></body></html>", "user": {"username": "Diego_Caleiro"}}, {"_id": "7PnbLnCoTTB3KGKiM", "title": "EA-commercials on national TV in Norway - for free!", "postedAt": "2015-07-16T16:18:18.938Z", "htmlBody": "<html><body><h4>TL;DR: Norwegian TV channels have to send informational videos&#xA0;from non-profits&#xA0;instead of regular commercials 4 days a year. The only important requirement is quality, which judging by the current videos, is set at a reachable level. We need input and people who can contribute with time, skills and/or funding.</h4>\n<p>&#xA0;</p>\n<p><strong>Background</strong></p>\n<p>The EA community is growing in Norway and one of the larger project that we are working on is starting a foundation that will promote, inform on and manage tax deductible donations to GW/GWWC recommended charities and meta charities. As a part of the promotional plan we want to make an informational video about effective giving that would spark attention, get people to visit the website and ultimately donate to effective charities. The main goal is to show the video in a 30 second version on national television (see details below), and a longer version (or the same version) could be spread on Facebook ant Twitter using the EA network. This video project is not necessarily dependent upon the rest of the foundation, and could be carried out even if we have to postpone the the foundation due to lack of funding.<br><br>By Norwegian law commercial TV stations are not allowed to send commercials four days a year (Christmas day, Pentecost, Good Friday and Easter). Instead they are required to send, equally in length and frequency, informational videos from non-profit organizations free of charge. We believe that this is a great opportunity for reaching out to a large audience and get valuable attention to effective causes, especially if we manage to create a video that sticks out, favorably without&#xA0;pitiful, poor and hungry children (as many of the other videos). The cost in time and money is dependent upon the skills of the persons producing the video and the quality we aim for.<br><br><br><strong>Some ideas of format and content</strong><br><br><em>Here are some examples of informational videos sent by other charities: <a href=\"https://www.youtube.com/watch?v=H_VMHvMtWiY\">Lions Club</a>, <a href=\"https://www.youtube.com/watch?v=D4m-Zq6y_Cc\">ParkinsonNorway</a>, <a href=\"https://www.youtube.com/watch?v=E32nYAoh0Yk\">Save the Children</a>.</em><br><br>We haven&apos;t decided on any core message or framing, so we are totally open for suggestions. However, one of the conditions from the TV-stations is that we cannot directly ask for donations. But we can present a web address and the logo at the end. The time limit is 30 seconds, but as pointed out, we can produce a longer version for using online.<br><br>Since we are new in the game, and most people haven&apos;t even heard of the charities we recommend, I think we will benefit from being bold and trying to create some attention by being different. Maybe we even should be provocative and challenging.<br><br>I have little experience with video production, but I imagine that making a computer animated video may be the best format. It&apos;s cheaper in equipment costs, more likely that EAs or friends of EAs already got the necessary software and knowledge and it&apos;s easier to collaborate over the&#xA0;web. I also think that few of the other videos are animated, such that this will stick out. Here are some examples of good animated videos I think of: <a href=\"https://www.youtube.com/watch?v=cFdCzN7RYbw\">The Science of Presuation</a>, <a href=\"https://www.youtube.com/watch?v=PHe0bXAIuk0\">How The Economic Machine Works</a>&#xA0;and <a href=\"https://www.youtube.com/watch?v=Lrw0Glcmowk\">The Girl Effect</a>&#xA0;(or may be more like an infographic like <a href=\"https://www.youtube.com/watch?v=eJoGd84Tiu8\">this</a>).<br><br>This is only some very loose ideas and the conditions we have to follow. Please feel free to build on this, or come up with something completely different. We would really appreciate all input, criticism, tips and ideas.</p>\n<h1>\n<p><span>What are needed to carry this out</span></p>\n</h1>\n<p>At this stage we need the resources in people, skills and money to be confident that the product would be good enough so that we can start the project. A reasonable goal is for the video to be done one month before Good Friday: the deadline for sending in videos that will be aired the two commercial free days of Easter.<br><br>By resources in people and skills we mean people who want to contribute to the creative process, the production process and/or the editing process. Do you have experience with doing similar projects and want to give us a hand? Just giving some tips or ideas will be valuable as well.<br><br>Given that we may not get people with the appropriate skills to make the video (the production part seems most demanding) who are sufficiently motivated to help without any pay, we&apos;ll have to hire someone. We got some names of friends of EAs with the appropriate skillset, but we don&apos;t know if they got time or that they are willing to doing it for free. Another aspect is the level of commitment friends of EAs will show for a pro bono project, about a cause that they don&apos;t usually are excited about. Then a limited fee could be well spent as it emphasizes that we are serious about this, and it creates a stronger commitment to the project.<br><br>Without having much experience about such projects, we estimate that expenses making the video would amount to:<br><span> </span>13 000 <span> </span>NOK - Paying a skilled producer/animator or two<br><span> </span>1500 <span> </span>NOK - Traveling expenses (Trondheim-Oslo)<br><span> </span>500 <span> </span>NOK - Food and snack for workshops<br><br><em>Sum&#xA0;<span> </span>15 000 NOK ($1840)</em><br><br>An eventual surplus, resulting from lower expenses than expected, will be donated to SCI if the donor doesn&apos;t have other wishes.<br><br>If you are interested in supporting this video project financially and thus helping us reach hundreds of thousands of Norwegians with a message of effective giving, please send an email to post(at)effektivaltruisme.no.<br><br>If you are interested in supporting or learning more about&#xA0;our greater project of starting a foundation, please also send us an email. For the foundation we are also trying <a href=\"http://bidra.no/kampanje/stiftelsen-effekt--mangedoble-din-effekt/64cb8b7e-3751-4888-a4c5-553d7296db35\">crowdfunding</a> and we will apply for funding to EA Ventures.</p>\n<p><br>We hope to hear from you in the comments!<br><br><br>- J&#xF8;rgen Lj&#xF8;nes<br>Co-president of EA NTNU, Norway</p></body></html>", "user": {"username": "Jorgen_Ljones"}}, {"_id": "ZiRsvD7ijDCGejGJf", "title": "New EA Global: Oxford program now live", "postedAt": "2015-07-16T02:54:02.206Z", "htmlBody": "<html><body><p>The program for Effective Altruism Global: Oxford - featuring <em>Predictably Irrational</em> author <strong>Dan Ariely</strong> and Skype cofounder <strong>Jaan Tallinn</strong> - is now live at <a href=\"http://eaglobal.org/oxford \">http://eaglobal.org/oxford&#xA0;</a></p>\n<p><a href=\"http://eaglobal.org/oxford \"></a>This year will mark the biggest gathering of the EA movement in history, with many members of this forum already attending. If you haven&apos;t applied yet, don&apos;t miss out! We&apos;ve cut down the price $200 from last year, and extensive financial aid is available.</p>\n<p>Apply here: <a href=\"http://eaglobal.org/apply\">http://eaglobal.org/apply</a></p>\n<p>&#xA0;</p>\n<p>---</p>\n<p>Nominate a friend to attend: <a href=\"http://eaglobal.org/nominate\">http://eaglobal.org/nominate</a></p>\n<p>Spread the word: <a href=\"http://bit.ly/eagoxfordhelp\">http://bit.ly/eagoxfordhelp</a></p>\n<p>&#xA0;</p>\n<p>&#xA0;</p></body></html>", "user": {"username": "tyleralterman"}}, {"_id": "nbjAuBFjEKaXbn4y4", "title": "Introducing Moral Economics", "postedAt": "2015-07-14T07:13:09.254Z", "htmlBody": "<html><body><p><span> </span></p>\n<p><span>Moral Economics </span></p>\n<p>&#xA0;</p>\n<p><span>On the shoulders of: </span><a href=\"http://lesswrong.com/lw/bk1/the_principle_of_altruistic_arbitrage/\"><span>Altruistic Arbitrage</span></a><span>, </span><a href=\"http://rationalaltruist.com/2014/11/15/certificates-of-impact/\"><span>Certificates of Impact</span></a><span>, </span><a href=\"http://lesswrong.com/r/discussion/lw/gvr/cognitive_load_and_effective_donation/\"><span>Cognitive Load and Effective Donation</span></a><span>, </span><a href=\"/ea/jb/solving_donation_coordination_problems/\"><span>Coordination Problems for Donations</span></a><span>, </span><a href=\"http://www.effective-altruism.com/ea/cc/help_a_canadian_give_with_a_taxdeduction_by/\"><span>Donation Swapping</span></a><span>, </span><a href=\"/ea/fu/can_we_set_up_a_system_for_international_donation/\"><span>International Donation Trade</span></a><span>, </span><a href=\"/ea/cx/gratipay_for_funding_eas/\"><span>Direct Funding for EAs</span></a><span> and especially </span><a href=\"http://www.amirrorclear.net/academic/papers/moral-trade.pdf\"><span>Moral Trade</span></a><span>. </span></p>\n<p>&#xA0;</p>\n<p><span><span>News: Giles created a new <a href=\"https://dotimpactteam.slack.com/messages/moraltrade/\">#Moraltrade</a> channel on Slack, which is being used during the Sunday US UK online EA workathons - in person for those in SF. To see the </span><a href=\"https://www.facebook.com/events/477791982396277/\"><span>workathon Sunday event go here</span></a><span>. And to enter the </span><a href=\"https://dotimpactteam.slack.com/messages/moraltrade/\"><span>channel for Moral Trade enter here</span></a><span>. </span></span></p>\n<p><span><span><br></span></span></p>\n<p><span>Special thanks to Ryan Carey, Ben Hoskin and Leo Arruda for ideas and corrections.</span></p>\n<p><span>Crossposted at <a href=\"http://diegocaleiro.com/2015/07/14/introducing-moral-economics/\">diegocaleiro.com</a></span></p>\n<p><span>In these writings we propose the creation of a subfield of knowledge, Moral Economics, and provide in broad strokes its characteristics. We assemble previous writings that can be considered prospective subfields. We also discuss several concepts that have been developed in recent years that are instrumentally useful for Moral Economic thinking, and propose several new ones that could also bear fruit if the study of this area develops further in the future. </span></p>\n<p>&#xA0;</p>\n<ol>\n<li>\n<p><a href=\"/ea/ky/introducing_moral_economics/\"><span><strong>Introducing Moral Economics</strong></span></a></p>\n</li>\n<li>\n<p><a href=\"/ea/l1/moral_economics_concepts/\"><span>Examples of Moral Economics Concepts</span></a></p>\n</li>\n<li>\n<p><a href=\"/ea/l1/moral_economics_concepts/\"><span>Branches Within Moral Economics</span></a></p>\n</li>\n<li>\n<p><span><a href=\"/ea/l9/moving_moral_economics_forward/\">Moving Moral Economics Forward</a></span></p>\n</li>\n<li>\n<p><a href=\"/ea/lg/direct_funding_between_eas_moral_economics/\">Direct Funding Between EAs</a></p>\n</li>\n<li>\n<p><span>Certificates of Impact, Doing It Right - Giles Edkins</span></p>\n<ol>\n<li>\n<p><span>Moral market failure: how COIs might help</span></p>\n</li>\n<li>\n<p><span>Problems with COIs, and their solutions</span></p>\n</li>\n<li>\n<p><span>Implementing COIs</span></p>\n</li>\n</ol></li>\n<li>\n<p><span>Agential Identity in Moral Economics</span></p>\n</li>\n</ol>\n<h2><span>The birth of a subfield of knowledge</span></h2>\n<p>&#xA0;</p>\n<p><span>Economics for altruists doesn&apos;t operate under the same rules as regular economics.</span></p>\n<p><span><br></span></p>\n<p><span>Economics for altruists, and for moral agents at large, could be a prolific field of study, if both similarities and differences were appreciated. To see them, we cite <a href=\"http://www.amirrorclear.net/academic/papers/moral-trade.pdf\">Ord</a> (In press): </span></p>\n<p><span> </span><span>Different self-regarding tastes allow for gains from trade. For example, if two children would prefer to eat each other&#x2019;s packed lunches, they can trade them and both benefit. Similarly, if people have different moral views, they can potentially realise gains from moral trade, making them both think that their moral view is better satisfied if they make a trade than if they don&#x2019;t. For example, consequentialists may think that the trade produces a better outcome, while deontologists may think that it better fulfils their duties or that it is a supererogatory option. &#xA0;</span></p>\n<p>&#xA0;</p>\n<p><span>As Carey pointed out while reviewing this: </span></p>\n<p><span>People do not behave in an entirely self-interested manner, and economists are often tempted to model people as though they are. Utility in economics is used to mean something different from how it is usually understood, which is at best confusing, and at worst distorts the discourse. [We can][</span><span>...] call into question the notion that what society common-sensically calls a person is necessarily one agent in the economic sense. Instead, you want to say that a person is made up of lots of desires, which might be subagents themselves (picoeconomics) that they might be the same as temporally distant similar people (UDT/TDT), and that their other-regarding beliefs should not be excluded from analysis, or from efforts to build robust institutions to fulfil these values.</span></p>\n<p>&#xA0;</p>\n<p><span>In traditional economics, monolithic self-interested agents that have full personal identity over time perform trade, make contracts and create firms in order to satisfy their preferences, especially with regards the consumption of goods and services. Over time, the opportunities for increased efficiency offered by the division of labour becomes a strong incentive for cooperation even if agents are mostly self-interested, so alliances and groups become more likely. Negative externalities frequently generate tragedy of the commons type dilemmas, a multiplayer version of prisoner&#x2019;s dilemma (Ingmar &amp; Savulescu 2013). </span></p>\n<p><span>There are many ways in which the assumptions of traditional economic models can be challenged. For altruists and moral philosophers, some of these are worth pointing out, not as critique of the homo economicus model, which has been done thoroughly and at this point would be attacking a strawman, but merely to increase the saliency of some aspects of economics that will be useful to reason about altruistic economics. Let us look at them in turn.</span></p>\n<p><span> &#xA0;&#xA0;</span></p>\n<ul>\n<li>\n<p><span>Heuristics and Biases</span><span>: famously associated with Kahneman and Tversky , this subfield has lead to many predictive models at the individual as well as the social level. They adjust the traditional assumptions of perfect or adaptive rationality, replacing them with specific ways in each human reasoning is predictably imperfect </span><a href=\"http://www.amazon.com/Cognitive-Illusions-Handbook-Fallacies-Judgement/dp/0415646758\"><span>Cognitive Illusions</span></a><span> is a good introduction to the field, and </span><a href=\"https://intelligence.org/rationality-ai-zombies/\"><span>Rationality, from AI to Zombies</span></a><span> contains a more intuitive introduction. </span><a href=\"http://rationality.org/\"><span>CFAR</span></a><span> attempts to help individuals utilize this knowledge for practical rationality. </span></p>\n</li>\n<li>\n<p><span>Picoeconomics: </span><span>George Ainslie has </span><a href=\"https://scholar.google.com/scholar?hl=en&amp;q=george+ainslie&amp;btnG=&amp;as_sdt=1%2C5&amp;as_sdtp=\"><span>elaborated a model</span></a><span> of intra-agent hyperbolic trading, deconstructing the assumption that agents are monolithic and have full personal identity over time. Instead he contends that there is a dispute between different time slices of the same individual, and they too perform trade and bargain at the sub-personal level. His model makes different mathematical predictions of what an individual would deem an acceptable trade or not and has also been empirically corroborated as a better model of what humans actually do than the Homo Economicus strawman, though alternative models have </span><a href=\"http://wolfweb.unr.edu/homepage/pingle/Teaching/BADM%20791/Week%207%20Procrastination,%20Impatience%20and%20Hyperbolic%20Discounting/Rubenstein-Hyperbolic%20Discounting.pdf\"><span>empirically equivalent accuracy</span></a><span>. </span></p>\n</li>\n<li>\n<p><span>Fitness economics:</span><span> Evolutionary Psychology, Parental Investment, Epigenetics and Human Behavioral Genomics</span><span> These subfields and theories are not traditionally considered part of economic theory, so I&apos;m lumping them all together under the umbrella of </span><span>fitness economics.</span><span> I consider these relevant as they provide an explanatory framework for the incentives that govern human behavior that is different from the heuristics and biases, the picoeconomics, and the homo economicus perspectives. Fitness economics provides a theory of the behavior of economic agents in terms not to the benefits to individuals themselves, but to the long term survival and propagation of the genes or some epigenetic elements that individuals carry. Frequently these explanations give a better understanding of why a particular bias or heuristic is ubiquitous in human cognition, and they are also utilized to generate hypotheses and empirical tests which are then carried on by behavioral economists, who evaluate heuristics and biases empirically. </span></p>\n</li>\n</ul>\n<p>&#xA0;</p>\n<p><span>We suggest the creation of another subfield of economics: </span></p>\n<p><span>Moral Economics</span><span>. </span></p>\n<p><span><br></span></p>\n<p><span>It could also be called </span><span>Altruistic Economics</span><span> if that seems more suitable down the road. The important intuition is that moral economics should be valuable for moral agents with many different perspectives, and even more so for altruistic agents and agents with broadly aggregative consequentialist values. </span></p>\n<h2><span>What does </span><span>Moral Economics </span><span>encompass?</span><span> </span></h2>\n<p>&#xA0;</p>\n<p><span><span> </span>It can be taken as drawing a line in idea-space around the ideas in</span><span> </span><a href=\"http://lesswrong.com/lw/bk1/the_principle_of_altruistic_arbitrage/\"><span>Altruistic Arbitrage</span></a><span>, </span><a href=\"http://rationalaltruist.com/2014/11/15/certificates-of-impact/\"><span>Certificates of Impact</span></a><span>, </span><a href=\"http://lesswrong.com/r/discussion/lw/gvr/cognitive_load_and_effective_donation/\"><span>Cognitive Load and Effective Donation</span></a><span>, </span><a href=\"/ea/jb/solving_donation_coordination_problems/\"><span>Coordination Problems for Donations</span></a><span>, </span><a href=\"http://www.effective-altruism.com/ea/cc/help_a_canadian_give_with_a_taxdeduction_by/\"><span>Donation Swapping</span></a><span>, </span><a href=\"/ea/fu/can_we_set_up_a_system_for_international_donation/\"><span>International Donation Trade</span></a><span>, </span><a href=\"/ea/cx/gratipay_for_funding_eas/\"><span>Direct Funding for EAs</span></a><span> and especially </span><a href=\"http://www.amirrorclear.net/academic/papers/moral-trade.pdf\"><span>Moral Trade</span></a><span>. </span></p>\n<p><span><span> </span>The idea is to create the concept of a field of knowledge which associates these in a cluster, and understand the mechanics and logic that makes them related in concept space, as well as provides a vocabulary and perspective which allows us to discover other ideas which belong to the same cluster.</span></p>\n<p>&#xA0;</p>\n<p><span><span><span> </span> </span>These ideas all use the methods of analysis that are traditionally associated with economics and game theory, but from a different perspective and under different assumptions about what matters for agents, what is valuable for them. It is also necessary to use different notions of externalities and of utility. Compared to traditional economic agents, we would &#xA0;expect moral economic agents to behave differently, for there are qualitative shifts - even sign reversals - in the desirability of some forms of trade, formation of firms, incentives, contracts, coalitions and other economic precepts. </span></p>\n<p><span><span><span> </span></span>Moral economics would also diverge from traditional economics in having a multidimensional notion of value, which causes further detachment between price and market price, because different individuals will assign different subjective values for equal actions. Frequently they will value actions equivalently if taken by themselves or others, in a way that enables more frequent trade, in particular arbitrage, than the type of subjective valuation individuals have in standard microeconomics. </span></p>\n<p><span> Economics has traditionally &#xA0;focused on positive predictions about states of affairs and passive evaluations about the desirability/efficiency of those states. Concerns about how to improve matters were generally passed off as being the responsibility of the state, which was assumed to be largely omniscient and benevolent. Though the latter assumption has been challenged by <a href=\"https://en.wikipedia.org/wiki/Public_choice\">Public Choice Economics</a>, economics in general has had little to say about the perspective of an individual agent whose primary concern was aggregative value. Moral Economics hopes to address this deficiency.</span></p>\n<p><span><span><span> </span></span>The moral market is currently much less developed than the conventional economic market. The latter benefits from a sophisticated infrastructure to facilitate trade, including contracts, speculation and financial intermediaries, all of which are largely lacking from the Moral Economic sphere. As such, we should expect the moral market to be significantly less efficient than traditional market. This gap in market efficiency is expected to diminish as a larger fraction of resources reaches price equilibrium in both markets at the same time, effectively unifying them as a market, although I don&apos;t anticipate the gap to close anytime soon, or ever. </span><a href=\"http://www.nickbostrom.com/fut/evolution.html\"><span>Bostrom</span></a><span> (2003), </span><a href=\"http://slatestarcodex.com/2014/07/30/meditations-on-moloch/\"><span>Scott Alexander</span></a><span>, Hanson (forthcoming), </span><a href=\"http://blog.practicalethics.ox.ac.uk/2015/06/what-got-us-here-wont-get-us-there/\"><span>Fabiano &amp; Caleiro</span></a><span> (2015), and </span><a href=\"http://rationalaltruist.com/2014/05/14/machine-intelligence-and-capital-accumulation/\"><span>Christiano</span></a><span> (2014) make the case for us having reason to suspect that incentive structures will not lead to morally desirable outcomes in the very long run. Despite these reasons for skepticism about moral outcomes thousands or millions of years into the future, there are still substantial benefits of moral trade that can be accrued now or in the nearer future, The creation of &quot;currency exchange&quot; institutions such as Givewell, Giving What We Can, and others can be seen as a first step in closing the efficiency gap separating the traditional market from the moral market.</span></p>\n<p>&#xA0;</p>\n<hr>\n<p><span>Next in the Moral Economics series (posts every other day):</span></p>\n<p>&#xA0;</p>\n<ul>\n<li><span><span>Examples of Moral Economics Concepts</span></span></li>\n<li><span><span>Branches Within Moral Economics</span></span></li>\n<li><span><span>Moving Moral Economics Forward</span></span></li>\n<li><span><span>Agential Identity in Moral Economics</span></span></li>\n</ul></body></html>", "user": {"username": "Diego_Caleiro"}}, {"_id": "4HwgjhYrGat9Lcds5", "title": "That UMD Extra Credit Question", "postedAt": "2015-07-13T23:23:51.741Z", "htmlBody": "<html><body><p>Crossposted on zachgroff.com</p>\n<p><span>A discussion recently erupted with several friends over a tweet about an extra credit question posed by a professor at the University of Maryland:</span></p>\n<blockquote>\n<div>WHAT KIND OF PROFESSOR DOES THIS <a href=\"http://t.co/ACtQ0FCwRm\">pic.twitter.com/ACtQ0FCwRm</a></div>\n&#x2014; name (@shaunhin) <a href=\"https://twitter.com/shaunhin/status/616378904752848896\">July 1, 2015</a></blockquote>\n<p><span>One of my friends commented that the rational thing to do is to select 6% - unless you happen to be that marginal student whose choice brings everyone down, you can only expect to gain by selecting 6%.</span><br><span><br></span><span>My immediate reaction was that, well no, that&apos;s the rational thing to do provided you are egoistic and only care about your own exam score. If you&apos;re a rational altruist, though, the rational thing to do may be to select 2%, since in the unlikely event that you are the marginal student, you threaten to lose points for everyone. Depending on the size of the class and the way you value each additional point on the exam, this could easily outweigh the slight chance of getting an extra 4% for yourself.</span><br><span><br></span><span>As is often the case, things are more complicated. The reason is this: what if there is a curve? If there&apos;s a curve, then additional points on the exam only serve to set you aside from anyone else, and if you cause everybody to lose their bonus points, you just leave the relative distribution unchanged. From an altruistic perspective, if the value of everybody&apos;s exam score is equal, then it&apos;s unclear which way to answer this question.</span><br><span><br></span><span>It&apos;s more likely that everybody&apos;s exam score is not equal, though. If I&apos;m a truly effective, altruistic person and (almost) the rest of the class is not, then I should select 6%, since in the scheme of things, it&apos;s better for those who will do good with their credentials to outcompete those who won&apos;t.</span><br><span><br></span><span>The irony is that a radically altruistic position leads to the same choice as a radically egoistic one. It seems to me that this is likely the correct assessment. I could see worries that effective altruism could lead to a cutthroat world, but these are easily allayed by the fact that the calculation changes if I know that 10% of the class is likely to be effective altruists.</span><br><span><br></span><span>In fact, this could be somewhat comforting for those who worry about effective altruism requiring some holier-than-thou self-sacrifice. Certainly, a dose of self-sacrifice is called for. But if you want to be not simply altruistic but also effective, the best default way of behaving in many situations may be the rationally egoistic one.</span></p>\n<p>&#xA0;</p></body></html>", "user": {"username": "zdgroff"}}, {"_id": "HbunzTyFPRwcYihg6", "title": "Long-lasting insecticide treated nets: $3,340 per life saved, $100 per DALY averted. How is this calculated?", "postedAt": "2015-07-13T16:08:20.169Z", "htmlBody": "<html><body><p>&#xA0;</p>\n<p><span>Disclaimer: </span><span>This is my personal opinion and does not reflect the opinions of Giving What We Can or any particular other organisation. This is a draft.</span></p>\n<p><span><br></span></p>\n<p>Many people have heard that it costs about US$ 3,340 to save a life by distributing insecticide treated bed nets and ~$100 to enable a life of health i.e. $100 per Disability-adjusted life year (DALY) averted. Where do these numbers come from? How are they calculated? And how do they relate to each other?</p>\n<p>&#xA0;</p>\n<p>These numbers are based on a calculation from Givewell&#x2019;s review of the Against Malaria Foundation<sup><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt1\">[1]</a></sup>.&#xA0;Givewell caveats that these estimates should be used with caution due to significant uncertainty around them, but that it is useful for comparative purposes and to &#x201C;think through as many of the relevant issues as possible&#x201D;<sup><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt2\">[2]</a></sup>.</p>\n<p>&#xA0;</p>\n<p>Givewell&#x2019;s spreadsheet<sup><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt3\">[3]</a></sup>&#xA0;shows that they take the average overall costs for bednet distributions by AMF and divide them by the expected lives saved / death averted &#x201C;per protected child under 5&#xA0;&#x2013;&#xA0;adjusted for today&apos;s lower rates of child mortality and insecticide resistance&#x201D;. The later estimate also takes into account factors such as wastage, years of protection per person per net, and pre-existing net ownership. This calculation gives us the $3,340 per life saved / deaths averted figure.</p>\n<p>&#xA0;</p>\n<p>But where does the $100 per DALY averted figure come from? And why does it cost $3,340 to avert a death of an 5-year-old child, which has a life expectancy of ~80 years, but ~$100 to enable a year of health life? Shouldn&#x2019;t it be ~$40 per DALY averted (i.e. $3340 /&#xA0;80 years)?&#xA0;<span>The answer is that the $</span><span>100</span><span>&#xA0;figure per DALY averted is time discounted at 3%.&#xA0;</span>If one were to not time discount then it would indeed only be ~$40 per DALY averted. But if one time discounts ~80 DALYs at 3%, then they become ~30 DALYs (see&#xA0;<sup><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt4\">[4]</a></sup>&#xA0;for the conversion table used and&#xA0;<sup><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt5\">[5]</a></sup>&#xA0;to read more about time discounting). You might have noticed that 30*100 is $3000 and not $3,340. This is because the average DALY averted figure used is actually ~$112.5 (in Malawi it&#x2019;s $98 per DALY averted, whereas in the DRC it&#x2019;s $125 per DALY averted). 112.5*30 = 3375,&#xA0;which is pretty much the&#xA0;stated $3,340,&#xA0;with the discrepancy being due to rounding errors.</p>\n<p>Incidentally, these figures are similar to&#xA0;the one published in a recent&#xA0;<span>Lancet&#xA0;</span>article<sup><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt6\">[6]</a></sup>, which estimates that, in low-income countries, to save a child&apos;s life, the cost is US$4205.</p>\n<p>&#xA0;</p>\n<p>&#xA0;</p>\n<div>\n<p><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt_ref1\">[1]</a><span>&#xA0;&quot;Against Malaria Foundation (AMF) | GiveWell.&quot; 2010. 13 Jul. 2015 &lt;</span><span><a href=\"http://www.google.com/url?q=http%3A%2F%2Fwww.givewell.org%2Finternational%2Ftop-charities%2FAMF%23Costperlifesaved&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFuJath2O3m-UhklSNStp8Z2miuXA\">http://www.givewell.org/international/top-charities/AMF#Costperlifesaved</a></span><span>&gt;</span></p>\n</div>\n<div>\n<p><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt_ref2\">[2]</a><span>&#xA0;&quot;Against Malaria Foundation (AMF) | GiveWell.&quot; 2010. 13 Jul. 2015 &lt;</span><span><a href=\"http://www.google.com/url?q=http%3A%2F%2Fwww.givewell.org%2Finternational%2Ftop-charities%2FAMF%23Costperlifesaved&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFuJath2O3m-UhklSNStp8Z2miuXA\">http://www.givewell.org/international/top-charities/AMF#Costperlifesaved</a></span><span>&gt;</span></p>\n</div>\n<div>\n<p><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt_ref3\">[3]</a><span>&#xA0;</span><span><a href=\"http://www.google.com/url?q=http%3A%2F%2Fwww.givewell.org%2Finternational%2Ftop-charities%2FAMF%23footnote81_jlayyrw&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNHQ-ujGgY2sZSqnH3wtOmSszdFpqw\">http://www.givewell.org/international/top-charities/AMF#footnote81_jlayyrw</a></span></p>\n</div>\n<div>\n<p><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt_ref4\">[4]</a><span>&#xA0;See Lopez et al. 2006, Table 5.1, Pg 402&#xA0;</span><span><a href=\"http://www.google.com/url?q=http%3A%2F%2Fwww-wds.worldbank.org%2Fexternal%2Fdefault%2FWDSContentServer%2FWDSP%2FIB%2F2006%2F06%2F06%2F000160016_20060606163437%2FRendered%2FPDF%2F364010PAPER0Gl101OFFICIAL0USE0ONLY1.pdf&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFZdQgolJP9FGtkxNtfdjaOvd7v_Q\">http://www-wds.worldbank.org/external/default/WDSContentServer/WDSP/IB/2006/06/06/000160016_20060606163437/Rendered/PDF/364010PAPER0Gl101OFFICIAL0USE0ONLY1.pdf</a></span><span>&#xA0;</span></p>\n</div>\n<div>\n<p><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt_ref5\">[5]</a><span>&#xA0;Ord, Toby, and Robert Wiblin. &quot;Should we discount future health benefits when considering cost-effectiveness?.&quot;</span></p>\n</div>\n<div>\n<p><a href=\"https://docs.google.com/document/d/1WGpMix0NbN1R2Fr6__wC1G6LigJbNAigk-vnYyFBBcw/pub#ftnt_ref6\">[6]</a><span>&#xA0;&quot;Keeping score: fostering accountability for children&apos;s lives ...&quot; 2015. 13 Jul. 2015 &lt;</span><span><a href=\"http://www.google.com/url?q=http%3A%2F%2Fwww.thelancet.com%2Fjournals%2Flancet%2Farticle%2FPIIS0140-6736(15)61171-0%2Ffulltext%3Frss%3Dyes&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFjp3faX7DovfEl6JemegAct3gCcQ\">http://www.thelancet.com/journals/lancet/article/PIIS0140-6736(15)61171-0/fulltext?rss=yes</a></span><span>&gt;</span></p>\n</div></body></html>", "user": {"username": "HaukeHillebrandt"}}, {"_id": "tfyMZqare9ZfCn3pA", "title": "Should EAs influence corporate giving?", "postedAt": "2015-07-13T02:28:04.883Z", "htmlBody": "<html><body><p><em>EDIT: As commenters below point out, my post was poorly named! The question my post actually addresses is something closer to &quot;Should we spread the brand and philosophy of the EA movement to corporate giving?&quot; (To which my answer is &quot;not yet.&quot;) There is a separate question, which is, &quot;Should we make corporate giving more effective?&quot; that I do not tackle. (The answer to this question is probably, &quot;Yes, as long as we err on the side of caution in our use of the EA brand. The Giving What We Can, The Life You Can Save, and the GiveWell sub-brands might be more appropriate here.&quot;)</em></p>\n<hr>\n<p>Some time ago, I set off on a plan to use this year&apos;s <a href=\"http://eaglobal.org\">EA Global</a> to improve corporate giving. This plan included the sketch of a <a href=\"https://docs.google.com/document/d/150ygMKZxornW7DPx3lJ4IMhTkp6jcjfb-t7MpuY3-x4/edit?usp=sharing\">corporate engagement model</a>&#xA0;aimed at steering billions of dollars to the best bets for saving and improving lives. The thought was that we&apos;d get a half-dozen high-level people in corporate giving to publicly support this model.</p>\n<p>I now think this plan was not well-considered, and have since put it on pause. Here&apos;s why.&#xA0;</p>\n<p>There are a number of reasons why the EA movement should be careful about large-scale attempts to influence giving in general, and corporate giving in particular at this early stage of the movement. The first two reasons detail why instituting truly EA giving policies may be intractable at this point in the movement&apos;s development. The last reason details why it might be net negative to influence large-scale corporate giving at present.</p>\n<h2>1. EA conclusions are idiosyncratic</h2>\n<p><a href=\"/ea/9s/effective_altruism_is_a_question_not_an_ideology/\">As Helen Toner put it best</a>, EA is principally about asking the question, &quot;How can I do the most good?&quot; (Or, less controversially, but somewhat less accurately, &quot;How can I save and improve the most lives?&quot;) This question regularly yields answers that likely feel too weird for the public at present, such as &quot;Support meta-charity&quot; or &quot;Prevent existential risks.&quot;</p>\n<p>Since much of corporate giving is understandably tied to PR, I suspect that many corporate philanthropists will feel constrained in their ability to sync their giving policies with off-beat giving opportunities, even if they believe that those opportunities are the best ones.</p>\n<p>Three caveats to this conclusion:</p>\n<ol>\n<li>The public&apos;s sense of what&apos;s weird can change quite rapidly. (See, e.g., gay rights.) In the future, if EA is successful as it currently seems on track to be, many EA conclusions may lose their stigma. In fact, it may become the case that <em>not</em> having an EA-based giving policy is a PR problem for many companies.</li>\n<li>There are some companies for which seeming innovative at the cost of controversy might be the right tradeoff. For example, let&apos;s say SpaceX wants to attract visionary employees who have critical thinking abilities. It might make sense for SpaceX to support more unusual EA conclusions in its public giving policy.</li>\n<li>If GiveWell/<a href=\"http://openphilanthropy.org\">Open Philanthropy Project</a> increase dramatically in status over the next few years, it might become permissable for a company to outsource its corporate giving policy to these initiatives. Outsourcing giving policies to another org might give companies a PR shield, since the giving decisions become one step removed. For instance, it would be hard to imagine a company publicly backing a charity which creates more pleasurable condoms to encourage birth control in developing countries. However, you can imagine a company contributing their funds to the Gates Foundation, even if the Gates Foundation decides to fund a few controversial initiatives (such as the condoms one).</li>\n</ol>\n<h2>2. Prioritization itself is controversial</h2>\n<p>The question, &quot;How can I save and improve the most lives?&quot; practically entails the assumption that there are some ways of saving/improving lives are better than others. From there, you get the importance of cause prioritization. This is still a controversial idea. E.g., a company might get flack for matching GiveWell/Open Phil-recommended donation while declining to match donations to unsupported nonprofits.</p>\n<h2>3. EA is still young and fragile</h2>\n<p>If we think global coordination on the world&apos;s best do-gooding opportunities is important, then we better do a good job of protecting some of the best things about the EA movement.</p>\n<p>EA is currently one of the best bets out there for creating global coordination. This is because:</p>\n<ol>\n<li>EAs approximately agree on ethics. E.g., that we should focus on saving/improving lives rather than on maximizing other things as ends-in-themselves. (For example: I&apos;d guess 99% of EAs would agree that they don&apos;t support maximizing something like, &quot;cultural richness&quot; if specific ways of maximizing that richness don&apos;t significantly improve lives.)&#xA0;</li>\n<li>EAs approximately agree on methodology (incl. standards of reason and evidence) when answering the question, &quot;How can I save/improve the most lives.&quot;</li>\n</ol>\n<p>This approximate agreement on values and methodology makes it possible for the words &quot;effective altruism&quot; to entail something quite substantive. It also enables EAs to coordinate even across dramatically different cause areas.</p>\n<p>However, given that the EA movement is still at an early stage, it is still possible for the words &quot;effective altruism&quot; to be co-opted and lose their current substance. My sense is that the ethical and intellectual core of EA needs much greater fortification before EA should be spread too widely, including via corporate giving reform. (At EA Outreach, we&apos;ve become fond of saying that we&apos;re currently in the &quot;movement-development&quot; business, rather than in the &quot;movement-building&quot; one.)</p>\n<p>For instance, it would be a really bad scenario if Twitter announced that they are adopting an EA-based giving policy if that giving policy lacked pieces like cause-prioritzation or focused too much the public&apos;s attention on a narrow definition of EA (e.g. that EA is <em>only</em> about charitable giving). Twitter has a bigger megaphone than we do, and can probably influence the meaning of the words &quot;effective altruism&quot; to a greater degree than we can.</p>\n<p>If you weaken the ethical and intellectual core of EA, you run the risk of undermining the community&apos;s ability to reach consensus on the best world-improvement opportunities, and then coordinate resources toward those opportunities.</p>\n<p>&#xA0;</p>\n<p>All that said, I still think people should take on the mission of improving corporate giving. However, they should practice the utmost care while doing so!</p>\n<p>Thoughts? Questions? Rebuttals?&#xA0;</p></body></html>", "user": {"username": "tyleralterman"}}, {"_id": "NKzY7oBZKXk87gFpz", "title": "Looking for EA work for your spare time? Look at (and add to) this list!", "postedAt": "2015-07-12T20:07:20.000Z", "htmlBody": "<html><body><p><a href=\"http://www.dotimpact.im\">.impact</a> is having it&apos;s <a href=\"https://www.facebook.com/events/1592346627696411/\">second workathon</a> (happening <a href=\"https://www.facebook.com/events/1592346627696411/\">now</a>! r<a href=\"/ea/kq/the_first_impact_workathon/\">ead about the first one here</a>) and one thing we&apos;re trying to get a clearer picture on is what useful things people can be doing to have an impact in their free time. &#xA0;Last time <a href=\"/ea/fr/a_call_for_ideas_ea_ventures/\">EA Ventures put out their call for EA project ideas</a> they got a lot of feedback. &#xA0;I&apos;m hoping we can do that again.</p>\n<p><strong>Therefore I&apos;m posting all of .impact&apos;s project ideas in this thread as comments on this thread.</strong> &#xA0;You can discuss individual project ideas in the comments. &#xA0;You can vote up the projects you think are highest impact. &#xA0;You can vote down the projects you expect to be a complete waste of time, though be friendly and explain why you think so in the comments. &#xA0;And you can add your own project ideas here!</p>\n<p>&#xA0;</p>\n<h2><strong>What are the criteria for adding a project?</strong></h2>\n<p><strong></strong>We&apos;re looking for projects that can be moved forward with less than ten hours of work a week. &#xA0;If it&apos;s to the point where working on this project requires quitting your full-time job, I suggest you look to <a href=\"http://www.eaventures.org/\">EA Ventures</a> instead.</p>\n<p>&#xA0;</p>\n<h2>Where Should You Start?</h2>\n<p>There are a bunch of activities that every EA can do to boost their own impact. &#xA0;This is a great starting point for anyone who is interested. &#xA0;Use the <a href=\"http://jacobhilton.github.io/findmeatask/\">EA Task Suggester</a> to find one of these tasks.</p>\n<p>Particularly high leverage tasks include:</p>\n<p>&#xA0;</p>\n<ul>\n<li><a href=\"http://www.charityscience.com/shop-for-charity.html\">Donate 5% of your Amazon purchases to SCI at no cost to you.</a></li>\n<li>Also sign up for <a href=\"http://smile.amazon.com/\">Amazon Smile</a> for an additional 0.5% (5.5% total). &#xA0;Amazon Smile has many charity choices. &#xA0;You can find GiveWell as &quot;The Clear Fund&quot; (their legal name).</li>\n<li><a href=\"http://www.charityscience.com/birthday-fundraisers.html\">Run a charity fundraiser for your birthday.</a></li>\n<li><a href=\"http://effectivealtruismhub.com/groups\">Join a local EA meetup</a> or <a href=\"http://effectivealtruismhub.com/groups/add\">start your own</a>!</li>\n<li>Stay informed about what organizations are up to by following <a href=\"http://www.thelifeyoucansave.org/Get-Involved/Newsletter\">The Life You Can Save mailing list</a>, <a href=\"http://www.givewell.org/about/stay-updated\">GiveWell mailing list</a>, and <a href=\"http://www.animalcharityevaluators.org/about/media/newsletter/\">Animal Charity Evaluators mailing list</a>.&#xA0;</li>\n<li>Talk to friends about GiveWell, 80K Hours, etc.</li>\n<li>Post EA articles on your social media.</li>\n</ul>\n<p>-</p>\n<p><strong>If you have a comment other than a project idea, <a href=\"/ea/ku/looking_for_ea_work_for_your_spare_time_look_and/4c5\">comment here</a>.</strong></p></body></html>", "user": {"username": "Peter_Hurford"}}]