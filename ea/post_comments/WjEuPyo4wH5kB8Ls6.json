[{"_id": "GzpgDmyyP7kP8QpDD", "postedAt": "2024-03-18T03:50:54.622Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<p>TBH this is me putting my tin foil hat on a bit, but even if my most paranoid thoughts are ruled out, it is still a weirdly under-discussed issue in the space and I'm cashing in all my chips for the Amnesty Week thing. Yolo.</p>", "parentCommentId": null, "user": {"username": "Yanni Kyriacos"}}, {"_id": "S9obn2sLTZC55QxKW", "postedAt": "2024-03-18T03:57:04.223Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<p>This (not getting more AIS orgs off the ground) seems like a coordination problem. EA can solve this, but we might need more public discussion to get the process kicked off.</p>", "parentCommentId": null, "user": {"username": "Yanni Kyriacos"}}, {"_id": "PMiK9FQacvcQhgTGF", "postedAt": "2024-03-18T05:36:32.681Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<p>\"As shown in this table 0% of CE staff (including me) identify AI as their top cause area. I think across the team people's reasons are varied but cluster around something close to epistemic scepticism. My personal perspective is also in line with that.\"</p>\n<p>A quote from Joey replying to your last post. Why would you start an org around something none of your staff have as their top cause area? All CE charities to date have focused on global development or animal welfare, why would they switch focus to AI now? Doesn't seem so mysterious to me anyway.</p>\n", "parentCommentId": null, "user": {"username": "NickLaing"}}, {"_id": "xndkMoh3ouenujjKu", "postedAt": "2024-03-18T06:13:55.405Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<p>AIM simply doesn't rate AI safety as a priority cause area. It's not any particular organisation's job to work on your favourite cause area. They are allowed to have a different prioritisation from you.</p>", "parentCommentId": null, "user": {"username": "David Mears"}}, {"_id": "RFfForkhGjMsfrA2J", "postedAt": "2024-03-18T06:44:12.707Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<blockquote><p>The AI Safety space has LOADS of very smart people that can't get jobs because there aren't enough organisations to hire them. It might be the biggest bottleneck in the cause area. Meanwhile, capabilities literally has dozens of billions being thrown into it</p></blockquote><p>Is not enough organizations really the problem? For technical AI safety research, at least, I hear research management capacity is a bottleneck. A new technical AI safety org would compete with the others over the same potential research managers.</p><p>Another issue could be that <a href=\"https://forum.effectivealtruism.org/posts/pxALB46SEkwNbfiNS/the-motivated-reasoning-critique-of-effective-altruism?commentId=6yFEBSgDiAfGHHKTD\">few interventions seem net positive</a> (maybe things have changed since that comment 3 years ago).</p>", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "oWyrbCzBQCkdHB76e", "postedAt": "2024-03-18T11:11:53.901Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<p>I think Yanni isn't writing about personal favourites. Assuming there is such a thing as objective truth, it makes sense to discuss cause prioritization as an objective question.</p>\n", "parentCommentId": "xndkMoh3ouenujjKu", "user": {"username": "rmoehn"}}, {"_id": "t2Ljr2cBFfjSxsAzr", "postedAt": "2024-03-18T21:01:55.690Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<p>Just as <a href=\"https://forum.effectivealtruism.org/posts/zuqpqqFoue5LyutTv/the-ea-community-does-not-own-its-donors-money\">the EA community does not own its donors' money </a>-- one of the most upvoted posts ever -- it also doesn't own the financial sacrifices people at A.I. make to do the work they think is important. People who donate to, and work at, A.I. know that it has a neartermist focus.</p><p>Looking at funding trends over the past few years, it seems relatively easier for new/newish AI safety organizations to get supported than new/newish global health or animal advocacy organizations. For example, <a href=\"https://forum.effectivealtruism.org/s/GcxnnGRGy8bondvBB/p/DaRvpDHHdaoad9Tfu\">Redwood </a>got over $20MM in funding from EA sources in the first ~2 years of its existence. Although the funding bar may be higher now than when those grants were made, I'm not convinced that the bottleneck here is that new AI safety orgs can't get the support needed to launch.</p>", "parentCommentId": null, "user": {"username": "Jason"}}, {"_id": "NdKd7gorJmpGzsJuA", "postedAt": "2024-03-20T00:13:10.969Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<p>Sorry, it is so confusing to refer to AIM as 'A.I.', particularly in this context...</p>", "parentCommentId": "t2Ljr2cBFfjSxsAzr", "user": {"username": "David Mears"}}, {"_id": "2eiunnxSHs23qdbGy", "postedAt": "2024-03-21T23:58:38.011Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<p>Yeah that was me attempting to be a bit cheeky but probably not worth it in exchange for clarity.</p>", "parentCommentId": "NdKd7gorJmpGzsJuA", "user": {"username": "Yanni Kyriacos"}}, {"_id": "JhSzaDcWxhhZZXry6", "postedAt": "2024-03-22T00:01:53.938Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<p>Hmmm, I think the fact that you felt this was worth pointing out AND that people upvoted it, means that I haven't made my point clear. My major concern is that there are things known about the challenges that come with incubating longtermist orgs that aren't being discussed openly.&nbsp;</p>", "parentCommentId": "xndkMoh3ouenujjKu", "user": {"username": "Yanni Kyriacos"}}, {"_id": "vKeduuhifDPBpzeya", "postedAt": "2024-03-22T00:04:36.246Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<p>That's an interesting hypothesis. I think \"seem\" is an important word, because it points to me something I see as another issue - inaction leading from conservativeness, leading to capabilities pulling even further away.</p>", "parentCommentId": "RFfForkhGjMsfrA2J", "user": {"username": "Yanni Kyriacos"}}, {"_id": "rWbA6JRRu5ydiHY4T", "postedAt": "2024-03-22T04:06:53.267Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<p>Maybe I misunderstood you.</p>\n<p>I think AIM doesn\u2019t constitute evidence for this. Your top hypothesis should be that they don\u2019t think AI safety is that good of a cause area, before positing the more complicated explanation. I say this partly based on interacting with people who have worked at AIM.</p>\n", "parentCommentId": "JhSzaDcWxhhZZXry6", "user": {"username": "David Mears"}}, {"_id": "WwBRTM9n3ie3SwMDY", "postedAt": "2024-03-22T10:31:37.922Z", "postId": "WjEuPyo4wH5kB8Ls6", "htmlBody": "<blockquote>\n<p>All CE charities to date have focused on global development or animal welfare</p>\n</blockquote>\n<p>CE incubated Training for Good, which runs two AI-related fellowships. They didn\u2019t start out with an AI focus, but they also didn\u2019t start out with a GHD or animal welfare focus.</p>\n", "parentCommentId": "PMiK9FQacvcQhgTGF", "user": {"username": "bec_hawk"}}]