[{"_id": "BXpBKNFX6Pv3AReYg", "postedAt": "2022-10-29T20:14:31.532Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p>\u201cUnlike effective altruists, longtermists don\u2019t really care about famines or floods because those won\u2019t lead to extinction\u201d</p>\n<p>I think this is an accurate characterization of the popular EV-maximizing total utilitarian longtermist worldview within the community. Note the \"really\", indicating that it's approximately true. I would be less comfortable attributing this view to longtermists as individuals, as a community or to weaker forms of longtermism, since longtermists aren't necessarily 100% bought into longtermism this strong.</p>\n<p>Also, even shortermist EAs don't really care about famines or floods, as evidenced by our lack of work on these problems because there are still more cost-effective (less neglected) things to work on.</p>\n<p>Rather than prioritization explaining that we do care, prioritization explains why we don't really care.</p>\n", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "Dc5omp9cbZhvGJxYA", "postedAt": "2022-10-29T21:24:43.302Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p>Let's taboo the word \"care\". &nbsp;I expect the average longtermist thinks that deaths from famines and floods are about as bad as the average non-longtermist EA. &nbsp; &nbsp;Problems do not become \"less bad\" simply because other problems exist.</p><p>Having different priorities, stemming from different beliefs about e.g. what things matter and how effectively we can address them, is orthogonal to relative evaluations of how bad any individual problem is.</p>", "parentCommentId": "BXpBKNFX6Pv3AReYg", "user": {"username": "T3t"}}, {"_id": "bMr5rEokPxvdcxz7X", "postedAt": "2022-10-29T21:49:43.060Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p><strong>Hossenfelder's final statement on Longtermism</strong></p><p>I watched the video. Starting at 14:45, she spends the last minute of the video giving an appreciative take on longtermism (it makes sense to protect the long-term future, but that you also have to protect present-day people and the environment in order to do so).</p><p><strong>How the political hit job works</strong></p><p>The previous ~15 minutes are a political hit job, using these techniques:</p><ol><li>Grab a couple of potentially offensive-sounding sound bites from old papers, misrepresent and spin them to give a false impression of longtermist discourse (i.e. say that longtermists consider present-day people to be \"expendable\").</li><li>Repeat the nastiest-sounding criticisms from newspaper columnists.</li><li>Zeroing in on associations with Silicon Valley billionaires.</li><li>Pit longtermists and non-longtermist EAs against each other (i.e. focusing on Peter Singer's criticism of Toby Ord complaining that too much money is spent on global health and not enough on longtermism).</li><li>Claims of things \"real longtermists\" should do that nobody, including longtermists, actually do (i.e. asserting that longtermism insists we have as many babies as possible, so we should all diet, so we should all stop eating chips).</li><li>Knocking down weakman/strawman arguments for longtermism.</li></ol><p><strong>How I'd prefer EA/longtermism respond to such criticisms</strong></p><p>There are critical arguments in this video worth taking seriously, as listed in the OP. Hossenfelder is far from the first person to notice or be uncomfortable with them.</p><p>I find it suspect if what prompts us to engage with an argument is that Sabine Hossenfelder yelled at us about it on her Youtube channel. That makes me think both that we don't actually care about the criticism (we're just feeling defensive), and also that we're probably focusing on the wrong arguments (because hit-job critics like Hossenfelder are optimizing for making their targets look and feel bad, not the substantive problems with their targets).</p><p>If we're interested in taking those arguments seriously, we should either make them ourselves, or cite sources that do so in a professional and collegial manner. I think this is basic to self-respect. I would not tolerate the kind of cruelty Hossenfelder showers on longtermism from friends, colleagues, or teachers, and I don't particularly want to receive it from the movements I look to for decision-making advice and information.</p>", "parentCommentId": null, "user": {"username": "AllAmericanBreakfast"}}, {"_id": "Y4nCgCEjvtEmCW7Yg", "postedAt": "2022-10-29T21:57:59.519Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p>They don't become less bad, but we pay less attention and devote fewer resources to them, which is a very plausible way of interpreting \"caring less\". On this interpretation, it's psychologically implausible that we can care as much about these other problems as others can, even if our abstract utility functions don't say they matter any less just because other things matter more.</p>\n<p>I don't think the right response is to argue some definitional point. We should just own that we care less on a commonsense interpretation of the word, and explain why that's right to do.</p>\n", "parentCommentId": "Dc5omp9cbZhvGJxYA", "user": {"username": "MichaelStJules"}}, {"_id": "qzMDKGTjMxWgmkZih", "postedAt": "2022-10-29T22:46:32.564Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p>Just flagging that a group here in Israel, led by Sella Nevo, has been working on flood forecasting for years (among other cool projects).</p>\n", "parentCommentId": "BXpBKNFX6Pv3AReYg", "user": {"username": "Guy Raveh"}}, {"_id": "yWvAGQpf5qKrDourq", "postedAt": "2022-10-29T23:05:39.995Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p>I agree that the definitional point would be uninteresting, except that I think the commensense interpretation bundles a bunch of connotations which are wrong (and negative). &nbsp;In context, people receiving this message will have <i>systematically incorrect beliefs</i> about longtermism and those who use it as a framework for prioritization. &nbsp;This is plainly obvious if you e.g. go read pretty much any Twitter thread where people who are hearing about it for the first time (or were otherwise introduced to it in an adversarial context) are debating the subject.</p>", "parentCommentId": "Y4nCgCEjvtEmCW7Yg", "user": {"username": "T3t"}}, {"_id": "te5gb9cW5KkPHvTFX", "postedAt": "2022-10-29T23:48:45.017Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<blockquote><p>They don't become less bad, but we pay less attention and devote fewer resources to them, which is a very plausible way of interpreting \"caring less\".</p></blockquote><p>One meaning of \"caring\" (let's call it Caring-1) is the kind of care a parent provides for their child. This is precisely the type of care you're talking about here. It implies a responsibility to nurture, protect, and feel for and individual person, place, or thing. Common sense is that we have a responsibility to care for a very limited number of others in this way, and to at least be cognizant enough to do no harm to a much wider circle of others.</p><p>\"Caring\" can also refer to one's receptivity to \"chance encounters with other people's problems.\" Let's call this Caring-2.</p><ul><li>If you had a golden opportunity to help out with a certain problem, would you (\"Do you want a hand with that\")?</li><li>Do you approve of the fact that somebody out there is working on a certain problem (\"X is doing amazing work on this problem!\")?</li><li>Do you feel and express sympathy for a certain problem when it is brought to your attention (\"I'm so sorry\")?</li><li>Do you acknowledge the reality of the suffering various problems cause, even if you don't personally work on that problem yourself (\"that is a really serious issue\")?</li><li>Will you acknowledge that the problem seem like a plausible choice for extending Caring-1, even if you don't personally choose to do so (\"somebody should do somethign!\")?</li></ul><p>Nobody can provide Caring-1 to every issue. The difference between short-termists and longtermists is to what sorts of issues they extend or reject Caring-2.</p><ul><li>Longtermists may reject or downplay Caring-2 for major present-day issues (famines, floods, etc), in favor of extending either Caring-1 or Caring-2 for far-future issues (astronomical waste).</li><li>Short-termists may reject or downplay Caring-2 for far-future issues (astronomical waste) in order to focus more on present-day issues (famines and floods).</li></ul><p>Hossenfelder expresses around 14:45 that she approves of extending Caring-2 to both the short-term and long-term future. What bothers her is the idea that we should extend <i>no</i> caring-2 or caring-1 to the present day, as well as some of the more far-out ideas longtermist thinkers have explored (i.e. simulation arguments).</p><p>Of course, Hossenfelder, a theoretical physicist, is smart enough to make this distinction herself. The fact that she chooses not to, and couches her argument in such heated language, says to me that this is just another crude political hit-job.</p>", "parentCommentId": "Y4nCgCEjvtEmCW7Yg", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "3LeLPH9zz2WbrgGrD", "postedAt": "2022-10-30T14:42:14.482Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p>Hmm, although I think I get what you mean, I'm not sure how it could actually be true given that (preference) utility functions are scale and offset invariant, so the extent of an agent's caring can only be described relative to the other things they care about?</p>\n", "parentCommentId": "Dc5omp9cbZhvGJxYA", "user": {"username": "MakoYass"}}, {"_id": "LeTrQ2nGHiDRmH834", "postedAt": "2022-10-31T02:48:15.254Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p>I've watched a few of Sabine Hossenfelder's videos in the past.  She didn't previously strike me as a \"hit-job critic\" -- for example, I remember thinking <a href=\"https://www.youtube.com/watch?v=0kahih8RT1k\">this video</a> about nuclear power was reasonable (not an area I have expertise in, though).</p>\n<p>Your model here seems to be that Sabine set out to make a hit job on longtermism.  I think a more likely sequence of events was something like:</p>\n<ul>\n<li>\n<p>Sabine supplements her academic income by making Youtube videos about popular science.</p>\n</li>\n<li>\n<p>The more videos she makes, the more money she makes.</p>\n</li>\n<li>\n<p>Longtermism has been in the news recently; she decides to make a video about it.</p>\n</li>\n<li>\n<p>She reads some news coverage of longtermism that ends up shaping her thinking about longtermism quite a lot.</p>\n</li>\n<li>\n<p>The video ends up being essentially a repetition of talking points from the news coverage.</p>\n</li>\n</ul>\n<p>I think it's incorrect to believe that Sabine knows everything about longtermism that you do, and is seeking to intentionally distort it.  It seems more likely to me that she is just repeating what has become the popular narrative about longtermism by this point.  (Note: I haven't been paying much attention to longtermism news coverage.  This is just a guess.)</p>\n<p>\"Never attribute to malice that which can be adequately explained by neglect.\"  The video did not strike me as especially \"cruel\", in sense of deliberately seeking to cause harm.  \"Uncharitable\" or \"dismissive\" seems more like it.</p>\n<p>Anyway, if the above story is true, my takeaways would be:</p>\n<ul>\n<li>\n<p>Before popularizing a subtle idea like longtermism, there should be a red teaming process: thinking through how critics are likely to respond, and also how the meme might evolve when introduced to a broader audience.  (Imagine the person you like least, then imagine them justifying their worst idea using longtermism.  How to prevent this?)</p>\n</li>\n<li>\n<p>If it's worthwhile to popularize an idea like longtermism, it's worthwhile to do it right.  Responding to critics doesn't actually take that much time.  (80/20 rule: Responding to 20% of critics gets you 80% of the benefit.)  A few people can be paid to watch for longtermism discussion using Google Alerts etc. and offer polite corrections if bad arguments are made.  Polite corrections probably won't cause the person who made the bad argument to reverse their position, but they can be persuasive to onlookers.  If no counterargument is made, some onlookers will assume that's because no counterargument <em>can</em> be made, and some of those onlookers could be people who <em>also</em> have a big social media platform.  Standard EA advice to ignore most critics makes little sense to me.</p>\n</li>\n</ul>\n", "parentCommentId": "bMr5rEokPxvdcxz7X", "user": {"username": "John_Maxwell_IV"}}, {"_id": "dic3fQTCiWmhSN7fA", "postedAt": "2022-10-31T03:18:43.906Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<blockquote><p>Before popularizing a subtle idea like longtermism, there should be a red teaming process: thinking through how critics are likely to respond, and also how the meme might evolve when introduced to a broader audience. (Imagine the person you like least, then imagine them justifying their worst idea using longtermism. How to prevent this?)</p></blockquote><p>To me, this sounds like PR, and I agree with Anna Salamon that <a href=\"https://www.lesswrong.com/posts/SWxnP5LZeJzuT3ccd/pr-is-corrosive-reputation-is-not\">PR is corrosive, reputation is not</a>. I view myself here as defending longtermism's reputation, or honor. When &nbsp;somebody who's talking beyond their expertise besmirches the reputation of an idea, person, or group, then it's right to push back directly against this behavior. Not to try and somehow avoid that outcome from occurring by modifying how you show up in public.</p><blockquote><p>A few people can be paid to watch for longtermism discussion using Google Alerts etc. and offer polite corrections if bad arguments are made. Polite corrections probably won't cause the person who made the bad argument to reverse their position, but they can be persuasive to onlookers. If no counterargument is made, some onlookers will assume that's because no counterargument <i>can</i> be made, and some of those onlookers could be people who <i>also</i> have a big social media platform.</p></blockquote><p>I'd be supportive of a well thought through experiment to try this out. I am not sure how one would approach this, or get feedback. My own few experiences of trying to politely respond to public figures making ill-founded criticisms is that they just ignore me. I expect this would be the result.</p><p>Remember that Sabine Hossenfelder is a theoretical physicist. She went through and read papers. She is an extremely intelligent person. I am sure she's smarter than me. I think it is far more likely that she understood the ideas and deliberately decided to distort them for her own political agenda, or maybe just for clicks, than that she misunderstood them. I really think that longtermism is an easier topic to grasp than <a href=\"https://www.sciencedirect.com/science/article/pii/S0370269303014217\">Collider signatures in the Planck regime</a>. If she can publish the latter, I think she can grasp the former.</p>", "parentCommentId": "LeTrQ2nGHiDRmH834", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "LLTHx8xLkyLkZEohp", "postedAt": "2022-10-31T04:35:22.493Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<blockquote>\n<p>To me, this sounds like PR, and I agree with Anna Salamon that PR is corrosive, reputation is not.</p>\n</blockquote>\n<p>I think any effort to popularize longtermism is in some sense a PR effort.  If you're going to deliberately push a meme you should do it strategically.  (Edit: To be clear, I'm not advocating for dishonesty.)</p>\n<p>I think the \"corrosiveness of PR\" point applies more strongly to personal and organizational conduct than advocating for a new idea.</p>\n<blockquote>\n<p>My own few experiences of trying to politely respond to public figures making ill-founded criticisms is that they just ignore me. I expect this would be the result.</p>\n</blockquote>\n<p>Publicly admitting you're incorrect is disincentivized.  Probably if someone finds your counterpoint persuasive, they will not say so, in order to save face.  In any case, onlookers seem more important -- there are far more of them.</p>\n<p>Also, if the counterpoint is published by a professional, they'll have a bit more of a platform, so the likelihood of them getting ignored will be a bit lower.  (Edit: Clarification -- I'm advocating that you publish counterpoints specifically in places where people who saw the original are also likely to see the counterpoint.  So e.g. if you have more Twitter followers, your reply to their tweet will be more visible.)</p>\n<blockquote>\n<p>Remember that Sabine Hossenfelder is a theoretical physicist. She went through and read papers. She is an extremely intelligent person. I am sure she's smarter than me. I think it is far more likely that she understood the ideas and deliberately decided to distort them for her own political agenda, or maybe just for clicks, than that she misunderstood them. I really think that longtermism is an easier topic to grasp than Collider signatures in the Planck regime. If she can publish the latter, I think she can grasp the former.</p>\n</blockquote>\n<p>I'm not referring to the difficulty of grasping it so much as the amount of time that was put in.  Also, framing effects are important.  Maybe Sabine just skimmed the paper to verify that the claims made in the media were correct.  Maybe she doesn't have much experience with moral philosophy discourse norms.  (\"You would kill baby Hitler?  Stop advocating for infanticide!!\")</p>\n<p>I'm not sure what you think her agenda is.  If she was focused on advancing an agenda, such as attempting a \"hit job\", would it make sense to include the bit at the end about how she really appreciates the longtermist focus on the prevention of existential risks so we have a long-term strategy for the next 10 billion years?  My guess is she is not deliberately pushing an agenda, so much as fitting longtermism into an existing worldview without trying to steelman it (or, adopting a frame from a someone else who did this).</p>\n", "parentCommentId": "dic3fQTCiWmhSN7fA", "user": {"username": "John_Maxwell_IV"}}, {"_id": "jX6zxkzps5b2XSXJt", "postedAt": "2022-10-31T06:28:25.165Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<blockquote><p>Publicly admitting you're incorrect is disincentivized. Probably if someone finds your counterpoint persuasive, they will not say so, in order to save face. In any case, onlookers seem more important -- there are far more of them.</p></blockquote><p>Mostly, I've contacted authors via email. I never get responses. This doesn't really surprise me, since they don't know who I am, stand to gain nothing by replying, and they might worry I'd use any reply they gave me to disparage them in public. Point being, though, that it's really not easy to foster dialog with a person who's already taken the step of disparaging you, your ideas, or your community in public.</p><blockquote><p>I'm not referring to the difficulty of grasping it so much as the amount of time that was put in. Also, framing effects are important. Maybe Sabine just skimmed the paper to verify that the claims made in the media were correct. Maybe she doesn't have much experience with moral philosophy discourse norms. (\"You would kill baby Hitler? Stop advocating for infanticide!!\")</p><p>I'm not sure what you think her agenda is. If she was focused on advancing an agenda, such as attempting a \"hit job\", would it make sense to include the bit at the end about how she really appreciates the longtermist focus on the prevention of existential risks so we have a long-term strategy for the next 10 billion years? My guess is she is not deliberately pushing an agenda, so much as fitting longtermism into an existing worldview without trying to steelman it (or, adopting a frame from a someone else who did this).</p></blockquote><p>Let's taboo \"hit job,\" since it's adding heat rather than light at least in this discussion between us. I do think that it makes sense to acknowledge the common-sense (actual longtermist) viewpoint at the end in the context of making a political attack on longtermism. Hossenfelder knows that her audience is sympathetic to the view that we should care for the long-term future. That makes it difficult to just outright dismiss longtermism the way mainstream political ideologies dismiss each other.</p><p>So she has to present an insane type of what we might call \"no chips\" longtermism, then argue against that, with the little caveat at the end. This is going to be just one of many examples to code longtermism as some sort of whacko right-wing hypernatalist escape from the burning wreckage of Earth to Mars for the rich 0.1% fantasy.</p><p>Having watched the video, I just frankly find it hard to believe that anybody would watch it and not see it as a clear politically motivated attack/smear attempt on longtermism.</p><p>It's not so much a sense that you're seeing the young woman and I'm seeing the old lady.</p><figure class=\"image\"><img src=\"https://cdn.mos.cms.futurecdn.net/rQkQZ6pDZbEHz23rxckWPm-320-80.jpg\"></figure><p>This isn't meant to be disparaging, but it's more a sense that I'm seeing the rabbit, while you're simultaneously claiming you're not colorblind but do not see the rabbit.</p><figure class=\"image\"><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/56a6654bed603eb6e8bc5141d695628de1425ca0270ac5d9.jpeg\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/56a6654bed603eb6e8bc5141d695628de1425ca0270ac5d9.jpeg/w_145 145w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/56a6654bed603eb6e8bc5141d695628de1425ca0270ac5d9.jpeg/w_225 225w\"></figure><p>I'm truly confused both about how you can watch Hossenfelder's video and not see it as a politically motivated attack, and also about how you imagine, in practical terms, that longtermism could have avoided becoming a target for such attacks.</p>", "parentCommentId": "LLTHx8xLkyLkZEohp", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "Fd5ZAwwTkkrXhz8yX", "postedAt": "2022-10-31T08:06:04.834Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<blockquote>\n<p>I'm truly confused both about how you can watch Hossenfelder's video and not see it as a politically motivated attack</p>\n</blockquote>\n<p>Supposing it <em>is</em> a politically motivated attack, what do you think her motivation was?  Why would she craftily seek to discredit longtermism in the way you describe?  I think that's the biggest missing piece for me.</p>\n<p>(I also think it's dangerous to mistake criticism for deliberate persecution.)</p>\n<blockquote>\n<p>how you imagine, in practical terms, that longtermism could have avoided becoming a target for such attacks.</p>\n</blockquote>\n<p>One of the most common ways to argue in moral philosophy is to make use of intuition pumps.  For example: \"Do you believe fighting global warming should be a top priority, even if it means less growth in developing countries and therefore more suffering in the near term?  If so, how would you justify that?\"</p>\n", "parentCommentId": "jX6zxkzps5b2XSXJt", "user": {"username": "John_Maxwell_IV"}}, {"_id": "dmHZ7o9KE4xSEddvD", "postedAt": "2022-10-31T12:15:00.767Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p>Can you say more about how you see intuition pumps as a potential way for longtermism to avoid political attacks? Seems to me we use them all the time.</p>\n<p>I think EA and longtermism are both coming under attack now because they are a currently visible/trendy competitor in the moral marketplace of ideas. I don\u2019t have a great explanation for why people do this, but it\u2019s a traditional human hobby. It just seems like a typical case of attacking a perceived outgroup, either because they seem like a legitimate threat to one\u2019s own influence or because you think your followers will enjoy the roast.</p>\n", "parentCommentId": "Fd5ZAwwTkkrXhz8yX", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "oJCJfTt9qz6So8RQz", "postedAt": "2022-10-31T18:46:27.373Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<blockquote>\n<p>Can you say more about how you see intuition pumps as a potential way for longtermism to avoid political attacks? Seems to me we use them all the time.</p>\n</blockquote>\n<p>The thought is to tailor the intuition pump for your audience, e.g. if your audience is left-wing, leverage moral intuitions they already have.</p>\n", "parentCommentId": "dmHZ7o9KE4xSEddvD", "user": {"username": "John_Maxwell_IV"}}, {"_id": "3uwMc55TD2zJBF3xs", "postedAt": "2022-10-31T18:49:36.941Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p>I guess I'm not sure when the point is that you transition from writing straightforward academic articles to writing politically-targeted articles. Hossenfelder said she skipped reading the more recent work (i.e. MacAskill's \"Doing Good Better\") in favor of looking at old papers published before longtermism/EA was in the news. So unless weird little nascent philosophical movements are couching their arguments in language appealing to every possible future political critic years before those critics will deign to even read the paper, it doesn't seem like this strategy could have prevented Hossenfelder's criticism.</p>", "parentCommentId": "oJCJfTt9qz6So8RQz", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "8r26W8N3qxK4ZpZ7r", "postedAt": "2022-10-31T20:13:45.409Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<blockquote><p>The thought is to tailor the intuition pump for your audience</p></blockquote><p>I would expect this would make the problem worse, because these attacks come from people looking for stuff to quote, and if you are saying different things to different people they can quote the stuff you said in one context to people in another.</p>", "parentCommentId": "oJCJfTt9qz6So8RQz", "user": {"username": "Larks"}}, {"_id": "o9vRKN2wF38LoN8tL", "postedAt": "2022-10-31T22:37:38.841Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<blockquote><p>even if our abstract utility functions don't say they matter any less just because other things matter more</p></blockquote><p>A utility function can't say anything else, in decision theory. Total caring is, roughly speaking, conserved.</p><p>The psuedo utility functions that a hedonic utilitarian projects onto others <i>can </i>introduce more caring for one thing without reducing their caring for other things, but they're irrelevant in this context. (and if you ask me, a preference utilitarian, they're not very relevant in the context of utilitarianism either, but never mind that.)</p>", "parentCommentId": "Y4nCgCEjvtEmCW7Yg", "user": {"username": "MakoYass"}}, {"_id": "JkE2MuXoC4byGsjp8", "postedAt": "2022-11-01T13:07:57.833Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p>I'm concerned by people connecting longtermism to Elon Musk (whom I think it's becoming increasingly harmful and naive) and I would be curious how the EA community van deal with him</p>\n", "parentCommentId": null, "user": {"username": "SiebeRozendal"}}, {"_id": "pRbN3okgm6BySrppr", "postedAt": "2022-11-08T08:33:11.336Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p><a href=\"https://twitter.com/willmacaskill/status/1554378994765574144\">Will MacAskill wrote a Twitter thread</a> about agreements + disagreements with Elon after Elon recommended WWOTF and said \"this is a close match for my philosophy.\"</p>", "parentCommentId": "JkE2MuXoC4byGsjp8", "user": {"username": "jakubkraus07@gmail.com"}}, {"_id": "uApCzYsynGyWoyiHa", "postedAt": "2022-11-08T08:39:21.476Z", "postId": "H35jDxtvvTpcgwuub", "htmlBody": "<p>Worth linking <a href=\"https://www.youtube.com/watch?v=aUBtdcdePE0\">this video</a> from <a href=\"https://benthams.substack.com/\">Bentham's Bulldog</a>, which critiques Sabine's video. It's nearly 90 minutes and sometimes optimizes for making fun of Sabine's video instead of giving a fair response, but it does have some good responses.</p>", "parentCommentId": null, "user": {"username": "jakubkraus07@gmail.com"}}]