[{"_id": "PR4qCCZ3sCkCJYhjF", "postedAt": "2023-12-03T14:03:54.950Z", "postId": "JCe8ykH9DtqPaCBbr", "htmlBody": "<blockquote><p>I define \u201coptimism\u201d as the tendency to weigh positive outcomes higher than their expected value and negative outcomes lower</p></blockquote><p>I don't think this is the definition that Pope &amp; Belrose are using. I think they are using it in the same sense as \"I'm optimistic about my relationship\": A genuine belief that something will go well.&nbsp;</p><p>I think they claim to be optimistic because they genuinely believe that the development of AI will have good effects and that significant harms are unlikely, and they want policies such as open sourcing to reflect that.&nbsp;</p>", "parentCommentId": null, "user": {"username": "titotal"}}, {"_id": "Y4FTuMDHLtttewvAE", "postedAt": "2023-12-03T15:21:01.692Z", "postId": "JCe8ykH9DtqPaCBbr", "htmlBody": "<p>I don't think that there's a huge difference. As long as there aren't very strong fact-based arguments for exactly how likely it is that we will be able to control AGI, my definition of \"optimists\" will end up with a significantly higher probability of things going well. From what I read, I believe that Belrose and Pope have this basic bias towards \"AGI is beneficial\" and weigh the upside potential higher than the downside risks. They then present arguments in favor of that position. This is of course just an impression, I can't prove it. In any case, even if they genuinely believe that everything they say is correct, they still should put in massive caveats and point out where exactly their arguments are weak or could be questioned. But that is not what a self-declared \"optimist\" does. &nbsp;So, instead they just present their beliefs. That's okay, but it is clearly a sign of optimism the way I define it.</p>", "parentCommentId": "PR4qCCZ3sCkCJYhjF", "user": {"username": "Karl von Wendt"}}, {"_id": "LvzsSXdzyhmwkNDKS", "postedAt": "2023-12-04T14:06:09.679Z", "postId": "JCe8ykH9DtqPaCBbr", "htmlBody": "<p><strong>Executive summary</strong>: The author argues that optimism can drive progress but becomes dangerous when downside risks are high, as with optimistic assumptions about AI safety.</p><p><strong>Key points:</strong></p><ol><li>Optimism motivates exploration and fuels adaptation, though often inefficiently. It likely evolved to promote growth despite negative expected outcomes.</li><li>However, optimism has downsides like wasted effort and becomes clearly problematic when potential harms are severe or irreversible.</li><li>AI safety intrinsically risks catastrophic and existential harms if control fails, so optimism seems unwarranted and dangerous absent strong arguments it is achievable.</li><li>More limited optimism about trying particular approaches to AI safety may still be warranted based on upside, even if success chances are low.</li><li>But general optimism about controlling any AGI system developed risks trivializing crucial safety issues and diminishing chances of averting disaster.</li></ol><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}, {"_id": "Ls5SmAKjhAjAw4DKo", "postedAt": "2023-12-05T17:26:06.076Z", "postId": "JCe8ykH9DtqPaCBbr", "htmlBody": "<p>This seems like a selective demand. I believe that doomers have a bias towards \"AGI is destructive\". Will you comment on doomer posts, demanding they add in massive caveats and point out exactly where their arguments are weak?&nbsp;</p><p>If you don't agree with Pope and Belrose, argue with them on the facts. Don't argue with disingenuous semantic games, and pretend that the word \"optimist\" doesn't have more than one definition in the dictionary.&nbsp;</p>", "parentCommentId": "Y4FTuMDHLtttewvAE", "user": {"username": "titotal"}}, {"_id": "ktky3ETrb5FvYjZcC", "postedAt": "2023-12-06T15:24:15.027Z", "postId": "JCe8ykH9DtqPaCBbr", "htmlBody": "<p>I agree that some \"doomers\" (you may count me as one) are \"pessimistic\", being biased towards a negative outcome. I can't rule out that I'm \"overly cautious\". However, I'd argue that this is net positive for AI safety on the same grounds that I think optimism as I defined it is net positive under different circumstances, as described.</p><p>I agree that the word \"optimism\" can be used in different ways, that's why I gave a definition of the way I usually use it. My post was a reaction to Pope and Belrose, but as I stated, not about their arguments but generally about being \"optimistic\" in the way I defined it. Nora Belrose said in a comment on LessWrong that my way of defining optimism is not how they meant it, and as long as I don't analyze their texts, I have to accept that. But I think my definition of optimism fits in the range of common uses of the word (see Wikipedia, for example). All I did was trying to point out that this kind of \"positive outcome bias\" may be beneficial under certain circumstances, but not for thinking about AI safety.</p><p>I believe that if Pope and Belrose try to have a truly rational and unbiased stance, the term \"AI Optimism\" is at least misleading, as it can be understood in the way I have understood it. I hope this post is at least helpful in the sense that I have pointed that possible misunderstanding out.</p>", "parentCommentId": "Ls5SmAKjhAjAw4DKo", "user": {"username": "Karl von Wendt"}}]