[{"_id": "fDzattSTjPHTL6DpH", "postedAt": "2014-09-22T10:24:15.736Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<blockquote>\n<p>When we first encounter a question, our initial aim is normally to work out: (i) who are the relevant experts? (ii) what would they say about this question?</p>\n</blockquote>\n<p>I think this is a valuable heuristic, but that it gets stronger by also trying to consider the degree of expertise, and letting that determine how much weight to put on it. The more the question is of the same type they routinely answer, and the more there are good feedback mechanisms to help their judgement, the stronger we should expect their expertise to be.</p>\n<p>For some questions we have very good experts. If I've been hurt by someone else's action, I would trust the judgement of a lawyer about whether I have a good case for winning damages. If I want to buy a light for my bike to see by at night, I'll listen to the opinions of people who cycle at night rather than attempt a first-principles calculation of how much light I need it to produce to see a certain distance.</p>\n<p>Some new questions, though, don't fall clearly into any existing expertise, and the best you can do is find someone who knows about something similar. I'd still prefer this over the opinion of someone chosen randomly, but it should get much less weight, and may not be worth seeking out. In particular, it becomes much easier for you to become more of an expert in the question than the sort-of-expert you found.</p>\n", "parentCommentId": null, "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "wYwdSbpyk3xcdtTwP", "postedAt": "2014-09-22T12:24:44.001Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>Excellent post. One minor question: what if one or two considerations actually do outweigh all others? </p>\n<p>I take it that <a href=\"http://en.wikipedia.org/wiki/The_Hedgehog_and_the_Fox\">hedgehogs (as opposed to toxes)</a> are biased in the sense that they are prone to focus on a single argument or a single piece of evidence even when other argument or pieces of evidence should be considered. That seems to me to be a very common mistake. But, in cases where a single argument or a single piece of evidence is so overwhelming that other arguments or pieces of evidence become unimportant, it seems one actually should rely only on that single argument or piece of evidence.</p>\n", "parentCommentId": null, "user": {"username": "Stefan_Schubert"}}, {"_id": "WZPage89HLaSfDrcD", "postedAt": "2014-09-22T15:07:27.946Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>I think the right way is to weight each argument by its robustness and the significance of the conclusions i.e.:\nIf you have a strong argument that an action, A, would be very bad, then you shouldn't do A.\nIf you have a speculative argument that A would be very bad, then you probably shouldn't do A.\nIf you have a speculative argument that A would be a little bit bad, then that doesn't mean much.</p>\n", "parentCommentId": "wYwdSbpyk3xcdtTwP", "user": {"username": "Benjamin_Todd"}}, {"_id": "o3reoLNfA6ichMgYB", "postedAt": "2014-09-23T14:15:46.787Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>I'd add a consideration for relative evidence here. If you have an action, A, that you know little about aside from one speculative argument that A would be very bad, but no strong arguments, how does that work? </p>\n<p>Here's a relevant example: say we have two forms of animal rights advocacy. One (A) that has a speculative argument that is very very good in inspiring Democrats, but a strong argument that it's bad in inspiring Republicans. (These are the two main US political parties.) The other (B) has only a strong argument that's it's decent in inspiring Republicans. There is no other evidence. Normally, we'd take down the speculative argument in (A) with a strong, low prior, like we have for developing world health charities (since the base rates for success are pretty low and after in-depth investigation many ones with high speculative arguments turn out to be duds). But in this case, there is no strong prior. To maximize expected value, we should then lean towards (A) in this example, even though this is, in some sense, putting speculative evidence above strong evidence.</p>\n<p>Overall, to maximize expected value, I would argue that strength/robustness only matters when comparing different sources of evidence on the same effect of the same action. But when speculative arguments are the only sources of evidence available for a particular effect of a particular action, they should be accounted for no differently than strong arguments of the same effect size.</p>\n", "parentCommentId": "WZPage89HLaSfDrcD", "user": null}, {"_id": "Xj5cCxscuHsTLLDtg", "postedAt": "2014-09-23T14:46:44.880Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>I think this is especially true for AI safety. Sometimes people will cite prominent computer scientists' lack of concern for AI safety as evidence it is an unfounded concern. However, computer scientists seem to typically answer questions on <strong>AI progress</strong> moreso than <strong>AI safety</strong>, and these questions seem pretty categorically different, so I'm hesitant to give serious weight to their opinions on this topic. Not to mention the biases we can expect from AI researchers on this topic, e.g. from their incentives to be optimistic about their own field.</p>\n", "parentCommentId": "fDzattSTjPHTL6DpH", "user": null}, {"_id": "DxQiH5RSLmZ2Z3vHw", "postedAt": "2014-09-23T20:51:32.704Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>Thanks, I'll adapt the page to point this out.</p>\n", "parentCommentId": "fDzattSTjPHTL6DpH", "user": {"username": "Benjamin_Todd"}}, {"_id": "rA6uvkGQFpaCMJyCz", "postedAt": "2014-09-24T02:04:53.222Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>I'm interested in how that differs from the way Givewell does it's assessments. What justifies these differences?</p>\n", "parentCommentId": null, "user": {"username": "Diego_Caleiro"}}, {"_id": "yt3gRPweH6sKgRzx5", "postedAt": "2014-09-24T22:18:44.061Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>The obvious gap here is the process formative of the pre-given question digested by this methodology, that obviously being the most consequential step. How are such questions arrived at and by whom? It seems difficult for such questions to completely transcend the prejudices of the group giving rise to them, ergo, value should be attributed to the particular steps taken in their formation.</p>\n<p>I have a related concern about boundary problems between questions. If you artificially individuate questions do you arrive at an appropriate view of the whole? i.e. the affect of one question on another, and the value of goods which have a small but significant positive influence across questions. I'm thinking particularly of second-order goods whose realisation will almost certainly benefit any possible future; like collective wisdom, moral virtue, world peace, and so forth. These issues clearly aren't reducible to a single question about a particular type of career, or assimilable to an 'expert common sense'. Or do you reject wide-spectrum goods at first principle because of analytic intractability?</p>\n", "parentCommentId": null, "user": {"username": "Geuss"}}, {"_id": "FPBPWs7jvxFqtMzNa", "postedAt": "2014-09-24T22:26:45.174Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>My impression is that the methodology doesn't significantly differ from GiveWell, but we might apply it with a different emphasis. It seems like GiveWell puts a bit less weight on speculative arguments and a bit more weight on common sense within their clusters. However, these differences are pretty small on the scale of things, and are hard to disentangle from having come across different evidence rather than having different methodology.</p>\n", "parentCommentId": "rA6uvkGQFpaCMJyCz", "user": {"username": "Benjamin_Todd"}}, {"_id": "3vnyjL24faDXZTavy", "postedAt": "2014-09-25T21:19:35.806Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>I think you could use this methodology to focus your questions too. Start from something very broad like &quot;what's a good life&quot;, then use the methodology to work out what the key sub-questions are within that question; and so on. My aim wasn't, however, to give a full account of rational inquiry, starting from zero.</p>\n<p>I also don't see there being an especial neglect for second-order goods. Experts and common sense generally think these things are good, so they'll come up in your assessment, even if you can't further analyse them or quantify them.</p>\n", "parentCommentId": "yt3gRPweH6sKgRzx5", "user": {"username": "Benjamin_Todd"}}, {"_id": "FrgQAGJjogLXFXLLt", "postedAt": "2014-09-25T21:21:00.275Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>It seems like quite a few people have downvoted this post. I'd be curious to know why to avoid posting something similar next time.</p>\n", "parentCommentId": null, "user": {"username": "Benjamin_Todd"}}, {"_id": "BR8YyuAWG6LfpZoNt", "postedAt": "2014-09-27T09:02:58.515Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>When I hover over the 3 upvotes in the corner by the title, it says &quot;100% positive&quot; - which suggests people haven't downvoted it, it's just that not many people have upvoted it? But maybe I'm reading that wrong.</p>\n<p>I thought it was a good and useful post, I don't see any reason why people would downvote it - but would also be interested to hear why if there were people who did.</p>\n", "parentCommentId": "FrgQAGJjogLXFXLLt", "user": {"username": "Jess_Whittlestone"}}, {"_id": "Aw4vRmRZnqTBRM25e", "postedAt": "2014-09-27T12:17:19.833Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>Same. Doesn't show any downvotes for me either. Maybe it's a bug?</p>\n", "parentCommentId": "BR8YyuAWG6LfpZoNt", "user": null}, {"_id": "mCwN5D9u8zZcsmXfj", "postedAt": "2014-09-27T13:48:16.447Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>Yes, it seems like the Forum's established a slightly more positive culture than LessWrong, where people are supportive (a la <a href=\"http://effective-altruism.com/ea/7x/supportive_scepticism/\">Jess_Whittlestons's post</a>) and don't downvote all that much which seems to me to be a good thing. I would think that people might have refrained from upvoting this post because it might have seemed narrowly focused on promoting 80,000 Hours, but not have downvoted it either.</p>\n", "parentCommentId": "Aw4vRmRZnqTBRM25e", "user": {"username": "Vincent_deB"}}, {"_id": "wc42xtmPox9CZvgrv", "postedAt": "2014-09-27T18:57:19.004Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>This is a question that I don't have an answer to, but I thought of it while I was reading the post, and it doesn't seem addressed. Here goes. As 80,000 Hours does atypical research, how much will they worry about biases that will affect their research, that don't usually affect other social science research?</p>\n", "parentCommentId": null, "user": {"username": "Evan_Gaensbauer"}}, {"_id": "pAGExBF4XqfH9n3za", "postedAt": "2014-09-27T19:00:32.356Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>I don't perceive a need to be frugal with upvotes. I was surprised this article didn't get as upvoted either, because I believe it covers a very important issue. Having read the article, I'm not too surprised by new information. Maybe others feel the same, because as users of this forum we're already familiar with 80,000 Hours methodology, and feel as if this is a rehash.</p>\n<p>I've upvoted the article so it will get more visibility, because more important than what's written in it is attracting the critical feedback that 80,000 Hours is seeking.</p>\n", "parentCommentId": "FrgQAGJjogLXFXLLt", "user": {"username": "Evan_Gaensbauer"}}, {"_id": "ZyHHTdF9svWo4Wq92", "postedAt": "2014-09-27T19:12:50.871Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>I believe selecting between cause areas is something that this epistemology may be insufficient for, and may need tweaking to work better. I don't believe this because the methodology is flawed in principle. These methods work by relying on the work of others who know what they're doing, which makes sense.</p>\n<p>However, there seems to be few experts to ask for advice on selecting cause areas. I mean, that's a peculiar problem I didn't encounter in any form before effective altruism posed it. I imagine there's not as much expert common sense, scientific literature, or experience to be learned from here. I imagine the United Nations, and governments of wealthy nations, have departments dedicated to answering these questions. Additionally, I thought of the Copenhagen Consensus. The CEA is in touch with the Copenhagen Consensus, correct? </p>\n", "parentCommentId": null, "user": {"username": "Evan_Gaensbauer"}}, {"_id": "xbkL2vQnpwhwqWoem", "postedAt": "2014-09-28T22:14:12.160Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>Ah I didn't know you could see the % by hovering over that icon. I must have misremembered how many upvotes it had before.</p>\n", "parentCommentId": "Aw4vRmRZnqTBRM25e", "user": {"username": "Benjamin_Todd"}}, {"_id": "LGD5RFTJZKQKzM7v9", "postedAt": "2014-10-08T15:29:13.271Z", "postId": "8EgnnAFjaDEvD8pYD", "htmlBody": "<p>Yeah, I'd say the main factor in lack of upvotes was the lack of new insight or substantive points to (dis)agree with.</p>\n", "parentCommentId": "pAGExBF4XqfH9n3za", "user": null}]