[{"_id": "fqhuc3X8sNWqcn9Jo", "postedAt": "2023-06-07T09:43:21.007Z", "postId": "BCwaWkMHTMjFMvedS", "htmlBody": "<blockquote><p>Natural selection will tend to promote AIs that disempower human beings. For example, we currently have chatbots that can help us solve problems. But AI developers are working to give these chatbots the ability to <a href=\"https://openai.com/blog/chatgpt-plugins\"><u>access the internet and online banking</u></a>, and even <a href=\"https://say-can.github.io/\"><u>control the actions of physical robots</u></a>. While society would be better off if AIs make human workers more productive, competitive pressure pushes towards AI systems that <a href=\"https://digitaleconomy.stanford.edu/news/the-turing-trap-the-promise-peril-of-human-like-artificial-intelligence/\"><u>automate human labor</u></a>. Self-preservation and power seeking behaviors would also give AIs an evolutionary advantage, even to the <a href=\"https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/\"><u>detriment of humanity</u></a>.</p></blockquote><p>In this vein, is there anything to the idea of focusing more on aligning incentives than AI itself? Meaning, is it more useful to alter selection pressures (which behaviors are rewarded <i>outside of training</i>) vs trying to induce \"useful mutations\" (alignment of specific AIs)? I have no idea how well this would work in practice, but it seems less fragile. One half-baked idea: heavily tax direct AI labor, but not indirect AI labor (i.e. make it cheaper to get AIs to help humans be more productive than to do it without human involvement)</p>", "parentCommentId": null, "user": {"username": "blueberry"}}, {"_id": "Nivjh5umAxwxnf2QH", "postedAt": "2023-06-07T23:59:11.796Z", "postId": "BCwaWkMHTMjFMvedS", "htmlBody": "<p>Yep, I think those kinds of interventions make a lot of sense. The <a href=\"https://arxiv.org/abs/2303.16200\">natural selection paper</a> discusses several of those kinds of interventions in sections 4.2 and 4.3. <a href=\"https://digitaleconomy.stanford.edu/news/the-turing-trap-the-promise-peril-of-human-like-artificial-intelligence/\">The Turing Trap </a>also makes an interesting observation about US tax law: automating a worker with AI would typically reduce a company's tax burden. Bill DeBlasio, Mark Cuban, and Bill Gates have all spoken in favor of a <a href=\"https://en.wikipedia.org/wiki/Robot_tax\">robot tax</a> to fix that imbalance.&nbsp;</p>", "parentCommentId": "fqhuc3X8sNWqcn9Jo", "user": {"username": "Aidan O'Gara"}}]