[{"_id": "dReLFizBEiYf4TMLn", "postedAt": "2023-11-08T07:31:14.068Z", "postId": "DQaZfaLRRGvtBsp3u", "htmlBody": "<p>Thanks very much!<br><br>Two questions:&nbsp;<br><br>(1) I have had to introduce cognitive biases to people myself and was wondering <i>what reasons to give </i>for the the precise selection of biases I present. As far as these 10 biases are concerned: Is it just a judgement call to choose this specific list of biases --- as they kind of seem practically relevant and much discussed? Or is there a more systematic reason for choosing these 10 or any other list?<br><br>(2) Yudkowsky's list is from 2008. Much has happened since. It would be nice if there were kind of a running update on which cognitive biases have moved up / down over time in terms of being supported by the evidence.</p>", "parentCommentId": null, "user": {"username": "dominicroser"}}, {"_id": "RELQiEsfb2jgBoFtg", "postedAt": "2023-11-09T12:37:48.071Z", "postId": "DQaZfaLRRGvtBsp3u", "htmlBody": "<p><strong>Executive summary:</strong> Cognitive biases like availability heuristic and confirmation bias can distort judgement about risks, especially unprecedented ones like human extinction.</p><p><strong>Key points:</strong></p><ol><li>Availability heuristic leads people to underestimate common risks and overestimate memorable ones. This could downplay preparations for unprecedented catastrophes.</li><li>Hindsight bias makes past events seem more predictable than they were. This may undermine appreciation for disaster prevention efforts.</li><li>Black swan events are highly impactful but unpredictable, so lack of preparation for them is dangerous.</li><li>Conjunction fallacy makes complex scenarios seem more likely than they are. This can skew assessments of risk.</li><li>Confirmation bias leads people to seek out confirming evidence rather than critically testing hypotheses.</li><li>Anchoring causes people to rely too heavily on initial irrelevant information when making judgments.</li><li>Affect heuristic boils information down to good/bad feelings, more so under time pressure. This can distort risk analysis.</li><li>Scope neglect means people do not scale concern proportionately to affected entities. So large problems may get inadequate responses.</li><li>Overconfidence leads to underestimating the costs, risks and timelines of plans and actions.</li><li>Bystander apathy causes inaction when people expect others to act. This can propagate collective inaction even in crises.</li></ol><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}]