[{"_id": "BKjRSa93ELtRx93jt", "postedAt": "2018-04-04T15:12:10.239Z", "postId": "CmNBmSf6xtMyYhvcs", "htmlBody": "<blockquote>\n<p>First, consider the individual level. Imagine a participant answered with \u201cinfinite\u201d in twenty dilemmas. Further assume that the average equivalence number of this participant in the remaining ten dilemmas was also extremely high, say, one trillion. Unless this person has an unreasonably high E-ratio (i.e. is unreasonably optimistic about the future), this person should, ceteris paribus, prioritize interventions that reduce s-risks over, say, interventions that primarily reduce risks of extinction but which might also increase s-risks (such as, perhaps, building disaster shelters11); especially so if they learn that most respondents with lower average equivalence numbers do the same.</p>\n</blockquote>\n<p>That's not descriptive ethics though, that's regular moral philosophy.</p>\n<p>For the 2nd point, moral compromise on a movement level makes sense but not in any unique way for population ethics. It's no more or less true than it is for other moral issues relevant to cause prioritization.</p>\n", "parentCommentId": null, "user": {"username": "kbog"}}, {"_id": "6jxmkw3h9p9BpwJ3w", "postedAt": "2018-04-05T09:04:29.252Z", "postId": "CmNBmSf6xtMyYhvcs", "htmlBody": "<blockquote>\n<p>That's not descriptive ethics though, that's regular moral philosophy.</p>\n</blockquote>\n<p>Fair enough. I was trying to express the following point: One of the advantages of descriptive ethics, especially if done via a well-designed questionnaire/survey, is that participants will engage in some moral reflection/philosophy, potentially illuminating their ethical views and their implications for cause prioritization. </p>\n<blockquote>\n<p>For the 2nd point, moral compromise on a movement level makes sense but not in any unique way for population ethics. It's no more or less true than it is for other moral issues relevant to cause prioritization.</p>\n</blockquote>\n<p>I agree that there are other issues, including moral ones, besides views on population ethics (one\u2019s N-ratios and E-ratios, specifically) that are relevant for cause prioritization. It seems to me, however, that the latter are comparatively important and worth reflecting on, at least for people who spent at most a very limited amount of time doing so.</p>\n", "parentCommentId": "BKjRSa93ELtRx93jt", "user": {"username": "David_Althaus"}}, {"_id": "QfTMwrEzh4228yJEA", "postedAt": "2018-04-15T19:26:40.739Z", "postId": "CmNBmSf6xtMyYhvcs", "htmlBody": "<p>This project seems to be a bit similar to an idea that I have. I start with a population ethical view of variable critical level utilitarianism <a href=\"https://stijnbruers.wordpress.com/2018/02/24/variable-critical-level-utilitarianism-as-the-solution-to-population-ethics/\">https://stijnbruers.wordpress.com/2018/02/24/variable-critical-level-utilitarianism-as-the-solution-to-population-ethics/</a>\nSo everyone can choose his or her own preferred critical level utility. Most people seem to agreggate around two values: \n1) the totalists prefer a critical level of 0, which corresponds with total utilitarianism (the totalist view) and \n2) the personalists or negativists prefer a conditionally maximum critical level (for example the utility of the most prefered state), which is close to negative utilitarianism and the person-affecting view. (I will not go into the conditionality part here)\nWhen we create new people, they can be either totalists or personalists (or something else, but that seems to be a minority. Or they can be in a morally uncertain, undecided superposition between totalists and personalists, but then we are allowed to choose for them their critical levels. If we make a choice for a situation where a totalist with a positive utility (well-being) is created, that positive utility counts as a benefit or a gratitude regarding our choice. If we caused the existence of a personalist (or negativist), we did not create a benefit. And if that personalist complains against our choice because it prefers another situation, we actually harmed that person. \nNow we have to add all benefits and harms (all gratitudes and complaints) for everyone who will exist in the choice that we will make. Concerning the far future and existential risks, we need to know how many totalists and personalists there will be in the future. Studying the current distribution of totalists and personalists can give us a good estimate. This might be related to the N-ratios of people. Totalists have low N-ratios, personalists/negativists have high N-ratios</p>\n", "parentCommentId": null, "user": null}, {"_id": "hoGXHber98g9gkWgF", "postedAt": "2018-04-15T20:21:41.669Z", "postId": "CmNBmSf6xtMyYhvcs", "htmlBody": "<blockquote>\n<p>Imagine you could create a new world inhabited by X humans living in a utopian civilization free of involuntary suffering, and where everyone is extremely kind, intelligent, and compassionate. In this world, however, there also exist 100 humans who experience extreme suffering. What\u2019s the smallest value of X for which you would want to create this world?</p>\n</blockquote>\n<p>The 100 suffering humans could, at a stretch, describe a particularly unfortunate group of early Homo sapiens (say 100,000 years ago) stuck in an inhospitable place and niche. If this new world also contains other species of animals and plants then even if X is zero, I would think it good to create such a world. The existence of the other species would make it worthwhile.</p>\n", "parentCommentId": null, "user": {"username": "jmckeown"}}, {"_id": "W5A3KA5Cw54cukgoR", "postedAt": "2018-04-16T11:54:47.767Z", "postId": "CmNBmSf6xtMyYhvcs", "htmlBody": "<p>Interesting, yeah, thx for the pointer! </p>\n", "parentCommentId": "QfTMwrEzh4228yJEA", "user": {"username": "David_Althaus"}}, {"_id": "znHQjYf7YBPvwt7xt", "postedAt": "2018-12-29T12:39:34.465Z", "postId": "CmNBmSf6xtMyYhvcs", "htmlBody": "<p>Hi Stijn. You mention that people tend to fall into these two categories mostly - totalist view and person-affecting view. Can you elaborate on how you obtained this impression? Did you already run a survey of some kind, or is the impression based on conversations with people, or from the comments on your blog? Does it reflect the intuitions of primarily EAs, or philosophy students, or the general population?</p>", "parentCommentId": "QfTMwrEzh4228yJEA", "user": {"username": "markus_over"}}, {"_id": "gXPPWBsTWn4sEABd5", "postedAt": "2020-12-10T15:45:37.491Z", "postId": "CmNBmSf6xtMyYhvcs", "htmlBody": "<p>Thanks for the interesting post! I just wanted to ask if there are any updates on these research projects? I think work along these lines could be pretty promising. One potential partner for cooperation could be <a href=\"http://clearerthinking.org\">clearerthinking.org</a>. They already have a <a href=\"https://programs.clearerthinking.org/intrinsic_values_graphic/graphic.html\">survey tool for intrinsic values</a> and this seems to hit in a similar direction.</p>\n", "parentCommentId": null, "user": {"username": "alexherwix"}}, {"_id": "haTX3MF8upiLuA2rb", "postedAt": "2020-12-11T17:04:19.801Z", "postId": "CmNBmSf6xtMyYhvcs", "htmlBody": "<p>Thanks! David Moss and others from Rethink Priorities have done some excellent work in this area.&nbsp;<br><br>Lucius Caviola, Geoffrey Goodwin, Andreas Morgensen, and I have been working on an academic paper in this area.</p><blockquote><p>One potential partner for cooperation could be <a href=\"http://clearerthinking.org/\">clearerthinking.org</a>.&nbsp;</p></blockquote><p>Agree, good idea!</p>", "parentCommentId": "gXPPWBsTWn4sEABd5", "user": {"username": "David_Althaus"}}]