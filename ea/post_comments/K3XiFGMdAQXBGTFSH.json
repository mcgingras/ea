[{"_id": "HELhmMj6kNvTkNHH9", "postedAt": "2023-06-18T13:50:16.989Z", "postId": "K3XiFGMdAQXBGTFSH", "htmlBody": "<p>Thanks, this work is likely to inform my own work significantly! One question: Have you considered ranking/rating the various categories for risk based on Metaculus predictions? One thing that interests me a lot are the Metaculus questions of the form \"<a href=\"https://www.metaculus.com/questions/1502/ragnar%25C3%25B6k-question-series-if-a-global-catastrophe-occurs-will-it-be-due-to-biotechnology-or-bioengineered-organisms/\">Ragnar\u00f6k Question Series: If a global catastrophe occurs, will it be due to X?</a>\" These questions currently sum to 150% which makes me think there is overlap between especially AI and nuclear, as well as AI and bio - both categories you have identified. Would you have any idea of how to infer the risks of bio or nuclear from the Metaculus questions? I think it might perhaps also strengthen your work, as you can rank/rate the different categories at least in terms of causing large scale loss of life.</p>", "parentCommentId": null, "user": {"username": "Ulrik Horn"}}, {"_id": "Qf38qcgR4RP2jLfpk", "postedAt": "2023-06-19T13:22:53.383Z", "postId": "K3XiFGMdAQXBGTFSH", "htmlBody": "<p>Ranking the risks is outside the scope of our work.\nInterpreting the metaculus questions sounds interesting, though it is not obvious how to disentangle the scenarios that forecasters had in mind. I think the Forecasting Research Institute is doing some related work, surveying forecasters on different risks.</p>\n", "parentCommentId": "HELhmMj6kNvTkNHH9", "user": {"username": "Jsevillamol"}}]