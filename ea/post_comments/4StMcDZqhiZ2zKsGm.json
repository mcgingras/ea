[{"_id": "ok4fy2roZwpMoLRXa", "postedAt": "2023-03-25T15:34:53.882Z", "postId": "4StMcDZqhiZ2zKsGm", "htmlBody": "<p>Few Things</p><ul><li>&nbsp;<a href=\"https://forum.effectivealtruism.org/graphiql\">https://forum.effectivealtruism.org/graphiql</a> if people want to scrape.</li><li>I only skimmed your post (let me know if I'm misunderstanding) but I have an issue with this idea. Many forecasts require complicated mathematical models to describe. You can't simply link to sources. You also need to link to a model. Blog posts/txt files, which are essentially what the forum is, are extremely hard to scrape and parse unless everyone starts adopting conventions. So you max you functionality out at linking, this isn't very automated.&nbsp;</li><li>If you are recommending connecting a full mathematical model from the forum, let me suggest that rather than connecting Metaculus to the forum, you connect it to <a href=\"https://www.getguesstimate.com/models,\">https://www.getguesstimate.com/models,</a> as this is much more scalable and clear.&nbsp;</li><li>thank you for thinking about these things, it inspired me to make my own post.&nbsp;</li></ul>", "parentCommentId": null, "user": {"username": "Charles_Guthmann"}}, {"_id": "fBd2PcgpNesBxChik", "postedAt": "2023-03-25T15:40:23.606Z", "postId": "4StMcDZqhiZ2zKsGm", "htmlBody": "<p>Glad you're thinking about improving research and forecasting! My very quick take after only skimming your post is that it just happens too rarely that an EA forum post significantly informs specific Metaculus questions. Consequently investing in such a feature seems not sufficiently useful. (Though that might change of course if there were many more Metaculus questions that relate to topics in EA.) Maybe you could list some concrete examples for such EA forum - Metaculus connections? (Sorry if I missed you listing examples!)</p><p>Some other random ideas about forecasting on the forum:</p><ul><li>Display relative Brier Scores from Metaculus in EAF profiles -&gt; incentivize forecasting, enable forum readers to roughly weigh comments by epistemic track records</li><li>Hook up the forum to the GPT-4 API and allow forum writers to generate forecasting questions at the end of their posts.<ul><li>Scott Alexander does this regularly and I find it useful to get a concrete bottom line of his uncertainties and concrete things he's forecasting based on the post, e.g. see <a href=\"https://astralcodexten.substack.com/p/against-ice-age-civilizations\">here</a>.</li></ul></li></ul>", "parentCommentId": null, "user": {"username": "MaxRa"}}, {"_id": "DSuCpSSJpPQTdJxcb", "postedAt": "2023-03-25T16:02:17.878Z", "postId": "4StMcDZqhiZ2zKsGm", "htmlBody": "<p>Good points.&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/FfxrwBdBDCg9YTh69/how-many-people-would-be-killed-as-a-direct-result-of-a-us\">This post</a> comes to mind, which I cited in my nuclear GCR forecasts <a href=\"https://damienlaird.substack.com/p/forecast-from-the-2022-hybrid-forecasting\">here</a>, along with many other posts from that series. In general I expect posts from Rethink Priorities to be relevant. I've seen similar quality posts for AI risks and pandemics here. Most of my familiarity is with GCR's but I expected there to be strong overlap between popular forecasting topics and popular EA forum topics more generally. There are lots of GCR related questions on Metaculus, and you can find many cited in that link with my forecasts.</p><p>Still, I think you're right that this wouldn't be applicable to the majority of EA forum posts. Maybe it's only even displayed once a post is cited in a forecast, or only a particular tag is eligible for this in order to simplify the implementation.&nbsp;</p><p>I do think making people's forecasting performance more obvious in different contexts would be very useful for the community (re: your brier scores in EAF profiles idea), and would love a central site that's sort of like a minimum viable linkedin that consolidates relevant metrics for an individual across the top forecasting platforms and has an API that makes it easy to connect to other accounts, or use with discord bots etc. I may write about this soon.</p><p>Generating forecasts associated with a post is interesting and I'm sure there are UX opportunities to make this easier / more common, but I need to think more about it.</p><p>Thanks for the thoughtful response!</p>", "parentCommentId": "fBd2PcgpNesBxChik", "user": {"username": "Damien Laird"}}, {"_id": "vguPNtEijg2YMwGiE", "postedAt": "2023-03-25T16:09:02.135Z", "postId": "4StMcDZqhiZ2zKsGm", "htmlBody": "<p>I would say it a little differently. I would say that \"judgmental\" forecasting, the kind typically done on Metaculus or Good Judgement Open or similar platforms, CAN involve mathemtical models, but oftentimes people are just doing some simple math, if any at all. In cases where people do use models, sure it would make sense to link to them as sources, and I agree that would also be valuable to track for similar reasons. Guesstimate seems like the obvious place to do that.</p><p>I think that is separate from the proposition I intended to communicate for primarily text based research.&nbsp;</p><p>I also wasn't anticipating any need to do scraping if this was implemented by the two platforms themselves. It should be easy enough for them to tell if a citation is linking to an EA forum post? Metaculus doesn't have a footnote/citation formatting tool today like the EA Forum's. (Although if you were to scrape, finding EA forum links within citations on this forum seems pretty well defined and achievable? idk, I don't write much code, thus me floating this out here for feedback)</p><p>Thanks for the thoughts!</p>", "parentCommentId": "ok4fy2roZwpMoLRXa", "user": {"username": "Damien Laird"}}, {"_id": "xcsqtg5k2WFpuja2H", "postedAt": "2023-03-25T17:35:41.238Z", "postId": "4StMcDZqhiZ2zKsGm", "htmlBody": "<p>I would say we are basically on the exact same page in terms of the overall vision. I'm also trying to get at these logical chains of information that we can travel backwards through to easily sanity check and also do data analysis.&nbsp;</p><p>Where I think we break is if there is no underlying structure to these logical chains outside of a bunch of arrows pointing between links, it reduces our ability to automate and take away insights.&nbsp;</p><p>A few examples&nbsp;</p><ul><li>&nbsp;you link to a ea forum post with multiple claims. In order to build logical chains, we now need a database to store each claim in each post. In order to do this, we now need to convince everyone to use certain formatting on claims or try to use an LLM to parse.</li><li>you link multiple sources, which themselves link multiple sources. Since linking is just drawing arrows in an abstract sense, I have no ability to discern how much each source went into the guess. I assume we would just use a uniform distribution to model how much each source went into the final guess? but this is clearly terribly off in many cases so we lose a lot of information.&nbsp;<ul><li>If we link to models we hold a lot more information down the chain.&nbsp;</li></ul></li></ul><p>Overall I wouldn't say my proposition isn't a full substitute for your idea, but I think there is overlapping functionality.&nbsp;</p>", "parentCommentId": "vguPNtEijg2YMwGiE", "user": {"username": "Charles_Guthmann"}}]