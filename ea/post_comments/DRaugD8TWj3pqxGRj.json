[{"_id": "x3WYCBhCifSDxhCDD", "postedAt": "2022-10-18T13:18:31.028Z", "postId": "DRaugD8TWj3pqxGRj", "htmlBody": "<p>Strong upvoting <a href=\"https://forum.effectivealtruism.org/posts/YzyuaHwXurqqpYnZZ/if-you-like-a-post-tell-the-author\">because</a> I think these are good, important points with an excellent TL;DR and title.</p><blockquote><p>As Frank Jackson stressed in his paper on \u2018<a href=\"https://philpapers.org/rec/JACDCA\">Decision-Theoretic Consequentialism</a>\u2019, in certain risky cases we may <i>know</i> that a \u201csafe\u201d option will not maximize value, yet it may nonetheless maximize <i>expected</i> value (if the alternatives risk disaster), and is for that very reason the prudent and rational choice.</p></blockquote><p>I suspect a lot of the 'systemic change' critique of donating to the Against Malaria Foundation is motivated by this kind of thinking. You'll often hear people say something like, \"Bed-nets alone will never eliminate poverty and injustice!\" as if accepting that claim would entail that buying bed-nets is worse than taking action that has a (more plausible) shot at transforming the entire system. Maximising expected value does not always mean maximising the chance of a perfect world.</p><p>(I also think that sometimes the reasoning in these cases is something closer to rule consequentialism, which I have more sympathy for. And I'm sure sometimes they're also using expected value, just plugging in different numbers.)</p><blockquote><p>I get that cluelessness in the face of massive invisible long-term stakes can be angst-inducing.</p></blockquote><p>The feeling I struggle with the most here is paralysis in the face of a seemingly relentless string of <a href=\"https://forum.effectivealtruism.org/topics/crucial-consideration\">crucial considerations</a> flipping the sign of the value of the path I'm on. (There's a great line in the <i>Zhuangzi</i> that captures this nicely for me: \"Confucius went along for sixty years and transformed sixty times. What he first considered right he later considered wrong. He could never know if what he presently considered right were not fifty-nine times wrong.\") Your arguments still work in such cases - there's still no need for paralysis, but emotionally speaking it's very tempting!</p>", "parentCommentId": null, "user": {"username": "Holly"}}, {"_id": "2CZGGxkAuAvFTqjFz", "postedAt": "2022-10-20T03:07:51.494Z", "postId": "DRaugD8TWj3pqxGRj", "htmlBody": "<p>I think I basically agree with all your responses, but I also think this misses a more important case of cluelessness, specifically complex cluelessness. Saving a child has impacts on farmed animals, wild animals, economic growth and climate change, some of which could be negative and some of which could be positive. How do you weigh them all together non-arbitrarily to come to the verdict that it's definitely good in expectation, or to the verdict that it's definitely bad in expectation? This isn't a case of having no reasons either way (or all reasons pointing in one direction), but of having important reasons each way that are too hard to weigh against one another in a way that's justified, non-arbitrary and defensible.</p>\n", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "tsxxbJ7dzWrszz3TT", "postedAt": "2022-10-20T19:59:19.162Z", "postId": "DRaugD8TWj3pqxGRj", "htmlBody": "<p>It would also be surprising for the direct effects on the child to be a tie-breaker if you have precise probabilities, given how much more is at stake.</p>\n", "parentCommentId": "2CZGGxkAuAvFTqjFz", "user": {"username": "MichaelStJules"}}, {"_id": "jmpf7fXQJePmY2Hen", "postedAt": "2022-10-21T18:17:07.830Z", "postId": "DRaugD8TWj3pqxGRj", "htmlBody": "<p>Seems natural to just go meta, treating the hard-to-assess determinants of expected value as akin to hard-to-discover empirical facts, and maximizing meta-expected value as one's \"best attempt\" to manage this additional uncertainty.</p><p>I'm less sure about this, but it seems like the defense of EV against simple cluelessness could carry over to defend meta-EV against complex cluelessness? E.g. &nbsp;in the long run (and across relevant possible worlds), we'd expect these agents to do better on average than agents following any other subjectively-accessible decision procedure.</p>", "parentCommentId": "2CZGGxkAuAvFTqjFz", "user": {"username": "RYC"}}, {"_id": "DwGeABdwgLLHfAKdm", "postedAt": "2022-10-22T18:25:02.316Z", "postId": "DRaugD8TWj3pqxGRj", "htmlBody": "<p>I'm not sure what you mean by maximizing meta-expected value. How is this different from just maximizing expected value?</p>\n<p>I'd claim that the additional uncertainty is unquantifiable, or at least no single set of precise probabilities (a single precise probability distribution over outcomes for each act) can be justified over all other alternatives. There's sometimes no unique best attempt, and no uniquely best way to choose between them or weigh them. Sometimes there's no uniform prior, and sometimes there are infinitely many competing candidates that might be called unform, because of different ways to parametrize your distribution. At the extreme for an idealized rational agent, you need to have a universal prior, but there are multiple, and they depend on arbitrary parametrizations. How do you pick one over all others?</p>\n<p>I do think it\u2019s possible we aren\u2019t always clueless, depending on what kinds of credences you entertain.</p>\n<p>FWIW, my preferred approach is something like this, although maybe we can go further:\n<a href=\"https://forum.effectivealtruism.org/posts/Mig4y9Duu6pzuw3H4/hedging-against-deep-and-moral-uncertainty\">https://forum.effectivealtruism.org/posts/Mig4y9Duu6pzuw3H4/hedging-against-deep-and-moral-uncertainty</a></p>\n<p>It builds on <a href=\"https://academic.oup.com/pq/article-abstract/71/1/141/5828678\">https://academic.oup.com/pq/article-abstract/71/1/141/5828678</a></p>\n<p>Also this might be useful in some cases:\n<a href=\"https://forum.effectivealtruism.org/posts/f4sep8ggXEs37PBuX/even-allocation-strategy-under-high-model-ambiguity\">https://forum.effectivealtruism.org/posts/f4sep8ggXEs37PBuX/even-allocation-strategy-under-high-model-ambiguity</a></p>\n", "parentCommentId": "jmpf7fXQJePmY2Hen", "user": {"username": "MichaelStJules"}}]