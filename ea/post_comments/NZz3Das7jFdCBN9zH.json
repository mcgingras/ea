[{"_id": "HzLdChp3uXhn9dBzN", "postedAt": "2023-03-10T03:13:23.451Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<blockquote><p>Conditional on AGI being developed by 2070, what is the probability that humanity will suffer an <a href=\"/topics/existential-catastrophe-1\"><u>existential catastrophe</u></a> due to loss of control over an AGI system?</p></blockquote><p>Requesting a few clarifications:</p><ul><li>I think of existential catastrophes as things like near-term extinction rather than things like \"the future is substantially worse than it could have been\". Alternatively, I tend to think that existential catastrophe means a future that's much worse than technological stagnation, rather than one that's much worse than it would have been with more aligned AI. What do you think?</li><li>Are we considering \"loss of control over an AGI system\" as a loss of control over a somewhat monolithic thing with a well-defined control interface, or is losing control over an ecosystem of AGIs also of interest here?</li></ul>", "parentCommentId": null, "user": {"username": "David Johnston"}}, {"_id": "shyjJXnm9aE8eNH9i", "postedAt": "2023-03-10T04:04:49.059Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>I guess the requirement that all authors be eighteen years of age or older rules out all(?) current high performing non-human generated essay sources, eg, from Virtual Beings generically, &nbsp;chatGPT, etc. &nbsp;In general, though, can AI/ML instances be used in the generation of raw text for this contest, besides as an example?&nbsp;</p>", "parentCommentId": null, "user": {"username": "Phil Shirts"}}, {"_id": "cWFfpKr5pkCHyA2gz", "postedAt": "2023-03-10T13:15:01.099Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>Hi David,</p>\n<p>Thanks for your questions. We're interested in a wide range of considerations. It's debatable whether human-originating civilization failing to make good use of its \"cosmic endowment\" constitutes an existential catastrophe. If you want to focus on more recognizable catastrophes (such as extinction, unrecoverable civilizational collapse, or dystopia) that would be fine.</p>\n<p>In a similar vein, if you think there is an important scenario in which humanity suffers an existential catastrophe by collectively losing control over an ecosystem of AGIs, that would also be an acceptable topic.</p>\n<p>Let me know if you have any other questions!</p>\n", "parentCommentId": "HzLdChp3uXhn9dBzN", "user": {"username": "Jason Schukraft"}}, {"_id": "Nk7Wy3ynJyfFbSdXL", "postedAt": "2023-03-10T13:20:11.237Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>Hi Phil - just to clarify: the entries must entirely be the original work of the author(s). You can cite others and you can use AI-generated text as an example, but for everything that is not explicitly flagged as someone else's work, we will assume it is original to the author.</p>\n", "parentCommentId": "shyjJXnm9aE8eNH9i", "user": {"username": "Jason Schukraft"}}, {"_id": "3eybnqTbsog3rM63d", "postedAt": "2023-03-12T19:06:13.022Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>Would you consider incorporating a broader panel of judges? OpenPhil, and effective altruists more generally, tends to have quite strong and niche views about the future of artificial intelligence. This contest would have broader credibility if it were evaluated from a set of perspectives more consistent with, and representative of the field as a whole.&nbsp;</p>", "parentCommentId": null, "user": {"username": "David Thorstad"}}, {"_id": "4psEK9v6dGuBYniYt", "postedAt": "2023-03-12T19:52:39.971Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>The objective of the contest isn't to farm prestige or credibility with some hypothetical third party, it's to inform OpenPhil's work, and it seems very likely OpenPhil is by far the best judge of that.</p><blockquote><p>The goal of the contest is to surface novel considerations that could influence our views on AI timelines and AI risk.</p></blockquote>", "parentCommentId": "3eybnqTbsog3rM63d", "user": {"username": "Larks"}}, {"_id": "WDm8zRkmDpY8YCz2P", "postedAt": "2023-03-12T20:58:59.459Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>There is a growing consensus among social scientists that diversity of approaches and perspectives is essential to reaching truth and avoiding bias. Most theorists now believe that deliberation among homogenous groups is likely to lead to groupthink, polarization, extremism, and other forms of failed group deliberation. They emphasize that the risk is especially strong in self-selecting groups, as well as in groups where discourse is heavily concentrated on the internet.</p><p>Many social scientists would tend to think that effective altruists fit most of the risk factors for failures of group deliberation. They would tend to think that if effective altruists are concerned with finding the truth about risks posed by future developments in artificial intelligence, effective altruists would do well to draw from a wider range of perspectives and approaches. They would tend to see developments such as this contest as primarily confirmatory, unlikely to substantially shift group views and quite likely to reinforce them. They would suggest that those developments could be redesigned in a more truth-seeking way by incorporating a broader range of perspectives in deliberation.</p>", "parentCommentId": "4psEK9v6dGuBYniYt", "user": {"username": "David Thorstad"}}, {"_id": "4c42hx2b4dNFsiB3t", "postedAt": "2023-03-13T02:26:15.341Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>These seem like arguments for OpenPhil to hire people with a broad range of perspectives, and to solicit contest submissions from a broad range of people, but not to adjust the judges. It doesn't benefit OpenPhil at all if, having put e.g. a social conservative on the board of judges, the winner does so by appealing to her with arguments that OpenPhil does not find compelling. OpenPhil is uniquely qualified to judge what arguments they have found informative.</p>", "parentCommentId": "WDm8zRkmDpY8YCz2P", "user": {"username": "Larks"}}, {"_id": "N2RqdgWdg2wrNRFxi", "postedAt": "2023-03-13T12:16:44.786Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>Hi David,</p>\n<p>Thanks for your comment. I am also concerned about groupthink within homogenous communities. I hope this contest is one small push against groupthink at Open Phil. By default, I do, unfortunately, expect most of the submissions to come from people who share the same basic worldview as Open Phil staff. And for submissions that come from people with radically different worldviews, there is the danger that we fail to recognize an excellent point because we are less familiar with the stylistic and epistemic conventions within which it is embedded.</p>\n<p>For these sorts of reasons, we did explicitly consider including non-Open Phil judges for the contest. Ultimately, we decided that didn\u2019t make sense for this use case. We are, after all, hoping that submissions update <em>our</em> thinking, and it\u2019s harder for an outside judge to represent our point of view.</p>\n<p>But this contest is not the only way we are stress-testing our thinking. For example, I\u2019m involved in another project in which we are engaging directly with smart people who disagree with us about AI risk. We hope that as a result of that adversarial collaboration, we can generate a consensus of cruxes so that we have a better handle on how new developments ought to change our credences. I hope to be able to share more details on that project over the summer.</p>\n<p>If you want to chat more about groupthink concerns, shoot me a DM. I believe it\u2019s a somewhat underappreciated worry within EA.</p>\n", "parentCommentId": "3eybnqTbsog3rM63d", "user": {"username": "Jason Schukraft"}}, {"_id": "sY3XQ7KPMpMqcdDYC", "postedAt": "2023-03-14T15:23:29.085Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>It might be worth considering whether the goal of this contest is to produce arguments that OpenPhil finds compelling and informative, or to produce arguments that are compelling and informative.&nbsp;</p><p>These would not be arguments in favor of the conclusion that a broader range of perspectives is a useful way to produce arguments that OpenPhil finds compelling and informative. The best way for OpenPhil to produce arguments that OpenPhil finds compelling and informative would be to select judges exclusively from its own membership, and that is what they have done.</p><p>They would instead be arguments in favor of the conclusion that a broader range of perspectives is a useful way to produce &nbsp;arguments that actually are compelling and informative, as well as to avoid a number of known biases and failure modes in group deliberation.</p>", "parentCommentId": "4c42hx2b4dNFsiB3t", "user": {"username": "David Thorstad"}}, {"_id": "ovb7MkeFjzQXzyAdx", "postedAt": "2023-03-14T16:25:29.576Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>Interestingly, the belief that there is an X-risk from AI might not be all that niche, relative to <i>the US public as whole</i>, though obviously Open Phil probably has other views that are niche in that context:<br><br><a href=\"https://www.monmouth.edu/polling-institute/reports/monmouthpoll_us_021523/\">https://www.monmouth.edu/polling-institute/reports/monmouthpoll_us_021523/</a><br><br>'A majority (55%) of Americans are now worried at least somewhat that artificially intelligent machines could one day pose a risk to the human race\u2019s existence. ' Of course, it's unclear exactly what \"could\" means in this sort of context. But Monmouth is a reputable pollster I think(?) and not everyone at Open Phil. is a Yudkowsky style doomer who thinks doom is near certain.&nbsp;<br><br><br>&nbsp;Not that this means your wrong to say they are niche in \"the field\", whatever exactly that is. (And to be clear, I actually am inclined to agree that having judges from outside Open Phil. with different views would be in theory an improvement.)&nbsp;<br><br>EDIT: To be clear, <i>I personally</i> think it is very unlikely (maybe 1 in 1000) that we will go extinct because of misaligned AI by 2100, so I'm not just defending &nbsp;a view I hold here.&nbsp;</p>", "parentCommentId": "3eybnqTbsog3rM63d", "user": {"username": "Dr. David Mathers"}}, {"_id": "DsnSRk8scs2Awaa58", "postedAt": "2023-03-14T16:43:03.803Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>What procedure would you recommend for how Open Phil chooses between allocating money to AI versus allocating it to other causes? Would you recommend essentially the same procedure for:&nbsp;<br>- A university deciding whether to fund a new department<br><br>-A local council deciding what to budget cuts to make, after an unexpected loss of central government funding<br><br>- A &nbsp;CEO setting corporate strategy<br><br>?<br><br>&nbsp;</p>", "parentCommentId": "sY3XQ7KPMpMqcdDYC", "user": {"username": "Dr. David Mathers"}}, {"_id": "Cm2Z8DqE7aL3JBezz", "postedAt": "2023-03-14T16:45:38.721Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>You could of course commit to acting on some kind of judgment of some diverse group you think worth differing too, rather than &nbsp;acting on your own opinion. &nbsp;One way to understand what David Thorstad is asking (which he might or might not endorse) is why you don't do that given it would (allegedly) mean acting on a more-like-to-be-correct opinion, rather than one that is less-likely to be correct. From that point of view, it's just missing the point to say 'we're trying to get our opinion updated', because you shouldn't be using your opinions, rather than some properly diverse groups opinions to be setting policy in general.<br><br>&nbsp;</p>", "parentCommentId": "N2RqdgWdg2wrNRFxi", "user": {"username": "Dr. David Mathers"}}, {"_id": "DTH9595XPhdMzqsvX", "postedAt": "2023-03-14T17:48:46.756Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>Ordinarily, a philanthropic foundation offering a prize meant to advance &nbsp;scientific understanding of some topic X would put at mot one or two of its own members on the prize panel. The rest of the panel would be composed of leading scientists, academics, industry professionals, and perhaps a few policymakers. They might also consider inviting leaders of relevant foundations. Most members of the panel would be chosen for specific expertise in topic X combined with broad respect and experience within their fields, although a few panelists might be chosen to represent generalist constituencies (for example, a university president). Members would typically be at mid- or late-career stages, and have substantial research records of their own as well as the esteem of their peers. They might, as appropriate, draw on a broader pool of peer reviewers or nominators in early rounds of the selection process.</p><p>Prizes would typically be broadly advertised, and left open for a sufficient period to allow original research (at least six months). They would encourage submissions of a standard length for original research contributions, rather than discouraging submissions greater than 5,000 words. If the focus was solely on the individual piece of submitted work, the review process would be double- or triple-blinded and announced as such.&nbsp;</p><p>I could go on, but I take it that all of the above are fairly standard.&nbsp;</p>", "parentCommentId": "DsnSRk8scs2Awaa58", "user": {"username": "David Thorstad"}}, {"_id": "vbcbRMiW4yLvDfcgY", "postedAt": "2023-03-14T18:35:09.544Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>Point taken:  I have a better idea what you mean you make it concrete in that way.</p>\n", "parentCommentId": "DTH9595XPhdMzqsvX", "user": {"username": "Dr. David Mathers"}}, {"_id": "t7GCmB3c84hdJWpFp", "postedAt": "2023-03-14T19:18:13.127Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>It'd be nice if some of the people who disagree voted here could say why they think using outside judges would be a bad idea.</p>\n", "parentCommentId": "3eybnqTbsog3rM63d", "user": {"username": "Dr. David Mathers"}}, {"_id": "RSCvwkkMSAvPkmQSh", "postedAt": "2023-04-07T21:51:30.365Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>For Question 2, should each submission define what timeframe they're considering for \"will suffer\"?</p><blockquote><p>Conditional on AGI being developed by 2070, what is the probability that humanity will suffer an existential catastrophe due to loss of control over an AGI system?</p></blockquote><p><br>I understand two timeframes here - one explicit and one implicit. The explicit timeframe of \"by 2070\" makes sense to me.&nbsp;</p><p>The implicit timeframe of \"will suffer\" is ambiguous to me and therefore should be defined in the submission. <a href=\"https://www.openphilanthropy.org/century-fellowship/\">Open Philanthropy</a> seems to emphasize <a href=\"https://www.cold-takes.com/most-important-century/\">this century's importance</a>. I plan to limit my estimate and reasoning to be \"catastrophe by the end of this century.\" For <i>this</i> contest, it seems unlikely the judges want to understand the tail of the yearly distribution (i.e. AGI deployed by 2070 but goes rouge in 2500 for some esoteric reason).</p>", "parentCommentId": null, "user": {"username": "Mitchell Reynolds"}}, {"_id": "ijthhDsWREaqSobi9", "postedAt": "2023-04-15T22:09:05.812Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>I have a question.</p>\n<p>IF:</p>\n<ul>\n<li>we can submit multiple entries (but only one will win), AND</li>\n<li>judging is based on 67% uncovering considerations and 33% clarifying concepts,</li>\n</ul>\n<p>THEN, would you prefer if I:</p>\n<ul>\n<li>make one large entry that puts all my research/ideas/information in one place, OR</li>\n<li>make several smaller entries, each one focusing on a single idea?</li>\n</ul>\n<p>(Assuming this is for answering one question. Presumably, since multiple entries are allowed, I could duplicate this strategy for the other question, or even use a different one for each. But if I'm wrong about this, I'd also like to know that!)</p>\n", "parentCommentId": null, "user": {"username": "NicholasKross"}}, {"_id": "pxYcRBu8xvcat9dM4", "postedAt": "2023-04-18T23:46:08.431Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>Hi Nicholas,</p>\n<p>Thanks for your question. It's a bit difficult to answer in the abstract. If your ideas hang together in a nice way, it makes sense to house them in a single entry. If the ideas are quite distinct and unrelated, it makes more sense to house them in separate entries. Another consideration is length. Per the contest guidelines, we're advising entrants to shoot for a submission length around 5000 words (though there are no formal word limits). All else equal, I'd prefer three 5000 word entries to one 15,000 word entry, and I'd prefer one 5000 word entry to ten 500 word entries.</p>\n<p>Hope this helps.</p>\n<p>Jason</p>\n", "parentCommentId": "ijthhDsWREaqSobi9", "user": {"username": "Jason Schukraft"}}, {"_id": "6BcKQLwynBhxpswPC", "postedAt": "2023-04-20T02:48:30.284Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>These details help, thank you!</p>\n", "parentCommentId": "pxYcRBu8xvcat9dM4", "user": {"username": "NicholasKross"}}, {"_id": "ef6RxsKFQkznSubp4", "postedAt": "2023-04-25T01:35:55.688Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>How would you respond to essays that are substantially or mostly in the form of bullet-points, lists, tables, and other information organization methods besides prose? (Prior discussion <a href=\"https://www.reddit.com/r/slatestarcodex/comments/m57i1c/prose_is_bad/\">here</a>, <a href=\"https://dynomight.net/lists/\">here</a>, and <a href=\"https://www.lesswrong.com/posts/dEcHid7tZPDNvhL4k/do-you-like-bullet-points\">here</a>, to get a sense of why I'm interested in doing this.)</p>\n", "parentCommentId": null, "user": {"username": "NicholasKross"}}, {"_id": "Bo8BCqxCtJn2ZdpiL", "postedAt": "2023-04-26T19:49:42.524Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>Hi Nicholas,</p>\n<p>The details and execution probably matter a lot, but in general I'm fine with bullet-point writing. I would, however, find it hard to engage with an essay that was mostly tables with little prose explaining the relevance of the tables.</p>\n", "parentCommentId": "ef6RxsKFQkznSubp4", "user": {"username": "Jason Schukraft"}}, {"_id": "rKtjvttmDmJnvQmn9", "postedAt": "2023-04-29T02:10:28.592Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>OK, thanks! Also, after more consideration and object-level thinking about the questions, I will probably write a good bit of prose anyway.</p>\n", "parentCommentId": "Bo8BCqxCtJn2ZdpiL", "user": {"username": "NicholasKross"}}, {"_id": "4j2Dsi3bLKdvJcrnX", "postedAt": "2023-05-05T17:08:01.399Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>I dunno, I feel like I want OpenPhil to reward based on that changes their minds. Having external judges feels kind of meaningless.</p>", "parentCommentId": "3eybnqTbsog3rM63d", "user": {"username": "nathan"}}, {"_id": "YXpuQy87iQCBrYGhF", "postedAt": "2023-05-05T19:01:17.831Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>It would be more likely to find the truth</p>\n", "parentCommentId": "4j2Dsi3bLKdvJcrnX", "user": {"username": "David Thorstad"}}, {"_id": "bWNtL87rfGus66ycC", "postedAt": "2023-05-06T01:36:30.710Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>But they want specific changes to their plans.</p>\n", "parentCommentId": "YXpuQy87iQCBrYGhF", "user": {"username": "nathan"}}, {"_id": "3Le5NkXomGjjYBzKT", "postedAt": "2023-05-06T02:08:59.313Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>Here's a proposed change to their plans: dump the focus on AI safety. This kind of change can only come from independent scrutiny.&nbsp;</p>", "parentCommentId": "bWNtL87rfGus66ycC", "user": {"username": "David Thorstad"}}, {"_id": "FbdMvpD3kjfcRfKk3", "postedAt": "2023-05-06T02:17:46.434Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>It's not necessary that it would be a bad idea. It's just that there's two different ways to run this competition and I think that the way OpenPhilanthropy is doing it is fine and there's no need to push them to change.<br><br>On the other hand, it also make sense for them to attempt to set up another competition afterward that attempts to form more of a consensus on this issue.</p>", "parentCommentId": "t7GCmB3c84hdJWpFp", "user": {"username": "casebash"}}, {"_id": "wLgKgXfvFYhGgtJmM", "postedAt": "2023-05-06T09:16:08.254Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>I think you and I think a different thing is going on here.</p>", "parentCommentId": "3Le5NkXomGjjYBzKT", "user": {"username": "nathan"}}, {"_id": "vLaXiMDQPcLB6g2gM", "postedAt": "2023-05-06T10:52:36.289Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>You think that OP should appoint an independent board of outsiders, have that board decide they should reject one of their key focus areas, and then defer unconditionally to that board? Basically no-one does that and with good reason!</p><p>If you don't think OP should defer unconditionally, and they should instead evaluate the arguments made by the board... well, that's basically the inputs they're soliciting with this competition.&nbsp;</p>", "parentCommentId": "3Le5NkXomGjjYBzKT", "user": {"username": "Larks"}}, {"_id": "j4iiJCftmftge5YJC", "postedAt": "2023-05-15T15:50:35.425Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>You note above that you encourage posting the entry as a forum post. Do have preferences regarding entries to be written primarily as research papers or as forum posts? I imagine this making some difference to style and referencing.</p>", "parentCommentId": null, "user": {"username": "paul_dfr"}}, {"_id": "6sxmMwsP9vz5oEYdi", "postedAt": "2023-05-15T17:22:03.567Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>Hi Paul, thanks for your question. I don't have an intrinsic preference. We encourage public posting of the entries because we believe that this type of investigation is potentially valuable beyond the narrow halls of Open Philanthropy. If your target audience (aside from the contest panelists) is primarily researchers, then it makes sense to format your entry according to the norms of the research community. If you are aiming for a broader target audience, then it may make sense to structure your entry more informally.</p>\n<p>When we grade the entries, we will be focused on the content. The style and reference won't (I hope) make much of a difference.</p>\n", "parentCommentId": "j4iiJCftmftge5YJC", "user": {"username": "Jason Schukraft"}}, {"_id": "9eBYutFZH6HGquzgS", "postedAt": "2023-05-15T18:01:21.225Z", "postId": "NZz3Das7jFdCBN9zH", "htmlBody": "<p>That's very helpful, thank you!</p>", "parentCommentId": "6sxmMwsP9vz5oEYdi", "user": {"username": "paul_dfr"}}]