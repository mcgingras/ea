[{"_id": "h5cJtbkevch3tmNP5", "postedAt": "2021-11-06T10:41:48.435Z", "postId": "cFRbLmhCEu74wcJ3D", "htmlBody": "<p>It seems like most of the work is being done here:</p><blockquote><p>If you think that AI won\u2019t be smarter than humans but agree that we cannot perfectly control AI in the same way that we cannot perfectly control humans</p></blockquote><p>If I were adopting my skeptic-hat, I don't think I would buy that assumption. (Or like, sure, we can't <i>perfectly&nbsp;</i> control AI, but your argument assumes that we are at least as unable to control AI as we are unable to control humans, which I wouldn't buy.) AI systems are <i>programs</i>; programs are (kind of) determined entirely by their source code, which we perfectly control, why should they be as hard to control as humans? You wouldn't make the same assumption for, say, Google Maps; what's the difference?</p>", "parentCommentId": null, "user": {"username": "rohinmshah"}}, {"_id": "p2TuDsWBwfLabgjEe", "postedAt": "2021-11-06T11:23:42.570Z", "postId": "cFRbLmhCEu74wcJ3D", "htmlBody": "<p>So what would you pitch for skeptics look like? Just ask which assumptions they don't buy, rebut and iterate?&nbsp;</p>", "parentCommentId": "h5cJtbkevch3tmNP5", "user": {"username": "mariushobbhahn"}}, {"_id": "LbekCuBjtsu6Nyn6z", "postedAt": "2021-11-06T16:22:02.104Z", "postId": "cFRbLmhCEu74wcJ3D", "htmlBody": "<p>One of my theories here is that it's helpful to pivot quickly towards \"here's an example concrete research problem that seem hard but not impossible, and people are working on it, and not knowing the solution seems obviously problematic\". This is good for several reasons, including \"pattern-matching to serious research, safety engineering, etc., rather than pattern-matching to sci-fi comics\", providing a gentler on-ramp (as opposed to wrenching things like \"your children probably won't die of natural causes\" or whatever), providing food for thought, etc. Of course this only works if you can engage in the technical arguments. Brian Christian's book is the extreme of this approach.</p>\n", "parentCommentId": null, "user": {"username": "steve2152"}}, {"_id": "BvvcfgB848ovcv49W", "postedAt": "2021-11-06T19:33:03.675Z", "postId": "cFRbLmhCEu74wcJ3D", "htmlBody": "<p>Yup</p>", "parentCommentId": "p2TuDsWBwfLabgjEe", "user": {"username": "rohinmshah"}}, {"_id": "DCe8nAjAy78NCXaRB", "postedAt": "2021-11-08T10:53:56.474Z", "postId": "cFRbLmhCEu74wcJ3D", "htmlBody": "<p>There was a paper on this recently:</p><h1><a href=\"https://arxiv.org/abs/2105.02704\"><strong>AI Risk Skepticism</strong></a></h1><p>Roman V. Yampolskiy</p><p>Abstract:</p><blockquote><p>In this work, we survey skepticism regarding AI risk and show parallels with other types of scientific skepticism. We start by classifying different types of AI Risk skepticism and analyze their root causes. We conclude by suggesting some intervention approaches, which may be successful in reducing AI risk skepticism, at least amongst artificial intelligence researchers.</p></blockquote>", "parentCommentId": null, "user": {"username": "HaukeHillebrandt"}}, {"_id": "cvvjHu9DopviCfrwA", "postedAt": "2021-11-08T14:28:02.659Z", "postId": "cFRbLmhCEu74wcJ3D", "htmlBody": "<p>One thing I could imagine happening in these situations is that people close themselves off to object level arguments to a degree, and maybe for (somewhat) good reason.</p><ul><li>to the general public, the idea of AI being a serious (existential) risk is probably still very weird</li><li>people may have an impression that believing in such things correlates with being gullible</li><li>people may be hesitant towards \"being convinced\" of something they haven't fully thought through themselves</li></ul><p>I remember once when I was younger talking to a Christian fanatic of sorts, who kept coming up with new arguments for why the bible must obviously be true due to the many correct predictions it has apparently made, plus some argument about irreducible complexity. In the moment, I couldn't really tell if/where/why his arguments failed. I found them somewhat hard to follow and just knew the conclusion would be something that is both weird and highly unlikely (for reasons other than his concrete arguments). So my impression then was \"there surely is something wrong about his claims, but in this very moment I'm lacking the means to identify the weaknesses\".&nbsp;</p><p>I sometimes find myself in similar situations when some person tries to get me to sign something or to buy some product they're offering. They tend to make very convincing arguments about why I should definitely do it. I often have no good arguments against that. Still, I tend to resist many of these situations because I haven't yet heard or had a chance to find the best counter arguments.</p><p>When somebody who has thought a lot about AI safety and is very convinced of its importance talks to people to whom this whole area is new and strange, I can imagine similar defenses being present. If this is true, more/better/different arguments may not necessarily be helpful to begin with. Some things that could help:</p><ul><li>social proof (\"these well respected people and organizations think this is important\")</li><li>slightly weaker claims that people have an easier time agreeing with</li><li>maybe some meta level argument about why the unintuitive-ness is misguided (although this could probably also taken as an attack)</li></ul>", "parentCommentId": null, "user": {"username": "markus_over"}}, {"_id": "5TazAXTLoygLJSnE8", "postedAt": "2021-11-11T01:40:53.837Z", "postId": "cFRbLmhCEu74wcJ3D", "htmlBody": "<p>As a meta-comment, I like the title \"What are the best intuition pumps for AI safety?\" for this post, rather than \"How do you convince skeptics?\". The former feels more like <a href=\"https://www.amazon.com/dp/B089CJ6SVS/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1\">scout mindset</a> to me, the latter like soldier mindset.</p><p>An intuition pump takes the form of a question or thought experiment that a person can think through themselves; an argument to \"convince\" a \"skeptic\" feels more like an attempt to push someone toward a view without letting them think too carefully.</p>", "parentCommentId": null, "user": {"username": "aarongertler"}}, {"_id": "aExW7gtcAmdsm9KJa", "postedAt": "2021-11-11T21:07:37.546Z", "postId": "cFRbLmhCEu74wcJ3D", "htmlBody": "<p>Makes sense. I changed it. Thanks!</p>", "parentCommentId": "5TazAXTLoygLJSnE8", "user": {"username": "mariushobbhahn"}}]