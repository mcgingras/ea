[{"_id": "dwyGAp3uH45Kyg7ac", "postedAt": "2024-03-29T01:32:40.291Z", "postId": "JSK8ZFc2fsNXYYoPP", "htmlBody": "<p>The concrete suggestions here seem pretty wild, but I think the possible tension between computationalism and shrimp welfare is interesting. I don't think it's crazy to conclude \"given x% credence on computationalism (plus these moral implications), I should reduce my prioritization of shrimp welfare by nearly x%.\"</p><p>That said, the moral implications are still quite wild. To paraphrase Parfit, \"research in [ancient Egyptian shrimp-keeping practices] cannot be relevant to our decision whether to [donate to SWP today].\" The Moral Law keeping a running tally of previously-done computations and giving you a freebie to do a bit of torture if it's already on the list sounds like a <i>reductio</i>.</p><p>A hazy guess is that something like \"respecting boundaries\" is a missing component here? Maybe there <i>is</i> something wrong with messing around with a water computer that's instantiating a mind, because that mind has a right to control its own physical substrate. Seems hard to fit with utilitarianism though.</p>", "parentCommentId": null, "user": {"username": "det"}}, {"_id": "ec8BXrJqA6GcKjGW6", "postedAt": "2024-03-29T04:54:59.525Z", "postId": "JSK8ZFc2fsNXYYoPP", "htmlBody": "<blockquote><p>But under diversity-valuing ethical theories, if we take a reasonable estimate of 10,000 meaningfully distinct shrimp minds at birth times 1 million possible external environmental inputs to those minds, that's only 10 billion distinct shrimp lived experiences.</p></blockquote><p>Why is 10,000 meaingfully distinct shrimp minds at birth a reasonable estimate? Why is 1 million possible external environmental inputs to those minds a reasonable estimate?</p><p>Also, the argument doesn't take into account uncertainty about these numbers. You discuss the possibility that we could be away from the ceiling, but not what to do under uncertainty. If there's a 1% chance that nearly all shrimp experiences are meaningfully distinct in practice, then we can just multiply through by 1% as a lower bound.</p>", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "knusuDGkq2GbcpwqW", "postedAt": "2024-03-29T04:57:48.075Z", "postId": "JSK8ZFc2fsNXYYoPP", "htmlBody": "<p>If you were being tortured, it seems horrible to create a copy of you being tortured identically (all else equal). I don't see why it would matter any less, let alone somewhat less or, as implied by your post, <i>not at all</i>.</p><p>(EDITED) And if a copy of you were to be tortured in mental states X in the future or elsewhere, then it wouldn't be bad for you to be tortured in mental states X here and now. If you're impartial, you'd actually be wrong to disvalue your own torture.</p><p><s>Or, you have to consider only simultaneous states or within some bands of time or discount some other way.</s> This doesn't get around simultaneous copies elsewhere.</p>", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "9y4cQjphrepEXJhSa", "postedAt": "2024-03-29T08:07:09.409Z", "postId": "JSK8ZFc2fsNXYYoPP", "htmlBody": "<blockquote><p><a href=\"https://philosophybear.substack.com/p/the-view-from-utopia\">most people intrinsically value diversity of experience</a>, and see a large number of very similar lives as less of a good thing.</p></blockquote><p>Especially in such a contentious argument, I think it's bad epistemics to link to a page with some random dude saying he personally believes x (and giving no argument for it) with the linktext 'most people believe x'.</p>", "parentCommentId": null, "user": {"username": "Arepo"}}, {"_id": "NiuRJM9goD9Syeffm", "postedAt": "2024-03-29T08:12:55.810Z", "postId": "JSK8ZFc2fsNXYYoPP", "htmlBody": "<p>This. I'm imagine some <a href=\"https://rickandmorty.fandom.com/wiki/Abrodolph_Lincoler\">Abrodolph Lincoler</a>-esque character - <a href=\"https://en.wikipedia.org/wiki/Bernard_Williams\">Abronard Willter </a>maybe - putting me in a brazen bull and cooing 'Don't worry, this will all be over soon. I'm going to create 10billion more of you also on a rack, and the fact that I continue to torture you personally will barely matter.'</p>", "parentCommentId": "knusuDGkq2GbcpwqW", "user": {"username": "Arepo"}}, {"_id": "tfnJEAJYPvAkHJfDH", "postedAt": "2024-03-29T08:51:04.437Z", "postId": "JSK8ZFc2fsNXYYoPP", "htmlBody": "<p>Also, I'd guess most people who value diversity of experience mean that only for positive experiences. I doubt most would mean repeated bad experiences aren't as bad as diverse bad experiences, all else equal.</p>", "parentCommentId": "9y4cQjphrepEXJhSa", "user": {"username": "MichaelStJules"}}, {"_id": "8oRqrbuaQWWRFEAfQ", "postedAt": "2024-03-29T08:52:43.770Z", "postId": "JSK8ZFc2fsNXYYoPP", "htmlBody": "<p>If you don't care about where or when duplicate experiences exist, only their number, then not caring about duplicates at all gives you a fanatical wager <i>against</i> the universe having infinitely many moral patients, e.g. by being infinitely large spatially, going on forever in time, having infinitely many pocket universes.</p><p>It would also give you a wager against the many-worlds interpretation of quantum mechanics, because there will be copies of you having identical experiences in (at least slightly) already physically distinct branches.</p>", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "nueei5uFwse2YFkkY", "postedAt": "2024-03-29T12:43:25.928Z", "postId": "JSK8ZFc2fsNXYYoPP", "htmlBody": "<p><strong>Executive summary:</strong> Diversity-oriented theories of moral value, which place intrinsic value on the diversity of experiences, have significant implications for the effectiveness of interventions aimed at improving shrimp welfare in factory farming.</p><p><strong>Key points:</strong></p><ol><li>Computational theories of mind and identity suggest that the moral value of an individual depends on the uniqueness of their mental experiences.</li><li>Shrimp likely have a limited number of meaningfully distinct mental experiences due to their small brain size.</li><li>Interventions that improve the quality of life for a subset of farmed shrimp may have little moral value if the same negative experiences are still instantiated in other farms.</li><li>Global interventions and those focused on wild shrimp may be more impactful due to affecting a greater diversity of experiences.</li><li>Standardizing shrimp farming conditions could potentially reduce the number of distinct negative experiences, even if the average quality of life worsens.</li><li>Further philosophical and empirical research is needed to assess the validity and implications of these theories for shrimp welfare and other factory farmed animals.</li></ol><p>&nbsp;</p><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}]