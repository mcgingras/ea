[{"_id": "ztKdFoJyxooHdPNf8", "postedAt": "2024-01-04T14:19:39.640Z", "postId": "HGf3WwRpgHXy9vzS6", "htmlBody": "<p><strong>Executive summary</strong>: AI could substantially improve or worsen humanity's epistemic capabilities. Key recommendations are to develop AI that provides honest advice, establish institutions trusted for using AI well epistemically, and regulate persuasive AI.</p><p><strong>Key points</strong>:</p><ol><li>AI could honestly investigate questions more competently and cheaply than humans, if developed properly.</li><li>But super-human persuasion capabilities could also spread misinformation.</li><li>Recommendations include:<ul><li>Develop AI that gives validated, honest advice</li><li>Survey public trust in hypothetical AI systems</li><li>Establish reputable institutions using AI transparently</li><li>Make legislative proposals restricting AI persuasion</li><li>Accelerate AI abilities on forecasting and philosophy over persuasion</li></ul></li><li>The development of reliable epistemic AI should be timely to provide guidance on emerging issues.</li><li>There may also be path dependencies around reputation and consensus that necessitate quick action.</li></ol><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}]