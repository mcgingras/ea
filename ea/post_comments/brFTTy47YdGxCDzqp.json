[{"_id": "rpBEdpD8RdXdLWKNp", "postedAt": "2022-12-27T23:08:14.780Z", "postId": "brFTTy47YdGxCDzqp", "htmlBody": "<p>This is helpful at the margin</p>\n<p>But my experience over 15 years of teaching at UK universities is that  \u201cmarking student research/take home essays \u201d was  already a highly problematic and inaccurate means of evaluation. Extremely time consuming to judge, especially with students who struggle with the English language. (And you are asked to not penalise them for this).  Students can and do pay others to write it for them.</p>\n<p>the availability of chat Gpt makes this substantially more difficult.</p>\n<p>My advice (to the educational system) would be a combination of:</p>\n<ol>\n<li>\n<p>Try to work with a smaller number of intrinsically motivated students. Focus less on evaluation. This is particularly true for research intensive subjects.</p>\n</li>\n<li>\n<p>If you need to do evaluation, arrange  proctored/Invigilated exams</p>\n</li>\n</ol>\n", "parentCommentId": null, "user": {"username": "david_reinstein"}}, {"_id": "rW7QLtRRqkFn5zZfD", "postedAt": "2022-12-27T23:34:25.421Z", "postId": "brFTTy47YdGxCDzqp", "htmlBody": "<blockquote>\n<p>I think this type of misuse is an emerging AI alignment problem.</p>\n</blockquote>\n<p>Misuse can be important or interesting, but the word \u201calignment\u201d should be reserved for problems like the problem of making systems try to do what their operators want, especially making very capable systems not kill everyone.</p>\n", "parentCommentId": null, "user": {"username": "zsp"}}]