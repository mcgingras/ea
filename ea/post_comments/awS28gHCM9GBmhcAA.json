[{"_id": "ju88P9bbQ4ZHPHNrQ", "postedAt": "2018-08-15T14:00:04.418Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<blockquote>\n<p>We do however recognize that when consulting others it\u2019s easy to end up selecting for people with similar views and this can leave us with blind spots in particular areas. We are thinking about how to expand the range of people we get advice from. While we cannot promise to enact all suggestions, we would like to hear suggestions from forum users about what else they might like to see from CEA in this area.</p>\n</blockquote>\n<p>It seems like you currently only consult people for EA Global content. Do you want to get advice on how to have a wider range of consultants for EA Global content, or are you asking for something else?</p>\n", "parentCommentId": null, "user": {"username": "Khorton"}}, {"_id": "qQiSrcKecfxr2qYLu", "postedAt": "2018-08-15T14:36:30.015Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>What are some open questions that you\u2019d like to get input on here (preferably of course from people who have enough background knowledge)?</p>\n<p>This post reads to me like an explanation of why your current approach makes sense (which I find mostly convincing). I\u2019d be interested in what assumptions you think should be tested the most here.  </p>\n", "parentCommentId": null, "user": {"username": "remmelt"}}, {"_id": "SgvaDN258zFA3kXwy", "postedAt": "2018-08-15T16:17:46.549Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<blockquote>\n<p>it\u2019s unclear what reference class we should be using when making our work more representative... The best solution is likely some hybrid approach, but it\u2019s unclear precisely how such an approach might work.</p>\n</blockquote>\n<p>Could you say more about what CEA is planning to do to get more clarity about who it should represent? </p>\n", "parentCommentId": null, "user": {"username": "Milan_Griffes"}}, {"_id": "PGbbstjncYarkPjCw", "postedAt": "2018-08-15T20:48:21.869Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>Just wanted to chip in on this. Although I do not think this addresses all the concerns I have with representativeness, I do think CEA has been making a more concerted and genuine effort at considering how to deal with these issues (not just this blog post, but also in some of the more recent conversations they have been having with a wider range of people in the EA movement). I think it's a tricky issue to get right (how to build a cause neutral EA movement when you think some causes are higher impact than others) and there is still a lot of thought to be done on the issue, but I am glad steps are happening in the right direction.</p>\n", "parentCommentId": null, "user": {"username": "Joey"}}, {"_id": "XRhDuw4jXjasjRz2v", "postedAt": "2018-08-15T20:58:48.416Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>At the moment our mainline plan is this post with a request for feedback. </p>\n<p>I've been talking with Joey Savoie and Tee Barnett about the issue. I intend to consult others as well, but I don't have a concrete plan for who to contact.</p>\n", "parentCommentId": "SgvaDN258zFA3kXwy", "user": {"username": "Kerry_Vaughan"}}, {"_id": "wDJbxixvCY6rBSiNb", "postedAt": "2018-08-15T21:01:16.028Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>The biggest open questions are:</p>\n<p>1) In general, how can we build a community that is both cause impartial and also representative?\n2) If we want to aim for representativeness, what reference class should we target?</p>\n", "parentCommentId": "qQiSrcKecfxr2qYLu", "user": {"username": "Kerry_Vaughan"}}, {"_id": "Sw8T6AH3QD3kmwRDj", "postedAt": "2018-08-15T21:06:50.953Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>We're asking for feedback on who we should consult with in general, not just for EA Global. </p>\n<p>In particular, the usual process of seeking advice from people we know and trust is probably producing a distortion where we aren't hearing from a true cross-section of the community, so figuring out a different process might be useful.</p>\n", "parentCommentId": "ju88P9bbQ4ZHPHNrQ", "user": {"username": "Kerry_Vaughan"}}, {"_id": "ZHY64H3CEpjBcPrvd", "postedAt": "2018-08-15T23:50:28.751Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<blockquote>\n<p>We would like to hear suggestions from forum users about what else they might like to see from CEA in this area.</p>\n</blockquote>\n<p>Here is my two cents. I hope it is constructive:</p>\n<hr />\n<p>1.</p>\n<p>The policy is excellent but the challenge lies in implementation.</p>\n<p>Firstly I want to say that this post is fantastic. I think you have got the policy correct: that CEA  should be cause-impartial, but not cause-agnostic and CEA\u2019s work should be cause-general.</p>\n<p>However I do not think it looks, from the outside, like CEA is following this policy.\nSome examples:</p>\n<ul>\n<li><p>EA London staff had concerns that they would need to be more focused on the far future in order to receive funding from CEA.</p>\n</li>\n<li><p>You explicitly say on your website: &quot;We put most of our credence in a worldview that says what happens in the long-term future is most of what matters. We are therefore more optimistic about others who roughly share this worldview.&quot;[1]</p>\n</li>\n<li><p>The example you give of the new EA handbook</p>\n</li>\n<li><p>There is a close association with 80000 Hours who are explicitly focusing much of their effort on the far future.</p>\n</li>\n</ul>\n<p>These are all quite subtle things, but collectively they give an impression that CEA is not cause impartial (that it is x-risk focused).\nOf course this is a difficult thing to get correct. It is difficult to draw the line between saying: 'our staff members believe cause___ is important' (a useful factoid that should definitely be said), whilst also putting across a strong front of cause impartiality. </p>\n<hr />\n<p>2.</p>\n<p>Suggestion: CEA should actively champion cause impartiality</p>\n<p>If you genuinely want to be cause impartial I think most of the solutions to this are around being super vigilant about how CEA comes across. Eg:</p>\n<ul>\n<li><p>Have a clear internal style guide that sets out to staff good and bad ways to talk about causes</p>\n</li>\n<li><p>Have 'cause impartiality' as a staff value</p>\n</li>\n<li><p>If you do an action that does not look cause impartial (say EA Grants mostly grants money to far future causes) then just acknowledge this and say that you have noted it and explain why it happened.</p>\n</li>\n<li><p>Public posts like this one setting out what CEA believes</p>\n</li>\n<li><p>If you want to do lots of &quot;prescriptive&quot; actions split them off into a sub project or a separate institution. </p>\n</li>\n<li><p>Apply the above retroactively (remove lines from your website that make it look like you are only future focused)</p>\n</li>\n</ul>\n<p>Beyond that, if you really want to champion cause impartiality you may also consider extra things like:</p>\n<ul>\n<li><p>More focus on cause prioritisation research. </p>\n</li>\n<li><p>Hiring people who value cause impartiality / cause prioritisation research / community building, above people who have strong views on what causes are important.</p>\n</li>\n</ul>\n<hr />\n<p>3.</p>\n<p>Being representative is about making people feel listened too.</p>\n<p>Your section on representatives feels like you are trying to pin down a way of finding an exact number so you can say we have this many articles on topic x and this many on topic y and so on. I am not sure this is quite the correct framing.</p>\n<p>Things like the EA handbook should (as a lower bound) have enough of a diversity of causes mentioned that the broader EA community does not feel misrepresented but (as an upper bound) not so much that CEA staff [2] feel like it is misrepresenting them. Anything within this range seems fine to me. (Eg. with the EA handbook both groups should feel comfortable handing this book to a friend.) Although I do feel a bit like I have just typed 'just do the thing that makes everyone happy' which is easier said than done.</p>\n<p>I also think that &quot;representativeness&quot; is not quite the right issue any way. The important thing is that people in the EA community feel listened too and feel like what CEA is doing represents them. The % of content on different topics is only part of that. The other parts of the solution are:</p>\n<ul>\n<li><p>Coming across like you listen: see the aforementioned points on championing cause impartiality. Also expressing uncertainty, mentioning that there are opposing views, giving two sides to a debate, etc.</p>\n</li>\n<li><p>Listening -- ie. consulting publicly (or with trusted parties) wherever possible.</p>\n</li>\n</ul>\n<p>If anything getting these two things correct is more important than getting the exact percentage of your work to be representative.</p>\n<hr />\n<p>Sam :-)</p>\n<hr />\n<p>[1] <a href=\"https://www.centreforeffectivealtruism.org/a-three-factor-model-of-community-building\">https://www.centreforeffectivealtruism.org/a-three-factor-model-of-community-building</a></p>\n<p>[2] Unless you have reason to think that there is a systematic bias in staff, eg if you actively hired people because of the cause they cared about.</p>\n", "parentCommentId": null, "user": {"username": "weeatquince"}}, {"_id": "LFjJnJnXc6jtgqDki", "postedAt": "2018-08-16T01:27:20.589Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>EA grants seems like it should be in between in terms of being prescriptive vs. descriptive. If I had to pull a number out of a hat, then perhaps half the grants could be in the areas CEA considers most important and the other half could be more open.</p>\n", "parentCommentId": null, "user": {"username": "casebash"}}, {"_id": "YkcR8S6v7NPBDgqA7", "postedAt": "2018-08-16T02:29:59.728Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<blockquote>\n<p>If you do an action that does not look cause impartial (say EA Funds mostly grants money to far future causes) then just acknowledge this and say that you have noted it and explain why it happened.</p>\n</blockquote>\n<p>Do you mean EA Grants? The allocation of EA Funds across cause areas is outside of CEA's control since there's a separate fund for each cause area. </p>\n", "parentCommentId": "ZHY64H3CEpjBcPrvd", "user": {"username": "RandomEA"}}, {"_id": "Y4aEkpt8obWbuTpW9", "postedAt": "2018-08-16T07:27:48.117Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>Yes thanks. Edited.</p>\n", "parentCommentId": "YkcR8S6v7NPBDgqA7", "user": {"username": "weeatquince"}}, {"_id": "CRywFFBBe9QPjpRCc", "postedAt": "2018-08-16T14:23:56.709Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>Just wanted to say I loved how specific and detailed the feedback is here - thank you!</p>\n", "parentCommentId": "ZHY64H3CEpjBcPrvd", "user": {"username": "Julia_Wise"}}, {"_id": "Xb5bqu92kd4ecXv8Z", "postedAt": "2018-08-16T15:10:05.409Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>To add a little more background: we're always glad to get ideas from the community about EA Global on our content/speaker <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfCfGs2T-Fp3ZgCc9rSGjwAY2wThes7XPY21nxR8u8nannK-Q/viewform\">suggestion form</a>. </p>\n<p>We also get feedback on major decisions that will affect the community from an <a href=\"http://effective-altruism.com/ea/180/advisory_panel_at_cea/\">advisory panel</a>, chosen because they had given us especially useful criticism in the past. However, we'd like to get more frequent, informal feedback as well.</p>\n", "parentCommentId": "Sw8T6AH3QD3kmwRDj", "user": {"username": "Julia_Wise"}}, {"_id": "9iXnWS565o2m7Cx6n", "postedAt": "2018-08-16T16:39:48.897Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>The &quot;what causes should CEA represent?&quot; issue seems especially tricky because the current canonical EA cause areas have very different metrics underpinning them.</p>\n<p>Global development &amp; animal welfare usually use GiveWell-style cost-effectiveness analysis to determine what's effective.</p>\n<p>X-risk usually uses theoretical argument &amp; back-of-the-envelope estimates to determine effectiveness.</p>\n<p>I'm not sure what movement building uses \u2013 probably theory and back-of-the-envelope as well?</p>\n<p>Anyway, point is that there's not a meta-metric that the current cause areas use to compare against each other. </p>\n<p>So when considering a new cause area, should we use the x-risk standard of effectiveness? Or the global development one? (rhetorical) </p>\n<p>Seems tricky \u2013 I'm glad CEA is thinking about this.</p>\n", "parentCommentId": null, "user": {"username": "Milan_Griffes"}}, {"_id": "ag4YoMq6dLWidAcfS", "postedAt": "2018-08-16T16:50:29.629Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>Is there a process for joining &amp; leaving the advisory panel, or is that handled informally?</p>\n<p>Also, could you say a little more about how &amp; when the panel is engaged for feedback?</p>\n", "parentCommentId": "Xb5bqu92kd4ecXv8Z", "user": {"username": "Milan_Griffes"}}, {"_id": "Z6m4bp2rFkY6Pix4q", "postedAt": "2018-08-18T00:25:39.114Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>Thanks Sam! This is really helpful. I'd be interested in talking on Skype about this sometime soon (just emailed you about it). Some thoughts below:</p>\n<p><strong>Is longtermism a cause?</strong></p>\n<p>One idea I've been thinking about is whether it makes sense to treat longtermism/the long-term future as a cause.</p>\n<p>Longtermism is the view that most of the value of our actions lies in what happens in the future. You can hold that view and also hold the view that we are so uncertain about what will happen in the future that doing things with clear positive short-term effects is the best thing to do. <a href=\"http://effective-altruism.com/ea/1r5/problems_with_ea_representativeness_and_how_to/f5e\">Peter Hurford explains this view nicely here.</a> </p>\n<p>I do think that longtermism as a philosophical point of view is emerging as an intellectual consensus in the movement. Yet, I also think there are substantial and reasonable disagreements about what that means practically speaking. I'd be in favor of us working to ensure that people entering the community understand the details of that disagreement.</p>\n<p>My guess is that while CEA is very positive on longtermism, we aren't anywhere near as positive on the cause/intervention combinations that longtermism typically suggests. For example, personally speaking, if it turned out that recruiting ML PhDs to do technical AI-Safety didn't have a huge impact I would be surprised but not <em>very</em> surprised.</p>\n<p><strong>Threading the needle</strong></p>\n<p>My feeling as I've been thinking about representativeness is that getting this right requires threading a very difficult needle because we need to optimize against a large number of constraints and considerations. Some of the constraints include:</p>\n<ul>\n<li><em>Cause areas shouldn't be tribes</em> -- I think cause area allegiance is operating as a kind of tribal signal in the movement currently. You're either on the global poverty tribe or the X-risk tribe or the animal welfare tribe and then people tend to defend the views of the tribe they happen to be associated with. I think this needs to stop if we want to build a community that can actually figure out how to do the most good and then do it. Focusing on cause areas as the unit of analysis for representativeness entrenches the tribal concern, but it's hard to get away from because it's an easy-to-understand unit of analysis.</li>\n<li><em>We shouldn't entrench existing cause areas</em> -- we should be aiming for an EA that has the ability to shift its consensus on the most pressing problems as we learn more. Some methods of increasing representativeness have the effect of entrenching current cause areas and making intellectual shifts harder.</li>\n<li><em>Cause-impartiality can include having a view</em> -- cause impartiality means that you do an impartial calculation of impact to determine what to work on. Such a calculation should lead to developing views on what causes are most important. Intellectual progress probably includes decreasing our uncertainty and having stronger views.</li>\n<li><em>The view of CEA staff should inform, but not determine our work</em> -- I don't think it's realistic or plausible for CEA to take actions as if we have no view on the relative importance of different problems, but it's also the case that our views shouldn't substantially determine what happens.</li>\n<li><em>CEA should sometimes exercise leadership in the community</em> -- I don't think that social movements automatically become excellent. Excellence typically has to be achieved on purpose by dedicated, skilled actors. I think CEA will often do work that represents the community, but will sometimes want to lead the community on important issues. The allocation of resources across causes could be one such area for leadership although I'm not certain.</li>\n</ul>\n<p>There are also some other considerations around methods of improving representativeness. For example, consulting established EA orgs on representativeness concerns has the effect of entrenching the current systems of power in a way that may be bad, but that gives you a sense of the consideration space.</p>\n<p><strong>CEA and cause-impartiality</strong></p>\n<blockquote>\n<p>Suggestion: CEA should actively champion cause impartiality</p>\n</blockquote>\n<p>I just wanted to briefly clarify that I don't think CEA taking a view in favor of longtermism or even in favor of specific causes that are associated with longtermism is evidence against us being cause-impartial. Cause-impartiality means that you do an impartial calculation of the impact of the cause and act on the basis of that. This is certainly what we think we've done when coming to views on specific causes although there's obviously room for reasonable disagreement.</p>\n<p>I would find it quite odd if major organizations in EA (even movement building organizations) had no view on what causes are most important. I think CEA should be aspiring to have detailed, nuanced views that take into account our wide uncertainty, not no views on the question.</p>\n<p><strong>Making people feel listened to</strong></p>\n<p>I broadly agree with your points here. Regularly talking to and listening to more people in the community is something that I'm personally committed to doing.</p>\n<blockquote>\n<p>Your section on representatives feels like you are trying to pin down a way of finding an exact number so you can say we have this many articles on topic x and this many on topic y and so on. I am not sure this is quite the correct framing.</p>\n</blockquote>\n<p>Just to clarify, I also don't think trying to find a number that defines representativeness is the right approach, but I also don't want this to be a purely philosophical conversation. I want it to drive action.</p>\n", "parentCommentId": "ZHY64H3CEpjBcPrvd", "user": {"username": "Kerry_Vaughan"}}, {"_id": "aRLiPEQguBrNrFQh8", "postedAt": "2018-08-18T01:53:52.320Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>We've had this panel for a little more than a year, and haven't yet have turnover. If looking for a new member, we'd look for someone who had given us helpful outside perspective / criticism in the past.</p>\n<p>We've asked the panel for feedback primarily when making decisions where CEA's view of its proper role in the community is especially likely to differ from others' view of CEA's proper role. One example is around whether CEA should express views on which other organizations are EA organizations.</p>\n", "parentCommentId": "ag4YoMq6dLWidAcfS", "user": {"username": "Julia_Wise"}}, {"_id": "xjr5NhiddrygyhpnX", "postedAt": "2018-08-18T21:00:28.903Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<blockquote>\n<p>I would find it quite odd if major organizations in EA (even movement building organizations) had no view on what causes are most important.</p>\n</blockquote>\n<p>I would definitely find it odd if individuals within an organization didn't have views on which causes are most important. I wouldn't find it that strange if CEA didn't have a formally stated view on which causes are most important, although I expect some views will be implied through your communication. </p>\n", "parentCommentId": "Z6m4bp2rFkY6Pix4q", "user": {"username": "Khorton"}}, {"_id": "HnznuMShcPWto5b7z", "postedAt": "2018-08-19T21:08:31.649Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>Disclosure: I copyedited a draft of this post, and do contract work for CEA more generally</p>\n<p>I don't think that longtermism is a consensus view in the movement.</p>\n<p>The 2017 EA Survey results had more people saying poverty was the top priority than AI and non-AI far future work combined. Similarly, AMF and GiveWell got by far the most donations in 2016, according to that same survey. While I agree that someone can be a longtermist and think that practicality concerns prioritize near-term good work for now anyway, I don't think this is a very compelling explanation for these survey results.</p>\n<p>As a first pass heuristic, I think EA leadership would guess correctly about community-held views more often if they held the belief &quot;the modal EA-identifying person cares most about solving suffering that is happening in the world right now.&quot;</p>\n", "parentCommentId": "Z6m4bp2rFkY6Pix4q", "user": {"username": "Justis"}}, {"_id": "333hHAdomn63vD3NS", "postedAt": "2018-08-19T21:23:45.959Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>I really like the Open Philanthropy Project's way of thinking about this problem:</p>\n<p><a href=\"https://www.openphilanthropy.org/blog/update-cause-prioritization-open-philanthropy\">https://www.openphilanthropy.org/blog/update-cause-prioritization-open-philanthropy</a></p>\n<p>The short version (in my understanding):</p>\n<ol>\n<li>Split assumptions about the world/target metrics into distinct &quot;buckets&quot;.</li>\n<li>Do allocation as a two step process: intra-bucket on that bucket's metric, and inter-bucket separately using other sorts of heuristics.</li>\n</ol>\n<p>(If you like watching videos rather than reading blog posts, Holden also discussed this approach in his fireside chat at EAG 2018: San Francisco.)</p>\n", "parentCommentId": "9iXnWS565o2m7Cx6n", "user": {"username": "Justis"}}, {"_id": "sdwxLX72HhcYyhGRw", "postedAt": "2018-08-19T22:08:07.737Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>(Speaking as a member of the panel, but not in any way as a representative of CEA). </p>\n<p>It\u2019s worth noting the panel hasn\u2019t been consulted on anything in the last 12 months. I don\u2019t think there\u2019s anything necessarily wrong with this, especially since it was set up partly in response to the Intentional Insights affair and AFAIK there has been no similar event in that time, but I have a vague feeling that someone reading Julia\u2019s posts would think it was more common, which I guess was part of the \u2018question behind your question\u2019, if that makes sense :)</p>\n", "parentCommentId": "ag4YoMq6dLWidAcfS", "user": {"username": "AGB"}}, {"_id": "sZyvnipkTcifDEprv", "postedAt": "2018-08-20T14:54:36.104Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>That's interesting background, thanks :-)</p>\n", "parentCommentId": "sdwxLX72HhcYyhGRw", "user": {"username": "Milan_Griffes"}}, {"_id": "dKaF5MShd8i8ACexc", "postedAt": "2018-08-20T15:07:32.544Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>Sure, but I don't think that framework gives a decision procedure for what buckets are worth considering. (Haven't read it closely recently, so maybe I missed this.) </p>\n<p>For example, I'm pretty sure a Christian who's interested in EA principles wouldn't be able to convince EA decision-makers that a Christian missionary intervention was effective, even if it was very cost-effective &amp; had a track record of success. </p>\n<p>The Christian wouldn't be able to make the case for their missionary intervention because &quot;spreading the word of God&quot; isn't a goal that EA considers worthwhile. As far as I know, EA doesn't have a strong case for why this kind of thing isn't worthwhile, it's just one of the &quot;deep judgment calls&quot; that Holden talks about in that post. </p>\n<p>Not caring about Christian missionary work is in cultural DNA of EA. It's not a particularly justified position, rather it's an artifact of the worldview assumptions that a quorum of EAs brought to the community at a certain point in time.</p>\n<p>(To be super-duper clear, I'm not advocating for Christian interventions to be included in EA; it's just an illustrative example.)</p>\n", "parentCommentId": "333hHAdomn63vD3NS", "user": {"username": "Milan_Griffes"}}, {"_id": "piL7FD6MNGpQBMyuq", "postedAt": "2018-08-20T21:59:51.549Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<blockquote>\n<p>Longtermism is the view that most of the value of our actions lies in what happens in the future. </p>\n</blockquote>\n<p>You mean 'in the <strong>far</strong> future', correct? Unless you believe in backwards causality, and excluding the value that occurs at the same moment you act, all the value of our actions is in the future. I presume by 'far future' you would mean actions affecting future people, as contrasted with presently existing people.</p>\n<blockquote>\n<p>I do think that longtermism as a philosophical point of view is emerging as an intellectual consensus in the movement</p>\n</blockquote>\n<p>Cards on the table, I am not a long-termist; I am sympathetic to person-affecting views in population ethics. Given the power CEA has in shaping the community, I think it's the case that any view CEA advocated would eventually become the consensus view: anyone who didn't find it appealing would eventually leave EA. </p>\n<blockquote>\n<p>I just wanted to briefly clarify that I don't think CEA taking a view in favor of longtermism or even in favor of specific causes that are associated with longtermism is evidence against us being cause-impartial. </p>\n</blockquote>\n<p>I don't think this can be true. If you're a longtermist, you can't also hold person-affecting views in population ethics (at least, narrow, symmetric person-affecting views), so taking the longtermist position requires ruling such views out of consideration. You might think you should rule out, as obviously false, such views in population ethics, but you should concede you are doing that. To be more accurate you could perhaps call it something like &quot;possibilism cause impartiality - selecting causes based on impartial estimates of impact assuming we account for the welfare of everyone who might possibly exist&quot; but then it would seem almost trivially true long-termist ought to follow (this might not be the right name, but I couldn't think of a better restatement off-hand).</p>\n", "parentCommentId": "Z6m4bp2rFkY6Pix4q", "user": {"username": "MichaelPlant"}}, {"_id": "eJWF7nmxhgT5pRkLZ", "postedAt": "2018-08-21T11:29:52.599Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>In terms of representation then my own opinion in relation to the animal welfare cause area is that it could relate to moral theory.  At present the dominant ideology (rational pragmatism) favoured by many utilitarians has functioned as a way for people to associate with one another, and offers a fairly easy way to become part of EAA through adopting certain organisations and ideas.  This is an ideology which in my view has been dismissive of rights based approaches by diminishing their value / relevance to effectiveness thinking.  </p>\n<p>To address this issue i believe rights based thinking ought to be valued and represented at various levels rather than dismissed in favour of the preferred ideology.  This isn't to say anything about which organisations or approaches are &quot;most&quot; effective but dismissing moral theory in favour of an ideology seems to be weak at both representativeness and integrity (particularly where it hasn't been agreed upon but is more unilateral).  </p>\n<p>I tend to think that addressing issues of representation in cause areas will have better follow on results in the community at large (informed from below rather than from above).  However, the problem here is that unrepresentative cause areas are more likely to be resistant to representation, because they are likely to gravitate toward that norm rather than away from it unless significant efforts are made, particularly where it has become institutionalised.  Whilst it is unclear whether some EAA leaders would think that a lack of representativeness (as i am stating it) or plurality would be a bad or concerning thing anyway as it can instead be associated with increasing utility, particularly through simplifying the cause area. </p>\n", "parentCommentId": "wDJbxixvCY6rBSiNb", "user": {"username": "KevinWatkinson"}}, {"_id": "3Mqw6yqiZqYxYa3Bo", "postedAt": "2018-08-21T20:25:27.494Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p><em>&quot;Cause areas shouldn't be tribes&quot;</em>\n<em>&quot;We shouldn't entrench existing cause areas&quot;</em>\n&quot;Some methods of increasing representativeness have the effect of entrenching current cause areas and making intellectual shifts harder.&quot;</p>\n<p>Does this mean you wouldn't be keen on e.g. &quot;cause-specific community liasons&quot; who mainly talk to people with specific cause-prioritisations, maybe have some money to back projects in 'their' cause, etc? (I'm thinking of something analogous to an <a href=\"https://www.openphilanthropy.org/about/team\">Open Philanthropy Project Program Officer</a> )</p>\n", "parentCommentId": "Z6m4bp2rFkY6Pix4q", "user": {"username": "HaydnBelfield"}}, {"_id": "mc39Pyxfg8yidLGzL", "postedAt": "2018-08-21T22:55:53.524Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>I agree that I might be wrong about this, but it's worth noting that I wasn't trying to make a claim about the modal EA. When talking about the emerging consensus I was implicitly referring to the influence-weighted opinion of EAs or something like that. This could be an area where I don't have access to a representative sample of influential EAs which would make it likely that the claim is false.</p>\n", "parentCommentId": "HnznuMShcPWto5b7z", "user": {"username": "Kerry_Vaughan"}}, {"_id": "Pr32ytZkZqYZR9Hdk", "postedAt": "2018-08-21T23:04:48.829Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<blockquote>\n<p>Does this mean you wouldn't be keen on e.g. &quot;cause-specific community liasons&quot; who mainly talk to people with specific cause-prioritisations, maybe have some money to back projects in 'their' cause, etc? (I'm thinking of something analogous to an Open Philanthropy Project Program Officer )</p>\n</blockquote>\n<p>I don't think I would be keen on this as stated. I would be keen on a system by which CEA talks to more people with a wider variety of views, but entrenching particular people or particular causes seems likely to be harmful to the long-term growth of the community.</p>\n", "parentCommentId": "3Mqw6yqiZqYxYa3Bo", "user": {"username": "Kerry_Vaughan"}}, {"_id": "xFPmR7dkAPjMqzm26", "postedAt": "2018-08-22T02:50:05.589Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>Sorry, I think we must have had a miscommunication within CEA - I had the understanding that we'd written to the panel last week about something, but apparently that didn't happen yet. In general, though, it's true that we've only asked the panel for input rarely.</p>\n", "parentCommentId": "sdwxLX72HhcYyhGRw", "user": {"username": "Julia_Wise"}}, {"_id": "rnXPaRDpxNQ86JS93", "postedAt": "2018-08-26T12:56:58.154Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>Hi Kerry, Some more thoughts prior to having a chat.</p>\n<p>-</p>\n<p><strong>Is longtermism a cause?</strong></p>\n<p>Yes and no. The term is used in multiple ways.</p>\n<p>A: Consideration of the long-term future.</p>\n<p>It is a core part of cause prioritisation to avoid availability biases: to consider the plights of those we cannot so easily be aware of, such as animals, people in other countries and people in the future. As such, in my view, it is imperative that CEA and EA community leaders promote this.</p>\n<p>B: The long-term cause area.</p>\n<p>Some people will conclude that the optimal use of their limited resources should be putting them towards shaping the far future. But not everyone, even after full rational consideration, will reach this view. Nor should we expect such unanimity of conclusions. As such, in my view, CEA and EA community leaders can recommend people to <em>consider</em> this causes area, but should not tell people this is <em>the</em> answer.</p>\n<p>-</p>\n<p><strong>Threading the needle</strong></p>\n<p>I agree with the 6 points you make here.</p>\n<p>(Although interestingly I personally do not have evidence that \u201carea allegiance is operating as a kind of tribal signal in the movement currently\u201d)</p>\n<p>-</p>\n<p><strong>CEA and cause-impartiality</strong></p>\n<p>I think CEA should be careful about how to express a view. Doing this in wrong way could make it look like CEA is not cause impartial or not representative.</p>\n<p>My view is to give recommendations and tools but not answers. This is similar to how we would not expect 80K to have a view on what the best job is (as it depends on an individual and their skills and needs) but we would expect 80K to have recommendations and to have advice on how to choose.</p>\n<p>I think this approach is also useful because:</p>\n<ul>\n<li><p>People are more likely to trust decisions they reach through their own thinking rather than conclusions they are pushed towards.</p>\n</li>\n<li><p>It handles the fact that everyone is different. The advice or reasoning that works for one person may well not make sense for someone else.</p>\n</li>\n</ul>\n<p>I think (as Khorton says) it is perfectly reasonable for an organisation to not have a conclusion.</p>\n<p>-</p>\n<p>(One other thought I had was on examples of actions I would be concerned about CEA or another movement building organisations taking would be: Expressing certainty about a area (in internal policy or externally), basing impact measurement solely on a single cause area, hiring staff for cause-general roles based on their views of what causes is most important, attempting to push as many people as possible to a specific cause area, etc)</p>\n", "parentCommentId": "Z6m4bp2rFkY6Pix4q", "user": {"username": "weeatquince"}}, {"_id": "jPw8xiwxmk23Y5tKx", "postedAt": "2018-09-22T07:20:02.197Z", "postId": "awS28gHCM9GBmhcAA", "htmlBody": "<p>Hi Kerry, Thank you for the call. I wrote up a short summary of what we discussed. It is a while since we talked so not perfect. Please correct anything I have misremembered.</p>\n<p>~</p>\n<p>1.</p>\n<p>~ ~ <strong>Setting the scene</strong> ~ ~</p>\n<ul>\n<li><strong>CEA should champion cause prioritisation.</strong> We want people who are willing to pick a new cause based on evidence and research and a community that continues to work out how to do the most good. (We both agreed this.)</li>\n<li>There is a difference between \u201ccause impartiality\u201d, as defined above, and \u201cactual impartiality\u201d, not having a view on what causes are most important. (There was some confusion but we got through it)</li>\n<li>There is a difference between long-termism as a methodology where one considers the long run future impacts which CEA should 100% promote and long-termism as a conclusion that the most important thing to focus on right now is shaping the long term future of humanity. (I asserted this, not sure you expressed a view.)</li>\n<li><strong>A rational EA decision maker could go through a process of cause prioritisation and very legitimately reach different conclusions</strong> as to what causes are most important. They may have different skills to apply or different ethics (and we are far away from solving ethics if such a thing is possible). (I asserted this, not sure you expressed a view.)</li>\n</ul>\n<p>~</p>\n<p>2.</p>\n<p>~ ~ <strong>Create space, build trust, express a view, do not be perfect</strong> ~ ~</p>\n<ul>\n<li><p><strong>The EA community needs to create the right kind of space so that people can reach their own decision about what causes are most important.</strong> This can be a physical space (a local community) or an online space. People should feel empowered to make their own decisions about causes. This means that they will be more adept at cause prioritisation, more likely to believe the conclusions reached and more likely to come to the correct answer for themselves, and EA is more likely to come to a correct answers overall. To do this they need good tools and resources and to feel that the space they are in is neutral. This needs trust...</p>\n</li>\n<li><p><strong>Creating that space requires trust</strong>. People need to trust the tools that are guiding and advising them. If people feel they being subtly pushed in a direction they will reject the resources and tools being offered. Any sign of a breakdown of trust between people reading CEA\u2019s resources and CEA should be taken very seriously. </p>\n</li>\n<li><p><strong>Creating that space does not mean you cannot also express a view.</strong> You just want to distinguish when you are doing this. You can create cause prioritisation resources and tools that are truly neutral but still have a separate section on what answers do CEA staff reach or what is CEA\u2019s answer.</p>\n</li>\n<li><p><strong>Perfection is not required</strong> as long as there is trust and the system is not breaking down.</p>\n</li>\n<li><p><strong>For example: providing policy advice</strong> I gave the example of writing advice to a Gov Minister on a controversial political issue, as a civil servant. The first ~85% of this imaginary advice has an impartial summary of the background and the problem and then a series of suggested actions with evaluations of their impact. The final ~15% has a recommended action based on the civil servant\u2019s view of the matter. The important thing here is that there generally is trust between the Minister and the Department that advice will be neutral, and that in this case the Minister trusts that the section/space setting out the background and possible actions is neutral enough for them to make a good decision. It doesn\u2019t need to be perfect, in fact the Minister will be aware that there is likely some amount of bias, but as long as there is sufficient trust that does not matter. And there is a recommendation which the Minister can choose to follow or not. In many cases the Minister will follow the recommendation.</p>\n</li>\n</ul>\n<p>~</p>\n<p>3.</p>\n<p>~ ~ <strong>How this goes wrong</strong> ~ ~</p>\n<ul>\n<li><p>Imagine someone who has identified cause X which is super important comes across the EA community. You do not want the community to either be so focused on one cause that this person is either put off or is persuaded that the current EA cause is more important and forgets about cause X</p>\n</li>\n<li><p>I mentioned some of the things that damage trust (see the foot of my previous comment).</p>\n</li>\n<li><p>You mentioned you had seen signs of tribalism in the EA community.</p>\n</li>\n</ul>\n<p>~</p>\n<p>4.</p>\n<p>~ ~ <strong>Conclusion</strong> ~ ~</p>\n<ul>\n<li><strong>You said that you saw more value in CEA creating a space that was \u201cactual impartial\u201d as opposed to \u201ccause impartial\u201d</strong> than you had done previously.</li>\n</ul>\n<p>~</p>\n<p>5.</p>\n<p>~ ~ <strong>Addendum: Some thoughts on evidence</strong> ~ ~</p>\n<p>Not discussed but I have some extra thoughts on evidence.</p>\n<p>There are two areas of my life where much of what I have learned points towards the views above being true.</p>\n<ul>\n<li><p><strong>Coaching</strong>. In coaching you need to make sure the coachee feels like you are there to help them not in any way with you own agenda (that is different from theirs).</p>\n</li>\n<li><p><strong>Policy</strong>. In policy making you need trust and neutrality between Minister and civil servant.</p>\n</li>\n</ul>\n<p>There is value in following perceived wisdom on a topic. That said I have been looking out for any strong evidence that these things are true (eg. that coaching goes badly if they think you are subtly biased one way or another) and I have yet to find anything particularly persuasive. (Counterpoint: I know one friend who knows their therapist is overly-bias towards pushing them to have additional sessions but this does not put them off attending or mean they find it less useful). Perhaps this deserves further study.</p>\n<p>Also worth bearing in mind there maybe dissimilarities between what CEA does and the fields of coaching and policy.</p>\n<p>Also worth flagging that the example of policy advice given above is somewhat artificial, some policy advice (especially where controversial) is like that but much of it is just: \u201cplease approve action x\u201d</p>\n<p><strong>In conclusion my views on this are based on very little evidence and a lot of gut feeling. My intuitions on this are strongly guided by my time doing coaching and doing policy advice.</strong></p>\n", "parentCommentId": "rnXPaRDpxNQ86JS93", "user": {"username": "weeatquince"}}]