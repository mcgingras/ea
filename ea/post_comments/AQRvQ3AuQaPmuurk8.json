[{"_id": "WpNz9CnrYAbGGN5Ez", "postedAt": "2022-09-22T02:46:34.656Z", "postId": "AQRvQ3AuQaPmuurk8", "htmlBody": "<p>Given that you have just published this on the forum, I have not yet finished watching the video, but it is playing in the background on 1.5x speed.&nbsp;</p><p>Your project is valuable to me since I am not up-to-date with my knowledge of the state of interpretability research and suspect that your project and manner of explanations will help slightly in this regard. Beyond the value, interpretability is simply interesting. I would very likely watch more video explanations of this nature on topics in AI Safety, interpretability, alignment, etc... which leads me to my question: Do you intend to continue to upload videos like the one you've uploaded today?&nbsp;</p><p>I really wish more EAs included video explanations / tutorials to supplement their work.&nbsp;</p><p>Thank you for posting this on the forum, and especially for creating the video.&nbsp;</p>", "parentCommentId": null, "user": {"username": "rodeo_flagellum"}}, {"_id": "DneSzH2vypTF7epzF", "postedAt": "2022-09-23T00:02:16.912Z", "postId": "AQRvQ3AuQaPmuurk8", "htmlBody": "<p>Thanks for the comment and for watching! I don't currently have any future videos planned, but I'd definitely consider it if there's interest. I'm also a fan of learning via videos, and you're right that there aren't that many in the AI Safety space. (<a href=\"https://www.youtube.com/c/RobertMilesAI\">Robert Miles</a> is the only AI Safety YouTuber, I'm aware of. &nbsp;Absolutely worth checking out if your interested in this kind of stuff.)</p>", "parentCommentId": "WpNz9CnrYAbGGN5Ez", "user": {"username": "Sean Osier"}}]