[{"_id": "7Laeo8efB2aBEuo6v", "postedAt": "2023-05-15T03:06:58.824Z", "postId": "ayWPwLRjxecTLEDkN", "htmlBody": "<p>A more pessimistic counterargument: Safely developing AGI is so hard as to be practically impossible. I do not believe this one, but some pessimistic sectors within AIS do. &nbsp;It combines well with the last counterargument you list (that the timelines where things turn out OK are all ones where we stop / radically slow down the development of AI capabilities). If you are confident that aligning AGI is for all practical purposes impossible, then you focus on preventing the creation of AGI and on improving the future of the timelines where AGI has been successfully avoided.</p>", "parentCommentId": null, "user": {"username": "Milan Weibel"}}, {"_id": "o9br6kePjbf8ajv9y", "postedAt": "2023-05-15T03:09:57.994Z", "postId": "ayWPwLRjxecTLEDkN", "htmlBody": "<p>Side note: calling a world modelling disagreement implied by differences in cause prioritisation a \"schism\" is in my opinion unwarranted and (low-probability, very negative value) risks becoming a self-fulfilling prophecy.</p>", "parentCommentId": null, "user": {"username": "Milan Weibel"}}, {"_id": "jBwaoc5XqkgPyCeNy", "postedAt": "2023-05-15T03:10:30.472Z", "postId": "ayWPwLRjxecTLEDkN", "htmlBody": "<p>Agreed! I think Geoffrey Miller makes this point rather excellently here:</p>\n<p><a href=\"https://forum.effectivealtruism.org/posts/5LNxeWFdoynvgZeik/nobody-s-on-the-ball-on-agi-alignment?commentId=KSaZ2NguEF8w93FhX#KSaZ2NguEF8w93FhX\">https://forum.effectivealtruism.org/posts/5LNxeWFdoynvgZeik/nobody-s-on-the-ball-on-agi-alignment?commentId=KSaZ2NguEF8w93FhX#KSaZ2NguEF8w93FhX</a></p>\n", "parentCommentId": "7Laeo8efB2aBEuo6v", "user": {"username": "Phib"}}, {"_id": "GWJo7Rmnfd2bXNNEf", "postedAt": "2023-05-15T03:13:52.734Z", "postId": "ayWPwLRjxecTLEDkN", "htmlBody": "<p>I think this is a fair point, thanks for making it. And I certainly overgeneralize at times here, where I believe I\u2019ve experienced moments that indicate such a schism, but also not enough to just label it as such in a public post. Idk!</p>\n", "parentCommentId": "o9br6kePjbf8ajv9y", "user": {"username": "Phib"}}, {"_id": "NSGuEqHXkYXzFF5SB", "postedAt": "2023-05-15T15:13:25.295Z", "postId": "ayWPwLRjxecTLEDkN", "htmlBody": "<p>Just for the sake of clarity: I think the word \"schism\" is inaccurate here because it carries false connotations of conflict.</p>", "parentCommentId": "o9br6kePjbf8ajv9y", "user": {"username": "Milan Weibel"}}, {"_id": "9BHGtQBHBDoLiPLuQ", "postedAt": "2023-06-19T04:00:09.596Z", "postId": "ayWPwLRjxecTLEDkN", "htmlBody": "<p>FWIW I think this post: <a href=\"https://forum.effectivealtruism.org/posts/J4cLuxvAwnKNQxwxj/how-does-ai-progress-affect-other-ea-cause-areas\">https://forum.effectivealtruism.org/posts/J4cLuxvAwnKNQxwxj/how-does-ai-progress-affect-other-ea-cause-areas</a></p>\n<p>Is a way better version of what I was trying to get at here, and MacAskill's answer is pretty good.</p>\n", "parentCommentId": null, "user": {"username": "Phib"}}]