[{"_id": "c5EoMhLhxA44dFMAe", "postedAt": "2023-10-07T11:19:26.871Z", "postId": "C5X3XbHQkj5d8EeXg", "htmlBody": "<p>Overall I think this post was well done and introduces valuable approaches, especially the focus on social engineering and the limits of psychometric data collection available to most firms, but generally a lot of different and valuable topics which I expect to be unfamiliar to most readers. Have you thought about cross posting this to Lesswrong, where users are friendlier to AI safety?&nbsp;</p><p>Something that's worth keeping in mind is that, although base rates of this seem low relative to employee incompetence, it's also true that a sufficiently sophisticated adversary will be highly capable of framing specific employees for the attack. This is important for AI labs, which will be noticed by unusually powerful adversaries, and yet nonetheless must get everything right. They should expect their top-performing security staff to start getting bumped off one by one, the same way they would expect that to happen to leadership.</p><blockquote><p><u>Train employees on personal cybersecurity</u> (securing smart home devices, managing logins, financial scams, etc.).</p></blockquote><p>Securing smart home devices isn't possible, not for anyone in or adjacent to EA anyway. The idea that you can make smart devices themselves safe is ludicrous and dangerous; unless by \"securing smart home devices\" you meant mitigating personal exposure to them, which I absolutely agree would reduce risk. The threat of smart home devices creating massive psychometric datasets and researching social engineering with sample sizes in the millions is a security nightmare, that every developed country has gotten entangled in; just because everyone's doing it doesn't make it sensible or reasonable, just like religion or meat consumption. The current paradigm of constant smart device exposure is already wildly inadequate for the basic infosec that AI labs currently require, let alone for the transformative slow takeoff world that many anticipate over the next 1-2 decades.</p>", "parentCommentId": null, "user": {"username": "trevorw96"}}, {"_id": "oZLgcMgpFMn9DeaXA", "postedAt": "2023-10-07T13:23:57.827Z", "postId": "C5X3XbHQkj5d8EeXg", "htmlBody": "<p><a href=\"https://forum.effectivealtruism.org/users/trevor1?mention=user\">@trevor1</a> Thank you for the detailed response!</p><p><u>RE: Crossposting to LessWrong</u></p><ul><li>I've <a href=\"https://www.lesswrong.com/posts/htchppMWKQLdg3bz2/fixing-insider-threats-in-the-ai-supply-chain\">crossposted it</a> now. If there are other forums relevant to cybersecurity topics in EA in particular, I'd appreciate suggestions :-)</li></ul><p><u>RE: Personal Cybersecurity and IoT</u></p><ul><li>Yes, I agree that the best way to improve cybersecurity with personal IoT devices is to avoid them. I'll update the wording to be more clear about that.&nbsp;</li></ul>", "parentCommentId": "c5EoMhLhxA44dFMAe", "user": {"username": "madhav-malhotra"}}]