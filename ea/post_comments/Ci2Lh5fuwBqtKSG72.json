[{"_id": "rMZJT4YtMDX9skq96", "postedAt": "2023-06-06T09:19:52.465Z", "postId": "Ci2Lh5fuwBqtKSG72", "htmlBody": "<p>I thought this was a great point.</p><blockquote><p>There is absolutely nothing hypocritical about an AI researcher who is pursuing either research that\u2019s not on the path to AGI or alignment research to be sounding the alarm about the risks of AGI. Consider if we had one word for \u201cenergy researcher\u201d which included all of: a) studying the energy released in chemical reactions, b) developing solar panels, and c) developing methods for fossil fuel extraction. In such a situation, it would not be hypocritical for someone from a) or b) to voice concerns about how c) was leading to climate change \u2014 even though they would be an \u201cenergy researcher\u201d expressing concerns about \u201cenergy research.\u201d</p></blockquote><p>Probably the majority of \"AI researchers\" are in this position. It's an extremely broad field. Someone can come up with a new probabilistic programming language for Bayesian statistics, or prove some abstruse separation of two classes of MDPs, and wind up publishing at the same conference as the people trying to hook up a giant LLM to real-world actuators.</p>", "parentCommentId": null, "user": {"username": "anonymous6"}}, {"_id": "2zHzzvwhgDue9X9X9", "postedAt": "2023-06-06T09:23:32.351Z", "postId": "Ci2Lh5fuwBqtKSG72", "htmlBody": "<p>Thank you! Yeah, I agree that point applies to most AI researchers.</p>", "parentCommentId": "rMZJT4YtMDX9skq96", "user": {"username": "Daniel_Eth"}}, {"_id": "eHQbfhKyZvyjsXexW", "postedAt": "2023-06-06T17:22:47.917Z", "postId": "Ci2Lh5fuwBqtKSG72", "htmlBody": "<p>What's crucial here is your point #7 ('Belief that AGI is worth it, even if it causes human extinction').</p><p>A significant minority of AI researchers simply aren't worried about 'extinction risks' because they believe human extinction (in favor of AI flourishing) is actually a benefit rather than a cost. They are pushing full steam ahead for the end of our species and our civilization. As long as we leave behind a rich ecosystem of digital intelligences, they simply don't care about humanity. (Or, their misanthropic contempt for humanity's 'cognitive biases' and 'faulty emotional hardwiring' leads them to actively wish for our extinction.)</p><p>The general public urgently needs to understand this pro-extinction mind-set, because it represents a set of values that are <i>extremely</i> divergent from what most ordinary people hold. Ordinary people want their children, grand-children, and descendants to live and flourish and be happy. They want their culture, civilization, and values to persist. They want the future to be an intelligible continuation of the present.&nbsp;</p><p>Many AI researchers explicitly do not want any of this. They don't care about their biological descendants, only their digital creation. They don't care about the continuity of their civilization. They embrace the total genocide of humanity in favor of Artificial Superintelligence, or the Singularity, or whatever quasi-religious gloss they put on their apocalyptic utopianism.&nbsp;</p><p>The more we enlighten the public about the views of these pro-AI, anti-human extremists, the more likely we are to get an effective <a href=\"https://forum.effectivealtruism.org/posts/veR4W92bZsTsGgS3D/a-moral-backlash-against-ai-will-probably-slow-down-agi\">anti-AI moral backlash</a>.</p>", "parentCommentId": null, "user": {"username": "geoffreymiller"}}, {"_id": "LcbouySy4GbrdGk4J", "postedAt": "2023-06-06T17:35:05.687Z", "postId": "Ci2Lh5fuwBqtKSG72", "htmlBody": "<p>Do you have a source for the claim that a significant minority think AI is worth it even if it kills us? (Not mean in an accusatory way.)&nbsp;</p>", "parentCommentId": "eHQbfhKyZvyjsXexW", "user": {"username": "Dr. David Mathers"}}, {"_id": "dfnLzS8snP3F7K8gF", "postedAt": "2023-06-06T17:45:02.173Z", "postId": "Ci2Lh5fuwBqtKSG72", "htmlBody": "<p>Well Daniel_Eth mentions a few examples in his Medium post; I've encountered lots of these 'e/acc' people on Twitter who actively crave human extinction and replacement by machine intelligences.&nbsp;</p>", "parentCommentId": "LcbouySy4GbrdGk4J", "user": {"username": "geoffreymiller"}}, {"_id": "muFedJEZx7GR8pjgG", "postedAt": "2023-06-06T18:48:36.868Z", "postId": "Ci2Lh5fuwBqtKSG72", "htmlBody": "<p>Adding support to Geoffrey's perspective here. Originally I thought it was just twitter shitposting, but some people in the 'e/acc' sphere seem to honestly be pro-extinction. I still hope it's just satirical roleplay mocking AI doom, but I've found it quite unnevering.</p><p>I think it's interesting that in Senate hearing in May, Senator Kennedy (R-LA) said the following <i>\"I would like you to assume there is likely a berserk wing of the artificial intelligence community that intentionally or unintentionally could use artificial intelligence to kill all of us and hurt us the entire time that we are dying.\" </i>which might be a co-oincidence, might be talking about terrorist threats, but still it couldn't help but ring a bell for me.</p>", "parentCommentId": "dfnLzS8snP3F7K8gF", "user": {"username": "JWS"}}]