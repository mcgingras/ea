[{"_id": "3jXgZXhkaeRzNBjEq", "postedAt": "2023-09-30T23:15:00.965Z", "postId": "BjgE7EpCKodQ3nAyp", "htmlBody": "<p>As someone who falls into the category of the student who would receive the same template talk I really appreciate you writing this up!</p>\n", "parentCommentId": null, "user": {"username": "Tym"}}, {"_id": "ydzzuYtPQ64LYETK8", "postedAt": "2023-10-04T19:08:15.264Z", "postId": "BjgE7EpCKodQ3nAyp", "htmlBody": "<p>Thank you. This is very helpful. Do you have any advice for getting into policy from a mathematical background? I have just completed my uderraduate degree in mathematics but think I am a good fit for policy work and research. any advice?</p>", "parentCommentId": null, "user": {"username": "joehindley"}}, {"_id": "LBczmxJyHJwHburaK", "postedAt": "2023-10-04T20:58:44.739Z", "postId": "BjgE7EpCKodQ3nAyp", "htmlBody": "<p>I did my bsc. in computer science so it's possible!&nbsp;<br><br>I joined a political party in my country, and started applying for jobs and internships. What got me my first was cold emailing the members of the European Parliament in my party, they put a good word in among the dozens of other people who applied through the official forms.</p>", "parentCommentId": "ydzzuYtPQ64LYETK8", "user": {"username": "MathiasKirkBonde"}}, {"_id": "Jz3AFfZgZoFh7BjaM", "postedAt": "2023-10-05T18:36:59.035Z", "postId": "BjgE7EpCKodQ3nAyp", "htmlBody": "<p>Thanks!&nbsp;</p><p>Are there any skills that you gained from your CS degree that you think have put you at an advantage in the policy sphere?</p>", "parentCommentId": "LBczmxJyHJwHburaK", "user": {"username": "joehindley"}}, {"_id": "Hr25zYuKNAopZ6RBH", "postedAt": "2023-10-06T15:38:12.183Z", "postId": "BjgE7EpCKodQ3nAyp", "htmlBody": "<p>I'm curating this post \u2014 I really like how it was short and focused on very concrete actions that could be done in one weekend.</p>", "parentCommentId": null, "user": {"username": "jpaddison"}}, {"_id": "3ZFLpfpNeCPoHnWBi", "postedAt": "2023-10-06T16:26:05.659Z", "postId": "BjgE7EpCKodQ3nAyp", "htmlBody": "<p>Is it just me or is the map image link broken?</p>", "parentCommentId": null, "user": {"username": "lukasj10"}}, {"_id": "C4AriKsPz2WQpuvsz", "postedAt": "2023-10-06T16:59:00.183Z", "postId": "BjgE7EpCKodQ3nAyp", "htmlBody": "<p>bugged out for me too, showed up when I tried editing the post, so just republished without any changes. seems to have fixed it</p>", "parentCommentId": "3ZFLpfpNeCPoHnWBi", "user": {"username": "MathiasKirkBonde"}}, {"_id": "gouSeKFGv9QGvyjpK", "postedAt": "2023-10-06T18:26:45.421Z", "postId": "BjgE7EpCKodQ3nAyp", "htmlBody": "<p>One thing I appreciate about both of these tests is that they seem to (at least partially) tap into something like \"can you think for yourself &amp; reason about problems in a critical way?\" I think this is one of the most important skills to train, particularly in policy, where it's very easy to get carried away with narratives that seem popular or trendy or high-status.</p><p>I think the current zeitgeist has gotten a lot of folks interested in AI policy. My sense is that there's a lot of potential for good here, but there are also some pretty easy ways for things to go wrong.</p><p>Examples of some questions that I hear folks often ask/say:</p><ul><li>What do the experts think about X?</li><li>How do I get a job at X org?</li><li>\"I think the work of X is great\"--&gt; \"What about their work do you like?\" --&gt; \"Oh, idk, just like in general they seem to be doing great things and lots of others seem to support X.\"</li><li>What would ARC evals think about this plan?</li></ul><p>Examples of some questions that I often encourage people to ask/say:</p><ul><li>What do you think about X?</li><li>What do you think X is getting wrong?</li><li>If the community is wrong about X, what do you think it's getting wrong? Do you think we could be doing better than X?</li><li>What do I think about this plan?</li></ul><p>So far, my experience engaging with AI governance/policy folks is that these questions are not being asked very often. It feels more like a field where people are respected for \"looking legitimate\" as opposed to \"having takes\". Obviously, there are exceptions, and there are a few people whose work I admire &amp; appreciate.</p><p>But I think a lot of junior people (and some senior people) are pretty comfortable with taking positions like \"I'm just going to defer to people who other people think are smart/legitimate, without really asking myself or others to explain why they think those people are smart/legitimate\", and this is very concerning.</p><p>As a caveat, it is of course important to have people who can play support roles and move things forward, and there's a failure mode of spending too much time in \"inside view\" mode. My thesis here is simply that, on the current margin, I think the world would be better off if more people shifted toward \"my job is to understand what is right and evaluate plans/people for myself\" and fewer people adopted the \"my job is to find a credible EA leader and row in the direction that they're currently rowing.\"&nbsp;</p><p>And as a final point, I think this is especially important in a context where there is a major resource/power/status imbalance between various perspectives. In the absence of critical thinking &amp; strong epistemics, we should not be surprised if the people with the most money &amp; influence end up shaping the narrative. (This model necessarily mean that they're wrong, but it does tell us something like \"you might expect to see a lot of EAs rally around narratives that are sympathetic toward major AGI labs, even if these narratives are wrong. And it would take a particularly strong epistemic environment to converge to the truth when one \"side\" has billions of dollars and is offering a bunch of the jobs and is generally considered cooler/higher-status.\"</p>", "parentCommentId": null, "user": {"username": "Akash"}}, {"_id": "Rcuvci2uKPbHESbCk", "postedAt": "2023-10-09T22:50:35.476Z", "postId": "BjgE7EpCKodQ3nAyp", "htmlBody": "<p>I worry people will wrongly think they are not a good fit after these exercises.\nRegulatory texts such as the AI act are written in complicated language and their logic is hard to understand. It takes time. For everyone. Even hearing refer to a lot of context that needs time to get used to. So please don't think \"oh I'm too stupid for this.\"</p>\n", "parentCommentId": null, "user": {"username": "fjcl"}}, {"_id": "bFEhXffJunhXxh57P", "postedAt": "2023-10-11T16:58:07.911Z", "postId": "BjgE7EpCKodQ3nAyp", "htmlBody": "<p>That's right, I imagine that for those with a technical background, reading legislation may not be intuitive. However, one can consider looking for simplified explanations or supplementary materials. These can provide a foundation for understanding the key principles, which are enough to understand their underlying assumptions and, consequently, allow for their evaluation.</p>", "parentCommentId": "Rcuvci2uKPbHESbCk", "user": {"username": "Daniel_Polak"}}]