[{"_id": "tkZXj5DDyABsg5pXq", "postedAt": "2017-11-24T21:28:01.583Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>Thanks for writing this.  I think the problem of cluelessness has not received as much attention as it should.</p>\n<p>I\u2019d add that, in addition to the brute good and x-risks approaches, there are approaches which attempt to reduce the likelihood of dystopian long-run scenarios.  These include suffering-focused AI safety and values-spreading.  Cluelessness may still plague these approaches, but one might argue that they are more robust to both empirical and moral uncertainty. </p>\n", "parentCommentId": null, "user": {"username": "JesseClifton"}}, {"_id": "48TkChuK5aY4p2NZH", "postedAt": "2017-11-25T21:21:42.616Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>I'd be curious how much you think previous attempts at calculating multiple impacts address cluelessness, such as <a href=\"http://effective-altruism.com/ea/1h6/causal_networks_model_i_introduction_user_guide/\">Causal Networks Model</a>, saving lives in the present generation and reducing X risk for <a href=\"http://effective-altruism.com/ea/1g9/should_we_be_spending_no_less_on_alternate_foods/\">AI and alternate foods</a>, and <a href=\"http://effective-altruism.com/ea/xr/a_complete_quantitative_model_for_cause_selection/\">cause area comparison</a>.</p>\n", "parentCommentId": null, "user": {"username": "Denkenberger"}}, {"_id": "ukrfmLXmPp6dASZFr", "postedAt": "2017-11-26T08:49:35.270Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p><a href=\"http://effective-altruism.com/ea/18h/link_crucial_considerations_and_wise_philanthropy/\">Another attempt</a>.</p>\n", "parentCommentId": "48TkChuK5aY4p2NZH", "user": {"username": "John_Maxwell_IV"}}, {"_id": "ridGTs8oDyfpZDGQE", "postedAt": "2017-11-28T06:10:14.133Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>It's worth noting that long-run consequences doesn't necessarily imply just looking at x-risks. A fully fleshed out long-run evaluation looks at many factors of civilization quality and safety, and I think it is good enough to dominate other considerations. It's certainly better than allowing mere x-risk concerns to dominate. </p>\n<blockquote>\n<p>But this objection only highlights the difficulty presented by cluelessness. In a very literal sense, a physician in this position is clueless about what action would be best. </p>\n</blockquote>\n<p>I don't think this is true. Killing a random baby on the off chance that it might become a dictator is a bad idea. You can do the math on that if you want, or just trust me that the expected consequences of it are hurtful to society.</p>\n", "parentCommentId": null, "user": {"username": "kbog"}}, {"_id": "jAJt85ZdudgeeMNmy", "postedAt": "2017-11-28T21:12:53.934Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<blockquote>\n<p>A potential objection here is that the Austrian physician could in no way have foreseen that the infant they were called to tend to would later become a terrible dictator, so the physician should have done what seemed best given the information they could uncover. But this objection only highlights the difficulty presented by cluelessness. In a very literal sense, a physician in this position is clueless about what action would be best. Assessing only proximate consequences would provide some guidance about what action to take, but this guidance would not necessarily point to the action with the best consequences in the long run.</p>\n</blockquote>\n<p>I think this example undermines, rather than supports, your point. Of course <em>it's possible</em> the baby would have grown up to be Hitler. It's also <em>possible</em> the baby would have grown up to be a great scientist. Hence, from the perspective of the doctor, who is presumably working on expected value and has no reason to think one special case is more likely than the other, these presumably just do cancel out. Hence the doctors looks the obvious causes. This seems like a case of what Greaves calls simple cluelessness.</p>\n<p>A couple of general comments. There is already an academic literature of cluelessness and it's known to some EAs. It would be helpful therefore if you make it clear what you're doing that's novel. I don't mean this in a disparaging way. I simply can't tell if you're disagreeing with Greaves et al. or not. If you are, that's potentially very interesting and I want to know what the disagreement exactly is so I can assess it and see if I want to take your side. If you're not presenting a new line of thought, but just summarising or restating what others have said (perhaps in an effort to bring this information to new audiences, or just for your own benefit) you should say that instead so that people can better decided how closely to read it.</p>\n<p>Additionally, I think it's unhelpful to (re)invent new terminology without a good reason. I can't tell the clear different between proximate, indirect and long-run consequences. I would much have preferred it if you'd explained cluelueness using Greaves' set up and then progressed from there as appropriate.</p>\n", "parentCommentId": null, "user": {"username": "MichaelPlant"}}, {"_id": "t7H7KsrHQA8FE8XqJ", "postedAt": "2017-11-29T04:08:29.043Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>Thanks for the thoughtful comment :-)</p>\n<blockquote>\n<p>This seems like a case of what Greaves calls simple cluelessness.</p>\n</blockquote>\n<p>I'm fuzzy on Greaves' distinction between simple &amp; complex cluelessness. Greaves uses the notion of &quot;systematic tendency&quot; to draw out complex cluelessness from simple, but &quot;This talk of \u2018having some reasons\u2019 and \u2018systematic tendencies\u2019 is not as precise as one would like;&quot; (from p. 9 of <a href=\"https://flightfromperfection.com/files/post_attachments/cluelessness_greaves_2016.pdf\">Greaves 2016</a>). </p>\n<p>Perhaps it comes down to symmetry. When we notice that for every imagined consequence, there is an equal &amp; opposite consequence that feels about as likely, we can consider our cluelessness &quot;simple.&quot; But when we can't do this, our cluelessness is complex.</p>\n<p>This criterion is unsatisfyingly subjective though, because it relies on our assessing the equal-opposite consequence as &quot;about as likely,&quot; plus relying on whether we are able to imagine an equal-opposite consequence or not.</p>\n", "parentCommentId": "jAJt85ZdudgeeMNmy", "user": {"username": "Milan_Griffes"}}, {"_id": "ozQrEQyFLaaSCn4oE", "postedAt": "2017-11-29T04:16:26.258Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<blockquote>\n<p>There is already an academic literature of cluelessness and it's known to some EAs. It would be helpful therefore if you make it clear what you're doing that's novel ...</p>\n</blockquote>\n<p>Do you know of worthwhile work on this beyond Greaves 2016? (Please point me to it, if you do!) </p>\n<p><a href=\"https://flightfromperfection.com/files/post_attachments/cluelessness_greaves_2016.pdf\">Greaves 2016</a> is the most useful academic work I've come across on this question; I was convinced by their arguments against Lenman 2000.</p>\n<p>I stated my goal at the top of the piece.</p>\n<blockquote>\n<p>I would much have preferred it if you'd explained cluelueness using Greaves' set up and then progressed from there as appropriate.</p>\n</blockquote>\n<p>I don't think Greaves presented an analogous terminology? </p>\n<p>&quot;Flow-through effects&quot; &amp; &quot;knock-on effects&quot; have been used previously, but they don't distinguish between temporally near &amp; temporally distant effects. That distinction seems interesting, so I decided to not those terms.</p>\n", "parentCommentId": "jAJt85ZdudgeeMNmy", "user": {"username": "Milan_Griffes"}}, {"_id": "bpB88qgDFa3KnJnj8", "postedAt": "2017-11-29T04:19:43.585Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>Good point, I was implicitly considering s-risks as a subset of x-risks.</p>\n", "parentCommentId": "tkZXj5DDyABsg5pXq", "user": {"username": "Milan_Griffes"}}, {"_id": "bvEj9yRdtCAwyufTm", "postedAt": "2017-11-29T04:24:05.115Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>Intuitively, I completely agree that killing a random baby is socially harmful.</p>\n<p>The example is interesting because it's tricky to &quot;do the math&quot; on. (Hard to arrive at a believable long-run cost of a totalitarian dictatorship; hard to arrive at a believable long-run cost of instituting a social norm of infanticide.)</p>\n", "parentCommentId": "ridGTs8oDyfpZDGQE", "user": {"username": "Milan_Griffes"}}, {"_id": "mDSLYEbdqEavMJEFb", "postedAt": "2018-01-02T13:48:26.350Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>I take Greaves' distinction between simple and complex cluelessness to be in the symmetry (just as you seem to do). However, I believe that this symmetry consists in that we are evaluating the same consequences following from either an act A, or a refraining of act A. For every story of long-term consequences happening from performing act A, there is a parallel story of these consequences C happening from refraining to do A. Thus, we can invoke a specific Principle of Indifference, where we take the probabilities of the options to be equal, reflecting our ignorance. Thus, P(C|A) = P(C|~A), where C is a story of some long-term consequences of either performing or refraining from doing A.</p>\n<p>In complex cases, this symmetry does not exist, because we're trying to compare different consequences (C1, C2, .., Cn) resulting from the same act.</p>\n", "parentCommentId": "t7H7KsrHQA8FE8XqJ", "user": {"username": "SiebeRozendal"}}, {"_id": "KLAZvRpKZWaP9apw6", "postedAt": "2019-03-12T15:55:52.400Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<blockquote>in reality the bulk of an intervention\u2019s impact is composed of indirect &amp; long-run effects which are difficult to observe and difficult to estimate.</blockquote><p>Robin Hanson has <a href=\"https://www.overcomingbias.com/2014/02/dust-in-the-wind.html\">some</a> <a href=\"https://www.overcomingbias.com/2018/10/long-legacies-and-fights-in-an-uncaring-universe.html\">posts</a> which are skeptical.  I think there&#x27;s probably a power law distribution of impact on the far future, and most actions are relatively unimpactful.  You could argue that the scale of the universe is big enough in time &amp; space that even a small relative impact on the far future will be large in absolute terms.  But to compromise with near future focused value systems, maybe we should still be focused on near-term effects of interventions which seem relatively unimpactful in the long run.</p><p>BTW, your typology neglects work to prevent s-risks.</p>", "parentCommentId": null, "user": {"username": "John_Maxwell_IV"}}, {"_id": "ozyFztLGn5kT6haWR", "postedAt": "2019-03-30T08:15:18.538Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<blockquote>But to compromise with near future focused value systems, maybe we should still be focused on near-term effects of interventions which seem relatively unimpactful in the long run.</blockquote><p>I&#x27;m not sure what meta-ethical framework we would use to broker such a compromise. Perhaps some kind of <a href=\"http://www.overcomingbias.com/2009/01/moral-uncertainty-towards-a-solution.html\">moral congress</a> (<a href=\"https://web.archive.org/web/20190110164526/http://www.overcomingbias.com/2009/01/moral-uncertainty-towards-a-solution.html\">a</a>)?</p><p>I haven&#x27;t yet figured out how to allot the proportions of such a congress in a way that feels principled. Do you know of any work on this?</p>", "parentCommentId": "KLAZvRpKZWaP9apw6", "user": {"username": "Milan_Griffes"}}, {"_id": "AsiwaGuRsva5w6rHX", "postedAt": "2019-03-30T08:16:11.737Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<blockquote>BTW, your typology neglects work to prevent s-risks.</blockquote><p>Good point; for the purposes of the argument they could be grouped with x-risks.</p>", "parentCommentId": "KLAZvRpKZWaP9apw6", "user": {"username": "Milan_Griffes"}}, {"_id": "KeiDDCRDgMoWXhTsi", "postedAt": "2019-03-30T08:18:30.469Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<blockquote>Robin Hanson has <a href=\"https://www.overcomingbias.com/2014/02/dust-in-the-wind.html\">some</a> <a href=\"https://www.overcomingbias.com/2018/10/long-legacies-and-fights-in-an-uncaring-universe.html\">posts</a> which are skeptical. I think there&#x27;s probably a power law distribution of impact on the far future, and most actions are relatively unimpactful.</blockquote><p>Thanks for the pointers to Hanson on this!</p><p>Agreed, and I think part of the trouble is that it&#x27;s very hard to tell prospectively whether an action is going to have a large impact on the far future.</p>", "parentCommentId": "KLAZvRpKZWaP9apw6", "user": {"username": "Milan_Griffes"}}, {"_id": "9z2H3unCCpw44b2PL", "postedAt": "2019-03-30T08:25:13.155Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>(Sorry I never replied to this!)</p><p>I&#x27;m generally skeptical of our ability to model far future outcomes quantitatively, given our present level of information. I haven&#x27;t thought particularly carefully about the specific examples you link to, though.</p><p></p>", "parentCommentId": "48TkChuK5aY4p2NZH", "user": {"username": "Milan_Griffes"}}, {"_id": "yEBNTf9jX63xBxhB7", "postedAt": "2019-03-30T08:40:39.085Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<blockquote>I haven&#x27;t yet figured out how to allot the proportions of such a congress in a way that feels principled. Do you know of any work on this?</blockquote><p>Not offhand, but I would probably use some kind of Bayesian approach.</p>", "parentCommentId": "ozyFztLGn5kT6haWR", "user": {"username": "John_Maxwell_IV"}}, {"_id": "LB4K95gQLWhdKfSkH", "postedAt": "2019-03-30T08:45:10.007Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<blockquote>I think part of the trouble is that it&#x27;s very hard to tell prospectively whether an action is going to have a large impact on the far future.</blockquote><p>I&#x27;m not convinced of that.</p>", "parentCommentId": "KeiDDCRDgMoWXhTsi", "user": {"username": "John_Maxwell_IV"}}, {"_id": "4qyecdienKX95aiHC", "postedAt": "2019-03-30T09:19:11.040Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>Do you have examples of heuristics you use to prospectively assess whether an action is going to have a large impact on the far future?</p>", "parentCommentId": "LB4K95gQLWhdKfSkH", "user": {"username": "Milan_Griffes"}}, {"_id": "q8Mgq4nWqGj3Rk3CJ", "postedAt": "2019-03-30T09:19:54.540Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>See <a href=\"https://forum.effectivealtruism.org/posts/MWquqEMMZ4WXCrsug/just-take-the-expected-value-a-possible-reply-to-concerns#Pb9nXf859sEi5vDHj\">toy dialogue</a>.</p>", "parentCommentId": "yEBNTf9jX63xBxhB7", "user": {"username": "Milan_Griffes"}}, {"_id": "cn8qwZqjhJ3LjErCb", "postedAt": "2019-03-31T20:43:02.174Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>Is it similar to the sort of actions I believe have had a large impact on the future in the past?</p>", "parentCommentId": "4qyecdienKX95aiHC", "user": {"username": "John_Maxwell_IV"}}, {"_id": "FrmCrgyo9myKpZZ6B", "postedAt": "2019-03-31T21:38:22.471Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>Got it. Is there an easy-to-articulate description of how you build the set of past actions that you believe had a large impact on the future?</p>", "parentCommentId": "cn8qwZqjhJ3LjErCb", "user": {"username": "Milan_Griffes"}}, {"_id": "gfTkHjrvLoKEtq7Qz", "postedAt": "2019-03-31T22:50:20.643Z", "postId": "LPMtTvfZvhZqy25Jw", "htmlBody": "<p>Use what I&#x27;ve read about history to try &amp; think of historical events I think were pivotal which share important similarities with the action in question, and also try to estimate the base rate of historical people taking actions similar to the action in question in order to have an estimate for the denominator.</p><p>If I was trying to improve my ability in this area, I might read books by Peter Turchin, <a href=\"https://www.lesswrong.com/posts/Lta4N7r2wSn9GnhW8/sapiens\">Yuval Noah Harari</a>, <a href=\"https://smile.amazon.com/Square-Tower-Networks-Freemasons-Facebook/dp/0735222916\">Niall</a> <a href=\"https://smile.amazon.com/Square-Tower-Networks-Freemasons-Facebook/dp/0735222916\">Ferguson</a>, <a href=\"https://sivers.org/book/LessonsOfHistory\">Will and Ariel Durant</a>, and people working on <a href=\"https://en.wikipedia.org/wiki/Big_History\">Big</a> <a href=\"https://www.coursera.org/learn/big-history\">History</a>.  Maybe <a href=\"https://smile.amazon.com/Fifty-Inventions-Shaped-Modern-Economy/dp/0735216134\">this book</a> too.  Some EA-adjacent discussion of this topic: <a href=\"https://forum.effectivealtruism.org/posts/n8nXqqgbwp58wuo6a/how-fragile-was-history\">1</a>, <a href=\"https://www.lesswrong.com/users/samo-burja\">2</a>, <a href=\"http://lukemuehlhauser.com/three-wild-speculations-from-amateur-quantitative-macrohistory/\">3</a>, <a href=\"https://www.facebook.com/li.van.nostrand/posts/10104756951303255\">4</a>.</p>", "parentCommentId": "FrmCrgyo9myKpZZ6B", "user": {"username": "John_Maxwell_IV"}}]