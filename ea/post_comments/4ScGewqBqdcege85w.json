[{"_id": "Mcxv5WxobxZanYBeS", "postedAt": "2017-12-19T19:58:14.219Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>Thanks for the update, much appreciated.</p>\n<p>I only have a question in one area: could you say a bit more about how the individual outreach team will find people and how it might try to help them? Maybe I'm misreading this, but there's something worryingly mysterious and opaque about there being someone in CEA who reaches out to 'pick winners' (in comparison to, say, having a transparent, formal application process for grants which seems unobjectionable).</p>\n<p>One worry (which I'm perhaps overstating) is this might lead to accidental social/intellectual conformism because people start to watch what they do/say in the hope of the word getting out and them getting 'picked' for special prizes.</p>\n", "parentCommentId": null, "user": {"username": "MichaelPlant"}}, {"_id": "fbZopqJzwobRBcsgF", "postedAt": "2017-12-19T20:14:04.832Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>That is an excellent update. The strategic directions broadly make sense to me for all of the teams, and I, like many people, am really happy with the ways CEA has improved over the last year.</p>\n<p>One item of feedback on the post: the description of mistakes is a bit long, boring, and over-the-top. Many of these things are not actually very important issues.</p>\n<p>One suggestion re the EA Forum revamp: the lesserwrong.com site is looking pretty great these days. My main gripes --- things like the front being slightly small for my preferences --- could be easily fixed with some restyling. Some of their features, like including sequences of archived material, could also be ideal for the EA Forum use case. IDK whether the codebase is good but recall that the EA Forum was originally created by restyling LessWrong1, so the notion of stealing that code comes from a healthy tradition! Also, This last part is probably a bit too crazy (and too much work), but one can imagine a case where you post content (and accept comments) from both sites at once. </p>\n<p>That aside, it's really appreciated that you guys have taken the forum over this year. And in general, it's great to see all of this progress, so here's to 2018!</p>\n", "parentCommentId": null, "user": {"username": "RyanCarey"}}, {"_id": "4oeC5cAfN49hhXmAY", "postedAt": "2017-12-19T20:21:11.597Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>Yeah, we have talked to the LW 2.0 team a bit about the possibility of using their codebase as a starting point or possibly doing some kind of actual integration, but we're still in the speculative phase at this point :)</p>\n", "parentCommentId": "fbZopqJzwobRBcsgF", "user": {"username": "sdspikes"}}, {"_id": "my5n3zf9NAWCE4auy", "postedAt": "2017-12-19T21:20:15.512Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>Good question. I agree that the process for Individual outreach is mysterious and opaque. My feeling is that this is because the approach is quite new, and we don't yet know how we'll select people or how we'll deliver value (although we have some hypotheses).</p>\n<p>That said, there are two answers to this question depending on the timeline we're talking about.</p>\n<p>In the short run, the primary objective is to learn more about what we can do to be helpful. My general heuristic is that we should focus on the people/activity combinations that seem to us to be likely to produce large effects so that we can get some useful results, and then iterate. (I can say more about why I think this is the right approach, if useful).</p>\n<p>In practice, this means that in the short-run we'll work with people that we have more information on and easier access to. This probably means working with people that we meet at events like EA Global, people in our extended professional networks, EA Grants recipients, etc.</p>\n<p>In the future, I'd want something much more systematic to avoid the concerns you've raised and to avoid us being too biased in favor of our preexisting social networks. You might imagine something like 80K coaching where we identify some specific areas where we think we can be helpful and then do broader outreach to people that might fall into those areas. In any case, we'll need to experiment and iterate more before we can design a more systematic process.</p>\n", "parentCommentId": "Mcxv5WxobxZanYBeS", "user": {"username": "Kerry_Vaughan"}}, {"_id": "gqNZfR3YFXMooijjT", "postedAt": "2017-12-20T01:03:22.946Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>I agree both with Ryan's overall evaluation (this is excellent) and that the 'mistakes' section, although laudable in intent, errs slightly too far in the 'self-flagellatory' direction. Some of the mistakes listed either seem appropriate decisions (e.g. &quot;We prioritized X over Y, so we didn't do as much Y as we'd like&quot;), or are the result of reasonable decisions or calculations ex ante which didn't work out. </p>\n<p>I think the main value of publicly recording mistakes is to allow others to learn from them or (if egregious) be the context for a public mea culpa. The line between, &quot;We made our best guess, it turned out wrong, but we're confident we made the right call ex ante&quot; and &quot;Actually, on reflection, we should have acted differently given what we knew at the time&quot; is blurry, as not all decisions can (or should) be taken with laborious care.</p>\n<p>Perhaps crudely categorising mistakes into 'major' and 'minor' given magnitude, how plausibly could have been averted, etc., and putting the former in updates like these but the latter linked to in an appendix might be a good way forward.  </p>\n", "parentCommentId": "fbZopqJzwobRBcsgF", "user": {"username": "Gregory_Lewis"}}, {"_id": "54ujD4C4JvcunN58r", "postedAt": "2017-12-20T08:02:31.484Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>Would love to see LW2.0 become the new code base, but it still undergoing rapid changes at the moment and isn't completely stable.</p>\n", "parentCommentId": "fbZopqJzwobRBcsgF", "user": {"username": "casebash"}}, {"_id": "pQSsNikzMASJ8Pzxr", "postedAt": "2017-12-20T13:44:34.282Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>Sure, although the tech team could presumably just wait six months while they work on other stuff.</p>\n", "parentCommentId": "54ujD4C4JvcunN58r", "user": {"username": "RyanCarey"}}, {"_id": "2KE5zjauLcHrHfqg4", "postedAt": "2017-12-22T14:53:33.312Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>I have a very similar concern to Michael's. In particular it looked like, to me, that participants picked for this were people with whom CEA had an existing relationship. For example picking from CEA's donor base. This means that participants were those that had a very high opportunity cost in moving to direct work (as they were big donors). I expect that this is a suboptimal way of getting people to move into direct work. </p>\n<p>Look forward to seeing:</p>\n<blockquote>\n<p>something much more systematic to avoid the concerns you've raised and to avoid us being too biased in favor of our preexisting social networks</p>\n</blockquote>\n", "parentCommentId": "my5n3zf9NAWCE4auy", "user": {"username": "weeatquince"}}, {"_id": "XoAnegg2rkpBgDDdi", "postedAt": "2017-12-22T15:19:17.075Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>This is fantastic. Thank you for writing up. Whilst reading I jotted down a number of thoughts, comments, questions and concerns.</p>\n<p>.</p>\n<p>ON EA GRANTS</p>\n<p>I am very excited about this and very glad that CEA is doing more of this. How to best move funding to the projects that need it most within the EA community is a really important question that we have yet to solve. I saw a lot of people with some amazing ideas looking to apply for these grants.</p>\n<p>1</p>\n<blockquote>\n<p>&quot;with an anticipated budget of around \u00a32m&quot;</p>\n</blockquote>\n<p>I think it is quite plausible that \u00a32m is too low for the year. Not having enough funding increases the costs to applicants (time spent applying) and you (time spent assessing) relative to the benefits (funding moved), especially if there are applicants above the bar for funding but that you cannot afford to fund.\nAlso I had this thought prior to reading that one of your noted mistakes was &quot;underestimated the number of applications&quot;, it feels like you might still be making this mistake.</p>\n<p>2</p>\n<blockquote>\n<p>&quot;mostly evaluating the merits of the applicants themselves rather than their specific plans&quot;</p>\n</blockquote>\n<p>Interesting decision. Seems reasonable. However I think it does have a risk of reducing diversity and I would be concerned that the applicants would be judged on their ability to hold philosophise in an academic oxford manner etc.</p>\n<p>Best of luck with it</p>\n<p>.</p>\n<p>OTHER THOUGHTS </p>\n<p>3</p>\n<blockquote>\n<p>&quot;encouraging more people to use Try Giving,&quot;</p>\n</blockquote>\n<p>Could CEA comment or provide advise to local group leaders on if they would want local groups to promote the GWWC pledge or the Try Giving pledge or when one might be better than the other? To date the advise seems to have been to as much as possible push the Pledge and not Try Giving </p>\n<p>4</p>\n<blockquote>\n<p>&quot;... is likely to be the best way to help others.&quot;</p>\n</blockquote>\n<p>I do not like the implication that there is a single answer to this question regardless of individual's moral frameworks (utilitarian / non-utilitarian / religious / etc) or skills and background. Where the mission is to have an impact as a &quot;a global community of people...&quot; the research should focus on supporting those people to do what they has the biggest impact given their positions. </p>\n<p>5\nPositives</p>\n<blockquote>\n<p>&quot;Self-sorting: People tend to interact with others who they perceive are similar to themselves&quot;</p>\n</blockquote>\n<p>This is a good thing to have picked up on.</p>\n<blockquote>\n<p>&quot;Community Health&quot;</p>\n</blockquote>\n<p>I am glad this is a team</p>\n<blockquote>\n<p>&quot;CEA\u2019s Mistakes&quot;</p>\n</blockquote>\n<p>I think it is good to have this written up.</p>\n<p>6</p>\n<blockquote>\n<p>&quot;Impact review&quot;</p>\n</blockquote>\n<p>It would have been interesting to see an estimates for costs (time/money) as well as for the outputs of each team.</p>\n<p>.</p>\n<p>WELL DONE FOR 2017. GOOD LUCK FOR 2018!</p>\n", "parentCommentId": null, "user": {"username": "weeatquince"}}, {"_id": "mrHSa5cxnv4XXu84n", "postedAt": "2017-12-22T21:56:55.380Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<blockquote>\n<p>I think it is quite plausible that \u00a32m is too low for the year. Not having enough funding increases the costs to applicants (time spent applying) and you (time spent assessing) relative to the benefits (funding moved), especially if there are applicants above the bar for funding but that you cannot afford to fund. Also I had this thought prior to reading that one of your noted mistakes was &quot;underestimated the number of applications&quot;, it feels like you might still be making this mistake.</p>\n</blockquote>\n<p>I haven\u2019t thought about this much, but a natural strategy is to try to have a budget sufficiently large that you know you\u2019ll definitely be able to fund all the good projects, and then binary search down to the amount that only funds all the good projects.</p>\n", "parentCommentId": "XoAnegg2rkpBgDDdi", "user": {"username": "Ben Pace"}}, {"_id": "3qDgohXoYsdrrEsiP", "postedAt": "2017-12-22T22:00:31.018Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>I\u2019d also be interested to find out what happens if CEA announces they\u2019re budgeting like 5 million for this, and see if there are any good projects that appear when that much money is potentially available in the community. Naturally CEA neednt give it all away.</p>\n<p>(But right now I\u2019d expect most of the best projects are just 1-3 people\u2019s full time salaries for a small team to work together, so each grant being &lt;200k at most.)</p>\n<p>Added: On the margin I\u2019d expect the <em>most</em> useful thing EA Grants could do would be to offer multi-year grants, so people in the community can consider major careeer changes based on what\u2019s most effective rather than what\u2019s most stable.</p>\n", "parentCommentId": "mrHSa5cxnv4XXu84n", "user": {"username": "Ben Pace"}}, {"_id": "i39wXZM6MkKQapRz7", "postedAt": "2017-12-23T18:27:32.005Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>Thanks for writing this.</p>\n<p>On EA Grants:\nWill you allow individuals to fund EA Grants in the future? This could either be letting individuals add to CEA's pot of funding for grants, publishing the rejected grants so that individuals can fund them independently or putting the applications on EA funds.</p>\n<p>On EA Funds:</p>\n<blockquote>\n<p>&quot;Potential expansion of EA Funds on offer and investigation of different models for running and &gt;using funds&quot;</p>\n</blockquote>\n<p>What types of funds and models might this investigation include?</p>\n", "parentCommentId": null, "user": {"username": "callum_calvert"}}, {"_id": "dJWx9HXosnKABkA9p", "postedAt": "2017-12-24T15:38:45.972Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>Just wanted to note that most of our staff are out of the office for the next few days, but will answer when they return!</p>\n", "parentCommentId": "i39wXZM6MkKQapRz7", "user": {"username": "Julia_Wise"}}, {"_id": "fkHfTjfbDKEYeWQSM", "postedAt": "2017-12-26T15:27:41.441Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>I would be also worried. Homophily is of the best predictors of links in social networks, and factors like being member of the same social group, having similar education, opinions, etc. are known to bias selection processes again toward selecting similar people. This risks having the core of the movement be more self encapsulated that it is, which is a shift in bad direction.</p>\n<p>Also I would be worried with 80k hours shifting also more toward individual coaching, there is now a bit overemphasis on &quot;individual&quot; approach and too little on &quot;creating systems&quot;.</p>\n<p>Also it seems lot of this would benefit from knowledge from the fields of &quot;science of success&quot;, general scientometry, network science, etc.  E.g. when I read concepts like &quot;next Peter Singer&quot; or a lot of thinking along the line &quot;most of the value is created by just a few peple&quot;, I'm worried. While such thinking is intuitively appealing, it can be quite superficial. E.g., a toy model: Imagine a landscape with gold scattered in power-law sized deposits. And prospectors, walking randomly, and randomly discovering deposits of gold. What you observe is the value of gold collected by prospectors is also power-law distributed. But obviously the attempts to emulate &quot;the best&quot; or find the &quot;next best&quot; would be futile. It seems open question (worth studying) how much some specific knowledge landscape resembles this model, or how big part of the success is attributable to luck.</p>\n", "parentCommentId": "my5n3zf9NAWCE4auy", "user": {"username": "Jan_Kulveit"}}, {"_id": "baLPxShAGCW3swuXf", "postedAt": "2017-12-26T19:36:07.031Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>That\u2019s a nice toy model, thanks for being so clear :-)</p>\n<p>But it\u2019s definitely wrong. If you look at Bostrom on AI or Einstein on Relativity or Feynman on Quantum Mechanics, you don\u2019t see people who are roughly as competent as their peers, just being lucky in which part of the research space was divvied up and given to them. You tend to see people with rare and useful thinking processes having multiple important insights about their field in succession - getting many thing right that their peers didn\u2019t, not just one as your model would predict (if being right was random luck). Bostrom has looked into half a dozen sci-fi looking areas that others looked to figure out which were important, before concluding with xrisk and AI, and he looked into areas and asked questions that were on nobody\u2019s radar. Feynman made breakthroughs in many different subfields, and his success looked like being very good at fundamentals like being concrete and noticing his confusion. I know less about Einstein, but as I understand it to get to Relativity required a long chain of reasoning that was unclear to his contemporaries. \u201cHow would I design the universe if I were god\u201d was probably not a standard tool that was handed out to many physicists to try.</p>\n<p>You may respond \u201csure, these people came up with lots of good ideas that their contemporaries wouldn\u2019t have, but this was probably due to them using the right heuristics, which you can think of as having been handed out randomly in grad school to all the different researchers, so it still is random just on the level of cognitive processes\u201d. </p>\n<p>To this I\u2019d say that, you\u2019re right, looking at people\u2019s general cognitive processes is really important, but I think I can do much better than random chance in predicting what cognitive processes will produce valuable insights. I\u2019ll point to Superforecasters and Rationality: AI to Zombies as books with many insights into which cognitive processes are more likely to find novel and important truths than others.</p>\n<p>In sum: I think the people who\u2019ve had the most positive impact in history are power law distributed because of their rare and valuable cognitive processes, not just random luck, and that these can be learned from and that can guide my search for people who (in future) will have massive impact. </p>\n", "parentCommentId": "fkHfTjfbDKEYeWQSM", "user": {"username": "Ben Pace"}}, {"_id": "mkATPZxnMGLzgLEGZ", "postedAt": "2017-12-26T23:27:43.680Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>Obviously the toy model is wrong in describing reality: it's one end of the possible spectrum, where you have complete randomness. On the other you have another toy model: results in a field neatly ordered by cognitive difficulty, and the best person at a time picks all the available fruit. My actual claims roughly are</p>\n<ul>\n<li><p>reality is somewhere in between</p>\n</li>\n<li><p>it is field-dependent</p>\n</li>\n<li><p>even in fields more toward the random end, there actually would be differences like different speeds of travel among prospectors</p>\n</li>\n</ul>\n<p>It is quite unclear to me where on this scale the relevant fields are. </p>\n<p>I believe your conclusion, that the power law distribution is all due to the properties of the peoples cognitive processes, and no to the randomness of the field, is not supported by the scientometric data for many research fields.</p>\n<p>Thanks for a good preemptive answer  :) Yes if you are good enough in identifying the &quot;golden&quot; cognitive processes. While it is clear you would be better than random chance, it is very unclear to me how good you would be. *</p>\n<p>I think its worth digging into an example in detail: if you look a at early Einstein, you actually see someone with an unusually developed geometric thinking and the very lucky heuristic of interpreting what the equations say as the actual reality. Famously special relativity transformations were written first by Poincare. &quot;All&quot; what needed to be done was to take it seriously. General relativity is a different story, but at that point Einstein was already famous and possibly one of the few brave enough to attack the problem.</p>\n<p>Continuing with the same example, I would be extremely doubtful if Einstein would be picked by selection process similar to what CEA or 80k hours will be probably running, before he become famous. 2nd grade patent clerk? Unimpressive. Well connected? No. Unusual geometric imagination? I'm not aware of any LessWrong sequence which would lead to picking this as that important :) Lucky heuristic? Pure gold, in hindsight.</p>\n<p>(*) At the end you can take this as an optimization problem depending how good  your superior-cognitive-process selection ability is. Let's have a practical example: You have 1000 applicants. If your selection ability is great enough, you should take  20  for individual support. But maybe its just good, and than you may get better expected utility if you are able to reach 100 potentially great people in workshops. Maybe you are much better than chance, but not really good... than, maybe you should create online course taking in 400 participants.</p>\n", "parentCommentId": "baLPxShAGCW3swuXf", "user": {"username": "Jan_Kulveit"}}, {"_id": "hWzuRKN4d8wr6e4wE", "postedAt": "2017-12-27T00:27:32.501Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>Examples are totally worth digging into! Yeah, I actually find myself surprised and slightly confused by the situation with Einstein, and do make the active predictions that he had <em>some</em> strong connections in physics (e.g. at some point had a really great physics teacher who'd done some research). In general I think Ramanujan-like stories of geniuses appearing from nowhere are not the typical example of great thinkers / people who significantly change the world. If I'm I right I should be able to tell such stories about the others, and in general I do think that great people tend to get networked together, and that the thinking patterns of the greatest people are noticed by other good people before they do their seminal work cf. Bell Labs (Shannon/Feynman/Turing etc), Paypal Mafia (Thiel/Musk/Hoffman/Nosek etc), SL4 (Hanson/Bostrom/Yudkowsky/Legg etc), and maybe the Republic of Letters during the enlightenment? But I do want to spend more time digging into some of those.</p>\n<p>To approach from the other end, what heuristics might I use to find people who in the future will create massive amounts of value that others miss? One example heuristic that Y Combinator uses to determine who in advance is likely to find novel, deep mines of value that others have missed is whether the individuals regularly build things to fix problems in their life (e.g. Zuckerberg built lots of simple online tools to help his fellow students study while at college).</p>\n<p>Some heuristics I use to tell whether I think people are good at figuring out what's true, and make plans for it, include:</p>\n<ul>\n<li>Does the person, in conversation, regularly take long silent pauses to organise their thoughts, find good analogies, analyse your argument, etc? Many people I talk to take silence as a significant cost, due to social awkwardness, and do not make the trade-off toward figuring out what's true. I always trust the people more that I talk to who make these small trade-offs toward truth versus social cost</li>\n<li>Does the person have a history of executing long-term plans that weren't incentivised by their local environment? Did they decide a personal-project (not, like, getting a degree) was worth putting 2 years into, and then put 2 years into it?</li>\n<li>When I ask about a non-standard belief they have, can they give me a straightforward model with a few variables and simple relations, that they use to understand the topic we're discussing? In general, how transparent are their models to themselves, and are the models general simple and backed by lots of little pieces of concrete evidence?</li>\n<li>Are they good at finding genuine insights in the thinking of people who they believe are totally wrong?</li>\n</ul>\n<p>My general thought is that there isn't actually a lot of optimisation process put into this, especially in areas that don't have institutions built around them exactly. For example academia will probably notice you if you're very skilled in one discipline and compete directly in it, but it's very hard to be noticed if you're interdisciplinary (e.g. Robin Hanson's book sitting between neuroscience and economics) or if you're not competing along even just one or two of the dimensions it optimises for (e.g. MIRI researchers don't optimise for publishing basically at all, so when they make big breakthroughs in decision theory and logical induction it doesn't get them much notice from standard academia). So even our best institutions at noticing great thinkers with genuine and valuable insights seem to fail at some of the examples that seem most important. I think there is lots of low hanging fruit I can pick up in terms of figuring out who thinks well and will be able to find and mine deep sources of value.</p>\n<hr />\n<p><strong>Edit</strong>: Removed Bostrom as an example at the end, because I can't figure out whether his success in academia, while nonetheless going through something of a non-standard path, is evidence for or against academia's ability to figure out whose cognitive processes are best at figuring out what's surprising+true+useful. I have the sense that he had to push against the standard incentive gradients a lot, but I might just be false and Bostrom is one of academia's success stories this generation. He doesn't look like he just rose to the top of a well-defined field though, it looks like he kept having to pick which topics were important and then find some route to publishing on them, as opposed to the other way round.</p>\n", "parentCommentId": "mkATPZxnMGLzgLEGZ", "user": {"username": "Ben Pace"}}, {"_id": "5uTac8wDrhwhpduMB", "postedAt": "2017-12-27T02:27:20.064Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>I share your caution on the difficulty of 'picking high impact people well', besides the risk of over-fitting on anecdata we happen to latch on to, the past may simply prove underpowered for forward prediction: I'm not sure any system could reliably 'pick up' Einstein or Ramanujan, and I wonder how much 'thinking tools' etc. are just epiphenomena of IQ.</p>\n<p>That said, fairly boring metrics are fairly predictive. People who do exceptionally well at school tend to do well at university, those who excel at university have a better chance of exceptional professional success, and so on and so forth. SPARC (a program aimed at extraordinarily mathematically able youth) seems a neat example. I accept none of these supply an easy model for 'talent scouting' intra-EA, but they suggest one can do much better than chance.</p>\n<p>Optimal selectivity also depends on the size of boost you give to people, even if they are imperfectly selected. It's plausible this relationship could be convex over the 'one-to-one mentoring to webpage' range, and so you might have to gamble on something intensive even in expectation of you failing to identify most or nearly all of the potentially great people.</p>\n<p>(Aside: Although tricky to put human ability on a cardinal scale, normal-distribution properties for things like working memory suggest cognitive ability (however cashed out) isn't power law distributed. One explanation of how this could drive power-law distributions in some fields would be a Matthew effect: being marginally better than competing scientists lets one take the majority of the great new discoveries. This may suggest more neglected areas, or those where the crucial consideration is whether/when something is discovered, rather than who discovers it (compare a malaria vaccine to an AGI), are those where the premium to really exceptional talent is less. )</p>\n", "parentCommentId": "mkATPZxnMGLzgLEGZ", "user": {"username": "Gregory_Lewis"}}, {"_id": "FueqCNZvGX24dST2K", "postedAt": "2017-12-28T11:58:17.554Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>For scientific publishing, I looked into the latest available paper[1] and apparently the data are best fitted by a model where the impact of scientific papers is predicted by Q.p, where p is &quot;intrinsic value&quot; of the project and Q is a parameter capturing the cognitive ability of the researcher. Notably, Q is independent of the total number of papers written by the scientist, and Q and p are also independent. Translating into the language of digging for gold, the prospectors differ in their speed and ability to extract gold from the deposits (Q). The gold in the deposits actually is randomly distributed. To extract exceptional value, you have to have both high Q and be very lucky.  What is encouraging in selecting the talent is the Q seems relatively stable in the career and can be usefully estimated after ~20 publications. I would guess you can predict even with less data, but the correct &quot;formula&quot; would be trying to disentangle interestingness of the problems the person is working on from the interestingness of the results.  </p>\n<p>(As a side note, I was wrong in guessing this is strongly field-dependent, as the model seems stable across several disciplines, time periods, and many other parameters.)</p>\n<p>Interesting heuristics about people :) </p>\n<p>I agree the problem is somewhat different in areas not that established/institutionalized where you don't have clear dimensions of competition, or the well measurable dimensions are not that well aligned with what is important. Loooks like another understudied area.</p>\n<p>[1] Quantifying the evolution of individual scientific impact, Sinatra et.al. Science,  <a href=\"http://www.sciencesuccess.org/uploads/1/5/5/4/15543620/science_quantifying_aaf5239_sinatra.pdf\">http://www.sciencesuccess.org/uploads/1/5/5/4/15543620/science_quantifying_aaf5239_sinatra.pdf</a></p>\n", "parentCommentId": "hWzuRKN4d8wr6e4wE", "user": {"username": "Jan_Kulveit"}}, {"_id": "SNpXDu6M2M9A6cHge", "postedAt": "2017-12-31T00:26:05.513Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>I copied this exchange to my blog, and there were an additonal bunch of interesting comments <a href=\"https://www.lesserwrong.com/posts/xnbW5iXRRFawgpNee/comments-on-power-law-distribution-of-individual-impact\">there</a>.</p>\n", "parentCommentId": "FueqCNZvGX24dST2K", "user": {"username": "Ben Pace"}}, {"_id": "5GFHBFmEEAaaGeFsf", "postedAt": "2018-01-02T21:52:53.677Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<blockquote>\n<p>Will you allow individuals to fund EA Grants in the future.</p>\n</blockquote>\n<p>We probably won't raise EA Grants money from more than a handful of donors. I think we can secure funding from CEA's existing donor base and the overhead of raising money from multiple funders probably isn't worth the cost.</p>\n<p>That said, there are two related things that we will probably do:</p>\n<ol>\n<li>We'll probably refer some promising projects to other funders. We did this last round for projects that we couldn't fund for legal reasons and for projects where existing funders had more expertise in the project than we did.</li>\n<li>We'll probably send applicants that were close to getting funding but didn't to other funders that might be interested in the project.</li>\n</ol>\n", "parentCommentId": "i39wXZM6MkKQapRz7", "user": {"username": "Kerry_Vaughan"}}, {"_id": "GWN44mdNSfqrndDJG", "postedAt": "2018-01-02T21:58:25.246Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<blockquote>\n<p>I think it is quite plausible that \u00a32m is too low for the year. Not having enough funding increases the costs to applicants (time spent applying) and you (time spent assessing) relative to the benefits (funding moved), especially if there are applicants above the bar for funding but that you cannot afford to fund. Also I had this thought prior to reading that one of your noted mistakes was &quot;underestimated the number of applications&quot;, it feels like you might still be making this mistake.</p>\n</blockquote>\n<p>That's fair. My thinking in choosing \u00a32m was that we would want to fund more projects than we had money to fund last year, but that we would have picked much of the low-hanging fruit, so there'd be less to fund.</p>\n<p>In any case, I'm not taking that number too seriously. We should fund all the projects worth funding and raise more money if we need it.</p>\n", "parentCommentId": "XoAnegg2rkpBgDDdi", "user": {"username": "Kerry_Vaughan"}}, {"_id": "d2JqmkHigeXMRo4tb", "postedAt": "2018-04-04T09:27:30.026Z", "postId": "4ScGewqBqdcege85w", "htmlBody": "<p>This is also worried me because I'm under the impression that, when selecting based on intuition, assessors look for applicants who remind them of themselves (&quot;He's just like me when I was his age!&quot;)\nIf the individual outreach team are similar to the rest of the community, relying on their intuitions could make our diversity problems worse. </p>\n", "parentCommentId": "Mcxv5WxobxZanYBeS", "user": {"username": "Khorton"}}]