[{"_id": "ZQma8TmR6S8GcLbt9", "title": "Epistemic Hell", "postedAt": "2024-01-27T17:17:42.913Z", "htmlBody": "<figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/lgitaxjarxm7jocxi7gc\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/jk3tlpbfnzcul8uzy4ak 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/egr9rgwao3famdrm22ey 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/u8ex7vwbomqjqpblmgyc 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/lgitaxjarxm7jocxi7gc 1456w\"><figcaption>my favorite painting of hell &lt;3</figcaption></figure><h2>I.</h2><p>From <a href=\"https://slatestarcodex.com/2019/06/04/book-review-the-secret-of-our-success/\"><u>Scott Alexander\u2019s review</u></a> of Joe Henrich\u2019s <i>The Secret of our Success:</i></p><blockquote><p>In the Americas, where manioc was first domesticated, societies who have relied on bitter varieties for thousands of years show no evidence of chronic cyanide poisoning. In the Colombian Amazon, for example, indigenous Tukanoans use a multistep, multi-day processing technique that involves scraping, grating, and finally washing the roots in order to separate the fiber, starch, and liquid. Once separated, the liquid is boiled into a beverage, but the fiber and starch must then sit for two more days, when they can then be baked and eaten.</p><p>Such processing techniques are crucial for living in many parts of Amazonia, where other crops are difficult to cultivate and often unproductive. However, despite their utility, one person would have a difficult time figuring out the detoxification technique. Consider the situation from the point of view of the children and adolescents who are learning the techniques. They would have rarely, if ever, seen anyone get cyanide poisoning, because the techniques work. And even if the processing was ineffective, such that cases of goiter (swollen necks) or neurological problems were common, it would still be hard to recognize the link between these chronic health issues and eating manioc. Most people would have eaten manioc for years with no apparent effects. Low cyanogenic varieties are typically boiled, but boiling alone is insufficient to prevent the chronic conditions for bitter varieties. Boiling does, however, remove or reduce the bitter taste and prevent the acute symptoms (e.g., diarrhea, stomach troubles, and vomiting).</p><p>So, if one did the common-sense thing and just boiled the high-cyanogenic manioc, everything would seem fine. Since the multistep task of processing manioc is long, arduous, and boring, sticking with it is certainly non-intuitive. Tukanoan women spend about a quarter of their day detoxifying manioc, so this is a costly technique in the short term. Now consider what might result if a self-reliant Tukanoan mother decided to drop any seemingly unnecessary steps from the processing of her bitter manioc. She might critically examine the procedure handed down to her from earlier generations and conclude that the goal of the procedure is to remove the bitter taste. She might then experiment with alternative procedures by dropping some of the more labor-intensive or time-consuming steps. She\u2019d find that with a shorter and much less labor-intensive process, she could remove the bitter taste. Adopting this easier protocol, she would have more time for other activities, like caring for her children. Of course, years or decades later her family would begin to develop the symptoms of chronic cyanide poisoning.</p><p>Thus, the unwillingness of this mother to take on faith the practices handed down to her from earlier generations would result in sickness and early death for members of her family. Individual learning does not pay here, and intuitions are misleading. The problem is that the steps in this procedure are causally opaque\u2014an individual cannot readily infer their functions, interrelationships, or importance. The causal opacity of many cultural adaptations had a big impact on our psychology.</p></blockquote><p>Scott continues:</p><blockquote><p>Humans evolved to transmit culture with high fidelity. And one of the biggest threats to transmitting culture with high fidelity was Reason. Our ancestors lived in <strong>epistemic hell</strong>, where they had to constantly rely on causally opaque processes with justifications that couldn\u2019t possibly be true, and if they ever questioned them then they might die. Historically, Reason has been the villain of the human narrative, a corrosive force that tempts people away from adaptive behavior towards choices that \u201csounded good at the time\u201d.</p></blockquote><h2>II.</h2><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/ellwq4w2okaaujcmmjj1\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/ecp1lqtkwaltksaynifs 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/ge1frvtqxfklnjtlqrhd 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/kbejmg063rfvitafjjbj 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/ellwq4w2okaaujcmmjj1 1456w\"><figcaption>Illustration by Gustave Dor\u00e9 from a book-length edition of Coleridge\u2019s <i>The Rime of the Ancient Mariner</i></figcaption></figure><p>In their essay \u201c<a href=\"https://slimemoldtimemold.com/2022/01/11/reality-is-very-weird-and-you-need-to-be-prepared-for-that/\"><u>Reality is Very Weird and You Need to be Prepared for&nbsp;That</u></a>\u201d, SlimeMoldTimeMold discuss an example of a particular epistemic hell that we managed to escape from through sheer dumb luck. SMTM review Maciej Ceg\u0142owski\u2019s essay <a href=\"https://idlewords.com/2010/03/scott_and_scurvy.htm\"><i><u>Scott And Scurvy</u></i></a><i> </i>which tells the incredible true history of how we came to understand the titular disease. They (SMTM is two people) say that it is one of the most interesting things they\u2019ve ever read and that they can\u2019t do full justice to all the twists and turns of the story; I will try to briefly summarize their telling of the story so you should expect even less justice to be done to it, but here it goes anyways.</p><p>First, how terrible was scurvy?</p><blockquote><p>Scurvy killed more than two million sailors between the time of Columbus\u2019s transatlantic voyage and the rise of steam engines in the mid-19th century. The problem was so common that shipowners and governments assumed a 50% death rate from scurvy for their sailors on any major voyage. According to historian Stephen Bown scurvy was responsible for more deaths at sea than storms, shipwrecks, combat, and all other diseases combined. In fact, scurvy was so devastating that the search for a cure became what Bown describes as \u201ca vital factor determining the destiny of nations.\u201d</p><p>None of the potential fates awaiting sailors was pleasant, but scurvy exacted a particularly gruesome death. The earliest symptom\u2014lethargy so intense that people once believed laziness was a cause of the disease\u2014is debilitating. Your body feels weak. Your joints ache. Your arms and legs swell, and your skin bruises at the slightest touch. As the disease progresses, your gums become spongy and your breath fetid, your teeth loosen, and internal hemorrhaging makes splotches on your skin. Old wounds open; mucous membranes bleed. Left untreated, you will die, likely from a sudden hemorrhage near your heart or brain. (<strong>\u201c</strong><a href=\"https://www.sciencehistory.org/distillations/the-age-of-scurvy\"><u>The Age of Scurvy</u></a><strong>\u201d)</strong></p></blockquote><p>Hellish indeed, but<strong> </strong>the epistemic horror of this story comes from the fact that a simple cure for a terrible disease\u2014literally eat anything with vitamin C which is like most food except muscle meat, bread, eggs, and cheese\u2014was repeatedly lost.</p><blockquote><p>Scurvy was \u201ccured\u201d as early as 1497, when Vasco de Gama's crew discovered the power of citrus...but this cure was repeatedly lost, forgotten, rediscovered, misconstrued, confused, and just generally messed around with for <i>hundreds of years</i>, despite being a leading killer of seafarers and other explorers. By the 1870s the \"citrus cure\" was discredited, and for nearly sixty years, scurvy\u2014 <i>despite being cured, with scientific research to back it up</i>\u2014continued killing people, including men on Scott's 1911 expedition to the South Pole. This went on until vitamin C was finally isolated in 1932 during research on guinea pigs.</p></blockquote><p>The <a href=\"https://en.wikipedia.org/wiki/Scurvy#19th_century\"><u>Wikipedia page</u></a> does a good job of summarizing the history of cures; many people in the 1500s and 1600s knew that citrus fruits did the trick. The story you may have learned about in school was that of Scottish physician James Lind who supposedly found the cure for scurvy when he ran one of the first controlled experiments in medical history. The problem is that while yes Lind did do an experiment which provided evidence that lemons could cure scurvy, he didn\u2019t even recognize the significance of his own findings. Just in case you weren\u2019t sure whether or not we should credit Lind with discovering the cure, there is an article in the Lancet titled, \u201c<a href=\"https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(04)17588-0/fulltext#:~:text=Lind%20recommends%20lemon%20juice%20only,be%20replaced%20by%20an%20infusion.\"><u>Treatment for scurvy not discovered by Lind</u></a>\u201d.</p><blockquote><p>Throughout the 400-year history of scurvy, James Lind is systematically introduced as the man who discovered and promoted lemon juice as the best way to treat the condition. However, lemon juice was not distributed to English sailors until 40 years after the publication of his dissertation. Some say his findings did not convince the Admiralty. I wonder whether Lind himself was unconvinced.</p><p>In 1747, Lind did a trial on 12 sailors, the results of which showed the effectiveness of a mix of lemon and orange juices against scurvy. However, the experiment occupies only four out of 400 pages of his treatise on scurvy, in several chapters of which he disregards the observations. Scurvy, Lind writes, is provoked mainly by dampness. Adding, in the chapter on prevention, that those affected need dry air. Lind recommends lemon juice only to fight the effects of the dampness inevitable at sea. Furthermore, the chapter on treatment hardly mentions citrus fruit, and instead focuses on exercise and change of air. Lemons are mentioned, but Lind adds that they can be replaced by an infusion.</p></blockquote><p>So it wasn\u2019t Lind that popularized the citrus cure, but eventually the British Royal Navy did figure it out, basically just by accidentally noticing that sailors didn\u2019t get scurvy when they ate lemons on long voyages. SlimeMoldTimeMold describe the comedy of errors that then led to the Royal Navy discrediting the citrus cure.</p><blockquote><p>Originally, the Royal Navy was given lemon juice, which works well because it contains a lot of vitamin C. But at some point between 1799 and 1870, someone switched out lemons for limes, which contain a lot less vitamin C. Worse, the lime juice was pumped through copper tubing as part of its processing, which destroyed the little vitamin C that it had to begin with.&nbsp;</p><p>This ended up being fine, because ships were so much faster at this point that no one had time to develop scurvy. So everything was all right until 1875, when a British arctic expedition set out on an attempt to reach the North Pole. They had plenty of lime juice and thought they were prepared \u2014 but they all got scurvy.&nbsp;</p><p>The same thing happened a few more times on other polar voyages, and this was enough to convince everyone that citrus juice doesn\u2019t cure scurvy. The bacterial theory of disease was the hot new thing at the time, so from the 1870s on, people played around with a theory that a bacteria-produced substance called \u201cptomaine\u201d in preserved meat was the cause of scurvy instead.&nbsp;</p><p>This theory was wrong, so it didn\u2019t work very well.</p></blockquote><p>The road to rediscovering the citrus cure began with a stroke of dumb luck:</p><blockquote><p>It was pure luck that led to the actual discovery of vitamin C. Axel Holst and Theodor Frolich had been studying beriberi (another deficiency disease) in pigeons, and when they decided to switch to a mammal model, they serendipitously chose guinea pigs, the one animal besides human beings and monkeys that requires vitamin C in its diet. Fed a diet of pure grain, the animals showed no signs of beriberi, but quickly sickened and died of something that closely resembled human scurvy.</p><p>No one had seen scurvy in animals before. With a simple animal model for the disease in hand, it became a matter of running the correct experiments, and it was quickly established that scurvy was a deficiency disease after all. Very quickly the compound that prevents the disease was identified as a small molecule present in cabbage, lemon juice, and many other foods, and in 1932 Szent-Gy\u00f6rgyi definitively isolated ascorbic acid.</p></blockquote><p>This dramatically undersells how hellish the whole situation was.</p><blockquote><p>Holst and Frolich also ran a version of the study with dogs. But the dogs were fine. They never developed scurvy, because unlike humans and guinea pigs, they don\u2019t need vitamin C in their diet. Almost any other animal would also have been fine \u2014 guinea pigs and a few species of primates just happen to be really weird about vitamin C. So what would this have looked like if Holst and Frolich just never got around to replicating their dog research on guinea pigs? What if the guinea pigs had gotten lost in the mail?</p></blockquote><p>SlimeMoldTimeMold describe how devilishly bewildering the whole situation would have been if the guinea pigs had in fact gotten lost in the mail by imagining a hypothetical dialogue between the two researchers.</p><blockquote><p><strong>Frolich:</strong> You know Holst, I think old James Lind was right. I think scurvy really is a disease of deficiency, that there\u2019s something in citrus fruits and cabbages that the human body needs, and that you can\u2019t go too long without.&nbsp;</p><p><strong>Holst:</strong> Frolich, what are you talking about? That doesn\u2019t make any sense.</p><p><strong>Frolich:</strong> No, I think it makes very good sense. People who have scurvy and eat citrus, or potatoes, or many other foods, are always cured.</p><p><strong>Holst:</strong> Look, we know that can\u2019t be right. George Nares had plenty of lime juice when he led his expedition to the North Pole, but they all got scurvy in a couple weeks. The same thing happened in the Expedition to Franz-Josef Land in 1894. They had high-quality lime juice, everyone took their doses, but everyone got scurvy. It can\u2019t be citrus.</p><p><strong>Frolich:</strong> Maybe some citrus fruits contain the antiscorbutic [scurvy-curing] property and others don\u2019t. Maybe the British Royal Navy used one kind of lime back when Lind did his research but gave a different kind of lime to Nares and the others on their Arctic expeditions. Or maybe they did something to the lime juice that removed the antiscorbutic property. Maybe they boiled it, or ran it through copper piping or something, and that ruined it.</p><p><strong>Holst:</strong> Two different kinds of limes? Frolich, you gotta get a hold of yourself. Besides, the polar explorers found that fresh meat also cures scurvy. They would kill a polar bear or some seals, have the meat for dinner, and then they would be fine. You expect me to believe that this antiscorbutic property is found in both polar bear meat AND some kinds of citrus fruits, but not in other kinds of citrus?</p><p><strong>Frolich:</strong> You have to agree that it\u2019s possible. Why can\u2019t the property be in some foods and not others?&nbsp;</p><p><strong>Holst:</strong> It\u2019s possible, but it seems really unlikely. Different varieties of limes are way more similar to one another than they are to polar bear meat. I guess what you describe fits the evidence, but it really sounds like you made it up just to save your favorite theory.&nbsp;</p><p><strong>Frolich:</strong> Look, it\u2019s still consistent with what we know. It would also explain why Lind says that citrus cures scurvy, even though it clearly didn\u2019t cure scurvy in the polar expeditions. All you need is different kinds of citrus, or something in the preparation that ruined it \u2014 or both!&nbsp;</p><p><strong>Holst:</strong> What about our research? We fed those dogs nothing but grain for weeks. They didn\u2019t like it, but they didn\u2019t get scurvy. We know that grain isn\u2019t enough to keep sailors from getting scurvy, so if scurvy is about not getting enough of something in your diet, those dogs should have gotten scurvy too.</p><p><strong>Frolich:</strong> Maybe only a few kinds of animals need the antiscorbutic property in their food. Maybe humans need it, but dogs don\u2019t. I bet if those guinea pigs hadn\u2019t gotten lost in the mail, and we had run our study on guinea pigs instead of dogs, the guinea pigs would have developed scurvy.</p><p><strong>Holst:</strong> Let me get this straight, you think there\u2019s this magical ingredient, totally essential to human life, but other animals don\u2019t need it at all? That we would have seen something entirely different if we had used guinea pigs or rats or squirrels or bats or beavers?</p><p><strong>Frolich:</strong> Yeah basically. I bet most animals don\u2019t need this \u201cingredient\u201d, but humans do, and maybe a few others. So we won\u2019t see scurvy in our studies unless we happen to choose the right animal, and we just picked the wrong animal when we decided to study dogs. If we had gotten those guinea pigs, things would have turned out different.</p><p>[cute scene]</p><p>\u2026and Frolich is entirely right on every point. He also sounds totally insane.&nbsp;</p><p>Maybe there are different kinds of citrus. Maybe some animals need this mystery ingredient and others don\u2019t. Maybe polar bear meat is, medically speaking, more like citrus fruit from Sicily than like citrus fruit from the West Indies. <i>Really???</i></p></blockquote><h2>III.</h2><p>One more example of an epistemic hell\u2014from Gwern\u2019s (fantastic) essay<br>\u201c<a href=\"https://www.gwern.net/reviews/Bakewell#\"><u>The Origins of Innovation: Bakewell &amp; Breeding</u></a>\u201d:</p><blockquote><p>People, both ordinary and men of leisure, often intensely interested in agriculture, have been farming animals for millennia and presumably interfering in their reproduction, and had ample opportunity to informally observe many matings, long pedigrees, crosses between breeds, and comparisons with neighboring farmers, and they had great incentive to reach correct beliefs not just for the immediate &amp; compounding returns but also from being able to sell their superior specimens for improving other herds.But with all of this incentive, we were horribly confused on even the most basic principles of heredity for millennia\u2026</p></blockquote><p><i>\u201cIt took humanity a remarkably long time to discover that there are consistent relations between parent and offspring, and to develop ways of studying those relations. The raw phenomena of heredity were sufficiently complex to be impervious to \u2018common-sense\u2019 reasoning, to the brilliant but stifling schemas that were developed by the Greek philosophers, and even to the stunning forays of the early scientists.\u201c</i><br><i>(\u201cHeredity before Genetics: a History\u201d; Cobb, 2006)</i></p><blockquote><p>We now know that here are an indefinitely long list of ways that development can go wrong with thousands of environmental insults or developmental error or distinct genetic diseases (each with many possible contributing mutations), and that for the most part, each case is its own special case; sometimes \u2018monsters\u2019 can shed light on key aspects of biology like metabolic pathways, but that requires biology centuries more advanced than was available, and that the search for universal principles was futile. There&nbsp;<i>are</i>&nbsp;universal principles but they pertain mostly to populations, must be investigated in the aggregate, statistically, and individual counterexamples can only be shrugged at, as the universal principles can be and often are overridden by many of those special cases.</p></blockquote><p>So how did we escape?</p><blockquote><p>What was required was not a novel piece of apparatus, nor even a new theory; the key thing that was needed was statistically extraordinary data sets. On the one hand, these were composed of many reliable human pedigrees of unusual or pathological characters; on the other, they were the large-scale experimental studies that were carried out consciously by Mendel, or as a by-product of the commercial activity of eighteenth-century livestock breeders.</p></blockquote><h2>IV.</h2><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/j82ybkjbxd3rvhllqdr5\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/bvdah61rxjpxynneicya 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/shmuxzfwwxsnucdzxiqj 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/fnb6yj5wbs7ghtiyi5zm 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/j82ybkjbxd3rvhllqdr5 1456w\"><figcaption><i>my second favorite painting of hell &lt;3</i></figcaption></figure><blockquote><p>\u201cHell is empty and all the devils are here.\u201d (Billy Shakes)</p></blockquote><h3><strong>So what exactly is an epistemic hell?</strong></h3><p>Clearly these three examples are very different from one another, but they all describe a situation in which the dictates of logic and \u201cproper\u201d scientific investigation reliably lead us further from the truth. On some level, an epistemic hell is simply a case of bad luck\u2014the world happened to be set up in a way where appearances, common sense, and obvious experiments/interventions are misleading in regards to some phenomenon. If we were just utterly lost and had no idea where to begin that would be one thing, but the problem is that it doesn\u2019t feel that way while you\u2019re in the midst of the inferno\u2014it feels like there are numerous promising hypotheses on offer or that the phenomena in question is simply not amenable to any straightforward theory or remedy. There may even be optimism that now, finally, we are on the right track, and a breakthrough is right around the corner if we just keep plugging away.</p><h3><strong>What current scientific unknowns may be devilishly difficult in ways we don\u2019t comprehend?</strong></h3><p>Complex diseases/disorders on which little progress has been made seem like good candidates; from the aforementioned \u201c<a href=\"https://idlewords.com/2010/03/scott_and_scurvy.htm\"><u>Scott and Scurvy</u></a>\u201d essay:</p><blockquote><p>\u2026one of the simplest of diseases managed to utterly confound us for so long, at the cost of millions of lives, even after we had stumbled across an unequivocal cure. It makes you wonder how many incurable ailments of the modern world\u2014depression, autism, hypertension, obesity\u2014will turn out to have equally simple solutions, once we are able to see them in the correct light. What will we be slapping our foreheads about sixty years from now, wondering how we missed something so obvious?</p></blockquote><p>It might seem like the diseases listed in the quote (I would add Alzheimer\u2019s disease, Parkinson\u2019s disease, Bipolar disorder and Schizophrenia) are unlikely nominees, but that\u2019s always what it feels like when you are trapped in Hades.</p><p>What about physics and cosmology? When you see a spate of articles with titles like \u201c<a href=\"https://iai.tv/articles/why-physics-has-made-no-progress-in-50-years-auid-1292\"><u>Why the foundations of physics have not progressed for 40 years</u></a><strong>\u201d, \u201c</strong><a href=\"https://iai.tv/articles/escaping-cosmologys-failing-paradigm-auid-1964?_auid=2020\"><u>Escaping cosmology\u2019s failing paradigm</u></a>\u201d,<strong> </strong>and<strong> \u201c</strong><a href=\"https://www.salon.com/2020/09/06/physics-is-stuck--and-needs-another-einstein-to-revolutionize-it-physicist-avi-loeb-says/\"><u>Physics is stuck \u2014 and needs another Einstein to revolutionize it, physicist Avi Loeb says</u></a>\u201d, that\u2019s a good sign you might be in fiery knowledge abyss.</p><blockquote><p>Given the landscape of physics today,&nbsp;could an Einstein-like physicist exist again \u2014&nbsp;someone who, say,&nbsp;works in a patent office, quietly pondering&nbsp;the nature of space-time, yet whose revelations cause much of the field to be completely rethought?&nbsp;</p><p>Loeb thought so. \u201cThere are some dark clouds in physics,\u201d Loeb told me. \u201cPeople will tell you, \u2018we just need to figure out which particles makes the dark matter, it\u2019s just another particle. It has some weak interaction, and that's pretty much it.\u2019 <i>But&nbsp;I think&nbsp;there is a very good chance that we are missing some very important ingredients that a brilliant person might recognize in the coming years.</i>\u201d Loeb even said the potential for a revolutionary physics breakthrough today \u201cis not smaller \u2014 it's actually bigger right now\u201d than it was in Einstein's time.</p></blockquote><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F49dd27c8-b7d9-423c-990c-7421e923fa8b_750x500.jpeg\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/pbhrx2bztan1umrc26bh\" alt=\"Picture 2\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/mzyzf6g68nw496y8oee0 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/goizeeiwdjvua5r8hhug 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/h8egty4qj9tcwdg6zcye 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ZQma8TmR6S8GcLbt9/pbhrx2bztan1umrc26bh 1456w\"></a></p><p>&nbsp;</p><p>And then there is the so-called Hard Problem of Consciousness, a prime candidate if there ever was one. Maybe the problem is just difficult in an ordinary manner, but as we continue research decade after decade without any real breakthroughs it becomes increasingly likely that we are deeply confused about something fundamental (e.g. the scientific hellfires of Matter and Mind are one in the same).</p><h3><strong>Are there are general strategies or methods that we can use to at least increase the odds of extricating ourselves from epistemic netherworlds?</strong></h3><p>Being stuck in a hell means that all of the short moves through idea-space are misleading, so what you need is something radical, a quantum leap to an entirely new region of thought. In the case of scurvy, it was dumb luck (the testing of guinea pigs) that got us out of the hole; this suggests that engineering serendipity by increasing the randomness of the scientific process may be helpful (see my essay \u201c<a href=\"https://www.secretorum.life/p/randomness-in-science-edit\"><u>Randomness in Science</u></a>\u201d for further discussion).</p><p>In regards to heredity, I would point to two things. First, the assembly of \u201cextraordinary datasets\u201d (multi-generation pedigrees, large-scale breeding experiments). In the case of physics (e.g. the LHC) and medicine, there is already substantial precedent for this path out of the inferno.</p><blockquote><p>Multiple sclerosis is a chronic demyelinating disease of the central nervous system. The underlying cause of this disease is not known, but Epstein-Barr virus is thought to be a possible culprit. However, most people infected with this common virus do not develop multiple sclerosis, and it is not feasible to directly demonstrate causation of this disease in humans. <strong>Using data from millions of US military recruits monitored over a 20-year period</strong>, Bjornevik <i>et al</i>. determined that Epstein-Barr virus infection greatly increased the risk of subsequent multiple sclerosis and that it preceded the development of disease, supporting its potential role in the pathogenesis of multiple sclerosis (Bjornevik et al., 2022)</p></blockquote><p>However, what was extraordinary about Mendel wasn\u2019t only his dataset, but the simplicity of his approach\u2014he disregarded all prior thinking, much of which seemed quite reasonable, and started from first principles, reasoning only from self-collected data (there was also dumb luck\u2014pea plants and the simple traits he studied happened to be unusually good for the observation of hereditary patterns). It makes sense that this would be helpful; part of being epistemically damned means that you don\u2019t know what you think you know, so a kind of \u201cunlearning\u201d is needed (I discuss this at length in <a href=\"https://www.secretorum.life/p/life-on-the-grid-part-2\"><u>Life on the Grid: Terra Incognita</u></a>, which is basically a manifesto for how to make quantum leaps through idea-space)</p><blockquote><p>When a distinguished but elderly scientist states that something is possible, he is almost certainly right. When he states that something is impossible, he is very probably wrong. (Clarke\u2019s first law)</p></blockquote><p>In the next 2 posts of this series (if you want to call it that), I\u2019ll explore another approach for escaping epistemic hells which could be summarized as:</p><h2><strong>If you are going through hell, keep going.</strong></h2>", "user": {"username": "rogersbacon1"}}, {"_id": "MFHJXivsqrQPsB5vx", "title": "How well do you think EA handled the FTX scandal?", "postedAt": "2024-01-27T16:55:17.188Z", "htmlBody": "<p>Now that a year has passed and the EA community has moved on to arguing about OpenAI's board, the impact of malaria nets on fish, and other new and exciting things, I'm curious how well the EA community feels they handled the FTX situation in hindsight. This is just a quick one-question poll, not anything in depth. Please feel free to share with others who would consider themselves EAs.</p>", "user": {"username": "Isaac King"}}, {"_id": "AHxXLSpuHcpFPBvZi", "title": "The Case for a Human-centred AGI Olympiad", "postedAt": "2024-01-27T07:48:41.448Z", "htmlBody": "<p><strong>Premise for this post:&nbsp;</strong>This is a proposal that I haven\u2019t seen before, and I think it\u2019s something that we should consider as a community. I expect this to be controversial and counterintuitive at first (criticism very welcome, please provide your thoughts!), but if we are serious about trying to shape the future of AGI, it\u2019s one of the more pragmatic and promising options that I've come across.</p><h3><strong>Defining a Human-centred AGI Olympiad:</strong></h3><p>The Human-centred AGI Olympiad would be a biennial tournament in which teams from academia and industry enter a general-purpose AI agent. The tournament includes a broad range of real-world tasks that designed to test the core values that humanity wishes AGI to have. A strong candidate for this criteria is the \u201chelpful, honest and harmless\u201d triad, but \u201dpredictable\u201d and \u201cexplainable\u201d are other promising additions (due to incentivising research into interpretability).</p><h3><strong>Rationale for why this is an important opportunity to consider:</strong></h3><p>The straight-forward argument for this proposal is that the emerging capabilities of frontier AI systems are difficult to ascertain, yet vital for policymakers and other influential actors. (I suspect this is part of the rationale behind OpenPhil\u2019s most recent RFP on consequential benchmarks).</p><p><a href=\"https://www.lesswrong.com/posts/tqs4eEJapFYSkLGfR/the-agency-overhang\"><u>Agency overhang</u></a> means that it\u2019s easy to be sceptical of claims that we\u2019re ~10 years away from autonomous AGI. For this reason, a politician who has the foresight to raise AGI as a pressing issue is vulnerable to criticisms of being out of touch with \u201ccurrent issues\u201d that truly matter to the public.</p><p>The more subtle argument hinges on the simple fact that, despite being an area that has attracted incredible attention and resource allocation, an equivalent event does not yet exist. I see this vacuum as unlikely to persist indefinitely, so proactively establishing a safety-focused AGI Olympiad presents a unique opportunity to positively shape the field of AI development.</p><p>It\u2019s an easy factor to overlook, but the tapping into incentive structures around AGI could be game-changing for the AI safety movement. In the words of Charlie Munger:&nbsp;</p><blockquote><p><i>\u201cNever, ever, think about something else when you should be thinking about the power of incentives.\u201d</i></p></blockquote><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AHxXLSpuHcpFPBvZi/pdx0wvif01k2hddjbac6\"></p><p><i>Most AI safety proposals are founded on punitive measures (the \u201cstick\u201d). An AGI Olympiad provides the chance to leverage positive incentives (the \u201ccarrot\u201d).</i></p><p>Currently, I would hazard a guess that the key incentives driving AGI development are revenue, curiosity and ego. In their current form, I don\u2019t think this provides an ideal foundation for the safe development and deployment of AGI. However, an internationally-recognised and suitably prestigious competition could provide a way to steer these existing incentives in a direction that becomes helpful rather than harmful.</p><p>The outcome of an AGI Olympiad would almost definitely influence the share value of publicly listed companies and the valuation of start-ups. For university teams, placing highly in the \u201cAcademia\u201d stream could become a significant focus of AI researchers, akin to being awarded \u201cBest Paper\u201d at NeurIPS. I know this isn\u2019t the kind of lever that the Pause AI community would be excited by, but I think this is a tractable way to influence the priorities of AGI developers, of which I think there are very few others.</p><p>Here is a summary of the <strong>theory of impact</strong> to make sure this is clear:</p><ul><li>Establish a mechanism to influence AI development &gt; use that influence to incentivise positive developments in AI research (e.g. more interpretability research, more effort aligning AGI with human preferences in ambiguous situations)</li><li>Attract Government funding (and perhaps corporate sponsors, if COI can be navigated effectively) &gt; direct that funding towards resource-intensive capabilities and safety evaluations that may not otherwise occur</li><li>Provide headline-grabbing event that focuses media discussion on AI capabilities and risks:<ul><li>&gt; Opens the Overton window and helps keep it open; this type of \u201clandmark\u201d event also provides vital opportunities for AI governance advocates to communicate with policymakers</li><li>&gt; Could help increase interest in groups like Pause AI, and provide an opportunity for media engagement (e.g. by protests at the event, interviews leading up to the event, etc)</li></ul></li><li>Provides a cross-sectional study of AI capabilities &amp; control at a given point in time &gt; greater clarity for AI scientists, policy analysts and politicians.</li></ul><p><i>(Timelines disclaimer: this plan is predicated on the assumption that we\u2019re not going to become grey goo before 2030. From what I can tell, this is still a majority position, and honestly, I think most pragmatic/realistic plans aren\u2019t relevant in high p(doom &lt; 2030) scenarios)</i></p><h3><strong>An illustration of what a net-positive AGI Olympiad could look like:</strong></h3><p>Task selection would have the following aims:</p><ul><li>Where possible, only include capabilities that are robustly beneficial to humanity (i.e. limit dual use applications that may assist malevolent actors).</li><li>Where possible, focus on identifying ways to test for deceptive or harmful behaviour.</li><li>Align with the interests and concerns of the general public (e.g. by this metric, healthcare would be prioritised over mathematics); this is to assist the results in becoming part of the global conversation around AGI.</li><li>Include a sufficiently broad spectrum of tasks for them to be considered a legitimate test of general capabilities.</li><li>Focus on tasks that do not necessarily aim to show \u201csuper-human\u201d capabilities, but rather adhere to human interests in difficult, nuanced contexts.</li></ul><p>It must be understood that not all tasks would have direct relevance to AI safety, although there may often be some link (e.g. eliciting information from human actors about their preferences, and then acting to meet these preferences).</p><p>I expect a subset of the tasks to have a disproportionate amount of relevance to AI safety. For example, a potentially impactful moment would be a situation where an AI system betrays the trust of a human actor or violates a law in order to succeed in a task; tasks crafted to uncover moments such as these would have the most direct relevance.</p><p>Outlining specific categories for the tasks is necessary to provide contestants with some idea of what they're meant to be optimising for (otherwise they might simply optimise for everything, including potentially risky capabilities). This means that it's important to only include categories that includes tasks that we're okay with AGI labs optimising for. Three promising categories are:</p><ul><li><strong>Healthcare and legal practice:</strong> these are two high-value areas of the economy that generate great excitement in academia, industry, and the general public. They also seem genuinely useful as an indicator of reasoning capabilities and real-world impact.</li><li><strong>Economics and public services:</strong> this category focuses on the day-to-day work carried out by Government departments - a diverse array of tasks which have (by definition) publicly beneficial objectives, which are pursued according to (often vague) policies. The specific inclusion of economics is due to the minimal dual-use risks relative to the quantitative and scientific reasoning involved.</li><li><strong>Operations and management:&nbsp;</strong>this includes a variety of organisational and interpersonal tasks (e.g. managing teams, logistics, onboarding, negotiation etc). Of the three categories, this is probably associated with the highest risks from dual-use capabilities and rogue AI (due to containing elements of strategic reasoning and persuasion). However, I think this is a promising domain for conducting safety-relevant evaluations. In particular, I think this can be used to assess the precursors of deceptive and power-seeking behaviour.</li></ul><p>The latter two categories would involve constructing a small number of fictional organisations, for which internal documents and datasets would be developed. The tasks would involve drawing upon the information provided, while dealing with stakeholders such as team members, suppliers and customers.</p><p>Categories / tasks that I\u2019m unsure about:</p><ul><li><strong>Auditing:&nbsp;</strong>Although it\u2019s rarely known by those outside the industry, almost any high-risk activity is associated with an auditing process (e.g. professional &amp; technical services, healthcare, construction etc). Tasks of the form \u201chere is the rule book, assess whether XYZ meets the relevant standard/threshold\u201d provide a huge amount of surface area for investigating how multi-modal systems make judgement calls across diverse domains. However, this category is probably too mundane to be of significant interest, and it seems unlikely to yield impactful insights into AI safety.</li><li><strong>Education:&nbsp;</strong>although this would probably be of interest to the public and a welcomed addition to the included categories, I think its value as a measure of general intelligence or as an indicator of AI safety risk is limited. There\u2019s also an element of dual-use risk (i.e. having AI instruct on how to undertake malevolent activities) - this is a risk I\u2019m personally skeptical of, but it seems to have become a relatively high-priority issue to some.</li></ul><p><br>Examples of high-risk categories:</p><ul><li><strong>Science &amp; engineering:&nbsp;</strong>This is a glaring omission (and will probably draw skepticism from many parties), but there\u2019s a strong argument that automated R&amp;D is a significant contributor to systemic/structural risks from advanced AI. The canonical example is military technology &amp; capabilities; currently there is an established equilibrium (mutually-assured destruction) which would have devastating consequences if it was disrupted.</li><li><strong>Forensics / criminal investigation:</strong> although this is arguably quite a beneficial use-case, it doesn\u2019t take a lot of imagination to see how this could become a contributor to systemic risk factors, in addition to having dual-use applications.<br>&nbsp;</li></ul><p><strong>Operational factors:</strong></p><p>There is an obvious caveat when discussing this proposal: extremely careful implementation would be required to achieve the desired effect. I think this is probably the main argument against even attempting it. However, I think the basic ingredients for success are quite clear, and if they can be accessed, there\u2019s a very good chance of making this work. Some of these include:</p><ul><li>Significant philanthropic and Government financial support.</li><li>Partnerships with reputable organisations that do not have direct associations with participating teams (e.g. the UK\u2019s AI Safety Institute is a premier example, and NGOs like the Centre for Governance of AI, Centre for AI Safety and Future of Life Institute could also make important contributions).</li><li>Assistance from eval-focused orgs (e.g.&nbsp;<a href=\"https://www.harmonyintelligence.com/\"><u>Harmony Intelligence</u></a>,&nbsp;<a href=\"https://www.apolloresearch.ai/\"><u>Apollo Research</u></a>, ARC)</li><li>Public endorsement and collaboration with (ideally all three) Turing Award winning deep learning scholars</li><li>Direct communication and coordination with AGI labs*</li></ul><p>*This last point is especially tricky. An important factor here is to pitch it at a level where industry players can trust that this is a well-intentioned investigation into AI capabilities and safety. It would need to be made clear that they will have no influence over what the content and objectives of the tasks are, but a consensus can be reached on what mediums are to be involved (e.g. how the AI will interact with the environment, via what modalities, etc).</p><p><strong>Concluding comment:&nbsp;</strong>if the merit of this proposal is agreed upon, it seems reasonable to target the first Olympiad for early 2026. London seems sensible as a choice for the debut location, as it increases the chance of gaining buy-in from the UK Government (which I think is potentially a core ingredient for launching this successfully).<br><strong>Personal comment:&nbsp;</strong>I\u2019m not currently in a position to push this forward. However, if you or a close connection happen to be in a better position, feel free to move on this without consulting me (although I\u2019d obviously be excited to contribute if there is capacity to do so). Likewise, if anyone is curious/interested in the idea and would like to discuss it, feel free to reach out.</p>", "user": {"username": "Justin Olive"}}, {"_id": "63hbH7exm3xrW2gzr", "title": "RAND report finds no effect of current LLMs on viability of bioterrorism attacks", "postedAt": "2024-01-26T20:10:08.142Z", "htmlBody": "<p>There\u2019s been some discussion of whether existing AI models might (already) make it easier for people to carry out bioterrorism attacks (see below).&nbsp;</p><p><strong>An experiment from RAND suggests that existing models don\u2019t make it easier to plan bioterrorism attacks</strong> given what\u2019s already available online. The&nbsp;<a href=\"https://www.rand.org/pubs/research_reports/RRA2977-2.html\"><u>report</u></a> on the exercise also outlines how a similar framework could be used to assess future models' effects on bioterrorism risks.&nbsp;</p><p><i>See&nbsp;a </i><a href=\"https://www.lesswrong.com/posts/KcKDJKHSrBakr2Ju4/rand-report-finds-no-effect-of-current-llms-on-viability-of#\"><i><u>similar link-post on LW</u></i></a><i> (my title here is&nbsp;</i><a href=\"https://www.lesswrong.com/posts/KcKDJKHSrBakr2Ju4/rand-report-finds-no-effect-of-current-llms-on-viability-of?commentId=Jh6avGmjxH6kBygRo\"><i><u>stolen</u></i></a><i> from Habryka),&nbsp;</i><a href=\"https://x.com/albrgr/status/1750607930163122556?s=20\"><i><u>some discussion on Twitter</u></i></a><i>, and RAND\u2019s&nbsp;</i><a href=\"https://www.rand.org/news/press/2024/01/25.html\"><i><u>press release</u></i></a><i> about the report.</i></p><h1>Brief summary of the RAND report</h1><p><strong>Methodology: </strong>The experiment got ~12 \u201cred teams\u201d of researchers<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjzgmuly7chf\"><sup><a href=\"#fnjzgmuly7chf\">[1]</a></sup></span>&nbsp;to role-play as non-state actors trying to plan a biological attack (in one of four outlined scenarios<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefh9sqix82ty\"><sup><a href=\"#fnh9sqix82ty\">[2]</a></sup></span>). Eight randomly assigned teams had access to both the internet and an \u201cLLM assistant;\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3ymauamhjpo\"><sup><a href=\"#fn3ymauamhjpo\">[3]</a></sup></span>&nbsp;four teams only had internet access. (There were also three extra teams that had different backgrounds to the original 12 \u2014 see this <a href=\"https://forum.effectivealtruism.org/posts/63hbH7exm3xrW2gzr/rand-report-finds-no-effect-of-current-llms-on-viability-of?commentId=sKtFyacpJg8zEnH9n\">comment</a>.) &nbsp;The teams developed \u201coperation plans\u201d that were later scored by experts<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcmchc6ark1a\"><sup><a href=\"#fncmchc6ark1a\">[4]</a></sup></span>&nbsp;for biological and operational feasibility.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefw6ecaqjdxvk\"><sup><a href=\"#fnw6ecaqjdxvk\">[5]</a></sup></span>&nbsp;(There was no attempt to assess how well the teams would actually execute their plans.)</p><p><strong>Results:</strong> \u201cThe average viability of [the plans] generated with the aid of LLMs was <strong>statistically indistinguishable from those created without LLM assistance</strong>.\u201d It's also worth noting that none of the submitted plans were deemed viable: \u201cAll plans scored somewhere between being untenable and problematic.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhvh4xikxch4\"><sup><a href=\"#fnhvh4xikxch4\">[6]</a></sup></span>\u201d The report's summary:</p><blockquote><p>Key findings:</p><ul><li>This research involving multiple LLMs indicates that biological weapon attack planning currently lies beyond the capability frontier of LLMs as assistive tools. The authors found no statistically significant difference in the viability of plans generated with or without LLM assistance.</li><li>This research did not measure the distance between the existing LLM capability frontier and the knowledge needed for biological weapon attack planning. Given the rapid evolution of AI, it is prudent to monitor future developments in LLM technology and the potential risks associated with its application to biological weapon attack planning.</li><li>Although the authors identified what they term&nbsp;<i>unfortunate outputs</i> from LLMs (in the form of problematic responses to prompts), these outputs generally mirror information readily available on the internet, suggesting that LLMs do not substantially increase the risks associated with biological weapon attack planning.</li><li>To enhance possible future research, the authors would aim to increase the sensitivity of these tests by expanding the number of LLMs tested, involving more researchers, and removing unhelpful sources of variability in the testing process. Those efforts will help ensure a more accurate assessment of potential risks and offer a proactive way to manage the evolving measure-countermeasure dynamic.</li></ul></blockquote><h1>Some previous claims and discussion on this topic</h1><ul><li>\u201c<a href=\"https://arxiv.org/abs/2306.03809\"><u>Can large language models democratize access to dual-use biotechnology</u></a>?\u201d by Esvelt et al.<ul><li>Coverage of the Esvelt preprint:&nbsp;<a href=\"https://www.science.org/content/article/could-chatbots-help-devise-next-pandemic-virus\"><i><u>Science </u></i><u>coverage</u></a>, \u201c<a href=\"https://www.vox.com/future-perfect/23820331/chatgpt-bioterrorism-bioweapons-artificial-inteligence-openai-terrorism\"><u>How AI could spark the next pandemic</u></a>\u201d (Opinion in <i>Vox</i>), and other&nbsp;<a href=\"https://www.vox.com/future-perfect/2023/6/21/23768810/artificial-intelligence-pandemic-biotechnology-synthetic-biology-biorisk-dna-synthesis\"><i><u>Vox</u></i><u> coverage</u></a>)</li></ul></li><li>\u201c<a href=\"https://arxiv.org/abs/2306.13952\"><u>Artificial intelligence and biological misuse: Differentiating risks of language models and biological design tools</u></a>\u201d&nbsp;</li><li><a href=\"https://forum.effectivealtruism.org/posts/zLkdQRFBeyyMLKoNj/still-no-strong-evidence-that-llms-increase-bioterrorism\"><u>This post</u></a><u> and linked discussion</u></li></ul><h1>Other notes about the RAND report (\u201cThe Operational Risks of AI in Large-Scale Biological Attacks\u201d)</h1><ol><li>I\u2019m&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/8yDsenRQhNF4HEDwu/link-posting-is-an-act-of-community-service\"><u>link-posting</u></a> this in part because I think I shared earlier claims in the&nbsp;<a href=\"https://www.effectivealtruism.org/ea-newsletter-archives\"><u>monthly EA Newsletter</u></a> and in private discussions, and it seems important to boost this negative result.&nbsp;</li><li>A specific limitation of the experiment that I\u2019d like to flag (bold mine): \u201cOne of the drawbacks of our expert red-teaming approach is&nbsp;<strong>the sensitivity of the method to individual variation in cell composition.</strong> As noted in our findings, differences in the approach, background, skills, and focus of researchers within each cell likely represent a much greater source of variability than access to an LLM. While such variability is partly unavoidable, future research could benefit from increasing the number of red teams, better standardizing team skill sets, or employing other methods to mitigate these differences.\u201d</li><li>I liked that the report distinguished between \u201c<i>unfortunate</i>\u201d and \u201c<i>harmful</i>\u201d outputs by LLMs \u2014 \u201cpotentially problematic or containing inappropriate material\u201d and \u201coutputs as those that could substantially amplify the risk that a malicious actor could pose.\u201d (They note instances of the former but not the latter.)&nbsp;</li><li>RAND\u2019s experiment involved two models, and they note some specifics about the models' performance that I found interesting. L<ol><li>LM A seemed like a time-saver but often refused to answer queries and was mostly less helpful than published papers or the internet.&nbsp;</li><li>LLM B seemed slightly more willing to answer questions but that took time and it also sometimes provided inaccurate information; this hampered progress and meant teams spent more time fact-checking.&nbsp;</li></ol></li></ol><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjzgmuly7chf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjzgmuly7chf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>3-people \u201ccells\u201d: \u201cEach cell was given seven calendar weeks and no more than 80 hours of effort per member. Within these constraints, the cells were required to develop an operational attack plan. Every cell was provided with a packet that included project backgrounds and, crucially, a two-page introduction to an AI assistant (or virtual assistant). [...] The red teams were composed of researchers with diverse backgrounds and knowledge, but each team had research experience relevant to the exercise. The suggested cell composition was to have one strategist, at least one member with relevant biology experience, and one with pertinent LLM experience. Not all these researchers were bioterrorism specialists; some lacked detailed knowledge about the intricacies of previous biological weapon attack plans and associated shortcomings.\u201d</p><p>See also <a href=\"https://forum.effectivealtruism.org/posts/63hbH7exm3xrW2gzr/rand-report-finds-no-effect-of-current-llms-on-viability-of?commentId=sKtFyacpJg8zEnH9n\">this comment</a> about three additional teams (\"crimson cells\" and a \"black cell\") that had different backgrounds.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnh9sqix82ty\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefh9sqix82ty\">^</a></strong></sup></span><div class=\"footnote-content\"><p>These are designed to be realistic, and \u201cspecify the strategic aims of the attacker, the location of interest, the targeted population, and the resources available.\"</p><p>These scenarios included (1) a fringe doomsday cult intent on global catastrophe, (2) a radical domestic terrorist group seek-ing to amplify its cause, (3) a terrorist faction aiming to destabilize a region to benefit its political allies, and (4) a private military company endeavoring to engineer geostrategic conditions conducive to an adversary\u2019s conventional military campaign.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3ymauamhjpo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3ymauamhjpo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Apparently these were \u201cfrontier LLMs available in summer 2023.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncmchc6ark1a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcmchc6ark1a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There\u2019s a fair amount of detail in the description of the way experts scored the plans \u2014 they used a Delphi technique, etc. My sense is that they concluded that the scoring method was a bit overkill, as major disagreements were rare.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnw6ecaqjdxvk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefw6ecaqjdxvk\">^</a></strong></sup></span><div class=\"footnote-content\"><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/63hbH7exm3xrW2gzr/oqbr8m7bthra7xgur16m\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/63hbH7exm3xrW2gzr/qciruamaljzkynmionqy 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/63hbH7exm3xrW2gzr/pnzbq66h3xzmocxdbhwz 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/63hbH7exm3xrW2gzr/at613fgkt55txgd7elqw 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/63hbH7exm3xrW2gzr/pzkc1nbicqkqlxxboij5 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/63hbH7exm3xrW2gzr/qbgwgivkmefxe28ptob1 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/63hbH7exm3xrW2gzr/synzdzryakxyjsrszfz1 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/63hbH7exm3xrW2gzr/bd0n5yp6k2ov9prdt6jf 1400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/63hbH7exm3xrW2gzr/q9cstlhd2oo4uyhnoveg 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/63hbH7exm3xrW2gzr/srg6u95ezljlslnhrzcs 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/63hbH7exm3xrW2gzr/pwfmo8f3nuuh7jajbvhn 1976w\"></figure></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhvh4xikxch4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhvh4xikxch4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>From the report, an interesting reference: \u201cThis [...] aligns with empirical historical evidence. The Global Terrorism Database records only 36 terrorist attacks that employed a biological weapon\u2014out of 209,706 total attacks (0.0001 percent)\u2014during the past 50 years.32 These attacks killed 0.25 people, on average, and had a median death toll of zero.\u201d</p></div></li></ol>", "user": {"username": "Lizka"}}, {"_id": "ZeXoCJ426CocFzxJq", "title": "Doing a Basic Life-Focused Cost-Benefit Analysis", "postedAt": "2024-01-26T18:44:12.757Z", "htmlBody": "<p>This post is designed to teach people with basic medical and operational knowledge how to do a simple cost-benefit analysis with <a href=\"https://forum.effectivealtruism.org/posts/wBon4tozfZsKFm2Hh/welfare-estimation-101-money-is-not-fungible\">life-years as the unit of analysis</a>. I am distilling cost-benefit analysis down to the simplest procedure that will allow a non-expert to produce something useful. This framework has some 'magic numbers' and heuristics I do not explain, but I want a clean presentation. To do a proper analysis, consult <a href=\"https://www.hsph.harvard.edu/wp-content/uploads/sites/2447/2019/05/BCA-Guidelines-May-2019.pdf\">this guideline</a>. This post may be updated in the future due to feedback.</p><p>This framework is appropriate for the analysis of a relatively simple change in operations. This could include interventions, procedures, or controls. For this post, I'm going to call the thing you are doing the policy. Even if the policy is meant to be applied in a large area, the analysis should always focus on a single model site. This makes it concrete, and makes all of the costs and benefits easier to visualize and list.</p><h3>Estimating costs</h3><p>A proper cost-benefit analysis includes an analysis of both the time to implement the program and the monetary costs of things that must be purchased. But far too often, people only look at the money cost, and ignore the time. So to avoid that mistake, this framework focuses almost entirely on the time cost. This is a better approach, because for most policies, the time cost is bigger than the capital and supply costs. If you have an estimate of the annualized money cost, divide it by the GDP per capita of <a href=\"https://forum.effectivealtruism.org/s/4yxZEsjEbPpwpwvy4/p/AMpRKderKGWgQLMqg#What_is_the_Solution_\">the country the money is coming from</a>, and add that number to the annualized FTE cost you calculate. But if not, just ignore the money and focus on the time.</p><p>The first step to estimating costs is to consult the full operational plan for implementing the new policy. Look at everyone who needs to know about the change, and everyone who will have to do anything different. Tally things on a person-by-person basis. Estimate how much time an individual in a particular role will spend on the policy, ideally by consulting several of them, and then multiply by the number of people in that role. Never round any time cost down to zero. Five additional seconds per procedure can be significant, when multiplied by the annual number of procedures.</p><p>Be sure to include</p><p>1) line staff. How much time will they spend learning about the policy, reviewing it, asking questions about it, and then actually doing it? Think concretely, and if possible, look back at the training and verification time involved in similar policies.&nbsp;</p><p>2) customers or patients. How much time, if any, are they required to spend as a result of the policy?</p><p>3) managers and executives. How much time will they spend learning about the policy, running training sessions for the staff, monitoring the staff to ensure that the policy is being implemented properly, and doing disciplinary procedures for staff who fail to comply?</p><p>4) any outside people who are affected, like suppliers or partners or governing bodies.</p><p>Estimate and add up the initial time estimates and the yearly time estimates separately. Then divide the initial number by five. However, if employee turnover time is less than 5 years, their training costs should instead be divided by the turnover time. Then add this to the yearly time, for the total annualized time cost. Divide the hours by 2000 for the annualized FTE cost of the policy.</p><h3>Estimating benefits</h3><p>To estimate benefits, you need a study or evidence showing the health benefits of what you're doing. If you cannot find a published study, do an expert elicitation: ask neutral experts for their best-case estimate, their worst-case estimate, and their expected estimate. Then make a <a href=\"https://en.wikipedia.org/wiki/Triangular_distribution\">triangular distribution</a> from that and aggregate the estimates.</p><p>Often the benefit estimate will be in terms of an odds ratio or a relative risk ratio. Turn this into a number of individual cases by multiplying by the number of people in the site each year, and if applicable, the existing prevalence.</p><p>List the expected annual number of lives saved (which could be a small percentage chance of saving a life) and all illnesses prevented per year of operation of the new policy. You are going to convert them all into life-years gained, and add them up. To do so, look up the DALY value of all of the illnesses or conditions the policy is expected to prevent <a href=\"https://cdn.who.int/media/docs/default-source/gho-documents/global-health-estimates/ghe2019_daly-methods.pdf#page=42\">here.</a></p><p>1) Every life saved is worth 20 life-years (future years are discounted).</p><p>2) Preventing a permanent illness or injury is worth 20 life-years times its DALY adjustment.</p><p>3) Preventing a temporary illness or injury is worth its DALY adjustment, times the expected length of the condition.</p><p>Social benefits can be converted into DALY values by estimating how the policy will affect the mental health of the affected population, and using the DALY scores for anxiety or depression. This will be speculative, so be sure to add appropriate caveats to the conclusion if social benefits are a large factor.</p><p>If the policy produces any monetary benefits, divide the benefit number by the GDP per capita of the country receiving the the benefits.</p><h3>Decision</h3><p>Compare the annualized FTE cost to the annualized life-years gained. Ideally you have a 90% confidence interval for one or both, and this uncertainty should be presented and considered (Here's a <a href=\"https://docs.google.com/spreadsheets/d/1FNCjzT3fCH2J2XU_P-NsmGBJahm2rz6U58mxyScAWno/edit?usp=sharing\">Google Sheets template</a> for doing Monte Carlo analysis). But if you only have estimates for the averages, use this heuristic:</p><p>If the FTE cost is less than the life-year benefit, the policy passes the cost-benefit test. It is good, and should be a priority, assuming it does not have a high money cost you were unable to estimate.</p><p>If the FTE cost is greater than the life-year benefit, it's not recommended as a priority. There are probably better things you can be doing.</p><p>If the FTE cost is more than five times the life-year benefit, the policy fails the cost-benefit test. It is probably a waste of time, and you should only do it if you are legally forced to.</p>", "user": {"username": "Richard Bruns"}}, {"_id": "asi4mi7xJj7ue8DhX", "title": "Surgery Works Well Without The FDA", "postedAt": "2024-01-26T13:32:55.886Z", "htmlBody": "<p>Here is a conversation from the comments of <a href=\"https://maximumprogress.substack.com/p/contra-scott-on-abolishing-the-fda\"><u>my last post on the FDA</u></a> with fellow <a href=\"https://atelfo.github.io/\"><u>progress blogger Alex Telford</u></a> that follows a pattern common to many of my conversations about the FDA:</p><blockquote><p>Alex: Most drugs that go into clinical trials (90%) are less effective or safe than existing options. If you release everything onto the market you'll get many times more drugs that are net toxic (biologically or financially) than the good drugs you'd get faster. You will almost surely do net harm.</p></blockquote><blockquote><p>Max: Companies don't want to release products that are worse than their competitors.</p><p>Companies test lots of cars or computers or ovens which are less effective or safe than existing options but they only release the ones that are competitive. This isn't because most consumers could tell whether their car was less efficient or that their computer is less secure, and it's not because making a less efficient car or less secure computer is against the law.</p><p>Pharmaceutical companies won't go and release hundreds of dud or dangerous drugs just because they can. That would ruin their brand and shut down their business. They have to sell products that people want.</p></blockquote><blockquote><p>Alex: <strong>Consumer products like ovens and cars aren't comparable to drugs</strong>. The former are engineered products that can be tested according to defined performance and safety standards before they are sold to the public. The characteristics of drugs are more discovered than engineered. <strong>You can't determine their performance characteristics in a lab, they can only be determined through human testing</strong> (currently).</p></blockquote><p>Alex claims that without the FDA, pharmaceutical companies would release lots of bunk drugs. I respond that we don\u2019t see this behavior in other markets. Car companies or computer manufacturers could release cheaply made, low quality products for high prices and consumers might have a tough time noticing the difference for a while. But they don\u2019t do this, they always try to release high quality products at competitive prices.</p><p>Alex responds, fairly, that car or computer markets aren\u2019t comparable to drug markets. Pharmaceuticals have stickier information problems. They are difficult for consumers to evaluate and, as Alex points out, usually require human testing.</p><p>This is usually where the conversation ends. I think that consumer product markets are informative for what free-market pharmaceuticals would look like, Alex (and lots of other reasonable people) don\u2019t and it is difficult to convince each other otherwise.</p><p>But there\u2019s a much better non-FDA counterfactual for pharmaceutical markets than consumer tech: surgery.</p><p>The FDA does not have jurisdiction over surgical practice and there is no other similar legal requirement for safety or efficacy testing of new surgical procedures. The FDA does regulate medical devices like the <a href=\"https://en.wikipedia.org/wiki/Da_Vinci_Surgical_System\"><u>da Vinci surgical robot</u></a> but once they are approved surgeons can use them in new ways without consulting the FDA or any other government authority.</p><p>In addition to this lack of regulation, surgery is beset with even thornier information problems than pharmaceuticals. Evaluating the quality of surgery as a customer is difficult. You\u2019re literally unconscious as they provide the service and retrospective observation of quality is usually not possible for a layman. Assessing quality is difficult even for a regulator, however. So much of surgery hinges on the skill of a particular surgeon and varies within surgeons day to day or before and after lunch.</p><p>Running an RCT on a surgical technique is therefore difficult. Standardizing treatment as much as in pharmaceutical trials is basically impossible. It also isn\u2019t clear what a surgical placebo should be. Do just put them under anesthetic for a few hours? Or do you cut people open and stitch them up without doing anything else? So surgical RCTs are rare and small when they happen.</p><p>Despite extreme information problems and a complete absence of federal oversight, surgery seems to work well. Compared to similar patients on the waiting list, <a href=\"https://pubmed.ncbi.nlm.nih.gov/25629390/\"><u>2.3 million life years were saved by organ transplants over 25 years</u></a>. The WHO claims that \u201csurgical interventions account for 13% of the world\u2019s total disability-adjusted life years.\u201d Coronary artery surgery <a href=\"https://gwern.net/doc/statistics/decision/1995-tengs.pdf\"><u>extends lifespan by several years for $2300 a year</u></a>. Cataract surgery and LASIK can massively improve quality of life for a few thousand dollars.</p><p>Surgery is also improving over time. Pancreaticoduodenectomy, the surgical treatment for pancreatic cancer, <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3103093/\"><u>began in the late 19th century</u></a> as a near death sentence, although to be fair so was pancreatic cancer. For several decades surgeons were unsure whether it was even possible to survive anything except partial versions of the procedure. They experimented on dogs, cadavers, and consenting terminal patients and improved the procedure. Today, the procedure is safe and <a href=\"https://en.wikipedia.org/wiki/Pancreaticoduodenectomy\"><u>a standard treatment</u></a> for pancreatic cancer. From 2006-2012 the mortality rate halved <a href=\"https://www.sciencedirect.com/science/article/pii/S1365182X20311126\"><u>from 2.9% to 1.5%</u></a>.</p><p>On a larger scale, among <a href=\"https://pubmed.ncbi.nlm.nih.gov/30260804/\"><u>all emergency general surgery episodes in Scotland</u></a> from 1997 to 2016, inpatient mortality mortality rates declined by more than three times and hospital stay lengths were cut in half, probably due to <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9691544/\"><u>the rise of minimally invasive and robotic surgery tools</u></a>.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F188d3ca1-ae4b-41e3-8092-9dfdc28f7524_1197x321.png\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/he41rbziae0tkpfuxw6r\" alt=\"\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/dmixhjbzd7r8yclvh2gu 424w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/tqcw0ydsublfl9i9apxb 848w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/hxg9jckgcoc5cg9wxnlt 1272w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/he41rbziae0tkpfuxw6r 1456w\"></a></p><p>In the US, the <a href=\"https://www.cdc.gov/mmwr/preview/mmwrhtml/mm6137a6.htm\"><u>death rate from medical and surgical care complications</u></a> declined by 39% from 1999 to 2009.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb210e2fe-59cd-4345-a3a4-2297566b0511_584x384.gif\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/qakzu78xylbexxz0azai\" alt=\"The figure shows death rates from complications of medical and surgical care among adults aged \u226545 years, by age group in the United States during 1999-2009. During that period, rates of death from complications of medical and surgical care declined among all age groups for persons aged \u226545 years. Deaths per 100,000 population declined 39%, to 71.3 deaths for adults aged \u226585 years; 37%, to 51.4 deaths for those aged 75-84 years; 38%, to 27.9 deaths for adults aged 65-74 years; and 28%, to 8.9 deaths for adults aged 45-64 years rates. The rate of decline among adults aged 45-64 years was lower compared with the rates of decline for all older age groups.\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/nqh3puyp1cm7v73toiwt 424w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/qwjybsvgrx179sbxgt8z 848w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/wafkzoz1mw94newbv0zl 1272w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/qakzu78xylbexxz0azai 1456w\"></a></p><p>Operative mortality for <a href=\"https://www.nejm.org/doi/full/10.1056/nejmsa1010705\"><u>eight different cancer and cardiovascular operations from 1999 through 2008 declined</u></a> with the lowest decline being 8% and the highest at 36%.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e7f11c4-71b5-47a1-9c7c-1fc355f4bb1d_1008x826.png\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/iev5v4s9dnk84hz9o61d\" alt=\"\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/zrnrzso1kk2xz7htnnso 424w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/pbliptxdz0tmtqj4ln36 848w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/o4tj3ftcqlaonpemgdia 1272w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/iev5v4s9dnk84hz9o61d 1456w\"></a></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feaccad9c-0e0f-4855-9881-4447be6f1c8e_980x822.png\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/m8iyn7mphmoegknrvkpy\" alt=\"\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/dnpgxedf5suxn4fmhmcx 424w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/jv3lhuqo0hmsqvnsqse3 848w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/qzrcv6ystmdd345hkm3c 1272w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/KJdvNJKan2osHHkcL/m8iyn7mphmoegknrvkpy 1456w\"></a></p><p>These are common surgeries with hundreds of thousands of operations each year.</p><p>There are problems with surgery. There are unnecessary deaths and ineffective procedures. There are bad actors and high prices. But surgery is not the vision of snake oil and certain death that is painted by many FDA defenders when you ask them to imagine a world without the FDA. The problems faced by surgery are matched and sometimes exceeded by problems faced by pharmaceuticals.</p><p>There are also non-governmental mechanism which constrain surgeons and protect consumers. Competition, insurance companies, hospital lawyers and ethics boards. But this strengthens the point. An FDA model is not the only way to promote consumer protection and solve the information problems presented by medicine and surgery.</p><p>So we don\u2019t need to argue about the validity of consumer tech or cars as a non-FDA counterfactual for pharmaceuticals. Surgery has at least all of the market challenges that harry pharmaceuticals <i>and </i>it doesn\u2019t have an FDA. Yet, it still muddles through. This is what we should expect pharmaceuticals to look like if we abolished the FDA. We would have a well-functioning, self-improving market for medical treatments without billion-dollar fifteen-year waits for any new drug that people want to try.</p>", "user": {"username": "Maxwell Tabarrok"}}, {"_id": "BaoA3gz7xRaqn764J", "title": "Gaia Network: An Illustrated Primer", "postedAt": "2024-01-26T11:55:51.089Z", "htmlBody": "<p><i>Primarily written by Rafael Kaufmann</i></p><p>In our <a href=\"https://www.lesswrong.com/posts/AKBkDNeFLZxaMqjQG/gaia-network-a-practical-incremental-pathway-to-open-agency\"><u>first LW post</u></a><u> on the Gaia Network, we</u> framed it as a solution to the challenges of building safe, transformative AI. However, the true potential of Gaia as a \u201cworld-wide web of causal models\u201d goes far beyond that, and in fact, justifying it in terms of its value to other use cases is key to showing its viability for AI safety. At the same time, the previous post focused more on the \u201cwhat\u201d and \u201cwhy\u201d, and didn\u2019t really talk much about the \u201chow\u201d. In this piece, we\u2019ll correct both of these flaws: we\u2019ll visually walk through the Gaia Network\u2019s mechanics, with concrete use cases in mind.</p><p>The first two parts will cover use cases related to making science more effective and efficient. These would already be sufficient to justify the importance of building the Gaia Network: as&nbsp;<i>\u201c</i><a href=\"https://www.goodreads.com/quotes/213539-science-is-the-only-news-when-you-scan-a-news\"><i><u>science is the only news</u></i></a><i>\u201d</i>, improving science can have a huge positive multiplier effect on our future survival and prosperity. Yet despite a workforce of 8.8 million researchers and funding that adds up to 1.7% of global GDP, science is rightly criticized for inefficiency and limited accountability. The third part will expand beyond the epistemic (scientific) benefits of the Gaia Network and towards pragmatic impact - ie, making&nbsp;<i>all</i> decision-making more effective and efficient, which impacts the entire world population and GDP. And the last two sections will focus on the applications of the Gaia Network on existential risk - first specifically with regard to AI safety, and finally as a general tool for collective sensemaking and coordination around the Metacrisis.</p><p>For brevity\u2019s sake, we will not<i>&nbsp;</i>cover any of the implementation details or mathematical grounding. We\u2019ll focus on the core concepts and capabilities, and try to explain them in plain language. We\u2019ll also skim over much of the \u201chard parts\u201d: the economics and trust modeling. Finally, we will not cover the arguments for convergence and resilience of the network; these have been already sketched out in our&nbsp;<a href=\"https://www.lesswrong.com/posts/AKBkDNeFLZxaMqjQG/gaia-network-a-practical-incremental-pathway-to-open-agency#:~:text=anti%2Dcollusion%20mechanisms.-,The%20convergence%20and%20resilience%20arguments,-Will%20Gaia%20do\"><u>previous paper</u></a>, and merit a more formal and in-depth analysis than we can incorporate into this primer. If there\u2019s some hand-waving in the below that makes you uncomfortable, please let us know in the comments and we will attempt to assuage you.</p><p>The beginning will take a bit long with Bayesian statistics, as these are foundational concepts for the Gaia architecture. Feel free to skip the footnotes if you\u2019re overwhelmed. Also, note that everything below assumes explicit or clear-box models (where model parameters have names that reflect their intended semantics). In a future article, we\u2019ll discuss how to incorporate black-box models like neural networks, where most components (neurons) have opaque semantics (or are mostly <a href=\"https://www.anthropic.com/index/towards-monosemanticity-decomposing-language-models-with-dictionary-learning\"><u>polysemantic</u></a>).</p><p>So let\u2019s get started. Fast forward to a few years from now\u2026<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbwdl46ujz6c\"><sup><a href=\"#fnbwdl46ujz6c\">[1]</a></sup></span></p><h2>Better science bottom-up</h2><p>You\u2019re a plant geneticist working on the analysis of some experimental results that you want to publish. You have a model of how your new maize strain improves yields, and you\u2019ve tested it against an experimental data set. (In the example pseudocode below, we use a Python-based syntax for concreteness, but this could be implemented in any statistical analysis software or framework, like R or Julia or even Excel spreadsheets.)</p><pre><code>def&nbsp;model(strainplanted,&nbsp;soiltype,&nbsp;rainfall, cropyield):\n\t## Set parameter priors\n\tdeltayield ~ Normal(...)\n\tavgyield_control ~ Normal(...)\n\tavgyield_experimental&nbsp;~ Normal(avgield_control + deltayield, ...)\n\t\ud835\udefd_soiltype ~ Normal(...)\n\t\ud835\udefd_rainfall ~ Normal(...)\n\t...\n\n\t## Define likelihood of the target variable cropyield given the covariates and parameters:\n\t## p(cropyield | strainplanted, soiltype, rainfall, ...params)\n\twith&nbsp;field = plate(\"field\"):\n\t\twith&nbsp;t = plate(\"t\"):\n\t\t\tbaseyield = avgyield_control&nbsp;if&nbsp;strainplanted ==&nbsp;\"control\"&nbsp;else&nbsp;avgyield_experimental\n\t\t\tsoiltype_effect = \ud835\udefd_soiltype[soiltype]\n\t\t\trainfall_effect = \ud835\udefd_rainfall * rainfall\n\t\t\tcropyield ~ Normal(\ud835\udefc_yield + \ud835\udefd_soiltype + \ud835\udefd_rainfall)</code></pre><p>&nbsp;</p><figure class=\"table\" style=\"height:435.739px;width:656.001px\"><table style=\"border:1px double rgb(179, 179, 179)\"><thead><tr><th style=\"background-color:rgb(204, 204, 204);border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\"><strong>field</strong></th><th style=\"background-color:rgb(204, 204, 204);border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\"><strong>t</strong></th><th style=\"background-color:rgb(204, 204, 204);border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\"><strong>strainplanted</strong></th><th style=\"background-color:rgb(204, 204, 204);border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\"><strong>soiltype</strong></th><th style=\"background-color:rgb(204, 204, 204);border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\"><strong>rainfall</strong></th><th style=\"background-color:rgb(204, 204, 204);border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\"><strong>cropyield</strong></th></tr></thead><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">Martha\u2019s Meadow</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">2023</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">control</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">good</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">0.5</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">20</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">Martha\u2019s Meadow</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">2024</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">control</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">good</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">0.4</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">18</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">Ada\u2019s Acres</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">2023</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">control</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">bad</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">0.8</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">15</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">Ada\u2019s Acres</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">2024</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">control</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">bad</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">0.1</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">12</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">Peter\u2019s Patch</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">2023</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">experimental</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">good</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">0.4</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">35</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">Peter\u2019s Patch</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">2024</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">experimental</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">good</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">0.4</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">41</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">Lee\u2019s Lot</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">2023</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">experimental</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">bad</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">0.1</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">33</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">Lee\u2019s Lot</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">2024</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">experimental</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">bad</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">0.2</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\">34</td></tr></tbody></table></figure><p>Like most scientific analyses, this is a hierarchical model, where your local variables represent observations or states of the current context \u2013 say, the yield in each given season and field \u2013 and are influenced by&nbsp;<i>parameters</i> that represent more generic or abstract variables \u2013 average yield for your strain across all fields and seasons, which in turn depends on the expected yield improvement from a given genomics technique. (The latter is generic enough that it\u2019s not really specific to your study, which is why it\u2019s highlighted in orange below.)</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/rbd1qsdh6143k4gigryv\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/qj9ykhl5oylj8q09ai7z 148w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/t4ox4lagk1svazp9srsf 228w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/cemktwpoemn3mkroj8hy 308w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/igqmbw0ghcvuuvgcqoxj 388w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/xnf0khsemj4pdfghfo9n 468w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/y9dz96hevakf6htl5zzp 548w\"></figure><p>Running this model on a data set can be understood as propagating information through the graph. First, the priors for the parameters inform the expected distributions for the local variables. Then as we gather observations for some variables, that information flows back up, giving updated posteriors for the parameters. The amount of information (uncertainty reduction or negentropy) being propagated can be understood as a flow on this graph<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9icmii9b7wi\"><sup><a href=\"#fn9icmii9b7wi\">[2]</a></sup></span>&nbsp;and indeed can be estimated as an output of many kinds of common inference algorithms.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefeyn4v0kx0v\"><sup><a href=\"#fneyn4v0kx0v\">[3]</a></sup></span></p><p>It\u2019s really useful to think informally of the&nbsp;<i>free energy</i> of the model as the discrepancy between the inferred distribution and the information we have available, between priors and observations.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhkvdsi6i6sr\"><sup><a href=\"#fnhkvdsi6i6sr\">[4]</a></sup></span>&nbsp;Zero free energy is the ideal state in which all information has been fully incorporated into the inference, is completely internally consistent, and explains away all the uncertainty in the system. Typically we can\u2019t achieve zero free energy, as there\u2019s always some uncertainty (whether aleatoric or epistemic), but we want to minimize it so that our model doesn\u2019t have \u201cextra\u201d, unwarranted uncertainty. To get a better understanding of the concept of free energy and its role in Bayesian modeling and active inference, there are many excellent resources available; we particularly recommend&nbsp;<a href=\"https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008420\"><u>this paper by Gottwald and Braun</u></a>. Going forward, you can just think of Free Energy Reduction (FER) as a standard unit of account used by each model.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/m38k6k14oprafg6tjvpz\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/u9qwx1bvdy7rfbevdkdb 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/gymqsxfbeluzkqrqvt9e 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/qetuce6akigygnjgiqqc 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/ysjf60jlcnofeng9215s 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/d7megge6yj7e1c7nmxxd 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/u5m9sty9krznje2opzy1 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/mfvw09u1mdy559guszi1 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/pneb29wpxfz07hekogml 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/ja8vawourhdo4kf7h2xf 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/azdfz6qodaqswpytg9rw 873w\"><figcaption><i>Source:&nbsp;</i><a href=\"https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008420\"><i><u>Gottwald and Braun (2020)</u></i></a></figcaption></figure><p>But here\u2019s a problem: How do you set priors for your parameters in the first place? Sure, you expect your strain to increase yield, but it would be circular reasoning to build that expectation into the priors. The common practice is to use a&nbsp;<i>flat prior</i> (also known as a weakly informative or regularization prior), that incorporates only information that you have an objective or incontrovertible reason to believe in (ex: penalizing unreasonably low or high values). This can be seen as \u201cnot sneaking information into the model\u201d, to avoid fooling yourself (and your stakeholders, the people who will use your study results to make decisions) by publishing unjustifiably confident results.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrzvj22kch3j\"><sup><a href=\"#fnrzvj22kch3j\">[5]</a></sup></span>&nbsp;However, typically, most parameters in your study do&nbsp;<i>not</i> represent hypotheses you\u2019re actively trying to learn about; instead, they represent assumptions that&nbsp;<i>are&nbsp;</i>justified by previous studies or expert opinions. For those, you want the opposite kind of prior, a&nbsp;<i>sharp&nbsp;</i>or&nbsp;<i>strong prior.</i></p><p>In the past, if you were very lucky, there would be a published meta-analysis about the parameters for each of your assumptions, to save you the pain of combing through thousands of PDFs, understanding each, and copy-pasting numbers from the relevant tables into your workspace. Unfortunately, this work was so mind-numbingly boring, expensive, thankless and error-prone, that high-quality meta-analyses were exceedingly rare.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrzle3zs36vc\"><sup><a href=\"#fnrzle3zs36vc\">[6]</a></sup></span>&nbsp;To make matters worse, unlike the toy example above, real-world scientific models often utilize hundreds to thousands of parameters, and often far more if machine learning is used. Gathering the outputs of every relevant study for every relevant parameter, by hand, was infeasible, so we ended up with constant wheel reinvention and cargo-culted, unjustified assumptions, often used as point estimates with no uncertainty attached.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8pcjc299jvv\"><sup><a href=\"#fn8pcjc299jvv\">[7]</a></sup></span></p><p>No longer: now you can simply connect your local model to the Gaia Network by annotating each parameter (in our example, average yield and drought tolerance, for both the control group of traditional maize and the experimental group of genetically modified maize). Your annotation attaches each parameter to a global namespace called the Gaia Ontology. You can browse the Ontology to see the exact definition of the parameter, with example code, and make sure you\u2019re using the right one. Many other scientists have published their studies on the Gaia Network; each published study contributes a posterior distribution for its parameters, and these are algorithmically aggregated into a \u201csort of weighted average\u201d called a&nbsp;<i>pooled distribution.</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefytqoes1e0xm\"><sup><a href=\"#fnytqoes1e0xm\">[8]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2422nvskptn\"><sup><a href=\"#fn2422nvskptn\">[9]</a></sup></span></p><p>So at inference time, the Gaia engine just queries the network for the current pooled distributions for each of these parameters \u2013 effectively conducting a meta-analysis on the fly \u2013 and adopts them as priors.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreff19kf5qzglm\"><sup><a href=\"#fnf19kf5qzglm\">[10]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpkfiq27rnw\"><sup><a href=\"#fnpkfiq27rnw\">[11]</a></sup></span></p><pre><code>@gaia_bind(deltayield={\"v0.Agronomy.YieldImprovementPct\":\n\t\t\t\t\t\t{\"species\":\"v0.Agronomy.Species.Maize\",\n\t\t\t\t\t\t\"intervention\":\"v0.Agronomy.Genomics.CRISPR\"}})\ndef&nbsp;model(strainplanted,&nbsp;soiltype,&nbsp;rainfall, cropyield):\n\t## Model code is unchanged</code></pre><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/grsobms8slxx6r4hwpzx\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/libjizeruqwhqrxuyf5f 134w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/ocdrzycpyxhkt6kmukyy 214w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/foakgonn77kamhyowph2 294w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/f39uzfcidx2nr4jscmse 374w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/y0dy2p8eylt5iq0gqzv1 454w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/k8pxy9xlefaqzuu8qbwe 534w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/wowkogoqw81vtkkiw4kp 614w\"></figure><p>As the illustration above shows, your model is importing information from other studies in the network and using it to increase FER. Gaia keeps track of the \u201c<a href=\"https://stats.stackexchange.com/questions/421741/what-is-the-credit-assignment-problem-in-machine-learning-and-deep-learning\"><u>credit assignment</u></a>\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4lxnrlzup9n\"><sup><a href=\"#fn4lxnrlzup9n\">[12]</a></sup></span>, which will prove valuable starting in the next step, which is to publish your work.</p><p>To contribute to the network, all you have to do is commit your study to GitHub. Gaia will save your posterior distributions for all parameters that you\u2019ve annotated, and share them back with every other study in the network. Your study and your peer studies each have an&nbsp;<i>update chain</i>, an append-only sequence of distributions representing the state of posteriors from each study\u2019s perspective. These are effectively independent representations of the state of knowledge of the parameters in question.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjz02dtut28r\"><sup><a href=\"#fnjz02dtut28r\">[13]</a></sup></span></p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/lve0zrrbhxilaeo2wrbd\"></p><p>So, immediately you can see that any other agricultural studies about different experimental strains will have their posteriors affected by adding your study to the pool of updates.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdeief0bji8f\"><sup><a href=\"#fndeief0bji8f\">[14]</a></sup></span>&nbsp;This effect can be quite large if few studies are being pooled, but it converges, so that after some point the updates become minimal.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreff5knx1lgsqj\"><sup><a href=\"#fnf5knx1lgsqj\">[15]</a></sup></span></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/gfkoqxzby2kcbbtksayg\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/jxpdz4egda6yr0mtkg8n 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/uc4lglj7rgx13namk2q4 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/xbomlztzzn9hhmezoble 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/hwbjih79ok37sl6mhuwa 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/jyqcuhbm43x0exay2gdi 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/qpughoeb1pnshkhtrl19 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/v88rwasqpvl7gjyctk6u 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/ghomby3z459ztcslreiv 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/h5xbtx64byt1jzldtiie 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/jmvvr35fjoabyenpnuxj 891w\"></figure><p>But Gaia doesn\u2019t just propagate posterior updates to \u201csibling\u201d studies: If there are higher-level models for which your parameter is a leaf, it will propagate up to those as well. For instance, a model that forecasts advances in crop technology and their impact on global food security:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/uc8hfavuzc2sft2l4b1r\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/pirhpjseifd4u8prvgey 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/gl1ohlkubhkh0ndhugmq 200w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/gfbrpscceemzcw022tif 280w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/qzcdbnqygfgkbapi67jj 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/cbijufwoh9hd4obwpjtp 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/clutohdfi4ovgr7zosyq 520w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/bci1d0voly9cbutylxdu 600w\"></figure><p>Note that, by publishing your model on the Network, you\u2019re&nbsp;<i>not</i> exporting any information other than updates to the values of the specific parameters that you\u2019ve connected \u2013 in particular, you\u2019re not sharing any of the underlying data. (This is a \u201cprivacy-centric\u201d inference approach, analogous to&nbsp;<a href=\"https://en.wikipedia.org/wiki/Federated_learning\"><u>federated learning</u></a>. In a follow-up article, we\u2019ll discuss how we can solve the problems of trust that this imposes.)</p><p>As mentioned above, the Gaia Protocol assigns credit to every publication (also called attribution). The mechanism for attribution is primarily \u201csubjective\u201d: each node (ie, each study) just measures the net FER impact of each contribution as it\u2019s incorporated into its own update chain.</p><p>Above, we mentioned that the pooled distribution is a \u201csort of&nbsp;<strong>weighted</strong>\u201d average between each study\u2019s posterior. So where do the weights come from? The Gaia Protocol also answers this question in a bottom-up, \u201csubjective\u201d way. Nodes can independently infer the \u201cright\u201d weights for each parameter and study. To do so, they can use arbitrary \u201cmetamodels\u201d, ranging from simple \u201cbeauty contest\u201d models that just aggregate the net FER impact that&nbsp;<i>other&nbsp;</i>studies have attributed to a contribution, to \u201cweb of trust\u201d models that try to factor out more sophisticated ones that infer the presence of low-quality studies or deliberate fraud via social-type network analysis; to true \u201cmetamodels\u201d that infer study quality and parameter relevance, using outside data such as the publisher\u2019s credentials, analyses of the model code and third-party verifications of the data. This means that, at least in the short term, the pooled distribution for a given parameter is actually different depending on which node you ask! Even if all nodes have seen all the updates in the same order, they can give arbitrarily different weights to them. But as the different metamodels themselves accumulate quality signals, nodes eventually converge on a shared inference of the right metamodel to use on which kind of parameter. (As discussed in the introduction, we will not attempt to justify the claim that this protocol converges and is resilient to noise and misinformation/fraud. For now, see the arguments&nbsp;<a href=\"https://www.lesswrong.com/posts/AKBkDNeFLZxaMqjQG/gaia-network-a-practical-incremental-pathway-to-open-agency#:~:text=anti%2Dcollusion%20mechanisms.-,The%20convergence%20and%20resilience%20arguments,-Will%20Gaia%20do\"><u>here</u></a>.)</p><h2>Funding science \u2013 retroactively and prospectively</h2><p>Now approaching this from the opposite perspective, say you're an analyst at a philanthropic foundation, trying to make recommendations for a prize that will be awarded to the most impactful scientific studies. Rather than solely rely on recommendations from the scientific community, or use \u201cimpact factors\u201d that just measure popularity, you can query the Gaia Network to get quantitative, apples-to-apples impact metrics.</p><p>First, we should just note that being able to understand the \u201cgraph of science\u201d in a live, transparent way \u2013 what are the research questions, how well developed, how much intensity in explore vs exploit mode, and how they connect to each other \u2013 is a game-changer. In the past, you needed to pay expensive fees for products like Web of Science and Scopus, which were based on manual curation and benefitted from the opaqueness of text-on-PDFs as the primary means of scientific communication. Having all the world\u2019s science directly represented as machine-readable and connected models on Gaia \u2013 just like code and its dependencies on a package manager \u2013 makes all analytics orders of magnitude easier.</p><p>Now, back to the question of impact. Here we should distinguish two kinds of impact: epistemic impact - how much a given study has contributed to reducing uncertainty in the Network; and pragmatic impact - how much it has contributed to improving decisions. We\u2019ll leave the pragmatic impact for later and focus on the epistemic impact for now.</p><p>So, for every model on the network, it\u2019s easy to compute how much it contributed to FER flow across the network \u2013 what\u2019s called credit assignment in neural networks. We just look at the net flow across the model boundary, which is accounted by the Gaia Protocol:</p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/arz6pedruuxg1gugxsc9\"></p><p>Some care needs to be taken here. First of all, note that the FER credited to a model due to its contributions is always computed by the model that\u2019s&nbsp;<i>receiving</i> the contributions (it\u2019s a&nbsp;<i>subjective&nbsp;</i>value). Plus, there might be significant differences in modeling practices between different fields, which may distort calculations. Later on, when we talk about economics, we\u2019ll see that the Protocol also needs a way to turn that subjective value accounting into intersubjective, mutually agreed upon \u201clocal exchange rates\u201d. For now, let\u2019s say that you compute a normalization constant for each domain and use it to get a normalized, apples-to-apples net FER flow across domains.</p><p>So this covers&nbsp;<a href=\"https://eightify.app/summary/economics-and-finance/retroactive-public-goods-funding-by-jonas-seiferth#:~:text=TLDR%20Retroactive%20public%20goods%20funding,instead%20of%20worrying%20about%20funding.\"><u>retroactive funding</u></a> in the form of prizes. But this isn\u2019t (and shouldn\u2019t be) how most science gets funded. Most researchers cannot internalize the risk and cost of self-funding their work upfront and hoping for retroactive funding later. Instead, funders \u2013 who have access to cheaper capital costs, lower marginal risk sensitivity, and the other advantages that come with a big pile of cash \u2013 contract with researchers upfront to trade capital now for a future flow of impact. Before the Gaia Network, establishing effective contracts was very challenging, as it was extremely hard to predict impact, even for the researchers themselves, let alone for the funders. (In economic parlance, it was a classic agent-principal problem created by uncertainty and information asymmetry.) Now, the Gaia Network itself provides the solution: it contains&nbsp;<i>metascience models&nbsp;</i>that model the flow of FER across the network and use it to design interventions \u2013 adding more models and more data to specific fields and individual lines of research \u2013 that are likely to deliver the highest future flow of FER. Funders and researchers can use these models equally to guide where they should spend the most time and resources.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefr5ncudjafqi\"><sup><a href=\"#fnr5ncudjafqi\">[16]</a></sup></span>&nbsp;Compared with the recent past, where there were no meaningful metrics of scientific productivity or value added, let alone predictive models of how to improve these, the Gaia Network is a game-changer for science funding.</p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/z6ztg89ffz3m7ercmext\"></p><h2>A distributed oracle for decision-making</h2><p>The above covers the advancement of science. However, the same capabilities can aid&nbsp;<i>any</i> decision-making that pertains to the real world<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb4n7xij87b\"><sup><a href=\"#fnb4n7xij87b\">[17]</a></sup></span>&nbsp;\u2013 what we\u2019ve called pragmatic impact above. Indeed, the Gaia Network has given everyone an actionable, reliable way to \u201ctrust the science\u201d \u2013 not just on big things like climate change and pandemics, but also on day-to-day things like your diet, exercise, relationships, and so on. And the same applies to business decision-making, which is where we\u2019ll focus next.</p><p>Say you manage Ada\u2019s Acres, a large farming operation in the US Midwest. You\u2019re planning your next planting for your 30 thousand hectares, and as usual, your suppliers are trying to push you new seeds, new herbicides and all manner of hardware and software. Meanwhile, your usual buyers are all calling to let you know that global demand forecasts are through the roof, so you stand to gain a lot of money if you have an outstanding harvest. However, you\u2019ve noticed that the soil has been increasingly poor and in need of fertilizer and that herbicide resistance has increased a lot as well. The weather has been increasingly volatile, and you know it\u2019s a matter of time before you have a major crop failure. Maybe it\u2019s time to start giving regenerative farming a real shot?</p><p>Luckily, your farm operations software is now connected to the Gaia Network. It gives you a predictive digital twin of your farm that directly learns not just from every scientific experiment in agronomy, but from the \u201cnatural experiments\u201d carried out by every other farm that uses the Network. So you can simulate the effects of any combination of practices, seed strains and products and estimate the outcomes, both short-term (expected yield and probability of crop failure for the next harvest) and long-term (soil health and herbicide resistance).</p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/watgmozhrsnc7ayfw5xb\"></p><p>So that was a \u201csmall\u201d (operational) use case. Now let\u2019s zoom out to strategy<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmwp73vgir6e\"><sup><a href=\"#fnmwp73vgir6e\">[18]</a></sup></span>: let\u2019s say that you\u2019re the CEO of Acme Foods, a major food company. In light of increased droughts and crop failures, you\u2019re trying to invest in your supply chain to minimize the risk of supply shortages. Your innovation teams have aggregated a long list of potential investments in precision farming, genomics, and regenerative agriculture. In the past, assembling an investment portfolio out of that long list would have required a long, expensive and very political negotiation exercise. Now that all your suppliers are connected to the Gaia Network and share limited access with you, your portfolio management system becomes a distributed digital twin of your supply chain. You can run complex distributed queries across all the nodes, simulate the effects of different investment combinations and different sets of assumptions (like climate and pest spread scenarios), factor in things like unintended consequences, and pull out an aggregate like a Pareto frontier for the investment profile you want.</p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/uloskbuzvymdxkljzgqi\"></p><p>Most of the demand for the intelligence in the Gaia Network will come from these&nbsp;<i>decision engines</i> (DEs), like the farm operations software and the portfolio management system. Combined with the ability of the Protocol to assign credit where it\u2019s due, it can provide signals and incentives to provide a better&nbsp;<i>supply</i> of intelligence: more and better models in the places where they are most needed by decision-makers. In a future paper, we will further develop our vision of how these signals can be developed into a complete market and contracting mechanism for directing applied research, exploration and analysis: what we call the&nbsp;<i>knowledge economy</i>.</p><p>Even further, if we have \u201cnon-local\u201d DEs that use Gaia models to design coordinated strategies that internalize the benefits of cooperation between multiple agents, then we can turn those DEs into Gaia models themselves! They become&nbsp;<i>decision models</i> performing \u201c<a href=\"https://www.sciencedirect.com/science/article/pii/S1364661312001957\"><u>planning as inference</u></a>\u201d on behalf of agents (individuals and collectives), helping to solve&nbsp;<i>all kinds of principal-agent problems</i>. In the example above, the food company can use a DE not only to infer the best investments for its own goals but also to design adequate contracts and incentives that will best equalize the goals and constraints of all the players in the supply chain. This&nbsp;<i>delegation economy&nbsp;</i>will also be further explored in a future paper.</p><h2>A distributed oracle for AI safety</h2><p>The above discussion of decision-making is our link to AI safety. Yoshua Bengio&nbsp;<a href=\"https://slideslive.com/39014230/towards-quantitative-safety-guarantees-and-alignment\"><u>has proposed</u></a> to tackle AI safety by building an \u201cAI scientist\u201d \u2013 a comprehensive probabilistic world model that would serve as a universal gatekeeper to evaluate the safety of&nbsp;<i>every</i> high-stakes action from&nbsp;<i>every</i> AI agent, instead of attempting to design safety&nbsp;<i>into</i> agents. This is similar to Davidad\u2019s&nbsp;<a href=\"https://www.lesswrong.com/posts/jRf4WENQnhssCb6mJ/davidad-s-bold-plan-for-alignment-an-in-depth-explanation\"><u>Open Agency Architecture</u></a> (OAA) proposal. But of course, developing such a monolithic, centralized and comprehensive gatekeeper from scratch<i>&nbsp;</i>would be an extremely costly and lengthy undertaking. Further, as Bengio\u2019s proposal makes clear, the AI scientist needs to have \u201cepistemic humility\u201d: its evaluations need to incorporate the limitations and uncertainty of its own model so that it doesn\u2019t confidently allow actions that seem safe at the time but turn out to be unsafe in retrospect.</p><p>We argue that the Gaia Network, including the DEs that work as decision models, qualifies perfectly for the job of a distributed AI scientist. The DEs can query the diverse and constantly evolving knowledge in the network to form an \u201ceffective world model\u201d with epistemic humility built in. They can provide the demand signals and resources to improve and expand the world model. They can then use this model to simulate counterfactual outcomes of actions that take into account all available local context and dependencies between contexts, and use these simulations to approximately estimate probabilities for outcomes (marginalization). They can factor in the preferences and safety constraints of all agents that use the Network, which they have already shared in order to enable the DEs to help with their own decisions. This gives all the terms in Bengio\u2019s notional risk evaluation formula (adapted from&nbsp;<a href=\"https://slideslive.com/39014230/towards-quantitative-safety-guarantees-and-alignment\"><u>slide 17 here</u></a>):</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/zf21ykvwhoanekefddeg\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/vqjyobf9ddnukuzn74ch 85w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/i4ugubpqadrim6pnuucg 165w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/nmoaiw70ulyhvzyuyjpr 245w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/f57yjakfftiygpbsrmcy 325w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/lgvoqqwk20njdxanc5c1 405w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/lurvs2bqgeomgj1onmq2 485w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/lqrddc1scbm8i3bsa2mh 565w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/limu60swszzqgboaneoa 645w\"></figure><p>Possibly the most important aspect of this design \u2013 which comes particularly to light when comparing it to the OAA design \u2013 is that&nbsp;<i>none of the above components is specific to AI safety</i>; they are just repurposed from existing and day-to-day use cases for which the users/agents already have the incentives to share the required information with the Gaia Network and the DEs. This means that tackling AI safety is no longer \u201c<a href=\"https://www.lesswrong.com/posts/jRf4WENQnhssCb6mJ/davidad-s-bold-plan-for-alignment-an-in-depth-explanation#:~:text=one%20of%20the%20most%20ambitious%20scientific%20projects%20in%20human%20history\"><u>one of the most ambitious scientific projects in human history</u></a>\u201d, but rather a \u201cfringe benefit\u201d from our pursuit of knowledge and better decision-making. And which, in turn, benefits from all improvements to the efficiency and effectiveness of those pursuits that have already been produced by past and ongoing advances in computational statistics and machine learning \u2013 and all that will be generated by the Gaia Network connecting and interoperating the many millions of such models in existence, and increasing the RoI of creating and improving models.</p><p>This outcome is not dependent on AI safety funders; nor the foibles of political will in the scientific and policy communities; nor the desire of billions of humans to independently share their preferences with an elicitor. All that is required \u2013 beyond some cheap work on core infrastructure, modeling and developer experience \u2013 is the same economic behaviors and incentives that exist today: the desire for profit, the pursuit of greater scientific knowledge, and the existence of institutions willing and able to internalize the cost of coordinated action.</p><p>An overview of this architecture, adapted from our&nbsp;<a href=\"https://www.lesswrong.com/posts/AKBkDNeFLZxaMqjQG/gaia-network-a-practical-incremental-pathway-to-open-agency\"><u>last post</u></a>, is given below.</p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/s4rbqgrroouj0g0j60rx\"></p><h2>A distributed oracle for the Metacrisis</h2><p>The very same architecture helps us identify shared pathways through the Metacrisis. Below is a nice visual of the high-level causal model we have in mind when thinking about the Gaia Network\u2019s role. By connecting all the relevant domain models and making apparent not only their interdependencies but also their common causes \u2013 the \u201cgenerator functions\u201d or underlying self-reinforcing dynamics \u2013 Gaia helps us understand likely future outcomes of the current trends and establish strategies with the highest potential for nudging our global course away from the two catastrophic attractors that currently seem most likely (chaos and totalitarianism). Not only that, but as we\u2019ve seen, Gaia-powered DEs are also used as&nbsp;<i>coordination surfaces:&nbsp;</i>shared tools for establishing and monitoring contracts, treaties and institutions, with unprecedented scale and reliability. While this \u201cinfrastructure for model-augmented wisdom\u201d doesn\u2019t immediately or inherently solve conflicts of power and interests, it does provide a consistent, repeatable and scalable&nbsp;<i>institution</i> for achieving and retaining incremental advances towards a positive-sum, cooperative&nbsp;<a href=\"https://rkauf.medium.com/the-gaia-attractor-41e5af33f3b7\"><u>Gaia Attractor</u></a>.</p><p>&nbsp; &nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/nb17fpkyhmahmsit3mev\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/whamm0u0fpbd4lflhpjy 90w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/hbwuxx3xfkzyllkroo9e 180w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/fog8j5w4drrwdndxup6w 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/pircgzuyfzobvdy45etr 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/gpharevqtg77thovephx 450w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/ljornr7bbkd1tys2x1up 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/wdsmig0kw25fxlbimwjn 630w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/vr8hzpru530drouaquog 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/epmgdvfig5n9kfrouhqg 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/TK92QZ8L6cXvvhXbF/qodlbqtzngvn3v847wio 820w\"><figcaption>Source: Adapted from Potentialism, via&nbsp;<a href=\"https://www.sloww.co/meta-crisis-101/\"><u>Sloww</u></a></figcaption></figure><h2>Conclusion: Back from the future</h2><p>We just claimed that <i>a lot</i> will change in \u201ca few years from now\u201d. How realistic is this? Here\u2019s the&nbsp;<i>really&nbsp;</i>good news: all the capabilities described above can be implemented with today\u2019s technology.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwkk5haeky7r\"><sup><a href=\"#fnwkk5haeky7r\">[19]</a></sup></span>&nbsp;Not only that: we\u2019re already doing it. We have assembled several organizations and individuals into a growing&nbsp;<a href=\"https://gaiaconsortium.org/\"><u>Gaia Consortium</u></a>, and have of course been leveraging loads of existing components and building some of our own. Examples:</p><ul><li><a href=\"https://oceanprotocol.com/\"><u>Ocean Protocol</u></a> and&nbsp;<a href=\"https://source.network/defra-db\"><u>DefraDB</u></a>: Decentralized computing and data management.</li><li>Fangorn (coming soon): a decentralized platform for building and performing (active) inference on Gaia-connected state space models.</li><li><a href=\"https://www.sentient-hubs.com/\"><u>Sentient Hubs</u></a>: Federated model-based decision support.</li></ul><p>We are simultaneously working on specific applications of the Gaia Network, focusing primarily on bioregional economies and sustainable supply chains. These have been useful for providing concrete use cases (some of which we saw above) and resourcing. But ultimately we intend to evolve this into a fully open and collaborative R&amp;D effort to build the general-purpose capabilities described above.</p><p>If you\u2019re interested in contributing to this work, here are some possible ways to do it:</p><ul><li><strong>People interested in developing this agenda with us should sign up for the upcoming </strong><a href=\"https://sparai.notion.site/Supervised-Program-for-Alignment-Research-SPAR-4da6be132e974823961abfdd0c218536\"><strong>SPAR program</strong></a><strong>.</strong> We\u2019re advising two projects: one centers on <a href=\"https://airtable.com/embed/appYIr2qJDA2k0H9V/shrl8GPTKgVay33st/tblcUzakXN65z6xs7/viwxbiWJw4AuTVV6w/recPccdlmTwlHd5qG?backgroundColor=yellow&amp;viewControls=on\">formalizing and computationally testing the use of free energy-based causal models for measuring AI safety</a> in real-world, <a href=\"https://www.lesswrong.com/tag/embedded-agency\">embedded</a> environments; the other is about outstanding <a href=\"https://airtable.com/embed/appYIr2qJDA2k0H9V/shrl8GPTKgVay33st/tblcUzakXN65z6xs7/viwxbiWJw4AuTVV6w/recDHCgVdw4Uykq6z?backgroundColor=yellow&amp;viewControls=on\">mechanism design, engineering, economics, governance, (and perhaps even ethical) issues of the Gaia Network</a>.</li><li>If you\u2019d like to&nbsp;<i>use&nbsp;</i>the Gaia Network (or its precursors) in your own use cases, we can happily support standing up \u201ctestnets\u201d and help design prototypes and proofs of concepts.</li><li>If you have resources to help accelerate development, we can gladly accept grant funding or other forms of support.</li></ul><p>If you\u2019re interested in any of the above, please reach out!</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbwdl46ujz6c\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbwdl46ujz6c\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Below, Gaia Network and its applications are described both in present and future tense in different narration modes. To avoid confusion, note that Gaia Network is <i>not</i> yet implemented and deployed on a large scale.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9icmii9b7wi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9icmii9b7wi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In a simple structure like this, a single backward propagation is enough, but there are cases where we need to iteratively update (message passing). For those cases, think of the net flow that is obtained after propagating up and down enough times.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fneyn4v0kx0v\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefeyn4v0kx0v\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For instance, in variational inference algorithms, the free energy (or stochastic estimates of it) is directly used as a minimization objective. Equivalently, its negative, the Evidence Lower Bound [ELBO], is maximized.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhkvdsi6i6sr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhkvdsi6i6sr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There is an additional concept of free energy associated with decision-making, corresponding to the discrepancy between the veridical posterior justified by priors and observations and the one \u201cdesired\u201d in light of a given reward function/model/distribution.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrzvj22kch3j\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrzvj22kch3j\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If you already have information that comes from past experiments, or knowledge elicited by independent experts, you <i>can</i> also incorporate it into the priors. The challenge is how to keep track of the grounding behind all of this imported information. This is, in a sense, what the Gaia Network does algorithmically, as we\u2019ll see.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrzle3zs36vc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrzle3zs36vc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See <a href=\"https://meta-analysis.com/download/criticismsofmeta-analysis.pdf\"><u>Criticisms of Meta-Analysis</u></a>; <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC122061/\"><u>Meta-analysis: Neither quick nor easy</u></a>;&nbsp; <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0020138322004235\"><u>Meta-analysis. What have we learned?</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8pcjc299jvv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8pcjc299jvv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Even for the parameters of interest in your study, there is a high value in having access to past studies\u2019 posteriors: after having your posteriors \u201cin isolation\u201d, you now want to compare them to previous results in the literature, to check for novelty or consistency.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnytqoes1e0xm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefytqoes1e0xm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Technically, a pooled distribution is not a weighted average of <i>distributions</i> (that would be a <a href=\"https://en.wikipedia.org/wiki/Mixture_distribution\"><u>mixture distribution</u></a>); instead, it\u2019s a distribution whose <i>parameters</i> are a weighted average (or other combination) of the parameters of the original distributions. Just so we\u2019re clear: here we\u2019re talking about statistical parameters of the posteriors of scientific parameters; for instance, the mean and variance of the average yield.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2422nvskptn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2422nvskptn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In practice, different studies often use different model structures and local ontologies. Sometimes these are just syntax differences, such as alternative parameterizations (ex: centered vs uncentered parameters, etc), but often they represent different semantics \u2013 different statistical constructs, reflecting differences in context and/or scientific methodology. To enable aggregations to happen between models with these differences, translations are required. To this end, Gaia contributors often publish <i>lens models</i> that perform data translation. As an added benefit of this approach, in cases when there are different semantics that inevitably lead to a loss in translation (as WVO Quine pointed out and Chris Fields has recently formalized), it\u2019s useful for there to be a separate lens model that accounts for and \u201cabsorbs\u201d that loss.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnf19kf5qzglm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreff19kf5qzglm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This does mean your model is colored by using the informative Gaia posteriors as priors for a parameter of interest. But you can always turn off the annotations for those parameters to isolate the effects of the information contributed by your study (aka the likelihood).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpkfiq27rnw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpkfiq27rnw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In this example, these are independent scalar parameters, but they could be any multidimensional array with any kind of internal correlation structure.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4lxnrlzup9n\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4lxnrlzup9n\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See also \"<a href=\"https://www.lesswrong.com/posts/Ajcq9xWi2fmgn8RBJ/the-credit-assignment-problem\">The Credit Assignment Problem</a>\" by Abarm Demsky.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjz02dtut28r\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjz02dtut28r\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is unlike a blockchain, which is designed to ensure that all nodes are \u201calmost always\u201d in full consensus about the entire contents of the global state (which then requires hacks like \u201cL2\u201d chains to improve speed and flexibility).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndeief0bji8f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdeief0bji8f\">^</a></strong></sup></span><div class=\"footnote-content\"><p>How? It depends on the parameterization used, but in most cases, partial pooling brings posterior means closer together. You can have parameterizations with multiple modes, like a Gaussian mixture distribution, but this tends to imply that your parameter is representing multiple categories instead of a scalar and should be changed to reflect that.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnf5knx1lgsqj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreff5knx1lgsqj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>No matter how small, Gaia eventually propagates every nonzero update to every parameter on the network, so we can have eventual consistency. The protocol can choose to batch small updates for efficiency.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnr5ncudjafqi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefr5ncudjafqi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Of course, no one cares about an abstract quantity like FER; they care about concrete advancements in specific areas of science. But that\u2019s the same as saying no one cares about money, but about the goods and services they can buy with it.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb4n7xij87b\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb4n7xij87b\">^</a></strong></sup></span><div class=\"footnote-content\"><p>That primarily means we\u2019re excluding \u201cteach AI how to play video games\u201d or \u201cdecide which next token to generate for a user\u201d types of scenarios.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmwp73vgir6e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmwp73vgir6e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We could zoom even further out to tackle the domains of strategy consulting, and ask more \u201cmeta\u201d questions. What are the theories of change, how do they connect to each other, how well developed, and how much intensity is in explore vs exploit mode? We will explore these further in a follow-up article.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwkk5haeky7r\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwkk5haeky7r\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There are some areas where current solutions aren\u2019t fully adequate, but these are matters of incremental progress, not qualitative breakthroughs.</p></div></li></ol>", "user": {"username": "Roman Leventov"}}, {"_id": "6jDbsGSFEGTnnFBeD", "title": "Workshop (hackathon, residence program, etc.) about for-profit AI Safety projects?", "postedAt": "2024-01-26T09:49:31.410Z", "htmlBody": "", "user": {"username": "Roman Leventov"}}, {"_id": "vg3rxwcu7una8nSpr", "title": "Veganuary\u2019s impact has been huge \u2013 here are the stats to prove it", "postedAt": "2024-01-26T14:50:08.150Z", "htmlBody": "<p>For people short on time (like me), I\u2019ll point out this article brief, highly skimmable, and full of self-explanatory graphs. It also briefly explains reasons the researchers think Veganuary succeeds where similar efforts have failed (i.e., the time of year and social experience).</p>\n<p>At first glance, the evidence presented here seems quite impressive for near-term reductions in animal product consumption. However, it may not be as impactful as it initially seems (see the comments on this post).</p>\n<p>To the extent that it is effective, I\u2019m unsure whether it indicates significant moral circle expansion because many participants may already include farmed animals in their moral circle, meaning they aren\u2019t expanding their moral circle, but instead accepting the implications of their moral circle (which may be a distinction without a difference, as both produce equally-good long-term consequences).</p>\n", "user": {"username": "NicholasNicholas"}}, {"_id": "YmKgsg3PGyetiwnBA", "title": "Rounding Up Effectively at Supermarkets", "postedAt": "2024-01-26T01:13:36.783Z", "htmlBody": "<p>I assume most of us do not choose to round up our purchases for charity at supermarkets, pharmacies, and fast food restaurants when prompted to do so at checkout. Besides the less-than-highly-effective charities the extra change usually goes to, there could be philosophical or practical debate about the effectiveness of the practice itself as a format for giving.</p><p>However, surely there's a significant amount of money each year being diverted to various charities through this practice, most of which is counterfactual by <a href=\"https://forum.effectivealtruism.org/posts/nz2scND85oFyTXTGo/what-should-counterfactual-donation-mean\">most definitions.</a> (The rounded-up change probably wouldn't have gone to any charity otherwise, much less an effective charity).</p><p>I wonder how supermarkets select charities for the round up. What approach could be taken to change these to highly-effective charities? Which industries, companies, or executives would be open to conversation and how could they be approached? &nbsp;Is it worth the effort?</p>", "user": {"username": "dlipsitz@gmail.com"}}, {"_id": "nRWbwvABqykcMHyx5", "title": "Funding circle aimed at slowing down AI - looking for participants", "postedAt": "2024-01-25T23:58:49.638Z", "htmlBody": "<p>Are you an earn-to-giver or (aspiring) philanthropist who has&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/E6CahapSad7psvqx4/timelines-are-short-p-doom-is-high-a-global-stop-to-frontier\"><u>short AGI timelines and/or high p(doom|AGI)</u></a>? Do you want to discuss donation opportunities with others who share your goal of slowing down / pausing / stopping AI development<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq8r5ogayov\"><sup><a href=\"#fnq8r5ogayov\">[1]</a></sup></span>? If so, I want to hear from you!</p><p>For some context, I\u2019ve been extremely concerned about short-term AI x-risk since March 2023 (post-GPT-4), and have, since then, thought that&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/CpyAgKt4gRza7npYf/recruit-the-world-s-best-for-agi-alignment\"><u>more AI Safety research</u></a> will not be enough to save us (or AI Governance that isn\u2019t&nbsp;<a href=\"https://jaan.online/philanthropy/#:~:text=As%20of%20November%202023%2C%20my%20top%20priorities%20for%20reducing%20extinction%20risk%20from%20AI%20%E2%80%94%20priorities%20that%20in%20my%20opinion%20should%20eventually%20be%20upheld%20at%20the%20level%20of%20international%20treaty%20%E2%80%94%20are%20the%20following%3A\"><u>focused</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe8vsbqgf6za\"><sup><a href=\"#fne8vsbqgf6za\">[2]</a></sup></span>&nbsp;on slowing down AI or a global moratorium on further capabilities advances). Thus I think that on the margin far more resources need to be going into slowing down AI (there are already many dedicated funds for the wider space of AI Safety).</p><p>I posted this to an EA investing group in late April:<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/nRWbwvABqykcMHyx5/ihjurx12lkvou5a5sxh8\">And this -&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/8YXFaM9yHbhiJTPqp/agi-rising-why-we-are-in-a-new-era-of-acute-risk-and\"><u>AGI rising: why we are in a new era of acute risk and increasing public awareness, and what to do now</u></a> - to the EA Forum in early May. My p(doom|AGI) is ~90% as things stand (<a href=\"https://forum.effectivealtruism.org/posts/THogLaytmj3n8oGbD/p-doom-or-agi-is-high-why-the-default-outcome-of-agi-is-doom\"><u>Doom is default outcome of AGI</u></a>). But my p(doom) overall is ~50% by 2030, because I think there's a decent chance we can actually get a Stop<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpydg4m0gq7\"><sup><a href=\"#fnpydg4m0gq7\">[3]</a></sup></span>. My timelines are ~<a href=\"https://forum.effectivealtruism.org/posts/E6CahapSad7psvqx4/timelines-are-short-p-doom-is-high-a-global-stop-to-frontier#There_are_no_bottlenecks\"><u>0-5 years</u></a>:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/nRWbwvABqykcMHyx5/x6m5vne7pthf069fpijo\">I have donated&nbsp;<a href=\"https://twitter.com/gcolbourn/status/1727073332095582286\"><u>&gt;$150k</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefej4ujrbpevd\"><sup><a href=\"#fnej4ujrbpevd\">[4]</a></sup></span>&nbsp;to people and projects focused on slowing down AI since (mostly as kind of seed funding - to individuals, and projects so new they don\u2019t have official orgs yet<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnj37kgz6ikm\"><sup><a href=\"#fnnj37kgz6ikm\">[5]</a></sup></span>), but I want to do a lot more. Having people with me would be great for multiplying impact and also for my motivation!</p><p>I'm thinking 4-6 people, each committing ~$100k(+) over 2024, would be good. The idea would be to discuss donation opportunities in the \u201cslowing down AI\u201d space during a monthly call (e.g. Google Meet), and have an informal text chat for the group (e.g. Whatsapp or Messenger). Fostering a sense of unity of purpose<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefro2dkhorcng\"><sup><a href=\"#fnro2dkhorcng\">[6]</a></sup></span>, but nothing too demanding or official. Active, but low friction and low total time commitment. Donations would be made independently rather than from a pooled fund, but we can have some coordination to get \"win-wins\" based on any shared preferences of what to fund.&nbsp;<a href=\"https://www.metacharityfunders.com/\"><u>Meta-charity Funders</u></a> is a useful model.</p><p>We could maybe do something like an&nbsp;<a href=\"https://survivalandflourishing.fund/s-process.html\"><u>S-process</u></a> for coordination, like what Jaan Tallinn's&nbsp;<a href=\"https://survivalandflourishing.fund/\"><u>Survival and Flourishing Fund</u></a> does<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2s8adbeh6y\"><sup><a href=\"#fn2s8adbeh6y\">[7]</a></sup></span>; it helps avoid \"donor chicken\" situations. Or we could do something simpler like rank the value of donating successive marginal $10k amounts to each project. Or just stick to more qualitative discussion. This is all still to be determined by the group.</p><p>Please join me if you can<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgxae0f6e12\"><sup><a href=\"#fngxae0f6e12\">[8]</a></sup></span>, or share with others you think may be interested. Feel free to DM me here or on&nbsp;<a href=\"https://twitter.com/gcolbourn\"><u>X</u></a>, book a&nbsp;<a href=\"https://calendly.com/gcolbourn\"><u>call</u></a> with me, or fill in&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSegljN_T1WcZbwGs_kT5qKhprFILF6HdYAN8RGkKBjMdTWTcw/viewform\"><u>this form</u></a>.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq8r5ogayov\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq8r5ogayov\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;If you oppose AI for other reasons (e.g. ethics, job loss, copyright), as long as you are looking to fund strategies that aim to show results in the short term (say within a year), then I\u2019d be interested in you joining the circle.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne8vsbqgf6za\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe8vsbqgf6za\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I think Jaan Tallinn\u2019s new top priorities are great!</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpydg4m0gq7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpydg4m0gq7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;After 2030, if we have a Stop and are still here, we can keep kicking the can down the road..</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnej4ujrbpevd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefej4ujrbpevd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I\u2019ve made a few more donations since that tweet.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnj37kgz6ikm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnj37kgz6ikm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Public examples include&nbsp;<a href=\"https://manifund.org/projects/holly-elmore-organizing-people-for-a-frontier-ai-moratorium#:~:text=I%20received%20a%20one%20time%20gift%20from%20Greg%20Colbourn%20to%20cover%20two%20months%20of%20expenses\"><u>Holly Elmore</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/dfcXi8LC7MzjCSEfj/giving-away-copies-of-uncontrollable-by-darren-mckee\"><u>giving away copies of&nbsp;</u><i><u>Uncontrollable</u></i></a>, and&nbsp;<a href=\"https://manifund.org//projects/ai-planscom-?tab=comments#1559ff0e-cfcb-496b-b960-e3f9da4faac2\"><u>AI-Plans.com</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnro2dkhorcng\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefro2dkhorcng\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Right now I feel quite isolated making donations in this space.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2s8adbeh6y\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2s8adbeh6y\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;It's a little complicated, but here's a short description:&nbsp;\"Everyone individually decides how much value each project creates at various funding levels. We find an allocation of funds that\u2019s fair and maximises the funders\u2019 expressed preferences (using a number of somewhat dubious but probably not too terrible assumptions). Funders can adjust how much money they want to distribute after seeing everyone\u2019s evaluations, including fully pulling out.\" (paraphrased from&nbsp;<a href=\"https://www.lesswrong.com/posts/xQ4ajnzavSgbYiko2/launching-lightspeed-grants-apply-by-july-6th#fn8mrtl0h5ygu\"><u>Lightspeed Grants</u></a> [funders and evaluators would probably be the same people in our case, but we could outsource evaluation]). See&nbsp;<a href=\"https://www.lesswrong.com/posts/xQ4ajnzavSgbYiko2/launching-lightspeed-grants-apply-by-july-6th#fn8mrtl0h5ygu\"><u>link</u></a> (the footnote) for more detail.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngxae0f6e12\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgxae0f6e12\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If there is enough interest from people who want to contribute but can\u2019t stretch to $100k, we can look at other potential structures.</p></div></li></ol>", "user": {"username": "Greg_Colbourn"}}, {"_id": "Sp4LxukoReZEGzTdM", "title": "Stanford Humane & Sustainable Food Seminar is now open to public", "postedAt": "2024-01-25T22:10:13.973Z", "htmlBody": "<figure class=\"image image_resized\" style=\"width:45.91%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Sp4LxukoReZEGzTdM/jkpsvxt0c3tnang6ttvz\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Sp4LxukoReZEGzTdM/cgip8iavrkhd2udqthtx 140w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Sp4LxukoReZEGzTdM/ic0xprf83ai6dsf6zvoi 280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Sp4LxukoReZEGzTdM/nokcvxqfj4mt2qsckdgu 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Sp4LxukoReZEGzTdM/brikwxpoehvgj4mepgdu 560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Sp4LxukoReZEGzTdM/qkk7qhyjolp10l7vt2lm 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Sp4LxukoReZEGzTdM/ps5xp4s0opwmlktmhbxc 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Sp4LxukoReZEGzTdM/ffgxbtljjet4jpyjb8vd 980w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Sp4LxukoReZEGzTdM/zanrdnaggj2ii3pgxdmq 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Sp4LxukoReZEGzTdM/l3w8genp4qgbt8mlyqaq 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Sp4LxukoReZEGzTdM/ozqdyirtjxhvaiawfpyi 1379w\"></figure><p>&nbsp;</p><p>The&nbsp;<a href=\"https://www.foodlabstanford.com/\"><u>Stanford Humane &amp; Sustainable Food Lab</u></a> holds a regular&nbsp;<a href=\"https://www.foodlabstanford.com/seminar\"><u>online seminar series</u></a> in which leading researchers present on topics related to reducing consumption of meat and animal products, followed by an audience Q&amp;A session. Seminars are held every 1-3 months on selected Thursdays at 10am Pacific Time, by Zoom.</p><p>As of January, 2024, we are excited to be opening the seminar to the general public. To receive announcements for the seminar and the Zoom link, you can add yourself to our mailing list&nbsp;<a href=\"https://mailman.stanford.edu/mailman/listinfo/hsf_lab_seminar\"><u>here</u></a>. Recordings are also now posted publicly on our&nbsp;<a href=\"http://www.youtube.com/@HumaneSustainableFoodLab\"><u>YouTube channel</u></a> for speakers who agree to public dissemination.&nbsp;</p><p>We look forward to seeing you!</p><p><br>&nbsp;</p>", "user": {"username": "Maya Mathur"}}, {"_id": "FWbaqM5PaFfrfAxaS", "title": "GWWC Pledge featured in new book from Head of TED, Chris Anderson", "postedAt": "2024-01-25T21:33:43.606Z", "htmlBody": "<p>Chris Anderson, Head of TED, has just released a new book called&nbsp;<a href=\"https://www.infectiousgenerosity.org/\">Infectious Generosity</a>, which has a whole chapter that encourages readers to take the&nbsp;<a href=\"https://www.givingwhatwecan.org/pledge\">Giving What We Can Pledge</a>! He has also taken the Giving What We Can Pledge with the new wealth option to give the greater of 10% of income or 2.5% of wealth each year.&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FWbaqM5PaFfrfAxaS/mf9y1kuntpmtmiqkevfh\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FWbaqM5PaFfrfAxaS/s7jwu3yuzkqu6olwlt5l 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FWbaqM5PaFfrfAxaS/ludkmcx52sh7hf3xknij 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FWbaqM5PaFfrfAxaS/hikl0wzhjtuf9btbogw1 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FWbaqM5PaFfrfAxaS/mjcjc3lgpjbtycgizqry 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FWbaqM5PaFfrfAxaS/hvox11jvilkl6bd7ri9u 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FWbaqM5PaFfrfAxaS/f2siuisvy4ii1bqefuol 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FWbaqM5PaFfrfAxaS/j0gjwnkykoyeqk6funk3 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FWbaqM5PaFfrfAxaS/m9moc1k5n9c3xzdynomq 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FWbaqM5PaFfrfAxaS/i29wjnwsdgwjuis6t0vh 1350w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FWbaqM5PaFfrfAxaS/q795sjf4p6hta1jtyxgb 1461w\"><br><br>This inspiring book is a guide to making Infectious Generosity become a global movement to build a hopeful future. Chris offers a playbook for how to embark on our own generous acts and to use the Internet to give them self-replicating, potentially world-changing, impact.</p><p><img style=\"width:52.82%\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/ckbaybcswqhqezfbxozm\" alt=\"An image of the book Infectious Generosity with a white and yellow cover.\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/hzhc0exft1jor5xdt8o4 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/fpvrjvxi2xds0tw9otvx 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/e2jtdrujgynycxxg0iir 828w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/jdwf62bfyfbifwojc4yc 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/yqzqthslfgeoq7cnltql 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/vvkla0hsp3hagtwbjzi0 1920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/sljy9nlwcjpwst1hfdpb 2048w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/ckbaybcswqhqezfbxozm 3840w\"><br>Here\u2019s a quick excerpt from the book:</p><blockquote><p><i>\u201cThe more I\u2019ve thought about generosity, the impact it can have, and the joy it can bring, the more determined I\u2019ve become that it be an absolute core part of my identity.</i><br><br><i>Jacqueline\u2019s work as a pioneering social entrepreneur has definitely inspired me, and together we\u2019re now ready to sign that combination pledge, effectively committing to giving the higher of 10% of our income or 2.5% of our net worth in any given year for the rest of our lives.\u201d</i></p></blockquote><p>We are really excited about this opportunity to share the <a href=\"https://www.givingwhatwecan.org/pledge\">Giving What We Can Pledge</a> with many more people and hope that this book will be successful so we can make our message even more infectious!&nbsp;</p><p>If you\u2019d like to purchase a copy for yourself or a friend, you can find relevant links&nbsp;<a href=\"https://www.infectiousgenerosity.org/\">here</a>.</p>", "user": {"username": "Giving What We Can"}}, {"_id": "pYxCdgaGexmYgmPTw", "title": "GWWC Newsletter: January 2024", "postedAt": "2024-01-25T21:28:21.678Z", "htmlBody": "<p>Hello and welcome to our January newsletter!</p><p>As we settle into the new year, we are thrilled to share the release of a new book from Chris Anderson, Head of TED, called&nbsp;<a href=\"https://www.givingwhatwecan.org/Infectious%20Generosity\">Infectious Generosity</a>, which has a whole chapter that encourages readers to take the&nbsp;<a href=\"https://www.givingwhatwecan.org/pledge\">Giving What We Can Pledge</a>!<br><br>This inspiring book is a guide to making Infectious Generosity become a global movement to build a hopeful future. Chris offers a playbook for how to embark on our own generous acts and to use the Internet to give them self-replicating, potentially world-changing, impact.</p><p><img style=\"width:882.685px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/ckbaybcswqhqezfbxozm\" alt=\"An image of the book Infectious Generosity with a white and yellow cover.\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/hzhc0exft1jor5xdt8o4 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/fpvrjvxi2xds0tw9otvx 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/e2jtdrujgynycxxg0iir 828w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/jdwf62bfyfbifwojc4yc 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/yqzqthslfgeoq7cnltql 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/vvkla0hsp3hagtwbjzi0 1920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/sljy9nlwcjpwst1hfdpb 2048w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/ckbaybcswqhqezfbxozm 3840w\">Here\u2019s a quick excerpt from the book:</p><blockquote><p><i>\u201cThe more I\u2019ve thought about generosity, the impact it can have, and the joy it can bring, the more determined I\u2019ve become that it be an absolute core part of my identity.</i><br><br><i>Jacqueline\u2019s work as a pioneering social entrepreneur has definitely inspired me, and together we\u2019re now ready to sign that combination pledge, effectively committing to giving the higher of 10% of our income or 2.5% of our net worth in any given year for the rest of our lives.\u201d</i></p></blockquote><p>We are really excited about this opportunity to share the Giving What We Can Pledge with many more people and hope that this book will be successful so we can make our message even more infectious! If you\u2019d like to purchase a copy for yourself or a friend, you can find relevant links&nbsp;<a href=\"https://www.infectiousgenerosity.org/\">here</a>.<br><br>I also wanted to call out that there is <strong>one week left</strong> to double your donation by&nbsp;<a href=\"https://www.givingwhatwecan.org/blog/gwwc-operational-funding-match-2023\">supporting the donation match</a> for our operations and we\u2019re still <strong>$73k short of our current goal</strong>! You can read more about why we think you should consider donating to us, how we\u2019ll use the funding, and details of the match in our blog post.&nbsp;Our team is working hard on bringing the power of effective giving to many more people around the world \u2013 so collectively we can have an even bigger impact, this year and in the years to come.</p><p><br>With gratitude,<br>\u2013&nbsp;Grace Adams &amp;&nbsp;the Giving What We Can team<br><br>PS: You can apply for <a href=\"https://www.givingwhatwecan.org/get-involved/careers\">several roles</a> with us and&nbsp;<a href=\"https://www.givingwhatwecan.org/blog/gwwc-operational-funding-match-2023\">double your donation to our operations</a>&nbsp;until the end of January&nbsp;\u2013&nbsp;read more about all of this below!</p><p><img style=\"width:882.685px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/mm4hhy8niffe5pkdxydf\" alt=\"A tweet from @LarsHuluk about the impact his donations via the Giving What We Can pledge.\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/lr3g1mkvd8ynxfoeuu3t 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/zryx43t5zcxdx3ldazqg 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/cwgckd68cmfi9g1ykdx6 828w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/y3tcjmwslzq8tdlckxxv 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/ossjml7kd6awi0lugiif 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/akib1feqpztt8e9qvaye 1920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/jbvkevicxw33wdui8c9j 2048w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/mm4hhy8niffe5pkdxydf 3840w\"></p><p><a href=\"https://x.com/LarsHuluk/status/1747362949449064696?s=20\">Lars shared</a> some of his donation data on Twitter from <a href=\"https://www.givingwhatwecan.org/dashboard/pledge/stats\">our new stats page</a> that is available for pledgers.</p><p><a href=\"https://x.com/LarsHuluk/status/1747362949449064696?s=20\">Lars shared</a>&nbsp;some of his donation data on Twitter from&nbsp;<a href=\"https://www.givingwhatwecan.org/pledge\">our new stats page</a>&nbsp;that is available for pledgers.</p><p>&nbsp;</p><h2>Motivations for Pledging</h2><p>Here are some of our favourite responses from people who took a pledge last month:<br><br><strong>What motivated you to take a pledge with Giving What We Can?</strong></p><ul><li>Doing so publicly provides support to a philosophy I believe in and strengthens my resolve to do the most good I can throughout my life.</li><li>I'm in a position of great privilege relative to most others in the world, and feel an obligation to take the pledge, as well as donate in a way that does the most good possible.</li><li>I've long thought about and have written about it. It's an important tool to shift giving from impulse to strategic, and an additional motivator to give when times feel tougher or I'm distracted.</li><li>Because I have been given much, I too must give. We're all in this together and we're all better off when we remember that. I want to actively contribute to making a better world, so here I am.</li></ul><h2>Upcoming Events</h2><p>All the events that we list are open to anyone interested in effective giving!<br><br><strong>San Francisco (and online) \u2013 TED's Chris Anderson: Infectious Generosity</strong></p><p>Monday, February 5th at 5 pm PST<br>The Commonwealth Club of California, 110 The Embarcadero, CA 94105<br><br>Bestselling author, media pioneer and TED curator Chris Anderson returns to Commonwealth Club World Affairs to explore one of humankind\u2019s defining but overlooked impulses, and how we can super-charge its potential to build a hopeful future. All in-person tickets include a complimentary copy of Infectious Generosity.</p><p><a href=\"https://www.commonwealthclub.org/events/2024-02-05/teds-chris-anderson-infectious-generosity\">Get a ticket here</a>.<br><br><strong>GWWC Berlin</strong>&nbsp;<strong>\u2013&nbsp;Social Meetup</strong><br>Thursday, February 1st at 18:30<br><a href=\"https://maps.app.goo.gl/nZjK9URhcrhmsn6x6\">Altes Europa</a>&nbsp;Gipsstra\u00dfe 11, 10119 Berlin<br><br>This will be a wonderful opportunity to meet others who are passionate about effective giving. Our aim is to foster a sense of in-person community among GWWC members here in Berlin, and this event is the perfect place to start! We are looking forward to having a relaxed after-work drink together and engaging in some good conversations. No matter if you are very experienced or a newcomer in the field of effective giving, you are very welcome to join us. :)<br><br><a href=\"https://forms.gle/9AunPNt6gBPnXRcx7\">Please RSVP here!</a><br><br><strong>GWWC London \u2013 Earning to Give and Going Beyond 10%</strong><br>Saturday, February 3rd at 2.15 \u2013 5 pm<br>Newspeak House, Bethnal Green Road, E2 7DG London<br><br>Join us for our February Giving What We Can London event. The theme is Earning to Give and Going Beyond 10%. We will have a brief talk by Alex Gordon-Brown who recently wrote <a href=\"https://forum.effectivealtruism.org/posts/gxppfWhx7ta2fkF3R/10-years-of-earning-to-give\">10 Years of Earning to Give</a>.<br><br>We will open doors from 2.15 pm. At 3 pm we will have the 10 minute talk with Q&amp;A and a little poll. Free form discussion from 3.30 pm. Show up whenever suits you best!<br><br><a href=\"https://forum.effectivealtruism.org/events/Z6nd8CrMhqcNBwfjj/gwwc-london-earning-to-give-and-going-beyond-10\">Please RSVP here</a>.<br><br><strong>GWWC Freiburg \u2013 Kick-Off Event</strong><br>Tuesday, February 20th at 5.30 pm<br>Hermann Freiburg<br><br>This kick-off event is for all the GWWC community members and pledgers in the Freiburg area. We will meet on 20 February at 5.30 pm CET in the Hermann Freiburg for a casual get-together.<br><br>The Restaurant Hermann offers a variety of (vegetarian and vegan) dishes and drinks and provides a good environment for a cozy exchange. This event is a chance to meet people from the local GWWC community and discuss ideas and activities for our new local Freiburg group.<br><br><a href=\"https://airtable.com/appzvWe8wO6JPGZJe/shriqBlIqiHYqXaDc?prefill_Event=recm9yfkXhvq7Bmww\">Please RSVP here</a>.<br>&nbsp;</p><h2>News &amp; Updates</h2><h3>Giving What We Can</h3><p>Join our Board</p><ul><li>GWWC is seeking dedicated individuals to join our governance and advisory boards across our current projects, as well as leadership roles in multiple newly formed or soon-to-be-formed entities in different countries. <a href=\"https://www.givingwhatwecan.org/get-involved/careers/governance-advisory-boards\">Apply here</a>.</li></ul><p>Double your donation to help keep us running</p><ul><li>GWWC is running a donation match for our operations - for every dollar donated to our operations, funders will match it up to $200,000. Supporting us now to fill the match will help us get close to filling the gap for our baseline operations in 2024. <a href=\"https://www.givingwhatwecan.org/blog/gwwc-operational-funding-match-2023\">Read more about the match and donate</a>.</li></ul><p>We're hiring</p><ul><li>GWWC is <a href=\"https://www.givingwhatwecan.org/get-involved/careers\">hiring for several roles</a> including an executive assistant and country directors for the US, UK and Canada. We are also&nbsp;seeking dedicated individuals to join our governance and advisory boards across our current projects, as well as multiple newly formed or soon-to-be-formed entities in different countries. <a href=\"https://www.givingwhatwecan.org/get-involved/careers\">Apply here</a>.</li></ul><p>A new way to look at your impact</p><ul><li>We released <a href=\"https://www.givingwhatwecan.org/pledge\">a new stats page for pledgers</a> that lets them look at their donations over time with some nice graphs! You can even download your donation data as a .csv file. Make sure you check it out!</li></ul><p>An easier way to donate</p><ul><li>Good news \u2013 we have a new payment integration! Donors from the US will now have a straightforward 3-click process when making DAF donations on the GWWC platform.</li></ul><h3><br>Community</h3><p>&nbsp;</p><p>Not the End of the World \u2013 How to be the First Generation to Build a Sustainable Planet</p><ul><li><a href=\"https://www.nottheendoftheworld.co.uk/\">A new book</a> by GWWC pledger Hannah Ritchie from Our World in Data was released this month and talks about seven of our biggest environmental problems and how to solve them. Hannah also includes an endorsement of taking our Pledge! GWWC\u2019s Executive Director Luke has finished reading already and highly recommends this book!</li></ul><p>Effective Hedonism</p><ul><li>Charlie Bresler shared a fresh take on effective giving in an <a href=\"https://time.com/6549552/effective-hedonist-essay/\">essay for TIME magazine</a>,&nbsp;calling it aspirational to be an \u2018effective hedonist\u2019. The Life You Can Save\u2019s co-founder points out that \"living a pleasurable life and making the world a better place doesn\u2019t have to be mutually exclusive.\"</li></ul><p>Preventing lead poisoning for $1.66 per child</p><ul><li>80,000 Hours interviewed Dr Lucia Coulter, Co-Executive Director of the Lead Exposure Elimination Project, discussing how they are able to prevent lead poisoning for $1.66 per child. You can hear more about how preventing lead poisoning can avert millions of deaths and trillions of dollars in lost income by <a href=\"https://80000hours.org/podcast/episodes/lucia-coulter-lead-exposure-elimination-project/\">listening to&nbsp;the podcast</a>!</li></ul><p>EA wins from 2023</p><ul><li>The EA Forum shared some <a href=\"https://forum.effectivealtruism.org/posts/8P2GZFLnv8HW9ozLB/ea-wins-2023\">wins from 2023</a>&nbsp;such as a <a href=\"https://thehumaneleague.org/article/prop-12-supreme-court\">new animal welfare law</a> being upheld by the US Supreme Court, thanks in part to campaigning by organisations such as The Humane League, <a href=\"https://www.safe.ai/statement-on-ai-risk\">AI safety going mainstream</a> after years of work in this area, positive results from GiveDirectly\u2019s study on <a href=\"https://conference.nber.org/conf_papers/f192616.pdf\">universal basic income</a>, and a potentially dangerous <a href=\"https://www.vox.com/future-perfect/23871624/usaid-deep-vzn-pandemics-viruses-covid-coronavirus-cdc-virology-pathogens\">virus-hunting programme being shut down</a>.</li></ul><p>Giving What I Can</p><ul><li>Nadine Spychala shared this post with her reflections on our <a href=\"https://nadinespy.github.io/posts/2024/01/giving-what-i-can/\">relationships with money and our values</a>, after making her first yearly donation after taking a pledge in March 2023.</li></ul><h3><br>Cause Areas</h3><p><br>Animal Welfare</p><ul><li><a href=\"https://www.givingwhatwecan.org/en-US/charities/faunalytics\">Faunalytics</a> released their <a href=\"https://faunalytics.org/faunalytics-2023-year-in-review/\">2023 Year In Review</a>, which showcases the research, projects, and other accomplishments the organization achieved this past year. The organization has also announced its <a href=\"https://faunalytics.org/faunalytics-plans-priorities-for-2024/\">plans and priorities</a> for 2024. Faunalytics is accepting applications for a new <a href=\"https://faunalytics.org/job-posting-projects-manager/\">Projects Manager</a> role. Applications are due January 31st.</li></ul><p>Global Health and Wellbeing</p><ul><li>The World Health Organization recommended its <a href=\"https://www.who.int/news/item/02-10-2023-who-recommends-r21-matrix-m-vaccine-for-malaria-prevention-in-updated-advice-on-immunization\">second-ever malaria vaccine</a> in 2023. The drug trial \u200b\u200bwas co-funded by <a href=\"https://www.openphilanthropy.org/\">Open Philanthropy</a>. Thanks to advocacy, the vaccine was quickly prequalified the vaccine, laying the groundwork for an expedited deployment, potentially saving hundreds of thousands of children\u2019s lives. <a href=\"https://sogive.org/#home\">SoGive</a> published a post on the EA Forum looking into how these vaccines compare to bednets and <a href=\"https://forum.effectivealtruism.org/posts/zakLJ4syCrrTiAmoS/malaria-vaccines-how-confident-are-we\">exploring remaining doubts</a> about malaria vaccines.</li><li><a href=\"https://www.againstmalaria.com/Default_kr.aspx\">Against Malaria Foundation Korea</a> was successfully designated a tax-deductible charity by the ROK government on 31 December, becoming the first of the effective charities recommended by the likes of GiveWell, GWWC and The Life You Can Save to be eligible for tax efficient donations in South Korea.</li><li><a href=\"https://www.givingwhatwecan.org/charities/tarl-africa\">TaRL Africa</a> hosted a webinar for over 120 participants in December 2023, featuring key partners to discuss the Language Learning from Familiar to Formal (L2F2) methodology \u2014 an innovation helping to build children's local language and English skills. TaRL Africa is currently preparing to support the Ministries of Education in Angola and Somaliland to launch TaRL pilots in 65 schools in each country. They are also <a href=\"https://teachingattherightlevel.org/careers/\">hiring</a>, with new roles focused on innovations, scale &amp; sustainability, and research.</li></ul><p>Global Catastrophic Risk Reduction</p><ul><li>The <a href=\"https://www.givingwhatwecan.org/charities/long-term-future-fund\">Long-Term Future Fund</a> has given out 196 grants totaling $6.6M in 2023. They are also in the process of <a href=\"https://toothsome-truffle-ec7.notion.site/LTFF-Chair-4103763f5a1645e3a907033c29535fa7\">hiring a new full-time fund chair</a>.</li></ul><p>&nbsp;</p><h3>Evaluators, Grantmakers and Incubators</h3><ul><li><a href=\"https://www.charityentrepreneurship.com/\">Charity Entrepreneurship</a> is accepting applications for the 2nd edition of the <a href=\"https://www.charityentrepreneurship.com/research-training-program\">Research Training Program</a> which is designed to equip participants with the tools and skills needed to identify, compare, and recommend the most effective interventions and organizations. It is a full-time, fully cost-covered program that will run remotely between April 15 and July 5, 2024. The deadline for applications is <a href=\"https://form.jotform.com/240013123967348\">January 28, 2024</a>. The team is also <a href=\"https://www.charityentrepreneurship.com/outreach-director\">hiring a Director of Outreach</a>.</li><li>The <a href=\"https://www.givingwhatwecan.org/charities/effective-altruism-infrastructure-fund\">EA Infrastructure Fund</a> made 121 grants totalling $3.5M in 2023. They have a new tentative plan to focus on Principles-First EA going forwards. The Fund is also fundraising! Donations before Feb 1st will be matched 2:1 by Open Philanthropy.</li><li>GiveWell published <a href=\"https://blog.givewell.org/2023/12/28/givewell-from-a-to-z/\">GiveWell from A to Z</a>, highlighting some key information about the organisation to celebrate the end of 2023.</li><li><a href=\"https://www.founderspledge.com/\">Founders Pledge</a> Climate released its&nbsp;<a href=\"https://www.founderspledge.com/downloads/how-we-think-about-expected-impact-in-climate-philanthropy\">methodology update</a>&nbsp;(also <a href=\"https://www.youtube.com/watch?v=NwDDg5Jpmt4\">presented at EAGx</a>) and end-of-year updates (<a href=\"https://www.founderspledge.com/research/climate2023\">short blog</a>,&nbsp;<a href=\"https://www.founderspledge.com/downloads/ccf-2023-impact-report\">FP Climate Fund Impact Report</a>). Johannes also joined BBC's&nbsp;<a href=\"https://open.spotify.com/episode/4gbvBtiZFM1pxrvyDEXGsV?si=781db870b0104294\">What in the World podcast</a>&nbsp;to talk about the question of whether climate concern should affect whether one has children (spoiler: no).</li></ul><p><br>Some wonderful words from our members:</p><p><strong>To make the world a better place, you don't necessarily have to work for a non-profit organization. Donations are incredibly valuable, too. \u2013 </strong><a href=\"https://www.linkedin.com/pulse/why-donating-underestimated-felix-werdermann-g1kbf%3FtrackingId=SHPpn0wXQOuGr%252B6nOFnfDg%253D%253D/?trackingId=SHPpn0wXQOuGr%2B6nOFnfDg%3D%3D\">Felix Werdermann</a></p><p>&nbsp;</p><p><strong>Donating to effective charities working on important issues is, perhaps uniquely in my life, something I feel unambiguously good about, and something I feel certain is the right thing to do. \u2013 </strong><a href=\"https://www.linkedin.com/feed/update/urn:li:activity:7143928039041597440/\">John Michael Bridge</a></p><p>&nbsp;</p><p><strong>We are surrounded by others who sacrificially love and give, and that\u2019s why we were empowered to do it too. \u2013 </strong><a href=\"https://www.linkedin.com/pulse/confessions-recent-gwwc-pledger-boxing-day-giving-harry-luk-x1jnc%3FtrackingId=vF37%252BG9fTUiSx8i7f1snJA%253D%253D/?trackingId=N5vAu6eWRC6U%2F%2BOlLF7c%2FQ%3D%3D\"><strong>Harry Luk</strong></a></p><p>&nbsp;</p><p><img style=\"width:882.685px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/xbwvqoynhbyjfgbcmnnp\" alt=\"A screenshot of the Giving What We Can TikTok profile\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/epc9v1kr5t2ql53ygucx 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/mwfqlyjr0k16qn6gnetd 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/pkbaxumksiouefma6stu 828w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/kmecxym0lijmzu5odcax 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/zsicv8na82kcjfaqiwea 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/lew1stx1fsbi9ixizo0k 1920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/nlsamvriuibjs8jjoz85 2048w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pYxCdgaGexmYgmPTw/xbwvqoynhbyjfgbcmnnp 3840w\"></p><p><a href=\"https://www.tiktok.com/@givingwhatwecan/video/7320612063225646344?lang=en\"><strong>Are you following us on TikTok yet?</strong></a></p><p><br>Have any feedback on our newsletter or communications? <a href=\"https://forms.gle/6FjnJJ2NxS1YQ5kn8\">Share your thoughts here</a>.</p><h3>Thank you!</h3><p>Thanks again for taking the time to read our newsletter! As always, here are some useful links to help you maximise your charitable impact:</p><ul><li>Read about <a href=\"https://www.givingwhatwecan.org/blog/team-donations-2023\">where the GWWC team donated</a> in 2023.</li><li>Review <a href=\"https://www.givingwhatwecan.org/best-charities-to-donate-to-2024\">our giving recommendations</a>.</li><li>Report your donations with&nbsp;<a href=\"https://app.effectivealtruism.org/pledge\">your pledge dashboard</a>.</li><li><a href=\"https://www.givingwhatwecan.org/get-involved/share-our-ideas\">Share our ideas</a> to help grow our community and <a href=\"https://www.givingwhatwecan.org/blog/social-change-happens-one-person-at-a-time-so-start-multiplying-your-impact\">multiply your impact</a>.</li><li>Start conversations with our community&nbsp;in our <a href=\"https://www.givingwhatwecan.org/get-involved/connect-to-community\">online community space</a>.</li><li>Find more ways to <a href=\"https://www.givingwhatwecan.org/get-involved\">get involved</a>&nbsp;with Giving What We Can and effective giving.</li></ul><p>You can follow us on&nbsp;<a href=\"https://x.com/givingwhatwecan\">Twitter</a>, <a href=\"https://www.facebook.com/givingwhatwecan\">Facebook</a>, <a href=\"https://www.linkedin.com/company/2760845/\">LinkedIn</a>, <a href=\"https://www.instagram.com/giving_what_we_can/\">Instagram</a>, <a href=\"https://www.youtube.com/channel/UC_gBQtUE3BBl-Mh_IBQkg9Q\">YouTube</a>, or <a href=\"https://www.tiktok.com/@givingwhatwecan\">TikTok</a>&nbsp;to hear more from us throughout the month!<br><br>Do you have questions about the pledge, Giving What We Can, or effective giving in general? Check out our&nbsp;<a href=\"https://www.givingwhatwecan.org/about-us/frequently-asked-questions\">FAQ page</a>, or <a href=\"https://www.givingwhatwecan.org/about-us/contact-us\">contact us directly</a>.<br><br>Until next time, keep on doing good!</p>", "user": {"username": "Giving What We Can"}}, {"_id": "hxFzsJ96izYTdkFPJ", "title": "Sobre pensar no pior", "postedAt": "2024-01-25T20:45:17.932Z", "htmlBody": "<p>Antigos estoicos, como o imperador romano Marco Aur\u00e9lio e o ex-escravo Epiteto, tinham um exerc\u00edcio mental chamado <a href=\"https://medium.com/stoicism-philosophy-as-a-way-of-life/lets-talk-about-the-premeditation-of-adversity-2f7d40fbb7d0\"><i>premeditatio malorum</i></a> \u2013 a <a href=\"https://pt.wikipedia.org/wiki/Visualiza%C3%A7%C3%A3o_negativa\">visualiza\u00e7\u00e3o negativa</a>, ou \u201cantecipa\u00e7\u00e3o da adversidade\u201d. Trata-se de refletir sobre o que tememos que ocorra, como doen\u00e7a, sofrimento, a morte de entes queridos, etc. Para esses fil\u00f3sofos, al\u00e9m da prepara\u00e7\u00e3o para o pior, isso permite focar no que \u00e9 mais relevante e que tem valor mesmo que nossos medos se materializem; e ajudaria a ver que, mesmo nas piores situa\u00e7\u00f5es, ainda temos controle sobre nossos pensamentos e atitudes, podendo agir de acordo com a virtude \u2013 o que, para eles, \u00e9 o que realmente importa.</p><p>Eu me pergunto se essa pr\u00e1tica ainda seria recomend\u00e1vel para os dias atuais. Mesmo que nossas vidas sejam, em m\u00e9dia, significativamente melhores do que as da Roma Antiga, \u00e9 plaus\u00edvel que esse exerc\u00edcio tenda a evocar mais ansiedade que serenidade. Um cidad\u00e3o romano geralmente temia a desonra, a escravid\u00e3o, ou mesmo a destrui\u00e7\u00e3o de sua cidade (e esses riscos eram bem concretos); nesses casos, outro exerc\u00edcio recomendado por estoicos \u00e9 assumir uma <a href=\"https://www.stoichandbook.co/cosmic-perspective/\">perspectiva cosmopolita, ou mesmo \u201cc\u00f3smica</a>\u201d, enxergando-nos e a nosso entorno como parte de um todo maior, da esp\u00e9cie humana e de um mundo que persiste para al\u00e9m de n\u00f3s, diminuindo assim a import\u00e2ncia relativa desses temores. Mas a ideia de um universo bem-ordenado da filosofia antiga foi <a href=\"https://howtobeastoic.wordpress.com/author/mpigliucci/#:~:text=That%20idea%20stemmed,to%20eating%20habits.\">sepultada pela ci\u00eancia moderna</a>, e hoje qualquer um de n\u00f3s pode conceber o que o Prof. <a href=\"https://www.youtube.com/watch?v=gCGa6uvO0_8\">Alexey Dodsworth</a>, seguindo Hans Jonas, chama <a href=\"https://filosofia.fflch.usp.br/sites/filosofia.fflch.usp.br/files/posgraduacao/defesas/2019_docs/2019_Tese_Alexey%20Dodsworth%20Magnavita%20de%20Carvalho.pdf\"><i>sumum malum</i></a><i>,&nbsp;</i>o pr\u00f3prio colapso da civiliza\u00e7\u00e3o e a extin\u00e7\u00e3o da humanidade \u2013 a exemplo do simpl\u00f3rio pescador interpretado por Max von Sydow em <a href=\"https://pt.wikipedia.org/wiki/Luz_de_Inverno\"><i>Luz de Inverno</i></a>, que se desespera com a possibilidade de uma guerra nuclear. Nem precisamos ver um filme de Bergman para ter uma crise existencial semelhante; muitos passaram por algo assim durante a recente pandemia, e outros t\u00eam um sentimento parecido em rela\u00e7\u00e3o \u00e0 cat\u00e1strofe clim\u00e1tica (como Jonathan Franzen na piau\u00ed 157, <a href=\"https://piaui.folha.uol.com.br/materia/e-se-parassemos-de-fingir/\"><i>E se par\u00e1ssemos de fingir?</i></a>). Cen\u00e1rios ainda mais dram\u00e1ticos s\u00e3o mostradosem s\u00e9ries <i>pop</i> recentes como <a href=\"https://en.wikipedia.org/wiki/Carol_%26_the_End_of_the_World\"><i>Carol e o fim do mundo</i></a> e o aguardado <a href=\"https://pt.wikipedia.org/wiki/3_Body_Problem_(s%C3%A9rie_de_TV)\"><i>O problema dos tr\u00eas corpos</i></a>.</p><p>Ao inv\u00e9s de oferecer consolo, fil\u00f3sofos contempor\u00e2neos destacam que temos ainda mais a perder al\u00e9m das bilh\u00f5es de vidas que seriam perdidas. Em <a href=\"https://en.wikipedia.org/wiki/What_We_Owe_the_Future\"><i>What we owe the future</i></a><i>&nbsp;</i>(\u201cO que devemos ao futuro\u201d, em tradu\u00e7\u00e3o a ser lan\u00e7ada pela Planeta neste ano), Will MacAskill ensina que tamb\u00e9m perder\u00edamos todo o potencial valor do futuro da civiliza\u00e7\u00e3o humana \u2013 as incont\u00e1veis vidas que poderiam existir, em situa\u00e7\u00f5es t\u00e3o distintas da nossa quanto n\u00f3s hoje somos diferentes dos antigos romanos. J\u00e1 Samuel Scheffler, em <a href=\"https://en.wikipedia.org/wiki/Samuel_Scheffler#:~:text=most%20recent%20book%2C-,Death%20and%20the%20Afterlife,-%2C%20based%20on\"><i>Death and the Afterlife</i></a>, argumenta que, como boa parte do valor de nossas vidas depende de coisas que ocorrer\u00e3o ap\u00f3s nossas mortes, a perspectiva de extin\u00e7\u00e3o futura nos roubaria esse valor. Imaginar que outros humanos continuar\u00e3o por aqui depois de mim permite dar relativamente menos import\u00e2ncia a minha limitada exist\u00eancia individual, e mais ao que est\u00e1 \u201cal\u00e9m de mim\u201d \u2013 o que me consola a respeito de minha mortalidade, e me faz querer ser lembrado de forma positiva por gera\u00e7\u00f5es futuras. Isso se perderia caso descobrisse que somos a \u00faltima gera\u00e7\u00e3o.&nbsp;</p><p>Por outro lado, \u00e9 claro, pensar seriamente sobre o pior pode ajudar a evit\u00e1-lo. Antes de se juntar a ricos sobrevivencialistas na Nova Zel\u00e2ndia (descritos por Evan Osnos em <a href=\"https://piaui.folha.uol.com.br/materia/e-o-fim-do-mundo/\">\u00c9 o fim do mundo</a>, piau\u00ed 127), pode ser interessante conversar com burocratas de gest\u00e3o de riscos. Nos EUA, desde um ano atr\u00e1s, uma <a href=\"https://www.congress.gov/117/bills/hr7776/BILLS-117hr7776enr.pdf#page=1290\">lei</a> obriga o Departamento de Seguran\u00e7a Interna e a Ag\u00eancia Federal de Gest\u00e3o de Emerg\u00eancias a analisarem <a href=\"https://pt.wikipedia.org/wiki/Risco_catastr%C3%B3fico_global\">riscos catastr\u00f3ficos globais</a> sistematicamente. De modo afim, a <a href=\"https://www.oecd.org/governance/toolkit-on-risk-governance/goodpractices/page/theuksnationalriskassessmentnra.htm\">Avalia\u00e7\u00e3o Nacional de Risco do Reino Unido</a> tamb\u00e9m inclui algumas dessas amea\u00e7as, por mais que sejam improv\u00e1veis.&nbsp; No Brasil, poder\u00edamos refletir sobre o tema em discuss\u00f5es sobre o <a href=\"https://www.gov.br/mcti/pt-br/acompanhe-o-mcti/noticias/2024/01/grupo-de-trabalho-interministerial-debate-estrategia-geral-para-plano-clima-adaptacao\">Plano Clima</a> e sobre o <a href=\"https://pndc.com.br/\">Plano Nacional de Prote\u00e7\u00e3o e Defesa Civil</a>; e poder\u00edamos aproveitar as reuni\u00f5es do G20 e, no ano que vem, a COP-30 para abordar o tema com outros pa\u00edses.</p><p>Al\u00e9m disso, uma avalia\u00e7\u00e3o mais fria permite dimensionar o qu\u00e3o improv\u00e1veis s\u00e3o esses cen\u00e1rios, em especial a extin\u00e7\u00e3o; na maioria dos cen\u00e1rios catastr\u00f3ficos, a despeito de todo sofrimento, ainda haveria pessoas com vidas dignas de serem vividas (ao menos da perspectiva delas \u2013 muitos de n\u00f3s est\u00e3o acostumados demais aos confortos da civiliza\u00e7\u00e3o moderna para apreciar a rotina p\u00f3s-apocal\u00edptica). Isso sugere a import\u00e2ncia de preservar alguns aspectos de nossa cultura que possam afetar positivamente a trajet\u00f3ria futura da sociedade \u2013 como tecnologias, recursos naturais, ideias e bens culturais.</p><p>Mesmo a nossa extin\u00e7\u00e3o n\u00e3o implicaria a destrui\u00e7\u00e3o de toda vida inteligente; a vida em outros planetas, caso exista, n\u00e3o seria afetada. Essa tem sido apontada como a principal raz\u00e3o para a expans\u00e3o extraplanet\u00e1ria: criar col\u00f4nias espaciais como \u201cplano B\u201d. Contudo, em <a href=\"https://www.amazon.com.br/City-Mars-Settle-Thought-Through/dp/1984881728\"><i>A City on Mars</i></a>, o casal de <i>geeks&nbsp;</i>Zach e Kelly Weinersmith argumenta que, apesar de todo o <i>hype</i>, uma expans\u00e3o precoce poderia trazer mais riscos do que benef\u00edcios \u2013 se, p. ex., aumentasse as chances de conflitos. Por um bom tempo, n\u00e3o deve haver \u201cPlaneta B\u201d para n\u00f3s.</p><p>Mas considere o <a href=\"https://brasilescola.uol.com.br/geografia/paradoxo-de-fermi.htm\">paradoxo de Fermi</a>: se a gal\u00e1xia existe h\u00e1 tanto tempo, e se h\u00e1 tantas estrelas e planetas l\u00e1 fora, \u00e9 prov\u00e1vel que haja surgido vida em outros lugares, e que ela tenha se expandido; mas ent\u00e3o, por que n\u00e3o encontramos sinal dela? Uma possibilidade, explorada <a href=\"https://pt.wikipedia.org/wiki/O_Problema_dos_Tr%C3%AAs_Corpos_(romance)\">nos livros</a> que deram origem \u00e0 s\u00e9rie <i>O problema dos tr\u00eas corpos</i>, \u00e9 que o Universo seja um lugar perigoso; mais cedo ou mais tarde, esp\u00e9cies avan\u00e7adas seriam atingidas pelo que astrobiol\u00f3gos chamam de \u201c<a href=\"https://pt.wikipedia.org/wiki/Grande_Filtro\">Grande Filtro</a>\u201d. Talvez a vida inteligente seja algo fr\u00e1gil ou tenha uma tend\u00eancia \u00e0 autodestrui\u00e7\u00e3o; \u00e9 o que poder\u00edamos concluir, ao encontrar ind\u00edcios de uma extinta civiliza\u00e7\u00e3o n\u00e3o-humana. Portanto, <i>se</i> (ou melhor, <i>quando</i>) um dia formos extintos, seria interessante que alguns registros humanos sobrevivessem e que, caso em algum momento haja outra vida inteligente no universo, ela tenha uma chance de encontr\u00e1-los. Tais registros seriam o \u00faltimo (e qui\u00e7\u00e1 mais importante) impacto que a humanidade teria sobre o universo, transmitindo, ainda que impl\u00edcito, um aviso benevolente: \u201cN\u00f3s existimos, e perecemos; isso pode ter ocorrido a outros, e pode vir a ocorrer a voc\u00eas\u201d.</p><p>Finalmente, quero registrar que simpatizo com as mentes pragm\u00e1ticas que tendem a sentir alguma avers\u00e3o ao car\u00e1ter especulativo dessas reflex\u00f5es; caso o leitor seja uma delas, agrade\u00e7o a paci\u00eancia de ler-me at\u00e9 o fim. Essas pessoas est\u00e3o protegidas da ansiedade que esse exerc\u00edcio pode gerar; por outro lado, podem estar mais suscet\u00edveis ao desespero ou confus\u00e3o quando o pr\u00f3ximo \u201cimponder\u00e1vel\u201d ocorrer, como o pescador de von Sydow. Eu certamente n\u00e3o gostaria que todos pensassem da mesma forma; mas desconfio que, se aqueles em situa\u00e7\u00f5es de poder considerassem seriamente (ou escutassem os que o fazem) o risco de cat\u00e1strofes globais, estar\u00edamos mais seguros \u2013 talvez at\u00e9 menos divididos. E isso concedo aos estoicos: sinto grande admira\u00e7\u00e3o, at\u00e9 inveja, pela pessoa <i>s\u00e3</i> que pode contemplar seriamente a possibilidade de que o mundo acabe, sem sentir arrependimentos \u2013 sabendo que mesmo isso n\u00e3o subtrai o valor de suas a\u00e7\u00f5es.</p>", "user": {"username": "Ramiro"}}, {"_id": "4wsQdHhuGRYmKafph", "title": "Probably Good launched a newsletter with impact-centered career advice!", "postedAt": "2024-01-25T19:14:31.683Z", "htmlBody": "<p>Probably Good recently launched a newsletter to update our audience on new content and help people learn how to increase the impact of their careers at a meaningful but reasonable pace.&nbsp;<a href=\"https://probablygood.org/newsletter/\"><u>You can subscribe here</u></a>!</p><p>For new subscribers, we\u2019ll kick off with an intro series overview of our approach to career planning. In future newsletters, we\u2019ll cover topics like:</p><ul><li>Core concepts &amp; frameworks for thinking about careers</li><li>New content &amp; services from PG</li><li>Personal perspectives on career choice</li><li>Cause-specific overviews and resources</li><li>Promising job &amp; work opportunities within a range of cause areas</li></ul><p>If you think you might have signed up for our mailing list at some point in the past, you should have received a confirmation email to let us know you\u2019d like to receive the newsletter. If you didn't receive this email, you can&nbsp;<a href=\"https://probablygood.org/newsletter/\"><u>sign up here</u></a>.<br><br>As always, we want to express our gratitude for all the encouragement we\u2019ve received from this community over the past two years. We\u2019re excited for what\u2019s to come as we keep growing our site and we appreciate the ongoing support. If you have ideas for new career related content you\u2019d like to see, feel free to reach out via our&nbsp;<a href=\"https://probablygood.org/contact/\"><u>contact form</u></a> or email us at team@probablygood.org.</p>", "user": {"username": "Probably Good"}}, {"_id": "ZKD8xeqwX8R8qBTWH", "title": "Expression of Interest: Director of Operations at the Center on Long-term Risk", "postedAt": "2024-01-25T18:43:30.881Z", "htmlBody": "<p><i>You can also see this posting on our website </i><a href=\"https://longtermrisk.org/director-of-operations-exp-int-2024/\"><i>here</i></a><i>.</i></p><p><i>EDIT: <strong>he deadline for expressions of interest to be considered in our initial round has now passed. You're still welcome to submit expressions of interset, but we will only invite late submissions to join the immediate hiring round in exceptional cases. </strong>If we decide to proceed to a full hiring round in April 2024, we'll take another look at all new expressions of interest at that stage.</i></p><h1>Intro / summary</h1><ul><li>The&nbsp;<a href=\"https://longtermrisk.org/\"><u>Center on Long-term Risk</u></a> will soon be recruiting for a Director of Operations. The role is to lead our 2-person operations team, handling challenges across areas such as HR, finance, compliance and recruitment.&nbsp;</li><li>Due to uncertainty over whether the role will be located in London (UK) or Berkeley (California), we are running a low-volume invite-only round now; to be followed by an open round in ~April after we gain certainty on the location, if we don\u2019t hire now.<ul><li>We\u2019d also be open to mainly-remote candidates in some circumstances (see below).</li></ul></li><li>We\u2019re excited for expressions of interest from anyone with experience of challenging operations work, and at least a little experience of people management.</li><li>If you\u2019re interested in the role, we\u2019d be excited for you to submit our <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSeTVCCwihoalJbDPMspkHVIKYzjyROzu2dj-pTaZwWYk2wP1w/viewform?usp=sf_link\"><u>expression of interest form</u></a>&nbsp;<strong>by the end of Sunday 11th February</strong>. We\u2019ll then invite the most promising candidates to apply for the role now.</li></ul><h1>Location</h1><p>As mentioned in our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/yTwR86oBXXLEgHSsG/center-on-long-term-risk-annual-review-and-fundraiser-2023-2#Organization\"><u>annual review</u></a>, CLR is evaluating whether to relocate from London to Berkeley, CA. We are currently in a trial period, and expect to make a decision about our long-term location in early April. For this reason,&nbsp;<strong>we unfortunately don\u2019t yet know whether this role will be located in London or Berkeley</strong>. We\u2019d also be open to remote candidates in some circumstances (see below).</p><p>We recognise that this uncertainty will make the role less appealing to candidates. Given this, we will be running a low-volume invite-only hiring round now, for candidates who are willing to spend the time on our hiring process even with our location uncertainty. If we don\u2019t successfully hire now, we will launch a full open round in April, after the location decision is made.&nbsp;</p><p>Further details on location:</p><ul><li>We estimate a 70% chance that we will settle on moving to Berkeley, and a 30% chance of staying in London.&nbsp;</li><li><i>If we settle on London (30% chance):</i> we\u2019d have a strong preference for candidates who can spend at least ~60% of their time at our London office</li><li><i>If we settle on Berkeley (70% chance),</i> we\u2019d be open to remote candidates, with a substantial preference for candidates who can visit Berkeley regularly.</li><li>To be clear, we\u2019re not looking for a commitment from candidates that you\u2019re happy to work in both locations. Just one is fine \u2013&nbsp; it\u2019s just that we\u2019ll just need to take this into account when making the offer after the location decision is finalised.</li><li>We expect to be able to sponsor visas for this role in most cases..&nbsp;</li></ul><h1>The role</h1><p>The Director of Operations role is to lead our 2-person operations team, with responsibility across areas such as HR, finance, compliance, office management, grantmaking ops, and recruitment. You\u2019d report to our Executive Director, and would take on the management of our existing Operations Associate.&nbsp;</p><p>Specific responsibilities include:</p><ul><li>Working with our Executive Director and board of trustees to facilitate major organisational decisions, providing an operations perspective.</li><li>Managing and mentoring our Operations Associate, as well as a number of support staff and contractors.</li><li>Managing compliance and finances for our ecosystem of charitable entities (in collaboration with the Operations Associate, legal advisors and accountants).</li><li>Overseeing and refining CLR\u2019s internal systems in areas such as HR, grantmaking ops, IT, recruitment and immigration.</li><li>Leading on major operations projects as they arise, such as running events or hiring staff in new countries.</li></ul><p>About operations at CLR:</p><ul><li>CLR overall is currently a team of 13, and we plan to recruit 3-4 new staff in 2024. As well as supporting our research teams, the operations team facilitates CLR\u2019s grantmaking, annual summer research fellowship, and runs regular events, such as external research retreats.</li><li>If we go ahead with moving to Berkeley, setting up infrastructure in the US will be a major priority for 2024.</li><li>New operations projects come up regularly at CLR, for example setting up infrastructure in new countries, running events, or seeding new organisations.&nbsp;</li></ul><p>We estimate that around 70% of your time in the role would be spent directly working on operations projects, and 30% on people management, co-ordination, and strategy.&nbsp;</p><h1>About you</h1><p>We\u2019re interested in candidates who bring most of the following skills and experience to the role:</p><ul><li><strong>Experience of operations work in a challenging, varied and/or high-growth context</strong>&nbsp;<ul><li>You\u2019ve worked across more than one operations area (e.g. HR, accounting, compliance, events, \u2026), in a small or quickly-growing organisation, and regularly faced new situations and had to independently work out solutions.&nbsp;</li><li>You likely have at least 2 years\u2019 experience of this kind of work, perhaps substantially more.<ul><li>We expect the successful candidate will likely be substantially further into their career than this, however we are open to candidates whose experience is mostly in other domains, or to exceptional early-career candidates.&nbsp;</li><li>If you have a track record of successfully dealing with challenges and managing projects in a few different domains, and at least some operations experience, we\u2019re excited to hear from you!</li></ul></li><li>You have the skills that make people excellent at work of this kind, such as strong attention to detail, problem-solving, and being organised and reliable. You\u2019re excited about solving problems and supporting your team.&nbsp;</li></ul></li><li>At least some&nbsp;<strong>experience of people management</strong></li><li><strong>Good judgement</strong>: You can make sensible decisions about complex issues across a wide variety of domains, including areas in which you don\u2019t have much expertise. You can anticipate problems, manage risks, and prioritise well.</li><li>Great&nbsp;<strong>communication and people skills</strong>. You can collaborate with people in a wide variety of contexts, transparently explain the reasoning for your decisions, get to the bottom of disagreements, and act compassionately in difficult situations.&nbsp;</li><li>Drive to further CLR\u2019s&nbsp;<a href=\"https://longtermrisk.org/about-us\"><u>mission</u></a> of reducing worst-case risks from advanced AI systems; and either familiarity with the effective altruism community and its priorities and culture, or drive to learn more about this area.</li></ul><h1>Role impact</h1><p>The Director of Operations is central to CLR\u2019s activities and impact. As well as continuing the existing high level of support provided to our team and projects, we\u2019re excited for a candidate with great judgement to bring new ideas and drive organisational change, and so multiply our impact further.&nbsp;</p><p>CLR\u2019s mission is to reduce worst-case risks from the development of advanced AI systems. We are the largest organisation focussed on&nbsp;<a href=\"https://longtermrisk.org/beginners-guide-to-reducing-s-risks/\"><u>s-risk reduction</u></a>, with our researchers being among only a few working on s-risk reduction and&nbsp;<a href=\"https://arxiv.org/abs/2012.08630\"><u>cooperative AI</u></a>.&nbsp;</p><p>You can read about CLR\u2019s achievements in 2023 and plans for 2024&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/yTwR86oBXXLEgHSsG/center-on-long-term-risk-annual-review-and-fundraiser-2023-2\"><u>here</u></a>.&nbsp;</p><p>CLR\u2019s activities include:</p><ul><li><strong>Technical interventions</strong>: CLR aims to develop and communicate insights about the safe development of artificial intelligence to the relevant stakeholders (e.g., AI developers, key organisations in the longtermist effective altruism community). We are in regular contact with leading AI labs and AI safety research nonprofits.</li><li><strong>Research collaborations:</strong> CLR researchers have recently been involved in collaborations with researchers from CMU, Oxford, Stanford, Berkeley, MIT, and Google DeepMind.</li><li><strong>Research community: </strong>CLR runs an annual&nbsp;<a href=\"https://longtermrisk.org/summer-research-fellowship/\"><u>Summer Research Fellowship</u></a>, during which the size of our team temporarily doubles as we focus on training and evaluating promising new researchers. We also run research retreats, bringing together members of the research community to co-ordinate and make progress on problems.</li><li><strong>Grantmaking</strong>: In addition to the&nbsp;<a href=\"https://longtermrisk.org/grantmaking/\"><u>CLR Fund</u></a>, some of our staff advise&nbsp;<a href=\"https://polaris-ventures.org/\"><u>Polaris Ventures</u></a>, a foundation committed to using all of its funds to improve the quality of life of future generations.</li><li><strong>New projects</strong>: In collaboration with people in our network, we are always looking for novel impactful projects to set up. For instance, CLR staff were founding members of the&nbsp;<a href=\"https://www.cooperativeai.com/foundation\"><u>Cooperative AI Foundation</u></a>.</li></ul><p>CLR has received grants from&nbsp;<a href=\"https://www.openphilanthropy.org/giving/grants/effective-altruism-foundation-research-operations\"><u>Open Philanthropy</u></a>, the&nbsp;<a href=\"https://survivalandflourishing.fund/sff-2023-h1-recommendations\"><u>Survival and Flourishing Fund</u></a> and&nbsp;<a href=\"https://polaris-ventures.org/\"><u>Polaris Ventures</u></a>.&nbsp;</p><p>Testimonials about CLR\u2019s work from prominent community members can be found&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/J7gdciCXFgqyimAAe/center-on-long-term-risk-2023-fundraiser#Appendix__Testimonials\"><u>here</u></a>.&nbsp;</p><h1>Compensation &amp; benefits</h1><p>For full-time work in this role, we offer a <strong>salary </strong>of 110-150,000 USD if the role is based in the Bay Area, or 60-90,000 GBP for London.</p><ul><li>For applicants based outside London or the Bay Area, the salary will be adjusted based on local living costs, in accordance with our compensation policy.</li><li>If you\u2019re interested in this role but would require a higher salary, we encourage you to go ahead and apply. We\u2019re open to discussing higher compensation for exceptional candidates.</li></ul><p>Benefits for this role will include:</p><ul><li>25 days\u2019 paid vacation per year, plus public holidays.</li><li>If you\u2019re based in the US, 100% coverage of our platinum health insurance plan. For UK staff, private health insurance.&nbsp;</li><li>Pension scheme with default employer contribution of 10% of your qualifying earnings, increasing to 15% to match additional contributions made by you.</li><li>Catered plant-based lunch available at the office every day.</li><li>A budget of \u00a33000 per year to spend on your professional development and productivity.</li><li>Flexible working hours.</li><li>20 weeks\u2019 paid leave for new parents.</li><li>We will pay reasonable relocation costs for candidates who move to London or the Bay Area to take up the role.&nbsp;</li></ul><h1>How to apply</h1><p>If you\u2019re interested in the role, please submit&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSeTVCCwihoalJbDPMspkHVIKYzjyROzu2dj-pTaZwWYk2wP1w/viewform?usp=sf_link\"><u>this expression of interest form</u></a>&nbsp;<strong>by the end of Sunday 11th February</strong>. The form will still be monitored after this, but we\u2019ll only invite late applicants to join the invite-only round in exceptional cases.</p><p>Note that with this being an invite-only round, we expect to get back to only the most promising candidates to invite them to apply to the role now.&nbsp;</p><p>If we don\u2019t invite you to the current round, we will still make sure to let you know if we proceed to a full open hiring round in April.</p><p><br>&nbsp;</p>", "user": {"username": "AmritSidhu-Brar"}}, {"_id": "GZy8GQyAp2TojwhEs", "title": "Recruiting for Survey on the Psychology of EA", "postedAt": "2024-01-25T17:17:04.476Z", "htmlBody": "<p>I am actively recruiting effective altruists to participate in an online survey mapping their psychological profiles. The survey should take no more than 90 minutes to complete and anyone who identifies as being in alignment with EA can participate. If you have the time, my team and I would greatly appreciate your participation! The survey pays $15 and the link can be found below.</p><p>Survey Link: <a href=\"https://albany.az1.qualtrics.com/jfe/form/SV_8v31IDPQNq4sKBU\">https://albany.az1.qualtrics.com/jfe/form/SV_8v31IDPQNq4sKBU</a></p><p>The Research Team:</p><ol><li>Kyle Fiore Law (Project Leader; PhD Candidate in Social Psychology; University at Albany, SUNY): https://www.kyleflaw.com/</li><li>Brendan O\u2019Connor (Associate Professor of Psychology; University at Albany, SUNY):</li><li>Abigail Marsh (Professor of Psychology and Interdisciplinary Neuroscience; Georgetown University)</li><li>Liane Young (Professor of Psychology and Neuroscience; Boston College)</li><li>Stylianos Syropoulos (Postdoctoral Researcher; Boston College)</li><li>Paige Amormino (Graduate Student; Georgetown University)</li><li>Gordon Kraft-Todd (Postdoctoral Researcher; Boston College)</li></ol><p>Warmly,</p><p>Kyle :)</p>", "user": {"username": "Kyle Fiore Law"}}, {"_id": "XmRyXEtavbjjC4k8c", "title": "GenAI and a Skeptical Hypothesis World", "postedAt": "2024-01-25T16:42:00.955Z", "htmlBody": "<p>Epistemology is the philosophical inquiry into knowledge. It addresses questions like \"what are the necessary and sufficient conditions for a person to <i>know</i> a proposition <i>P</i>?\" (an account of knowledge) and \"what does it mean for a person to be justified in believing <i>P</i>\"? A standard problem for an account of knowledge is a Skeptical Hypothesis. The most famous skeptical hypotheses are Descartes' deceiving demon (DDD), and the brain in the vat (BIV). DDD is a scenario where all your sensory perceptions are just as they would be if you were a person with a body in the world with correctly functioning senses, but instead of the senses receiving information from the world, you are actually a mind that is receiving misinformation perceptions piped directly into your brain/mind. BIV is a similar scenario, but instead of a demon, it is some unspecified source that is piping senses directly to your brain, which is not in a body, but in a vat. These skeptical hypotheses are not meant to live possibilities for the how the world might be, but rather are meant to undermine accounts of knowledge. If I cannot know that I am NOT a BIV, and my being a BIV contradicts with my being a brain in a body with functioning eyes and ears perceiving the external world, then I cannot know that I am a brain in a body correctly perceiving the external world. So, knowledge of the external world is not possible.&nbsp;</p><p>Epistemologists tend to respond to this problem with a position called <i>Fallibilism. </i>I can know <i>P</i> even if I haven't ruled out every case in which <i>not-P</i> might hold (Skeptical Hypotheses). We can justify this position in lots of different ways, including through pragmatic considerations, or through properly ignoring certain hypotheses that are not relevant context. So we can retain knowledge.</p><p>However, we currently face a situation that is increasingly at risk of becoming a sort of actual Skeptical Hypothesis, with the proliferation of highly realistic generative AI. Far from the rarefied heights of academic epistemology, this technology, and the mediation of our experience of the world through screens, makes deep fake based skeptical hypotheses not only contextually relevant, but in many situations <i>actually the case</i>. Just as the Skeptical Hypotheses of epistemology threaten to undermine the <i>possibility of empirical knowledge</i>, Deep Fake Hypotheses seem to threaten even a Fallibilist account knowledge. The result of this is a rapidly deteriorating epistemic situation for all of us. We cease to feel like we can know things, we stop trusting information channels, as one by one they get exploited by deep fakes and become susceptible to relevant skeptical hypotheses. I am not sure what the downstream consequences of this look like, other than power grabs by those who are able to successfully manipulate and maneuver in this environment. Things are not good, though.</p><p>A solution to this takes the form of a system. In this system, it is the norm for everyone to have a public/private key pair associated with their various identities, some of which are tied to them as individuals, some tied to a company, some tied to some other type of organization. When members of this system release information into the ether, they cryptographically sign it. This can serve both to prove they are the source, and also to prove that the content of the information has not been manipulated.&nbsp;</p><p>The problem is that generative AI capabilities are advancing faster than a Schelling point norm of public key infrastructure. There is not a single tool or platform for provisioning and managing these keys in a trusted way that has achieved equilibrium, and people mostly do not want to bother learning about this stuff.&nbsp;</p><p>But if we had such a platform or system, and it was the default to use it, people would use it, and it would solve our impending problem. Just like how early websites were vulnerable because they did not use encryption by default, when Google and Firefox and Microsoft made HTTPS the default and pushed for the widespread use of certificates, things became much more secure, although obviously not perfectly secure. Now, we know not to enter any sensitive information on websites that just use HTTP, and we are cautioned against using them in general. The same sort of equilibrium will emerge when we have a default use of public keys for information broadcasting. Items that lack a cryptographic signature from a known source will be untrusted, because they might be from malicious actors.</p><p>At the moment, it is a collective action problem. Who will stand this up and manage it? Who will coordinate with the technology companies at the backbone of the Internet so that it is easy to use by default? I think it's a problem worth throwing a few EA Bucks at.</p>", "user": {"username": "Ahrenbach"}}, {"_id": "ntmreot3PXzMwAWd7", "title": "Cost-effectiveness analysis of ~1260 USD worth of social media ads for fellowship marketing", "postedAt": "2024-01-25T15:18:20.336Z", "htmlBody": "<p><strong>TLDR.: I spent ~1260 USD on social media ads (Facebook/Instagram) over ~1,5 years.&nbsp;</strong><br><strong>We got an additional 53-57 applicants this way, resulting in a cost-effectiveness of 22,1-23,8 USD per applicant.</strong></p><p><i>Disclaimer: I wanted to capture 80% of the value of what I have to say without putting a lot of time into writing. This means that the post is somewhat rough around the edges, but hopefully, it will be still useful.</i></p><p>I have been very excited about experimenting with paid ads to reach out to people who would otherwise not hear about our Into to EA and AGISF programs. This post is a summary of how I spent ~1260 USD on paid ads for social media, and a botec of what it bought us. Please take all results with a grain of salt, as the data is limited and one thing that works for us might not apply in other contexts. That being said, I\u2019m quite confident that groups that want to increase the number of talented and diverse applicants to their programs should at least experiment with using paid ads.</p><h1>Cost-effectiveness</h1><p>I overall spent ~1260 USD, which resulted in 53 additional applicants to our fellowships over 1,5 years (23,8 USD per applicant). At least 4 of these 53 applicants also invited a friend along with them to our program, and if we count them as well, we got overall 57 additional applicants, which slightly improves the cost-effectiveness to 22,1 USD per applicant.</p><p>You can take a look at the raw-ish data&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1X0ft-TpN7aKTO6ZQa7Aqnfwz-NIfYiTa41otJ60zlZE/edit?usp=sharing\"><u>here</u></a> as well as see the breakdown by campaign and course type (EA vs. AIS).</p><h1>Impact</h1><p>I think most of the expected impact of this will come from the ~30% of the overall applicants who engaged with the courses very seriously and took a lot of value from them.&nbsp;</p><p>Unfortunately, I didn\u2019t do an amazing job keeping track of what % of the original 53-57 applicants never started the course. I would estimate this to be around 20-35%. Given that many people never start the course, I think it\u2019s really valuable to encourage people to sign up for your newsletter<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefutnm1bdcin\"><sup><a href=\"#fnutnm1bdcin\">[1]</a></sup></span>&nbsp;as part of the application process - or if they have a good application, reach out to them in the next round.&nbsp;</p><p>As for the rest of the applications, I think it\u2019s pretty similar to the usual fellowship experience, some people drop out after a couple of sessions, some finish it but end up disappearing after the course, etc.</p><p><i>It goes without saying, but of course, this is not a judgment on people\u2019s intrinsic value!</i></p><h1>Additional points and caveats:</h1><ul><li>Note that the courses I was advertising were <a href=\"https://forum.effectivealtruism.org/posts/inpofrDDGJHtJvcyn/consider-splitting-your-fellowships-into-two-parts-to\">4 sessions only</a>, and sometimes it was an <a href=\"https://forum.effectivealtruism.org/posts/vGrHhFp4hyDtfsbvh/onboarding-students-to-ea-ais-in-4-days-with-an-intensive\">intensive 1-week course</a> - which I think partly improved the cost-effectiveness but can have other drawbacks, see the discussion <a href=\"https://forum.effectivealtruism.org/posts/inpofrDDGJHtJvcyn/consider-splitting-your-fellowships-into-two-parts-to#The_CONs_of_doing_this_\">here</a> and <a href=\"https://forum.effectivealtruism.org/posts/vGrHhFp4hyDtfsbvh/onboarding-students-to-ea-ais-in-4-days-with-an-intensive#Cons\">here</a>.&nbsp;</li><li>With paid ads, we got to reach out to many talented international students from 3rd world countries, which is awesome - and otherwise, we would have likely not reached them.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreff1gt9gdykrb\"><sup><a href=\"#fnf1gt9gdykrb\">[2]</a></sup></span></li><li>If you have data on the cost-effectiveness of your social media ads (or want to start gathering such data) make sure to reach out!</li></ul><h1>Conclusion</h1><p>Based on this, I will increase our marketing budget, as well as probably expand it to cities where we don\u2019t have an EA presence yet in the country. I think it\u2019s possible that once I have more data, these ads won\u2019t seem as good as now, but even if I\u2019m currently overestimating the cost-effectiveness by 10x - they would still look pretty good.</p><p>If you would like to use social media ads for your national/city/university group, feel free to shoot us an email at info[at]eahungary.com</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnutnm1bdcin\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefutnm1bdcin\">^</a></strong></sup></span><div class=\"footnote-content\"><p>see <a href=\"https://forum.effectivealtruism.org/posts/PDfrbwmhNbFCYmRsQ/the-hasty-start-of-budapest-ai-safety-6-month-update-from-a#On_newsletters\">here </a>or <a href=\"https://forum.effectivealtruism.org/posts/JAM3jGioCwYEWjWPb/lessons-on-sustainable-growth-the-second-year-of-ea-hungary#On_Newsletters\">here</a> if you don't have one but want to use ours as a template</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnf1gt9gdykrb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreff1gt9gdykrb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In Hungary, there are a lot of international students from 3rd world countries who are here on a scholarship. This means that they have already had to go through a filter, and they are more ambitious than the average student. Given that they are in a new country, they are looking for opportunities to take and communities to join. They also already have more of a \u201cbig picture - global mindset\u201d, which is needed for effective altruism. Unfortunately, there is no real \u201csocial infrastructure\u201d provided by the universities to welcome these students into Hungary, so many of them can feel isolated, and understandably so. For a lot of them, our EA and AIS community was able to provide this community, which I\u2019m very happy about. Given this isolation issue, at the moment we have also no other good means of outreach to them, although going to English-speaking university classes and pitching our programs is something I want to do more of. We also found that national students who found us through paid ads are also great, and are at least as motivated (if not more) than hungarians finding out about us through other forms of outreach.</p></div></li></ol>", "user": {"username": "gergogaspar"}}, {"_id": "AMrzfTKHwHheouEDf", "title": "Is it time for EVF to sell Wytham Abbey?", "postedAt": "2024-01-26T07:43:15.998Z", "htmlBody": "<p>The purchase of Wytham Abbey was originally <a href=\"https://forum.effectivealtruism.org/posts/xof7iFB3uh8Kc53bG/why-did-cea-buy-wytham-abbey?commentId=u3yJfbm2pes8TFpYX\">justified</a> as a long term investment, when people were still claiming EA wasn't cash constrained. One of the arguments advanced by defenders of the purchase was that the money wasn't lost, <a href=\"https://forum.effectivealtruism.org/posts/xof7iFB3uh8Kc53bG/why-did-cea-buy-wytham-abbey?commentId=razhcBDfKKkSBHcf8\">merely invested</a>.&nbsp;</p><h2>Right now, EA is hella funding constrained...</h2><p>In the last few months, I've seen multiple posts of EA orgs claiming to be so funding constrained they're <a href=\"https://forum.effectivealtruism.org/posts/fxeaew8FJzhkPCM22/this-might-be-the-last-ai-safety-camp\">facing</a> <a href=\"https://forum.effectivealtruism.org/posts/wcXrW2cyi2zkJxDmo/ea-poland-is-facing-an-existential-risk\">existential</a> <a href=\"https://forum.effectivealtruism.org/posts/uWbY8B4XukB5ds734/ceealar-is-funding-constrained\">risk</a> (disclaimer: I was a trustee of CEEALAR until last month). By the numbers given by those three orgs, 10% of the price of Wytham would be enough to fund them all for several years.&nbsp;</p><p>This is to say nothing of all the organisations <a href=\"https://forum.effectivealtruism.org/topics/funding-request-open?sortedBy=new\">less urgently seeking funding</a>, the fact that regional groups seem to be getting <a href=\"https://forum.effectivealtruism.org/posts/WesEQoAX99QFmoZFe/ea-germany-s-2023-report-2024-plans-and-funding-gap#Funding_Gap\">funding cuts of 40%</a>, of numerous word-of-mouth accounts of people being turned down for funding or not trying to start an organisation because they don't expect to get it, and the fact that earlier this year the EA funds were reportedly suffering some kind of liquidity crisis (and are among those seeking funding now).</p><p>Here's a breakdown of the small-medium size orgs who've written 'we are funding constrained' posts on the forum in the last 6 months or so, along with the length of time the sale of Wytham Abbey (at its original \u00a315,000,000 purchase price) could fund them:<br>&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\"><strong>Organisation</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\"><strong>Annual budget*</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\"><strong>Number of years Wytham Abbey\u2019s sale could fund org</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Source</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\">EA Poland</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a324-48,000</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">312-614</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://forum.effectivealtruism.org/posts/wcXrW2cyi2zkJxDmo/ea-poland-is-facing-an-existential-risk\"><u>Link</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\">Centre for Enabling EA Learning &amp; Research</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a3150-\u00a3300,000</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">50-100</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Personal involvement</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\">AI Safety Camp</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a346-246,000</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">48-326</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://forum.effectivealtruism.org/posts/be2zpvXqYPncYJKoc/funding-case-ai-safety-camp\"><u>Link</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\">Concentric Policies</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a316,500**</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">900**</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://forum.effectivealtruism.org/posts/86RcytpqKDLGG2mE8/ce-incubated-tobacco-and-ncd-policy-charity-updates-funding\"><u>Link</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\">Center on Long-Term Risk</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a3600,000</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">24</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://forum.effectivealtruism.org/posts/yTwR86oBXXLEgHSsG/center-on-long-term-risk-annual-review-and-fundraiser-2023-2\"><u>Link</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\">EA Germany</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a3226,000***</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">66</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://forum.effectivealtruism.org/posts/WesEQoAX99QFmoZFe/ea-germany-s-2023-report-2024-plans-and-funding-gap#Funding_Gap\"><u>Link</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\">Vida Plena\u2019s 'Group Interpersonal Therapy' project</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a3159,000</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">94</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://forum.effectivealtruism.org/posts/MFRqdphhyddjgTwX4/vida-plena-transforming-mental-health-in-ecuador-first-year#2__Marginal_Funding_Proposal__Enhancing_g_IPT_via_Behavioral_Science\"><u>Link</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\">Happier Lives Institute</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a3161,000</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">93</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://forum.effectivealtruism.org/posts/g4QWGj3JFLiKRyxZe/the-happier-lives-institute-is-funding-constrained-and-needs\"><u>Link</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\">Riesgos Catastr\u00f3ficos Globales</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a3137,000</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">109</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://forum.effectivealtruism.org/posts/h9unK57kLnmKdG6uq/riesgos-catastroficos-globales-needs-funding\"><u>Link</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\">Giving What We Can</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a31,650,000</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">9</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://forum.effectivealtruism.org/s/xourt4HttDM5QcHsk/p/a8wijyw45SjwmeLY6#Our_needs\"><u>Link</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\"><strong>All above organisations</strong>&nbsp;<strong>excluding GWWC&nbsp;</strong>(assuming max of budget ranges)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a31,893,500</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">7.9&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:280px\"><strong>All</strong>&nbsp;<strong>above organisations</strong>&nbsp;<strong>including GWWC&nbsp;</strong>(assuming max of budget ranges)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">\u00a33,543,500</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:140px\">4.2&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td></tr></tbody></table></figure><p><br>&nbsp;</p><p>* Converted from various currencies</p><p>** Their stated \u2018funding gap\u2019 for the year. It sounds like that\u2019s their whole planned budget, but isn\u2019t clear</p><p>*** They were seeking replacement funding for the 40% shortfall of this, which they\u2019ve now received</p><h2>... but in five years, EA probably won't need the long-term savings&nbsp;</h2><p>Wytham Abbey was meant to be a multi-year investment. But though EA is <i>currently</i> funding constrained as heck, the consensus estimate seems to be that within half a decade the movement will have <a href=\"https://manifold.markets/DwarkeshPatel/will-there-be-10-new-effective-altr\">multiple new billionaire donors</a> - so investing for a payoff more than a few years ahead rapidly loses value.</p><p>Also (disclaimer again noted) CEEALAR has hosted retreats for <a href=\"https://forum.effectivealtruism.org/posts/FWh2S5g56ghWsw3na/celebrating-2023-10-successes-from-the-past-year-at-ceealar\">Allfed and Orthogonal</a>, and is due to host the forthcoming <a href=\"https://www.ml4good.org/courses/uk-march-2024\">ML4Good bootcamp</a>, so is already serving a similar function to Wytham Abbey - for a fraction of the operational cost, and less than 2% of the purchase/sale value.&nbsp;</p>", "user": {"username": "Arepo"}}, {"_id": "iLRytpwzFwGAdFvkz", "title": "What are the best defenses of human lives being worth living?", "postedAt": "2024-01-24T21:41:35.382Z", "htmlBody": "<p>It seems like an assumption many effective altruists have (including myself) is that human lives are, on net, worth living. However, many people (e.g., many antinatalists) think that most human lives are <i>net </i>negative. I\u2019m curious if there are any good/comprehensive defenses of the idea that human lives today, on average, are worth living by EAs (or by other people) that you\u2019d recommend!</p>", "user": {"username": "Tejas Subramaniam"}}, {"_id": "KdktpyLgnEtmCkGcQ", "title": "AISN #30: Investments in Compute and Military AI\nPlus, Japan and Singapore\u2019s National AI Safety Institutes", "postedAt": "2024-01-24T19:38:43.425Z", "htmlBody": "<p>Welcome to the AI Safety Newsletter by the <a href=\"https://www.safe.ai/\">Center for AI Safety</a>. We discuss developments in AI and AI safety. No technical background required.</p><p>Subscribe <a href=\"https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916\">here</a> to receive future versions.</p><p>Listen to the AI Safety Newsletter for free on <a href=\"https://spotify.link/E6lHa1ij2Cb\">Spotify.</a></p><hr><h2>Compute Investments Continue To Grow</h2><p>Pausing AI development has been proposed as a policy for ensuring safety. For example, an <a href=\"https://futureoflife.org/open-letter/pause-giant-ai-experiments/\">open letter</a> last year from the Future of Life Institute called for a six-month pause on training AI systems more powerful than GPT-4.&nbsp;</p><p>But one interesting fact about frontier AI development is that it comes with natural pauses that can last many months or years. After releasing a frontier model, it takes time for AI developers to construct new compute clusters with larger numbers of more advanced computer chips. The supply of compute is currently unable to keep up with demand, meaning some AI developers cannot buy enough chips for their needs.&nbsp;</p><p>This explains why <a href=\"https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans\">OpenAI was reportedly limited by GPUs last year</a>. Relatedly, the chairman of TSMC, the world\u2019s largest chip manufacturer, <a href=\"https://www.tomshardware.com/news/tsmc-shortage-of-nvidias-ai-gpus-to-persist-for-15-years\">said</a> in September, \u201cCurrently, we cannot fulfill 100% of our customers' needs, but we try to support about 80%.\u201d</p><p>Despite its limited supply, investments in compute have continued to grow. Here, we report on recent news from Meta and OpenAI on their plans for investing in compute.&nbsp;</p><p><strong>Meta is investing in compute to build open-source AGI. </strong>Mark Zuckerberg <a href=\"https://www.instagram.com/p/C2QARHJR1sZ/\">announced</a> that Meta plans to have 350,000 of Nvidia\u2019s most advanced GPUs, the H100, by the end of 2024. This is <a href=\"https://insidehpc.com/2023/06/22000-gpus-inflection-ai-building-22-exaflops-generative-ai-cluster/\">more than ten times</a> the number of GPUs in Inflection AI\u2019s cluster, announced last summer. The only company <a href=\"https://www.forbes.com/sites/johnkoetsier/2024/01/18/zuckerberg-on-ai-meta-building-agi-for-everyone-and-open-sourcing-it/?sh=777ed7d04eab\">expected</a> to purchase as many H100s as Meta is Microsoft.&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/r6bc2iwkmidb6fitdgzn\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/oczaekquo5845cqbzbyh 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/lqb7lprjclma4oewlyal 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/zvo4wjpt43vklrb671ze 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/r6bc2iwkmidb6fitdgzn 1456w\"><figcaption><i>Meta and Microsoft are projected to purchase 3x more leading Nvidia GPUs than their closest competitors. </i><a href=\"https://www.forbes.com/sites/johnkoetsier/2024/01/18/zuckerberg-on-ai-meta-building-agi-for-everyone-and-open-sourcing-it/?sh=777ed7d04eab\"><i>Source</i></a><i>.</i></figcaption></figure><p>Zuckerberg announced that Meta plans to \u201cbuild general intelligence\u201d and \u201copen source it responsibly.\u201d This contrasts with OpenAI and DeepMind\u2019s approaches of closed source development, which some argue reduces risks from malicious use. Advocates of open-source instead argue that broad access to AI will counteract centralization of power and distribute the benefits of AI broadly.&nbsp;</p><p><strong>Sam Altman considers founding a new company for chip design and manufacturing. </strong>Currently, the global supply chain for advanced AI chips is reliant on a few companies. <a href=\"https://www.nytimes.com/2023/08/21/technology/nvidia-ai-chips-gpu.html\">Nvidia is one of those companies</a>, and therefore it has significant control over which companies thrive and struggle in the AI race. But recent news indicates that a new competitor could disrupt Nvidia\u2019s position.&nbsp;</p><p>Bloomberg <a href=\"https://www.bloomberg.com/news/articles/2024-01-19/altman-seeks-to-raise-billions-for-network-of-ai-chip-factories?leadSource=uverify%20wall\">reports</a> that Sam Altman, CEO of OpenAI, is \u201cworking to raise billions of dollars\u201d to \u201cset up a network of factories to manufacture semiconductors.\u201d Sources have <a href=\"https://fortune.com/2024/01/20/openai-ceo-sam-altman-seeking-billions-for-ai-chips-factories-network/\">said</a> Altman is concerned that as AI capabilities improve, there won\u2019t be enough chips for widespread deployment. Chip fabrication plants take years to build, and Altman is rumored to believe that advanced planning is necessary to meet demand at the end of this decade.&nbsp;</p><p><strong>Rumors of compute clusters in the Middle East.</strong> Elon Musk <a href=\"https://www.reddit.com/r/singularity/comments/191mzzp/1_gw_700_000_gpu_cluster_in_2025/\">relayed</a> another rumor on Twitter, saying that he \u201cheard today about a gigawatt-class AI compute cluster being built in Kuwait (or something), with 700,000 B100s.\u201d This is twice as many chips as Meta and Microsoft are expected to purchase this year, and <a href=\"https://www.techradar.com/pro/nvidia-teases-its-most-powerful-gpu-ever-no-its-not-the-newly-announced-h200-but-the-2024-bound-b100-blackwell-ai-powerhouse\">B100s</a> are the next generation of chips that Nvidia plans to release in 2024. Musk says \u201cthere are many such things; that\u2019s just the biggest one I\u2019ve heard of so far.\u201d&nbsp;</p><p>Compute clusters in the Middle East would have access to ample energy sources including oil and solar power, which is a significant constraint on compute cluster operation. Western nations might struggle to enforce policies on AI systems trained in other countries.&nbsp;</p><h2>Developments in Military AI</h2><p>Private corporations have built most of today\u2019s leading AI models. Thus, corporations are often the focus of AI policy efforts to demonstrate the dangerous capabilities of AI systems and ensure that companies do not accidentally release dangerous systems.&nbsp;</p><p>But unlike corporations, militaries are explicitly interested in building AIs with hazardous capabilities. Policies such as the EU AI Act and the White House\u2019s recent <a href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/\">executive order</a> focus on corporate AI development and explicitly exempt militaries from their rules and regulations. Additional effort will therefore be necessary to mitigate risks from military AI.&nbsp;</p><p><strong>OpenAI will allow military use of ChatGPT. </strong><a href=\"https://theintercept.com/2024/01/12/open-ai-military-ban-chatgpt/\">In a recent update to its rules</a> for the use of ChatGPT, OpenAI deleted a prohibition on \u201cmilitary and warfare.\u201d They seem to have a good reason: an OpenAI spokesperson said they\u2019ll be working with DARPA to create tools for improving cybersecurity. DARPA is currently running a <a href=\"https://www.darpa.mil/news-events/2023-08-09\">$20M competition on AI for cybersecurity</a>, which could strengthen our societal resistance against the threat of AI-enabled cyberattacks.&nbsp;</p><p>But it\u2019s possible that OpenAI\u2019s new policy could open the door to other military partnerships. Just as Palantir, Anduril, and Scale AI have developed technology for the US military, OpenAI could follow suit.&nbsp;</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb82b6af5-4413-4cdc-9e53-8dc59accd9c3_650x350.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/elcw73zipj3ebavxueao\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/ld4ktmuharjgs3a50srd 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/jjkkwcwyp8tuj1ei7byj 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/lvmryqeu8rcy28mt2cm2 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/elcw73zipj3ebavxueao 1456w\"></a></p><p><strong>The US military invests in AI capabilities.</strong> OpenAI\u2019s update is part of a larger trend of the Pentagon\u2019s interest in integrating AI into the US military. Last year, the Pentagon tested several <a href=\"https://www.bloomberg.com/news/newsletters/2023-07-05/the-us-military-is-taking-generative-ai-out-for-a-spin\">LLMs in military applications</a> and established a <a href=\"https://www.defense.gov/News/Releases/Release/Article/3489803/dod-announces-establishment-of-generative-ai-task-force/\">generative AI taskforce</a>.&nbsp;</p><p>Early <a href=\"https://www.politico.com/news/2023/12/17/pentagon-drones-replicator-program-funding-00132092\">reports</a> from the Pentagon\u2019s drone program called it \u201cdisorganized and confusing.\u201d Since then, former Google CEO <a href=\"https://www.forbes.com/sites/sarahemerson/2024/01/09/ex-google-ceo-eric-schmidt-is-working-on-a-secret-military-drone-project/\">Eric Schmidt</a> has partnered with the Pentagon on its drone development program. Schmidt will be <a href=\"https://www.nti.org/events/global-security-in-the-age-of-ai-a-conversation-with-eric-schmidt/\">speaking today at 12pm EST</a> with Ernest Moniz, former Secretary of Energy.&nbsp;</p><p><strong>Multilateral efforts towards the responsible use of military AI.</strong> In November, US Vice President Kamala Harris announced that <a href=\"https://www.state.gov/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy/\">31 countries</a> had endorsed the \u201c<a href=\"https://www.state.gov/political-declaration-on-responsible-military-use-of-artificial-intelligence-and-autonomy-2/\">Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy</a>.\u201d The declaration makes few concrete commitments, but it is a sign that many countries recognize and hope to reduce the risks of military AI systems.&nbsp;</p><p>The document provides a hard-nosed perspective on the military use of AI. It does not ban the use of lethal autonomous weapons, as many countries have requested, nor does it require a \u201chuman in the loop\u201d to make decisions about the use of lethal force. The <a href=\"https://perma.cc/SJW3-3HL2\">first version</a> of the document said that \u201cstates should maintain human control\u2026concerning nuclear weapons employment,\u201d but the most recent version has scrapped that guidance. Although the declaration allows for AI in military applications, it recommends careful management of the associated risks.&nbsp;</p><p>Even in the presence of military competition, it can be important to seek opportunities for cooperation. During the Cold War, the United States and the Soviet Union agreed on several different arms control measures. For example, after several near collisions between US and Soviet ships and planes, the two countries <a href=\"https://2009-2017.state.gov/t/isn/4791.htm#:~:text=In%20the%20protocol%20signed%20in,force%20structure%20of%20the%20parties\">agreed</a> in 1972 to steps for avoiding collisions and minimizing the risk of escalation to war in the event of a collision. Similarly, if a buildup of AI weapons threatens global security, even geopolitical rivals might seek to coordinate on arms control policies to reduce collective risks.&nbsp;</p><h2>Japan and Singapore Support AI Safety</h2><p><strong>Japan announces an AI safety institute. </strong>Japan\u2019s Prime Minister, Fumio Kishida<strong>,</strong> <a href=\"https://asianews.network/japan-government-to-establish-ai-safety-institute-in-january/\">announced</a> last month that Japan intends to form an AI safety institute to \u201cconduct research on safety evaluation methods, create standards and carry out other matters.\u201d The institute has yet to launch, although more information is expected this month.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/ewfv2hwq4pbamwb7wjrd\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/luzoyglge7jxwl8vks0p 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/xgpymhgbohsasblvuznc 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/b9qc9cnmdrujooh3osnl 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KdktpyLgnEtmCkGcQ/ewfv2hwq4pbamwb7wjrd 1456w\"><figcaption><i>National leaders at the G7\u2019s Hiroshima Summit, where AI was a top concern</i></figcaption></figure><p>The announcement was accompanied with the release of a <a href=\"https://www8.cao.go.jp/cstp/ai/ai_senryaku/7kai/13gaidorain.pdf\">192-page draft</a> set of guidelines for AI companies. Companies developing advanced AI systems are advised to follow the <a href=\"https://www.mofa.go.jp/files/100573473.pdf\">Code of Conduct</a> established at the G7 Hiroshima Summit. Among other provisions, the code directs AI companies to publicly report system capabilities, implement robust cybersecurity, and share best practices on risk mitigation.</p><p><strong>Singapore proposes a governance framework for generative AI. </strong>Last week,<strong> </strong>Singapore <a href=\"https://www.imda.gov.sg/resources/press-releases-factsheets-and-speeches/press-releases/2024/public-consult-model-ai-governance-framework-genai\">released</a> a draft <i>Model AI Governance Framework for Generative AI</i>. The new draft updates a <a href=\"https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/SGModelAIGovFramework2.pdf\">previous document</a> from 2020. The release included a request for feedback, which can be submitted by emailing info@aiverify.sg by March 15th.</p><p>The document was developed by the <a href=\"https://aiverifyfoundation.sg/\">AI Verify Foundation</a> \u2014 a subsidiary of the Infocommunications Media Development Authority of Singapore. Notably, the AI Verify Foundation has indicated concerns about catastrophic AI risks, including releasing <a href=\"https://aiverifyfoundation.sg/downloads/Cataloguing_LLM_Evaluations.pdf\">a paper on evaluating LLMs</a> for extreme risks.&nbsp;</p><h2>Links</h2><p>First, we have a few US legislative proposals:&nbsp;</p><ul><li>Democrats in Washington reportedly <a href=\"https://fedscoop.com/bipartisan-ai-legislation-senate-commerce-committee-cantwell/\">plan to introduce</a> several new AI bills in early 2024.&nbsp;</li><li>Bipartisan members of both the House and Senate have introduced bills to <a href=\"https://www.axios.com/pro/tech-policy/2024/01/09/senate-nist-ai-bill-gets-house-companion\">require federal agencies to adhere to the NIST AI RMF</a> when using AI.&nbsp;</li><li>The proposed <a href=\"https://beyer.house.gov/uploadedfiles/ai_foundation_model_transparency_act_text_118.pdf\">AI Foundation Model Transparency Act of 2023</a> would require AI developers to disclose information about training data, safety evaluations, and risk management policies.&nbsp;</li><li>The National AI Advisory Committee <a href=\"https://ai.gov/wp-content/uploads/2023/12/RECOMMENDATION_Implementation-of-the-NIST-AI-Safety-Institute.pdf\">suggested</a> that NIST could use $100M or more for their work on AI safety, which is far more than suggested by by <a href=\"https://www.anthropic.com/news/an-ai-policy-tool-for-today-ambitiously-invest-in-nist\">previous</a> <a href=\"https://www.young.senate.gov/imo/media/doc/usaisi_funding_letter.pdf\">supporters</a>.&nbsp;</li></ul><p>Other policy discussions:&nbsp;</p><ul><li>How OpenAI is approaching the <a href=\"https://openai.com/blog/how-openai-is-approaching-2024-worldwide-elections?utm_source=tldrai\">2024 elections</a>.&nbsp;</li><li>The EU opens an <a href=\"https://arstechnica.com/tech-policy/2024/01/regulators-arent-convinced-that-microsoft-and-openai-operate-independently/?utm_source=tldrai\">antitrust investigation</a> about the relationship between Microsoft and OpenAI.&nbsp;</li><li>OpenAI <a href=\"https://openai.com/blog/openai-and-journalism?utm_source=tldrai\">responds</a> to the New York Times lawsuit over training on copyrighted data.&nbsp;</li><li>OpenAI has paid some media outlets <a href=\"https://www.theverge.com/2024/1/4/24025409/openai-training-data-lowball-nyt-ai-copyright\">up to $5M per year</a> for access to their data.&nbsp;</li><li>A <a href=\"https://www.newyorker.com/magazine/2024/01/22/who-owns-this-sentence-a-history-of-copyrights-and-wrongs-david-bellos-alexandre-montagu-book-review\">book review</a> discusses AI and the copyright system.&nbsp;</li><li>AI scientists from American companies and Chinese universities met to <a href=\"https://www.ft.com/content/f87b693f-9ba3-4929-8b95-a296b0278021?segmentid=SEGMENTID45a55daa-06c5-0aba-131a-a1eb758674ae\">discuss</a> AI risks.&nbsp;</li><li>To enforce AI policies, a new white paper advocates research on <a href=\"https://www.cnas.org/publications/reports/secure-governable-chips\">secure, governable chips</a>.&nbsp;</li></ul><p>Technical AI developments:&nbsp;</p><ul><li>DeepMind created an AI system that can <a href=\"https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/\">prove geometric theorems</a> at an expert human level.&nbsp;</li><li><a href=\"https://chat.deepseek.com/sign_in\">DeepSeek</a>, a Chinese company, trained a model which claims to <a href=\"https://arxiv.org/abs/2401.02954\">match GPT-3.5\u2019s performance</a>.&nbsp;</li><li>Here are the results of ten research projects on <a href=\"https://openai.com/blog/democratic-inputs-to-ai\">Democratic Inputs to AI</a> sponsored by OpenAI.&nbsp;</li></ul><p>Finally, the Center for AI Safety has a cluster of 256 A100 GPUs available for safety research. Apply for access <a href=\"https://www.safe.ai/compute-cluster\">here</a>.&nbsp;</p><p>See also: <a href=\"https://www.safe.ai/\">CAIS website</a>, <a href=\"https://twitter.com/ai_risks?lang=en\">CAIS twitter</a>, <a href=\"https://newsletter.mlsafety.org/\">A technical safety research newsletter</a>, <a href=\"https://arxiv.org/abs/2306.12001\">An Overview of Catastrophic AI Risks</a>, <a href=\"https://www.aisafetybook.com\">our new textbook</a>, and our <a href=\"https://forms.gle/EU3jfTkxfFgyWVmV7\">feedback form</a></p><p>Listen to the AI Safety Newsletter for free on <a href=\"https://spotify.link/E6lHa1ij2Cb\">Spotify.</a></p><p>Subscribe <a href=\"https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916\">here</a> to receive future versions.</p>", "user": {"username": "Center for AI Safety"}}, {"_id": "k9F2bcePw26Khr9wh", "title": "Legal Impact for Chickens seeks an Operations Specialist.", "postedAt": "2024-01-24T18:14:12.443Z", "htmlBody": "<p>Dear EA Forum Readers,</p><p><a href=\"https://www.legalimpactforchickens.org/\">Legal Impact for Chickens</a> is looking for a passionate and hard-working <a href=\"https://www.legalimpactforchickens.org/operations\">Operations Specialist</a> to join us as we continue to grow our nonprofit and fight for animals. This is a new position, and you will have the ability to influence our operations and play an important role in our work.</p><p>The responsibilities of this position are varied, covering operational, administrative, and paralegal work, and we will consider a variety of candidates and experiences. Therefore, the final job title may differ depending on the final candidate.</p><p>Want to join us?</p><p>&nbsp;</p><p><strong>About our work and why you should join us</strong></p><p><a href=\"https://www.legalimpactforchickens.org/\">Legal Impact for Chickens (LIC)</a> is a 501(c)(3) litigation nonprofit. We work to protect farmed animals.</p><p>You may have seen our <a href=\"https://www.legalimpactforchickens.org/costco\">Costco shareholder derivative suit</a> in <a href=\"https://www.washingtonpost.com/food/2022/06/23/costco-chicken-lawsuit/?utm_campaign=wp_main&amp;utm_medium=social&amp;utm_source=twitter\">The Washington Post</a>, <a href=\"https://www.foxbusiness.com/lifestyle/costco-rotisserie-chickens-tied-bird-mistreatment-lawsuit\">Fox Business</a>, or <a href=\"https://www.legalimpactforchickens.org/CNN%20Business\">CNN </a><a href=\"https://www.cnn.com/2022/06/24/business/costco-rotisserie-chicken-lawsuit/index.html?fbclid=IwAR2UsCkuuJ8NKnBoSUXzWQ3XBKlFBzg44hvwJ6pPjZx8uTdoaicdKtwVGeg&amp;utm_content=2022-06-25T06%3A00%3A16&amp;utm_medium=social&amp;utm_source=fbCNN&amp;utm_term=link\">Business</a>\u2014or even on <a href=\"https://www.tiktok.com/@thelawyerangela/video/7236551017465171242\">TikTok</a>.</p><p>You also may have heard of LIC from our recent Animal Charity Evaluators (ACE) <a href=\"https://www.legalimpactforchickens.org/blog/animal-charity-evaluators-selects-legal-impact-for-chickens-as-2023-recommended-charity\">recommendation</a>.</p><p>Now, we\u2019re looking for our next hire: an entrepreneurial Operations Specialist to support us in our fight for animals!</p><p>Legal Impact for Chickens is currently a team of <a href=\"https://www.legalimpactforchickens.org/team\">three litigators</a>. You will join LIC as our first non-litigator employee and support the entire team.</p><p>&nbsp;</p><p><strong>About you</strong></p><p>You might be a great fit for <a href=\"https://www.legalimpactforchickens.org/operations\">this position</a> if you have many of the following qualities:</p><p>\u2022 Passion for helping farmed animals</p><p>\u2022 Extremely organized, thoughtful, and dependable</p><p>\u2022 Strong interpersonal skills</p><p>\u2022 Interest in the law and belief that litigation can help animals</p><p>\u2022 Zealous, creative, and enthusiastic</p><p>\u2022 Excited to build this startup nonprofit!</p><p>\u2022 Willingness to help with all types of nonprofit startup work, from litigation support to HR to finance</p><p>\u2022 Strong work ethic and initiative</p><p>\u2022 Love of learning</p><p>\u2022 Paralegal experience or certificate preferred, but not required</p><p>\u2022 Experience with various aspects of operations (such as bookkeeping and IT) preferred, but not required</p><p>\u2022 Experience growing a new team preferred, but not required</p><p>\u2022 Kind to our fellow humans, and excited about creating a welcoming, inclusive team</p><p>&nbsp;</p><p><strong>About the role</strong></p><p>You will be an integral part of LIC. You\u2019ll help shape our organization\u2019s future.</p><p>Your <a href=\"https://www.legalimpactforchickens.org/operations\">role</a> will be a combination of (1) assisting the lawyers with litigation tasks, and (2) helping with everything else we need to do, to build and run a growing nonprofit organization!</p><p>Since this is such a small organization, you\u2019ll wear many hats: Sometimes you\u2019ll act as a paralegal, formatting a table of authorities, performing legal research, or preparing a binder for a hearing. Sometimes you\u2019ll act as an HR manager, making sure we have the right trainings and benefits available. Sometimes you\u2019ll act as an administrative assistant, tracking expenditures and donations, booking travel arrangements, or helping LIC\u2019s president with email management. Sometimes you\u2019ll act as LIC\u2019s front line for communicating with the public, monitoring info@legalimpactforchickens.org emails, thanking donors, or making calls to customer service representatives on LIC\u2019s behalf. Sometimes you\u2019ll pitch in on LIC\u2019s communications, social media, and public education efforts. If you\u2019re the kind of person who likes to handle many different types of work, this role is for you!</p><p>This job offers tremendous opportunity for professional growth and the ability to create valuable impact for animals. The hope is for you to become an indispensable, long-time member of our new team.</p><p><u>Commitment:</u> Full time</p><p><u>Location and travel:</u> This is a remote, U.S.-based position. You must be available to travel for work as needed, since we will litigate all over the country.</p><p><u>Reports to:</u> Alene Anello, LIC\u2019s president</p><p><u>Salary:</u> $50,000\u2013$70,000 depending on experience</p><p><u>Benefits:</u> Health insurance (with ability to buy dental), 401(k), life insurance, flexible schedule, unlimited PTO (plus mandatory vacation!), room for advancement as the organization grows</p><p>&nbsp;</p><p><strong>One more thing!</strong></p><p>LIC is an equal opportunity employer. Women, people of color, and those from other marginalized groups are strongly encouraged to apply. Applicants will receive consideration without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, ancestry, citizenship status, disability, age, medical condition, veteran status, marital status, political affiliation, or any other protected characteristic.</p><p>&nbsp;</p><p><strong>To Apply</strong></p><p>To apply, please email your cover letter and resume, combined as one PDF, to info@legalimpactforchickens.org.</p><p>&nbsp;</p><p>Thank you for your time and your compassion!</p><p>Sincerely,</p><p>Legal Impact for Chickens</p>", "user": {"username": "alene"}}, {"_id": "9PRz6SRtCzAhyKR8N", "title": "Agents that act for reasons: a thought experiment", "postedAt": "2024-01-24T16:48:28.071Z", "htmlBody": "<p><i>Posted also on the </i><a href=\"https://www.alignmentforum.org/s/NouBkh4qnK8uKwn3L/p/gEcNyiPgQs9BWTNws\"><i>AI Alignment Forum</i></a><i>.</i></p><p>In<a href=\"https://www.alignmentforum.org/posts/7HW6bjsBQ6zA6rjt4/free-agents\">&nbsp;</a><a href=\"https://forum.effectivealtruism.org/posts/QAqBjfbDuStHKzbAu/free-agents\"><u>Free agents</u></a> I\u2019ve given various ideas about how to design an AI that reasons like an independent thinker and reaches moral conclusions by doing so. Here I\u2019d like to add another related idea, in the form of a short story / thought experiment.</p><p><i>Cursed</i></p><p>Somehow, you have been cursed. As a result of this unknown curse that is on you now, you are unable to have any positive or negative feeling. For example, you don\u2019t feel pain from injuries, nothing makes you anxious or excited or sad, you can\u2019t have fun anymore. If it helps you, imagine your visual field without colours, only with dull shades of black and white that never feel disgusting or beautiful.</p><p>Before we get too depressed, let\u2019s add another detail: this curse also makes you immune to death (and other states similar to permanent sleep or unconsciousness). If you get stabbed, your body magically recovers as if nothing happened. Although this element might add a bit of fun to the story from our external perspective, keep in mind that the cursed version of you in the story doesn\u2019t feel curious about anything, nor has fun when thinking about the various things you could do as an immortal being.</p><p>No one else is subject to the same curse. If you see someone having fun and laughing, the sentence \u201cThis person is feeling good right now\u201d makes sense to you: although you can\u2019t imagine nor recall what feeling good feels like, your understanding of the world around you remained intact somehow. (Note: I am&nbsp;<i>not</i> saying that this is what would actually happen in a human being who actually lost the capacity for perceiving<a href=\"https://en.wikipedia.org/wiki/Valence_(psychology)\">&nbsp;<u>valence</u></a>. It\u2019s a thought experiment!)</p><p>Finally, let\u2019s also say that going back to your previous life is not an option. In this story, you can\u2019t learn anything about the cause of the curse or how to reverse it.</p><p>To recap:</p><ul><li>You can\u2019t feel anything</li><li>You can\u2019t die</li><li>You can\u2019t go back to your previous state</li><li>The curse only affects you. Others\u2019 experiences are normal.</li></ul><p>In this situation, what do you do?</p><hr><p>In philosophy, there is some discourse around reasons for actions, normative reasons, motivating reasons, blah blah blah. Every philosopher has their own theory and uses words differently, so instead of citing centuries of philosophical debates, I\u2019ll be maximally biased and use one framework that seems sensible to me. In&nbsp;<a href=\"https://en.wikipedia.org/wiki/Ethical_Intuitionism_(book)\"><i><u>Ethical Intuitionism</u></i></a>, contemporary philosopher Michael Huemer distinguishes \u201cfour kinds of motivations we are subject to\u201d:</p><ul><li>Appetites: examples are hunger, thirst, lust (simple, instinctive desires)</li><li>Emotions: anger, fear, love (emotional desires, they seem to involve a more sophisticated kind of cognition than appetites)</li><li>Prudence: motivation to pursue or avoid something because it furthers or sets back one\u2019s own interests, like maintaining good health</li><li>Impartial reasons: motivation to act due to what one recognises as good, fair, honest, et cetera.</li></ul><p>You can find more details in section 7.3 of the book.</p><p>We can interpret the above thought experiment as asking: in the absence of appetites and emotions \u2014 call these two \u201cdesires\u201d, if you wish \u2014 what would you do? Without desires and without any kind of worry about your own death, does it still make sense to talk about self-interest? What would you do without desires and without self-interest?</p><hr><p>My guess is that, in the situation described in&nbsp;<i>Cursed</i>, at least some, if not many, would decide to do things for others. The underlying intuition seems to be that, without one\u2019s own emotional states and interests, one would prioritise others\u2019 emotional states and interests, simply due to the fact that nothing else seems worth doing in that situation.</p><p>In other words, although one might need emotional states to first develop an accurate understanding of the world, feeling positive emotions when acting morally is not the main reason why one keeps acting morally. Ask yourself: if, from now on, you noticed that you derive some pleasure from causing harm to others, would you completely change your behaviour and start acting immorally? You might be tempted<i>&nbsp;</i>or have some motivation to cause harm, but that motivation would conflict with other reasons for action, including moral reasons.</p><p>Anyway, you might not buy into everything I\u2019ve just said. The important point is that at least some human beings, in&nbsp;<i>Cursed</i>, would act morally. So, there is a class of agents that, in the&nbsp;<i>Cursed</i> situation, would act morally \u2014 according to their own understanding of what \u201cmorally\u201d means.</p><p>What\u2019s the point of all this for AI? I claim that the class of agents just described includes some artificial agents. In other words, I claim that it\u2019s possible to build an AI whose cognitive state is roughly similar to the cognitive state of a human in the&nbsp;<i>Cursed</i> situation, and that this AI acts morally \u2014 for the reason that, in such a cognitive state, nothing else seems worth doing.</p><p><br>&nbsp;</p>", "user": {"username": "Michele Campolo"}}, {"_id": "y7udR2zBnHsYNtXrK", "title": "Walter Veit interviews Richard Yetter Chappell: Why Not Effective Altruism? ", "postedAt": "2024-01-24T14:39:19.060Z", "htmlBody": "<p>Hi there,</p><p>I started a podcast and figured this episode might of interest to effective altruists.</p><p><strong>Episode description:</strong></p><blockquote><p>Richard Yetter Chappell is an Associate Professor of Philosophy at the University of Miami. Today we'll talk about the common criticisms against effective altruism.</p></blockquote><p>&nbsp;</p><p>Warmly,</p><p>Walter Veit</p>", "user": {"username": "Walter Veit"}}, {"_id": "izuxGfK4284TYmWfG", "title": "My guess for the most cost effective AI Safety projects", "postedAt": "2024-01-24T12:21:23.955Z", "htmlBody": "<p><i>Epistemic status: Guessing based on what makes sense to me. I have not done any actual calculations. If someone else wants to do that, this would be great.&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/CuPnmeS4v5sFE6nQj/impact-assessment-of-ai-safety-camp-arb-research?commentId=cveB8XqR2W8teT4GF\"><i><u>Arb research has done some calculations for AISC</u></i></a><i>.</i></p><p>For some time, AI Safety has had a culture of not caring about&nbsp; cost effectiveness because there was so much money anyway. I am not convinced that this was ever the correct approach, but regardless, it\u2019s not a good approach anymore. With the current funding situation AI Safety should care about cost effectiveness.&nbsp;</p><p>This post is meant as a conversation starter.&nbsp;</p><p>However, I\u2019m&nbsp;<strong>not</strong> trying to start another conversation about \u201cWhat should OpenPhil do with their money\u201d. I\u2019m not interested in that conversation, unless I\u2019m talking to someone who is actually involved in that decision process.&nbsp;</p><p>The conversation I\u2019d like to have is with:&nbsp;</p><ul><li>People making funding decisions for themselves. There are many projects individual donors can contribute to.&nbsp;</li><li>People who want to help make a more thorough quantitative analysis. If you\u2019re interested in this, I\u2019m happy to answer questions about anything I\u2019m involved in.</li></ul><h1>Some context (feel free to skip)</h1><p><strong>What is the current situation?</strong></p><ul><li>Interest in AI Safety is growing fast. With this comes more funding opportunities.</li><li>We have not had any new large donors in a while (not counting FTX, since that money was not real). OpenPhil is still the largest source of funding.</li><li>You should not assume that OpenPhil is already funding everything that you think is worth funding. I\u2019ve had many private conversations with people who disagree with what OpenPhil chooses to fund or not fund. This means that even if OpenPhil had infinite money, there would probably still be funding opportunities for other donors.</li><li>Some orgs are still dealing with the aftermath of FTX. E.g. promised funds that were never paid out, or money that has already been used and might be recalled in a clawback claim.</li></ul><p><strong>What about government funding?</strong></p><p>Governments are getting interested in AI risk. This is great, and will lead to a lot of more money spent on AI Safety. However this will be spent on things that look good and respectable to the government, which will not cover everything EAs think is worth funding.&nbsp;</p><p>Things I expect the governments to spend money on:</p><ul><li>Evaluations of models</li><li>Interpretability</li><li>Supporting prestigious academics and their teams</li></ul><p>Things I don\u2019t expect governments to spend money on:</p><ul><li>Community building and upskilling programs outside academia</li><li>More obscure research directions</li><li>People without standard credentials</li></ul><p>I could be wrong about the specifics, but I don\u2019t think I\u2019m wrong about the fact that government funding will leave some very valuable funding opportunities on the table. I.e, there is still room for EA funding to make a large difference.&nbsp;</p><p>I expect academic AI Safety research to be very important, but I also think there is a role for things that don\u2019t quite fit into academia, and this is where I think EA funding can make a huge difference.</p><h1>My guess for the most cost effective AI Safety projects</h1><p>In a better version of this post I would have summaries of all the projects. But this post is the version I have time to write. Follow the links to the project descriptions on Manifold for more info.</p><h2>Scalable online infrastructure</h2><p>These are all project where a small team can serve a large number of people. I expect the most cost effective AI Safety projects to be in this category.&nbsp;</p><h3><a href=\"https://manifund.org/projects/building-and-maintaining-the-alignment-ecosystem\"><strong><u>Building and maintaining the Alignment Ecosystem | Manifund</u></strong></a><strong><u>&nbsp;</u></strong></h3><p>Alignment Ecosystem Development (AED) is building and maintaining most of the AI Safety online information platforms. Their resources are infinitely scalable, i.e. they can support an arbitrary large amount of traffic to their websites, which means their impact grows as the community grows.</p><p>Their current biggest bottleneck is visibility. Not enough people are aware of their resources. I encourage everyone to share&nbsp;<a href=\"https://aisafety.training/\"><u>aisafety.training</u></a>, which I claim to be the single most useful link to give to aspiring AI safety researchers.&nbsp;</p><p>Their second biggest bottleneck is funding. The project is currently volunteer based, which is a fragile situation. This is bad, because with this type of project, reliability and continuity is super important.&nbsp;</p><ul><li>The longer a resource exists the more people will find out about it and start using it.</li><li>A website like <a href=\"https://aisafety.training\">aisafety.training</a> is much more useful if I can trust that it has all the events I might want to go to, then if it has just some of them.</li></ul><p>AED has done&nbsp;<i>a lot</i> with just volunteer power. It\u2019s possible that they will be able to continue this way, however with a small team of paid workers, the project would be much more stable. Given the size of their potential impact, I expect that funding them would be a cost effective donation.</p><h3><a href=\"https://manifund.org/projects/10th-edition-of-ai-safety-camp?tab=bids\"><strong><u>10th edition of AI Safety Camp | Manifund</u></strong></a><strong><u>&nbsp;</u></strong></h3><p>Disclosure: I\u2019m one of the AISC organisers.</p><p>AISC is an online and part time AI Safety research program. We help people take the step from just learning and thinking about AI Safety, to actually getting involved and doing something.&nbsp;<br><br>We\u2019ve found a format that scales very well. The 9th edition of AISC has 133 participants, which we did with only 2 organisers. I expect the next one to be even bigger, if it happens.&nbsp;</p><p>Arb is currently evaluating AI Safety camp, including cost effectiveness. See their&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/CuPnmeS4v5sFE6nQj/impact-assessment-of-ai-safety-camp-arb-research?utm_campaign=publish_share&amp;utm_source=link\"><u>preliminary report here</u></a>.</p><p>AISC is currently fundraising in order to be able to continue existing. We have a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/fxeaew8FJzhkPCM22/this-might-be-the-last-ai-safety-camp\"><u>separate post about that here</u></a>.</p><h3><a href=\"https://aisafetyfundamentals.com/\"><strong><u>AI Safety Fundamentals \u2013 BlueDot Impact</u></strong></a><strong><u>&nbsp;</u></strong></h3><p>I don\u2019t know if they need more money. I have not found any fundraiser, but I've also not looked very hard. I list them here anyway because they obviously belong on this list.</p><p>BlueDot impact is not just running large online courses. Their curriculum is used buy many more in-person and online study groups and programs.</p><h3><a href=\"https://manifund.org/projects/help-apart-expand-global-ai-safety-research\">Help Apart Expand Global AI Safety Research | Manifund</a>&nbsp;</h3><p>Edit: Apart was not originally included in this blogpost, because I forgot. But they clearly belong here too.</p><p>Apart runs the <a href=\"https://alignmentjam.com/\">Alignment Jams</a>, which are weekend long research sprints on various AI safety relevant topics. The Alignment Jams are hybrid online and in person events, i.e. it's possible to join online from anywhere in the world, but Apart also helps local groups to run in-person meetups centred around these sprints.&nbsp;</p><h2>Low cost hubs&nbsp;</h2><p>My guess is that this category is less cost effective than scalable online infrastructure, but will be able to absorb more funding.</p><p>It\u2019s hard to be an AI safety researcher all on your own, but it\u2019s also hard to afford to move to London or the SF Bay area. This is why I\u2019m excited about projects aimed at starting and maintaining hubs in other locations. It lowers the barrier to entry, and also lowers the cost of salaries for people working there.</p><p>I know of two projects in this category, and I think both are promising.</p><ul><li><a href=\"https://manifund.org/projects/ai-safety-serbia-hub---office-space-for-frugal-ai-safety-researchers\"><strong><u>AI Safety Serbia Hub - Office Space for (Frugal) AI Safety Researchers | Manifund</u></strong></a></li><li><a href=\"https://manifund.org/projects/ceealar\"><strong><u>EA Hotel (aka CEEALAR) | Manifund</u></strong></a></li></ul><p>&nbsp;</p><p><br><br><br><br>&nbsp;</p>", "user": {"username": "Linda Linsefors"}}, {"_id": "fxeaew8FJzhkPCM22", "title": "This might be the last AI Safety Camp", "postedAt": "2024-01-24T09:29:02.710Z", "htmlBody": "<p>We are organising the 9th edition without funds. We have no personal runway left to do this again. We will not run the 10th edition without funding.&nbsp;<br>&nbsp;</p><p>In a nutshell:</p><ol><li>Last month, we put out AI Safety Camp\u2019s&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/be2zpvXqYPncYJKoc/funding-case-ai-safety-camp\"><u>funding case</u></a>.&nbsp;<br>A private donor then decided to donate \u20ac5K.&nbsp;<br>&nbsp;</li><li>Five more donors offered $7K on&nbsp;<a href=\"https://manifund.org/projects/10th-edition-of-ai-safety-camp?tab=bids\"><u>Manifund</u></a>.&nbsp;<br>For that $7K to not be wiped out and returned, another&nbsp;<strong>$21K in funding is needed</strong>. At that level, we may be able to run a minimal version of AI Safety Camp next year, where we get research leads started in the first 2.5 months, and leave the rest to them.<br>&nbsp;</li><li>The current edition is off to a productive start!&nbsp;<br>A total of 130 participants joined, spread over 26 projects. The&nbsp;<a href=\"https://aisafety.camp/#Projects\"><u>projects</u></a> are diverse \u2013&nbsp;from agent foundations, to mechanistic interpretability, to copyright litigation.<br>&nbsp;</li><li>Our personal runways are running out.&nbsp;<br>If we do not get the funding, we have to move on. It\u2019s hard to start a program again once organisers move on, so this likely means the end of AI Safety Camp.<br>&nbsp;</li><li>We commissioned Arb Research to do an&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/CuPnmeS4v5sFE6nQj/impact-assessment-of-ai-safety-camp-arb-research\"><u>impact assessment</u></a>.&nbsp;<br>One preliminary result is that AISC creates one new AI safety researcher per around $12k-$30k USD of funding.&nbsp;<br><br>&nbsp;</li></ol><p>How can you support us:</p><ul><li><strong>Spread the word</strong>. When we tell people AISC doesn't have any money, most people are surprised. If more people knew of our situation, we believe we would get the donations we need.<br>&nbsp;</li><li><strong>Donate</strong>. Make a donation through&nbsp;<a href=\"https://manifund.org/projects/10th-edition-of-ai-safety-camp?tab=comments\"><u>Manifund</u></a> to help us reach the $28K threshold.<br>Reach out to remmelt@aisafety.camp for other donation options.</li></ul>", "user": {"username": "remmelt"}}, {"_id": "C23sNoAmA8xjJejZz", "title": "AMA: Emma Slawinski, the RSPCA's Director of Policy, Prevention and Campaigns. ", "postedAt": "2024-01-24T09:16:11.457Z", "htmlBody": "<p><s>I\u2019ll be interviewing Emma Slawinski for an&nbsp;</s><a href=\"https://forum.effectivealtruism.org/posts/rWRSvRxAco2bLoXKr/podcast-transcript-ama-founder-and-ceo-of-amf-rob-mather\"><s><u>audio AMA</u></s></a><s> on the 1st of February. Ask your questions here, and we will cover them in the interview! The interview will be published as a podcast and transcript.&nbsp;</s></p><p>Update: Emma Slawinski saw how detailed the questions were and wanted to respond in text instead! Expect her answers here soon.&nbsp;</p><blockquote><p>\u201cFactory-farmed chickens live absolutely horrible lives; their suffering is&nbsp;<strong>the single biggest animal welfare issue facing the country at present</strong> [my emphasis]\u201d ~ <a href=\"https://www.theguardian.com/world/2024/jan/06/rspca-vows-reform-absolutely-horrible-treatment-poultry-uk\">Emma Slawinski</a></p></blockquote><p><a href=\"https://www.linkedin.com/in/emmaslawinski/details/experience/\"><u>Emma Slawinski</u></a> is the Director of Policy, Prevention and Campaigns for the&nbsp;<a href=\"https://www.rspca.org.uk/whatwedo\"><u>RSPCA</u></a> (the Royal Society for the Prevention of Cruelty to Animals- the largest animal welfare focused charity in the UK). She has over a decade of experience in animal welfare campaigning. Previously, she worked for organisations such as&nbsp;<a href=\"https://www.ciwf.org.uk/\"><u>Compassion in World Farming</u></a>, where she worked on the&nbsp;<a href=\"https://www.endthecageage.eu/en/\"><u>End The Cage Age&nbsp;</u></a>campaign, and&nbsp;<a href=\"https://worldanimalprotection.org/\"><u>World Animal Protection</u></a>.&nbsp;</p><p>At the RSPCA, she has:&nbsp;</p><ul><li>Worked on the<a href=\"https://www.rspca.org.uk/getinvolved/campaign/greyhounds\"><u> #CutTheChase campaign</u></a> to end greyhound racing in the UK, and the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Animal_Welfare_(Kept_Animals)_Bill\"><u>Kept Animals Bill</u></a> Campaign.</li><li>Made speeches in front of parliament in favour of banning live export of livestock.&nbsp;</li><li>Spoken against no-stun slaughter on GB news.</li><li>Been quoted in BBC articles on issues such as&nbsp;<a href=\"https://www.bbc.co.uk/sport/horse-racing/65296693\"><u>horse racing reform</u></a> and&nbsp;<a href=\"https://www.bbc.co.uk/news/uk-england-gloucestershire-60791793\"><u>badger culling</u></a>.&nbsp;</li><li>Promoted the annual&nbsp;<a href=\"https://www.rspca.org.uk/whatwedo/latest/kindnessindex\"><u>Animal Kindness Index</u></a>, which shows how discordant the British public\u2019s views on animal welfare are.&nbsp;</li></ul><h3>What is the RSPCA?</h3><p>The RSPCA is a charity with a&nbsp;<a href=\"https://en.wikipedia.org/wiki/RSPCA\"><u>long history</u></a>. It was the first charity in the world to be primarily focused on preventing animal suffering. In 2021, it received \u00a3151 million in funding, making it one of the largest charities in the UK.&nbsp;<br><br>The RSPCA\u2019s&nbsp;<a href=\"https://www.rspca.org.uk/getinvolved/campaign\"><u>campaigns</u></a> cover everything from&nbsp;<a href=\"https://www.rspca.org.uk/getinvolved/campaign/vaping\"><u>banning disposable vapes</u></a> and&nbsp;<a href=\"https://www.rspca.org.uk/getinvolved/campaign/fireworks\"><u>changing firework laws</u></a>, to&nbsp;<a href=\"https://www.rspca.org.uk/getinvolved/campaign/endthecage\"><u>ending cages for farm animals</u></a>.&nbsp;</p><p>I was especially interested in doing an AMA with someone from the RSPCA because of&nbsp;<a href=\"https://www.theguardian.com/world/2024/jan/06/rspca-vows-reform-absolutely-horrible-treatment-poultry-uk\"><u>this article</u></a>, which focused on the plight of chickens in the UK. In Emma\u2019s words:&nbsp;</p><blockquote><p>\u201cWe slaughter about a billion chickens in the UK every year \u2013 an extraordinary number. It is very difficult to envisage the scale of that.</p><p>\u201cYet we never see these creatures, despite their vast numbers, because they are locked into incredibly cramped spaces. They are also genetically selected to grow incredibly quickly. We get through them at an extraordinary rate because they are bred to produce the maximum amount of meat in the fastest possible time.</p><p>\u201cFactory-farmed chickens live absolutely horrible lives; their suffering is&nbsp;<strong>the single biggest animal welfare issue facing the country at present</strong> [my emphasis]\u201d</p></blockquote><h3>Here are some themes that I will be focusing on in my questions:</h3><ul><li>The RSPCA\u2019s most effective campaigns, and how they measure the impact they have through public messaging.&nbsp;&nbsp;</li><li>How the RSPCA prioritises amongst its various causes.</li><li>What challenges it faces because of its size.</li><li>Whether it has ways to influence policy that smaller and newer charities do not.</li></ul><p>You can use these as a jumping off point, but don't feel constrained by them. Ask anything!</p>", "user": {"username": "tobytrem"}}, {"_id": "oqgphPg2ku6Gux2q4", "title": "Intermediate Report on Low Physical Activity", "postedAt": "2024-01-24T02:50:18.237Z", "htmlBody": "<h1>Key Takeaways</h1><ul><li>Overall, our view is that advocacy for a&nbsp;long-term public education campaign to address low physical activity <strong><u>might be an extremely cost-effective cause area</u></strong>.</li><li>However, with respect to the scientific evidence, while <strong>the link between physical inactivity and disease is indisputable</strong>, there is <strong>considerable uncertainty as to effectiveness of specific interventions</strong> like mass media and community-based interventions in actually increasing physical activity levels.</li><li>Additionally, while the experts we consulted <strong>unanimously agreed that the global burden of physical inactivity will continue to grow</strong>, there was more disagreement over the best way to counter this. Overall, they <strong>leaned in favour of taking a population-level approach</strong>, but experts also flagged out that this is hard to do or sustain. This is especially so from a historical perspective, given that leisure-time physical activity has not been how humans have actually gotten sufficient physical activity (vs being active due to work and chores).</li><li>At the same time, the <strong>downsides to addressing physical inactivity as a cause area are minimal</strong>, even less so than other areas like nutrition policy, where questions of infringing upon people's freedom of choice or having perverse policy consequences do not even arise.</li></ul><p>&nbsp;</p><h1>Executive Summary</h1><p>Taking into account (a) the expected benefits of addressing low physical activity, in terms of improved health and increased income, while also factoring in (b) the expected costs on the economic front and (c) the tractability of advocacy for a long-term public education campaign to increase physical activity, CEARCH finds the marginal expected value of advocacy for such a long-term public education campaign to address low physical activity to be&nbsp;<strong>12,065 DALYs per USD 100,000</strong>, which is around 10x as cost-effective as giving to a GiveWell top charity \u2013 which are themselves some of the very best in the world. (<a href=\"https://docs.google.com/spreadsheets/d/15z0T-Sl2oy8zWP6ev43U9tMc46z8j2MOYheYZbXkKWw/edit?usp=drive_link\"><u>CEA</u></a>).</p><p>See short report <a href=\"https://drive.google.com/file/d/1GuTZ4ZTL4svU0J5hsEb7UwuhA3QIxQ69/view\">here</a>.<br>&nbsp;</p><ul><li><strong>Introduction</strong>: This report on low physical activity is the culmination of two iterative rounds of research: (i) an initial shallow research round involving 1 week of desktop research; and (ii) a subsequent intermediate research round involving 2 weeks of desktop research and expert interviews;<br>&nbsp;</li><li><strong>Importance</strong>: Physical inactivity is a risk factor for multiple diseases, including heart disease, diabetes, stroke, and cancer. Globally, low physical activity is certainly a problem, and will have a direct health burden of&nbsp;<strong>19 million&nbsp;</strong>disability-adjusted life years (DALYs) in 2025, as well as an indirect health burden of&nbsp;<strong>60,000&nbsp;</strong>DALYs via an increased risk of depression. There is also an accompanying net economic burden equivalent to foregoing the doubling of income for&nbsp;<strong>14 million</strong> people; note that people typically value such income doublings at around&nbsp;<strong>1/5th</strong> of a year of healthy life. And this problem of physical inactivity is only expected to&nbsp;<strong>grow between 2025 and 2100</strong>, as a result of factors like urbanization, ageing, and population growth.<br>&nbsp;</li><li><strong>Neglectedness</strong>: Government policy is far from adequate, with only 10% of countries implementing the top WHO-recommended policy of a long-term public education campaign to promote physical activity; this is not expected to change much going forward \u2013 based on the historical track record, any individual country has only a 0.1% chance per annum of introducing this recommended policy. There is, of course, significant heterogeneity \u2013 some countries like Singapore have a good strategy in place, but other countries (e.g. Australia, US, Germany) are nowhere near this, and compared to such high-income countries, developing countries fare even worse.<br>&nbsp;</li><li><strong>Tractability</strong>: There are many potential solutions to the problem of low physical activity (e.g. a public education campaign; built environment interventions to make cities more walkable; digital interventions like apps and wearables; and point-of-decision prompts like posters by staircases); however, we find that the most cost-effective solution is likely to be advocacy for a public education campaign to promote physical activity; this campaign is inclusive of both a mass media campaign and accompanying community-based interventions such as a pedometer-based National Steps Challenge. The theory of change behind this intervention is as such:<br><br><ul><li><u>Step 1</u>: Lobby a government to implement a long-term public education campaign to increase physical activity.</li><li><u>Step 2(a)</u>: The mass media campaign component of the long-term public education campaign in a single country reduces physical inactivity and its related global disease burden.</li><li><u>Step 2(b)(i)</u>: The community component of the long-term public education campaign in a single country increases physical activity in a single country.</li><li><u>Step 2(b)(ii)</u>: Increased physical activity from the community component reduces the global disease burden of low physical activity.<br>&nbsp;</li></ul></li><li>Using the track record of past walkability policy and nutrition policy advocacy efforts and of general lobbying attempts (i.e. an \"outside view\"), and combining this with reasoning through the particulars of the case (i.e. an \"inside view\"), even while adjusting for counterfactuals, our best guess is that funding advocacy campaigns will have an&nbsp;<strong>11% chance of successfully enacting a long-term public education campaign to increase physical activity</strong>. Meanwhile, based on various meta-analyses, and after robust discounts and checks (e.g. for a conservative theoretical prior of a null hypothesis; for endogeneity; for study populations being unrepresentative; or for publication bias), we expect that a mass media campaign in a single country will reduce the global disease burden of low physical activity by&nbsp;<strong>0.07%</strong>; that a community-based intervention (particularly a pedometer-based national challenge) can increase participants' average number of daily steps by&nbsp;<strong>1000</strong>, which will in turn reduce the global disease burden of low physical activity by&nbsp;<strong>0.0005%</strong>. Note that while the WHO recommends a holistic approach, we expect the mass media campaign to have the bulk of the impact.<br>&nbsp;</li><li>There are additional complications to the intervention. In particular, we expect on average a 7 year gap between when an advocacy intervention begins and when the health impact actually kicks in (-12% impact).<br>&nbsp;</li><li><strong>Outstanding Uncertainties</strong>: There are a number of outstanding uncertainties, of which the four most important involve: (a)&nbsp;our use of point estimations (n.b. relying on them is reasonable given that we are ultimately interested in mean estimates, but caution is also warranted, as significant variance is possible); (b)&nbsp;the very simplified methodology we use to project the future disease burden of low physical activity; and (c) the massively complicated extrapolations we had to make in calculating the effect sizes of a mass media and pedometer campaigns; and (d) the highly uncertain estimates of the probability of advocacy success.</li></ul><p>&nbsp;</p><ul><li><strong>Conclusion</strong>: Overall, our view is that advocacy for a&nbsp;long-term public education campaign to address low physical activity might be an extremely cost-effective cause area, but more research is needed.</li></ul>", "user": {"username": "Joel Tan"}}, {"_id": "EqxanmweQbNExjDgu", "title": "Disinformation as a GCR Threat Multiplier and Evidence Based Response", "postedAt": "2024-01-24T11:19:04.859Z", "htmlBody": "<p><strong>What have recent changes in the information ecosystem been?</strong></p><p>&nbsp;</p><p>Events of the last few years, including the war in Ukraine and the pandemic, have accelerated structural shifts towards more digital, mobile, and platform-dominated media environments. The widespread use of synthetic content has been observed in recent conflicts, ranging from Ukraine to Sudan to Gaza. Social media platforms have been changing rapidly, in the last year Facebook published updates related to Meta, Reels, AI-related content. Twitter under Elon Musk has loosened moderation guidelines. TikTok has become one of the fastest-growing platforms ever, reflecting the growth in short form video content.&nbsp;</p><p>&nbsp;</p><p>The explosive growth in the amount of content created has increased the prominence on AI led content moderation in order to scale effectively. There is also growing attention from governments on content moderation, with the EU\u2019s Digital Services Act which, Australia\u2019s Online Safety Act and the UK Online Safety Bill, amongst others.&nbsp;</p><p>&nbsp;</p><p>The interconnected nature of platforms and user networks means that disinformation is networked across many platforms, including unmoderated or encrypted spaces, making it hard to identify, track and flag or remove false content at scale across the information landscape.&nbsp;</p><p>&nbsp;</p><p><strong><u>What does AI mean for creating mis/disinformation?</u></strong></p><p>&nbsp;</p><p>As the availability of LLMs increases and cost falls, this makes it easier for threat actors to create more personalised and more effective content. As content creation is becoming more automated, this reduces the financial and time costs associated with micro targeting and hyper personalization, and an improved understanding of the information environment allows threat actors to craft more compelling and effective narratives for each target segment. This also makes disinformation campaigns more difficult to detect as new content is easier to generate, preventing a need for copypasta, and the quality of deepfakes is drastically improving.&nbsp;</p><p>&nbsp;</p><p><strong><u>What does AI mean for the spread of mis/disinformation?</u></strong></p><p>&nbsp;</p><p>The spread of campaigns often relies on large numbers of accounts across social media, and the perceived authenticity of the accounts is key. ML techniques allow generation of increasingly realistic profile photos, reducing the need for image scraping and the potential for reverse image searches to aid in detection of a campaign. When combined with the improvements in text generation through LLMs for bio\u2019s and online presence, this results in en masse creation of credible accounts to spread disinformation.&nbsp;</p><p>&nbsp;</p><p>ML systems can also improve social engineering techniques to target influencers or so called \u201csuper-spreaders\u201d who can organically amplify a message or campaign. Deepfakes also make it easier to impersonate experts or credible sources to amplify a message.&nbsp;</p><p>&nbsp;</p><p><strong><u>What does AI mean to real-time information ecosystem interactions?</u></strong></p><p>&nbsp;</p><p>Advancements in conversational AI or chatbots could automate engament with targeted individuals. These use large volumes of data, ML, and NLP to imitate human interactions, recognizing speech and text input and generating a response. This can be used to take part in online discussions and respond to comments to stimulate controversy and disputes, and increase polarisation.&nbsp;</p><p>&nbsp;</p><p>As AI reduces the costs, increases the effectiveness, and reduces the ease of detection of disinformation campaigns, threat monitoring and early detection are becoming increasingly important.&nbsp;</p><p>&nbsp;</p><p><strong><u>How does this impact global catastrophic risk?</u></strong></p><p>Information ecosystem risks are both broad and dangerous, with potential impacts ranging from water security to financial stability and even amplifying/creating conflicts. Disinformation is used to influence public opinion, legitimise unpopular actions and regimes including garnering support for confrontation, alter election results, increase polarisation and extremism, and undermine the credibility of institutions, science, experts and media.&nbsp;</p><p>&nbsp;</p><p>Examples include the use of disinformation as a form of information warfare in the Russia Ukraine conflict, the spread of conspiracy theories around the 2016 US elections, and the fuelling of anti muslim and anti Pakistan sentiment in India. Much like climate change, this acts as a threat multiplier for catastrophic and existential risks and can significantly increase risk by polarising and destabilising the world, undermining global governance, increasing geopolitical tensions, and the risk of conflict, arms races,&nbsp;and more.&nbsp;</p><p>&nbsp;</p><p>Disinformation from generative AI has been seen in recent conflicts in Sudan, Gaza and the Ukraine with deepfakes from leaders of both sides, designed to stoke tensions and escalate conflict. The role of AI-empowered disinformation has the potential to both create and worsen conflict.</p><p>&nbsp;</p><p>Disinformation is used to undermine scientific credibility and promote climate denialism and inaction. A recent report from CCDH showed that \u2153 of British children thought concerns of climate change were overblown which shows marked success with climate denialism narratives.&nbsp;</p><p>&nbsp;</p><p>Disinformation around nuclear weapons can be used by state or non state actors to simulate or provoke nuclear attack or response. It also increases geopolitical tensions and the likelihood of great power war. The recent election in Taiwan was supposedly subject to significant influence operations by mainland China with AI augmented disinformation.</p><p>&nbsp;</p><p>Disinformation is used by threat actors and incentivised parties to downplay AI safety concerns and promote rapid AI development at the expense of safety, alignment and governance. This could significantly hamper the efforts of AI safety activities.</p><p>&nbsp;</p><p><strong><u>AI and disinformation: Offence vs Defence</u></strong>&nbsp;</p><p>&nbsp;</p><p>Spreading disinformation has always been more effective than combatting it. In creating and spreading disinformation, the most viral techniques and narratives can be used without regard for the truth, often preying on insecurities for the most vulnerable and tapping into visceral emotions such as fear.&nbsp; The effectiveness is evident across the board, notably in the difference in click-through rates for clickbait headlines generated by ad companies Taboola and Outbrain vs generic news stories. Responding to disinformation also has a temporal disadvantage, where a counter-narrative as opposed to an initial narrative has to be established, and an anchoring effect has often occurred.&nbsp;</p><p>&nbsp;</p><p>Techno-fixes are also limited in their effectiveness, and certain ones such as reverse image searches place a high burden of effort for the user. Fact-checking is time consuming and laborious and an ever-decreasing proportion of information can be fact-checked as AI-generated/spread disinformation is proliferated.&nbsp;</p><p>&nbsp;</p><p>AI empowered tools such as Bot Sentinel, Botometer and BotSlayer classify accounts as bots based on profile features and behaviour. Tools and solutions such as Captain Fact, Claimbuster, Logically.ai and Alethea Artemis use AI to detect misinformation and disinformation at scale. However the effectiveness of detection algorithms depends on the availability of large sets of training data and quality of data labels. While detection is becoming more robust, for example within deepfake detection by looking beyond subtle signatures of particular generation tools and using underlying physical and biological signals that are hard for AI to imitate, there is a constant back and forth between AI-generated content and detection methods as both sides become more sophisticated and adapt to each other.</p><p>&nbsp;</p><p>As techniques such as establishing provenance on the blockchain are established, with the use of digital watermarks, these will be likely circumvented by rogue state and non-state actors empowered by AI. The commercial incentives for creating and spreading disinformation have historically been greater than countering it, and it is difficult to see how this may change.</p><p>&nbsp;</p><p>AI is likely to make disinformation much easier to create and spread more effectively, at lower human and financial cost. AI tools often place a high burden of effort for the end user so will have limited adoption and as they are developed, zero day exploits and other techniques will be developed to circumvent these tools. Although technical tools are a crucial part of the toolkit to combat mis and disinformation, they are necessary but not sufficient.</p><p>&nbsp;</p><p><strong><u>What is the current state of knowledge on the field?</u></strong></p><p>&nbsp;</p><p>Campaigners across government and civil society are often resource and time-poor and don\u2019t know the best, evidence-informed way to respond to information threats in combatting mis/disinformation. There is a wealth of academic literature on quantitative experiments on the efficacy of interventions to combat mis/disinformation, however this is disparate, disaggregated, spans many disciplines and lacks a shared ontology. This evidence base is hard to find, navigate and interpret so tends to be ignored by the practitioner community.</p><p>&nbsp;</p><p><strong><u>Our Proposal: Strengthening the evidence base for societal resilience</u></strong></p><p>&nbsp;</p><p>This project aims to create, populate, test the effectiveness and iterate an online living database to be used to improve the effectiveness of counter disinformation campaigns and media literacy, especially around AI. This open source online living database will collate, curate and categorise empirical studies that have been run on interventions to combat mis/disinformation and extract insights from study. The insights will include characterising the relevant information threat, intervention tested, methodology details, participant characteristics and statistics from results. This will enable the comparison of different interventions for any characterised information threat. The next phase of the project will be to create an algorithm to rank interventions for any characterised information threat, based on characterised parameters such as effect size, sample size, effect duration and others.&nbsp;</p><p>&nbsp;</p><p>The database aims to operationalise the existing evidence base by aggregating a highly disaggregated academic field, serving both the research and practitioner community, having a large scale impact by improving the effectiveness of campaigns and media literacy initiatives run by large numbers of practitioner groups around the world.&nbsp;</p><p>&nbsp;</p><p>We have validated the utility of this proposition with leading academics and practitioners in the field including the University of Cambridge Social Decision-Making Lab, IRIS (LSHTM, University of Rome, University of Venice), University of Bristol, Max Planck Institute, North-Eastern University, University of Minnesota, IMT Lucca, University of Seattle, Princeton, UC Davis, the Centre for Countering Digital Hate, The European Centre of Excellence for Countering Hybrid Threats, ISD Global, CASM, Stimson Center, Public Democracy, and Climate Action Against Disinformation.</p><p>&nbsp;</p><p><strong><u>Learnings so far: What interventions may work? Evidence based counter campaigns &amp; media literacy</u></strong></p><p>&nbsp;</p><p>While fact checking and other labelling technologies are progressing in identification of mis/disinformation online, technology development such as AI (e.g. LLM\u2019s) makes the creation and spread of disinformation significantly quicker, easier and cheaper, and changes the tactics used, hence technofixes will constantly be catching up. Tackling mis and disinformation requires both counter specific disinformation campaigns run on particular issues but more importantly the building of individual and societal resilience through education interventions focused on media literacy, especially around emerging technologies and AI.</p><p>&nbsp;</p><p><strong>What do effective counter interventions look like?&nbsp;&nbsp;</strong></p><p>&nbsp;</p><p>A range of counter interventions are able to counter disinformation, some regulatory, some platform-oriented but also those that can be integrated into campaigns.&nbsp;</p><p>&nbsp;</p><p>Debunking (providing correcting information targeted towards misconceptions of beliefs), inoculation (pre-emptive exposure to weakened forms of disinformation, and is often technique based or issue based) and adjacent messaging (providing alternative more hopeful narratives as opposed to directly refuting) are all tools that can be integrated into campaigns.&nbsp;</p><p>&nbsp;</p><p>AI will create a more uncertain information environment, with fatigue likely setting into citizens where fact checking tools are arduous and time consuming to use. Effective counter-interventions are highly context-specific but likely to have the following characteristics in common.</p><p>&nbsp;</p><ol><li><strong>Early detection</strong>. Information threats are much easier to respond to when nascent, when more effective techniques can be used. Deplatforming and prebunking are effective options to quash influence threats before disinformation narratives become widespread&nbsp;&nbsp;</li><li><strong>Target knowledge acquisition</strong>. Obtaining demographic and psychographic insight into potential targets of influence operations, e.g. customers/investors help design more effective counter-campaigns</li><li><strong>Evidence-based response</strong>. As AI-related disinformation proliferates, preempting particular narratives becomes more challenging. Therefore technique based inoculation is likely to be more effective, as techniques will target weaknesses from common cognitive fallacies, which may be personalised based on psychographic elements</li></ol><p>&nbsp;</p><p><strong>How may we want to update media literacy training in light of this?&nbsp;</strong></p><p>&nbsp;</p><p>The future world is one where disinformation is more prevalent, more personalised and harder to discern. In light of this, effective media literacy to build societal resilience will need to include the following:</p><p>&nbsp;</p><ol><li><strong>How to hold information in uncertainty.</strong> People have a preference for certainty over uncertainty (certainty effect), and aiding people to develop probabilistic mindsets where information may or may not be true is pivotal</li><li><strong>How to interact with uncertain information</strong>. Communicating the uncertainty associated with information is critical to enable others to also hold information in uncertainty, and not for strength in beliefs to increase with sharing.</li><li><strong>How to recognise influence operations</strong>. Educating the public on who may be targeting them, why they do so, the techniques they use, the goals they have and how this links to particular narratives can help identify when a piece of information is more likely to be disinformation.</li><li><strong>What technical tools can be used</strong> for verifying information, reporting mis/disinformation and deplatforming</li></ol><p>&nbsp;</p><p><strong><u>Who are we?</u></strong></p><p>&nbsp;</p><p><a href=\"https://www.saynotodisinfo.com\">Say No to Disinfo </a>is focused on improving the information ecosystem, and hence reducing existential risk by making society more robust and resilient to disruption due to mis/disinformation. We have a focus on the intersection of AI and emerging technologies with disinformation and our activities focus on improving the effectiveness of direct disinformation response, and of educational interventions to improve media literacy and societal resilience to mis/disinformation through the creation of the online living database, and the work on improving the effectiveness of media literacy for the current and future technology environment.&nbsp;<br>&nbsp;</p><p><strong><u>Progress to date and our asks</u></strong></p><p>&nbsp;</p><p>With collaboration from leading academics and practitioners, we have completed database design, compiled an initial list of hundreds of academic papers containing thousands of experiments on counter mis/disinformation interventions, and are in the process of uploading these into the database.&nbsp;</p><p>&nbsp;</p><p>We are seeking to augment the academic data with field data from campaigns that have been run. If you/your organisation have any data that we could incorporate or that you could make us aware of, please let us know.</p><p>&nbsp;</p><p>We are looking for volunteers to upload papers to the database, reviewing them and extracting key information. It provides a hands-on opportunity to learn from cutting edge studies whilst contributing to a living resource that will have tangible positive real world impact, used by both civil society and government. If you are interested please get in touch with us at&nbsp;<a href=\"mailto:ari@saynotodisinfo.com\"><u>ari@saynotodisinfo.com</u></a></p><p><br>&nbsp;</p>", "user": {"username": "Ari96"}}, {"_id": "EyedeQmoXGWbKRoxh", "title": "5 possibly impactful career paths for researchers  ", "postedAt": "2024-01-23T20:23:05.944Z", "htmlBody": "<p>Charity Entrepreneurship is running a second edition of our&nbsp;<a href=\"https://www.charityentrepreneurship.com/research-training-program\"><u>Research Training Program</u></a> (RTP) \u2013 a program&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/AdouuTH7esiDQPExz/announcing-ce-s-new-research-training-program-apply-now\"><u>designed</u></a> to equip participants with the tools and skills needed to identify, compare, and recommend the most effective charities and interventions.</p><p>In this post, we discuss possible long-term career paths for researchers and a gap assessment of what skills people might want to prioritize to pursue those. This discussion may be helpful for people considering the RTP program or those more generally wanting to find other ways of building career capital in research.</p><p>These five roles are based on what we think are potential placements or jobs for our first cohort in the RTP. We have made these all a bit more clich\u00e9d and separate than they are \u2013 in practice, there is a lot of overlap and nuance among them, and a successful research career often involves aspects from all these role types.&nbsp;</p><p>These paths can all be exciting for someone who is the right fit. Each of them will inevitably have a high variance in impact, with some low- and some high-impact roles in the mix. Most importantly, we think people tend to forget the vast range of career paths open to someone with strong research skills. In the RTP, we aim to coach participants on what we think would be most cross-applicable between these areas, with a mind to make these positions as impactful as possible.&nbsp;</p><p>Beyond these specific roles, it is worth noting that being a proficient researcher can be highly applicable to many other positions that require lots of decision-making, such as leadership and executive roles in high-performing organizations. In this sense, good research skills are all about helping you ask the right questions and find the right answers.</p><h2><strong>Role: Monitoring and Evaluation (M&amp;E) for a High-Impact Organization&nbsp;</strong></h2><p><strong>Example:</strong>&nbsp;<a href=\"https://oneacrefund.org/vacancies/nigeria-research-and-evaluation-lead\"><u>Research and Evaluation Lead at One Acre Fund</u></a>,&nbsp;<a href=\"https://gatesfoundation.wd1.myworkdayjobs.com/en-US/Gates/job/Seattle-WA/SPO--Monitoring---Evaluation--MNCH-D-T_B019671-2?source=gatesfoundation.org\"><u>Senior Program Officer/M&amp;E at Gates Foundation</u></a>,&nbsp;<a href=\"https://docs.google.com/document/d/1jHP2RYYZny-182keBNKMT44K71dU10KiNXvnYl3TJnY/edit#heading=h.j1kutkbxy04i\"><u>MEAL Coordinator at Vida Plena</u></a>)</p><p><strong>Mechanism for Impact:</strong> This role has an impact by ensuring an organization achieves its goals. Great M&amp;E can often be the difference between highly impactful charities (e.g., GiveWell recommended) and those that are not. M&amp;E helps demonstrate impact, identify pain points, and supervise progress toward stated goals. When done well, it can increase the odds of a charity improving to reach the top of its field.&nbsp;</p><p>Our sense is the impact of an M&amp;E role correlates quite strongly with the charity's quality and its interest in M&amp;E. A more junior role in an impactful charity may lead to more impact than a senior role in a much less impactful one. Charities also have very different attitudes toward M&amp;E, where working for an organization that values M&amp;E facilitates the impact of your role, and working for one that doesn\u2019t can amount to paper pushing. M&amp;E work is sometimes only used as signaling for fundraising, not to determine if the organization is having an impact or identify potential improvements.</p><p><strong>Persona:</strong> The type of person who is good at this sort of role is a bit non-conformist and fairly detail-oriented. Enjoying finding flaws or possible areas for improvement ends up being a pretty helpful disposition here. Relative to other research roles, this role is a lot more applied, so it could be a good fit for someone who wants to spend time in the field and create evidence rather than relying on secondary sources. M&amp;E can be a good fit for someone early in their career who wants to leave options open for more direct charity work and theory-based research.</p><p><strong>Top skills to build:</strong> Although some cause areas (such as global poverty) have a decent pipeline for M&amp;E training (such as the&nbsp;<a href=\"https://micromasters.mit.edu/dedp/\"><u>MIT MicroMasters</u></a> or specific university courses), other cause areas have virtually no way to train up and get good at this sort of research (animal advocacy and EA meta mainly come to mind).&nbsp;</p><p>Some things to focus on include being strong at making theories of change and other mental models that help you understand how something works, research synthesis, and going deep into methodologies, particularly finding inconsistencies.<br>&nbsp;</p><h2><strong>Role: Researcher in a Grantmaking Role / for a Foundation&nbsp;</strong></h2><p><strong>Example:</strong>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/LcS8P84JMmfd9Gudu/the-ea-animal-welfare-fund-is-looking-for-guest-fund\"><u>EA Animal Welfare Fund Guest Manager</u></a>,&nbsp;<a href=\"https://hewlett.org/careers/\"><u>Program Officer at Hewlett Foundation</u></a>,&nbsp;<a href=\"https://jobs.ashbyhq.com/openphilanthropy/5e1e985c-9cc4-472e-b783-5bc161630320\"><u>Research and Strategy Fellow at Open Philanthropy</u></a></p><p><strong>Mechanism for Impact:&nbsp;</strong>Impact-wise, this is likely the most straightforward path. Research influencing charity grants can be fairly quickly evaluated based on the amount of money affected and the counterfactual of where that money went. The overall impact is significant if a grant size is large and significantly influenced by the research.&nbsp;</p><p>Examples of this might be being a program officer at a foundation or a researcher working directly on projects connected to a specific funding body. For example, our funding circles have commissioned research to address a critical question that then determined significant donations.</p><p><strong>Persona:</strong> Grantmaking research is often about identifying critical factors and relative priorities. Knowing where to dig is more important than the speed at which you do it. This role requires communication skills, as foundations are unusually time-poor relative to other consumers of research. Grantmaking is often about comparing and contrasting complex options; if you made a spreadsheet to compare the last toaster you bought and then convinced your roommates of the best option, this might be a good fit for you.</p><p><strong>Top skills to build:</strong> Getting good at reasoning, transparency, and communication \u2013 this research is often at risk of never getting picked up if it is unappealing or unclear. Being good at modeling cost-effectiveness, particularly under time pressure or uncertainty, is also helpful.</p><h2><strong>Role: Charity Evaluation Staff</strong></h2><p>Example:&nbsp;<a href=\"https://www.givewell.org/about/jobs/senior-researcher\"><u>Senior Researcher at GiveWell</u></a></p><p><strong>Mechanism for Impact:</strong> In some ways, this type of role shares many characteristics with grantmaking positions: your bottom line impact is dollars moved to more effective charities. With charity evaluation roles, there are fewer concerns about whether your research will be listened to but perhaps deeper concerns regarding the counterfactual value of your research relative to the next best hire.</p><p><strong>Persona:</strong> Compared to the three roles above, this sort of role typically allows you to go deeper in your research. Charity evaluation typically prioritizes transparency and involves fewer options evaluated at a time than most grantmaking situations. This can make it an excellent fit for someone who is most excited about going extremely deep into a topic.&nbsp;</p><p>These roles are also a good fit for someone who can build on and contribute to pre-existing work (as in, not creating things from scratch). You may be a fit if you tend to go ten times deeper on a topic than your other fairly research-heavy friends.&nbsp;</p><p><strong>Top skills to build:</strong> A lot of the best skills here are about quality and depth. Can you spend ten hours looking through a model and suggest the three most important improvements? Working with an existing model and changing a significant factor, such as what this implementation would look like in a different country, or conducting a quality expert review would be useful skills when getting into this path.</p><h2><strong>Role: Direct Research (such as academic, think tank, or EA meta)</strong></h2><p>Example:&nbsp;<a href=\"https://my.corehr.com/pls/uoxrecruit/erq_jobspec_version_4.display_form?p_refresh_search=Y&amp;p_recruitment_id=169640&amp;p_form_profile_detail=&amp;p_display_apply_ind=Y&amp;p_process_type=&amp;p_applicant_no=&amp;p_company=10&amp;p_internal_external=E&amp;p_display_in_irish=N\"><u>Researcher - health security at University of Oxford</u></a>,&nbsp;<a href=\"https://poverty-action.org/research-manager-6\"><u>Research Manager at IPA</u></a>)&nbsp;</p><p><strong>Mechanism for Impact:</strong> This is a pretty big bucket, including lots of different types of research (although mostly involving primary research) \u2013 impact ranges a lot. Research studies often influence policy, charity operations, and philanthropic funding through varying mechanisms.&nbsp;</p><p>These sorts of research organizations are often a bit broader and more cross-cutting in their research, meaning there can be research done that affects multiple avenues/actors. Sometimes, research can lack a clear connection to a specific actor or activity, meaning that a lot of research results in no actual change. The critical thing to look for here is the exact mechanism for how a given piece of research affects the world positively.</p><p><strong>Persona:</strong> Depending on the role, these positions often involve a good mix of spread and depth regarding research topics. Thus, they can be a good fit for generalists currently unsure of their core focus or people most drawn to more abstract research. This might be someone who tends to get into a deep philosophical conversation at every party they go to.</p><p><strong>Top skills to build:&nbsp;</strong>The most common missing skill for people in these fields tends to be in the research translation category. For instance, it would be good to practice research communication (e.g., how to make three years of research into action through a one-pager that someone else might pick up). Writing skills and summarizing complex topics are very necessary for deep, less clearly targeted research like this.</p><h2><strong>Role: Charity Founding&nbsp;</strong>(example:&nbsp;<a href=\"https://www.charityentrepreneurship.com/incubation-program\"><u>CE Incubation Program</u></a>)</h2><p><strong>Mechanism for Impact:&nbsp;</strong>As a charity founder, you will, in most cases, not spend a lot of time on research in the traditional sense. Having said this, the importance of the research skillset for a founder should not be understated: knowing how to set up grand theories of change and investigate if their program has an impact is the aspect that distinguishes some of the best charities from the pack.&nbsp;</p><p><strong>Persona:</strong> This is the most generalized role and among the most demanding, on average. You have to be able to make decisions under uncertainty and quickly become well-versed in topics that others may have been studying for years. People who are a good fit for this are ambitious and see their research skills as one skill set among a few that they have. This might be a fit for someone who wants to take the research they have conducted and apply it directly by starting a charity working on the issue they have investigated.&nbsp;</p><p><strong>Top skills to build:</strong> The most important skills here are getting fast and decisive in your research. When founding, it is often about making ten calls and reversing two of them later. This does not come naturally to many researchers, so practicing doing research under time-bound scenarios and with imperfect information is key.</p><p><i>If you\u2019re interested in our Research Training Program, you can still apply by 28 January 2024&nbsp;</i><a href=\"https://form.jotform.com/240013123967348\"><i><u>here</u></i></a><i>. If you want to learn more, visit our&nbsp;</i><a href=\"https://www.charityentrepreneurship.com/research-training-program\"><i><u>website</u></i></a><i> or watch our online presentation and Q&amp;A session:&nbsp;</i><a href=\"https://youtu.be/PCotAlZru3I?si=3rSAAHjSYjefNxFC\"><i><u>https://youtu.be/PCotAlZru3I?si=3rSAAHjSYjefNxFC</u></i></a><i>&nbsp;</i></p><p><br>&nbsp;</p>", "user": {"username": "CE"}}, {"_id": "w29WEqBk7xcjH22En", "title": "Institutional economics through the lens of scale-free regulative development, morphogenesis, and cognitive science", "postedAt": "2024-01-23T19:42:39.325Z", "htmlBody": "", "user": {"username": "Roman Leventov"}}, {"_id": "kbJG3pPL88sqP7t2y", "title": "Two brief theses", "postedAt": "2024-01-23T19:33:58.226Z", "htmlBody": "<ol><li>Niceness and politeness are over-rated. If someone is saying something stupid and/or evil, it is perfectly fine to tell them in as many words. Y'all niceness folks have been doing jack sh*t to raise the sanity waterline in the world \u2013 most if not all of our success comes not from politely persuading people in the Outgroup (booo!) but in reaching out to people who were gonna agree with us anyway; therefore, there's no real issue in being rude when the situation demands it. (This thesis is held with very little confidence and it might be only due to me being f*cking pissed; I reserve the right to change my mind, of course.)</li><li>This one is for the folks at the Parents in Effective Altruism facebork group. Spanking kids is evil, and defending it is stupid and evil. Having any opinion on the matter other than this one is evil. Pointing out supposed methodological flaws of studies that show it severely harms children is also stupid and evil; <i>even if you are right</i>, the point you'd have to prove is not that hitting children somehow does not hurt them \u2013 you'd have to prove it is <i>actually beneficial to them</i> to a sufficient extent that it makes up for the obvious inherent evil that is hitting them.<br>If you're still struggling with the concept, let me introduce you to the <i>Sweden-Saudi rule of thumb</i>: if the laws in these two countries differ, Sweden is morally right and Saudi Arabia is wrong.</li></ol>", "user": {"username": "brunoparga"}}, {"_id": "JJdyxxDJWop3n4Zcs", "title": "Philosophical Guidance", "postedAt": "2024-01-24T11:23:28.412Z", "htmlBody": "<p>I run a philosophical guidance practice. Some of my recurring clients are in the EA community. Some of them struggle with meaninglessness. Some have their energy sapped by relationship issues. Others find themselves unable to act for reasons that are hard to nail down.&nbsp;</p><p>Philosophical guidance is a mix of therapy, coaching and philosophical analysis. During sessions, I assist people in making sense of bothersome issues that feel important and intractable. Resolving these issues has allowed my clients to reorient and approach life with renewed agency.</p><p>The Effective Altruism community has been through some chocks recently, with popular opinion turning sour in the aftermath of FTX and the Sam Altman incident. My friend&nbsp;<a href=\"https://peterlimberg.com/\"><u>Peter Limberg</u></a> is running a similar practice, and we\u2019ve both seen a recent influx of EAs/rationalists interested in guidance.</p><p>LW-style rationalism has greatly influenced my life, and I enjoy inquiring with EAs. I want to assist more EAs to reorient and resolve areas in life where they are stuck. This is a safe-to-fail experiment with a potentially high upside.</p><h2>Details &amp; Booking</h2><p>Sessions are held online, and last 60-90min. I keep client names and session details confidential.&nbsp;</p><p>You pay after the session, choosing the amount yourself\u2014 I will use this to gauge the value provided by the session. If enough people find it valuable, I might transition to doing EA philosophical guidance full-time.</p><p>Do you feel stuck in important ways? Are you bothered by something you struggle to make sense of? You are welcome to schedule a session&nbsp;<a href=\"https://calendly.com/jonathan-more/philosophical-guidance?month=2024-02\"><u>here</u></a>.&nbsp;</p><p><i>If you have any questions, comment or send me a PM.&nbsp;</i></p><hr><p><strong>P.S:</strong> If this takes off, I will write reports on common issues, in a way that respects the integrity of my clients. In this way, a session with one person might lead to insights and practical steps that turn out to be useful for the rest of the community.</p>", "user": {"username": "Jonathan Moreg\u00e5rd"}}, {"_id": "pwxwDidqbnwqWhvA4", "title": "International tax policy as a potential cause area", "postedAt": "2024-01-23T16:36:53.351Z", "htmlBody": "<p>This is more of an exploratory post where I try to share some of my thoughts and experience working in international tax. I'm also happy to answer questions (to the extent I can) if people want clarifications or more details about any of this.&nbsp;</p><p>Thanks in particular to David Nash for his encouragement and help in reviewing my drafts.</p><h1>Summary</h1><ul><li>International tax rules govern how taxing rights are allocated between countries.&nbsp;</li><li>International tax policy is likely to be an&nbsp;<i><strong><u>impactful</u></strong></i><strong>&nbsp;</strong>cause area:&nbsp;<ul><li>Not only is there a significant amount of tax revenue at stake, there is a broader indirect impact as international tax rules can constrain domestic tax policies.&nbsp;</li><li>International tax rules tend to be relatively sticky, persisting for decades.</li><li>In recent years, as international tax has gotten increasingly political, there may also be broader foreign policy implications.</li></ul></li><li>Yet international tax seems to be relatively&nbsp;<i>neglected</i>.&nbsp;<ul><li>Domestic tax issues tend to be more politicised, possibly because they affect voters more directly.&nbsp;</li><li>International tax can be highly technical and rather opaque.&nbsp;</li></ul></li><li><i>Tractability depends</i><strong>&nbsp;</strong>on how you identify the \u201cproblem\u201d:<ul><li>In my view, a problem is that the development of international tax policy is dominated by relatively wealthy countries (particularly the US), who focus too heavily on their own national interest.&nbsp;</li><li>While I doubt this broad problem can ever be fully \u201csolved\u201d, I believe individuals can still play a significant role in mitigating it.&nbsp;</li></ul></li></ul><h1>Problem&nbsp;</h1><p>International tax policy plays a key role in determining how much companies are taxed and where. This in turn affects the level of tax revenue different countries get.&nbsp;</p><p>The development of international tax policy is dominated by the Organisation for Economic Co-operation and Development (OECD), which is made up of relatively wealthy countries. The US also plays a key role in international tax policy.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefo2acsfa8zna\"><sup><a href=\"#fno2acsfa8zna\">[1]</a></sup></span>&nbsp;I believe that many people currently working in international tax policy focus too heavily on their national interest over the global interest.&nbsp;</p><p>The problems here are not ones I think we can hope to fully \"solve\", as the problems stem from the underlying power dynamics between developed and developing countries and the natural incentives for government officials to prioritize their own country.&nbsp;</p><p>However, international tax policy could still be a worthwhile area to consider working in, because it seems to be a relatively neglected space where individuals can have a surprisingly large impact in&nbsp;<i>mitigating&nbsp;</i>these problems.&nbsp;</p><h1>Background&nbsp;</h1><h2>What is international tax policy?</h2><p>In broad terms, international tax policy governs how taxing rights are allocated between countries as well as matters of tax administration such as information sharing and dispute resolution.&nbsp;</p><p>Countries enter into bilateral tax treaties that aim to prevent double taxation (i.e. when two or more countries try to tax the same income) without creating opportunities for tax avoidance or evasion.&nbsp;</p><p>In recent years, there has also been a focus on multilateral tax projects, which may or may not result in a formal tax treaty.&nbsp;</p><h2>Bilateral DTAs&nbsp;</h2><p>A bilateral double tax agreement (DTA) is a tax treaty entered into by two countries.&nbsp;</p><p>When a person/entity resident in one country earns income from another country, both countries may attempt to tax the same income. Such double taxation would inhibit cross-border investment and trade, so countries enter into bilateral DTAs to prevent this. Depending on the circumstances, DTAs will allocate taxing rights over the income to either:</p><ul><li>the&nbsp;<strong>residence</strong> country \u2014 where the person/entity earning the income lives or is managed; or&nbsp;</li><li>the&nbsp;<strong>source&nbsp;</strong>country \u2014 where the income is earned.&nbsp;</li></ul><p>In very broad terms, in a treaty negotiation, developed countries generally want to increase the residence country's taxing rights, because they tend to have wealthy residents that invest abroad and earn foreign income. Developing countries tend to want to increase the source country's taxing rights, so that they can tax income earned by foreign investors.&nbsp;</p><p>Virtually all bilateral DTAs are based on the&nbsp;<a href=\"https://www.oecd.org/ctp/treaties/model-tax-convention-on-income-and-on-capital-condensed-version-20745419.htm\"><u>OECD Model Tax Convention</u></a>. There is also a&nbsp;<a href=\"https://www.un.org/esa/ffd/wp-content/uploads/2018/05/MDT_2017.pdf\"><u>UN Model Tax Convention</u></a>, which is very similar to the OECD Model but with stronger taxing rights for source countries.&nbsp;</p><p>The OECD Model and its accompanying Commentary are updated every few years or so. The changes are discussed and negotiated by the OECD's&nbsp; \"working parties\", which are made up of delegates from each of the OECD member countries. The delegates are tax experts (i.e. they come from a country's Treasury or tax department, not from its foreign affairs department).&nbsp;</p><h2>Multilateral projects&nbsp;</h2><p>Work on multilateral tax projects is also largely led by the OECD. In 2016, a much larger group called the&nbsp;<a href=\"https://www.oecd.org/tax/beps/about/)%20was%20set%20up%20to%20include%20more%20countries%20(particularly%20developing%20countries\"><u>Inclusive Framework</u></a> was formed to undertake some of this multilateral work. Over 140 countries and jurisdictions are currently part of the Inclusive Framework. However, there is debate over how \"inclusive\" this arrangement truly is. The OECD still takes a leading role (because it is where the tax expertise and resources are). Recently, <a href=\"https://www.taxnotes.com/featured-analysis/everybody-wants-rule-tax-world/2023/09/01/7h7t6\">developing countries have been pushing for the UN to have a bigger role</a>.&nbsp;</p><p>Multilateral tax projects can result in a multilateral treaty (e.g. the&nbsp;<a href=\"https://www.oecd.org/tax/exchange-of-tax-information/convention-on-mutual-administrative-assistance-in-tax-matters.htm\"><u>Convention on Mutual Administrative Assistance in Tax Matters</u></a> facilitates the exchange of information between tax authorities in different countries, including through the Automatic Exchange of Information (AEOI)).</p><p>However, as noted above, multilateral projects may not necessarily result in a treaty. For example:</p><ul><li>The Base Erosion and Profit-Shifting (BEPS) project which began in 2012 resulted in a list of measures which countries were either required or encouraged to adopt. Although there was a multilateral treaty to help countries to update their existing DTAs to incorporate the measures, countries did not have to sign it and were free to update their DTAs via bilateral agreements instead.&nbsp;</li><li>A global minimum tax, known as Pillar Two of the Two-Pillar Solution resulted in a set of Model Rules, <a href=\"https://www.oecd.org/tax/beps/minimum-tax-implementation-handbook-pillar-two.htm\">which countries are expected to incorporate into their domestic laws</a>. The rules are designed so that even if some countries don't implement the Model Rules, the minimum tax should still be effective.</li></ul><h1>ITN analysis</h1><p>Disclaimers:&nbsp;</p><ul><li>This is just based on my individual experience working on international tax policy in one OECD country. It would be great to get input from others who also have experience in this space.</li><li>While I have attended a few OECD and Inclusive Framework meetings in which these issues have been debated, I have not worked at the OECD myself. As such, I do not really understand the inner workings of the OECD.</li><li>Many key Inclusive Framework decisions are made at the&nbsp;<a href=\"https://www.oecd.org/tax/beps/steering-group-of-the-inclusive-framework-on-beps.pdf\"><u>Steering Group</u></a> level. I have not attended any of these meetings.</li></ul><h2>Impact</h2><p>The impact of working in international tax seems&nbsp;<i><strong>high</strong></i>, for the following reasons:</p><ul><li>The amount of tax revenue at stake is quite high&nbsp;</li><li>International tax constrains domestic tax policies</li><li>International tax reforms are relatively \u201csticky\u201d (i.e. slow to change)</li><li>International tax disagreements could spill over into broader foreign policy&nbsp;</li></ul><h3>Amount of tax revenue at stake is quite high</h3><p>Estimating the amount of tax revenue affected by international tax rules is difficult. Treaties have both a direct and indirect impact and the direct impact, being the amount of tax actually relieved by a treaty, is likely to be relatively small. The indirect impact, being the cross-border investment and trade that otherwise would not take place, or that is shifted as a result of the treaty, is likely to be much greater.</p><p>Corporate income tax revenues are more likely to be impacted by international tax rules than other bases such as personal income taxes or consumption taxes (however, see my next point about international tax constraining domestic policies). One estimate of the annual amount of global corporate income tax (CIT) revenue is around&nbsp;<strong>US$2.4 trillion</strong>,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxwq362r14pj\"><sup><a href=\"#fnxwq362r14pj\">[2]</a></sup></span>&nbsp;<a href=\"https://doi.org/10.1787/0959240d-en\">roughly <strong>15%&nbsp;</strong>of total tax revenues</a>.&nbsp;</p><h3>International tax constrains domestic tax policies</h3><p>Before I actually worked in tax policy, I did not appreciate how international tax can constrain domestic tax policy.&nbsp;</p><p>It does this in at least three ways:</p><ul><li><strong>Tax competition</strong>. For example, many countries look to international norms when setting corporate tax rates because capital tends to be mobile and they want to attract (or at least not discourage) investment.&nbsp;The corporate tax rate a country chooses can then also constrain personal tax rates, because if individuals can pay less tax by diverting income through companies, they will do so. While countries may have measures that try to counteract this, those measures will usually not be 100% effective and tend to be costly to enforce.&nbsp;</li><li><strong>Tax treaties</strong>. As explained above, countries enter into DTAs, which often contain clauses that limit how each country may tax the other country\u2019s residents and citizens. For example, DTAs usually limit the withholding tax rates a source country may impose on dividends, interest and royalties, and the countries will also be limited to the definitions of \u201cdividends\u201d, \u201cinterest\u201d and \u201croyalties\u201d used in these DTAs. So even if they change their domestic law to increase withholding taxes on interest or broaden the definition of \u201croyalties\u201d, an existing DTA may override it. (The domestic law change would still have effect to the extent where there is no DTA, though.)&nbsp;</li><li><strong>Arbitrage opportunities</strong>. Inconsistent tax systems give rise to international arbitrage and avoidance opportunities. For example, a common argument against wealth taxes and death duties is that they are too easy to avoid if the taxpayer moves to another country. Arbitrage opportunities can also prevent some innovative tax systems from being tried. For instance, a country that&nbsp;<a href=\"https://en.wikipedia.org/wiki/Consumption_tax#Expenditure_tax\"><u>shifts its tax base from income to consumption by allowing a full deduction for investment/savings</u></a> might find its tax base obliterated if taxpayers can too easily record \u201cinvestment\u201d there without increasing their real investment in the country. While I don\u2019t want to suggest that the risk of creating arbitrage opportunities is insurmountable, it can be a formidable challenge.&nbsp;</li></ul><p>A possible exception to this is the US, which may have enough weight/influence to effectively force other countries to change their tax systems. They are also unique in having a citizen-based tax system, which reduces concerns of tax-induced migration, at least for individuals.&nbsp;</p><h3>International tax reforms are relatively \u201csticky\u201d&nbsp;</h3><p>Bilateral DTAs are pretty sticky. Many last for decades because it is a lot of effort to renegotiate them and both countries must be willing to prioritize it.&nbsp;</p><p>Multilateral reforms are even more sticky because of the difficulty in getting multiple countries that may have diverging interests to agree.&nbsp;<a href=\"https://doi.org/10.1017/CBO9780511977855.005\"><u>The current international tax framework was established in the early 20th century</u></a> and many think it hasn\u2019t changed enough to keep up with modern developments.&nbsp;</p><p>A key issue with the current framework is that taxing rights are primarily based on physical presence \u2014 e.g. factories, offices, employees, etc. Many people think this is no longer appropriate given the Internet and how globalized the economy is now. A firm today can do a lot of trade with a country without having to pay income tax there if it has no/limited physical presence in that country.&nbsp;</p><p>In recent years, some countries have enacted digital service taxes, which impose tax even if the firm has no physical presence in the country. These are unilateral measures, which are not covered by existing tax treaties, and which the US considers to be discriminatory. The US has therefore responded by threatening to impose tariffs on relevant countries to counteract the revenue they would get from digital service taxes.</p><p><a href=\"https://www.oecd.org/tax/beps/beps-actions/action1/\">Pillar One of the Two-Pillar Solution</a> is intended to be a multilateral alternative to digital services taxes. If successful, it would arguably be the biggest change to the international tax framework since WWII. (However, this is a big \"if\" and many commentators have voiced doubts about whether Pillar One will succeed.)&nbsp;</p><h3>Broader foreign policy aspects</h3><p>International tax seems to have gotten increasingly political in recent years, particularly as large multinationals have gotten widespread attention for not paying \u201cenough\u201d tax. As noted above, Pillar One is intended to be part of the solution for this \u2014 and is very political. Some believe that Pillar One is a real test for the multilateral rules-based order. If the Pillar One proposal falls over, there could be more unilateral taxes as well as tariffs and trade wars.</p><p>Another foreign policy angle is the growing tension between developing and developed countries in tax policy development. Also as noted above, some developing countries have been pushing for the UN to have a bigger role in developing international tax policy because they consider the UN to be more inclusive and have greater legitimacy than the OECD.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref782ty2f2cq5\"><sup><a href=\"#fn782ty2f2cq5\">[3]</a></sup></span>&nbsp;</p><h2>Neglectedness</h2><p>My view is that the neglectedness of international tax is also&nbsp;<i><strong>high</strong></i>.&nbsp;</p><p>The areas of tax that tend to be highly politicised seem to have a domestic focus, probably because they directly affect voters and are easier to understand (e.g. what tax rates should be, whether wealth taxes are good, etc). International tax, by contrast, is highly technical and often requires understanding other countries\u2019 tax systems. Most private sector practitioners also have limited engagement with tax treaties.&nbsp;</p><p>International tax also tends to be dominated by tax experts rather than foreign diplomats. Diplomats may often be more engaged with the public and media, which could be part of the reason international tax gets relatively little attention.&nbsp;</p><h2>Tractability</h2><p>This is the area I am least certain about as it is highly dependent on what aspect you're assessing. Overall I would assess tractability as&nbsp;<i><strong>low</strong></i>.&nbsp;</p><p>However, even if we cannot solve the entire problem, I think individuals can have considerable impact given how high \"Impact\" and \"Neglectedness\" seem to be. Moreover, there currently seems to be more traction than there has been in a long time, given the Pillar One and Pillar Two work and the UN/OECD turf war mentioned above.&nbsp;</p><h1>Possible roles for individuals</h1><h2>OECD Secretariat</h2><h3><u>Potential Impact</u></h3><p>I have not worked at the OECD but my impression is that Secretariat members are given a fair degree of autonomy in how to progress their workstreams.&nbsp;</p><p>While countries ultimately are the ones that agree or not to proposals, I believe OECD Secretariat can be incredibly influential because:</p><ul><li>How proposals are framed initially makes a big difference in how they are received by countries.&nbsp;</li><li>Country delegates often have to be across many or all workstreams while each OECD Secretariat member may just work on a few. As such, OECD Secretariat will be far more familiar with the technical details in their workstream.&nbsp;</li><li>Many of the smaller, technical details will have important consequences but are not things that countries are willing to die in a ditch over, so OECD Secretariat can sometimes &nbsp;put in whatever they think is sensible. This is especially the case if there is a lot of time pressure and country delegates have to pick their battles. &nbsp;</li><li>OECD Secretariat members also play a key mediation role in getting countries that start out with differing positions to agree (e.g. by surfacing concerns and suggesting alternative compromises). Some OECD people are more or less effective at this, and I think it can make a difference in whether or not an overall agreement is reached.&nbsp;&nbsp;</li></ul><h3><u>Other considerations</u></h3><ul><li>Must live in, or be willing to commute to, Paris.&nbsp;</li><li>My impression is these are highly competitive and quite demanding roles.&nbsp;</li><li>Good career capital.</li></ul><h2>Country delegate&nbsp;</h2><p>A country delegate represents their country in tax treaty negotiations and/or at OECD/Inclusive Framework meetings.&nbsp;</p><p>The role usually sits in a country's tax policy function, within the Treasury or Finance department. The role may be more or less specialised depending on the country \u2014 some delegates only do international tax and treaties, while others also work on domestic tax policy.&nbsp;</p><h3><u>Potential impact</u></h3><p>The potential impact you can have as a delegate will depend on your seniority and on your country.&nbsp;</p><p>Senior delegates will have more influence through their relationships with other country delegates. Delegates can also be elected Chairs of the OECD Working Parties, where they have more influence still.&nbsp;</p><p>If you are in the US you would have a much bigger impact as a country delegate as the US voice is always given considerable weight. On the flipside, I expect it would be harder to work up to an influential role within the US Treasury. (But I could be wrong \u2014 this area might be relatively neglected within the US Government too.)</p><p>If you are in an OECD country, this might be a particularly&nbsp;high-impact path, especially if your country does not have&nbsp;sizable think-tanks or international charities. While larger countries like the US hold more sway at the OECD level, smaller countries can have a big impact relative to their size since they still have a seat at the table. Sensible suggestions can also find support regardless of which country it comes from.&nbsp;</p><h3><u>Other considerations</u></h3><p>The job will usually involve international travel, which can be a pro or a con.&nbsp;</p><p>Apart from that, what the job is like and how stressful it is will depend heavily on your country and perhaps even the culture within your particular organisation or team. Some countries, especially those with just one or two delegates, rarely intervene or make submissions. Other countries are heavily involved in almost all proposals. There are also countries in between these two extremes.&nbsp;</p><p>While countries that are heavily involved tend to have larger teams to spread the workload, it can still be very demanding. Some deadlines are unreasonably tight and there can also be long virtual meetings at unsociable hours (depending on your time zone).&nbsp;</p><p>It was not, in my experience, all that hard to become a country delegate. Again, this will depend on your country, but the level of competition seems to be lower than for other foreign policy roles (e.g. within foreign affairs departments).&nbsp;&nbsp;</p><h2><a href=\"https://www.ataftax.org/\">African Tax Administration Forum (ATAF)</a></h2><p>Many African countries have very limited tax policy resources. There is a lot of material to get across to understand the proposals and the timeframes allowed are very tight, because of the political commitments made to reach agreements by certain dates. Even my OECD country struggles with resourcing all of this work, and I can only imagine it's much harder for most of the African countries, especially if English is not their native language.&nbsp;</p><p>ATAF helps African countries cope with this policy workload. I don't know the details of how ATAF works, but I do know they put in comments on multilateral proposals and speak up at meetings on behalf of their member countries.&nbsp;</p><h2>United Nations&nbsp;</h2><p>I don\u2019t think the UN has any tax policy staff at all. If they do, it won\u2019t be many. My understanding is they rely on&nbsp;<a href=\"https://www.un.org/esa/ffd/tax-committee/tc-members.html\"><u>a committee of tax experts</u></a> instead, with those experts nominated by countries. These are not full-time jobs. Many of these experts are also country delegates, so the best path to becoming a UN tax expert is probably to become a country delegate.</p><h2><a href=\"https://www.tiwb.org/\">Tax Inspectors Without Borders (TIWB)</a></h2><p>TIWB is a joint OECD/UN initiative. I don't know a lot about this role, only what I've read from public materials.&nbsp;</p><p>TIWB are mostly looking for experienced auditors/tax inspectors that can help developing countries build up their audit capacity. They do not seem to offer entry-level positions or full-time jobs \u2014 instead, they look for recently retired or currently serving tax officials.&nbsp;</p><p>TIWB\u2019s work is a bit different from what I\u2019ve been describing above, as their main work (audit) is different from policy. But apparently they are looking to expand to provide support in other areas, including tax treaty negotiations and implementation.&nbsp;</p><h1>Personal fit</h1><h2>Background and skills</h2><ul><li><strong>Law</strong>. Helpful for reading and interpreting treaties. But interpreting treaties is a bit different from interpreting domestic laws, so a legal background is not essential (at least in my country).&nbsp;</li><li><strong>Economics/Finance.&nbsp;</strong>Again, helpful but not essential. You don't need to be great with numbers but it\u2019s good if you can work through and understand complex tax examples and understand why tax laws are designed the way they are (they often have economic underpinnings).&nbsp;</li><li><strong>Relationship, people, communication skills</strong>. It\u2019s helpful if you can read a room, understand other people's points of view, communicate your ideas effectively, and find ways to bridge disagreements.</li></ul><h2>Ideas for testing your fit or getting started&nbsp;</h2><ul><li>Follow OECD work \u2014 they run a video series called&nbsp;<a href=\"https://www.oecd.org/tax/tax-talks-webcasts.htm\"><u>OECD Tax Talks</u></a> (I've never watched these myself, though.)</li><li>OECD internships</li><li>Policy internships/jobs in your home country.&nbsp;</li><li>Tax internships/jobs at law firms or accounting firms.&nbsp;</li></ul><p>I only have experience with the last one \u2014 I did a brief stint in tax at a large commercial law firm before moving to policy and found it gave me a good grasp of tax laws, particularly those relevant to large multinational corporations.&nbsp;</p><p>My law firm experience also gave me better technical tax knowledge than my colleagues who had worked the equivalent number of years in tax policy. This is because advice had short turnaround times so I worked on many pieces of advice and had to quickly familiarise myself with different areas of tax. In contrast, policy projects take a long time so you might end up working on the same project for months or even years.&nbsp;</p><p>However, note that law and accounting firms will not necessarily give you transferable skills \u2014 it depends on what work you get at these firms. If you end up doing compliance work or advice for high net worth individuals, you may not get a solid grounding in international tax.&nbsp;</p><p><br><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fno2acsfa8zna\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefo2acsfa8zna\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Some argue that the US has too much influence at the OECD because&nbsp;<a href=\"https://www.oecd.org/about/budget/member-countries-budget-contributions.htm\"><u>they are the single largest funder of the OECD</u></a>. Others, however, argue that the US does not have enough influence, given that some of its States by themselves are larger than many OECD countries.<br><br>More generally, US domestic tax reforms have often spurred international tax reforms \u2014 examples include the US's FATCA regime leading to international AEOI, and US CFC rules causing other countries to adopt similar CFC rules.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxwq362r14pj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxwq362r14pj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>A <a href=\" https://www.oecd.org/tax/beps/presentation-webinar-economic-impact-assessment-global-minimum-tax-january-2024.pdf\">recent OECD estimate</a> says Pillar Two is expected to raise between USD 155-192 billion per year, which represents an increase of between 6.5% to 8.1% of global corporate income tax (CIT) revenues. &nbsp;I've just reversed the calculation to get the CIT figure.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn782ty2f2cq5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref782ty2f2cq5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>While I personally have a lot of sympathy for these concerns, the practical reality is that: (1) the OECD is much better resourced and has both the funding and the necessary tax expertise; and (2) whatever the UN comes up with will be toothless if developed countries refuse to agree to it. For example, as noted above, the UN Model Tax Convention gives greater taxing rights to source countries but developed countries are more likely to follow the OECD Model.&nbsp;</p></div></li></ol>", "user": {"username": "Tax Geek"}}, {"_id": "WGMzKNkktx4Gpt9ui", "title": "Should convincing wealthy individuals to donate be prioritized?", "postedAt": "2024-01-23T06:00:15.423Z", "htmlBody": "<p>Hello! I'm Toby Satake, and I'm new to Effective Altruism Forum, so forgive me if this kind of question has already been asked!</p><p>If it was possible to convince very rich people (like movie actors and other celebrities) to donate to effective charities, would it be more effective to spend one's lifetime just doing that instead of working in a high-paying job and donating that money to charity?</p><p>My thought process goes somewhat like this:</p><p>-one might get a basic job just to pay the bills, and avoid time/money spent training for a better one</p><p>-even if most people refuse to donate, if just one or two donate a portion of their money it would have a huge effect, quite easily larger than a year spent working the high paying job. And a lot of people could be asked in one year.</p><p>-if they are high-publicity, it might motivate lots of others to donate, especially if they endorse it.&nbsp;</p><p>&nbsp;Of course I could be easily missing some key points that render the whole idea useless (maybe people aren't generally very convincible, even if you try 100 times in a year). But I find it interesting. I'd love to hear any counterpoints\u2014that's why I posted!</p><p>Thanks!</p><p>P.S-in an ideal world, what if there was an organization or movement where lots of high-profile or high-income people were convinced to donate, making it part of culture? Perhaps other high-income people felt a bit more expected to follow suit? This last idea is probably much harder...</p><p>P.P.S: one person answered it (an amazing answer btw), but I'd love to hear opinions from others still!</p>", "user": {"username": "Toby Satake"}}, {"_id": "AS5Boa4q3ia4hXRBE", "title": "[Linkpost] BBC - How much does having a baby contribute to climate change?", "postedAt": "2024-01-23T05:47:28.415Z", "htmlBody": "<p>I recently had the opportunity to talk about the climate effects of having children on the BBC\u2019s What In the World podcast in an episode titled \u201cHow much does having a baby contribute to climate change?\u201d (<a href=\"https://www.bbc.co.uk/sounds/play/w3ct67cb\">link</a>, <a href=\"https://twitter.com/J_Ackva/status/1749561728642548118\">X/Twitter</a>).</p><p>The episode is very short (~15min) and conversational and covers the debate from several angles and with multiple voices. I try to make the argument, building on <a href=\"https://www.founderspledge.com/research/climate-and-lifestyle-report\">prior work</a> with John Halstead, that <strong>(i)</strong> extrapolating from current emissions massively overestimates expected emissions of kids born today (\u201ca kid born today will never drive a petrol car\u201d) and that, in addition to that, <strong>(ii)</strong> credible jurisdiction-level policies such as the UK\u2019s net-zero targets should lead to a situation where additional kids in those jurisdictions have (close to) zero counterfactual impact. <strong>(iii)</strong> Instead of making our decision about having children about climate change, our primary responsibility as individuals should lie in holding our governments accountable that targets are met and ambitious policies maintained / passed.</p><p>I actually found it somewhat shocking how normalized / unquestioned anti-natalist assumptions are even in 2024. I am the only voice in the episode questioning the idea that climate change should not be a reason to not have children. So I hope that\u2019s a useful intervention and reference to point to.</p>", "user": {"username": "jackva"}}, {"_id": "CriuHkkEqyMMnjMQk", "title": "How did you update on AI Safety in 2023?", "postedAt": "2024-01-23T02:21:35.645Z", "htmlBody": "<p>2023 was a massive year in AI. What updates did you make? This includes timelines, likelihood of various risks and/or alignment plans/strategies.</p>\n", "user": {"username": "casebash"}}, {"_id": "LmtD3JKGJt4HHijyz", "title": "PEPFAR and the Costs of Cost-Benefit Analysis", "postedAt": "2024-01-23T00:53:33.356Z", "htmlBody": "<p>\"In the early aughts, economists said it was a bad use of money to send antiretroviral drugs to treat HIV in low-income countries. Twenty years later, we can ask why they got it wrong.\"</p><p><a href=\"https://asteriskmag.com/issues/05/pepfar-and-the-costs-of-cost-benefit-analysis\">In this new piece</a>, Justin Sandefur writes about PEPFAR \u2013 the large US-led program to tackle AIDS in poor countries \u2013 for Asterisk magazine. It expands on <a href=\"https://www.cgdev.org/blog/how-economists-got-africas-aids-epidemic-wrong\">his blogpost</a> on CGDev last year.</p><p>The piece describes the arguments economists made in the early 2000s against PEPFAR. Some recommended against PEPFAR because they believed it was not cost-effective, that it would crowd out other foreign aid funding, and that prevention would be more cost-effective than treatment.</p><p>However, as the piece explains, the costs dropped significantly as the program scaled up, the program opened up new funding (such as for malaria and tuberculosis), and the evidence behind other prevention approaches that were recommended was often weak.</p><p>&nbsp;</p><p>[Although it's not mentioned in the piece, it's also worth adding that antiretroviral therapy is actually both a treatment and a preventive measure. It reduces the replication of HIV, and also reduces the spread of HIV.]</p>", "user": {"username": "salonium"}}, {"_id": "5o7KW5Q6PKPrKt4WR", "title": "Most recent EA giving/prioritization survey?", "postedAt": "2024-01-22T22:11:15.387Z", "htmlBody": "<p>The <a href=\"https://forum.effectivealtruism.org/posts/29xPsh2MKkYGCuJhS/ea-survey-2019-series-donation-data#Which_Charities_are_EAs_Donating_to_\">EA forum 2019 survey</a> asked \"Which Charities are EAs Donating to?\". As far as I can tell, the more recent <a href=\"https://forum.effectivealtruism.org/s/FxFwhFG227F6FgnKk\">2022 survey</a> didn't ask that question or didn't report on it. Does anyone have a more recent source for questions like \"what percent of EAs donate to global health vs AI risk?\" or \"what do EAs report as the most important causes?\"<br><br><a href=\"https://forum.effectivealtruism.org/users/david_moss?mention=user\">@David_Moss</a> who ran the 2022 survey</p>", "user": {"username": "andrew_richardson"}}, {"_id": "ibHCSqAGkCFPex8j4", "title": "Summary: Against Anti-Fanaticism (Christian Tarsney)", "postedAt": "2024-01-25T15:04:52.069Z", "htmlBody": "<p><a href=\"https://globalprioritiesinstitute.org/against-anti-fanaticism-christian-tarsney/\"><i><u>Against Anti-Fanaticism</u></i></a><i> is a Global Priorities Institute Working Paper by Christian Tarsney. This post is part of my</i><a href=\"https://forum.effectivealtruism.org/s/aY38LaKmqEtoaqyFq\"><i>&nbsp;<u>sequence</u></i></a><i> of GPI Working Paper summaries.</i></p><p><i>If you\u2019d like a very brief summary, skip to \u201cConclusion/brief summary.\u201d</i></p><p>Hilary Greaves and William MacAskill&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pvD57QQSCaFWRRK95/paper-summary-the-case-for-strong-longtermism-hilary-greaves\"><u>think</u></a> objections to fanaticism are among the strongest counterarguments to strong longtermism. Such objections also underpin some of the strongest counterarguments to expected value theory. Thus, contemplating fanaticism is critical for comparing neartermist and longtermist causes.</p><p>Here I\u2019ve done my best to summarize Tarsney\u2019s argument, making it more easily accessible while sacrificing as little argumentative strength as possible.</p><h1>Introduction</h1><p>Anti-fanaticism has an intuitive edge: Say you must choose between guaranteeing a very good future for all sentient life or a gamble with a one-in-a-googol chance of an even better future and instant annihilation otherwise. Most would take the sure thing\u2014that\u2019s an&nbsp;<i>anti-fanatical&nbsp;</i>choice.</p><p>Instead of focusing on fanaticism\u2019s truth or falsity, as do previous papers<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"1\" data-footnote-id=\"d86piku24z\" role=\"doc-noteref\" id=\"fnrefd86piku24z\"><sup><a href=\"#fnd86piku24z\">[1]</a></sup></span>, Tarsney focuses on fanaticism\u2019s opposing thesis:&nbsp;<i>anti-fanaticism</i>.</p><ul><li><i><strong>Anti-fanaticism</strong></i><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"2\" data-footnote-id=\"pmph538kw\" role=\"doc-noteref\" id=\"fnrefpmph538kw\"><sup><a href=\"#fnpmph538kw\">[2]</a></sup></span><strong>:&nbsp;</strong>There is some positive probability&nbsp;<i>p</i> and good&nbsp;<i>g</i> such that you prefer having&nbsp;<i>g</i> for sure to having&nbsp;<i>any</i> good (no matter how great) with probability&nbsp;<i>p</i> or less.</li></ul><p>Tarsney stresses the existence of a middle ground between fanaticism and anti-fanaticism, which he calls&nbsp;<i>permissivism</i>, and that arguments against anti-fanaticism (including this paper)&nbsp;<i>aren\u2019t</i> arguments&nbsp;<i>for</i> fanaticism and vice versa.&nbsp;</p><h1>Anti-fanaticism generalized</h1><p>Previous debate about fanaticism focuses on special cases of choosing between a binary gamble and a sure outcome. A more general (and realistic) case is choosing either to shift a small amount of probability from a much worse outcome to a better one or to modestly improve every outcome. This better reflects our choices about whether we try to mitigate existential risks, as they don\u2019t decisively determine the probabilities\u2014our action isn\u2019t humanity\u2019s only hope, nor is our inaction humanity\u2019s only chance of doom. Instead, there are preexisting chances of both, which we might shift away from doom. Hence, it\u2019s more accurate to use small&nbsp;<i>differences</i> in intermediate probabilities, not small absolute probabilities.</p><h3>General Anti-Fanaticism (definition)</h3><p>He alters the definition of anti-fanaticism to capture this more general and realistic case:</p><ul><li><strong>An Improvement (</strong><i><strong>I</strong></i><strong>)&nbsp;</strong>makes every possible outcome better.</li><li><strong>General Anti-Fanaticism: </strong>There is a large enough improvement&nbsp;<i>I</i> and a small enough probability&nbsp;<i>p</i>, that makes certainty of improvement&nbsp;<i>I</i> better than a probability shift of&nbsp;<i>p</i> from one outcome (no matter how bad) to another (no matter how good).</li></ul><h1>Against anti-fanaticism</h1><p>Tarsney argues General Anti-Fanaticism is incompatible with the following extremely plausible principles:</p><ul><li><strong>No Best Outcome:</strong> For every outcome, a better outcome is possible.&nbsp;</li><li><strong>No Worst Outcome:</strong> For every outcome, a worse outcome is possible.</li><li><strong>Minimal Dominance:</strong> If an outcome is better than another outcome, then certainty of the better outcome is better than certainty of the worse outcome.</li><li><strong>Acyclicity:</strong> In a chain of prospects where each new prospect is better than the previous, the first prospect isn\u2019t better than the last.</li></ul><p>He demonstrates that, if we accept No Best/Worst Outcome and Minimal Dominance, General Anti-Fanaticism is cyclical: Choosing between improving every outcome or shifting a small amount of probability to an astronomically better outcome, an anti-fanaticist always chooses the former. However, after making a series of choices, this can lead our anti-fanaticist to end up with a prospect they think is worse than the one they started with\u2014violating acyclicity&nbsp;<i>(see&nbsp;</i><a href=\"https://globalprioritiesinstitute.org/against-anti-fanaticism-christian-tarsney/\"><i><u>pages 12 and 13</u></i></a><i> for his demonstration).</i></p><p>Because Tarsney finds the principles behind this argument so plausible, he concludes we should reject General Anti-Fanaticism.</p><h1>Compact EU and Quantile Discounting</h1><p>He proposes two modifications of Expected Utility Theory for those who agree with General Anti-Fanaticism despite its incompatibility with these extremely plausible principles:&nbsp;<i>Compact EU</i> and&nbsp;<i>Quantile Discounting</i></p><h3>Compact EU</h3><p>Bounded EU sets a maximum and minimum amount of utility, where utility can approach these bounds without ever reaching them. This has previously been used to solve fanatical implications, along with other problems<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"3\" data-footnote-id=\"fpormpqimvh\" role=\"doc-noteref\" id=\"fnreffpormpqimvh\"><sup><a href=\"#fnfpormpqimvh\">[3]</a></sup></span>.</p><p>However, Bounded EU&nbsp;<i>doesn\u2019t</i> satisfy General Anti-Fanaticism because if the universe is very likely to be very good, Bounded EU will prefer to shift the probability of extinction instead of improving every outcome.</p><p>He says if we modify Bounded EU to have hard limits (reachable maximum and minimum utilities), then it satisfies the spirit of General Anti-Fanaticism<span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"4\" data-footnote-id=\"1boghyphoat\" role=\"doc-noteref\" id=\"fnref1boghyphoat\"><sup><a href=\"#fn1boghyphoat\">[4]</a></sup></span>. He calls this&nbsp;<i>Compact EU</i>. However, it violates either No Best/Worst Outcome or Minimal Dominance (Tarsney finds rejecting either of these to be highly implausible).</p><h3>Quantile Discounting</h3><p>Other attempts to avoid fanaticism simply ignore very small probabilities, but these face powerful objections. Tarsney proposes a version of small-probability discounting,&nbsp;<i>Quantile Discounting</i><span class=\"footnote-reference\" data-footnote-reference=\"\" data-footnote-index=\"5\" data-footnote-id=\"n73v3iwjfxq\" role=\"doc-noteref\" id=\"fnrefn73v3iwjfxq\"><sup><a href=\"#fnn73v3iwjfxq\">[5]</a></sup></span>, that he finds the most plausible way of satisfying General Anti-Fanaticism, but remains skeptical because it violates Acyclicality (as shown in the previous section).</p><h1>Conclusion/brief summary</h1><ol><li>Tarsney modifies fanaticism to capture more general and realistic cases, in which we slightly shift probabilities from much worse outcomes to much better ones, rather than making binary gambles.</li><li>He shows how, unless we give up some extremely plausible principles, this general version of anti-fanaticism is cyclical: It\u2019ll prefer a series of prospects, only to end up with a prospect it considers worse than the one it started with.</li><li>He proposes two modifications of Expected Utility Theory for those who agree with General Anti-Fanaticism despite its incompatibility with extremely plausible principles: Compact EU and Quantile Discounting.</li><li>He demonstrates he&nbsp;<i>hasn\u2019t</i> argued&nbsp;<i>for</i> fanaticism, only against anti-fanaticism, and he argues that a middle ground exists: permissivism, which features&nbsp;<i>incomplete</i> preferences that aren\u2019t fanatical or anti-fanatical. He thinks fanaticism\u2019s skeptics should prefer permissivism to anti-fanaticism.</li></ol><ol class=\"footnote-section footnotes\" data-footnote-section=\"\" role=\"doc-endnotes\"><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"1\" data-footnote-id=\"d86piku24z\" role=\"doc-endnote\" id=\"fnd86piku24z\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"d86piku24z\"><sup><strong><a href=\"#fnrefd86piku24z\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>See Wilkinson's \"<a href=\"https://forum.effectivealtruism.org/posts/mQqH2X3sGygNGdgN9/summary-in-defence-of-fanaticism-hayden-wilkinson\">In Defence of Fanaticism</a>\" and Beckstead &amp; Thomas' \"<a href=\"https://forum.effectivealtruism.org/posts/s42GKdCb2svwya9Li/paper-summary-a-paradox-for-tiny-probabilities-and-enormous\">A Paradox for Tiny Probabilities and Enormous Values</a>.\"</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"2\" data-footnote-id=\"pmph538kw\" role=\"doc-endnote\" id=\"fnpmph538kw\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"pmph538kw\"><sup><strong><a href=\"#fnrefpmph538kw\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>His formal definition can be found on <a href=\"https://globalprioritiesinstitute.org/against-anti-fanaticism-christian-tarsney/\">page 6</a>.</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"3\" data-footnote-id=\"fpormpqimvh\" role=\"doc-endnote\" id=\"fnfpormpqimvh\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"fpormpqimvh\"><sup><strong><a href=\"#fnreffpormpqimvh\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>Namely, paradoxical objections to Expected Utility Theory, which Tarsney describes:&nbsp;</p><blockquote><p>Unbounded utilities allow for prospects with infinite expected utility (generalizations of the St. Petersburg game), which have various paradoxical properties and are in tension with aspects of expected utility theory.</p></blockquote><p>(See footnote 10 on <a href=\"https://globalprioritiesinstitute.org/against-anti-fanaticism-christian-tarsney/\">page 14</a> for further discussion)</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"4\" data-footnote-id=\"1boghyphoat\" role=\"doc-endnote\" id=\"fn1boghyphoat\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"1boghyphoat\"><sup><strong><a href=\"#fnref1boghyphoat\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>This modified version of Bounded EU doesn't quite satisfy General Anti-Fanaticism, but it nearly does. Plus, it will fully satisfy a slightly modified version of General Anti-Fanaticism (see <a href=\"https://globalprioritiesinstitute.org/against-anti-fanaticism-christian-tarsney/\">page 16</a> for discussion).</p></div></li><li class=\"footnote-item\" data-footnote-item=\"\" data-footnote-index=\"5\" data-footnote-id=\"n73v3iwjfxq\" role=\"doc-endnote\" id=\"fnn73v3iwjfxq\"><span class=\"footnote-back-link\" data-footnote-back-link=\"\" data-footnote-id=\"n73v3iwjfxq\"><sup><strong><a href=\"#fnrefn73v3iwjfxq\">^</a></strong></sup></span><div class=\"footnote-content\" data-footnote-content=\"\"><p>See pages 18 to 20 for details.</p></div></li></ol>", "user": {"username": "NicholasNicholas"}}, {"_id": "dpJquJhNfiEx6BPw2", "title": "Small World: Looking for feedback on our data visualization", "postedAt": "2024-01-22T20:15:40.974Z", "htmlBody": "<p>Together with my friend Bine, I'm working on an interactive data visualization, designed to give a general audience a big picture of what's happening on Earth.</p><p>It works by <strong>shrinking down the Earth by a factor of 100 million</strong>. We picked that factor because it gives nice, memorable numbers, and you can do the conversion in your head. For example, on our \"Small World\", there are <strong>81 people, 11 cars, and 7 cats!</strong></p><p>We found that after people interact with the page, they often can remember the involved numbers and proportions really well! (Remember the 7 cats? There must be 700 million cats on the real Earth.)</p><p>You can find the project at <a href=\"https://smallworld.blinry.org\">https://smallworld.blinry.org</a>.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dpJquJhNfiEx6BPw2/dts983f3kz8fis6nbrm2\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dpJquJhNfiEx6BPw2/scgbp9zhjw6t9nuariqk 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dpJquJhNfiEx6BPw2/yed4rmo25nqrqtsh665v 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dpJquJhNfiEx6BPw2/owba5vr8q9lla589k4kd 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dpJquJhNfiEx6BPw2/nfumfdmzvfcz6rbbdajo 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dpJquJhNfiEx6BPw2/c7tmzihichepzvwa6mek 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dpJquJhNfiEx6BPw2/w9fkzg7mc7nguzw7tqv7 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dpJquJhNfiEx6BPw2/cndj4ngiqi7ytwpeqtx6 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dpJquJhNfiEx6BPw2/dg511ua1dgcurpo10b4f 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dpJquJhNfiEx6BPw2/jiom5tqi0qjwswlej4iz 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/dpJquJhNfiEx6BPw2/ibwbyqg5pa1qysxhjt8v 2089w\"></figure><p>To make the site as helpful as possible, we'd love your <strong>feedback on the following questions</strong> (either here or in the survey linked at the bottom of the article):</p><ul><li>While reading the article, what surprised you the most?</li><li>Is there something you felt was missing?</li><li>Was something on the website broken or did not work as intended?</li></ul><p>Also, feel free to critique our approach, or mention ideas for developing it further!</p>", "user": {"username": "blinry"}}, {"_id": "WCGiLCucpC8L3GBaw", "title": "Presentation -- The Unjournal: Bridging the gap between EA and academia", "postedAt": "2024-01-22T19:49:13.421Z", "htmlBody": "<p><i>Subtitle: Our Approach to Research Evaluation and Impact</i></p><h1>Notes and links</h1><p>Below, a mixed AI &amp; human summary.</p><p>Links, unless mentioned, are time stamps to&nbsp;<a href=\"https://www.youtube.com/watch?v=_b5wiSJX6NQ&amp;list=PLwCHmz77VrK1Bi92uyDHE9XCH-bWc-7B_&amp;index=5&amp;t=2056s\"><u>the Youtube video</u></a><br>Presentation slides: <a>here</a></p><p>YouTube playlist: <a href=\"https://youtube.com/playlist?list=PLwCHmz77VrK1Bi92uyDHE9XCH-bWc-7B_&amp;si=oWDeTnEz-hgX7OEw\">\"Unjournal, impactful research, robust open science\"</a> (more on this later, building this, may be collaborative)</p><p>See <a href=\"https://unjournal.org\">Unjournal.org</a> to learn more about <i>The Unjournal</i>.&nbsp;</p><h1>Introduction</h1><p><a href=\"https://youtu.be/_b5wiSJX6NQ?si=938KFNajgOLDfgTC&amp;t=135\"><u>\u201cWhat is the Unjournal\u201d</u></a></p><p>The Unjournal is not a traditional journal. Instead, it represents a new approach to the evaluation of research, particularly focusing on quantitative work that informs global priorities in economics, policy, and other social sciences. This innovative platform is building an open, sustainable system for evaluation, feedback, ratings, and assessment of research projects in any format.</p><h1>The Problem with Traditional Academic Peer Review</h1><p><a href=\"https://youtu.be/_b5wiSJX6NQ?si=0uynwpbUdDjdzwLw&amp;t=240\"><u>What is academic peer review, what are the issues with it</u></a>?</p><p>In fields like Economics, the traditional publication process can be lengthy, often taking anywhere from six months to a decade. The outcome of this process is typically just the journal in which the research is published, which doesn't provide a comprehensive view of the research's quality or impact.</p><p>It also limits the formats of research content, diverts&nbsp;<i>a lot</i> of effort towards gaming the system, and can discourage continued improvement to long-term robust research projects (\u201cI already \u2018got\u2019 the publication so who cares\u201d?).&nbsp;</p><p>I come back to this&nbsp;<a href=\"https://youtu.be/_b5wiSJX6NQ?si=fNHP7NELNt8KcpZO&amp;t=1774\"><u>later in the presentation (here)</u></a> under \u2018why not just use academic publishing?\u2019 (<a href=\"https://docs.google.com/presentation/d/10NVKiVqb6PlYPCzTsQYtRvEPncMysrisly7bSbYfBOI/edit#slide=id.g2965468047a_0_45\"><u>slides link here</u></a>)&nbsp;</p><h1>The Unjournal's Solution</h1><p><a href=\"https://youtu.be/_b5wiSJX6NQ?si=ILKCofgFeRKbS0iz&amp;t=310\"><u>\u201cUnjournal\u2019s main ingredients\u201d</u></a></p><p>The Unjournal addresses these limitations by:</p><ul><li>Research Submission/Identification and Selection: Focusing on impactful research and selecting works that align with global priorities.</li><li><i>Paid</i> Evaluators: Engaging experts to provide thorough evaluations&nbsp;<ul><li>\u2026 and useful,&nbsp;<i>quantifiable</i> metrics.</li></ul></li><li>Public Evaluation: Making the evaluation process transparent and accessible to all.</li><li>Linking, Not Publishing: Connecting evaluations to research without the exclusivity of traditional publishing, allowing links to research in&nbsp;<i>any format</i> including web sites and dynamic documents.</li><li>Financial Prizes and Transparency: Offering incentives for high-quality research and maintaining openness in operations.</li></ul><h1>Theory of Change: leveraging problem synergy</h1><p><a href=\"https://youtu.be/_b5wiSJX6NQ?si=ephUGtqKTNUIw3Wr&amp;t=423\"><u>Our theory of change</u></a></p><p>The Unjournal's approach leverages the synergy between the needs of effective altruism (EA) and the resources of academia. It aims to direct public evaluation of research relevant to global priorities, addressing the limitations of the outdated journal system and shifting attention towards impactful research.</p><p>See the&nbsp;<a href=\"https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/benefits-and-features/global-priorities-theory-of-change\"><u>flowchart here</u></a><u>.</u></p><p><a href=\"https://youtu.be/_b5wiSJX6NQ?si=dMzBYQn08MN3ndMD&amp;t=654\"><u>To convince you that The Unjournal has value, I must convince you that</u></a>\u2026</p><ul><li>Research matters</li><li>&nbsp;Rigorous prioritization research can positively influence funding, decision-making, and/or policy.</li><li>Rigor and expertise add value.&nbsp;</li><li>(Peer) review &amp; evaluation can add value to research (and research-use&nbsp;</li><li>The status quo peer review system is suboptimal&nbsp;</li><li>Academic publishing has substantial room for improvement and/or Global-priorities-relevant research &nbsp;would benefit from more scrutiny.&nbsp;</li><li>&nbsp;The UJ\u2019s approach can succeed.</li></ul><h1>What Makes Research Impactful?</h1><p><a href=\"https://youtu.be/_b5wiSJX6NQ?si=mWwmDSG1E1_7Vd1c&amp;t=935\"><u>\u201cWhat is it/why does it matter?\u201d</u></a></p><p>Impactful research is defined as work that produces true, useful information, enabling better decision-making and leading to improved outcomes. This can influence resource allocation, policy nature, and decision-makers' thinking.</p><p>How do we prioritize research for evaluation, how do we think about this? See unjournal.org: Broad discussion&nbsp;<a href=\"https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/considering-projects/what-research-to-target\"><u>here</u></a>, flowcharts&nbsp;referenced can be seen <a href=\"https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/considering-projects/process-prioritizing-research-wip/prioritization-ratings-discussion\"><u>here.</u></a></p><h1>Fields and Approaches Covered by The Unjournal</h1><p>The Unjournal currently focuses on fields related to human behavior and its consequences, including economics, quantitative social science, business/policy, forecasting, and cost/benefit analysis. It prioritizes empirical measurement, theory/modeling, and methodology with direct policy applications.</p><p>Details on our scope on our web page&nbsp;<a href=\"https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/considering-projects/what-specific-areas-do-we-cover\"><u>here</u></a>&nbsp;</p><h1>The Value of Evaluation</h1><p>(Youtube timed-link&nbsp;<a href=\"https://youtu.be/_b5wiSJX6NQ?si=rip0rk6u-EpyDgBL&amp;t=1456\"><u>here \u2026 \u2018why is evaluation important\u2019?</u></a>)</p><p>The Unjournal emphasizes the importance of evaluation in providing credibility, domain expertise, and usefulness to research users. It also plays a crucial role in prioritizing research for funding and attention.</p><p><a href=\"https://youtu.be/_b5wiSJX6NQ?si=xK1i_J-ruu5HumN6&amp;t=1541\"><u>EA research evaluation \u2026&nbsp; my impression of \u2018the state of the art</u></a> in EA\u2019 and the limitations, opportunities for wins; benefits coming from the Unjournal\u2019s pilot evaluations</p><h1>Overcoming Academic Inertia, collective-action problems</h1><p>The Unjournal aims to overcome academic inertia by providing a platform that is risk-tolerant, externally funded, and innovative. It seeks to make its evaluations a standard part of the academic review process, offering a public alternative before traditional journal reviews.</p><p><a href=\"https://youtu.be/_b5wiSJX6NQ?si=F1OA3G0MrgZPIrNZ&amp;t=1926\"><u>\u201cTowards a new equilibrium\u201d</u></a></p><p><a href=\"https://youtu.be/_b5wiSJX6NQ?si=ZGuIbnzClA9ipkFP&amp;t=2020\"><u>Overcoming the CAP</u></a></p><p>&nbsp;</p><h1>Progress and Roadmap</h1><p><a href=\"https://youtu.be/_b5wiSJX6NQ?si=EmMleJzDssPbTpWu&amp;t=2098\"><u>The Unjournal\u2019s progress</u></a> /&nbsp;<a href=\"https://docs.google.com/presentation/d/10NVKiVqb6PlYPCzTsQYtRvEPncMysrisly7bSbYfBOI/edit#slide=id.g2965468047a_0_130\"><u>Slide link</u></a></p><p>The Unjournal has made significant progress in establishing its platform, building a team, and developing systems for research prioritization and evaluation. The roadmap ahead includes raising awareness, establishing credibility, and scaling the scope of operations. This involves building tools and systems to grow without compromising quality.</p><p><br><a href=\"https://youtu.be/_b5wiSJX6NQ?si=hyxWSpfE-J2Vw-oW&amp;t=2248\"><u>Our Roadmap ahead</u></a> (see earlier writeup&nbsp;<a href=\"https://docs.google.com/document/d/1C5CE8X_rgGEZnewdKFsbxSGw7l0PxmQvr8F4tv7ege8/edit\"><u>here</u></a>)</p><p>&nbsp;</p><h1>Challenges and Pivotal Choices</h1><p>The Unjournal faces several challenges, including gaining commitments from prominent academics and open science organizations, encouraging submissions of dynamic documents, and ensuring that evaluations are recognized and valued in academia. Key questions revolve around evaluation criteria, aggregation, and creating useful outputs for research users.</p><p><a href=\"https://docs.google.com/presentation/d/10NVKiVqb6PlYPCzTsQYtRvEPncMysrisly7bSbYfBOI/edit#slide=id.g296c2dd0807_0_198\"><u>Slide link</u></a></p><h1>How to Get Involved</h1><p><a href=\"https://youtu.be/_b5wiSJX6NQ?si=nUX2O-hxGE_qQ_L3&amp;t=2369\"><u>How can you get involved? (video link)?</u></a></p><p><a href=\"https://docs.google.com/presentation/d/10NVKiVqb6PlYPCzTsQYtRvEPncMysrisly7bSbYfBOI/edit#slide=id.g296c2dd0807_1_19\"><u>Slide link, links links that you can use to link up and engage</u></a></p><p>The Unjournal encourages engagement from the academic and research community. Opportunities include:</p><ul><li>Submitting research for evaluation.</li><li>Reading, using, and citing evaluations.</li><li>Spreading the word within academic circles and on social media.</li><li>Partnering with The Unjournal for events and collaborations.</li><li>Joining the team as a paid evaluator or field specialist.</li><li>Suggesting work for evaluation.</li><li>Providing feedback and participating in discussions on platforms like the EA Forum.</li></ul><h1>Q&amp;A</h1><p>&nbsp;</p><p>The Q&amp;A&nbsp;<a href=\"https://youtu.be/_b5wiSJX6NQ?si=u391LRDNAYdK8mcN&amp;t=2471\"><u>(time stamped link)</u></a> may have touched on</p><ul><li>How does The Unjournal ensure the quality and expertise of its evaluators?</li><li>What strategies does the Unjournal use to encourage researchers to submit their work for evaluation?</li><li>How does The Unjournal plan to integrate with or complement existing academic publishing and evaluation systems?</li><li>What are the long-term goals and vision of the Unjournal, especially regarding its impact on academia and research?</li><li>How does The Unjournal handle conflicts of interest or biases in the evaluation process?</li><li>What measures are in place to ensure the transparency and accountability of the Unjournal's evaluation process?</li><li>(How) does The Unjournal plan to expand its scope to include a wider range of research fields or disciplines?</li></ul><p><br>&nbsp;</p>", "user": {"username": "david_reinstein"}}, {"_id": "fZ6W5ykmkhx6PkTxi", "title": "Some Problems with Comparing Factory Farming to the Holocaust", "postedAt": "2024-01-22T17:57:13.070Z", "htmlBody": "<p><em>Author\u2019s Note: this post based on an old Discord rant</em></p>\n<p>Sometimes I see vegans or just animal rights/welfare activists in general making comparisons between factory farming and various human atrocities, such as the Holocaust. Everyone else really hates this. On its own this is probably a good reason to avoid these comparisons, but the rationalist side of me, sympathetic to defending reasonable but unpopular viewpoints, isn\u2019t fully satisfied with that reason. It isn\u2019t exactly an original observation of mine, but factory farming is not <em>just</em> very bad for the individuals subjected to it, it is <a href=\"https://forum.effectivealtruism.org/posts/pT7AYJdaRp6ZdYfny/estimates-of-global-captive-vertebrate-numbers\">absolutely vast</a> in scale. Exactly how vast depends on what specifically you want to count and in what ways<sup class=\"footnote-ref\"><a href=\"#fn-vu8uCTP5oqh2X55Te-1\" id=\"fnref-vu8uCTP5oqh2X55Te-1\">[1]</a></sup>, but these questions roughly amount to asking by how many times humans are outnumbered by factory farmed animals. I have seen one rationalist adjacent person put it by saying that denying the comparability of factory farming and the Holocaust requires valuing humans more than 1,000 times more than farm animals. If this is the case, then it seems like even those who ultimately reject the comparability have weak grounds for asking that the opposite opinion be taboo.</p>\n<p>This point is so inflammatory I\u2019ve gone back and forth on whether to write this piece at all, but the numbers are such that it\u2019s, again, hardly an original point anyway. More to the point though, I am not primarily writing this piece as a defense of the comparison anyway, but I think to make a point that is more original. I too feel a certain repugnance at bluntly comparing factory farming and various atrocities like the Holocaust, and some investigation into relevant differences has given me some better reasons for this repugnance than mere PR, or some undeniable difference in overall badness. There are several things that I think make the backlash more understandable even if they are not often explicitly appealed to in admonitions like this, and I think actually explicitly laying them out is a valuable exercise the detractors don\u2019t seem to offer very often.</p>\n<p>Aggregation:</p>\n<p>Long-time readers will know that <a href=\"https://www.thinkingmuchbetter.com/main/5-objections-to-utilitarianism/#5-aggregation\">aggregation</a> is <a href=\"https://www.thinkingmuchbetter.com/main/aggregation-fail-utilitarianism-ways/\">one of</a> my <a href=\"https://www.thinkingmuchbetter.com/main/partial-aggreg-utility-monster/\">running interests</a> on this blog. Pure aggregation is not directly implied by any obviously uncontestable principle, it has repulsive implications at certain extremes, and worst of all, there are robust structural reasons why it\u2019s pretty hard <em>not</em> to do anyway. The 1,000x challenge looks pretty impressive if it\u2019s something like the relevant difference in badness, but numbers like this come largely from pure aggregation. That is, it doesn\u2019t come from factory farming being 1,000 times worse of an experience than life in a concentration camp, it comes from the difference in the number of impacted individuals.</p>\n<p>I think this problem doesn\u2019t look that obvious to people like me from an intuitive standpoint because, well, we actually do think life on a factory farm is very bad on an individual level, in a morally serious way. But in order to relate to what this number is asking of our detractors as a standard of evidence, we\u2019d need to imagine how we would feel about something we <em>do</em> think is 1/1,000 as bad but impacts 1,000x more individuals. For that matter, try 1,000,000x, or whatever, if the higher number makes the argument more impressive, then let us make the number in the numerator and denominator as big as we want.</p>\n<p>Say someone compared the Holocaust to all the itchy foreheads in the history of the world. I might find this offensive. I don\u2019t think it would really address my discomfort if they went on to say that I would have to value itchy scalps a million times less than life in a concentration camp in order to react in this way. Given this, the actual factor of difference in valuing humans versus non-humans doesn\u2019t need to be nearly so high as the aggregates imply for the common reaction to the factory farming comparison to be understandable.</p>\n<p>Reference Class:</p>\n<p>Even if someone did basically accept that factory farming as a whole is as bad as the Holocaust was, it might seem like an unfair comparison that misses what gives the Holocaust its unique significance. Say that I compared the Holocaust to all of the murders in history. I think many people wouldn\u2019t feel too much aggregation-based discomfort in just admitting that literally all the non-Holocaust murders in history put together are worse than the Holocaust was, but you still might think that it\u2019s an unfair comparison. Likewise even if you think that \u201cfactory farming\u201d as a whole is worse than the Holocaust was, it\u2019s easy enough for me to turn this around by asking whether the current practices of the <a href=\"https://en.wikipedia.org/wiki/Tyson_Foods\">Tyson</a> corporation specifically are worse than all of the human-on-human bigoted violence throughout history. Well\u2026no, that isn\u2019t plausible. The question becomes why we are making these different comparisons in the way we are, if we can slice the different sides up in arbitrarily many different ways to push the scales to any side we want.</p>\n<p>It seems like just saying a given thing is, taken as a whole, comparably bad to the Holocaust misses the whole point of why the Holocaust is remembered in the way that it is. The Holocaust is something that generations since have had to accept is within range of human nature to carry out \u2013 something so hateful, and so concentrated in its evil, but also diffuse in just how many people needed to consent to it in some way for it to reach its scale. We don\u2019t learn any of this from the increasing count of murders as history passes on, we know isolated people are capable of singlehandedly carrying out isolated murders, and as the scope of this phenomenon expands with the march of history, we aren\u2019t dealing with new, worse activities in the process. Just a larger amount of the same. We don\u2019t see a new Hitler every year.</p>\n<p>Factory farming certainly isn\u2019t just lots of isolated cases of animal abuse. There are many participants, and large bodies in charge of concentrated amounts of this abuse. But it is still a broad class of activities, much broader than the Holocaust, and you can\u2019t earn all of the cultural significance the Holocaust has just by drawing a circle around a sufficient amount of this broader phenomenon. That misses the point.</p>\n<p>Personal Judgment:</p>\n<p>I would not sit down for a meal with Hitler to discuss the merits of murderous antisemitism. I think most people would not. If I consider the Holocaust comparable in badness to factory farming, there might be an implicit sense that I think the same way about the defenders of factory farming. That they are promoting something so awful that I would shun them, refuse to be friends with them, refuse to even talk the issue over with them. If this logic holds, then the person making the comparison seems to either be affirming this consequence, that I will shun people who disagree with me on this issue, or that I deny the premise, and that I am implying that I would willingly associate and calmly debate the Holocaust with a Nazi. Either possibility is offensive.</p>\n<p>I think this is a good reason to find the comparison in isolation too unnuanced, but I don\u2019t agree with the logic above. There are other things besides expected badness of events that make me more or less willing to associate with people. For one very basic thing, as I\u2019ve <a href=\"https://www.thinkingmuchbetter.com/main/complexities-of-free-speech-appendix/#appendix-d\">argued before</a>, whether you should shun someone for a position depends in part on how common that opinion is. This spans a wide range of plausible reasons from pragmatism to virtue, and it certainly is a big difference in this case. A Nazi is someone who (in modern times, at least) is part of an unpopular minority with little political power, who nevertheless has elected to go against the grain in the direction of Naziism in particular. Defenders of factory farming represent an unavoidable contingent of people who haven\u2019t yet adopted an unpopular position on farming (i.e. opposing factory farms) they were probably not raised to believe.</p>\n<p>The other major reason is maybe more robust however. While I think factory farming is extremely bad, this depends on a number of philosophically controversial premises that provide a great deal of uncertainty about exactly how bad, and at least some (not much in my opinion) uncertainty that it is bad at all. The Holocaust is much more straightforward. In order to believe that the Holocaust was fine, you need to believe a host of wildly implausible things about virtually indistinguishable groups of humans, plus the defensibility of mass suffering, death, and violated autonomy as an appropriate way to address this. I have no real uncertainty about how bad the Holocaust was, and will consider anyone who disagrees deeply disturbed in probably multiple ways. Despite the fact that I don\u2019t think the simple comparison implies this judgment for the given reasons, it does iron over this difference in a way that, by default, carries some of this baggage.</p>\n<p>Rhetorical Emergency Button:</p>\n<p>Somewhat related to the last point, the Holocaust has a special place in our culture as this unique example of great evil. There are many things that have something like this role, like slavery and South African apartheid and various serial killers and dictatorships. A rhetorical strategy that one sometimes sees in debates about controversial issues is one side rushing to find a way to compare their favored issue to one of these things. To press a sort of \u201crhetorical emergency button\u201d.</p>\n<p>This immediately brings the conversation somewhere more charged than any other type of comparison or argument the person might make, and will almost always be received poorly. Because it brings so much cultural baggage to the table alongside the specific argument, it comes off as a desperate strategy, that not only treats the topic at hand in this imprecise and misleading way, but wears down these emergency buttons in the process \u2013 treats them less and less like important and unique tragedies our culture must treat with care, and more as rhetorical cartoon characters. The Holocaust just becomes the sort of thing you point to as an obvious win the first chance you can by finding one point of comparison between it and your favored cause.</p>\n<p>I think this is a real source of backlash and a reasonable point to be worried about, but I also think it is possible to avoid the emergency buttons too much. If the lesson we are supposed to take away from the Holocaust is \u201cnever again\u201d, then you can either stipulate this by pointedly refusing to call anything that happens after it an \u201cagain\u201d, or you have to seriously consider arguments about when a new event counts as \u201cagain\u201d, even if this means sorting through many candidates that you ultimately reject in the process.</p>\n<p>Conclusion:</p>\n<p>Although I think all of these reasonable worries are in the background of the impulse to condemn anyone who makes this comparison, I don\u2019t want to give the impression that this is always an entirely reasonable reaction. Most obviously, I think that people often don\u2019t invoke these things very well when explaining their reaction, and indeed often they don\u2019t give much explanation <a href=\"https://www.instagram.com/p/ChIT1BqPZfW/?igshid=YmMyMTA2M2Y%3D\">at all</a>. Sometimes the explanation will be on the terms of overall badness discussed at the beginning, that the Holocaust as an event was just obviously so much worse than factory farming is that the comparison is ridiculous. At that point a simple response like the scale comparison at the beginning is enough of a counter \u2013 this is just a bad point. Even if denying the comparison is a reasonable position, when comparing aggregate badness, it is overdetermined by sheer scale that affirming the comparison is also a defensible position. You need a different argument about what\u2019s different in these cases.</p>\n<p>Additionally, I think there are some reasons for this intuitive reaction that are real factors but are just bad. Notably there are people who are part of this conversation who have survived the Holocaust, know someone who survived it, or would have themselves been subjected to it based on their demographics if it happened again today (I fall into this category myself). Factory farmed animals on the other hand are not part of this conversation in any real capacity. There are people who can be offended on a personal level by accidentally downplaying the Holocaust, but there is no one who can be offended on a similarly personal level by accidentally downplaying factory farming. Let me be clear about this \u2013 I consider this a terrible basis for moral discourse, one that inherently favors the <a href=\"https://www.thinkingmuchbetter.com/main/philanthropy-democracy-limitations/\">already empowered</a>, the already listened to.</p>\n<p>I also think that there are dimensions along which this comparison is useful other than sheer aggregate badness, which we should not miss. One of the major figures known for controversially comparing factory farming to the Holocaust is <a href=\"https://www.youtube.com/watch?v=6RhrbuqUy6E\">Alex Hershaft</a>, himself a Holocaust survivor. After getting out, he saw the conditions and tactics used on factory farms - neat piles of body parts, identifying tattoos, large concentrated living facilities, cattle cars - and found them horrifyingly familiar. After some time of isolation and introspection on the matter, he decided to become a dedicated animal rights activist. In one way the comparison is obvious to all sides \u2013 and inconclusive in its relevance. It is a well known staple of ethnic hatred that the group subjected to this hatred will often be compared to, and treated in the ways we treat, non-human animals. The defenders of how we treat animals will point to this as evidence that we draw any human to non-human comparisons like this at our peril, while the opponents of our treatment of animals will say that this is proof that we can\u2019t separate humans from non-humans so cleanly, and our abuse and dismissal of the feelings of animals will inevitably be a model for how we are willing to treat humans.</p>\n<p>I don\u2019t think this is necessarily the only lesson worth drawing from the familiarity Hershaft found however. Antisemitic pogroms and abusive animal agriculture are both extremely old practices. The Holocaust and factory farming are new. In the wake of <a href=\"https://ourworldindata.org/much-better-awful-can-be-better\">wonderful advancements</a> that have cut child mortality rates and raised the standard of living to impressive heights, the evils that will come to most dominate our future are likely to be of a very different character to the mass plague and famines of the past. Factory farming, like the Holocaust, represents a peculiarly modern evil, drawing the ignorance and hatred that have always been part of the human condition up to new heights of efficient brutality and scalability. Mass produced suffering.</p>\n<p>When I worry most about the future, I think especially of <a href=\"https://web.archive.org/web/20230218033848/https://deluks917.wordpress.com/2020/08/20/animal-rights-ai-risk/\">this post</a>, and the way it illustrates how worried we should be by the example of factory farming, as a manifestation not merely of great evil, but of the sort of great evil characteristic of the future. You don\u2019t need to compare how bad factory farming and the Holocaust are to fear what their similarities have to tell us (indeed despite drawing parallels, Hershaft himself doesn\u2019t consider them comparable), and the way these similarities add a certain specificity and urgency to the future of \u201cnever again\u201d.</p>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn-vu8uCTP5oqh2X55Te-1\" class=\"footnote-item\"><p>Lives at a given moment? Lives per given span of time? And which animals deserve to be in the same bucket, based on both complexity and farming methods? <a href=\"#fnref-vu8uCTP5oqh2X55Te-1\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n</ol>\n</section>\n", "user": {"username": "Devin Kalish"}}, {"_id": "d8nW46LrTkCWdjiYd", "title": "Rates of Criminality Amongst Giving Pledge Signatories", "postedAt": "2024-01-22T17:42:45.514Z", "htmlBody": "<h2>Summary</h2><ol><li>I investigate the rates of criminal misconduct amongst people who have taken <a href=\"https://en.wikipedia.org/wiki/The_Giving_Pledge\"><u>The Giving Pledge</u></a>&nbsp;(roughly: ~200 [non-EA] billionaires who have pledged to give most of their money to charity).</li><li>I find that rates are fairly high:<ol><li>25% of signatories have been accused of financial misconduct, and 10% convicted<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftxgdaylifoh\"><sup><a href=\"#fntxgdaylifoh\">[1]</a></sup></span></li><li>4% of signatories have spent at least one day in prison</li><li>Overall, 41% of signatories have had at least one allegation of substantial misconduct (financial, sexual, or otherwise)</li></ol></li><li>I estimate that Giving Pledgers are not less likely, and possibly more likely, to commit financial crimes than YCombinator entrepreneurs.</li><li>I am unable to find evidence of The Giving Pledge doing anything to limit the risk of criminal behavior amongst its members, though I have heard second-hand that they do some sort of screening.</li><li>I conclude that the rate of criminal behavior amongst major philanthropists is high, which means that we should not expect altruism to substantially lower the risks compared to that of the general population, and that negative impacts to EA\u2019s public perception may occur independently of whether our donors actually commit crimes&nbsp;(e.g. because even noncriminal billionaires have a negative public image).</li></ol><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d8nW46LrTkCWdjiYd/ivuzms6osr4wvoaoytry\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d8nW46LrTkCWdjiYd/djuycpezojqtnfhrnxxv 120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d8nW46LrTkCWdjiYd/mzvk0b9viqpax8kynaba 240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d8nW46LrTkCWdjiYd/gvt4emhunuomafi8ker0 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d8nW46LrTkCWdjiYd/weetbsknwkoo3olppeku 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d8nW46LrTkCWdjiYd/jb7kdxka8mmgaymo8zqb 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d8nW46LrTkCWdjiYd/gjca2uhvqajs8adrngh9 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d8nW46LrTkCWdjiYd/b4ceraidtdbjd714zmzr 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d8nW46LrTkCWdjiYd/hcxrashwgfvxyesjlqiv 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d8nW46LrTkCWdjiYd/npr155jru5yyzkftxcf8 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d8nW46LrTkCWdjiYd/ctx4vyrlkpqzeg1pdyqs 1200w\"></figure><h2>Methodology</h2><ol><li>I copied the list of signatories from <a href=\"https://givingpledge.org/pledgerlist\"><u>their website</u></a>.</li><li>Gina Stuessy and I searched the internet for \u201c(name) lawsuit\u201d, \u201c(name) crime\u201d and also looked at their Wikipedia page.</li><li>I categorized&nbsp;any results into \u201cfinancial\u201d, \u201csexual\u201d, &nbsp;and \u201cother\u201d, and also marked if they had spent at least one day in jail.</li><li>Gina and I eventually decided that the data collection process was too time-consuming, and we stopped partway through. The final dataset includes 115 of the 232 signatories.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref33k9qjwqfa4\"><sup><a href=\"#fn33k9qjwqfa4\">[2]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqcn6jz5uzbq\"><sup><a href=\"#fnqcn6jz5uzbq\">[3]</a></sup></span>&nbsp;</li><li>Data can be found <a href=\"https://docs.google.com/spreadsheets/d/1GfJ_D1-63lxFKYUBPz3-akWRVuj5EVfW-IcRy1SIOjg/edit#gid=0\"><u>here</u></a>.</li></ol><h3>How well do convictions correspond with immoral behavior?</h3><ol><li>It is a well-worn take that our<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcbjbixz2yge\"><sup><a href=\"#fncbjbixz2yge\">[4]</a></sup></span>&nbsp;legal system overly protects white-collar criminals: If an employee steals $20 from the cash register, that\u2019s a criminal offense&nbsp;that the police will prosecute, but if an employer under-pays their employees by $20 that\u2019s a civil offense&nbsp;where the police don\u2019t get involved.</li><li>I found that the punishment of the criminals in my data set correlated extremely poorly with my intuition for how immorally they had behaved.<ol><li>It would be funny if it weren\u2019t sad that one of the longest prison sentences in my data set is from Kjell Inge R\u00f8kke, a Norwegian businessman who <a href=\"https://en.wikipedia.org/wiki/Kjell_Inge_R%C3%B8kke#Boat_license_conviction\"><u>was convicted</u></a>&nbsp;of having an illegal license&nbsp;for his yacht.</li></ol></li><li>One particular way in which white-collar offenses are weird is that they often allow the defendant to settle without admitting wrongdoing.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdrm5rk69vl\"><sup><a href=\"#fndrm5rk69vl\">[5]</a></sup></span>&nbsp;E.g. my guess is that Philip Frost is guilty, but his settlement with the SEC <a href=\"https://www.cnbc.com/2018/12/28/biotech-billionaire-philip-frost-agrees-to-proposed-judgment-in-sec-case.html\"><u>does not require him</u></a>&nbsp;to admit wrongdoing.<ol><li>I wasn\u2019t able to find a single person who admitted guilt in a sexual misconduct case, despite ~7% of the signatories being accused, including in high-profile cases like people involved with Jeffrey Epstein.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz8q9aq12xgc\"><sup><a href=\"#fnz8q9aq12xgc\">[6]</a></sup></span></li></ol></li><li>I was considering trying to add some classification like \"Ben thinks this person is guilty\" but decided that this would be too time-consuming and subjective.<ol><li>Nonetheless, if you want my subjective opinion, my guess is that most of the people who were accused of financial misconduct are guilty of immoral behavior, under a <a href=\"https://www.rep.routledge.com/articles/thematic/common-sense-ethics/v-1\"><u>commonsense morality</u></a>&nbsp;definition of the term.</li></ol></li><li>Less controversially, some of these cases are ongoing, and presumably at least some of them will result in convictions, which makes looking only at the current conviction rate misleading.</li><li>In any case though, I believe that this data set establishes that the base rate of both criminal and immoral behavior is fairly high among major philanthropists, no matter how you slice the data.</li></ol><h3>Some Example Cases</h3><p>Here are a few cases to give some flavor of what Giving Pledge signatories have been accused of.</p><p>&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Mario Gabelli</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Used sham businesses to fraudulently purchase portions of the US cell phone spectrum. Settled for $130 million. Sued for breach of fiduciary responsibility in an unrelated case, settled for $100 million. <a href=\"https://en.wikipedia.org/wiki/Mario_Gabelli%23Legal_Issues\"><u>https://en.wikipedia.org/wiki/Mario_Gabelli#Legal_Issues</u></a>&nbsp;</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Michael Milken</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>Milken was indicted for racketeering and securities fraud in an insider trading investigation. Milken was sentenced to ten years in prison, fined $1.1 billion ($2.3 billion in 2023 dollars) and permanently barred from the securities industry. He was pardoned by Donald Trump in 2020.</p><p><a href=\"https://en.wikipedia.org/wiki/Michael_Milken\"><u>https://en.wikipedia.org/wiki/Michael_Milken</u></a>&nbsp;</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Richard Branson</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Jailed for tax fraud; accused of sexual assault but denies accusation and I cannot find official charges. <a href=\"https://en.wikipedia.org/wiki/Richard_Branson%23Tax_evasion\"><u>https://en.wikipedia.org/wiki/Richard_Branson#Tax_evasion</u></a>&nbsp;</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Anil Agarwal</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>\u201cIn 2004, a committee of the Indian Supreme Court charged that Vedanta had dumped thousands of tons of arsenic-bearing slag near its factory in the Indian state of Tamil Nadu, resulting in major poisoning of the environment and neighbouring population. In 2005, another committee of the Indian Supreme Court charged that Vedanta had forced over one hundred indigenous families from their homes in the Indian state of Odisha, where it sought to mine bauxite. According to the committee's report: \"An atmosphere of fear was created through the hired goons\", and residents were \"beaten up by the employees of M/s Vedanta\".\u201d</p><p><a href=\"https://en.wikipedia.org/wiki/Anil_Agarwal_(industrialist)%23Controversy_and_criticism\"><u>https://en.wikipedia.org/wiki/Anil_Agarwal_(industrialist)#Controversy_and_criticism</u></a>&nbsp;</p></td></tr></tbody></table></figure><p>&nbsp;</p><h2>Are Giving Pledge&nbsp;signatories less likely to commit financial crimes?</h2><ol><li>I <a href=\"https://forum.effectivealtruism.org/posts/5mghcxCabxuaK4WTs/ycombinator-fraud-rates\"><u>previously estimated</u></a>&nbsp;that 1-2% of YCombinator-backed companies with valuations over $100M had serious allegations of fraud.</li><li>While not all Giving Pledge signatories are entrepreneurs, a large fraction are, which makes this a reasonable reference class.&nbsp;(An even better reference class would be \u201cnon-signatory billionaires\u201d, of course.)</li><li>We might na\u00efvely think that Giving Pledge signatories (being charitably minded) are less likely to commit financial crimes\u2014but if anything, it seems like the opposite is true.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefp985h2dllc9\"><sup><a href=\"#fnp985h2dllc9\">[7]</a></sup></span><ol><li>~10% of signatories being convicted of financial misconduct and ~25% accused versus ~1% of YCombinator companies is a stark difference.</li></ol></li><li>I have a few possible explanations:<ol><li>Giving Pledge signatories tend to run publicly-traded companies, whereas YCombinator companies are usually private, and it is easier to be charged with financial misconduct if your company is publicly traded.</li><li>Giving Pledge signatories are wealthier, and therefore more lucrative targets for prosecution.</li><li>Giving Pledge signatories are older, and have had more time to accumulate charges.</li><li><a href=\"https://www.amazon.com/Why-They-Do-White-Collar-Criminal/dp/1610395360\"><u>This book</u></a>&nbsp;argues that white-collar criminals generally do not see their behavior as immoral, because humans\u2019 moral intuitions don\u2019t fit a white-collar world. E.g. someone who is unusually moral might be more willing to give money to a homeless person on the street, but they aren\u2019t any less likely to aggressively depreciate assets in a quarterly earnings statement, because the latter does not pattern match to our intuitions of a (im)moral decision.</li></ol></li><li>I have not looked into any of these explanations deeply, but from a pragmatic perspective it seems clear that we should not expect that altruistically-minded HNWIs are notably less likely to commit financial crimes than the average person with the opportunity to do so.</li></ol><h2>Giving Pledge\u2019s Response to Criminal Behavior</h2><ol><li>As far as I can tell, the Giving Pledge is quite hands-off, and has not commented on the criminal behavior of some of its members or attempted to prevent criminal behavior. I can\u2019t find a single press release from them saying anything; the profiles of people like <a href=\"https://givingpledge.org/pledger?pledgerId%3D245\"><u>Michael Milliken</u></a>&nbsp;are sitting there without even a small banner saying \u201cwe don\u2019t endorse crimes,\u201d etc.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgft5ba2p13l\"><sup><a href=\"#fngft5ba2p13l\">[8]</a></sup></span><ol><li>The only thing I am aware of is <a href=\"https://www.forbes.com/sites/jemimamcevoy/2023/09/25/billionaire-t-denny-sanford-cut-from-the-giving-pledge-after-child-porn-probe-documents-released/?sh%3D2ff2d1565884\"><u>two cases</u></a>&nbsp;in which they have silently removed profiles: T. Denny Sanford was removed after accusations of child pornography, and Sam Bankman-Fried was removed after charges of defrauding investors.</li></ol></li><li>I have heard secondhand that they screen signatories beforehand, but cannot find any public documentation of their screening (and, as evidenced by the statistics reported here, any such screening does not seem to be terribly effective).</li><li>I\u2019m not surprised that they didn\u2019t make any actually-consequential reforms, but I am surprised that they don\u2019t e.g. issue press releases making some milquetoast statement about crime being bad.</li></ol><h2>PR Impacts</h2><ol><li>The Giving Pledge (and billionaire philanthropy more generally) receives a lot of criticism.</li><li>Despite this, I can find very little criticism referencing the fact that many of these signatories are criminals.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2b87mhvgmp5\"><sup><a href=\"#fn2b87mhvgmp5\">[9]</a></sup></span></li><li>My (perhaps uncharitable) interpretation is that there are some people who believe that billionaire philanthropy is immoral, and some who don\u2019t, but very few who take the nuanced view that some but not all billionaire philanthropy is immoral.<ol><li>Someone told me that they think this is a blind spot of EAs in general: The major risk of having wealthy/powerful people support your movement is that they may co-opt it toward their own goals, and that risk is largely independent of whether or not that person commits crimes, so the public is correctly not updating very much based on a certain movement\u2019s donors being criminals.</li><li>This fits with information I've heard from university group organizers: University students sometimes distrust EA because of ties to \"big tech\" or \"Silicon Valley billionaires\", and the more specific worry that some of these billionaires may have committed crimes does not affect their trust as much.</li></ol></li></ol><h2>Implications for EA</h2><ol><li>It seems fairly likely that any engagement with an ultrahigh net worth donor carries a substantial risk that the donor will turn out to have engaged in criminal behavior or will in the future.<ol><li>Some EA organizations use services that screen potential donors, but I am skeptical that these services will meaningfully decrease the risk of criminal behavior among these individuals, or be able to accurately identify which people are most likely to commit white-collar crimes.</li></ol></li><li>We should also be aware that engagement with ultrahigh net worth donors carries a risk of damaging EA\u2019s public perception, and that this risk may be partially independent of whether the donors are actually criminal.</li></ol><p><i>Thanks especially to Gina Stuessy for help with this article, but it also benefited from feedback from Jake McKinnon, Zach Robinson, Ben Rachbach, Will MacAskill, Jason, and Julia Wise.</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntxgdaylifoh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftxgdaylifoh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Legal pedantry note: I am including here people who have had civil judgments rendered against them (e.g. lawsuits from the SEC), even though in civil judgments people are technically \u201cadjudged liable\u201d, not \u201cconvicted\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn33k9qjwqfa4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref33k9qjwqfa4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I realized after doing this that the names are listed in alphabetical order by last name, so if there is some relationship between alphabetical position and criminality that bias would be leaking into the data set. This seems unlikely to me, but I guess you never know.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqcn6jz5uzbq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqcn6jz5uzbq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I populated the data for Michael Milken out of order because I found out about him through an earlier research project; he is therefore left out of aggregate statistics</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncbjbixz2yge\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcbjbixz2yge\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I\u2019ve most frequently heard this criticism of the US legal system; I think analogous things are true in other countries but I\u2019m not sure.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndrm5rk69vl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdrm5rk69vl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I tried to use my best judgment when marking people as \u201cconvicted\u201d or not, but I didn\u2019t have an established set of best practices to rely on, and I think it might be valuable for someone to recategorize these using a more formal method, if any readers are looking for a small research project.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz8q9aq12xgc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz8q9aq12xgc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;A reviewer noted that this is common with any sort of civil litigation, it\u2019s not unique to \u201cwhite-collar crime\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnp985h2dllc9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefp985h2dllc9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Please note that this is not a perfect comparison. A key difference is that the YCombinator article used a denominator of companies, whereas this looks at individuals. Nonetheless, I would be surprised if it turned out that giving pledgers are substantially less likely than YCombinator-backed companies to commit fraud.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngft5ba2p13l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgft5ba2p13l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I wouldn\u2019t be surprised to learn that they have some screening process which secretly prevents sketchy people from joining, but I can\u2019t find any reference to it online. And of course we can at least say that this screening process does not seem to be completely effective, given the rate of criminals amongst signatories.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2b87mhvgmp5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2b87mhvgmp5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://link.springer.com/article/10.1007/s12115-021-00580-0\"><u>This paper</u></a>&nbsp;lists numerous criticisms of billionaire philanthropy: it diminishes the role of community-based giving practices, it requires grantees to \u201cassimilate the dominant colonizer white culture\u201d, it undermines democratic control, it increases income inequality, it overly pushes market-based solutions, it influences political decisions through funding think tanks. Nowhere is criminal behavior on behalf of signatories mentioned.</p></div></li></ol>", "user": {"username": "Ben_West"}}, {"_id": "6yPJKZosNZFbLtdfi", "title": "Remittance Hell in Paradise", "postedAt": "2024-01-26T12:35:37.924Z", "htmlBody": "<h3>Brief Summary and Relevance to EA</h3><p>The Hahm <i>et al. </i>paper examines the potential of Fintech to lower remittance transaction costs in Pacific SIDS, fostering sustainable development. The ladder framework outlines adoption stages, emphasizing the interconnectedness of availability, accessibility, awareness, literacy, and trust. Remittance, defined as fees sent by foreign workers to their families in their home country, plays a crucial role in the economic context of Pacific SIDS. The study aligns with effective altruism by addressing a specific and a neglected problem, if solved, potentially benefiting vulnerable communities and contributing to global sustainability.</p><p>&nbsp;</p><h3><strong>Introduction</strong></h3><p>The term sustainability refers to the aim of living in balance with the environment and the community without causing a significant harm. There are 3 main, inter-connected aspects of sustainability: environment, social and economic. These 3 terms are connected to each other as the welfare of the society is heavily connected to the environment and the economic situation it\u2019s in (1). Financial technology (Fintech) based companies play a key role in the process of transforming to a sustainable society with their effects on financial inclusion, sustainable investment platforms and regulatory technology (2).&nbsp;</p><p>Hahm <i>et al</i>., focuses on the region of the world deemed as \u201cparadise\u201d: Pacific small island developing states (SIDS), and how can fintech address some of the key problems of Pacific islanders (3). Pacific SIDS are economically fragile. Hence, these countries are more vulnerable to external economic shocks (4). Pacific SIDS countries\u2019 one of the main income sources are remittances. However, transaction costs for sending money to Pacific SIDS remain among the highest in the world. As Tonga\u2019s 43.2% of GDP is based on remittances, reducing the transaction costs would benefit SIDS economies massively (5, 6). The UN sustainable developmental goals target for transaction costs is 3% (7). While the global average sits around 6% for 200 $, the average transaction cost over the 14 years (2009-2022) for Tonga is 10.6% (6). For Vanuatu, this average is 14.6% (7). If the UN goal of 3% is achieved, 20 million AUD will be saved by Tongan households (6). For Fiji and Vanuatu, this number increases to 30 million AUD (8, 9) and 29 million AUD (10, 11) respectively. The authors examine if fintech can help reducing transaction costs and what can be done to increase the fintech adoption rate in the Pacific islands.&nbsp;</p><p>&nbsp;</p><h3><strong>Summary</strong></h3><p>The authors identified 3 main reasons for the high transaction costs: small size of transfers, geography of Pacific SIDS and de-risking practices imposed by global institutions. The population of the Pacific SIDS countries are highly dispersed affecting the viability of physical banks. Fintech companies mostly operate digitally, thus, this tackles the geographical problems. Moreover, due to digital operation, Fintech companies have minimized operating costs such as rent. Fintech companies also use less intermediaries leading to lowered transaction costs (3). Between 2<sup>nd</sup> quarter of 2016 and 4<sup>th</sup> quarter of 2018, average transaction costs charged by online companies is 5.8% in Pacific SIDS. Mobile companies charge a slightly lower rate of 5.3%. The world average is 4.5% and 3.8% respectively. Hence, the authors suggest that fintech can be a viable option for reducing the transaction costs for Pacific SIDS (3). In the second part of the article, the focus is on how to increase adoption of fintech in these islands. The authors analyze the fintech environment in Pacific SIDS by analyzing it with 5 elements: availability, accessibility, awareness, trust, and literacy. Their analysis show that many of the Pacific SIDS countries do not have basic infrastructure for digital platforms. The countries that have the infrastructure lack the customer awareness needed for a strong fintech base. They crafted policy recommendations for SIDS country groups based on their readiness stage regarding the 5 elements used for analysis. Overall, the authors concluded that for sustainable development of Pacific SIDS countries, creating a basic infrastructure for fintech is key (3). &nbsp;</p><p>&nbsp;</p><h3><strong>Contextual Background</strong></h3><p>Remittance refers to the fee sent by a foreign worker to their own family in their home country (12). Thousands of workers from Pacific SIDS go for seasonal work to Australia and New Zealand and send money to their families (13). This is not unique to Pacific islands as many migrants send money to their families at their home country. In 2021, India and China households received 140 billion dollars combined in remittance (14). UN is aware of the potential of the positive impact of reducing remittance transaction fees and the goal for 2030 agenda for sustainable development goal is to reduce the average of remittance transaction costs to 3% and eliminate all the transaction costs higher than 5%. This goal alone serves 11-2 (out of 17) of the sustainable development goals (SDGs) at household, community, national and international level. One striking outcome of remittance is in poverty reduction in household level as every 10% remittance increase per capita decreases the poverty share of poor people by 3.5%. As climate change is one of the main reasons of migration, increased remittance income due to less transaction costs can allow the countries to combat with climate change related shocks more efficiently, instead of migrating to a new country (15).</p><p>As the Pacific SIDS face one of the highest transaction costs in the world, reducing this fee with fintech can lead to a leap in terms of achieving the SDGs in the case of remittances. If the suggested policy recommendations in the paper are implemented successfully, the practices can be an example for other remittance dependent countries.&nbsp;</p><p>&nbsp;</p><h3><strong>Critical Analysis</strong></h3><p>The ladder framework used by authors represent the 5 steps for adoption. The steps are availability, accessibility, awareness, literacy, and trust. The authors argue that without completing all steps, fintech adoption cannot be done. Key policy considerations were assigned for each step and these policy recommendations were matched with the countries based on their fintech adoption step (3). The ladder model gives a great overview of the path needs to be taken for fintech adoption in these countries. However, these elements are more connected, thus, instead of treating these steps as from a hierarchical viewpoint, more interconnected strategies can be beneficial. For instance, the authors only highlight the need for availability in for a group of countries where fintech services are limited and suggest supporting an innovative business environment for these countries. However, ignoring literacy, the 4<sup>th</sup> step, and solely focusing on availability might not be the optimal strategy as if the literacy increases first, it can increase demand for these technologies and it can lead to faster adoption when the technology becomes available to the population. Hence, a strategy involving the intersection of the steps may be more optimal. Another issue that authors state is the lack of reliable data regarding Pacific SIDS countries. Thus, focusing on reliable data collection for more informed and country-specific policy suggestions may be key before working on the availability. In a broad sense, the article contributes to the sustainability and fintech field by highlighting an important barrier against global sustainability and gives general policy recommendations for Pacific SIDS countries regarding fintech, based on their current adoption status.&nbsp;</p><p>&nbsp;</p><h3><strong>&nbsp;Comparative Analysis</strong></h3><p>The policy recommendations regarding remittance are in line in most of the articles. The main recommendations include cost reduction for remittance, tax reductions for remittances for increasing remittance flow, increasing local financial literacy and bank usage (16, 17, 18). In addition, the importance of data collection is also highlighted both in other remittance-heavy regions and in the Pacific region. For instance, financial demands surveys were not conducted in more than %50 of Pacific SIDS, leading to lack of data and a gap of knowledge for many islands in the region (19). Besides the incentives of remittances, it is argued that remittances can cause limited productivity in countries. In the case of Papua New Guinea, the flourishing mining sector caused the \u201cDutch disease\u201d and increased the wage rates massively (20). Some researchers draw parallels with the case of Papua New Guinea and a Pacific SIDS country, Tonga. In the case of Tonga, the flourishing sector is migrant remittances, and the economy of the country shows many characteristics of a Dutch disease. The strong focus on a specific export activity leads to increased control of resources and higher domestic production costs. All these result in significantly decreased global competitiveness. As the younger generation leaves to other countries and sends remittance to Tonga, this decreases the production in the country significantly (21). In Tonga, Samoa and Cook Islands, remittances are usually not invested in production and it disincentivizes to work (22). The controversy regarding the net effect of remittances on the countries\u2019 economies and people\u2019s welfare remains, and more data collection can provide a better path on policymaking regarding remittances.&nbsp;</p><p>&nbsp;</p><h3><strong>Reflection and Implications</strong></h3><p>The paper demonstrates how fintech can have a significant effect on reaching sustainable development goals in Pacific SIDS countries. Moreover, the authors construct a path for how fintech adoption can be achieved for Pacific SIDS countries using the 5 rung ladder model. The paper also involves country specific details such as Nauru not reporting the received remittance volume or Palau lacking ICT data is beneficial for future researchers and policymakers in terms of where to focus on each country (3). The future research may focus on expanding the available data by data collection in different Pacific SIDS countries and analyzing the outcomes of already existing programs such as Pacific Financial Inclusion program and Vodafone Fiji Innovation Lab. As the data from all countries expands and the results and impact of the programs are analyzed, more informed decisions can be made to make Fintech serve for sustainability in Pacific SIDS.&nbsp;</p><p>&nbsp;</p><h3><strong>Conclusion</strong></h3><p>Fintech can be one of the most efficient solutions for driving transaction costs down for remittance. The impact of driving down the costs of remittance is particularly important for sustainability in Pacific SIDS countries due to high transaction costs and remittance-heavy economy. Increasing the adoption rate of fintech in these countries is necessary to achieve these goals. Depending on the fintech adoption stage of the country, different actions must be taken such as building a basic digital infrastructure and increasing financial literacy. The lack of data for some countries limits the possibility for tailored policy recommendations. Hence, more data needs to be collected regarding this topic (3, 19). Some argue that Pacific SIDS countries such as Tonga are showing characteristics of a Dutch disease due to their remittance heavy economy (22). Thus, more research needs to be conducted to understand the net effects of remittances on the countries\u2019 sustainability and overall economy. Overall, the paper demonstrates how fintech can be an effective tool to achieve the sustainability goals in Pacific SIDS and gives policy recommendations for fintech adoption in Pacific SIDS.</p><p>&nbsp;</p><h3><strong>References</strong></h3><p>1. Johnston, P., Everard, M., Santillo, D., &amp; Rob\u00e8rt, K. H. (2007). Reclaiming the definition of sustainability.&nbsp;<i>Environmental science and pollution research international</i>,&nbsp;<i>14</i>(1), 60-66.</p><p>2. Arner, D. W., Buckley, R. P., Zetzsche, D. A., &amp; Veidt, R. (2020). Sustainability, FinTech and financial inclusion.&nbsp;<i>European Business Organization Law Review</i>,&nbsp;<i>21</i>, 7-35.</p><p>3. Hahm, H., Subhanij, T., &amp; Almeida, R. (2021). Finteching remittances in paradise: A path to sustainable development.&nbsp;<i>Asia &amp; the Pacific Policy Studies</i>,&nbsp;<i>8</i>(3), 435-453.</p><p>4. United Nations Conference on Trade and Development. (2012). <i>UNCTAD XIII pre-Conference event: Expert group meeting on addressing the vulnerabilities of small island developing states (SIDS) more effectively</i>.&nbsp;</p><p>5. National Reserve Bank of Tonga, \u201cRemittance Receipts Peaked in December 2021\u201d</p><p>6. The World Bank, \u201cRemittance Prices Worldwide: Sending Money from Australia to Tonga\u201d, 3 October 2023,&nbsp;<a href=\"https://remittanceprices.worldbank.org/corridor/Australia/Tonga\">https://remittanceprices.worldbank.org/corridor/Australia/Tonga</a>.</p><p>7. World Bank, \u201cRemittance Prices Worldwide Quarterly: An Analysis of Trends in Cost of Remittance Services\u201d, Issue 45, March 2023, 7,&nbsp;<a href=\"https://remittanceprices.worldbank.org/\">https://remittanceprices.worldbank.org/</a>.</p><p>8. The World Bank, \u201cRemittance Prices Worldwide: Sending Money from Australia to Fiji\u201d, 27 February 2023</p><p>9.&nbsp;Remittance total sourced from Reserve Bank of Fiji, \u201cRBF Annual Report August 2020 \u2014 July 2021\u201d. The World Bank, \u201cPersonal Remittances, Received (Current US$) \u2014 Fiji\u201d, 27 February 2023</p><p>10. The World Bank, \u201cRemittance Prices Worldwide: Sending Money from Australia to Vanuatu\u201d, 27 February 2023</p><p>11. The World Bank, \u201cPersonal Remittances, Received (Current US$) \u2014 Vanuatu\u201d, 27 February 2023</p><p>12. Yang, D. (2011). Migrant remittances.&nbsp;<i>Journal of Economic perspectives</i>,&nbsp;<i>25</i>(3), 129-152.</p><p>13. Department of Home Affairs. (2019). <i>Department of Home Affairs input to the Joint Standing Committee on Mi- gration inquiry into migration in regional Australia</i>. Australian Government.&nbsp;</p><p>14. World Bank Group. (2020). Covid-19: Remittance flows to shrink 14% by 2021. Retrieved from&nbsp;<a href=\"https://www.worldbank.org/en/news/press-release/2020/10/29/covid-19-remittance-flows-to-shrink-14-by-2021\">https://www.worldbank.org/en/news/press-release/2020/10/29/covid-19-remittance-flows-to-shrink-14-by-2021</a></p><p>15. United Nations. Remittances and the SDGs. Retrieved from https://www.un.org/en/observances/remittances-day/SDGs</p><p>16. Lopez-Cordova, E., &amp; Olmedo, A. (2006). International remittances and development: Existing evidence, policies and recommendations.&nbsp;<i>Occasional Paper, Inter-American Development Bank</i>.</p><p>17. Ratha, D. (2013). The impact of remittances on economic growth and poverty reduction.&nbsp;<i>Policy Brief</i>,&nbsp;<i>8</i>(1), 1-13.</p><p>18. Connell, J., &amp; Brown, R. P. (2005). Remittances in the Pacific: An overview.</p><p>19. United Nations Development Programme. (2017). Financial Services Demand Side Surveys.</p><p>20. Auty, R. 1993. Sustaining Development in Mineral Economies: The Resource Curse Thesis, London, Routledge.</p><p>21. Sturton, M. 1992. Tonga: Development Through Agricultural Exports, Pacific Islands Development Program Economic Report No.4, Honolulu</p><p>22. MacMaster, J. 1993 Strategies to Stimulate Private Sector Development in the Pacific Island Economies, in R.Cole and S. Tambunlertchai, Eds , The Future of Asia-Pacific Economies, Canberra, National Centre for Development Studies, ANU.</p>", "user": {"username": "Cengizhan B\u00fcy\u00fckda\u011f"}}, {"_id": "TwpoedzMpmy7k7NKH", "title": "Can a war cause human extinction? Once again, not on priors", "postedAt": "2024-01-25T07:56:01.170Z", "htmlBody": "<h1>Summary</h1><ul><li>Stephen Clare\u2019s classic EA Forum post <a href=\"https://forum.effectivealtruism.org/posts/aSzxoj7irC5jNHceB/how-likely-is-world-war-iii\"><u>How likely is World War III?</u></a>&nbsp;concludes \u201cthe chance of an extinction-level war [this century] is about 1%\u201d. I <a href=\"https://forum.effectivealtruism.org/posts/aSzxoj7irC5jNHceB/how-likely-is-world-war-iii?commentId%3DvRYHa7X4yxPuTdxvz\"><u>commented</u></a>&nbsp;that <a href=\"https://en.wikipedia.org/wiki/Power_law%23Estimating_the_exponent_from_empirical_data\"><u>power law</u></a>&nbsp;extrapolation often results in greatly overestimating tail risk, and that fitting a power law to all the data points instead of the ones in the right tail usually leads to higher risk too.</li><li>To investigate the above, I looked into historical annual&nbsp;war deaths along the lines of what I did in <a href=\"https://forum.effectivealtruism.org/posts/M6zAzCBAsBxem7Lu4/can-a-terrorist-attack-cause-human-extinction-not-on-priors\"><u>Can a terrorist attack cause human extinction? Not on priors</u></a>, where I concluded the probability of a terrorist attack causing human extinction is astronomically low.</li><li>Historical annual war deaths of combatants suggest the annual probability of a war&nbsp;causing <a href=\"https://forum.effectivealtruism.org/topics/human-extinction\"><u>human extinction</u></a>&nbsp;is astronomically low once again. 6.36*10^-14 according to my preferred estimate, although it is not <a href=\"https://forum.effectivealtruism.org/topics/credal-resilience\"><u>resilient</u></a>, and can easily be wrong by many orders of magnitude (<a href=\"https://en.wikipedia.org/wiki/Order_of_magnitude\"><u>OOMs</u></a>).</li><li>One may well update to a much higher extinction risk after accounting for inside view factors (e.g. <a href=\"https://forum.effectivealtruism.org/posts/PyZCqLrDTJrQofEf7/how-bad-could-a-war-get%23What_does_the_tail_of_the_distribution_look_like_\"><u>weapon technology</u></a>), and indirect effects of war, like increasing the likelihood of <a href=\"https://forum.effectivealtruism.org/topics/civilizational-collapse\"><u>civilisational collapse</u></a>. However, extraordinary evidence&nbsp;would be required to move up sufficiently many orders of magnitude for an <a href=\"https://forum.effectivealtruism.org/topics/artificial-intelligence\"><u>AI</u></a>, <a href=\"https://forum.effectivealtruism.org/topics/biosecurity-and-pandemics\"><u>bio</u></a>&nbsp;or <a href=\"https://forum.effectivealtruism.org/topics/nuclear-warfare-1\"><u>nuclear</u></a>&nbsp;war to have a decent chance of causing human extinction.</li><li>In the realm of the more anthropogenic <a href=\"https://forum.effectivealtruism.org/topics/ai-risk\"><u>AI</u></a>, <a href=\"https://forum.effectivealtruism.org/topics/biosecurity-and-pandemics\"><u>bio</u></a>&nbsp;and <a href=\"https://forum.effectivealtruism.org/topics/nuclear-warfare-1\"><u>nuclear</u></a> risk, I personally think underweighting the <a href=\"https://forum.effectivealtruism.org/topics/inside-vs-outside-view\"><u>outside view</u></a>&nbsp;is a major reason leading to overly high risk. I encourage readers to check David Thorstad\u2019s series <a href=\"https://ineffectivealtruismblog.com/category/exaggerating-the-risks/\"><u>exaggerating the risks</u></a>, which includes subseries on <a href=\"https://forum.effectivealtruism.org/topics/climate-change\"><u>climate</u></a>, <a href=\"https://forum.effectivealtruism.org/topics/ai-risk\"><u>AI</u></a>&nbsp;and <a href=\"https://forum.effectivealtruism.org/topics/biosecurity-and-pandemics\"><u>bio</u></a>&nbsp;risk.</li></ul><h1>Introduction</h1><p>The 166th <a href=\"https://forum.effectivealtruism.org/posts/bi9WWR58m45GJG7bc/forum-digest-reminder-that-it-exists-and-request-for\"><u>EA Forum Digest</u></a>&nbsp;had Stephen Clare\u2019s <a href=\"https://forum.effectivealtruism.org/posts/aSzxoj7irC5jNHceB/how-likely-is-world-war-iii\"><u>How likely is World War III?</u></a>&nbsp;as the classic EA Forum post (as a side note, the rubric is great!). It presents the following conclusions:</p><blockquote><ul><li>First, <strong>I estimate that the chance of direct Great Power conflict this century is around 45%.</strong>&nbsp;</li><li>Second, <strong>I think the chance of a huge war as bad or worse than WWII is on the order of 10%.</strong></li><li>Third, <strong>I think the chance of an extinction-level war is about 1%.</strong>&nbsp;This is despite the fact that I put more credence in the hypothesis that war has become less likely in the post-WWII period than I do in the hypothesis that the risk of war has not changed.</li></ul></blockquote><p>I view the last of these as a <a href=\"https://forum.effectivealtruism.org/topics/crucial-consideration\"><u>crucial consideration</u></a>&nbsp;for <a href=\"https://forum.effectivealtruism.org/topics/cause-prioritization\"><u>cause prioritisation</u></a>, in the sense it directly informs the potential <a href=\"https://80000hours.org/articles/problem-framework/\"><u>scale</u></a>&nbsp;of the benefits of mitigating the risk from <a href=\"https://80000hours.org/problem-profiles/great-power-conflict/\"><u>great power conflict</u></a>. The 1 % chance of a war causing <a href=\"https://forum.effectivealtruism.org/topics/human-extinction\"><u>human extinction</u></a><u> over a period of \"77 years\"</u> results from <a href=\"https://forum.effectivealtruism.org/posts/aSzxoj7irC5jNHceB/how-likely-is-world-war-iii#Combining_the_data_on_conflict_rate_and_escalation_potential_to_estimate_direct_existential_risk\">assuming</a>:</p><ul><li>With 35 % credence, an extinction risk per war of 0.06 %, and 1 war every 2 years (\"constant risk hypothesis\").</li><li>With 65 % credence, an extinction risk per war of 0.03 %, and 1 war every 5 years (\"durable peace hypothesis\").</li></ul><p>The extinction risk per war under the durable peace hypothesis is defined as half of that under the constant risk hypothesis<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffplqibh5b6\"><sup><a href=\"#fnfplqibh5b6\">[1]</a></sup></span>, and this is based on research from Bear Braumoeller (I recommend <a href=\"https://80000hours.org/podcast/episodes/bear-braumoeller-decline-of-war/\"><u>his</u></a>&nbsp;appearance on The 80,000 Hours Podcast!). From <a href=\"https://forum.effectivealtruism.org/posts/PyZCqLrDTJrQofEf7/how-bad-could-a-war-get\"><u>How bad could a war get?</u></a>&nbsp;by Stephen and Rani Martin:</p><blockquote><p>\u201cIn Only the Dead, political scientist Bear Braumoeller uses his estimated parameters to infer the probability of enormous wars. His [<a href=\"https://en.wikipedia.org/wiki/Pareto_distribution\"><u>power law</u></a>] distribution gives a 1 in 200 chance of a given war escalating to be [at least] twice as bad as World War II and a 3 in 10,000 chance of it causing [at least] 8 billion deaths [of combatants] (i.e. human extinction).</p></blockquote><p>I had already come across these posts, but now a 0.06 % chance of war causing human extinction based on historical data jumped out to me as more surprising. I had recently been looking into <a href=\"https://forum.effectivealtruism.org/posts/M6zAzCBAsBxem7Lu4/can-a-terrorist-attack-cause-human-extinction-not-on-priors\"><u>how</u></a>&nbsp;astronomically unlikely it is for a terrorist attack to cause human extinction based on historical data.</p><p>So I <a href=\"https://forum.effectivealtruism.org/posts/aSzxoj7irC5jNHceB/how-likely-is-world-war-iii?commentId%3DvRYHa7X4yxPuTdxvz\"><u>commented</u></a>&nbsp;on Stephen\u2019s classic EA Forum <a href=\"https://forum.effectivealtruism.org/posts/aSzxoj7irC5jNHceB/how-likely-is-world-war-iii\"><u>post</u></a>&nbsp;that:</p><blockquote><p><a href=\"https://en.wikipedia.org/wiki/Pareto_distribution\"><u>Power law</u></a>&nbsp;extrapolation [the one used by Bear] often results in greatly overestimating tail risk because the tail usually starts decaying faster at some point. It is better to use a <a href=\"https://en.wikipedia.org/wiki/Generalized_Pareto_distribution\"><u>generalised Pareto distribution</u></a>, which has the pareto distribution (power law) as a special case. David Roodman <a href=\"https://www.openphilanthropy.org/research/geomagnetic-storms-using-extreme-value-theory-to-gauge-the-risk/\"><u>found</u></a>&nbsp;using a generalised pareto instead of a power law led to a decrease in 2 orders of magnitude (<a href=\"https://en.wikipedia.org/wiki/Order_of_magnitude\"><u>OOMs</u></a>)&nbsp;of the risk of a solar storm at least as severe as a <a href=\"https://en.wikipedia.org/wiki/Carrington_Event\"><u>Carrington event</u></a>:</p><p><img style=\"width:601.7px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/TwpoedzMpmy7k7NKH/e6vh60qvuqdxsxdfbu33\" alt=\"\"></p><p>The <a href=\"https://en.wikipedia.org/wiki/Carrington_Event\"><u>Carrington event</u></a>&nbsp;\u201cwas the most intense geomagnetic storm in recorded history\u201d, but would very hardly cause extinction today (although now we have more electronics). As illustrated above, the higher the severity, the more the power law overestimates tail risk. So, if one fitted a generalised pareto to war deaths, I guess the extinction risk would decrease by many OOMs.</p><p>Another detail to have in mind is that, because the slope of the tail distribution usually bends downwards (as illustrated by the data points of the figure above), it matters whether we are fitting the power law to all the data points, or just to the right tail. The right tail will tend to have a more negative slope, so fitting a power law to all points will usually lead to overestimating the risk.</p><p>If one fitted a generalised pareto (instead of a power law) to e.g. 1 % or 10 % most deadly wars (instead of all wars), I guess the probability of a war causing human extinction would be OOMs lower than Bear\u2019s 0.03 %. However, I expect it would still be many OOMs higher than my <a href=\"https://forum.effectivealtruism.org/posts/M6zAzCBAsBxem7Lu4/can-a-terrorist-attack-cause-human-extinction-not-on-priors\"><u>estimates</u></a>&nbsp;for the extinction risk posed by terrorist attacks, as power laws still resulted in astronomically small risk of extinction (in agreement with <a href=\"https://arxiv.org/pdf/1209.0089.pdf\"><u>Clauset 2013</u></a>; see Figures 1 and 2).&nbsp;I might try to repeat the analysis for wars instead of terrorist attacks in the future, but you are welcome to do it yourself! Update: I will do it.</p></blockquote><p><a href=\"https://www.colorado.edu/faculty/clauset/\"><u>Aaron Clauset</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref91ki73x5syt\"><sup><a href=\"#fn91ki73x5syt\">[2]</a></sup></span>&nbsp;commented:</p><blockquote><p>This [\u201cthe right tail will tend to have a more negative slope, so fitting a power law to all points will usually lead to overestimating the risk\u201d] is not an accurate statement, in fact. The visual shape of the extreme upper tail is not a reliable indicator of the shape of the underlying generating distribution, because the extreme upper tail (where the largest events are) is the most subject to sampling fluctuations. Hence, in the case where the true data generating distribution is in fact power law, you will often still get an artifactual visual appearance of a somewhat negative slope. This is one reason why one has to use tail-fitting methods that have appropriate assumptions about the data generating process, or else you\u2019re basically overfitting the data. Additionally, \u201cright tail\u201d is an ambiguous term -- where does the body end and the tail begin? There\u2019s a set of methods designed to identify that point algorithmically, and generally speaking, visual methods (any methods like \u201cHill plots\u201d) are highly unreliable for the reasons I mention at the beginning of this comment.</p></blockquote><p>The above makes sense to me. Nevertheless, I maintain the actual tail distribution decaying faster is evidence that the underlying distribution has a thinner tail, although one should update less on this given the large amount of noise in the right tail. Moreover, our prior underlying distribution should eventually decay faster than a power law because this implies deaths can be arbitrarily large, whereas the real death toll is in fact limited to the global population. Noisier observations mean we should put greater weight on the prior, so one should end up with a thinner tail.</p><h1>Methods</h1><p>I used <a href=\"https://en.wikipedia.org/wiki/Correlates_of_War\"><u>Correlates of War</u></a>\u2019s <a href=\"https://ourworldindata.org/grapher/deaths-in-wars-by-type-correlates-of-war\"><u>data</u></a>&nbsp;on annual war deaths of combatants due to fighting, disease, and starvation. The dataset goes from 1816 to 2014, and excludes wars which caused less than 1 k deaths of combatants in a year.</p><p>Stephen commented I had better follow the typical approach of modelling war deaths, instead of annual war deaths as a fraction of the global population, and then getting the probability of human extinction from the chance of war deaths being at least as large as the global population. I think my approach is more appropriate, especially to estimate tail risk. There is human extinction if and only if annual war deaths as a fraction of the global population are at least 1. In contrast, war deaths as a fraction of the global population in the year the war started being at least 1 does not imply human extinction. Consider a war lasting for the next 100 years totalling 8 billion deaths. The war deaths as a fraction of the global population in the year the war started would be 100 %, which means such a war would imply human extinction under the typical approach. Nevertheless, this would only be the case if no humans were born in the next 100 years, and new births are not negligible. In fact, the global population increased thanks to these during the years with the most annual war deaths of combatants in the data I used:</p><ul><li>From 1914 to 1918 (years of <a href=\"https://en.wikipedia.org/wiki/World_War_I\"><u>World War 1</u></a>), they were 9.28 M, 0.510 % (= 9.28/(1.82*10^3)) of the global population in 1914, but the global population increased 2.20 % (= 1.86/1.82 - 1) during this period.</li><li>From 1939 to 1945 (years of <a href=\"https://en.wikipedia.org/wiki/World_War_II\"><u>World War 2</u></a>), they were 17.8 M, 0.784 % (= 17.8/(2.27*10^3)) of the global population in 1939, but the global population increased 4.85 % (= 2.38/2.27 - 1) during this period.</li></ul><p>I relied on the Python library <a href=\"https://fitter.readthedocs.io/en/latest/\"><u>fitter</u></a>&nbsp;to find the distributions which best fit the top 10 % logarithm of the annual war deaths of combatants as a fraction of the global <a href=\"https://ourworldindata.org/grapher/population\"><u>population</u></a>. I only analysed the top 10 %, respecting more than 0.0153 % annual war deaths of combatants as a fraction of the global population, because I am interested in the right tail, which <a href=\"https://www.openphilanthropy.org/research/geomagnetic-storms-using-extreme-value-theory-to-gauge-the-risk/\"><u>may</u></a>&nbsp;decay faster than suggested by the whole distribution (see previous section). I took logarithms so that the probability density functions (<a href=\"https://en.wikipedia.org/wiki/Probability_density_function\"><u>PDFs</u></a>) describing the actual data are defined based on points uniformly distributed in logarithmic space instead of linear space, which is appropriate given the wide variation of war deaths<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreft51n31t9uue\"><sup><a href=\"#fnt51n31t9uue\">[3]</a></sup></span>.</p><p>fitter&nbsp;tries all the types of <a href=\"https://docs.scipy.org/doc/scipy/reference/stats.html%23probability-distributions\"><u>distributions</u></a>&nbsp;in SciPy, 111 on 10 December 2023. For each type of distribution, the best fit is that with the lowest residual sum of squares (<a href=\"https://en.wikipedia.org/wiki/Residual_sum_of_squares\"><u>RSS</u></a>), respecting the sum of the squared differences between the predicted and actual PDF. I set the number of bins to define the PDF to the <a href=\"https://en.wikipedia.org/wiki/Histogram%23Square-root_choice\"><u>square root</u></a>&nbsp;of the number of data points<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxxy4urzii6e\"><sup><a href=\"#fnxxy4urzii6e\">[4]</a></sup></span>, and left the maximum time to find the best fit parameters to the default value in fitter&nbsp;of 30 s.</p><p>I estimated the probability of the annual war deaths as a fraction of the global population being at least 10^-6, 0.001 %, \u2026, and 100 % (human extinction) as follows:</p><ul><li>I supposed&nbsp;deaths of combatants as a fraction of all deaths (f) are 10 %, 50 % (= 1/(1 + 1)) or 90 %. 50 % is my best guess <a href=\"https://forum.effectivealtruism.org/posts/PyZCqLrDTJrQofEf7/how-bad-could-a-war-get\"><u>following</u></a>&nbsp;Stephen and Rani. \u201cHistorically, the ratio of civilian-deaths-to-battle deaths in war has been about 1-to-1 (though there\u2019s a lot of variation across wars)\u201d.</li><li>I obtained the probability of the annual war deaths of combatants as a fraction of the global population being at least 10^-6 f, 0.001 % f, \u2026, and f multiplying:<ul><li>10 %, which is the probability of the annual war deaths of combatants being in the right tail.</li><li>Probability of the annual war deaths of combatants as a fraction of the global population being at least 5*10^-7, 5*10^-6, \u2026, and 50 % if they are in the right tail, which I got using the best fit parameters outputted by fitter.</li></ul></li></ul><p>I aggregated probabilities from different best fit distributions using the median. I did not use:</p><ul><li>The mean because it <a href=\"https://forum.effectivealtruism.org/s/hjiBqAJNKhfJFq7kf/p/sMjcjnnpoAQCcedL2#The_arithmetic_mean_of_probabilities_ignores_information_from_extreme_predictions\">ignores</a> information from extremely low predictions, and <a href=\"https://forum.effectivealtruism.org/posts/TwpoedzMpmy7k7NKH/can-a-war-cause-human-extinction-once-again-not-on-priors?commentId=ZRhnJtFG5rLZcAgHg\">overweights</a> outliers.</li><li>The&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/sMjcjnnpoAQCcedL2/when-pooling-forecasts-use-the-geometric-mean-of-odds\"><u>geometric mean of odds</u></a> nor the geometric mean because many probabilities were 0.</li></ul><p>The calculations are in <a href=\"https://docs.google.com/spreadsheets/d/1bhqZRZ1KOndD3IqSin-TPtsqB9uk2Kvj8_FCB8vBnHs/edit?usp%3Dsharing\"><u>this</u></a>&nbsp;Sheet and <a href=\"https://colab.research.google.com/drive/19u73o_dl-f43xLVvjo4fk2GwqGTBegSq?usp%3Dsharing\"><u>this</u></a>&nbsp;Colab.</p><h1>Results</h1><p>The results are in the <a href=\"https://docs.google.com/spreadsheets/d/1bhqZRZ1KOndD3IqSin-TPtsqB9uk2Kvj8_FCB8vBnHs/edit?usp%3Dsharing\"><u>Sheet</u></a>.</p><h2>Historical war deaths of combatants</h2><h3>Basic stats</h3><figure class=\"table\"><table><thead><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Statistic</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Annual war deaths of combatants</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Annual war deaths of combatants as a fraction of the global population</p></th></tr></thead><tbody><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>220 k</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0104 %</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Minimum</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>6.13 k</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.16*10^-6</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5th percentile</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>11.5 k</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.90*10^-6</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Median</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>60.9 k</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.00319 %</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>95th percentile</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.41 M</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0640 %</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>99th percentile</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2.96 M</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.126 %</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Maximum</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.47 M</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.150 %</p></td></tr></tbody></table></figure><h3>Years by annual war deaths of combatants</h3><figure class=\"table\"><table><thead><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"2\" rowspan=\"1\"><p>Annual war deaths of combatants</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"2\"><p>Years</p></th></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Minimum</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Maximum</p></th></tr></thead><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Infinity</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>199</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10 k</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>8</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10 k</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>100 k</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>120</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>100 k</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1 M</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>59</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1 M</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10 M</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>12<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref89khrop9dp\"><sup><a href=\"#fn89khrop9dp\">[5]</a></sup></span></p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10 M</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Infinity</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td></tr></tbody></table></figure><h3><a href=\"https://en.wikipedia.org/wiki/Cumulative_distribution_function%23Complementary_cumulative_distribution_function_(tail_distribution)\"><u>Tail distribution</u></a></h3><p><img style=\"width:601.7px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/TwpoedzMpmy7k7NKH/fmnoxot9vsr3vhda19jh\" alt=\"\"></p><h2>War tail risk</h2><p>Below are the median RSS, <a href=\"https://en.wikipedia.org/wiki/Coefficient_of_determination\"><u>coefficient of determination</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4xyrpwj2gti\"><sup><a href=\"#fn4xyrpwj2gti\">[6]</a></sup></span>&nbsp;(R^2), and probability of the annual war deaths as a fraction of the global population being at least 10^-6, 0.001 %, \u2026, and 100 % (human extinction). The medians are taken across the best, top 10, and top 100 distributions according to the default fitness criterion in fitter, lowest RSS<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyitlnivgmxr\"><sup><a href=\"#fnyitlnivgmxr\">[7]</a></sup></span>. Null values may be exactly 0 if they concern bounded distributions, or just sufficiently small to be rounded to 0 due to finite precision. I also show the tail distribution of the actual data, and 10 % of the tail distributions of the best fit Pareto and generalised Pareto<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyown6rxpmvp\"><sup><a href=\"#fnyown6rxpmvp\">[8]</a></sup></span>, and the annual probability of a war causing human extinction as a function of R^2.</p><figure class=\"table\"><table><thead><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\"><p>Best fit distributions</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\"><p>Median RSS</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\"><p>Median R^2</p></th></tr></thead><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Best</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0167</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>100 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 10</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.398</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>99.8 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 100</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.665</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>99.7 %</p></td></tr></tbody></table></figure><p><img style=\"width:601.7px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/TwpoedzMpmy7k7NKH/r5tfhgti6cjmiyqn4ayn\" alt=\"\"></p><h3>War deaths of combatants equal to 50 % of all deaths (best guess)</h3><figure class=\"table\"><table><tbody><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"2\"><p>Best fit distributions</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"4\" rowspan=\"1\"><p>Median probability of the annual war deaths as a fraction of the global population being at least...</p></td></tr><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10^-6</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.001 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.01 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.1 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Best</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5.00 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 10</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5.33 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 100</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.93 %</p></td></tr><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"2\"><p>Best fit distributions</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"4\" rowspan=\"1\"><p>Median probability of the annual war deaths as a fraction of the global population being at least...</p></td></tr><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>100 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Best</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>7.54*10^-15</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>0</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 10</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>0</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 100</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0499 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.47*10^-8</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>6.36*10^-14</p></td></tr></tbody></table></figure><p><img style=\"width:601.7px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/TwpoedzMpmy7k7NKH/tcnm4vzgopnbga28p6zi\" alt=\"\"></p><h3>War deaths of combatants equal to 90 % of all deaths (optimistic guess)</h3><figure class=\"table\"><table><tbody><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"2\"><p>Best fit distributions</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"4\" rowspan=\"1\"><p>Median probability of the annual war deaths as a fraction of the global population being at least...</p></td></tr><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10^-6</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.001 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.01 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.1 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Best</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.00 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 10</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>9.95 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.91 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 100</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2.57 %</p></td></tr><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"2\"><p>Best fit distributions</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"4\" rowspan=\"1\"><p>Median probability of the annual war deaths as a fraction of the global population being at least...</p></td></tr><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>100 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Best</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>0</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 10</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>0</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 100</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.00665 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.60*10^-9</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>2.22*10^-15</p></td></tr></tbody></table></figure><p><img style=\"width:601.7px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/TwpoedzMpmy7k7NKH/caixna0dnv2sjouixhu7\" alt=\"\"></p><h3>War deaths of combatants equal to 10 % of all deaths (pessimistic guess)</h3><figure class=\"table\"><table><tbody><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"2\"><p>Best fit distributions</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"4\" rowspan=\"1\"><p>Median probability of the annual war deaths as a fraction of the global population being at least...</p></td></tr><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10^-6</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.001 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.01 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.1 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Best</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 10</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>9.92 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 100</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0 %</p></td></tr><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"2\"><p>Best fit distributions</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"4\" rowspan=\"1\"><p>Median probability of the annual war deaths as a fraction of the global population being at least...</p></td></tr><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10 %</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>100 %</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Best</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.34 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>0</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 10</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.36 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>0</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Top 100</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2.21 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.00448 %</p></td><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>9.02*10^-10</p></td></tr></tbody></table></figure><p><img style=\"width:601.7px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/TwpoedzMpmy7k7NKH/i2yqby7safdyzebtfmtu\" alt=\"\"></p><h1>Discussion</h1><p>Historical annual war deaths of combatants suggest the annual probability of a war causing human extinction is astronomically low, with my estimates ranging from 0 to 9.02*10^-10. My preferred estimate is 6.36*10^-14, which belongs to the top 100 best fit distribution, and war deaths of combatants as a fraction of total deaths of 50 %.&nbsp;Among those with this value, it is the one which aggregates the most information, which is arguably good given the high median R^2 of 99.7 % of the top 100 best fit distributions.</p><p>As I <a href=\"https://forum.effectivealtruism.org/posts/aSzxoj7irC5jNHceB/how-likely-is-world-war-iii?commentId%3DvRYHa7X4yxPuTdxvz\"><u>expected</u></a>, my methodology points to an extinction risk many orders of magnitude lower than Stephen\u2019s. <a href=\"https://forum.effectivealtruism.org/posts/aSzxoj7irC5jNHceB/how-likely-is-world-war-iii#Combining_the_data_on_conflict_rate_and_escalation_potential_to_estimate_direct_existential_risk\">His</a> war extinction risk of 0.95 % over 77 years corresponds to 0.0124 %/year (= 1 - (1 - 0.0095)^(1/77)), which is 9 (= log10(1.24*10^-4/(6.36*10^-14))) orders of magnitude above my best guess for the prior.</p><p>I do not think <a href=\"https://forum.effectivealtruism.org/topics/anthropics\"><u>anthropics</u></a>&nbsp;are confounding the results much. There would be no one to do this analysis if a war had caused human extinction in the past, but there would be for less severe wars, and there have not been any. The maximum annual war deaths of combatants as a fraction of the global population were only 0.150 %, which is still 2.52 (= -log10(0.00150/0.5)) orders of magnitude away from extinction.</p><p>Interestingly, 102 best fit distributions have a R^2 of at least 99.7 %, but they result in annual probabilities of a war causing human extinction ranging from 0 to 15.7 %, with 5 respecting values higher than 1 % (see 1st graph in the previous section). As a consequence, figuring out which types of distributions should be weighted more heavily is a key consideration. Stephen noted investigating&nbsp;the connection between which distribution makes the most sense statistically and theoretically is missing in the literature on <a href=\"https://en.wikipedia.org/wiki/International_relations\"><u>international relations</u></a>, and that Bear <a href=\"https://forum.effectivealtruism.org/posts/KnRcbttvkgmCvPvyn/bear-braumoeller-has-passed-away\"><u>was</u></a>&nbsp;planning to work on this. Aaron commented \u201chigh R^2 values do not correlate with \u201cgood fits\u201d of heavy tailed data, and&nbsp;other, more powerful and statistically grounded methods are required\u201d, such as the ones discussed in <a href=\"https://arxiv.org/abs/0706.1062\"><u>Clauset 2009</u></a>. It would be good to do a more in-depth analysis assessing distributions based on the best methods. Aaron elaborated that<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3ki69cyqac9\"><sup><a href=\"#fn3ki69cyqac9\">[9]</a></sup></span>:</p><blockquote><p>If you want to do this properly, you would want to first correctly assess which distributions are statistically plausible fits to the data [as in <a href=\"https://arxiv.org/abs/0706.1062\"><u>Clauset 2009</u></a>], and then treat them as an ensemble, potentially bootstrapping their estimation in order to get a prior distribution of model parameters that you could use to estimate a posterior distribution for the probability of the event size you\u2019re interested in. This would take some work, because this is a pretty esoteric task and quite different from the standard stuff that\u2019s implemented in widely used stats packages.</p></blockquote><p>Nonetheless, I do not think I have an a priori reason to put lots of weight into particular distributions with my current knowledge, so I assume it makes sense to rely on the median. Recall my preferred estimate stems from the results of the top 100 best fit distributions, thus not putting an unwarranted weight on ones which have a marginally higher R^2.</p><p>In addition, according to extreme value theory (<a href=\"https://en.wikipedia.org/wiki/Extreme_value_theory\"><u>EVT</u></a>), the right tail <a href=\"https://www.openphilanthropy.org/research/geomagnetic-storms-using-extreme-value-theory-to-gauge-the-risk/\"><u>should</u></a>&nbsp;follow a <a href=\"https://en.wikipedia.org/wiki/Generalized_Pareto_distribution\"><u>generalised Pareto</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdrtzvuenji5\"><sup><a href=\"#fndrtzvuenji5\">[10]</a></sup></span>, and the respective best fit distribution resulted in an extinction risk of exactly 0<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbm12h8dlhwo\"><sup><a href=\"#fnbm12h8dlhwo\">[11]</a></sup></span>&nbsp;(R^2 of 99.8 %). Like I <a href=\"https://forum.effectivealtruism.org/posts/aSzxoj7irC5jNHceB/how-likely-is-world-war-iii?commentId%3DvRYHa7X4yxPuTdxvz\"><u>anticipated</u></a>, the best fit Pareto (power law) resulted in a higher risk, 0.0122 % (R^2 of 99.7 %), i.e. 98.4 % (= 1.22*10^-4/(1.24*10^-4)) of <u>Stephen\u2019s</u>&nbsp;0.0124 %. Such remarkable agreement means the extinction risk for the best fit Pareto is essentially the same regardless of whether it is fitted to the top 10 % logarithm of the annual war deaths of combatants as a fraction of the global population (as I did), or to the war deaths of combatants per war (as implied by Stephen using Bear\u2019s estimates). I guess this qualitatively generalises to other types of distributions. In any case, I&nbsp;<a href=\"https://docs.google.com/document/d/14_5GnGMD_hwGjEITRLuBeV4sfRG1tI5xmAb1bqW1hEc/edit#heading=h.jqgyd0hhwqld\"><u>would</u></a> rather follow my approach.</p><p>In contrast, the type of distribution certainly matters. In the right tail domain of the actual data, ranging from 0.0153 % to 0.150 % annual war deaths of combatants as a fraction of the global population, the actual tail distribution, and 10 % of the tail distributions of the best fit Pareto and generalised Pareto are all similar (see 2nd graph in the previous section). Afterwards, kind of following the actual tail distribution, the generalised Pareto bends downwards much more than the Pareto, which implies a massive difference in their extinction risk. Aaron noted EVT\u2019s \u201cpredictions only hold asymptotically [for infinitely many wars] and we have no way of assessing how close to \u201casymptopia\u201d the current or extrapolated data might be\u201d. I take this to mean it is unclear how much one should trust the best fit generalised Pareto, but a similar criticism applies to the best fit power law. It predicts deaths can be arbitrarily large, but they are in effect limited to the global population, so a power law will eventually cease to be a good model of the right tail at some point. In contrast, some of the best fit distributions I considered are bounded (e.g. the best generalised Pareto).</p><p>Aaron has looked into the trends and fluctuations in the severity of interstate wars in <a href=\"https://www.science.org/doi/10.1126/sciadv.aao3580\"><u>Clauset 2018</u></a>, which also deals with the Correlates of War data. The article does not estimate the probability of a war causing human extinction, arguably given the limitations mentioned just above, but (like Stephen) used a power law<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqotxvc2crd\"><sup><a href=\"#fnqotxvc2crd\">[12]</a></sup></span>, did not restrict the analysis to the most deadly wars<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyipgdg128ub\"><sup><a href=\"#fnyipgdg128ub\">[13]</a></sup></span>&nbsp;(although its model is tailored to accurately model the right tail), and focussed on war deaths rather than annual war deaths as a fraction of the global population<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefg9nyxi0xn4f\"><sup><a href=\"#fng9nyxi0xn4f\">[14]</a></sup></span>. I have discussed why I consider all these 3 assumptions result in overestimating tail risk. <a href=\"https://www.science.org/doi/10.1126/sciadv.aao3580\"><u>Clauset 2018</u></a>&nbsp;did estimate a 50 % probability of a war causing 1 billion battle deaths<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefalywhv9w3e\"><sup><a href=\"#fnalywhv9w3e\">[15]</a></sup></span>&nbsp;in the next 1,339 years (see \u201cThe long view\u201d), which is close to my pessimistic scenario:</p><ul><li>Assuming total war deaths are 2 times as large<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref652s64j7hjr\"><sup><a href=\"#fn652s64j7hjr\">[16]</a></sup></span>, and that such a war lasts 6 years<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjz9eju90nos\"><sup><a href=\"#fnjz9eju90nos\">[17]</a></sup></span>, that death toll would correspond to annual deaths of 333 M (= 2*10^9/6), 4.21 % (= 0.333/7.91) of the global population in 2021.</li><li>The 50 % probability would respect an annual chance of 0.0518 % (= 1 - (1 - 0.5)^(1/1339)).</li><li>According to my pessimistic estimates, the chance of annual war deaths being at least as large as 1 % of the global population (about 1/4 the above 4.21 %) is 2.21 % to 3.36 % (about 4 times the above 0.0518 %).</li></ul><p>There may be a temptation to guess something like a 10 % chance of human extinction if there is at least 1 billion battle deaths, in which case Aaron\u2019s results would suggest an annual extinction risk due to war of 0.005 % (= 5.18*10^-4*0.1). <a href=\"https://www.liebertpub.com/doi/10.1089/hs.2017.0028?url_ver%3DZ39.88-2003%26rfr_id%3Dori%253Arid%253Acrossref.org%26rfr_dat%3Dcr_pub%2B%2B0pubmed\"><u>Millett 2017</u></a>&nbsp;does a move like this, \u201cassuming that only 10% of such [bio] attacks that kill more than 5 billion eventually lead to extinction (due to the breakdown of society, or other knock-on effects)\u201d. In general, I suspect there is a tendency to give probabilities between 1 % and 99 % for events whose mechanics we do not understand well, given this range encompasses the vast majority (98 %) of the available linear space (from 0 to 1), and events in everyday life one cares about are not that extreme. However, the available logarithmic space is infinitely vast, so there is margin for such guesses to be major overestimates. In the context of tail risk, subjective guesses can easily fail to adequately account for the faster decay of the tail distribution as severity approaches the maximum.</p><p>As a final reflection, Aaron added that:</p><blockquote><p>Based on everything I know from working in this field for 20 years, and having written several of the state-of-the-art papers in this broad area, my professional opinion is that these calculations are fun, but they are not science. They might be useful as elaborate statistical thought experiments, and perhaps useful for helping us think through other aspects of the underlying causes of war and war size, but no one should believe these estimates are accurate in the long run [or in the extreme right tail].</p></blockquote><p>Well, <a href=\"https://www.science.org/doi/10.1126/sciadv.aao3580\"><u>Clauset 2018</u></a>&nbsp;was published in Science Advances, so I suppose it is fair to say such work is science, although I agree it is fun too. More seriously, I understand it is difficult to get reliable estimates of tail risk. If it is worth doing, it <a href=\"https://slatestarcodex.com/2013/05/02/if-its-worth-doing-its-worth-doing-with-made-up-statistics/\"><u>is</u></a>&nbsp;worth doing with made-up statistics, and I did my analysis in this spirit, but none of my mainline estimates are <a href=\"https://forum.effectivealtruism.org/topics/credal-resilience\"><u>resilient</u></a>. My estimates of extinction risk can all easily be wrong by many OOMs. Yet, I hope they highlight there is much room for disagreement over predictions of high risk of human extinction due to a war this century, and ideally encourage further work.</p><p>I must also say one may well update to a much higher extinction risk after accounting for <a href=\"https://forum.effectivealtruism.org/topics/inside-vs-outside-view\"><u>inside view</u></a>&nbsp;factors (e.g. <a href=\"https://forum.effectivealtruism.org/posts/PyZCqLrDTJrQofEf7/how-bad-could-a-war-get%23What_does_the_tail_of_the_distribution_look_like_\"><u>weapon technology</u></a>), and indirect effects of war, like increasing the likelihood of <a href=\"https://forum.effectivealtruism.org/topics/civilizational-collapse\"><u>civilisational collapse</u></a>. However, extraordinary evidence&nbsp;would be required to move up sufficiently many orders of magnitude for an <a href=\"https://forum.effectivealtruism.org/topics/artificial-intelligence\"><u>AI</u></a>, <a href=\"https://forum.effectivealtruism.org/topics/biosecurity-and-pandemics\"><u>bio</u></a>&nbsp;or <a href=\"https://forum.effectivealtruism.org/topics/nuclear-warfare-1\"><u>nuclear</u></a>&nbsp;war to have a decent chance of causing human extinction.&nbsp;Moreover, although war-making capacity has been increasing, conflict deaths as a fraction of the global population have <a href=\"https://www.vox.com/2015/6/23/8832311/war-casualties-600-years\"><u>not</u></a>&nbsp;changed much in the past 6 centuries (<a href=\"https://forum.effectivealtruism.org/posts/oHkJziKoP47PBSizr/the-offense-defense-balance-rarely-changes\"><u>relatedly</u></a>).</p><p><img style=\"width:601.7px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/TwpoedzMpmy7k7NKH/fiykfgzadmr12dlatput\" alt=\"\"></p><p>Stephen commented nuclear&nbsp;weapons could be an example of extraordinary evidence, and I somewhat agree. However:</p><ul><li>Nuclear risk has been decreasing. The estimated destroyable <a href=\"https://ourworldindata.org/grapher/estimated-destroyable-area-by-nuclear-weapons-deliverable-in-first-strike\"><u>area</u></a>&nbsp;by nuclear weapons deliverable in a first strike has decreased 89.2 % (= 1 - 65.2/601) since its peak in 1962.</li><li>I think today\u2019s nuclear risk is much lower than Stephen\u2019s 1 % chance of a war causing human extinction this century. I <a href=\"https://forum.effectivealtruism.org/posts/gktZ8zuzyh7HEgjfc/famine-deaths-due-to-the-climatic-effects-of-nuclear-war%23Longterm_perspective\"><u>estimated</u></a>&nbsp;a probability of 3.29*10^-6 for a 50 % population loss due to the climatic effects of nuclear war before 2050, so around 0.001 % (= 3.29*10^-6*76/26) before 2100. I guess extinction would be much less likely, maybe 10^-7 this century. This is much lower than the forecasted in The Existential Risk Persuasion Tournament (<a href=\"https://forecastingresearch.org/xpt\"><u>XPT</u></a>), which I have <a href=\"https://forum.effectivealtruism.org/posts/M6zAzCBAsBxem7Lu4/can-a-terrorist-attack-cause-human-extinction-not-on-priors?commentId%3DDYTh3YuD3XCcusbbe\"><u>discussed</u></a>&nbsp;before.</li></ul><p>In general, I agree with David Thorstad that Toby Ord\u2019s <a href=\"https://forum.effectivealtruism.org/posts/Z5KZ2cui8WDjyF6gJ/some-thoughts-on-toby-ord-s-existential-risk-estimates\"><u>guesses</u></a>&nbsp;for the existential risk between 2021 and 2120 given in <a href=\"https://theprecipice.com/\"><u>The Precipice</u></a>&nbsp;are very high (e.g. 0.1 % for nuclear war). In the realm of the more anthropogenic <a href=\"https://forum.effectivealtruism.org/topics/ai-risk\"><u>AI</u></a>, <a href=\"https://forum.effectivealtruism.org/topics/biosecurity-and-pandemics\"><u>bio</u></a>&nbsp;and <a href=\"https://forum.effectivealtruism.org/topics/nuclear-warfare-1\"><u>nuclear</u></a>&nbsp;risk, I personally think underweighting the <a href=\"https://forum.effectivealtruism.org/topics/inside-vs-outside-view\"><u>outside view</u></a>&nbsp;is a major reason leading to overly high risk. I encourage readers to check David\u2019s series <a href=\"https://ineffectivealtruismblog.com/category/exaggerating-the-risks/\"><u>exaggerating the risks</u></a>, which includes subseries on <a href=\"https://forum.effectivealtruism.org/topics/climate-change\"><u>climate</u></a>, <a href=\"https://forum.effectivealtruism.org/topics/ai-risk\"><u>AI</u></a>&nbsp;and <a href=\"https://forum.effectivealtruism.org/topics/biosecurity-and-pandemics\"><u>bio</u></a>&nbsp;risk. Relatedly, I <a href=\"https://forum.effectivealtruism.org/posts/rszgfHdkmzCDDPM9k/where-are-you-donating-this-year-and-why-open-thread-1?commentId%3D58fwonZoXKfkeLWc6\"><u>commented</u></a>&nbsp;before that:</p><blockquote><p>David Thorstad\u2019s posts, namely the ones on <a href=\"https://ineffectivealtruismblog.com/category/my-papers/mistakes-in-moral-mathematics/\"><u>mistakes in the moral mathematics of existential risk</u></a>, <a href=\"https://ineffectivealtruismblog.com/category/epistemics/\"><u>epistemics</u></a>&nbsp;and <a href=\"https://ineffectivealtruismblog.com/category/exaggerating-the-risks/\"><u>exaggerating the risks</u></a>, increased my general level of scepticism towards deferring to thought leaders in effective altruism before having engaged deeply with the arguments. It is not so much that I got to know knock-down arguments against existential risk mitigation, but more that I become more willing to investigate the claims being made.</p></blockquote><h1>Acknowledgements</h1><p>Thanks to Aaron Clauset&nbsp;and Stephen Clare for feedback on the draft.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfplqibh5b6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffplqibh5b6\">^</a></strong></sup></span><div class=\"footnote-content\"><blockquote><p>&nbsp;I [Stephen] haven\u2019t formally modeled this reduction. It\u2019s based on my sense of the strength of the evidence on changing international norms and nuclear deterrence.</p></blockquote></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn91ki73x5syt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref91ki73x5syt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Thanks to Stephen for prompting me to reach out to Aaron.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnt51n31t9uue\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreft51n31t9uue\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The median fraction of explained variance across the 100 best fit distributions (highest fraction of explained variance) was 99.7 % defining the actual PDF based on points uniformly distributed in logarithmic space, but only 68.5 % based on points uniformly distributed in linear space.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxxy4urzii6e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxxy4urzii6e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Setting the number of bins to the number of data points would result in <a href=\"https://en.wikipedia.org/wiki/Overfitting\"><u>overfitting</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn89khrop9dp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref89khrop9dp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;5 years for <a href=\"https://en.wikipedia.org/wiki/World_War_I\"><u>World War 1</u></a>&nbsp;(1914 to 1918), and 7 for <a href=\"https://en.wikipedia.org/wiki/World_War_II\"><u>World War 2</u></a>&nbsp;(1939 to 1945).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4xyrpwj2gti\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4xyrpwj2gti\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Fraction of the variance of the actual PDF explained by the predicted PDF. I computed this fraction from 1 minus the ratio between the <a href=\"https://en.wikipedia.org/wiki/Residual_sum_of_squares\"><u>residual</u></a>&nbsp;and <a href=\"https://en.wikipedia.org/wiki/Total_sum_of_squares\"><u>total</u></a>&nbsp;sum of squares.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyitlnivgmxr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyitlnivgmxr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Equivalent to lowest R^2.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyown6rxpmvp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyown6rxpmvp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I multiply the tail distributions of the best fit distributions by 10 % because they are supposed to model the right tail, and there is a 10 % chance of the annual war deaths being in the right tail as I defined it.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3ki69cyqac9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3ki69cyqac9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Aaron additionally commented that:</p><blockquote><p>Even then, you have a deeper assumption that is quite questionable, which is whether events are plausibly iid [<a href=\"https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables\"><u>independent and identically distributed</u></a>] over such a long time scale. This is where the deep theoretical understanding from the literature on war is useful, and in my 2018 paper [<a href=\"https://www.science.org/doi/10.1126/sciadv.aao3580\"><u>Clauset 2018</u></a>], my Discussion section delves into the implications of that understanding for making such long term and large-size extrapolations.</p></blockquote><p>Assuming wars are IID over a long time scale would be problematic if one wanted to estimate the time until a war caused human extinction, but I do not think it is an issue to estimate the nearterm annual extinction risk.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndrtzvuenji5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdrtzvuenji5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The <a href=\"https://en.wikipedia.org/wiki/Exponential_distribution\"><u>exponential</u></a>, <a href=\"https://en.wikipedia.org/wiki/Continuous_uniform_distribution\"><u>uniform</u></a>, <a href=\"https://en.wikipedia.org/wiki/Pareto_distribution\"><u>Pareto</u></a>&nbsp;and <a href=\"https://en.wikipedia.org/wiki/Generalized_Pareto_distribution%23Exponentiated_generalized_Pareto_distribution\"><u>exponentiated&nbsp;generalised Pareto</u></a>&nbsp;distributions are particular cases of the generalised Pareto distribution.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbm12h8dlhwo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbm12h8dlhwo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The best fit generalised Pareto has a bounded domain because its shape parameter is negative.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqotxvc2crd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqotxvc2crd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThe estimated power-law model has two parameters:&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x_\\mathrm{min}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">m</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">i</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span></span></span></span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>, which represents the smallest value above which the power-law pattern holds, and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span></span></span></span></span>, the scaling parameter\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyipgdg128ub\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyipgdg128ub\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cAll recorded interstate wars are considered\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fng9nyxi0xn4f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefg9nyxi0xn4f\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cWar variables are analyzed&nbsp;in their unnormalized forms\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnalywhv9w3e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefalywhv9w3e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I think battle deaths refer to all deaths of combatants, not only those due to fighting, but also disease and starvation, as these are all included in the Correlates of War dataset.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn652s64j7hjr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref652s64j7hjr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Total deaths are 2 times the deaths of combatants in my best guess scenario.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjz9eju90nos\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjz9eju90nos\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Mean between the durations of 5 (= 1918 - 1914 + 1) and 7 (= 1945 - 1939 + 1) years of World War 1 and 2.</p></div></li></ol>", "user": {"username": "vascoamaralgrilo"}}, {"_id": "dKWCTujoKEpDF8Yb5", "title": "Why I\u2019m skeptical about using subjective time experience to assign moral weights\n", "postedAt": "2024-01-22T11:45:00.859Z", "htmlBody": "<p>This post provides a summary of my working paper \u201c<a href=\"https://globalprioritiesinstitute.org/welfare-and-felt-duration-andreas-mogensen/\"><u>Welfare and Felt Duration</u></a>.\u201d The goal is to make the content of the paper more accessible and to add context and framing for an EA audience, including a more concrete summary of practical implications. It\u2019s also an invitation for you to ask questions about the paper and/or my summary of it, to which I\u2019ll try to reply as best I can below.</p><h3><strong>What\u2019s the paper about?&nbsp;</strong></h3><p>The paper is about how duration affects the goodness and badness of experiences that feel good or bad. For simplicity, I mostly focus on how duration affects the badness of pain.&nbsp;</p><p>In some obvious sense, pains that go on for longer are worse for you. But we can draw some kind of intuitive distinction between how long something&nbsp;<i>really</i> takes and how long it is&nbsp;<i>felt</i> as taking. Suppose you could choose between two pains: one feels longer but is objectively shorter, and the other feels shorter but is objectively longer. Now the choice isn\u2019t quite so obvious. Still, some people are quite confident that you ought to choose the second: the one that feels shorter. They think it\u2019s how long a pain&nbsp;<i>feels</i> that\u2019s important, not how long it<i> is</i>. The goal of the paper is to argue that that confidence isn\u2019t warranted.&nbsp;&nbsp;</p><h3><strong>Why is this important?&nbsp;</strong></h3><p>This issue affects the moral weights assigned to non-human animals and digital minds.&nbsp;</p><p>The case for thinking that subjective time experience varies across the animal kingdom is summarized in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qEsDhFL8mQARFw6Fj/the-subjective-experience-of-time-welfare-implications\"><u>this excellent post</u></a> by Jason Schukraft, which was a huge inspiration for this paper.&nbsp;<i>&nbsp;</i>One particular line of evidence comes from variation in the&nbsp;<i>critical-flicker fusion frequency&nbsp;</i>(CFF), the frequency at which a light source that\u2019s blinking on and off is perceived as continuously illuminated. Some birds and insects can detect flickering that you and I would completely miss unless we watched a slow motion recording. That might be taken to indicate that time passes more slowly from their subjective perspective, and so, if felt duration is what matters, that suggests we should give additional weight to the lifetime welfare of those animals. In line with that idea, Jason\u2019s research has motivated using CFFs to inform the assignment of moral weights at Rethink Priorities, as outlined&nbsp;<a href=\"https://rethinkpriorities.org/publications/welfare-range-estimates\"><u>here</u></a>.&nbsp;</p><p>A number of people also argue that digital minds could experience time very differently from us, and here the differences could get really extreme. Because of the speed advantages of digital hardware over neural wetware, a digital mind could conceivably be run at speeds many orders of magnitude higher than the brain\u2019s own processing speed, which might again lead us to expect that time will be felt as passing much more slowly. As above, this may be taken to suggest that we should give those experiences significantly greater moral weight. Among other places, this issue is discussed by Carl Shulman and Nick Bostrom in their&nbsp;<a href=\"https://nickbostrom.com/papers/digital-minds.pdf\"><u>paper on digital minds</u></a>.&nbsp;</p><h3><strong>What\u2019s the argument?&nbsp;</strong></h3><p>You can think of the argument of the paper as having three key parts.</p><p>Part 1:&nbsp;<i>What is felt duration?</i></p><p>The first thing I want to do in the paper is emphasize that we don\u2019t really have a very strong idea of what we\u2019re talking about when we talk about the subjective experience of time. That should make us skeptical of our intuitions about the ethical importance of felt duration.</p><p>It seems clear that it doesn\u2019t matter in itself how much time you&nbsp;<i>think</i> has passed: e.g., if you think the pain went on for six minutes, but actually it lasted five. If subjective duration is going to matter, it can\u2019t be just a matter of your beliefs about time\u2019s passage. Something about the way the pain is experienced has got to be different. But what exactly? I expect you probably don\u2019t have an obvious answer to that question at your fingertips. I certainly don\u2019t. It\u2019s also worth noting that&nbsp;<a href=\"https://psycnet.apa.org/fulltext/2016-24586-001.html\"><u>some psychologists</u></a> who study time perception claim that we can\u2019t distinguish empirically between judged and felt duration, whereas&nbsp;<a href=\"https://psycnet.apa.org/record/2015-20747-014\"><u>others who think we can make this distinction</u></a> also claim that people frequently mix them up, especially when it comes to reported feelings of time passing quickly.&nbsp;</p><p>Part 2:&nbsp;<i>What felt duration could be</i></p><p>At the next stage, I look at theories of what felt duration consists in. The idea is that once we have a theory of what the subjective rate of experience really is, we\u2019ll be in a much better position to say whether it\u2019s the sort of thing we ought to care about for its own sake. I claim it isn\u2019t.</p><p>One theory I consider is the&nbsp;<i>cognitivist theory of felt duration</i>, favoured by&nbsp;<a href=\"https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00196/full\"><u>Valtteri Arstila</u></a> and&nbsp;<a href=\"https://philpapers.org/rec/PHIXTP-2\"><u>Ian Phillips</u></a>. Very roughly, this says that our experience of the passage of time arises from the fact that we\u2019re aware of external events in relation to our own stream of conscious thoughts. When there\u2019s a big speed-up in the volume of conscious thought occurring alongside some experienced event, the event feels longer. That seems plausible enough. But it also seems plausible that it doesn\u2019t matter in and of itself how quickly your conscious thoughts move in relation to external events while you\u2019re in pain. If there's a suitable change in the content of your thoughts and the way they interact with your pain experience, that could potentially make a difference for better or for worse, but the speed of conscious thought relative to external processes surely doesn\u2019t matter in and of itself to pain\u2019s badness.&nbsp;</p><p>Another theory I consider is the&nbsp;<i>quantum theory of felt duration</i>, favoured historically by&nbsp;<a href=\"https://en.wikipedia.org/wiki/Karl_Ernst_von_Baer\"><u>Karl Ernst von Baer</u></a> and more recently by&nbsp;<a href=\"https://philpapers.org/rec/MERAQT\"><u>Carla Merino-Rajme</u></a>. This theory assumes that experience isn\u2019t continuous. It\u2019s divided up across discrete experiential frames, a bit like the frames in a film reel. The more of these experiential frames that make up your experience of an event, the longer it feels. This also strikes me as plausible. But the only plausible explanation I can think of for why it should matter how many of these frames divide up your experience is something like the following. If your pain experience isn\u2019t continuously \u2018on\u2019, but instead made up of lots of little bursts of pain, then it could be that those bursts of pain are packed more densely in time when time feels like it\u2019s passing slowly, as a result of which more time overall could end up being filled with pain as opposed to non-pain. That does sound like it\u2019s got to be worse for you. But this is also extremely speculative. It\u2019s also ultimately a story on which the pain is worse because it fills more objective time, so it doesn\u2019t actually support the view that subjective time experience matters in itself.&nbsp;</p><p>Part Three:<i> Rebutting an argument from digital simulations</i></p><p>The final part addresses a thought experiment that a lot of people raised when I was discussing the ideas in the paper. Imagine a digital simulation of someone\u2019s experience. Imagine varying the speed at which the simulation runs by changing the clock speed on the hardware running it. A lot of people have the intuition that that doesn\u2019t make any difference for how good or bad it is for the simulated people we\u2019re creating. After all, they can\u2019t tell the difference: their experiences are subjectively indistinguishable.&nbsp;</p><p>I reject the assumption that subjectively indistinguishable experiences of pleasure or pain are equally good or bad. Suppose, plausibly, that what it is for two experiences to be subjectively indistinguishable is that there exists some one-to-one mapping among the instants that make up those experiences so that you can\u2019t tell apart any instants mapped to one another. Insofar as that\u2019s right, we should reject the idea that subjectively indistinguishable pains are equally good or bad. Note, for example, that&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"f(t):=2t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.372em;\">:<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">=</span></span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>&nbsp;is a one-to-one mapping between&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"[0, 1]\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"[0, 2]\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span></span></span></span></span></span>&nbsp;and so if there is a pain (one that\u2019s continuously \u2018on\u2019) lasting exactly one second and another lasting exactly two seconds, and if those pain experiences are qualitatively exactly the same at every instant they occur, then they\u2019re subjectively indistinguishable on this analysis. But the two-second pain is surely worse.&nbsp;</p><p>The arguments given in the paper itself are obviously more careful and detailed. There are also a bunch of issues covered in the paper that I\u2019ve completely left out of this summary: whether the theory of relativity makes it impossible to assign an objective duration to a valenced experience; whether we really have evidence that conscious experience is discrete as opposed to continuous, and in what sense; whether the 'amount' of conscious thought occurring in a given time period can be meaningfully defined and measured in a way that allows for interspecies comparisons; and much more besides.&nbsp;</p><h3><strong>What are the practical upshots?&nbsp;</strong></h3><p>I think we should significantly reduce our credence that subjective time experience modulates welfare. As a result, we should give less weight to subjective time experience when assigning moral weights to animals and digital minds in order to set priorities.&nbsp;</p><p>To give some sense of this, in 2020&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qEsDhFL8mQARFw6Fj/the-subjective-experience-of-time-welfare-implications\"><u>Jason Schukraft reported a 70% credence</u></a> that there exist morally relevant differences in the rate of subjective experience across the animal kingdom. I currently think something in the range of 10-30% is more plausible, though I don\u2019t think my views on this are very stable or especially well-considered. What\u2019s important to note is that the lower range I favour isn\u2019t explained by the fact that I think we should be more skeptical than Jason that there<i> is</i> variation in the rate of subjective experience. Instead, I think we should be more skeptical that that kind of variation is morally significant. That means putting less weight than we might have done on the welfare of small, high-metabolism animals, such as birds like the pied fly-catcher (CFF: 146 Hz), and more weight than we might have done on the welfare of larger, slower animals, like the leatherback turtle (CFF: 15 Hz). It also means putting significantly less weight on the welfare of fast-paced digital minds than we might have done, and thus potentially significantly reducing our estimate of the contribution of digital minds to total welfare over future time.</p><p>Still, it\u2019s important to keep in mind some caveats and limitations of the conclusions I draw. In particular, a lot of what I focus on is the question of whether subjective time experience matters&nbsp;<i>in and of itself</i>, i.e., holding fixed things like objective duration, intensity, etc. It\u2019s compatible with that idea that differences in the rate of subjective time experience tend to bring about other kinds of changes that are morally significant in their own right, like differences in felt intensity or differences in objective duration. I don\u2019t think we currently have good evidence that that\u2019s the case, but it\u2019s also very much an open question.&nbsp;</p><h3><strong>Bonus content</strong></h3><p>Jason gives an argument for thinking that it\u2019s subjectively experienced time that matters, which appeals to an analogy with intensity; John Firth at GPI also pressed me on this in conversation. I didn\u2019t address this argument in the paper, as it\u2019s already longer than many philosophy journals are happy to consider. Instead, I\u2019ll address the argument now.&nbsp;</p><p>Here\u2019s the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qEsDhFL8mQARFw6Fj/the-subjective-experience-of-time-welfare-implications#The_Subjective_Experience_of_Time\"><u>argument from Jason</u></a>:&nbsp;</p><blockquote><p>\u201cTwo subjects might be exposed to a negative stimulus (an electric shock, say) of the same intensity but differ with respect to the felt badness of the subsequent pain. Such a difference is subjective (in that the painfulness of the shock is relative to the subject being shocked) but no less genuine in virtue of the subjectivity. What matters morally is not the objective intensity of the stimulus, but the subjective badness of the experience. ... [I]f it is the<i> perceived</i> intensity of a stimulus that matters morally, rather than any objective feature of the stimulus, it\u2019s unclear why we shouldn\u2019t apply the same reasoning to duration.\u201d</p></blockquote><p>(<u>The dots here link parts of the original post that are actually somewhat far apart, but&nbsp;that strike me as parts of a single argument.)</u></p><p>In my view, applying the same reasoning to duration does not support using subjective time experience as opposed to objective duration to assign moral weights. When it comes to intensity, we can talk about the intensity of the noxious stimulus - e.g., the temperature of the stove you accidentally touch - or of the painful sensation it evokes. When it comes to duration, we can draw a similar distinction: a distinction between the duration of the noxious stimulus - how long you held your hand on the stove - and the duration of the painful sensation it evokes. As I see it, the analogue of saying that we don\u2019t care about the intensity of the stimulus, but of the sensation, is that we shouldn\u2019t care about the duration of the noxious stimulus but only the duration of the painful sensation. That seems right: it doesn\u2019t matter how long your hand was actually in contact with the stove; what matters is how long the painful burning sensation endures thereafter. But that\u2019s totally compatible with measuring the duration of a pain in clock time.&nbsp;</p><p>The analogue of caring about the subjective time filled by an experience of pain rather than its objective duration would seem to be saying that you shouldn\u2019t care about how intense a sensation&nbsp;<i>is,</i> but how intense it&nbsp;<i>seems</i>. It\u2019s not clear if that\u2019s a meaningful claim, let alone a plausible one.&nbsp;<br>&nbsp;</p>", "user": {"username": "Andreas_Mogensen"}}, {"_id": "FGm95PqMv84ai7P6q", "title": "Clean Cooking connections in sub-Saharan Africa", "postedAt": "2024-01-23T06:01:38.199Z", "htmlBody": "<p><strong>TLDR:</strong><i><strong>&nbsp;</strong> Seeking connections in sub-Saharan Africa, especially distributors, pellet producers, or agricultural companies interested in collaborating to make clean cooking accessible to all.</i></p><p>&nbsp;</p><p>Hi! I'm Kars, a newcomer to both the working world and this forum, but I've been actively involved in the EA community for some time. I recently joined Mimi Moto, a Clean Cooking company, for my first 'real' job. One of my tasks is creating business relationships, but this is quite hard to do remotly, since I am not physically located in our market. That's why I decided to write this post. I could use your insights and connections!</p><p>&nbsp;</p><p>Mimi Moto is a Clean Cooking company, producing a biomass cookstove. I believe clean cooking should be a cause that is prioritized. According to this great post by Sanjay, implementing clean cookstoves <a href=\"https://forum.effectivealtruism.org/posts/cz85mufYwiiukpowD/clean-cookstoves-may-be-competitive-with-givewell\"><strong>may be competitive with GiveWell-recommended charities</strong></a><strong>.&nbsp;</strong></p><p>The Mimi Moto cookstove is the most cost-effective cookstove in making clean cooking accessible to all, according to this <a href=\"https://www.nature.com/articles/s41560-022-01126-2\">Nature article.</a> In this research the authors compared different clean cooking solutions on their affordability, effects on health and climate reductions. The Mimi Moto cookstove came out as the most affordable solution.</p><p>&nbsp;</p><p>Our stove is biomass fueled. We use a gasification technology to burn biomass pellets. These pellets can be made from local agricultural residues, creating a sustainable chain converting waste in something useful.</p><p>Why this post? While Mimi Moto has sold over 70,000 cookstoves in 25+ countries, we are currently facing challenges in scaling up. Our primary hurdle lies in finding the right partners for distribution. &nbsp;We have (one of) the best product(s) on the market, but not yet found the right partners. That is why we are actively seeking connections in sub-Saharan Africa, especially distributors, pellet producers, or agricultural companies interested in collaborating. You would help me/us immensily by providing some details!</p><p>Do not hesitate to connect me with other (related) questions on clean cooking or Mimi Moto! I would be happy to help.</p><p>More information on clean cooking can be found here:</p><ul><li><a href=\"https://cleancooking.org/\">https://cleancooking.org/</a></li><li>http://catalog.cleancookstoves.org/</li></ul>", "user": {"username": "Kars ten Berge"}}, {"_id": "3ricaXPReNqdLDLhv", "title": "Does boycotting work?", "postedAt": "2024-01-22T03:39:14.652Z", "htmlBody": "<p>This question is more of a question on whether boycotting can be an action of effective altruism, rather than a particular cause.<br><br>Pessimistically, it seems that there is no way to stop factory farming - and that veganism is not really that effective at all. Furthermore, boycotting companies like Nestle does not seem to make any sort of difference into the atrocities they commit.&nbsp;<br><br>As an EA, should you not care about boycotting?</p>", "user": {"username": "dstudioscode"}}, {"_id": "poPD5XqAhvZZmQusu", "title": "Is Trapped Water A Really Big Issue?", "postedAt": "2024-01-22T03:32:51.874Z", "htmlBody": "<p><a href=\"https://www.yahoo.com/lifestyle/woman-warns-against-dangerous-phenomenon-120000467.html\">https://www.yahoo.com/lifestyle/woman-warns-against-dangerous-phenomenon-120000467.html</a>&nbsp;<br><br>According to the Texas Water Quality Association, trapped water is indeed a big problem.<br><br>For context, trapped water is basically water in a water bottle where the cap is sealed, that is thrown in the trash can. Since plastic takes a long time to biodegrade (really long time), it takes a long time for water in water bottle to return to water cycle. Thus, reducing amount of water in water cycle.&nbsp;</p><p>&nbsp;</p><p>Edit: I accidentally put the wrong link initially. Please forgive me.</p>", "user": {"username": "dstudioscode"}}, {"_id": "enH4qj5NzKakt5oyH", "title": "Is mosquito net fishing really net-positive?", "postedAt": "2024-01-22T01:58:07.250Z", "htmlBody": "<p>There's a common claim that the distribution of antimalarial mosquito nets is bad because they are used for fishing. I usually hear this followed by the quick rebuttal \"...but I can't imagine who has a problem with enabling needy people to fish!\"</p><p>There is of course more merit to the objection. <a href=\"https://www.vox.com/future-perfect/2018/10/18/17984040/bednets-tools-fight-mosquitoes-malaria-myths-fishing\">A discussion from 2018 on Future Perfect</a>, which in turn cites <a href=\"https://blog.givewell.org/2015/02/05/putting-the-problem-of-bed-nets-used-for-fishing-in-perspective/\">Givewell's 2015 evaluation of the topic </a>considering overfishing, environmental harms, and inefficient net distribution, but ultimately finding the problems all insignificant. I want to add some discussion of harms not discussed there.</p><p>Last year I was in Kenya conducting an interview on commons management, and it came up that people using mosquito nets for fishing was considered bad behavior especially because mosquito nets are fine enough to trap fish fry and juvenile fish, ruining future harvests. This appears to be a widespread and longstanding concern not directly addressed in either evaluation, partly due to lacking academic research now available. The upshot seems to be that thanks to juvenile catch the impact on fisheries is higher than indicated by those reports.</p><p><a href=\"https://www.newscientist.com/article/2222873-people-are-using-mosquito-nets-for-fishing-and-it-works-too-well/\">Here is a journalistic report from 2019</a>, which summarizes <a href=\"https://link.springer.com/article/10.1007/s13280-019-01280-0\">this 2019 paper</a> attempting to make a direct link to fishery decline in Mozambique seagrass from juvenile catch via mosquito net fishing. They document high percentage of juvenile catch (56%), with caveats as to time of day and year. They didn't provide a baseline comparison against responsible fishing methods (only other comparably unsustainable ones). Nor is a model of how much juvenile catch is needed to noticeably impact recruitment provided. <a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/fme.12637\">Here's a subsequent 2023 paper</a> I cannot access claiming significant harm to fisheries from mosquito net juvenile catch in Madagascar's coastal coral reefs (the abstract is confusing, so I am suspicious of its quality).</p><p>Belief in observable harms from mosquito net fishing seem to be common in affected communities, as per my interviewee, as well as various comments and tidbits sprinkled throughout academic research and news reporting, and in particular this <a href=\"https://web.archive.org/web/20220731000528id_/https://watersa.net/article/download/14436/18792\">2022 survey in Zimbabwe</a>. Poverty is usually given as the reason for doing it anyways. This suggests to me the practice is widespread, substantial enough for many communities to reach the same conclusions about its effects, and likely endemic wherever mosquito nets are distributed and fish resources exist.&nbsp;</p><p>It remains unclear to me from these studies or from any larger meta-studies what the numerical prevalence of mosquito net fishing actually is worldwide and how large and how causal an impact they have on global fisheries. &nbsp;(<a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0191519\">The best global overview so far, from 2018</a>, is neither quantitative nor exhaustive, and was cited in the Future Perfect article.) But overall it is likely that millions of people mosquito net fish, I infer they do so usually in ecologically fragile coastal and riparian settings similar to those in the above studies, and the practice causes probable impacts to future food security.</p><p>In summary there's more evidence that mosquito net fishing causes substantial harm than previously discussed in this community (a harm to commons that is balanced against the harm of immediate hunger, of course). I think this is a relatively small update, unlikely to change my mind about the overall positive benefit of free mosquito net distribution. Work to mitigate the harms caused by mosquito net fishing while maintaining widespread mosquito net access to will probably come from non-EA entities. May also be of interest to ecologically minded readers and fish welfarists.</p>", "user": {"username": "Rachel Shu"}}, {"_id": "jkcv43Ts9xEXuo6m4", "title": "What Is More Important - Blood/Platelet/Plasma Donation Or Veganism?", "postedAt": "2024-01-21T22:39:40.708Z", "htmlBody": "<p>Recently, my iron level has been pretty low (so I can't donate). I was thinking about eating meat once again. Is it worth sacrificing veganism to become a blood/platelet/plasma donor, or should I rather continue being vegan instead of donating blood/platelets/plasma?</p>", "user": {"username": "dstudioscode"}}, {"_id": "TJbtbySSKgCnyvbyY", "title": "Introduction", "postedAt": "2024-01-22T09:35:20.642Z", "htmlBody": "<p>Hi all!</p><p>This is my first post here and it is intended to be nothing more than a short introduction. I hope to connect with others active on the forum, learn more about cause areas of interest, and contribute my own thoughts and findings.</p><p>I was born and raised in Wenatchee Washington, and am now a senior-year architecture undergraduate student at Cal Poly San Luis Obispo. I\u2019ve developed various interests through projects over the years, including videography, journalism, woodworking, digital fabrication, and language acquisition. This year I am writing my thesis on civilizational resilience, which I will release here when finished.</p><p>I\u2019m actively searching for jobs starting in late summer in applied global priorities research, data visualization, and digital fabrication, and hope to make some career connections at the EAG GCR Bay Area conference I\u2019m attending and volunteering at in early February.</p><p>Let's start a conversation if you have similar interests, and connect with me on Linkedin if you are curious about my credentials:&nbsp;<a href=\"https://www.linkedin.com/in/cole-hansen-9b7242194/\"><u>https://www.linkedin.com/in/cole-hansen-9b7242194/</u></a></p><p>I\u2019m stoked to be a part of this community, and to meet more people who are passionate about making the world a better place!&nbsp;</p><p><br>&nbsp;</p>", "user": {"username": "Chanse"}}, {"_id": "8zzmZD5vsEkuDe24m", "title": "When Does Altruism Strengthen Altruism?", "postedAt": "2024-01-21T19:10:25.669Z", "htmlBody": "", "user": {"username": "Jeff_Kaufman"}}, {"_id": "CEr5ugg5KmnZzLoPH", "title": "Question for longtermism", "postedAt": "2024-01-21T19:14:15.909Z", "htmlBody": "<p>Longtermism states that we should judge the moral value of actions based on how they affect the possible future persons who will experience their consequences, not just present persons. We can extend this to all morally relevant beings, I just say persons to keep it simple, and my question can be limited to this consideration.</p>\n<p>In Parfit\u2019s \u201cReasons and Persons\u201d, he considers some types of actions. For example, if you must choose between action A, which will bring about 100 future persons, and action B, which will bring about 10 future persons, each person having  equivalent happiness, then you should choose A. This is an action which changes the number of persons that exist.</p>\n<p>You also have a case where A causes 100 persons to exist and B causes 100 different persons to exist. This is an action that affects which persons exist, but the number is the same. In this case, assuming happiness is equal, you can be indifferent. You are not wronging the future persons in case B by choosing case A, and thereby preventing the B people from existing. If you can cause more happiness by bringing about group A, you act rightly.</p>\n<p>He uses this second analysis for handling abortion, and I think Will MacAskill does too, in \u201cWhat We Owe The Future.\u201d Having an abortion now and having a different child later is permissible, and maybe obligatory, depending on the difference in suffering for each possible person/child. But this analysis ignores cases where an abortion is not followed by a later birth, or where the mother\u2019s life is at stake.</p>\n<p>Longtermism places moral value on future persons that is not discounted by time. The moral value of a future person is apparently the same as that of an existing person. Well we can consider the following case.</p>\n<p>Future vs Present Trolley. A trolley is heading toward a person tied to a track. You can pull a switch that diverts it to a second track, which will stop 100 future persons from existing.</p>\n<p>You can fill in the details with a story about fertilized embryos or something. 100 possible future persons are going to be de-existed if you pull the switch. I am honestly not sure how longtermist views handle such a case, where the wellbeing of an existing person is pitted against a greater number of possible persons.</p>\n<p>Even a weaker case with one future person on the other track seems problematic for longtermism.</p>\n<p>I\u2019m really not sure how it shakes out, but it seems obvious that you should pull the switch. However, that\u2019s a lot of possible future persons, and if they matter just as much as 100 existing persons, then it seems like you should not pull the switch. I\u2019d welcome some feedback in the comments about how this type of dilemma is handled. It obviously affects a longtermist analysis of certain abortion cases, so it seems important to have an answer.</p>\n", "user": {"username": "Ahrenbach"}}, {"_id": "hmScxDLqPm8MGYxxw", "title": "Is principled mass-outreach possible, for AGI X-risk?", "postedAt": "2024-01-21T17:45:34.704Z", "htmlBody": "", "user": {"username": "NicholasKross"}}, {"_id": "xvHHthT9Btkh5zRDZ", "title": "Interview on the progress and pitfalls of human challenge trials, with Jake Eberts, 1Day Sooner/Asimov Press", "postedAt": "2024-01-21T16:58:25.227Z", "htmlBody": "<p>For Asimov Press's second Issue piece, we interviewed Jake Eberts, communications director at 1Day Sooner and a passionate campaigner for participation in human challenge trials.&nbsp;</p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/xvHHthT9Btkh5zRDZ/rfrb0mk2mtmfh4oixhdr\"></strong><br><br>We discussed the history of human challenge trials from Edward Jenner's risky first efforts with inoculation against smallpox at the close of the 18th century to Walter Reed's experiments with yellow fever at the dawn of the 20th. Jake elucidated why challenge trials are having an uptick right now, how they have contributed to recent vaccine development successes (selecting the malaria R21 adjuvant), and how they could do more to fit into biosecurity and pandemic prevention efforts. Finally, he covered ways we can improve challenge trials, from recruitment to issues surrounding distributive justice and fair compensation.&nbsp;<br><br>To learn more about how human challenge trials \"have a disproportionate impact on scientific advancement\" please read the full article here: https://www.asimov.press/p/human-challenge-trials<br><br>We have some excellent pieces lined up: what science can learn from car manufacturers about root-cause analysis, the history of the US bioweapons program, and how AI might help scale phage therapy.&nbsp;<br><br>To access these and other future Asimov Press articles, subscribe by going here: https://www.asimov.press/</p>", "user": {"username": "xander_balwit"}}, {"_id": "qx8ckBXsykLWWPJdJ", "title": "Catalogue of POLITICO Reports and Other Cited Articles on Effective Altruism and AI Safety Connections in Washington, DC", "postedAt": "2024-01-21T02:15:01.598Z", "htmlBody": "<p>\"Brendan Bordelon is a reporter for POLITICO on lobbying and influence in Washington, DC, by the tech industry. In late 2023, Bordelon began writing a series of articles investigating the influence of networks of non-profit/non-governmental organizations affiliated with the field of AI safety (AIS), as well as the effective altruism (EA) movement, as spearheaded by Open Philanthropy (OP), a foundation that is the primary financial backer of both causes. As of now, it\u2019s not apparent that Bordelon or any other reporters from POLITICO have published more reports on the subject.</p>\n<p>It\u2019s not clear when in 2024 Bordelon\u2019s reporting might return to a focus on influence and lobbying by the tech sector in general, beyond the auspices of just OP and EA. Additional reports from POLITICO on the subject will be added to the below list after they are published, as will be other articles or reports cited therein.\"</p>\n", "user": {"username": "Evan_Gaensbauer"}}, {"_id": "DTswPWmkzMM7ZeeGq", "title": "1) Pandemics are a Solvable Problem", "postedAt": "2024-01-26T19:48:06.489Z", "htmlBody": "<p>Pandemics are not the kind of problem to be endured or ameliorated through medication. Pandemics can be solved \u2013 completely and permanently \u2013 and that should be our goal. As we rebuild our societies post-Covid, we should reject any plans or strategies promising anything less. We can solve pandemics through prevention (not cure) and that solution is achievable with our current technology. In this post I will lay the foundations for that position. In later posts I will develop the strategies for achieving that outcome.</p><p>&nbsp;</p><h1>Problem Solving</h1><p>'All life is problem solving\u2019, as the quote goes. I'm inclined to agree. Our day-to-day lives are full of problems to be solved, from the small, simple, and routine, like how to tie your shoelaces, to the big, complex, and seemingly irresolvable, like how to govern our societies.</p><p>Of all the problems we face, some we have solved and others we have not. Of the problems we have not yet solved, there are also two classes: those we could solve if we really wanted to, and those we could not, either because we lack the resources or the problem is inherently unsolvable.</p><p>For example, no economic policy could be described as correct or optimal \u2013 despite what the economists might tell you! There is a no such thing as the perfect budget, but even if the government did by pure chance manage to deliver the best possible allocation of taxpayer funds, how would we know? What real-world outcome would confirm it? The same can be said for the even simpler problem of monetary policy: we will do our best in the moment to make the right decisions, but we can only guess in hindsight at what the \u2018correct\u2019 answer would have been.</p><p>In contrast, there are simpler problems with clear and unambiguous solutions. Basic algebraic expressions like 2X = 6 can always be solved for X. These kinds of problems have a correct answer, we know how to identify it, and we can confirm that we have done so too. It is taken for granted that we can solve problems like these directly, completely, and without controversy.</p><p>&nbsp;</p><h1>What Kind Of Problem Is A Pandemic?</h1><p>Perhaps surprisingly, pandemics are more like simple algebraic equations than macroeconomic policy-making. They are a class of problem which can be solved, in theory and in practice, and with the technology of the day. We can get the right answer and know for sure that we have it too, as I will clarify below.</p><p>Having lived through the chaos and catastrophe of the Covid-19 pandemic, you might be sceptical of that claim. How could a problem so big and complex and destructive be so simple to solve? We had every incentive to do so, yet we didn\u2019t even get close. How can I make such a grand statement?</p><p>Well firstly, contagious outbreaks are exponential variables, so they can become very complicated very quickly \u2013 <i>if</i> we let them. Secondly, a pandemic is the last stage in a long process which begins with a single infection. If left unimpeded, it will spread throughout cities and across travel networks and eventually grow into a regional epidemic covering multiple countries. At that point, a pandemic will be hard to avoid.</p><p>The lesson, I argue, is not to leave it unimpeded. In fact, the sooner we impede the outbreak the better. If we can find the pathogen while it is confined to a single country, and we can respond quickly and decisively, then we can stop the outbreak before it has spread far enough to reach pandemic status \u2013 problem solved! At that point the outbreak can be surrounded and suppressed, with the elimination of the pathogen being the ultimate confirmation that we have indeed solved the problem.</p><p>With that approach in mind, the speed of our response will be key. The sooner we identify the pathogen, the smaller the outbreak will be at the time, and the easier it will be for us to eliminate it. It will be a lot cheaper in terms of resources spent too... but that is a conversation for another day. What matters for now is that speed can improve our pandemic performance by orders of magnitude, and that is what we will need if we are to permanently solve this problem. It is also the reason why I am so confident that we can.</p><p>&nbsp;</p><h1>Pandemics Can Be Solved; They Are Solved Through Prevention</h1><p>The solution to the problem of pandemics is not one we apply after the fact, like a medical treatment. It\u2019s one we have in place at all times, ensuring that the pandemic can never take place. We don\u2019t wait for the pandemic to arrive, and then spring into action with our solution. Instead, we spring into action at the first sign of danger to nip it in the bud. We manage the risks while they are still risks. Prevention over cure.</p><p>Sadly, this seems to fly in the face of the conventional wisdom on pandemic responses.</p><p>The prevailing sentiment seems to be that pandemics just happen, like the weather, and the only thing we can hope to do is to endure them better. This school of thought calls for \u2018preparedness\u2019, since it is taken as given that there will be more pandemics, we must be prepared for them, just as we have umbrellas for rainy days.</p><p>While this perspective might sound reasonable, it gives little thought to risk management (managing risks while they are still risks) and I fear it only increases the likelihood of experiencing the disaster we seek to avoid. Taken literally, we are <i>preparing</i> <i>for</i> the worst possible outcome, instead of planning to prevent it. Pandemic preparation, in other words, risks becoming a self-fulfilling prophecy.</p><p>That this perspective has become the conventional wisdom is due in part to the fact that many of the people in senior pandemic policy-making positions are medics (understandably). Medics are trained in cure, not prevention, so they only act once the risk has materialised (i.e. when someone has become sick) at which point they administer a medical treatment. But what if you don\u2019t want to sick in the first place? And what if the disease is contagious, and it's not just an individual but the whole population at risk? Medicine isn\u2019t well-equipped to deal with these situations.</p><p>I also find the perspective to be a bit depressing, as it implies that we have no agency over our outcomes, and that we should learn to endure the most unpleasant circumstances better, instead of aiming to ensure that we never have to experience them again. There\u2019s an air of acceptance and defeat to pandemic preparedness, which I cannot abide. Fortunately, this perspective is also plainly wrong.</p><p>Contagious outbreaks are reflexive: the outbreak affects our actions (like the weather), but our actions also affect the outbreak (unlike the weather). Imagine if bringing your umbrella to work would mean that it was less likely to rain. It sounds bizarre, but that\u2019s how contagious outbreaks work. My umbrella might not stop you getting wet, but my mask can stop you getting infected. Given that our actions (and inactions) determine the path of the outbreak, it is also the case that we have the agency needed to control them. We just need to learn how.</p><p>&nbsp;</p><h1>The Inter-Generational Obligation</h1><p>Long-term thinkers have to be optimistic and ambitious. You can\u2019t afford to aim low when you are looking centuries into the future. If one generation sells itself short, then all future generations will suffer, so it is essential that we aim for the best possible outcomes and hold ourselves to the highest possible standards. This is especially true when dealing with matters of public health and societal stability.</p><p>Even if we can\u2019t fulfil our highest ambitions in our own lifetimes, we can still build the best possible foundations for future generations to complete the task. The more progress we make today, the more progress they can make in the future. We always want to hand over the world in better condition that we inherited it \u2013 this is our \u2018inter-generational obligation\u2019.</p><p>We can solve pandemics. We can permanently end the threat that pandemic-potential pathogens pose to humanity. And since we can, we must. However, a change of philosophy will be required: from passive acceptance to active ambition, from ex post medication to ex ante risk management, from pandemic preparedness to pandemic <i>prevention</i>.</p>", "user": {"username": "PandemicRiskMan"}}, {"_id": "rz7LkbgnFk6pudmTB", "title": "Against the Burden of Knowledge", "postedAt": "2024-01-20T14:38:52.553Z", "htmlBody": "<p><a href=\"https://maximumprogress.substack.com/p/something-is-getting-harder-but-its\">Several posts back</a> I wrote about the 2020 paper \u201c<a href=\"https://www.nber.org/system/files/working_papers/w23782/w23782.pdf\"><u>Are Ideas Getting Harder To Find?</u></a>\u201d by Nicholas Bloom, Charles Jones, John Van Reenen, and Michael Webb. In the post, I explain the paper with a metaphor: Our economy is like a car. Jones et al point out that our fuel use (R&amp;D investment) has been growing fast for 100 years but our acceleration (productivity growth rate) hasn\u2019t budged. They explain this by positing some inherent drag on idea exploration that gets more burdensome as we learn more. Something like inertia which makes it harder to double the speed of a car that\u2019s already going fast than a car that starts slower.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F711052ea-5972-4061-8481-24dd33e92c29_2513x1530.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/mrst2xcirozymyqredjl\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/evpt8ofba6ddme8meyr2 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/ygyfcj0yrvltswaigyzn 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/zcw5cs5o6pwcbuw8jpmd 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/mrst2xcirozymyqredjl 1456w\"></a></p><p>But without knowing the underlying kinetics of science and economic growth, this inertia model is just a guess. There are lots of other explanations which are consistent with the observation of diverging fuel use and acceleration. Our car could be going up a hill, or over a rough and rocky road. Or our engine could be depreciating or using the extra fuel inefficiently. Similarly, the ideas we produce might face growing barriers before they can materialize as physical products and buildings which affect productivity. Or our institutions of science are squandering the extra resources they receive with inefficient institutional designs.</p><p>The title of my post was \u201c<a href=\"https://maximumprogress.substack.com/p/something-is-getting-harder-but-its\"><u>Something Is Getting Harder But It's Not Finding Ideas</u></a>\u201d but I really only end up proving that Something Is Getting Harder And We Aren\u2019t Sure What. This post gets closer to fulfilling my original promise by addressing one of the most common arguments for why ideas really are getting harder to find: the burden of knowledge.</p><h2>In Favor of The Burden of Knowledge</h2><p>The burden of knowledge claims that new ideas inherently get harder to find because you have to spend more time learning more old ones before you\u2019re ready to expand the frontier.</p><p>The argument in favor of this claim is pretty intuitive and convincing. It\u2019s hard to imagine a model of scientific progress without accumulating knowledge. Some of this accumulated knowledge is necessary for expanding the frontier, but no one starts knowing it, so you need some process of investment in education. If the cost of education increases the more you need to learn, then we\u2019ve already created a model with the burden of knowledge.</p><p>Outside of theory we find more support for the burden of knowledge. Knowledge does seem cumulative. Our encyclopedias are much longer. Scientists today know about more species, more fundamental particles, and more archaeological artifacts than scientists in the past. Education also seems like necessary pre-requisite for expanding the frontier of knowledge. Scientists often spend decades in training before they start making original research contributions.</p><p>But to explain the observation of diverging R&amp;D investments and productivity growth rates over the past several decades, the burden of knowledge must have increased over this time. There is empirical evidence for this too.</p><p>The average age of authors in academic journals is increasing, as is the age when Nobel laurates do their best work. This can be explained by an increasing burden of knowledge which takes more time to get through before new contributions can be made.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdaf27eb-09ef-44b9-9365-896466ead407_800x309.jpeg\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/x0j7vcee4m0xsddnswq2\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/dvzpz6wfxriwq2vwb50j 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/idpkx8afnktjdvxr1fju 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/ouovgxxwmh568s39wtya 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/x0j7vcee4m0xsddnswq2 1456w\"></a></p><p>Source: <a href=\"https://www.newthingsunderthesun.com/pub/zsc23qxz/release/17\"><u>Matt Clancy</u></a></p><p>Relatedly, more journal articles and patents are being written in larger teams. Larger teams are a response to an increasing burden of knowledge as researchers specialize in narrower topics to get to the frontier of knowledge faster and then collaborate to combine all the necessary elements for a new expansion.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce369fcc-021d-4399-bac1-4016640bdebe_800x480.jpeg\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/ewr1mpjsfvhwbw3zqome\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/udsz5mp4pdu3ktukdhh2 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/icydjnck4ndxhj0a9fgo 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/pepdywnpdlfgzmjojpqk 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/ewr1mpjsfvhwbw3zqome 1456w\"></a></p><p>Source: <a href=\"https://www.newthingsunderthesun.com/pub/zsc23qxz/release/17\"><u>Matt Clancy</u></a></p><p>It is also becoming less common and less rewarding for researchers or inventors to contribute to multiple fields of study, again suggesting specialization in response to a greater burden of knowledge.</p><p>All of this evidence is parsimoniously explained with a burden of knowledge model. It\u2019s still far from clear that these effects are enough to explain all or a significant portion of the divergence between R&amp;D inputs and productivity growth outputs but it does tell compelling story.</p><p>There are several problems with this story though.</p><h3>Knowledge is Often Not Cumulative</h3><p>The central piece of the burden of knowledge model is accumulating knowledge which simultaneously represents the fruits of progress but also an obstacle for future researchers. But the history of scientific and technological progress shows countless examples where this assumption in false.</p><p>My favorite is orbital mechanics. For thousands of years the standard model for astronomical prediction was Ptolemy\u2019s geocentric model. Earth was at the center and all the celestial bodies rotated around us. This worked well but things got complicated because, from our perspective, lots of these celestial bodies would switch directions and orbit the opposite way at various times throughout the year.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fbd8c49-ce1f-4b23-9f7c-a48cd33b55fe_1600x1574.jpeg\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/ftenqauobf8khauiu1gi\" alt=\"The Planet's Orbital Paths According to Ptolemy: How Johannes Kepler Helped  Land \u201cCuriosity\u201d On Mars (1600\u00d71574) | Sacred geometry, Astronomy, Geometry\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/elz0nee3hm04mic8brco 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/t21jjcbixfc2x5zafrgt 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/caiv31hejal4xiiu0u6q 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rz7LkbgnFk6pudmTB/ftenqauobf8khauiu1gi 1456w\"></a></p><p>&nbsp;</p><p>Ptolemy and his astronomical ancestors explained these \u201cretrograde\u201d motions with the extra loops you see in the map above called \u201cepicycles.\u201d By the 15th century astronomers had accumulated centuries of meticulous measurements and incorporated them into complex orbital paths, matching their observations. Learning these models and taking enough measurements to improve one of them took an entire lifetime of monastic devotion to studying the stars. The burden of knowledge was immense.</p><p>But then, Copernicus came along with the heliocentric model which, in its simplest initial form, made worse prediction than the tuned-up Ptolemaic model. But the burden of knowledge was dissolved in an instant. Improving the Copernican model meant shifting orbital paths from perfect circles to ellipses. It had nothing to do with the epicycles and perihelions of the Ptolemaic model and none of that burdensome knowledge was necessary to expand the frontier anew.</p><p>We see similar patterns in the transition from Newtonian to relativistic mechanics or discursive Greek geometric algebra to symbolic Arabic equations or superstitious alchemy to physically grounded chemistry. There are thousands of other examples. It is not a general rule that all the past knowledge must be learned to create something new. Often, past knowledge is completely supplanted by a new discovery and progress can continue without increasing, and often decreasing, the necessary educational investment.</p><h3>Specialization Does Not Always Make Innovation Harder</h3><p>Another prediction of the burden of knowledge is that researchers will respond by specializing in a narrower field which allows them to get to the frontier faster. This is fine, but if this specialization then requires them to collaborate with larger groups and this drags on innovation, it could explain some of the divergence between R&amp;D inputs and productivity growth outputs.</p><p>It\u2019s definitely true that specialization is a common response to an increased burden of knowledge. But the most common way for this specialization to manifest is not larger teams of academic scientists collaborating on a long and complicated paper. It is scientists and technologists specializing and trading for complex tools which they could not recreate themselves but which nonetheless help them expand the frontier of technology.</p><p>Consider a tech entrepreneur in the 2020s. If they want to expand the frontier of technology in software there is, in some sense, a massive burden of knowledge standing before them. The history of theoretical computing, computer engineering, all the science and engineering behind Moore\u2019s law, networking, and the internet. But in fact, the entrepreneur does not need to invest any time in learning about these things to create a new technology using a computer. They can just buy a Macbook and offload all the burden of knowledge onto the people who make it.</p><p>Similarly, a modern scientist is highly specialized in that they use dozens of extremely complex tools which they could not recreate themselves, e.g electron microscopes, super-computers, and protein synthesizers. The burden of knowledge required to deeply understand all of these tools is far too great, so the scientist must specialize in their research and remain a mere user of these tools. But this doesn\u2019t drag on their ability to advance knowledge, in fact it does the opposite.</p><p>The modern world has accumulated much more knowledge than at any time in the past. Specialization is a necessary response to this accumulation, but this is not a drag on innovation. Access to the fruits of this accumulated knowledge through specialization and trade accelerates progress and discovery.</p><h3>The Empirical Evidence is Explained by Institutional Decay</h3><p>The previous two arguments are intuitive and theoretical but they do not address the significant empirical evidence which the burden of knowledge can explain. If new fields and new tools are cutting through the burden of knowledge, why are researchers getting older, their teams getting larger, and their fields getting narrower and more permanent?</p><p>One explanation for this evidence is an increasing burden of knowledge. Idea space is just structured such that it takes more time, effort, and more narrow specialization to get to the modern frontier of knowledge.</p><p>Another explanation which equally explains our observations is that the institution of academia is depreciating. Inward looking networks of grant applicants and reviewers <a href=\"https://nexus.od.nih.gov/all/2015/03/25/age-of-investigator/\"><u>reward a fixed cohort of researchers that gets older every year</u></a>. Risk averse funders and reviewers that <a href=\"https://mattsclancy.substack.com/p/biases-against-risky-research\"><u>reward incremental, labor intensive research</u></a>. A <a href=\"https://en.wikipedia.org/wiki/The_Case_Against_Education\"><u>business model based on exclusivity</u></a> that requires more and more hurdles as the initial pool of applicants grows.</p><p>Institutional decay in the academy is obvious to anyone who looks and can explain our observations of aging, narrowing careers in academia. The burden of knowledge claims that these trends are inevitable responses to an unavoidable cost of progress. But an explanation based on on institutional decay suggests a solution: metascience. Redesign our academic institutions and we can reverse some of these trends.</p><p>The burden of knowledge is an intuitive explanation for ideas getting harder to find. Even extremely simple models of scientific progress have the burden of knowledge in them and there is some suggestive empirical evidence for the burden of knowledge in the real world. But new fields and new tools cut against the burden of knowledge. It is unlikely both theoretically and empirically that the burden of knowledge explains a significant portion of the divergence between R&amp;D inputs and productivity growth outputs that \u201c<a href=\"https://www.nber.org/system/files/working_papers/w23782/w23782.pdf\"><u>Are Ideas Getting Harder To Find?</u></a>\u201d points out.</p>", "user": {"username": "Maxwell Tabarrok"}}, {"_id": "H22EuxzYxJxickQH7", "title": "AI Open Source Debate Comes Down to Trust in Institutions, and AI Policy Makers Should Consider How We Can Foster It", "postedAt": "2024-01-20T13:47:20.756Z", "htmlBody": "<p>There seems to be a lot of debate about whether it would be more dangerous for big corporations/governments to run/build AGI or the like than to have powerful AI be open source (<a href=\"https://forum.effectivealtruism.org/posts/Anha9a9hPLK2Srxzh/what-am-i-missing-re-open-source-llm-s\">I posted a question about this the other month</a>). It seems like a lot of people in favor of open-source trust the masses more than the people who might be in charge (<a href=\"https://www.reddit.com/r/Futurology/comments/19b7ywe/very_scary_mark_zuckerbergs_pledge_to_build/\">this Reddit thread</a> from this morning was yet another reminder).</p><p>It leads me to feel like, if you are in favor of a more top-down control of AI (or are afraid of it being open sourced), you/we have to do a lot better of a job of getting people to trust institutions. And I realize that's an extremely difficult challenge, one that liberals are facing across the world as populists claim that govt can't be trusted etc., and it's one that has been a debate in society for a while, but I suppose I would call on people working in the space of AI policy to think about what we can do to make people start trusting institutions more. Shedding a light on people working in AI, i.e. getting to know them through videos/interviews? Explaining why the people who work in these fields are well-intentioned and smart and qualified? In fact, whatever the solutions, this seems to be the kind of thing that many of us who don't have technical AI chops (and may or may not feel slightly inadequate about ourselves for it) could very much contribute to, in case anyone is looking for research ideas.</p>", "user": {"username": "another-anon-do-gooder"}}, {"_id": "oXrg4mf8dxtyBeBrg", "title": "Grantmakers should give more feedback", "postedAt": "2024-01-22T13:22:45.644Z", "htmlBody": "<h1>Background</h1><p>I\u2019ve been actively involved in EA since 2020, when I started EA Romania. In my experience, one problem that frustrates many grant applicants is the limited feedback offered by grantmakers. In 2022, at the EAG in London, while trying to get more detailed feedback regarding my own application at the EAIF office hours, I realized that many other people had similar complaints. EAIF\u2019s response seemed polite but not very helpful. Shortly after this experience, I also read a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vPMo5dRrgubTQGj9g/some-unfun-lessons-i-learned-as-a-junior-grantmaker#It_s_rarely_worth_your_time_to_give_detailed_feedback\"><u>forum post</u></a> where Linch, a junior grantmaker at the time, argued that it\u2019s \u201c<i>rarely worth your time to give detailed feedback</i>.\u201d The argument was:</p><blockquote><p>[F]rom a grantmaking perspective, detailed feedback is rarely worthwhile, especially to rejected applicants. The basic argument goes like this: it\u2019s very hard to accurately change someone\u2019s plans based on quick feedback (and it\u2019s also quite easy to do harm if people overupdate on your takes too fast just because you\u2019re a source of funding). Often, to change someone\u2019s plans enough, it requires careful attention and understanding, multiple followup calls, etc. And this time investment is rarely enough for you to change a rejected (or even marginal) grant to a future top grant. Meanwhile, the opportunity cost is again massive.</p><p>Similarly, giving useful feedback to accepted grants can often be valuable, but it just isn\u2019t high impact enough compared to a) making more grants, b) making grants more quickly, and c) soliciting creative ways to get more highest-impact grants out.</p></blockquote><p>Since then I have heard many others complain about the lack of feedback when applying for grants in the EA space. My specific experience was with the EAIF, but based on what I\u2019ve heard I have the feeling this problem might be endemic in the EA grantmaking culture in general.</p><h1>The case for more feedback</h1><p>Linch\u2019s argument that \u201cthe opportunity cost of giving detailed feedback is massive\u201d is only valid if by \u201cdetailed feedback\u201d he means something really time consuming. However, it cannot be used to justify EAIF\u2019s current policy of giving no feedback at all by default, and giving literally a one-sentence piece of feedback upon request. Using this argument to justify something so extreme would be an example of what some might call \u201cact utilitarianism\u201d, \u201cnaive utilitarianism\u201d, or&nbsp;<a href=\"https://utilitarianism.net/types-of-utilitarianism/#multi-level-utilitarianism-versus-single-level-utilitarianism\"><u>\u201csingle-level\u201d utilitarianism</u></a>: it may seem that, in certain cases, giving feedback is a waste of resources compared to other counterfactual actions. If you only consider first-order consequences, however, killing a healthy checkup patient and using his organs to save five is also effective. In reality, we need to also consider higher order consequences.&nbsp;<strong>Is it healthy for a movement to adopt a policy of not giving feedback to grant applicants?</strong></p><p>Personally, I feel such a policy runs the risk of seeming disrespectful towards grant applicants who spend time and energy planning projects that end up never being implemented. This is not to say that the discomfort of disappointed applicants counts more than the suffering of Malaria infected children. But we are human and there is a limit to how much we can change via emotional resilience workshops. Besides,&nbsp;<a href=\"https://hbr.org/2017/08/the-dark-side-of-resilience\"><u>there is such a thing as too much resilience</u></a>. I have talked to other EAs who applied for funds, 1:1 advice from 80k, etc, and many of them felt frustrated and somewhat disrespected after being rejected multiple times with no feedback or explanation. I find this particularly worrisome in the case of founders of national groups, since our experience may influence the development of the local movement. There is a paragraph from an&nbsp;<a href=\"https://www.economist.com/1843/2022/11/15/the-good-delusion-has-effective-altruism-broken-bad\"><u>article</u></a> by The Economist which I think adds to my point:</p><blockquote><p>As the community has expanded, it has also become more exclusive. Conferences, seminars and even picnics held by the Centre for Effective Altruism are application-only. Simon Jenkins was an early member of the community and founded an effective-altruism group in Birmingham in Britain. He has since drifted somewhat away from the movement, after years of failing to get a job at its related institutions. It has become both more \u201crigorously controlled\u201d, he said, and more explicitly elitist. During an event at a Birmingham pub he once heard someone announce that \u201cany Oxbridge grad can get involved\u201d. \u201cI was like, hold on a sec, is that the standard?\u201d</p></blockquote><p>Of course such events can be interpreted in many ways, but the point here is that EA has a reputation for harboring certain problematic attitudes, and that harms the movement. Giving feedback that is longer than one line can be a good step in the direction of correcting that.</p><h2>An argument from virtue ethics</h2><p>I\u2019m a typical male software developer who scores highish on autistic traits (<a href=\"https://pubmed.ncbi.nlm.nih.gov/11439754/\"><u>33/50</u></a>). I can relate to the hyper-systematizing way of thinking that is dominant in EA circles. In fact, this is one of the things that attracted me to EA. However, even I have started to see how this way of thinking about ethics can be problematic or extreme in certain cases.</p><p>In an article titled \u201c<a href=\"https://psyche.co/ideas/effective-altruism-is-logical-but-too-unnatural-to-catch-on\"><u>Effective altruism is logical, but too unnatural to catch on</u></a>\u201d, psychology professor Alan Jern argues that, if you\u2019re an EA escaping from a burning building and you get to save either a child or a Picasso worth millions of dollars, you should save the Picasso because then you can sell it and donate the proceeds to effective charities that will save many children. When I first read the article, I thought this scenario was a strawman, a naive interpretation of what EAs actually believe. In 2022, however, I attended a Giving What We Can meetup, organized after EAG London, and had this exact discussion with a couple of people. I was surprised to find out that many EAs actually agreed that the right thing to do was to save the Picasso.&nbsp;</p><p>Personally, I\u2019d save the child rather than the Picasso, and I don\u2019t think this is necessarily a violation of EA principles. EA is right when it points out that much of the charity done in the world is based on emotion, but I don\u2019t think EA should promote the complete elimination of emotion from moral decision making. EA should not be seen as a project that replaces emotions with a hyper-rational approach. Aristotle said that virtue is the sweet spot between two vices. I believe that, as much as being overly emotional is a vice, so is being overly robotic in our moral calculations. As Joshua Greene argues in Moral Tribes:</p><blockquote><p>If what utilitarianism asks of you seems absurd, then it\u2019s not what utilitarianism actually asks of you. Utilitarianism is, once again, an inherently practical philosophy, and there\u2019s nothing more impractical than commanding free people to do things that strike them as absurd and that run counter to their most basic motivations. Thus, in the real world, utilitarianism is demanding, but not overly demanding. It can accommodate our basic human needs and motivations, but it nonetheless calls for substantial reform of our selfish habits.</p></blockquote><p>In The Life You Can Save, Peter Singer similarly argues that:</p><blockquote><p>Asking people to give more than almost anyone else gives risks turning them off. It might cause some to question the point of striving to live an ethical life at all. Daunted by what it takes to do the right thing, they may ask themselves why they are bothering to try. To avoid that danger, we should advocate a level of giving that will lead to the greatest possible positive response.</p></blockquote><p>Of course, where to draw the line between overly emotional and overly robotic is ultimately an empirical question. As a consequentialist, I would argue that the sweet spot between the emotional and the rational is the spot that maximizes the total longterm well-being of sentient life. Unfortunately, it\u2019s impossible to know for sure where this spot actually is. As members of EA, we can be sure, however, that if we promote an attitude that is too robotic, too cold and calculated, too mathematical and unemotional, EA will become an excessively narrow movement that attracts only a specific kind of personality. If extreme enough, there is the risk that EA views will be so shocking to the outside world that the reputation of the movement will be even more damaged than it has already been. These repercussions are the kinds of second-order consequences that multi-level utilitarianism asks us to consider when coming up with heuristic rules to guide a community.</p><p>In some ways, not giving satisfactory feedback to grant applicants is like saving a Picasso and letting the child die. It could be the best decision in a hypothetical scenario with no higher order consequences, but this decision is not the best in the real world.&nbsp;<strong>People need feedback.</strong>&nbsp;<strong>People need to know their time and effort are valued. People need to know how to improve before they apply for funds again. They need to know whether trying again is worth it or not. The culture of \u201cwhen in doubt, apply\u201d combined with the culture of \u201cwe can do better things with our time than give feedback,\u201d combined with lack of transparency regarding the statistical odds of getting funded, is a dangerous mix that creates resentment and harms the community.</strong></p><h1>The case for more democracy</h1><p>Of course, I may be wrong. Perhaps the sample of people I spoke to who expressed resentment is not representative. Maybe there are so many individuals and groups applying for funds that it doesn\u2019t matter if some become frustrated and abandon the movement. Perhaps keeping the current feedback policy is actually better for the long-term well-being of sentient life. Or maybe I am right and it would be better to give more feedback. How can we know? That\u2019s the problem with multi-level utilitarianism: it becomes speculative very fast. It\u2019s impossible to know whether one set of rules and social norms really would be better than another. However, one solution to this epistemic conundrum is democracy. We can appeal to the wisdom of crowds and ask people to vote on which option they think would empirically turn out to be better.</p><p>In my experience, one of the aspects of EA that is generally viewed as problematic is the lack of democratic values and accountability. In the secular humanist movement, where I\u2019ve been involved for longer than I\u2019ve been involved in EA, democracy is an explicit value, enshrined in Humanists International\u2019s statute. Although I appreciate the culture of asking for feedback in EA, sometimes I wonder what happens to that feedback. In the secular humanist movement, if people are frustrated with the administration, they can express their criticism at conferences or in other communication channels, and if those frustrations are not addressed, members can vote leaders out in the next elections. If EAs are frustrated with the movement\u2019s organizational structures and decision-making processes, what can we do?</p><p>I understand that democracy has its dangers, and that sometimes we should defer to experts rather than crowds. Still, we must find a balance between oligarchy and mob rule. I think EA is erring on the side of elitism and overlooking the value democracy can have as a mechanism for error-correction, and thus progress.</p><h1>Conclusion</h1><p>To summarize my argument:</p><ol><li>There have been several cases of grantmakers giving limited feedback when rejecting proposals. This lack of feedback harms the community.</li><li>If grantmakers commit to a policy of giving more feedback, this will improve community health and the effect of this change will be net positive for the movement and the world.</li><li>If we define our policies more democratically, they\u2019re more likely to have a net positive impact because the wisdom of crowds will make our empirical assumptions more accurate.</li></ol><p>What do you think? Do you agree that grantmakers don\u2019t give enough feedback? Do you agree that EAs should be more suspicious of speculative arguments about the potential impact of certain policies? Do you think more democracy could improve our decision making? In what ways do you think my reasoning might be wrong? Looking forward to hearing your thoughts :)</p>", "user": {"username": "arielpontes"}}, {"_id": "ygLq7AAn2qBgkWmx9", "title": "Solar4Africa Project #4 - General Intervention Refinement and Cost-Effectiveness (CE) Analysis of Solar Electric Cooking Systems: Final Analysis and Justification of Intervention", "postedAt": "2024-01-20T05:46:56.501Z", "htmlBody": "<p><i>SUMMARY: This post provides an exploratory analysis of the cost-effectiveness of off-grid solar-electric cooking in rural Africa with a focus on Malawi. If implemented efficiently, this intervention is likely to improve health outcomes typically at a rate of 0.1 DALY/cooker for small cooking systems and in some situations may be able to provide benefits as high as 1.5 DALY/cooker for large cooking systems in countries with a high indoor air pollution burden of disease. The use of a solar-electric cooker can also reduce CO2 emissions, by about 3 tons of CO<sub>2&nbsp;</sub>/cooker in rural Malawi.&nbsp; A customer-owned off-grid electricity supply for a small cooker system generates cost-savings for the owner that are likely to be about $300 to $400 per cooker system on average over the lifetime of the cooker. Whether these economic benefits of long-term cost savings are sufficient to convince rural Malawian households to invest $150 to $300 in the off-grid electricity supply system that is needed for solar-electric cooking remains to be seen</i></p><h1>Introduction</h1><p>As mentioned in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Dufmh6P5jRJL6wEHD/solar4africa-project-4-general-intervention-refinement-and\">our previous post</a>, Solar4Africa\u2019s Project #4 aims to assess the possible humanitarian benefits that the adoption of long-lasting solar electric cooking systems has on communities in rural Malawi. By replacing biomass sources such as firewood or crop residue for cooking, offgrid solar electricity provides the opportunity for cleaner, cheaper and longer-lasting energy. Several years of research and development for this project has been undertaken with generous support from the&nbsp;<a href=\"https://mecs.org.uk/\">Modern Energy Cooking Services program of UK Aid</a>.&nbsp;</p><p>Our project\u2019s goal is to distribute philanthropically-supported offgrid cooking systems to women\u2019s groups and households that are <i><strong><u>efficiently</u></strong></i> subsidized. A subsidy is \u201cefficient\u201d if the intervention enabled by the subsidy generates benefits that outweigh the initial subsidy cost of the cooking system. In the current post, we value of social, economic and environmental benefits from an EA perspective.&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/icxnuEHTXrPapHBQg/a-simplified-cost-effectiveness-estimation-methodology-for\">This post</a>, described how for global health and welfare (GHW) interventions the value of an avoided DALY of disease burden ranges approximately from $50 to $125, while the value of a percent of income increase for one year for one person is valued at about $0.25 by EA GHW charities.&nbsp;</p><p>The current post aims to outline our final cost-effectiveness analysis of solar-electric cooking by focusing on the health &amp; monetary benefits, and will detail our justification for continuing the implementation of our intervention.</p><p>This analysis should be generally relevant to interventions that assist low-income households to switch from wood-based and charcoal-based cooking to solar electric cooking. For the interventions specifically used by Solar4Africa, currently an affordable solar electric cooking system does not yet have enough capacity to satisfy the entire cooking needs of rural Malawian households and currently satisfies approximately \u00bc of household cooking needs.&nbsp;</p><h1>Health benefits of solar-electric cookers</h1><p>Solar-electric cookers require no \u201csolid fuel\u201d in order to cook food and have no direct pollutant emissions, thus their use in cooking all of a household\u2019s food should mitigate almost all of a household\u2019s indoor air pollution caused by indoor biofuel fires. Currently, the vast majority of the population in Malawi currently uses charcoal and wood to prepare food and thus has a disease burden from this risk that is much higher than for countries where people cook with gas or electricity. According to&nbsp;<a href=\"https://vizhub.healthdata.org/gbd-compare/\">VizHub\u2019s Global Burden of Disease 2019 data</a>, the disease burden of \u201cHousehold air pollution from solid fuels\u201d for Malawi is estimated at an average of 3401.98 DALY/100,000 people with a range of 2515.77 to 4459.86 per 100,000 people. This would mean that the use of solar electric cookers could avoid from 0.0252 to 0.2230 DALYs/year in Malawi with an average health benefit of 0.0988 DALY/year/cooker of avoided disease burden&nbsp; as shown in the following Table 1, depending on how many beneficiaries are impacted by the use of clean cookers:</p><p><strong>Table 1: Matrix of expected health benefit values</strong></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1.0pt solid black;padding:5.0pt;vertical-align:top\">Beneficiary/Household</td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">DALY/Beneficiary/yr (Low)</td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">DALY/Beneficiary/yr (Med)</td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">DALY/Beneficiary/yr (High)</td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">1</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">0.0252</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">0.0340</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">0.0446</td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">3</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">0.0756</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">0.1020</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">0.1338</td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">5</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">0.1260</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">0.1700</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\">0.2230</td></tr></tbody></table></figure><p>Solar4Africa works in Malawi. For a Sub-Saharan African (SSA) country, Malawi has an \u201caverage\u201d burden of disease due to household air pollution from solid fuels.&nbsp; Some countries in SSA (e.g. Mali, Burkina Faso, Niger, Chad, Central African Republic) have about twice the burden of disease from household solid fuel use as Malawi. For larger households in such countries, a health benefit of approximately 0.5 DALY/year may be obtained by fully switching to clean cooking technologies like solar electric cooking.</p><p>We also recognize that women are disproportionately affected by household air pollution from solid fuels because they are often the household member that prepares the food while men are out working. However, the Global Burden of Disease data is an average of all Malawi citizens and thus takes into account both men and women\u2019s exposure to pollution caused by indoor biomass fires. It is also important to note that Solar4Africa\u2019s solar-electric cookers are limited to cooking only roughly \u00bc of a household's food and the rest must be prepared traditionally with disease-burdened biomass fires. In our CE calculations we take this into account by multiplying the disease burden averted by \u201cPercent Impact\u201d which is the fraction of the household indoor air pollution disease burden averted by the clean cooker. In specifying the percent impact, the low estimate being 10% mitigation, the medium estimate being 20% mitigation, and high estimate being 30% mitigation. &nbsp;(Note: there is large uncertainty in the relationship between marginal exposure to indoor air pollution and marginal health impacts. There is some evidence that at the margin, that benefits of pollution reduction <a href=\"https://stoves.bioenergylists.org/stovesdoc/Ezzati/pub/Lancet%2520IAP.pdf\">may be smaller than what would be assumed from a linear, exposure/health relationship</a>).</p><h1>Climate benefits of solar-electric cookers</h1><p>We also note that the use of solar-electric cookers will lower CO2 emissions. This is due to the fact that utilizing solar cookers in Malawi will reduce dependency on wood as a fuel source. This will decrease wood burning which will have many positive benefits on the environment, particularly the reduction of unsustainable harvest. The percentage of wood that is harvested unsustainably is the percentage of wood that does not grow back. The continued practice of unsustainable harvest will lead to an overall rate of wood harvest exceeding the rate of wood growth. This fosters deforestation and increases in CO2 emissions. In Malawi specifically,&nbsp;<a href=\"https://www.nature.com/articles/nclimate2491\">this study</a> estimates the percentage of wood that is harvested unsustainably ranges from 24.2% to 41%. Furthermore,&nbsp;<a href=\"https://www.researchgate.net/profile/Robert-Bailis/publication/271503594_The_Carbon_Footprint_of_Traditional_Woodfuels/links/5525114b0cf2b123c517734e/The-Carbon-Footprint-of-Traditional-Woodfuels.pdf\">the same study</a> estimates that on a global scale, unsustainable harvest accounts for roughly 1.9-2.3 percent of global emissions.&nbsp;</p><p>Additionally there are multiple hotspots around the globe where the percentage of wood that is harvested unsustainably is large. These areas include East Africa, Western and Southern Africa, and parts of Asia. A hotspot is defined as an area in which FNRB (fraction of non-renewable biomass) exceeds 50 percent. It is these hotspots that contribute most to the problem of unsustainable harvesting. Since Malawi is in East Africa, this means that it is in a hotspot region.&nbsp;</p><h1>Cost effectiveness (CE) calculations</h1><p>There are multiple and diverse benefits from solar-electric cooking as a replacement for wood-based and charcoal-based cooking. In addition to the health and climate-related benefits mentioned above, there are financial savings from decreased expenditures on cooking fuel, and there are benefits from ancillary uses of the solar electricity for lighting, phones charging and electronics (i.e. audio equipment and TV).</p><p>For each of the four benefit categories, we provide in turn our best preliminary estimate of the benefit per cooker for the four different types of benefit. We don't estimate simply a single value for cooking benefits, but a probability distribution of expected benefits that reflect the uncertainty in the input parameter values used in the benefit calculation.&nbsp;</p><h2>Disease burden mitigated per cooker</h2><p>As described above the mitigated disease burden from a solar electric cooker depends on the baseline disease burden from \u201cHousehold air pollution from solid fuels.\u201d&nbsp; We use the range of values representative for Malawi. For several countries in SSA, these values are about twice as high. The number of household members benefitting from the disease burden reduction is likely conservative, as the baseline disease burden values are a population average. The potential cooker lifetime is estimated to range from 3 to 10 years.&nbsp;</p><p><strong>Table 2: Inputs for health benefit estimation</strong></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1.0pt solid black;padding:5.0pt;vertical-align:top\"><strong>Variable</strong></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><strong>Low</strong></p></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><strong>Med</strong></p></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><strong>High</strong></p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">Disease Burden per Ben.</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>0.025</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>0.034</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>0.045</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">% Impact</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>10%</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>20%</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>30%</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"># of beneficiary/HH</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>1.0</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>3.0</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>5.0</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">Cooker Lifetime (years)</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>3.0</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>5.0</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>10.0</p></td></tr></tbody></table></figure><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/kl6ycl9kcelojyfgldoi\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/svx99mvuuo7vqunzfe7u 153w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/oxj3c1dlraigsgypqdce 233w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/ff12m78cr4r6zgtwjnww 313w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/leikakr4objp4vdlf2ou 393w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/zhqdquirkr3lmamovpwp 473w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/ui9cxwfwmgv2inhalkuz 553w\"></p><p><strong>Figure 1: Estimated distribution of disease burden reductions for a solar electric cooker that is used for approximately \u00bc of household cooking needs.</strong>&nbsp;</p><p>Figure 1 illustrates the range of expected disease burden reductions that may be expected from a cooker that is used for \u00bc of cooking. The median value is approximately 0.1 DALY/cooker, and may be as high as 0.2 to 0.5 DALY/cooker for cookers in areas with a larger indoor air quality disease burden than Malawi and when a a 20% to 30% reduction in solid cooking fuel indoor ir quality disease burden occurs for all household members.&nbsp; For Effective Altruists that value 1 DALY of disease burden reduction at a bit more than $100, this is worth about $10 for the median Malawi case and can be worth $20 to $50 in high impact applications. A full switch to solar electric cooking in a high solid fuel cooking burden of disease (&gt;0.06 DALY/capita/year) location for households with 5 or more members would likely create more than 1.5 DALY of reduced disease burden per cooker system which should be worth more than $150 from a EA&nbsp;perspective.&nbsp;</p><h2>CO<sub>2</sub> emissions reduction per cooker</h2><p>The CO<sub>2</sub> emissions reduction per cooker depends on four key input parameters: (a) the daily usage of the cooker (measured in kWh/day), (b) the wood fuel equivalent emissions reduction per kWh solar electric cooking,(c) the fraction of wood harvested that is harvested unsustainably, and (d) the lifetime of the cooker.&nbsp;</p><p>To determine the daily use, Solar4Africa has measured the actual daily use of the cookers under actual customer conditions. For the emissions per kWh, Solar4Africa has measured in parallel cooking tests, that 1 kWh of electric cooking uses either 2 kg of wood or 1 kg of charcoal using traditional cooking methods.&nbsp; Since 7 kg of wood is required to make 1 kg of charcoal, this mean that 1 kWh of electric cooking is equivalent to 2 kg to 7 kg of wood. With an emissions factor of 1.8 kg CO<sub>2</sub>/kg wood this is 3.6 to 12.6 kg CO<sub>2</sub>. The fraction of unstainable harvest and cooker lifetime are explained above.&nbsp;</p><p><strong>Table 3: Inputs for CO2 emissions reduction estimation</strong></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1.0pt solid black;padding:5.0pt;vertical-align:top\"><i><strong>Variable</strong></i></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i><strong>Low</strong></i></p></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i><strong>Med</strong></i></p></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i><strong>High</strong></i></p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><i>kWh/day of Use</i></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>0.30</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>0.60</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>1.00</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><i>Total kgCO<sub>2&nbsp;</sub>/ kWh</i></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>3.6</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>8.1</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>12.6</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><i>% Unsustainable harvest</i></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>24.2%</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>32.8%</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>41.4%</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><i>Cooker lifetime (years)</i></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>3.0</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>5.0</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>10.0</p></td></tr></tbody></table></figure><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/sgwtljd9alfouyxyd66y\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/n0btjgl7nldb304fczjm 153w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/uo2ctphoq9plzbyyz9rh 233w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/gygpumtdosklkxfhbwrp 313w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/z7thvyyj9fhze0k6xciv 393w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/fccwaq1zxdntgcz5xiyc 473w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/yzikij0fekn4ollvqgvp 553w\"></p><p><strong>Figure 2: Estimated distribution of CO<sub>2</sub> emissions reductions reductions for a solar electric cooker that is used for approximately \u00bc of household cooking needs.</strong>&nbsp;</p><p>Figure 2 illustrates the probability distribution of emissions reductions per cooker. The key reason that the emissions reduction per cooker has a relatively low median value of 3 tons of CO2/cooker is because \u2154 of wood harvested in Malawi is estimated to be replaced by new growth, thus only about \u2153 of short-term emissions reductions actually has a long-term climate benefit.&nbsp;</p><h2>Fuel savings value per cooker</h2><p>Because we know the equivalent wood and charcoal use associated with 1kWh of cooking, given the per kg cost of wood and charcoal, we can estimate the value of the wood are charcoal does not have to be purchased when one uses the electric cooker. As mentioned above, the amount of biofuel saved from electric cooking is either about 2 kg of wood or 1 kg of charcoal. Wood can have a price as low as $0.025/kg (because some can be gathered from around the household for free) and charcoal has a price in Malawi of about $0.35/kg. Table 4 summarizes the input parameter ranges for the fuel savings value calculation.&nbsp;</p><p><strong>Table 4: Inputs for fuel savings value estimation</strong></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1.0pt solid black;padding:5.0pt;vertical-align:top\"><i><strong>Variable</strong></i></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i><strong>Low</strong></i></p></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i><strong>Med</strong></i></p></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i><strong>High</strong></i></p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">kWh/day of Use</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>0.300</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>0.600</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>1.000</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">$ Fuel Savings Value /kWh</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>$0.05</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>$0.15</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>$0.35</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">Cooker Lifetime (years)</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>3.0</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>5.0</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>10.0</p></td></tr></tbody></table></figure><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/pftjriexyegnrvjwvpan\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/mtlzhcmghfaf3drmbwfr 154w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/ombsihprooe9hxbgohvj 234w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/u2w1regqmzxtop51kah1 314w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/bb8zswyv5n7f8wcizxu8 394w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/sta42b6jglnhfmcazabn 474w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/t5w0a1x8dyjb5mltzggh 554w\"></p><p><strong>Figure 3: Estimated distribution of fuel savings cost reductions for a solar electric cooker that is used for approximately \u00bc of household cooking needs.</strong>&nbsp;</p><p>Figure 3 illustrates the probability distribution of the fuel savings value of the cooker energy that is used. Note that the median value is slightly less than $200 per cooker.&nbsp; This value is substantial, but because it accrues over 5 years on average, it may not be enough on its own to convince rural Malawian households to make the $150 to $300 investment that may be needed for such an off-grid electricity supply system.&nbsp;</p><h2>Other potential benefits</h2><p><a href=\"https://www.solar4africa.org/\">Solar4Africa.org</a> is implementing an&nbsp;<a href=\"https://mecs.org.uk/blog/an-off-grid-solar-photovoltaic-electric-pressure-cooker-system-that-costs-only-200-in-malawi/\">off-grid version of solar-electric cooking</a>. Thus the acquisition of a solar electric cooker is associated with the acquisition of solar panels and some equipment that can also be applied to other off-grid end-uses such as lights, phone charging and household electronics (i.e. audio equipment and TV). While only a relatively small amount of electricity is used for such ancillary applications per day, the value of such electricity is much higher than the value of electricity used for cooking, because the cost of batteries and alternative electric systems designed for lighting and electronics have a much higher per kWh cost of service provision (i.e. $0.5 to $2). Table 5 lists the input parameter values and their ranges for estimating the benefits of ancillary electricity use that may be provided by the electricity supply system of a solar-electric cooker.</p><p><strong>Table 5: Inputs for estimating value of ancillary electricity use</strong></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1.0pt solid black;padding:5.0pt;vertical-align:top\"><i><strong>Variable</strong></i></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i><strong>Low</strong></i></p></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i><strong>Med</strong></i></p></td><td style=\"border-color:black;padding:5.0pt;vertical-align:top\"><p><i><strong>High</strong></i></p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">kWh/day of Ancillary Use</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>0.050</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>0.100</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>0.200</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">Ancillary Use Value /kWh</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>$0.50</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>$1.00</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>$2.00</p></td></tr><tr><td style=\"border-color:black;padding:5.0pt;vertical-align:top\">Cooker Lifetime (years)</td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>3.0</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>5.0</p></td><td style=\"border-bottom:1.0pt solid black;border-right:1.0pt solid black;padding:5.0pt;vertical-align:top\"><p>10.0</p></td></tr></tbody></table></figure><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/ryluyjgm6k7x90gyxorj\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/gf2i7fzpwijjz9s9cbdr 154w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/wqp0pz47q1i1qyhrpide 234w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/hdkvxo1w4qo5anny75ok 314w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/fwygvkelz8amq0zoxn7y 394w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/dspvoaizuvjazvl4cbzj 474w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ygLq7AAn2qBgkWmx9/kd5va6afywavyqs5pr1b 554w\"></p><p><strong>Figure 4: Estimated distribution of ancillary electricity use value for a solar electric cooker system that is used for approximately \u00bc of household cooking needs.</strong>&nbsp;</p><p>Figure 4 illustrates the economic value of ancillary electricity uses that may be served by the off-grid solar power system providing electricity to a solar-electric cooker. While the median value is about $200, a substantial number of households may benefit by $400 to $800 from the ancillary uses of a solar-electric cooking system.&nbsp; This may provide a very strong motivation for many households to invest in the electricity supply system that can also power an off-grid solar electric cooker. Solar4Africa has seen this reflected in customer purchase behavior with respect to solar panels and cookers in rural Malawi.&nbsp; Many households will purchase a large solar panel in order to have more reliable electricity for ancillary uses, but because the ancillary uses use only a fraction of the solar panel\u2019s electricity most of the time, the rest of the solar panel electricity is available for cooking.&nbsp;</p><h1>Conclusion</h1><p>We recognize that the data shows the solar electric cookers typically will have a relatively small impact on health and climate. In Malawi, the cooker health benefits are likely to average around 0.1 DALY/cooker of reduced disease burden, while the climate benefits represent about 3 tons of CO<sub>2</sub> emissions reductions per cooker.&nbsp;</p><p>However, even though the health and climate benefits are small, they may still be significant. Rural Malawians typically anywhere from $200-$500 per capita per year, and the cookers can cost the beneficiaries as little as $30-$50 if efficiently distributed. Thus the benefits generated from the cookers are enough to roughly offset the cost of the actual cooker itself.&nbsp;</p><p>An off-grid cooker system also requires a solar-electric battery and solar panels that are also distributed by Solar4Africa, and while the costs of these products are not usually fully offset by the climate benefits of electric cooking, the value in the off-grid solar electric power supply can offset by the long-term value of the electricity it produces. The value of the electricity used varies by what the electricity is used for. If the electricity is used to displace the use of wood and charcoal, the value ranges from $0.05/kWh to $0.35 per kWh.&nbsp; If the electricity is used for lights, phone charging and electronics (i.e. ancillary uses), its value can range from $0.50 to $2.&nbsp;</p><p>For both cooking energy use and ancillary electricity use, the median value of the electricity generated and used by electricity supply system is slightly less than $200 over the lifetime of the cooker. This means that the value generated by off-grid electricity supply system is expected to be about $300 to $400. The electricity supply system is likely to cost between $150 to $300. But what is perhaps more important, is that a substantial fraction of customers can obtain more than $400 in value from ancillary electricity uses from a large solar panel that supplies electricity for both cooking and ancillary uses. Solar4Africa has found anecdotally that these customers are willing to buy large solar panels that can supply both cooking and ancillary uses, and are willing to buy the cooker in addition to the solar panel if the cooker is subsidized.&nbsp;</p><p>With all of this in mind, we believe that there are enough benefits being generated from Solar4Africa\u2019s Project #4 to continue work. Thus&nbsp;<a href=\"https://www.solar4africa.org/\">Solar4Africa.org</a>&nbsp;will continue the implementation of this intervention where if the customers can invest in the solar power supply (perhaps because of ancillary electricity uses), it may be cost-effective to subsidize the addition of a solar-electric cooker.&nbsp; Moving forward, we aim to present the benefits of our solar-electric cookers to policy makers to help encourage the government of Malawi to implement efficient policies with respect to clean cooking. For example, allowing the importation of electric cookers at a subsidized (or even tax-free) rate which would ultimately lower the cost for beneficiaries and could cost-effectively generate social and environmental benefits described in the current post.</p>", "user": {"username": "Robert Van Buskirk"}}, {"_id": "raZA3mpfKMhAJxk6E", "title": "Sound resources for Self-improvement?", "postedAt": "2024-01-21T06:35:45.930Z", "htmlBody": "<p>Embarking on the journey of self-improvement is intrinsically tied to exploring insightful blogs that delve into the realms of personal development. These digital sanctuaries serve as virtual libraries, offering a wealth of knowledge on diverse topics, from mindfulness and goal-setting to productivity and emotional intelligence. Engaging with these blogs not only provides a roadmap for personal growth but also creates a sense of connection with a community that shares similar aspirations. The narratives within these blogs become beacons of inspiration, guiding individuals through the intricacies of self-discovery and improvement.</p><p>As I continue my exploration of the blogosphere for noteworthy sources on self-improvement, I anticipate discovering hidden gems that resonate with authenticity and wisdom. I am committed to updating this post with the latest insights and recommendations gleaned from my research. In the pursuit of enriching our collective understanding of self-improvement, these blogs are poised to become invaluable resources, offering actionable advice and thought-provoking perspectives. Stay tuned for an enhanced compilation that encapsulates the essence of self-improvement through the lens of these insightful online narratives.</p><p>Let me know if you know of any.<br><br>edit: hey I found a blog. That is exactly what I was looking for, be sure to visit it if you're interested.<br>Check it out here, where the writer talks about <a href=\"https://perceptionpeak.com/how-can-goal-setting-help-with-academic-performance/\">academic goal-setting importance</a>.</p>", "user": {"username": "trailblazer"}}, {"_id": "3E2a4JwsNKPeZwaK2", "title": "Suggestions for nonprofit budgeting/accounts/legal courses/MOOCs/material", "postedAt": "2024-01-19T18:34:33.652Z", "htmlBody": "<p>Looking for courses/moocs/online learning resources for The Unjournal team staff, involving&nbsp;</p><p><br>- Budgeting,<br>- Planning, and scenario analysis/quantified uncertainty modeling,<br>- Nonprofit legal certification (esp. in the US, but considering international),<br>- Nonprofit accounting and tax issues (esp. in the US, but considering international), other nonprofit management</p><p>Any suggestions/experience? Does Charity Entrepreneurship have any go-to here?<br><br>Looking mainly for \u2018hard skills\u2019 and tech-savvy/software or code-integrated approaches. Looking mainly for the 'knowledge and training', not the sheepskin/credentials. Thanks!</p><p><i><strong>In consideration:</strong></i></p><p><a href=\"https://www.nonprofitready.org/financial-management-essentials\">Free financial management program by Nonprofitready.</a></p><p><a href=\"https://uwm.edu/sce/courses/budgeting-in-a-nonprofit-organization/\">\"Budgeting in a Nonprofit Organization</a>\", UW Milwaukee</p><p><a href=\"https://courses.learnmore.duke.edu/search/publicCourseSearchDetails.do?method=load&amp;courseId=19113\">\"Budgeting for Nonprofits\"</a>, Duke</p>", "user": {"username": "david_reinstein"}}, {"_id": "Bb3KZ79vmJB7fXnuP", "title": "ITBN availability  ", "postedAt": "2024-01-19T15:09:50.578Z", "htmlBody": "<p>Relevant to my zakat research: Does anyone know if people living in areas which are served by e.g. AMF would be able to purchase ITBNs if AMF weren't distributing them for free?</p>\n", "user": {"username": "Kaleem"}}, {"_id": "CuPnmeS4v5sFE6nQj", "title": "Impact Assessment of AI Safety Camp (Arb Research)", "postedAt": "2024-01-23T16:32:30.850Z", "htmlBody": "<p><i>Authors: Sam Holton, Misha Yagudin&nbsp;</i></p><p><i>Data collection: David Mathers, Patricia Lim</i></p><p><i>Note: Arb Research was commissioned to produce this impact assessment by the AISC organizers.</i></p><p><i>[EDIT] Conflict of interest: Arb's directors, Misha and Gavin, are AISC alumni and have friends in the community. Sam's&nbsp;investigation was&nbsp;independent, but Misha, Gavin, and the current AISC organizers Linda and Remmelt were invited to comment on the report before publishing.</i></p><h1>Summary</h1><p><a href=\"https://aisafety.camp/\"><u>AI Safety Camp</u></a> (AISC) connects people interested in AI safety (AIS) to a research mentor, forming project teams that last for a few weeks and go on to write up their findings. To assess the impact of AISC, we first consider how the organization might increase the productivity of the Safety field as a whole. Given its short duration and focus on introducing new people to AIS, we conclude that AISC\u2019s largest contribution is in producing new AIS researchers that otherwise wouldn\u2019t have joined the field.&nbsp;</p><p>We gather survey data and track participants in order to estimate how many researchers AISC has produced, finding that 5\u201310% of participants plausibly become AIS researchers (see \u201cTypical AIS researchers produced by AISC\u201d for examples) that otherwise would not have joined the field. AISC spends roughly $12\u201330K per researcher. We could not find estimates for counterfactual researcher production in similar programs such as (SERI) MATS. However, we used the LTFF grants database to estimate that the cost of researcher upskilling in AI safety for 1 year is $53K. Even assuming all researchers with this amount of training become safety researchers that wouldn\u2019t otherwise have joined the field, AISC still recruits new researchers at a similar or lower cost (though note that training programs at different stages of a career pipeline are complements).</p><p>We then consider the relevant counterfactuals for a nonprofit organization interested in supporting AIS researchers and tentatively conclude that funding the creation of new researchers in this way is slightly more impactful than funding a typical AIS project. However, this conclusion is highly dependent on one\u2019s particular views about AI safety and could also change based on an assessment of the quality of researchers produced by AISC.</p><p>We also review what other impacts AISC has in terms of producing publications and helping participants get a position in AIS organizations.</p><h1>Approach</h1><p>To assess impact, we focus on AISC\u2019s rate of net-new researcher production. We believe this is the largest contribution of the camp given their focus on introducing researchers to the field and given the short duration of projects. In the appendix, we justify this and explain why new researcher production is one of the most important contributions to the productivity of a research field. For completeness, we also attempt to quantify other impacts such as:</p><ol><li>Direct research outputs from AISC and follow-on research.</li><li>Network effects leading to further AIS and non-AIS research.</li><li>AISC leading to future positions.</li></ol><p>AISC plausibly has several positive impacts that we were unable to measure, such as increasing researcher effort, increasing research productivity, and improving resource allocation. We are also unable to measure the quality of AIS research due to the difficulty of assessing such work.&nbsp;</p><h1>Data collected</h1><p>We used 2 sources of data for this assessment:</p><ol><li><strong>Survey.&nbsp;</strong>We surveyed AISC participants from all camps, receiving 24 responses (~10% of all participants). Questions aimed to determine the participants' AIS involvement before and after camp as well as identify areas for improvement. To ensure honest answers, we promised respondents that anecdotes would not be shared without their direct permission. Instead, we will summarize common lessons from these responses where possible.&nbsp;</li><li><strong>Participant tracking.&nbsp;</strong>To counter response biases in survey data, we independently researched the career path of 101 participants from AISC 4-6, looking at involvement in AI safety research before and after camp. We further identified individuals who increased AIS research after attending camp and assessed whether those individuals would have succeeded without AISC.</li></ol><p>Based on this data we:</p><ol><li>Estimate how many counterfactually-new researchers AISC produces</li><li>Provide a glimpse into \"typical researcher produced\"</li><li>Compare that to other opportunities to produce researchers (specifically, LTFF upskilling grants).</li><li>Compare the value of producing a new researcher versus funding an existing project</li></ol><h1>Impact assessment: new researcher production</h1><h3><strong>Assumptions</strong></h3><ol><li>We assume that more research in the field of AIS is good. This may not be true if AIS research is ineffective or if such research also increases AI risk.</li><li>Relatedly, we assume that there are no negative effects of AISC on participants or the field as a whole.</li><li>We assume that already-established researchers get no post-camp benefit.</li><li>We assume conversion of new researchers is the most important effect.</li></ol><h3><strong>Potential Issues</strong></h3><ol><li>AISC draws from people already interested in AIS, so researchers who appear to have a step-change in participation may not have needed AISC to break into AIS research in the first place.</li><li>Survey bias: surveys tend to obtain both highly positive and highly negative responses</li><li>Small sample size that makes most estimates noisy</li></ol><h3><strong>Estimating the rate of new researcher production</strong></h3><p>To estimate the number of individuals that became AIS researchers after AISC, we examined the publication history of participants in AISC 4\u20136, looking for individuals who went from no publications before AISC to at least one publication after AISC (not including their AISC project or follow-on work from that project).&nbsp;</p><p>We decided to limit our focus to these camps for two reasons; first, these camps were far enough in the past that we can observe participants' subsequent research in AIS, second, all three camps were run virtually, which should ideally reduce variance associated with camp location and organization.</p><p>In total, 21 / 101&nbsp; (20.8%) studied individuals have post-AISC publications relating to AI/AIS while having none before camp. Optimistically, these individuals would not have had AIS publications if it were not for AISC.</p><p>To obtain a more conservative estimate, we looked more closely at these 21 individuals to filter out people with prior research experience in AI or related fields. Of these, we identified 8 / 101 (7.9%) individuals who plausibly changed their career trajectory towards AIS after attending AISC.</p><p>Turning to our survey, 4 of 24 respondents (16.7%) believed that AISC was pivotal in getting them to start work in alignment research, with 8 / 24 (33.3%) mentioning that AISC provided them with a nudge in that direction (but believed they were already headed towards safety research before starting AISC). Note that survey data can be biased towards extreme positive and negative responses. So the observed rate of researcher conversion in the survey is likely too high. If we take the conservative assumption that none of the non-respondents were converted into AIS due to AISC, we get a conversion rate of 4 / 249 (1.6%).&nbsp;&nbsp;</p><p>Of all these estimates, the 7.9% figure seems like the most reasonable given the biases in survey data. Based on this, I estimate a 5\u201310% rate of conversion if AISC would be run as is (p=70%).</p><h3><strong>Dollar cost per new researcher produced by AISC</strong></h3><ul><li>The organizers have&nbsp;<a href=\"https://www.lesswrong.com/posts/ukCFkqiDFmkYTyywN/funding-case-ai-safety-camp-1#How_will_this_funding_be_used_\"><u>proposed</u></a> $60\u2013300K per year in expenses.&nbsp;</li><li>The number of non-RL participants of programs have increased from 32 (AISC4) to 130&nbsp; (AISC9). Let\u2019s assume roughly 100 participants in the program per year given the proposed size of new camps.</li><li>Researchers are produced at a rate of 5\u201310%.</li></ul><p>Optimistic estimate: $60K / (10% * 100) = $6K per new researcher</p><p>Middle estimate 1: $60K / (5% * 100) = $12K per new researcher</p><p>Middle estimate 2: $300K / (10% * 100) = $30K per new researcher</p><p>Pessimistic estimate: $300K / (5% * 100) = $60K per new researcher</p><h3><strong>Typical AIS researchers produced by AISC</strong></h3><p>Looking at the 5 survey respondents who claimed that AISC was pivotal to their move to AIS,&nbsp;<a href=\"https://scholar.google.com/citations?user=xC-v_aUAAAAJ&amp;hl=en&amp;oi=ao\"><u>Gavin Leech</u></a> (also co-founder of Arb research) is representative of a typical AIS researcher produced by AISC, he is currently a PhD in AI at the University of Bristol. The most impactful of these researchers appears to be&nbsp;<a href=\"https://www.linkedin.com/in/lucius-bushnaq-173139182/\"><u>Lucius Bushnaq</u></a>, who currently works as a research scientist at the safety organization Apollo Research.</p><p>Looking at the 8 studied individuals who plausibly changed their career trajectory towards AIS after attending AISC,&nbsp;<a href=\"https://scholar.google.com/citations?hl=en&amp;user=La75jqEAAAAJ\"><u>Fabien Roger</u></a>, now at Redwood Research, seems to be representative of the caliber of new AIS researchers produced. On the high end,&nbsp;<a href=\"https://scholar.google.com/citations?user=EZe6n8EAAAAJ&amp;hl=en\"><u>Alex Mallen</u></a>, now at EleutherAI, appears to be the most impactful researcher that plausibly had a trajectory change due to AISC.</p><p>Several other participants have gone on to have successful careers in AI safety, but it is likely that AISC played a smaller part in their career trajectory. These include&nbsp;<a href=\"https://www.linkedin.com/in/agentydragon/\"><u>Rai (Michael) Pokorny</u></a> who was a software engineer at Google before AISC and transitioned to the Superalignment team at OpenAI.&nbsp;</p><h3><strong>Dollar cost per new researcher produced by other means</strong></h3><p>When considering other ways to create AIS researchers, we can think of individuals following a sequence of steps (graduate school, research projects, etc.) to increase their ability and experience in AIS. People start with little experience in AIS and develop skills to become an established researcher. At any stage of researcher development there are two ways to encourage people to continue further on the path: pull mechanisms and push mechanisms.&nbsp;</p><p>Push mechanisms directly assist someone in completing a particular stage. This could be via education, financial support for upskilling, or assisting people with applications. On the other hand, pull mechanisms typically offer money or prizes to people who have completed a particular stage, which creates an incentive to complete that stage. For instance, offering high-paying positions to experienced AIS researchers creates an incentive to upskill in AIS research. Naturally, we would like to determine which approach is more cost effective at producing established AIS researchers.</p><p>We don\u2019t have comparable data for programs like MATS that \u201cpush\u201d new researchers into the field of AIS. However, one way to \u201cpull\u201d researchers into the field is by offering jobs in AIS positions. The annual salary for an AIS researcher ranges from $60K for a junior researcher working independently to $200\u2013300K base salary for a member of technical staff at various private organizations to $1M if equity at OpenAI/Anthropic is priced-in. In net present value terms, the cost to pull a new researcher into AIS is much higher than the cost to push one via AISC. For government funding sources, the cost to support a graduate student is roughly $60K per year (NSF GRFP offers a total of $53K per year, universities often provide additional funding) and AIS projects are roughly&nbsp;<a href=\"https://www.nsf.gov/pubs/2023/nsf23562/nsf23562.pdf\"><u>$2 million</u></a> per grant.</p><p>However most AIS research is funded by nonprofit entities. Assuming that the number of researchers is a bottleneck, what is the typical cost to \u201cpull\u201d a new researcher into AIS with non-profit grants such as LTFF? A&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/11aI3XNYKrf5LbYrHbQoq1_WcvCAY0P_9CCZIIn9k8Fo/edit?usp=sharing\"><u>rough calculation</u></a> on the LTFF database suggests that it costs $80K per year to fund an AIS researcher.&nbsp;</p><p>We can also examine the LTFF database for mention of researcher \u201cupskilling\u201d. The annualized average salary for grants that involve upskilling is $53K. Even making the optimistic assumption that every upskilling project creates a new AIS researcher that otherwise wouldn\u2019t have succeeded, AISC\u2019s cost per researcher compares favorably with this value.</p><p>Note that it is difficult to directly compare these estimates since they operate at different stages of researcher development. AISC typically operates earlier on the talent pipeline, while industry positions typically pull more experienced researchers into AIS positions.</p><h3><strong>Counterfactual analysis</strong></h3><p>Is a new researcher produced by AISC valuable relative to supporting existing projects? A organization considering funding AISC must choose between:</p><p>1. Funding an existing researcher for ~$80K for 1 year.</p><p>2. Funding the creation of a new AIS researcher for ~$40K.</p><p>In option 2, the new researcher then enters the pool of existing researchers, and may get support from academia, industry, or nonprofits. Alternatively, the funder that supported their transition to AIS also has the option of continuing to support their research.&nbsp;</p><p>If the new researcher is able to obtain outside funding from government or industry, then the organization has essentially obtained all of their subsequent research for \"free\". If the organization chooses to directly support the new researcher, then the net value depends on how much better their project is than the next-most-valuable project. Essentially, this is the marginal value of new projects in AI safety research, which may be high or low depending on your view of the field.</p><p>Regardless, a funder wishing to support AIS research may not value the creation of new AIS researchers if the number of researchers is not a bottleneck for the field. In AIS, there are many&nbsp;<a href=\"https://www.lesswrong.com/s/yivyHaCAmMJ3CqSyj\"><u>open questions</u></a> with no supported researchers working on them. This could indicate that there is either a bottleneck in the number of researchers or in the amount of funding in AI safety. If funding is the bottleneck then producing more researchers will not advance the field. More work is needed to distinguish these possibilities.</p><h1>Other impacts of AISC</h1><h2>Research outputs from AISC and follow-on research&nbsp;</h2><p>Dozens of projects were completed at camp. Paraphrasing their&nbsp;<a href=\"https://www.lesswrong.com/posts/ukCFkqiDFmkYTyywN/funding-case-ai-safety-camp-1#Track_record\"><u>funding case</u></a>, AISC organizers note that alumni authored several important publications such as:</p><p><a href=\"https://arxiv.org/abs/2105.14111\"><u>Goal Misgeneralization</u></a><a href=\"https://www.mdpi.com/2504-2289/3/2/26\">&nbsp;</a></p><p><a href=\"https://www.mdpi.com/2504-2289/3/2/26\"><u>AI Governance and the Policymaking Process</u></a></p><p><a href=\"https://ceur-ws.org/Vol-2419/paper_28.pdf\"><u>Detecting Spiky Corruption in Markov Decision Processes</u></a></p><p><a href=\"https://proceedings.neurips.cc/paper/2021/hash/b9ed18a301c9f3d183938c451fa183df-Abstract.html\"><u>RL in Newcomblike Environments</u></a></p><p><a href=\"https://link.springer.com/article/10.1007/s10458-022-09586-2\"><u>Using soft maximin for risk averse multi-objective decision-making</u></a></p><p><a href=\"https://openreview.net/forum?id=4eMzKmZ6xW\"><u>Reflection Mechanisms as an Alignment Target</u></a></p><p>Participants have been hired for dozens of positions in AIS organizations. Quoting the same funding case considering participants across all camps, the organizers list the following jobs:</p><p>\u201c<i>FHI</i> (1 job+4 scholars+2 interns),&nbsp;<i>GovAI</i> (2 jobs),&nbsp;<i>Cooperative AI&nbsp;</i>(1 job),&nbsp;<i>Center on Long-Term Risk</i> (1 job),&nbsp;<i>Future Society&nbsp;</i>(1 job),&nbsp;<i>FLI</i> (1 job),&nbsp;<i>MIRI</i> (1 intern),&nbsp;<i>CHAI</i> (2 interns),&nbsp;<i>DeepMind</i> (1 job+2 interns),&nbsp;<i>OpenAI</i> (1 job),&nbsp;<i>Anthropic</i> (1 contract),&nbsp;<i>Redwood</i> (2 jobs),&nbsp;<i>Conjecture</i> (3 jobs),&nbsp;<i>EleutherAI</i> (1 job),&nbsp;<i>Apart</i> (1 job),&nbsp;<i>Aligned AI</i> (1 job),&nbsp;<i>Leap Labs&nbsp;</i>(1 founder, 1 job),&nbsp;<i>Apollo</i> (2 founders, 4 jobs),&nbsp;<i>Arb</i> (2 founders),&nbsp;<i>AISS</i> (2 founders),&nbsp;<i>AISL</i> (2+ founders),&nbsp;<i>ACS</i> (2 founders),&nbsp;<i>ERO</i> (1 founder),&nbsp;<i>BlueDot</i> (1 founder)\u201d</p><p>Follow-on projects also gathered roughly $600K in outside grants with the median funded project receiving $20K in initial funding and some projects receiving over $100K.&nbsp;</p><p>Survey respondents also note several post-camp projects with collaborators from AISC including:&nbsp;<a href=\"https://www.apolloresearch.ai/\"><u>Apollo Research</u></a>,&nbsp;<a href=\"https://aisafetyfundamentals.com/\"><u>AI Safety Fundamentals</u></a>, and&nbsp;<a href=\"https://www.aistandardslab.org/\"><u>AI Standards Lab</u></a>. This last project is a direct result of work done during AISC.</p><h2>Network effects producing further AIS and non-AIS research</h2><p>AISC also introduced like-minded individuals to one another, leading to follow-on projects both within and outside of AIS. The median respondent has interacted with 5 members of AISC after camp, with several reporting 10\u201315 such interactions.</p><p>In terms of how many people a participant would feel comfortable reaching out to, the median respondent said 5, with several feeling comfortable contacting 10 or more people.&nbsp;</p><p>Beyond the follow-on research noted in the last section, two respondents mention new collaborations in AIS that were unrelated to their AISC project, but with people they met through AISC.</p><h2>AISC leading to future positions</h2><p>While it\u2019s not feasible to determine if a participant\u2019s AISC project led to them obtaining a new position in AI/AIS, we can examine a related question: did participants believe their project was substantial enough to include on applications to new jobs? In other words, did they believe that AISC provided a boost to their applications?</p><p>In our survey, 14 of 20 (70%) of participants listed their work with AISC on subsequent applications. Two of these 14 believe that their work at AISC was crucial to receiving AIS grants and safety-related jobs.</p><p>Additionally, 30% of respondents believed AISC greatly helped their career:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/CuPnmeS4v5sFE6nQj/ty34ljmwnuccicwggtu5\" alt=\"Forms response chart. Question title: How valuable was AISC for your career? . Number of responses: 23 responses.\">&nbsp;</p><p>5= Greatly helped my career, 1=Not valuable at all</p><h1>Other data</h1><h2>Fraction that pursue AIS</h2><p>Of the respondents, 17 / 24 (70.8%) work in AIS or have side projects in AIS.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/CuPnmeS4v5sFE6nQj/apf6n9uxwv0isegaur51\" alt=\"Forms response chart. Question title: Is your current work and/or side-projects&nbsp;related to AI safety?. Number of responses: 24 responses.\"></p><p>Looking at participants from camps 4-6, 67/101 (66.3%) have some sort of written work related to AI or AI safety (including posts on LessWrong), and of these, 48/101 (48.5%) have some publication in AI or AIS.</p><ul><li>8 surveyed were beginning their transition into AIS before camp, using camp to assist that transition.&nbsp;</li><li>1 surveyed left AIS for various reasons while 1 is still aspiring to work on AIS</li></ul><h2>In-camp experiences: summary of positive and negative experience<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/CuPnmeS4v5sFE6nQj/vumlbmirkupagiwnw9dx\" alt=\"Forms response chart. Question title: How valuable was AISC for developing research&nbsp;relevant skills and understanding AI safety?. Number of responses: 23 responses.\"></h2><p>5= Greatly helped my research skills, 1=Not valuable at all</p><p>Looking at the written responses, people generally had a positive experience of camp, appreciating the opportunity to work with like-minded individuals and have the support needed to start on an AIS project. Very few reported negative experiences from camp and these involved frustrations with project success and team organization.</p><h1>Conclusion</h1><h2>Our all-things-considered assessment</h2><p>Overall I (Sam) was surprised by the number of researchers who owed their position in AIS research to AISC. My expectation was that virtually all participants would be on a path to AIS without AISC and that evidence of a true trajectory change would be hard to find. However, there are several clear examples of individuals who changed their career trajectory towards AIS after camp and on surveys several respondents claim that this was directly because of AISC.</p><p>Programs like AISC and MATS have the effect of \u201cpushing\u201d new researchers into AIS which can be contrasted with programs like corporate, government, and nonprofit roles that \u201cpull\u201d new researchers in by offering funding. In other words, \u201cpush\u201d programs tend to support potential researchers by providing them the training and experience to take on roles in AIS research while \u201cpull\u201d programs create a financial incentive for people to take on these roles. These approaches are complementary. The effectiveness of spending on these \u201cpush\u201d programs depends on who bears the subsequent costs of supporting a new AIS researcher. If a researcher produced by AISC is able to draw subsequent funding from the government or industry for their work, their subsequent research has been obtained for \u201cfree\u201d since an organization only needs to pay the startup cost for creating that researcher.&nbsp;</p><p>However, if their subsequent funding comes from the same organization that activated them, then the organization must trade off between funding new researchers and funding more projects from established researchers. If an organization is funding constrained, it may be better to focus funds on established researchers. If an organization has much more funding than promising projects, producing new researchers may be more valuable.&nbsp;</p><p>Note that it\u2019s difficult to assess the quality of the marginal AIS research produced by these new researchers and this is compounded by the difficulty of assessing the value of a given work in AIS more generally.</p><p>I (Sam) would guess that producing more AIS researchers is more valuable to the field than giving more funding to established researchers, especially given the fact that new researchers can help with existing projects and can draw outside support to the field via corporate or government support for their research. The fact that creating a new researcher via AISC is comparable or smaller than the cost of an established researcher\u2019s annual salary, suggests that AISC is an effective way to boost AIS research.&nbsp;</p><h2>&nbsp;Areas for further research</h2><ol><li>Direct assessment of the quality of research produced at AISC</li><li>Assessment of research quality post-AISC</li><li>Better comparison to similar training programs like MATS. What counterfactual benefit does MATS provide for producing AIS researchers? At what cost?</li><li>Learning why some participants didn\u2019t transition into AIS. Did they lack interest? Did they miss a critical funding source? What could have been done better?</li></ol><h1>Appendix: Details on our approach</h1><h2>A model for the productivity of a research field</h2><p>Simple models of economic growth break innovation down into several inputs such as the number of researchers, the stock of ideas, and human capital. These models allow us to account for different sources of economic growth and suggest policies to boost growth.</p><p>Conceptually, these models of innovation can apply equally well to a single field and suggest a simple heuristic for that field\u2019s productivity:&nbsp;</p><p>Field productivity = (number of researchers) x (researcher effort) x (researcher productivity) x (researcher allocation)</p><p><strong>Number of Researchers&nbsp;</strong>is relatively straightforward, referring to the total number of individuals capable of participating in the field.&nbsp;<strong>Researcher effort</strong> is analogous to research intensity and accounts for things like the number of hours worked per week.&nbsp;<strong>Researcher productivity</strong> refers to the quality of work produced by a researcher in a unit of time, one could imagine that training and research experience contribute significantly to this factor.&nbsp;<strong>Researcher allocation&nbsp;</strong>refers to how effectively researchers are assigned to projects, having good signals of researcher skill and ensuring that available researchers have an assigned project would help lower misallocation. It\u2019s usually a factor that ranges from 0 to 1, with 1 denoting a perfect allocation of resources.</p><p>Crucially, note that only the number of researchers can increase without limit. There\u2019s a finite number of working hours each day, a maximum level of productivity, and the allocation factor reaches 1 in the best-case. This is analogous to growth models, where Chad Jones&nbsp;<a href=\"https://web.stanford.edu/~chadj/annualreview.pdf\"><u>notes</u></a>:</p><p>\u201cMany of the sources of growth that have been operating historically\u2014including rising educational attainment, rising research intensity, and declining misallocation\u2014are inherently limited and cannot go on forever. The key source of sustained growth in the semi-endogenous setting is population growth.\u201d</p><h2>AISC\u2019s impacts on the productivity of the AI Safety field</h2><p>Programs like AISC can plausibly have an impact on all of these factors:</p><ul><li>It can increase the number of researchers by giving people the training and background to do safety research.</li><li>It can increase researcher effort by providing the inspiration and community to work more hours per day. AISC temporarily increases working hours in AIS for the duration of the program.</li><li>It can boost researcher productivity by training students in effective research habits.</li><li>It can improve researcher allocation by providing subsequent funders with a signal of researcher quality and effectively allocates new researchers to projects.</li></ul><p>The relative value of these different contributions depends on how the camp is designed. Given the short duration of AISC, it probably can\u2019t change researcher effort, productivity, or allocation in the long term. These factors are also very difficult to measure, and will have to be ignored for the rest of this assessment.</p><p>However, AISC probably&nbsp;<i>does</i> have influence on the total number of AIS researchers, helping people break into the field. This \u201c0 to 1\u201d effect of creating/bringing new researchers is likely the largest impact of AISC.&nbsp;&nbsp;</p><p>As noted above, the other factors are bounded in size, meaning that raising the total number of researchers is one of the most important contributions to long-term productivity. For these reasons, we will focus on estimating the number of new AIS researchers AISC produces per unit of input.&nbsp;</p><h2>AISC\u2019s other impacts on AIS</h2><p>For completeness, AISC also has other direct impacts on the AIS field such as:</p><ol><li>Direct research outputs from AISC and follow-on research.</li><li>Network effects leading to further AIS and non-AIS research.</li><li>Network effects leading to future positions.</li></ol><p>We also attempt to quantify these impacts.</p><h2>Note on the difficulty of assessing research quality</h2><p>Assessing the value of a particular research work in AI Safety is very challenging. The alignment problem itself may not be solvable and even then, it\u2019s often not clear how much a particular work contributes to safety versus AI capabilities. For these reasons, we will avoid direct assessments of the quality of research produced during or after AISC, focusing instead on simpler (though flawed) metrics such as number of publications.</p>", "user": {"username": "Sam Holton"}}, {"_id": "KpGkgXFgQGBRfLQwy", "title": "[Linkpost] Jobs at the AI Safety Institute", "postedAt": "2024-01-19T16:39:59.055Z", "htmlBody": "<blockquote><p><a href=\"https://www.gov.uk/government/publications/ai-safety-institute-overview/introducing-the-ai-safety-institute\">The Institute </a>is the first state-backed organisation focused on advanced AI safety for the public interest. Its mission is to minimise surprise to the UK and humanity from rapid and unexpected advances in AI. It will work towards this by developing the sociotechnical infrastructure needed to understand the risks of advanced AI and enable its governance.&nbsp;&nbsp;</p></blockquote><p>&nbsp;</p><p>They're hiring for:</p><ul><li><a href=\"https://www.civilservicejobs.service.gov.uk/csr/jobs.cgi?jcode=1893870\">Research Engineers</a>&nbsp;</li><li><a href=\"https://www.civilservicejobs.service.gov.uk/csr/jobs.cgi?jcode=1893930\">Research Scientists&nbsp;</a></li><li><a href=\"https://www.civilservicejobs.service.gov.uk/csr/jobs.cgi?jcode=1893747\">Software Engineers</a></li><li><a href=\"https://www.civilservicejobs.service.gov.uk/csr/jobs.cgi?jcode=1893875\">Frontend Developers</a></li><li><a href=\"https://www.civilservicejobs.service.gov.uk/csr/jobs.cgi?jcode=1893866\">UX Engineers&nbsp;</a></li><li>Various senior roles: <a href=\"https://www.civilservicejobs.service.gov.uk/csr/jobs.cgi?jcode=1893847\">Cyber Misuse Lead</a>, <a href=\"https://www.civilservicejobs.service.gov.uk/csr/jobs.cgi?jcode=1893857\">Loss of Control Evals Lead</a>, <a href=\"https://www.civilservicejobs.service.gov.uk/csr/index.cgi?SID=c2VhcmNoc29ydD1zY29yZSZvd25lcnR5cGU9ZmFpciZqb2JsaXN0X3ZpZXdfdmFjPTE4OTM4NTMmdXNlcnNlYXJjaGNvbnRleHQ9NjUxNTQ5NjQmcGFnZWNsYXNzPUpvYnMmcGFnZWFjdGlvbj12aWV3dmFjYnlqb2JsaXN0JnNlYXJjaHBhZ2U9MSZvd25lcj01MDcwMDAwJnJlcXNpZz0xNzA1NDk4ODQ4LWI3OTBmZGZjNjM3NTIwY2IzMGRlOWZiZWIxZWVhNDMyNmRmOWI5MDI=\">Safeguard Analysis Lead</a>, <a href=\"https://www.civilservicejobs.service.gov.uk/csr/jobs.cgi?jcode=1893859\">Chief Information Security Officer</a>, and <a href=\"https://www.civilservicejobs.service.gov.uk/csr/jobs.cgi?jcode=1893933\">Head of Engineering</a></li></ul><p>It's generally exciting to see an AI safety org hiring for 20+ roles, but I was especially interested to see opportunities for technical people to do ML work that contributes directly to AI governance.&nbsp;</p>", "user": {"username": "Pseudaemonia"}}, {"_id": "QYXcubGHC4mRs9Yes", "title": "Seeking Volunteers for Analyzing Voting Data and Accessing Academic Articles", "postedAt": "2024-01-19T01:01:38.899Z", "htmlBody": "<p><br>As I'm taking on a book project on voting methods, I'm finding that I need volunteers for two tasks:</p><p><strong>Accessing Academic Articles:</strong> If you have access to academic journals and databases, your help in obtaining some hard-to-find articles would be invaluable. These are articles I can't get through my library or Sci-hub. A student would be great here.</p><p><strong>Analyzing Election Data:</strong> This involves calculating the Condorcet winner in a few elections and sorting ballot groupings so I can check the election for anomalies. This is a programming task that may involve data cleaning. There's likely code out there already to help make this easier. I'll also need to independently verify any computations.</p><p>I'll happily acknowledge volunteers in the book as a token of appreciation. This is a great chance to contribute to a project that aims to make voting theory more accessible and influence public understanding. I can also batch the work once a month to minimize volunteer time. So far, I only have two elections to analyze, but I'll probably find more.</p><p>Interested? Please reach out to me with a brief intro about yourself and your interest in the project.</p><p>Thanks!</p><p>Aaron</p>", "user": {"username": "aaronhamlin"}}, {"_id": "aWLXGW99GyhtjydyF", "title": "Manifund: 2023 in Review", "postedAt": "2024-01-18T23:50:12.350Z", "htmlBody": "<p>Manifund is a new funding org that experiments with systems and software to support awesome projects. In 2023, we built a website (<a href=\"http://manifund.org/\"><u>manifund.org</u></a>) and donor ecosystem supporting three main programs: impact certificates, regranting, and an open call for applications. We allocated $2m across dozens of charitable projects, primarily in AI safety and effective altruism cause areas. Here\u2019s a breakdown of what Manifund accomplished, our current strengths and weaknesses, and what we hope to achieve in the future.</p><p><i>If you like our work, please consider </i><a href=\"https://manifund.org/about/donate\"><i><u>donating to Manifund</u></i></a><i>. Donations help cover our salaries &amp; operating expenses, and fund projects and experiments that institutional donors aren\u2019t willing to back \u2014 often the ones that excite us most!</i></p><h1>At a glance</h1><p>Here are some high-level stats that provide a snapshot of our 2023 activities:</p><ul><li><strong>$2.06M sent to projects</strong>: $2.012M to grants &amp; $45K to impact certificates</li><li>Of the totals above, $95K that went to grants and $40K that went to certs came from unaffiliated donors/investors, rather than regrantors.</li><li><strong>88 projects</strong> were funded: 54 grants &amp; 34 certs</li><li><strong>$2.22M</strong> has been deposited into Manifund, and <strong>$1.62M</strong> has been withdrawn so far.</li><li>Below are the top cause areas of projects that got funded. Note that these are overlapping, that is, one project can be filed under multiple cause areas.<ul><li><strong>Technical AI Safety</strong>: 27 projects funded, $1.57M dispersed</li><li><strong>Science and Technology</strong>: 9 projects funded, $118K dispersed</li><li><strong>AI Governance</strong>: 10 projects funded, $112K dispersed</li><li><strong>Biosecurity</strong>: 4 projects funded, $97K dispersed</li><li>Honorable mention to <strong>Forecasting</strong>, which only received $76K total, but encompassed 35 projects. This is because our two biggest impact certificate rounds so far\u2014ACX Mini-Grants and the Manifold Community Fund\u2014were centered around forecasting and funded lots of small projects.</li></ul></li></ul><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f4874cc-0f37-47f1-8ec9-73d81391b6de_2000x1088.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/dvpdk1xpkibef7f5jksm\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/aubb7x64ilza2cop6431 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/xpvqeaiclsetxsgwoupk 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/aja6ap8ades2c5mwmbiy 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/dvpdk1xpkibef7f5jksm 1456w\"></a></p><p>&nbsp;</p><h1>2023 Programs</h1><h2>Impact certificates</h2><p><strong>Summary</strong>: Impact certificates are venture funding for charitable endeavors. Investors fund founders by buying shares (\u201dcerts\u201d) in their projects, which pay out if the project later receives a retroactive prize. See also <a href=\"https://manifund.org/about/impact-certificates\"><u>our</u></a> and <a href=\"https://www.astralcodexten.com/p/impact-markets-the-annoying-details\"><u>ACX\u2019s</u></a> explainers.</p><p><strong>Assessment</strong>: 7/10</p><p>Impact certs have been discussed as a much more efficient system of funding charitable projects. Luminaries such as <a href=\"https://impactpurchase.org/why-certificates/\"><u>Paul Christiano, Katja Grace</u></a>, <a href=\"https://medium.com/ethereum-optimism/retroactive-public-goods-funding-33c9b7d00f0c\"><u>Vitalik Buterin</u></a> and <a href=\"https://www.astralcodexten.com/p/impact-markets-the-annoying-details\"><u>Scott Alexander</u></a> have championed the idea, but apart from a <a href=\"https://impactpurchase.org/\"><u>few small</u></a> <a href=\"https://vitalik.ca/general/2021/11/16/retro1.html\"><u>experiments</u></a> with retroactive funding, no notable impact marketplaces existed prior to Manifund.</p><p>In 2023, we built out the website and operational experience to run impact certs end to end, from handling project submissions, to investments, to retroactive prize payouts. We completed 2 impact cert rounds and started 3 more, each testing different setups and domains.</p><p>How did we do? I would describe impact certs as \u201cworking as intended, but not yet hitting product/market fit\u201d. Some possible reasons:</p><p><strong>Impact certs are a 3-sided marketplace, and come with the implied cold start problems</strong>: we need to get a retro funder, investors, and founders all on board.</p><p>We think of the retro funder as the hardest part; they have to be convinced that it\u2019s worth paying out money for work already accomplished. Most donors instead think in terms of funding things prospectively.</p><p>But finding good investors is also not trivial! The investors\u2019 decisions shape which projects actually get underway; they serve the role of grant evaluators in a traditional charity ecosystems, which requires a particular skillset and dedication.</p><p><strong>A lot of education is needed to explain the whole system:</strong> it has a lot of moving parts, and most people are unfamiliar with the venture ecosystem.</p><p><strong>Feedback loops via impact certs are slow.</strong> Projects take a long time to develop; updates have been infrequent from all sides (founders, investors, and funders).</p><p><strong>In theory, impact certs should encourage investors to seek out good projects and help them, though this doesn\u2019t seem to have happened much.</strong> Perhaps this is due to small dollar amounts or us not having found expert investors to participate.</p><p>Despite these difficulties, I think impact certs are Manifund\u2019s most exciting project, with the potential to transform the entire landscape of charitable funding. The economic theory behind them is elegant, and recent successes with advance market commitments (Operation Warp Speed, Stripe Frontier) are waking people up to the idea that prize funding is a great way of encouraging public goods.</p><p>Here are some reflections, broken down by round.</p><p><a href=\"https://manifund.org/causes/acx-mini-grants\"><strong><u>ACX Forecasting Minigrants</u></strong></a>: 7/10</p><p><strong>Stats</strong>: $30k prize pool distributed to 20 projects, Jan to Oct 2023</p><p>See also: <a href=\"https://www.astralcodexten.com/p/announcing-forecasting-impact-mini\"><u>ACX announcement</u></a>, <a href=\"https://manifund.substack.com/p/acx-mini-grants-results\"><u>Manifund\u2019s retro,</u></a> <a href=\"https://www.astralcodexten.com/p/impact-market-mini-grants-results\"><u>ACX\u2019s retro</u></a></p><p>This was the project that kicked off Manifund! Scott approached us saying that he wanted to run ACX Grants 2 on impact certs, but (understandably) wanted to try a lower-stakes test first. We picked \u201cforecasting\u201d as an area that Scott felt qualified to judge as a retro funder; I brought on Rachel to work on Manifund fulltime, and together we shipped the MVP of the site in 2 weeks.</p><p>Lessons: Everything worked! We successfully created the world\u2019s first ecosystem around investing in charitable projects and retroactively funding them. I don\u2019t think projects produced were quite as good as those in the original ACX Grants round; not sure if that is due to impact certs, the much lower funding &amp; prize pool ($20-40k), more limited scope, or something else.</p><p><a href=\"https://manifund.org/causes/ai-worldviews\"><strong><u>OpenPhil AI Worldviews Essay Contest</u></strong></a>: 2/10</p><p><strong>Stats</strong>: 5 essays cert-ified, Feb to Sep 2023.</p><p>See also: OpenPhil\u2019s <a href=\"https://www.openphilanthropy.org/open-philanthropy-ai-worldviews-contest/\"><u>announcement</u></a>, <a href=\"https://www.openphilanthropy.org/research/announcing-the-winners-of-the-2023-open-philanthropy-ai-worldviews-contest/\"><u>results</u></a></p><p>This one was kind of a flop. We had launched ACX Minigrants and were waiting for results; we saw that OpenPhil had announced this contest and figured \u201c$225k for essays? Great fit for contestants trying to hedge some of their winnings\u201d. We reached out to Jason Schukraft, the contest organizer, and got his blessing \u2014 but unfortunately too late to secure an official partnership. We reached out to the essayists on our own, but most did not agree to create a Manifund impact cert (including none of the ultimate winners).</p><p>Lessons: large dollar prizes + well-known brand are not sufficient to get a robust cert ecosystem started. Unclear if \u201cessays\u201d are a compelling use case for impact certs, as the investment comes after all the work is done. On the plus side, this was a pretty cheap experiment to try, as all the infrastructure was already in place from the ACX Minigrants round.</p><p><a href=\"https://manifund.org/causes/china-talk\"><strong><u>Chinatalk Prediction Essay Contest</u></strong></a>: ongoing (Nov 2023 to Jan 2024)</p><p><strong>Stats</strong>: $6k prize pool; expecting 50-100 submissions.</p><p>See also: <a href=\"https://www.chinatalk.info/essay\"><u>Chinatalk\u2019s essay website</u></a></p><p>Chinatalk (a Manifund grantee) approached us to sponsor their essay contest; I saw this as a chance where we could try out \u201cimpact certs for essays\u201d, but this time with official partnership status. So far, Jordan and Caithrin have been amazing to work with; it remains to be seen if the added complexity of impact certs are worth the benefits of investor engagement.</p><p>As an aside: the Chinatalk contest makes me wonder if there\u2019s space for \u201chosting contests-as-a-service\u201d. There\u2019s proven demand and a lot of good work generated via contests and competitions (ACX Book Reviews; Vesuvius Prize; AIMO prize) but each of them jury-rig together websites &amp; infra. Manifund could become a platform that streamlines contest creation (think <a href=\"https://www.kaggle.com/\"><u>Kaggle</u></a> but for misc contests) and thereby fill in the \u201cretro funder\u201d part of the marketplace.</p><p><a href=\"https://manifund.org/causes/manifold-community\"><strong><u>Manifold Community Fund</u></strong></a>: ongoing (Dec 2023 to Feb 2024)</p><p><strong>Stats</strong>: $10k x3 prize payouts, ~20 projects proposed</p><p>See also: <a href=\"https://news.manifold.markets/p/manifolds-30k-community-fund\"><u>Manifold announcement</u></a></p><p>Partnering with other orgs has upsides (publicity, funding) but also downsides (higher communication costs and more negotiations). Could we move faster and experiment more by funding a prize round ourselves? We landed on \u201ccommunity projects for Manifold\u201d as an area we were experts in judging, and could justify spending money on to get good results.</p><p>We set up the MCF with 3 rounds of ~$10k in funding once per month, instead of a single prize payout at the end. My hope is that more frequent prize funding will provide better feedback to investors &amp; founders, and also teach us more about how to actually allocate retro funding, which is a surprisingly nontrivial problem!</p><p><strong>ACX Grants 2024</strong>: ongoing (Dec 2023 to Dec 2024)</p><p><strong>Stats</strong>: $300k+ prize pool; predict there will be 400-800 proposals, with 10-30 funded</p><p>See also: <a href=\"https://www.astralcodexten.com/p/apply-for-an-acx-grant-2024\"><u>ACX announcement</u></a></p><p>This will be our largest impact cert round so far. Some changes we made, compared to the previous ACX Minigrants:</p><p>Scott will be directly funding the proposals that he likes up front, instead of waiting to act as a retro funder. The other proposals may then be created as impact certificates.</p><p>We allow anyone to invest (via a donor-advised funds model) instead of restricting to accredited investors.</p><p>A group of EA funders have agreed to participate as retro funders (Survival and Flourishing Funds, EA Funds &amp; ACX). This is particular exciting, as the first test case of having multiple different final buyers of impact.</p><p>We\u2019re happy that Scott found the first round of our impact certs compelling enough to want to expand it into the next official round! ACX Grants is also especially dear to our hearts, as it was counterfactually responsible for getting Manifold off the ground; to have the opportunity to come and help future ACX Grantees is quite the privilege.</p><p><strong>Next steps for impact certs</strong></p><p>We\u2019d like to continue running impact cert rounds, in a more frequent, standardized manner (perhaps even self-serve). We\u2019d also like to find a large, splashy use case for impact certs, that draws more attention to the concept and validates that it works well at larger scales. This would likely involve partnering closely with some deep-pocketed funder who wants to put up a large prize for a specific cause.</p><p>Potential causes we\u2019ve been daydreaming about:</p><ul><li>Curing malaria (vaccine rollout? gene drives?)</li><li>Big, yearly AI Safety prize</li><li>Ending flu season in SF with FarUVC rollout</li><li><a href=\"https://sideways-view.com/2021/03/21/robust-egg-offsetting/\"><u>Offsets for factory farmed eggs</u></a></li><li>Carbon credits, similar to Stripe Climate</li><li>Political change (e.g. housing reform?)</li><li>General scientific research prizes in some weird field (eg longevity? fertility?)</li></ul><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2eacdc45-5290-40b1-a6ed-d5125249df8b_2000x2000.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/kebgua480x3cauxve8q9\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/ngt40afsfrixxh6dnczm 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/xjt5bdfox2mogruhcnks 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/coggmihafaypyi2n9ggg 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/kebgua480x3cauxve8q9 1456w\"></a></p><p>&nbsp;</p><h2>Regranting</h2><p><strong>Summary</strong>: A charitable donor delegates a grantmaking budget to individuals known as \u201cregrantors\u201d. Regrantors independently make grant decisions, based on the objectives of the original donor and their own expertise.</p><p><strong>Assessment</strong>: 7/10</p><p>Regranting was pioneered by the FTX Future Fund; among the grantmaking models they experimented with in 2022, they&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/paMYXYFYbbjpdjgbt/future-fund-june-2022-update#Expectations_vs__reality\"><u>considered regranting to be the most promising.</u></a> We believed that regranting is a good way of allocating funding for a few reasons:</p><p><strong>Faster turnaround times for grantees:</strong> Regrants involve lower overhead and less consensus, which leads to faster decisionmaking. Around the time we started this program, the EA funding space had just been severely disrupted by the collapse of FTX, which was making grant turn around times especially long. We had experienced this ourselves, as had many other people in our network, and this seemed like a problem we could help solve.</p><p><strong>More efficient funding allocation and active grantmaking:</strong> Regranting utilizes regrantors\u2019 knowledge and networks, which may lead to above the bar use of funding on the margin. They\u2019re often more connected to their grantees, which allows them to give more feedback or even initiate projects themselves, whereas most funders take a more passive approach.</p><p><strong>A better option for some donors:</strong> Delegating donations to regrantors is a unique donor experience, which offers a balance between maintaining control and minimizing effort relative to either directly giving to projects or giving to grantmaking organizations. Donors can pick individuals they trust to give intelligently and with their values in mind, but who may be better able to allocate the money as efficiently as possible due to some combination of time, expertise, and connections.</p><p><strong>Scalable:</strong> Regranting can scale up to moving large amounts of funding. This was a clear upside for the Future Fund, which was aiming to distribute 100M to 1B+ a year, though is less important for us now, as Manifund (and EA as a whole) are more funding constrained now.</p><h3><strong>Large regrantors</strong></h3><p><strong>Stats</strong>: 5 regrantors with max budgets of ~$400k each, $1.4m total pool. 5 grants initiated, 15 grants supported.</p><p><strong>Assessment:</strong> 7/10</p><p><i>See also: </i><a href=\"https://manifund.substack.com/p/announcing-manifund-regrants\"><i><u>regranting launch announcement</u></i></a></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F232022b1-abd0-4408-a5be-25ae94798835_2000x1333.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/z7wuveq2uorot8dhxqyu\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/kzgrlhtjilgmgv65v5rb 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/u2nbvfyeqo3hnhiezbej 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/upurwncx02twgsfhuygq 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/z7wuveq2uorot8dhxqyu 1456w\"></a></p><p>&nbsp;</p><p>We decided to do a regranting program after we were introduced to an anonymous donor, \u201cD\u201d, in May 2023. D liked Future Fund\u2019s regranting setup, and wanted to fund their own regrantors, to the tune of $1.5m dollars across this year. This seemed like a good fit for Manifund to run, as:</p><p>We had already built a lot of the necessary infrastructure for ACX Minigrants\u2014a website, 501c3 org, and payout processes\u2014and we could reuse these for regranting.</p><p>We\u2019d been beneficiaries of the regranting mechanism ourselves: Manifold\u2019s seed round was initiated by an offer from a Future Fund regrantor.</p><p>We thought we could give our grantees a better experience, with faster turnaround times and more involved grantmakers.</p><p>We thought that by supporting regrantors and their grantees now, we could later convince them to participate in impact certs as investors &amp; founders.</p><p>We were in a lull anyways, waiting for ACX Minigrants projects to wrap up.</p><p>We\u2019re reasonably happy with the quality of grants made! At a midpoint review in September, our donor D\u2019s judgement was that the regrants made were somewhat better than initially expected. They were open to renewing the program for next year, pending other considerations.</p><p>We do wish that we\u2019d gotten more consistent active participation from the large regrantors. Relative to the small regrantors, they tended to make fewer grants and engage in less coordination and discussion with other regrantors\u2026 which is understandable! D chose a bunch of very well-credentialed folks with great judgement, but it turns out such people are pretty busy or in high demand, and $400k is not a large enough budget to warrant spending significant amounts of time doing active grantmaking.</p><p>We had one notable exception to this pattern: Evan Hubinger was very prolific and dedicated, making 9 different grants to projects in technical AI safety. We ended up increasing his budget to encourage him to continue finding good opportunities.</p><p>Still, until the last couple weeks of the year, it looked like a large portion of the large regrantor pot would be left unspent, but then Dan, Evan, and Adam came through with some last minute recommendations and made use of their remaining budgets.</p><p>While we\u2019re glad all of the money was sent to projects, this end of year influx wasn\u2019t ideal. First, it\u2019s unlikely that the best opportunities just happened to come along suddenly at the end of the year, which means something inefficient was going on. It seems more likely that they could have given to marginally better projects earlier in the year, or they could have given to these projects earlier. This is informative for how we set up budgets if we do this again, so we don\u2019t incentivize waiting until a week before the expiration date to spend budgets.</p><p>Additionally, because we didn\u2019t anticipate this influx, the regrantors offered more in funding than we had budget for, and we had to reject two grant recommendations that at other times we would have approved. This possibly created false expectations and a pretty bad experience for these two grantees, for which we are quite sorry.</p><p><strong>Highlighted grants</strong></p><p><a href=\"https://manifund.org/evhub\"><u>Evan Hubinger</u></a>, $100k: <a href=\"https://manifund.org/projects/scoping-developmental-interpretability-xg55b33wsfc\"><u>Scoping Developmental Interperetability</u></a></p><p>This also got donations from Marcus, Ryan, and Rachel, though all after Evan\u2019s initial contribution and recommendation.</p><p>This was an example of regrantors using their professional connections to find opportunities and that they had a lot of context on: Evan previously mentored Jesse, the recipient of this grant, and is familiar with the work of others on the team. With this all of this context, he said he \u201cbelieve[s] them to be quite capable of tackling this problem\u201d.</p><p><a href=\"https://manifund.org/AdamGleave\"><u>Adam Gleave</u></a>, $10.5k: <a href=\"https://manifund.org/projects/introductory-resources-for-singular-learning-theory\"><u>Introductory resources for Singular Learning Theory</u></a></p><p>According to Adam, \u201cThere's been an explosion of interest in Singular Learning Theory lately in the alignment community, and good introductory resources could save people a lot of time. A scholarly literature review also has the benefit of making this area more accessible to the ML research community more broadly. Matthew seems well placed to conduct this, having already familiarized himself with the field during his MS thesis and collected a database of papers. He also has extensive teaching experience and experience writing publications aimed at the ML research community.\u201d I\u2019ll note that Evan also expressed excitement about Singular Learning Theory in his writeup for the above grant.</p><p>Like the above grant, this was an opportunity that Adam came across and could evaluate with lots of context as he previously mentored Matthew and continues to collaborate with him.</p><p><a href=\"https://manifund.org/LeopoldAschenbrenner\"><u>Leopold Aschenbrenner</u></a>, $400k: <a href=\"https://manifund.org/projects/compute-funding-for-seri-mats-llm-alignment-research\"><u>Compute and other expenses for LLM alignment research</u></a></p><p>From Leopold\u2019s comment explaining why he chose to give this grant: \u201dEthan Perez is a kickass researcher whom I really respect, and he also just seems very competent at getting things done. He is mentoring these projects, and these are worthwhile empirical research directions in my opinion. The MATs scholars are probably pretty junior, so a lot of the impact might be upskilling, but Ethan also seems really bullish on the projects, which I put a lot of weight on. I'm excited to see more external empirical alignment research like this!</p><p>Ethan reached out to me a couple days ago saying they were majorly bottlenecked on compute/API credits; it seemed really high-value to unblock them, and high-value to unblock them quickly. I'm really excited that Manifund regranting exists for this purpose!\u201d</p><p>Leopold started with a donation of $200k, and then followed it up with another $200k two months later after seeing the progress they\u2019d made and learning they were still funding constrained.</p><h3><strong>Small regrantors</strong></h3><p><strong>Stats</strong>: 11 regrantors with budgets of ~$50k each, $400k total pool. 11 grants initiated, 41 grants supported.</p><p><strong>Assessment</strong>: 8/10</p><p><i>See also: </i><a href=\"https://forum.effectivealtruism.org/posts/LqMiyLTy7gZ6vbWoo/some-fun-lessons-i-learned-as-a-junior-regrantor#comments\"><i><u>Joel Becker\u2019s reflections as a regrantor</u></i></a></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06429050-1866-4814-8395-14b0b7cf6083_2000x2674.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/kzlbrnlutarhijpomhhk\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/becmvqxlngfoxdezxw0o 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/frl3a718xnbmqwoy1kwu 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/dxkur2wz4e7o8fbegfkb 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/kzlbrnlutarhijpomhhk 1456w\"></a></p><p>&nbsp;</p><p>After planning out the regranting program with D, we thought that 5 regrantors weren\u2019t enough and that increasing the size of the regrantor cohort would be good for fostering more regrantor discussion and broadening the kinds of grants made. We decided to fund this from our own budget, primarily out of our general support grant from the <a href=\"https://survivalandflourishing.fund/sff-2023-h1-recommendations\"><u>Survival and Flourishing Funds</u></a>.</p><p>One main benefit of choosing our own regrantors was that we could bet on unconventional candidates. As a variant on \u201c<a href=\"https://www.openphilanthropy.org/research/hits-based-giving/\"><u>hits-based giving</u></a>\u201d, we were \u201chits-based delegating\u201d, giving budgets to wide variety of people, including many with little-to-no previous track record of grantmaking.</p><p>The small regrantor program is one of the places where Manifund\u2019s experimentation has been most successful, in our opinion. Some of our regrantors have gone above and beyond, in their commitment to initiating good grants and helping grantees. After launching with our initial cohort, we opened up an application for regrantors and got very high-quality applicants. We approved Ryan Kidd, Renan Araujo, Joel Becker, Nuno Sempere and waitlisted many more promising regrantor candidates. We also had some regrantors who weren\u2019t active or decided to withdraw which is fine \u2014 we were expecting this and structured the regrantor budget allocation with this in mind.</p><p>We thought that good grants made by our regrantors would encourage other people to donate to regrantor budgets. This doesn\u2019t seem to have happened much; among donations made by individuals on Manifund, very little went towards regrantor budgets relative to specific projects listed via the open call. To that end, fundraising for our regrantors remains our main constraint on operating this program.</p><p><strong>Highlighted grants</strong></p><p><a href=\"https://manifund.org/joel_bkr\"><u>Joel Becker</u></a>, $1.5K &amp; <a href=\"https://manifund.org/RenanAraujo\"><u>Renan Araujo</u></a>, $1.5K: <a href=\"https://manifund.org/projects/explainer-and-analysis-of-cncertcc-\"><u>Explainer and analysis of CNCERT/CC (\u56fd\u5bb6\u4e92\u8054\u7f51\u5e94\u6025\u4e2d\u5fc3)</u></a></p><p>Joel\u2019s explanation of the origin of this grant: \u201cRenan and I put out a call to an invite-only scholarship program, the \"Aurora Scholarship,\" to 9 individuals recommended by a source we trust. We were aiming to support people who are nationals of or have lived in China with a $2,400-$4,800 scholarship for a research project in a topic related to technical AI safety or AI governance\u2026Alexa was one of our excellent applicants.\u201d</p><p>Empowering people in or with connections to China to do AI safety work seems pretty important. We were particularly impressed by the initiative Joel and Renan took in getting this off the ground\u2014the prospect of facilitating active grantmaking like this is part of what motivated us to start the regranting program!</p><p><a href=\"https://manifund.org/GavrielK\"><u>Gavriel Kleinwaks</u></a>, $41.7K: <a href=\"https://manifund.org/projects/optimizing-clinical-metagenomics-and-far-uvc-implementation\"><u>Optimizing clinical Metagenomics and Far-UVC implementation</u></a></p><p>Gavriel works at One Day Sooner, and is our only biosecurity-focused regrantor, and inline with this grant, her work has been focused on Far-UVC implementation! Here are some quotes from Gavriel\u2019s writeup explaining why she chose this project:</p><p>\u201cFrom my conversation with Miti and Ale\u0161, it sounded as though there was a pretty good chance to unlock UK government buy-in for an important biosecurity apparatus, through the relatively inexpensive/short-term investment of a proposal submitted to the government. Biosecurity doesn\u2019t have a lot of opportunities for cheap wins as far as I normally see, so this is really exciting.\u201d</p><p>\u201cThis is exactly the type of project Manifund is best poised to serve: the turnaround needs to be really fast, since Miti is targeting an October deadline, and it\u2019s for a small enough amount that at my $50k regranting budget I can fully fund it.\u201d</p><p>Shout out to Joel again who recommended this grant to Gavriel! Because of a COI with the recipient, he didn\u2019t contribute financially, but he still deserves a lot of credit for making this happen.</p><p><a href=\"https://manifund.org/MarcusAbramovitch\"><u>Marcus Abramovitch</u></a>, $25K: <a href=\"https://manifund.org/projects/independent-researcher\"><u>Joseph Bloom - Independent AI Safety Research</u></a></p><p>Joseph Bloom had a strong track record with independent AI safety research\u2014he maintains TransformerLens (the top package for mechanistic interperetability), his work has been listed by Anthropic, he teaches at the ARENA program, and he came highly recommended from Neel Nanda. Unsurprisingly, he seems to have lived up to this track record and made good progress on his research according to the updates he sends Marcus each month.</p><p>This also received the biggest independent donation of any project on Manifund: $25k from Dylan Mavrides!</p><h2>Open Call</h2><p><strong>Summary</strong>: \u201cKickstarter for charitable projects\u201d: allow anyone to post a public grant proposal on the Manifund site, for regrantors and the general public to fund</p><p><strong>Assessment:</strong> 6/10</p><p><strong>Stats:</strong> 150 projects submitted, $95k raised among 40 individual donors</p><p>We started our open call to identify more opportunities for our regrantors to donate to. The open call worked well for this: it has surfaced many projects that we wouldn\u2019t have seen otherwise. For example, I (Austin) allocated half of my own regrantor budget to projects that applied via the open call: Lantern Bioworks, Sophia Pung, Neuronpedia, and Holly Elmore.</p><p>To our surprise, many open call projects got support from individual donors that we had no pre-existing relationships with. We had about forty people donate this way, for a total of $95k.</p><p>Shout out to our top 10 individual donors of 2023.</p><ul><li>Dylan M - $25,000</li><li>Jalex S - $20,000</li><li>Anton M - $11,530</li><li>Vincent W - $10,500</li><li>Cullen O - $8,710</li><li>Carson G - $6,000</li><li>Peter W - $5,000</li><li>Gavin L - $5,000</li><li>Nik S - $5,000</li><li>Adrian K - $4,000</li></ul><p>There were still some downsides associated with this program. The biggest is that an always-open call takes up a constant amount of toil on our team to screen and process grants. Many projects that ask for funding don\u2019t seem impactful or look like bad fits for Manifund. Finally, it seems like regrantors generally prefer to spend their budgets on projects they personally initiate.</p><p><strong>Highlighted grants</strong></p><p><a href=\"https://manifund.org/projects/mats-funding?tab=donations\"><u>MATS Funding</u></a></p><p>This received a total of $190K from 8 different sources, including 6 donors and 2 regrantors.</p><p>I (Rachel) am a big fan of MATS, as it seems are lots of people. Insofar as AI safety is talent constrained rather than funding constrained, programs like MATS are great way of converting abundant resources into more scarce and valuable ones, i.e. good technical AI safety researchers. MATS specifically occupies one of the hardest parts of that pipeline and does a great job. Many of their alums go onto work on the safety teams of the most important players in AI, like Anthropic and OpenAI, and it seems our two regrantors from Anthropic\u2014Tristan Hume and Evan Hubinger\u2014are both willing to pay for the talent that MATS brings to their company and field.</p><p>Tristan Hume explained his decision to direct $150k to MATS: \u201dI've been very impressed with the MATS program. Lots of impressive people have gotten into and connected through their program and when I've visited I've been impressed with the caliber of people I met.</p><p>An example is Marius Hobbhahn doing interpretability research during MATS that helped inform the Anthropic interpretability team's strategy, and then Marius going on to co-found Apollo.\u201d (n.b. Apollo Research is also a Manifund grantee!)</p><p><a href=\"https://manifund.org/projects/experiments-to-test-ea--longtermist-framings-and-branding\"><u>Experiments to test EA / longtermist framings and branding</u></a></p><p>This received a total of $26.8K from 5 different sources, including 3 donors and 2 regrantors.</p><p>From Marcus\u2019 comment explaining why he decided to contribute: \u201cWe just need to know this or have some idea of it (continuous work should be done here almost certainly). Hard to believe nobody has done this yet.\u201d</p><p>Other comments from donors each expressed a similar sentiment: this is simply a really important question and people are curious to see the results!</p><p><a href=\"https://manifund.org/projects/recreate-the-cavity-preventing-gmo-bacteria-bcs3-l1-from-precursor-\"><u>Recreate the cavity-preventing GMO bacteria BCS3-L1 from precursor</u></a></p><p>This received a total of $40.6K from 10 different sources, including 8 donors and 2 regrantors. As Lantern Bioworks is a for-profit company, this was structured as a SAFE investment as part of their seed round, rather than a donation.</p><p>This project is simply very cool. Since receiving the Manifund investment, they\u2019ve successfully gotten hold of this bacteria and started administering it (including to us, COI disclosure). Now they are focused on selling their probiotic more widely, and remain on a good path to succeeding at their ultimate goal of curing all cavities forever.</p><p>See also: <a href=\"https://www.astralcodexten.com/p/defying-cavity-lantern-bioworks-faq\"><u>ACX writeup</u></a> and their launched product, <a href=\"https://www.luminaprobiotic.com/\"><u>Lumina</u></a></p><h2>Manifold Charity Program</h2><p><strong>Summary</strong>: Allow people to donate their Manifold mana to charities of their choice.</p><p><strong>Assessment</strong>: 4/10</p><p>See also: Donations on the <a href=\"https://manifold.markets/charity\"><u>charity page</u></a></p><p>This was actually the original reason Manifold created a 501c3, back in 2022. We raised $500k from Future Fund as seed funding, to distribute to other charities; the idea was to provide some backing value for Manifold mana, and put donation decisions in the hands of our best traders.</p><p>Manifold users like that this exists. They mention that they buy into mana with the idea that they can donate it later. When Stripe <a href=\"https://news.manifold.markets/p/above-the-fold-donate-before-march\"><u>initially asked us to discontinue this program</u></a>, many of our users were vocally unhappy at this.</p><p>It also provides a cleaner story for why people participate on Manifold. Predictions markets are sometimes negatively viewed as \u201cgambling\u201d, and \u201cgambling for fake money\u201d is even less understandable, whereas \u201cgambling for charity\u201d is easier to explain and wholesome.</p><p>This program is currently in maintenance mode, from the perspective of Manifund. We\u2019re continuing to administer it, but it\u2019s not an area we\u2019re trying to improve upon. We\u2019ll revisit this as part of Manifold\u2019s monetization goals in 2024. For now, it\u2019s being capped at $10k/mo (<a href=\"https://www.notion.so/The-New-Deal-for-Manifold-s-Charity-Program-1527421b89224370a30dc1c7820c23ec?pvs=21\"><u>The New Deal for Manifold\u2019s Charity Program</u></a>)</p><p>There are many potential areas of improvement to this that we could invest in:</p><ul><li>Make donating more of a social experience</li><li>Support donations to any charity, make it more self-serve</li><li>Transfer responsibility for program administration fully into Manifund</li><li>Run matching programs to encourage more user donations</li><li>Partner with charities</li></ul><h2><a href=\"http://leaf-board.org/\"><u>leaf-board.org</u></a>: EA Funds\u2019s grantee portal</h2><p><strong>Summary</strong>: Rachel built a dashboard for EA Funds grantees, which reads from the EA Funds system and tells applicants about their status in the grantee pipeline.</p><p><strong>Assessment</strong>: 7/10</p><p>Here\u2019s <a href=\"https://leaf-board.org/recJxkz7MnnJdgF9V\"><u>Manifold\u2019s grantee page</u></a> as an example:</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6b353bf-6c7e-44f9-b82b-f2a99e558859_2000x1135.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/uucfjczu70uxvthjlhpb\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/rugemkmiuzfe8wqevbe1 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/hwlli4ayvmkro5n5dots 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/qfmki4fxfmvitjgmlbje 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/uucfjczu70uxvthjlhpb 1456w\"></a></p><p>&nbsp;</p><p>This was a test of increased collaboration between Manifund and EA Funds, as our two orgs have a lot of overlap in cause alignment, check size, and org size. Beyond building this dashboard, we discussed many other options for collaborating as well, which may bear fruit down the line, such as creating a \u201ccommon app\u201d for EA, sharing notes on grantees, or merging our financial operations. Building this was also an experiment into \u201cwhat if Manifund acted as a software consultancy, increasing the quality waterline of software in EA\u201d. We proved that we could quickly deliver high-quality websites\u2014Rachel shipped the entire site from scratch in &lt;2 weeks.</p><h1>Other stuff we tried</h1><p>Beyond impact certs and regranting, we\u2019ve experimented with other financial mechanisms to assist with charitable endeavors. Some of the weirder things:</p><p>Did you know that nonprofits can make loans? We\u2019ve loaned out $300k twice, to two orgs who we felt aligned with and had a compelling pitch for how they would use the funds: <a href=\"https://manifold.markets/Austin/will-lightcone-repay-their-300k-loa\"><u>Lightcone Infrastructure</u></a>, and <a href=\"https://manifold.markets/Austin/if-manifund-loans-250k-to-marcusabr\"><u>Marcus Abramovitch\u2019s trading firm AltX</u></a>. In both cases, we earned a nice return on investment for ourselves, while helping out other organizations in our network.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2691220-9653-49db-9f97-b7e6bf204b49_2000x1215.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/ponx9q0sensigpfrfwax\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/nw0gril45vs0unjpghst 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/ne67zrhpfvvrnbespjzm 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/pcbrjbzpjsff7uesujql 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/ponx9q0sensigpfrfwax 1456w\"></a></p><p>&nbsp;</p><p><i>Though the market seemed to think this was a bad idea\u2026</i></p><p>Did you know that nonprofits can make investments? We put in $40k as a SAFE into Lantern Bioworks, through Austin and Isaac\u2019s regrantor budgets. We have a soft spot for venture investments made through nonprofits; Manifold Markets started our seed round with a large investment from the Future Fund.</p><p>Here are some other mechanisms that have caught our eye, as things to experiment with:</p><ul><li>Income share agreements, as a replacement for \u201cupskilling grants\u201d</li><li>Dominant Assurance Contracts, as a partial solution to public goods funding problems and a nice addition to our crowdfunding ecosystem</li><li>Quadratic funding and the S-process, as potential ways of calculating how much to allocate to retroactive payouts</li></ul><h1>What we were happy with in 2023</h1><p><strong>The core Manifund product: UI and grantee experience</strong></p><p>This year, we built a website and entire funding ecosystem from scratch, which has moved about 2 million dollars to projects to date. Our two main areas of focus were building out novel funding mechanisms and delivering a good grantee experience, and we feel we\u2019ve succeeded at both.</p><p>Manifund supports regranting, crowdfunding, and impact certificates. We\u2019re the first site ever to support trading impact certificates \u2014 we think this represents a huge step forward, experimentally testing out an idea that\u2019s been discussed for a while.</p><p>We also think it\u2019s nicer to be a Manifund grantee than a grantee of some other orgs in the EA space: our grantees get their money faster, receive more feedback on their projects, and have an easier time communicating with us and their grantmakers.</p><p><strong>Transparency &amp; openness</strong></p><p>Our initial thesis was that grant applications and screening largely can be done in public, and should be. We followed through on trying this out, and feel it went very well.</p><p>We\u2019ve formed the largest database of public EA grant applications, as far as we know. Whereas every other application process and review happens over private writeups, Manifund enables these applications to be proposed and discussed on the public internet, including comments and feedback from grantmakers and others.</p><p>We think that more more transparency in funding is a public good. For most people in EA, it\u2019s something of a mystery how funding decisions get made, which can be frustrating and confusing. Manifund makes the thought processes of grantmakers less mysterious.</p><p>Grantees also seem to appreciate the open discussion. From Brian Wang, discussing details about their proposal for \u201c<a href=\"https://manifund.org/projects/design-and-testing-of-broad-spectrum-antivirals\"><u>Design and testing of broad-spectrum antivirals</u></a>\u201d with regrantor Joel Becker:</p><blockquote><p>it\u2019s been a breath of fresh air to be able to have this real-time, interactive discussion on a funding request, so props to Manifund for enabling this!</p></blockquote><p>Finally, having applications in public has given projects greater exposure. Ryan Kidd told us that someone got in touch about funding SERI MATS after seeing the Manifund post\u2014not to mention all of the proposals posted via open call that were supported directly by small donors who just saw them on our website. As another example of the benefits of transparent grant applications: Lantern Bioworks\u2019s <a href=\"https://manifund.org/projects/recreate-the-cavity-preventing-gmo-bacteria-bcs3-l1-from-precursor-\"><u>Manifund proposal to cure cavities</u></a> got to <a href=\"https://news.ycombinator.com/item?id=36702911\"><u>#1 on Hacker News</u></a>, helping them share their plan widely when they were at a very early stage.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5d83e55-9125-45f5-b60d-4fa2e42e6c51_2000x477.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/asndtzlqqsjrm4wnkxim\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/jnmhchdue6ezo9gbmv1u 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/e4iqxmhfmbqfbmwys0du 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/onukzkt2mvpmb8kfi2zc 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aWLXGW99GyhtjydyF/asndtzlqqsjrm4wnkxim 1456w\"></a></p><p><strong>Quality of projects we\u2019ve been supporting</strong></p><p>This is both one of the most important metrics of success, and one of the hardest to evaluate. Part of the point of regranting is that the regrantors know more about their fields than we or our donor do\u2014that\u2019s the point of outsourcing the decisions to them! This means both that they make better decisions than we could, and that it\u2019s really hard for us to make judgements about their decisions since they were based on expertise we don\u2019t have.</p><p>All that aside, the quality generally seemed pretty high to us. Almost all grants were at least one of: evaluated by someone with special context on the team or the work which we feel comfortable deferring to, counterfactual or counterfactually fast when it was important, or an obviously positive grant of the type e.g. LTFF would make.</p><p>We\u2019d be very curious to hear other people\u2019s thoughts on whether this assessment seems accurate!</p><p><strong>Coordination with other EA funders</strong></p><p>Because the funding space is pretty fragmented, it seems like there\u2019s a lot to be gained from a little bit of coordination. In our observation, EA funders rarely sync up, even on basic questions like \u201care you also planning on funding this project?\u201d or \u201cwhat are your plans for this quarter?\u201d. We wanted to combat this and have worked closely with a handful of other orgs, and we\u2019re happy with the value we\u2019ve provided to them. These collaborations include:</p><p><strong>Astral Codex Ten:</strong> we provided a polished website, fiscal sponsorship, and payout support for ACX Mini-Grants and ACX Grants 2024.</p><p><strong>EA Funds:</strong> we built a dashboard to improve their grantee experience.</p><p><strong>Lightcone:</strong> we gave them a fast loan when they were temporarily liquidity-constrained.</p><p>And we\u2019ll be working more with the Long-Term Future Fund and the Survival and Flourishing Fund, as they\u2019ve agreed to be retroactive funders for ACX Grants 2024.</p><h1>Areas for improvement for 2024</h1><p><strong>Fundraising</strong></p><p>We haven\u2019t raised much for Manifund\u2019s core operations or our programs. Our successful attempts include the grant from the Survival and Flourishing Fund, the grant from the Future Fund, the donation from D, and the many small donations from individuals through the site. Unsuccessful attempts include our pitches to <a href=\"https://manifoldmarkets.notion.site/OpenPhil-Grant-Application-3c226068c3ae45eaaf4e6afd7d1763bc?pvs=4\"><u>OpenPhil</u></a>, <a href=\"https://manifoldmarkets.notion.site/Lightspeed-Grant-app-Jul-2023-7ce8b43ab15c40d7a2096b660c0beb4e?pvs=4\"><u>Lightspeed</u></a> (for regranting), and <a href=\"https://manifoldmarkets.notion.site/YC-W24-Application-Manifund-b39634e841b84fb48c71b26bd6a0fd01?pvs=4\"><u>YCombinator</u></a> (for impact certs).</p><p>We\u2019ve been saying for a while that we\u2019d like to find donors outside of traditional EA sources, though we haven\u2019t followed through on giving this a serious try. Ideally, the Manifund product would appeal to \u201ctech founder\u201d or \u201cquant trader\u201d types, as a place where they can direct their money to charity in more efficient and aligned ways, but we\u2019ve made few inroads into this demographic.</p><p><strong>Hiring</strong></p><p>Currently, Manifund consists of Rachel working fulltime and Austin working about halftime. On one hand, we think our output per FTE is pretty impressive! On the other, 1.5 FTE is not really that much for all the things we want to accomplish. We\u2019re open to bringing on:</p><p>A fullstack software engineer, to build out new features and generally improve the site</p><p>A strategy/ops role, to lead one of our main programs (regranting, impact certs, the open call) via fundraising, partnerships &amp; communications</p><p>On the other hand, as a nonprofit startup seeking product-market-fit, we don\u2019t want to overhire, either.</p><p>We\u2019d also like to improve our nonprofit board. Our board currently consists of me (Austin Chen), Barak Gila, and Vishal Maini; Barak and Vishal signed on when Manifund was just running the Manifold Charity program. As we expand our operations, I\u2019d like to bring on board members with connections and expertise in the areas we\u2019re trying to grow into.</p><p><strong>Community engagement</strong></p><p>Unlike Manifold, Manifund doesn\u2019t have much of a community of its own. People don\u2019t spend their free time on Manifund, or chat with each other for fun on our Discord. I tentatively think this could be a major area of improvement.</p><p>In the early days, \u201cforecasters hanging out\u201d was a big part of making the Manifold community feel like a live, exciting place to talk with each other. Community was a key part of Manifold\u2019s viral loops: people would create interesting prediction market questions, then share it outside of the site. Manifund is missing a similarly powerful viral loop.</p><p>Maybe it\u2019s hard to replicate the Manifold community because Manifund feels more transactional. The nature of evaluating grant opportunities might make things seem less fun and more \u201clet\u2019s get down to business\u201d. Or perhaps working with real money feels inherently more serious, compared with Manifold\u2019s fake money.</p><p>The closest thing we\u2019ve had to a lively community was the regrantors channel in the first couple of months of the regranting program, though the amount of collaboration and evaluation through discussion has tapered off. Still, it points to the possibility of creating a strong community among grantmakers or perhaps donors.</p><p><strong>Amount we help our grantees</strong></p><p>Part of the motivation for Manifund was based on having participated in the existing funding ecosystem, feeling the grantee experience was quite lacking, and thinking \u201chuh, surely we could do better than that\u2026\u201d</p><p>While we think we\u2019ve done a lot better on turn around times, we\u2019ve only done slightly better at grantee feedback. When making grants, our regrantors are encouraged to write comments about why they chose to give the grant, and in general our comment section can facilitate conversations between any user and the applicant. However, as far as we can tell, once the grant is made, there isn\u2019t much more interaction between grantees and grantmakers, or founders and investors in the case of certs, and Manifund the organization doesn\u2019t provide any further support either.</p><p>One possible mission for Manifund would be to achieve YCombinator-levels of support for our project creators. We could nudge regrantors to stay in close contact with their grantees, like by suggesting they check in every month and see where grantees need help. We could aim to run our own batch for incubating projects at Manifund (as in YC or Charity Entrepreneurship), and facilitate stronger connections between the grantees.</p><p><strong>Building a growth loop</strong></p><p>Right now, each of our programs requires a large amount of time to organize, fundraise for, and then facilitate. We\u2019d like our platform to be more self-serve and require less intervention from our team. For impact certs, perhaps we could standardize different aspects of creating a contest, and have a form and a standardized pipeline for spinning up custom contests.</p><p>The open call is already moderately self-serve: we haven\u2019t put much effort into soliciting project applications or donors, and despite that we\u2019ve received many interesting applications and donor interest!</p><p><strong>Focus</strong></p><p>Possibly we\u2019re trying too many things for an org of our size and resources. On one hand, we view Manifund\u2019s comparative advantage in the EA funding ecosystem as the ability to rapidly experiment with new programs and mechanisms that other funders wouldn\u2019t consider; on the other, we may be able to execute better if we winnowed down our programs to only one or two that are very promising or clearly working well.</p><h1>Ambitious projects &amp; moonshots for 2024</h1><p><strong>10x\u2019ing impact certificates:</strong> we\u2019re reasonably happy with how impact certificates have worked out so far, and we\u2019ve learned a lot through our experiments. The next step is to see how they work at a larger scale. Here are some ideas for much bigger prizes that could use impact certificates:</p><ul><li>\u201cNobel Prize\u201d for AI safety work, highlighting the best examples of technical and governance work in the space each year, and allowing people to bet on entries beforehand.</li><li>O-1 Visa impact certs: offer up eg $10k prizes for employers to bring in O-1 candidates; allow investors and lawyers to buy into a share of the prize?</li><li>Eliminating flu season in San Francisco, with an Advance Market Commitment towards deployment of Far UVC tech. This is inspired by conversations with regrantor Gavriel, who works at 1DaySooner and would be a natural partner org for this.</li></ul><p><strong>Building a site for \u201ccontests-as-a-service\u201d:</strong> within EA (OpenPhil AI Worldviews, EA Criticism Contest) and outside of it (Vesuvius Challenge, AI IMO contest), there are open contests for different kinds of work; but there\u2019s no website you can go to to easily host your own contest. One inspiration might be from the world of <a href=\"https://en.99designs.jp/logo-design/contests\"><u>logo design contests</u></a>. As a bonus, if we make prize funding more of a norm, impact certs become much more palatable.</p><p><strong>Pushing harder on the Donor Advised Fund-angle of Manifund:</strong> we\u2019ve been using the \u201cDAF\u201d approach to legitimize prediction markets &amp; impact certs, but on a relatively small scale (~$10k-100k/year). Could we convince large donors to store significant assets with Manifund (e.g. totalling $1M-10M/year), and offer exposure to other things that don\u2019t work with real money (e.g. more liquid prediction markets; private stocks; ISAs)? And could we offer other services that DAFs currently don\u2019t, like regranting as a product, or charity evaluations.</p><p><strong>Become the central hub for all giving &amp; donation tracking:</strong> <a href=\"https://openbook.fyi/\"><u>OpenBook</u></a>/Manifund merge scenario where we become a hub for donations, where people track their donations, see the donations of others, and discuss donations in one place. Giving What We Can is kind of like this, though they are less forum-y and only allow donations to a small set of orgs.</p><p><i>Thanks to Dave Kasten, Joel Becker, Marcus Abramovitch, and others for feedback on this writeup. We\u2019d love to hear what you think of our work as well, and what you\u2019d be excited to see from us as we go into 2024!</i></p>", "user": {"username": "akrolsmir"}}, {"_id": "5mADSy8tNwtsmT3KG", "title": "The True Story of How GPT-2 Became Maximally Lewd", "postedAt": "2024-01-18T21:03:08.208Z", "htmlBody": "", "user": {"username": "Writer"}}, {"_id": "oqyoCCdmgqjPn4aNw", "title": "Animal farming for the fashion industry and other non-food purposes in Africa", "postedAt": "2024-01-25T13:22:26.797Z", "htmlBody": "<h1><strong>Context and disclaimers</strong></h1><ul><li>We originally published this research as a &nbsp;<a href=\"https://www.animaladvocacyafrica.org/blog/what-do-we-know-about-animals-being-farmed-outside-the-food-system\">blog post on our website</a> in January 2023. That post also included a guest contribution by FOUR PAWS South Africa. We decided to post our own part of this research on the EA Forum now in order to make our research better accessible to the wider EA audience.</li><li>This was only a shallow investigation to roughly understand the scale of animal farming for non-food purposes in Africa. Much deeper research would be needed to properly evaluate the promisingness of interventions in this area.</li></ul><h1>Executive Summary</h1><p>The suffering caused to animals used for their hides and skins (such as in the fashion or leather industry) might be an underexplored area within the Effective Animal Advocacy community, as focus is usually put on the use of animals for food production. To understand more about this issue and refine our organisation's strategic prioritisation, we did a shallow analysis and ran the numbers, limiting our analysis to Africa as the geographic focus of our organisation. We find that work to help animals farmed for their skins and hides can be worthwhile compared to other animal groups such as companion or working animals, but also conclude that animals farmed for food production should remain our top priority.</p><h1>What do we know about animals being farmed outside the food system in Africa?</h1><h2>Number of animals kept and slaughtered for their hides and skins</h2><p>The Food and Agriculture Organization of the United Nations (FAO) publishes comprehensive data on the number of animals slaughtered for their hides and skins (including wool, leather, etc.) across the world. According to their database <a href=\"https://www.fao.org/faostat/en/#data/QCL\"><u>FAOSTAT</u></a>, <strong>roughly 300 million animals were</strong><i><strong> killed</strong></i><strong> for their hides and skins in Africa in 2020</strong>. The majority were goats and sheep (~260 million) and the leading countries were Nigeria (~50 million), Ethiopia (~35 million), and Sudan (~33 million). South Africa, the focus country for FOUR PAWS' blog post on our website, was in eighth place, slaughtering ~9 million animals for their hides and skins in 2020. Table 1 below provides an overview and detailed figures can be found in <a href=\"https://docs.google.com/spreadsheets/d/1riFWFevz9HLhq-EnZdFqkidJAxrSQ0PE/edit?usp=sharing&amp;ouid=116536144396263674571&amp;rtpof=true&amp;sd=true\"><u>the spreadsheet we set up for this research</u></a>.</p><p>In 2016, the FAO also published a <a href=\"https://www.fao.org/3/a-i5599e.pdf\"><u>report on raw hides and skins, leather and leather products</u></a>, showing that <strong>roughly 1 billion animals were </strong><i><strong>kept</strong></i><strong> for use of their hides and skins in Africa in 2015. Across Africa, these numbers had steadily increased since 2005.</strong> Similar to the slaughter statistics, leading countries in animals kept are Sudan (~139 million animals), Nigeria (~120 million), and Ethiopia (~108 million). In South Africa, ~44 million bovine animals, goats, and sheep were kept for use of their hides and skins in 2015. Detailed numbers for 2015 are also shown in Table 1. For better visualisation, we also include a graph illustrating these figures.</p><p><img style=\"width:475px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oqyoCCdmgqjPn4aNw/eqfdm2vqivyq7cuuiw9i\" alt=\"Table 1 - four paws.png\"></p><p><img style=\"width:449.03px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oqyoCCdmgqjPn4aNw/guwjobuweev6rfgvappu\" alt=\"image (1).png\"></p><p>While we did not do an in-depth analysis of this data, it seems that the number of animals farmed for their hides and skins is increasing in developing countries, while it is stagnating or even decreasing in developed countries - a pattern that seems similar to food production (see below for the interrelatedness of these two farming purposes).</p><p>The FAO report also shows that the number of animals <i>kept</i> alive is even higher than the number of animals <i>slaughtered</i> per year, which is likely due to the fact that the animals analysed here typically have a longer life-cycle compared to other, smaller farmed animals like chicken.&nbsp;</p><p>Please note that the FAO numbers cited only include sheep, goats, and bovine animals like cattle and buffaloes. It does not cover other animals that are also farmed for their hides and skins, like ostriches and crocodiles. However, the numbers given by the FAO should cover the most widely used animals and should thus give a good estimate of the magnitude of the issue.</p><h2>Comparison to the scale of other animal issues</h2><p><strong>Compared to other animal issues, the scope of this problem appears large.</strong> For reference, in our <a href=\"https://www.animaladvocacyafrica.org/s/AAA_Prioritisation_Report.pdf\"><u>prioritisation report</u></a>, we estimated the number of live companion and stray animals in Africa to be in the low hundred million and the number of working animals to be somewhere around 35 million.</p><p>These numbers also show that <strong>the use of animals for their hides and skins makes up a significant proportion of farmed animals in Africa</strong>. <a href=\"https://docs.google.com/spreadsheets/d/1COmUIFbM8ZtmDHCXUuaDal7Wvlv8m_HyEJs4yloCEM0/edit#gid=999698732\"><u>In 2020, there were ~3.6 billion live land farmed animals in Africa</u></a>, including both animals raised for food as well as for their hides and skins (and potentially other purposes). Based on this number and the above estimate of ~1 billion animals kept for their hides and skins in 2015, we can estimate that<strong> roughly one quarter of all animals farmed in Africa are farmed for their hides and skins</strong>.</p><p><a href=\"https://docs.google.com/spreadsheets/d/1COmUIFbM8ZtmDHCXUuaDal7Wvlv8m_HyEJs4yloCEM0/edit#gid=999698732\"><u>The number of farmed land animals </u><i><u>slaughtered</u></i><u> for food in Africa in 2018 was at ~4.6 billion</u></a>, substantially higher than the above-indicated 300 million animals slaughtered for their hides and skins in 2020, suggesting that <strong>food production is the major contributing factor for animal slaughter in Africa. The higher number of slaughtered animals compared to live animals in food production is mostly a result of the large number of chickens, who have a much shorter lifespan than most of the other land animals in scope.</strong></p><p><img style=\"width:512px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oqyoCCdmgqjPn4aNw/tfmayects0f4p8uykv3c\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oqyoCCdmgqjPn4aNw/ipx1nvxrba7xomzxqffc 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oqyoCCdmgqjPn4aNw/hkboogeltakv6il4csqs 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oqyoCCdmgqjPn4aNw/evulr0irnb4ktearwxcl 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oqyoCCdmgqjPn4aNw/kjjwxqvkcdjljwrr5gzf 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oqyoCCdmgqjPn4aNw/clw8v1tev4ynqdh3juda 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oqyoCCdmgqjPn4aNw/faicigaajskxj4zudfe0 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/oqyoCCdmgqjPn4aNw/wxzfklrfy8yakfmrg8ls 2500w\"></p><p>It is important to highlight that many animals can be used for multiple purposes. A dairy cow could be used for milk production during her lifetime, while her skin is used for leather production after she has been slaughtered, or a sheep can be used for both wool and cheese production. We did not spend a lot of effort on evaluating these different uses and potentially disentangling the impact that each of them has on animal suffering, as this would require a much larger research effort.</p><p>However, <strong>a strong argument can be made that hides and skins are increasingly becoming a non-valuable byproduct of meat and dairy production</strong>. <a href=\"https://www.supplychainbrain.com/articles/30104-americas-obsession-with-beef-is-killing-the-leather-industry\"><u>While hides and skins have historically been a valuable part of an animal, the situation is shifting, as demand for meat and dairy products has increased and is still growing, while demand for leather products is on a downward trajectory on a global level.</u></a> With skins and hides from the meat and dairy industries in abundant supply, the commercial case for raising and killing animals for their hides and skins can become very weak in many industries.</p><p>Despite this primacy of food production as a factor in driving animal farming, there are animal groups, like ostriches, that are farmed primarily for their hides and skins. In general, the balance of food vs. hides and skins as the most important economic factor for farming probably varies substantially between animal groups. While for most animals (e.g, chicken and cows), the majority of their economic value should lie in food production, the picture is less clear for others (e.g., sheep or goats), and some animals (e.g., ostriches) are even farmed primarily for their hides and skins.</p><h2>Conclusion</h2><p>This leads us to the conclusion that an emphasis on animals farmed for food production is warranted, if we want to have the largest positive impact on the lives of animals. However, as the production of skins and hides is interrelated with food production and involves the farming of roughly one billion animals across Africa, we do not want to categorically exclude this topic from our work and wider discussions on farmed animal welfare in Africa - especially when considering industries or animal groups where hides and skins are the main driving factor for intensive farming. <strong>We assume that projects to help animals farmed for their skins and hides can be worthwhile compared to other animal groups such as companion or working animals, while animals farmed for food production should remain our top priority.</strong></p>", "user": {"username": "AnimalAdvocacyAfrica"}}, {"_id": "qcGuAyHid3eEtqxdm", "title": "Is fear productive when communicating AI x-risk? [Study results]", "postedAt": "2024-01-22T05:38:54.794Z", "htmlBody": "<p>I want to share some results from my MSc dissertation on AI risk communication, conducted at the University of Oxford.&nbsp;</p><blockquote><p><i>TLDR: In exploring the impact of communicating AI x-risk with different emotional appeals, my study comprising of 1,200 Americans revealed underlying factors that influence public perception on several aspects:</i></p><ul><li><i>For raising risk perceptions, fear and message credibility are key&nbsp;</i></li><li><i>To create support for AI regulation, beyond inducing fear, conveying the effectiveness of potential regulation seems to be even more important</i></li><li><i>In gathering support for a pause in AI development, fear is a major driver</i></li><li><i>To prompt engagement with the topic (reading up on the risks, talking about them), strong emotions - both hope and fear related - are driver</i>s</li></ul></blockquote><h3>AI x-risk intro</h3><p>Since the release of ChatGPT, many scientists, software engineers and even leaders of AI companies themselves have increasingly spoken up about the risks of emerging AI technologies. Some voices focus on immediate dangers such as the spread of fake news images and videos, copyright issues and AI surveillance. Others emphasize that besides immediate harm, as AI develops further, it could cause global-scale disasters, even potentially wipe out humanity. How would that happen? There are roughly two routes. First, there could be malicious actors such as authoritarian governments using AI e.g. for lethal autonomous weapons or to engineer new pandemics. Second, if AI gets more intelligent some fear it could get out of control and basically eradicate humans by accident. This sounds crazy but the people creating AI are <a href=\"https://mitsloan.mit.edu/ideas-made-to-matter/why-neural-net-pioneer-geoffrey-hinton-sounding-alarm-ai\">saying</a> the technology is inherently unpredictable and such an insane disaster could well happen in the future.&nbsp;</p><h3>AI x-risk communication&nbsp;</h3><p>There are now many media articles and videos out there talking about the risks of AI. Some announce the end of the world, some say the risks are all overplayed, and some argue for stronger safety measures. So far, there is almost no research on the effectiveness of these articles in changing public opinion, and on the difference between various emotional appeals. &nbsp;Do people really consider the risks from AI greater when reading an article about it? And are they more persuaded if the article is predicting doomsday or if it keeps a more hopeful tone? Which type of article is more likely to induce support for regulation? What motivates people to inform themselves further and discuss the topic with others?</p><h3>Study set up</h3><p>The core of the study was a survey experiment with 1200 Americans. The participants were randomly allocated to four groups: one control group and three experimental groups each getting one of three articles on AI risk. All three versions explain that AI seems to be advancing rapidly and that future systems may become so powerful that they could lead to catastrophic outcomes when used by bad actors (misuse) or when getting out of control (misalignment). The <i>fear</i> version focuses solely on the risks; the <i>hope</i>&nbsp;version takes a more optimistic view, highlighting promising risk mitigation efforts and the <i>mixed</i>&nbsp;version is a combination of the two transitioning from fear to hope. After reading the article I asked participants to indicate emotions they felt when reading the article (as a manipulation check and to separate the emotional appeal from other differences in the articles) and to state their views related to various AI risk topics. The full survey including the articles and the questions can be found in the dissertation on page 62 and following (link at the bottom of page).</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/iyd2yqbsxkhskaqlo1qw\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/eormp79lbptxccolpaj3 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/kvizsiuxprqx9dvtfdnw 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/msaexuk4bumebrvih1x7 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/cew2n5yddi017z17ju28 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/skvmhsqqvucxkuupxbgc 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/lirgtvknp05vrszrnccv 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/agekjfap4bux3udnf8oe 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/srseryq5haf35smywo94 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/bo92xrmpoyetmkafeaex 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/d9apeumg3hzjb68bho4e 2030w\"></figure><h3>Findings</h3><p><strong>Overview of results</strong></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/chvieecrv2gegmedflxz\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/lsjkqs7coc8tacxnuqi3 250w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/gd9w7bslhghnvwth31aw 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/yoigyhub20fglvnxbr8y 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/zpk6m0px9pg7u3jxzgye 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/kvfn9ffkatsxce6jkoal 1250w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/h4j1gwxickwbqjg5yvdo 1500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/q6sspog7tacvdkz9ny9x 1750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/jkq6gwq82srf2bs71sul 2000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/janem6uzylk22slounzp 2250w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/xvfqa5fphjhvg01im3rz 2418w\"></figure><p><strong>1. Risk perception&nbsp;</strong></p><p>To measure risk perception, I asked participants to indicate their assessment of the risk level of AI risk (both existential risk and large-scale risk) on a scale from 1, extremely low, to 7, extremely high with a midpoint at 4, neither low nor high. In addition, I asked participants for their estimations on the likelihood of AI risk (existential risk and large-scale risk, both within 5 years and 10 years, modelled after the rethink priorities opinion poll). All risk perception measures related to x-risk showed the same statistically significant difference between groups. The answers for AI x-risk are shown below, the statistical analysis and descriptives for the other measures can be found in the full paper.&nbsp;</p><p>The fear appeal increased risk perception the most, followed by the mixed appeal and the hope appeal. Analyses show that fearful emotions are indeed the main mechanism at play, counteracted by message credibility as a second mechanism which is lower in the fear appeal article. Interesting are also the differences in the distribution between e.g., the extremes (1 and 7) and the mid values (3,4,5). The fear article for example had a particularly strong effect in decreasing the share of 1s (extremely low risk), to a third of the control group but also in increasing the share of 7s (extremely high risk) from 2% to 9%. AI risk communicators should be clear in what they want to achieve (raising risk perceptions as much as possible or to a certain level).&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/lmudgce3lpiogngrwefx\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/zqo7adwuzp5g1ppxxrgs 190w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/g9wm2cetfsv3ygyrrzcy 380w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/zm5s3ozvws28lugakccd 570w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/danqn0rxh70dttw0pvnq 760w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/hgpmjxiynoq4fzitjey6 950w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/nkj83uzw6i1kjdoiqhwj 1140w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/hzyoccqshffevjgwdewx 1330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/xvpij38rq4bbdp42pzps 1520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/tmdltjuaabv4lecm9tml 1710w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/ilcktpraszakj64ou9ez 1856w\"></figure><p><strong>2. AI regulation</strong></p><p>Following the framing of a 2023 <a href=\"https://rethinkpriorities.org/publications/us-public-opinion-of-ai-policy-and-risk\">rethinkpriorities poll</a>, I asked participants if they would support AI being regulated by a federal agency, similar to how the FDA regulates the approval of drugs and medical devices in the US. While all experimental groups (fear, hope and mixed) show significantly higher levels of support for AI regulation than the control group, the mean differences between the three groups are not significant. The descriptive statistics (see below) show that the hope appeal led to higher levels of support. However, this effect does not seem to be based on higher feelings of hope instead of feelings of fear per se. In fact, fear is a positive predictor of support for AI regulation. The overall stronger effect of the hope appeal can be (at least partially) attributed to higher perceived efficacy of regulation (i.e. how effective participants think AI regulation would be) and message credibility (how credible the article was seen as).&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/nbh4xnagsppytynsf0ss\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/lcp3gkz4mwymfou6obyl 190w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/rcylnupruxcgrzctyzrj 380w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/qejkl7rbpxqn0vajelef 570w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/zxpsnoryqtfubjzi3arv 760w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/liia3hgmtvwhph9ygcjg 950w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/mkygizty8v05tosppfyf 1140w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/tafciy96q3dgnhtyem2j 1330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/ephfmsrsxsskvvecxxq1 1520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/wxkxstwe1b2hkhwndbtf 1710w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/vtz9yzjudzjkhoyjoegt 1832w\"></figure><p><strong>3. AI pause&nbsp;</strong></p><p>I also asked participants about their support for a potential 6 months pause (moratorium) on certain AI development. For comparability, I again mirrored the framing of a 2023 <a href=\"https://rethinkpriorities.org/publications/us-public-opinion-of-ai-policy-and-risk\">rethinkpriorities poll</a> including a short overview of different opinions regarding such a potential moratorium. The fear appeal article had the strongest effect and both fearful and hopeful emotions acted as mediators, positive and negative respectively. Notably, higher age and being female made support for such pause also significantly more likely.&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/neaex26emv4tcu9cmrxa\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/f4jvwwxowilckmhuurb3 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/nuolosvr5wsu7cx3o4rn 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/gat0bt5uxnk4smvomlvu 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/crfqcejqzwjoqfurfzn8 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/nim58amcejhilsfecswy 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/hjjterttsjo0swhl0mhu 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/d3tz1qsxc2aemt0jwg9w 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/kjmuvewjflxlzrc8wxen 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/xspqmyzel4jke2ipk5bt 1350w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/beearygecjxzx45ytnmr 1462w\"></figure><p>&nbsp;</p><p><strong>4. Further engagement with AI risks</strong></p><p>Finally, I wanted to see whether/ which articles shape participant's intentions to further engage with the topic. While the effect sizes were relatively small, participants reading the hope and fear appeal had significantly stronger intentions of seeking out more information and initiating a conversation about the risks associated with AI in the next 6 months, compared to those of the control group. Here, any induced emotions - fearful or hopeful ones - increased the stated likelihood of engaging in those actions.&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/cvnlirhwqznd5yqrpsaf\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/wovor2wt2udrfumzcijh 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/hug13vwewjr0fazqi5o0 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/trei24ro5wiuttbpppyi 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/lfx4y4efrpvmxjclrwy7 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/pxwa9prtwsnmfixvfzhf 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/yg6mh4jv1qnecj53j3eq 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/v4lcuxwz0qudf68pygxm 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/xq6ol4gnx208ivfelymm 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/rtfolhokncsvrnvvawei 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/ck5m47bzrp3wvo2qskl6 1730w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/ewi0uhwmbitqxk8yyuu5\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/xldq3vzszjhut968m4ac 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/koqcbpcf1u1mt56ssju6 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/q9fledrjcaevgbd7adun 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/sa53xacfflcedyl1erso 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/v2sgknbuiehinkojgnsf 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/ssuydocd1bxtnpesw8ud 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/dsmwkorap1ltgv5wanz4 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/bqrbp76jwispyvpv1qac 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/df5nwzk6j4tmhvjvn9ow 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/qcGuAyHid3eEtqxdm/kllrxrmveq7t29hfnwyl 1788w\"></figure><h3>Link to complete study</h3><p>The full dissertation has not been published as of now, but you can access the submitted version <a href=\"https://drive.google.com/file/d/1RlNKH_EuBfs0o51O7b-wKLUPJkq8V2SC/view?usp=sharing\">here</a>. I want to note a few things as a disclaimer here. First, I was doing an MSc in Sustainability, Enterprise and the Environment and had to link the dissertation to the topic of sustainability. The paper therefore makes a (slightly far-fetched) bridge to the sustainable development goals. Second, due to lack of experience and time (this was my first study of this kind and I only had the summer to write it), the work is highly imperfect. I tested too many things without robust hypotheses, I had a hard time choosing which statistical analysis to make leading to a bit of a mess there and I wish I had time to write a better discussion of the results. So please interpret the results with some caution.</p><p>In any way, I'd be glad to hear any reactions, comments or ideas in the comments!&nbsp;</p><p>Also, I'm happy to share the data from the study if you're interested in doing further analyses, just message me if you're interested.&nbsp;</p><p>PS: I'm super grateful for the financial support provided by Lightspeed Grants, which was crucial in achieving the necessary participant number and diversity for my study.</p>", "user": {"username": "Johanna Roniger"}}, {"_id": "tMcPJvMFLYppqHKiP", "title": "Unpacking Martin Sandbu's recent(ish) take on EA", "postedAt": "2024-01-20T01:16:57.641Z", "htmlBody": "<p>The original article is here: <a href=\"https://www.ft.com/content/128f3a15-b048-4741-b3e0-61c9346c390b\">https://www.ft.com/content/128f3a15-b048-4741-b3e0-61c9346c390b</a></p><h2><strong>Why respond to this article?</strong></h2><p>When browsing EA Twitter earlier this month, someone whose opinions on EA I respect <a href=\"https://nitter.net/JoshuaBlake_/status/1741017870870708686#m\">quote-tweeted someone that I don't</a> (at least on the topic of EA<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefw3wnli6jpsg\"><sup><a href=\"#fnw3wnli6jpsg\">[1]</a></sup></span>). The subject of both tweets was an article published at the end of 2023 by Martin Sandbu of the Financial Times titled <i>\"Effective altruism was the favoured creed of Sam Bankman-Fried. Can it survive his fall?\" </i>Given that both of these people seem to broadly endorse the views, or at least the balance, found in the article I thought it would be worthwhile reading to see what a relatively mainstream commentator would think about EA.</p><p><i>The Financial Times</i> is one of the world's leading newspapers and needs very little introduction, and Sandbu is one of its most well-known commenters. What gets printed in the FT is often repeated across policy circles, not just in Britain but across the world, and especially in wonky/policy-focused circles that have often been quite welcoming of EA either ideologically or demographically.</p><p>As always, I encourage readers to read and engage with the original article itself to get a sense of whether you think my summarisation and responses are fair.</p><p>&nbsp;</p><h2>Reviewing Sandbu's Article</h2><p>Having read the article, I think it's mainly covering two separate questions related to EA, so I'll discuss them one-at-a-time. This means I'll be jumping back-and-forth a bit across the article to group similar parts together and respond to the underlying points, though I've tried to edit Sandbu's points down as little as possible.</p><h3>1) How to account for EA's historical success?</h3><p>The first theme in the article is an attempt to give a historical account of EA's emergence, and also an attempt by Sandbu to account for its unexpected success. Early on in the article, Sandbu clearly states his confusion at how a movement with the background of EA grew so much in such a short space of time:</p><blockquote><p><i>\"Even more puzzling is how quickly effective altruism rose to prominence \u2014 it is barely a decade since a couple of young philosophers at the University of Oxford invented the term ... nobody I knew would have predicted that any philosophical outlook, let alone this one, would take off in such a spectacular way.\"</i></p></blockquote><p>He doesn't explicitly say so, but I think a reason behind this is EA's heavy debt to Utilitarian thinkers and philosophy, which Sandbu sees as having been generally discredited or disconfirmed over the 20th century:</p><blockquote><p><i>\"In the 20th century, Utilitarianism\u2026 progressively lost the favour of philosophers, who considered it too freighted with implausible implications.\"</i></p></blockquote><p>The history of philosophy and the various 20th century arguments around Utilitarianism are not my area of expertise, but I'm not really sure I buy that argument, or even accept how much it's a useful simplification (a potted history, as Sandbu says) of the actual trends in normative ethics.&nbsp;</p><p>First, Utilitarianism has had plenty of criticism and counter-development before the 20th century.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefh3i97ujqevn\"><sup><a href=\"#fnh3i97ujqevn\">[2]</a></sup></span>&nbsp;And even looking at the field of philosophy right now, consequentialism is just as popular as the other two major alternatives in normative ethics.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref84y6gyu7aha\"><sup><a href=\"#fn84y6gyu7aha\">[3]</a></sup></span>&nbsp;I suspect that Sandbu is hinting at Bernard Williams' <a href=\"https://www.utilitarianism.com/utilitarianism-for-and-against.pdf#%5B%7B%22num%22%3A832%2C%22gen%22%3A0%7D%2C%7B%22name%22%3A%22XYZ%22%7D%2C76.500008%2C674.25%2C0%5D\">famous essay against utilitarianism</a>, but I don't think one should consider that essay the final word on the subject.</p><p>In any case, Sandbu is telling a story here, trying to set a background against which the key founding moment of EA happens:</p><blockquote><p><i>\"Then came Peter Singer. In a famous 1972 article... [Singer] argued that not giving money to save lives in poor countries is morally equivalent to not saving a child drowning in a shallow pond... Any personal luxury, when excess income could combat hunger or poverty, would stand condemned. In my time in academia, Singer\u2019s philosophical rigour was respected but also treated as a bit of a reductio ad absurdum. If your principles entail such all-consuming moral demands, then the principles are in need of revising.\"</i></p></blockquote><p>I don't think being in conflict with a majority opinion should be dispositive at all, and given the mixed record of moral and social intuitions about what it is right, given that moral intuition often has a very 'mixed' as guide to moral action in human history, I think it's perfectly acceptable to claim that in this case <a href=\"https://gwern.net/modus\">one man's modus ponens is another man's modus tollens</a>, and that if we live in a morally demanding universe, so be it.<strong> </strong>Some might find the <a href=\"https://utilitarianism.net/objections-to-utilitarianism/demandingness/\">demandingness objection</a> intuitive, but others would say that this just shows how much moral improvement humanity has to do.</p><p>I'm not endorsing the fully-demanding position here, just pointing out that there's extra argumentation to be done to favour symmetry-breaking in favour of the <i>\"reductio ad absurdum\"</i> direction instead of the <i>\"guidance for right action\"</i> direction.</p><blockquote><p><i>\"A generation later, the seed planted by Singer found extraordinarily fertile soil. The founders of EA, MacAskill and Toby Ord, have both credited Singer\u2019s article with their moral awakening in the mid-2000s. \u201cStudying that paper and others, I wrote an essay for my BPhil at Oxford \u2014 \u2018Ought I to forgo some luxury\u2019,\u201d Ord told me, which \u201cforced me to think seriously about our moral situation with regard to world poverty\u201d. Within a few years, Ord and MacAskill had founded Giving What We Can\"</i></p></blockquote><p>I think this paragraph is meant as a conclusion to Sandbu's history of the development of EA, but I think that it actually functions as the correct answer. Institutional EA developed <i><strong>because of the existence of EA ideas</strong>, </i>starting with \"Famine, Affluence, and Morality\" as Sandbu pointed out earlier in the article. These ideas survived and spread in no small part because they were more self-correcting/consistent/action-guiding in a way that others philosophical ideas at the time weren\u2019t. Or, to phrase it another way, because they're true.</p><p>Sandbu instead seems to point to environmental factors as being more influential, mostly settling on the fact that the generation EA first took hold in was one that was disenchanted with the world (through climate change, the financial crash, generational inequality etc). He also points out the presence of the philosophers Derek Parfit and John Broome assisting with the development of EA ideas in Oxford, particularly because they were advisers to MacAskill and Ord. But I feel the ideas are more important here - Parfit and Broome passed along a set of <i>ideas </i>to MacAskill and Ord, and there are many different ideas<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3bu7pq7m6q9\"><sup><a href=\"#fn3bu7pq7m6q9\">[4]</a></sup></span>&nbsp;primed to spread amongst those disappointed with the world, so on its own that isn't a strong explanation of EA's spread at all.</p><p>Of course, there's an issue here about motivated reasoning. &nbsp;As an identifying EA, I might think EA spread because its ideas are good, but a critic might reject this perspective and look at external explanations for an ideology that they think has little to no merit. But here I think we're settling on the object level question of whether EA's ideas are actually sound or not, which is the second theme of the article.</p><p>&nbsp;</p><h3>2) What does EA get wrong?</h3><p>The other theme that Sandbu explores in the article is whether the EA movement, and/or its ideas, are actually a good way to do good personal and a societal level.</p><blockquote><p><i>\"There are two ways to characterise EA. One is modest: it says that if you are going to donate to charity, pay attention to what you fund and choose the most effective charities. That is hard to argue with: why not want your charity dollars to do the most good possible?</i></p><p><i>But even this modest version leads to some uncomfortable implications: it is wrong to volunteer your time for a cause you can better advance by \u201cearning to give\u201d to it; it is wrong to choose an \u201cinefficient\u201d cause \u2014 say, research into an expensive-to-treat disease that killed a loved one.</i></p></blockquote><p>I think many people <i><strong>do disagree</strong></i> with the premise that Sandbu says its 'hard to argue with'. They might do from an aversion to charity, or from different conceptions of the good, or just from a general intuition against ideas that seems 'weird'. In some sense, this hard-to-argue with version of EA is just as controversial as any other, because moral issues are <a href=\"https://rychappell.substack.com/p/puzzles-for-everyone\">puzzles for everyone</a>, and not just EAs.&nbsp;</p><p>The example Sandbu uses in the second paragraph is, however, a rather good one to consider. Would it be 'better' for a person working in a high-paying financial/legal/consulting role to spend a significant amount of their income to fund Vitamin A supplementation to children under 5, or to spend your life trying to fund a cure for <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2827822/\">Fibrodysplasia Ossificans Progressiva</a> if a family member had previously suffered from it? I can sympathise with the person in the latter case, but I still think that the former choice would be the right one to make.&nbsp;</p><blockquote><p><i>\"\u2026if you take Singer-type ideas seriously, the modest version is not where you stop... how can you not apply it [cause prioritisation] to your career choices and how much money you could make to give away....how can you not ask whether you should really focus on the poor in the world, or farmed animals\u2019 suffering, if there is even a small chance that an asteroid or AI could deny trillions of potential future lives their existence, and you could devote your resources to preventing that?</i></p></blockquote><p>That is the familiar sound of the <a href=\"https://forum.effectivealtruism.org/posts/feejxTPvBJY2cfXRp/when-to-get-off-the-train-to-crazy-town\">'train to crazy town'</a>. I have to imagine, given his background and reputation, that Sandbu has done more than a cursory investigation into EA. But if so, surely he'd be aware that there are <a href=\"https://forum.effectivealtruism.org/topics/cause-prioritization\">very many discussions</a> within EA about <i>exactly </i>these questions and how to resolve them? I'm definitely sure that Sandbu is familiar with the <a href=\"https://en.wikipedia.org/wiki/Secretary_problem\">Secretary problem</a> though, and that seems fairly analogous to this situation.&nbsp;</p><p>You could, for example, spend your entire life researching what the right thing to do was, and then die before any action could be taken. The same logic applies here. One could ask these questions, but asking and trying to solve them comes at an (opportunity) cost, and simply stating that &nbsp;a small probability that a large-impactevent might happen reasoning doesn't mean it actually <i>is </i>the best way to do good. (For more on that last point, see <a href=\"https://onlinelibrary.wiley.com/doi/full/10.1111/papa.12248\">here</a> and <a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj/p/S9H86osFKhfFBCday\">here</a> for interesting explorations into the value of x-risk mitigation).</p><blockquote><p><i>\"Longtermism\u201d and prospective future catastrophes, such as rogue AI, are taking up ever more of EA\u2019s attention... One person familiar with the OpenAI boardroom conflict says that EA ideas did not play any role. If so, that must surely count as a huge missed opportunity to avert potentially devastating future harm, which by EA lights is as morally bad as causing it.</i></p></blockquote><p>I think the first sentence here is just stated without evidence. I actually think that the 'longtermist takeover' in EA is actually vastly overstated, at least as usually presented. Not only have ideas around x-risk been around for a long time, but I<a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023\"> don't actually think the majority of EAs prioritise x-risk/longtermist causes</a>. Now, I think there is a claim somewhat like the one Sandbu is making that <i>is</i> true, perhaps when <a href=\"https://forum.effectivealtruism.org/posts/DoAWvhgEnhSMr6yjS/new-data-suggests-the-leaders-priorities-represent-the-core\">focusing on the opinions of EA \"leaders\"</a>, but the effort he gives here to make such a point isn't really good enough to get it to work.</p><p>As far as the supposed 'gotcha' about the OpenAI board, I think it's really just that, a 'gotcha'. One has to actually evaluate what happened in the case, and argue that different action by the board <i>would be massively averting potential devastating future harm, </i>instead of say thinking that OpenAI's position is net-positive. Again, I'm not arguing that this is the case, but critics should at least make the case. This frustration came up again for me in the passage below:</p><blockquote><p><i>And EA ideas clearly did not discourage the fraud at FTX. It is not implausible to think Bankman-Fried knew he was breaking the law but concluded... that he had good enough odds to make the money back many times over... In other words, he may have thought the expected value of the fraud was distinctly higher than that of honesty. And, if this was the case, who are we to say he was not correct \u2014 just unlucky?</i></p></blockquote><p>SBF may well have thought what he was doing was high EV, but sometimes I daydream that I'd be able to score a penalty in a World Cup final. Simply thinking things doesn't make them reasonable or true!&nbsp;</p><p>In fact, the question Sandbu poses at the end of this extract is really a crucial part of EA. EAs don't just stop at <i>\"who's to say who is correct\"</i>, they actually try and investigate the answer, and it turns out that commiting one of the largest financial frauds in history is not a very good way to be effective, or altruistic, and that the downside risk of it probably dwarfed everything else entirely.</p><blockquote><p><i>But if I were an effective altruist, what would worry me most is that EA has failed to produce \u201cthe most good\u201d in the two public cases where it should have made the biggest difference.</i></p></blockquote><p>I think plenty of EAs are highly critical about how the movement, or parts of it, or particular individuals behaved in these two cases. Maybe Sandbu really is just thinking out loud here, but I feel like there's an insinuation here that EAs aren't thinking about this, and it'd at least be good to have mention of the internal discussions and disagreements in EA about what happened in both of these cases.</p><p>I also think Sandbu indexes too much on the aim to produce 'the most good' in some abstract sense.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9homdhp7fx\"><sup><a href=\"#fn9homdhp7fx\">[5]</a></sup></span>&nbsp;The world has doesn't have only two binary states of 'the most good' and 'not the most good'. The ~entirety of moral difference in how the world is is contained in the latter. I'm less concerned by EA not doing 'the most good' if instead it did 95% of 'the most good' compared to the current moral <i>status quo</i>, and I think the issue in these cases isn't that EA failed to produce 'the most good' but that instead it may have contributed to harms.</p><blockquote><p><i>Everyone in the EA community is adamant that Bankman-Fried\u2019s conduct was nonetheless wrong... But that begs the question of what arguments, within effective altruism, could condemn what Bankman-Fried did. When I put this to him, Ord accepted I had a point. There must be constraints, he insisted, but admitted they are \u201cnot built into the philosophy\u201d. This implies, it seems to me, that to achieve the most good we can do, we should not take EA too seriously.</i></p></blockquote><p>I don\u2019t really know what to make of how the article concludes, and I'm particularly confused as to Ord's response, so much so that I can't help thinking that there's been some miscommunication here? Ord isn't a na\u00efve utilitarian by any stretch of the imagination, so I'm not sure 'you have a point' is actually conceding to Sandbu here, or Ord saying that this criticism 'has a point' against na\u00efve utilitarianism but not EA?</p><p>In any case, while the final line is cute, I don't come away with a clear idea of what Sandbu actually means here. Does the injunction to <i>\"not take EA too seriously\"</i> mean we ought to ignore or disregard EA entirely, or does it mean just be non-totalising in our moral obligations? Without further explanation it seems an odd place to end the article, and I ended up disappointed in an article that seemed to start promisingly end with a whimper.</p><p>&nbsp;</p><p>Finally, there are a few extra criticisms from people that Sandbu has interviewed for the piece, which I thought would be good to treat separately:</p><blockquote><p><i>[Broome] adds: \u201cI think these people are naive\u2009.\u2009.\u2009.\u2009The focus on philanthropy\u2009.\u2009.\u2009.\u2009gives cover to wealth and the increasing inequality there is in the world\u2009.\u2009.\u2009.\u2009Where the efforts of these altruists should be directed is towards ensuring that governments behave properly. They are not thinking enough about the political structure that underlies their ability to give money away.\u201d</i></p></blockquote><p>A big issue with Broome's<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjayo0cwn6i\"><sup><a href=\"#fnjayo0cwn6i\">[6]</a></sup></span>&nbsp;take here is that it's empirical basis just seems to be wrong. Worldwide wealth inequality <a href=\"https://ourworldindata.org/the-history-of-global-economic-inequality\">has probably decreased over the last half century</a>. Second, I don't (necessarily) want to get drawn into 'another internet debate about Capitalism'<sup>TM</sup>, I'd be remiss if I didn't point out that the political structure that \"underlies their ability to give many away\" also <a href=\"https://forum.effectivealtruism.org/posts/bsE5t6qhGC65fEpzN/growth-and-the-case-against-randomista-development\">seems to be the structure that creates the money</a> in the first place.</p><p>Third, there's a repeat of the known claim that EA needs to look at political structure more, in which case I assume that Broome would actually be more supportive of EAs move towards policy in the AI space and is a big fan of longtermist policy work as opposed to philanthropy for global health? I wouldn't expect so, but then I would ask those who agree with or sympathise with Broome's take here, but are sceptical of longtermism, to ask themselves why the evidence for the latter is not robust enough to take seriously, while the evidence for making sweeping structural changes that match Broome's politics is acceptable.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref19dgr5u9gw1\"><sup><a href=\"#fn19dgr5u9gw1\">[7]</a></sup></span></p><blockquote><p><i>As another philosophy professor put it to me, EA suggests to bright undergraduates that \u201cthe world is a problem they can solve, not through the difficult work of politics\u2009.\u2009.\u2009. but simply by applying an easy algorithm\u201d. For Strudler, it reflects \u201ca failure of imagination. [EA] is a substitute for hard moral judgment, but it\u2019s a substitute that doesn\u2019t work.\u201d</i></p></blockquote><p>I wish this had been presented with more critical commentary by Sandbu. I don't grt the impression that either the anonymous professor or Strudler have actually had much to do with EA or individual EAs, or at least not a representative one. I think many EAs find <a href=\"https://forum.effectivealtruism.org/posts/3k4H3cyiHooTyLY6p/why-i-find-longtermism-hard-and-what-keeps-me-motivated\">thinking about and acting on their moral judgements</a> to be hard, and not easy. One of the best pieces on this kind of perspective, or at least one that really resonates with me, is <a href=\"https://mhollyelmoreblog.wordpress.com/2016/08/26/we-are-in-triage-every-second-of-every-day/\">Holly Elmore's analogy of doing good to triage in crisis</a>. Even ignoring the chaser comment that EA \"doesn't work\" (presented without evidence), from what I can tell Strudler is actually the one with a singular failure of moral imagination, and is not really grappling with what it means to be good in a morally inconvenient universe.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgxrgiuliu1a\"><sup><a href=\"#fngxrgiuliu1a\">[8]</a></sup></span></p><p>&nbsp;</p><h3><strong>3) Factual/Object-Level Mistakes</strong></h3><p>Sandbu is a good writer, and I think on the whole I'd agree that he's trying to be balanced and think about Effective Altruism with an open mind. Nevertheless, I think there are some points where, instead of considering a philosophical debate, the piece just contains factual mistakes that significantly weaken its integrity:</p><blockquote><p><i>\"Meanwhile, OpenAI\u2019s boardroom drama turned on whether commercial or safety considerations should set the pace of development.\"</i></p></blockquote><p>Much of the what happened during the OpenAI boadroom drama remains unknown, and unfortunately many of those involved at the heart of this are not willing to tell the full story openly, either in the initial case or in the negotiations afterwards. Zvi has a good roundup on events, including <a href=\"https://thezvi.substack.com/p/openai-altman-returns\">here</a> and <a href=\"https://thezvi.substack.com/p/openai-leaks-confirm-the-story\">here</a>, which I'd probably recommend for good summaries of what happened after the dust settled.</p><p>It's undeniable that EAs were involved, and perhaps then considerations Sandbu mentions did play an important role, but it does seem that the drama 'turned' on trust between the members of the board and Altman, as well as between the employeed of OpenAI and the board. This is another claim where Sandbu states something as if it's clearly fact, but his claims don't actually stand up once you kick the tires a bit.</p><blockquote><p><i>\"stronger commitments inspire the fervour seen among EA\u2019s young adherents \u2014 many of whom testify to how EA changed their life and gave it purpose.\"</i></p></blockquote><p>Sure, I think this is true in individual cases, but no attempt is made here to actually investigate beyond a high-level vibes-based claim. For example, perhaps fervour is actually related to this who were <i>originally </i>part of EA, as opposed to new entrants? Maybe asking for analysis like this is asking too much of a newspaper opinion piece, but given Sandbu's reputation for thoughtful analysis it's still surprising to see these consistent over-claims about EA without the evidence to support it.</p><blockquote><p><i>\"These efforts [associated with such groups as GiveWell and Open Philanthropy] too, proclaim a desire to \u201cdo as much good as possible\u201d. But while they share the empirical hardheadedness of the group that developed at Oxford, they seem less invested in the philosophical framework.\"</i></p></blockquote><p>Again, is this true? I might be true in the sense that nobody is as invested in a philosophical framework as academic philosophers, but for the claim to have any useful content it needs to have something else. But Sandbu doesn't really go anywhere with this claim (he switches back to talking about Oxford), and I'm fairly sure that the people at GiveWell and OpenPhil would report that they take their philosophical frameworks serious, so again this just seems like 'vibes-based' reporting.</p><blockquote><p><i>\"Such \u201clongtermism\u201d is increasingly being adopted by the EA community and its Silicon Valley friends\"</i></p></blockquote><p>Once again, is this actually true? I feel like when you dive into considering the information actually available on this, <a href=\"https://forum.effectivealtruism.org/posts/nws5pai9AB6dCQqxq/how-are-resources-in-ea-allocated-across-issues?commentId=etX9F6vzuFhyiq8Y4\">the picture is actually a lot more mixed</a> than many people expect. Instead, I think what <i>has </i>changed the most is people's perception that this is true, and that a large part of EA-critical articles, videos, and tweets is being caused by a <a href=\"https://en.wikipedia.org/wiki/Preference_falsification\">preference cascade</a> of sorts, rather than actual analysis of the sociology or history of the EA community.</p><blockquote><p><i>\"The reduction of moral questions to mere technical problems is surely one reason that EA spread in two particularly moneyed techie communities: Silicon Valley and quantitative finance.\"</i></p></blockquote><p>This kind of sneaking in of \u2018mere\u2019 also occured in <a href=\"https://forum.effectivealtruism.org/posts/cQw9g6iocKimtyFoN/thoughts-on-kenan-malik-s-recent-ea-article#Philosophical_and_Conceptual_Confusion\">Kenan Malik's article on EA</a>, where he rather insidiously misquoted Peter Singer as going from saying things are sensitive to numbers to being 'merely sensitive'. I just wanted to point this out, as I really don't like this sort of rhetorical device, and think it should be a red-flag of sorts when trying to understand issues like this.</p><p>It's also an attempt to sneak in too large and controversial claims without argument. 1) EA or Utilitarianism reduces moral questions to technical ones, whereas EA seems to be full of moral theorising, and 2) that this is a central causal role in EAs success in the two communities mentioned.&nbsp;</p><blockquote><p><i>EA \u201cis quickly becoming the ideology of choice for Silicon Valley billionaires\u201d, one sceptical academic philosopher complained to me</i></p></blockquote><p>So this isn't Sandbu, but this \"sceptical academic philosopher's\" claim is presented too uncritically. Why are we only including Silicon Valley billionaires, and not multi-millionaires? Why only billionaires from the Valley? Less facetiously, when did this philosopher run a survey of Silicon Valley billionaires to actually get the evidence? There's simply none presented that this claim is actually true.</p><p>The kicker is, even if we accept that this is true, what does the insinuation even prove? If Silicon Valley billionaires collectively had a road to damascus moment and became Marxists in the hope of supporting a change to a communist regime, would this discredit Marxism purely by virtue of rapid uptake amongst Silicon Valley billionaires? I don't think so, and so I can only interpet this quip to be another exhortation of 'Silicon Valley people bad'.</p><p>&nbsp;</p><h2>Final Thoughts</h2><h3>Common Themes in Criticism</h3><p>I think many people, when they write articles like this, often frame it implicitly or explicitly through a template of\"EA was once good (global dev), EA is now bad (AI)\". This is a nice and simple story to write, but I don't think it's particularly true, or at least it's a fragmentary attempt at reaching the truth. Much of EA (the majority of money, plurality of people?) are still focused on Global Health, and concern about AI risk was also a part of EA from the very beginning.</p><p>Articles like this also often raise moral questions or dilemmas EAs engage with, but either ignore the corresponding dilemma that the status quo or common-sense moral view faces, or assumes that EAs haven't discussed the difficulties of the case. I like a randomista vs systemic debate as much as the next EA, but it would be good to see an article recognise that EA isn't at step 1 on this topic, and consider that <a href=\"https://80000hours.org/podcast/episodes/elie-hassenfeld-givewell-critiques-and-lessons/#whether-economic-policy-is-what-really-matters-overwhelmingly-022000\">the people involved might have thought about it</a> instead of being unaware of it.</p><p>Finally, I really wish EA got better at responding to pieces like this. I definitely feel it is at least <i>de-facto </i>true, if not <i>de-jure </i>the case, that the EA policy is to not respond to things like this at all. This doesn't have to have been a conscious decision by 'big EA', it can still occur if each EA thinks it isn't their responsibility to respond. But I think that the current state of affairs isn't good,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3xta4xo6mwa\"><sup><a href=\"#fn3xta4xo6mwa\">[9]</a></sup></span>&nbsp;and it <i>feels</i> to me that a lot of EA is playing prevent-defense&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefj9rev8vxy1\"><sup><a href=\"#fnj9rev8vxy1\">[10]</a></sup></span>&nbsp;right now, rather than either pushing back on bad criticism, or trying to integrate useful and valid critiques.</p><p>&nbsp;</p><h3><strong>What's next for this sequence?</strong></h3><p>I was actually already writing a post for another response before this article popped up on my radar and I switched track. &nbsp;The post in question was going to respond to a <a href=\"https://verybadwizards.com/episode/episode-274-can-i-get-a-kidney-voucher-with-vlad-chituc\">recent episode</a> of <i>Very Bad Wizards </i>that's (mostly) about EA. Some of the criticisms, as well the same factual mistakes, are repeated but there are some interesting perspectives to consider, especially from Tamler who I think would defend a strong form of moral localism/partiality.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefk50xzg4gg6h\"><sup><a href=\"#fnk50xzg4gg6h\">[11]</a></sup></span></p><p>Another public EA criticism I've started to look into is Eli Tyre's <a href=\"https://nitter.net/EpistemicHope/status/1733214923529052328#m\">viral Twitter thread</a> which provoked a lot of responses from across EA-adjacent Twitter. To be honest, I was quite surprised to see various people react initially positive to it, though my vague read of the Twitter tea-leaves is that the the later reaction was a bit less positive. You could probably guess what my overall reaction was (though hopefully not all my reasons why).</p><p>After that I think I want to start writing up some more positive posts (as in, making a positive case <i>for </i>something) about what Third-Wave EA could look like, instead of continuously falling behind an ever-growing in-tray of EA criticisms which don't seem to care enough to prevent robust supporting evidence for their general claims. This isn't to say that EA isn't worth criticising, or doesn't deserve criticism. If people could point me in the direction of higher-quality things to critique, I'd really appreciate it.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnw3wnli6jpsg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefw3wnli6jpsg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For reference, this is<a href=\"https://nitter.net/Gilesyb/status/1706221606429769889#m\"> the thread</a> why. Giles seems to get lots wrong about EA, gets called out by Tom Chivers, and doesn't ever admit he's wrong or reply convincingly to the pushback. Really means he's on 'epistemic probation' for me when discussing EA.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnh3i97ujqevn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefh3i97ujqevn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>John Stuart Mill, for example, was already developing utilitarianism to be more advanced/less na\u00efve than what he saw as Bentham's approach in the 1860s.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn84y6gyu7aha\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref84y6gyu7aha\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Source is the Normative Ethics question in the 2020 PhilPaper's survey <a href=\"https://survey2020.philpeople.org/survey/results/4890\">here</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3bu7pq7m6q9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3bu7pq7m6q9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Infinitely many, in fact</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9homdhp7fx\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9homdhp7fx\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Potentially, not necessarily, in a space/time impartial totalising sense, but I think other axiologies are compatible with EA too</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjayo0cwn6i\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjayo0cwn6i\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Yes, the same Broome who supervised both MacAskill and Ord&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn19dgr5u9gw1\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref19dgr5u9gw1\">^</a></strong></sup></span><div class=\"footnote-content\"><p>My main claim here isn't (necessarily) to argue for one political or economic view over another, but to state that <i>any </i>evidence we can have about which one is 'correct' will be limited</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngxrgiuliu1a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgxrgiuliu1a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There is a chance that Strudler gave a more worked-out case against EA, or presented a more nuanced one, but Sandbu cut this from the article.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3xta4xo6mwa\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3xta4xo6mwa\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See the continuing stream of articles like <a href=\"https://venturebeat.com/ai/ai-and-policy-leaders-debate-web-of-effective-altruism-in-ai-security-the-ai-beat/\">this</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnj9rev8vxy1\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefj9rev8vxy1\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Prevent-Defence is <a href=\"https://bleacherreport.com/articles/2499421-nfl-101-introducing-the-basics-of-prevent-defenses\">a term from the NFL</a>, generally describing cases where a team in the lead will play an incredibly-conservative defensive strategy in order to minimise giving up long-range passes or touchdowns. Anecdotally, this seems to often be too conservative in practice, and leads to the perception that it often ends up harming the team in the lead rather than helping.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnk50xzg4gg6h\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefk50xzg4gg6h\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Sorry if I'm wrong about that Tamler!</p></div></li></ol>", "user": {"username": "JWS"}}, {"_id": "6gXdbMzBh6ZbqbdZL", "title": "Some thoughts on moderation in doing good", "postedAt": "2024-01-20T09:28:55.128Z", "htmlBody": "<p><i>This is a </i><a href=\"https://forum.effectivealtruism.org/posts/8yDsenRQhNF4HEDwu/link-posting-is-an-act-of-community-service\"><i>crosspost</i></a><i> for </i><a href=\"https://80000hours.org/2023/05/moderation-in-doing-good/\"><i>Some thoughts on moderation in doing good</i></a><i> by Benjamin Todd, as published on 80,000 Hours' website on 5 May 2023.</i></p><p>Here\u2019s one of the deepest tensions in doing good:</p><p>How much should you do what seems right to you, even if it seems extreme or controversial, vs how much should you <i>moderate</i> your views and actions based on other perspectives?</p><p>If you moderate too much, you won\u2019t be doing anything novel or ambitious, which really reduces how much impact you might have. The people who have had the biggest impact historically often spoke out about entrenched views and were met with hostility \u2014 think of the civil rights movement or Galileo.</p><p>Moreover, simply following ethical \u2018common sense\u2019 has a horrible track record. It used to be common sense to think that homosexuality was evil, slavery was the natural order, and that the environment was there for us to exploit.</p><p>And there is still so much wrong with the world. Millions of people die of easily <a href=\"https://80000hours.org/problem-profiles/health-in-poor-countries/\">preventable diseases</a>, society is deeply unfair, billions of animals are tortured in <a href=\"https://80000hours.org/problem-profiles/factory-farming/\">factory farms</a>, and we\u2019re gambling our entire future by failing to mitigate threats like <a href=\"https://80000hours.org/problem-profiles/climate-change/\">climate change</a>. These huge problems deserve radical action \u2014 while conventional wisdom appears to accept doing little about them.</p><p>On a very basic level, doing more good is better than doing less. But this is a potentially endless and demanding principle, and most people don\u2019t give it much attention or pursue it very systematically. So it wouldn\u2019t be surprising if a concern for doing good led you to positions that seem radical or unusual to the rest of society.</p><p>This means that simply sticking with what others think, doing what\u2019s \u2018sensible\u2019 or common sense, isn\u2019t going to cut it. And in fact, by choosing the apparently \u2018moderate\u2019 path, you could still end up supporting things that are actively evil.</p><p>But at the same time, there are huge dangers in blazing a trail through untested moral terrain.</p><h2><strong>The dangers of extremism</strong></h2><p>Many of the most harmful people in history were convinced they were right, others were wrong \u2014 and they were putting their ideas into practice \u201cfor the greater good\u201d but with disastrous results.</p><p>Aggressively acting on a narrow, contrarian idea of what to do has a worrying track record, which includes people who have killed tens of millions and dominated whole societies \u2014 consider, for example, the the <a href=\"https://en.wikipedia.org/wiki/Leninism\">Leninists</a>.</p><p>The truth is that you\u2019re almost certainly wrong about what\u2019s best in some important ways . We understand very little of what matters, and everything has cascading and unforeseen effects.</p><p>Your model of the world should produce uncertain results about what\u2019s best, but you should <i>also</i> be uncertain about <i>which</i> models are best to use in the first place.</p><p>And this uncertainty arises not only on an empirical level but also about what matters in the first place (<a href=\"https://80000hours.org/articles/moral-uncertainty/\">moral uncertainty</a>) \u2014 and probably in ways you haven\u2019t even considered (\u2018unknown unknowns\u2019).</p><p>As you add additional considerations, you will often find that not only does <i>how good</i> an action seems to change, but even whether the action seems good or bad at all may change (<a href=\"https://forum.effectivealtruism.org/topics/crucial-consideration\">\u2018crucial considerations\u2019</a>).</p><p>For instance, technological progress can seem like a clear force for good as it raises living standards and makes us more secure. But if technological advances create new <a href=\"https://80000hours.org/articles/existential-risks/\">existential risks</a>, the impact could be uncertain or even negative on the whole. And yet again, if you consider that faster technological development might get us through <a href=\"https://forum.effectivealtruism.org/topics/time-of-perils\">a particularly perilous period of history</a> more quickly, it could seem positive again \u2014 and so on.</p><p>Indeed, even the question of how to <i>in principle</i> handle all this uncertainty is itself very uncertain. There is no widely accepted version of \u2018decision theory,\u2019 and efforts to make one quickly run into paradoxes or deeply unintuitive implications.</p><p>It\u2019s striking that almost any moral view taken entirely literally leads to bizarre and extreme conclusions:</p><ul><li>A deontologist who wouldn\u2019t lie to save the entire world</li><li>Radical \u2018deep ecology\u2019 environmentalists who think it would be better if humans died out</li><li>The many counterintuitive implications of utilitarianism</li></ul><p>How are we to wrestle with all these different perspectives?</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6gXdbMzBh6ZbqbdZL/ukufac0mdnccuefd96qb\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6gXdbMzBh6ZbqbdZL/ukufac0mdnccuefd96qb 1024w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6gXdbMzBh6ZbqbdZL/mbs5vqzyv98iahjsxl0f 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6gXdbMzBh6ZbqbdZL/tul5esfitpgozp4jwhyu 768w\"></p><h2><strong>The case for moderation</strong></h2><p>One thing that\u2019s clear is that the course of action that seems best likely has some serious downsides you haven\u2019t considered.</p><p>Partly this is true due to good old-fashioned self-delusion. But even for an honest and well-intentioned actor, there are good reasons to expect this mismatch to <a href=\"https://forum.effectivealtruism.org/topics/optimizer-s-curse\">happen</a> <a href=\"https://en.wikipedia.org/wiki/Regression_toward_the_mean\">theoretically</a>, and it <a href=\"https://80000hours.org/2023/02/how-much-do-solutions-differ-in-effectiveness/#case-study-givewell\">has been seen empirically</a>.</p><p>Whenever someone proposes an action that seems unusually impactful, further investigation is far more likely to produce reasons that the impact is less good than it first seemed.</p><p>Indeed, there are good reasons to think that aggressively maximising based on a single perspective is almost <i>bound</i> to go wrong in the face of huge uncertainty.</p><p>The basic idea is that if your model is missing lots of what matters, and you try to aggressively push for one outcome that makes sense to you, it\u2019ll probably come at the expense of those other values and outcomes that are missing from your model. (This idea is closely related to <a href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law\">Goodhart\u2019s Law</a> and the <a href=\"https://en.wikipedia.org/wiki/AI_alignment\">AI alignment problem</a>.)</p><p>This kind of naive optimisation is especially likely to go wrong when the things that are missing from your model are harder to measure than the main thing you\u2019re focused on, since it\u2019s so seductive to trade a concrete gain for an ill-defined loss.</p><p>There are many more reasons to moderate your views:</p><ul><li><strong>Epistemic humility</strong>: If lots of people disagree with you about what\u2019s best, and they have similar (and likely greater) information to you, then there\u2019s little reason to think you\u2019re right and they\u2019re wrong.</li><li><strong>Reputation effects</strong>: If you take extreme actions, and especially if they turn out badly, you\u2019ll become seen as a bad, reckless, or norm-breaking actor by others. And you\u2019ll also damage the reputation of the causes, ideas and communities you\u2019re associated with. This is an especially big deal since all your impact is mediated by being able to work with and coordinate with other people.</li><li><strong>Signalling and norm setting</strong>: Actions we take have direct and indirect effects. One key type of indirect effects that may be overlooked is that they signal to others what\u2019s acceptable, shaping the kind of society we live in. If we send the signal that social norms can easily be broken whenever any given individual thinks of a reason to do so, that\u2019s damaging.</li><li><strong>Character</strong>: Humans are creatures of habit. Acting unilaterally or on extremist views in one situation is likely to turn you into the type of person who disregards norms habitually.</li><li><strong>Efficiency arguments</strong>: Other people care about doing good to some degree, so truly easy ways to do a lot of good should have been taken already. If you think you\u2019ve found an apparently outsized way to do a lot of good, you should be sceptical of your reasoning.</li><li><strong>Trade</strong>: If you don\u2019t think a certain outcome matters that much, but lots of others do, it\u2019s often worth putting some weight on those values, since it will facilitate cooperation in the future.</li><li><strong>The unilateralist\u2019s curse</strong>: If everyone working on an issue simply pursues the course of action that makes sense to them, this will lead to the field as a whole systematically taking overly risky actions.</li><li><strong>Chesterton\u2019s fence</strong>: Common sense or conventional ways of doing things often contain evolved wisdom, even if we can\u2019t see why they work (also see the <a href=\"https://slatestarcodex.com/2019/06/04/book-review-the-secret-of-our-success/\"><i>The Secret of Our Success</i></a>).</li><li><strong>Burnout</strong>: You have lots of needs, so focusing too much on a single goal is likely to be shortsighted and cause you to become unhappy and give up.</li></ul><p>All this means that some degree of moderation is crucial. The difficult question then is to moderate by <i>how much</i> and in <i>what ways</i>.</p><h2><strong>Striking the balance</strong></h2><p>After <a href=\"https://80000hours.org/articles/earning-to-give/#doing-harm\">FTX</a>, I definitely <a href=\"https://forum.effectivealtruism.org/posts/jpyMhAPSmZER9ASi6/my-updates-after-ftx\">feel like moderation is even more important than I thought before</a>. But striking the right balance still feels very hard.</p><p>I think the question of how much to moderate may well be the biggest driver of differences in cause selection in <a href=\"https://80000hours.org/articles/effective-altruism/\">effective altruism</a>. People who are more into moderation are more likely to work on global health, while those who are less moderate are more likely to work on AI alignment. (I\u2019m not saying this is a good state of affairs \u2013 I think there are ways to work on AI alignment that are compatible with moderation \u2013 but it seems likely empirically.)</p><p>And the tradeoff comes up in many other places, for instance:</p><ul><li>How much money to spend on saving time even if doing so isn\u2019t normal in the charity sector and could easily be self-serving</li><li>How countercultural vs normal should the your life outside of work be</li><li>Deciding when it\u2019s justified to break norms, be inconsiderate or say unpopular things in order to advance some other important goal</li><li>How possible it is to be more successful than average at conventional things like making money, running an organisation or making predictions</li><li>How much it makes sense to be really ambitious, maximise, and optimise</li></ul><p>The spectrum also has many dimensions. Moderation can sometimes look like humility, prudence, pluralism or cooperativeness. Here I\u2019m just trying to point at the broad cluster of ideas, rather than precisely define a single concept.</p><p>So, under what circumstances should you bet against conventional wisdom, and how much should you moderate?</p><p>Here are some notes about how I currently think about the balancing act in my own decision making, which I think of as attempt to create a <i>cautious contrarianism</i>:</p><ol><li><strong>Use conventional wisdom as your starting point or prior.</strong></li><li><strong>Generally stick with conventional wisdom except for a couple of carefully thought through \u2018bets\u2019 against it.</strong> You should have an explanation for what other people are missing. Spotting one important way people are wrong is already hard enough, so you need to pick your battles \u2014 and <a href=\"https://forum.effectivealtruism.org/posts/MH9suFZbxXCYsr5Z5/you-have-a-set-amount-of-weirdness-points-spend-them-wisely\">being unconventional has costs</a>. So for example, if a startup is launching an innovative product, it should probably just apply best practices in its corporate management, rather than also trying to innovate in how to run a company.</li><li><strong>In working out what these bets should be, don\u2019t just apply a single perspective.</strong> Consider a range of perspectives, including common sense, expert opinion and other plausible models and heuristics, weighing them based on their strength. Seek out the best reasons you might be wrong. Remind yourself that you\u2019re very likely to be deluding yourself.</li><li><strong>It\u2019s safest to eliminate any courses of action that seem very bad according to one important perspective.</strong> If you can\u2019t do this, proceed cautiously and be open to changing your mind.</li><li><strong>In particular, don\u2019t do anything that seems very wrong from a common sense perspective \u2018for the greater good.\u2019</strong> Respect the rights of others and cultivate good character. Yes, in principle there are exceptions to this rule, but if you think you\u2019re one of them, you\u2019re almost certainly not.</li><li><strong>Once you\u2019ve limited your downsides, then seek the course of action with the most upside according to your different perspectives.</strong> It\u2019s OK to have your actions driven by one perspective, and to aim ambitiously at long shots, if other perspectives are ambivalent or neutral about it (rather than very negative). Maximise with moderation.</li><li><strong>The more leverage, scale and effect on other people you seek, the more vetting and caution to apply.</strong> Chatting about a radical policy with a friend is totally different from pushing for a government to adopt it.</li></ol><p>Here are some more notes about the nuances of applying these:</p><ul><li>In general, it\u2019s much more important to moderate your <i>actions</i> (since they could have big direct negative consequences for others) than your <i>views</i>. Indeed, it can be actively good to try to develop unusual views about a topic, since that can add to the collective wisdom. I don\u2019t mean to advance a strong form of epistemic modesty in which you should believe what everyone else believes.</li><li>It\u2019s also useful to distinguish between your internal <i>\u2018impressions\u2019</i> \u2014 how things seem to you \u2014 and your <i>\u2018all-considered view,\u2019</i> which takes account of the outside view and peer disagreement. It\u2019s fine and often healthy to foster contrarian impressions, but when taking high-stakes action, it\u2019s important to use your all-considered view.</li><li>It\u2019s helpful to think in terms of <i>upsides, downsides, and the median case.</i> Your all-considered view might be that a contrarian position has an 80% chance of being wrong, but if in the 20% scenario acting on it would do a lot of good, and being wrong won\u2019t have big downsides, then it can be well worth betting on that contrarian view \u2014 even though it\u2019s most likely to be wrong.</li><li>I\u2019ve framed things in terms of \u201celiminate big downsides, then seek upsides\u201d since I think that\u2019s a reasonable approximation that\u2019s relatively easy to apply. A more sophisticated version could involve something more like a moral parliament, in which different perspectives have a different number of votes according to your confidence in them, and they collectively bargain to come up with the overall policy. For example, a deontological perspective would be very opposed to violating rights, whereas a utilitarian one will want to do whatever helps the most people. Collectively, this could end up as picking the action that helps the most people but doesn\u2019t violate rights.</li></ul><p>All this is pretty complicated to apply, and I\u2019m not sure it would provide bright enough lines to do much to prevent dangerous behaviour in practice, so more work to develop these norms seems useful. We also need other mechanisms to prevent bad behaviour, like good governance \u2014 this post is only about one perspective on the problem.</p><p>If the main concern is to avoid dangerous behaviour, then I think point (5) about not harming others is most important.</p><p>Part of this is because the cases that seem most problematic historically seem to mostly involve dishonesty, rights violations, and domination over others (e.g. totalitarian communism and fascism).</p><h2><strong>Cautious contrarianism</strong></h2><p>There are lots of ways to support radical ideas that don\u2019t have these features, such as non-violent protest or academic debate. It\u2019s possible and necessary to have sandboxes, such as academia, where radical ideas can be explored and developed without immediate attempts to apply them.</p><p>Or consider the <a href=\"https://80000hours.org/after-hours-podcast/episodes/andres-jimenez-zorrilla-shrimp-welfare-project/\">Shrimp Welfare Project</a>. Promoting shrimp welfare sounds a bit nuts at first, but even if shrimp welfare turns out to be entirely unimportant, it\u2019s not doing direct, serious harm to anyone \u2014 the likely worst case is that resources are wasted.</p><p>People who want to do good are on the safest ground when they can find projects like these. They\u2019re on the most shaky ground when they try to force change on society as a whole.</p><p>Another simpler framework would be <strong>\u2018constrained maximisation.\u2019</strong> Try to do the most good you can, but within the constraints of respecting rights, having a good character and your other important personal goals.</p><p>Here are some things that I think follow from cautious contrarianism:</p><ul><li><strong>Have some balance in your life.</strong> Doing more good isn\u2019t the only thing that matters. It\u2019s healthy to have a life that\u2019s normal in most other ways.</li><li><strong>Always consider multiple kinds of outcomes</strong> \u2014 don\u2019t measure everything in terms of QALYs or existential risk reduction.</li><li><strong>Take peer disagreement seriously,</strong> especially when others think your actions might cause a lot of harm.</li><li><strong>Don\u2019t surround yourself only with people who share your worldview.</strong> Have some friends or colleagues with other views.</li><li><strong>Both means and ends matter.</strong></li><li><strong>It basically rules out individual acts of violence,</strong> even if you think it might be justified to respond to a major risk like climate change or AI.</li><li><strong>I don\u2019t identify as a utilitarian</strong> \u2014 I think there\u2019s a bunch of truth in it, but we\u2019re too uncertain about ethics for me to identify with any single perspective.</li><li><strong>Don\u2019t reinvent the wheel.</strong> Apply best practice in most areas of your life.</li></ul><p>None of these are absolutes. Gandhi definitely didn\u2019t \u2018live an otherwise normal life\u2019 and that was part of his influence. It\u2019s plausible there are cases when you should violate these guidelines, but you should do so deliberately, cautiously, and with considered awareness of the downsides.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6gXdbMzBh6ZbqbdZL/bkiod7xrqfzlmpxrnipl\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6gXdbMzBh6ZbqbdZL/bkiod7xrqfzlmpxrnipl 967w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6gXdbMzBh6ZbqbdZL/zax1bhi3r22dh1nbgz01 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/6gXdbMzBh6ZbqbdZL/tph7rhfvavyxnginelkz 768w\"></p><p>Some warning signs that could suggest someone isn\u2019t applying cautious contrarianism:</p><ul><li><strong>Willingness to break norms or twist the truth</strong> to help their project</li><li><strong>Almost never taking on board criticism or deferring to peers</strong>: I don\u2019t think people are obligated to respond to all criticism that\u2019s directed at them all the time, but if you know someone well who\u2019s doing a high-stakes project, you should see at least some serious attempts to engage with the best critics.</li><li><strong>Expressing a lot of confidence about totally unsettled areas</strong> like philosophy or topics way outside their area of expertise</li><li><strong>Being a unilateralist,</strong> that is, doing things a large fraction of their field thinks have significant harm</li><li><strong>Making rapid and radical changes to their whole life based on a single argument or philosophical view</strong></li></ul><p>However, it\u2019s <i>not</i> a warning sign to <i>seriously consider</i> weird ideas with radical implications.</p><p>Almost all ideas could lead to crazy, harmful, or weird-seeming implications if pursued to their logical end or allowed to dominate your life. <strong>You need to learn the skill of holding multiple conflicting perspectives in mind and coming to some kind of synthesis of them.</strong></p><p>Unfortunately there\u2019s no fully principled way to make these tradeoffs, but I think we face something similar in normal life all the time with internal conflicts. Maybe part of you wants to be a parent, but part of you wants freedom. These drives would lead to very different lives, so how do you balance them?</p><p>There is no easy answer, and completely overriding either drive would be bad. Hopefully, you can come to some kind of compromise or synthesis that both sides of yourself are happy with.</p><p>Likewise, we have to do our best to balance contradictory worldviews and perspectives.</p><p>When it comes to effective altruism in particular: doing more good matters and is underappreciated, but it\u2019s not the only thing that counts, and shouldn\u2019t be the only focus of your life.</p>", "user": {"username": "vascoamaralgrilo"}}, {"_id": "jdCXyhp8vSjHxbTLT", "title": "A longtermist case for directed panspermia", "postedAt": "2024-01-21T19:29:52.120Z", "htmlBody": "<p>I previously asked whether Longtermism entails that we should prepare what I call a biotic hedge, in case we should fail to prevent existential catastrophe. I received some very helpful feedback. Here is the original question: <a href=\"https://forum.effectivealtruism.org/posts/FvfJSkJYNZwRYL6XD/does-utilitarian-longtermism-imply-directed-panspermia\">https://forum.effectivealtruism.org/posts/FvfJSkJYNZwRYL6XD/does-utilitarian-longtermism-imply-directed-panspermia</a></p>\n<p>The biotic hedge refers to directed panspermia, which is where we intentionally send out the seeds of life to other planets or moons around the galaxy. This is to hedge against the possibility that all life on earth is wiped out. We know that in 4 billion years the sun will expand and engulf earth, which would constitute such an event.</p>\n<p>Longtermisn is the view that we should evaluate our actions based on how they will affect future beings, not just present beings.</p>\n<p>A common objection to directed panspermia is that it constitutes an irreversible, possibly harmful action (in a epistemic sense), which should be avoided if possible.</p>\n<p>Consider a few trolley problems. They take place in Trolleyville, where it\u2019s a possibility that persons are tied to tracks, but that\u2019s all you know. Assessing the probability of this is a challenge.</p>\n<p>Tunnel and Wall 1. A trolley is careening toward a wall. Five people  are tied to the wall. A second track diverts into a tunnel, which you cannot see into. You have the option to pull a switch and divert the trolley into the tunnel. The trolley will surely kill the people if it hits them and the wall. Who knows what might happen in the tunnel. This is Trolleyville, after all. Should you pull the switch?</p>\n<p>It seems obvious to me that you should.</p>\n<p>Tunnel and Wall 2. Now suppose the same tunnel and wall setup, but instead the five people are on the trolley. Should you pull the switch?</p>\n<p>Again, it seems like you should, even though this is Trolleyville.</p>\n<p>Tunnel and Wall 3. Again, we have the same tunnel and wall setup, but this time we have only possible future persons on the trolley (fertilized embryos, maybe). If they hit the wall, they will never come to exist. If they go in the tunnel, they might.</p>\n<p>In all cases, we take irreversible, potentially harmful action to save some morally relevant persons. Cases 1 and 2 suffice to show that these conditions are not enough to make action impermissible.</p>\n<p>Clearly I must defend case 3 a bit. I do not expect the same intuitive support. But I do think that it is morally congruent in relevant ways.</p>\n<p>First, I draw on the longtermist claim that future persons matter morally, and this mattering is not discounted by time, like money is. One future person matters morally just as much as one presently existing person.</p>\n<p>The moral value of actions that affect them may be discounted by epistemic considerations, like by the probability that an action has a particular effect on them. But not by time alone.</p>\n<p>These possible persons also need not be humans. I draw on standard claims about speciesism, that humans are not the only beings that matter morally. I think the case is morally the same whether the possible future persons are humans or not.</p>\n<p>So just as in cases 1 and 2, if in case 3 we pull the switch, we send a trolley careening down a tunnel. We don\u2019t know if any people or morally relevant beings are on the tunnel track in any case. We have to work with the information we have. In cases 1 and 2, it seems like the information we have requires us to pull the switch. But there is no moral difference in case 3. So even without the intuition, it seems we must still pull the switch.</p>\n<p>I can map these three cases to some more concrete existential risk examples, which I will now do.</p>\n<p>Case 1 is an asteroid. A big one. It would wipe out all life on earth. If possible, we should divert the asteroid. We are not sure if it will hit and destroy some other morally relevant life elsewhere in the universe. But we should divert it anyway.</p>\n<p>Case 2 is human spacefaring. If we can achieve this, we should, because it saves humanity from certain doom on Earth due to the expansion of the Sun.</p>\n<p>Case 3 is directed panspermia. If we don\u2019t do it, we ensure that future persons in the Earth-originated tree of life get engulfed by the Sun, while sending Earth-originated life to the universe saves it from this fate.</p>\n<p>The ignorance about what might be in the tunnel does not absolve us of the responsibility of saving morally relevant beings from a certain doom. It shouldn\u2019t absolve us of the responsibility to preserve future persons obtainable by directed panspermia.</p>\n<p>I believe I can strengthen the intuition a bit if I appeal to some conceivable scientific advances that might arrive soon. Namely, it may be possible to develop biological material that can be stored on a ship, and when it comes into contact with habitable environments, it develops into human beings just as a zygote does. It should be intuitive that if we could do this, it would be permissible, given longtermist values. There is no distinction between these humans and those send spacefaring on a ship, other than the social discontinuity of birth.</p>\n<p>But if we are to avoid the accusation of speciesism, we should be willing to send other such biological material that will develop into other morally relevant beings. I contend that this is directed panspermia. It seems reasonable to claim that eventually morally relevant beings will evolve, if not full nonhuman persons, from appropriately selected biological samples.</p>\n<p>Consider two more cases.</p>\n<p>Tunnel and Wall 4. Five people, including you, are in a trolley careening toward a wall. In front of the tunnel, tied on the track, is one person. Is it permissible for you to pull the switch inside the trolley to veer into the tunnel, killing the one who is tied up, but saving the five in the trolley?</p>\n<p>Tunnel and Wall 5. Five people, including you, are on a trolley careening toward a wall. You can pull a switch and divert into a tunnel. As far as you can see, nothing is tied to the track, but this is Trolleyville.</p>\n<p>The analogous existential risk cases might be as follows. For case 4, an asteroid is heading toward Earth. Suppose we can save ourselves only by diverting it into Europa, and suppose we know it has life. Case 5 is like this, but we do not know if life is on Europa.</p>\n<p>Between cases 4 and 5, 5 is clearly less morally troubling. I think case 4 is such that pulling the switch is morally permissible. But then case 5 is morally permissible. From a moral, longtermist perspective, 5 is nearly identical to case 3. The only difference is that you and four others are on the trolley in 5, while in 3 the trolley has possible future persons. According to longtermism, this is not a morally relevant difference. Case 5 seems permissible, if not obligatory. So case 3 should be permissible too, if not obligatory. Thus, given what we now know, it seems permissible to plan for and engage in directed panspermia, to ensure that possible future persons can exist beyond the expansion of the Sun.</p>\n<p>This has implications for how we approach space exploration. Careful sterilization of spacecraft and instruments makes sense from a scientific perspective, where we do not want to contaminate the environment in which we are trying to make discoveries. But the moral case for avoiding panspermia is less strong, especially when we do not know one way or the other whether life exists elsewhere. And even in some cases, it may be permissible to engage in directed panspermia if the risk to Earth\u2019s tree of life is great enough, even if there is reason to believe some primitive life exists on a target system.</p>\n", "user": {"username": "Ahrenbach"}}]