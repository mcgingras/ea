[{"_id": "Lpsqyr2Nu8pzNLajG", "postedAt": "2023-09-05T21:40:26.157Z", "postId": "GBAzW4pZ5JgJqGMJg", "htmlBody": "<p><strong>Executive summary</strong>: The post discusses the open source and closed source models for AI development, arguing that both have failure modes of enabling catastrophic or dystopian outcomes. It proposes regulated source as an alternative model.</p><p><strong>Key points</strong>:</p><ol><li>Open source risks irresponsible use of AI, while closed source risks centralized control and dystopia. Both have concerning failure modes.</li><li>The post proposes regulated source as an alternative model, with transparent standards and sharing of code/knowledge among approved organizations.</li><li>This aims to balance open proliferation and centralized control, avoiding the failure modes of both.</li><li>The IAEA provides a real-world model of regulated technology sharing among approved parties.</li><li>Much discussion focuses just on open vs closed source, but we need new approaches like regulated source.</li><li>The idea needs more development and analysis of opportunities, challenges, and drawbacks.</li></ol><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}]