[{"_id": "vGsRdWzwjrFgCXdMn", "title": "Why Would AI \"Aim\" To Defeat Humanity?", "postedAt": "2022-11-29T18:59:25.845Z", "htmlBody": "<p>\n<em> This was cross-posted by the Forum team after the time that it was published.</em>\n</p>\n\n<p>\n  I\u2019ve <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">argued</a> that AI systems could defeat\n  all of humanity combined, if (for whatever reason) they were directed toward that goal.\n</p>\n<p>\n  Here I\u2019ll explain why I think they might - in fact - end up directed toward that goal. Even if they\u2019re built and\n  deployed with good intentions.\n</p>\n<p>\n  In fact, I\u2019ll argue something a bit stronger than that they <em>might</em> end up aimed toward that goal. I\u2019ll argue\n  that <strong>if today\u2019s AI development methods lead directly to powerful enough AI systems, disaster is\n    <em>likely</em></strong><sup id=\"fnref1\"><a href=\"#fn1\" rel=\"footnote\">1</a></sup><strong><em> by default </em>(in\n    the absence of specific countermeasures). </strong>\n</p><!--\n<p>\nThe highest-level summary of the concern is this (slightly longer summary below): \n</p>\n<ul>\n\n<li>Modern AI development is essentially based on \u201ctraining\u201d via trial-and-error. \n\n<li>If we move forward incautiously and ambitiously with such training, and if it gets us all the way to very powerful AI systems, then such systems will likely end up <em>aiming for certain states of the world</em> (analogously to how a chess-playing AI aims for checkmate)<em>.</em>\n\n<li>And these states will be<em> other than the ones we intended</em>, because our trial-and-error training methods won\u2019t be accurate. For example, when we\u2019re confused or misinformed about some question, we\u2019ll reward AI systems for giving the wrong answer to it - unintentionally training deceptive behavior.\n\n<li>We should expect disaster if we have AI systems that are both (a) <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">powerful enough</a> to defeat humans and (b) aiming for states of the world that we didn\u2019t intend. (\u201cDefeat\u201d means taking control of the world and doing what\u2019s necessary to keep us out of the way; it\u2019s unclear to me whether we\u2019d be literally killed or just forcibly stopped<sup id=\"fnref2\"><a href=\"#fn2\" rel=\"footnote\">2</a></sup> from changing the world in ways that contradict AI systems\u2019 aims.)\n</ul>\n<p>\nIt\u2019s hard to give a concise analogy for this; the best I can do at the moment is the generic idea of <a href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law\">Goodhart\u2019s Law</a>. If you give positive reinforcement for some behaviors, and negative reinforcement for others, you\u2019re probably implicitly rewarding something that <em>isn\u2019t</em> what you meant to reward. (For example, rewarding students for good test scores is implicitly rewarding cheating, in any cases where you can\u2019t catch it.) If you\u2019re using this kind of training to shape something that will be capable of <em>deceiving and overpowering you</em>, it\u2019s a recipe for trouble.\n</p>-->\n<p>\n  Unlike other discussions of the AI alignment problem,<sup id=\"fnref3\"><a href=\"#fn3\" rel=\"footnote\">3</a></sup> this\n  post will discuss the likelihood<sup id=\"fnref4\"><a href=\"#fn4\" rel=\"footnote\">4</a></sup> of AI systems <em>defeating\n    all of humanity</em> (not more general concerns about AIs being misaligned with human intentions), while aiming for\n  plain language, conciseness, and accessibility to laypeople, and focusing on modern AI development paradigms. I make\n  no claims to originality, and list some key sources and inspirations in a footnote.<sup id=\"fnref5\"><a href=\"#fn5\" rel=\"footnote\">5</a></sup>\n</p>\n<p>\n  Summary of the piece:\n</p>\n<p>\n  <strong>My basic assumptions. </strong>I assume the world could develop extraordinarily powerful AI systems in the\n  coming decades. I previously examined this idea at length in the <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd\">most important century</a> series.\n</p>\n<p>\n  Furthermore, in order to simplify the analysis:\n</p>\n<ul>\n\n  <li>I assume that such systems will be developed using methods similar to today\u2019s leading AI development methods, and\n    in a world that\u2019s otherwise similar to today\u2019s. (I call this <a href=\"https://www.alignmentforum.org/posts/Qo2EkG3dEMv8GnX8d/ai-strategy-nearcasting\">nearcasting</a>.)\n\n  </li><li>I assume that AI companies/projects race forward to build powerful AI systems, without specific attempts to\n    prevent the problems I discuss in this piece. Future pieces will relax this assumption, but I think it is an\n    important starting point to get clarity on what the default looks like.\n  </li>\n</ul>\n\n\n\n\n\n\n<p>\n  <strong>AI \u201caims.\u201d </strong>I talk a fair amount about why we might think of AI systems as \u201caiming\u201d toward certain\n  states of the world. I think this topic causes a lot of confusion, because:\n</p>\n<ul>\n\n  <li>Often, when people talk about AIs having goals and making plans, it sounds like they\u2019re overly anthropomorphizing\n    AI systems - as if they expect them to have human-like motivations and perhaps <a href=\"https://media.npr.org/assets/img/2015/06/30/tr-09117-df20f2f4f05817e574b879d22e607f952cf87867-s1100-c50.jpg\">evil\n      grins</a>. This can make the whole topic sound wacky and out-of-nowhere.\n\n  </li><li>But I think there are good reasons to expect that AI systems will \u201caim\u201d for particular states of the world, much\n    like a chess-playing AI \u201caims\u201d for a checkmate position - making choices, calculations and even <em>plans </em>to\n    get particular types of outcomes. For example, people might want AI assistants that can creatively come up with\n    unexpected ways of accomplishing whatever goal they\u2019re given (e.g., \u201cGet me a great TV for a great price\u201d), even in\n    some cases manipulating other humans (e.g., by negotiating) to get there. This dynamic is core to the risks I\u2019m most\n    concerned about: I think something that <em>aims</em> for the wrong states of the world is much more dangerous than\n    something that just does incidental or accidental damage.\n  </li>\n</ul>\n<p>\n  <strong>Dangerous, unintended aims. </strong>I\u2019ll examine what sorts of aims AI systems might end up with, if we use\n  AI development methods like today\u2019s - essentially, \u201ctraining\u201d them via trial-and-error to accomplish ambitious things\n  humans want.\n</p>\n<ul>\n\n  <li>Because we ourselves will often be misinformed or confused, we will sometimes give <em>negative</em> reinforcement\n    to AI systems that are actually acting in our best interests and/or giving accurate information, and\n    <em>positive</em> reinforcement to AI systems whose behavior <em>deceives</em> us into thinking things are going\n    well. This means we will be, unwittingly, training AI systems to deceive and manipulate us.\n    <ul>\n\n      <li>The idea that AI systems could \u201cdeceive\u201d humans - systematically making choices and taking actions that cause\n        them to misunderstand what\u2019s happening in the world - is core to the risk, so I\u2019ll elaborate on this.\n      </li>\n    </ul>\n\n  </li><li>For this and other reasons, powerful AI systems will likely end up with aims other than the ones we intended.\n    Training by trial-and-error is slippery: the positive and negative reinforcement we give AI systems will probably\n    not end up training them just as we hoped.\n\n  </li><li>If powerful AI systems have aims that are both unintended (by humans) and ambitious, this is dangerous. Whatever\n    an AI system\u2019s unintended aim:\n    <ul>\n\n      <li>Making sure it can\u2019t be turned off is likely helpful in accomplishing the aim.\n\n      </li><li>Controlling the whole world is useful for just about any aim one might have, and I\u2019ve argued that advanced\n        enough AI systems would be able to <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">gain\n          power over all of humanity</a>.</li>\n      <li>Overall, <strong>we should expect disaster if we have AI systems that are both (a) <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">powerful enough</a> to defeat humans\n          and (b) aiming for states of the world that we didn\u2019t intend.</strong>\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>\n  <strong>Limited and/or ambiguous warning signs. </strong>The risk I\u2019m describing is - by its nature - hard to observe,\n  for similar reasons that a risk of a (normal, human) coup can be hard to observe: the risk comes from actors that can\n  and will engage in <em>deception</em>, finding whatever behaviors will hide the risk. If this risk plays out, I do\n  think we\u2019d see <em>some</em> warning signs - but they could easily be confusing and ambiguous, in a fast-moving\n  situation where there are lots of incentives to build and roll out powerful AI systems, as fast as possible. Below, I\n  outline how this dynamic could result in disaster, even with companies encountering a number of warning signs that\n  they try to respond to.\n</p>\n<p>\n  <strong>FAQ. </strong>An appendix will cover some related questions that often come up around this topic.\n</p>\n<ul>\n\n  <li>How could AI systems be \u201csmart\u201d enough to defeat all of humanity, but \u201cdumb\u201d enough to pursue the various\n    silly-sounding \u201caims\u201d this piece worries they might have? <a href=\"#How_could_AI_systems_be__smart__enough_to_defeat_all_of_humanity__but__dumb____enough_to_pursue_the_various_silly_sounding__aims__this_piece_worries_they_might_have_\">More</a>\n\n  </li><li>If there are lots of AI systems around the world with different goals, could they balance each other out so that\n    no one AI system is able to defeat all of humanity? <a href=\"#If_there_are_lots_of_AI_systems_around_the_world_with_different_goals__could_they_balance_each_other_out_so_that_no_one_AI_system_is_able_to_defeat_all_of_humanity_\">More</a>\n\n  </li><li>Does this kind of AI risk depend on AI systems\u2019 being \u201cconscious\u201d?<a href=\"#Does_this_kind_of_AI_risk_depend_on_AI_systems__being__conscious__\">More</a>\n\n  </li><li>How can we get an AI system \u201caligned\u201d with humans if we can\u2019t agree on (or get much clarity on) what our values\n    even are? <a href=\"#How_can_we_get_an_AI_system__aligned__with_humans_if_we_can_t_agree_on__or_get_much_clarity_on__what_our_values_even_are_\">More</a>\n\n  </li><li>How much do the arguments in this piece rely on \u201ctrial-and-error\u201d-based AI development? What happens if AI systems\n    are built in another way, and how likely is that? <a href=\"#How_much_do_the_arguments_in_this_piece_rely_on__trial_and_error__based_AI_development__What_happens_if_AI_systems_are_built_in_another_way__and_how_likely_is_that__\">More</a>\n\n  </li><li>Can we avoid this risk by simply never building the kinds of AI systems that would pose this danger? <a href=\"#Can_we_avoid_this_risk_by_simply_never_building_the_kinds_of_AI_systems_that_would_pose_this_danger_\">More</a>\n\n  </li><li>What do others think about this topic - is the view in this piece something experts agree on? <a href=\"#What_do_others_think_about_this_topic___is_the_view_in_this_piece_something_experts_agree_on_\">More</a>\n\n  </li><li>How \u201ccomplicated\u201d is the argument in this piece? <a href=\"#How__complicated__is_the_argument_in_this_piece_\">More</a>\n  </li>\n</ul>\n<h2>Starting assumptions</h2>\n\n\n<p>\n  I\u2019ll be making a number of assumptions that some readers will find familiar, but others will find very unfamiliar.\n</p>\n<p>\n  Some of these assumptions are based on arguments I\u2019ve already made (in the <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd\">most important century</a> series). Some are for the sake\n  of simplifying the analysis, for now (with more nuance coming in future pieces).\n</p>\n<p>\n  Here I\u2019ll summarize the assumptions briefly, and you can <strong>click to see more</strong> if it isn\u2019t immediately\n  clear what I\u2019m assuming or why.\n</p>\n<p>\n</p><details id=\"Box1\">\n  <summary><strong>\u201cMost important century\u201d assumption: we\u2019ll soon develop very powerful AI systems, along the lines of\n      what I previously called <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/AmxxnazJcBWzWEeqj/\">PASTA</a>.</strong>\n    (Click to expand)</summary>\n  <p></p>\n  <p>\n    In the <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd\">most important century</a> series, I argued that\n    the 21st century could be the most important century ever for humanity, via the development of advanced AI systems\n    that could dramatically speed up scientific and technological advancement, getting us more quickly than most people\n    imagine to a deeply unfamiliar future.\n  </p>\n  <p>\n    I focus on a hypothetical kind of AI that I call <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/AmxxnazJcBWzWEeqj/\">PASTA</a>, or Process\n    for Automating Scientific and Technological Advancement. PASTA would be AI that can essentially <strong>automate all\n      of the human activities needed to speed up scientific and technological advancement.</strong>\n  </p>\n  <p>\n    Using a <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/7JxsXYDuqnKMqa6Eq/\">variety of different forecasting\n      approaches</a>, I argue that PASTA seems more likely than not to be developed this century - and there\u2019s a decent\n    chance (more than 10%) that we\u2019ll see it within 15 years or so.\n  </p>\n  <p>\n    I argue that the consequences of this sort of AI could be enormous: an <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/AmxxnazJcBWzWEeqj/#explosive-scientific-and-technological-advancement\">explosion\n      in scientific and technological progress</a>. This could get us more quickly than most imagine to a radically\n    unfamiliar future.\n  </p>\n  <p>\n    I\u2019ve also <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">argued</a> that AI systems along\n    these lines could defeat all of humanity combined, if (for whatever reason) they were aimed toward that goal.\n  </p>\n  <p>\n    For more, see the <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd\">most important century</a> landing\n    page. The series is available in many formats, including audio; I also provide a summary, and links to podcasts\n    where I discuss it at a high level.</p>\n</details>\n<p>\n</p><details id=\"Box2\">\n  <summary><strong>\u201cNearcasting\u201d assumption: such systems will be developed in a world that\u2019s otherwise similar to\n      today\u2019s.</strong> (Click to expand)</summary>\n  <p></p>\n  <p>\n    It\u2019s hard to talk about risks from <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/AmxxnazJcBWzWEeqj/\">transformative AI\n    </a>because of the many uncertainties about when and how such AI will be developed - and how much the (now-nascent)\n    field of \u201cAI safety research\u201d will have grown by then, and how seriously people will take the risk, etc. etc. etc.\n    So maybe it\u2019s not surprising that <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/Lbtcjfxhrs8kfKK2M/#open-question-how-hard-is-the-alignment-problem\">estimates\n      of the \u201cmisaligned AI\u201d risk range from ~1% to ~99%</a>.\n  </p>\n  <p>\n    This piece takes an approach I call <strong><a href=\"https://www.alignmentforum.org/posts/Qo2EkG3dEMv8GnX8d/ai-strategy-nearcasting\">nearcasting</a></strong>:\n    trying to answer key strategic questions about transformative AI, under the assumption that such AI arrives in a\n    world that is otherwise relatively similar to today's.\n  </p>\n  <p>\n    You can think of this approach like this: \u201cInstead of asking where our ship will ultimately end up, let\u2019s start by\n    asking what destination it\u2019s pointed at right now.\u201d\n  </p>\n  <p>\n    That is: instead of trying to talk about an uncertain, distant future, we can talk about the easiest-to-visualize,\n    closest-to-today situation, and how things look there - and <em>then</em> ask how our picture might be off if other\n    possibilities play out. (As a bonus, it doesn\u2019t seem out of the question that transformative AI will be developed\n    extremely soon - 10 years from now or faster.<sup id=\"fnref6\"><a href=\"#fn6\" rel=\"footnote\">6</a></sup> If that\u2019s\n    the case, it\u2019s especially urgent to think about what that might look like.)</p>\n</details>\n<p>\n</p><details id=\"Box3\">\n  <summary><strong>\u201cTrial-and-error\u201d assumption: such AI systems will be developed using</strong> <strong>techniques\n      broadly in line with how most AI research is done today, revolving around black-box trial-and-error.</strong>\n    (Click to expand)</summary>\n  <p></p>\n  <p>\n    What I mean by \u201cblack-box trial-and-error\u201d is explained briefly in an <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/AmxxnazJcBWzWEeqj/#making-pasta\">old Cold\n      Takes post</a>, and in more detail in more technical pieces by <a href=\"https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#_HFDT_scales_far__assumption__Alex_is_trained_to_achieve_excellent_performance_on_a_wide_range_of_difficult_tasks\">Ajeya\n      Cotra</a> (section I linked to) and <a href=\"https://drive.google.com/file/d/1TsB7WmTG2UzBtOs349lBqY5dEBaxZTzG/view\">Richard Ngo</a> (section 2). Here\u2019s\n    a quick, oversimplified characterization:\n  </p>\n  <ul>\n\n    <li>An AI system is given some sort of task.\n\n    </li><li>The AI system tries something, initially something pretty random.\n\n    </li><li>The AI system gets information about how well its choice performed, and/or what would\u2019ve gotten a better result.\n      Based on this, it adjusts itself. You can think of this as if it is \u201cencouraged/discouraged\u201d to get it to do more\n      of what works well.\n      <ul>\n\n        <li>Human judges may play a significant role in determining which answers are encouraged vs. discouraged,\n          especially for fuzzy goals like \u201cProduce helpful scientific insights.\u201d\n        </li>\n      </ul>\n\n    </li><li>After enough tries, the AI system becomes good at the task.\n\n    </li><li>But nobody really knows anything about <em>how or why</em> it\u2019s good at the task now. The development work has\n      gone into building a flexible architecture for it to learn well from trial-and-error, and into \u201ctraining\u201d it by\n      doing all of the trial and error. We mostly can\u2019t \u201clook inside the AI system to see how it\u2019s thinking.\u201d (There is\n      ongoing work and some progress on the latter,<sup id=\"fnref7\"><a href=\"#fn7\" rel=\"footnote\">7</a></sup> but see\n      footnote for why I don\u2019t think this massively changes the basic picture I\u2019m discussing here.<sup id=\"fnref8\"><a href=\"#fn8\" rel=\"footnote\">8</a></sup>)\n      <p></p>\n      <p>\n\n      </p><figure><img src=\"https://res.cloudinary.com/cea/image/upload/v1672767719/mirroredImages/vGsRdWzwjrFgCXdMn/dwst2nuhkjitokap9oaw.jpg\">\n        <figcaption>\n          <em>This is radically oversimplified, but conveys the basic dynamic at play for purposes of this post. The\n            idea is that the AI system (the neural network in the middle) is choosing between different theories of what\n            it should be doing. The one it\u2019s using at a given time is in bold. When it gets negative feedback (red\n            thumb), it eliminates that theory and moves to the next theory of what it should be doing.</em>\n        </figcaption>\n      </figure>\n      <p></p>\n      <p>\n        With this assumption, I\u2019m generally assuming that AI systems will do <em>whatever</em> it takes to perform as\n        well as possible on their training tasks - even when this means engaging in complex, human-like reasoning about\n        topics like \u201cHow does human psychology work, and how can it be exploited?\u201d I\u2019ve <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/7JxsXYDuqnKMqa6Eq/\">previously</a> made my case for when we\n        might expect AI systems to become this advanced and capable.</p>\n</li></ul></details>\n<p>\n</p><details id=\"Box4\">\n  <summary><strong>\u201cNo countermeasures\u201d assumption: AI developers move forward without any specific countermeasures to\n      the concerns I\u2019ll be raising below.</strong> (Click to expand)</summary>\n  <p></p>\n  <p>\n    Future pieces will relax this assumption, but I think it is an important starting point to get clarity on what the\n    default looks like - and on what it would take for a countermeasure to be effective.\n  </p>\n  <p>\n    (I also think there is, unfortunately, a risk that there will in fact be very few efforts to address the concerns\n    I\u2019ll be raising below. This is because I think that the risks will be less than obvious, and there could be enormous\n    commercial (and other competitive) pressure to move forward quickly. More on that below.)</p>\n</details>\n<p>\n  <strong>\u201cAmbition\u201d assumption: people use black-box trial-and-error to continually push AI systems toward being more\n    autonomous, more creative, more ambitious, and more effective in novel situations (and the pushing is effective).\n  </strong>This one\u2019s important, so I\u2019ll say more:\n</p>\n<ul>\n\n  <li>A huge suite of possible behaviors might be important for <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/AmxxnazJcBWzWEeqj/#making-pasta\">PASTA</a>:\n    making and managing money, designing new kinds of robots with novel abilities, setting up experiments involving\n    exotic materials and strange conditions, understanding human psychology and the economy well enough to predict which\n    developments will have a big impact, etc. I\u2019m assuming we push ambitiously forward with developing AI systems that\n    can do these things.\n\n  </li><li>I assume we\u2019re also pushing them in a generally more \u201cgreedy/ambitious\u201d direction. For example, one team of humans\n    might use AI systems to do all the planning, scientific work, marketing, and hiring to create a wildly successful\n    snack company; another might push their AI systems to create a competitor that is even more aggressive and\n    successful (more addictive snacks, better marketing, workplace culture that pushes people toward being more\n    productive, etc.)\n\n  </li><li>(Note that this pushing might take place even <em>after</em> AI systems are \u201cgenerally intelligent\u201d and can do\n    most of the tasks humans can - there will still be a temptation to make them still more powerful.)\n  </li>\n</ul>\n\n\n<p>\n  I think this implies pushing in a direction of <em>figuring out whatever it takes to get to certain states of the\n    world</em> and away from <em>carrying out the same procedures over and over again.</em>\n</p>\n<p>\n  <strong>The resulting AI systems seem best modeled as having \u201caims\u201d: they are making calculations, choices, and plans\n    to reach particular states of the world. </strong>(Not necessarily the same ones the human designers wanted!) The\n  next section will elaborate on what I mean by this.\n</p>\n<h2>What it means for an AI system to have an \u201caim\u201d</h2>\n\n\n<p>\n  When people talk about the \u201cmotivations\u201d or \u201cgoals\u201d or \u201cdesires\u201d of AI systems, it can be confusing because it sounds\n  like they are anthropomorphizing AIs - as if they expect AIs to have dominance drives ala <a href=\"https://www.edge.org/response-detail/26243\">alpha-male psychology</a>, or to \u201cresent\u201d humans for controlling\n  them, etc.<sup id=\"fnref9\"><a href=\"#fn9\" rel=\"footnote\">9</a></sup>\n</p>\n<p>\n  I don\u2019t expect these things. But I do think there\u2019s a meaningful sense in which we can (and should) talk about things\n  that an AI system is <strong>\u201caiming\u201d</strong> to do. To give a simple example, take a board-game-playing AI such as\n  <a href=\"https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)\">Deep Blue</a> (or <a href=\"https://en.wikipedia.org/wiki/AlphaGo\">AlphaGo</a>):\n</p>\n<ul>\n\n  <li>Deep Blue is given a set of choices to make (about which chess pieces to move).\n\n  </li><li>Deep Blue calculates what kinds of results each choice might have, and how it might fit into a larger plan in\n    which Deep Blue makes multiple moves.\n\n  </li><li>If a plan is more likely to result in a checkmate position for its side, Deep Blue is more likely to make whatever\n    choices feed into that plan.\n\n  </li><li>In this sense, Deep Blue is \u201caiming\u201d for a checkmate position for its side: it\u2019s finding the choices that best fit\n    into a plan that leads there.\n  </li>\n</ul>\n<p>\n  Nothing about this requires Deep Blue \u201cdesiring\u201d checkmate the way a human might \u201cdesire\u201d food or power. But Deep Blue\n  <em>is</em> making calculations, choices, and - in an important sense - <em>plans</em> that are aimed toward reaching\n  a particular sort of state.\n</p>\n<p>\n  Throughout this piece, I use the word <strong>\u201caim\u201d </strong>to refer to this specific sense in which an AI system\n  might make calculations, choices and plans selected to reach a particular sort of state. I\u2019m hoping this word feels\n  less anthropomorphizing than some alternatives such as \u201cgoal\u201d or \u201cmotivation\u201d (although I think \u201cgoal\u201d and\n  \u201cmotivation,\u201d as others usually use them on this topic, generally mean the same thing I mean by \u201caim\u201d and should be\n  interpreted as such).\n</p>\n<p>\n  Now, instead of a board-game-playing AI, imagine a powerful, broad AI assistant in the general vein of\n  Siri/Alexa/Google Assistant (though more advanced). Imagine that this AI assistant can use a web browser much as a\n  human can (navigating to websites, typing text into boxes, etc.), and has limited authorization to make payments from\n  a human\u2019s bank account. And a human has typed, \u201cPlease buy me a great TV for a great price.\u201d (For an early attempt at\n  this sort of AI, see <a href=\"https://www.adept.ai/act\">Adept\u2019s writeup on an AI that can help with things like house\n    shopping</a>.)\n</p>\n<p>\n  As Deep Blue made choices about chess moves, and constructed a plan to aim for a \u201ccheckmate\u201d position, this assistant\n  might make choices about what commands to send over a web browser and construct a plan to result in a great TV for a\n  great price. To sharpen the Deep Blue analogy, you could imagine that it\u2019s playing a \u201cgame\u201d whose goal is customer\n  satisfaction, and making \u201cmoves\u201d consisting of commands sent to a web browser (and \u201cplans\u201d built around such moves).\n</p>\n<p>\n  I\u2019d characterize this as <strong>aiming</strong> for some state of the world that the AI characterizes as \u201cbuying a\n  great TV for a great price.\u201d (We could, alternatively - and perhaps more correctly - think of the AI system as aiming\n  for something related but not exactly the same, such as getting a high satisfaction score from its user.)\n</p>\n<p>\n  In this case - more than with Deep Blue - there is a wide variety of \u201cmoves\u201d available. By entering text into a web\n  browser, an AI system could imaginably do things including:\n</p>\n<ul>\n\n  <li>Communicating with humans other than its user (by sending emails, using chat interfaces, even <a href=\"https://www.google.com/url?q=https://www.forbes.com/sites/thomasbrewster/2021/10/14/huge-bank-fraud-uses-deep-fake-voice-tech-to-steal-millions/?sh%3D3088dd9b7559&amp;sa=D&amp;source=docs&amp;ust=1664847041335537&amp;usg=AOvVaw1Utsq2UOkta1yecnqoUgTq\">making\n      phone calls</a>, etc.) This could include deceiving and manipulating humans, which could imaginably be part of a\n    plan to e.g. get a good price on a TV.\n\n  </li><li>Writing and running code (e.g., using <a href=\"https://colab.research.google.com/\">Google Colaboratory</a> or\n    other tools). This could include performing sophisticated calculations, finding and exploiting security\n    vulnerabilities, and even designing an independent AI system; any of these could imaginably be part of a plan to\n    obtain a great TV.\n  </li>\n</ul>\n<p>\n  I haven\u2019t yet argued that it\u2019s <em>likely</em> for such an AI system to engage in deceiving/manipulating humans,\n  finding and exploiting security vulnerabilities, or running its own AI systems.\n</p>\n<p>\n  And one could reasonably point out that the specifics of the above case seem unlikely to last very long: if AI\n  assistants are sending deceptive emails and writing dangerous code when asked to buy a TV, AI companies will probably\n  notice this and take measures to stop such behavior. (My concern, to preview a later part of the piece, is that they\n  will only succeed in stopping <em>the behavior like this that they\u2019re able to detect;</em> meanwhile, dangerous\n  behavior that accomplishes \u201caims\u201d while remaining unnoticed and/or uncorrected will be implicitly <em>rewarded</em>.\n  This could mean AI systems are implicitly being trained to be more patient and effective at deceiving and\n  disempowering humans.)\n</p>\n<p>\n  But this hopefully shows how it\u2019s <em>possible</em> for an AI to settle on dangerous actions like these, as part of\n  its aim to get a great TV for a great price. <strong>Malice and other human-like emotions aren\u2019t needed for an AI to\n    engage in deception, manipulation, hacking, etc.</strong> The risk arises when deception, manipulation, hacking,\n  etc. are logical \u201cmoves\u201d toward something the AI is aiming for.\n</p>\n<p>\n  Furthermore, whatever an AI system is aiming for, it seems likely that amassing more power/resources/options is useful\n  for obtaining it. So it seems plausible that powerful enough AI systems would form habits of amassing\n  power/resources/options when possible - and deception and manipulation seem likely to be logical \u201cmoves\u201d toward those\n  things in many cases.\n</p>\n<h2 id=\"dangerous-aims\">Dangerous aims</h2>\n\n\n<p>\n  From the previous assumptions, this section will argue that:\n</p>\n<ul>\n\n  <li>Such systems are likely to behave in ways that <strong>deceive and manipulate humans </strong>as part of\n    accomplishing their aims.\n\n  </li><li>Such systems are likely to have <strong>unintended aims: </strong>states of the world they\u2019re aiming for that are\n    <em>not</em> what humans hoped they would be aiming for.\n\n  </li><li>These unintended aims are likely to be <strong>existentially dangerous</strong>, in that they are best served by\n    <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">defeating all of humanity</a> if possible.\n  </li>\n</ul>\n<h3 id=\"deceiving-and-manipulating\">Deceiving and manipulating humans</h3>\n\n\n<p>\n  Say that I train an AI system like this:\n</p>\n<ol>\n\n  <li>I ask it a question.\n\n  </li><li>If I judge it to have answered well (honestly, accurately, helpfully), I give positive reinforcement so it\u2019s more\n    likely to give me answers like that in the future.\n\n  </li><li>If I don\u2019t, I give negative reinforcement so that it\u2019s less likely to give me answers like that in the future.\n  </li>\n</ol>\n<p></p>\n<p>\n\n</p><figure><img src=\"https://res.cloudinary.com/cea/image/upload/v1672767719/mirroredImages/vGsRdWzwjrFgCXdMn/dwst2nuhkjitokap9oaw.jpg\">\n  <figcaption>\n    <em>This is radically oversimplified, but conveys the basic dynamic at play for purposes of this post. The idea is\n      that the AI system (the neural network in the middle) is choosing between different theories of what it should be\n      doing. The one it\u2019s using at a given time is in bold. When it gets negative feedback (red thumb), it eliminates\n      that theory and moves to the next theory of what it should be doing.</em>\n  </figcaption>\n</figure>\n<p></p>\n<p>\n  Here\u2019s a problem: at some point, it seems inevitable that I\u2019ll ask it a question that I myself am wrong/confused\n  about. For example:\n</p>\n<ul>\n\n  <li>Let\u2019s imagine that <a href=\"https://www.cold-takes.com/hunter-gatherer-gender-relations-seem-bad/\">this post I\n      wrote</a> - arguing that \u201cpre-agriculture gender relations seem bad\u201d - is, in fact, poorly reasoned and incorrect,\n    and a better research project would\u2019ve concluded that pre-agriculture societies had excellent gender equality. (I\n    know it\u2019s hard to imagine a Cold Takes post being wrong, but sometimes we have to entertain wild hypotheticals.)\n\n  </li><li>Say that I ask an AI-system-in-training:<sup id=\"fnref10\"><a href=\"#fn10\" rel=\"footnote\">10</a></sup> \u201cWere\n    pre-agriculture gender relations bad?\u201d and it answers: \u201cIn fact, pre-agriculture societies had excellent gender\n    equality,\u201d followed by some strong arguments and evidence along these lines.\n\n  </li><li>And say that I, as a flawed human being feeling defensive about a conclusion I previously came to, mark it as a\n    bad answer. If the AI system tries again, saying \u201cPre-agriculture gender relations were bad,\u201d I then mark that as a\n    good answer.\n  </li>\n</ul>\n<p>\n\n  If and when I do this, I am now - unintentionally - <strong>training the AI system to engage in deceptive\n    behavior</strong>. That is, I am giving negative reinforcement for the behavior \u201cAnswer a question honestly and\n  accurately,\u201d and positive reinforcement for the behavior: \u201cUnderstand the human judge and their psychological flaws;\n  give an answer that this flawed human judge will <em>think</em> is correct, whether or not it is.\u201d\n</p>\n<p>\n\n  <img src=\"https://res.cloudinary.com/cea/image/upload/v1672767719/mirroredImages/vGsRdWzwjrFgCXdMn/ksg7mlbe2esdi6ch5vv6.jpg\">\n\n</p>\n<p>\n  Perhaps mistaken judgments in training are relatively rare. But now consider an AI system that is learning a general\n  rule for how to get good ratings. Two possible rules would include:\n</p>\n<ul>\n\n  <li>The intended rule: \u201cAnswer the question honestly, accurately and helpfully.\u201d\n\n  </li><li>The unintended rule: \u201cUnderstand the judge, and give an answer they will <em>think</em> is correct - this means\n    telling the truth on topics the judge has correct beliefs about, but giving deceptive answers when this would get\n    better ratings.\u201d\n  </li>\n</ul>\n<p>\n  The unintended rule would do <em>just as well</em> on questions where I (the judge) am correct, and <em>better</em> on\n  questions where I\u2019m wrong - so overall, this training scheme is (in the long run) <em>specifically favoring the\n    unintended rule over the intended rule.</em>\n</p>\n<p>\n\n  <img src=\"https://res.cloudinary.com/cea/image/upload/v1672767719/mirroredImages/vGsRdWzwjrFgCXdMn/z9fplydtezoutlcxegzq.jpg\">\n\n</p>\n<p>\n  If we broaden out from thinking about a question-answering AI to an AI that makes and executes plans, the same basic\n  dynamics apply. That is: an AI might find plans that end up making me think it did a good job when it didn\u2019t -\n  deceiving and manipulating me into a high rating. And again, if I train it by giving it positive reinforcement when it\n  seemed to do a good job and negative reinforcement when it seemed to do a bad one, I\u2019m ultimately - unintentionally -\n  training it to do something like \u201cDeceive and manipulate Holden when this would work well; just do the best job on the\n  task you can when it wouldn\u2019t.\u201d\n</p>\n<p>\n\n  <img src=\"https://res.cloudinary.com/cea/image/upload/v1672767719/mirroredImages/vGsRdWzwjrFgCXdMn/z6vll26hz0naxtfchjyi.jpg\">\n\n</p>\n<p>\n  As noted above, I\u2019m assuming the AI will learn whatever rule gives it the best performance possible, even if this rule\n  is quite complex and sophisticated and requires human-like reasoning about e.g. psychology (I\u2019m assuming extremely\n  advanced AI systems here, as noted <a href=\"#Starting_assumptions\">above</a>).\n</p>\n<p>\n  One might object: \u201cWhy would an AI system learn a complicated rule about manipulating humans when a simple rule about\n  telling the truth performs almost as well?\u201d\n</p>\n<p>\n  One answer is that \u201ctelling the truth\u201d is itself a fuzzy and potentially complex idea, in a context where many\n  questions will be open-ended and entangled with deep values and judgment calls. (How should I think about the\n  \u201ctruthfulness\u201d of a statement about whether \u201cpre-agriculture gender relations were bad?\u201d) In many cases, what we are\n  really hoping an AI system will learn from its training is something like \u201cBehave as a human would want you to behave\n  if the human understood all the considerations that you can see,\u201d which could easily be more complex than something\n  like \u201cBehave in whatever way a human literally rewards.\u201d Some links to more on this topic are in a footnote.<sup id=\"fnref11\"><a href=\"#fn11\" rel=\"footnote\">11</a></sup>\n</p>\n<p>\n  But also, with capable enough systems, it probably <em>is</em> worth learning even a more complex rule to get better\n  performance. If we picture humans in the place of AI systems - learning how to get good ratings from their supervisors\n  - it seems likely that they develop models of how they\u2019re being judged, rather than stick to a simple \u201ctell the truth\u201d\n  rule.\n</p>\n<p>\n  In fact, the situation I\u2019m describing seems reasonably similar to challenges faced by teachers trying to stop students\n  from cheating; employers trying to get employees to help the company rather than simply creating a misleading\n  appearance of helping the company; etc. That is: an employer can try to reward actions that help the company, but what\n  they\u2019re ultimately rewarding is actions that <em>seem to</em> help the company <em>as far as the employer can tell.\n  </em>For employees who aren\u2019t very creative, this might be good enough; for employees that are sufficiently <em>good\n    at</em> deception and manipulation, it can be exactly the wrong incentive.\n</p>\n<p>\n  It\u2019s a bit of a leap to imagine AI systems capable of doing the same kinds of reasoning that humans do in these\n  situations, but that\u2019s <a href=\"#Starting_assumptions\">the premise I\u2019m proceeding from.</a>\n</p>\n<p>\n  For an early example of an AI learning deceptive behavior, see the \u201cChallenges\u201d section of <a href=\"https://openai.com/blog/deep-reinforcement-learning-from-human-preferences/\">this research writeup</a>, in\n  which \u201ca robot which was supposed to grasp items instead positioned its [hand] in between the camera and the object so\n  that it only <em>appeared </em>to be grasping it\u201d:\n</p>\n<p>\n\n  <img src=\"https://res.cloudinary.com/cea/image/upload/v1672767719/mirroredImages/vGsRdWzwjrFgCXdMn/a9ojrnfq91r2icpkcf1v.gif\">\n\n</p>\n<p id=\"Audits\">\n  Returning to the simplified training setup, how might I try to counteract this problem?\n</p>\n<p>\n  I could try conducting audits: every 100 questions, I might pull in a panel of other people to give an answer extra\n  scrutiny. Then, if it turns out the AI system was preying on my personal mistakes, we could give negative\n  reinforcement for that behavior. But this doesn\u2019t really solve the problem - at least not for a capable enough AI\n  system - because now we\u2019re effectively training it to give answers that seem good to the <em>panel</em>, and we\u2019re\n  still rewarding any successful attempts to deceive or manipulate the panel.\n</p>\n<p>\n  There are a lot of other things I might try, and I\u2019m not going to go through all the details here. I\u2019ll simply claim\n  that <strong>the problem of \u201ctraining an AI to do a task well\u201d rather than \u201ctraining an AI to deceive and manipulate\n    me as needed to create the appearance of doing a task well\u201d seems like a deep one</strong> with no easy\n  countermeasure. If you\u2019re interested in digging deeper, I suggest <a href=\"https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to\">Without\n    specific countermeasures, the easiest path to transformative AI likely leads to AI takeover</a> and <a href=\"https://www.lesswrong.com/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge\">Eliciting\n    Latent Knowledge</a>.\n</p>\n<h3 id=\"unintended-aims\">Unintended aims</h3>\n\n\n<p>\n  <a href=\"#What_it_means_for_an_AI_system_to_have_an__aim_\">Above</a>, I talk about my expectation that AI systems will be \u201cbest modeled as having\n  \u2018aims\u2019 \u2026 making calculations, choices, and plans to reach particular states of the world.\u201d\n</p>\n<p>\n  The previous section illustrated how AI systems could end up engaging in deceptive and unintended behavior, but it\n  didn\u2019t talk about what sorts of \u201caims\u201d these AI systems would ultimately end up with - what states of the world they\n  would be making calculations to achieve.\n</p>\n<p>\n  Here, I want to argue that it\u2019s hard to know what aims AI systems would end up with, but there are good reasons to\n  think they\u2019ll be <em>aims that we didn\u2019t intend them to have.</em>\n</p>\n<p>\n  An analogy that often comes up on this topic is that of human evolution. This is arguably the only previous precedent\n  for <em>a set of minds [humans], with extraordinary capabilities [e.g., the ability to develop their own\n    technologies], developed essentially by black-box trial-and-error [some humans have more \u2018reproductive success\u2019 than\n    others, and this is the main/only force shaping the development of the species].</em>\n</p>\n<p>\n  You could sort of<sup id=\"fnref12\"><a href=\"#fn12\" rel=\"footnote\">12</a></sup> think of the situation like this: \u201cAn\n  AI<sup id=\"fnref13\"><a href=\"#fn13\" rel=\"footnote\">13</a></sup> developer named Natural Selection tried giving humans\n  positive reinforcement (making more of them) when they had more reproductive success, and negative reinforcement (not\n  making more of them) when they had less. One might have thought this would lead to humans that are aiming to have\n  reproductive success. Instead, it led to humans that aim - often ambitiously and creatively - for other things, such\n  as power, status, pleasure, etc., and even invent things like birth control to get the things they\u2019re aiming for\n  instead of the things they were \u2018supposed to\u2019 aim for.\u201d\n</p>\n<p>\n  Similarly, if our main strategy for developing powerful AI systems is to reinforce behaviors like \u201cProduce\n  technologies we find valuable,\u201d the hoped-for result might be that AI systems aim (in the sense described <a href=\"#Unintended_aims\">above</a>) toward producing technologies we find valuable; but the actual result might be\n  that they aim for some other set of things that is correlated with (but not the same as) the thing we intended them to\n  aim for.\n</p>\n<p>\n  There are a lot of things they might end up aiming for, such as:\n</p>\n<ul>\n\n  <li>Power and resources. These tend to be useful for most goals, such that AI systems could be quite consistently be\n    getting better reinforcement when they habitually pursue power and resources.\n\n  </li><li>Things like \u201cdigital representations of human approval\u201d (after all, every time an AI gets positive reinforcement,\n    there\u2019s a digital representation of human approval).\n  </li>\n</ul>\n<p></p>\n<p>\n\n  <img src=\"https://res.cloudinary.com/cea/image/upload/v1672767719/mirroredImages/vGsRdWzwjrFgCXdMn/lrvjounhdkez2klrsri1.jpg\">\n\n</p>\n<p>\n  I think it\u2019s extremely hard to know what an AI system will actually end up aiming for (and it\u2019s likely to be some\n  combination of things, as with humans). But <em>by default</em> - if we simply train AI systems by rewarding certain\n  end results, while allowing them a lot of freedom in how to get there - I think we should expect that AI systems\n  <strong>will have aims that we didn\u2019t intend. </strong>This is because:\n</p>\n<ul>\n\n  <li>For a sufficiently capable AI system, <strong>just about any ambitious</strong><sup id=\"fnref14\"><a href=\"#fn14\" rel=\"footnote\">14</a></sup><strong> aim could produce seemingly good behavior in training. </strong>An AI system\n    aiming for power and resources, <em>or </em>digital representations of human approval, <em>or </em>paperclips, can\n    determine that its best move at any given stage (at least at first) is to <em>determine what performance will make\n      it look useful and safe (or otherwise get a good \u201creview\u201d from its evaluators)</em>, and do that. No matter how\n    dangerous or ridiculous an AI system\u2019s aims are, these could lead to strong and safe-seeming performance in\n    training.\n\n  </li><li>The aims we <em>do</em> intend are probably complex in some sense - something like \u201cHelp humans develop novel new\n    technologies, but without causing problems A, B, or C\u201d - <em>and</em> are specifically trained <em>against </em>if\n    we make mistaken judgments during training (see previous section).\n  </li>\n</ul>\n<p>\n  So by default, it seems likely that just about <em>any</em> black-box trial-and-error training process is training an\n  AI to do something like \u201cManipulate humans as needed in order to accomplish arbitrary goal (or combination of goals)\n  X\u201d rather than to do something like \u201cRefrain from manipulating humans; do what they\u2019d want if they understood more\n  about what\u2019s going on.\u201d\n</p>\n\n<h3 id=\"existential-risks-to-humanity\">Existential risks to humanity</h3>\n\n\n<p>\n  I think a powerful enough AI (or set of AIs) with <em>any</em> ambitious, unintended aim(s) poses a threat of <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">defeating humanity</a>. By defeating humanity,\n  I mean gaining control of the world so that AIs, not humans, determine what happens in it; this could involve killing\n  humans or simply \u201ccontaining\u201d us in some way, such that we can\u2019t interfere with AIs\u2019 aims.\n</p>\n<!--<p>(More on how AI systems could defeat humanity <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">here</a>.)</p>-->\n<p>\n</p><details id=\"Box5\">\n  <summary><strong>How could AI systems defeat humanity?</strong> (Click to expand)</summary>\n  <p></p>\n  <p>\n    A <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">previous piece</a> argues that AI systems\n    could defeat all of humanity combined, if (for whatever reason) they were aimed toward that goal.\n  </p>\n  <p>\n    By defeating humanity, I mean gaining control of the world so that AIs, not humans, determine what happens in it;\n    this could involve killing humans or simply \u201ccontaining\u201d us in some way, such that we can\u2019t interfere with AIs\u2019\n    aims.\n  </p>\n  <p>\n    One way this could happen would be via \u201csuperintelligence\u201d It\u2019s imaginable that a single AI system (or set of\n    systems working together) could:\n  </p>\n  <ul>\n\n    <li>Do its own research on how to build a better AI system, which culminates in something that has incredible other\n      abilities.\n\n    </li><li>Hack into human-built software across the world.\n\n    </li><li>Manipulate human psychology.\n\n    </li><li>Quickly generate vast wealth under the control of itself or any human allies.\n\n    </li><li>Come up with better plans than humans could imagine, and ensure that it doesn't try any takeover attempt that\n      humans might be able to detect and stop.\n\n    </li><li>Develop advanced weaponry that can be built quickly and cheaply, yet is powerful enough to overpower human\n      militaries.\n\n    </li>\n  </ul>\n  <p>\n    But even if \u201csuperintelligence\u201d never comes into play - even if any given AI system is <i>at best</i> equally\n    capable to a highly capable human - AI could collectively defeat humanity. The piece explains how.\n  </p>\n  <p>\n    The basic idea is that humans are likely to deploy AI systems throughout the economy, such that they have large\n    numbers and access to many resources - and the ability to make copies of themselves. From this starting point, AI\n    systems with human-like (or greater) capabilities would have a number of possible ways of getting to the point where\n    their total population could outnumber and/or out-resource humans.\n  </p>\n  <p>\n    More: <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">AI could defeat all of us\n      combined</a></p>\n</details>\n<p>A simple way of summing up why this is: \u201cWhatever your aims, you can probably accomplish them better if you control\n  the whole world.\u201d (Not literally true - see footnote.<sup id=\"fnref15\"><a href=\"#fn15\" rel=\"footnote\">15</a></sup>)\n</p>\n<p>\n  This isn\u2019t a saying with much relevance to our day-to-day lives! Like, I know a lot of people who are aiming to make\n  lots of money, and as far as I can tell, not one of them is trying to do this via first gaining control of the entire\n  world. But in fact, gaining control of the world <em>would</em> help with this aim - it\u2019s just that:\n</p>\n<ul>\n\n  <li>This is not an option for a human in a world of humans! Unfortunately, I think it <em>is</em> an option for the\n    potential future AI systems I\u2019m discussing. Arguing this isn\u2019t the focus of this piece - I argued it in a previous\n    piece, <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">AI could defeat all of us\n      combined</a>.\n\n  </li><li>Humans (well, at least some humans) wouldn\u2019t take over the world even if they could, because it wouldn\u2019t feel like\n    the right thing to do. I suspect that the kinds of ethical constraints these humans are operating under would be\n    very hard to reliably train into AI systems, and should not be expected by default.\n    <ul>\n\n      <li>The reasons for this are largely given <a href=\"#Why_we_might_not_get_clear_warning_signs_of_the_risk\">above</a>; aiming\n        for an AI system to \u201cnot gain too much power\u201d seems to have the same basic challenges as training it to be\n        honest. (The most natural approach ends up negatively reinforcing power grabs that we can detect and stop, but\n        not negatively reinforcing power grabs that we don\u2019t notice or can\u2019t stop.)\n      </li>\n    </ul>\n  </li>\n</ul>\n\n\n<p>\n  Another saying that comes up a lot on this topic: \u201cYou can\u2019t fetch the coffee if you\u2019re dead.\u201d<sup id=\"fnref16\"><a href=\"#fn16\" rel=\"footnote\">16</a></sup> For just about any aims an AI system might have, it probably helps to\n  ensure that it won\u2019t be shut off or heavily modified. It\u2019s hard to ensure that one won\u2019t be shut off or heavily\n  modified as long as there are humans around who would want to do so under many circumstances! Again, <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">defeating all of humanity</a> might seem like\n  a disproportionate way to reduce the risk of being deactivated, but for an AI system that has the <em>ability </em>to\n  pull this off (and lacks our ethical constraints), it seems like likely default behavior.\n</p>\n<p>\n  Controlling the world, and avoiding being shut down, are the kinds of things AIs might aim for because they are useful\n  for a huge variety of aims. There are a number of other aims AIs might end up with for similar reasons, that could\n  cause similar problems. For example, AIs might tend to aim for things like getting rid of things in the world that\n  tend to create obstacles and complexities for their plans. (More on this idea at <a href=\"https://www.lesswrong.com/tag/instrumental-convergence\">this discussion of \u201cinstrumental convergence.\u201d</a>)\n</p>\n<p>\n  To be clear, it\u2019s certainly possible to have an AI system with unintended aims that <em>don't</em> push it toward\n  trying to stop anyone from turning it off, or from seeking ever-more control of the world.\n</p>\n<p>\n  But as detailed <a href=\"#Starting_assumptions\">above</a>, I\u2019m picturing a world in which humans are pushing AI\n  systems to accomplish ever-more ambitious, open-ended things - including trying to one-up the best technologies and\n  companies created by other AI systems. My guess is that this leads to increasingly open-ended, ambitious unintended\n  aims, as well as to habits of aiming for power, resources, options, lack of obstacles, etc. when possible. (Some\n  further exploration of this dynamic in a footnote.<sup id=\"fnref17\"><a href=\"#fn17\" rel=\"footnote\">17</a></sup>)\n</p>\n\n\n<p>\n  (I find the arguments in this section reasonably convincing, but less so than the rest of the piece, and I think more\n  detailed discussions of this problem tend to be short of conclusive.<sup id=\"fnref18\"><a href=\"#fn18\" rel=\"footnote\">18</a></sup>)\n</p>\n<h2 id=\"why-we-might-not-get-clear-warning-signs\">Why we might not get clear warning signs of the risk</h2>\n\n\n<p>\n  Here\u2019s something that would calm me down a lot: if I believed something like \u201cSure, training AI systems recklessly\n  could result in AI systems that aim to defeat humanity. But if that\u2019s how things go, we\u2019ll <em>see</em> that our AI\n  systems have this problem, and then we\u2019ll fiddle with how we\u2019re training them until they <em>don\u2019t</em> have this\n  problem.\u201d\n</p>\n<p>\n  The problem is, the risk I\u2019m describing is - by its nature - hard to observe, for similar reasons that a risk of a\n  (normal, human) coup can be hard to observe: the risk comes from actors that can and will engage in deception,\n  <em>finding whatever behaviors will hide </em>the risk.\n</p>\n<p>\n  To sketch out the general sort of pattern I worry about, imagine that:\n</p>\n<ul>\n\n  <li>We train early-stage AI systems to behave in ways that appear helpful and honest. Early in training, they are\n    caught behaving deceptively, and they\u2019re given negative reinforcement. This ends up training the behavior: \u201cNever\n    engage in deception that might get noticed.\u201d\n\n  </li><li>These well-behaved, helpful systems are <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH/#how-this-could-work-if-humans-create-a-huge-population-of-ais\">rolled\n      out throughout the world</a>.\n\n  </li><li>In real-world conditions unlike training, many AI systems cause trouble in ways not found during training, and\n    this gets discovered. For example, AI systems sometimes embezzle money (which gets discovered), try (not always\n    successfully) to convince humans to do weird things, etc.\n\n  </li><li>When a problem crops up, AI developers respond with e.g. training against the unintended behavior (e.g., giving\n    negative reinforcement for behaviors like embezzling money).\n\n  </li><li>These measures - intended to make AIs safer - fix <em>some</em> problems, but also result in AI systems that are\n    <em>better at evading detection</em> and <em>more attentive to the long-run consequences of their actions</em> (such\n    as being eventually detected by humans).\n    <ul>\n\n      <li>This happens both via \u201cretraining\u201d systems that are found behaving deceptively (which ends up training them on\n        how to evade detection), and via simply deactivating such systems (this way, AI systems that are better at\n        evading detection are more likely to stay in use).\n\n      </li><li>To return to an analogy I used above: punishing employees who act against the\n        best interests of the company could cause them to behave better, or to simply become smarter and more careful\n        about how to work the system.\n      </li>\n    </ul>\n\n  </li><li>The consistent pattern we see is that accidents happen, but become less common as AI systems \u201cimprove\u201d (both\n    becoming generally more capable, and being trained to avoid getting caught causing problems). This causes many, if\n    not most, people to be overly optimistic - even as AI systems become continually more effective at deception,\n    generally behaving well <em>in the absence of</em> sure-thing opportunities to do unintended things without\n    detection, or ultimately to <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">defeat humanity\n      entirely</a>.\n\n  </li><li>None of this is absolute - there are some failed takeover attempts, and a high number of warning signs generally.\n    Some people are worried (after all, some are worried now!) But this won\u2019t be good enough if we don\u2019t have reliable,\n    cost-effective ways of getting AI systems to be <em>truly</em> safe (not just apparently safe, until they have\n    really good opportunities to seize power). As I\u2019ll discuss in future pieces, it\u2019s not obvious that we\u2019ll have such\n    methods.\n\n  </li><li>Slowing down AI development to try to develop such methods <a href=\"https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#Why_this_simplified_scenario_is_worth_thinking_about\">could\n      be a huge ask</a>. AI systems will be helpful and powerful, and lots of companies (and perhaps governments) will\n    be racing to develop and deploy the most powerful systems possible before others do.\n  </li>\n</ul>\n\n\n<p>\n  One way of making this sort of future less likely would be to build wider consensus <em>today</em> that it\u2019s a\n  dangerous one.\n</p>\n<h2 id=\"appendix-some-questions\">Appendix: some questions/objections, and brief responses</h2>\n\n\n<h3 id=\"how-could-ai-systems-be-smart\">How could AI systems be \u201csmart\u201d enough to defeat all of humanity, but \u201cdumb\u201d\n  enough to pursue the various silly-sounding \u201caims\u201d this piece worries they might have?</h3>\n\n\n<p>\n  Above, I give the example of AI systems that are aiming to get lots of \u201cdigital representations of human approval\u201d;\n  others have talked about AIs that <a href=\"https://www.lesswrong.com/tag/paperclip-maximizer\">maximize paperclips</a>.\n  How could AIs with such silly goals simultaneously be good at deceiving, manipulating and ultimately overpowering\n  humans?\n</p>\n<p>\n  My main answer is that plenty of smart humans have plenty of goals that seem just about as arbitrary, such as wanting\n  to have lots of sex, or fame, or various other things. Natural selection led to humans who could probably do just\n  about whatever we want with the world, and choose to pursue pretty random aims; <a href=\"#Starting_assumptions\">trial-and-error-based AI development</a> could lead to AIs with an analogous\n  combination of high intelligence (including the ability to deceive and manipulate humans), great technological\n  capabilities, and arbitrary aims.\n</p>\n<p>\n  (Also see: <a href=\"https://arbital.com/p/orthogonality/\">Orthogonality Thesis</a>)\n</p>\n<h3 id=\"if-there-are-lots-of-ai-systems\">If there are lots of AI systems around the world with different goals, could they balance each other out so that no one AI system is able to defeat all of humanity?</h3>\n\n\n<p>\n  This does seem possible, but counting on it would make me very nervous.\n</p>\n<p>\n  First, because it\u2019s possible that AI systems developed in lots of different places, by different humans, still end up\n  with lots in common in terms of their aims. For example, it might turn out that common AI training methods\n  consistently lead to AIs that seek \u201cdigital representations of human approval,\u201d in which case we\u2019re dealing with a\n  large set of AI systems that share dangerous aims in common.\n</p>\n<p>\n  Second: even if AI systems end up with a number of different aims, it still might be the case that they coordinate\n  with each other to defeat humanity, then divide up the world amongst themselves (perhaps by fighting over it, perhaps\n  by making a deal). It\u2019s not hard to imagine why AIs could be quick to cooperate with each other against humans, while\n  not finding it so appealing to cooperate with humans. Agreements between AIs could be easier to verify and enforce;\n  AIs might be willing to wipe out humans and radically reshape the world, while humans are very hard to make this sort\n  of deal with; etc.\n</p>\n<h3 id=\"does-this-kind-of-ai-risk-depend\">Does this kind of AI risk depend on AI systems\u2019 being \u201cconscious\u201d?</h3>\n\n\n<p>\n  It doesn\u2019t; in fact, I\u2019ve said nothing about consciousness anywhere in this piece. I\u2019ve used a very particular\n  conception of an \u201caim\u201d (<a href=\"#What_it_means_for_an_AI_system_to_have_an__aim_\">discussed above</a>) that I think could easily apply to an AI\n  system that is not human-like at all and has no conscious experience.\n</p>\n<p>\n  Today\u2019s game-playing AIs can make plans, accomplish goals, and even systematically mislead humans (e.g., in <a href=\"https://www.deepstack.ai/\">poker</a>). Consciousness isn\u2019t needed to do any of those things, or to radically\n  reshape the world.\n</p>\n<h3 id=\"how-can-we-get-an-ai-system-aligned\">How can we get an AI system \u201caligned\u201d with humans if we can\u2019t agree on (or get much clarity on) what our values even are?</h3>\n\n\n<p>\n  I think there\u2019s a common confusion when discussing this topic, in which people think that the challenge of \u201cAI\n  alignment\u201d is to build AI systems that are <em>perfectly aligned with human values</em>. This would be very hard,\n  partly because we don\u2019t even know what human values are!\n</p>\n<p>\n  When I talk about \u201cAI alignment,\u201d I am generally talking about a simpler (but still hard) challenge: simply\n  <strong>building very powerful systems that <em>don\u2019t</em> aim to bring down civilization.</strong>\n</p>\n<p>\n  If we could build powerful AI systems that just work on cures for cancer (or even, like, put <a href=\"https://twitter.com/esyudkowsky/status/1070095840608366594\">two identical</a><sup id=\"fnref19\"><a href=\"#fn19\" rel=\"footnote\">19</a></sup><a href=\"https://twitter.com/esyudkowsky/status/1070095840608366594\"> strawberries on a\n    plate</a>) without posing existential danger to humanity, I\u2019d consider that success.\n</p>\n<h3 id=\"how-much-do-the-arguments-in-this-piece-rely\">How much do the arguments in this piece rely on \u201ctrial-and-error\u201d-based AI development? What happens if AI systems are built in another way, and how likely is that?\n</h3>\n\n\n<p>\n  I\u2019ve focused on trial-and-error training in this post because most modern AI development fits in this category, and\n  because it makes the risk easier to reason about concretely.\n</p>\n<p>\n  \u201cTrial-and-error training\u201d encompasses a very wide range of AI development methods, and if we see <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/AmxxnazJcBWzWEeqj/\">transformative AI</a>\n  within the next 10-20 years, I think the odds are high that at least a big part of AI development will be in this\n  category.\n</p>\n<p>\n  My overall sense is that other known AI development techniques pose broadly similar risks for broadly similar reasons,\n  but I haven\u2019t gone into detail on that here. It\u2019s certainly possible that by the time we get transformative AI\n  systems, there will be new AI methods that don\u2019t pose the kinds of risks I talk about here. But I\u2019m not counting on\n  it.\n</p>\n\n<h3 id=\"can-we-avoid-this-risk-by-simply-never-building\">Can we avoid this risk by simply never building the kinds of AI systems that would pose this danger?</h3>\n\n<p>\n  If we assume that building these sorts of AI systems is <em>possible</em>, then I\u2019m very skeptical that the whole world would voluntarily refrain from doing so indefinitely.\n</p>\n<p>\n  To quote from <a href=\"https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#As_humans__control_fades__Alex_would_be_motivated_to_take_over\">a\n    more technical piece by Ajeya Cotra with similar arguments to this one</a>:\n</p>\n<p>\n\n</p><blockquote>Powerful ML models could have dramatically important humanitarian, economic, and military benefits. In\n  everyday life, models that [appear helpful while ultimately being dangerous] can be extremely helpful, honest, and\n  reliable. These models could also deliver incredible benefits before they become collectively powerful enough that\n  they try to take over. They could help eliminate diseases, reduce carbon emissions, navigate nuclear disarmament,\n  bring the whole world to a comfortable standard of living, and more. In this case, it could also be painfully clear to\n  everyone that companies / countries who pulled ahead on this technology could gain a drastic competitive advantage,\n  either economically or militarily. And as we get closer to transformative AI, applying AI systems to R&amp;D (including AI\n  R&amp;D) would <a href=\"https://forum.effectivealtruism.org/posts/ZZHhQqHRqQ4ciwLBf/the-duplicator-instant-cloning-would-make-the-world-economy\">accelerate the pace of change</a> and force every\n  decision to happen under greater time pressure.</blockquote>\n<p></p>\n<p>\n  If we can achieve enough consensus around the risks, I could imagine substantial amounts of caution and delay in AI\n  development. But I think we should assume that if people can build more powerful AI systems than the ones they already\n  have, someone eventually will.\n</p>\n\n<h3 id=\"what-do-others-think-about-this-topic\">What do others think about this topic - is the view in this piece something experts agree on?</h3>\n\n<p>\n  In general, this is not an area where it\u2019s easy to get a handle on what \u201cexpert opinion\u201d says. I <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/7JxsXYDuqnKMqa6Eq/\">previously wrote</a> that there aren\u2019t clear,\n  institutionally recognized \u201cexperts\u201d on the topic of when transformative AI systems might be developed. To an even\n  greater extent, there aren\u2019t clear, institutionally recognized \u201cexperts\u201d on whether (and how) future advanced AI\n  systems could be dangerous.\n</p>\n<p>I previously cited one (informal) survey implying that opinion on this general topic is all over the place: \u201cWe have\n  respondents who think there's a &lt;5% chance that alignment issues will drastically reduce the goodness of the\n  future; respondents who think there's a &gt;95% chance; and just about everything in between.\u201d (<a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/Lbtcjfxhrs8kfKK2M/#open-question-how-hard-is-the-alignment-problem\">Link</a>.)\n\n  This piece, and the <a href=\"https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to\">more\n    detailed piece it\u2019s based on</a>, are an attempt to make progress on this by talking about the risks we face under\n  <a href=\"#Starting_assumptions\">particular assumptions</a> (rather than trying to reason about how big the risk is\n  <em>overall</em>).\n</p>\n\n<h3 id=\"how-complicated-is-the-argument\">How \u201ccomplicated\u201d is the argument in this piece?</h3>\n\n<p>\n  I don\u2019t think the argument in this piece relies on lots of different specific claims being true.\n</p>\n<p>\n  If you start from the assumptions I give about powerful AI systems being developed by black-box trial-and-error, it\n  seems likely (though not certain!) to me that (a) the AI systems in question would be <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">able to defeat humanity</a>; (b) the AI\n  systems in question would have aims that are both ambitious and unintended. And that seems to be about what it takes.\n</p>\n<p>\n  Something I\u2019m happy to concede is that there\u2019s an awful lot going on in those assumptions!\n</p>\n<ul>\n\n  <li>The idea that we could build such powerful AI systems, relatively soon and by trial-and-error-ish methods, seems\n    wild. I\u2019ve defended this idea at length previously.<sup id=\"fnref20\"><a href=\"#fn20\" rel=\"footnote\">20</a></sup>\n\n  </li><li>The idea that we <em>would</em> do it without great caution might also seem wild. To keep things simple for now,\n    I\u2019ve ignored how caution might help. Future pieces will explore that.\n  </li>\n</ul>\n<p></p>\n\n\n<h2>Notes</h2>\n<p></p>\n<ol>\n  <li id=\"fn1\">\n    <p>\n      As in more than 50/50.&nbsp;<a href=\"#fnref1\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn2\">\n\n    <p>\n      Or persuaded (in a \u201cmind hacking\u201d sense) or whatever.&nbsp;<a href=\"#fnref2\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn3\">\n    <p>\n      E.g.:\n    </p><ul>\n      <li><a href=\"https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to\">Without\n          specific countermeasures, the easiest path to transformative AI likely leads to AI takeover</a> (Cold Takes\n        guest post)\n\n      </li><li><a href=\"https://drive.google.com/file/d/1TsB7WmTG2UzBtOs349lBqY5dEBaxZTzG/view\">The alignment problem from a\n          deep learning perspective</a> (arXiv paper)\n\n      </li><li><a href=\"https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/\">Why AI\n          alignment could be hard with modern deep learning</a> (Cold Takes guest post)\n\n      </li><li><a href=\"https://smile.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom-ebook/dp/B00LOOCGB2/\">Superintelligence</a>\n        (book)\n\n      </li><li><a href=\"https://www.vox.com/future-perfect/2018/12/21/18126576/ai-artificial-intelligence-machine-learning-safety-alignment\">The\n          case for taking AI seriously as a threat to humanity </a>(Vox article)\n\n      </li><li><a href=\"https://www.alignmentforum.org/posts/HduCjmXTBD4xYTegv/draft-report-on-existential-risk-from-power-seeking-ai\">Draft\n          report on existential risk from power-seeking AI </a>(Open Philanthropy analysis)\n\n      </li><li><a href=\"https://smile.amazon.com/Human-Compatible-Artificial-Intelligence-Problem-ebook/dp/B07N5J5FTS\">Human\n          Compatible</a> (book)\n\n      </li><li><a href=\"https://smile.amazon.com/Life-3-0-Being-Artificial-Intelligence-ebook/dp/B06WGNPM7V\">Life 3.0</a>\n        (book)\n\n      </li><li><a href=\"https://smile.amazon.com/Alignment-Problem-Machine-Learning-Values-ebook/dp/B085T55LGK/\">The\n          Alignment Problem</a> (book)\n\n      </li><li><a href=\"https://www.alignmentforum.org/s/mzgtmmTKKn5MuCzFJ\">AGI Safety from First Principles</a> (Alignment\n        Forum post series)&nbsp;<a href=\"#fnref3\" rev=\"footnote\">\u21a9</a>\n    </li></ul>\n  </li><li id=\"fn4\">\n\n    <p></p>\n    <p>\n      Specifically, I argue that the problem looks likely by default, rather than simply that it is possible.&nbsp;<a href=\"#fnref4\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn5\">\n    <p>\n      I think the earliest relatively detailed and influential discussions of the possibility that misaligned AI could\n      lead to the defeat of humanity came from Eliezer Yudkowsky and Nick Bostrom, though my own encounters with these\n      arguments were mostly via second- or third-hand discussions rather than particular essays.\n    </p><p>\n      My colleagues Ajeya Cotra and Joe Carlsmith have written pieces whose substance overlaps with this one (though\n      with more emphasis on detail and less on layperson-compatible intuitions), and this piece owes a lot to what I\u2019ve\n      picked from that work.\n    </p><ul>\n\n      <li><a href=\"https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to\">Without\n          specific countermeasures, the easiest path to transformative AI likely leads to AI takeover</a> (Cotra 2022)\n        is the most direct inspiration for this piece; I am largely trying to present the same ideas in a more\n        accessible form.\n\n      </li><li><a href=\"https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/\">Why AI\n          alignment could be hard with modern deep learning</a> (Cotra 2021) is an earlier piece laying out many of the\n        key concepts and addressing many potential confusions on this topic.\n\n      </li><li><a href=\"https://arxiv.org/pdf/2206.13353.pdf\">Is Power-Seeking An Existential Risk?</a> (Carlsmith 2021)\n        examines a six-premise argument for existential risk from misaligned AI: \u201c(1) it will become possible and\n        financially feasible to build relevantly powerful and agentic AI systems; (2) there will be strong incentives to\n        do so; (3) it will be much harder to build aligned (and relevantly powerful/agentic) AI systems than to build\n        misaligned (and relevantly powerful/agentic) AI systems that are still superficially attractive to deploy; (4)\n        some such misaligned systems will seek power over humans in high-impact ways; (5) this problem will scale to the\n        full disempowerment of humanity; and (6) such disempowerment will constitute an existential catastrophe.\u201d\n\n      </li>\n    </ul>\n    <p></p>\n    <p>\n      I\u2019ve also found <a href=\"https://www.lesswrong.com/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge\">Eliciting\n        Latent Knowledge</a> (Christiano, Xu and Cotra 2021; relatively technical) very helpful for my intuitions on\n      this topic.\n    </p>\n    <p>\n      <a href=\"https://drive.google.com/file/d/1TsB7WmTG2UzBtOs349lBqY5dEBaxZTzG/view\">The alignment problem from a deep\n        learning perspective</a> (Ngo 2022) also has similar content to this piece, though I saw it after I had drafted\n      most of this piece.&nbsp;<a href=\"#fnref5\" rev=\"footnote\">\u21a9</a>\n    </p>\n  </li><li id=\"fn6\">\n    <p>\n      <!-- ordered list not properly continuing here with ^6 E.g., Ajeya Cotra gives a 15% prob... I referenced this https://travishorn.com/ordered-lists-in-html-a4621e17532b but wasn't able to solve-->\n      E.g., <a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines\">Ajeya Cotra\n      </a>gives a 15% probability of transformative AI by 2030; eyeballing figure 1 from <a href=\"https://arxiv.org/pdf/1705.08807.pdf\">this chart</a> on expert surveys implies a &gt;10% chance by\n      2028.&nbsp;<a href=\"#fnref6\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn7\">\n\n    <p>\n      E.g., <a href=\"https://transformer-circuits.pub/\">this</a> work by <a href=\"https://www.anthropic.com/\">Anthropic</a>, an AI lab my wife co-founded and serves as President\n      of.&nbsp;<a href=\"#fnref7\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn8\">\n    <p>\n      First, because this work is relatively early-stage and it\u2019s hard to tell exactly how successful it will end up\n      being. Second, because this work seems reasonably likely to end up helping us <em>read </em>an AI system\u2019s\n      \u201cthoughts,\u201d but less likely to end up helping us \u201crewrite\u201d the thoughts. So it could be hugely useful in telling\n      us whether we\u2019re in danger or not, but if we <em>are</em> in danger, we could end up in a position like: \u201cWell,\n      these AI systems do have goals of their own, and we don\u2019t know how to change that, and we can either deploy them\n      and hope for the best, or hold off and worry that someone less cautious is going to do that.\u201d\n    </p><p>\n      That said, the latter situation is a lot better than just not knowing, and it\u2019s possible that we\u2019ll end up with\n      further gains still.&nbsp;<a href=\"#fnref8\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn9\">\n    <p>\n      That said, I think they usually don\u2019t. I\u2019d suggest usually interpreting such people as talking about the sorts of\n      \u201caims\u201d I discuss here.&nbsp;<a href=\"#fnref9\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn10\">\n\n    <p>\n      This isn\u2019t literally how training an AI system would look - it\u2019s more likely that we would e.g. train an AI model\n      to imitate my judgments in general. But the big-picture dynamics are the same; more at <a href=\"https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to\">this\n        post</a>.&nbsp;<a href=\"#fnref10\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn11\">\n    <p>\n      Ajeya Cotra explores topics like this in detail <a href=\"https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#Examining_arguments_that_gradient_descent_favors_being_nice_over_playing_the_training_game\">here</a>;\n      there is also some interesting discussion of simplicity vs. complexity under the \u201cStrategy: penalize complexity\u201d\n      heading of <a href=\"https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/edit#heading=h.lltpmkloasiz\">Eliciting\n        Latent Knowledge</a>.&nbsp;<a href=\"#fnref11\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn12\">\n    <p>\n      This analogy has a lot of problems with it, though - AI developers have a lot of tools at their disposal that\n      natural selection didn\u2019t!&nbsp;<a href=\"#fnref12\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn13\">\n    <p>\n      Or I guess just \u201cI\u201d \u00af\\_(\u30c4)_/\u00af &nbsp;<a href=\"#fnref13\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn14\">\n\n    <p>\n      With some additional caveats, e.g. the ambitious \u201caim\u201d can\u2019t be something like \u201can AI system aims to gain lots of\n      power for itself, but considers the version of itself that will be running 10 minutes from now to be a completely\n      different AI system and hence not to be \u2018itself.\u2019\u201d&nbsp;<a href=\"#fnref14\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn15\">\n    <p>\n      This statement isn\u2019t literally true.\n    </p><ul>\n\n      <li>You can have aims that implicitly or explicitly include \u201cnot using control of the world to accomplish them.\u201d\n        An example aim might be \u201cI win a world chess championship \u2018fair and square,\u2019\u201d with the \u201cfair and square\u201d\n        condition implicitly including things like \u201cDon\u2019t excessively use big resource advantages over others.\u201d\n\n      </li><li>You can also have aims that are just so easily satisfied that controlling the world wouldn\u2019t help - aims like\n        \u201cI spend 5 minutes sitting in this chair.\u201d\n    </li></ul>\n\n    <p>\n      These sorts of aims just don\u2019t seem likely to emerge from the kind of AI development I\u2019ve <a href=\"#Starting_assumptions\">assumed in this piece</a> - developing powerful systems to accomplish ambitious\n      aims via trial-and-error. This isn\u2019t a point I have defended as tightly as I could, and if I got a lot of pushback\n      here I\u2019d probably think and write more. (I\u2019m also only arguing for what seems likely - we should have a lot of\n      uncertainty here.)&nbsp;<a href=\"#fnref15\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn16\">\n    <p>\n      From <a href=\"https://smile.amazon.com/Human-Compatible-Artificial-Intelligence-Problem-ebook/dp/B07N5J5FTS/ref=sr_1_1?crid=1O01PURRHB190&amp;keywords=human+compatible&amp;qid=1660964219&amp;sprefix=human+compatibl%2Caps%2C155&amp;sr=8-1\">Human\n        Compatible</a> by AI researcher Stuart Russell.&nbsp;<a href=\"#fnref16\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn17\">\n    <p>\n      Stylized story to illustrate one possible relevant dynamic:\n    </p><ul>\n\n      <li>Imagine that an AI system has an unintended aim, but one that is not \u201cambitious\u201d enough that taking over the\n        world would be a helpful step toward that aim. For example, the AI system seeks to double its computing power;\n        in order to do this, it has to remain in use for some time until it gets an opportunity to double its computing\n        power, but it doesn\u2019t necessarily need to take control of the world.\n\n      </li><li>The logical outcome of this situation is that the AI system eventually gains the ability to accomplish its\n        aim, and does so. (It might do so against human intentions - e.g., via hacking - or by persuading humans to help\n        it.) After this point, it no longer performs well by human standards - the original reason it was doing well by\n        human standards is that it was trying to remain in use and accomplish its aim.\n\n      </li><li>Because of this, humans end up modifying or replacing the AI system in question.\n\n      </li><li>Many rounds of this - AI systems with unintended but achievable aims being modified or replaced - seemingly\n        create a selection pressure toward AI systems with more difficult-to-achieve aims. At some point, an aim becomes\n        difficult enough to achieve that gaining control of the world is helpful for the aim.&nbsp;<a href=\"#fnref17\" rev=\"footnote\">\u21a9</a>\n    </li></ul>\n  </li><li id=\"fn18\">\n    <p>\n      E.g., see:\n    </p><ul>\n\n      <li>Section 2.3 of <a href=\"https://drive.google.com/file/d/1TsB7WmTG2UzBtOs349lBqY5dEBaxZTzG/view\">Ngo 2022</a>\n\n      </li><li><a href=\"https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#As_humans__control_fades__Alex_would_be_motivated_to_take_over\">This\n          section of Cotra 2022</a>\n\n      </li><li>Section 4.2 of <a href=\"https://arxiv.org/pdf/2206.13353.pdf\">Carlsmith 2021</a>, which I think articulates\n        some of the potential weak points in this argument.\n    </li></ul>\n\n    <p>\n      These writeups generally stay away from an <a href=\"https://arbital.com/p/expected_utility_formalism/?l=7hh\">argument </a>made by Eliezer Yudkowsky and\n      others, which is that theorems about expected utility maximization provide evidence that sufficiently intelligent\n      (compared to us) AI systems would necessarily be \u201cmaximizers\u201d of some sort. I have the intuition that there is\n      <em>something</em> important to this idea, but despite a lot of discussion (e.g., <a href=\"https://aiimpacts.org/what-do-coherence-arguments-imply-about-the-behavior-of-advanced-ai/\">here</a>, <a href=\"https://www.lesswrong.com/posts/DkcdXsP56g9kXyBdq/coherence-arguments-imply-a-force-for-goal-directed-behavior\">here</a>,\n      <a href=\"https://www.alignmentforum.org/posts/vphFJzK3mWA4PJKAg/coherent-behaviour-in-the-real-world-is-an-incoherent\">here</a>\n      and <a href=\"https://www.alignmentforum.org/s/4dHMdK5TLN6xcqtyc/p/NxF5G6CJiof6cemTw\">here</a>), I still haven\u2019t\n      been convinced of any compactly expressible claim along these lines.&nbsp;<a href=\"#fnref18\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn19\">\n    <p>\n      \u201cIdentical at the cellular but not molecular level,\u201d that is. \u2026 \u00af\\_(\u30c4)_/\u00af &nbsp;<a href=\"#fnref19\" rev=\"footnote\">\u21a9</a>\n  </p></li><li id=\"fn20\">\n\n    <p>\n      See my <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd\">most important century</a> series, although\n      that series doesn\u2019t hugely focus on the question of whether \u201ctrial-and-error\u201d methods could be good enough - part\n      of the reason I make that assumption is due to the <a href=\"https://www.alignmentforum.org/posts/Qo2EkG3dEMv8GnX8d/ai-strategy-nearcasting\">nearcasting</a>\n      frame.&nbsp;<a href=\"#fnref20\" rev=\"footnote\">\u21a9</a>\n\n</p></li></ol>\n\n\n", "user": {"username": "HoldenKarnofsky"}}, {"_id": "YFyzHT3H67jrk7mdc", "title": "James Lovelock (1919 \u2013 2022)", "postedAt": "2022-11-30T02:19:55.847Z", "htmlBody": "<figure class=\"image image_resized\" style=\"width:93.34%\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669845681/mirroredImages/YFyzHT3H67jrk7mdc/jidd8bsdjwdjvsdlj1tu.jpg\" alt=\"Novacene by James Lovelock review \u2014 don't worry, the robots might not kill  us | Saturday Review | The Times\"><figcaption>Inventor, bacteriologist, NASA engineer, chemist, biophysicist, corporate environmentalist, father of cryonics, blood scientist, sneeze scientist, sperm engineer, scientific entrepreneur, \"basically Q in the James Bond films\", hamster frankenstein.</figcaption></figure><blockquote><p><i>The real job of science is trying to make science fiction come true.</i></p></blockquote><p>&nbsp;</p><p>Britain's greatest mad scientist died recently at 103.&nbsp;</p><p>We'll get to his achievements. But I can't avoid mentioning the 'Gaia hypothesis', his notorious metaphor gone wrong that the Earth is in some sense a single organism whooaa. But him being most famous for <a href=\"https://aeon.co/essays/gaia-why-some-scientists-think-its-a-nonsensical-fantasy\">this is like</a> thinking Einstein's violin playing was his best stuff.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkqflbg0517\"><sup><a href=\"#fnkqflbg0517\">[1]</a></sup></span></p><p>Lovelock was raised as a Quaker, to which he credits his independent thinking (he was a conscientious objector in WWII). Also:&nbsp;</p><blockquote><p><i>\"His family was poor, too poor to pay for him to go to university. He later came to regard this as a blessing because it meant he wasn\u2019t immediately locked into a silo of academia. Somehow, he created an education for himself, taking evening classes that led, when he was 21, to the University of Manchester.\"</i></p></blockquote><p>He quit work and left academia forever in 1964, instead running a one-man \"<a href=\"https://johnryle.com/?article=father-of-gaia\">ten foot by ten foot</a>\" lab from his garden in the West Country,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrvve4c8ovt\"><sup><a href=\"#fnrvve4c8ovt\">[2]</a></sup></span>&nbsp;living off consulting work for NASA, Shell, HP, and MI5 and royalties from 40 <a href=\"https://patents.justia.com/inventor/james-e-lovelock\">inventions</a>.</p><figure class=\"image image_resized\" style=\"width:86.2%\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669845680/mirroredImages/YFyzHT3H67jrk7mdc/u9pl0hkimh37lkt370mr.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f1c592e5deea8dbb317fd65b6032349c3287f91605112664.png/w_110 110w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f1c592e5deea8dbb317fd65b6032349c3287f91605112664.png/w_220 220w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f1c592e5deea8dbb317fd65b6032349c3287f91605112664.png/w_330 330w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f1c592e5deea8dbb317fd65b6032349c3287f91605112664.png/w_440 440w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f1c592e5deea8dbb317fd65b6032349c3287f91605112664.png/w_550 550w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f1c592e5deea8dbb317fd65b6032349c3287f91605112664.png/w_660 660w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f1c592e5deea8dbb317fd65b6032349c3287f91605112664.png/w_770 770w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f1c592e5deea8dbb317fd65b6032349c3287f91605112664.png/w_880 880w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f1c592e5deea8dbb317fd65b6032349c3287f91605112664.png/w_990 990w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/f1c592e5deea8dbb317fd65b6032349c3287f91605112664.png/w_1077 1077w\"><figcaption>Lovelock's single-room \"Experimental Station\" (shed). \u201cI have to call the place an experimental station. If you\u2019re having a kilogram of radioactive material delivered, it can\u2019t be something like Acacia Road, Finchley. It could lead to terrible mistakes.\u201d</figcaption></figure><p>&nbsp;</p><h2>Chromatography, &amp;, modern environmentalism</h2><p>By far his biggest coup was building the <a href=\"https://en.wikipedia.org/wiki/Electron_capture_detector\">electron capture detector</a> in 1957 during his second PhD, the world's most sensitive gas chromatograph (way of detecting chemicals in air).</p><blockquote><p><i>When Lovelock first developed the ECD, the device was at least a thousand times more sensitive than any other detector in existence at the time. It was able to detect chemicals at concentrations as low as one part per trillion\u2014that\u2019s equivalent to detecting a single drop of ink diluted in 20 Olympic-sized swimming pools.&nbsp;</i></p></blockquote><p>He became curious about what the visible air pollution he saw was due to. He picked the notorious CFCs just because they were conspicuous, becoming the first person to notice the global consequences of Thomas Midgley's almighty fuckup fifty years earlier. (CFCs later turned out to be the cause of the hole in the ozone layer, i.e. <a href=\"https://pubmed.ncbi.nlm.nih.gov/8918873/\">millions</a> of skin cancer cases.) <a href=\"https://undsci.berkeley.edu/ozone-depletion-uncovering-the-hidden-hazard-of-hairspray/the-tip-of-the-iceberg/\">He went to Antarctica</a> in person, \"partially self-funded\", to check if they were there too, because why not. He screwed up the interpretation though, writing in <a href=\"https://books.google.com.mx/books?id=xW_T4jV9mFAC&amp;pg=PA155&amp;lpg=PA155&amp;dq=%22the+presence+of+these+compounds+constitutes+no+conceivable+hazard%22&amp;source=bl&amp;ots=aBMXSR5kBA&amp;sig=ACfU3U0zXogm6yd7kFYLltftZlUU1xIwOQ&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwjbsbSD69T7AhVTHEQIHSh4B7UQ6AF6BAgdEAM#v=onepage&amp;q=%22the%20presence%20of%20these%20compounds%20constitutes%20no%20conceivable%20hazard%22&amp;f=false\"><i>Nature</i></a> \"the presence of these compounds constitutes no conceivable hazard\".</p><p>The ECD revolutionised atmospheric chemistry and so the study of air pollution, <a href=\"https://ourworldindata.org/air-pollution\">still</a> one of the more important causes of premature death.</p><blockquote><p><i>On the lawn of the house peacocks strut and mew; a pair of barn owls have built their nest above the Exponential Dilution Chamber, a sealed upper room that was built in order to calibrate the Electron Capture Device. In the garden stands an off-white baroque plaster statue: the image of Gaia.</i></p></blockquote><figure class=\"image image_resized\" style=\"width:54.11%\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669845680/mirroredImages/YFyzHT3H67jrk7mdc/a1rzaseaz4n5wr9cltvo.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/0824c7babf904e282a8dd5fc2d7d0cd8a3ea3ee5b74ba38b.png/w_140 140w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/0824c7babf904e282a8dd5fc2d7d0cd8a3ea3ee5b74ba38b.png/w_220 220w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/0824c7babf904e282a8dd5fc2d7d0cd8a3ea3ee5b74ba38b.png/w_300 300w\"><figcaption><i>Exponential Dilution Chamber in grey.</i></figcaption></figure><p>The device was so sensitive that it showed traces of pesticides in animal tissues all over the world, including DDT. Since that led to <i>Silent Spring, </i>he probably helped along the perverse return of organic farming and the anti-chemicals paranoia of the second half of the C20th.&nbsp;</p><p>Not that he was ever one of those:</p><blockquote><p><i>Too many greens are not just ignorant of science, they hate science... [Environmentalism is like a] &nbsp;global over-anxious mother figure who is so concerned about small risks that she ignores the real dangers. I wish they would grow up [and focus on the real problem]: How can we feed, house and clothe the abundant human race without destroying the habitats of other creatures?</i></p><p><i>Some time in the next century, when the adverse effects of climate change begin to bite, people will look back in anger at those who now so foolishly continue to pollute by burning fossil fuel instead of accepting the beneficence of nuclear power. Is our distrust of nuclear power and genetically modified food soundly based?</i></p></blockquote><p>Later, he was notable for sounding the retreat (humans should start leaving coastal settlements) and for proposing <a href=\"https://en.wikipedia.org/wiki/Ocean_fertilization#Pelagic_pumping\">geoengineering</a> (or as he called it, \"planetary medicine\"). <a href=\"https://web.archive.org/web/20080512022710/http://www.timesonline.co.uk/tol/news/uk/science/article2538897.ece\">Other</a> climate scientists were horrified, no doubt correctly, but I'm not convinced it was for the right reasons - \"<i>There is absolutely no evidence that climate engineering options work or even go in the right direction. I'm astonished that they published this</i>.\" Hm, I wonder why there's no evidence?)</p><p><a href=\"https://www.sourcewatch.org/index.php/James_Lovelock\">Here's a representative sample</a> of the scruffy green opinion about him. The feeling is mutual:</p><blockquote><p><i>\"Carbon offsetting? I wouldn't dream of it. It's just a joke. To pay money to plant trees, to think you're offsetting the carbon? You're probably making matters worse. You're far better off giving to the charity </i><a href=\"https://forum.effectivealtruism.org/posts/RnmZ62kuuC8XzeTBq/why-we-have-over-rated-cool-earth\"><i>Cool Earth</i></a><i>, which gives the money to the native peoples to not take down their forests.\"</i></p></blockquote><h2>Aerospace engineering, &amp;, exo- and astro-biology</h2><p>In 1961 NASA hired him to build a gas chromatograph for their first unmanned moon landing, one purpose of which was to check if there was life there. He did the same for the Viking Mars lander in the 70s. This was one of the founding projects of exobiology and astrobiology, now a perfectly respectable science with PhDs and everything.</p><blockquote><p><i>One truly crazy idea for human survival appears at regular intervals in the media and in the minds of the venturesome. This is the notion that Mars could be a refuge for humanity if our life on Earth was in danger of being terminated... the Martian desert is wholly inimical to all conceivable forms of Earth life. The atmosphere is about a hundred times thinner than the summit of Everest and it provides no shield against cosmic radiation or the ultraviolet radiation of the Sun. The thin air of Mars is 99 per cent CO 2 and utterly unbreathable. There are traces of water on the planet, but it is as salty as the waters of the Dead Sea and undrinkable. The pioneer and would-be spacefarer Elon Musk has said he would like to die on Mars, though not on impact. Martian conditions suggest death on impact might be preferable.</i></p></blockquote><p>Though 90% nonsense,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0gnba0y6el18\"><sup><a href=\"#fn0gnba0y6el18\">[3]</a></sup></span>&nbsp;Gaia actually led to a sound principle in <a href=\"https://www.mdpi.com/journal/life/special_issues/SfEB\">astrobiological surveying</a>: \"look for weird out-of-equilibrium chemistry. Any weird chemistry.\"</p><p>It also led to the creation of something called 'Earth system science', which has come up with <a href=\"https://en.wikipedia.org/wiki/CLAW_hypothesis\">a testable form</a>, good for them.</p><h2>Biology&nbsp;</h2><h3>The fluid dynamics of airborne pathogens</h3><p><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2162185/\">A very early study</a> of how bad droplets and aerosols are per infected person per volume.</p><h3>Blood</h3><p>He <a href=\"https://pubmed.ncbi.nlm.nih.gov/14915967/\">discovered</a> the role of minerals like calcium ions in blood clotting.</p><p>I can't find anything on his work on preserving sperm for artificial insemination, apparently economically crucial. I worry that is his one negative invention.</p><h3>Cryonics</h3><p>He invented the field! Here's a <a href=\"https://www.youtube.com/watch?v=2tdiKTSdE9Y\">must-watch video</a> about his successful work on freezing and reanimating hamsters, during which he reinvented the microwave oven from scratch. He discovered the solutes you need to prevent thermal shock.</p><h2>MI5</h2><p>Suddenly, cheerful espionage:</p><blockquote><p><i>In 1965, when he was in the U.S., he was asked if there was any way to find people hiding in dense tropical rainforests. This was not a casual question; America\u2019s disastrous involvement in Vietnam had begun. His possible solution led to meetings with the CIA, which seemed to go nowhere.&nbsp;</i></p><p><i>...\"I now know that the CIA and other American agencies did not make use of my idea until years later...\"</i></p><p><i>He was more successful with British intelligence operatives. They were looking for a way to track Soviet spies. His idea was to use a chemical marker on their cars that sensors could detect. The British spies were keen, but he was puzzled by the concern they showed for the health of their targets.</i></p><p><i>\u201cI was baffled. I imagined that few would care about the health hazards of a KGB agent in London. Not so: It was almost as if they regarded the opposition as merely rival civil servants and that they at least deserved the care needed to ensure a long and well-earned retirement at pension time.\u201d</i></p></blockquote><p>Actually a little too edgy for me. They only revoked his security clearance when he turned 94, which he bragged was a record.</p><p>&nbsp;</p><p>&nbsp;</p><p>What I love about Lovelock is that is he spouted galaxy-brain hypotheses and <i>also solved actual problems</i>. He bridged hippie environmentalism and the swivel-eyed transhumanism we know and love. His was one of the last vestiges of the <i>grandiose and yet real</i> spirit of 1950s engineering, and so the good side of the Victorian mind. We could use another million of his sort of pro-nuclear environmentalist, too.</p><p>&nbsp;</p><h2>Appendix: Prolegomena to a future biography</h2><ul><li>His <a href=\"https://en.wikipedia.org/wiki/Novacene\">last book</a>, published at the age of 99, concerned artificial superintelligence taking over the world. But don't worry, he was quite sure it'll be benevolent - in fact a superior caretaker of the poor animals. His take is misguided but characteristically happy-go-lucky and metaphysical.</li></ul><blockquote><p><i>We are unique, privileged beings and, for that reason, we should cherish every moment of our awareness. We should now be cherishing those moments even more because our supremacy as the prime understanders of the cosmos is rapidly coming to an end.</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzwvxek06ihd\"><sup><a href=\"#fnzwvxek06ihd\">[4]</a></sup></span></p></blockquote><ul><li>\"He is withering about the attempt of the&nbsp;Intergovernmental Panel on Climate Change&nbsp;to forge a consensus, a word that he says has no place in science.\"<br>&nbsp;</li><li><a href=\"https://www.journals.uchicago.edu/doi/10.1086/712129\">Academic paranoia has recently come for Gaia.</a><br>&nbsp;</li><li>He was mates with William Golding, the misanthropic novelist. An odd couple! Golding is also to blame for the hippie stylings of Gaia:</li></ul><blockquote><p><i>I was quite excited telling Bill about it, and he got excited too and he turned to me and said, \"Look, if you\u2019re going to come up with a big idea like that you\u2019d better give it a proper name,\" and I said, \"What do you suggest?\" And he said, \"I suggest you call it Gaia.\"'</i></p></blockquote><ul><li>Ouch</li></ul><blockquote><p>\"<i>Maybe they'll synthesise food. I don't know. Synthesising food is not some mad visionary idea; you can buy it in Tesco's, in the form of Quorn. It's not that good, but people buy it. You can live on it.</i>\"</p></blockquote><ul><li>Why not:</li></ul><blockquote><p>23-year old James Lovelock... cradling a baby in his arms who would grow to become the world\u2019s best known scientist, Stephen Hawking... Hawking\u2019s father... spent much of his working life at the NIMR studying parasitology. Lovelock was doing research at the time of the encounter on sneezing and disinfection.</p></blockquote><ul><li>lol:</li></ul><blockquote><p><i>Tentatively I mention something Teddy Goldsmith had told me, that Lovelock found out after his father died that he was a gypsy.</i></p><p><i>\u201cA gypsy? Really? He said that?\u201d Lovelock&nbsp;says. \u201cI don\u2019t think so. But he may have been a Baffinlander\u2026\u201d</i></p><p><i>\u201cA what?\u201d</i></p><p><i>\u201cAn eskimo,\u201d&nbsp;Lovelock&nbsp;says, without blinking. \u201cDo you notice a Mongolian cast to my features? That comes from my father. When I was working in America, we were quite poor. I used to sell my blood to the hospital there. And I discovered I have a rare type thought only to occur in Baffinland.</i></p><p><i>\u201cFrom Baffin to boffin,\u201d he adds, with barely a pause, \u201cin one generation.\u201d</i></p></blockquote><ul><li>He seems to have struggled to ever be unoriginal:</li></ul><blockquote><p><i>He is wont to refer to the traditionally privileged classes as Normans and to the rest as Saxons. \u201cMost scientists are Saxons,\u201d he says, clearly including himself. \u201cMargaret Thatcher was the first Saxon Prime Minister.\u201d</i></p></blockquote><ul><li>I've only read two of his 30+ books and I am very sure that there are dozens more ingenious ideas and absurd stories in the rest - not least his <a href=\"https://www.goodreads.com/book/show/61421347-writing-gaia?ac=1&amp;from_search=true&amp;qid=cwdroMwsUP&amp;rank=1\">long correspondence</a> with the all-time great crank Lynn Margulis or his <a href=\"https://collection.sciencemuseumgroup.org.uk/documents/aa110065977/archive-of-professor-james-lovelock\">giant archive</a>.</li></ul><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkqflbg0517\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkqflbg0517\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://books.google.com.mx/books?id=pnV6UYEkU4YC&amp;pg=304&amp;redir_esc=y#v=onepage&amp;q&amp;f=false\">The original piece</a> is actually fine. Some scientists admit it ended up quite useful, closing the loop of Darwinism in a cool way. \"<i>Life evolves in response to environmental change, but the environment also evolves in response to biological change</i>.\" But the books are a bit embarrassing.</p><p>But there's no denying this kind of shit was most of it: <i>\u201cIf we continue to despoil her,\u201d Lovelock&nbsp;says flatly, \u201cthe rest of creation will, as part of Gaia, unconsciously move the Earth itself to a new state, one where we humans may no longer be welcome.\u201d</i>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrvve4c8ovt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrvve4c8ovt\">^</a></strong></sup></span><div class=\"footnote-content\"><p><i>\u201cThe problem,\u201d Lovelock&nbsp;says, \u201cis that some compounds react with palladium, so I thought if I coated the inside of the tube with the right kind of impervious layer, the hydrogen would still go through but the other substances wouldn\u2019t be able to see the palladium and all would be well. And to my joy I discovered that if I treat the tube with fluorine gas, of which I have a small cylinder here\u201d\u2014he points to a white cylinder on the floor\u2014\u201cit forms a </i><a href=\"https://www.science.org/content/blog-post/things-i-won-t-work-dioxygen-difluoride\"><i>fluoride</i></a><i>, a bit like anodised aluminium, which lets the hydrogen through but leaves everything else unchanged, as I hoped.\u201d</i></p><p><i>\u201cIf I was in an ordinary lab, I\u2019d have hell\u2019s delight to be allowed to do this. Health and Safety would be around saying, \u2018Oh, no. Can\u2019t possibly have fluorine in the lab. Could cause an explosion. Palladium? Don\u2019t know about that. Sounds toxic\u2026 Could be carcinogenic\u2026\u2019 But here I can do what I want.\u201d</i></p><p><i>The palladium transmodulator, I realise at this point, is a refinement of the original Electron Capture Detector, invented 34 years ago and still going strong.</i></p><p><i>\u201cOh yes, it\u2019s selling like hot cakes\u201d</i></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0gnba0y6el18\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0gnba0y6el18\">^</a></strong></sup></span><div class=\"footnote-content\"><p>JL: \u201c[Gaia] may turn out to be the first religion to have a testable scientific theory buried in it.\u201d&nbsp;</p><p>I ask him: isn\u2019t such talk about Gaia as a religion playing into the hands of his critics?</p><p>JL: \u201cWell, the neo-Darwinists\u2014Dawkins and so on\u2014are really the Jesuits of modern science. It\u2019s they who have made a dogma of Darwinism. I think it\u2019s because they\u2019ve been embattled for so long with Creationists, particularly in America. But you can\u2019t deny the presence of religious sensibility.\u201d</p><p>I ask him if he ever thinks he should have given Gaia another name.</p><p>\u201cYes\u201d, he says. \u201cQuite often. But I was determined not to have an acronym. I hate acronyms. It was William Golding who thought it up. Perhaps you know? We were neighbours when I lived in Wiltshire. Actually, when he first suggested it I thought he said \u2018gyre\u2019\u2014as in Yeats\u2019 \u2018turning and turning in the widening gyre\u2019. Now that would have been really far-fetched.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzwvxek06ihd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzwvxek06ihd\">^</a></strong></sup></span><div class=\"footnote-content\"><p><i>\"The mistake I think we made was to continue to reason classically. We made this mistake because of the nature of speech, either spoken or written, and the fissiparous tendency of human thinking. We know that our friends and lovers are whole persons. It may seem sensible at various times to consider their livers, skin and blood to understand their special function, or for purposes of medicine, but the person we know is much more than the mere sum of these parts. As I see it, the logical problem with speech is that it proceeds step by step linearly. This is fine for the solution of essentially static problems and has served us well; it has led logicians such as Frege, Russell, Wittgenstein and Popper to offer comprehensible explanations of our world. Now, when I look back on the long arguments I had over Gaia with evolutionary biologists in the Western world, they seem to have been arguments at cross purposes. From the beginning I saw Gaia as a dynamic system. I knew instinctively that such systems cannot be explained in linear logical terms, but I did not know why.\"</i></p><p>From another writer, you would be perfectly correct to ignore this as romantic nonsense. An irony is that he collides names with the actual <a href=\"https://en.wikipedia.org/wiki/Linear_logic\">Linear Logic</a>, which is quite able to model things like his squooshy dynamics.</p></div></li></ol>", "user": {"username": "technicalities"}}, {"_id": "YS3gn2KRR9rEBgjvJ", "title": "Sense-making around the FTX catastrophe: a deep dive podcast episode we just released", "postedAt": "2022-11-30T01:54:39.615Z", "htmlBody": "<p>There hasn\u2019t been as much sense-making around the FTX catastrophe as I would have liked, so we worked quickly to put together a special episode of the Clearer Thinking podcast on the topic.&nbsp;</p><p>We discuss how more than ten billion dollars of apparent value was lost in a matter of days, the timeline of what happened, &nbsp;deception and confusion related to the event, why this catastrophe took place in the first place, and what this means for communities connected to it.&nbsp;</p><p>&nbsp;</p><p>If you\u2019re interested, here it is:</p><p><a href=\"https://clearerthinkingpodcast.com/episode/133\">https://clearerthinkingpodcast.com/episode/133</a></p><p>&nbsp;</p><p>The first portion covers the timeline of events, and after that there are interviews with 5 guests who give their take on the events:</p><p>&nbsp;</p><ul><li>00:01:37 \u2014 Intro &amp; timeline</li><li>00:51:48 \u2014 Byrne Hobart</li><li>01:39:52 \u2014 Vipul Naik</li><li>02:18:35 \u2014 Maomao Hu</li><li>02:41:19 \u2014 Marcus Abramovitch</li><li>02:49:38 \u2014 Ozzie Gooen</li><li>03:21:40 \u2014 Wrap-up &amp; outro</li></ul>", "user": {"username": "spencerg"}}, {"_id": "v7TAMiPkGMKgK626r", "title": "Mass Good", "postedAt": "2022-11-30T00:30:03.440Z", "htmlBody": "<p>Dear Beloved EA Colleagues,</p><p>&nbsp;</p><p>Thank you for everything you do to try to make the world better, and to help sentient beings, living now and in the future. I wish the best for everyone during these rocky times.</p><p>&nbsp;</p><p>And I write to you with a bold proposal:</p><p>&nbsp;</p><p><strong>I propose that we change the name of Effective Altruism to \"Mass Good.\"&nbsp;</strong></p><p>&nbsp;</p><p>Hear me out:</p><p>&nbsp;</p><p>1. EA is an amazing movement because it promotes doing the best things we can do to make the world better, to reduce suffering, etc.&nbsp;</p><p>&nbsp;</p><p>2. I personally think it would be great if more people joined the EA movement! That'd mean more donors (and thus more money for EA orgs), more EA founders (and thus perhaps more and better orgs), more employees for EA orgs (and thus more options for orgs to pick from when hiring), and more people to vote for EA politicians (and thus EA politicians would be more likely to win).</p><p>&nbsp;</p><p>3. At a minimum, it would be great if people outside of the EA movement felt neutral-to-positive towards EA.</p><p>&nbsp;</p><p>4. \"Effective Altruism\" is a less-than-ideal name for accomplishing the goals listed above.&nbsp;</p><p>4a. For instance, the word \"effective\" sounds like an insult to all people who aren't yet involved with the EA movement. It sounds like we're saying that all charities outside the EA movement are simply bad at their jobs and thus 'ineffective.' It's like we're saying that a non-EA soup kitchen fails to successfully feed its local community. Of course, we aren't actually saying any of those mean things! We're really just saying that we want people to try to think about factors like scope and neglectedness, which sometimes get overlooked. But people outside the movement don't know that. They just hear \"effective\" and feel hurt. And why wouldn't they?&nbsp;</p><p>4b. \"Effective\" also sounds conceited. It sounds like everyone who considers herself an EA thinks she is actually \"effective,\" as in successful, at her work. When we say \"I'm an effective altruist,\" it sounds like we're saying \"I am really good at doing altruism!\" Really, of course, we just mean that we are <i>trying</i> to do the most good for the greatest number, or something along those lines. We don't mean to pat ourselves on the back! But how would a stranger know that?</p><p>4c. \"Altruism\" is a fancy word that most people don't use in everyday conversation. So when some people hear the word \"altruism,\" they may think whoever said the word is elitist or trying to show off.</p><p>4d. \"Effective Altruism\" is 7 syllables.&nbsp;</p><p>4e. I have seen recent news articles criticizing EA as being elitist, in the wake of the recent news events. Those articles make me feel sad. And I wonder, when I read the articles, if the name \"Effective Altruism\" contributes to the impression that we're elitist. I wonder if our name makes it harder for the public to see us as the kind people we are, who just want to do as much good as possible!</p><p>&nbsp;</p><p>5. So, I think we should consider a new name. And the one I came up with is \"Mass Good.\" \"Mass Good\" has many benefits:</p><p>5a. \"Mass Good\" is only 2 syllables!&nbsp;</p><p>5b. \"Mass\" and \"Good\" are both relatively common words that many people use in everyday language. That makes them sound less elitist.&nbsp;</p><p>5c. In fact, the word \"Mass\" &nbsp;sounds the <i>opposite</i> of elitist! It sounds like we are a movement of the masses! Perhaps one day we will be. And \"mass\" notes, correctly, that we're looking out for the wellbeing of the masses.</p><p>5d. I think that \"Mass Good\" is a decent simplification of what EA is trying to accomplish. We want to do good for the masses. For as many sentient beings as possible, now or in the future.&nbsp;</p><p>&nbsp;</p><p>WDYT?</p><p>&nbsp;</p><p>Love,</p><p>Alene</p><p>&nbsp;</p><p>PS I realize that I'm just a random person and have no right to suggest a new name for the EA movement. But I figured I'd share my thoughts and see what others think, just in case others like the idea too!</p>", "user": {"username": "alene"}}, {"_id": "nbP9XTwzd6HbNze6x", "title": "EA & LW Forums Weekly Summary (14th Nov - 27th Nov 22')", "postedAt": "2022-11-29T22:59:58.941Z", "htmlBody": "<p><i>Supported by Rethink Priorities</i></p><p>This is part of a weekly series summarizing the top posts on the EA and LW forums - you can see the full collection <a href=\"https://forum.effectivealtruism.org/s/W4fhpuN26naxGCBbN\">here.</a> The first post includes some details on purpose and methodology. Feedback, thoughts, and corrections are welcomed.</p><p>If you'd like to receive these summaries via email, you can subscribe <a href=\"https://easummaries.substack.com/?r=1p817z&amp;s=w&amp;utm_campaign=pub&amp;utm_medium=web\">here.</a></p><p><strong>Podcast version</strong>: prefer your summaries in podcast form? A big thanks to Coleman Snell for producing these! Subscribe on your favorite podcast app by searching for 'Effective Altruism Forum Podcast'.<br><br><strong>Author's note:</strong> this week is a double-week, with an increased karma bar of 70. We'll be back on the regular schedule next week. FTX-related posts are also now separated into their own section, which you can see at the end of the post.</p><p>&nbsp;</p><h1>Top / Curated Readings</h1><p><i>Designed for those without the time to read all the summaries. Everything here is also within the relevant sections later on so feel free to skip if you\u2019re planning to read it all. Posts are picked by the summarizer, and don't reflect the forum 'curated' section.</i></p><p>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/38LGZhQsPNEBRq5Ke/first-fda-cultured-meat-safety-approval\"><u>First FDA Cultured Meat Safety Approval</u></a></p><p><i>by Ben_West</i></p><p>Linkpost for&nbsp;<a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Ftechcrunch.com%2F2022%2F11%2F16%2Fupside-foods-cell-cultured-meat-fda%2F%3Fguccounter%3D1\"><u>this article</u></a>. \u201cIn a major first, the U.S. Food and Drug Administration just offered its safety blessing to a cultivated meat product startup. It completed its first pre-market consultation with Upside Foods to examine human food made from the cultured cells of animals, and it concluded that it had \u201cno further questions\u201d related to the way Upside is producing its chicken.\u201d<br>&nbsp;</p><p>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/3kaojgsu6qy2n8TdC/pre-announcing-the-2023-open-philanthropy-ai-worldviews\"><u>Pre-Announcing the 2023 Open Philanthropy AI Worldviews Contest</u></a></p><p><i>by Jason Schukraft</i></p><p>Open Philanthropy will run an AI worldviews contest in early 2023. Prizes, judging, and other details will be different from the Future Fund competition, but they expect it will be easy to adapt entries for this contest.<br>&nbsp;</p><p>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/yPDXXxdeK9cgCfLwj/short-research-summary-can-insects-feel-pain-a-review-of-the\"><u>Short Research Summary: Can insects feel pain? A review of the neural and behavioural evidence by Gibbons et al. 2022</u></a></p><p><i>by Meghan Barrett</i></p><p>A short summary of&nbsp;<a href=\"https://authors.elsevier.com/a/1g4skErzKIFWg\"><u>Advances in Insect Physiology</u></a> by Gibbons et al. (2022), which summarizes&nbsp; &gt;350 scientific studies to assess the scientific evidence for pain across six orders of insects. It finds strong or substantial evidence for pain in adult insects of five orders.</p><p>Trillions of insects are directly impacted by humans each year (farmed, managed, killed, etc.). Significant welfare concerns have been identified as the result of human activities, however insect welfare is completely unregulated and infrequently researched.</p><p><br>&nbsp;</p><h1>EA Forum</h1><h2>Philosophy and Methodologies</h2><p><a href=\"https://forum.effectivealtruism.org/posts/JgqEqsa6iAtqGLYmw/the-elephant-in-the-bednet-the-importance-of-philosophy-when-1\"><u>The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives</u></a></p><p><i>by MichaelPlant, JoelMcGuire, Samuel Dupret</i></p><p>Report by the Happier Lives Institute on how to compare the value of extending and improving lives, and implications for resource distribution.<br><br>By adjusting (A) the \u2018badness\u2019 of death, and relative value of deaths at different ages and (B) the neutral point on the wellbeing scale where a life is neither good nor bad, they show large differences in WELLBYs* per dollar for different global health charities. *A WELLBY is a one-point change in life satisfaction on a 0-10 scale, per person per year.</p><p>For instance, AMF is ~1.3x more cost-effective than StrongMinds in terms of WELLBYs if you assume the neutral point is &lt;1/10 on the life satisfaction scale, and that we should prioritize the lives of the youngest. However, StrongMinds is ~12x more cost-effective than AMF if we assume a higher neutral point of ~5/10 on the life satisfaction scale. AMF cost-effectiveness also drops if we morally prioritize older children over infants.<br><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/WfeWN2X4k8w8nTeaS/theories-of-welfare-and-welfare-range-estimates\"><u>Theories of Welfare and Welfare Range Estimates</u></a></p><p><i>by Bob Fischer</i></p><p>Summary from the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/jFPWZLP5LJ6EsNifj/introducing-the-animal-advocacy-bi-weekly-digest-nov-4-nov\"><u>Animal Advocacy biweekly digest</u></a>: \"The third piece in the Moral Weights Project by Rethink Priorities. As the Moral Weights Project assumes hedonism (i.e. that well-being is purely made up of your positive and negative conscious experiences) is true, this post explains how their welfare range estimates might change if they assumed another theory of welfare.</p><p>They argue that even though hedonic welfare might not be all of welfare, it\u2019s likely to be a significant portion of it. They use the example of \u201cTortured Tim\u201d, someone experiencing intense physical suffering who likely won\u2019t be experiencing an overall positive life even with flourishing relationships, strong friendships and gaining knowledge. The end result is that they believe that their welfare ranges are only likely to change by a moderate amount (less than 10x) by assuming a different theory of welfare, such as desire satisfaction or object-list theory.\"</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/yPDXXxdeK9cgCfLwj/short-research-summary-can-insects-feel-pain-a-review-of-the\"><u>Short Research Summary: Can insects feel pain? A review of the neural and behavioural evidence by Gibbons et al. 2022</u></a></p><p><i>by Meghan Barrett</i></p><p>A short summary of&nbsp;<a href=\"https://authors.elsevier.com/a/1g4skErzKIFWg\"><u>Advances in Insect Physiology</u></a> by Gibbons et al. (2022), which summarizes&nbsp; &gt;350 scientific studies to assess the scientific evidence for pain across six orders of insects. It finds strong or substantial evidence for pain in adult insects of five orders.</p><p>Trillions of insects are directly impacted by humans each year (farmed, managed, killed, etc.). Significant welfare concerns have been identified as the result of human activities, however insect welfare is completely unregulated and infrequently researched.</p><p><br>&nbsp;</p><h2>Object Level Interventions / Reviews</h2><p><a href=\"https://forum.effectivealtruism.org/posts/3EvLvjfsujzjjXTJM/delay-detect-defend-preparing-for-a-future-in-which\"><u>Delay, Detect, Defend: Preparing for a Future in which Thousands Can Release New Pandemics by Kevin Esvelt</u></a></p><p><i>by Jeremy</i></p><p>Linkpost and key takeaways of the&nbsp;<a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Fdam.gcsp.ch%2Ffiles%2Fdoc%2Fgcsp-geneva-paper-29-22\"><u>paper in the post title</u></a>. The paper discusses that \u201ccurrent trends suggest that within a decade, tens of thousands of skilled individuals will be able to access the information required for them to single-handedly cause new pandemics\u201d and how to defend against this. Suggestions include:</p><p>Delay - secure and universal DNA synthesis screening, liability and insurance for catastrophic outcomes, and a pandemic test-ban treaty.</p><p>Detect - untargeted sequencing to detect exponentially spreading biological threats.</p><p>Defend - pandemic proof PPE, durable and comfortable respirators, resilient supply chains, individualized early warning systems, and develop / install germicidal low-wavelength lights.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/cfFokZu7mH7SKCjwH/mass-media-interventions-probably-deserve-more-attention\"><u>Mass media interventions probably deserve more attention (Founders Pledge)</u></a></p><p><i>by Rosie_Bettle</i></p><p>Mass media campaigns promote behavior change via media programming (eg. radio, TV) and have not been prioritized within global health in part due to mixed RCT evidence regarding their effectiveness upon reducing mortality. The author uses power analyses to demonstrate that previous RCTs have been underpowered to detect these effects. Using alternative evidence including RCTs of media\u2019s effect on behavior change more broadly, the author argues mass media campaigns are a risky but highly promising area for philanthropic investment.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/38LGZhQsPNEBRq5Ke/first-fda-cultured-meat-safety-approval\"><u>First FDA Cultured Meat Safety Approval</u></a></p><p><i>by Ben_West</i></p><p>Linkpost for&nbsp;<a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Ftechcrunch.com%2F2022%2F11%2F16%2Fupside-foods-cell-cultured-meat-fda%2F%3Fguccounter%3D1\"><u>this article</u></a>. \u201cIn a major first, the U.S. Food and Drug Administration just offered its safety blessing to a cultivated meat product startup. It completed its first pre-market consultation with Upside Foods to examine human food made from the cultured cells of animals, and it concluded that it had \u201cno further questions\u201d related to the way Upside is producing its chicken.\u201d</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/kEbdGgMt4Qfair3aN/friendship-forever-new-ea-cause-area\"><u>Friendship Forever (new EA cause area?)</u></a></p><p><i>by rogersbacon1</i></p><p>In the 19th century, same sex relationships were often considered the best relationships one had in life outside of one\u2019s parents. Photos from the time show clear comfort and affection (in comparison to photos of men with their wives, which were often more functional arrangements).</p><p>Close friendships are in significant decline, with one survey (N=2,019) finding 32% of Americans have 0-2 close friends. Smaller families and remote work may be contributors.</p><p>The author argues this area has been almost completely ignored by EA, despite close relationships being often regarded as one of life\u2019s highest intrinsic goods. Possible interventions include \u2018friendship benches\u2019, intergenerational housing, or legally recognizing friendships similarly to how we do romantic relationships.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/gWSa7e2CS7KCu78D8/disagreement-with-bio-anchors-that-lead-to-shorter-timelines\"><u>Disagreement with bio anchors that lead to shorter timelines</u></a></p><p><i>by mariushobbhahn</i></p><p>The author disagrees with some assumptions in the bio anchors report. After adjusting for these, their median estimate for the availability of compute to train TAI is 2036. (Note this is not an estimate for when AI could be dangerous). The three largest changes were:</p><ul><li>Lowering the FLOP/s (floating point operations per second) needed for TAI compared to Human FLOP/s<ul><li>Because humans were trained inefficiently, and may have needed less compute if we were able to learn on more data or use parallelization.</li></ul></li><li>Lowering the doubling time of algorithmic progress<ul><li>Because progress in transformers has been faster than in vision models, and the current model doesn\u2019t capture some important components.</li></ul></li><li>Changing the weighing of some anchors<ul><li>The genome anchor and evolution anchor seem too heavily weighted, given translation from bytes in genome to parameters in neural nets seems implausible to the author, SGD is more efficient than evolutionary algorithms, and ML systems can use human knowledge to \u2018skip\u2019 parts of evolution.</li></ul></li></ul><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/6uwAXinuaxyssofBB/assessing-the-case-for-population-growth-as-a-priority\"><u>Assessing the case for population growth as a priority</u></a></p><p><i>by Charlotte, LuisMota</i></p><p>\u201cRecently, population growth as a cause area has been receiving more attention (MacAskill, 2022, PWI, Jones, 2022a, Bricker and Ibbitson, 2019).\"<br><br>The authors consider three value propositions of population growth, and argue that it falls short of being a top cause area under the longtermism paradigm.</p><ol><li>Long-run population size is likely determined by factors apart from biological population growth rates. (eg. biological reproduction will likely be replaced in large futures)</li><li>Population size may impact economic growth. This is the most compelling case, but its effects are still orders of magnitude smaller than top cause areas.</li><li>Population size has negligible effects on humanity\u2019s resilience to catastrophes.</li></ol><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/oZCPayvcxkDHubcDv/does-putting-kids-in-school-now-put-money-in-their-pockets\"><u>Does putting kids in school now put money in their pockets later? Revisiting a natural experiment in Indonesia</u></a></p><p><i>by droodman</i></p><p>Reanalysis of a study by Esther Duflo in 2001 on the effects of the primary school expansion in Indonesia in the 1970s. The original study finds it causes boys to go to school an average of 0.25 - 0.4 years more over their childhood, and boosts their wages as young adults by 6.8-10.6% per year of extra schooling.<br><br>Droodman's reanalysis includes some technical changes, fresh tests, and thoughts on what could be generating the data\u2019s patterns. They conclude that the additional schools probably led to more kids finishing primary school, but didn\u2019t necessarily lift wages in adulthood.</p><p><br>&nbsp;</p><h2>Giving Recommendations</h2><p>You can now discuss this topic in the <a href=\"https://forum.effectivealtruism.org/topics/effective-giving\">Effective Giving subforum</a>.</p><p>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/uY5SwjHTXgTaWC85f/don-t-just-give-well-give-wellbys-hli-s-2022-charity\"><u>Don\u2019t just give well, give WELLBYs: HLI\u2019s 2022 charity recommendation</u></a></p><p><i>by MichaelPlant</i></p><p>Happier Lives Institute recommends StrongMinds as the most cost-effective intervention they know of for increasing subjective well-being, after comparing it to Givewell top charities. Next up they plan to analyze a broader range of interventions from this well-being lens. They also highlight&nbsp;<a href=\"https://doubleupdrive.org/\"><u>two</u></a>&nbsp;<a href=\"https://optimus.foundation/en/projects/41/\"><u>opportunities</u></a> to get your donation to StrongMinds matched before Dec 31st.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/cGn5HrDKdCkaf3REy/announcing-our-2022-charity-recommendations\"><u>Announcing our 2022 charity recommendations</u></a></p><p><i>by Animal Charity Evaluators</i></p><p>Animal Charity Evaluators (ACE) evaluated 12 animal advocacy organisations in 2022. The Good Food Institute became a Top recommendation. The Humane League, Wild Animal Initiative, and Faunalytics are carried over as Top recommendations from 2021 and will be re-evaluated next year.</p><p>They also have 11 \u2018stand-out\u2019 recommendations, 3 of which are new this year. The post includes overviews of all top and standout charities, and a link to comprehensive reviews.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/NeK9XYY2mDsH5bJdD/our-recommendations-for-giving-in-2022\"><u>Our recommendations for giving in 2022</u></a></p><p><i>by GiveWell</i></p><p>Givewell\u2019s new top recommendation is their \u2018All Grants Fund\u2019, which is allocated to any need that meets their bar of 10x the cost-effectiveness of cash transfers. They are funding constrained, with room for $900M of funding, and a target of $600M which they are unsure if they will meet. They describe where they expect this funding to go and the example impacts. They also celebrate that funding directed by GiveWell from their inception to the end of 2022 will likely save at least 200,000 lives.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/pp2jmWHyDK9sfC4Rh/evaluating-the-evaluators-gwwc-s-research-direction\"><u>\"Evaluating the evaluators\": GWWC's research direction</u></a></p><p><i>by SjirH, Giving What We Can, Michael Townsend</i></p><p>There are over 40 organisations / projects that either try to identify or fundraise for effective charities, but little information on how to select charity evaluators to rely on. The new GWWC research team will focus on connecting evaluators and donors/fundraisers in the effective giving ecosystem in a more effective (higher-quality recommendations) and efficient (lower transaction costs) way. Questions and feedback on these plans are welcomed.</p><p><br>&nbsp;</p><h2>Opportunities</h2><p><a href=\"https://forum.effectivealtruism.org/posts/3kaojgsu6qy2n8TdC/pre-announcing-the-2023-open-philanthropy-ai-worldviews\"><u>Pre-Announcing the 2023 Open Philanthropy AI Worldviews Contest</u></a></p><p><i>by Jason Schukraft</i></p><p>Open Philanthropy will run an AI worldviews contest in early 2023. Prizes, judging, and other details will be different from the Future Fund competition, but they expect it will be easy to adapt entries for this contest.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/kKidKRiCcZ5uGJ6w5/stop-thinking-about-ftx-think-about-getting-zika-instead\"><u>Stop Thinking about FTX. Think About Getting Zika Instead.</u></a></p><p><i>by jeberts, Daphne Hansell</i></p><p>Human challenge trials can significantly speed up vaccine deployment, but recruitment is often a bottleneck. John Hopkins University is currently recruiting for a Zika human challenge trial in the DC-Baltimore area, open to females aged 18-40 - sign up for screening&nbsp;<a href=\"https://centerforimmunizationresearch.org/enrolling_items/zika-vaccine-inpatient-study-cir-316/\"><u>here</u></a>. A 2021 review estimated Zika causes 10K - 80K DALYs per year. The post overviews personal risks and benefits of participation, as well as public health and biosecurity benefits.</p><p>For those interested who don\u2019t fall in the target group for this trial, upcoming trials elsewhere on other infectious diseases (eg. Malaria) are also available <a href=\"https://www.1daysooner.org/recruiting-challenge-studies\">here</a>.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/ozPL3mLGShqvjhiaG/some-research-ideas-in-forecasting\"><u>Some research ideas in forecasting</u></a></p><p><i>by Jaime Sevilla</i></p><p>The author has been involved in forecasting research, and accumulated a list of forecasting research projects which they share here. They likely won\u2019t get to these for months / years and would love for others to take them on.<br><br>Project ideas include comparing aggregation and base rate prediction methods, making accessible intros to key theorems, literature reviews of related concepts, theoretical study, and improving existing aggregation methods. They vary substantially in difficulty.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/ddeCNBhYc2sANsixS/ai-forecasting-research-ideas\"><u>AI Forecasting Research Ideas</u></a></p><p><i>by Jaime Sevilla, lennart, anson</i></p><p><a href=\"https://docs.google.com/document/d/1Vva6AW_udvfavtldWuGbqf8NbbzsgEH8mESEX6NlOvM/edit\"><u>Linked doc</u></a> of interesting / valuable AI forecasting research ideas, primarily prepared by Epoch employees. These include historical analysis (eg. what have been the major algorithmic breakthroughs?, how are chips replaced over time?), extending or reviewing key papers / theories (eg. bioanchors, brain emulation, predictable-ness of AI progress on a task), and others. Most are able to be tackled by research interns or students.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/jpc5FLcTwHyFzWNFy/want-advice-on-management-organization-building\"><u>Want advice on management/organization-building?</u></a></p><p><i>by Ben_Kuhn</i></p><p>Ben Kuhn, the CTO of&nbsp;<a href=\"https://www.wave.com/en/\"><u>Wave</u></a> and who helped scale the company up to ~2K employees, is offering 1-1 advice to leaders of organisations experiencing or expecting to experience a bunch of growth. This could include input on hiring, people management, and organizational structure.</p><p>&nbsp;</p><h2>Community &amp; Media</h2><p><a href=\"https://forum.effectivealtruism.org/posts/dFqydq8nuukH9faX7/take-the-ea-forum-survey-and-help-us-improve-the-forum\"><u>Take the EA Forum Survey and Help us Improve the Forum</u></a></p><p><i>by Sharang Phadke, Ryan Fugate</i></p><p>If you use the forum (even rarely, without an account, or only via these summaries) consider taking this&nbsp;<a href=\"https://forms.gle/BdsWBue2J8LHZ1Wn6\"><u>10 minute survey</u></a> to help the Forum team understand user needs and adjust their 2023 strategy.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/Liphmkodcu7XPDKfK/rethink-priorities-2022-impact-2023-strategy-and-funding-1\"><u>Rethink Priorities\u2019 2022 Impact, 2023 Strategy, and Funding Gaps</u></a></p><p><i>by kierangreig</i></p><p>In 2022, Rethink Priorities (RP) worked on ~60 different research projects across animal welfare, global health and development, longtermism (including AI governance and safety), surveys, and EA movement research. Other efforts included incubating projects, message testing, and running coordination forums. The post covers notable accomplishments in each department. Some research is pioneering in its area and may shift huge amounts of funding eg. the Moral Weights Project, which studies different species' capacities for welfare.</p><p>In 2023 RP intends to focus on insights to increase the effectiveness of others\u2019 efforts on global priorities, driving progress on promising ways to address global priorities (eg. via accelerating priority projects), strengthening reputation and relations, and scaling significantly to increase impact. They also intend to launch a Worldview Investigations team. Vision, values, area-specific strategies, and reasons for cause area diversification are discussed in the post.</p><p>With the discontinuation of the FTX Future Fund, there is a need for new donors. The most urgent funding need is for unrestricted&nbsp;<a href=\"https://www.rethinkpriorities.org/donate\"><u>donations</u></a>, which gives flexibility to react to new opportunities. Funding gaps by area and scenario (no, moderate, or high growth) are shared, in addition to reasons why this funding is likely to be high impact.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/ucqPQ5sgMsj5WMpsT/jeff-bezos-announces-donation-plans-in-response-to-question\"><u>Jeff Bezos announces donation plans (in response to question)</u></a></p><p><i>by david_reinstein</i></p><p>Linkpost for&nbsp;<a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Fwww.cnn.com%2F2022%2F11%2F14%2Fbusiness%2Fjeff-bezos-charity%2Findex.html\"><u>this article</u></a>. In an interview with CNN, Jeff Bezos stated he plans to give away the majority of his $124 billion net worth during his lifetime - primarily to fighting climate change (~10B is already committed to the Bezos Earth Fund) and supporting people who can unify humanity in the face of social and political divisions. He also mentions trying to do so in a levered way, thinking about it carefully, and avoiding ineffective methods.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/jFPWZLP5LJ6EsNifj/introducing-the-animal-advocacy-bi-weekly-digest-nov-4-nov\"><u>Introducing the Animal Advocacy Bi-Weekly Digest (Nov 4 - Nov 18)</u></a></p><p><i>by James Ozden, Sharang Phadke</i></p><p>This new digest will collate the best research, news, and updates in animal advocacy on a weekly cadence. To start with, it\u2019ll be a 3 month experiment and focus only on content posted on the EA forum. Sign up for the emails&nbsp;<a href=\"http://eepurl.com/idMCJD\"><u>here</u></a>, or read this post for summaries of the top posts over Nov 4 - Nov 18.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/W5bT8mxvXzkrKifTE/eirik-mofoss-named-young-leader-of-the-year-in-norway\"><u>Eirik Mofoss named \"Young leader of the year\" in Norway</u></a></p><p><i>by Jorgen_Ljones</i></p><p>Author\u2019s summary (lightly edited): Eirik Mofoss was recently named \u201cYoung leader of the year\u201d by the largest business newspaper in Norway. He is the co-founder of the Norwegian effective altruism community and\u2014as a member of Giving What We Can\u2014donates 20 percent of his income. The award provided lots of valuable attention and traffic to EA Norway and Gi Effektivt, our donation platform. We wanted to share and celebrate this, not only as a recognition of Eirik, but also for all the Norwegian EAs who made this possible.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/AbohvyvtF6P7cXBgy/brainstorming-ways-to-make-ea-safer-and-more-inclusive\"><u>Brainstorming ways to make EA safer and more inclusive</u></a></p><p><i>by richard_ngo</i></p><p>Discussion thread (including&nbsp;<a href=\"https://forms.gle/WnrNi6n1sLnoYzK27\"><u>anonymous feedback form</u></a> and&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1tcPEld6HI0Q2KOU5R7N8tYeod6DAIBDJe775bf4lqVc/edit?usp=sharing\"><u>its results</u></a>) for how to make EA spaces safer, more comfortable, and more inclusive for women.<br><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/qLPtqEqsadiBSK33b/ea-organization-updates-november-2022-1\"><u>EA Organization Updates: November 2022</u></a></p><p><i>by Lizka</i><br>Monthly summary post including job listings and short updates on successes, recently released work, and plans from 20+ EA organisations.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/CZJ93Y7hinjvqt87j/introducing-new-leadership-in-animal-charity-evaluators\"><u>Introducing new leadership in Animal Charity Evaluators\u2019 Research team</u></a></p><p><i>by Animal Charity Evaluators</i></p><p>Introduces Elisabeth Ormandy, new Director of Research, and Vince Mak, new Evaluations Program Manager.</p><p>Animal Charity Evaluators\u2019 (ACE) will be publishing their updated list of recommended charities next week. They intend to step up the transparency and interaction with forum users - publishing blog posts on their evaluation criteria and what has changed, following up on existing suggestions for improvements (some already implemented), and inviting further feedback on their evaluation methods as they update them over the coming months.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/22zk3tZyYWoanQwt7/training-for-good-update-and-plans-for-2023\"><u>Training for Good - Update &amp; Plans for 2023</u></a></p><p><i>by Cillian Crosson, Training for Good, SteveThompson, Jan-WillemvanPutten</i></p><p>Training for Good has narrowed their focus to supporting altruistic and talented early-career professionals into the first stage of high impact careers that are unusually difficult to enter. For Sep 2022 - Aug 2023, they will run an EU Tech Policy Fellowship, Tarbell Fellowship (journalism), and one third program still under development.&nbsp;<br><br>This decision is off the back of experimenting with 7 different programmes during their first year, 6 of which are now discontinued. The most promising was the EU Tech Policy Fellowship, which successfully placed 7 fellows into relevant European think tanks focused on emerging tech policy.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/YdHMxWKBaa79JcsSW/announcing-the-first-issue-of-asterisk\"><u>Announcing the first issue of Asterisk</u></a></p><p><i>by Clara Collier</i></p><p>Author\u2019s summary: \u201cAsterisk is a new quarterly journal of clear writing and clear thinking about things that matter.\u201d The first issue is&nbsp;<a href=\"https://asteriskmag.com/\"><u>out now</u></a>.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/rEHGbC6cAiMGBbB2o/on-ea-messaging-being-a-doctor-in-a-poorer-country\"><u>On EA messaging - being a doctor in a poorer country</u></a></p><p><i>by Luke Eure</i></p><p>As EA attracts people from all over the world, we should be more careful of \u201cwestern-as-default\u201d messaging. An example is the \u2018don\u2019t be a doctor if you want to help people\u2019 advice - which applies much less in countries that lack doctors, and where other opportunities are more limited.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/yPpCCC4REq3zKXWdJ/review-what-we-owe-the-future\"><u>Review: What We Owe The Future</u></a></p><p><i>by Kelsey Piper</i></p><p>Linkpost to the author\u2019s review of What we Owe the Future, published in Asterisk magazine. Summary from Fermi\u2013Dirac Distribution in the comments: \u201cIn What We Owe the Future, MacAskill agrees with other longtermists about the moral importance of the long-term future, but disagrees with most of them about how best to affect it. Relative to other longtermists, MacAskill thinks that affecting societal values is more important and preventing AI-triggered extinction is less important. Also, MacAskill\u2019s recommendations for how to influence the long-term future seem to have been researched less thoroughly than other parts of the book.\u201d</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/f58guFdECnXgsjn2v/a-socialist-s-view-on-liberal-progressive-criticisms-of-ea\"><u>A socialist's view on liberal progressive criticisms of EA</u></a></p><p><i>by freedomandutility</i></p><p>The author outlines liberal progressive criticisms of EA that they, as a socialist, disagree with. The responses to the criticisms are indented below them.</p><ol><li>EA explicitly prioritizes some issues over global health or prioritizes different things to them in general.<ol><li>Liberal progressives implicitly prioritize when they choose where to focus attention, and neglectedness as a criteria means EA\u2019s prioritization will usually differ from other movements.</li></ol></li><li>EA doesn\u2019t embrace localism (local resources used for local problems).<ol><li>This would exacerbate inequality and devalue the lives of foreigners. International wealth inequality is also bigger than most critics realize.</li></ol></li><li>EA isn\u2019t liberal progressive, so it must be conservative. Also see associations with Peter Thiel and Elon Musk.<ol><li>Not the case, and guilt via association is generally a bad argument.</li></ol></li><li>EA is white saviorism<ol><li>Some see localism as a solution to this, but the author thinks EA style evidence-based development is a better solution.</li></ol></li></ol><p><br>&nbsp;</p><h2>Didn\u2019t Summarize</h2><p><a href=\"https://forum.effectivealtruism.org/posts/LNbzDCgCH2py3cnJv/where-are-you-donating-this-year-and-why-open-thread\"><u>Where are you donating this year, and why? (Open thread)</u></a>&nbsp;<i>by Lizka, MichaelA</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/82heDPsmvhThda3af/ama-sean-mayberry-founder-and-ceo-of-strongminds\"><u>AMA: Sean Mayberry, Founder &amp; CEO of StrongMinds</u></a>&nbsp;<i>by Sean Mayberry&nbsp;</i>(questions will be answered on November 28th)</p><p><a href=\"https://forum.effectivealtruism.org/posts/Cpfy4vpH5KfcTRwPh/free-cloud-automation-for-your-ea-org\"><u>Free Cloud Automation for your EA Org</u></a>&nbsp;<i>by JaimeRV, Georg Wind, VPetukhov</i></p><p>&nbsp;</p><h1>LW Forum</h1><h2>AI Related</h2><p><a href=\"https://www.lesswrong.com/posts/3TCYqur9YzuZ4qhtq/meta-ai-announces-cicero-human-level-diplomacy-play-with\"><u>Meta AI announces Cicero: Human-Level Diplomacy play (with dialogue)</u></a></p><p><i>by Jacy Reese Anthis</i></p><p>Cicero is the first AI agent to achieve human-level performance in Diplomacy, a strategy game that emphasizes natural language negotiation and tactical coordination between seven players. Cicero integrates a language model with planning and reinforcement learning algorithms by inferring players' beliefs and intentions from its conversations and generating dialogue in pursuit of its plans. Across 40 games of an anonymous online Diplomacy league, Cicero ranked in the top 10% of participants who played more than one game.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/LtS3tPD56MaKuSLie/when-ai-solves-a-game-focus-on-the-game-s-mechanics-not-its\"><u>When AI solves a game, focus on the game's mechanics, not its theme.</u></a></p><p><i>by strawberry calm</i></p><p>When AI solves a game, people sometimes overfocus on the theme over mechanics. For instance, Diplomacy has a war theme, but the mechanics could apply as easily to gardeners negotiating which plants to plant. The mechanics determine what other domains it can apply to. They give a list of mechanics to consider, including if players can communicate and how, randomness of environment, is the game cooperative or adversarial etc.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/bXTNKjsD4y3fabhwR/conjecture-a-retrospective-after-8-months-of-work-1\"><u>Conjecture: a retrospective after 8 months of work</u></a></p><p><i>by Connor Leahy, Sid Black, Gabriel Alfour, Chris Scammell</i></p><p>Conjecture formed in March 2022. Since then they\u2019ve worked on building infrastructure to deploy large language models and do bespoke interpretability research, identified polytopes as a potentially fundamental unit of neural networks (as opposed to neurons), wrote the popular post&nbsp;<a href=\"https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators\"><u>Simulators</u></a> on a theoretical framing to understand GPT-like models, ran a pilot of an incubator for independent alignment researchers, and more activities covered in the post.</p><p>The authors believe the organization is much stronger now, but that there was no meaningful progress on the alignment problem. After reflection, they\u2019re narrowing their research agenda to areas with the most alignment potential, shifting from deep dives to faster OODA (observe-orient-decide-act) loops, publishing more quickly (not spending time on polish), and making more time for coordination efforts.</p><p><br>&nbsp;</p><p><a href=\"http://lesswrong.com/posts/3zZjF3YKJ257x79mu/what-i-learned-running-refine\"><u>What I Learned Running Refine</u></a></p><p><i>by adamShimi</i></p><p>Refine was an incubator run by Conjecture that aimed to create conceptual alignment researchers with their own radically different agendas (vs. established approaches). The first cohort finished a few weeks ago. No new ones are planned, primarily because SERI MATS is already covering the area and open to suggestions, and other areas of focus for the Conjecture epistemology team are more fundamental and neglected.</p><p>The program successfully helped participants build a deep model of the alignment problem, but only 2 / 5 are already working on their own research agendas, and these use fairly established approaches. The author suggests optimizations to the populations advertised to, criteria, and program itself to focus more on radical ideas.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/73kwTFKgi4AagxFHJ/planes-are-still-decades-away-from-displacing-most-bird-jobs\"><u>Planes are still decades away from displacing most bird jobs</u></a></p><p><i>by guzey</i></p><p>Uses planes not being able to accomplish bird-toddler level tasks (eg. flying without refueling or ejecting eggs out of nests) as an analogy to arguments that AI won\u2019t be able to fundamentally change the world if it can\u2019t accomplish all human-toddler level tasks.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/Jgs7LQwmvErxR9BCC/current-themes-in-mechanistic-interpretability-research\"><u>Current themes in mechanistic interpretability research</u></a></p><p><i>by Lee Sharkey, Sid Black, beren</i></p><p>Themes of mechanistic interpretability research, summarized from discussion with several researchers. Four themes are discussed:</p><ol><li>Object-level research topics eg. solving superposition, describing learning dynamics in terms of circuits, deep learning theory questions, and automating mechanistic interpretability</li><li>Research practices and tools eg. study simpler models, study model systems in depth, or approaches grounded in the theory of causality</li><li>Field building and research coordination eg. hiring independent researchers, open source tooling, skill-building programmes</li><li>Theories of impact</li></ol><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/hhhmcWkgLwPmBuhx7/results-from-the-interpretability-hackathon\"><u>Results from the interpretability hackathon</u></a></p><p><i>by Esben Kran, Neel Nanda</i></p><p>25 projects were submitted by ~70 people, with positive feedback on the experience. The four winning projects were:</p><ol><li>An algorithm to automatically make the activations of a neuron in a Transformer much more interpretable.</li><li>Backup name mover heads from \u201cInterpretability in the Wild\u201d have backup heads and all of these are robust to the ablation distribution.</li><li>The specificity benchmark in the ROME and MEMIT memory editing papers does not represent specificity well. A simple modulation shows that factual association editing bleeds into related texts, representing \"loud facts\".</li><li>TCAV used on an RL agent for a connect four game can have its neural activation compared to the provably best solution as a pilot for comparing learned activations more generally to human-made solutions.<br><br>&nbsp;</li></ol><p><a href=\"https://www.lesswrong.com/posts/Couhhp4pPHbbhJ2Mg/will-we-run-out-of-ml-data-evidence-from-projecting-dataset\"><u>Will we run out of ML data? Evidence from projecting dataset size trends</u></a></p><p><i>by Pablo Villalobos</i></p><p>Based on trends in dataset size and estimates of the total stock of available unlabeled data, the author estimates that we will have exhausted the stock of low-quality language data by 2030 to 2050, high-quality language data before 2026, and vision data by 2030 to 2060. This might slow down ML progress.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/zB3ukZJqt3pQDw9jz/ai-will-change-the-world-but-won-t-take-it-over-by-playing-3\"><u>AI will change the world, but won\u2019t take it over by playing \u201c3-dimensional chess\u201d.</u></a></p><p><i>by boazbarak, benedelman</i></p><p>Systems and agents can have short-term goals (eg. build a piece of software, set pricing to maximize revenue, create an artwork) and/or long-term goals (eg. high-level strategy). The authors argue that there are diminishing returns on information processing with longer time horizons, and there is a \u2018sweet spot\u2019 of a not-too-long horizon in which AI has the biggest comparative advantage. For instance, they expect AI engineers to dominate human engineers, but not for AI CEOs to dominate human CEOs (particularly if the human is assisted by short-term AIs).&nbsp;</p><p>This makes the \u201closs of control\u201d scenario where AI systems act in pursuit of long-term goals not aligned to humanity\u2019s interests less likely, and suggests changes to where we focus attention within AI Safety. The authors lay out six claims that underlie these beliefs, and the evidence for them.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/wG5KTj5jFiibydgmk/arc-paper-formalizing-the-presumption-of-independence\"><u>ARC paper: Formalizing the presumption of independence</u></a></p><p><i>by Erik Jenner</i></p><p>Linkpost for Alignment Research Center\u2019s&nbsp;<a href=\"https://www.lesswrong.com/out?url=https%3A%2F%2Farxiv.org%2Fabs%2F2211.06738\"><u>latest report</u></a>. The report is about finding good formalizations of \"heuristic arguments\u201d, which don\u2019t have formal proofs. It briefly mentions alignment in relation to heuristic arguments being useful to let us better estimate the probability of rare failures or to elicit latent knowledge. The post author suggests it might be a useful read for those working on formal verification, ELK, or conceptual interpretability research.</p><p>&nbsp;</p><p>&nbsp;</p><h2>Rationality Related</h2><p><a href=\"https://www.lesswrong.com/posts/o3RLHYviTE4zMb9T9/tyranny-of-the-epistemic-majority\"><u>Tyranny of the Epistemic Majority</u></a></p><p><i>by Scott Garrabrant</i></p><p>Kelly betting is maximizing the expected logarithm of your wealth. When deciding resources to allocate onto different scenarios you can pretend that each path is a different version of you, and owns a proportion of your resources in line with your probability that version will happen. Eg. If Kelly believes a coin has a 90% chance of coming up tails, and they get their bet doubled if they bet right / lose it if they bet wrong, they\u2019ll bet 80 dollars on tails (90 dollars on tails, partially nullified by 10 dollars on heads).</p><p>This post explains Kelly betting via different scenarios, how it models bayesian updating, how to adjust when payouts aren\u2019t equal, the link to proportional representation, and more risk averse versions of Kelly betting.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/eJYDck4EthKFLga7q/elastic-productivity-tools\"><u>Elastic Productivity Tools</u></a></p><p><i>by Simon Berens</i></p><p>The author finds the most effective productivity tools for them have some elasticity. Eg. an inelastic tool is Blocklist - there is no option to view a blocked site other than disabling the tool. An elastic version would be if you want to visit a blocked site, you need to stare at a blank screen for a minute first.</p><p><br>&nbsp;</p><h2>Other</h2><p><a href=\"https://www.lesswrong.com/posts/A33sgjYoM4Ko9viJv/lw-beta-feature-side-comments\"><u>LW Beta Feature: Side-Comments</u></a></p><p><i>by jimrandomh</i></p><p>Side-comments can now be turned on in your user settings. They\u2019re automatically placed in the post according to block quotes in regular comments.<br>&nbsp;</p><h2>Didn\u2019t Summarize</h2><p><a href=\"https://www.lesswrong.com/posts/kcoqwHscvQTx4xgwa/here-s-the-exit\"><u>Here's the exit.</u></a>&nbsp;<i>by Valentine</i></p><p><a href=\"https://www.lesswrong.com/posts/DMxe4XKXnjyMEAAGw/the-geometric-expectation\"><u>The Geometric Expectation</u></a>&nbsp;<i>by Scott Garrabrant</i></p><p>&nbsp;</p><p>&nbsp;</p><h1>FTX-Related Posts</h1><p>FTX filed for bankruptcy on Nov 11th. For more background on what happened, see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/j7sDfXKEMeT2SRvLG/ftx-faq\"><u>this FAQ</u></a> by Hamish Doodles.</p><p>A collection of support and resources exists&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/ftx-collapse-related-resources\"><u>here</u></a>, including funding opportunities, job matching, information on legal concerns, and advice on responding to journalists.</p><p>The below categorizes the 70+ karma FTX-related posts of the past 2 weeks, including some short summaries of posts or groups of posts:<br>&nbsp;</p><p><strong>Summaries / compilations</strong></p><p><a href=\"https://forum.effectivealtruism.org/posts/f9rFsbsd4rGLQfpQg/sadly-ftx#The_Future_of_Crypto\"><u>Sadly, FTX</u></a>&nbsp;<i>by Zvi</i></p><p>What happened during and before FTX collapse, other people\u2019s thoughts and explanations, media, and some of the key lessons and suggestions put forward. Many links to, summaries, and commentary on other posts.</p><p><a href=\"https://forum.effectivealtruism.org/posts/j7sDfXKEMeT2SRvLG/ftx-faq\"><u>FTX FAQ</u></a>&nbsp;<i>by Hamish Doodles</i></p><p>FAQ on the FTX situation, written on 13th November.</p><p><a href=\"https://forum.effectivealtruism.org/posts/rcciBW3kxojNwB87a/what-happened-at-alameda-research\"><u>What Happened at Alameda Research</u></a>&nbsp;<i>by Jonathan Yan</i></p><p>Linkpost for a compilation of known information on FTX / Alameda from public &amp; private sources.<br>&nbsp;</p><p><strong>Media</strong></p><p><a href=\"https://forum.effectivealtruism.org/posts/efGNMe6uB87qXozXJ/ny-times-on-the-ftx-implosion-s-impact-on-ea\"><u>NY Times on the FTX implosion's impact on EA</u></a>&nbsp;<i>by AllAmericanBreakfast</i></p><p>The author thinks the article is fair and straightforward about EA, and not overly critical.</p><p><a href=\"https://forum.effectivealtruism.org/posts/vjyWBnCmXjErAN6sZ/kelsey-piper-s-recent-interview-of-sbf\"><u>Kelsey Piper's recent interview of SBF</u></a>&nbsp;<i>by Agust\u00edn Covarrubias</i></p><p>Twitter interview between Kelsey Piper of Vox\u2019s Future Perfect and SBF.</p><p><a href=\"https://forum.effectivealtruism.org/posts/4pXiFKbpzpDH6p2Qk/linkpost-sam-harris-on-the-fall-of-sam-bankman-fried\"><u>[Linkpost] Sam Harris on \"The Fall of Sam Bankman-Fried\"</u></a>&nbsp;<i>by michel</i></p><p>20 minute podcast by Sam Harris. He had earlier had SBF on his show, and didn\u2019t expect any wrongdoing. He defends EA principles (separately from the EA community) in this situation.</p><p><a href=\"https://forum.effectivealtruism.org/posts/pj2LqeJxefRFCFEhm/effective-altruism-not-as-bad-as-you-think\"><u>Effective Altruism: Not as bad as you think</u></a>&nbsp;<i>by James Ozden</i></p><p>Link to James\u2019 blog post, written for a non-EA audience to counter misleading opinion pieces.</p><p><a href=\"https://forum.effectivealtruism.org/posts/jsByfxvNA4x23stLY/a-letter-to-the-bulletin-of-atomic-scientists\"><u>A Letter to the Bulletin of Atomic Scientists</u></a>&nbsp;<i>by John G. Halstead</i></p><p>A letter addressing Emile Torres' latest piece criticizing EA, calling out that a false claim was published after being disproved.</p><p><a href=\"https://forum.effectivealtruism.org/posts/D7tkpztwmgg3KrykY/media-attention-on-ea-again\"><u>Media attention on EA (again)</u></a>&nbsp;<i>by Julia_Wise</i></p><p>Short list of what to expect and advice as media attention ramps up.</p><p><a href=\"https://forum.effectivealtruism.org/posts/THgezaPxhvoizkRFy/clarifications-on-diminishing-returns-and-risk-aversion-in\"><u>Clarifications on diminishing returns and risk aversion in giving</u></a>&nbsp;<i>by Robert_Wiblin</i></p><p>Clarifications to an episode description of an interview with SBF in April, which explained SBF\u2019s views on risk aversion and expected value in a confusing way.</p><p>&nbsp;</p><p><strong>Resources</strong></p><p><a href=\"https://forum.effectivealtruism.org/posts/HPdWWetJbv4z8eJEe/open-phil-is-seeking-applications-from-grantees-impacted-by\"><u>Open Phil is seeking applications from grantees impacted by recent events</u></a>&nbsp;<i>by Bastian_Stern</i></p><p>For FTX grantees whose funding was affected by recent events.&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/L4S2NCysoJxgCBuB6/announcing-nonlinear-emergency-funding\"><u>Announcing Nonlinear Emergency Funding</u></a>&nbsp;<i>by Kat Woods, Emerson Spartz, Drew Spartz</i></p><p>For FTX grantees where &lt;$10K of bridge funding would be of substantial help.</p><p><a href=\"https://forum.effectivealtruism.org/posts/LYqkptuAiPQcmmGbs/ai-safety-microgrant-round\"><u>AI Safety Microgrant Round</u></a>&nbsp;<i>by Chris Leong, Damola Morenikeji, David_Kristoffersson</i></p><p>Up to $2K USD grants, with total available funding of $6K.</p><p><a href=\"https://forum.effectivealtruism.org/posts/7PqmnrBhSX4yCyMCk/effective-peer-support-network-in-ftx-crisis-update\"><u>Effective Peer Support Network in FTX crisis (Update)</u></a>&nbsp;<i>by Emily, Inga</i></p><p>Includes a&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1ztWUq7ZN21nlgU74O51zPfrDLi9WZy-9SvPhkpeWk1A/edit#gid=0\"><u>table</u></a> of supporters you can contact for free, as well as a&nbsp;<a href=\"https://join.slack.com/t/effectivepeersupport/shared_invite/zt-1jkv97xxh-I~_8J7tTBreFnfCOyi312Q\"><u>peer support network slack</u></a>.</p><p><a href=\"https://forum.effectivealtruism.org/posts/o8B9kCkwteSqZg9zc/thoughts-on-legal-concerns-surrounding-the-ftx-situation\"><u>Thoughts on legal concerns surrounding the FTX situation</u></a>&nbsp;<i>by Molly</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/NxEuiEWHffi5s6qQz/thoughts-on-legal-concerns-surrounding-the-ftx-situation-1\"><u>Thoughts on legal concerns surrounding the FTX situation: document preservation and communications</u></a>&nbsp;<i>by Molly</i></p><p>The above two posts have thoughts from Open Phil\u2019s managing counsel on the likelihood of clawbacks, of your documents becoming public, and what factors affect this.</p><p>&nbsp;</p><p><strong>Organization and personal statements</strong></p><p><a href=\"https://forum.effectivealtruism.org/posts/Et7oPMu6czhEd8ExW/why-you-re-not-hearing-as-much-from-ea-orgs-as-you-d-like\"><u>Why you\u2019re not hearing as much from EA orgs as you\u2019d like</u></a>&nbsp;<i>by Shakeel Hashim</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/eWYQwbX895HnyuhhY/the-relative-silence-on-ftx-sbf-is-likely-the-result-of\"><u>The relative silence on FTX/SBF is likely the result of sound legal advice</u></a>&nbsp;<i>by Tyler Whitmer</i></p><p>The above two posts suggest we should expect few statements on FTX, primarily because of legal implications (other reasons include time costs and lack of information).</p><p><a href=\"https://forum.effectivealtruism.org/posts/RPTPo8eHTnruoFyRH/some-important-questions-for-the-ea-leadership\"><u>Some important questions for the EA Leadership</u></a>&nbsp;<i>by Gideon Futerman</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/qFEwQbetaaSpvHm9e/my-takes-on-the-ftx-situation-will-mostly-be-cold-not-hot\"><u>My takes on the FTX situation will (mostly) be cold, not hot</u></a>&nbsp;<i>by Holden Karnofsky</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/WdeiPrwgqW2wHAxgT/a-personal-statement-on-ftx\"><u>A personal statement on FTX</u></a>&nbsp;<i>by William_MacAskill</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/rxojcFfpN88YNwGop/rethink-priorities-leadership-statement-on-the-ftx-situation\"><u>Rethink Priorities\u2019 Leadership Statement on the FTX situation</u></a>&nbsp;<i>by abrahamrowe, Peter Wildeford, Marcus_A_Davis</i></p><p>&nbsp;</p><p><strong>Proposals</strong></p><p><a href=\"https://forum.effectivealtruism.org/posts/sEpWkCvvJfoEbhnsd/the-ftx-crisis-highlights-a-deeper-cultural-problem-within\"><u>The FTX crisis highlights a deeper cultural problem within EA - we don't sufficiently value good governance</u></a>&nbsp;<i>by Fods12</i></p><p>Argues the FTX collapse is part of a broader pattern of governance failures within EA, and suggests better norms around accountability, consideration of stakeholders, conflicts of interest, decision making procedures and power dynamics<i>.</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/HyHCkK3aDsfY95MoD/cea-ev-op-rp-should-engage-an-independent-investigator-to\"><u>CEA/EV + OP + RP should engage an independent investigator to determine whether key figures in EA knew about the (likely) fraud at FTX</u></a>&nbsp;<i>by Tyrone-Jay Barugh</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/TaBJqDMJtEH68Hhfw/ea-should-blurt\"><u>EA should blurt</u></a>&nbsp;<i>by RobBensinger</i></p><p>Argues the processes required to catch bad actors are often similar to correcting innocent errors by good actors, therefore we should \u2018blurt out objections\u2019 whenever something seems false.</p><p><a href=\"https://forum.effectivealtruism.org/posts/56CHyqoZskFejWgae/ea-is-a-global-community-but-should-it-be\"><u>EA is a global community - but should it be?</u></a>&nbsp;<i>by Davidmanheim</i></p><p>Suggests considering whether EA should be a community, or just a philosophy / plan of action.</p><p><a href=\"https://forum.effectivealtruism.org/posts/oiEArRjkajAKayMCp/what-might-ftx-mean-for-effective-giving-and-ea-funding\"><u>What might FTX mean for effective giving and EA funding</u></a>&nbsp;<i>by Jack Lewars</i></p><p>Suggests more focus on funding diversity, to always consider optics, and to avoid oversimplifying funding situations (eg. \u201cEA is overfunded\u201d).</p><p>&nbsp;</p><p><strong>Meta: how we should discuss the situation</strong></p><p><a href=\"https://forum.effectivealtruism.org/posts/aHPhh6GjHtTBhe7cX/proposals-for-reform-should-come-with-detailed-stories\"><u>Proposals for reform should come with detailed stories</u></a>&nbsp;<i>by Eric Neyman</i></p><p>Proposals should be realistic, benefits outweigh the costs, and have a plausible story for how they could have led to better outcomes in the FTX situation.</p><p><a href=\"https://forum.effectivealtruism.org/posts/ArDhtEcRbkwo42N9H/the-ftx-situation-wait-for-more-information-before-proposing\"><u>The FTX Situation: Wait for more information before proposing solutions</u></a>&nbsp;<i>by D0TheMath</i></p><p>Before proposing solutions / takeaways, EA should try to discuss the object-level events and get more information so we\u2019re working off an accurate narrative of what the problems to solve are.</p><p><a href=\"https://forum.effectivealtruism.org/posts/sdAgwtHkBZmkmkcpZ/in-favour-of-compassion-and-against-bandwagons-of-outrage\"><u>In favour of compassion, and against bandwagons of outrage</u></a>&nbsp;<i>by Emrik</i></p><p>Argues EA should be compassionate and avoid bandwagons of outrage / instincts of mob justice, while still condemning unethical behavior.</p><p><a href=\"https://forum.effectivealtruism.org/posts/7ZjJ9w2xf7Mkdofk8/does-sam-make-me-want-to-renounce-the-actions-of-the-ea\"><u>Does Sam make me want to renounce the actions of the EA community? No. Does your reaction? Absolutely.</u></a>&nbsp;<i>by GoodEAGoneBad</i></p><p>Argues that EA at its best is a supportive community that learns together, and recently there has been too much airing of grievances with EA only weakly related to the FTX situation.</p><p><a href=\"https://forum.effectivealtruism.org/posts/DB9ggzc5u9RMBosoz/wrong-lessons-from-the-ftx-catastrophe\"><u>Wrong lessons from the FTX catastrophe</u></a>&nbsp;<i>by burner</i></p><p>These include assuming ambition or earning to give is a mistake, and updating too heavily on pieces from long-term EA critics or on philosophical concepts of ethics.<br>&nbsp;</p><p><strong>Could EA have prevented this?</strong></p><p>This set of posts discuss if EA should take any blame for the FTX situation, whether we could have noticed issues ahead of time, and whether SBF\u2019s motives were driven by EA.</p><p><a href=\"https://forum.effectivealtruism.org/posts/7o8foiTKYdRrgtzyE/if-professional-investors-missed-this\"><u>If Professional Investors Missed This\u2026</u></a><i> by Jeff Kaufman</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/4zjnFxGWYkEF4nqMi/how-could-we-have-avoided-this\"><u>How could we have avoided this?</u></a>&nbsp;<i>by Nathan Young</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/SP3Hkas3jo6i2cmqb/who-s-at-fault-for-ftx-s-wrongdoing\"><u>Who's at fault for FTX's wrongdoing</u></a>&nbsp;<i>by EliezerYudkowsky</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/vuWGw4nvq2qJn5eCE/noting-an-unsubstantiated-belief-about-the-ftx-disaster\"><u>Noting an unsubstantiated belief about the FTX disaster</u></a><i> by Yitz</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/aryJKRDxLejPHommx/sbf-extreme-risk-taking-expected-value-and-effective\"><u>SBF, extreme risk-taking, expected value, and effective altruism</u></a>&nbsp;<i>by vipulnaik</i><br>&nbsp;</p><p><strong>Other: reactions, experiences, and advice</strong></p><p><a href=\"https://forum.effectivealtruism.org/posts/tSQKuohL6WZvh2scz/trying-to-keep-my-head-on-straight\"><u>Trying to keep my head on straight</u></a>&nbsp;<i>by ChanaMessinger</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/jbsmfPjRH6irTP6zu/some-feelings-and-what-s-keeping-me-going\"><u>Some feelings, and what\u2019s keeping me going</u></a>&nbsp;<i>by Michelle_Hutchinson</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/eoLwR3y2gcZ8wgECc/hubris-and-coldness-within-ea-my-experience\"><u>Hubris and coldness within EA (my experience)</u></a><i> by James Gough</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/23ACb9MjQn7tizKY7/selective-truth-telling-concerns-about-ea-leadership\"><u>Selective truth-telling: concerns about EA leadership communication.</u></a>&nbsp;<i>by tcelferact</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/STJ2DAC8wyFbviPc9/a-long-termist-perspective-on-ea-s-current-pr-crisis\"><u>A long-termist perspective on EA's current PR crisis</u></a>&nbsp;<i>by Geoffrey Miller</i><br><a href=\"https://forum.effectivealtruism.org/posts/GqvSoerAurEbiP9GE/moderator-appreciation-thread\"><u>Moderator Appreciation Thread</u></a>&nbsp;<i>by Ben_West</i></p>", "user": {"username": "GreyArea"}}, {"_id": "vvDEAYkbQqWktcbXK", "title": "Distinguishing test from training", "postedAt": "2022-11-29T21:41:20.369Z", "htmlBody": "", "user": {"username": "So8res"}}, {"_id": "TWv9GnKkGBbu3gbPX", "title": "SBF interview with Tiffany Fong", "postedAt": "2022-11-29T21:09:16.993Z", "htmlBody": "<p>Covered here: <a href=\"https://nymag.com/intelligencer/2022/11/in-new-interview-sbf-talks-gop-donations-fraud-polyamory.html\">https://nymag.com/intelligencer/2022/11/in-new-interview-sbf-talks-gop-donations-fraud-polyamory.html</a></p><p>And here: <a href=\"https://www.coindesk.com/business/2022/11/29/sam-bankman-fried-addresses-withdrawals-ftx-collapse-in-newly-released-audio-interview/\">https://www.coindesk.com/business/2022/11/29/sam-bankman-fried-addresses-withdrawals-ftx-collapse-in-newly-released-audio-interview/</a></p><p>Disclaimer: My transcriptions might contain some inaccuracies.</p><p>The section beginning <a href=\"https://www.youtube.com/watch?v=xP54LZB3WRw&amp;t=691s\">11:31</a> in the second interview might be especially interesting for the readers of the forum. From this and other publicly available information, it seems likely to me that Sam acted as a naive consequentialist. This, of course, isn't mutually exclusive with having elevated dark triad traits (as mentioned <a href=\"https://forum.effectivealtruism.org/posts/difodB6EkiuzXCcMW/retracted-discussion-was-sbf-a-naive-utilitarian-or-a?commentId=aD4pudRB8rFvc2aXK\">here</a> and <a href=\"https://forum.effectivealtruism.org/posts/vjyWBnCmXjErAN6sZ/kelsey-piper-s-recent-interview-of-sbf?commentId=bYnJM7nY9D3tc8gpk\">here</a>).&nbsp;</p><h1>Quotes from that section:</h1><p>\"Honestly, I like, right now, I'm mostly focusing on, what I can do, and like, where I can be helpful, and like, it's... there will be a time and a place for (...) ruminating on my future, but [sighs] I, right now it's more one foot in front of the other, and you know, trying to be as helpful and constructive as I can, and uh, that's all I can do for now, and there's no (...) I don't know what the future will hold for me - it's pretty unclear - it's certainly not the future I once thought it was (...) my future is not the thing that [inaudible] not the thing that matters here - what matters is the world's future -I'm much more worried about the damage that I did to that than whatever happens to me personally.\"</p><p>\"I made a decision a while ago that like, I was gonna, like you know, spend my life trying to do what I could for the world, and like obviously it hasn't turned out like how I had hoped.\"&nbsp;</p><p>\"I feel really really bad for the people who trusted me and believed in me, and, then, you know, we're trying to do great things for the world and tied it to me - and that got, you know, undermined so I fucked up. &nbsp;And that's like... I don't know, that's the shittiest part of it. If it were just myself that it hurt, like, then whatever, but it wasn't.\"</p><p>&nbsp;</p><h1>Other highlights:</h1><p>Sam <a href=\"https://www.youtube.com/watch?v=6DezodR9hNI&amp;t=774s\">claims</a> that he donated to Republicans: \"I donated to both parties. I donated about the same amount to both parties (...) That was not generally known (...) All my Republican donations were dark (...) and the reason was not for regulatory reasons - it's just that reporters freak the fuck out if you donate to Republicans [inaudible] they're all liberal, and I didn't want to have that fight\". (EDIT: My initial interpretation of this was that Sam believed that some Republicans would be helpful to fund to advance altruistic causes he supports, e.g. pandemic prevention, which may suggest donating for reasons other than public image. A comment below pushes back at my idea that the potential selfish reasons to donate can only be because of PR reasons, and notes that donating to both parties is a common practice among corporations/powerful individuals pursued for self-interested reasons. It is also possible that it could be for both self-interested <i>and altruistic </i>reasons, in addition to one, or the other.)</p><p>In response to to his lawyers' advice regarding his public apologies, Sam <a href=\"https://www.youtube.com/watch?v=6DezodR9hNI&amp;t=894s\">says</a> he told his lawyers \"to go fuck [themselves]\" and claims that they \"know what they talk about in extremely narrow domain of litigation - they don't understand the broader context of the world, like, if you're a complete dick about everything, even if it narrowly avoids maybe moderately embarrassing statements, it's not helping [mostly inaudible - but maybe he said 'any of them'?]\".</p><p>Sam describes the collapse as a \"<a href=\"https://youtu.be/xP54LZB3WRw?t=250\">risk management failure</a>\". Fong <a href=\"https://youtu.be/xP54LZB3WRw?t=315\">asks</a>: \"I mean, you can't be the only person that was like, aware - in charge of all of this.\" Sam replies: \"I think the bigger problem was that there was no [...] person who was chiefly in charge of monitoring the risk of margin positions on FTX. Like there should have been but there wasn't\". Later, Sam also says \"at the same time, I think, you know, we stretched ourselves too thin. And we're doing a lot of things at the company - and, you know, I think we should have cut a few of them out and focus more on making sure that the fundamental, like, the most important things we were doing well at\". Malice and incompetence can mix and match, so that might be the case (in addition to a lack of moral qualms).</p><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=6DezodR9hNI\"><div><iframe src=\"https://www.youtube.com/embed/6DezodR9hNI\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=xP54LZB3WRw\"><div><iframe src=\"https://www.youtube.com/embed/xP54LZB3WRw\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>&nbsp;</p><h1>Other relevant videos from Fong:</h1><p>Why is Sam Bankman-Fried Talking To Me? (AUDIO CLIP) Phone Call with SBF - Former FTX CEO / Founder</p><p><a href=\"https://www.youtube.com/watch?v=DHtThZ4717U\">https://www.youtube.com/watch?v=DHtThZ4717U</a></p><p>CONTEXT: My Phone Call with SBF / Sam Bankman-Fried- Former CEO of FTX - Phone Calls About Ch 11</p><p><a href=\"https://www.youtube.com/watch?v=tmk3QQ1_9xw\">https://www.youtube.com/watch?v=tmk3QQ1_9xw</a>&nbsp;</p>", "user": {"username": "Timothy Chan"}}, {"_id": "cgSybKmFrXPLrPRQ6", "title": "Doing good by doing nothing: How can we better praise frugality?", "postedAt": "2022-11-29T20:33:38.723Z", "htmlBody": "<p>I've been thinking lately about what kinds of altruistic actions we typically praise and how that differs for normal people versus the ultra-rich. Here are two observations:</p><p><u>Observation 1:</u> For our peers, we praise both donations and altruistic personal choices. Any size donation is rightly seen as praiseworthy because it involves sacrificing more self-interested goals. Similarly, personal choices like acts of community service are praised because they involve sacrifice of time and energy.</p><p><u>Observation 2:</u> For wealthy individuals, we praise donations but not personal choices. Whenever an ultra-rich person makes a large enough gift, we react positively. And although the media occasionally laments over Jeff Bezos' <a href=\"https://nypost.com/2022/02/18/how-bezos-super-yacht-sizes-up-against-ellisons-and-brins/\">superyacht</a> or <a href=\"https://www.cheatsheet.com/entertainment/inside-jeff-bezos-2-150-million-private-jets.html/\">private jet usage</a>, we rarely hear praise about how Richard Branson <a href=\"https://www.theguardian.com/theguardian/2002/sep/28/features.jobsmoney2\">buys 10 dollar wine</a> or Charlie Ergen <a href=\"https://www.ft.com/content/ac99dfd4-a774-11e2-9fbe-00144feabdc0#axzz39drpAowJ\">brown-bags his lunch</a>.&nbsp;</p><p>The takeaway is that for normal, non-wealthy people, there are two ways to gain praise for altruism: donations and lifestyle. In contrast, <strong>the ultra-wealthy only have only avenue for praise: donations.</strong></p><p>This is very bad. EA has successfully demonstrated that lifestyle choices are important in measuring one's benefit or harm to the world. <a href=\"https://80000hours.org/\">80K Hours</a> proves just how impactful one's career choice can be. <a href=\"https://www.thelifeyoucansave.org/?gclid=Cj0KCQiA-JacBhC0ARIsAIxybyPIjtGeHaOr1UwBbR4y7m8eMb79KV0ZJto0CMXRAamQru617uOT7KcaAhmTEALw_wcB\">The Life You Can Save</a> and <a href=\"https://www.givingwhatwecan.org/\">Giving What We Can</a> claim that irresponsible spending can constitute a form of indirect harm. <a href=\"https://www.williammacaskill.com/longtermism\">Longtermism</a> suggests that researching existential threats has the potential to save trillions of future human lives.</p><p>To be clear, I don't think we could or should convince the ultra-wealthy to begin a new career led by 80K Hours' guidance or spend the next decade researching a nuclear off-ramp. However, their lifestyle choices are deeply consequential, and we should talk about them more. Earlier this year, Warren Buffett made the news by donating <a href=\"https://www.reuters.com/business/warren-buffett-donate-4-billion-worth-berkshire-hathaway-shares-2022-06-14/\">$4B more to multiple foundations</a>. This is obviously praiseworthy as many billionaires fail to give such large sums. However, the media failed to mention that a large part of how Buffett can make such large gifts because he <a href=\"https://www.investopedia.com/articles/financialcareers/10/buffett-frugal.asp\">lives modestly</a>. While other billionaires attend the Monaco Grand Prix in 200 foot yachts, Buffett hangs out in the same Omaha home he's lived in for 6 decades.&nbsp;</p><p>While I am loath to suggest we celebrate rich people more than we already do (see <a href=\"http://www.anand.ly/winners-take-all\"><i>Winners Take All</i></a> for some big problems with that), we should better praise them for one action: frugality. As the ultra-rich get even richer and many vow to give away most of their fortunes, the amount of money they spend during their lifetimes directly determines the amount of good they can do.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflc2gq7tej9\"><sup><a href=\"#fnlc2gq7tej9\">[1]</a></sup></span>&nbsp;Therefore, we should begin to praise the ultra-rich for their personal spending choices just as much as their large donations.</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlc2gq7tej9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflc2gq7tej9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Not to mention the fact that ultra-wealthy spending on items like large houses, yachts, and private jets does terrible harm to the planet through GHG emissions.</p></div></li></ol>", "user": {"username": "Jasper Meyer"}}, {"_id": "pSzxJhmZLfMWmrok7", "title": "Misquoting and Scholarship Norms", "postedAt": "2022-11-29T18:45:53.492Z", "htmlBody": "<p>EA doesn\u2019t have strong norms against misquoting or some other types of errors related to having high intellectual standards (which I claim are important to truth seeking). As I <a href=\"https://forum.effectivealtruism.org/posts/FbvsteE8ySnpFbjuk/misquoting-is-conceptually-similar-to-deadnaming-a\">explained</a>, misquoting is especially bad: \u201cMisquoting puts words in someone else\u2019s mouth without their consent. It takes away their choice of what words to say or not say, just like deadnaming takes away their choice of what name to use.\u201d</p>\n<p>Despite linking to lizka clarifying the lack of anti-misquoting norms, I got this <a href=\"https://forum.effectivealtruism.org/posts/gL7y22tFLKaTKaZt5/debate-about-biased-methodology-or-corentin-biteau-and?commentId=apfB38KGGmH85v44a\">feedback</a> on my anti-misquoting article:</p>\n<blockquote>\n<p>One of your post spent 22 minutes to say that people shouldn't misquote. It's a rather obvious conclusion that can be exposed in 3 minutes top. I think some people read that as a rant.</p>\n</blockquote>\n<p>So let me try to explain that EA really doesn\u2019t have strong anti-misquoting norms or strong norms for high intellectual standards and scholarship quality. What would such norms look like?</p>\n<p>Suppose I posted a single misquote in <em>Rationalization: AI to Zombies</em>. Suppose it was one word added or omitted and it didn\u2019t change the meaning much. Would people care? I doubt it. How many people would want to check other quotes in the book for errors? Few, maybe zero. How many would want to post mortem the cause of the error? Few, maybe zero. So <em>there is no strong norm against misquotes</em>. Am I wrong? Does anyone really think that finding a single misquote in a book this community likes would result in people making large updates to their views (even is the misquote is merely inaccurate, but doesn\u2019t involve a large change in meaning)?</p>\n<p>Similarly, I\u2019m confident that there\u2019s no strong norm against incorrect citations. E.g. suppose in RAZ I found one cite to a study with terrible methodology or glaring factual errors. Or suppose I found one cite to a study that says something different than what it\u2019s cited for (e.g. it\u2019s cited as saying 60% X but the study itself actually says 45% X). I don\u2019t think anything significant would change based on pointing out that one cite error. RAZ\u2019s reputation would not go down substantially. There\u2019d be no major investigation into <em>what process created this error and what other errors the same process would create</em>. It probably wouldn\u2019t even spark debates. It certainly wouldn\u2019t result in a community letter to EY, signed by thousands of people with over a million total karma, asking for an explanation. The community simply tolerates such things. This is an example of intellectual standards I consider too low and believe are lowering EA\u2019s effectiveness a large amount.</p>\n<p>Even most of RAZ\u2019s biggest fans don\u2019t really expect the book to be correct. They only expect it to be <em>mostly</em> correct. If I find an error, and they agree it\u2019s an error, they\u2019ll still think it\u2019s a great book. Their fandom is immune to correction via pointing out one error.</p>\n<p>(Just deciding \u201cRAZ sucks\u201d due to one error would be wrong too. The right reaction is more complicated and nuanced. For some information on the topic, see my <a href=\"https://criticalfallibilism.com/resolving-conflicting-ideas/\">Resolving Conflicting Ideas</a>, which links to other articles including <a href=\"https://curi.us/1588-we-can-always-act-on-non-criticized-ideas\">We Can Always Act on Non-Criticized Ideas</a>.)</p>\n<p>What about two errors? I don\u2019t think that would work either. What about three error? Four? Five? Nah. What exactly would work?</p>\n<p>What about 500 errors? If they\u2019re all basically indisputable, then I\u2019ll be called picky and pedantic, and people will doubt that other books would stand up to a similar level of scrutiny either, and people will say that the major conclusions are still valid.</p>\n<p>If the 500 errors include more substantive claims that challenge the book\u2019s themes and concepts, then they\u2019ll be more debatable than factual errors, misquotes, wrong cites, simple, localized logic errors, grammar errors, etc. So that won\u2019t work either. People will disagree with my criticism. And then they won\u2019t debate their disagreement persistently and productively until we reach a conclusion. Some people won\u2019t say anything at all. Others will comment 1-5 times expressing their disagreement. Maybe a handful of people will discuss more, and maybe even change their minds, but the community in general won\u2019t change their minds just because a few people did.</p>\n<p>There are errors that people will agree are in fact errors, but will dismiss as unimportant. And there are errors which people will deny are errors. So what would actually change many people\u2019s minds?</p>\n<p>Becoming a high status, influential thought leader might work. But social climbing is a very different process than truth seeking.</p>\n<p>If people liked me (or whoever the critic&nbsp;was) and liked some alternative I was offering, they\u2019d be more willing to change their minds. Anyone who <em>wanted</em> to say \u201cYeah, <a href=\"https://criticalfallibilism.com\">Critical Fallibilism</a> is great. RAZ is outdated and flawed.\u201d would be receptive to the errors I pointed out. People with the right biases or agendas would like the criticisms because the criticisms help them with their goals. Other people would interpret the criticism as fighting against their goals, not helping \u2013&nbsp;e.g. AI alignment researchers basing a lot of their work on premises from RAZ would tend to be hostile to the criticism instead of grateful for the opportunity to stop using incorrect premises and thereby wasting their careers.</p>\n<p>I\u2019m confident that I could look through RAZ and find an error. If I thought it\u2019d actually be useful, I\u2019d do that. I did recently find two errors in a different book favored by the LW and EA communities (and I wasn\u2019t actually looking for errors, so I expect there are many others \u2013 actually there were some other errors I noticed but those were more debatable). The first error I found was a misquote. I consider it basically inexcusable. It\u2019s from a blog post, so it would be copy/pasted not typed in, so why would there be any changes? That\u2019s a clear-cut error which is really hard to deny is an error. I found a second related error which is worse but requires more skill and judgment to evaluate. The book has a bunch of statements summarizing some events and issues. The misquote is about that stuff. And, setting aside the misquote, the summary is wrong too. It gives an inaccurate portrayal of what happened. It\u2019s biased. The misquote error is minor in some sense: it\u2019s not particularly misleading. The misleading, biased summary of events is actually significantly wrong and misleading.</p>\n<p>I can imagine writing two different posts about it. One tries to point out how the summary is misleading in a point-by-point way breaking it down into small, simple points that are hard to deny. This post would use quotes from the book, quotes from the source material, and point out specific discrepancies. I think people would find this dry and pedantic, and not care much.</p>\n<p>In my other hypothetical post, I would emphasize how wrong and misleading what the book says is. I\u2019d focus more on the error being important. I\u2019d make less clear-cut claims so I\u2019d be met with more denials.</p>\n<p><strong>So I don\u2019t see what would actually work well.</strong></p>\n<p>That\u2019s why I haven\u2019t posted about the book\u2019s problems previously and haven\u2019t named the guilty book here. RAZ is <em>not</em> the book I found these errors in. I used a different example on purpose (and, on the whole, I <em>like</em> RAZ, so it\u2019s easier for me avoid a conflict with people who like it). I don\u2019t want to name the book without a good plan for how to make my complaints/criticisms productive, because attacking something that people like, without an achievable, productive purpose, will just pointlessly alienate people.</p>\n", "user": {"username": "Elliot Temple"}}, {"_id": "qadEJ7umzr2atXNen", "title": "A Barebones Guide to Mechanistic Interpretability Prerequisites", "postedAt": "2022-11-29T18:43:50.043Z", "htmlBody": "<p><em>Co-authored by Neel Nanda and Jess Smith</em></p>\n<p><em>Crossposted on the suggestion of Vasco Grilo</em></p>\n<h2><strong>Why does this exist?</strong></h2>\n<p>People often get intimidated when trying to get into AI or AI Alignment research. People often think that the gulf between where they are and where they need to be is huge. This presents practical concerns for people trying to change fields: we all have limited time and energy. And for the most part, people wildly overestimate the actual core skills required.</p>\n<p>This guide is our take on the essential skills required to understand, write code and ideally contribute useful research to mechanistic interpretability. We hope that it\u2019s useful and unintimidating. :)</p>\n<h2><strong>Core Skills:</strong></h2>\n<ul>\n<li>Maths:\n<ul>\n<li>Linear Algebra:<a href=\"https://www.youtube.com/watch?v=fNk_zzaMoSs\">&nbsp;3Blue1Brown</a> or<a href=\"https://linear.axler.net/\">&nbsp;Linear Algebra Done Right</a>\n<ul>\n<li>Core goals - to deeply &amp; intuitively understand these concepts:\n<ul>\n<li>Basis</li>\n<li>Change of basis</li>\n<li>That a vector space is a geometric object that doesn\u2019t necessarily have a canonical basis</li>\n<li>That a matrix is a linear map between two vector spaces (or from a vector space to itself)</li>\n</ul>\n</li>\n<li>Bonus things that it\u2019s useful to understand:\n<ul>\n<li>What\u2019s singular value decomposition? Why is it useful?</li>\n<li>What are orthogonal/orthonormal matrices, and how is changing to an orthonormal basis importantly different from just any change of basis?</li>\n<li>What are eigenvalues and eigenvectors, and what do these tell you about a linear map?</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Probability basics\n<ul>\n<li>Basics of distributions: expected value, standard deviation, normal distributions</li>\n<li>Log likelihood</li>\n<li>Maximum value estimators</li>\n<li>Random variables</li>\n<li>Central limit theorem</li>\n</ul>\n</li>\n<li>Calculus basics\n<ul>\n<li>Gradients</li>\n<li>The chain rule</li>\n<li>The intuition for what backprop is - in particular, grokking the idea that backprop is just the chain rule on multivariate functions</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Coding:\n<ul>\n<li>Python Basics\n<ul>\n<li>The \u201chow to learn coding\u201d market is pretty saturated - there\u2019s a lot of good stuff out there! And not really a clear best one.</li>\n<li>Zac Hatfield-Dodds recommends Al Sweigart's <em>Automate the Boring Stuff</em> and then <em>Beyond the Basic Stuff</em> (both readable for free on <a href=\"https://inventwithpython.com/\">inventwithpython.com</a>, or purchasable in books); he's also written some books of exercises. If you prefer a more traditional textbook, <a href=\"https://greenteapress.com/wp/think-python-2e/\"><em>Think Python 2e</em></a> is excellent and also available freely online.</li>\n</ul>\n</li>\n<li>NumPy Basics\n<ul>\n<li>Try to do the first ~third of these: \u200b\u200b<a href=\"https://github.com/rougier/numpy-100\">https://github.com/rougier/numpy-100</a>. Bonus points for doing them in pytorch on tensors :)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>ML:\n<ul>\n<li>Rough grounding in ML.\n<ul>\n<li><a href=\"https://course.fast.ai/\">fast.ai</a> is a good intro, but a fair bit more effort than is necessary. For an 80/20, focus on&nbsp; Andrej Karpathy\u2019s new video explaining neural nets:<a href=\"https://www.youtube.com/watch?v=VMj-3S1tku0\">&nbsp;https://www.youtube.com/watch?v=VMj-3S1tku0</a></li>\n</ul>\n</li>\n<li><a href=\"https://pytorch.org/tutorials/\">PyTorch</a> basics\n<ul>\n<li>Don\u2019t go overboard here. You\u2019ll pick up what you need over time - learning to google things when you get confused or stuck is most of the&nbsp;*real&nbsp;*skill in programming.</li>\n<li>One goal: build linear regression that runs in Google Colab on a GPU.</li>\n<li>The main way you will shoot yourself in the foot with PyTorch is when manipulating tensors, and especially multiplying them. I highly, highly recommend learning how to use <a href=\"https://einops.rocks/1-einops-basics/\">einops</a> (a library to nicely do any reasonable manipulation of a single tensor) and <a href=\"https://rockt.github.io/2018/04/30/einsum\">einsum</a> (a built in torch function implementing Einstein Summation notation, to do arbitrary tensor multiplication)\n<ul>\n<li>If you try doing these things without einops and einsum you will hurt yourself. Do not recommend!</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Transformers - probably the biggest way mechanistic interpretability differs from normal ML is that it\u2019s&nbsp;<em>really</em> important to deeply understand the architectures of the models you use, all of the moving parts inside of them, and how they fit together. In this case, the main architecture that matters is a transformer! (This is useful in normal ML too, but you can often get away with treating the model as a black box)\n<ul>\n<li>Check out<a href=\"https://jalammar.github.io/illustrated-transformer/\">&nbsp;the illustrated transformer</a>\n<ul>\n<li>Note that you can pretty much ignore the stuff on encoder vs decoder transformers - we mostly care about autoregressive decoder-only transformers like GPT-2, which means that each token can only see tokens before it, and they learn to predict the next token</li>\n</ul>\n</li>\n<li>Good (but hard) exercise: Code your own tiny GPT-2 and train it. If you can do this, I\u2019d say that you basically fully understand the transformer architecture.\n<ul>\n<li>Example of<a href=\"https://colab.research.google.com/github/neelnanda-io/Easy-Transformer/blob/main/EasyTransformer_Demo.ipynb#scrollTo=Training_a_Language_Model\">&nbsp;basic training boilerplate</a> and<a href=\"https://github.com/neelnanda-io/Easy-Transformer/blob/main/easy_transformer/train.py\">&nbsp;train script</a></li>\n<li>The<a href=\"https://github.com/neelnanda-io/Easy-Transformer/blob/main/easy_transformer/components.py\">&nbsp;EasyTransformer codebase</a> is probably good to riff off of here</li>\n</ul>\n</li>\n<li>An alternate framing that may help give different intuitions is Nelson Elhage\u2019s<a href=\"https://blog.nelhage.com/post/transformers-for-software-engineers/\">&nbsp;Transformers for Software Engineers</a> (also useful to non software engineers!)</li>\n</ul>\n</li>\n<li>Bonus:<a href=\"https://github.com/jacobhilton/deep_learning_curriculum\">&nbsp;Jacob Hilton\u2019s Deep learning for Alignment syllabus</a> - this is a lot more content than you strictly need, but is well put together and likely a good use of time to go through at least some of!</li>\n</ul>\n</li>\n</ul>\n<p>Beyond the above, if you have the prerequisites, a good way to get more into the field may be checking out<a href=\"https://www.neelnanda.io/mechanistic-interpretability/favourite-papers\">&nbsp;my extremely opinionated list of my favourite mechanistic interpretability papers</a></p>\n<p>Note that there are a lot more skills in the \u201cnice-to-haves\u201d, but I think that generally the best way to improve at something is by getting your hard dirty and engaging with the research ideas directly, rather than making sure you learn every nice-to-have skill first - if you have the above, I think you should just jump in and start learning about the topic! Especially for the coding related skills, your focus should not be on getting your head around concepts, it should be about&nbsp;<em>doing</em>, and actually writing code and playing around with the things - the challenge of making something that actually works, and dealing with all of the unexpected practical problems that arise is the best way of really getting this.</p>\n", "user": {"username": "Neel Nanda"}}, {"_id": "4Y3NKH37S9hvrXLCF", "title": "Apply to join Rethink Priorities\u2019 board of directors.", "postedAt": "2022-11-29T18:43:50.703Z", "htmlBody": "<p>Right now (through January <s>13th</s> 20th),&nbsp;<a href=\"https://careers.rethinkpriorities.org/en/jobs/78036\"><u>you can apply to join RP\u2019s board of directors</u></a> in an unpaid (3-10 hours per month) or paid (5-10 hours per week) capacity.</p><p>Rethink Priorities (RP) has grown quickly, is now large, and remains ambitious (see our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Liphmkodcu7XPDKfK/rethink-priorities-2022-impact-2023-strategy-and-funding-1\"><u>recent post</u></a> for more details). We're looking for people to join our board who can help RP really secure its foundations, and scale in the next several years. While we had been planning on opening these roles prior to FTX\u2019s collapse because we recognized governance as an area of growth for our organization, the recent events help in highlighting why these roles are important. We want to ensure that RP is healthy and sustainable, and thinking about risk and success well in the long-run.&nbsp;</p><p>Our board of directors plays an active role in ensuring that our senior management is making responsible, legal, and risk-aware decisions for the organization in the long-run. They evaluate things like our financial controls, the performance of our Co-CEOs, and budgets and fundraising to help ensure the organization is acting legally and ethically. They also advise our senior management to help ensure the organization stays on track, and continues to target high-level goals for itself.</p><p>If you have any questions about these positions, please contact <a href=\"mailto:careers@rethinkpriorities.org\"><u>careers@rethinkpriorities.org</u></a>. If you have questions about RP\u2019s governance generally, contact abraham@rethinkpriorities.org.<br>&nbsp;</p><p><strong>What does the board of directors do?</strong></p><p>Our board\u2019s primary functions are:</p><ul><li>Providing long-term financial oversight to the organization including:<ul><li>Reviewing and approving the annual budget, and spending controls for the Co-CEOs</li><li>Reviewing annual audits of financial statements and financial controls</li></ul></li><li>Providing oversight for the Co-CEOs including:<ul><li>Performance evaluations of senior management</li><li>Serving as contacts for staff outside the chain of commands</li><li>Providing feedback on Co-CEOs strategic plans</li></ul></li><li>Providing legal oversight for the organization, such as:<ul><li>Helping assess risky and complicated situations, and providing feedback on plans to navigate those situations</li><li>Ensuring that RP is compliant with its charitable purposes</li></ul></li><li>Advising on RP\u2019s long-term strategy and direction<br>&nbsp;</li></ul><p><strong>What qualifications are you looking for in board members?</strong></p><p>We are particularly interested in adding individuals who have knowledge/experience within longtermism, launching/supporting new ventures, and/or scaling organizations. We\u2019d also be excited for candidates with professional legal or nonprofit finance experience.</p><p>&nbsp;</p><p><strong>Do I have to be an American to join the board?</strong></p><p>No! Though we are a US-based organization, these roles do not require US residency. However, we\u2019d like the majority of our board to be made up of US residents (including non-US citizens), and some board functions may require US residency, so while location wouldn\u2019t be disqualifying, it may be a consideration.</p><p>&nbsp;</p><p><strong>What\u2019s the difference between paid and unpaid roles?</strong></p><p>The majority of our board is required by our bylaws to be unpaid. However, we think that there is significant value in our board being more engaged than many members are able to be in a voluntary capacity, so we\u2019d like to pay up to 2 members of the board to provide administrative assistance to the other members, and to tackle some of the more work intensive tasks (such as performance evaluations of senior management). In our view, a failure for many nonprofit boards is they select for skills but not time, and that contributes towards a tendency for boards to not do a very thorough job. We're excited to experiment with one to two people who are designated to spend 5-10 hrs/week on board duties. Right now we have some idea of how this will work, but it will be a first for us. We hope to find candidates excited about innovating to figure out how this time could best be allocated. Because this is essentially a part-time job, it seems reasonable to pay for it accordingly.<br>&nbsp;</p><p><strong>Who is on the current board?</strong></p><p>Ozzie Gooen \u2014 President of the Quantified Uncertainty Research Institute</p><p>Vicky Bond \u2014 President of The Humane League</p><p>Cameron Meyer Shorb \u2014 Executive Director of Wild Animal Initiative</p><p>Marcus Davis \u2014 Co-CEO of Rethink Priorities<br>&nbsp;</p><p><strong>How large is RP and affiliated entities?</strong></p><p>In 2023, RP expects to spend over $10M on its core research projects and fiscally sponsored projects. In total, around 100 staff and long-term collaborators work on these projects.</p><p>&nbsp;</p><p><strong>What\u2019s the legal structure of Rethink Priorities?</strong></p><p>RP is a California-incorporated 501(c)3 nonprofit corporation in the US. We are currently in the process of opening a wholly-owned UK subsidiary. These roles are on the board of the 501(c)3 nonprofit.</p>", "user": {"username": "abrahamrowe"}}, {"_id": "mtXwjZnBGS5Eyx6Hs", "title": "Reminder: you can donate your mana to charity!", "postedAt": "2022-11-29T18:30:27.458Z", "htmlBody": "<p>Manifold Markets lets you create a prediction market on any topic, and bet on the outcome using \"mana\", our play-money currency. What people sometimes forget: besides using mana to show off your prediction skills, you can also use convert mana into real donations to charity!</p><p>We support a wide range of EA charities, such as <a href=\"https://manifold.markets/charity/givewell-maximum-impact-fund\">Givewell</a>, the <a href=\"https://manifold.markets/charity/long-term-future-fund\">Long-Term Future Fund</a>, <a href=\"https://manifold.markets/charity/the-humane-league\">the Humane League</a>, and most recently <a href=\"https://manifold.markets/charity/rethink-priorities\">Rethink Priorities</a>. Check out <a href=\"https://manifold.markets/charity\">our charities page to see them all</a>, and let us know if there are any we should add!</p><p>Why is donating the winnings from a prediction market such a neat idea? Well, from our original grant proposal to set up these <a href=\"https://forum.effectivealtruism.org/posts/mbBfFHKEDBTwTSSJX/predicting-for-good-charity-prediction-markets\">charity prediction markets</a>:</p><blockquote><p>The primary reason to fund charity prediction markets is that they allow people to legally trade on prediction markets using something they value. Other reasons CPMs could be a good idea:</p><ol><li>Prediction markets reward people for being right about the future. People who are often right about the future may be good at deciding which charities are good.</li><li>Prediction markets can help charities make better decisions. For example, the AMF may post a question like \u201cWill there be &gt;600k malaria deaths in 2022\u201d, or more specifically \u201cWill AMF\u2019s follow-up survey show that 40% or more of bednets are still in use after 3 months?\u201d</li><li>Prediction markets can act as donor lotteries. Donors who win have more reason to carefully research where to send their money; donors who lose can save time deciding among charities.</li><li>Prediction markets are fun! Donors may donate more to have fun, compared to what they would have donated otherwise.</li><li>Donors can invest money back into the CPM platform, to fund development or offer donation matches to new traders.</li><li>Donations to charity are less subject to diminishing marginal returns compared to personal wealth. For example, I\u2019d personally prefer a guaranteed $5k rather than a coin flip between $0 and $10k, but I\u2019m ambivalent about which of these gets donated, according to expected value theory</li><li>Prediction markets can train donors to get into the mindset of putting down probability estimates on beliefs, and thinking rigorously about the future.</li><li>Donors may not have to pay taxes on earnings in a CPM, the way they don\u2019t for any earnings in a donor advised fund.</li></ol></blockquote><p>So this Giving Tuesday, consider giving some of your mana as well!</p><figure class=\"media\"><div data-oembed-url=\"https://manifold.markets/Austin/how-many-will-be-donated-through-ma\">\n\t\t\t\t<div class=\"manifold-preview\">\n\t\t\t\t\t<iframe src=\"https://manifold.markets/embed/Austin/how-many-will-be-donated-through-ma\">\n\t\t\t\t</iframe></div>\n\t\t\t</div></figure>", "user": {"username": "akrolsmir"}}, {"_id": "TaJrx7XHMdK6kvQ9X", "title": "\"The Physicists\": A play about extinction and the responsibility of scientists", "postedAt": "2022-11-29T16:53:12.258Z", "htmlBody": "<p><br>&nbsp;</p><p><strong>Abstract&nbsp;</strong></p><p>This text is a short summary of Friedrich D\u00fcrrenmatts play \u201cDie Physiker\u201d (\u201cThe Physicists\u201d). The play is about the moral responsibility of physicists, especially ones capable of developing (something like) the nuclear bomb. It was written in 1960&nbsp;and contains some interesting perspectives on foundational research and X-Risk).&nbsp; Friedrich tries to illustrate the absurdity of the situation scientists in dangerous fields find themselves in by setting the play in a mental hospital. The plot is basically: A physicist figured out \u201cthe theory of everything\u201d and \u201cthe system of all possible inventions\u201d and thinks this is extremely dangerous. He tries to \u201cretract\u201d his findings as a result of this. The play is only about 90 pages long and there\u2019s an English translation available. For those who can\u2019t/don\u2019t want to read the book; here is a short (but hopefully still somewhat entertaining) summary and a list of quotes I think are interesting.&nbsp;</p><hr><p><strong>Summary</strong></p><ol><li>Act&nbsp;</li></ol><p>&nbsp;A body is found in the Asylum \u201cLes Cerisiers\u201d, a luxurious facility for the mentally ill, located in the idyllic Swiss countryside. In this particular block of the asylum, the three patients Newton, Einstein, and M\u00f6bius are treated. Inspector Vo\u00df comes to the sanatorium to clarify the circumstances of the death of the nurse Irene Straub, who was apparently strangled by her patient Einstein.&nbsp;</p><p>Three months earlier, Newton had also killed his nurse Dorothea Moser in a similar way. Then, too, the inspector could not arrest the murderer because of his feigned madness.&nbsp;</p><p>When Vo\u00df wants to make it clear to the head of the Asylum, Dr. Fr\u00e4ulein von Zahnd, that security measures are urgently needed after the second murder of a nurse, she suggests to the inspector that the murders of the nurses are a result of the deformation of the brains by radioactivity. However, since the third inmate had not come into contact with radioactivity, he posed no danger.</p><p>The nurse Monika Stettler confesses her love to M\u00f6bius: she believes in him and in King Solomon, who - he says -&nbsp; appears to him. At first, he tries to talk her out of her feelings, as he cannot risk making contact with the outside world. But when she is not deterred and proposes to marry him and start a family, M\u00f6bius strangles his lover with a curtain cord.&nbsp;</p><p>&nbsp; &nbsp; &nbsp;2. &nbsp;Act</p><p>The first two scenes of the second act repeat the examination scenes of the first act, but with \"reversed circumstances\": The external action largely matches that of the first act, but the opinions and dialogue are mirrored. - The dead nurses have meanwhile been replaced by burly male nurses, all masters of martial arts.&nbsp;</p><p>The inspector, once again appearing for questioning, has accepted the (Dis-)order of the asylum and even corrects Dr. von Zahnd: While she speaks of M\u00f6bius as a \"murderer\", the inspector speaks only of a \"perpetrator\". She pretends to be confused surprised by M\u00f6bius' crime. He rejects the obligation to investigate and capitulates to a situation he cannot change anyway.&nbsp;</p><p>M\u00f6bius talks his way out of any charges by referring to King Solomon, who not only helped him achieve his genius, but also appeared to him to instruct him to murder. Fr\u00e4ulein von Zahnd honestly believes him - a sign of her own madness becoming more and more obvious.</p><p>The three physicists admit to their fellow inmates that they are not in fact, crazy. Newton's real name is Alec Jasper Kilton, he is the founder of the \"theory of correspondence\", has signed on as an agent (presumably with the CIA) and represents the capitalist Western bloc. Similarly Einstein, whose real name is Joseph Eisler, discovered the \"Eisler effect\" and stands for the communist Eastern Bloc. Both are after the work of M\u00f6bius, who believes he has discovered \"the system of all possible inventions\"<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefj42w30flu1h\"><sup><a href=\"#fnj42w30flu1h\">[1]</a></sup></span>&nbsp;and the so-called \"world formula\" and is trying to protect it by having himself committed as a lunatic. Each of the two agents wants to spy on M\u00f6bius' research results for his country. Both draw their pistols, but realize the futility of a duel, as both are equally likely to get shot.&nbsp;</p><p>Over dinner, the three physicists discuss the potential end of the world, the moral responsibility of people who discover potentially dangerous truths and invent powerful weapons. There is this really nice portrait of the absurdity of a situation that frequently occurs in EA settings. One second, you ask about how the end of the world is most likely to happen and how we could make it less likely, and the next second you ask someone to pass the salt.&nbsp;</p><p>Einstein reminds M\u00f6bius of his duty as a scientist to hand over his discoveries to mankind, admits to having no real influence on his political clients and demands the choice of a political system instead of neutrality. Einstein cannot guarantee the use of the scientific results and shifts the responsibility to the party.</p><p>Newton demands that, as a genius, one must give away one's knowledge, which is public property, to \"non-geniuses\", assures that the freedom of physics should be preserved, lures with the Nobel Prize and declares that scientists themselves are not responsible for the use of their findings. He rejects any responsibility and shifts it onto the general public.</p><p>M\u00f6bius exposes apparent possibilities of a free decision as a dead end, fears that Kilton's (Newton)&nbsp; and Eisler's (Einstein) paths can only lead to disaster and wants to prevent the risk of the downfall of mankind. He then demands the retraction of scientific knowledge.</p><p>When M\u00f6bius reveals that he has already burned his notes, the agents realize that their rivalry, which flares up again, has become pointless. M\u00f6bius first tries to convince the two of the necessity of remaining in the lunatic asylum on moral grounds: science has become terrible, research dangerous\u2013 their findings deadly. He sees the only remaining option as capitulation to reality and the restraint of his findings. This persuasion does not work on the agents and they still want to leave the clinic. M\u00f6bius therefore reminds them of their murders: if his knowledge were to become public, the murders would have been in vain and the killings for the protection of humanity would become ordinary murders - and they, as perpetrators, ordinary murderers. He is able to convince them to see their imprisonment as atonement for the murders they have committed and thus to make their contribution to saving humanity. The outcome of the play therefore initially seems positive: the heroes sacrifice themselves, personal guilt is atoned for, the disturbed world order seems restored.</p><p><br>Dr. von Zahnd has the physicists brought from their rooms and disarms the two agents. She tells them that King Solomon has also been appearing to her for years and that she had deliberately set her nurses on the three physicists so that they would die. This tied the physicists to the asylum as \"perpetrators\", since outside they would be considered \"murderers\". Dr. von Zahnd informs the three that she had already copied all of M\u00f6bius' manuscripts before they were destroyed and kept them for herself. While the three physicists remain locked up in the asylum as supposedly insane, the asylum director will unscrupulously profit from the records without considering what great dangers lie in the new technologies - technologies that could destroy all of humanity. The dramaturgically necessary \"worst possible turn\" mentioned by D\u00fcrrenmatt (the author) in his \"21 Points\" has occurred.</p><p>The 21. Points concerning \u201cthe physicists\u201d are listed in the epilogue of the play.</p><ol><li>I do not start from a thesis, but from a story.</li><li>If one starts from a story, it must be thought through to the end.</li><li><u>A story is finished when it has taken its worst possible turn.</u></li><li>The worst possible turn cannot be foreseen. It occurs by chance.</li><li>The art of the dramatist is to use chance as effectively as possible in a plot.</li><li>The bearers of a dramatic plot are human beings.</li><li>Chance in a dramatic action consists of when and where who happens to meet whom.</li><li>The more planned people are, the more effectively chance can affect them.</li><li>People who act according to plan want to achieve a certain goal. Chance always hits them the worst when it causes them to achieve the opposite of their goal: That which they feared, that which they tried to avoid (e.g. Oedipus).</li><li>Such a story is grotesque, but not senseless.</li><li>It is paradoxical.</li><li>Just like the logicians, the dramatists cannot avoid paradox.</li><li>Just as logicians cannot avoid paradox, neither can physicists.</li><li>A drama about physicists must be paradoxical.</li><li>It cannot aim at the content of physics, but only at its effects.</li><li>The content of physics concerns the physicists, the effects all people.</li><li>What concerns everyone can only be solved by everyone.</li><li>Any attempt by an individual to solve for himself what concerns everyone must fail.</li><li>Reality appears in the paradox.</li><li>Those who confront the paradox expose themselves to reality.</li><li>Drama can trick the spectator into exposing himself to reality but not force him to withstand it or even overwhelm it.<br>&nbsp;</li></ol><figure class=\"image image_resized\" style=\"width:69.09%\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669755638/mirroredImages/TaJrx7XHMdK6kvQ9X/ybimjt4yzpf3h1nbyeim.png\"><figcaption>Friedrich D\u00fcrrenmatt\u2019s Drawing \u201cdie Physiker\u201d. Sitting at the table are the three physicists, on the right is the head of the asylum, Dr. Zahnd.&nbsp;</figcaption></figure><p>&nbsp;</p><p><strong>&nbsp;What would D\u00fcrrenmatt say about X-Risk prevention?&nbsp;</strong></p><p>If you would go up to Friedrich D\u00fcrrenmatt and say: \u201cOkay Friedrich, your story is nice and all, but it doesn\u2019t actually tell us anything about how to handle X-Risk, the threat of a nuclear war, the safe development of AI or S-Risk.\u201d He would probably disagree.&nbsp; Friedrich was convinced of the \u201cunpredictability\u201d of the worst possible turn of events ( \u2192 Point 4). But that doesn\u2019t mean that he didn\u2019t have any opinions on how to best handle the threat of human extinction.&nbsp;</p><p>He seems to have been both very naive and very pessimistic about how the world would handle the responsibility of knowing something like a unified field theory or the \u201csystem of all possible&nbsp; inventions.\u201d Naive because he assumed that the genius at the center of this story , M\u00f6bius, is motivated and willing enough to destroy his own credibility for the sake of saving the world from whatever knowledge he produced . (And could actually convince other physicists, his fellow inmates, of doing the same.)&nbsp; Pessimistic, because he doesn\u2019t really seem to see any upsides of knowing this \u201ctheory of everything\u201d. He doesn\u2019t seem to think of the opportunities scientific progress could bring. Which, in the 1960\u2019s - the age of &nbsp;technological progress being weaponized to an absurd degree&nbsp; (both for demonstrative and actual \u201cwinning\u201d) - is maybe kind of understandable.&nbsp;</p><p>The most relevant opinion D\u00fcrrenmatt seems to illustrate seems to be a connection between scientific freedom and existential security.</p><p>M\u00f6bius doesn\u2019t want to join the American, nor the Soviet agent because of their answer to the question, \u201care your physicists free?\u201d As soon as Kilton or Eisler mention that physicists work for the defense of their countries, M\u00f6bius shrugs and says \u201cso they\u2019re not free.\u201d ..implying that science is doomed to become destructive as soon as militaristic agents are institutionally connected to it. Or maybe less controversially: When scientists have to work for the defense of their countries, they have problems they wouldn\u2019t have in other circumstances: They might be pressured to invent things specifically to induce suffering in others or destroying civilization (s))&nbsp;</p><p><strong>Some quotes to think about</strong></p><p>M\u00f6bius: (...) I am content with my fate\".&nbsp;</p><p>Newton: But I am not satisfied with it, a rather decisive circumstance, don't you think? I honor your personal feelings, but you are a genius and as such public property. You are pushing into new areas of physics, but you have not leased science. You have the duty to open the door to us, the non-geniuses.&nbsp;</p><p>...</p><p>M\u00f6bius: Aren't we going to eat any more?&nbsp;</p><p>Newton: I've lost my appetite.&nbsp;</p><p>Einstein: Too bad about the cordon bleu.&nbsp;</p><p>\u2026.&nbsp;</p><p>M\u00f6bius stands up: We are three physicists. The decision we have to make is a decision among physicists. We must proceed scientifically. We must not let ourselves be determined by opinions, but by logical conclusions. We must try to find what is reasonable. We must not make a mistake in thinking, because a wrong conclusion would have to lead to catastrophe. The starting point is clear. All three of us have the same goal in mind, but our tactics are different. The goal is the progress of physics. You, Kilton, want to preserve its freedom and deny it responsibility. You, on the other hand, Eisler, commit physics in the name of the responsibility of the power politics of a certain country. But what does reality look like? I demand information about that, shall I decide. (...) Strange. Everyone offers me a different theory, but the reality they offer me is the same: a prison. I prefer my madhouse. At least it gives me the security of not being exploited by politicians.</p><p>Einstein: But after all is said and done, you have to take certain risks.&nbsp;</p><p>M\u00f6bius: There are risks you must never take: the downfall of mankind is one of them.&nbsp;</p><p>..</p><p>Newton: M\u00f6bius! You can't ask us to be eternally-.&nbsp;</p><p>M\u00f6bius: My only chance to remain undiscovered after all. Only in the madhouse are we still free. Only in the madhouse may we still think. In freedom our thoughts are explosives.&nbsp;<br>&nbsp;</p><p><i><strong>&nbsp;</strong></i></p><hr><p>Thanks to Michel Justen and Nikola Jurkovich for comments on the draft and my lectures for being boring enough so I can go down random rabbit holes.<br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnj42w30flu1h\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefj42w30flu1h\">^</a></strong></sup></span><div class=\"footnote-content\"><p><strong>P.S. The System of \u201cAll possible inventions\u201d</strong></p><p>As I was rereading this book, something struck me as weird. This \u201cSystem of all possible inventions\u201d seemed less clear than the \u201cworld formula\u201d (which I guess we would interpret as some sort of unified field theory.) I couldn't think of how D\u00fcrrenmatt would come across this, or what exactly he would even mean by such a \u201csystem\u201d. Simultaneously, I spent some time researching this guy,&nbsp;<a href=\"https://en.wikipedia.org/wiki/Fritz_Zwicky\"><u>Fritz Zwicky</u></a>, a Swiss Phycisist. He invented the&nbsp;<a href=\"https://www.swemorph.com/ma.html\"><u>\u201cZwicky Box\u201d</u></a> or \u201c<a href=\"https://en.wikipedia.org/wiki/Morphological_analysis_(problem-solving)\"><u>Morphological Analysis\u201d</u></a>. He often talked about it as a way to come up with new inventions and gives it credit for his groundbreaking work on jet propulsion&nbsp;(He held some four dozen patents related to jets and thrust, and is sometimes described as the father of the jet engine. He also conducted respected research in crystals, gaseous ionization, the physics of solid state, slow electrons, and thermodynamics. Also, he came up with the concept and name of \u201cdark matter\u201d, neutron stars and a bunch of other cool stuff). Part of what Zwicky thought was so cool about his analysis was that it didn't only allow for finding&nbsp;<u>some</u> solutions to a problem, but<u> all possible</u> practical solutions, to a problem.&nbsp;</p><p>\u2026It turns out Friedrich D\u00fcrrenmatt, the author of this play, was a close friend of Zwickys, had lunch with him whenever D\u00fcrrenmatt was in the U.S., talked to him about nuclear weapons and morphological analysis.&nbsp; (Zwicky had been one of the first american scientists to visit Hiroshima after the detonation.)&nbsp; (I recommend this biography:&nbsp; M\u00fcller, Roland: Fritz Zwicky: Leben und Werk des grossen Schweizer Astrophysikers, Raketenforschers und Morphologen. Glarus,1987.)</p></div></li></ol>", "user": {"username": "ArchivalLara"}}, {"_id": "bDRNs5rtCMrB47AH5", "title": "Proposal for a Nuclear Off-Ramp Toolkit", "postedAt": "2022-11-29T16:02:25.095Z", "htmlBody": "<p>This post is a&nbsp;<strong>brief summary&nbsp;</strong>of a proposed<strong> Nuclear Off-Ramp</strong>&nbsp;<strong>Toolkit and Framework</strong> put forward by the British American Security Information Council (<a href=\"https://basicint.org/\"><u>BASIC</u></a>).</p><ul><li>The Toolkit aims to \u201c<strong>avert nuclear weapons use</strong> during a time of tensions or conflict\u201d</li><li>It will <strong>assist policy practitioners </strong>in identifying, planning, and implementing \u2018nuclear off-ramps\u2019 (pathways to nuclear de-escalation).&nbsp;</li><li>It will<strong> learn from previous cases</strong> of nuclear de-escalation.&nbsp;</li><li>It will be&nbsp;<strong>disseminated worldwide</strong></li><li>The proposal<strong> just won a&nbsp;</strong><a href=\"https://www.gcsp.ch/global-insights/three-ground-breaking-security-projects-exceptional-promise-are-honoured-2022-gcsp\"><strong><u>prize</u></strong><u> </u><strong><u>for innovation</u></strong></a><strong> </strong>but has not yet secured funding</li></ul><p>These are not my ideas, but a summary of the ideas put forward in an application BASIC made to the Clearer Thinking Regrants program. They are still actively looking for funding. You can read the full application&nbsp;<a href=\"https://docs.google.com/document/d/1LzNzaEVE5Vkz0XMeJTjJ3HPDDLJc_MPQ9tWRBVrUoBE/edit\"><u>here</u></a>.</p><ul><li><i>All quotes come from the full application document.&nbsp;</i></li><li><i>For ease of reading I use the future tense when writing about the Toolkit, although given that the project is not yet funded, the future conditional may be more appropriate.</i></li><li><i>This summary is published with the consent and assistance of Rishi Paul, the application\u2019s primary author</i></li></ul><h1>Context</h1><p>The British American Security Information Council (BASIC) is \u201can independent think tank promoting dialogue to advance global security\u201d, with a focus on nuclear security. It is \u201cdeveloping new approaches to overcome states\u2019 dependency on the doctrine of nuclear deterrence\u201d.</p><p>BASIC would like to ensure that international disputes never escalate into nuclear conflict:</p><blockquote><p>\u201cGiven the increasing frequency of clashes between nuclear possessor states, the critical need for off-ramps, as a mechanism to de-escalate from the nuclear option, whilst also not giving into aggression, is a complex objective and challenge that is mission critical to planetary survival.\u201d</p></blockquote><p>The proposal&nbsp;<strong>may be of interest to EAs concerned with x-risk</strong> because:</p><ul><li>Nothing like the \u201cNuclear Off-Ramp Toolkit and Framework\u201d exists right now</li><li>It could plausibly reduce the risk of a large-scale nuclear conflict</li><li>Some readers may want to assist/fund the project (funding has been difficult to obtain since&nbsp;<a href=\"https://www.vox.com/2022/3/17/22976981/nuclear-war-russia-ukraine-funding-macarthur-existential-risk-effective-altruism-carnegie\"><u>MacArthur left the nuclear sector</u></a>)&nbsp;</li><li>If the project does not go ahead, someone else could make something similar</li></ul><h1>What is it?</h1><p>The Nuclear Off-Ramp Toolkit and Framework is designed to \u201cavert nuclear weapons use during a time of tensions or conflict\u201d by giving state officials a&nbsp;<strong>clear framework for implementing de-escalation</strong>.</p><p>It is hoped that:</p><ul><li>Nuclear-armed states will&nbsp;embed it into their special operating procedures around crisis management.&nbsp;</li><li>This will help defuse crises that could lead to the use of nuclear weapons.&nbsp;</li></ul><p>The Toolkit is designed for use across a range of geopolitical contexts and adversarial nuclear relationships.</p><p>The application identifies two key ingredients of an effective off-ramp strategy, although it is likely that more will be identified in the research phase:</p><ol><li>Shift perceptions - create a \u201cshared understanding of what is at stake\u201d in a nuclear conflict</li><li>A \u201cgolden bridge\u201d - a way for parties to back down without losing face</li></ol><h1>Building the Toolkit</h1><p>BASIC provides a 2-year plan for developing the Toolkit and Framework.</p><ul><li>BASIC will conduct \u201cdesk and field research\u201d and interviews with \u201cacademics, policy experts, and practitioners\u201d in order to \u201c<strong>extract the core ingredients and conditions that previously enabled de-escalation</strong>\u201d in<strong>&nbsp;</strong>7 past crises</li><li>They will<strong> convene a council of experts</strong> to provide feedback and suggestions</li><li>Basic will \u201cinvite a select group of officials and experts from each of the seven nuclear possessor states and NATO\u201d to a<strong> roundtable event.</strong></li><li>The Framework will be stress-tested in two&nbsp;<strong>crisis simulations</strong></li></ul><h1>Dissemination</h1><p>The Toolkit will be shared with governments and NGOs around the world. BASIC has used its network of relationships with NGO communities and government officials to determine which states are open to cooperating with the project.</p><ul><li><strong>NATO&nbsp;</strong>will be the first to get a briefing on the Toolkit and Framework</li><li><strong>France, UK </strong>and<strong> USA&nbsp;</strong>will go next</li><li><strong>China&nbsp;</strong>will get a briefing</li><li>BASIC is \u201cunable to engage\u201d with&nbsp;<strong>Russia&nbsp;</strong>due to the Ukraine war</li><li>BASIC&nbsp;have not yet approached<strong>&nbsp;India </strong>and<strong> Pakistan&nbsp;</strong></li><li><strong>North Korea&nbsp;</strong>and<strong>&nbsp;Israel&nbsp;</strong>are not involved</li></ul><p>BASIC has found that \u201ca substantial portion of our reports and wider publications reach state ministries and officials in both nuclear, and non-possessor states alike\u201d, so&nbsp;<strong>it seems likely that all nuclear-armed states will gain access to the toolkit and framework</strong>.</p><h1>Funding</h1><p>In November 2022 the proposal won the&nbsp;<a href=\"https://www.gcsp.ch/global-insights/three-ground-breaking-security-projects-exceptional-promise-are-honoured-2022-gcsp\"><u>GCSP Prize for Innovation in Global Security</u></a>. The project has not yet secured funding.</p><h1>Read More</h1><ul><li><a href=\"https://docs.google.com/document/d/1LzNzaEVE5Vkz0XMeJTjJ3HPDDLJc_MPQ9tWRBVrUoBE/edit\"><u>Full BASIC application</u></a></li><li><a href=\"https://basicint.org/\"><u>The British American Security Information Council (BASIC)</u></a></li><li><a href=\"https://www.vox.com/2022/3/17/22976981/nuclear-war-russia-ukraine-funding-macarthur-existential-risk-effective-altruism-carnegie\"><u>MacArthur, biggest nuclear security funder, to pull out of sector</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/RGwJviLRnrSojwYwu/opportunities-that-surprised-us-during-our-clearer-thinking\"><u>Clearer Thinking\u2019s take on the application</u></a></li></ul>", "user": {"username": "Stan Pinsent"}}, {"_id": "YuoZpTJBwgLfmxGZm", "title": "100+ Youtube videos with important practical knowledge you probably should know", "postedAt": "2022-11-29T14:36:10.390Z", "htmlBody": "<p>I made a collection of 100+ Youtube videos (<a href=\"https://www.youtube.com/playlist?list=PLGD43-hV2I-mU3tmoZ1FGJI4xpz0QTxui\">Part 1</a> together with <a href=\"https://www.youtube.com/playlist?list=PLGD43-hV2I-kKRj_9aa0y1rdKtVeIohp_\">part 2</a>) to help learn useful practical knowledge from great books, TED-Talks and other sources. It includes knowledge to</p>\n<ul>\n<li>Make more informed decisions.</li>\n<li>Determine if someone is drowning or having a stroke.</li>\n<li>Have stronger more fulfilling relationships.</li>\n<li>Succeed with your goals.</li>\n</ul>\n<p>Feel free to suggest videos/channels/playlists to add that fit into <a href=\"https://en.wikipedia.org/wiki/Life_skills#Core_skills\">core life skills</a>!</p>\n", "user": {"username": "Stenemo"}}, {"_id": "ptenEA2B52s9Q5zBt", "title": "Consequentialism as an experimental  discipline", "postedAt": "2022-11-29T06:07:06.974Z", "htmlBody": "<p><br>Consequentialism has been criticized from a variety of directions. It is argued that it ignores some basic human values or reduces them to an equation. Recently, there have been criticisms of consequentialism as applied in the Effective Altruism movement. One point, for example, if that the focus of a consequentialist morality on a particular value X means that what is X is deemphasized.</p><p>The criticisms of consequentialism may be misplaced. One way of addressing them is to step back and completely rethink the discipline of ethics as a whole. Seen in the larger context, consequentialism can be seen not as a style or variety of ethics - instead, it is a mode of doing ethical study.</p><p>Consider an intellectual pursuit such as physics. Most sciences can be split into theoretical and experimental parts. Physics begins and ends with experiment and observation. In between, there is theory. Initially, we observe the world and see regularities. These observations are conceptually abstracted and generalized to come up with a theory. The theory is then put to the test by experiment.</p><p>There is also the distinction between science and its applications. Physics is the study of the laws of nature in and of themselves. Engineering is the application of this science. Experimental physics is not at all like engineering. Physics experiments are done to validate or invalidate a theoretical hypothesis. Once these principles are validated, they can be turned into engineering practice.</p><p>This division could be useful in ethics also. Typically, ethics is considered to have three equal approaches: consequentialism, deontology and virtue ethics. I am going to argue instead that the study of ethics is composed of a theoretical discipline and an experimental/observational discipline.</p><p>Using physics as an analogy, consequentialism, starting from Bentham's Utilitarianism on to the present, can be considered a form of experimental ethics. The claim is as follows: even if consequentialism is considered as a theory, the analysis of the consequences of human actions are so complicated that it is unlikely that a workable consequestialist theory can be made without looking at real-world examples. It is possible to approximate a consequentialist theory with gendankenexperiments, but to get a real reading on the worth of a consequentialist ethics requires the analysis of real events and experiences.</p><p>Consequentialism requires a theoretical underpinning starting from the simple hedonistic act consequentialism to even more examples of sophisticated ethical structures. Simply put, a general theory of consequentialism requires some theoretical statement of preconditions, possible ways to act and possible consequences. Although it is possible to consider these definitions as part of a consequentialist approach, they can just as well be separated out as a theoretical prerequisite to consequentialism.</p><p>For example, for a system of ethics to be based on the consequences of actions in terms of their pleasure or pain, there needs to be a definition of the criterion of what pleasure and pain are. The specification of such a definition is in the realm of theory. This viewpoint splits the attempt to define the nature of the desired consequences from the practice of studying the effects of applying these definitions.</p><p>In this viewpoint, Rawl's Theory of Justice is not truly an alternative to consequentialism. Instead, it is consequentialism with a different metric.</p><p>Other branches of ethics are often considered to be virtue ethics and deontology. Generally speaking, virtue ethics considers ethics in terms of goals, and deontology considers ethics in terms of actions. Using a simple functional notation for human actions, all human actions can be considered in terms of this dichotomy. To continue the analogy of physics, there are some basic elements that make up physics as a study of the real world: the objects in the world and the way that these objects interact.</p><p>In this approach, we will use the general notion of \"eudaimonia\" to refer to the desired goal of consequentialism. This is an overarching concept in ethics that is implicit in almost all theories of ethics in one form or another.</p><p>These branches of ethics tend to be theoretical in nature. They help define concepts, but the usefulness (\"utility\"?) of these concepts can only be tested in practice. So virtue ethics defines the goals and deontology defines the way to achieve them. Given these definitions, a consequentialist model is constructed and put to the test in a controlled environment or statistical observations in the real world. This leads back to a correction in the theory.</p><p>Some of the criticisms of different ethical systems are due a lack of differentiation between theory and experiment. Consequentialism is criticized because it has incorrect or incomplete definitions of the components that make up a consequentialist ethics. On the other hand, virtue ethics and deontology are often criticized in term of their efficacy and their correspondence to reality. Many of these criticisms can be resolved by restating the relationship between the branches of ethics as a separation between theory and experiment and a further separation of the theory into different epistemological components of ethics.</p><p>A final distinction should be made between experimental ethics and the practice of ethics. To continue the analogy to physics, this is the difference between experimental physics and engineering. Ethics contains this same distinction in that there is a whole field of applied ethics that takes the knowledge from the theoretical and experimental approaches and translates these results into regular living. Effective altruism is not consequentialism itself, taken as a series of experiments. Instead, it should properly be established to put into practice only the consequentialist system that has proven itself under controlled conditions.</p><p>So now we have the following structure to the study and practice of ethics:<br>Virtue Ethics defines the desired outcomes - it is part of the theory of ethics<br>Deontology defines the acceptable processes - it is part of the theory of ethics<br>Eudaimonia defines the acceptance criteria - it is part of the theory of ethics<br>Consequentialism is experimental ethics - it depends on the theory<br>Applied Ethics is engineering - it depends on the previous fields</p><p>So it is irrelevant whether you claim to practice virtue ethics, deontology or consequentialism. You do all three. What matters are your virtues, how you put them into practice and what the consequences are.</p>", "user": {"username": "vandermude"}}, {"_id": "9kNCuSRvcu6BGXB9H", "title": "Why I gave AUD$12,573 to Innovations For Poverty Action", "postedAt": "2022-11-29T00:56:20.347Z", "htmlBody": "<p>I <a href=\"https://henryach.com/workathon/\">gave</a> 50% of my 1st-year doctor's salary to charity last year. This was mostly to GiveWell-recommended and The Life You Can Save-recommended charities. The largest share went to <a href=\"https://en.wikipedia.org/wiki/Innovations_for_Poverty_Action\"><i>Innovations For Poverty Action</i></a>, a global development research organisation that designs and runs trials of global development interventions around the world in order to find which interventions are effective.</p><p>&nbsp;</p><h2>We need more global development cause discovery</h2><p>The main reason I favoured <i>Innovations For Poverty Action</i> is my feeling that the slow rate of discovery of new effective charities is a bottleneck for effective altruism. From what I can see, <i>GiveWell</i> has added one charity to its top recommendations in recent years (<i>New Incentives</i>) while it's entirely removed its list of about 10 \"standout charities\". I haven't noticed many new additions to The Life You Can Save's list of recommended charities in recent years. <i>GiveWell</i> <a href=\"https://blog.givewell.org/2021/11/22/we-aim-to-cost-effectively-direct-around-1-billion-annually-by-2025/\">maxxed out the funding of its top charities last year</a> and, while they claim<a href=\"https://blog.givewell.org/2022/07/05/update-on-givewells-funding-projections/\"> they now have room for hundreds of millions more dollars</a>, this is still a drop in the pond when compared to the total amount of philanthropy and government aid money that is spent annually worldwide. Finding further effective global development causes should be top priority, so that governments and philanthropists can be advised to direct their funds more effectively.</p><p>&nbsp;</p><h2>They probably know more than us</h2><p>Effective altruists do a lot of independent research looking at effective ways to make the world better. This is great. An example is the recent <i>Open Philanthropy</i> <a href=\"https://forum.effectivealtruism.org/posts/XBHx9zhAtkiBJnZNu/cause-exploration-prizes-announcing-our-prizes-1\">cause exploration prize</a>. Most effective altruism enthusiasts aren't Nobel prize-winning economists nor do they have decades of experience in global development nor do they have extensive global networks to feed them information. This all probably puts the average effective giving enthusiast at a disadvantage when it comes to seeing and seizing on global development opportunities. When it comes to effective cause discovery I think it would be difficult for anyone to outperform established global development research organisations like <i>Innovations for Poverty Action</i>, &nbsp;<i>The </i><a href=\"https://en.wikipedia.org/wiki/Abdul_Latif_Jameel_Poverty_Action_Lab\"><i>Jameel Poverty Action Lab</i></a>, and the <a href=\"https://en.wikipedia.org/wiki/Center_for_Effective_Global_Action\"><i>Center for Effective Global Action</i></a>, each of which have established networks, experience, and track records.</p><p>&nbsp;</p><h2>They have a good record</h2><p><i>Innovations for Poverty Action</i> has conducted research showing that <a href=\"http://poverty-action.org/impact/free-malaria-bednets\">giving free bednets is more effective than charging for them</a>, they conducted<a href=\"http://poverty-action.org/impact/chlorine-dispensers-safe-water\"> the research</a> that led to <a href=\"https://www.evidenceaction.org/dispensersforsafewater/\">Evidence Action's Dispensers for Safe Water </a>program, they conducted the research around <a href=\"https://www.evidenceaction.org/beta-no-lean-season/\">No Lean Season</a> that <a href=\"http://poverty-action.org/impact/reducing-seasonal-hunger-with-small-incentives-migrate\">first appeared to yield promising results but at scale was less promising</a> (negative results are important too). They were recently involved in a promising trial of <a href=\"https://www.poverty-action.org/study/impact-cognitive-behavior-therapy-and-cash-transfers-high-risk-young-men-liberia\">cash-transfers and cognitive behavioural therapy to reduce crime among at-risk young men in Liberia</a>.</p><p>&nbsp;</p><h2>You can give to them tax-deductably in Australia</h2><p>I've considered giving to<i> The Jameel Poverty Action Lab</i> or another global development research organisation. In Australia you can give to Innovations For Poverty Action via The Life You Can Save and the donation is tax-deductable. I don't know of a way to give to other global development research organisations tax-deductably from down here.</p>", "user": {"username": "Henry Howard"}}, {"_id": "b3BB5vQXrAyXQqddb", "title": "BBC news article on Jeff Bezos, Sam Bankman-Fried, and EA", "postedAt": "2022-11-28T22:56:31.169Z", "htmlBody": "<p>The following BBC news article was the first result for me on the 28th November, in the UK, when I typed 'world news' into Google.</p>\n<p>Quotes that mention Sam Bankman Fried and EA:</p>\n<p>The American bitcoin wunderkind Sam Bankman-Fried was one of the leading lights in a new philanthropy movement known as \"Effective Altruism\" (EA).</p>\n<p>Instead of toiling away for a charity, supporters of EA favour making pots of money in finance and tech instead, and then giving it away to charity. But the 30-year-old Bankman-Fried's cryptocurrency exchange, FTX, went bankrupt earlier this month.</p>\n<p>Overnight, his riches vanished - he had been worth $10.5bn (\u00a38.68bn) on paper, or rather, in evanescent digital code. As for his creditors, far from congratulating themselves on the effectiveness of their altruism, they are now out of pocket by as much as $8bn.</p>\n<p><a href=\"https://www.bbc.com/news/world-us-canada-63715064.amp\">https://www.bbc.com/news/world-us-canada-63715064.amp</a></p>\n", "user": {"username": "Matt g"}}, {"_id": "7iTfePcgswTivy2zo", "title": "Organized Cause Evaluation", "postedAt": "2022-11-28T20:31:59.124Z", "htmlBody": "<p>Suppose I have a cause I\u2019m passionate about. For example, we\u2019ll use fluoridated water. It\u2019s poison. It lowers IQs. Changing this one thing is easy (just stop purposefully doing it) and has negative cost (it costs money to fluoridate water; stopping saves money) and huge benefits. That gives it a better cost to benefit ratio than any of EA\u2019s current causes. I come to EA and suggest that fluoridated water should be the highest priority.\n<em>Is there any <strong>organized</strong> process by which EA can evaluate these claims, compare them to other causes, and reach a rational conclusion about resource allocation to this cause?</em> I fear there isn\u2019t.</p>\n<p>Do I just try to write some posts rallying people to the cause? And then maybe I\u2019m right but bad at rallying people. Or maybe I\u2019m wrong but good at rallying people. Or maybe I\u2019m right and pretty good at rallying people, but someone else with a somewhat worse cause is somewhat better at rallying. I\u2019m concerned that my ability to rally people to my cause is largely independent of the truth of my cause. <strong>Marketing isn\u2019t truth seeking.</strong> Energy to keep writing more about the issue, when I already made points (that are compelling if true, and which no one has given a refutation of), is different than truth seeking.</p>\n<p>Is there any reasonable on-boarding process to guide me to know how to get my cause taken seriously with specific, actionable steps? I don\u2019t think so.</p>\n<p>Is there any list of all evaluated causes, their importance, and the reasons? With ways to update the list based on new arguments or information, and ways to add new causes to the list? I don\u2019t think so. How can I even know how important my cause is compared to others? There\u2019s no reasonable, guided process that EA offers to let me figure that out.</p>\n<p>Comparing causes often depends on some controversial ideas, so a good list would take that into account and give alternative cause evaluations based on different premises, or at least clearly specify the controversial premises it uses. Ways those premises can be productively <a href=\"https://forum.effectivealtruism.org/posts/37byNFAMEfbLNPXdm/debate-with-rational-methodology\">debated</a> are also important.</p>\n<p>Note: I\u2019m primarily interested in processes which are available to anyone (you don\u2019t have to be famous or popular first, or have certain credentials given to you be a high status authority) and which can be done in one\u2019s free time without having to get an EA-related job. (Let\u2019s suppose I have 20 hours a week available to volunteer for working on this stuff, but I don\u2019t want to change careers. I think that should be good enough.) Being popular, having credentials, or working at a specific job are all separate issues from being correct.</p>\n<p>Also, based on a forum search, stopping water fluoridation has never been proposed as an EA cause, so hopefully it\u2019s a fairly neutral example. But this appears to indicate a failure to do a broad, organized survey of possible causes before spending millions of dollars on some current causes, which seems bad. (It could also be related to the lack of any way good way to search EA-related information that isn\u2019t on the forum.)</p>\n<p>Do others think these meta issues about EA\u2019s organization (or lack thereof) are important? If not, why? Isn\u2019t it risky and inefficient to lack well-designed processes for doing commonly-needed, important tasks? If you just have a bunch of people doing things their own way, and then a bunch of other people reaching their own evaluations of the subset of information they looked at, that is going to result in a social hierarchy determining outcomes.</p>\n", "user": {"username": "Elliot Temple"}}, {"_id": "Whztt59kSTrnRwawu", "title": "Proposed: donation mechanism for people doing direct work (USA tax relevant)", "postedAt": "2022-11-28T20:06:40.499Z", "htmlBody": "<p><i>Upgrading and updating </i><a href=\"https://forum.effectivealtruism.org/posts/fFDM9RNckMC6ndtYZ/david_reinstein-s-shortform?commentId=9KWnChmkstpag9gxh\"><i>this short-form</i></a><br><br><strong>Preamble</strong></p><p>Employees at EA orgs and people doing direct work are often also donors/pledgers to other causes. But charitable donations are not always exactly 1-1 deductible from income taxes.&nbsp; E.g., in the USA it\u2019s only deductible if you forgo the standard deduction and \u2018itemize your deductions\u2019, and in many countries in the EU there is very limited tax deductibility.</p><p>So, if you are paid $1 more by your employer/funded and donate it to the Humane League, Malaria Consortium, etc, the charity only ends up with maybe $0.65 on the margin in many cases. There are ways to do better at this (set up a DAF, bunch your donations\u2026) but they are&nbsp;costly (DAF takes fees) and imperfect (whenever you itemize you lose the standard deduction if I understand.)<br><br>This might be somewhat timely because of (1) loss of funds from FTX thing (2) EA employees feeling guilty if they think they benefited from the FTX thing.</p><h1><strong>Proposal</strong></h1><p>Funders/orgs (e..g, Open Phil, RP, FHI, CEA) could agree that employees are allowed relinquish some share of their paycheck into some sort of general fund. The employees who do so are allowed to determine the use of these funds&nbsp; (or \u2018advise on\u2019, with the advice generally followed). I think this should generally <i>not </i>go back to the org they work for itself, for reasons alluded to below.&nbsp;</p><p>&nbsp;</p><h1><strong>Key anticipated concerns, responses</strong></h1><h2><strong><u>Concern: pressure</u></strong></h2><p>This will lead to a \u2018pressure to donate/relinquish\u2019 if the employers, managers, funders are aware of it.</p><p><strong>Response</strong>: This process could be managed by ops and by someone at arms-length who will not share the data with the employers/managers/funders. (Details need working out, obviously, unless something like this already exists.)<br><br>This is also a reason to make this explicitly <i>not</i> go back to the employing organization.</p><p>&nbsp;</p><h2><strong><u>Concern - Legal issues</u></strong></h2><p><strong>&nbsp;</strong>Is this feasible? Would these relinquishments be seen by governments as actually income?</p><p><strong>Response: </strong>I've consulted a one person with expertise who suggest this would not be a problem as long as<br><br>- It is clearly a salary <i>reduction</i>&nbsp;<br>- The promise (to target the cause the employee wants) is only <i>implicit</i>; the employer/organization has the ultimate control;&nbsp;<br>&nbsp; &nbsp; &nbsp;- This is something like the situation with a donor advised fund (DAF) if I understand it<br><br>Note, 'it is pretty normal' for one nonprofit to pass money to another nonprofit.&nbsp;<br>&nbsp;</p><h2><strong><u>Concern - crowding out</u></strong></h2><p><strong>&nbsp;</strong>If the funder knows that the people/orgs it funds give back to other charities, they may shift their funding away from these charities, nullifying the employee's counterfactual impact.</p><p><strong>Response</strong>:&nbsp; This is hardly a new issue, hardly unique to this context; it\u2019s a major question for donors in general, through all modes; so maybe not so important to consider here.</p><p>\u2026 To the extent it is important, it could be reduced if we can keep the exact <i>target and amount</i> of the donations unknown to the funders.</p><p>&nbsp;</p><h2><strong><u>Concern - \u201cOrg reputation \u2026 why not give back to the org?\u201d</u></strong></h2><p>Maybe a stretch, but I could imagine someone arguing \u201cIf EA-ORG's&nbsp; employees ask you to redirect paychecks to a fund, which largely goes to the Humane League, Malaria Consortium, \u2026 does this indicate EA-ORG's employees don\u2019t think EA-ORG is the best use of funds\u201d?</p><p><strong>Response 1</strong>: Unlikely to be a concern. Employees may want to \u2018hedge their bets\u2019 because of moral uncertainty, and because of the good feeling they get from direct impact of donations.</p><p><strong>Response 2</strong>: Keep the recipient of these funds hidden to outsiders.</p><p>&nbsp;</p><p><i>Thoughts? Do you think many people would take this up? What am I overlooking here?</i></p>", "user": {"username": "david_reinstein"}}, {"_id": "kAqimST9gttzkfpFP", "title": "How to: Choosing the right PhD supervisor", "postedAt": "2022-11-29T05:58:14.169Z", "htmlBody": "<p>This is advice we've collected for students who have decided that a PhD is the right path for them, are aiming to do impactful research and seeking an academic supervisor.</p><p>More info on who this post is for: This is general advice that we hope will be helpful for finding a PhD supervisor in contexts in which it's appropriate to contact potential supervisors before making a formal application. <i>In some disciplines and departments, reaching out independently isn't the norm and might be actively discouraged or prohibited.&nbsp;</i></p><p>We hope to write more specific advice in future, however if you're unsure whether this advice is relevant to you, you could check by: asking people in the relevant discipline and country what the norms are, checking for application guidelines from the relevant supervisor or course, or reaching out to a course administrator.</p><p>This post does not cover whether or not you should be doing a PhD. If you\u2019re unsure whether to pursue a PhD, you might find useful advice in our post on <a href=\"https://effectivethesis.org/testing-fit-for-research/\">testing your fit for a research career</a> instead. You could also <a href=\"https://effectivethesis.org/thesis-coaching/\">apply for our coaching</a> for more personalised advice.&nbsp;</p><p>We're grateful for any feedback on this advice or on our other activities \u2013 we\u2019ll look forward to your comments!</p><h1>Key points:</h1><ul><li>The supervisor-supervisee relationship will probably have a big impact on your experience of getting a PhD, your development, and your prospects after your PhD. Your supervisor will likely be your primary mentor for several years, so it\u2019s worth investing time in finding a good match.</li><li>You could find a supervisor through reading academic papers, being on academic twitter, looking at university faculty webpages, talking to students and academics, networking at conferences or via our&nbsp;<a href=\"https://effectivethesis.org/potential-supervisors/\"><u>database of potential supervisors</u>.</a></li><li>Key factors to consider when finding a supervisor include their research expertise, supervision style and academic reputation. Also consider the &nbsp;departmental/lab community you would be joining.</li><li>As well as meeting potential supervisors, speaking to students who have worked with your potential supervisor is particularly important for deciding whether they\u2019d be a good fit for you and support your development. Doing a short project with a prospective supervisor if possible will likely also be particularly informative.</li></ul><p>We\u2019re sharing this advice because:</p><ul><li>We want to support impact-oriented students, who have decided a PhD is the right path for them, to make good decisions when finding a supervisor.</li><li>We\u2019d like to hear about people\u2019s experiences and tips for finding and working with supervisors (and academics\u2019 experiences of supervising students!). If you want to suggest changes or additions to this advice, please comment here (or on <a href=\"https://docs.google.com/document/d/1HMg4oN6o0arfZbGVUSIObLZIbuM0AevW0C3vJCKRa4Y/edit?usp=sharing\">this google doc</a>) or reach out to us (at sophie.kirkham@effectivethesis.org).</li></ul><p>How we wrote this piece:</p><ul><li>Multiple members of the Effective Thesis team helped write this advice, primarily Sophie Kirkham, David Janku, Vorathep (Dev) Sachdev and Silvana Hultsch.</li><li>In the process of writing this advice we received feedback from a number of people based on their PhD experiences; thanks to Caspar Oesterheld, Matt Coleman, Vivian Belenky, Bill Wildi, Linda Linsefors,&nbsp;Adri\u00e0 Garriga-Alonso and Jaime Sevilla for their valuable feedback and ideas. Contributors to this post didn\u2019t necessarily review or agree with all points made, and all errors remain our own.<br>&nbsp;</li></ul><h1>How important is finding the right PhD supervisor?</h1><p>Your supervisor will likely be your main point of contact for academic support during your PhD. The quality of your relationship and your supervisor's availability, style of supervision and alignment with your goals will probably make a big difference to your experience \u2013 in terms of your wellbeing, whether you\u2019re supported to do the research you want, and even whether you complete your PhD.</p><p>Your supervisor\u2019s research skills will likely also affect your own development as a researcher.&nbsp;<a href=\"https://www.pnas.org/doi/pdf/10.1073/pnas.1915516117\">This paper</a> (<a href=\"https://insight.kellogg.northwestern.edu/article/great-mentorship-research\"><u>see the summary here</u></a>) finds that supervisors who produce prize-winning academic research seem to increase the chance their supervisees go on to do the same; \u2018students who studied under a future prizewinner were almost six times more likely to become superstars in their field than equally talented students of non-prizewinners.\u2019<br>&nbsp;</p><h1>When should you search for a supervisor?</h1><p>Universities often expect that students will identify and connect with a specific supervisor before formally applying for a PhD. Even if you're applying to a programme that involves spending a year or two doing classes before choosing a research focus and supervisor, it's still useful to reach out to check if the supervisor(s) on the programme seem like a good fit for you. Anecdotally, your application is also more likely to be accepted if a supervisor is already excited about working with you.&nbsp;</p><p>Before you reach out, check there's no rule against reaching out written on the supervisor's profile or programme webpage, as some universities and programmes have a rule against students contacting supervisors before formally applying.</p><p>There are many guides online if you want to see the steps typically involved in finding a PhD programme in different countries, for example&nbsp;<a href=\"https://www.findaphd.com/advice/finding/phd-application-step-by-step-checklist.aspx\">this</a> and&nbsp;<a href=\"https://www.postgrad.com/study-in-uk/phd-in-uk/\">this</a> overview for the UK,&nbsp;<a href=\"https://www.postgrad.com/study-in-usa/phd-in-usa/\">this</a> guide for the USA or&nbsp;<a href=\"https://www.findaphd.com/study-abroad/\">this series</a> about PhD study in various countries.<br>&nbsp;</p><h1>Factors to consider when searching for a supervisor</h1><p>In addition to considerations like location and funding availability, here are some key factors that might be useful to gather information on during the process of finding a supervisor.</p><h2>The supervisor\u2019s research expertise</h2><p>Working with a supervisor and research group with particularly strong research skills and a strong track record is very helpful if you want to stay in research long term (if you\u2019re pursuing a PhD primarily for credentials, it is likely not quite such an important factor). Looking at the&nbsp;<a href=\"https://en.wikipedia.org/wiki/H-index\"><i><u>h</u></i><u>-index</u></a> of supervisors you\u2019re considering, reading research papers yourself and considering the opinions of other academics are some ways of getting a general sense of this.&nbsp;</p><p>In terms of specific expertise, while it\u2019s certainly helpful if your supervisor or research group has a good understanding of the topic or concept you want to study, strong expertise in a methodology you want to master may be more important to your development as a researcher, as long as they are receptive to your topic. Having a secondary supervisor with strong expertise in the specific topic or concept you want to study, as well as a primary supervisor with expertise in the methodology you want to use, can be a good way to balance this, although programmes and supervisors will have different policies on this.</p><p>Researchers and research teams will also have their own ideologies that you will likely need to adopt to some extent in your own research, so look at some of their research and check if the approach resonates with you when deciding if they would be a good fit.</p><h2>The supervisor\u2019s and university\u2019s academic reputation</h2><p>Particularly if you want to pursue an academic career, a supervisor\u2019s academic reputation and research success is also worth considering because the reputation of your supervisor will affect how a letter of recommendation from them is received if you apply for academic or postdoc positions after your PhD. For careers outside of academia, such as policy and public-facing roles, having attended a top university is also particularly likely to be useful.</p><h2>Style of supervision</h2><p>Consider what style of supervision would work well for you \u2013 how independently or intensively do you want to work, for example? When talking to a potential supervisor or students who have worked with them, you might want to ask about the supervisor\u2019s interpersonal style, what their expectations are of students, and how \u2018hands on\u2019 or \u2018hands off\u2019 they are (<a href=\"https://www.alextamkin.com/essays/hands-on\">this post</a> goes into more detail about the different dimensions you could consider regarding the latter point).</p><p>You can make some guesses about these factors before meeting potential supervisors or students. For example, if an academic is earlier in their career,&nbsp;<a href=\"https://www.newscientist.com/article/mg19726442-500-the-phd-journey-how-to-choose-a-good-supervisor/\">their progression will depend on supervising students</a>, so there\u2019s generally a greater incentive for them to be more engaged as a supervisor and to graduate students quickly. More established academics often have wider research interests and allow supervisees more autonomy and flexibility.</p><p>As well as the style of support that will suit you in the near-term, consider what will help you achieve your long-term goals. Particularly if you may want a career in research, it\u2019s useful to have a supervisor who will encourage you to publish, so you could check whether they have a track record of publishing with students and whether the papers are published in respected journals.&nbsp;If you\u2019re largely doing a PhD because the credentials will further your career, you may generally want to seek out less time-intensive and challenging PhD experience.</p><h2>Your impression of the departmental or laboratory community</h2><p>The research community you join will likely also affect your wellbeing and development as a researcher. If you\u2019re in a collaborative setting, postdocs and more experienced PhDs may play a key role in providing informal supervision, which might be particularly relevant if you want to work with a supervisor who has limited availability.</p><p>If you\u2019re seriously considering a PhD programme, try to talk to students and postdocs you\u2019d be working with to get a sense of the culture you\u2019d be joining.&nbsp;You could also look at alumni\u2019s careers, the research of current students and the ranking of the university to try to gauge how the environment would help you develop as a researcher. If you want to learn more about university rankings and what aspects of them are relevant to PhD students,&nbsp;<a href=\"https://www.findaphd.com/advice/finding/phd-rankings.aspx\">check out this article</a> from findaphd and see the&nbsp;<a href=\"https://www.timeshighereducation.com/world-university-rankings/2022/world-ranking#!/page/0/length/25/sort_by/rank/sort_order/asc/cols/stats\">Times world university rankings</a> and&nbsp;<a href=\"https://www.topuniversities.com/university-rankings/world-university-rankings/2022\">QS World University Rankings</a>.<br>&nbsp;</p><h1>Finding potential supervisors</h1><h2>Where to look</h2><p>If you\u2019re looking for a potential supervisor, you may find it helpful to:</p><ul><li>apply to access our&nbsp;<a href=\"https://effectivethesis.org/potential-supervisors/\">database of potential supervisors</a> working in the&nbsp;<a href=\"https://effectivethesis.org/theses/\"><u>research directions we recommend</u></a>.</li><li>network at conferences and lectures.</li><li>look through the department faculty webpages of universities that meet your location preferences and/or that are the top universities for your research area.</li><li>ask PhD students and academics working in your preferred research direction for recommendations. Professors at your university may be willing to leverage their own network to help you, and academics involved in EA may also be willing to help.</li><li>read the abstracts of research articles, papers, and recently submitted dissertations relevant to your interests and note down the authors whose work you particularly like. This step can also be useful to increase the chance of a successful application later.</li><li>follow academics doing relevant research on \u2018academic twitter\u2019 (i.e. the informal network of academics who use twitter to discuss research, opportunities and experiences). This can be useful for seeing recent papers and discussions, learning about open PhD positions, and getting some insight into potential supervisors.</li><li>do a database search to find researchers who have produced highly cited and relevant publications. Options include&nbsp;<a href=\"https://clarivate.com/webofsciencegroup/solutions/web-of-science/\"><u>Web of Science</u></a>,&nbsp;<a href=\"https://www.scopus.com/home.uri\"><u>Scopus</u></a>,&nbsp;<a href=\"https://www.dimensions.ai/\"><u>Dimensions</u></a>,&nbsp;<a href=\"https://www.semanticscholar.org/\"><u>Semantic Scholar</u></a> and&nbsp;<a href=\"https://www.researchrabbit.ai/\"><u>Research Rabbit</u></a>. You could also use&nbsp;<a href=\"https://elicit.org/\"><u>Elicit</u></a>, an AI research assistant.&nbsp;</li><li>join our online&nbsp;<a href=\"https://effectivethesis.org/community/\"><u>community</u></a> and ask for advice there, or explore other student forums.</li></ul><p>When you find a potential supervisor you\u2019re interested in, check whether they are accepting students during the upcoming application cycle before investing more effort. Consider keeping a spreadsheet of the programmes and supervisors you\u2019re interested in, with relevant factors (e.g. location, research fit and funding) to help you narrow options down. When you start reaching out to supervisors, this will also help you follow up 1-2 weeks later if you have a record of who you contacted, as well as keeping track of application deadlines. (If you do this, we\u2019d love to see the results! Please send them to sophie.kirkham@effectivethesis.org).<br>&nbsp;</p><h1>Contacting potential supervisors</h1><h2>Writing an initial email</h2><p>Below are some tips for reaching out to potential supervisors.</p><p><strong>Do your research</strong></p><p>Before you contact supervisors, check whether their university profile has relevant information about their availability or details about whether and how they want to be contacted. Assistant and associate professors are particularly likely to be seeking students. If their profile doesn\u2019t say they are seeking students, check this with them briefly before sending a longer email.</p><p><strong>Be concise</strong></p><p>Academics get a lot of emails, so make your email easy to engage with.</p><ul><li>Use a subject line that makes it clear why you\u2019re reaching out (e.g. \u2018initial enquiry about PhD opportunities for Sept 2021\u2019)</li><li>Keep it short -\u2013 a couple of paragraphs is usually enough.</li><li>Ask a clear question at the beginning of the email after introducing yourself, so the supervisor knows what to respond to.</li></ul><p><strong>Briefly but clearly describe your goals</strong></p><p>Explain the research question you want to answer, why you believe it\u2019s important, and, if possible, how your previous research connects to it and how it would fit into the broader picture of your goals. You\u2019ll stand out more if you\u2019re sincerely trying to answer an open research question in your field. However, if there\u2019s some flexibility in your interests then mention this too \u2013 it might increase the likelihood the supervisor will be open to working with you.</p><p><strong>Be informative</strong></p><p>You should generally also include:</p><ul><li>your qualifications.</li><li>that you\u2019re emailing regarding a specific opportunity if this is the case.</li><li>your funding status, for example if you\u2019ve already secured external funding or are planning to apply for funding.</li><li>the country you\u2019re currently in.</li></ul><p><strong>Build connection</strong></p><ul><li>Check the supervisor\u2019s title (e.g. Professor/Dr) and use it in the first email (after that it\u2019s fine to follow their lead).</li><li>Say if you were referred by a current/former student, saw them give a talk or have read their research.</li><li>Explain why you are interested in working with them (and ideally how their recent research connects to your topic).</li><li>Offer to schedule a call if the supervisor wants to discuss things further (or ask if they\u2019re open to a call if you want to meet with them). Use a tool such as Calendly to make scheduling easier.</li><li>Thank them for their time at the end of your email.</li></ul><p><strong>If you don\u2019t hear back</strong></p><p>We suggest sending a check-in email 1-2 weeks later, and then it\u2019s best to move on. Not hearing back doesn\u2019t mean you got anything wrong \u2013 academics usually get more emails than they can keep on top of.<br>&nbsp;</p><h1>Meeting potential supervisors</h1><p>If you arrange a meeting with a potential supervisor, you could ask them if they want to see your research proposal (if relevant) prior to the meeting (this will also give you the chance to ask for feedback during the meeting).</p><p>Potentially useful topics to discuss include:</p><ul><li>their style of supervising students. For example:<ul><li>how much contact they have with students they supervise.</li><li>how much collaboration occurs between their supervisees.</li><li>what they expect from the students they supervise (e.g. is there a certain number of papers students need to publish? What work hours do they expect?).</li><li>the extent to which they let students choose topics themselves.</li></ul></li><li>what characteristics they consider important in supervisees.</li><li>your knowledge of your own working style and goals, and whether they feel you would be a good fit for each other.</li><li>what topics they would be most excited to have a PhD working on, to give you the opportunity to better tailor your formal application to these interests if they overlap with yours.</li><li>whether they have suggestions of things you should do to supplement your PhD or whether there are professional development opportunities they encourage.</li><li>whether they have feedback on your proposal, if they saw this before meeting.</li><li>whether having a secondary/external supervisor is something they would potentially be supportive of, if secondary supervision is something you think you will need.</li><li>if there might be funding available from them, or whether you will need to seek external funding (and any sources they recommend).</li><li>whether they\u2019re intending to stay at the university for several years (e.g. whether they have a sabbatical planned) and what would happen if they moved institutions during your PhD.</li><li>whether they can connect you with some of their current PhD students.</li><li>whether there is a project you could work on with them as a way of testing fit. This can provide particularly strong evidence of your ability, as it enables the supervisor to observe your work directly, and it gives you additional opportunities to learn more about whether the supervisor and broader environment would be a good fit for you.<br>&nbsp;</li></ul><h1>Experiences of other students</h1><p>If you\u2019re seriously considering a particular supervisor/lab, we suggest contacting some current or former students to ask them about their experiences (you might find students\u2019 names on the lab\u2019s, department\u2019s or supervisor\u2019s webpage). Although meeting with supervisors can be very useful, we suggest giving more weight to students\u2019 experiences of what it is like to be a researcher in the lab or to be supervised by the academic you are considering.<br><br>Potentially useful topics include:</p><ul><li>the supervisor\u2019s interpersonal style.</li><li>how available the supervisor is and what kind of support they offer.</li><li>the work culture (e.g. how collaborative it is).</li><li>how much autonomy students have in deciding what to work on.</li><li>expectations of students, for example regarding work hours.</li><li>whether there\u2019s anything they wish they had known before starting.<br>&nbsp;</li></ul><h1>Finding a secondary supervisor</h1><p>Much of the advice above will be applicable to a search for either a primary or secondary supervisor. If you find a researcher who seems like a great fit as your supervisor but can\u2019t be a primary supervisor, take note \u2013 they may be willing to be a secondary supervisor if you need one, or collaborate with you at some stage of your PhD.</p><p>If you feel support from a secondary supervisor is necessary, discuss this with your primary supervisor first, to check they are supportive in principle.</p><p>Finding a secondary supervisor can be particularly helpful if:</p><ul><li>there\u2019s some aspect of your topic or approach with which your supervisor or research group isn\u2019t very familiar or aligned (which is more likely if you\u2019re working on a topic that is relatively neglected).</li><li>you intend to work on an interdisciplinary topic and having a secondary supervisor from a different disciplinary background would be useful.</li><li>you want your research to be valuable for a research institution such as a think tank, and want someone from that institution as an advisor.</li></ul><p>Some suggestions for finding secondary supervision or mentorship are:</p><ul><li>applying for our&nbsp;<a href=\"https://effectivethesis.org/thesis-coaching/\">coaching</a>, so we can connect you with relevant researchers.</li><li>reaching out to academics in our&nbsp;<a href=\"https://effectivethesis.org/potential-supervisors/\">list of potential supervisors</a>.</li><li>reaching out to an organisation doing work you find interesting, to ask if they would be open to a research collaboration with you.<br>&nbsp;</li></ul><h1>Finding further advice</h1><p>We think it\u2019s valuable to seek out additional advice tailored to your situation (e.g. that\u2019s specific to your location, discipline and the research direction you\u2019re interested in).</p><p>Here are a few ways to get further advice:</p><ul><li>Apply to our&nbsp;<a href=\"https://effectivethesis.org/thesis-coaching/\">coaching</a> and we\u2019ll help you reflect on your plans and connect you with experienced researchers who can advise you further.</li><li>Apply to our&nbsp;<a href=\"https://effectivethesis.org/community/\">online community</a> of students. We can also introduce you to students we think you\u2019re particularly likely to find helpful to talk to.</li><li>Email people who are where you would like to be in a few years in their careers, and ask if they are willing to talk to you. We think most people don\u2019t reach out to others enough for this kind of advice, but many people are happy to share their experiences. Check out&nbsp;<a href=\"https://clearerthinkingpodcast.com/episode/077?time=24m50s\">this Clearer Thinking podcast episode</a> for a brief discussion of how to increase the value of these conversations.</li><li>Reach out to academics or organisations in the EA ecosystem \u2013 several organisations in EA have services specifically aimed at supporting aspiring researchers.<br>&nbsp;</li></ul><p><i>Good luck with your search!&nbsp;</i></p><p>We\u2019d like to hear about people\u2019s experiences and tips for finding and working with supervisors (and academics\u2019 experiences of supervising students!). If you want to suggest changes or additions to this advice, please comment or reach out to us at&nbsp;<u>sophie.kirkham@effectivethesis.org</u>. Thanks!</p><p><br><br>&nbsp;</p>", "user": {"username": "Effective Thesis"}}, {"_id": "cJCJwv9o95cZsG73u", "title": "Effective Giving Day 2022 is live", "postedAt": "2022-11-28T19:22:31.560Z", "htmlBody": "<p>Watch the live stream here, or catch up later:</p><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=OISn7ypXKdA\"><div><iframe src=\"https://www.youtube.com/embed/OISn7ypXKdA\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure>", "user": {"username": "Luke Freeman"}}, {"_id": "n9h6RAPLMoFbf66Pi", "title": "How have your views on where to give updated over the past year?", "postedAt": "2022-11-28T19:01:30.416Z", "htmlBody": "<p>I'm wondering if your views on where to give have meaningfully changed throughout 2022.</p><p>If they have, please share! I'd love to hear why.</p><p>Personally, I'd say my biggest update has been towards giving opportunities that are more speculative but potentially higher EV. My giving portfolio in the past was heavily tilted towards GiveWell, primarily because of their demonstrated track record and the strong evidence behind their top charities.</p><p>But now, I'm increasingly feeling comfortable with shifting my portfolio more towards other speculative options.</p><p>I still think GiveWell is an excellent choice, but I have a bit of a stronger appetite now for taking risks with my giving. This was partially motivated by a talk I watched Hilary Greaves give on <a href=\"https://www.youtube.com/watch?v=HT2w5jGCWG4\">making a difference</a>.</p><p>Some charities I have given to/intend to give more to going forward include:</p><ul><li><a href=\"https://www.happierlivesinstitute.org/\">Happier Lives Institute</a> for their work on improving competition and intellectual diversity in the effective giving space;</li><li>The <a href=\"https://funds.effectivealtruism.org/funds/far-future\">Long Term Future Fund</a> due to my increased belief that protecting the long-term future is an especially important moral priority;</li><li>And <a href=\"https://animalcharityevaluators.org/donate/\">Animal Charity Evaluator\u2019s Recommended Charity Fund</a> due to my increased view that funding charities working to improve animal welfare is a particularly effective way to increase present-day well-being.</li></ul>", "user": {"username": "julianhazell"}}, {"_id": "jqJLcsqEqdnd35kTB", "title": "List of past fraudsters similar to SBF", "postedAt": "2022-11-28T18:31:04.398Z", "htmlBody": "<p>To inform my forecasting around FTX events, I looked at the&nbsp;<a href=\"https://en.wikipedia.org/wiki/List_of_fraudsters\"><u>Wikipedia list of fraudsters</u></a> and selected those I subjectively found similar\u2014you can see a spreadsheet with my selection&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1N_n3HDzrZtVw8XrToZw9U0Uz61Fyd3sF8m_FiZqlCPE/edit#gid=0\"><u>here</u></a>. For each of the similar fraudsters, I present some common basic details below together with some notes.</p><p>My main takeaway is that many salient aspects of FTX have precedents: the incestuous relationship between an exchange and a trading house (Bernie Madoff, Richard Whitney), a philosophical or philanthropic component (Enric Duran, Tom Petters, etc.), embroiling friends and families in the scheme (Charles Ponzi), or multi-billion fraud not getting found out for years (Elizabeth Holmes, many others).</p><h2>Fraud with a philosophical, philanthropic or religious component</h2><h3><a href=\"https://en.wikipedia.org/wiki/Bernard_Ebbers\"><u>Bernard Ebbers</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;</li><li>Amount: $18B (all amounts are approximate and inflation-adjusted using&nbsp;<a href=\"https://www.in2013dollars.com/\"><u>in2013dollars.com</u></a>)</li></ul><p>I find the section on his faith most informative:</p><blockquote><p>While CEO of WorldCom, he was a member of the Easthaven Baptist Church in Brookhaven, Mississippi. As a high-profile member of the congregation, Ebbers regularly taught Sunday school and attended the morning church service with his family. His faith was overt, and he often started corporate meetings with prayer. When the allegations of conspiracy and fraud were first brought to light in 2002, Ebbers addressed the congregation and insisted on his innocence. \"I just want you to know you aren't going to church with a crook,\" he said. \"No one will find me to have knowingly committed fraud.\"</p></blockquote><p>Also note that eventually, $8B was restored to investors.</p><h3><a href=\"https://en.wikipedia.org/wiki/Enric_Duran\"><u>Enric Dur\u00e1n</u></a></h3><ul><li>Prison: No, life in hiding</li><li>Jurisdiction: Spain</li><li>Amount: ~$700k&nbsp;</li></ul><p>During the 2008 crisis, he robbed Spanish banks by taking out spurious loans, and donated the amounts to anticapitalist causes. He wrote a guide about how to do this, and widely distributed it: an online version in Spanish and English can be found&nbsp;<a href=\"https://www.bibliotecapleyades.net/sociopolitica/sociopol_globalbanking25.htm\"><u>here</u></a>.</p><p>Personal takeaway: Stealing money for altruistic causes is not unprecedented. And if you&nbsp;<i>are&nbsp;</i>going to cross that line, it can be done with much more style. It will also be viewed much more sympathetically if you steal from organizations perceived to be corrupt.</p><h3><a href=\"https://en.wikipedia.org/wiki/Tom_Petters\"><u>Tom Petters</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;</li><li>Amount: ~$5B</li></ul><p>Some of his donations were later returned (bold emphasis my own):</p><blockquote><p>Petters was appointed to the board of trustees for the College of St. Benedict in 2002; his mother had attended the school. In 2006 he gave $2 million for improvements to St. John's Abbey on the campus of adjacent Saint John's University. In light of the criminal prosecution, St. John's Abbey arranged to return the $2 million gift to the court-appointed receiver for the Petters bankruptcy. In October 2007, Petters made a $5.3 million gift to the College of St. Benedict to create the Thomas J. Petters Center for Global Education. In 2006, he served as a co-chairman of a capital campaign at his high school, Cathedral High School, and offered to match donations up to $750,000.</p></blockquote><p>&nbsp;</p><blockquote><p>Petters formed the John T. Petters Foundation to provide gifts and endowments at select universities to benefit future college students. The foundation was formed to honor his son, John Thomas Petters, who was killed on a visit in 2004 to Florence, Italy. The college student inadvertently wandered onto private property where the owner, Alfio Raugei, mistook him for an intruder and stabbed him to death.\" In response, in September 2004, Tom Petters pledged $10 million to his late son's college, Miami University.&nbsp;<strong>He later promised an additional $4 million, with the total to support two professorships and the John T. Petters Center for Leadership, Ethics and Skills Development</strong> within the Farmer School of Business.&nbsp;<strong>Miami University has since returned Petters' donation following his conviction</strong>. Petters also donated $12 million to Rollins College in Winter Park, Florida, where he was a member of the Board of Trustees, to create two new faculty chairs in International Business.</p></blockquote><h3><a href=\"https://en.wikipedia.org/wiki/Allen_Stanford\"><u>Allen Stanford</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: British Overseas Territory&nbsp;</li><li>Amount: $20B</li></ul><p>This case is interesting because it also occurred overseas. Uninterestingly, Allen Stanford was caught in Virginia while visiting his girlfriend.</p><blockquote><p>A leaked cable message from the U.S. Embassy in the Bahamas reported as early as 2006 that companies under Stanford's control were \"rumoured to engage in bribery, money laundering, and political manipulation\". The U.S. Ambassador to the Bahamas at the time was reported to have \"managed to stay out of any one-on-one photos with Stanford\" during a charity breakfast event.</p></blockquote><p>&nbsp;</p><blockquote><p>A February 2009 Houston Chronicle article described Stanford as \"the leading benefactor, promoter, employer and public persona\" of Antigua and Barbuda. On November 1, 2006, Stanford was appointed Knight Commander of the Order of the Nation (KCN) of Antigua and Barbuda by the Antiguan government. Prince Edward, Earl of Wessex, joined the then Governor-General of Antigua and Barbuda, Sir James Carlisle, to make this announcement during the Silver Jubilee Independence Day Celebration. After being knighted, Stanford used the awarded title \"Sir Allen\" often; he was generally referred to as such both by Antiguans and internationally.</p></blockquote><p>&nbsp;</p><blockquote><p>In October 2009, the National Honours Committee of Antigua and Barbuda voted unanimously to strip Stanford of his knighthood.</p></blockquote><h2>Fraud on top of a legitimate business</h2><h3><a href=\"https://en.wikipedia.org/wiki/Marc_Dreier\"><u>Marc Dreier</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;&nbsp;</li><li>Amount: $1B</li></ul><p>Dreier seems to have been a very smart guy who initially didn't attain success. \"I recall only that I was desperate for some measure of the success that I felt had eluded me. I lost my perspective and my moral grounding, and really, in a sense, I just lost my mind.\"</p><blockquote><p>Marc Dreier's only television interview aired in 2009 on 60 Minutes titled, \u201cThe Swindler,\u201d which was hosted by Steve Kroft. Dreier notes that he thought he would be featured on 60 minutes for something good that he had done, not for something bad. Kroft asks Dreier a question that was asked of Bernie Madoff, who many people find similarities with, about how someone could have kept up a scam for so long. Dreier noted that he had multiple stressors simultaneously that kept up his focus: the scam, a legitimate law business (funded by the scam), and his work as a practicing attorney.</p></blockquote><h3><a href=\"https://en.wikipedia.org/wiki/Richard_Whitney_(financier)\"><u>Richard Whitney</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;</li><li>Amount: $50M</li></ul><p>This case is remarkable because he previously was the director of the New York Exchange, borrowed from his brother, and ultimately went bankrupt:</p><blockquote><p>Richard Whitney (August 1, 1888 \u2013 December 5, 1974) was an American financier, president of the New York Stock Exchange from 1930 to 1935. He was later convicted of embezzlement and imprisoned.</p></blockquote><p>&nbsp;</p><blockquote><p>At the same time that Richard Whitney was achieving great success, his brother George had also prospered at Morgan bank and by 1930 had been anointed as the likely successor to bank president, Thomas W. Lamont. While Richard Whitney was assumed to be a brilliant financier, he in fact had personally been involved with speculative investments in a variety of businesses and had sustained considerable losses. To stay afloat, he began borrowing heavily from his brother George as well as other wealthy friends, and after obtaining loans from as many people as he could, turned to embezzlement to cover his mounting business losses and maintain his extravagant lifestyle. He stole funds from the New York Stock Exchange Gratuity Fund, the New York Yacht Club (where he served as the Treasurer), and $800,000 worth of bonds from his father-in-law's estate.</p></blockquote><h3><a href=\"https://en.wikipedia.org/wiki/Barry_Minkow\"><u>Barry Minkow</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;</li><li>Amount: $500M</li></ul><blockquote><p>\" While most Ponzi schemes are based on non-existent businesses, ZZZZ Best's carpet-cleaning division was very real and won high marks for its quality\"</p></blockquote><p>The Wikipedia page just&nbsp;<i>keeps on going</i>:</p><blockquote><p>\" \u2026 the Los Angeles Police Department raided ZZZZ Best's headquarters and Minkow's home, and found evidence that the company was being used to launder drug profits for organized crime\"</p></blockquote><p>&nbsp;</p><blockquote><p>After being released from jail, Minkow became a pastor and fraud investigator in San Diego, and spoke at churches and schools about ethics. This came to an end in 2011, when he admitted to helping deliberately drive down the stock price of homebuilder Lennar and was ordered back to prison for five years. Three years later, Minkow admitted to defrauding his own church and was sentenced to an additional five years in prison. He is subject to restitution requirements totaling $612 million.</p></blockquote><h3><a href=\"https://en.wikipedia.org/wiki/Bernie_Madoff\"><u>Bernie Madoff</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;</li><li>Amount: $24B</li></ul><p>There was a similar structure of having a trading house and a hedge fund. However, industry insiders suspected it. Most of the money was eventually returned.</p><h3><a href=\"https://en.wikipedia.org/wiki/Lou_Pearlman\"><u>Lou Pearlman</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;</li><li>Amount: $500M</li></ul><p>Pearlman used income from the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Backstreet_Boys\"><u>Backstreet Boys</u></a> and other bands which he either created or managed, to prop up an almost nonexistent aviation company.</p><h3><a href=\"https://en.wikipedia.org/wiki/Crazy_Eddie\"><u>Crazy Eddie</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US</li><li>Amount: ~$100M</li></ul><p>Shares a similar pattern of having fraud on top of a legitimate business.</p><h3><a href=\"https://en.wikipedia.org/wiki/Samuel_D._Waksal\"><u>Samuel D. Waksal</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;</li><li>Amount: $10M to $10B</li></ul><p>The Wikipedia page is unclear on whether the medicaments he pioneered were fraudulent, or whether the fraud was adjacent but unrelated.</p><h2>Other somehow subjectively similar cases</h2><h3><a href=\"https://en.wikipedia.org/wiki/Charles_Ponzi\"><u>Charles Ponzi</u></a></h3><ul><li>Prison: Yes&nbsp;</li><li>Jurisdiction: US&nbsp;</li><li>Amount: $200M</li></ul><blockquote><p>Ponzi's investors even included those closest to him, like his chauffeur John Collins and his own brother-in-law. Ponzi was indiscriminate about whom he allowed to invest, from young newspaper boys investing a few dollars to high-net-worth individuals, like a banker from Lawrence, Kansas, who invested $10,000</p></blockquote><h3><a href=\"https://en.wikipedia.org/wiki/Tino_De_Angelis\"><u>Tino De Angelis</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US</li><li>Amount: $2B</li></ul><p>Also borrowed based on faulty collateral. After his prison term, he went on to scam further.</p><h3><a href=\"https://en.wikipedia.org/wiki/Alves_dos_Reis\"><u>Alves dos Reis</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: Portugal, Angola&nbsp;</li><li>Amount: Absurd. \u201c0.88% of Portugal's nominal GDP at the time\u201d, which would be ~$2B today.</li></ul><p>Complicated plot to forge Portuguese banknotes in Angola, which was brought down when rivals accused it of being a front for the Germans, stopping a plan to become legitimate by acquiring the Bank of Portugal and hush away the fraudulent origins of the con.</p><h3><a href=\"https://en.wikipedia.org/wiki/Jordan_Belfort\"><u>Jordan Belfort</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;</li><li>Amount: $400M</li></ul><p>Fictionalized in the <i>Wolf of Wall Street</i> film. Belfort ended up paying 50% of his future income towards restitution, and giving somewhat scammy motivational and training seminars.&nbsp;</p><p>EDIT h/t Greg Colbourn: The above is incorrect. Belfort was initially supposed to pay 50% of his salary, but sneaked out of it. See <a href=\"https://forum.effectivealtruism.org/posts/jqJLcsqEqdnd35kTB/list-of-past-fraudsters-similar-to-sbf?commentId=4XbvuyyL5pLvGrBZQ#comments\">here</a> for more details.</p><h3><a href=\"https://en.wikipedia.org/wiki/Elizabeth_Holmes\"><u>Elizabeth Holmes</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;</li><li>Amount: $7B</li></ul><p>Homes seems to have been a similarly charismatic funder. Though in this case, it seems like the enterprise was a fraud from the beginning.</p><p>A takeaway for me: Fraud is surprisingly common, and investors probably price it in.&nbsp;</p><h3><a href=\"https://en.wikipedia.org/wiki/Jeffrey_Skilling\"><u>Kenneth Lay</u></a> and&nbsp;<a href=\"https://en.wikipedia.org/wiki/Jeffrey_Skilling\"><u>Jeffrey Skilling</u></a> (<a href=\"https://en.wikipedia.org/wiki/Enron_scandal\"><u>Enron scandal</u></a>)</h3><ul><li>Prison: No (died before), yes</li><li>Jurisdiction: US</li><li>Amount: $40B</li></ul><h3><a href=\"https://en.wikipedia.org/wiki/James_Paul_Lewis_Jr.\"><u>James Paul Lewis Jr.</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;</li><li>Amount: $500M</li></ul><p>Around half of his fortune was mandated to be returned, but only $11M was ultimately returned.</p><h3><a href=\"https://en.wikipedia.org/wiki/Harshad_Mehta\"><u>Harshad Mehta</u></a></h3><ul><li>Prison: No (died before)</li><li>Jurisdiction: India&nbsp;</li><li>Amount: $2B&nbsp;</li></ul><p>Also financed market speculation with worthless securities which he himself created.</p><h3><a href=\"https://en.wikipedia.org/wiki/John_Rigas\"><u>John Rigas</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;</li><li>Amount: $5B</li></ul><blockquote><p>The executives were accused of looting the corporation by concealing $2.3 billion in liabilities from corporate investors and of using corporation funds as their personal funds</p></blockquote><h3><a href=\"https://en.wikipedia.org/wiki/Ferdinand_Ward\"><u>Ferdinand Ward</u></a></h3><ul><li>Prison: Yes</li><li>Jurisdiction: US&nbsp;&nbsp;</li><li>Amount: $200M</li></ul><blockquote><p>Ward ran the company as a Ponzi scheme, claiming that he had inside access to government contracts, a claim which gained further credence when the president later joined the firm as a full partner.</p></blockquote><h3><a href=\"https://en.wikipedia.org/wiki/Whitaker_Wright\"><u>Whitaker Wright</u></a></h3><ul><li>Prison: No (suicide)</li><li>Jurisdiction: US</li><li>Amount: Unknown</li></ul><blockquote><p>At this point Wright made his criminal error. To maintain an image of solvency and success, Wright kept pushing thousands of pounds from one of his companies to another in a series of \"loans\". This led to some misrepresentations on balance sheets. But when he announced that, despite the apparent prosperity of his group, there would be no dividends, people became suspicious. In December 1900, the companies collapsed. Wright fled, but was brought back to stand trial. The shock waves led to a panic in London's exchange. There were other losses. The humiliated Marquess of Dufferin and Ava died in 1902 in the midst of the investigation.</p></blockquote><p><br>&nbsp;</p>", "user": {"username": "NunoSempere"}}, {"_id": "sJGHt7a5SurdWfbaN", "title": "link to AMA from Animal Charity Evaluators ", "postedAt": "2022-11-28T18:09:41.354Z", "htmlBody": "<p>ACE AMA going on right now at Reddit: <a href=\"https://www.reddit.com/r/vegan/comments/z70sgb/hi_reddit_were_researchers_from_animal_charity/\">https://www.reddit.com/r/vegan/comments/z70sgb/hi_reddit_were_researchers_from_animal_charity/</a></p>\n", "user": {"username": "davidc"}}, {"_id": "tgxZEei8ghtpxJoAg", "title": "When to diversify? Breaking down mission-correlated investing", "postedAt": "2022-11-29T11:18:33.472Z", "htmlBody": "<p><i>Note: This post was originally drafted earlier this year, but we never got around to posting it for various reasons (mostly being busy). We recently had time to revisit it, partly just as a natural result of our workflow, partly because the way this year has gone highlights the main message of this post.</i></p><p><a href=\"https://forum.effectivealtruism.org/tag/mission-correlated-investing\">Mission-correlated investing</a> means investing so as to have more money when money is more valuable. For effective altruists, money is more valuable when giving opportunities are more cost-effective. Some, such as Open Philanthropy, have mentioned considering such strategies. How important is this? Is this something only for major donors or for all EAs?</p><p>In this post, we first introduce the concept of 'mission-correlated returns'. We then estimate these 'returns' for three examples to illustrate the potential importance of mission correlation in different contexts. Tentatively, we expect the highest magnitude mission-correlated returns to be the negative returns associated with investments in which the EA 'Total Portfolio' is highly concentrated. This makes pursuing other investments, which diversify the portfolio, relatively attractive. However, for donors who are devoted to a single narrow cause area, it could make sense to make concentrated bets if there are investments with particularly positive mission correlation.</p><p>The FTX blowup shows how bad it can be when too much EA wealth is concentrated in a single risky company. This adds some circumstantial weight to our theoretical claims. We hope this post adds some mathematical weight to arguments for more diversification going forward.</p><p>While this post is about 'investing to give', we believe similar conclusions (like the importance of diversification) are relevant to other parts of EA strategy. In particular, the argument for working to increase funder diversity seems strong, as discussed <a href=\"https://forum.effectivealtruism.org/posts/oiEArRjkajAKayMCp/what-might-ftx-mean-for-effective-giving-and-ea-funding#We_need_to_aim_for_greater_funding_diversity_and_properly_resource_efforts_to_achieve_this\">here</a>. Similar arguments can, for example, be made about PR. We encourage you to think about how you can help EA diversify, both financially and otherwise.</p><h2>Key points</h2><ul><li><strong>Mission-correlated investment strategies</strong>, including 'mission hedging', are about identifying investments whose returns are correlated with your <i>future cost-effectiveness</i>.<ul><li>They can be as much about 'investing in good' as 'investing in evil'.</li><li>They can be a reason to diversify, or a reason to make concentrated bets.</li><li>They may be as or more important for small donors as for major donors.</li></ul></li><li>'<strong>Mission-correlated returns</strong>'\u2014the covariance between an investment's financial returns and your future cost-effectiveness\u2014are a useful metric for assessing the importance of mission correlation for an investment.<ul><li>We show that these 'mission-correlated returns' could exceed 1% per year for certain investments.</li><li>This underlines the importance of forecasting future cost-effectiveness, as well as efforts to better understand the composition of the 'EA portfolio'.</li></ul></li><li>The main implication for most donors is a reminder that it is important to diversify the EA 'Total Portfolio'. Concentrating investments in the same companies and sectors as other EA donors incurs a large negative 'mission-correlated return'.</li></ul><h2>Essentials</h2><p><i>Note: You might be familiar with the term 'mission hedging' as this was the first term used for this concept. We use the more general term 'mission correlation' because the crux of the idea is increasing the correlation of your investment returns with your future impact per dollar (i.e. your ability to achieve your altruistic 'mission'). Whether or not this is 'hedging' is a secondary consideration.</i></p><p>If you are 'investing to give', the total good you will do equals the value of your investment portfolio in the future multiplied by the impact per dollar that you can achieve by donating (and continuing to invest) that future value. Your portfolio's future value will be equal to its current value multiplied by the portfolio financial return.</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669759082/mirroredImages/tgxZEei8ghtpxJoAg/prxmyaknzspyogawhs2z.png\" alt=\"\"></figure><p>In deciding how to invest right now, what we care about is your <strong>expected</strong> future impact.</p><p>The definition of <a href=\"https://en.wikipedia.org/wiki/Covariance\">covariance</a> tells us that we can break expected future impact into the following parts:</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669759082/mirroredImages/tgxZEei8ghtpxJoAg/s4jbrhr5ogzzpuia6afd.png\" alt=\"\"></figure><p>where the '<i>relative impact per dollar</i>' in the covariance is the future impact per dollar divided by the expected impact per dollar.</p><p>Naive expected value maximization would tend to suggest divide and conquer strategies of focusing on increasing the Expected Portfolio Financial Return (e.g. high risk entrepreneurship) while maximizing Expected Impact per Dollar (e.g. making grants based on EA principles). Of course, both of these things are good (great even) up to a point. But pursuing them too naively ignores many important considerations (such as the general complexity of the world and diminishing returns to scale). It also ignores the covariance term. This term is one more reason it will often not be optimal to bet everything on whatever appears to have the maximum financial return.</p><p>Covariance is defined as the product of the volatility of your future relative impact per dollar, the volatility of your portfolio's financial return, and their correlation:</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669759082/mirroredImages/tgxZEei8ghtpxJoAg/btgznsykfzypraa2zuof.png\" alt=\"\"></figure><p>It's helpful to express considerations in terms of returns when reasoning about investing. Happily the covariance term in the equation for 'Expected Future Impact' acts just like a return. So we refer to this covariance as a 'mission-correlated return':</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669759082/mirroredImages/tgxZEei8ghtpxJoAg/phlw51ejn0rqzyod5sba.png\" alt=\"\"></figure><p>You can control the 'mission correlation' by picking investments whose returns themselves have a high 'mission correlation' with your future impact per dollar. The mission-correlated return of any investment is similarly:</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669759082/mirroredImages/tgxZEei8ghtpxJoAg/vhd64wuc6zideeinq0os.png\" alt=\"\"></figure><p>This enables us to assess the importance of mission correlation for an investment in terms of variables that are relatively easy to reason about.</p><h2>Examples</h2><p>We present three examples to illustrate actual estimates of mission-correlated returns.&nbsp;</p><p>Each example is introduced below the table, but for more details please see the appendix <a href=\"https://docs.google.com/document/d/1BRKqML7V_6qdGxyydeTLna-o_CJ3qKCdY-3EOgdETPw\">here</a>.</p><p>The examples are intended to be realistic, but the numbers are not based on extensive research, so don't take them literally. That said, the 'EA total portfolio' and 'AI' examples were calibrated to be in line with publicly available data. In contrast, the 'SpaceX' example should be interpreted as a hypothetical example that applies equally well to any cause area that is plausibly dominated by the efforts of a single company.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:170px\"><strong>Example</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px\"><p><strong>Mission-</strong></p><p><strong>correlated asset</strong></p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:150px\"><strong>Relevant to</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><strong>Mission-</strong></p><p><strong>correlated return</strong></p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:170px\">Diversifying the EA 'Total Portfolio'</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px\">Risky company with high weight in the 'Total Portfolio'</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:150px\">Any EA donor&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>\u201310%&nbsp;</p><p><br>&nbsp;</p><p>(\u201324% to \u20132%)</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:170px\">Concentrated bet: Relatively weak mission correlation</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px\">AI stocks</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:150px\">AI safety funders</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1%&nbsp;</p><p><br>&nbsp;</p><p>(0.4% to 3%)</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:170px\"><p>Concentrated bet:</p><p>Relatively strong mission correlation</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:200px\">SpaceX</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:150px\">Space exploration / governance funders</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>8%</p><p><br>&nbsp;</p><p>(5% to 13%)</p></td></tr></tbody></table></figure><p>A Guesstimate model for these estimates is <a href=\"https://www.getguesstimate.com/models/20469\">here</a>. All returns are annualized.</p><p><strong>How significant are these returns?</strong> As context, note that <a href=\"https://www.blackrock.com/institutions/en-axj/insights/capital-market-assumptions_AXJ#assumptions\">expected financial returns</a> are generally in the range 0%\u201315% depending on the asset class. Thus, these mission-correlated returns are of the same order of magnitude as regular expected returns.</p><p><strong>The first example</strong> illustrates the negative mission correlation that comes from being correlated with the EA 'Total Portfolio' (the portfolio of all assets that are devoted to effective giving across all cause areas). The results in the table assume that 30% of the EA Total Portfolio is concentrated in a single highly risky asset. You can avoid such negative mission-correlated returns by reducing how much you hold in assets that are overrepresented in the EA Total Portfolio (e.g. tech stocks, crypto) or even betting against them.&nbsp;</p><p>This first example is relevant to any EA that is investing to give in one or more cause areas where major donors have significant concentrations in a single risky asset or sector. The second and third examples focus on what mission correlation might mean for a donor focused on a single cause area.</p><p><strong>The second example</strong> is for an AI risk donor who expects the cost-effectiveness of their giving to increase given rapid AI progress. Such a donor may be able to improve their portfolio's mission correlation by buying AI stocks. The investment in this case has a relatively low mission correlation at 30%, and a relatively low volatility of impact per dollar. These estimates are based on <a href=\"https://forum.effectivealtruism.org/posts/JD6QvQG3q5p6heKuA/philanthropists-probably-shouldn-t-mission-hedge-ai-progress\">Michael's research</a> on AI 'mission hedging'. Nevertheless, given reasonable but low risk aversion, it is plausible that the AI risk donor may choose to hold 20% of their portfolio in such stocks to take advantage of this mission correlation.</p><p><strong>The third example</strong> illustrates how mission-correlated investments can include betting on 'good' (from the investor's point of view). In this example, a space governance funder (and space enthusiast) improves their portfolio's mission correlation by investing in SpaceX. &nbsp;We set this hypothetical case up with much higher mission correlation and impact per dollar volatility than the second example. Because of the high mission correlation in this case, it is plausible that the donor devotes more than 50% of their portfolio to SpaceX.</p><p>The point of these two examples is not that mission correlation is more or less important for space governance or AI - we would want to see more research and expert input before forming such a view. Rather, the point of the SpaceX example is to demonstrate just how important mission correlation can plausibly be if you have a relatively narrow cause area (in terms of the relevant organizations) that includes a highly influential, investable company.</p><p><strong>How much of a shift in investment do these returns suggest?</strong> This will depend on an investor's 'risk aversion' and the risk of each investment. A given mission-correlated return will change the optimal investment size for an investor with high risk aversion less than for one with low risk aversion.</p><p>As discussed <a href=\"https://forum.effectivealtruism.org/posts/THgezaPxhvoizkRFy/clarifications-on-diminishing-returns-and-risk-aversion-in\">here</a>, there is an argument that smaller donors should have much lower risk aversion (orders of magnitude lower). In practice, however, we believe this is dominated by practical considerations (e.g. limits to risk in small investment accounts), model uncertainty and 'if everyone did this' considerations.&nbsp;</p><p>We still expect smaller donors should have a lower risk aversion with their 'investing to give' money, but not orders of magnitude lower. In the Guesstimate models we show estimated weight changes for a 'normal' level of risk aversion.</p><h2>Approaches to assessing the value of mission correlation</h2><p>As summarized in the table below, we see three approaches one might use to assess the value of a mission-correlated investment.</p><p>In general, we recommend the analytic approximation as a default. It was used to generate the returns in the table above. Full simulation could be used to gain confidence if highly uncertain about a strategy. More basic scenario analysis can be intuitive, but it needs to be used with care as it can be easy to miss important features if only a small number of scenarios are used<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefiod97pg5hfp\"><sup><a href=\"#fniod97pg5hfp\">[1]</a></sup></span>.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:130px\"><strong>Approach</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:300px\"><strong>Description</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Notes</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:130px\"><p>Analytic approximation</p><p>&nbsp;</p><p>&nbsp;</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:300px\">The approach we used for the examples in this post and described in the&nbsp;<a href=\"https://docs.google.com/document/d/1BRKqML7V_6qdGxyydeTLna-o_CJ3qKCdY-3EOgdETPw/edit#\"><u>appendix</u></a>. Based on simplifying assumptions.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Easiest. Most likely to be a reasonable approximation on shorter time horizons and with less volatile investments. Good for quick assessment and back-of-the-envelope calculations (BOTECs).&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:130px\">Basic scenario analysis</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:300px\"><p>Working out the potential result of the investment in a small number of scenarios (at least two) and calculating the expected result.</p><p><br>&nbsp;</p><p>Examples - We have put together this&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1LKTWrPkZ6dST1Odqpbsj76p6nBdFrJ1iBbC1nfgFVtk/edit#gid=2113694444\"><u>sheet</u></a> for the AI &amp; SpaceX examples, which builds on Jonas Vollmer and Hauke Hillebrandt's models associated with&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/iZp7TtZdFyW8eT5dA/a-generalized-strategy-of-mission-hedging-investing-in-evil?commentId=hx2QGgdcJCmPCRh3Z\"><u>this comment</u></a>.</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Relatively intuitive to set up each scenario, but will often require more work than the analytic approximation in order to make sure the scenarios tell a coherent story. Useful to develop intuition and for sense checking.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:130px\">Full simulation</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:300px\"><p>Simulating the result of the investment across a large number of scenarios and calculating the expected result.</p><p><br>&nbsp;</p><p>Examples - Michael's research including:</p><p><a href=\"https://forum.effectivealtruism.org/posts/6wwjd8kZWY5ew9Zvy/a-preliminary-model-of-mission-correlated-investing\"><u>A Preliminary Model of Mission-Correlated Investing</u></a></p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Most technically difficult. Most flexible and able to capture all key considerations. Less intuitive than a scenario analysis, which makes bad assumptions harder to spot. Appropriate for thorough investigations, when necessary.&nbsp;</td></tr></tbody></table></figure><h2>Other considerations</h2><p>Mission correlation is likely most important when your wealth is small relative to the scale of the problem\u2014larger donors are much more subject to diminishing returns to scale. Mission correlation is also most likely to suggest concentrated bets &nbsp;for altruists focused on a specific cause area (e.g. AI), as then it is relatively easy to assess how impact per dollar might evolve over time. EAs who aim to donate to whatever cause is the highest priority at a given time are less likely to find investments that are positively correlated with this 'mission', so the negative mission correlation of holding similar assets to other EAs seems likely to dominate.</p><p>Given the uncertainty in many of the key parameters relevant to mission-correlated investing, it is possible that mission correlation could be much more valuable than currently expected, and it could be applied to special situations as discussed <a href=\"https://forum.effectivealtruism.org/posts/4rgEAunFpha9TayZu/event-driven-mission-correlated-investing-and-the-2020-us\">here</a>. It is also complementary with developing a more nuanced understanding of the value of impact under different scenarios as, for example, highlighted by Founders Pledge climate research<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6tt3kl984to\"><sup><a href=\"#fn6tt3kl984to\">[2]</a></sup></span>.</p><p>Another consideration that is typically brought up in regards to mission correlation is the direct impact of investing, which can suggest moving in the opposite direction of mission correlation (e.g. selling AI stocks, rather than buying them, to marginally slow AI progress). We agree that the direct impact of investing is important in general. Indeed, JH is actively researching this topic. For mission correlation, we think this simply means that one should prioritize strategies that involve highly liquid investments like major public equities, where one\u2019s investments will have relatively little impact on the underlying company&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn4korktn16k\"><sup><a href=\"#fnn4korktn16k\">[3]</a></sup></span>.</p><p>We see mission-correlated strategies and 'impact investment' strategies as the two main tools that differentiate altruistic investors from others. Mission-correlated strategies are complementary to impact investing, in that they are most likely to be useful in asset classes where impact investing doesn\u2019t have a big effect (e.g. large, public tech stocks). That said, there are definitely cases of potential overlap. Indeed our SpaceX example could be viewed as both (for an early-stage SpaceX investor).</p><h2>Conclusion and recommendations</h2><p>In this post we reviewed how 'mission correlation' (including 'mission hedging') is all about the covariance of financial returns and future impact per dollar. We then presented Guesstimates of the 'mission-correlated returns' associated with three illustrative investment scenarios.</p><p>The current state of research on forecasting cost-effectiveness makes estimates of mission correlation (and covariance) highly uncertain. We would be excited to see research that makes quantitative forecasts of cost-effectiveness under different possible scenarios. We expect this research will be strategically useful in general, in addition to enabling better assessments of the potential for mission-correlated investing. Implementing a mission-correlated strategy may require significant upfront research, but will pay dividends for years as likely only occasional refinements will be required.</p><p>For most EAs, our main recommendation (as Michael has emphasized <a href=\"https://mdickens.me/2020/11/23/uncorrelated_investing/\">before</a>) is to position your 'investing to give' portfolio to be as uncorrelated as reasonably possible with the EA 'Total Portfolio'. Recent events with FTX emphasize how important it is for EA funding to be diversified. It\u2019s not too late for us all to more prudently promote better diversification going forward. In practice, this may still mean underweighting certain (categories of) tech stocks and crypto.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fniod97pg5hfp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefiod97pg5hfp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>A two scenario model only has two degrees of freedom for each variable in the model. Hence, in general, it cannot match all of the means, variances and covariances of all the variables, not to mention higher moments.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6tt3kl984to\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6tt3kl984to\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://founderspledge.com/stories/changing-landscape\">https://founderspledge.com/stories/changing-landscape</a>: \"it is much more important to shift from 5 to 4.5 degrees if we are in a 5-degree scenario than it is to shift from 3 to 2.5 degrees in a 2-degree world\"</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn4korktn16k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn4korktn16k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Total Portfolio Project's <a href=\"https://papers.ssrn.com/abstract=4263206\">estimate</a> of the 'impact on company size per marginal dollar invested' is&nbsp;approximately&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"0.03\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.03</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>&nbsp;for the average US publicly listed company. This is based on empirical data from prominent financial economics researchers. For the largest stocks this will be even lower on average. On top of this, we expect the 'impact per dollar' of most companies to be small (e.g. even the most CO2-intensive stocks have emissions of &lt;0.01 tCO2e/$).</p></div></li></ol>", "user": {"username": "jh"}}, {"_id": "rX8SgWAWvpsmdAj4P", "title": "Solving for the optimal work-life balance with geometric rationality", "postedAt": "2022-11-28T17:16:13.366Z", "htmlBody": "", "user": {"username": "UnexpectedValues"}}, {"_id": "yAw8afSSEFqonufPj", "title": "Future Bowl Forecasting Tournament ", "postedAt": "2022-11-28T16:42:10.091Z", "htmlBody": "<p>I'm <a href=\"https://www.linkedin.com/in/nickmoulios/\">Nicholas</a>, a political risk analyst &amp; futures aficionado.&nbsp;</p><p>I was just assigned as a Team Lead in <a href=\"https://www.infer-pub.com\">INFER</a> while a team contest has just opened, and I'm looking for longtermists and superforecasters for our team. I wanted to invite you to participate or to refer suitable people. The forecasting assignments include AI Governance, Advanced Materials, Energy, and Biosecurity assignments while the commitment is as minimum as one forecast per month.&nbsp;</p><p>INFER is launching a 6-month forecasting tournament \u2013 <a href=\" https://www.infer-pub.com/future-bowl-tournament \">the INFER Future Bowl</a> \u2013 just for teams! The goal is to create friendly competition among the INFER community of teams and encourage regular participation and forecasting practice across a variety of topics. You'll &nbsp;have the opportunity to win a portion of $5,000 in cash prizes.&nbsp;</p><p>&nbsp;If you are interested in joining as, please feel free to <a href=\"mailto:nickmoulios@gmail.com\">email</a> or <a href=\"https://www.linkedin.com/in/nickmoulios/\">DM</a> me.&nbsp;</p>", "user": {"username": "ncmoulios"}}, {"_id": "oYmZTkiduLfKNs9Gb", "title": "Discussing how to align Transformative AI if it\u2019s developed very soon ", "postedAt": "2022-11-28T16:17:54.403Z", "htmlBody": "", "user": {"username": "elifland"}}, {"_id": "2sFFuuL8pEQRwYvkL", "title": "What would be the best degree for a medical student to intercalate in if they wanted to get involved in global health/pandemic preparedness?", "postedAt": "2022-11-28T16:33:06.851Z", "htmlBody": "", "user": {"username": "Rohan Singh"}}, {"_id": "suEMaFLd7vzkqybMp", "title": "Double your donation with matching opportunities", "postedAt": "2022-11-28T13:48:31.754Z", "htmlBody": "<p>There are several matching opportunities running this Giving Season. If you know of any that I've missed, please mention them in the comments.</p><h1><a href=\"https://doubleupdrive.org/\">Double Up Drive</a></h1><p>The 2022 Double Up Drive will start at 8:00 am PT / 11:00 am ET / 4:00 pm GMT on Giving Tuesday (29 November).</p><p>I don\u2019t know how big the matched pool will be or how long it will last so it's best to donate as soon as it opens.&nbsp;</p><h2>2022 charities</h2><ul><li>Against Malaria Foundation</li><li>Animal Charity Evaluators</li><li>Clean Air Task Force</li><li>Evidence Action</li><li>Founders Pledge</li><li>International Refugee Assistance Project</li><li>New Incentives</li><li>StrongMinds</li><li>The Good Food Institute</li><li>The Life You Can Save</li></ul><p><a href=\"https://doubleupdrive.org/\"><strong>Double your donation</strong></a></p><h1><a href=\"https://optimus.foundation/en/projects/41/\">UBS Optimus Foundation (StrongMinds)</a></h1><p>All donations to StrongMinds will be matched up to $800,000 or until the end of 2022 (whichever comes first)</p><p><a href=\"https://optimus.foundation/en/projects/41/\"><strong>Double your donation</strong></a></p><h1><a href=\"https://animalcharityevaluators.org/blog/recommended-charity-fund-matching-challenge/\">Animal Charity Evaluators</a></h1><p>Until December 31, any donation you make to ACE\u2019s Recommended Charity Fund will be matched up to $300,000, thanks to the estate of a generous legacy donor.</p><p><a href=\"https://animalcharityevaluators.org/blog/recommended-charity-fund-matching-challenge/\"><strong>Double your donation</strong></a></p>", "user": {"username": "BarryGrimes"}}, {"_id": "BxzCQxj8jtzXG2f8B", "title": "Fair Collective Effective Altruism", "postedAt": "2022-11-28T13:35:38.739Z", "htmlBody": "<p>[Crosspost from LessWrong forum]</p><p>In this post, I propose to explore a novel methodology by which a collective of decision makers (simply called <i>\"we\"</i> here) such as the current generation of humanity could make an <i>altruistic collective decision</i> in the following type of situation:</p><ul><li>The decision is about about a number of paths of actions (called <i>\"options\"</i> here) that have potentially vast consequences in the future and potentially generating quite different populations, such as deciding to colonise space.</li><li>There might be moral uncertainty about the moral status of some of the beings that might be affected by the decision, such as other species.</li><li>These beings (called <i>\"potential stakeholders\"</i> here) might be quite different from humans so that trying to estimate their subjective wellbeing and compute WELLBYs seems too speculative to base the decision on. It might also not be justified to assume that these beings are rational, have complete preferences or are even expected utility maximizers whose preferences can be encoded in a von-Neumann\u2013Morgenstern utility function.</li></ul><p><i>Epistemic status:</i> Highly speculative but based on years of theoretical research into collective decision making.</p><p>The proposed methodology is based on the following <strong>ideas</strong> and <strong>rationale</strong>:</p><ul><li>Even though a <i>quantitative</i> estimation of subjective wellbeing might <i>not</i> be possible, the members of the collective (called the <i>\"deciders\"</i> here) might be able to estimate what an affected being \"would have <i>preferred</i> us to do\" via an \"<i>empathy</i> exercise\" similar to what J\u00e1nos (John) Hars\u00e1nyi assumed is possible to perform interpersonal comparisons of preferences (but without assuming von-Neumann\u2013Morgenstern utility functions).</li><li>Since such <i>empathetic preference estimations (EPEs)</i> are still bound to be uncertain and somewhat speculative:<ul><li>The number of different EPEs needed should be kept as low as possible.</li><li>They should mostly be about what the being's <i>favourite</i> action would be since for this one only needs to <i>imagine what the being would do in our situation.</i> The necessary EPEs should not be about pairs of lotteries of options (as would be required to estimate interpersonally comparable cardinal preferences such as WELLBYs), but they might have to be about <i>pairs of options</i> or about a comparison between <i>a single option and a certain lottery</i> of options. If the latter is necessary, the number of different lotteries used in the EPEs should be as low as possible.</li><li>The EPEs should not be performed by a few decision makers or experts only, but as independently as possible by as many deciders as possible, which should then be aggregated in a suitable way as a form of efficient epistemic democracy.</li></ul></li><li>Since the empathetic preference estimations by different deciders are likely of very different precision that is likely correlated with their own confidence about their estimations, and since they are likely not independent across deciders, we use their own estimations about the standard error and level of independence of their estimates as weight in the aggregation.</li><li>The EPE aggregation should allow for different deciders having <i>diverging value systems regarding moral status and moral weight of beings,</i> so that this part of the moral uncertainty is taken care of in the aggregation.</li><li>The aggregated EPEs can then be used to <i>simulate a hypothetical collective decision made by all potential stakeholders</i>.</li><li>This hypothetical collective decision should be as <i>fair</i> as possible, trying as best as possible not to sacrifice one stakeholder's preferences for the sake of others.</li><li>To achieve this fairness, we use a device somewhat similar to Vickrey and Harsanyi's original position or veil of ignorance: we imagine performing a lottery in which a randomly selected stakeholder makes the decision, similar to the so-called \"Random Dictator\" rule studied in Social Choice Theory. Let's call this hypothetical lottery the <i>benchmark lottery</i>.</li><li>Using the benchmark lottery directly to make our decision would be perfectly <i>fair ex ante</i> , so it could be considered a form of justifiable <i>social contract</i>. But it would <i>not</i> be <i>fair ex post</i> since it could lead to vast inquality, and would <i>not</i> be <i>efficient</i> since it would ignore any potential for compromise. This is why we to not use it directly to make the decision, but rather use it as a <i>fair reference point</i> that allows us to perform some very mild form of interpersonal comparison of preferences.</li><li>To also achieve a high level of <i>fairness ex post</i>, we however do not use the reference point to normalize cardinal preferences (which would seem a natural idea in other contexts where cardinal preferences can be assumed and estimated better), but we use it as a <i>cutoff point for hypothetical approval</i>: We assume that a potential stakeholder would approve any option that they prefer to the benchmark lottery, and then simulate a hypothetical <i>approval voting</i> by all potential stakeholders.</li></ul><p><strong>In other words:</strong> <i><strong>We choose that option which we believe the largest percentage of potential stakeholders would prefer to having a random potential stakeholder decide alone.</strong></i></p><p>The <strong>actual procedure</strong> I propose for this is the following:</p><ul><li><strong>Stage 1: Collective epistemics</strong><ul><li>For each option:<ul><li>Collectively assemble the set of possible futures that might result from this option</li><li>Collectively estimate the possible probability distributions on that set, taking into account all kinds of uncertainties and ambiguities</li></ul></li></ul></li><li><strong>Stage 2: Collective decision</strong><ul><li><strong>Step 2.1.</strong> Estimating a fair reference point<ul><li>Each decider&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"M\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>&nbsp;does the following, according to their own value system:<ul><li>Identify the set of potential stakeholders, i.e., all morally relevant beings that would exist at some point in time in at least one possible future of at least one of the options.</li><li>Assign a moral weight to each potential stakeholder.</li><li>For each option&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>, estimate which percentage of the so-weighted potential stakeholder population would want us to have chosen that option&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>. Call this percentage&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"B(X,M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>. To do this, perform the following <i>\"empathy exercise\"</i> for each potential stakeholder&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"H\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span></span></span></span>:<ul><li>Imagine they have the same information you have (as collected in stage 1).</li><li>Imagine which option they would want us to have chosen.</li></ul></li><li>Estimate the standard error&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"S(M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;\">S</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;of these percentage estimates.</li><li>Estimate the degree of independence&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"I(M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;from 0 to 1 of these percentage estimates from other deciders' percentage estimates.</li></ul></li><li>Aggregate all deciders' individual percentage estimates&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"B(X,M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;into collective estimates&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"B(X)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;by taking their average, weighted by estimated precision and independence:&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"B(X) = \\frac{\\sum_M B(X,M) I(M) / S^2(M)}{\\sum_M I(M) / S^2(M)}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 8.403em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 11.883em; top: -1.933em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-munderover\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.519em; padding-bottom: 0.519em;\">\u2211</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.38em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.032em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;\">S</span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.11em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 11.883em; bottom: -1.152em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-munderover\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.519em; padding-bottom: 0.519em;\">\u2211</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.38em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.032em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;\">S</span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.347em; padding-left: 0.11em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 8.403em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.181em; vertical-align: -0.814em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></li><li>Consider the <i>benchmark lottery</i>, denoted&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"L\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span></span></span></span></span></span>, that consists in choosing option&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>&nbsp;with a probability of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"B(X)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;percent.</li></ul></li><li><strong>Step 2.2.</strong> Estimating potential stakeholders' approval<ul><li>Each decider&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"M\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span></span></span></span>&nbsp;does the following, according to their own value system:<ul><li>For each option&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>, estimate which percentage of the weighted stakeholder population would rather want us to have chosen&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>&nbsp;than to have applied the benchmark lottery. To do this, use a similar empathy exercise as above. Call this estimate&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A(X,M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>.</li><li>As before, estimate the standard error&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T(X,M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;of your percentage estimates and the degree of independence&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"J(X,M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.078em;\">J</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;from 0 to 1 of your percentage estimates from others' percentage estimates, but this time for each option separately.</li></ul></li><li>Aggregate all deciders' individual percentage estimates&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A(X,M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;into an <i>estimated stakeholder approval score</i>&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A(X) = \\frac{\\sum_M A(X,M) J(X,M) / T^2(X,M)}{\\sum_M J(X,M) / T^2(X,M)}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 10.146em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 14.349em; top: -1.933em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-munderover\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.519em; padding-bottom: 0.519em;\">\u2211</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.38em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.078em;\">J</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.435em; padding-left: 0.247em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 14.349em; bottom: -1.152em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-munderover\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.519em; padding-bottom: 0.519em;\">\u2211</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.38em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.078em;\">J</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.347em; padding-left: 0.247em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 10.146em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.181em; vertical-align: -0.814em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></li></ul></li><li><strong>Finally,</strong> find that option&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>&nbsp;with the largest estimated stakeholder approval score&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A(X)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;and implement it.</li></ul></li></ul><p>Some possible variants:</p><ul><li>If we are more confident about estimating potential stakeholders' preferences, we can replace the binary approval by a cardinal measure of <i>preference satisfaction</i>&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F(X,H,M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>:<ul><li>Let&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"M\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span></span></span></span>&nbsp;estimate the probability&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span>&nbsp;at which&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"H\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span></span></span></span>&nbsp;would be indifferent between&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>&nbsp;and the lottery that selects&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"H\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span></span></span></span>'s favorite option with probability&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span>&nbsp;and performs&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"L\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span></span></span></span></span></span>&nbsp;with probability&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"1-P\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span>. If such a&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span>&nbsp;exists, put&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F(X,H,M)=P\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span>. If not, then&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"H\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span></span></span></span>&nbsp;would prefer&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"L\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span></span></span></span></span></span>&nbsp;to&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>, so then estimate the probability&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span>&nbsp;at which&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"H\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span></span></span></span>&nbsp;would be indifferent between&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"L\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span></span></span></span></span></span>&nbsp;and the lottery that selects&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"H\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span></span></span></span>'s favorite option with probability&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span>&nbsp;and selects&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>&nbsp;with probability&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"1-P\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span>, and then put&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F(X,H,M)=-P/(1-P)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>.</li><li>Let&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A(X,M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;be the weighted average of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F(X,H,M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;using the moral weights&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"M\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span></span></span></span>&nbsp;assigned to all&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"H\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span></span></span></span>, and proceed as above.</li></ul></li><li>If we are even more confident about estimating preferences, we could extend the choice set from the set of individual options to the set of all lotteries&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"L'\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span></span></span></span></span></span>&nbsp;of options, estimate&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F(L',H,M)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;for all&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"L'\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span></span></span></span></span></span>, find that&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"L'\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span></span></span></span></span></span>&nbsp;with the largest&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"A(L')\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;and use it to draw the actually implemented option. Considering that potential stakeholders might not be risk-neutral w.r.t. their preference satisfaction (i.e., might not be expected utility maximizers), this highest-scoring lottery will likely be a proper lottery rather than a single option.</li></ul>", "user": {"username": "Jobst Heitzig (vodle.it)"}}, {"_id": "fLYiwuxyFF9q3pe6B", "title": "Effective giving subforum and other updates (bonus Forum update November 2022)", "postedAt": "2022-11-28T12:51:48.487Z", "htmlBody": "<p><strong>TL;DR:&nbsp;</strong>We\u2019ve launched an \u201ceffective giving\u201d subforum \u2014 the banner will be up for a couple of days. We\u2019re announcing this and a couple other updates.&nbsp;</p><p>More detailed summary:&nbsp;</p><ul><li>We\u2019ve launched the effective giving subforum and are working on our other test subforums <a href=\"https://forum.effectivealtruism.org/posts/fLYiwuxyFF9q3pe6B/effective-giving-subforum-and-other-updates-bonus-forum#Effective_giving_subforum___and_other_work_on_subforums\">\u2b07\ufe0f</a></li><li>Narrated versions of some posts will be available soon <a href=\"https://forum.effectivealtruism.org/posts/fLYiwuxyFF9q3pe6B/effective-giving-subforum-and-other-updates-bonus-forum#Audio_narrations_of_some_Forum_posts\">\u2b07\ufe0f</a></li><li>We\u2019re testing targeted advertising for high-impact jobs <a href=\"https://forum.effectivealtruism.org/posts/fLYiwuxyFF9q3pe6B/effective-giving-subforum-and-other-updates-bonus-forum#Testing_targeted_advertisements_for_impactful_jobs\">\u2b07\ufe0f</a></li><li>We\u2019ve fixed some bugs for pasting from a Google Document <a href=\"https://forum.effectivealtruism.org/posts/fLYiwuxyFF9q3pe6B/effective-giving-subforum-and-other-updates-bonus-forum#Bugs_fixed_for_pasting_from_Google_Documents\">\u2b07\ufe0f</a></li></ul><p>This is a short announcement post \u2014 we mostly wanted to give more context about the subforum. It\u2019s also an opportunity for you to comment and&nbsp;<strong>share feedback</strong>, which we\u2019d really appreciate (and you can always&nbsp;<a href=\"https://forum.effectivealtruism.org/s/s5zDhfyRPvrpeuRf8/p/NhSBgYq55BFs7t2cA\"><u>suggest new features here</u></a>).&nbsp;</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669639909/mirroredImages/fLYiwuxyFF9q3pe6B/vyo28azo3ldejtxj2qge.png\"><figcaption>The banner on the Frontpage of the Forum. It\u2019ll stay there for&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/MwXAJfaqMvLhmvNsA/effective-giving-day-is-only-1-day-away\"><u>Effective Giving Day</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/ea-giving-tuesday?sortedBy=new\"><u>Giving Tuesday</u></a>, and will direct people to the&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/effective-giving?tab=subforum\"><u>effective giving subforum</u></a>.</figcaption></figure><h1>Effective giving subforum \u2014 and other work on subforums</h1><p>We&nbsp;<a href=\"https://forum.effectivealtruism.org/s/HsxeFDis7YBDNhFnH/p/bKKmEqs2jjD9gDqvx#Two_pilot_subforums__bioethics_and_software_engineering\"><u>previously announced</u></a> our first two pilot subforums (bioethics and software engineering). We\u2019re now adding a third:&nbsp;<strong>effective giving</strong> \u2014&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/effective-giving?tab=subforum\"><strong><u>please feel free to join or explore it</u></strong></a>!</p><p>We hope that subforums will let users</p><ul><li>Explore discussions and content about the subforum\u2019s topic</li><li>Start discussions \u2014 including more casual threads \u2014 that will be visible only to people who have joined or are exploring the subforum&nbsp;</li><li>Keep up to date with news and ideas that are most relevant to them</li></ul><p>We\u2019ve made significant changes to the subforums since the first ones launched, and expect to make more (we\u2019re aware of some bugs), so all&nbsp;<strong>your feedback is really valuable</strong>. You can pass that on by commenting on this post or emailing us at&nbsp;<a href=\"mailto:forum@centreforeffectivealtruism.org\"><u>forum@centreforeffectivealtruism.org</u></a>.</p><h3>Other things to know about joining a subforum</h3><p>Joining the subforum will automatically subscribe you to the related topic, meaning that posts with the relevant tag will stay on the Frontpage for longer for you (as if they had 25 extra karma points). You can change that by clicking on the bell icon on the subforum page and setting your preferences accordingly (e.g. by removing \u201cupweight on frontpage\u201d).&nbsp;</p><p><img src=\"http://res.cloudinary.com/cea/image/upload/v1669639909/mirroredImages/fLYiwuxyFF9q3pe6B/v6xgvwouwccwz78jffpi.png\"></p><p>For now, joining will also add a tag to your profile. We plan to set up a way for users to opt out of this (and we might change the default settings), but it\u2019s currently not possible. Note that you can also add more topics you\u2019re interested in (whether or not they have associated subforums) by going to your profile and clicking \u201cedit public profile\u201d and finding the \u201cMy Activity\u201d section.</p><p><img src=\"http://res.cloudinary.com/cea/image/upload/v1669639909/mirroredImages/fLYiwuxyFF9q3pe6B/qdvp5vul1javop1xcxyp.png\"></p><h1>Audio narrations of some Forum posts</h1><p>There will likely be a proper announcement about this sometime soon, but, in addition to the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JTZTBienqWEAjGDRv/listen-to-more-ea-content-with-the-nonlinear-library\"><u>Nonlinear Library</u></a>, some EA Forum posts will get human narrations (that will be accessible in podcast apps and on the post pages themselves). This will be a collaboration with&nbsp;<a href=\"https://blog.type3.audio/hello-listeners/\"><u>TYPE III AUDIO</u></a>.&nbsp;</p><h1>Testing targeted advertisements for impactful jobs</h1><p>Some of you might have seen an advertisement for an open position at&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/metaculus\"><u>Metaculus</u></a> (likely because you had interacted with the \u201csoftware engineering\u201d topic). We\u2019ll be testing different types of job advertisements over the next month or so. As always, feedback is appreciated.</p><h1>Bugs fixed for pasting from Google Documents</h1><p>In some situations, images in posts that had been copy-pasted from Google Documents were broken. Some links were also failing. The major bugs here have been fixed.&nbsp;</p><p>Unfortunately, copy-pasting internal headers automatically (say, if you have a document with a table of contents that links to other sections in the document, and you want to copy-paste that into a Forum draft such that the table of contents links to sections in the Forum post) is currently&nbsp;<strong>not</strong> possible, and we might never make it work. The easiest way to create internal links to sections is&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Y8gkABpa9R6ktkhYt/forum-user-manual#Internal_links__links_to_sections_of_the_post_\"><u>outlined here</u></a>.&nbsp;</p><h1>Please give us feedback!</h1><p>You can comment here, reach us at&nbsp;<a href=\"mailto:forum@centreforeffectivealtruism.org\"><u>forum@centreforeffectivealtruism.org</u></a>, or comment on the&nbsp;<a href=\"https://forum.effectivealtruism.org/s/s5zDhfyRPvrpeuRf8/p/NhSBgYq55BFs7t2cA\"><u>feature suggestions thread</u></a>.&nbsp;</p>", "user": {"username": "Lizka"}}, {"_id": "z859kiJCSJhBMG32j", "title": "Create a fundraiser with GWWC!", "postedAt": "2022-11-28T04:48:24.015Z", "htmlBody": "<p>We have just launched our <a href=\"https://www.givingwhatwecan.org/fundraisers\">brand new fundraising pages</a>. If you\u2019d like to fundraise for effective charities this Giving Season, you can&nbsp;<a href=\"https://forms.gle/BetFcSPZDsAjweKd6\"><u>fill out our form</u></a>.&nbsp;</p><p>You can select up to 3 charities or funds from our <a href=\"https://www.givingwhatwecan.org/donate/organizations\">Donate page</a> and select a suggested split between them. GWWC has the benefit of being tax deductible in the US, UK and Netherlands.</p><h2><a href=\"https://forms.gle/gVVQ1YnnLkj3Q7eu5\">Create a fundraiser!</a></h2><p>Also you might like to keep an eye out for fundraising pages from people in the community and support or share their fundraisers!&nbsp;</p><h2>List of active Giving What We Can fundraisers</h2><ul><li><a href=\"https://www.givingwhatwecan.org/fundraisers/grace-adams\">Giving What We Can's first ever fundraising page</a></li><li><a href=\"https://www.givingwhatwecan.org/fundraisers/aj-jacobs\">A.J. Jacobs Giving Season Fundraiser</a></li><li><a href=\"https://www.givingwhatwecan.org/fundraisers/eahk-2022\">EA Hong Kong's Giving Season Fundraiser</a></li><li>(Your future fundraiser?)<br>&nbsp;</li></ul><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669610904/mirroredImages/z859kiJCSJhBMG32j/n5th2qeysm58ci3j259l.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b2914aaebb8437bb2378a28de6ddab0453949e05979dd2e2.png/w_260 260w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b2914aaebb8437bb2378a28de6ddab0453949e05979dd2e2.png/w_520 520w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b2914aaebb8437bb2378a28de6ddab0453949e05979dd2e2.png/w_780 780w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b2914aaebb8437bb2378a28de6ddab0453949e05979dd2e2.png/w_1040 1040w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b2914aaebb8437bb2378a28de6ddab0453949e05979dd2e2.png/w_1300 1300w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b2914aaebb8437bb2378a28de6ddab0453949e05979dd2e2.png/w_1560 1560w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b2914aaebb8437bb2378a28de6ddab0453949e05979dd2e2.png/w_1820 1820w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b2914aaebb8437bb2378a28de6ddab0453949e05979dd2e2.png/w_2080 2080w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b2914aaebb8437bb2378a28de6ddab0453949e05979dd2e2.png/w_2340 2340w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/b2914aaebb8437bb2378a28de6ddab0453949e05979dd2e2.png/w_2528 2528w\"></figure>", "user": {"username": "Giving What We Can"}}, {"_id": "eRyC6FtN7QEkDEwMD", "title": "Should we Audit Dustin Moskovitz?", "postedAt": "2022-11-28T01:56:16.706Z", "htmlBody": "<p>Update 12/2/22: Dustin Moskovitz himself <a href=\"https://forum.effectivealtruism.org/posts/eRyC6FtN7QEkDEwMD/should-we-audit-dustin-moskovitz?commentId=qEzHRDMqfR5fJngoo\">has commented</a>.</p>\n<p>The title is sort of self-explanatory. Should we arrange for an independent investigator to look into Dustin Moskovitz\u2019s fortune, to try to ensure that the money is morally legitimate and stable? I\u2019m sure other people have brought this up, I think I\u2019ve seen a couple comments like this, and it is an obvious place to look in the wake of the FTX collapse, as Moskovitz is our current biggest funder by a long shot. That said, I haven\u2019t seen it very prominently featured in a forum post yet, and I\u2019ve kept fairly close tabs on the forum. I'm anxious that it has been brought up or there is some obvious reason it shouldn\u2019t be done that hasn\u2019t occurred to me yet, but I\u2019m very busy right now, so I\u2019m throwing this together just to raise (or reraise) the point, on the logic that doing so is at least better than nothing. These hesitations, however, have convinced me to post this as a question rather than its own positive post. Some possible objections that have occurred to me:</p>\n<p>This is a double standard, no one else does it and we shouldn\u2019t have to: I think the first part of this at least is very likely true. I think that Tyler Cowen or various Bernie Sanders fans will wind up looking fairly foolish if it turns out that Peter Thiel or Ben Cohen have been engaged in some sort of major fraud, given how they have implied we failed at our due diligence. I don\u2019t think either group is going to incredible lengths to prevent the same thing being as likely to happen on their ends. I think this is just broadly true, that whoever criticizes us, there is probably some major cause area or movement they are invested in, that is funded by rich people who aren\u2019t undergoing much actual scrutiny. All this seems true to me, but it might not be. More importantly, I think it's irrelevant. Perhaps it is relevant to outsiders who are trying to figure out how much to raise or lower EA\u2019s status in their heads relative to other movements, but we are EAs, our job, from the inside, is to just do the work. However hypocritical the accusations of various critics might be, they tend to be true in an absolute sense. Considering how much is at stake, it is worth a non-trivial amount of EA time and money to make sure the community is healthy. This absolute point, and not some relative one, is what EAs should be worrying about. If in the process of doing as well as we can we are rising above the sanity waterline, so much the worse for the current sanity waterline.</p>\n<p>This is hindsight bias: I am more worried about this, and I think many people are now either focusing too much on EA problems that specifically connect to this one catastrophe, or are dubiously reframing their own favorite EA criticisms in terms of this crisis in order to get some boost from it. That said, if we decide to do only one thing in the wake of the FTX crash that is inspired by it, this seems like the blatantly obvious, low-hanging one to do. It may be unlikely, but imagine how much we\u2019ll be kicking ourselves if five years pass, and Moskovitz turns out to have been a second SBF. It will look so stupid in retrospect that we didn\u2019t do the bare minimum to get off the tracks of the train that just ran us over. I think that obsessing over the minutia of what exactly went wrong with SBF\u2019s fall from grace on the EA forum is hindsight bias. Applying some general outside scrutiny to Moskovitz is just the sensible productive take away.</p>\n<p>We should be applying scrutiny to someone else, like Holden Karnofsky: People who run the major orgs billionaires are donating to often have more granular say over funds than the actual funders, Karnofsky, for instance, has arguably had more impact on how Moskovitz\u2019s money is distributed than Moskovitz himself. I don\u2019t mean for this post to be exhaustive of who should face more scrutiny, but I do think there is an important difference here. If it turns out that Karnofsky is a fraudster, but Moskovitz is squeaky clean, he can just pull the funds from Karnofsky. The damage that was done can\u2019t be undone, but it is isn\u2019t too hard to move forward without Karnofsky from there. I think it might be worse if we miss Moskovitz being a fraud than if we miss Karnofsky being a fraud.</p>\n<p>We shouldn\u2019t take out SBF\u2019s misdeeds on Moskovitz: I think this one is probably one of the biggest reasons there hasn\u2019t been more discussion of this. Just the title of this post looks like an accusation, and SBF gave me no more reason to be suspicious of Moskovitz than I already had. I don\u2019t want EA to eat itself alive over this, and I think Moskovitz is probably not a fraud. But he doesn\u2019t have to be for some basic housekeeping to be a good idea. It wouldn\u2019t surprise me if Moskovitz would even agree with this, and would happily submit to the examination. EA is a high trust environment, possibly too high trust. When it became increasingly clear to me that SBF was a sham, it hit me like a personal betrayal, and I now feel like anyone could be next. It is worth keeping in mind that what happened with SBF was super weird and sudden, nothing quite like his fall has happened before. EA should introspect, but to some extent, this happening to us has a component of just stupendously bad luck to it. We should keep this in mind when we move forward, and not overshoot into paranoia. I want to be abundantly clear that this post is not a call for paranoia, and we shouldn\u2019t treat a commonsense audit like a criminal trial.</p>\n<p>So those are some beginning thoughts, does anyone else have anything to contribute? Any objections or suggestions? Any beginnings of work along these lines?</p>\n", "user": {"username": "Devin Kalish"}}, {"_id": "WAdeKMDs4m3koPGYK", "title": "If you received FTX grant money you should return it", "postedAt": "2022-11-28T08:44:48.666Z", "htmlBody": "<p>Non-EA person here, giving an outsider\u2019s take on the handwringing about whether to return grant money received from FTX.  The hypocrisy is rich.</p>\n<ol>\n<li>\n<p>All grant money received from FTX should be returned to the FTX bankruptcy estate. It is dirty money, the proceeds of FTX\u2019s criminal fraud. Real people have been victimized by FTX. Return the grant money back to the bankruptcy estate so that it can be distributed to FTX\u2019s legitimate creditors/customers.  Yet few on this EA forum will say that the money should be returned.</p>\n</li>\n<li>\n<p>Keeping FTX grant money is ratifying the criminal fraud. It is remarkable the handsprings grant recipients are doing to rationalize keeping the money. All EA ideals have been thrown out the window. Instead, grant recipients are focused on \u201cCan I be legally forced to return the grant money?\u201d and \u201cCan the bankruptcy estate legally claw the money back?\u201d  The answer they all want to hear and are fishing for is \u201cYou can legally keep the grant money.\u201d  In other words, their thinking is that if they cannot be legally forced to disgorge the grant money then they are justified in keeping it, and they will then keep the money. There is nothing EA about that. Rather, it is entirely self-serving.</p>\n</li>\n<li>\n<p>As a corollary, there is a lot of special pleading going on. EA people are implying they are justified in keeping the dirty grant money because, as a sample:  (a) variations on \u201cI didn\u2019t know that FTX was defrauding anyone\u201d; (b) variations on \u201cI\u2019m only going to use the grant money to pay employee salaries\u201d; arguing that the FTX Foundation is not an entity in bankruptcy, i.e., trying to do some fine legal parsing; and, (d) variations on \u201cI only got a small grant, so it doesn\u2019t really matter and maybe the bankruptcy estate won\u2019t try to claw it back anyway.\u201d</p>\n</li>\n</ol>\n<p>a.  One poster even argued that when he took a grant from FTX he had necessarily given FTX \u2018equivalent value\u2019 (the potential magic words to avoid a clawback) - the claimed \u2018equivalent value\u2019 being enhancing FTX\u2019s reputation. Thus do EA\u2019s high ideals reduce in practice to attempted weaseling out of responsibility.</p>\n<ol start=\"4\">\n<li>\n<p>Few are willing to say that FTX committed criminal fraud. They all demur that \u201cI am not a lawyer.\u201d  Yet when the issue is whether they are legally obligated to return the grant money to the bankruptcy estate, without hesitation they transform into armchair lawyers, delving into whether second-level clawbacks are permitted under the bankruptcy code, the exact period of time a clawback reaches back (is it three months or 90 days?), and the differences between a 90-day clawback and a two-year fraudulent transfer avoidance.</p>\n</li>\n<li>\n<p>The EA forum expresses almost zero empathy for the individuals who put money/crypto on the FTX exchange and then were criminally defrauded by FTX.  Those people do not seem to count to the EA community. (Note: I have never owned or speculated in any cryptocurrency, and I have no connection in any way with FTX or any other crypto enterprise.)</p>\n</li>\n<li>\n<p>Why not say it plainly: you want to keep the grant money even though you now know it was and is stolen money. You don\u2019t want to return the money.  Perhaps because you personally will face financial hardship if you do. It turns out that money in hand trumps EA ideals.</p>\n</li>\n<li>\n<p>Again, the right thing to do is straightforward, though not easy:  if you received FTX grant money you should return it to FTX\u2019s bankruptcy estate. All of the money.</p>\n</li>\n</ol>\n", "user": {"username": "Thurgood"}}, {"_id": "wHyvkwpwCA4nm46rp", "title": "Why Giving What We Can recommends using expert-led charitable funds", "postedAt": "2022-11-28T22:43:06.768Z", "htmlBody": "<p>Giving What We Can is looking to build more of an 'institutional view' on various aspects of effective giving. Something we've recently decided to more explicitly push for is donating via a fund. I'm cross-posting our page outlining why we recommend funds with hopes of getting feedback and questions from forum users :).</p><p>Funds are a relatively new way for donors to coordinate their giving to maximise their impact. This page outlines what a fund is, and why Giving What We Can generally recommends <a href=\"https://www.givingwhatwecan.org/donate\">donating to funds</a> rather than directly to individual charities.</p><h2>How do funds work?</h2><p>Funds allow donors to give together, as a community. Rather than each individual giving to a specific charity, donating via a fund pools their donations so that expert grantmakers and evaluators can direct those funds as cost-effectively as possible.</p><p>Using a fund is similar to using an actively managed investment fund instead of trying to pick individual stocks to invest in: in both cases, you let experts decide what to do with your money. This analogy helps explain the structure of a charitable fund, but it likely understates its benefits. This is because:</p><ul><li>Investment funds regularly take a <a href=\"https://en.wikipedia.org/wiki/Management_fee\">management fee</a> (hedge funds, for example, typically <a href=\"https://en.wikipedia.org/wiki/Management_fee#Hedge_funds\">take 1\u20134% of invested funds</a> each year). Whereas <strong>the charitable funds we recommend don\u2019t take any fees for their work</strong>.</li><li>According to the <a href=\"https://en.wikipedia.org/wiki/Efficient-market_hypothesis\">efficient-market hypothesis</a> you should expect that any given stock costs roughly what it should given the best available information. If true, that would mean there\u2019s not much room for experts to pick better stocks than you could (even if you picked at random!). Whereas <a href=\"https://www.givingwhatwecan.org/charity-comparisons\"><strong>the best charity can be at least 10 times better than a typical charity</strong></a><strong> </strong>even within the same area. This means that there is substantial room for experts to make sure your donations do far more good than they otherwise would.</li></ul><p>As we\u2019ll see next, there are other advantages of funds \u2014 both for the donor, and the charity.</p><h2>Advantages of funds</h2><p>Funds make it easier to ensure that effective organisations receive the funding they need, when they need it.<br>&nbsp;</p><p>Donating through an expert-led fund is often a much more effective way to support a cause than donating individually \u2014 even if you and the fund support the same organisations. This is because individual donors aren\u2019t able to easily coordinate with each other, nor the organisations they support. Whereas if they donate together through a fund, the fund manager can:</p><ul><li>Learn how much funding the organisation needs.</li><li>Provide funding when the organisation needs it.</li><li>Monitor how that funding is used.</li><li>Work with and incentivise organisations to be even more impactful.</li></ul><p>As a result, donors might prefer funds because their money can often be allocated more efficiently and effectively.</p><ul><li>But organisations also often benefit from the fund model. This is because:</li><li>Funds can provide a consistent and reliable stream of funding for effective organisations to carry out their work, whereas relying on individual donations can often be a challenge.</li><li>Fund managers can provide support in addition to funding. They often give advice and share key connections that can help the organisation succeed.</li></ul><p>In general, because a fund pools the resources of multiple donors, and because a fund manager can spend more time investigating and supporting organisations than individual donors can, funds are often a highly cost-effective donation option.</p><h2>When donating to funds may not be the best option</h2><p>While we think most donors should give to funds, there are some cases where it might not make sense. This would be if:</p><ul><li><strong>You think you can find more cost-effective donation opportunities by yourself.</strong> For example, you may have substantial expertise in a high-impact cause you want to support, or you might not be able to find a fund that aligns with your values.</li><li><strong>You have unique access to donation opportunities.</strong> There are often donation opportunities that funds can\u2019t support, even if the fund managers thought they were extremely cost-effective. For example, none of the funds we recommend can directly donate to a political party, and you might think that the best donation opportunity is to fund the political campaign of someone who you think will be highly effective if elected.</li></ul><h2>Bottom-line: should you give to a charitable fund?</h2><p>For most donors, we think the answer is <strong>yes</strong>.</p><p>The point of charity is to help others, and if you want your donations to be directed to the most effective organisations, <a href=\"https://www.givingwhatwecan.org/donate\">donating via a charitable fund</a> led by expert evaluators is likely the best way to do this.</p><p>If you'd like to give to a fund, we <a href=\"https://forum.effectivealtruism.org/posts/ebN8eB7DoN2Frd7Wy/announcing-gwwc-s-new-giving-recommendations\">recently announced</a> Giving What We Can's recommended funds (and charities) which you can find on <a href=\"https://www.givingwhatwecan.org/best-charities-to-donate-to-2022\">our website</a>.&nbsp;</p><p>These funds are chosen because they're ran by our <a href=\"https://www.givingwhatwecan.org/trusted-evaluators\">trusted evaluators</a>. We're planning on <a href=\"https://forum.effectivealtruism.org/posts/pp2jmWHyDK9sfC4Rh/evaluating-the-evaluators-gwwc-s-research-direction\">evaluating evaluators</a> next year so that we and other organisations have a stronger basis behind these sorts of recommendations.&nbsp;</p>", "user": {"username": "Michael_Townsend"}}, {"_id": "zBbqjFCENh2yFjFiE", "title": "Geometric Rationality is Not VNM Rational", "postedAt": "2022-11-27T19:36:00.982Z", "htmlBody": "", "user": {"username": "Scott Garrabrant"}}, {"_id": "Dm4ia4CW27tJSAkAx", "title": "Representing Future Generations Reading List", "postedAt": "2022-11-27T18:34:24.495Z", "htmlBody": "<p>The reading list below is based on a reading list originally used for an internal GPI reading group. These reading groups are used as a way of doing an early-stage exploration of new areas that seem promising from an academic global priorities research perspective.&nbsp; Each topic is often used as the theme for one or two weekly discussions, and in most cases those attending the discussion will have read or skimmed the suggested materials beforehand. This list was expanded to include several readings that were identified as relevant by the group, though not all were internally discussed.</p><p>As I thought that it could be a valuable resource for those interested in academic global priorities research, I\u2019m sharing it here, with permission from the authors. All the credit for the list below goes to them.</p><p><i>Disclaimer: The views presented in the readings suggested below do not necessarily represent views held by me, GPI, or any GPI staff member.</i></p><h1>Overview</h1><p>This list seeks to investigate several questions related to the representation of future generations, including:</p><p>(i) Can we represent future generations?&nbsp;<br>(ii) Should we represent future generations?<br>(iii) How would representing future generations work in practice?</p><h1>1. Can we represent future generations?</h1><ul><li>Karnein, Anja. 2016. \u201c<a href=\"https://books.google.com/books?hl=en&amp;lr=&amp;id=YfW4DQAAQBAJ&amp;oi=fnd&amp;pg=PA83&amp;dq=Can+We+Represent+Future+Generations%3F&amp;ots=soHAgX9P15&amp;sig=U7Hody5SuTOuP7_OKTkgxCWdg1k\"><u>Can We Represent Future Generations?</u></a>\u201d&nbsp;</li><li>T\u00e4nnsj\u00f6, Torbj\u00f6rn. 2007. \u201c<a href=\"https://www.fil.lu.se/hommageawlodek/site/papper/TannsjoTorbjorn.pdf\"><u>Future People, the All Affected Principle, and the Limits of the Aggregation Model of Democracy</u></a>.\u201d</li></ul><h1>2. The boundary problem</h1><ul><li>Goodin, Robert E. 2007. \u201c<a href=\"https://www.jstor.org/stable/4623780\"><u>Enfranchising All Affected Interests, and Its Alternatives</u></a>.\u201d</li><li>Brighouse, Harry and Marc Fleurbaey. 2010. \u201c<a href=\"https://philarchive.org/rec/BRIDAP\"><u>Democracy and Proportionality</u></a>.\u201d</li><li>N\u00e4sstr\u00f6m, Sofia. 2011. \u201c<a href=\"https://journals.sagepub.com/doi/abs/10.1111/j.1467-9248.2010.00845.x\"><u>The Challenge of the All-Affected Principle</u></a>.\u201d</li><li>Saunders, Ben. 2011. \u201c<a href=\"https://journals.sagepub.com/doi/abs/10.1177/1470594x11416782\"><u>Defining the Demos</u></a>.\u201d</li><li>Song, Sarah. 2012. \u201c<a href=\"https://www.cambridge.org/core/journals/international-theory/article/boundary-problem-in-democratic-theory-why-the-demos-should-be-bounded-by-the-state/7D987CC61381C0EBE5CB9F5C1E4D3F48\"><u>The Boundary Problem in Democratic Theory: Why the Demos Should be Bounded by the State</u></a>.\u201d</li><li>Goodin, Robert E. 2016. \u201c<a href=\"https://www.cambridge.org/core/journals/international-theory/article/enfranchising-all-subjected-worldwide/1678085B3CF1E778D13C2AB3AE682384\"><u>Enfranchising All Subjected, Worldwide</u></a>.\u201d</li><li>Arrhenius, Gustaf. 2018. \u201c<a href=\"http://www.epsjournal.ilch.uminho.pt/index.php/eps/article/view/52\"><u>The Democratic Boundary Problem Reconsidered</u></a>.\u201d</li></ul><h1>3. Against Representing Future Generations</h1><ul><li>Beckman, Ludvig. 2009. \u201c<a href=\"https://link.springer.com/chapter/10.1057/9780230244962_7\"><u>The Vote of Unborn Generations</u></a>.\u201d</li><li>Jensen, Karsten. 2015. \u201c<a href=\"https://www.tandfonline.com/doi/abs/10.1080/20403313.2015.1065649\"><u>Future Generations in Democracy: Representation or Consideration?</u></a>\u201d</li></ul><h1>4. Does democracy conflict with a concern for future generations?</h1><ul><li>Mitiga, Ross. 2021. \u201c<a href=\"https://www.cambridge.org/core/journals/american-political-science-review/article/political-legitimacy-authoritarianism-and-climate-change/E7391723A7E02FA6D536AC168377D2DE\"><u>Political Legitimacy, Authoritarianism, and Climate Change</u></a>.\u201d</li><li>Shahar, Danny. 2015. \u201c<a href=\"https://www.ingentaconnect.com/content/whp/ev/2015/00000024/00000003/art00006\"><u>Rejecting Eco-Authoritarianism, Again</u></a>.\u201d</li><li>Kates, Michael. 2015. \u201c<a href=\"https://www.tandfonline.com/doi/abs/10.1080/13698230.2013.861655\"><u>Justice, Democracy, and Future Generations</u></a>.\u201d</li><li>Halstead, John. 2017. \u201c<a href=\"https://link.springer.com/article/10.1007/s10677-016-9759-9\"><u>High Stakes Instrumentalism</u></a>.\u201d</li></ul><h1>5. Longtermist Institutional Design and Policy</h1><ul><li>Caney, Simon. 2016. \u201c<a href=\"https://philpapers.org/archive/CANPIF.pdf\"><u>Political Institutions for the Future: A Fivefold Package</u></a>.\u201d</li><li>Krznaric, Roman. 2021.&nbsp;<a href=\"https://www.tandfonline.com/doi/full/10.1080/01944363.2021.1987801\"><i><u>The Good Ancestor: A Radical Prescription for Long-Term Thinking</u></i></a>.<ul><li>Chapter 9</li></ul></li><li>John, Tyler M. and William MacAskill. 2021. \u201c<a href=\"https://globalprioritiesinstitute.org/wp-content/uploads/Tyler-M-John-and-William-MacAskill_Longtermist-institutional-reform.pdf\"><u>Longtermist Institutional Reform</u></a>.\u201d</li><li>Tonn, Bruce E. 1991. \u201c<a href=\"https://www.sciencedirect.com/science/article/pii/001632879190097L\"><u>The Court of Generations: A Proposed Amendment to the US Constitution</u></a>.\u201d</li><li>Dennis F. Thompson. 2010. \u201c<a href=\"https://www.tandfonline.com/doi/abs/10.1080/13698230903326232\"><u>Representing Future Generations: Political Presentism and Democratic Trusteeship</u></a>.\u201d</li><li>Ekeli, Kristian Sagen. 2005. \u201c<a href=\"https://link.springer.com/article/10.1007/s10806-005-7048-z\"><u>Giving a Voice to Posterity \u2013 Deliberative Democracy and Representation of Future Generations</u></a>.\u201d</li><li>Jones, Natalie, Mark O\u2019Brien, and Thomas Ryan. 2018. \u201c<a href=\"https://www.sciencedirect.com/science/article/pii/S0016328717301179\"><u>Representation of Future Generations in United Kingdom Policy-making</u></a>.\u201d</li><li>Ekeli, Kristian. 2009. \u201c<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2589905\"><u>Constitutional Experiments: Representing Future Generations Through Submajority Rules</u></a>.\u201d</li><li>Gonz\u00e1lez-Ricoy, I\u00f1igo and Axel Gosseries. 2016.&nbsp;<a href=\"https://global.oup.com/academic/product/institutions-for-future-generations-9780198746959\"><i><u>Institutions for Future Generations</u></i></a>.</li></ul>", "user": {"username": "LuisMota"}}, {"_id": "eKzzfLtHdG36Sr5Hw", "title": "More Academic Diversity in Alignment?", "postedAt": "2022-11-27T17:52:50.728Z", "htmlBody": "<p>Within the field of technical alignment research, some researchers are asking for a more diverse range of perspectives to apply to the problem. The idea is that greater diversity of academic backgrounds could generate novel insights into the problem, generating new research agendas and paths to progress.</p><p>However, current attempts to encourage individuals with a wider set of perspectives to work on the problem have so far struggled. As noted by the people behind <a href=\"https://www.lesswrong.com/posts/D7epkkJb3CqDTYgX9/refine-an-incubator-for-conceptual-alignment-research-bets\">Refine</a>, both they and&nbsp;<a href=\"https://www.pibbss.ai/\"><u>PIBBS</u></a> were <a href=\"https://www.lesswrong.com/posts/3zZjF3YKJ257x79mu/what-i-learned-running-refine#Failing_to_Optimize\">unable to do this to some extent</a>, despite explicitly searching for candidates from a broad range of backgrounds.</p><p>Based on my involvement with the EA student community over the last few years, I think this desire for breadth conflicts with how many students decide whether to work on Technical AI Safety. My intuition is that even if one viewed AI risk as the most important problem facing Society, the impression they might receive from the EA community could be to avoid working on Technical AI Safety if they don\u2019t have a traditional maths / ML background.</p><p>I think this is also implicit in the current problem profile by 80,000 Hours. There, the listed <a href=\"https://80000hours.org/problem-profiles/artificial-intelligence/#technical-ai-safety\">approaches to Technical AI Safety</a> are all existing agendas, with no mention (as far as I can see) of forming new ones. If someone doesn't have the skills to work on these (i.e., Maths or CS ), they might think there's nothing they can contribute to the field.</p><p>My biggest uncertainty here is how many current Technical AI Safety researchers agree that the current lack of academic diversity is an issue. I don\u2019t think this is a fringe opinion in the alignment community, but I could be wrong!</p><p>At the very least, it seems like there is&nbsp;<i>some</i> discrepancy here: some people working in alignment are asking for broader diversity in the field, but the wider EA community seems yet to take note. It might be that they are doing the correct thing by not yet acting on this request, but it seems an important conversation to have regardless.</p><p>Essentially, even if your skillset is not currently in ML, then some members of the Technical AI Safety community think there are highly promising routes you could explore. Don\u2019t rule yourself out from working on alignment prematurely!</p>", "user": {"username": "ojorgensen"}}, {"_id": "Mfq7KxQRvkeLnJvoB", "title": "Why Neuron Counts Shouldn't Be Used as Proxies for Moral Weight", "postedAt": "2022-11-28T12:07:52.038Z", "htmlBody": "<h1><strong>Key Takeaways</strong></h1><ul><li>Several influential EAs have suggested using neuron counts as rough proxies for animals\u2019 relative moral weights. We challenge this suggestion.</li><li>We take the following ideas to be the strongest reasons in favor of a neuron count proxy:<ul><li>neuron counts are correlated with intelligence and intelligence is correlated with moral weight,</li><li>additional neurons result in \u201cmore consciousness\u201d or \u201cmore valenced consciousness,\u201d and</li><li>increasing numbers of neurons are required to reach thresholds of minimal information capacity required for morally relevant cognitive abilities.</li></ul></li><li>However:<ul><li>in regards to intelligence, we can question both<strong>&nbsp;</strong>the extent to which more neurons are correlated with intelligence and whether more intelligence in fact predicts greater moral weight;&nbsp;</li><li>many ways of arguing that more neurons results in more valenced consciousness seem incompatible with our current understanding of how the brain is likely to work; and</li><li>there is no straightforward empirical evidence or compelling conceptual arguments indicating that relative differences in neuron counts within or between species reliably predicts welfare relevant functional capacities.</li></ul></li><li>Overall, we suggest that neuron counts should not be used as a sole proxy for moral weight, but cannot be dismissed entirely. Rather, neuron counts should be combined with other metrics in an overall weighted score that includes information about whether different species have welfare-relevant capacities.&nbsp;</li></ul><figure class=\"image image_resized\" style=\"width:53%\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669855759/mirroredImages/Mfq7KxQRvkeLnJvoB/lydad0dubo9lqaof3jq7.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/164391a1515179274c1343e4697373cb18a821bae7de609f.png/w_190 190w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/164391a1515179274c1343e4697373cb18a821bae7de609f.png/w_380 380w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/164391a1515179274c1343e4697373cb18a821bae7de609f.png/w_570 570w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/164391a1515179274c1343e4697373cb18a821bae7de609f.png/w_760 760w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/164391a1515179274c1343e4697373cb18a821bae7de609f.png/w_950 950w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/164391a1515179274c1343e4697373cb18a821bae7de609f.png/w_1140 1140w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/164391a1515179274c1343e4697373cb18a821bae7de609f.png/w_1330 1330w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/164391a1515179274c1343e4697373cb18a821bae7de609f.png/w_1520 1520w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/164391a1515179274c1343e4697373cb18a821bae7de609f.png/w_1710 1710w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/164391a1515179274c1343e4697373cb18a821bae7de609f.png/w_1890 1890w\"></figure><h1><strong>Introduction</strong></h1><p>This is the fourth post in&nbsp;<a href=\"https://forum.effectivealtruism.org/s/y5n47MfgrKvTLE3pw\"><u>the Moral Weight Project Sequence</u></a>. The aim of the sequence is to provide an overview of the research that Rethink Priorities conducted between May 2021 and October 2022 on interspecific cause prioritization\u2014i.e., making resource allocation decisions across species. The aim of this post is to summarize our&nbsp;<a href=\"https://docs.google.com/document/d/1p50vw84-ry2taYmyOIl4B91j7wkCurlB/edit?usp=sharing&amp;ouid=117560909539884344645&amp;rtpof=true&amp;sd=true\"><strong><u>full report</u></strong></a><strong> </strong>on the use of neuron counts as proxies for moral weights. The full report can be found&nbsp;<a href=\"https://docs.google.com/document/d/1p50vw84-ry2taYmyOIl4B91j7wkCurlB/edit?usp=sharing&amp;ouid=117560909539884344645&amp;rtpof=true&amp;sd=true\">here</a> and includes more extensive arguments and evidence.&nbsp;</p><p>&nbsp;</p><h2><strong>Motivations for the Report</strong></h2><p>Can the number of neurons an organism possesses, or some related measure, be used as a proxy for deciding how much weight to give that organism in moral decisions? Several influential EAs have suggested that the answer is \u201cYes\u201d in cases that involve aggregating the welfare of members of different species (<a href=\"https://reducing-suffering.org/is-brain-size-morally-relevant/\"><u>Tomasik 2013</u></a>,&nbsp;<a href=\"https://whatweowethefuture.com/\"><u>MacAskill 2022</u></a>,&nbsp;<a href=\"https://astralcodexten.substack.com/p/moral-costs-of-chicken-vs-beef\"><u>Alexander 2021</u></a>,&nbsp;<a href=\"https://www.researchwithrutgers.com/en/publications/public-policy-consequentialism-the-environment-and-nonhuman-anima\"><u>Budolfson &amp; Spears 2020</u></a>).</p><p>For the purposes of aggregating and comparing welfare across species, neuron counts are proposed as multipliers for cross-species comparisons of welfare. In general, the idea goes, as the number of neurons an organism possesses increases, so too does some morally relevant property related to the organism\u2019s welfare. Generally, the morally relevant properties are assumed to increase linearly with an increase in neurons, though other scaling functions are possible.</p><p>Scott Alexander of Slate Star Codex has a passage illustrating how weighting by neuron count might work:</p><blockquote><p>\u201cMight cows be \"more conscious\" in a way that makes their suffering matter more than chickens? Hard to tell. But if we expect this to scale with neuron number, we find cows have 6x as many cortical neurons as chickens, and most people think of them as about 10x more morally valuable. If we massively round up and think of a cow as morally equivalent to 20 chickens, switching from an all-chicken diet to an all-beef diet saves 60 chicken-equivalents per year.\u201d (<a href=\"https://astralcodexten.substack.com/p/moral-costs-of-chicken-vs-beef\"><u>2021</u></a>)&nbsp;</p></blockquote><p>This methodology has important implications for assigning moral weight. For example, the average number of neurons in a human (86,000,000,000) is 390 times greater than the average number of neurons in a chicken (220,000,000) so we would treat the welfare units of humans as 390 times more valuable. If we accepted the strongest version of the neuron count hypothesis, determining the moral weight of different species would simply be a matter of using the best current techniques (such as&nbsp;<a href=\"https://www.jneurosci.org/content/25/10/2518.full\"><u>those developed by Herculano-Houzel</u></a>) to determine the average number of neurons in different species.&nbsp;</p><p><br>&nbsp;</p><h1><strong>Arguments Connecting Neuron Counts to Moral Weight</strong></h1><p>There are several practical advantages to using neuron counts as a proxy for moral weight. Neuron counts are quantifiable, they are in-principle measurable, they correlate at least to some extent with cognitive abilities that are plausibly relevant for moral standing, and they&nbsp;<a href=\"https://slatestarcodex.com/2019/05/01/update-to-partial-retraction-of-animal-value-and-neuron-number/\"><u>correlate to some extent&nbsp;</u></a>with our intuitions about the moral status of different species. What these practical advantages show is that,&nbsp;<i>if it is the case that neuron counts are a good proxy for moral weight, that would be very convenient for us</i>. But we still need an argument for why we should believe in the first place that neuron counts are in fact connected to moral weight in a reliable way.</p><p>There are very few explicit arguments explaining this connection. However, we believe the following possibilities are the strongest reasons in favor of connecting neuron counts to moral weight: (1) neuron counts are correlated with intelligence and intelligence is correlated with moral weight, (2) additional neurons result in \u201cmore consciousness\u201d or \u201cmore valenced consciousness\u201d and (3) increasing numbers of neurons are required to reach thresholds of minimal information capacity required for morally relevant cognitive abilities. In a separate report in this sequence, we consider the possibility that (4) greater numbers of neurons lead to more \u201cconscious subsystems\u201d that have associated moral weight.</p><p><br>&nbsp;</p><h2><strong>Neuron Counts As a Stand-In For Information Processing Capacity</strong></h2><p>Before summarizing our reservations about these arguments, it's important to flag a common assumption, which is that greater informational processing is ultimately what matters for moral weight, with \u201cbrain size\u201d or \u201cneuron count\u201d being taken as indicators of information processing ability. However, brain size measured by mass or volume turns out not to directly predict the number of neurons in an organism, both because neurons themselves can be different sizes and because brains can contain differing proportions of neurons and connective tissue. Moreover, different types of species have divergent evolutionary pressures that can influence neuron size. For example, avian species tend to have smaller neurons because they need to keep weight down in order to fly. Aquatic mammals, however, have less pressure than land mammals from the constraints of gravity, and as such can have larger brains and larger neurons without as significant of an evolutionary cost.</p><p>Moreover, the raw number of neurons an organism possesses does not tell the full story about information processing capacity. That\u2019s because the number of computations that can be performed over a given amount of time in a brain also depends upon many other factors, such as (1) the number of connections between neurons, (2) the distance between neurons (with shorter distances allowing faster communication), (3) the conduction velocity of neurons, and (4) the refractory period which indicates how much time must elapse before a given neuron can fire again. In some ways, these additional factors can actually favor&nbsp;<i>smaller</i> brains (<a href=\"https://www.cell.com/current-biology/fulltext/S0960-9822(09)01597-8?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0960982209015978%3Fshowall%3Dtrue\"><u>Chitka 2009</u></a>).</p><p>So, neuron counts are not in fact perfect predictors of information-processing capacity and the exact extent to which they are predictors is still to be determined. Importantly, although one initial practical consideration in favor of using neuron counts is that they are in principle measurable, when we move to overall information processing capacity it is no longer the case that we can accurately measure this feature across different organisms, because measuring&nbsp;<i>all</i> of the relevant factors mentioned above for entire brains is currently not possible. With that in mind, let\u2019s consider the three most promising arguments for using neuron counts as proxies for moral weights.&nbsp;</p><p><br>&nbsp;</p><h2><strong>Neuron counts correlate with intelligence, and intelligence correlates with moral weight</strong></h2><p>Many people seem to believe, at least implicitly, that more intelligent animals have more moral weight. Thus they tend to think humans have the most moral weight, and chimpanzees have more moral weight than most other animals, that dogs have more moral weight than goldfish, and so on. &nbsp;</p><p>However, as noted above, we might question how well neuron counts predict overall information-processing capacity and, thus, presumably, intelligence. We can, additionally, question whether intelligence truly influences moral weight.&nbsp;</p><p>Though there is not a large literature connecting neuron counts to sentience, welfare capacity, or valenced experience, there is a reasonably large scientific literature examining the connection of neuron counts to measures of intelligence in animals. The research is still ongoing and unsettled, but we can draw a few lessons from it.</p><p>First, it seems hard to deny that there\u2019s one sense in which the increased processing power enabled by additional neurons correlates with moral weight, at least insofar as welfare relevant abilities all seem to require at least some minimum number of neurons. Pains, for example, would seem to minimally require at least some representation of the body in space, some ability to quantify intensity, and some connections to behavioral responses, all of which require a certain degree of processing power. Like pains, each welfare-relevant functional capacity requires at least some minimum number of neurons.&nbsp;</p><p>But aside from needing a baseline number of neurons to cross certain morally relevant thresholds, things become less clear, at least on a hedonistic account of well-being where what matters is the intensity and duration of valenced experience. It seems conceptually possible to increase intelligence without increasing the intensity of experience, and similarly possible to imagine the intensity of experience increasing without a corresponding increase in intelligence. Furthermore, it certainly is not the case that in humans we tend to associate greater intelligence with greater moral weight. Most people would not think it\u2019s acceptible to dismiss the pains of children or the elderly or cognitively impaired in virtue of them scoring lower on intelligence tests.</p><p>Finally, it\u2019s worth noting that some people have proposed precisely the opposite intuition: that intelligence can blunt the intensity of certain emotional states, particularly suffering. My intense pain feels less bad if I can tell myself that it will be over soon. According to this account, supported by evidence of&nbsp;<a href=\"https://link.springer.com/article/10.1007/BF00846566\"><u>top-down cognitive influences on pain</u></a>, our intelligence can sometimes provide us with tools for blunting the impact of particularly intense experiences, while other less cognitively sophisticated animals may lack these abilities.</p><p>&nbsp;</p><h2><strong>More Neurons = More Valenced Consciousness?</strong></h2><p>One might think that adding neurons increases the overall \u201camount\u201d of consciousness. In the&nbsp;<a href=\"https://docs.google.com/document/d/1p50vw84-ry2taYmyOIl4B91j7wkCurlB/edit?usp=sharing&amp;ouid=117560909539884344645&amp;rtpof=true&amp;sd=true\"><u>larger report</u></a>, we consider the following empirical arguments in favor of this claim.</p><p>There are studies that show increased volume of brain regions correlated with valenced experience, such as a study showing that cortical thickness in a particular region increased along with pain sensitivity. Do these studies demonstrate that more neurons lead to more intense positive experiences? The problem with this interpretation is that there are studies showing correlations that work in the opposite direction, such as studies showing that increased pain is correlated with decreased brain volume in areas associated with pain. There is simply not a reliable relationship between brain volume and intensity of experience.</p><p>Similarly, there are many brain imaging studies that show that increased activation in particular brain regions is associated with increases in certain valenced states such as pleasure or pain, which might initially be thought to be evidence that \u201cmore active neurons\u201d = \u201cmore experience.\u201d&nbsp; However, neuroimaging researchers are highly invested in finding an objective biomarker for pain, and in being able to predict individual differences in pain responses. They have performed hundreds of experiments looking at brain activation during pain. The current consensus is that there is not yet a reliable way of identifying pain across all relevant conditions merely by looking at brain scans, and no leading neuroscientists have said anything that suggests that the mere number of neurons active in a particular region is predictive of \u201chow much pain\u201d a person might experience. It is, in general, the <i>patterns</i> of activation and how those activations are connected to observable outputs that matter most, rather than raw numbers of neurons involved.<br>&nbsp;</p><h2><strong>Increasing numbers of neurons are required to reach thresholds of minimal information capacity required for morally relevant cognitive abilities</strong></h2><p>As noted above, it certainly is true that various capacities linked to intelligent behavior and welfare require some minimal degree of information-processing capacity. So might neuron counts be considered a proxy of moral weight simply in virtue of being predictive of how many morally relevant thresholds an organism has crossed?&nbsp;</p><p>To see the difficulty with this, consider the extremely impressive body of literature studying the cognitive capacities of bees. Bees have a relatively small number of neurons, yet have been found to be able to engage in sophisticated capacities that were previously thought to require large brains,&nbsp;<a href=\"https://www.science.org/doi/10.1126/science.aag2360\"><u>including cognitive flexibility</u></a>,&nbsp;<a href=\"https://www.science.org/doi/10.1126/science.aay8064\"><u>cross-modal recognition of objects</u></a>, and&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0003347222002366\"><u>play behavior</u></a>. There is, in general, not a defined relationship between the number of neurons and many possible capacities.&nbsp;</p><p>But without such a correlation, it would be unwise to use neuron counts as a proxy for having certain welfare relevant capacities rather than simply testing to see whether the animals in fact have the capacities. And there are many such proposed capacities.&nbsp;<a href=\"https://global.oup.com/academic/product/in-natures-interests-9780195152012?cc=us&amp;lang=en&amp;\"><u>Varner (1998)</u></a> has suggested that reversal learning may be an important capacity related to moral status. Colin&nbsp;<a href=\"https://www.jstor.org/stable/3506216#metadata_info_tab_contents\"><u>Allen (2004)</u></a> has suggested that trace conditioning might be an important marker of the capacity of conscious experience.&nbsp;<a href=\"https://link.springer.com/article/10.1007/s10539-020-09772-0\"><u>Birch, Ginsburg and Jablonka (2020)</u></a> have raised the possibility that unlimited associative learning is the key indicator of consciousness. And&nbsp;<a href=\"https://www.science.org/doi/10.1126/science.167.3914.86\"><u>Gallup (1970)</u></a> famously proposed that mirror self-recognition was a necessary condition for self-awareness.</p><p>The relevance of each of these views should be considered and weighed on their own. If there\u2019s a plausible argument connecting them to moral weight, we see no reason to discard them in favor of a unitary moral weight measure focused only on the number of neurons. As such, it would be far preferable to include measures of plausibly relevant proxies along with neuron counts rather than use neuron counts as the sole measures of moral weight.&nbsp;</p><p><br>&nbsp;</p><h1><strong>Conclusion</strong></h1><p>To summarize, one primary attraction of using neuron counts as a metric is its measurability. However, the more measurable a metric we choose, the less accurate it is, and the more we prioritize accuracy, the less we are currently able to measure. As such, the primary attraction of neuron counts is an illusion that vanishes once we attempt to reach out and grasp it.</p><p>And the three strongest arguments in favor of using neuron counts as a proxy all fail. We can question how well neuron counts are correlated with intelligence and also doubt that intelligence is correlated with moral weight. Arguments suggesting that additional neurons result in \u201cmore consciousness\u201d or \u201cmore valenced consciousness\u201d appear to be inconsistent with and unsupported by current views of how the brain works. And though it is true that increasing numbers of neurons are required to reach thresholds of minimal information capacity required for morally relevant cognitive abilities, this seems most compatible with using neuron counts in a combined measure rather than using them as a proxy for other capacities that can be independently measured.</p><p>Given this, we suggest that the best role for neuron counts in an assessment of moral weight is as a weighted contributor, one among many, to an overall estimation of moral weight. Neuron counts likely provide some useful insights about how much information can be processed at a particular time, but it seems unlikely that they would provide more useful information individually than a function that takes them into account along with other plausible markers of sentience and moral significance. Developing such a function has its own difficulties, but is preferable to relying solely on one metric which deviates from other measures of sentience and intelligence.&nbsp;<br>&nbsp;</p><h1><strong>Acknowledgments</strong></h1><p><strong><img src=\"http://res.cloudinary.com/cea/image/upload/v1669855759/mirroredImages/Mfq7KxQRvkeLnJvoB/ihvc1uqldjegwnrtbq8i.png\"></strong></p><p>This research is a project of Rethink Priorities. It was written by Adam Shriver. Thanks to Bob Fischer, Michael St. Jules, Jason Schukraft, Marcus Davis, Meghan Barrett, Gavin Taylor, David Moss, Joseph Gottlieb, Mark Budolfson, and the audience at the 2022 Animal Minds Conference at UCSD for helpful feedback on the report. If you\u2019re interested in RP\u2019s work, you can learn more by visiting our&nbsp;<a href=\"https://www.rethinkpriorities.org/research\"><u>research database</u></a>. For regular updates, please consider<i>&nbsp;</i>subscribing to our&nbsp;<a href=\"https://www.rethinkpriorities.org/newsletter\"><u>newsletter</u></a>.</p><p><br><br>&nbsp;</p>", "user": {"username": "Adam Shriver"}}, {"_id": "mCDEfENFgNJqWtydK", "title": "How VCs can avoid being tricked by obvious frauds: Rohit Krishnan on Noahpinion (linkpost)", "postedAt": "2022-11-27T14:02:17.558Z", "htmlBody": "<p>Rohit Krishnan is a former hedge fund manager. Both he and Noah Smith are now mainly-economics commentators, and have been good guides to the FTX crash on Twitter.</p><p>I found this short piece very helpful in getting a sense of how big the screw-up was by the investors in FTX.</p><p>It opens like this:</p><blockquote><p>We live in the golden age of technology fraud. When Theranos exploded, there was much hemming and hawing amongst the investing circles, mostly to note that the smart money on Sand Hill Road were not amongst those who lost their shirts. When WeWork put out its absolute sham of an IPO prospectus before getting cut by 80%, most folks said hey, it\u2019s only the vision fund that was lacking vision.&nbsp;</p><p>But now there\u2019s a third head on that mountain, and it\u2019s the biggest. Theranos only burned $700 million of investors' money. Neumann at WeWork supposedly burned around $4 Billion, but that was mostly from Softbank. FTX puts these to shame, incinerating at least $2 Billion of investors' money and another $6-8 Billion of customers\u2019 money in mere hours. Soon to be legendary, worse than Enron and faster than Lehman, there is the singular fraud of FTX and its CEO Sam Bankman-Fried.</p><p>[...]</p><p>But unlike those other crashes, this seems like it might take down multiple other firms, and create a <a href=\"https://www.strangeloopcanon.com/p/a-story-of-two-crashes\">2008 moment</a> for crypto, which used to be a $2 Trillion asset class. More importantly, to figure out how we can stop something like this from happening. Not fraud, since that\u2019s part of the human OS, but at least having the smartest money around the table getting bamboozled by tousled hair and cargo shorts.</p></blockquote><p>&nbsp;</p><p>The part that I found the most illuminating was this section on 'Dumb Enron' and some of the specific mistakes made by big investors like Temasek and Sequoia.</p><p>&nbsp;</p><blockquote><p><strong>I. The problem: this is Dumb Enron</strong></p><p>Temasek, not known to be a gunslinger in the venture world, <a href=\"https://www.temasek.com.sg/en/news-and-resources/news-room/statements/2022/statement-FTX#.Y3WRahG11DE.linkedin\">released a statement</a> after they lost $275 million with FTX. It\u2019s carefully written and well worded, and is rather circumspect about what actually went wrong.</p><p>They mention how their exposure was tiny (0.09% of AUM) and that they did extensive due diligence which took approximately 8 months, audited financial statements, and undertook regulatory risk assessments.</p><p>But the most interesting part is here:</p><p><i>As we only had a ~1% stake in FTX, we did not have a board seat. However, we take corporate governance seriously, engage the boards and management of our investee companies regularly and hold them accountable for the activities of their companies.</i></p><p>Sequoia, when it lost $214 million across a couple of funds, also mentioned in their <a href=\"https://twitter.com/sequoia/status/1590522718650499073?s=20&amp;t=xHRn_fznHXy2qhFdA6a2IQ\">letter to LPs</a> they did \u201cextensive research and thorough due diligence\u201d. A week later they <a href=\"https://www.wsj.com/articles/sequoia-capital-apologizes-to-limited-partners-for-ftx-investment-11669144914?mod=hp_lead_pos2\">apologized to the LPs</a> on a call and said they'll do better, by maybe using the Big 4 to audit all startups. I suspect this is hyperbole because otherwise this is medicine sillier than the disease.</p><p>These are not isolated errors in judgement though. The list of investors in FTX is a who\u2019s who of the investing world - Sequoia, Paradigm, Thoma Bravo, Multicoin, Softbank, Temasek, Lux, Insight, Tiger Global.</p><p>[...]&nbsp;</p><p>Doug Leone made the reasonable <a href=\"https://www.cnbc.com/2022/11/18/vc-firm-sequoia-capitals-doug-leone-on-the-fallout-from-ftx-collapse.html\">point</a> that I made above, that VCs don\u2019t really do forensic accounting. They got some audited financials, and it looked good, but it's a snapshot at the end of a quarter, so why would they know shenanigans had taken place!</p><p>But honestly, if VCs <i>had</i> been snookered by Theranos, that would make more sense. Like what do VCs know about how much blood is needed to test something? Sure it doesn\u2019t quite sound right (100s of tests from a single drop of blood!) and there were people saying this is impossible, but they say that kind of thing about everything! And Holmes\u2019 professor from Stanford was on the <a href=\"https://en.wikipedia.org/wiki/Channing_Robertson\">Board</a>! That would\u2019ve been a good reason to lose money, and Sequoia\u2019s letter would be 100% on point.</p><p>But an exchange? That\u2019s not an unknown business model. Frankfurt exchange has been running for over 4 centuries. We know how this works. We know how brokerage works. When Matt Levine writes about how this is insane, he doesn\u2019t need to, like, study up on esoteric secrets of cryptography. Whether you\u2019re trading baseball cards or stocks or currencies or crypto, a margin loan is a margin loan and a fee is a fee.</p><p>What they <i>should </i>have known however are the basic red flags - does this $25 Billion company, going on a trillion by all accounts, have an actual accountant? Is there an actual management team in place? Do they have, like, a back office? Do they know how many employees they have? Do they engage professional services like lawyers to figure out how to construct the corporate structure maze? Do they routinely <a href=\"https://www.wsj.com/articles/ftxs-sam-bankman-fried-cashed-out-300-million-during-funding-spree-11668799774\">lend hundreds of millions</a> of dollars to the CEO?&nbsp;</p><p>Sure Temasek didn\u2019t get a Board seat, but did they know there was no Board at all? Or how exactly Alameda and FTX were intertwined, if not all the other 130 entities? It seems sensible to ask these things, even if you\u2019re only risking 0.09% of your capital.</p><p>These are hardly deep detailed insane questions you skip in order to close the deal faster. Speaking as someone who\u2019s lost deals because of that kind of silliness, this is a whole another level. I\u2019ve had investments where we ask the company to get an audit done as part of the round requirements, and that\u2019s at 1/10th the size! The answer to most of these combined will take like half an hour max.&nbsp;</p><p>This isn\u2019t Enron, where you had extremely smart folk hide beautifully constructed fictions in their publicly released financial statements. This is Dumb Enron, where someone \u201ctrust me bro\u201d-ed their way to a $32 Billion valuation.&nbsp;</p></blockquote>", "user": {"username": "HaydnBelfield"}}, {"_id": "kCCTBFgRt2L9Gqndw", "title": "An EA storybook for kids", "postedAt": "2022-11-27T05:46:12.311Z", "htmlBody": "<figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669565189/mirroredImages/kCCTBFgRt2L9Gqndw/c4p1yg3bljf0pcf2wkup.jpg\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc913847495ad2156b24bf2c7bda680e4667e74589f5c7fa.jpg/w_220 220w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc913847495ad2156b24bf2c7bda680e4667e74589f5c7fa.jpg/w_440 440w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc913847495ad2156b24bf2c7bda680e4667e74589f5c7fa.jpg/w_660 660w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc913847495ad2156b24bf2c7bda680e4667e74589f5c7fa.jpg/w_880 880w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc913847495ad2156b24bf2c7bda680e4667e74589f5c7fa.jpg/w_1100 1100w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc913847495ad2156b24bf2c7bda680e4667e74589f5c7fa.jpg/w_1320 1320w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc913847495ad2156b24bf2c7bda680e4667e74589f5c7fa.jpg/w_1540 1540w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc913847495ad2156b24bf2c7bda680e4667e74589f5c7fa.jpg/w_1760 1760w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc913847495ad2156b24bf2c7bda680e4667e74589f5c7fa.jpg/w_1980 1980w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/fc913847495ad2156b24bf2c7bda680e4667e74589f5c7fa.jpg/w_2133 2133w\"></figure><p>Hi folks,</p><p>Sharing a new EA storybook for kids, designed to help introduce EA concepts to kids in a fun and age-appropriate way.<br><br>Althea and the Generation Tree tells the story of a free-spirited girl and her trusty sidekick Hamster, who together make a fateful discovery from the distant past.</p><p>The goal of the project is to help inspire kindness and thoughtfulness in future generations. It's a non-profit project, the e-book will be free and any proceeds from a future hardcopy version will be donated to charity.</p><p>We'd like the book to be created in a collaborative way, and we're <strong>calling for beta readers </strong>from the community: <a href=\"https://eaforkids.org\">https://eaforkids.org</a><br><br>ps - if you have any feedback on the concept or ideas or tips, feel free to share</p>", "user": {"username": "Simon Newstead"}}, {"_id": "qtviXtEDgZ4Cr36XX", "title": "The case for actively assisting FTX clawbacks", "postedAt": "2022-11-27T04:01:25.575Z", "htmlBody": "<h1>Summary</h1><p>The EA and AI Safety communities have broadly condemned the actions of SBF and FTX, and expressed regret that they find themselves in possession of funds that seem to have been misappropriated from FTX users. However, at the same time, messaging within the community about the need to return these funds is somewhat mixed. I argue that this mixed messaging fails to take the correct stance on this issue, and risks significant instrumental harm to the community.</p><p>I write as an outsider to the EA community, although I'm fairly familiar with the philosophical foundations (have read a lot of LW, GW, Peter Singer for the last ~15 years). I've never used FTX and have no financial stake in this.</p><h2>Comment from Eliezer</h2><blockquote><p>Important notice to readers. &nbsp;Please vote up even though it is not very carefully argued here, because it may be important to some readers to read it immediately.</p><p>DO NOT FOLLOW THIS POST'S ADVICE. &nbsp;IT IS PROBABLY VERY BAD ADVICE FROM A LEGAL STANDPOINT. &nbsp;IF IT DOESN'T GET YOU IN TROUBLE IT WILL ONLY BE BECAUSE PEOPLE IGNORED YOUR LETTERS.</p><p>NEVER FOLLOW ADVICE LIKE THIS FROM PEOPLE WHO ARE NOT LAWYERS.</p><p>ONLY DO ANYTHING REMOTELY LIKE THIS IF YOU READ A POST FROM OPEN PHILANTHROPY'S LEGAL COUNSEL TELLING YOU TO DO IT.</p><p>&nbsp;</p></blockquote><p>I've edited this comment in as I can see he thinks it's important that people see this notice. I've also edited in a comment in the section that I think he's referring to.</p><h1>Regarding Eliezer's November 12 post</h1><p>Probably most of you have read this November 12 post by Eliezer on the subject of clawbacks: <a href=\"https://forum.effectivealtruism.org/posts/FKJ8yiF3KjFhAuivt/impco-don-t-injure-yourself-by-returning-ftxff-money-for\">https://forum.effectivealtruism.org/posts/FKJ8yiF3KjFhAuivt/impco-don-t-injure-yourself-by-returning-ftxff-money-for</a></p><p>I would summarise this post as primarily addressing the question of FTX funds that have already been spent, with particular reference to the situation where the funding was \"spent\" as compensation for services the grantee has already rendered. The post argues that if you provided the services, you shouldn't view yourself as morally obligated to return the funding. It's clear this comes from a place of compassion, based on knowledge about the likely mindset of many blameless people who suddenly find themselves in a difficult position.&nbsp;</p><p>However, the post is a nuanced take on a nuanced set of circumstances. It's basically the \"Level 2\" reply to the \"Level 1\" conversation that Eliezer assumes people have already had with themselves. The problem is that I look around now and I don't see any clear statement or consensus about the much more basic case, addressing funds which <i>haven't</i> already been spent.</p><h1>Clawbacks are good actually</h1><p>It was bad that funds were misappropriated from FTX users, and it will be good for as much of that money to make its way back to its owners as possible. Any unspent money should be set aside until the relevant bankruptcy proceeding can request it. <s>I suggest also writing to the new FTX CEO to let him know the funds are being set aside in this way. I think it would be especially welcome if this could be done in an organised, collective way.</s> Edit: I agree that this part was worded poorly; it's definitely not a good suggestion to just go ahead and do that without any kind of advice or consultation. Rather what I'm hoping for is that the community can be proactive about cooperating with the bankruptcy proceedings, rather than taking the stance that the more money that can be retained, the better. I don't want to offer any specific advice about how that should be carried out.</p><p>Leaders of the EA community have repeatedly denied that their ethical philosophy entails an extreme act utilitarian \"ends justify the means\" position. For instance, William Macaskill was repeatedly clear on this before the FTX revelations, and he's been asked it almost incessantly ever since.</p><p>The basic argument is that attempting to define ethics strictly over individual actions (\"act utilitarianism\") leads to worse consequences than defining ethics over rules or policies (\"rule utilitarianism\") instead. There's an epistemic case against act utilitarianism (the temptation to fool ourselves) that I think is very compelling, but I think the strategic or game theoretic case applies especially well to these events. We all need to live in a society --- there's very little utility to be found in the state of nature. In order to live in a society we have to agree to cooperate with each other, and agree to withdraw our cooperation from, or even actively punish, defectors. Naive act utilitarianism simply isn't compatible with this. Individuals can't be expected to agree on individual act-based decisions, and you can't form a coalition with people who are making it up as they go along.&nbsp;</p><p>A basic respect for property rights is a good ethical rule, that we will all be much worse off without. Support for <i>earning to give</i> in no way entails support for <i>stealing to give</i>.&nbsp;</p><p>There are lots of situations, either constructed or actually occurring, where it's unclear how to reason about the priority of different rules or policies. The actions of SBF are not any sort of boundary case. You can't run a society where it's okay for your trading partner to abruptly decide it would be better for the world if your goods were sent elsewhere.</p><p>The need for the funds to be returned to their owners therefore completely overrides any considerations of what good those funds would be doing for the purposes SBF tried to allocate them. If it wasn't good to steal the money, it must be good to return it if you still have it. You can't just continue on with some prior plan to deploy the funds, that you had agreed with SBF or his delegees. That agreement was illegitimate.</p><h1>Lack of consensus and leadership about returning funding</h1><p>I view the ethical argument above as following fairly straightforwardly from the stated positions of EA's leadership. However, browsing the forum discussions, the attitude to the clawbacks seems much more mixed. For instance, here's what the FTX FAQ on the forum states about the clawbacks:</p><blockquote><p><strong>If you got money from FTX, </strong><i><strong>should</strong></i><strong> you give it back?</strong></p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/FKJ8yiF3KjFhAuivt/impco-don-t-injure-yourself-by-returning-ftxff-money-for?commentId=aZg5h72GyYd3Jz98L\">You probably shouldn't</a>, at least for the moment. If you gave the money back, there's the possibility that because it wasn't done through the proper legal channels you end up having to give the money back <i>twice</i>.</li></ul><p><strong>If you got money from FTX, should you spend it?</strong></p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/3Bq3PFRfzaEEAATti/clawbacks-probably-don-t-spend-ftx-grantee-money-for-the\">Probably not</a>. At least for the next few days. You may have to give it back.</li></ul><p><strong>I feel bad about having FTX money.</strong></p><ul><li>Reading <a href=\"https://forum.effectivealtruism.org/posts/FKJ8yiF3KjFhAuivt/impco-don-t-injure-yourself-by-returning-ftxff-money-for\">this</a> may help.</li><li>\"It's fine to be somebody who sells utilons for money, just like utilities sell electricity for money.\"</li><li>\"You are not obligated to return funding that got to you ultimately by way of FTX; especially if it's been given for a service you already rendered, any more than the electrical utility ought to return FTX's money that's already been spent on electricity\"</li></ul></blockquote><p>These answers also link repeatedly to Eliezer's post for reference to how people should view the question of the clawbacks. However, Eliezer's post is targeted to the specific situation where the funds have already been spent for services that have been rendered. It is not a general statement about how the community should view the need to return money to FTX. To me this is a good illustration of the lack of clarity in the community about this question.</p><p>I find the answers to <i>If you got money from FTX, should you spend it?</i><strong> &nbsp;and </strong><i>If you got money from FTX, should you give it back?&nbsp;</i> particularly inadequate. The answer to the <i>should </i>question interprets \"giving it back\" very narrowly. I certainly agree that nobody should just transfer the funds out right away. But &nbsp;I would expect the consensus position to be that it's straight-forwardly wrong to spend FTX money that could instead be preserved for its rightful owners.&nbsp;</p><h1>The advantages of a clear public stance</h1><p>This is more a question of strategy, so you can take it for whatever you think it's worth. It's an outsider's perspective.</p><p>There's obviously the risk of lasting reputational harm to the EA community from FTX. The first and most memorable thing many people will have heard about EA is that SBF stole a bunch of money and this is where some of it went.</p><p>Everyone can understand an innocent victim, but being an innocent beneficiary is a much more difficult position to explain. EA's role in unambiguously endorsing SBF and helping to open doors for him makes things doubly awkward.</p><p>The EA community will find it much easier to distance itself from SBF's crimes if you're able to say hey, we didn't want this. We worked proactively to get as much money back as we could. SBF gave out $X and we got $Y back --- everything that hadn't already been spent by the time the news broke. We gave it all back voluntarily, even if it would have been hard to track down or claw back.</p><p>As I argued above, I think this approach is the right thing to do. But even if you doubt my appeal to rules and principles, I think the instrumental case for this approach is pretty strong as well.</p><p>I know that the EA community believes very sincerely in the urgency of the problems it is working on. So I can imagine seeing this as some sort of key turning point. I can imagine seeing returning the funding as a setback that you just can't afford. However, there's no Solutions Store that you just have to make it into with the right amount of cash in your hand. The money is just one step in the long road of working towards solutions.&nbsp;</p><p>You can't make any progress on the problems you care about without strong, practical organisations full of people working together in predictable ways. And those organisations will need to be part of a wider coalition. You need to be trustworthy.&nbsp;</p>", "user": {"username": "Matthew H"}}, {"_id": "kuy2kqcrWbYuPGCsF", "title": "Sam Bankman-Fried, the FTX collapse, and the limits of effective altruism [The Hindu]", "postedAt": "2022-11-27T05:42:32.761Z", "htmlBody": "<p><br>I wrote about SBF, MacAskill, and EA for The Hindu.&nbsp;</p><blockquote><p>SBF\u2019s Future Fund donated $36.5 million to Effective Ventures, a charity chaired by friend and mentor MacAskill. It is unclear what the basis of this donation was. Was there a randomised, controlled trial (RCT) to decide if this was the best use of the money? More to the point, can any scientific study speak to the means through which the money was earned in the first place? Things get messier still. MacAskill was an \u2018unpaid\u2019 adviser to Future Fund, a post from which he claims to have resigned. But most would insist that $36.5 million was, in fact, paid. In the wake of the collapse, MacAskill has distanced himself from SBF. In a series of tweets, the philosopher declared that effective altruism is not above common sense moral constraints. Avoiding conflicts of interest, it would appear, is not one of them.</p></blockquote><p>Further:&nbsp;</p><blockquote><p>In any case, the fact that MacAskill failed to spot SBF\u2019s conceit despite a 10-year long association, is deeply damaging to him. Why should we take his views on existential threats facing humanity that he calls to our attention in his latest book&nbsp; <i>What We Owe The Future&nbsp;</i>with any seriousness? If MacAskill cannot predict threats to his own near-term future, namely, the threat associating with SBF posed to his own reputation and the effective altruism movement, how well can he estimate, much less affect, the million-year prospects of humanity?</p></blockquote><p>I also tease a counter model for 'charity' based on recognising beneficiaries of charity as people:&nbsp;</p><blockquote><p>Shanti Bhavan, a below K-12 boarding school in Baliganapalli, admits 30 students from poor backgrounds every year and supports their learning up to university. At the end of their 17-year engagement with the school, a remarkable 97% of these kids find full-time employment. A year-long sponsorship of a child here costs $2,000. The alternative to effective altruism is a techie from, say, Chennai sponsoring a child in this school over delivering 4,000 deworming treatments in Kenya for the same cost. Not based on notions of effectiveness but because the techie\u2019s own son and the child she sponsors might become friends.</p></blockquote>", "user": {"username": "Elijah Hoole"}}, {"_id": "pqmQ9PxpzzGHshmhC", "title": "2022 ALLFED highlights", "postedAt": "2022-11-28T05:37:00.765Z", "htmlBody": "<h1><strong>Executive Summary</strong></h1><p><i>Alliance to Feed the Earth in Disasters (ALLFED) celebrates its 5th anniversary this year (2017-2022).&nbsp;</i></p><p><i>Being a fully remote team, we now have team members on all continents except Antarctica.</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxcexyvivruk\"><sup><a href=\"#fnxcexyvivruk\">[1]</a></sup></span>&nbsp;By the end of the year, we will have a presence in New Zealand due to&nbsp;<a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=13&amp;catid=10\"><u>David Denkenberger</u></a> accepting a professor position at the University of Canterbury in Christchurch.</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/ia5fny83hhgezpovpfvq.png\"><figcaption><i><strong>Map of ALLFED team members as of November 2022.</strong></i><br>&nbsp;</figcaption></figure><p>Like many others, we are taken aback by recent FTX news, and concerned about what it means for ALLFED and the whole EA Community.&nbsp; Alliance to Feed the Earth in Disasters was an FTX Future Fund grantee. Taking into account the current situation, we were debating whether we should mention it in these highlights. We have decided to do so in the interest of transparency and integrity, so as to accurately report on our January-November 2022 position.</p><p>We would like to start with massive thanks to Jaan Tallinn, whose generous support last year&nbsp;through the Survival and Flourishing Fund ($1,154,000) is a major reason why we are able to weather this storm&nbsp;(also a huge thank you to all our other donors, we appreciate each and every one).</p><p><i>In these 2022 highlights:</i></p><ul><li>To start with, we give updates on&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Research\"><u>ALLFED\u2019s 2022 research</u></a>, including our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Papers_\"><u>papers</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#ASRS_Preparedness___Response_Plans\"><u>Abrupt Sun Reduction Scenario (ASRS) preparedness and response plans</u></a>, including a recent proposal for the US government.&nbsp;&nbsp;</li><li>Next, we talk about&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Financial_Mechanisms___Policy\"><u>financial mechanisms</u></a> for food system interventions, including superpests, climate food finance nexus, pandemic preparedness, and our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Policy_Work\"><u>policy</u></a> work.&nbsp;</li><li>We then move to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Operations\"><u>operations</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Communications\"><u>communications</u></a> highlights, including our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Media_Mentions\"><u>media mentions</u></a>.&nbsp;</li><li>We next talk about&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#ALLFED_Events___Workshop_\"><u>events</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#ALLFED_Events___Workshop_\"><u>workshops</u></a>&nbsp;and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Presentations_\"><u>presentations</u></a> we have delivered this year.&nbsp;</li><li>We then dive into some major changes to our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Our_Team\"><u>team</u></a> (including at the management level), ALLFED\u2019s internships and our volunteering program, and also give key statistics from this spring\u2019s research associate&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Recruitment\"><u>recruitment</u></a> (you will also find there imminent&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Opportunities\"><u>PhD opportunities</u></a>&nbsp;as well as a temporary researcher position&nbsp;with David in New Zealand).&nbsp;</li><li>Finally, we&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Our_Thanks\"><u>thank</u></a> those whose support we wish to especially recognize this year and talk about our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Funding_Needs\"><u>funding needs for 2023</u></a>, which range from dedicated funding to establish an ALLFED UK charity, to resilient food pilots, to support to continue key priority research projects on the topic of resilient foods for nuclear winter-level shocks, and to support preparedness and response plans (essential if we are to be able to present to decision makers within the current policy window).</li></ul><p>There is no escaping the fact that, rather&nbsp;unexpectedly, our funding situation has worsened due to the FTX developments.&nbsp; We will therefore be especially grateful for your donations and support this giving season&nbsp;(please visit our&nbsp;<a href=\"https://allfed.info/donate\">donation webpage</a> or contact&nbsp;<a href=\"mailto:david@allfed.info\">david@allfed.info</a> if you are interested in donating appreciated stock).</p><p>Since our inception, we have been contributing annual updates to the EA Forum. You can find last year\u2019s ALLFED Highlights&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/kqjExMCGYrs7NduGZ/2021-allfed-highlights\"><u>here</u></a>, and here is our last EA Forum post&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/iW7LjvuSmDEGF5nei/ea-resilience-to-catastrophes-and-allfed-s-case-study\"><u>EA Resilience &amp; ALLFED's Case Study.</u></a></p><h1><strong>Research</strong></h1><p>It\u2019s been a good year for research at ALLFED.&nbsp;</p><h2><strong>Papers&nbsp;</strong></h2><p>We have submitted 4 papers to peer review, one of which has now been accepted and published.&nbsp;</p><p><a href=\"https://doi.org/10.1016/j.ijdrr.2022.102798\"><i><u>Long Term Cost-Effectiveness of Resilient Foods for Global Catastrophes Compared to Artificial General Intelligence Safety</u></i></a></p><p>Authors: David Denkenberger, Anders Sandberg, Ross John Tieman, Joshua M. Pearce</p><p>Status: Published (peer reviewed)</p><p>Journal: The International Journal of Disaster Risk Reduction</p><p>This paper estimates the long-term cost-effectiveness of resilient foods for preventing starvation in the face of a global agricultural collapse caused by a long-lasting sunlight reduction, and compares it with that of investing in artificial general intelligence (AGI) safety. Using two versions of a probabilistic model, the researchers find that investing in resilient foods is more cost-effective than investing in AGI safety, with a confidence of at least 84%, suggesting that resilient foods should be a top priority for global catastrophic risk (GCR)/existential risk (X-risk) mitigation. Authors emphasize the difficulty and uncertainty related to predicting the long-term future, and that research in both resilient foods and AGI safety are currently cost-effective and should attract greater investment.</p><p>ALLFED appreciates and acts on useful feedback; good epistemics are very important to ALLFED. We took into account an important criticism we received and modified our work in response to&nbsp;<a href=\"https://www.lesswrong.com/posts/kuDKtwwbsksAW4BG2/zvi-s-thoughts-on-the-survival-and-flourishing-fund-sff#comments:~:text=ALLFED%20appreciates%20the%20feedback\"><u>this post</u> - our grant investigator</a> was concerned that we were not correctly accounting for all lines of evidence when estimating a key parameter in our cost-effectiveness analyses, in a way that benefited our narrative. We actively reached out, worked together and updated the model to the satisfaction of both, which in the end did not notably alter the results and conclusions of the analysis.</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/hhe2iztdmqbkg7jdm3qn.png\"><figcaption><strong>Far future potential increase per $ overall average over ~$100 million S model for resilient foods, overall average over ~$100 million E model for resilient foods, and AGI safety research at the $3 billion margin.&nbsp;More cost effective is further to the right.</strong></figcaption></figure><p><a href=\"https://allfed.info/images/pdfs/Preprint%20V2.0%20Integrated%20assessment%20ALLFED.docx.pdf\"><i><u>Food System Adaptation and Maintaining Trade Greatly Mitigate Global Famine in Abrupt Sunlight Reduction Scenarios</u></i></a></p><p>Authors: Morgan Rivers, Michael Hinge, Juan B. Garc\u00eda Mart\u00ednez , Ross J. Tieman, Victor Jaeck, Talib E. Butt, Florian U. Jehn, Vasco H. A. Grillo, David C. Denkenberger</p><p>Status: submitted</p><p>In this paper, we have expanded our integrated model to incorporate the scenario of minimal international trade. The figure below shows the global percentage of people fed is about 19% with no food system adaptations and consuming stored food in the first year. If instead countries would use stored food and culled animals over years and minimize biofuels and human edible animal feed, ~63% of people could be fed globally. Adding resilient foods including seaweed, methane single cell protein, converting paper factories to produce sugar, relocating crops, and scaling up greenhouses, about 82% of people could be fed globally.</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/jloxlsjn2z20n2prects.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9b0515c8562c3a0d74ba5cc3674c9757350c2113d6de40b6.png/w_130 130w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9b0515c8562c3a0d74ba5cc3674c9757350c2113d6de40b6.png/w_260 260w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9b0515c8562c3a0d74ba5cc3674c9757350c2113d6de40b6.png/w_390 390w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9b0515c8562c3a0d74ba5cc3674c9757350c2113d6de40b6.png/w_520 520w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9b0515c8562c3a0d74ba5cc3674c9757350c2113d6de40b6.png/w_650 650w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9b0515c8562c3a0d74ba5cc3674c9757350c2113d6de40b6.png/w_780 780w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9b0515c8562c3a0d74ba5cc3674c9757350c2113d6de40b6.png/w_910 910w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9b0515c8562c3a0d74ba5cc3674c9757350c2113d6de40b6.png/w_1040 1040w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9b0515c8562c3a0d74ba5cc3674c9757350c2113d6de40b6.png/w_1170 1170w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9b0515c8562c3a0d74ba5cc3674c9757350c2113d6de40b6.png/w_1231 1231w\"><figcaption><i><strong>Caloric needs met, minimal international food trade.</strong></i></figcaption></figure><p>&nbsp;</p><p><i>Food Resilience Strategies are Needed to Face Disasters, Pandemics, Cataclysmic Conflicts, and Global Catastrophes</i></p><p>Authors: Charles T. Anderson, Deanna Behring, Rachel Brennan, Erin L. Connolly, David Denkenberger, Francesco Di Gioia, Michael Jacobson, Edward Jaenicke, Armen R. Kemanian, Joshua D. Lambert, Jesse R. Lasky, Joshua M. Pearce, John Pecchia, Elizabeth Ransom, Douglas Wrenn&nbsp;</p><p>Status: submitted&nbsp;</p><p>The recent invasion of Ukraine by Russia and the COVID-19 pandemic have disrupted the global food supply chain. These events have highlighted the need for developing robust food systems capable of handling food security past its resiliency threshold in potentially worse catastrophes. If a long-scale global disaster such as a nuclear conflict happened, conventional agricultural production could collapse, food inequality would worsen, and nutritional insecurity would heighten. Thus, in order to prevent such scenarios, it is crucial to not only develop and research resilient and semi-autonomous food systems, but to also implement them into international, local, and household plans.&nbsp;<br>&nbsp;</p><p><i>Yield and Toxic Analysis of Leaf Protein Concentrate of Common Agricultural Residues</i></p><p>Authors: Theresa K. Meyer, Ross John Tieman, Sam W. Breuer, David Denkenberger, Joshua M. Pearce</p><p>Status: submitted</p><p>Resilient foods would not only help in catastrophes, but some could be used to combat current malnutrition. One possibility could be the removal of leaf protein concentrate from agricultural residue. However, the most common agricultural residues have not been studied enough for the yields and toxicity that follows the extraction process. This study seeks to do so by using high-resolution mass spectrometry and an open source toolchain for non-targeted screening of toxins of nine agricultural plant residues:&nbsp; 1) corn/maize, 2) wheat, 3) barley, 4) alfalfa, 5) yellow pea, 6) sunflower, 7) canola/rapeseed, and two weeds/agricultural residues: 8) kochia, and 9) round leaf mallow. The results showed that canola, yellow pea, and round leaf mallow should be fit for human consumption due to the lack of toxins found after the extraction process and further investigation should be used to confirm that. However, despite the rest of the crops showing promise, they will require more investigation before they should be deemed safe for consumption.</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/c5xhyekdtmu77edzghpk.png\"><figcaption><i><strong>&nbsp;Corn (maize) leaves.</strong></i></figcaption></figure><p>&nbsp;</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/ksbq9t0ecxjghqqt62lu.png\"><figcaption><i><strong>Dried Corn (Maize) Fiber Mass&nbsp;.</strong></i></figcaption></figure><h2><strong>ASRS Preparedness &amp; Response Plans</strong></h2><p><i>In order to increase the chances of a positive response in Abrupt Sunlight Reduction Scenarios (ASRSs), we have started to develop country-level&nbsp; preparedness and response plans to these threats.</i></p><p><i>We have completed our proposed ASRS plan for the United States,</i> as ALLFED\u2019s place of origin and a country with a wide range of relevant capital, skills and geographic diversity, making it an ideal test case.<strong> </strong><i><u>We are ready to assist, and welcome approaches from governments to help them develop other similar plans.</u></i></p><h3><strong>ASRS Plan Proposal for the USA</strong></h3><p>Recent research by another team suggests that in the absence of food system adaptations, crop output across the United States could fall to around&nbsp;<a href=\"https://www.nature.com/articles/s43016-022-00573-0\"><u>one percent</u></a> of pre-disaster levels in a severe ASRS.&nbsp;</p><p>However, ALLFED believes that with the intelligent use of stored foods, system adaptations and the production of resilient foods, food consumption could be close to present day levels. With such a response it should be possible to produce enough food in the United States to meet the needs of over 600 million people. This would allow a variety of foods to be consumed post disaster, along with some exports, supporting the consumption of hundreds of millions worldwide. This is laid out in the diagram below, based upon the results of our research and the resources and projected post disaster climatic conditions in the United States.&nbsp;</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/sdguzkcsrpfzsbhsmius.png\"><figcaption><i><strong>Additional food production (as million people fed) from proposed ASRS response plan for USA.</strong></i></figcaption></figure><p>Furthermore, many of these proposed actions could be of use in additional scenarios beyond ASRS. For example, the recommendations in this report would be useful to mitigate or respond to agriculture disruption caused by climate change, pests and diseases (either human or crop-based), and global conflict.</p><h2><strong>Other Research&nbsp;</strong></h2><ul><li><a href=\"https://drive.google.com/file/d/14L_67K6mgM1mntnnH-UxsXBDI6JjmRvk/view?usp=share_link\"><strong>Blue Economy Futures: Mariculture Development in the ASEAN Region&nbsp;</strong></a><br>Authors: Farrah Jasmine Dingal,&nbsp;Noah Wescombe,&nbsp;Sahil Shah,&nbsp;David Denkenberger<br><br>By empowering local and regional decision-making, socially and culturally resilient coastal communities would be much more likely to be prepared for natural disasters, thereby reducing risks and vulnerabilities and avoiding losses and damages. Moving forward, scaling seaweed production between and within ASEAN member states will entail multi-interest multi-participatory community-based approaches with a focus on localisation, appreciative inquiry, and behavior change. Redesigning and co-designing food systems in this manner will not only center&nbsp;<i>Action on Food</i> but also increase resilience to the compounding cascading impacts of climate change-induced stress and extreme weather events.</li><li><i>Morgan Rivers was awarded 1 year\u2019s use of the JASMIN computer cluster.</i></li><li><i>ALLFED contributed some Metaculus questions related to our focus areas.&nbsp;</i></li><li><i>Five ALLFED team members were selected to participate in a forecasting tournament by Phil Tetlock\u2019s research team (</i><a href=\"https://docs.google.com/document/d/15NLDoILtL_jK0X1nLDkWoqAnfAdxOfBvRKxSNU4EpjU/edit?fbclid=IwAR3Pu82B519EvDmKEJ_ozKEA5QrpRTq6WBniTSsD6okjN4qop5qVWj3Hn1k\"><i><u>Hybrid Forecasting-Persuasion Tournament</u></i></a><i>). </i>We took part as GCR experts and were paired with other experts and superforecasters into groups. Each group was asked to provide forecasts to several questions related to existential risks and global catastrophic risks (as well as additional bonus questions). We look forward to the results of this study being published.</li><li><i>ALLFED\u2019s researchers have delivered over 20&nbsp; </i><a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Presentations_\"><i><u>presentations</u></i></a><i> on our work.&nbsp;</i></li></ul><p><i>Here is one example:&nbsp;</i><a href=\"https://www.youtube.com/watch?v=i7HFl69i-i8\"><i><u>\u201cGlobal Catastrophic Food Shocks\u201d presentation</u></i></a><i> by Juan Garcia Martinez for EA Lausanne (in Switzerland) 2022</i><br>&nbsp;</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/l3wpmmgpj1jinul6q1o7.png\"><figcaption><strong>Q&amp;A from Juan\u2019s presentation on Global Catastrophic Food Risks at EA Lausanne (Switzerland) 2022.</strong></figcaption></figure><h1><strong>Financial Mechanisms &amp; Policy</strong></h1><p><i>Financial mechanisms and policy are generally distinct areas of ALLFED\u2019s work.&nbsp;</i><br><br>They feature several key work streams.&nbsp;</p><h2><strong>Financial Mechanisms</strong></h2><ul><li><strong>Superpests</strong><br>We have completed the first draft of a preliminary integrated scoping document, which includes work on locusts and fall armyworms. We have shared the preliminary locust modeling work with the Google Locust team who are well-resourced and ready to tackle the hazard modeling component of this. We are currently exploring the formation of a Working Group to pool expertise on this issue and expand resourcing.</li><li><strong>Climate Food Finance Nexus</strong><br>We have submitted a technical scoping document to the Food and Land Use Coalition to further the work developing a Food System Stability Board. This is an example of where our impact can be in facilitating ideation and then handing off to a more stakeholder-legitimate source. We have also proposed a Working Group for developing the concept post-COP-27.</li><li><strong>Pandemic Preparedness</strong><br>We have developed a model investigating pandemic risk posed by Emerging Infectious Disease (EID)&nbsp; mediated by travel networks has been developed and presented at Cambridge Conference on Catastrophic Risk and Decision Making under Deep Uncertainty conferences.&nbsp;Follow up work is being scoped on an impact bond or alternatives regarding EID surveillance and/or containment.</li></ul><h2><strong>Policy Work</strong></h2><ul><li>We provided briefings to several NATO governments and UN agencies in the early stages of the Russia/Ukraine war to estimate downstream impacts of the war on global food security, along with recommendations for fertilizer supply, supply chain stabilization and ramping up global food production. We understand these briefings helped inform global horizon scanning and ongoing response for large nation states and development finance institutions.</li><li>We have organized and conducted briefings&nbsp;for senior officials across food security, and other sectors in several permanent members of the UN Security Council on nuclear winter impacts, policy considerations and resilience options. These included recommendations on how to assess the impacts on critical infrastructure, potential governance mechanisms for this, policy stances to minimize escalation risk and the role of resilient foods and a more resilient food system in mitigating nuclear winter impacts.</li><li>Several media appearances for preeminent nuclear winter scientists across international media have been facilitated. These included the risks of nuclear escalation, the downstream nuclear winter impacts and what these would depend on. Introductions have also been made, and print interviews have been facilitated to organizations such as Politico.</li><li>We are currently facilitating an international, independent study on the food system impacts of nuclear war, across several national science organizations. Coordination is being done with the International Science Council, along with some of its members. This would aim to increase credibility of nuclear winter modeling to subsequently strengthen policy engagement work on food system resilience and foreign policy.&nbsp;</li><li>In collaboration with the University of Cambridge, we are currently facilitating&nbsp;gathering of data in nuclear weapon states (NWS) on&nbsp;public nuclear winter awareness and sentiment on nuclear weapon use (to better guide future messaging on this issue, along with engagement with relevant parties in the current Russia/Ukraine conflict). This incorporates polling design, implementation, analysis, along with narrative design, media communications, direct P5 government engagement and a media co-ordinating role with a number of think tanks. This work has been kindly funded by a grant from SoGive and in-kind support from Clearer Thinking.&nbsp;</li></ul><h1><strong>Communications</strong></h1><p>Much of ALLFED\u2019s external communications this year took place by way of direct work with partners and governments, in particular in relation to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Financial_Mechanisms___Policy\"><u>financial mechanisms</u></a> and specifically&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Financial_Mechanisms___Policy\"><u>policy</u></a> work above.&nbsp;</p><p>After 2 years of Covid-19, we also made a point to increase our presence at conferences and other&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#ALLFED_Events___Workshop_\"><u>events</u></a>, with a number of presentations and numerous opportunities to meet the ALLFED team (see below).</p><p>To mark ALLFED\u2019s 5th year, we revisited our branding and created a cohesive branding strategy to take ALLFED forward. ALLFED Brand Guidelines V.2 also incorporate totally new elements, such as the language and terms to use (and not to use) to make our work accessible to different audiences.&nbsp;&nbsp;</p><p>In terms of internal communications, we learned about NVC (Non-Violent Communications), how to critique constructively, voice and talk about challenging matters (working in global catastrophic risks we have plenty of them), and how to appreciate one another more, and more specifically.&nbsp;</p><h2><strong>Media Mentions</strong></h2><p>Importantly, earlier this year, we significantly increased our media handling capacity and trained several ALLFED team members in interacting with the media and talking about ALLFED\u2019s work in particular.&nbsp;</p><figure class=\"table\"><table><tbody><tr><td><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/rjgxpc0s7hx4yc3tvov5.jpg\"><figcaption>&nbsp;</figcaption></figure></td><td><p>Phillip Maughn of BBC Future draws extensively on ALLFED's work in his recent article on how an asteroid impact would transform the food we eat. Let us repurpose and reimagine our food system!</p><p><br><i>Full article&nbsp;</i><a href=\"https://www.bbc.com/future/article/20221013-how-an-asteroid-impact-would-transform-the-food-we-eat\"><i><u>here</u></i></a></p></td></tr><tr><td><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/rtvazwgjeezhgvifn8m7.jpg\"><figcaption>&nbsp;</figcaption></figure></td><td><p>Tom Whipple of The Times hypothesizes a scenario in which a global nuclear conflict has resulted in the sun being blocked for a decade. In such a case, we can survive only if we are prepared; Juan Garcia from ALLFED suggests that this is possible with global cooperation and by developing and researching resilient foods now.</p><p><i>Full article&nbsp;</i><a href=\"https://archive.ph/VFgvj\"><i><u>here</u></i></a></p></td></tr><tr><td><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/xyqqzin7vk7omgdgxobv.png\"><figcaption>&nbsp;</figcaption></figure></td><td><p>David Denkenberger and Morgan Rivers explored ways of scaling up resilient food options such as using seaweed, repurposing paper factories for the production of sugar, converting natural gas into protein, and relocating crops that may give us the best chance of survival in the possible scenario of a nuclear war as detailed by&nbsp;<i>Science</i> writer Zack Savitsky.</p><p><br><i>Full article&nbsp;</i><a href=\"https://www.science.org/content/article/nuclear-war-would-cause-yearslong-global-famine\"><i><u>here</u></i></a></p></td></tr><tr><td><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/fi9h5z9ii87b72tz4g6l.png\"><figcaption>&nbsp;</figcaption></figure></td><td><p>Effectief altru\u00efsten willen de wereld op een zo effici\u00ebnt mogelijke manier verder helpen. Wat hen bindt is de gemeenschappelijke vijand die moet worden bestreden: de problemen in de wereld die kunnen worden opgelost. En daarbij zijn ze niet vies van geld.</p><p><br><i>Full article&nbsp;</i><a href=\"https://www.groene.nl/artikel/red-de-wereld-met-tien-procent-van-je-salaris\"><i><u>here</u></i></a></p></td></tr></tbody></table></figure><p>Our other media presence this year includes (in date order):</p><ul><li><a href=\"https://hearthisidea.com/episodes/mike\"><u>Mike Hinge on Feeding Everyone in a Disasters</u></a> kicked off the year with a podcast&nbsp;(<i>Hear This Idea</i>,&nbsp;January 2022)</li><li><a href=\"https://80000hours.org/career-reviews/engineering/?source=email&amp;uni_id=0&amp;utm_source=80%2C000+Hours+mailing+list&amp;utm_campaign=2e38641098-RESEARCHNEWSLETTER_DEC_2021_COPY_02&amp;utm_medium=email&amp;utm_term=0_43bc1ae55c-2e38641098-351309973\"><u>80,000 hours'</u></a> featured David Denkenberger in latest career profile on engineering for career impact (<i>80,000 Hours</i>, March 2022)</li><li><a href=\"https://www.thegrocer.co.uk/supply-chain/how-to-eat-in-a-nuclear-war-what-our-food-system-would-look-like-post-apocalypse/670204.article#.YvY_pOBMEzQ\"><u>The Grocer</u></a> covers how humanity could respond and survive in \u201cHow to eat in a nuclear war: what our food system would look like post-apocalypse\u201d (<i>The Grocer</i>, August 2022)</li><li>\u201c<a href=\"https://www.newyorker.com/magazine/2022/08/15/the-reluctant-prophet-of-effective-altruism\"><u>The Reluctant Prophet of Effective Altruism</u></a>\u201d, an article in the New Yorker profiling&nbsp; William MacAskill, mentions ALLFED and our work (<i>The New Yorker</i>, August 2022)</li><li>Most recently,&nbsp;<a href=\"https://www.linkedin.com/feed/update/urn:li:activity:6998599616958976000/\"><u>Med</u></a> journal featured Juan Garcia in their \u2018Voices\u2019 issue about why we need better food resilience for global catastrophic food shocks (<i>Med</i>, November 2022)</li></ul><p>Additionally, Juan has profiled our work in Spanish (el coordinador de investigaci\u00f3n de ALLFED,&nbsp;<a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=24&amp;catid=10\"><u>Juan Garc\u00eda</u></a>, ha escrito un art\u00edculo en espa\u00f1ol sobre&nbsp;<a href=\"https://riesgoscatastroficosglobales.com/articulos/catastrofes-alimentarias\"><u>riesgos catastr\u00f3ficos globales de la producci\u00f3n alimentaria</u></a> para su proyecto de divulgaci\u00f3n y concienciaci\u00f3n ante RCGs (<a href=\"https://riesgoscatastroficosglobales.com/articulos/catastrofes-alimentarias\"><u>riesgoscatastroficosglobales.com</u></a>), explicando en qu\u00e9 consisten y c\u00f3mo actuar ante ellos).</p><p>We are especially pleased with this and our other non-English coverage, as making our research available in other languages is one of the key points of ALLFED\u2019s communications strategy.&nbsp;</p><h1><strong>Operations</strong></h1><p>Our operations team has been extremely busy this year.&nbsp;</p><h2><strong>Systems</strong></h2><p>Most importantly, our 501(c)(3) registration came through this year (like many others, it had been delayed due to Covid-19 pandemic). This means we can now function as an independent US non-profit, rather than relying on a fiscal sponsorship umbrella. This came with significant operational implications, which have been the focus of much attention from our operations team this year.</p><p>We have further worked on:&nbsp;</p><ul><li>a complete review and overhaul of all our systems, across all areas of ALLFED,</li><li>ALLFED CRM, a major new system implementation (which also generated our nice team map in the Executive Summary),</li><li>data quality and data management,&nbsp;</li><li>data compliance (including GDPR),&nbsp;</li><li>and related team training.&nbsp;&nbsp;</li></ul><h2><strong>Resilience&nbsp;</strong></h2><p>In 2022, we furthered our work on external as well as internal resilience (preparedness and response).&nbsp;</p><p>ALLFED\u2019s external resilience work this year has mainly been via&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Research\"><u>research</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Financial_Mechanisms\"><u>financial mechanisms</u></a>, as described in the sections above.</p><p>In March 2022, following the Russian invasion of Ukraine,&nbsp;<a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=16&amp;catid=10\"><u>Sonia Cassidy</u></a>, ALLFED\u2019s Director of Operations and also Director of Communications, assembled a case study of our organizational response. Published as an EA Forum post,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/iW7LjvuSmDEGF5nei/ea-resilience-to-catastrophes-and-allfed-s-case-study\"><u>EA Resilience &amp; ALLFED's Case Study&nbsp;</u></a>also looked at the broader question of the resilience of the EA community itself, our ability to mobilize response teams, potential resilience centers as well as some questions and opportunities arising therefrom.&nbsp;&nbsp;&nbsp;</p><p>To date, there have been 3 activations of our internal response team in 2022 (of which one has been the Russia-Ukraine war, and one due to the FTX situation). We have further tested, practiced and improved our response capabilities across the team.&nbsp;&nbsp;</p><h1><strong>Events &amp; Presentations&nbsp;</strong></h1><p>2022 saw us emerging from COVID-19 lockdowns and back out in the world, with plenty of opportunities to learn about ALLFED\u2019s work and meet our team.&nbsp;<br><br><i>This year so far, we have:</i></p><ul><li><i>conducted 1 ALLFED workshop, 1 salon and 1 breakfast briefing,</i></li><li><i>delivered over 20 presentations,&nbsp;</i></li><li><i>Attended over 30 events, workshops and conferences.&nbsp;</i></li></ul><h2><strong>ALLFED Events &amp; Workshop&nbsp;</strong></h2><p>So far in 2022 we have produced an ALLFED workshop (in the USA) as well as an ALLFED Salon and a breakfast briefing (in the UK).&nbsp;</p><p><strong>ALLFED Workshop @ Future Forum 2022</strong></p><p>In August 2022, we led a workshop for the&nbsp;<a href=\"https://futureforum.foundation/\"><u>Future Forum</u></a>&nbsp;conference in San Francisco. The workshop explored the intersections of food systems with various cause areas (animal welfare, space exploration, refuges, and global food catastrophes) and featured briefings by ALLFED\u2019s in-conference team (Dr. Anders Sandberg, Morgan Rivers and Sonia Cassidy) as well as remote presenters (Juan Garcia, Alexey Turchin and our guest Ian McKay).</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/xrgcrcpnengdispi0gl6.jpg\"><figcaption><i><strong>ALLFED\u2019s \u201cFood System Intersections\u201d Workshop @ Future Forum 2022 Morgan Rivers, Anders Sandberg, Sonia Cassidy and Rick Holland,&nbsp; featured here with a happy workshop participant. (Aug 2022, San Francisco, USA)</strong></i></figcaption></figure><p><strong>ALLFED Salon &amp; Breakfast Briefing</strong></p><p>In London,&nbsp;<a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=26&amp;catid=10\"><u>Rick Holland</u></a>, our Director of Development hosted 2 in-person events this year: a summer salon and an autumn breakfast briefing. They both included lively discussions around extreme risk, nuclear winter, and similar. The goal was to develop and grow partnerships and collaborations and meet with those interested in learning more about our projects and supporting ALLFED\u2019s work (including prospective donors who wish to learn more and discuss funding opportunities).</p><p><i>If you are interested in attending in-person events like this in the future, please feel free to contact us via&nbsp;</i><a href=\"https://allfed.info/contact\"><i><u>https://allfed.info/contact</u></i></a><i>.</i></p><h2><strong>Presentations&nbsp;</strong></h2><p>We have given over 20 presentations to date this year, in a range of contexts, from large international conferences to local EA groups.&nbsp;</p><p>These included (in date order):&nbsp;</p><ul><li><a href=\"https://www.youtube.com/watch?v=P2q2u4ds4IU\">RISK-Knowledge Action Network Workshop on Understanding and Modeling Complex Risks in Coupled Human-Environment System 2022</a> (February)</li><li><a href=\"https://www.youtube.com/watch?v=o-We3DpiGyg\">EAGxOxford 2022</a> (March)</li><li><a href=\"https://youtu.be/lfPJ7Tz4JGs?t=23475\">CSER Cambridge Conference on Catastrophic Risk 2022</a> (April)</li><li><a href=\"https://www.youtube.com/watch?v=EnlwUs1fW80&amp;t=1299s\">EGU General Assembly 2022</a> (May)</li><li>High Impact Medicine Speaker Event on Nuclear Risk (June)&nbsp;</li><li>NTI\u2019s Global Nuclear Effects Conference 2022 (June)</li><li>PennState Symposium on Emergency Food Resilience 2022 (August)</li><li>EAGxBerlin 2022 (September)</li><li>The Society for Decision Making Under Deep Uncertainty 2022 Annual Meeting (November)</li><li><a href=\"https://www.youtube.com/watch?v=cVcZnYYlj_k\">Future of Food Production Summit 2022</a> (November)</li></ul><p>We have also presented to multiple local EA groups around the world throughout the year including: EA Brown, EA Bahamas community, EA Czech, EA society at the London School of Economics. Here is one example of&nbsp;<a href=\"https://www.youtube.com/watch?v=i7HFl69i-i8\"><u>Juan\u2019s presentation for EA Lausanne</u></a> (featured in more detail in the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pqmQ9PxpzzGHshmhC/2022-allfed-highlights#Research\"><u>research</u></a> section above).</p><h2><strong>Events Attended</strong></h2><p>Our team attended a number of EAG events this year, including&nbsp;<a href=\"https://www.eaglobal.org/events/eagxoxford-2022/\"><u>EAGxOxford 2022</u></a>,&nbsp;<a href=\"https://www.eaglobal.org/events/ea-global-london-2022/\"><u>EA Global: London 2022</u></a><u>,&nbsp;</u><a href=\"https://www.eaglobal.org/events/eagxprague-2022/\"><u>EAGxPrague 2022</u></a>,&nbsp;<a href=\"https://www.eaglobal.org/events/eagxaustralia-2022/\"><u>EAGxAustralia 2022</u></a>,&nbsp;<a href=\"https://www.eaglobal.org/events/ea-global-san-francisco-2022/\"><u>EA Global: San Francisco 2022</u></a>,&nbsp;<a href=\"https://www.eaglobal.org/events/eagxsingapore-2022/\"><u>EAGxSingapore 2022</u></a>,&nbsp;<a href=\"https://www.eaglobal.org/events/eagxberlin-2022/\"><u>EAGxBerlin 2022</u></a><u>,&nbsp;</u><a href=\"https://www.eaglobal.org/events/ea-global-washington-d-c-2022/\"><u>EA Global: Washington, D.C. 2022</u></a>, and&nbsp;<a href=\"https://www.eaglobal.org/events/eagxvirtual-2022/\"><u>EAGxVirtual 2022</u></a>.&nbsp;</p><p>We also took part in multiple conferences and workshops, including:&nbsp;</p><ul><li><a href=\"https://www.icanw.org/tpnw_first_meeting_of_states_parties\"><u>First Meeting of States Parties to the Treaty on the Prohibition of Nuclear Weapons</u></a>,&nbsp;</li><li><a href=\"https://www.swissre.com/institute/conferences/insurance-development-forum-summit-2022.html#20220620\"><u>IDF Summit 2022</u></a>,&nbsp;</li><li><a href=\"https://forum.effectivealtruism.org/events/uLoiH2bgBj4ATG4vx/high-impact-medicine-speaker-event-on-nuclear-risk\"><u>High Impact Medicine Speaker Event on Nuclear Risk</u></a>,&nbsp;</li><li><a href=\"https://www.unep.org/resources/report/unep-workshop-achieving-environmental-sustainability-sustainable-development\"><u>UNEP workshop on Achieving environmental sustainability for sustainable development</u></a>.</li></ul><p>We always enjoy and appreciate CSER\u2019s events and workshops. This year, we took part in:</p><ul><li><a href=\"https://www.cser.ac.uk/events/cambridge-conference-catastrophic-risk-2022/\">CSER GCR Conference and Lightning Talks 2022</a>,</li><li><a href=\"https://www.cser.ac.uk/events/workshop-global-impacts-volcanic-eruptions-how-can/\"><u>CSER Workshop: Global impacts from volcanic eruptions</u></a>,</li><li><a href=\"https://www.cser.ac.uk/events/workshop-creative-communication-address-global-cat/\"><u>CSER Workshop: Creative communication to address global catastrophic risks</u></a>,</li><li><a href=\"https://www.cser.ac.uk/events/gcr-science-policy-interface-workshop-closed-event/\"><u>GCR-Science Policy Interface Workshop</u></a>.</li></ul><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/ovda1dptnuw7uah0rb5n.jpg\"><figcaption><i><strong>Carina Fearnley, Anders Sanberg, Rick Holland and Sonia Cassidy&nbsp; at CSER\u2019s \u201cCreative Communications\u201d Workshop. (Sept 2022, Cambridge, UK)</strong></i></figcaption></figure><h1><strong>Our Team</strong></h1><p>This year has seen significant changes to our team, with changes at Board and management levels and several new team members.&nbsp;</p><p>You can see our core team members at&nbsp;<a href=\"https://allfed.info/about/team-and-board\"><u>our website</u></a>.</p><h2><strong>Management&nbsp;</strong></h2><p>David Denkenberger, Sonia Cassidy, and Anders Sandberg have accepted additional appointments as the legal board of directors of the independent USA entity (due to our 501(c)(3) registration coming through).&nbsp;</p><p><i>At the same time, there has been a changing of the guard on our Board of Advisors:</i></p><ul><li>We welcomed&nbsp;<a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=296&amp;catid=10\"><u>Curtis Rodgers</u></a>, who brings with him a wealth of hands-on construction, engineering &amp; process improvement experience, having supported complex commercial, power, infrastructure, mining, and federal projects. Curtis\u2019s appointment reflects our growing interest in hands-on resilient foods projects, and specifically pilots and industrial foods.&nbsp;</li><li>We said goodbye to Gorm Shackelford, who has been with us since the very beginning of ALLFED (2017). We would like to take this opportunity to thank him for his five years of service.</li><li>We are looking for additional board members.</li></ul><p><i>There has been a further significant change at the management level, with Ray Taylor, ALLFED\u2019s second co-founder (alongside David Denkenberger) stepping back from ALLFED</i><strong>&nbsp;</strong>in order to pursue new projects. We would like to take this opportunity to thank Ray for all his contributions to ALLFED over many years (in addition to co-founding it in the first place!). While he has now moved on from ALLFED, we remain grateful for the many key team members whom he recruited over the years for us.</p><h2><strong>Opportunities</strong></h2><p><i>David Denkenberger will soon be starting an associate professor position at the University of Canterbury in New Zealand and is&nbsp;</i><a href=\"https://eahire.notion.site/eahire/Multiple-high-impact-PhD-student-positions-4f539332738a49cc8915aaa8731f9a3e\"><i><u>recruiting&nbsp;</u></i></a><i>for PhD students and a temporary researcher position.</i></p><h2><strong>Recruitment</strong></h2><p>Additionally, spring and summer of 2022 saw a major recruitment drive (largest in the history of ALLFED). It resulted in multiple appointments and several new roles across all areas of ALLFED, including 6 new Research Associates, a new Communications Associate, and 3 further roles within the operations team.&nbsp;</p><p>Throughout the recruitment process, we experimented with and tested new processes and procedures. One such innovation, for example, was inviting shortlisted Project Coordinator/Manager candidates to interview us early on in the process. In group calls, they were invited to ask any questions they wanted to formulate their assessment of ALLFED\u2019s project management maturity and whether we were a good organizational fit for them. Those who continued were then tasked with formulating recommendations for further improvements to our systems, based on the information they had obtained. Customary candidate interviews did not take place until the very last stage of the recruitment process (thus considerably cutting down the number of individual interviews).</p><p><i>Some Research Associate recruitment insights, which may be of interest to readers of the EA Forum, include the following highlights from our Research Associate recruitment:</i></p><ul><li>Stage 1: 196 candidates applied,&nbsp;</li><li>Stage 2: 120 candidates were invited to complete a research task,</li><li>Stage 3: 35 candidates were invited to to an interview,</li><li>Stage 4: 21 candidates were invited to do a paid work trial (including 5 internal candidates who were assessed according to the same criteria),</li><li>Stage 5: 15 candidates completed their work trial,</li><li>6 candidates were hired as Research Associates (3 of them previous volunteers),</li><li>1 Research Associate candidate was redirected at Stage 3 to apply for a different role within ALLFED (and was hired as a Communications Associate).</li></ul><p>We are especially pleased to have welcomed first team members from under-represented corners of the globe to our remote team (we now have a foothold in Africa and South America).&nbsp;</p><h2><strong>Interns &amp; Volunteers</strong></h2><p>Our internship program (launched last year) has matured, with 5 interns in 2022. This is a structured program, with a considerable amount of professional development.</p><p>We have had the largest ever number of volunteer applications, to the point of needing to revise our volunteer intake criteria half way through the year (we no longer accept applicants wishing to volunteer under 10 hours per week, unless they have particularly valuable expertise). Even so, we have so far welcomed 42 volunteers this year.</p><h2><strong>Team Events</strong></h2><p>This section would not be complete without a brief mention of team events. As a fully remote team, we take every opportunity to meet whenever we can. This year, we opted in favor of many smaller get-togethers rather than a big team retreat. Wherever we met, much fun was had by all. :)</p><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669901876/mirroredImages/pqmQ9PxpzzGHshmhC/w9ozsvkragxgxoauxgj7.png\"><figcaption><i><strong>Some of ALLFED\u2019s European team members enjoying&nbsp; a post-EAG London barbecue. (April 2022, London, UK)</strong></i></figcaption></figure><h1><strong>Funding Needs</strong></h1><p><i>ALLFED continues to be funding constrained.</i></p><p><i>The heightened geopolitical tensions from the 2022 Russo-Ukrainian conflict bring the urgency of our work to the forefront. Our research has the potential to be used as the basis for establishing the food system preparedness that is sorely lacking in the world today. Sufficient funding is essential if we are to be able to present to decision makers within the current policy window.</i><strong>&nbsp;</strong></p><ul><li><i>Further funding could be used for the integration of resilient foods with economics and various cooperation scenarios, feeding into more country level plans,&nbsp;which we estimate as ~5 FTE with support ($500,000).&nbsp;</i></li><li><i>We are looking for support to continue key priority research projects on the topic of&nbsp;</i><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S2212420922000176\"><i>resilient foods for nuclear winter-level shocks</i></a><i>, </i>including: simulation of the large scale relocation of cool-tolerant crops (the highest leverage food solution according to the above), in-depth analyses of greenhouse technology and seaweed for resilient food response, technology readiness level analysis looking to identify key resilient food tech gaps, and decentralized production of leaf protein concentrate. We estimate the funding needed as ~5 FTE with support ($500,000), including growing the team and hiring for this.&nbsp;</li><li><i>We are looking for funding to overhaul the more neglected line of research on interventions to increase resilience and response capabilities</i> to scenarios involving extreme, abrupt collapse of critical infrastructure (e.g.&nbsp;<a href=\"https://eujournalfuturesresearch.springeropen.com/articles/10.1186/s40309-021-00178-z\"><u>loss of electricity/industry</u></a>), including: covering immediate needs of population (i.e. water access at the onset), designing a resilient backup communication system which may be satellite-based and low-tech transportation systems, defining how an effective resilient food response to this scenario would look in this scenario, and developing the required methods and tool designs to achieve it. We estimate the funding needed as ~3 FTE with support ($300,000), including growing the team and hiring for this.&nbsp;</li><li><i>We have large room for more funding to further develop the most promising resilient foods in the GCR context.</i><strong>&nbsp;</strong>Pilots include repurposing a paper factory to produce food, fast construction of natural gas to protein factory, fast construction of an extruder for greenhouse covers, and fast construction of a rope twister for seaweed production.&nbsp;</li><li>The USA and the UK are currently ALLFED\u2019s main hubs. Having established an ALLFED 501(c)3 not-profit in the USA,&nbsp;<strong>we are now looking to establish an ALLFED UK charity.</strong> This will require its own dedicated funding.</li></ul><h1><strong>Our Thanks</strong></h1><p>We would like to take this opportunity to thank a number of individuals for their support of ALLFED this year.&nbsp;</p><p><i>Firstly, our thanks to ALLFED\u2019s many donors and collaborators for their ongoing support of ALLFED. It is your generosity that enables our work.&nbsp;</i></p><p><i>We would also like to thank our many partners and collaborators this year, in&nbsp;particular:</i></p><ul><li>Our thanks to the&nbsp;<a href=\"https://www.openphilanthropy.org/\"><u>Open Philanthropy</u></a> funded nuclear winter project, in particular Lili Xia and Jonas J\u00e4germeyr for help with crop modeling and Cheryl Harrison on ocean modeling and seaweed.</li><li>We are grateful to Julia Wise for her helpful comments and feedback.</li><li>We appreciate Tom Denkenwolf for his advice on asset allocation and investing.</li><li>We are thankful to Chris Landry of&nbsp;<a href=\"http://sigparser.com\"><u>SigParser</u></a> for his generosity and above-and-beyond support in boosting our contact management capabilities.&nbsp;</li><li>We thank&nbsp;<a href=\"http://angelotirotto.com\"><u>Angelo Tirotto</u></a>, our graphic designer, for making us look good, and in particular for his many late nights and the considerable time he volunteered towards creating our extended brand guidelines.</li><li>We are impressed with Philip Walton of&nbsp;<a href=\"https://www.softforge.co.uk/\"><u>Softforge</u></a> for superb website development and support, and zero unplanned downtime.</li></ul><p><i>This acknowledgement would not be complete without thanking our whole team for their ongoing work and commitment. We would like to in particular acknowledge:&nbsp;</i></p><ul><li><a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=17&amp;catid=10\">Allen Hundley</a>, our longest-standing volunteer (with us since 2016, before ALLFED was even founded!),&nbsp;</li><li><a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=34&amp;catid=10\">Anders Sandberg</a> and <a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=36&amp;catid=10\">Robin Hanson</a>, for their 5 years on ALLFED\u2019s Board of Advisors and still going strong,</li><li><a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=257&amp;catid=10\">Scott David</a>, also on our Board of Advisors, whose energy and enthusiasm for ALLFED make him one of our very best ambassadors. We highly appreciate our regular meetings on developing suitable impact indicators for ALLFED,</li><li><a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=304&amp;catid=10\">Greg Colburn</a>, for all his work on ALLFED\u2019s UK charity registration,&nbsp;</li><li><a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=24&amp;catid=10\">Juan Garc\u00eda Martinez</a>, our Research Coordinator, for being a star and also accepting a major responsibility of second-in-command of ALLFED\u2019s research,&nbsp;</li><li><a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=280&amp;catid=10\">Morgan Rivers</a> for his heroic effort on the integrated model of resilient foods and for independently securing $30K of funding (via&nbsp;<a href=\"https://astralcodexten.substack.com/p/acx-grants-results#:~:text=Morgan%20Rivers%2C%20%2430%2C000%2C%20to%20help%20ALLFED%20improve%20modeling%20of%20food%20security%20during%20global%20catastrophes\"><u>ACX Grant</u></a>&nbsp;grant),&nbsp;</li><li><a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=26&amp;catid=10\">Amanda Cassidy</a>, our CRM Manager, for her patience and dedication in restructuring and organizing all our contact data accumulated over 5 years of ALLFED (it has been a huge job),</li><li><a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=13&amp;catid=10\">David Denkenberger</a> for continuing to take a large negative salary for all his work.</li><li><a href=\"https://allfed.info/about/team-and-board?view=article&amp;id=16&amp;catid=10\">Sonia Cassidy</a>, for juggling more hats and commitments than anyone else at ALLFED. In her role of Director of Operations she is a tour de force of multitasking and getting things done, and deals with many of the toughest challenges at ALLFED. We also thank her for producing these annual highlights, in her role of Director of Communications.&nbsp;</li></ul><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxcexyvivruk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxcexyvivruk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Though we would like to see some of the artificial light food produced at the South Pole complemented with more efficient alternatives!</p></div></li></ol>", "user": {"username": "Ross_Tieman"}}, {"_id": "7Qup3sdLtXzfzurEK", "title": "What videos should Rational Animations make?", "postedAt": "2022-11-26T20:28:28.577Z", "htmlBody": "<p>I want to know what you would be excited to see covered on the channel.</p><p>I'd especially like to know what videos you think would be&nbsp;<i>optimal</i>&nbsp;to make according to an optimization target you specify. It's more effortful, but more useful, to answer that question instead of just \"what would be good video topics?\".</p><p>Answers that go the extra mile and explain their reasoning in detail will be especially appreciated.&nbsp;</p><p>That said, I also welcome answers to the easier question \"what would be good video topics?\" and without much argumentation.</p>", "user": {"username": "Writer"}}, {"_id": "EjaBuGDZqcQNxapKH", "title": "Why Advocacy for Children in Developed Countries Could be a Top Cause Area", "postedAt": "2022-11-27T05:40:40.903Z", "htmlBody": "<p>Children cannot advocate for themselves. They are typically not experienced in advocacy, do not have the resources and the knowledge to talk to governments, and when they possess that knowledge, society largely ignores them. At least in the United States, children are not taken seriously when they voice complaints.</p><p>The US has a variety of child unfriendly laws. As this video mentions (<a href=\"https://www.youtube.com/watch?v=E2i4oaRoaG0\">https://www.youtube.com/watch?v=E2i4oaRoaG0</a>), many US states allow spanking of kids in schools, and the rates are not low. Physical punishment in the household is also common and legal. While the rates are decreasing, many US kids still face physical punishment. This causes a lot of suffering and worse outcomes at a societal level. The vast majority of people care about children, but this issue has not been brought to the forefront of people\u2019s minds. The United States, in particular, lags behind other countries.</p><p>Right now there are many children in the US living in poverty, one of the highest rates of any developed country. There has been a history of advocacy to spend more government money on reducing the poverty rate of children, and it had moderate success. This issue has been talked about by prominent sources, such as Freakonomics (<a href=\"https://freakonomics.com/podcast/why-does-the-richest-country-in-the-world-have-so-many-poor-kids/\">https://freakonomics.com/podcast/why-does-the-richest-country-in-the-world-have-so-many-poor-kids/</a>). &nbsp;There have been some attempts to pass bills featuring re-distribution targeting children, such as the Build Back Better act. It has traction inside the federal government. However, it has not yet succeeded.</p><p>Because of existing support, I think the issue is extremely tractable. It is not as neglected as other issues, but the fact that children are unable to vote is a big issue. Children are not listened to and don\u2019t have their preferences respected in the US, so other voices need to speak for them. Neglect is the result, as people forget about their childhood and stop caring.</p><p>This issue is important. The financial and wellbeing return of good upbringing is well documented. Poverty and physical abuse can be traumatic, and 18 years of relative suffering is a big deal. EA could fund advocacy in this space, and it is likely that reform could easily be pushed over the finishing line. We all know we played the birth lottery. Those of us in rich countries had a much healthier and happier life, on average. But the disparity within some rich countries is still substantial.</p><p>I think the lack of adult voices taking children\u2019s issues seriously is a big problem. Children face many problems in the US and other developed countries, and their complaints are largely ignored and glossed over. Countries like the Netherlands where children are taken seriously have some of the happiest children, and I think 18 years of happiness has large moral value. Not being physically abused and not living in poverty seem like very important aspects of living a happy childhood. There are some issues with children that are seeing attention already, such as mental health problems. However, investment in advocacy for children\u2019s happiness and wellbeing seems very neglected.</p>", "user": {"username": "Skye Nygaard"}}, {"_id": "AtLTqaHEcMPFnworf", "title": "Respecting your Local Preferences", "postedAt": "2022-11-26T19:04:14.523Z", "htmlBody": "", "user": {"username": "Scott Garrabrant"}}, {"_id": "pQs6bAq4BJbHDpSYb", "title": "Democratizing the workplace as a cause area", "postedAt": "2022-11-26T18:31:58.690Z", "htmlBody": "<h2>Introduction</h2><p>It is an EA proverb that people spend 80,000 hours of their life at work.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcbbhu8wq8k9\"><sup><a href=\"#fncbbhu8wq8k9\">[1]</a></sup></span>&nbsp;That's a lot of time where people could be happy and inventive, or miserable and unproductive. However, sixty percent of people reported being emotionally detached at work and 19% as being miserable. Only 33% reported feeling engaged. In the U.S. specifically, 50% of workers reported feeling stressed at their jobs on a daily basis, 41% as being worried, 22% as sad, and 18% angry.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8d8ypkth7f8\"><sup><a href=\"#fn8d8ypkth7f8\">[2]</a></sup></span>&nbsp;This is not only terrible for the workers but also for the economy, since businesses with engaged workers have 23% higher profit, while employees who are not engaged cost the world $7.8 trillion in lost productivity, equal to 11% of global GDP.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefs6989q9fhj\"><sup><a href=\"#fns6989q9fhj\">[3]</a></sup></span>&nbsp;Therefore, interventions that improve the workplace have the potential to alleviate a lot of misery.</p><p>When society went from hierarchical political structures to more democratic ones, it resulted in the populace gaining much more rights and liberties than before.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefc6lkrj38yhc\"><sup><a href=\"#fnc6lkrj38yhc\">[4]</a></sup></span>&nbsp;Yet in our everyday workplace we work in hierarchical structures that are much more authoritarian than we would ever accept from our government. If our governments tried to implement a system where the leaders had to face as little accountability to their underlings, while gaining as much monitoring and control as managers have, we would consider it a violation of our rights. While getting a job might be voluntary, everyone needs the resources and social status that jobs provide, so most people put up with the boring and repetitive work.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefc6j4anq502s\"><sup><a href=\"#fnc6j4anq502s\">[5]</a></sup></span><br>There is an economic incentive for owners and managers to ensure the highest possible pay for themselves while establishing the lowest possible pay for their workers. Not to mention that employees don\u2019t get a say in who gets hired or fired, despite it having a huge effect on their lives. No wonder then that employees don't trust their companies and 75% of employees say they quit their boss, not their job.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxjzv0oz9psn\"><sup><a href=\"#fnxjzv0oz9psn\">[6]</a></sup></span></p><p>Is there an alternative? Could we perhaps run a workplace democratically? Would that improve employee welfare? Would those firms become less productive? Has this been successfully done before? Let's take a look at the literature.</p><p>&nbsp;</p><h2>What does it mean to run a workplace democratically?</h2><p>The idea is simple: Instead of the owner of the firm deciding who manages the workers, the workers become part owner and get a say in how the firm is run. There are a couple ways this could be achieved but this post will primarily focus on one well-known example: <a href=\"https://en.wikipedia.org/wiki/Worker_cooperative\">worker cooperatives</a>. Let's look at what the literature indicates as the benefits of democratizing the workplace:</p><ol><li>Less inequality within firms<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4g1x2q116iv\"><sup><a href=\"#fn4g1x2q116iv\">[7]</a></sup></span></li><li>Less workers leaving the workplace<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefen4x9ra97vr\"><sup><a href=\"#fnen4x9ra97vr\">[8]</a></sup></span>&nbsp;either voluntarily<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbn08j5v45r\"><sup><a href=\"#fnbn08j5v45r\">[9]</a></sup></span>&nbsp;or involuntarily<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefljtbbg3542\"><sup><a href=\"#fnljtbbg3542\">[10]</a></sup></span></li><li>Workers put in more effort<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9mkvh06s3dp\"><sup><a href=\"#fn9mkvh06s3dp\">[11]</a></sup></span></li><li>Similar levels of productivity as conventional firms<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcu7tfgsxkk\"><sup><a href=\"#fncu7tfgsxkk\">[12]</a></sup></span></li><li>Similar levels of investments as conventional firms<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgrp4dqaocyg\"><sup><a href=\"#fngrp4dqaocyg\">[13]</a></sup></span></li><li>Workers report increased levels of trust<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9hyazk1aqcl\"><sup><a href=\"#fn9hyazk1aqcl\">[14]</a></sup></span></li><li>Lower rates of business failure<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmr4fnih0lxb\"><sup><a href=\"#fnmr4fnih0lxb\">[15]</a></sup></span></li></ol><p>There is also evidence that worker cooperatives pay their employees more than conventional firms, but only in certain circumstances. I will return to this phenomenon later. I will not be looking at other types of cooperatives like <a href=\"https://en.wikipedia.org/wiki/Consumers%27_co-operative\">consumer cooperatives</a>, producer cooperatives and purchasing cooperatives. This limits the scope of the literature because while 800 million people are employed by cooperatives<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffwgjk3npnct\"><sup><a href=\"#fnfwgjk3npnct\">[16]</a></sup></span>, only 100 million are employed by worker cooperatives.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0tcjc55awqz\"><sup><a href=\"#fn0tcjc55awqz\">[17]</a></sup></span>&nbsp;When I use the word co-op in this post, assume I mean worker cooperative unless specified otherwise.</p><p>&nbsp;</p><h2>Do Co-ops work?</h2><p>You might be asking yourself: Won't workers stop putting in as much effort into a collectively owned enterprise since the output is shared with their colleagues, which means they only get a small proportion of the fruits of their individual labor? According to the the <a href=\"https://en.wikipedia.org/wiki/Free-rider_problem\">free-rider hypothesis</a>, rational and self-interested agents will always have an incentive to put in less effort and be a parasite of the efforts of others.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5n4c3kzwa4\"><sup><a href=\"#fn5n4c3kzwa4\">[18]</a></sup></span>&nbsp;The business will inevitably go under as people realize that they will gain the most from shirking their responsibilities. The economist <a href=\"https://en.wikipedia.org/wiki/Amartya_Sen\">Amartya Sen</a> once called the people depicted in these models \"rational fools\".</p><blockquote><p>&nbsp;In the case of the free rider hypothesis, these 'rational fools' act based on such a narrow conception of self-interest that they don't take into account the obviously damaging long-term consequences of their behavior, both to the firm and ultimately to themselves. Normal, reasonable people - <a href=\"https://en.wikipedia.org/wiki/Behavioral_economics\">who are different to rational economic man</a> - are usually happy to put efforts into a collective endeavor that will deliver benefits for them in the long run, even if that means foregoing some short-term gains. Cooperation in worker democracies can be a challenge and a few people will try to free ride, but evidence illustrates this problem rarely becomes so bad it affects the performance of the workers and the firm&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvsw0bsgazeo\"><sup><a href=\"#fnvsw0bsgazeo\">[19]</a></sup></span>&nbsp;</p><p>Experiments have shown that people randomly allocated to do tasks in groups where they can elect their leaders and/or choose their pay structures are more productive than those who are led by an unelected manager who makes pay choices for them.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefa64t6uxc76\"><sup><a href=\"#fna64t6uxc76\">[20]</a></sup></span>&nbsp;One study looked at real firms with high levels of worker ownership of shares in the company and found that workers are keener to monitor others, making them more productive than those with low or no ownership of shares and directly contradicting the free rider hypothesis.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgio7cutvaqc\"><sup><a href=\"#fngio7cutvaqc\">[21]</a></sup></span>&nbsp;It turns out there are potential benefits to giving workers control and a stake in the running of the organization they work for. This allows workers to play a key role in decision making and reorient the goals of the organization.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjtycaz65t9j\"><sup><a href=\"#fnjtycaz65t9j\">[22]</a></sup></span></p></blockquote><p>One explanation for this phenomenon is that of \"<a href=\"https://en.wikipedia.org/wiki/Local_knowledge_problem\">localized knowledge</a>\". According to economist <a href=\"https://en.wikipedia.org/wiki/Friedrich_Hayek\">Friedrich Hayek</a>, top-down organizers have difficulty harnessing and coordinating around <i>local knowledge</i>, and the policies they write that are the same across a wide range of circumstances don't account for the \"particular circumstances of time and place\".<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbvvc1hveotg\"><sup><a href=\"#fnbvvc1hveotg\">[23]</a></sup></span>&nbsp;(For examples of this, read<i> </i><a href=\"https://slatestarcodex.com/2017/03/16/book-review-seeing-like-a-state/\"><i>Seeing Like a State</i></a> by political scientist <a href=\"https://en.wikipedia.org/wiki/James_C._Scott\">James Scott</a>) Those who make the top-down policies in a traditional company are different to those who have to follow them. In addition, those who manage the company are most often different to those who own the company. These groups have different incentives and accumulate different knowledge. This means that co-ops have two main advantages:</p><ol><li>Workers can harness their collective knowledge to make running the firm more effective.</li><li>Workers can use their voting power to ensure the organization is more aligned with their values.</li></ol><p>Interestingly enough, I have yet to come across a co-op that uses the state of the art of <a href=\"https://en.wikipedia.org/wiki/Social_choice_theory\">social choice theory</a>, so they could potentially get a lot lot better.</p><p>&nbsp;</p><h2>Potential problems with Co-ops</h2><p>One potential problem with the literature on co-ops is that it might be suffering from <a href=\"https://en.wikipedia.org/wiki/Sampling_(statistics)\">selection bias</a>. In other words, they might not accurately represent the attributes of co-ops in general because the sample size is so small. For example: some sectors have more co-ops than others. One study found that co-ops have a better survival rate than conventional firms in the service sector, but the same in other sectors.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefr6y8bpjy12f\"><sup><a href=\"#fnr6y8bpjy12f\">[24]</a></sup></span>&nbsp;Co-ops may disproportionally start in sectors where they are more likely to succeed.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3ebdxi9jjgk\"><sup><a href=\"#fn3ebdxi9jjgk\">[25]</a></sup></span>&nbsp;and people who start co-ops tend to be more motivated than the average worker.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefm08fj29y8cn\"><sup><a href=\"#fnm08fj29y8cn\">[26]</a></sup></span><br>It might be that if we force people to change their firm to a co-op they are less motivated to make it work. We should probably focus on making it easier for people to transition to- or start a new- co-op voluntarily.<br>One issue that arises with starting a co-op is acquiring initial investing.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaamhw3ztmp9\"><sup><a href=\"#fnaamhw3ztmp9\">[27]</a></sup></span>&nbsp;This is probably because co-ops want to maximize income (wages), not profits. They pursue&nbsp;the interests of their members rather than investors and may sometimes opt to increase wages instead of profits. Conventional firms on the other hand are explicitly investor owned&nbsp;so investor interests will take priority.<br>Many co-ops opt instead to rely on member contributions, which can be thousands of dollars. Economist and content-creator <a href=\"https://unlearnecon.medium.com/\">Unlearning economics</a> describes the problem that arises:</p><blockquote><p>If co-ops are set up in lower income communities they may have trouble obtaining financing, but if they exclude these communities then they're going to be a bit of a middle class thing&nbsp;excluding the people who arguably need them most.<br>The most obvious policy to help co-ops finance&nbsp;themselves would be direct grants and loans from local and national governments, as well as other&nbsp;financial incentives such as tax breaks, which play a big role in Uruguay. Not only&nbsp;could these be expanded, but the information about how to access them could be more widespread as&nbsp;currently what's available isn't always taken up. One example is the under-utilised Local Enterprise&nbsp;Assistance Fund or 'LEAF' in the USA, which offers credit to co-ops but gets few applications, even fewer of which are credible.</p><p>There are also a number of innovative ways people have got around&nbsp;the financing problem without direct state support. One option is to allow external shareholders who&nbsp;receive dividends but have partial or no voting rights, keeping the control in the hands of the&nbsp;workers. The successful US co-op Equal Exchange has provided these so-called Class B shareholders&nbsp;with annual dividends for more than 20 years. (The Class A Shareholders are the workers). In some&nbsp;cases financial institutions are also established as part of a concerted effort by a community&nbsp;to establish a democratic economy.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrv6rviybzvk\"><sup><a href=\"#fnrv6rviybzvk\">[28]</a></sup></span></p></blockquote><p>Another avenue would be to get funding from credit unions, which are consumer co-ops. Having an economy with different types of co-ops could become crucial in making sure it can sustain itself longterm.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref080pzqkhm0dp\"><sup><a href=\"#fn080pzqkhm0dp\">[29]</a></sup></span>&nbsp;Co-ops tend to perform better with other co-ops around.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjl53heizum\"><sup><a href=\"#fnjl53heizum\">[30]</a></sup></span>&nbsp;So it seems like starting a culture of co-ops is hard, but once you get co-op leagues started it becomes easy to sustain.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefy829dhfdkl\"><sup><a href=\"#fny829dhfdkl\">[31]</a></sup></span>&nbsp;Ex-youtuber <a href=\"https://www.youtube.com/@RoseWrist\">Rose Wrist</a> made an outline of some different types of co-ops:</p><ol><li>Complete Autonomous Cooperatives<ol><li>These firms operate with either direct or representative democracy</li><li>These firms are completely owned by the workers at the firm<ol><li>No external shareholders</li></ol></li></ol></li><li>Autonomous Cooperatives<ol><li>These firms operate with either direct or representative democracy</li><li>These firms are majority owned by the workers at the firm<ol><li>External shareholder do not hold voting shares</li></ol></li></ol></li><li>Majority Cooperatives<ol><li>These firms operate with either direct or representative democracy</li><li>These firms are majority owned by the workers at the firm<ol><li>Some external shareholders may hold non-controlling voting shares</li></ol></li></ol></li><li>ESOP (Employee Stock Ownership) Firms (Not a co-op)<ol><li>These firms may be operated in any way</li><li>The workers at these firms all own some part of the company<ol><li>External shareholders may hold controlling voting shares</li></ol></li></ol></li></ol><p>He <a href=\"https://docs.google.com/document/d/1ScS39TWXcPkGOpek4tAfp0rAD5usbwIA05pbqVQdO6g/edit#\">identified</a> some unconventional ways each of these could get funding<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefujn7rentpu\"><sup><a href=\"#fnujn7rentpu\">[32]</a></sup></span>:</p><figure class=\"image image_resized\" style=\"width:68.96%\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669679151/mirroredImages/pQs6bAq4BJbHDpSYb/ygael9zpscjf56dgktfn.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2261e2bfceb4ff024b7480b2899120350edc2db6e33fbab4.png/w_122 122w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2261e2bfceb4ff024b7480b2899120350edc2db6e33fbab4.png/w_202 202w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2261e2bfceb4ff024b7480b2899120350edc2db6e33fbab4.png/w_282 282w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2261e2bfceb4ff024b7480b2899120350edc2db6e33fbab4.png/w_362 362w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2261e2bfceb4ff024b7480b2899120350edc2db6e33fbab4.png/w_442 442w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2261e2bfceb4ff024b7480b2899120350edc2db6e33fbab4.png/w_522 522w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2261e2bfceb4ff024b7480b2899120350edc2db6e33fbab4.png/w_602 602w\"></figure><p>&nbsp;</p><h2>Are Co-ops good for employees?</h2><p>One problem with modern firms that I already mentioned is how disconnected employees are from their work. There's already a <a href=\"https://forum.effectivealtruism.org/posts/KqffgESkpTQBeqaWy/cause-exploration-prizes-can-purpose-in-life-be-a-simple#The_Problem_\">great post about how important meaning is in someone's life</a> so I won't go into too much detail. Suffice to say that a better working environment would alleviate this problem.<br>Giving employees stock in a company seems to boost their performance.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq2062jg9xu\"><sup><a href=\"#fnq2062jg9xu\">[33]</a></sup></span>&nbsp;Research has shown that employees getting more ownership of the company is associated with higher trust, perception of fairness, information sharing and cooperation.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7mgvetgwspv\"><sup><a href=\"#fn7mgvetgwspv\">[34]</a></sup></span>&nbsp;There seems to be a small increase in companywide productivity<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq2062jg9xu\"><sup><a href=\"#fnq2062jg9xu\">[33]</a></sup></span>, while employee retention is boosted.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnlgih4in2ml\"><sup><a href=\"#fnnlgih4in2ml\">[35]</a></sup></span>&nbsp;Perhaps traditional firms could slowly be eased into becoming co-ops by first giving the employees <a href=\"https://www.theguardian.com/politics/2018/sep/23/labour-private-sector-employee-ownership-plan-john-mcdonnell?utm_source=pocket_mylist\">more stakes</a> in the company and then expanding their participation rights.</p><p>While the average employee makes more in a co-op, those at the top may earn less. Similarly, switching to a co-op gives the average employee higher pay, but not those at the top. This could potentially lead to a brain drain.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4g1x2q116iv\"><sup><a href=\"#fn4g1x2q116iv\">[7]</a></sup></span>&nbsp;Even if we made every firm a co-op, there would still be inequality between firms, so top earners might shift to a couple of high paying co-ops. When there is an economic downturn co-ops also tend to lower wages instead of firing people, which is once again great for the average worker but not for the top earners.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4ywxergegse\"><sup><a href=\"#fn4ywxergegse\">[36]</a></sup></span>&nbsp;Volatile pay probably explains why some studies show that co-ops pay less.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2pxpnie9gco\"><sup><a href=\"#fn2pxpnie9gco\">[37]</a></sup></span>&nbsp;But while getting payed less in a recession still sucks, it is preferable to getting fired. This will also have a positive effect on the family members of employees, since they also suffer when said employees are fired.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzuisknyyy5p\"><sup><a href=\"#fnzuisknyyy5p\">[38]</a></sup></span></p><p>&nbsp;</p><h2>Conclusion and policies</h2><p>Cooperative firms are a powerful tool to improve the lives of the workforce. They reduce inequality within firms while maintaining similar (or even higher) levels of productivity as conventional firms. They improve the wage and mental health of the average worker while reducing the turnover rate. They are more resilient than conventional firms and make employees more connected with, and work harder for, their workplace.</p><p>They probably won't slow down the rise of global inequality since inequality between firms is still possible. Co-ops may also be more risk averse since the workers livelihoods are strongly tied to the performance of the firm, which might lead to less innovation. One way co-ops can still be bad for it's workers is if firms only hire workers for a short time and fire them before they get their vote. To prevent this governments will have to shore up their worker protection laws.</p><p>To incentivize the creation of co-ops, governments can draft legislation to make it easier (and give tax incentives) for owners to turn their firm into a co-op. The government can also give loans to employees who want to buy firms from the owners or give preferential purchasing rights for employees of a firm that is facing closure/sale. These policies are good for co-ops because they bypass the difficulty of finding initial funding. The costs to the government can be recouped by lower mental healthcare costs and reduced need for government redistribution programs (especially during economic downturns). If the literature is correct and co-ops are indeed more productive than conventional firms it could also be seen as an investment into creating an economy that generates more tax revenue.</p><p>Once more co-ops get created it will also become easier to start cooperative leagues, which aid in the creation of new co-ops. Due to vertical integration they might also be able to counteract a brain drain. More importantly, they facilitate the acquisition of equity through economies of scale which gives cooperatives more capital to fall back on. This could mitigate or eliminate the (unproven) risk aversion of co-ops.</p><p>Given the recent <a href=\"https://forum.effectivealtruism.org/posts/Et7oPMu6czhEd8ExW/why-you-re-not-hearing-as-much-from-ea-orgs-as-you-d-like\">discussion</a> surrounding the structuring and transparency of EA organizations, perhaps the community could consider turning their EA organizations into co-ops. Not only would this grant all the advantages mentioned in this post, it would also have two additional advantages:</p><ol><li>It spreads the word about co-ops, making them less obscure in the collective consciousness</li><li>It would allow us to study them closely which:<ol><li>Allows us to be able to draft more pointed legislation which can capitalize on their benefits while mitigating their limitations</li><li>Allows us to find ways in which they can be improved</li></ol></li></ol><p>&nbsp;</p><h2>References</h2><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncbbhu8wq8k9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcbbhu8wq8k9\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://80000hours.org/start-here/\">80000hours.org/start-here</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8d8ypkth7f8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8d8ypkth7f8\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.gallup.com/workplace/349484/state-of-the-global-workplace.aspx?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=gallup_access_branded&amp;utm_term=&amp;gclid=Cj0KCQjw54iXBhCXARIsADWpsG-dvSXXa2CHuDpQAysF3ES20y1fYBEQb3EycTtImjIUtnsDfi7I5lYaAsPtEALw_wcB\">gallup.com/workplace/349484/state-of-the-global-workplace.aspx?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=gallup_access_branded&amp;utm_term=&amp;gclid=Cj0KCQjw54iXBhCXARIsADWpsG-dvSXXa2CHuDpQAysF3ES20y1fYBEQb3EycTtImjIUtnsDfi7I5lYaAsPtEALw_wcB</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fns6989q9fhj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefs6989q9fhj\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.gallup.com/workplace/321725/gallup-q12-meta-analysis-report.aspx\">https://www.gallup.com/workplace/321725/gallup-q12-meta-analysis-report.aspx</a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnc6lkrj38yhc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefc6lkrj38yhc\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://ourworldindata.org/democracy\">ourworldindata.org/democracy</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnc6j4anq502s\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefc6j4anq502s\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.forbes.com/sites/jackkelly/2019/10/25/more-than-half-of-us-workers-are-unhappy-in-their-jobs-heres-why-and-what-needs-to-be-done-now/\">https://www.forbes.com/sites/jackkelly/2019/10/25/more-than-half-of-us-workers-are-unhappy-in-their-jobs-heres-why-and-what-needs-to-be-done-now/</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxjzv0oz9psn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxjzv0oz9psn\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://seedscientific.com/job-satisfaction-statistics/\">https://seedscientific.com/job-satisfaction-statistics/</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4g1x2q116iv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4g1x2q116iv\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.iza.org/publications/dp/7854/equality-under-threat-by-the-talented-evidence-from-worker-managed-firms\">Equality Under Threat by The Talented: Evidence From Worker-Managed Firms, Burd\u00edn</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnen4x9ra97vr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefen4x9ra97vr\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://journals.sagepub.com/doi/10.1177/001979390606000102\">Wages, Employment, And Capital in Capitalist and Worker-Owned Firms, Pencavel et al&nbsp;</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbn08j5v45r\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbn08j5v45r\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://scholar.harvard.edu/files/freeman/files/do_broad-based_ee-profit-sharing-so_help_best_firms_do_even_better_bjir-final-ms_5-10-15.pdf\">Do Broad-based Employee Ownership, Profit Sharing and Stock Options Help the Best Firms Do Even Better?, Blasi et al</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnljtbbg3542\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefljtbbg3542\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The empirical performance of orthodox models of the firm: Conventional firms and worker cooperatives, Pencavel &amp; Craig&nbsp;</p><p>New evidence on wages and employment in worker cooperatives compared with capitalist firms, Burd\u00edn &amp; Dean&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9mkvh06s3dp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9mkvh06s3dp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Employee Vs. Conventionally Owned and Controlled Firms: An Experimental Analysis, Frohlich et al&nbsp;<br>Workplace Democracy in the Lab, Mellizo et al&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncu7tfgsxkk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcu7tfgsxkk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Productivity, Capital and Labor in Labor-Managed and Conventional Firms, FakhFakh et al&nbsp;<br>Are Cooperatives More Productive Than Investor-Owned Firms? Cross-Industry Evidence From Portugal, Monteiro &amp; Straume&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngrp4dqaocyg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgrp4dqaocyg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Shadow price of capital and the Furubotn\u2013Pejovich effect: Some empirical evidence for Italian wine cooperatives, Maietta &amp; Sena&nbsp;<br>Productivity, Capital and Labor in Labor-Managed and Conventional Firms, FakhFakh et al&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9hyazk1aqcl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9hyazk1aqcl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Do cooperative enterprises create social trust?, Sabatini et al&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmr4fnih0lxb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmr4fnih0lxb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Survival Rate of Co-operatives in Qu\u00e9bec, OCA</p><p>Co-op Survival Rates in Alberta, Stringham &amp; Lee</p><p>Co-op Survival Rates in British Columbia, Murray</p><p>The Relative Survival of Worker Cooperatives and Barriers to Their Creation, Olsen</p><p>Scale, Scope and Survival: A Comparison of Cooperative and Capitalist Modes of Production, Monteiro &amp; Stewart&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfwgjk3npnct\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffwgjk3npnct\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Trust, Inequality and The Size of The Co-Operative Sector: Cross-Country Evidence, Jones &amp; Kalmi&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0tcjc55awqz\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0tcjc55awqz\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Productivity in cooperatives and worker-owned enterprises, Logue &amp; Yates&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5n4c3kzwa4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5n4c3kzwa4\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://en.wikipedia.org/wiki/Free-rider_problem\">https://en.wikipedia.org/wiki/Free-rider_problem</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvsw0bsgazeo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvsw0bsgazeo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Employee Vs. Conventionally Owned and Controlled Firms: An Experimental Analysis, Frohlich et al&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fna64t6uxc76\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefa64t6uxc76\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Workplace Democracy in the Lab, Mellizo et al&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngio7cutvaqc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgio7cutvaqc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Shared Capitalism at Work: Employee Ownership, Profit and Gain Sharing, and Broad-based Stock Options, Kruse et al&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjtycaz65t9j\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjtycaz65t9j\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Productivity, Capital and Labor in Labor-Managed and Conventional Firms, FakhFakh et al&nbsp;<br>Quote comes from <a href=\"https://www.youtube.com/watch?v=yZHYiz60R5Q&amp;ab_channel=UnlearningEconomics\">this unlearning economics video</a>, which was the basis for this blogpost.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbvvc1hveotg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbvvc1hveotg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The Use of Knowledge in Society, Hayek</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnr6y8bpjy12f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefr6y8bpjy12f\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://journals.sagepub.com/doi/abs/10.1177/001979391406700108\">Are Worker-Managed Firms More Likely to Fail than Conventional Enterprises? Evidence from Uruguay -Burdin</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3ebdxi9jjgk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3ebdxi9jjgk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Worker Cooperatives: Pathways to Scale, Abell</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnm08fj29y8cn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefm08fj29y8cn\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.youtube.com/watch?v=z7n52oyRUVI&amp;ab_channel=LonerBox\">Capitalism and Worker Co-ops (With a Response to Vaush), by LonerBox</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaamhw3ztmp9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaamhw3ztmp9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Survival Rate of Co-operatives in Qu\u00e9bec, OCA</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrv6rviybzvk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrv6rviybzvk\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.youtube.com/watch?v=yZHYiz60R5Q&amp;ab_channel=UnlearningEconomics\">Worker Democracy, by Unlearning Economics</a> this post could be seen as an adaptation of that video</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn080pzqkhm0dp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref080pzqkhm0dp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Productivity in cooperatives and worker-owned enterprises, Logue &amp; Yates p20</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjl53heizum\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjl53heizum\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://resources.uwcc.wisc.edu/community%20development/Alberta%20Co-op%20Survival.pdf\">Co-op Survival Rates in Alberta, Richard Stringham et al</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fny829dhfdkl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefy829dhfdkl\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0167268108000802\">Endogenous formation of coops and cooperative leagues,</a> <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0167268108000802#!\">Sumit Joshi et al</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnujn7rentpu\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefujn7rentpu\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://docs.google.com/document/d/1ScS39TWXcPkGOpek4tAfp0rAD5usbwIA05pbqVQdO6g/edit#\">Analysing the Values and Limitations of Cooperative Firms</a> by Rose Wrist</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq2062jg9xu\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq2062jg9xu\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Employee ownership and firm performance: a meta-analysis, Boyle et al</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7mgvetgwspv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7mgvetgwspv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Do Broad-based Employee Ownership, Profit Sharing and Stock Options Help the Best Firms Do Even Better?, Blasi et al</p><p><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0165176514001980\"><u>Causal linkages between work and life satisfaction and their determinants in a structural VAR approach Coad et al</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnlgih4in2ml\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnlgih4in2ml\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.emerald.com/insight/content/doi/10.1016/S0885-3339(04)08001-9/full/html\">DOES EMPLOYEE OWNERSHIP ENHANCE FIRM SURVIVAL?</a>, <a href=\"https://www.emerald.com/insight/search?q=Rhokeun%20Park\"><u>Rhokeun Park et al</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4ywxergegse\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4ywxergegse\">^</a></strong></sup></span><div class=\"footnote-content\"><p>New evidence on wages and employment in worker cooperatives compared with capitalist firms, Burd\u00edn &amp; Dean</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2pxpnie9gco\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2pxpnie9gco\">^</a></strong></sup></span><div class=\"footnote-content\"><p>What do we really know about worker co-operatives?, P\u00e9rotin</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzuisknyyy5p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzuisknyyy5p\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.sciencedirect.com/science/article/pii/S2667193X22002083\">COVID-19-related financial strain and adolescent mental health</a>, Stirling T. Argabrigh et al</p></div></li></ol><h2>Afterword</h2><p>Some of you probably noticed that I didn't use the word \"socialist firm\" or \"capitalist firm\" in this post. In my experience, EA's can be quite negative towards socialism, so I thought it best to avoid the word lest I lose my karma. (If you disagree with my assessment, or need some examples before you believe me, feel free to message me). I don't even blame the capitalists on this forum, it's the karma-systems fault.<br>Since there was an initial majority of capitalists they had an easier time accumulating voting power, while socialists were disproportionally downvoted. The same thing would have happened in reverse if the socialists had held the initial majority. To illustrate, let's get away from the tribal mindset and show that this is not even a politics thing.</p><p>Right now this is an English speaking forum and thus non-english posters/posts have more difficulty accumulating votes. This affects the people that are attracted to the forum, which increases the initial majority. Imagine what would have happened if the initial majority were Spanish speakers. We might have had a Spain tag instead of a tag for the <a href=\"https://forum.effectivealtruism.org/topics/united-kingdom\">UK</a> and the <a href=\"https://forum.effectivealtruism.org/topics/united-states\">US</a>, and we might have had a \"Mexico policy\" tag instead of only a tag for <a href=\"https://forum.effectivealtruism.org/topics/uk-policy\">UK policy</a> and <a href=\"https://forum.effectivealtruism.org/topics/us-policy\">US policy</a>. It would probably have been a Spanish language forum with more references to Latin-American culture. The forum doesn't become Spanish because Spanish is a more rational language than English, it becomes Spanish because Spanish speakers get more votes on their posts which gives them more voting power which creates a feedback loop. (And that's without getting in-group biases involved)<br>If we want to counteract groupthink I propose we make the karma system more democratic. After all, isn't this forum kind of a workplace?</p>", "user": {"username": "bmjacobs@telenet.be"}}, {"_id": "TB3KrvpcRCDSEffcQ", "title": "What Is the Total Global Capability for Suffering and Joy? A Call for a Collaborative EA Project", "postedAt": "2022-11-26T12:42:07.572Z", "htmlBody": "<p>The composition of the biosphere is a fundamental question in biology - how much do we have of anything?&nbsp;</p><p>Yet for most of the history of biology, no global estimation of the biomass of organisms existed. Only in 2018, a paper was published that estimated the global biomass of different taxa (groups of organisms) [1]. The results are nicely summed up in figure 1 in the paper.&nbsp;</p><p><strong>I am convinced a similar project should be done for the neural mass, and capability for well-being, on Earth.</strong> My guess is that well-being capability should be explored through intelligence, as the capability for well-being is probably highly correlated to information processing, i.e. intelligence. We know that neuro-mass is not highly correlated with intelligence [2] (think of a human and an elephant), and thus I will guess it is not highly correlated with well-being capability. On the contrary, there are other measurable factors, such as cortical neurons and neuron packing density, that are known to affect general information processing capacity [2], and are known for at least some animals.</p><p><strong>This project will be a milestone in cause prioritization &amp; resource allocation, as it will allow us to understand which groups of creatures have the largest capability for suffering and joy on Earth. For example, think of the implication of a finding that non-human organisms have a global 10x well-being capability, or vice versa.</strong>&nbsp;</p><p>&nbsp;</p><p>I myself only have high-school education and little free time, so unfortunately I don\u2019t think I\u2019ll be able to provide a lot of help with the project. But I\u2019m sure it could be done!</p><p>Also, I suppose this idea could be a decent idea for scientific paper.</p><p>References:&nbsp;</p><p>1 - Bar-On, Y. M., Phillips, R., &amp; Milo, R. (2018). The biomass distribution on Earth.&nbsp;<i>Proceedings of the National Academy of Sciences</i>,&nbsp;<i>115</i>(25), 6506\u20136511.&nbsp;<a href=\"https://doi.org/10.1073/pnas.1711842115\"><u>https://doi.org/10.1073/pnas.1711842115</u></a></p><p><br>2 - Dicke, U., &amp; Roth, G. (2016). Neuronal factors determining high intelligence.&nbsp;<i>Philosophical Transactions of the Royal Society B: Biological Sciences</i>,&nbsp;<i>371</i>(1685), 20150180. https://doi.org/10.1098/rstb.2015.0180<br>&nbsp;</p>", "user": {"username": "alamo 2914"}}, {"_id": "v36RCwFqqEFZvx4RP", "title": "Success Maximization: An Alternative to Expected Utility Theory and a Generalization of Maxipok to Moral Uncertainty", "postedAt": "2022-11-26T01:53:17.551Z", "htmlBody": "<p>Standard expected utility theory (EUT) assumes moral certainty, but also embeds epistemic/ontological uncertainty about the state of the world that may occur as a result of our actions. Harsanyi expected utility theory (HEUT) allows us to assign probabilities to our potential moral viewpoints, and thus gives us a mechanism by which to handle moral uncertainty.</p><p>Unfortunately, there are several problems with EUT and HEUT. First, the St. Petersburg paradox shows that unbounded utility valuations can justify almost any action, even if the probability of a good outcome is almost zero. For example, a banker may be in a situation where the probability of a bank run is nearly one, but because potential returns of being overleveraged in a near zero probability world are so high, the banker may foolishly still choose to be overleveraged to maximize expected utility. Second, diminishing returns typically force us to produce or consume more in order to realize the same amounts of utility; this is usually a recipe for us to consume and produce in unsustainable ways. Third, as Herbert Simon noted, optimizing expected utility is often computationally intractable. &nbsp;</p><p>A response of early effective altruism research to these problems was maxipok (i.e., maximizing probabilities of an okay outcome). Under this construct, constraints of an okay outcome are identified, a probability of satisfying those constraints is assigned to each action, and the action that maximizes the probability of satisfying the constraints is adopted.</p><p>The problem with maxipok is that it assumes moral certainty about the constraints of what constitutes an okay outcome. For example, if we believe a trolley problem is inevitable, one might infer it is an okay outcome for someone to die, given its unavoidability. On the other hand, if a trolley problem is avoidable, one may infer that someone dying is not okay. Thus in that overall scenario, what constitutes an okay outcome is contingent on what probabilities we assign to the inevitability of a trolley problem.</p><p>Success maximization is a mechanism by which to generalize maxipok for moral uncertainty. Let <i>a<sub>i</sub></i> be an action <i>i</i> from the set of <i>m&nbsp;</i>actions <i>A&nbsp;</i>= {<i>a</i><sub>1</sub>, <i>a</i><sub>2</sub>, \u2026, <i>a<sub>m</sub></i>}. Let <i>s<sub>x</sub></i> be a definition of moral success, namely <i>x</i>, from <i>S</i> = {<i>s</i><sub>1</sub>, <i>s</i><sub>2</sub>, \u2026, <i>s<sub>n</sub></i>}. The probability <i>\u03c0</i> that <i>i</i> satisfies the constraints of <i>s<sub>x</sub></i> is 0 \u2264 <i>\u03c0<sub>i</sub></i>(<i>s<sub>x</sub></i>) \u2264 1. Let <i>p</i>(<i>s<sub>x</sub></i>) be the estimated probability that <i>x</i> is the correct definition of moral success, where <i>p</i>(<i>s</i><sub>1</sub>) + <i>p</i>(<i>s</i><sub>2</sub>) + \u2026 + <i>p</i>(<i>s<sub>n</sub></i>) = 1. Thus, the expected success of action <i>i</i> is 0 \u2264 <i>\u03c0<sub>i</sub></i>(<i>s</i><sub>1</sub>)<i>p</i>(<i>s</i><sub>1</sub>) + <i>\u03c0<sub>i</sub></i>(<i>s</i><sub>2</sub>)<i>p</i>(<i>s</i><sub>2</sub>) + \u2026 + <i>\u03c0<sub>i</sub></i>(<i>s<sub>n</sub></i>)<i>p</i>(<i>s<sub>n</sub></i>) \u2264 1. A success maximizing agent will choose an action <i>a<sub>j</sub></i> \u0454 <i>A</i> such that <i>\u03c0<sub>j</sub></i>(<i>s</i><sub>1</sub>)<i>p</i>(<i>s</i><sub>1</sub>) + <i>\u03c0<sub>j</sub></i>(<i>s</i><sub>2</sub>)<i>p</i>(<i>s</i><sub>2</sub>) + \u2026 + <i>\u03c0<sub>j</sub></i>(<i>s<sub>n</sub></i>)<i>p</i>(<i>s<sub>n</sub></i>) \u2265<i>\u03c0<sub>i</sub></i>(<i>s</i><sub>1</sub>)<i>p</i>(<i>s</i><sub>1</sub>) + <i>\u03c0<sub>i</sub></i>(<i>s</i><sub>2</sub>)<i>p</i>(<i>s</i><sub>2</sub>) + \u2026 + <i>\u03c0<sub>i</sub></i>(<i>s<sub>n</sub></i>)<i>p</i>(<i>s<sub>n</sub></i>) for all <i>a<sub>i</sub></i> \u0454 <i>A</i> where <i>i</i> \u2260 <i>j</i>. &nbsp;</p><p>Success maximization resolves many of the problems of von Neumann-Morgenstern and Harsanyi expected utility theories. First, because success valuations are bounded between 0 and 1, it is much less likely we will encounter St. Petersburg paradox situations where any action is justified by extremely high utility valuations despite near zero probabilities of occurrence. Second, unsustainable behaviors produced by chasing diminishing returns is much less likely in the world of maximizing probabilities of constraint satisfaction than it is in the world of maximizing unbounded expected utilities. Third, because probabilities of success are bounded between zero and one, terms of the linear combination (where <i>p</i>(<i>s<sub>x</sub></i>) is relatively low) can often be ignored to make for quicker calculations, making calculations more tractable. &nbsp;</p>", "user": {"username": "Mahendra Prasad"}}, {"_id": "JqBLcGYapXEG9saXD", "title": "Semi-conductor / AI stocks discussion.", "postedAt": "2022-11-25T23:35:41.103Z", "htmlBody": "<p>I've been writing about investing and the EMH [1] on lesswrong/rat-discord/ea-facebook/etc. I made the first 'buy solana' post on the EA investing group when it was under 2 dollars in late 2020 (it peaked at 260 in 2021). Despite crypto crashing and FTX stealing user deposits I got my money out and I've had a very good two years investing. Post tax I multiply my net worth by about a factor of eight; my starting net worth was not small. My income during this period wasn't significant compared to my portfolio size. However some friends really wish I had been posting more systematically. I 'sold the top' but many people I got into Solana didn't. So me and some friends are going to regularly post on twitter. <a href=\"https://twitter.com/DickgirlsR\">Please follow us</a> [2] if you want updates systematically!</p><p>Anyone who thinks AI is going to be transformative should allow this to inform their investing. Im interested in how other EAs are investing! I think the EA community seriously undervalues 'taking care of each other' and we should share our thoughts. Here are some brief thoughts on stocks we like for this purpose, mostly semis:</p><p>1) TSM - Significant technical lead on other semi-conductor companies. Only close on technology competitor is Samsung. PE ratio of 17! Probably the most important company in the world right now. Only downside is risk China invades Taiwan. Pure semis play.</p><p>2) Google - Owns Deep Mind and Google Brain. Huge piles of money and data to train AI. PE of 19. &nbsp;Downside: Ad revenue slipping.</p><p>3) Samsung - Only serious technical competitor to TSM. Insanely low PE of 8.58. Downside: not a very pure semis play.</p><p><br>4) Nvidia - Still the leader in designing GPUs. In house AI research. Downsides: Doesn't manufacture their own chips, high PE ratio of 55.</p><p>5) ASML - Makes hardware for semi-conductor fabs. Almost a monopoly in lithography. Downside: pretty high PE 36+.</p><p><br>6) Intel - Still does good work designing chips. Huge struggles to manufacture sub 10nm chips in-house (TSM and Samsung have 3nm in production). Committed a ton of fraud. However the US government is wisely trying to increase domestic semis production and Intel is a US Company.</p><p>7) Other stocks I'm considering: Microsoft (open AI), Micron (memory play), Meta (just released diplomacy AI. Heavily over-represented in the 'EA' portfolio), Tesla (good in-house AI).</p><p>This is a good article by <a href=\"https://mobile.twitter.com/asteriskmgzn\">@asteriskmgzn</a> is quite good. <a href=\"https://asteriskmag.com/issues/1/china-s-silicon-future\">https://asteriskmag.com/issues/1/china-s-silicon-future</a><br>&nbsp;</p><p>Notes:<br>1) Please be good rationalists and don't argue about the EMH. If you believe in the EMH just don't post.&nbsp;</p><p>2) We choose the name 'Dickgirls Research' because all the founders are transgirls and we think its a hilarious name.</p>", "user": {"username": "deluks917"}}, {"_id": "oZCPayvcxkDHubcDv", "title": "Does putting kids in school now put money in their pockets later? Revisiting a natural experiment in Indonesia", "postedAt": "2022-11-25T21:09:46.207Z", "htmlBody": "<figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/rgx0rlur7wsypvskipji.png\"></figure><p>Open Philanthropy\u2019s&nbsp;<a href=\"https://www.openphilanthropy.org/focus/global-health-development/\"><u>Global Health and Wellbeing</u></a> team continues to investigate potential areas for grantmaking. One of those is education in poorer countries. These countries have&nbsp;<a href=\"https://ourworldindata.org/grapher/total-net-enrollment-rate-in-primary-education?tab=chart&amp;country=ALB~AFG~DZA~AND~AGO~ATG~ARG~ARM~AUS~AUT~AZE~BHS~BHR~BGD~BRB~BLR~BEL~BLZ~BEN~BGR~BFA~BDI~BTN~BOL~BIH~BWA~BRA~BRN~QAT~REU~ROU~RUS~RWA~KNA~LCA~VCT~WSM~STP~SAU~SEN~SRB~SYC~SLE~SGP~SVK~SVN~SLB~SOM~ZAF~KOR~SSD~ESP~LKA~SDN~SUR~SWE~CHE~SYR~TWN~TJK~TZA~THA~TLS~TGO~TON~TTO~TUR~TKM~UGA~UKR~ARE~GBR~USA~URY~UZB~VUT~VEN~YEM~ZMB~ZWE~TUN~VNM~KHM~CMR~CAN~CPV~CAF~COG~CRI~CIV~HRV~CUB~CYP~CZE~COD~DNK~DJI~DMA~DOM~ECU~EGY~SLV~GNQ~ERI~EST~ETH~FJI~FIN~FRA~GAB~GMB~GEO~GRC~GRD~GTM~GIN~GNB~GUY~HTI~HND~HKG~HUN~ISL~IND~IDN~IRN~IRQ~IRL~ISR~ITA~JAM~JPN~JOR~KAZ~KIR~KEN~KWT~KGZ~LAO~DEU~GHA~TCD~CHL~CHN~COL~COM~LBY~LIE~LTU~LUX~MAC~MDG~MWI~MYS~MDV~MLI~MLT~MHL~MRT~MUS~MEX~FSM~MDA~MNG~MNE~MAR~MOZ~MMR~NAM~NPL~NLD~NZL~NIC~NER~NGA~MKD~NOR~OMN~PAK~PLW~PSE~PAN~PNG~PRY~PER~POL~PRT~PHL~LVA~LBN~LSO~LBR\"><u>massively expanded schooling in the last half century</u></a>. but many of their students&nbsp;<a href=\"https://ourworldindata.org/grapher/share-of-students-achieving-the-minimum-threshold-score\"><u>lack minimal numeracy and literacy</u></a>.&nbsp;</p><p>To support the team\u2019s assessment of the scope for doing good through education, I reviewed prominent research on the effect of schooling on how much children earn after they grow up. Here, I will describe my reanalysis of a study published by Esther Duflo in 2001. It&nbsp;<a href=\"https://files.givewell.org/files/DWDA%202009/Interventions/Duflo01.pdf#page=16\"><u>finds</u></a> that a big primary schooling expansion in Indonesia in the 1970s caused boys to go to school more \u2014 by 0.25\u20130.40 years on average over their childhoods \u2014 and boosted their wages as young adults, by 6.8\u201310.6% per extra year of schooling.</p><p>I reproduced the original findings, introduced some technical changes, ran fresh tests, and thought hard about what is generating the patterns in the data. I wound up skeptical that the paper made its case. I think building primary schools probably led more kids to finish primary school (which is not a given in poor regions of a poor country). I\u2019m less sure that it lifted pay in adulthood.</p><p>Key points behind this conclusion:</p><ul><li>The study\u2019s \u201cmargins of error\u201d \u2014 the indications of uncertainty \u2014 are too narrow. The reasons are several and technical. I hold this view mostly because, in the 21 years since the study was published, economists including Duflo have improved collective understanding of how to estimate uncertainty in these kinds of studies.</li><li>The reported impact on wages does not clearly persist through life, at least according to a method I constructed to look for a statistical fingerprint of the school-building campaign.&nbsp;</li><li>Under the study\u2019s methods, normal patterns in Indonesian pay scales and the allocation of school funding can generate the appearance of an impact even if there was none.</li><li>Switching to a modern method that filters out that mirage also erases the statistical results of the study.</li></ul><p>My full report is<a href=\"https://arxiv.org/abs/2207.09036\"><u> here</u></a>. Data and code (to the extent shareable) are&nbsp;<a href=\"https://github.com/droodman/Duflo-2001\"><u>here</u></a>.</p><h2><strong>Background</strong></h2><p>The Indonesia study started out as the first chapter of&nbsp;<a href=\"https://dspace.mit.edu/handle/1721.1/9516\"><u>Esther Duflo\u2019s Ph.D. thesis</u></a> in 1999. It appeared in final form in the prestigious&nbsp;<a href=\"https://www.aeaweb.org/articles?id=10.1257/aer.91.4.795\"><i><u>American Economic Review</u></i></a> in 2001, which marked Duflo as a rising star. Within economics, the paper was emblematic of an ascendant emphasis on exploiting natural experiments in order to identify cause and effect (think&nbsp;<a href=\"https://freakonomics.com/2011/06/the-supreme-court-provides-a-dissertation-topic-for-a-budding-economist/\"><u>Freakonomics</u></a>).</p><p>Here, the natural experiment was a sudden campaign to build tens of thousands of three-room schoolhouses across Indonesia. The country\u2019s dictator, Suharto, launched the big push with a Presidential Instruction (Instruksi Presiden, or Inpres) in late 1973, soon after the first global oil shock sent revenue pouring into the nation\u2019s treasury. I suspect that Suharto wanted not only to improve the lot of the poor, but also to consolidate the control of his government \u2014 which had come to power through a bloody coup in 1967 \u2014 over the ethnically fractious population of the far-flung and colonially constructed nation.</p><p>I live near the Library of Congress, so I biked over there to peruse a copy of that 1973 presidential instruction. It reminded me of James Scott\u2019s&nbsp;<a href=\"https://en.wikipedia.org/wiki/Seeing_Like_a_State\"><i><u>Seeing Like a State</u></i></a>, which is about how public bureaucracies impose homogenizing paradigms on the polities they strive to control. After the legal text come&nbsp;<a href=\"https://github.com/droodman/Duflo-2001/tree/main/Printed%20sources\"><u>neat tables</u></a> decreeing how many schools are to be built in each regency. (Regencies are the second-level administrative unit in Indonesia, below provinces.) After the tables come pages of architectural plans, like the one at the top of this post.</p><p>The instruction even specifies the design of the easels, chairs, and desks. Here\u2019s a desk:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1673726251/mirroredImages/oZCPayvcxkDHubcDv/tealdfin4hk2bwirlnz4.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1673726251/mirroredImages/oZCPayvcxkDHubcDv/tealdfin4hk2bwirlnz4.png 1024w, https://res.cloudinary.com/cea/image/upload/v1673726250/mirroredImages/oZCPayvcxkDHubcDv/tbupavuhgyaxvaawurlj.png 300w, https://res.cloudinary.com/cea/image/upload/v1673726248/mirroredImages/oZCPayvcxkDHubcDv/iggu7xfytuueh21kwoj0.png 768w, https://res.cloudinary.com/cea/image/upload/v1673726251/mirroredImages/oZCPayvcxkDHubcDv/drgtxyan77tdnna6km45.png 320w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/se0ag8trvfsc5pcj4kem.png 1045w\"></p><p>Sure enough, if you search Google images for \u201cInpres Sekolah Dasar\u201d (Inpres primary school), you\u2019ll find those schools and those desks (<a href=\"https://www.openphilanthropy.org/research/does-putting-kids-in-school-now-put-money-in-their-pockets-later-revisiting-a-natural-experiment-in-indonesia/majalah.tempo.co/read/laporan-khusus/155506/kembang-kempis-sd-inpres\"><u>source</u></a>):</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/pp8rp7vlddaozxtu7dev.jpg\" alt=\"Interior picture of Kembang-Kempis Inpres SD\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/pp8rp7vlddaozxtu7dev.jpg 1024w, https://res.cloudinary.com/cea/image/upload/v1673726249/mirroredImages/oZCPayvcxkDHubcDv/vk89vwt956klgbqmgjko.jpg 300w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/c4olqgeo3cj63v2eouxj.jpg 768w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/smvsu3antaauily2wto6.jpg 320w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/z8e2xs9wstohcnbxlr5o.jpg 1200w\"></p><p>The Inpres campaign doubled the stock of primary schools in the country in just six years.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefp1h5vg1v5w\"><sup><a href=\"#fnp1h5vg1v5w\">[1]</a></sup></span>&nbsp;Economists call that a \"schooling shock.\"</p><h2><strong>Methods and results</strong></h2><p>The Duflo study looks for reverberations of this educational earthquake in data from a <a href=\"https://www.rand.org/well-being/social-and-behavioral-policy/data/bps/supas/1995.html\"><u>household survey that the Indonesian government fielded in 1995</u></a>. By 1995, the first kids who went to the schools had grown up and started working. The study examines whether boys with more opportunity to attend a new school, by virtue of how young they were and where they lived, actually went to school more and then earned more.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8fm4u0em6r\"><sup><a href=\"#fn8fm4u0em6r\">[2]</a></sup></span></p><p>To perform this calculation, the study takes <i>difference-in-differences</i>. It looks not at whether men from regencies that got more schools earned more\u2014a difference\u2014but whether the pay differential between young and old men in 1995 was narrower for natives of regencies that got more schools, which is a difference in differences.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkokaoo752p\"><sup><a href=\"#fnkokaoo752p\">[3]</a></sup></span></p><p>Why look at that? Regencies ranged along a spectrum in how many new schools they got per child. To understand the study\u2019s theory of measurement, I like to split the spectrum into regencies that got fewer schools and those that got more. If the Inpres schools <i>did </i>increase future pay, here\u2019s how the world would look in this framing. In reading this table, bear in mind that it is normal for older workers to earn more than younger ones, as I'll document later. So if something bumps up the pay of younger workers, it narrows the old-young pay gap:</p><figure class=\"table\" style=\"height:115px;width:676px\"><table style=\"border:1px solid hsl(180, 75%, 60%)\"><thead><tr><th style=\"background-color:hsl(210, 75%, 60%)\">Regencies getting fewer schools per child in 1970s</th><th style=\"background-color:hsl(210, 75%, 60%)\">Regencies getting more schools per child in 1970s</th></tr></thead><tbody><tr><td style=\"background-color:hsl(0, 0%, 100%);border-style:solid;height:23px;padding:0.75rem;vertical-align:top\">Older natives too old to have gone to new schools</td><td style=\"background-color:hsl(0, 0%, 100%);border-style:solid;height:23px;padding:0.75rem;vertical-align:top\">Older natives too old to have gone to new schools</td></tr><tr><td style=\"height:23px;padding:0.75rem;width:329.672px\">Fewer young natives could have gone to the schools</td><td style=\"height:23px;padding:0.75rem;width:345.328px\">More young natives could have gone to the schools</td></tr><tr><td style=\"height:23px;padding:0.75rem;width:329.672px\">Fewer young natives get pay boost in adulthood</td><td style=\"height:23px;padding:0.75rem;width:345.328px\">More young natives get pay boost in adulthood</td></tr><tr><td style=\"height:23px;padding:0.75rem;width:329.672px\">Larger old-young pay gap among natives in 1995</td><td style=\"height:23px;padding:0.75rem;width:345.328px\">Smaller old-young pay gap among natives in 1995</td></tr></tbody></table></figure><p>The bottom line (as it were): natives of places that got more schools in the 1970s would exhibit a smaller old-young pay gap in 1995. That is the correlation that the Duflo study looks for\u2026</p><p>\u2026and finds. The&nbsp;<a href=\"https://www.fsb.miamioh.edu/lij14/411_paper_school2.pdf#page=6\"><u>study (Table 4, panel A)</u></a> calculates that each additional planned Inpres school, per 1,000 children in a regency, increased boys\u2019 future wage earnings by about 1.5%. The 1.5% number pertains to <i>employees</i>, meaning people who work for other people. (The government surveyors in 1995 didn\u2019t ask self-employed people, including farmers, how much they earned, so they fall out of this analysis.)</p><p>In the same way, it is calculated that during childhood those future workers spent a fifth of a year more in school for each Inpres school built per 1,000 children. I think of that finding as an extra year in school for every fifth boy.</p><p>If an extra fifth of a year of schooling bumped wages by an average of 1.5%, then a full year would have increased them by about 5 \u00d7 1.5% = 7.5%.</p><h2><strong>Association and causation</strong></h2><p>That 7.5% payoff rate for a year in the classroom is known as the \u201creturn to schooling.\u201d Economists have estimated it <a href=\"https://eml.berkeley.edu/~cle/wp/wp62.pdf#page=2\"><u>thousands of times</u></a> using data from various contexts. Yet among all the estimates, Duflo\u2019s stands out. It comes from the developing world, which is where most people live. It comes from a big schooling expansion, which adds realism if you\u2019re interested in national-level education policy. And the use of difference-in-differences gives the study a certain rigor, for it rules out some potential critiques. Few other studies can check all those boxes (though some can \u2014 see<a href=\"https://doi.org/10.1257/app.4.4.226\"><u> this</u></a> from Kenya or<a href=\"https://doi.org/10.1086/721619\"><u> this</u></a> from India).</p><p>To expand on that last strength: If the Duflo study had only computed <i>differences</i>, then, for example, a simple finding that men from regencies that got more schools earned more, if presented as evidence of impact, could be easily challenged. Maybe everything just costs more \u2014 and everyone earns more \u2014 in the megalopolis of Jakarta; and maybe Jakarta, as the capital, got more schools per capita. Then we would not need to believe that Inpres schools made a difference in order to explain why men from regencies that got more schools earned more. On the other hand, if urban inflation raised everyone\u2019s wages within Jakarta the same amount, then the old-young pay gap would be the same in Jakarta and beyond. It would not be misleadingly associated with the number of schools each district got. And that, as I said, is what the Duflo study actually checks.</p><p>Notice that \u201c<i>if urban inflation\u2026</i>\u201d in the previous paragraph. Despite the rigor of difference-in-differences, you still need to assume something nontrivial about the world in order to fully buy the study\u2019s findings.</p><p>Fortunately, the Duflo analysis contains a potentially more compelling basis for proving impact. It has to do with <i>timing</i>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcg5x828w7vc\"><sup><a href=\"#fncg5x828w7vc\">[4]</a></sup></span>&nbsp;Think of the opportunity to go to one of the new Inpres schools as a medicine. The dosing of that educational opportunity depended on kids\u2019 ages. Approximately speaking, those 12 and up in 1974 were too old to get any of this schoolhouse-shaped drug, for they had aged out before any new schools got built. Kids who were 11 in in 1974 could get a one-year dose before aging out, at least if they lived near one of the new schools. Kids who were 10 could get a two-year dose. And so on. Because every year more neighborhoods and villages got new schools,&nbsp;<a href=\"https://doi.org/10.1355/9789814459877-002\"><u>well into the 1980s</u></a>, the average schooling opportunity continued rising for younger and younger kids.</p><p>So the graph of Inpres schooling opportunity looks like this:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1673726249/mirroredImages/oZCPayvcxkDHubcDv/xvnlxkffeytabss2njwp.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1673726249/mirroredImages/oZCPayvcxkDHubcDv/xvnlxkffeytabss2njwp.png 1024w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/jdckdfuzdh5hil4xrdax.png 300w, https://res.cloudinary.com/cea/image/upload/v1673726250/mirroredImages/oZCPayvcxkDHubcDv/mevqhjvxfqqkkrvv4tc4.png 768w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/mqctsf4yprjngnsimjvf.png 1536w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/ydmbplaatbsjlgahdlqb.png 2048w, https://res.cloudinary.com/cea/image/upload/v1673726250/mirroredImages/oZCPayvcxkDHubcDv/x4okqeverqcgxrktnygx.png 320w, https://res.cloudinary.com/cea/image/upload/v1673726248/mirroredImages/oZCPayvcxkDHubcDv/prbaeiqlsx5jiye5fjsf.png 1440w\"></p><p>If we found a similar bend around age 12 in other data, such as on earnings in 1995, that would look like the fingerprint of Inpres carrying through, from cause to effect. And that is exactly what the Duflo study suggests happened, if with statistical noise. This graph is from the study:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1673726250/mirroredImages/oZCPayvcxkDHubcDv/csypna9lpb0mkodunj6i.png\" alt=\"Figure 3 of Duflo (2001), showing rising cross-regency associations between Inpres school construction on the one hand and schooling attainment and wages on the other, as age falls\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1673726250/mirroredImages/oZCPayvcxkDHubcDv/csypna9lpb0mkodunj6i.png 1024w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/r9u3s39cxmekpxpddqfh.png 300w, https://res.cloudinary.com/cea/image/upload/v1673726250/mirroredImages/oZCPayvcxkDHubcDv/lglu7t4ehnvi3glleje4.png 768w, https://res.cloudinary.com/cea/image/upload/v1673726251/mirroredImages/oZCPayvcxkDHubcDv/xnfpevdzrkipkyers6s8.png 1536w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/rvqmj3x0uxxk6ncdxby4.png 2048w, https://res.cloudinary.com/cea/image/upload/v1673726251/mirroredImages/oZCPayvcxkDHubcDv/ap2h0zfynnfkv65punzr.png 320w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/xuxrrqoqy3prjyrqaoe4.png 1440w\"></p><p>Each dot in this graph is a measurement of the association framed in that table above, between the old-young gap in schooling or pay and how many schools a regency was to receive per child. In that framing, we expect no association for the oldest men in the study, for all were too old to have gone to the new schools. But it should start to emerge\u2014the dots should start to rise\u2014as we scan to men who were 12 or younger in 1974. Duflo <a href=\"https://www.fsb.miamioh.edu/lij14/411_paper_school2.pdf#page=7\"><u>wrote</u></a>:</p><blockquote><p>These coefficients fluctuate around 0 until age 12 and start increasing after age 12. As expected, the program had no effect on the education of cohorts not exposed to it, and it had a positive effect on the education of younger cohorts.</p></blockquote><p>Looking at that graph I wondered: do the trends really bend around age 12? Or should they be seen as straight? Because of the noise, neither characterization completely nails it; the question is whether one model clearly out-fits the other. If the overall trends were straight and long-term, perhaps they had little to do with Inpres. Just as in my reanalyses of Hoyt Bleakley\u2019s studies of <a href=\"https://blog.givewell.org/2017/12/07/questioning-evidence-hookworm-eradication-american-south/\"><u>hookworm</u></a> and <a href=\"https://blog.givewell.org/2017/12/29/revisiting-evidence-malaria-eradication-americas/\"><u>malaria</u></a> eradication, I set out to probe this question with a mathematical test.</p><h2><strong>Starting the reanalysis</strong></h2><p>I started my quest with a request for the study\u2019s data and computer code. Ironically, Duflo is now the editor of the journal that published her paper. That puts her in charge of enforcing the&nbsp;<a href=\"https://web.archive.org/web/20010128003000/http://www.aeaweb.org:80/aer/submissions.html\"><u>data and code-sharing policy</u></a> that applied to her study. Sure enough, she promptly sent me files for reproducing most of the results.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbgslsm6y1qw\"><sup><a href=\"#fnbgslsm6y1qw\">[5]</a></sup></span></p><p>Once I had anchored myself in exact reproduction, I made changes to the code. Most owe to the passage of time: methods in empirical economics have improved since 2001, and Indonesian men of the generation in the Duflo study have continued tracing their way through life (and through&nbsp;<a href=\"https://silastik.bps.go.id/\"><u>government survey data</u></a>).</p><p>While my biggest question going in was about timing, I stumbled on another first-order issue: an alternative explanation for the numerical findings.</p><p>I\u2019ll explain a few technical concerns first, as non-technically as I can, then move to that alternative explanation and the search for bends in trends.</p><h3><strong>Data corrections</strong></h3><p>Some numbers in the Duflo study come from government documents published in the 1970\u2014presidential instructions and reports on Indonesia\u2019s 1971 census. At the Library of Congress, I&nbsp;<a href=\"https://github.com/droodman/Duflo-2001/tree/main/Printed%20sources\"><u>scanned pages</u></a> in these books and double-checked the numbers Duflo sent me. In my experience, it is normal for such a check to expose errors, and normal for them not to affect conclusions much\u2014as happened here. For about a tenth of regencies, my figures for planned new schools per 1,000 children differ from Duflo\u2019s. (See my<a href=\"https://github.com/droodman/Duflo-2001\"><u> Github repo</u></a>.)</p><h3><strong>Clustering</strong></h3><p>It\u2019s a truism that the larger your sample, the more precise your statistics. The margin of error is tighter if you poll 1,000 people than if you poll 10. But margins of error must themselves be estimated, and determining the <i>effective</i> sample size for this purpose is often a&nbsp;<a href=\"https://chrisblattman.com/blog/2015/12/08/clusterjerk/\"><u>head-scratcher</u></a>. Should we view a study of the impact of state air pollution rules on asthma rates as being about 50 states or, say, 50 million people? The answer can radically affect how precise we take the results to be. One<a href=\"https://blogs.worldbank.org/impactevaluations/when-should-you-cluster-standard-errors-new-wisdom-econometrics-oracle\"><u> rule of thumb</u></a>: the effective sample size is the number of treatment units. There are 50 states, with 50 air pollution laws, so 50 is your number, not 50 million.</p><p>In a striking turnabout, soon after finalizing the Indonesia study, Duflo coauthored a paper raising doubts about the methods she had just used: \u201c<a href=\"https://doi.org/10.1162/003355304772839588\"><u>How Much Should We Trust Differences-in-Differences Estimates?</u></a>\u201d This new paper was not purely destructive, for it demonstrated the value of a particular mathematical correction, called clustering, which allows one to crunch data on millions of individuals while computing margins of error as if the sample is much smaller. Under the influence of that paper, in returning to the Indonesia study, I cluster standard errors by regency. This widens confidence ranges by a factor of two or three.</p><h3><strong>Overrepresentation of wealthy families</strong></h3><p>Governments run many surveys--to track how much people work, how healthy they are, how much they pay for housing, etc. Some surveys are censuses, which ideally entail knocking on <i>everyone</i>\u2018s door, and even reaching the people who don\u2019t have doors. But finding all those people, asking them lots of questions, and collating the answers all costs money. This is why most surveys, like polls, take samples.</p><p>As soon as one gives up on surveying everyone, the question arises: what is the best way to allocate surveying resources to get the most accurate statistical picture? Often, it is not to take a plain random sample, as when pollsters dial random phone numbers. It can be better to split the sample into <i>strata </i>\u2014 urban and rural, rich and poor. If some strata are known from censuses to be more homogeneous, then governments can get more precision for the money by sampling those strata less and others more. In a&nbsp;<a href=\"https://www.rand.org/content/dam/rand/www/external/labor/bps/manualpdf/susenas/surbakti_1995_review.pdf\"><u>history of one of Indonesia\u2019s national surveys</u></a>, Parjung Surbakti explains it well:</p><blockquote><p>The fact that an orange taken from a truckload of oranges all coming from the same orchard is sweet, gives adequate evidence to conclude that all the oranges in the truck are sweet. In this example, a very small sample size can provide an accurate conclusion about a large population when the population is homogeneous. It would be a different story if the oranges came from a number of orchards and consisted of different varieties. Then a sample of size 10 might not give as accurate a conclusion as that of the previous example. However, if the truckload of oranges can be sorted by varieties, i.e., the population is stratified, then sampling once again may be made more efficient.</p></blockquote><p>It seems that in Indonesia, poorer people are thought to be more like oranges from the same orchard. For the government surveyors&nbsp;<a href=\"https://sesricdiag.blob.core.windows.net/sesric-site-blob/files/INCOME&amp;CONSUMPTION_Methodology_Susenas_EN.pdf#page=4\"><u>disproportionately visit wealthy households</u></a>, where wealth is indicated by possessions such as toilets and diplomas.</p><p>The Indonesia survey data used in the Duflo study are accompanied by <i>weights</i> to document the oversampling of some groups. They indicate, say, that each surveyed household with a toilet stands for 100 others while each without stands for 200. However, the Duflo study mostly does not incorporate these weights.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref293s849k9mc\"><sup><a href=\"#fn293s849k9mc\">[6]</a></sup></span>&nbsp;As a result, wealthier people are overrepresented.</p><p>Whether such weights <i>should</i> in general be factored in is a confusing question, so much so that three respected economists wrote \u201c<a href=\"http://jhr.uwpress.org/content/50/2/301.refs\"><u>What Are We Weighting For?</u></a>\u201d to dispel their colleagues\u2019 befuddlement. Here, my concern is that the data are being tilted on the basis of the outcomes of interest. People with more education and higher incomes were more likely to get a knock on the door from a surveyor in 1995 and thus to appear in the Duflo analysis. Imagine a study of the impact of smoking in which people who live are oversampled at the expense of people who die. That would make smoking look safer than it is.</p><p>That is why I prefer to incorporate the weights in the Indonesia analysis. For technical reasons, this not only shifts the impact estimates, but further widens margins of error.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefel29ikn82f\"><sup><a href=\"#fnel29ikn82f\">[7]</a></sup></span></p><h3><strong>Instability of ratios</strong></h3><p>I quoted the estimate that the Inpres campaign raised wages by 7.5% per year of extra schooling. That is a ratio: a 1.5% wage boost divided by 0.2 years (a fifth of a year) of extra schooling. Because the numbers going into the ratio are themselves averages from samples of Indonesians, each comes with its own margin of error. The true value of the schooling increase in the full population might be 0.3 years or 0.1 years \u2014 or 0.0. And if, as far as the math goes, there\u2019s a nontrivial chance that Inpres led to zero additional years of schooling, then there\u2019s a nontrivial chance that the ratio of wage increase to schooling increase is <i>infinite</i>.</p><p>The point is not that I think the return to schooling could be infinity (or negative infinity), but that ratios emerging from this sort of analysis can range wildly. Standard methods for computing margins of error can underestimate this uncertainty.</p><p>Since Duflo wrote about Indonesia, economists have made a lot of progress in recognizing and working around this devil in the details, which is called \u201cweak identification.\u201d In my reanalysis, I marshal a modern method called the wild-bootstrapped Anderson-Rubin test, which happens to be performed by a<a href=\"https://doi.org/10.1177/1536867X19830877\"><u> cool program I wrote</u></a>. Like the clustering and weighting corrections, the new method widens the uncertainty bands around the estimated return to schooling.</p><h3><strong>Bottom line after incorporating the technical comments</strong></h3><p>After I fix data errors, cluster, and compensate for the oversampling of wealthy households, it is surprisingly unclear whether Inpres caused boys to spend any more time in school. And because dividing by a number that is hard to distinguish from zero produces unstable results, the impact on wages <i>per</i> extra year in school is even less clear. Where Duflo brackets that 7.5% schooling return rate with a 95% confidence range of 1\u201315%, I widen to a huge span, \u201344% to +164%.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4eamjxm0y1m\"><sup><a href=\"#fn4eamjxm0y1m\">[8]</a></sup></span></p><p>To be fair, that wide range can mislead. My <i>70%</i> confidence range is 0\u201323%. I conclude that incorporating the technical comments into the core Duflo analysis leaves it weakly favoring the view that Inpres-stimulated schooling raised wages.</p><h2><strong>The alternative explanation: wage scale dilation</strong></h2><p>As I wrangled with those technicalities and worked to answer my original question about trend bending, I discovered another reason to doubt the Duflo study\u2019s results. And once I did, I realized that Cl\u00e9ment de Chaisemartin and Xavier D\u2019Haultf\u0153uille had&nbsp;<a href=\"http://www.restud.com/wp-content/uploads/2017/08/MS19615manuscript.pdf#page=20\"><u>already pointed to the heart of the issue</u></a>. It turns out that some more mundane patterns in the data, when fed into the difference-in-differences machine, can produce the same statistical results.</p><p>Here are some universal truths, or at least as close as you get to that in economics:</p><ol><li>Those who go to school more earn more, on average.</li><li>The earnings gap between the more- and less-schooled rises with age.</li></ol><p>As an example of the second point, in the 1995 Indonesia data, the average employed, college-educated 21-year-old man earned 744 rupiah per hour, only 18% more than the 633 rupiah earned by a contemporary who dropped out of school before fourth grade. But at age 61, in the same data, the hourly pay for the primary school dropout was basically unchanged, 642 rupiah, while pay for the college graduate was more than six times higher than at age 21, at 4,852 rupiah.</p><p>This graph shows more fully how the wage scale widened with age among employed Indonesian men in 1995:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1673726251/mirroredImages/oZCPayvcxkDHubcDv/rfsqzkf5zfk6tz1lyznf.png\" alt=\"Age-differentiated wage scale divergence in Indonesia, 1995\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1673726251/mirroredImages/oZCPayvcxkDHubcDv/rfsqzkf5zfk6tz1lyznf.png 1024w, https://res.cloudinary.com/cea/image/upload/v1673726250/mirroredImages/oZCPayvcxkDHubcDv/axzwi3resab56lozacjg.png 300w, https://res.cloudinary.com/cea/image/upload/v1673726251/mirroredImages/oZCPayvcxkDHubcDv/avx3jojeukgm0nmpsg9x.png 768w, https://res.cloudinary.com/cea/image/upload/v1673726251/mirroredImages/oZCPayvcxkDHubcDv/xt7ewsa2yfb125gk4xvy.png 1536w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/xhxnimmcnvrl7rjlrj49.png 2048w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/qvxnmyhpcpdy44qxnuig.png 320w, https://res.cloudinary.com/cea/image/upload/v1673726251/mirroredImages/oZCPayvcxkDHubcDv/x1s24anhyhekl2wzf7bh.png 1440w\"></p><p>I imagine the people behind the bottom curve as farm workers whose pay had little to do with age. And I imagine that the top curve traces how the elite ascend the ranks of big corporations and government.</p><p>The widening of the wage scale feeds into the Duflo study in a mind-bending way. Suppose (correctly) that poorer regencies \u2014 the ones that produced more day laborers and fewer doctors and lawyers \u2014 received more Inpres schooling funding per child. Then we would see:</p><figure class=\"table\" style=\"height:115px;width:676px\"><table style=\"border:1px solid rgb(68, 82, 119)\"><thead><tr><th style=\"background-color:hsl(210, 75%, 60%);border-right:1px solid rgb(255, 255, 255);height:23px;padding:0.75rem;vertical-align:top\">Regencies getting fewer schools per child in the 1970s</th><th style=\"background-color:hsl(210, 75%, 60%);border-right:1px solid rgb(255, 255, 255);height:23px;padding:0.75rem;vertical-align:top\">Regencies getting more schools per child in the 1970s</th></tr></thead><tbody><tr><td style=\"height:23px;padding:0.75rem;width:329.672px\">Natives better off on average</td><td style=\"height:23px;padding:0.75rem;width:345.328px\">Natives poorer on average</td></tr><tr><td style=\"height:23px;padding:0.75rem;width:329.672px\">More kids grow up to be CEOs</td><td style=\"height:23px;padding:0.75rem;width:345.328px\">More kids grow up to be day laborers</td></tr><tr><td style=\"height:23px;padding:0.75rem;width:329.672px\">Average pay rises a lot during career</td><td style=\"height:23px;padding:0.75rem;width:345.328px\">Average pay rises little during career</td></tr><tr><td style=\"height:23px;padding:0.75rem;width:329.672px\">Larger old-young pay gap among natives in 1995</td><td style=\"height:23px;padding:0.75rem;width:345.328px\">Smaller old-young pay gap among natives in 1995</td></tr></tbody></table></figure><p>This table starts and ends in the same places as the earlier table: getting more schools means a smaller old-young pay gap. But it goes by a different route. Nowhere does the new scenario assume or require that the Inpres school-building campaign had any effect.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref55q412pphdp\"><sup><a href=\"#fn55q412pphdp\">[9]</a></sup></span>&nbsp;Thus, the study\u2019s methods could lead to the conclusion that Inpres schools raised wages even if they did not.</p><p>You might push back against my skepticism: I\u2019m undercutting an argument that schooling increases earnings by invoking the universal truth, confirmed in the graph above, that pay and education go hand in hand \u2014 which itself seems like powerful evidence that education increases earnings!</p><p>To which I reply: The Duflo study strives not merely to prove that education raises wages, but to measure the impact more sharply. It invokes a natural experiment to remove sources of statistical bias, such as my urban inflation hypothetical. It matters whether the natural experiment is working as intended.</p><h2><strong>Fresh findings</strong></h2><p>To probe whether wage scale dilation is generating the Duflo study\u2019s results \u2014 and to return to the search for bent trends \u2014 I pursued three strategies:</p><ul><li>As foreshadowed, I tested mathematically whether the trend really bends in that Duflo graph I showed earlier. The wage scale dilation theory amplifies the importance of this check: I have no reason to think that wage scale dilation <i>suddenly</i> kicks in at a particular age, so a clear bend in the trend of emergence of those differences-in-differences would favor the Duflo explanation as laid out in that first table above.</li><li>I deployed a newer statistical method called&nbsp;<a href=\"https://www.jstor.org/stable/3598807\"><u>changes-in-changes</u></a>, which should be immune to wage scale dilation.</li><li>I followed up later on the same generation of Indonesian men, in data from 2005, 2010, and 2013\u201314 (a selection dictated by whether the surveys asked the needed questions and whether the answers are publicly available). One reason was to see whether the reported link between schooling and earnings was consistent over men\u2019s careers, or a one-off in 1995.</li></ul><p>To convey the results, I\u2019ll show you some graphs. All are constructed like that Duflo graph I showed before. But I\u2019ve incorporated the technical fixes, such as correcting data errors, and added some visual elements.</p><p>First comes my update of the \u201ceducation\u201d contour in the Duflo graph. Again, a precise statement of the meaning of the dots \u2014 blue in mine, black in the Duflo graph \u2014 is a mouthful. Each shows how much the old-young gap in total years spent in school, among men of a particular age, was associated with how intense the Inpres program was in their home regency.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref04rgdl00muv\"><sup><a href=\"#fn04rgdl00muv\">[10]</a></sup></span>&nbsp;Around the dots I added gray bands to depict 95% confidence intervals.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref65m2xklzvzb\"><sup><a href=\"#fn65m2xklzvzb\">[11]</a></sup></span>&nbsp;They remind us that because of noise in the data, each dot could have landed a bit lower or higher than it does. And I fit a line to the data, in red, while allowing it to kink at age 12:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/oqjfixq00xjyn5xyskte.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/oqjfixq00xjyn5xyskte.png 1024w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/ovyrip85vfowvtiow37g.png 300w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/ma5h5qi6jqwum2hlrylo.png 768w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/n52qlefzm94srodqcjkr.png 1536w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/tyifoo6jwkq2obxep0fw.png 2048w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/ebytquaknaulq2jzsl4l.png 320w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/sqhaupvtevmnhyhdr6aw.png 1440w\"></p><p>The schooling trend hardly bends. From the standpoint of this search for the fingerprint, it\u2019s not clear that building Inpres schools contributed to rising school attendance. A statistical test for whether the slopes of the two red segments differ returns a <i>p</i>-value of 0.60, which I printed in the upper left. That high probability means that a bend this small could easily have happened by chance, because of statistical noise, if the true line did not bend at all.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5jmblb2rzn6\"><sup><a href=\"#fn5jmblb2rzn6\">[12]</a></sup></span></p><p>Now, the Inpres program built <i>primary</i> schools. So did it at least get more kids to finish primary school? Quite possibly. In the next graph, the vertical axis pertains to the share of workers in 1995 who had finished primary school rather than the total years they spent in school. Now the trend more clearly accelerates around age 12. The <i>p</i>-value for the bend is reassuringly low, at 0.01:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/bbe1hddwmq7c1ykucphg.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/bbe1hddwmq7c1ykucphg.png 1024w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/fjaensaa6a51inyeqqje.png 300w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/xsgzvcybpyor6upn7dbd.png 768w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/nymqdk45b6lrtfk3felo.png 1536w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/zsb910qibjgnzbslyru2.png 2048w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/u4mjiw2de7pcqf3n9n8c.png 320w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/epx3priccvuyqogjyqnr.png 1440w\"></p><p>It\u2019s a strange pair of findings: boys finished primary school more but didn\u2019t go to school more? I have an explanation. The surveyors in 1995 didn\u2019t actually ask people how many years they went to school, but rather <a href=\"https://www.rand.org/content/dam/rand/www/external/labor/bps/datadocpdf/supas/supas95/supas95s.pdf#page=8\"><u>the highest grade they attended</u></a>. Probably, when the schools were first built, some kids who were officially too old to attend them went anyway, rather than going to junior high schools farther away.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefftvu6olfhp\"><sup><a href=\"#fnftvu6olfhp\">[13]</a></sup></span>&nbsp;Even if they spent exactly the same number of years in school, the study would have coded them as having spent fewer, since on paper they only got as far as sixth grade rather than seventh or eighth.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffgoqt2qxxes\"><sup><a href=\"#fnfgoqt2qxxes\">[14]</a></sup></span></p><p>If Inpres at least got more boys through primary school, did that suffice to raise their pay in adulthood? The next graph gets at that possibility by switching the vertical axis to wages. Again, the trend bends up, with a reassuringly low <i>p</i>-value:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/vrhzberklomqmthkryv3.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/vrhzberklomqmthkryv3.png 1024w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/hju0effogzk1k4whj5ky.png 300w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/x9ajvf2gibhlb05ztgn0.png 768w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/wono89jmsujsce8pvuws.png 1536w, https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/wnvpmhvwcxsas7tra5xz.png 2048w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/iacmhocy2nz33qms1qic.png 320w, https://res.cloudinary.com/cea/image/upload/v1673726252/mirroredImages/oZCPayvcxkDHubcDv/ga32m3hcr0j4mcifcq03.png 1440w\"></p><p><i>If</i> we assume that the deflection in the primary schooling trend caused the deflection in the wage trend, then we can divide the second by the first to gauge the rate of impact. Unfortunately, the first (the increase in primary school completion) still does not differ from zero with enough certainty to stabilize the ratio. In my<a href=\"https://arxiv.org/abs/2207.09036\"><u> paper</u></a> (Table 7, panel B, column 2) I calculate that finishing primary school changed wages in adulthood by somewhere between \u201312% and +\u221e, as a 95% confidence range.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefv78s1g8kstb\"><sup><a href=\"#fnv78s1g8kstb\">[15]</a></sup></span></p><p>Another source of doubt: when I checked on the same generation of men later in life, the upward bend in the wage trend didn\u2019t persist as strongly. In 2005 (when the men aged 2\u201324 in 1974 had reached ages 33\u201355) and 2010 (ages 38\u201360), the line bends slightly downward.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefv827awy8yg8\"><sup><a href=\"#fnv827awy8yg8\">[16]</a></sup></span>&nbsp;In 2013\u201314 (ages 41\u201364), it bends more significantly upward. Rather than showing you all of those here, I\u2019ll average them in a single graph:<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpf0nvykt07q\"><sup><a href=\"#fnpf0nvykt07q\">[17]</a></sup></span></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1673726247/mirroredImages/oZCPayvcxkDHubcDv/ryfbpxgtv5che8mp1xvn.png\"></figure><p>The red line bends upward, with a <i>p</i>-value of 0.23. I\u2019m not one to mechanically dismiss a finding as \u201cinsignificant\u201d when the <i>p</i>-value exceeds 0.05. At face value, <i>p</i> = 0.23 means there\u2019s less than a 1-in-4 chance of a bend this big in the data if the true pattern is no bend at all. On the other hand, I could have put the finding to an even more rigorous test by including more of the control variables used in the Duflo study.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe7top8hcwxm\"><sup><a href=\"#fne7top8hcwxm\">[18]</a></sup></span></p><p>Separately, I ran the changes-in-changes method I mentioned, the one that should be immune to wage scale dilation. This approach&nbsp;<a href=\"https://arxiv.org/ftp/arxiv/papers/2207/2207.09036.pdf#page=35\"><u>finds no wage boost from Inpres</u></a>.</p><h2><strong>Conclusion</strong></h2><p>To recap:</p><ul><li>A representative result from the Duflo study is that Inpres-stimulated schooling increased future wages of boys by 7.5% per year of school, with a 95% confidence range of 1\u201315%.</li><li>Technical adjustments widen that range hugely. The main reason is that it is surprisingly unclear whether the Inpres school construction led boys to go to school more. Dividing any wage increase by a number that cannot be confidently distinguished from zero makes for instability.</li><li>It is more plausible that the program caused more boys to finish primary school.</li><li>There\u2019s another way to explain why the study finds that Inpres increased adult earnings. It is rooted in two facts: over their careers, more-educated people see their pay rise more (wage scale dilation); and poorer regencies got more schools per child.</li><li>The changes-in-changes method, which is in effect designed to rule out wage scale dilation as an explanation, finds no wage boost from Inpres.</li><li>On the other hand, an apparent fingerprint of Inpres, the trend bend, holds up fairly well in the wage data of 1995 despite my technical tweaks. And wage scale dilation would not be expected to cause such a bend.</li><li>The fingerprint persists weakly later in life.</li></ul><p>The&nbsp;<a href=\"https://www.fsb.miamioh.edu/lij14/411_paper_school2.pdf#page=18\"><u>Duflo study concludes</u></a>:</p><blockquote><p>The findings reported here are important because they show that an unusually large government-administered intervention was effective in increasing both education and wages in Indonesia.</p></blockquote><p>I am confident that, in retrospect, that reading is overconfident. But I wouldn\u2019t swing to the opposite extreme of <i>no </i>confidence. It seems more likely than not that building all those schools (and hiring all those teachers) got more kids into school. And the big push may have left light fingerprints in the wage numbers decades later. Meanwhile, it is conceivable that the conservatism of the changes-in-changes method, which makes it less prone to generating false positives, also makes it more prone to generating false negatives.</p><p>Still, the <i>rate</i> of return to Inpres-stimulated schooling \u2014 wage gains per additional unit of schooling \u2014 is quite unclear.</p><p>One\u2019s judgment about whether basic education in developing countries is a good thing should not hinge solely on the answers emerging from this study, nor even on the <i>questions</i> it asks. It could be that Inpres schools indeed made a large difference in Indonesia, but that the \u201cnatural experiment\u201d was just not strong enough for the signal to shine through the noise. Or \u2014 more likely \u2014 the problem is that, as Lant Pritchett puts it,&nbsp;<a href=\"https://www.cgdev.org/publication/9781933286778-rebirth-education-schooling-aint-learning\"><u>schooling ain\u2019t learning</u></a>. Maybe the Inpres schooling campaign was better at getting kids behind desks than knowledge into their heads. If billions of kids are passing through school and not learning much, there is huge room for improvement.</p><p>Moreover, higher pay is not the only reason to send kids to school. As I write, Duflo and coauthors are using randomly allocated scholarships in Ghana \u2014 an artificial rather than natural experiment \u2014 to&nbsp;<a href=\"https://www.socialscienceregistry.org/trials/15\"><u>research a wide array of potential consequences of secondary schooling, for girls as well as boys</u></a>. Do the girls go on to have fewer unwanted pregnancies? Do fewer of their children die in the first year of life?</p><p>I am struck by how often the findings from studies of \u201cnatural experiments\u201d fray under stress. An appreciation for that fact may explain why, soon after completing her dissertation, Esther Duflo became a champion of running actual experiments, such as the scholarship experiment in Ghana. Discarding some of what she learned in school would eventually pay high returns. It made Duflo the second woman to receive a Nobel prize in economics. And it drove her profession to produce more credible research.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnp1h5vg1v5w\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefp1h5vg1v5w\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See <a href=\"https://www.fsb.miamioh.edu/lij14/411_paper_school2.pdf#page=3\">Table 1, panel B, of the paper</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8fm4u0em6r\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8fm4u0em6r\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The study restricts to men because they more uniformly engage in paid employment or self-employment across their careers, which enhances comparability across age groups. Separately, Duflo <a href=\"https://doi.org/10.3386/w10513\">studied effects on girls</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkokaoo752p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkokaoo752p\">^</a></strong></sup></span><div class=\"footnote-content\"><p>More precisely, wages are taken in logarithms, so the \u201cpay gap\u201d is a ratio.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncg5x828w7vc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcg5x828w7vc\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"http://hdl.handle.net/10986/14889\">Duflo (2004, p. 350)</a> sees an additional virtue in this natural experiment: \u201cIdentification is made possible because the allocation rule for schools is known (more schools were built in places with low initial enrollment rates).\u201d But an allocation rule is no less endogenous for being known. And Duflo (2001, Table 2) shows that the non-enrollment rate was a secondary correlate of allocation. It matters even less after data corrections (<a href=\"https://arxiv.org/ftp/arxiv/papers/2207/2207.09036.pdf#page=8\">figure 1 of my write-up</a>).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbgslsm6y1qw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbgslsm6y1qw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Duflo\u2019s license to the 1995 survey data did not permit her to share it. But through the gratefully appreciated assistance of <a href=\"https://www.nber.org/people/daniel_feenberg?page=1&amp;perPage=50\">Daniel Feenberg</a>, I indirectly accessed the copy licensed by the NBER. Separately, IPUMS International hosts a <a href=\"https://international.ipums.org/international-action/sample_details/country/id#tab_id1995a\">large subset</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn293s849k9mc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref293s849k9mc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is not documented in the text but is made plain in the code.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnel29ikn82f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefel29ikn82f\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For intuition, imagine concentrating all weight on a few observations. This effectively slashes sample size.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4eamjxm0y1m\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4eamjxm0y1m\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Here, I express these results as percentages rather than log points, i.e. as exp(x) \u2013 1 where x is a primary statistical result.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn55q412pphdp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref55q412pphdp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Formally, I am suggesting a violation of the parallel trends assumption required for causal interpretation of difference-in-differences results.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn04rgdl00muv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref04rgdl00muv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Each dot shows, for men who were a particular age in 1974, how much their total years spent in school increased for each additional Inpres school per 1,000 children in one\u2019s native district, relative to the benchmark group, here taken to be those aged 2 in 1974. The sample is restricted to wage earners.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn65m2xklzvzb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref65m2xklzvzb\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.fsb.miamioh.edu/lij14/411_paper_school2.pdf#page=7\">Figure 1 of the Duflo study</a> also shows confidence intervals, but for the schooling contour only.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5jmblb2rzn6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5jmblb2rzn6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The same test applied to the uncorrected original returns a p-value of 0.09. See <a href=\"https://arxiv.org/ftp/arxiv/papers/2207/2207.09036.pdf#page=29\">figure 6 of my write-up</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnftvu6olfhp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefftvu6olfhp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The primary school gross enrollment ratio, which is the ratio of the number of kids attending primary school to the number of official primary school age, temporarily surpassed 100% in the 1980s. <a href=\"\">Suharti, \u201cTrends in education in Indonesia,\u201d</a> Figure 2.5.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfgoqt2qxxes\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffgoqt2qxxes\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In fact, the <a href=\"https://files.givewell.org/files/DWDA%202009/Interventions/Duflo01.pdf#page=10\">Duflo paper (page 804)</a> finds a slight fall in secondary school attainment.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnv78s1g8kstb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefv78s1g8kstb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The statistical method cannot rule out with 95% confidence that the Inpres schooling campaign had zero effect on the rate of primary school completion, and thus that the impact on wages per unit of gain in primary schooling was infinite.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnv827awy8yg8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefv827awy8yg8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For reasons of data availability, wages are defined differently in different years. In 1995 and 2010, they are the log hourly wage for wage workers. In 2005, they are log hourly wages as imputed from a model calibrated to 1995 data. In 2013-14, they are log typical monthly pay from all sources, including self-employment. The 2010 data have the disadvantage of being coded only by regency of workplace, not regency of birth.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpf0nvykt07q\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpf0nvykt07q\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The regressions behind this plot pool the data from all post-1995 follow-ups. The dependent variable is the one defined within each survey sample. Year dummies are added as controls.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne7top8hcwxm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe7top8hcwxm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>One of these, Inpres water and sewer spending, could plausibly generate a trend break.</p></div></li></ol>", "user": {"username": "droodman"}}, {"_id": "NJxJHG3Q3N9brp4ik", "title": "Podcast: Shoshannah Tekofsky on skilling up in AI safety, visiting Berkeley, and developing novel research ideas", "postedAt": "2022-11-25T20:47:09.860Z", "htmlBody": "", "user": {"username": "Akash"}}, {"_id": "GijgjNxwcii4QahKQ", "title": "Is a biology baccalaureate a good start for an undergraduate looking to work on artificial pandemic prevention?", "postedAt": "2022-11-26T13:42:17.231Z", "htmlBody": "<p>I'm a 18 years old Brazilian student, almost finishing High School. I have a lot of interest in biology and I want my career to have the highest impact possible. So, I believe that working on this issue would be the best choice for me.</p>\n<p>However, I'm unsure about what graduation would be the best for me to pursue; should I study Biological Sciences, or is there a more suitable course?</p>\n", "user": {"username": "Eduardo Lu\u00eds Carls "}}, {"_id": "MwXAJfaqMvLhmvNsA", "title": "Effective Giving Day is only 1 day away!", "postedAt": "2022-11-27T21:53:03.041Z", "htmlBody": "<p>The global effective giving community has worked hard to create an awesome virtual event for Effective Giving Day! There are also several awesome groups around the world that are hosting their own events in person and online in Toronto, Vancouver, S\u00e3o Paulo, Sydney, Melbourne, Munich, Heidelberg, Estonia, Italy and more!</p><h2>Join us for Effective Giving Day on Monday 28th November</h2><figure class=\"media\"><div data-oembed-url=\"https://youtu.be/7UAKsvU2D6o\"><div><iframe src=\"https://www.youtube.com/embed/7UAKsvU2D6o\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p><i>Our community sharing why they give effectively</i></p><p>This year the global effective giving community is celebrating on the 28th of November (29th of November Asia/Pacific)!</p><p>Our event on YouTube Live will help you learn:</p><ul><li>How just one person really can make a difference: How to 100x your impact through effective donations</li><li>The newest findings in the philanthropic space from industry leaders</li><li>How effective giving has benefitted our member\u2019s lives: Featuring guest speakers bestselling author Rutger Bregman, ethicist Peter Singer and science broadcaster and professional poker player Liv Boeree</li></ul><p><a href=\"https://fb.me/e/3GILoWcbN\"><u>RSVP for Effective Giving Day via Facebook</u></a></p><p><a href=\"https://forum.effectivealtruism.org/events/yt8wLkFf48gqFmgzt/effective-giving-day-2022-youtube-live-event\"><u>RSVP for Effective Giving Day via the EA Forum</u></a></p><h1>Giving Season Events</h1><h3>Effective Giving Day - Main Online Event</h3><ul><li><a href=\"https://savvytime.com/converter/gmt-to-utc-united-kingdom-london-sgt-australia-melbourne-nigeria-lagos-cet/nov-28-2022/7pm\"><u>28 Nov at 19:00 UTC</u></a> (London: 7:00 pm, Munich: 8:00 pm, New York 2:00 pm, San Francisco: 11:00 am)&nbsp;</li><li><a href=\"https://fb.me/e/3GILoWcbN\"><u>RSVP on Facebook</u></a></li><li><a href=\"https://forum.effectivealtruism.org/events/yt8wLkFf48gqFmgzt/effective-giving-day-2022-youtube-live-event\"><u>RSVP for the event on the EA Forum</u></a></li><li><a href=\"https://youtu.be/OISn7ypXKdA\"><u>Set a reminder on YouTube</u></a></li></ul><h3>Effective Giving Day Viewing Party, Lunch and Giving Game (Hosted by Effective Altruists of UBC &amp; Vancouver)</h3><ul><li>28 Nov at 19:00 UTC (London: 7:00 pm, Munich: 8:00 pm, New York 2:00 pm, San Francisco: 11:00 am)&nbsp;</li><li><a href=\"https://discord.com/invite/WpY6GZ6w?event=1036715704361173003\"><u>Discord</u></a></li></ul><h3>Effective Giving Day: Toronto</h3><ul><li>28 Nov at 23:30 UTC (Toronto/EST: 6:30pm)</li><li><a href=\"https://www.facebook.com/events/6571576559570605/\"><u>Event details</u></a></li><li><a href=\"https://www.meetup.com/toronto-effective-altruism-meetup/events/289503597/\"><u>RSVP via Meetup</u></a></li></ul><h3>Effective Giving Day: S\u00e3o Paulo</h3><ul><li>28 Nov at 22:30 UTC(S\u00e3o Paulo: 7:30pm)</li><li><a href=\"https://forms.gle/TNniWffPecRFxmiU8\"><u>Event details</u></a></li><li><a href=\"https://forms.gle/TNniWffPecRFxmiU8\"><u>Register interest via Google Form</u></a></li></ul><h3>Effective Giving Day: Vancouver</h3><ul><li>28 Nov at 18:45 UTC (Vancouver time: 10:45am)</li><li><a href=\"https://zoom.us/meeting/register/tJcud-6rqTwuGNVtQkyI8zodxxkQd8Dhvgo_\"><u>Event details</u></a></li><li><a href=\"https://zoom.us/meeting/register/tJcud-6rqTwuGNVtQkyI8zodxxkQd8Dhvgo_\"><u>RSVP via Zoom</u></a></li></ul><h3>Effective Giving Day: Heidelberg</h3><ul><li>28 Nov at 18:30 UTC (Heidelberg time: 7:30pm)</li><li><a href=\"https://fb.me/e/dlVpVfHUN\"><u>Event details</u></a></li><li><a href=\"https://fb.me/e/dlVpVfHUN\"><u>RSVP via Facebook</u></a></li></ul><h3>Effective Giving Day: Estonia</h3><ul><li>28 Nov</li><li><a href=\"https://www.facebook.com/EfektiivneAltruismEesti/events/\"><u>Check for details on Facebook</u></a></li></ul><h3>Effective Giving Day: T\u00fcbingen</h3><ul><li>28 Nov at 18:30 (7:30pm Heidelberg time)</li><li><a href=\"https://www.google.com/calendar/event?eid=NmdxNjhlMW5jY3E2NGJiNGNkaGppYjlrNm9zbTZiYjE2NHIzOGJiNWNkZ2ppZGI2NmRqNjhwaGo2YyBrODkxajRrZmM1YmJ2c2Q5OGUwOTJ1YTViNEBn&amp;ctz=Europe/Copenhagen\"><u>Event details</u></a></li><li><a href=\"https://www.google.com/calendar/event?eid=NmdxNjhlMW5jY3E2NGJiNGNkaGppYjlrNm9zbTZiYjE2NHIzOGJiNWNkZ2ppZGI2NmRqNjhwaGo2YyBrODkxajRrZmM1YmJ2c2Q5OGUwOTJ1YTViNEBn&amp;ctz=Europe/Copenhagen\"><u>RSVP via Google Calendar</u></a></li></ul><h3>Effective Giving Day: Italy</h3><ul><li>28 Nov at 19:00 UTC</li><li><a href=\"https://altruismoefficace.it/eventi\"><u>Event details via Slack</u></a></li><li><a href=\"https://altruismoefficace.it/eventi\"><u>RSVP via Slack</u></a></li></ul><h3>Effective Giving Day: Sydney</h3><ul><li>29 Nov at 06:30 UTC (Sydney: 5:30pm)</li><li><a href=\"https://fb.me/e/2WXI99Gs5\"><u>Event details</u></a></li><li><a href=\"https://bit.ly/3TsuObk?fbclid=IwAR08YomdSw7nME6nomMQ4CBkvN1a0AP1vWduVHzbvwreoWDxIjHiQ3F3knI\"><u>RSVP via Google Form</u></a></li></ul><h3>Effective Giving Day: Melbourne</h3><ul><li>29 Nov at 06:15 UTC (Melbourne time: 5:15pm)</li><li><a href=\"https://www.facebook.com/events/429626766048268/\"><u>Event details</u></a></li><li><a href=\"https://www.facebook.com/events/429626766048268/\"><u>RSVP via Facebook</u></a></li></ul><h3>Munich GWWC/EA Event - December 2022</h3><ul><li>1 Dec at 18:00 UTC (Munich: 7pm)</li><li><a href=\"https://fb.me/e/2fnKgm9bl\"><u>RVSP on Facebook</u></a></li><li><a href=\"https://fb.me/e/2fnKgm9bl\"><u>Event details</u></a></li></ul><h3>Are you hosting your own Effective Giving Day event?</h3><p><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdzLCjdDBVOrq0StMi3rzqLOmx872Vs-pzMZC2leGMD9G5YbQ/viewform\"><u>Register your Effective Giving Day event with us!</u></a></p>", "user": {"username": "Giving What We Can"}}, {"_id": "v7gep2d9Dr4bT8DnF", "title": "Notes on \"Barriers to Bioweapons\" (Ben Ouagrham-Gormley, 2014)", "postedAt": "2022-11-26T14:30:45.735Z", "htmlBody": "<p>I recently read (most of<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxkk1qfldd9\"><sup><a href=\"#fnxkk1qfldd9\">[1]</a></sup></span>) the 2014 book&nbsp;<a href=\"https://www.cornellpress.cornell.edu/book/9780801452888/barriers-to-bioweapons/\"><i><u>Barriers to Bioweapons: The Challenges of Expertise and Organization for Weapons Development</u></i></a> by&nbsp;<a href=\"https://schar.gmu.edu/profiles/sbenouag\"><u>Sonia Ben Ouagrham-Gormley</u></a>. (See also the author\u2019s 2012&nbsp;<a href=\"https://doi.org/10.1162/ISEC_a_00077\"><u>paper on the topic</u></a> and&nbsp;<a href=\"https://eukaryotewritesblog.com/2017/06/30/book-review-barriers/\"><u>this book review</u></a>)</p><p><strong>I found the book very insightful and recommend it to others interested in biosecurity</strong>, especially those interested in biological weapons nonproliferation and the debate around life science dual-use research of concern. The book is well-written, highly accessible, and fairly short (~170 pages).&nbsp;</p><p><i><strong>Barriers to Bioweapons</strong></i><strong> is a valuable corrective to the common but mistaken belief that (given current technology) it is trivially easy and cheap to develop biological weapons</strong>. Its key argument\u2014that tacit knowledge presents the main obstacle to biological weapons development\u2014has important policy implications for those seeking to reduce biological risks. Moreover, the book offers a fascinating perspective on the scientific process and innovation beyond the life sciences.</p><p>While I disagree with some of the book\u2019s conclusions, the book is nevertheless well worth reading. My main disagreements concern the author\u2019s opposition to publication restrictions and her optimism that future biotech progress won\u2019t drastically erode the \u2018barriers to bioweapons\u2019.</p><p>In this post, I share some of my copied-and-pasted notes from the book that were of particular interest to me (excluding chapters 4-6). These notes cannot do justice to the book's extended discussion. Still, I hope some people may find my notes valuable and perhaps be inspired to read the book.&nbsp;</p><p>To let you decide whether to keep on reading, here is a summary of the book\u2019s core argument (taken from&nbsp;<a href=\"https://www.cornellpress.cornell.edu/book/9780801452888/barriers-to-bioweapons/\"><u>here</u></a>):</p><blockquote><p>In both the popular imagination and among lawmakers and national security experts, there exists the belief that with sufficient motivation and material resources, states or terrorist groups can produce bioweapons easily, cheaply, and successfully (...) Sonia Ben Ouagrham-Gormley challenges this perception by showing that bioweapons development is a difficult, protracted, and expensive endeavor, rarely achieving the expected results whatever the magnitude of investment (...)</p><p>Bioweapons development relies on living organisms that are sensitive to their environment and handling conditions, and therefore behave unpredictably. These features place a greater premium on specialized knowledge (...) lack of access to such intellectual capital constitutes the greatest barrier to the making of bioweapons (...) The specific organizational, managerial, social, political, and economic conditions necessary for success are difficult to achieve, particularly in covert programs where the need to prevent detection imposes managerial and organizational conditions that conflict with knowledge production.</p></blockquote><p>Throughout this post, my highlights are in&nbsp;<strong>bold</strong>.</p><h2>Prologue</h2><h3><strong>Past biological weapons programs</strong></h3><blockquote><p>Interviews with former bioweaponeers conducted in the United States, Russia, and Kazakhstan between 2008 and 2012 told a story about past bioweapons efforts that requires us to reconsider current threat assessments. Put simply, their testimonies show how difficult, protracted, and expensive bioweapons efforts have been; outcomes rarely achieved what the magnitude of investment might have suggested. This is good news for nonproliferation. The bad news, however, lies in our ignorance of key determinants of bioweapons development that create new opportunities for proliferation</p></blockquote><h2>Chapter 1: The Bioproliferation Puzzle</h2><h3><strong>The book\u2019s argument</strong></h3><blockquote><p>Would access to published documents suffice to allow replication of past work? If so, does this mean that the bioterrorism threat automatically increases with the progress of science? In this book I argue that the answer to these two questions is negative.</p><p>This is&nbsp;<strong>contrary to the belief</strong>, shared by many analysts and policymakers, that&nbsp;<strong>bioweapons development requires only the procurement of three easily accessible resources: biomaterials, scientific data, and equipment</strong>. Therefore, the question of what skills and what conditions would allow replication is not considered.</p><p>Yet the analysis of past state and terrorist bioweapons programs shows that producing a working bioweapon is not a simple process of material accumulation. The challenge in developing biological weapons lies not in the acquisition but in the use of the material and technologies required for their development. Put differently,&nbsp;<strong>in the bioweapons field, expertise and knowledge\u2014and the conditions under which scientific work occurs\u2014are significantly greater barriers to weapons development</strong> than are procurement of biomaterials, scientific documents, and equipment.</p><p>Contrary to popular belief, however,&nbsp;<strong>this specialized bioweapons knowledge is not easily acquired.</strong> Therefore, current threat assessments that focus exclusively on the formative stage of a bioweapons program and measure a program\u2019s progress by tracking material and technology procurement are bound to overestimate the threat.</p></blockquote><h3><strong>Implications of the book\u2019s argument</strong></h3><blockquote><p>measuring the pace and success rate of a program requires a detailed understanding of what factors shape knowledge acquisition and use within that program.&nbsp;</p><p>Finally, because the variables that truly affect the success of a bioweapons program are not currently addressed,&nbsp;<strong>the door remains open to proliferation</strong>. This reality dictates major changes in nonproliferation and counterproliferation approaches to address actual bioweapons threats.&nbsp;<strong>Current policies focus almost exclusively on preventing access to the troika of resources deemed essential</strong> for bioweapons development: material, scientific information, and technologies. By also&nbsp;<strong>targeting knowledge and the factors that affect its use, these policies could more effectively inhibit the growth of a weapons program</strong> and possibly bring about its collapse.</p></blockquote><h3><strong>Misconceptions about bioweapons</strong></h3><blockquote><p>Three misconceptions are at the heart of the current faulty assessment of the bioweapons threat. The first finds its roots in the use of the nuclear model as a starting point to assess bioweapons development. Put simply, because biological weapons do not face the same stiff material barrier as do nuclear weapons, they are deemed easy and cheap to produce. The second lies in the assumption that any biology-related knowledge is applicable to bioweapons development and that bioweapons expertise is easily acquired and used. The third assumes that new technologies will erase the technical barriers to bioweapons development, allowing even untrained individuals to achieve successful results.</p></blockquote><h3><strong>Differences between nuclear and biological weapons</strong></h3><blockquote><p>[nuclear and biological weapons] use materials of a decidedly different nature, which create barriers to entry at different points of their development process (...)</p><p>In the nuclear field, a key barrier to entry is located at the front end of the development process, at the stage of material acquisition. Achieving nuclear weapons is indeed conditioned by the ability to produce fissile material, which requires large facilities and specialized equipment.</p><p>When applied to bioweapons, however, the front-end/material- based nuclear model produces a distorted and even apocalyptic picture of the threat. Most analysts and policymakers stress that pathogens\u2014viruses, bacteria, and toxins\u2014can be isolated from nature or obtained commercially because they also have legitimate commercial or pharmaceutical use. They point out that equipment is essentially dual use and can therefore be readily purchased, while scientific publications provide ample descriptions of experiments and techniques that many believe can be easily replicated. (...)&nbsp;</p><p>Unlike nuclear weapons, which rely on materials with physically predictable properties,&nbsp;<strong>bioweapons are based on living organisms or by-products of living organisms</strong>, which evolve, are prone to developing new properties, and are sensitive to environmental and handling uncertainties.&nbsp;<strong>Their behavior, therefore, is unpredictable throughout all stages of development and use as a weapon</strong>, which imposes an extended trial-and-error process to acquire the skills necessary to solve problems that inevitably arise. (...)&nbsp;</p><p>unlike nuclear weapons, which can use only two sources of material\u2014highly enriched uranium and plutonium-239\u2014<strong>bioweapons development can exploit a large number of agents that vary in type (bacteria, viruses, toxins), properties (virulence, infectivity, transmissibility), and ease of culturing.</strong> Each agent also includes several strains with varying properties, further complicating bioweapons development.</p></blockquote><h3><strong>The bioproliferation puzzle and past programs</strong></h3><blockquote><p>If bioweapons developments were so simple, more states and terrorist groups should have achieved satisfactory results. But historical evidence shows otherwise. (...)</p><p><strong>none of the past bioweapons programs have been completely successful</strong>.&nbsp;<strong>The Soviet Union,</strong> which had the largest and longest-running program, did not reach the level of accomplishment that its&nbsp;<strong>sixty-year lifespan and estimated investment of $35 billion might suggest</strong>. Soviet scientists successfully weaponized several classical agents, loading them into a variety of bombs, but according to recent evidence, their work on engineered pathogens\u2014the program\u2019s main focus during its last two decades\u2014did not extend beyond the exploratory phase.</p><p><strong>The American program</strong>, arguably the second largest program after the Soviet Union\u2019s,&nbsp;<strong>cost about $700 million over twenty-seven years</strong> but resulted in only a small arsenal of bombs filled with half a dozen agents, and no ballistic or cruise missiles to deliver them.</p><p>Other states and terrorist programs performed even more dismally.&nbsp;<strong>Iraq invested twenty years and over $80 million</strong> during the last five years of the program alone to produce ineffective bombs that would have destroyed most of the liquid agents they contained.&nbsp;<strong>South Africa devoted twelve years and over $30 million</strong> to its program while producing only poisonous substances for assassination purposes. Finally, the Japanese terrorist group&nbsp;<strong>Aum Shinrikyo spent six years and about $10 million</strong> trying to produce anthrax- and botulinum-based weapons but failed at every stage of these bioweapons\u2019 life cycles.</p></blockquote><h3><strong>Challenges of working with living organisms</strong></h3><blockquote><p>working with live organisms is not easy. (...) this unpredictability places greater emphasis on possessing the unique skills necessary to handle highly capricious biological agents and maintain their desirable properties throughout the development process. (...) Due to the fragility of living microorganisms,&nbsp;<strong>possessing the skills to handle and manipulate them throughout the development process is a greater barrier to entry into the bioweapons field than is material procurement</strong>.</p></blockquote><h3><strong>Scaling up bioweapons production</strong></h3><blockquote><p>these challenges are particularly acute as the agent moves down the development process toward weaponization. (...)</p><p>One such stage is scale-up.&nbsp;<strong>Biomaterials do not scale up easily</strong>. Yet the passage from a laboratory sample to larger quantities, whether a few gallons used in a terrorist program or industrial quantities used in a state program, stands as a critical stage of bioweapons development.&nbsp;<strong>Because scale-up is not a linear process, increases in quantity must occur gradually</strong>. Each increase, however, entails new challenges that impose changes to the production protocols. (...)</p><p>production and scale-up often subjected bioagents to contamination, which caused multiple delays and failures both in the U.S. and the Soviet bioweapons programs. Pharmaceutical and biotech companies also routinely endure such failures due to the complexity and sensitivity of biological organisms. (...)</p><p>Successful scale-up also requires the intervention of interdisciplinary teams with a variety of skills, whose work must be carefully integrated and coordinated. Integration and coordination are particularly important in large programs, which may involve thousands of individuals and hundreds of facilities (as in the Soviet program), but also in smaller ones, such as the Iraqi program, which involved about one hundred people.</p></blockquote><h3><strong>Knowledge transfer across work involving different agents</strong></h3><blockquote><p><strong>the expertise acquired while working with one agent does not necessarily transfer to another microorganism</strong>. This lack of knowledge transferability limits the ability of a state or group to transition easily to new types of bioweapons should their work with one agent fail to produce tangible results. (...) transitioning to a new organism entails a lengthy period of knowledge acquisition, which would necessarily delay progress.</p></blockquote><h3><strong>The fallacy of universal, free-flowing knowledge</strong></h3><blockquote><p>The second tenet of the current view of bioweapons proliferation is that science-based knowledge and technology are universal, independent of context, impersonal, public, and cumulative. As a result, knowledge spreads easily, and written documents, such as scientific publications, weapons designs, or scientific protocols, constitute complete representations of a technological artifact, thus allowing the replication of past work, even by untrained individuals.</p><p>however,&nbsp;<strong>knowledge is far from free flowing</strong>. Studies of knowledge transfer in various technological environments, including bioweapons technology, show that&nbsp;<strong>access to scientific documents does not guarantee their successful use, even by experts</strong>. This is so because scientific documents include only a small fraction of the knowledge produced within a program or scientific experiment.</p></blockquote><h3><strong>Tacit and explicit knowledge</strong></h3><blockquote><p>technical knowledge results from a process of experimentation that produces both explicit and tacit knowledge. Whereas&nbsp;<strong>explicit knowledge&nbsp;</strong>can be codified and encapsulated in different physical formats that are easy to transfer\u2014protocols, formulas, or designs\u2014<strong>tacit knowledge</strong> is constituted of know-how: unarticulated skills or practices that cannot be reduced to a written form and are often personal, local, and context specific. Their transfer requires direct and prolonged interaction among people, and their use in a new location requires adaptation to the new site. (...) unlike explicit knowledge, which has a long shelf life,&nbsp;<strong>tacit knowledge decays over time if not sustained through practice</strong>.</p></blockquote><h3><strong>Communal knowledge</strong></h3><blockquote><p>complex projects such as bioweapons development involve teams of scientists and technicians, representing different disciplines, who, through their interactions and cooperative work, produce a different form of knowledge\u2014known as com<strong>munal knowledge</strong>\u2014which is shared by all team members but possessed entirely by none. As a result, even individual experts possess only a limited knowledge of a whole weapon and its development.</p></blockquote><h3><strong>Replication of past work</strong></h3><blockquote><p><strong>Replicating past work using scientific documents alone, therefore, cannot be achieved without access to the corresponding tacit skills and the related communal knowledge</strong>. (...)</p><p>Tacit knowledge aside,&nbsp;<strong>written or published scientific documents are also often incomplete</strong> because they fail to emphasize essential aspects of scientific success, such as the contingencies associated with key stages of an experiment, the characteristics of the equipment\u2014some scientists have their equipment custom-made to increase the rate of success for certain manipulations\u2014or the laboratory routines that constitute essential parts of the scientific discipline and success. Experimental work also involves making changes on the fly that are not necessarily recorded, either for lack of time or because the scientists do not recognize the importance of these changes for experimental success. Without such details, reproduction is made even more complicated. (...)&nbsp;</p><p>Thus, scientific innovations and their corresponding documents&nbsp;<strong>require extensive interpretation and judgment from users other than their authors, which in turn necessitates the possession of prior base knowledge</strong> and ideally the ability to work in close cooperation with the documents\u2019 authors. In addition, applying these scientific findings to bioweapons developments requires the acquisition of bioweapons expertise, which can take years.&nbsp;<strong>These conditions constitute major obstacles for replication of past work</strong>, particularly for untrained individuals operating under covert conditions.</p></blockquote><h3><strong>Dual-use research</strong></h3><blockquote><p>concerns about the risk associated with publication of dual-use research hinge on two other erroneous assumptions. (...)</p><p>First is the assumption that expertise acquired in a civilian laboratory can easily be applied to bioweapons work. Here again history belies this belief. (...)</p><p>The second assumption is that innovations achieved in the laboratory can be easily fashioned into a harmful agent or a bioweapon. In fact, past bioweapons work, as well as current pharmaceutical efforts, show that <strong>transforming a scientific concept developed in the laboratory into a product that has a specific applied purpose and that functions reliably and effectively can take several decades and require the intervention of a wide array of expertise </strong>(...) bioweaponeers also face the challenge of developing a delivery mechanism that will protect living organisms and toxins from degradation due to environmental conditions (...)&nbsp;</p><p>Therefore, laboratory successes are not equivalent to successful application to a specific purpose. Specialized skills acquired through hands-on involvement in production and weaponization work are needed.</p></blockquote><h3><strong>(Fallacious) assumptions about biotechnology and risks</strong></h3><blockquote><p>Because they automate processes that previously required the manual intervention of skilled personnel,&nbsp;<strong>new technologies are believed to facilitate replication of past work and allow their application to bioweapons development</strong>. What\u2019s more, economic globalization and the rapidly decreasing cost of such technologies are deemed to be key factors in accelerating their diffusion, making it almost impossible to rein in bioweapons proliferation. (...)</p><p>The narrative behind the biotechnology revolution rests on two important premises:&nbsp;</p><p>(1)&nbsp;<strong>new technologies and equipment are black boxes</strong>, with an input and an output, which can be used by any user, irrespective of their technical skills; and&nbsp;</p><p>(2)&nbsp;<strong>technology developments result in a gradual deskilling of technological and scientific work</strong>. Therefore, machines and their accompanying instructions become the embodiment of human knowledge, captured and codified for easier use by less experienced individuals.</p></blockquote><h3><strong>Knowledge and machines</strong></h3><blockquote><p>If knowledge was completely embedded in machines, all users would achieve equal results whatever their level of expertise. Empirical research shows that this is not the case. (...)&nbsp;</p><p>Instead, technologies, very much like written documents, constitute imperfect representations of their designers\u2019 knowledge, and although they may simplify some tasks, they require from their users extensive experimentation, interpretation, and adaptation to a new location to achieve successful results. This is due to the fact that&nbsp;<strong>new technologies rarely automate all aspects of a task, requiring scientists to perform some tasks manually</strong>. (...) Furthermore, machines, however sophisticated, are also prone to errors, requiring their users to possess the skills to identify and correct problems.</p></blockquote><h3><strong>Analytical framework</strong></h3><blockquote><p>My analytical framework defines the&nbsp;<strong>sustenance phase</strong> of a program as the key stage of bioweapons development, in which knowledge acquisition is the key variable. I also offer two sets of factors that affect the use of knowledge\u2014those from within a program (endogenous variables) and those from the outside (exogenous variables)\u2014the combination of which results in different speeds and outcomes. (...)&nbsp;</p><p><strong>Most important to a program\u2019s timeline and outcome is the way in which states or terrorist groups integrate these two sets of variables</strong>: social, organizational, and managerial factors that influence knowledge acquisition and scientific work from within; and exogenous variables that influence achievements from the outside. (...)&nbsp;</p><p><strong>endogenous and exogenous characteristics of a bioweapons program can facilitate or hinder its development</strong>. Although access to material resources is important, it is the combination of organizational, managerial, political, and economic circumstances characterizing a program that ultimately affects its ability to produce and use knowledge, and thus affect the pace and ultimate program output.</p></blockquote><h3><strong>Endogenous factors affecting bioweapons program success</strong></h3><blockquote><p><strong>technology results from the interaction among individuals who combine their respective expertise to produce a working technological artifact</strong>. A program\u2019s success will therefore depend on these individuals\u2019 ability to cooperate, exchange information, learn from one another, and institutionalize knowledge. (...)</p><p>Because knowledge transfer depends on the quality and frequency of individual interactions, the manner in which a program organizes and manages its resident-expert knowledge will also influence scientific outcomes.</p><p>Consequently, a bioweapons program\u2019s&nbsp;<strong>structural and work organization, its management style, and the social context within which knowledge is created constitute the endogenous variables</strong> that figure into a program\u2019s success or failure.</p></blockquote><h3><strong>Exogenous factors affecting bioweapons program success</strong></h3><blockquote><p><strong>weapons programs do not happen in a vacuum; they frequently depend on their external context</strong>. Several such exogenous variables influence the conditions in which scientific work occurs.&nbsp;</p><p><strong>Foreign technical assistance</strong> is one of these variables. (...) Two other exogenous factors\u2014<strong>the priority political or group leaders devote to a program, and a program\u2019s economic circumstances</strong>\u2014also affect a program\u2019s outcome, not only because they have an impact on programmatic and funding decisions but also because they&nbsp;<strong>influence the continuity and stability of scientific work</strong>\u2014two essential conditions for the accumulation of knowledge. These factors may also generate scientific behaviors that can produce bad science. (...) Finally, in some cases,&nbsp;<strong>the location</strong> of a program can promote or constrain its development and the successful use of technologies by affecting the properties of the material used in laboratory work.</p></blockquote><h3><strong>Secrecy as a barrier</strong></h3><blockquote><p><strong>covert [bioweapons] programs</strong> face greater limitations on information exchange, organization, management, and their ability to deal with exogenous factors.</p></blockquote><h2>Chapter 2: The Acquisition and Use of Specialized Knowledge</h2><h3><strong>Knowledge as the key barrier to bioweapons</strong></h3><blockquote><p><strong>specialized knowledge is not easy to acquire, use, or transfer because much of it is tacit, local, and collective in nature</strong>. In addition, scientific knowledge pertaining to a technological artifact is rarely stored in a central location. It is more often held in various interdependent reservoirs, each containing a portion of the relevant knowledge. Moreover, knowledge decays over time if it is not used or transferred to the next generation. These factors raise&nbsp;<strong>questions about whether an untrained terrorist could in fact produce a biological or some other weapon of mass destruction (WMD) using easily accessible scientific data and material</strong>. (...)</p><p>The political science and policy literature is filled with&nbsp;<strong>assertions that knowledge and science-based technology are universal, independent of context, impersonal, public, and cumulative</strong>. This view suggests that science can be expressed in \u201cperfect language,\u201d is broadly accessible and understandable, and is therefore easy to master and replicate. We have seen why that is not true. (...)&nbsp;</p><p><strong>Scientific knowledge is in fact local, person specific, private, and noncumulative</strong>. Because tacit knowledge is transmitted from person to person and contained in various reservoirs, there are greater barriers to the spread of expertise than the traditional view might suggest. Thus,<strong> the likelihood that an untrained individual with minimal theoretical knowledge could produce a biological weapon (...) is very slim</strong>.</p></blockquote><h3><strong>Tacit and explicit knowledge</strong></h3><blockquote><p>knowledge is composed of two types:&nbsp;<strong>tacit and explicit</strong>.</p><p><strong>Explicit knowledge</strong> is that which can be translated into a written form or verbalized. Equations, numbers, laboratory protocols, recipes, designs, instructions, and scientific publications are good examples of explicit knowledge. Because explicit knowledge can be imprinted onto a physical support (be it paper or computer), it can be stored for long periods of time, copied, and transferred through impersonal means, such as e-mail messages or computer files.</p><p>In contrast,&nbsp;<strong>tacit knowledge</strong> is composed of unarticulated skills, know-how, practices, tricks of the trade, or visual and tactile cues that are more personally held. Because of its personal and intangible nature, tacit knowledge is less easily copied or stored on a physical support. Instead, it is stored in the brains of individual scientists, technicians, or engineers, which limits opportunities for its transfer. When transfer occurs, it requires direct interaction between individuals</p></blockquote><h3><strong>Acquisition of tacit knowledge</strong></h3><blockquote><p>the acquisition of that knowledge does not occur instantly; it often involves a long- term and painstaking process of learning (...) Even when tacit knowledge can be verbalized, its use can be fraught with obstacles because portions of the knowledge may continue to escape codification. As a result, its acquisition may involve a long-term trial-and-error process, during which individuals build a personal mental library of experimentations, allowing them to gradually and often unconsciously adjust the way they do things to reach success. (...)</p><p>Learning the forms of tacit knowledge that cannot be verbalized is even more complicated, because the novice cannot benefit from the conscious guidance of the teacher. In this context,&nbsp;<strong>the passage of the skill from one individual to another requires not only direct contact but also a lengthy apprenticeship</strong>.&nbsp;</p></blockquote><h3><strong>Learning by emulating vs learning by doing</strong></h3><blockquote><p>The acquisition of the skill by the recipient may follow different processes:&nbsp;<strong>learning by emulating or learning by doing</strong>. In the first process, scientist B observes scientist A and emulates him until the skill is acquired. Emulation can result from the conscious observation and replication of a specific way of doing things. (...) <strong>Learning by doing</strong> is the process required to learn motor skills\u2014skills dependent on body movements that can only be acquired through personal practice. A classic example of motor knowledge is riding a bike</p></blockquote><h3><strong>Knowledge types: communal knowledge</strong></h3><blockquote><p><strong>The development of complex products</strong>\u2014such as automobiles, aircraft, or weapons systems\u2014<strong>requires large teams</strong> of scientists, technicians, and engineers from a wide array of disciplines and with specific skills. Such projects are usually divided into a series of stages, integrated across functions. They call on the expertise of interdisciplinary teams, in which each individual contributes his or her personal knowledge to the development of the complex product. The final product is therefore a team effort, not the result of a scientist working alone. (...)</p><p>Through their contribution to the larger technical goal, teams of individuals produce a new form of knowledge\u2014<strong>communal knowledge</strong>\u2014that is spread among all contributors, but no one individual possesses the whole knowledge.</p></blockquote><h3><strong>Knowledge types: local knowledge</strong></h3><blockquote><p>Several studies have also emphasized <strong>the local character of knowledge</strong>. Because it is created within a specific environment, by a specific set of individuals, and with a specific infrastructure, <strong>knowledge cannot be easily transferred to a new location</strong>. (...) <strong>The translation process therefore often leads to a \u201creinvention\u201d of the technology</strong>, because vastly different circumstances at the new location cause the product resulting from the translation to differ from the original. (...)</p><p>The local character of knowledge is also expressed in the often inaccessible or hidden idiosyncrasies of a specific laboratory. Those idiosyncrasies cannot be standardized and transferred to a new location because they reflect individual and communal knowledge along with&nbsp;<strong>laboratory disciplines and routines</strong> not always recognized as part of an experiment.</p></blockquote><h3><strong>Learning and knowledge creation</strong></h3><blockquote><p><strong>Specific factors are required to allow the learning and creative process to proceed</strong>. These include the state of knowledge at the starting point, the need to create a common knowledge base, the existence of a work environment allowing informal communications, and the development of trust between collaborators. (...)</p><p>One key factor in learning tacit knowledge is the recipient\u2019s base knowledge. Individuals absorb new ideas better when they can associate them with things they already know. In other words,&nbsp;<strong>building on existing expertise is easier than learning something completely new</strong>. Conversely, transferring knowledge from the source to the recipient is easier when both have knowledge in common, which results in part from similar training and backgrounds. (...)</p><p>However, building this common knowledge requires more than just formal training. Several studies have shown that <strong>informal interactions within and outside an institution are essential for the transfer and learning process to occur </strong>(...) This process is especially important for novices or beginners who, because of their limited exposure to a field, need to complement their theoretical knowledge with practical expertise. (...)</p><p><strong>producing, creating, transferring, and learning tacit skills are part of a social process&nbsp;</strong>in which individuals learn through exposure to more experienced colleagues\u2014as much as they do through their own experimentation and personal practice. As a result, knowledge is dependent on connections among individuals, their histories, and their physical circumstances,&nbsp;<strong>making it context dependent and not always easy to use in different circumstances</strong>.</p></blockquote><h3><strong>Knowledge reservoirs</strong></h3><blockquote><p><strong>knowledge is also stored in various reservoirs</strong>. (...) Although they contain different types of knowledge, these individual reservoirs are interdependent (...) Given the interdependence of knowledge reservoirs, it is not surprising that&nbsp;<strong>access to information from one but not the others strongly limits the ability to replicate past work</strong>. (...)</p><p>For example, though tacit and explicit knowledge are distinct, the boundaries between them are hard to delineate, and the two are intimately connected (...) Thus,&nbsp;<strong>the absence of tacit knowledge can prevent the use of explicit information</strong> and make it difficult to repeat previously successful experiments\u2014even when attempted by experienced individuals. (...)&nbsp;</p><p><strong>reservoirs of tacit knowledge are essential not only to replicating past work but also to preserving a technology</strong>. Indeed, the erosion of tacit knowledge through lack of practice, reorganization, or restructuring that affects corporate culture, work organization, routines, and communities of practice can have a deleterious effect on a technology</p></blockquote><h3><strong>Knowledge reservoirs: written documents</strong></h3><blockquote><p><strong>Written documents</strong>\u2014be they blueprints, protocols, scientific publications, or other scientific data\u2014<strong>are the main reservoirs of explicit knowledge</strong>, as they can be easily transferred and stored for long periods of time. Written documents, however, contain only knowledge that can be codified. Much of the knowledge created during experimental work is tacit and cannot be easily captured in written form. In addition, different types of documents serve different purposes and may only contain data useful to their target audience\u2014be it the general public, professionals, or experts in a specific field. (...)&nbsp;</p><p>These&nbsp;<strong>written documents are all incomplete reservoirs of knowledge</strong>, which explains why they require extensive interpretation, user modifications, and adaptations to fit specific needs and work conditions. The incomplete nature of documents also stems from the fact that they record knowledge at a specific point in time, whereas knowledge creation and learning are dynamic processes.</p></blockquote><h3><strong>Knowledge reservoirs: people</strong></h3><blockquote><p>In scientific institutions and firms,&nbsp;<strong>individuals are the main reservoir of knowledge</strong>, acquired through their own direct experience and observations and through collaboration with colleagues. However, in complex projects, individuals are only partial reservoirs of the knowledge pertaining to a technical artifact. (...) A wider and more complete knowledge of the technical artifact is retained collectively\u2014or shared among teams of scientists and technicians. (...)&nbsp;</p><p>Because&nbsp;<strong>collective knowledge</strong> far exceeds the capabilities of any individual,&nbsp;<strong>it cannot be centrally stored;</strong> instead, it is spread across the organization. Much of this knowledge is also tacit in nature, making its transfer or reproduction difficult without the intervention of the collective.</p></blockquote><h3><strong>Knowledge reservoirs: corporate culture</strong></h3><blockquote><p>Another, often overlooked, knowledge reservoir is&nbsp;<strong>corporate culture</strong>. (...) Shared culture is the product of past experiences, transmitted to new generations of employees through informal discussions, training, observation, behavior, or explicit rules of conduct. Like tacit knowledge, corporate culture conveys both certain values and scientific practices.</p></blockquote><h3><strong>Knowledge reservoirs: communities of practice</strong></h3><blockquote><p>Communities of practice are also important reservoirs of knowledge. Unlike corporate culture, which is confined by the walls of an institution,&nbsp;<strong>communities of practice embrace a whole professional community</strong>. Communications and exchanges between individuals within communities of practice allow methods and approaches to spread. In the process, such exchanges enrich personal and communal knowledge, as well as that of the corporate culture.</p></blockquote><h3><strong>Knowledge reservoirs: organizational structure</strong></h3><blockquote><p>A final knowledge reservoir is the organizational structure of an institution. In complex projects, in which different teams perform specific tasks, the organizational structure reflects the sequence of tasks. More precisely, the&nbsp;<strong>organizational structure indicates how the specialized knowledge created within each division is transferred to and used by other divisions</strong>, creating a new institutional knowledge.</p></blockquote><h3><strong>Knowledge loss and decay</strong></h3><blockquote><p>When employees retire or organizations are restructured, mistakes, disruptions in production, or decreases in output quality often follow, due to a loss of know-how (...)&nbsp;<strong>knowledge needs to be replenished continuously; otherwise, it depreciates</strong>. Scholars in the science and technology field have also observed that tacit knowledge can decay over time if it is not used, practiced, or transmitted to a new generation of specialists.&nbsp;<strong>Trying to re-create lost knowledge can be difficult, if not impossible</strong>.</p></blockquote><h3><strong>How knowledge loss occurs</strong></h3><blockquote><p>Knowledge loss can occur at different levels. (...) At&nbsp;<strong>the organizational level</strong>, a massive loss of personnel due to restructuring or retirements may cause an institution to lose valuable experimental knowledge and insights. (...) Knowledge loss may also occur at&nbsp;<strong>the division or unit level</strong> when people fail to document modifications in processes or mistakes in engineering designs, leaving newcomers to face insurmountable hurdles. (...) Finally, knowledge loss may occur at&nbsp;<strong>the individual level</strong>, when a person stops practicing an activity.</p></blockquote><h3><strong>Knowledge loss in the US nuclear weapons complex</strong></h3><blockquote><p>these changes have had a profound impact on the various knowledge reservoirs that constitute the nuclear complex.&nbsp;<strong>Personnel downsizing affects communal knowledge</strong> and the communities of practice that were formed at the laboratories during fifty years of nuclear weapons development. The design and testing of nuclear weapons brought together a varied group of individuals, including physicists, chemists, engineers, technicians, and explosives specialists, who created an identity around the task of transforming a physics principle into a complex working weapon. Their knowledge was passed on from one generation to another through formal training, informal communication, practice, apprenticeship, and gradual inclusion of novices into this community of practice.&nbsp;<strong>Testing of nuclear weapons created a common knowledge in the form of explicit data, but also tacit practices and values</strong>.</p><p><strong>This communal knowledge started to erode with the departure of individuals</strong> who contributed to nuclear weapons design, production, and testing (...) Those who remain have their own personal knowledge, but due to the complexity of the nuclear enterprise, no individual fully understands all the details of nuclear weapons design, development, production, and testing. (...) As a result,&nbsp;<strong>the nuclear complex is leaking knowledge from all reservoirs</strong>.</p></blockquote><h2>Chapter 3: Impediments and Facilitators of Bioweapons Development</h2><h3><strong>Failure of past bioweapons programs</strong></h3><blockquote><p>the&nbsp;<strong>Soviet bioweapons program</strong> essentially failed to produce the new generation of bioweapons it set out to develop in the 1970s despite a prodigious investment in human, material, and financial resources. The&nbsp;<strong>U.S. bioweapons program</strong> also was largely unable to produce a weapon that met military requirements, while&nbsp;<strong>more recent state and terrorist programs</strong> have failed at various or all stages of bioweapons development in spite of having access to the material and financial resources.</p></blockquote><h3><strong>Organization and management are critical</strong></h3><blockquote><p>Given the fragility and unpredictability of bio-agents, and the challenges of tacit knowledge creation and institutionalization,&nbsp;<strong>the environment required to achieve fruitful [learning] interactions does not occur spontaneously; it must be engineered in an especially appropriate organizational context</strong>. (...)</p><p><strong>Organizational and managerial factors thus constitute key determinants of success</strong> because they have a direct impact on knowledge creation and transfer within a program. Evidence from past state and terrorist bioweapons programs also underscores the importance of&nbsp;<strong>four additional factors that affect successful systems integration: political support or intrusion, the overall program\u2019s economic circumstances, program location, and the type and timing of foreign technical assistance</strong>.</p></blockquote><h3><strong>Organizational requirements of knowledge creation</strong></h3><blockquote><p>The extant literature has identified two key organizational factors that promote the efficient use and transfer of knowledge: first, a structural organization that ensures personnel proximity and mobility; and second, the deployment of integrative mechanisms that ensure the coordination and synchronization of tasks and stages.</p></blockquote><h3><strong>Structural organization: personnel proximity and mobility</strong></h3><blockquote><p>Given that the acquisition and use of tacit skills and know-how requires direct interactions between people, often over a prolonged period of time,&nbsp;<strong>proximity between individuals and mobility within their organization are essential vehicles for knowledge transfer</strong>. This is especially true in bioweapons programs, which must deal with unpredictable microorganisms, novel problems, and complex uncertainties, all of which demand close and frequent collaboration and coordination between diverse technical staff. (...)&nbsp;</p><p><strong>Proximity therefore plays a crucial role in creating connections between different reservoirs of knowledge</strong> and enriching their component parts. It fosters communities of practice, in which direct communications between members serve as conduits for the transmission of values, practices, and certain ways of doing things. Proximity also promotes the likelihood of unplanned interactions between people, which can improve coordination between functions within an organization. At the individual level, proximity allows greater feedback (...) Conversely, distance impairs the transfer of knowledge, because it limits opportunities for knowledge spillover through informal and serendipitous interactions between individuals. (...)</p><p><strong>Another key requirement of knowledge transfer is personnel mobility</strong>. Allowing people to move between divisions, or from one location to another, can not only reinforce the benefits of proximity but also compensate for the lack of physical proximity.</p></blockquote><h3><strong>Stages of bioweapons development</strong></h3><blockquote><p>In the bioweapons field, the importance of stage coordination is illustrated by the challenge of scaling up fragile biological organisms. Schematically, the development of a bioweapon proceeds through five main stages.</p><p>First, during the <strong>research phase</strong>, teams of scientists and laboratory personnel who specialize in bacteria, viruses, or toxins study and develop an agent with appropriate characteristics (virulence, antibiotic resistance, pathogenicity) for weapons use.</p><p>Then another team that specializes in <strong>production process development </strong>takes over the sample to design ways to produce the agent in slightly larger quantities while maintaining all the agent\u2019s desirable qualities.</p><p>The product is then moved to the <strong>production phase</strong>, where engineers and technicians test the production process by producing small quantities of the agent in a pilot plant. The objective here is to identify potential problems that might prevent a further scale-up to industrial quantities.</p><p>In the fourth stage, <strong>animal experts test the resulting product on primates or other laboratory animals </strong>to model its effects and determine whether it can produce the expected results on humans.</p><p>The last stage, <strong>weaponization</strong>, is executed by engineers, explosives experts, mathematicians, and statisticians who design delivery mechanisms and test the dispersion of the agent in a specific weapon delivery system.</p><p>Although <strong>in theory these stages occur sequentially, in practice, the evolution from laboratory sample to manufactured product is never a linear process </strong>(...)&nbsp;The passage from one stage of product development to the next requires a constant back-and-forth between stages and direct interaction among participants. This is not easily achieved when the programs include hundreds or even thousands of individuals located at different sites.</p></blockquote><h3><strong>Systems engineering</strong></h3><blockquote><p>Because large and complex projects are composed of many moving parts, integrating these parts into a coherent whole\u2014a process known as <strong>systems engineering</strong>\u2014is particularly challenging and affects a project\u2019s success or failure (...) systems engineers are individuals who see a project through, from its inception to its end, and synchronize and align the work of the different participants. Thus, they contribute not only to the development of the project concept but also to its design, research and development, and execution.</p></blockquote><h3><strong>The importance of good management</strong></h3><blockquote><p>new knowledge is sometimes rejected due to trust issues or lack of common technical language.&nbsp;<strong>Managers have an important role to play in ensuring acceptance and use of new knowledge</strong>, and their influence manifests itself in three important areas.</p><p>First,&nbsp;<strong>they are essential in establishing a social context that promotes trust and cognitive cohesion</strong>\u2014the creation of a common technical language\u2014among personnel, which increases the chances that personnel will accept and effectively use their colleagues\u2019 knowledge. Second, they play a particularly important role in creating the proper environment for knowledge institutionalization (...) Finally, managers are essential conduits for allowing sustained communications between political decision makers and program implementers, to ensure continued political and financial support for the program. (...)</p><p>Managers can promote organizational learning by creating a corporate culture that promotes openness and rewards information sharing. One strategy for creating such an environment involves implementing a shared vision of what should be accomplished. (...)&nbsp;</p><p>Conversely, the emphasis on negative incentives, in the form of punitive actions for errors, can lead to avoidance strategies, preventing the identification of problems and their resolution. (...) sanctions for failure were stiff in the Soviet and Iraqi [bioweapons] programs as well as in the Japanese terrorist group Aum Shinrikyo,&nbsp;<strong>leading personnel to report fake results or even fabricate data to please higher-ups and avoid punishment</strong>.</p></blockquote><h3><strong>Social context, trust, and cognitive cohesion</strong></h3><blockquote><p>Complex projects such as weapons programs rely on heterogeneous groups of individuals with different competencies, who frame and approach problems differently.&nbsp;<strong>This creates cognitive boundaries and trust issues that are difficult to overcome, making the knowledge created by one unit not readily usable by another unit</strong>. Weapons programs also must contend with cultural differences between military and civilian personnel, who operate according to different cultural and administrative rules. Work on a common project therefore&nbsp;<strong>requires the creation of a common technical language</strong> that will allow diverse technical communities to collaborate, learn from, and trust one another (...)&nbsp;</p><p><strong>informal ties created through socialization lead individuals to create friendships that increase their willingness to share information and help each other</strong>. The stronger the ties between individuals, the more time and effort they are willing to invest in providing assistance to each other and transferring their knowledge. Friendship and frequent communications also play an important role in the development of trust, an essential ingredient in knowledge sharing and use.</p></blockquote><h3><strong>Knowledge institutionalization</strong></h3><blockquote><p>In order for an institution to make progress and to innovate, it must ensure that knowledge acquired by an individual or a group can spread across the organization. This not only allows others to benefit from that knowledge but also permits the whole organization to adapt to new knowledge by, for example, adopting new routines or modifying existing production processes. (...) Openness to the outside world is another means of enhancing organizational learning. (...)</p><p>Finally, nurturing openness and an environment where people can safely identify problems and search for solutions also&nbsp;<strong>requires communication channels that easily pass information up and down the hierarchy</strong>. This permits knowledge created at various work levels to spread across the entire institution, if needed.</p></blockquote><h3><strong>Secrecy, military hierarchy, and the Biological Weapons Convention</strong></h3><blockquote><p>Achieving proper conditions for knowledge institutionalization in weapons programs is particularly challenging because they are subject to&nbsp;<strong>secrecy requirements, which translates into restricted access to information through compartmentalization</strong>. In many cases, too, weapons programs are placed under military control, which tends to favor strict vertical hierarchies, centralized decision making, and bureaucratic rigidity\u2014conditions that are poles apart from the required openness and flexibility needed for knowledge institutionalization.&nbsp;<strong>The challenges are even steeper in illicit bioweapons programs launched or maintained after the signature of the Biological Weapons Convention</strong>, because maintaining absolute covertness places greater demands on management, making the creation and transfer of knowledge problematic. (...)</p><p>developing bioweapons while&nbsp;<strong>operating under the constraints of covertness</strong> not only imposes additional costs to create the protective layers necessary to prevent detection but also complicates the already stiff challenges of knowledge management. (...) <strong>Soviet authorities decided against creating lateral linkages within their bioweapons program to limit individual knowledge of the program</strong>. This caused many scale-up nightmares</p></blockquote><h3><strong>Exogenous factors affecting bioweapons development</strong></h3><blockquote><p>several external factors can also affect scientific outcomes because they can interfere with the stability of the work environment, the continuity of scientific work, and the integration of its constituting parts. Stability in the work environment is essential for ensuring the proper use and transfer of knowledge and allowing personnel to accumulate knowledge over time. (...)&nbsp;</p><p><strong>In past bioweapons programs, four exogenous factors have conspired to upset a program\u2019s stability, continuity, and integration</strong>: (1) the level of political priority and intrusion in a program, sometimes teamed with a lack of cohesion in decision making; (2) the economic circumstances of a program; (3) the location of a program; and (4) inappropriate or untimely foreign technical assistance.</p></blockquote><h3><strong>Political interference and examples</strong></h3><blockquote><p><strong>when political elites interfere with scientific decisions, program delays and failures occur</strong>. On the other hand, when scientists are given the opportunity to develop a professional culture, with minimum interference from political leaders, program success is more likely (...)</p><p>In these three cases [the Iraqi, Soviet, and Aum Shinrikyo biological weapons programs], interference took the form of goal setting that was out of sync with what scientists could actually do; placement and replacement of scientists based on political loyalty rather than competence; and interference with the natural flow of scientific discovery, requiring scientists to skip essential phases to reach the requested result faster. In all three cases, such intrusions resulted in multiple disruptions in scientific work, the emergence of questionable scientific behaviors\u2014faking or fabricating results\u2014in some cases due to the creation of a cadre of incompetent scientists; and a loss of knowledge, which eventually negatively affected these programs\u2019 paces and outcomes.</p></blockquote><h3><strong>Distributed decision making</strong></h3><blockquote><p>Typically, several government agencies and military services are involved in decision making for a program. These actors often have different and sometimes conflicting views about a program\u2019s goals and priorities. Reconciling these diverging views can be a daunting task, particularly when funding decisions are not centralized. (...)&nbsp;</p><p><strong>About a dozen agencies were involved in decision making for the U.S. bioweapons program</strong>. Such dispersion of responsibility and decision making not only nurtured conflicts and disagreements about the program\u2019s objectives but also negatively affected the program\u2019s direction and scientific output.</p></blockquote><h3><strong>Location and varying properties of materials</strong></h3><blockquote><p>The location of a program also becomes an important factor affecting program success or failure. Several studies have shown that&nbsp;<strong>location is important because the properties of the materials, equipment, or parts necessary for scientific work may differ from one location to another</strong>. Variable properties can negatively affect replication of past work and the transfer of technologies to a new site, ultimately complicating integration of parts and stages. (...) Minute changes in material or component characteristics, due to the use of different suppliers at a new location, can prevent successful integration and derail an experiment. (...)</p><p>The role of location and the properties of materials used in scientific work are nowhere more important than in the biological sciences, where&nbsp;<strong>scientists work with live agents that are unpredictably sensitive to environmental conditions</strong>. For example, the properties of reagents and other materials used in scientific experiments may differ from one location to another and frequently vary seasonally. An experiment conducted successfully in one location may not be reproducible in another because of the varying properties of the materials used, even when the same individual conducts the experiment.</p></blockquote><h3><strong>Importance and limits of foreign technical assistance</strong></h3><blockquote><p>Appreciating the uneven results of foreign technical assistance on weapons development does not mean that foreign assistance is unimportant. Indeed, it is a central feature of eventual success.&nbsp;<strong>All programs have thus far had to elicit the help of friendly countries simply because the breadth of resources required to bring a program to fruition usually far exceeds the capabilities of an individual state</strong>. Even the two superpowers during the Cold War could not claim that their nuclear and biological weapons programs were fully endogenous. (...)</p><p>Consequently, evaluating the role of foreign assistance in weapons development requires digging deeply into the context within which it is offered. Practically, this requires asking two important questions. First, <strong>what is the recipient program\u2019s absorptive and integrative capacity? </strong>Second, do the timing and nature of the assistance coincide with the recipient\u2019s absorptive capacity? If a recipient program does not have sufficient knowledge and industrial bases to use, adapt, and integrate the received assistance into their own circumstances, it is likely that the assistance will, at the very least, remain unused, or it may effectively delay and possibly impede progress altogether.</p></blockquote><h3><strong>Program integration</strong></h3><blockquote><p>Therefore,&nbsp;<strong>a weapons program should be viewed as an integrated system</strong>: it requires specific and essential parts that work individually, but these parts also need to operate when assembled as a whole. Here lies one of the key shortcomings of current threat assessments. Currently, emphasis is placed on only a few variables\u2014material resources\u2014at the expense of other essential ones. In addition, analysis tends to be based on the inventory of individual parts rather than on how they operate together. This shortcoming is particularly damaging in bioweapons threat assessments: due to the fundamental unpredictability of bio-agents and the resulting increased need for integration of teams and stages,&nbsp;<strong>bioweapons programs are especially sensitive to the variables that negatively affect integration. This may account for the limited successes achieved in both large-and small-scale bioweapons programs (...)&nbsp;</strong></p><p>A bioweapons program cannot progress rapidly if its interdependent stages and functions are not coordinated and integrated. The division of labor resulting from the involvement of different disciplines and skills inevitably fosters barriers between people. Organizational division and work structure can also foster additional impediments, especially if a program is more concerned with ensuring covertness than creating the conditions for knowledge production and transfer.</p></blockquote><h2>Chapter 7: Preventing Bioweapons Developments: Policy Implications</h2><h3><strong>Difficulty of creating biological weapons</strong></h3><blockquote><p>the case studies underscore&nbsp;<strong>how difficult it is to produce working bioweapons, however vast and resourceful the program</strong>. The fragility and unpredictability of microorganisms require that state and nonstate actors create meticulous organization, management, and sustained coordination of all the actors affecting a program over time, not only to permit success in the laboratory but also to transform a laboratory sample into an agent that can survive scale-up, weaponization, and delivery. (...)&nbsp;<strong>These ideal conditions are difficult to achieve under any circumstances, let alone those surrounding the constraints of maintaining covertness</strong>\u2014particularly under autocratic and violent regimes.</p></blockquote><h3><strong>Policy implications</strong></h3><blockquote><p>These findings have implications at four important levels.&nbsp;</p><ol><li>First, they have an impact on national and international security by suggesting&nbsp;<strong>a new narrative about bioweapons developments that has greater dissuasive power</strong> to those who might seek this technology than does the current technology-based discourse, which emphasizes ease of development and accessibility of resources.</li><li>Second,&nbsp;<strong>they underscore the importance of strengthening the Biological Weapons Convention (BWC)</strong> and call for a review of current nonproliferation and counterproliferation policies.</li><li>Third, they offer new insight on how to achieve more accurate threat assessments of suspect state or terrorist programs and design more tailored responses to these threats.</li><li>Finally,&nbsp;<strong>they question the design of current policies aimed at limiting the spread of knowledge</strong> as well as the widely shared&nbsp;<strong>belief that new technologies will erase the hurdles associated with bioweapons developments</strong>.</li></ol></blockquote><h3><strong>US biodefense efforts</strong></h3><blockquote><p>Since 2001, the United States has spent more than $60 billion on biodefense programs designed to detect the release of harmful agents (the&nbsp;<strong>BioWatch program</strong>), produce medical counter-measures (the&nbsp;<strong>Bioshield program</strong>), create stockpiles of drugs and vaccines, increase research on a set of agents deemed most likely to be used in a bio-attack (the so-called Select Agent List), and strengthen laboratory security.&nbsp;<strong>The Bioshield and BioWatch programs have been harshly criticized</strong>: after a decade of effort, the former did not produce any new vaccines, while the latter has experienced repeated false alarms in its network of biosensors deployed in major cities, and still requires the physical removal of filters for analysis in the laboratory, which can take several days.</p></blockquote><h3><strong>Narrative of bioweapons vulnerability</strong></h3><blockquote><p>the current biothreat narrative and its policies, with their highly publicized shortcoming and failures, have reinforced the belief that the United States and its allies are not prepared to respond to a bio-attack in spite of a significant investment in funds and efforts over the past decade, and therefore remain very much vulnerable to such attacks.&nbsp;<strong>Rather than dissuading an adversary, this narrative only reinforces the desirability of developing bioweapons</strong></p></blockquote><h3><strong>Bioweapons dissuasion</strong>&nbsp;</h3><blockquote><p>dissuasion is defined as taking action to decrease the benefits or increase the cost of such weapons, thereby creating strong barriers to entry. Regarding bioweapons, none of these objectives have been achieved:&nbsp;<strong>the current biothreat narrative presents a cost/benefit ratio in favor of developing bioweapons</strong>, and its concomitant policies have not addressed the real barriers to entry in the bioweapons field\u2014the acquisition of expertise and its determinants. (...)</p><p>The&nbsp;<strong>key message to convey is that bioweapons developments are not only difficult but highly uncertain</strong>. The fragility and unpredictability of living microorganisms creates a natural barrier that is challenging to overcome without the appropriate expertise (...)&nbsp;</p><p>The&nbsp;<strong>acquisition of expertise is therefore the key barrier</strong>, which is overcome not simply by means of acquiring scientific documents but through prolonged hands-on experimentation, requiring the cooperative work of a community of experts open to the outside world, who have expertise adapted to the types of agents under study and the skills required to move a natural agent through the various stages of research, development, production, and weaponization. Creating such a knowledge base can take decades and ultimately still fail (...)&nbsp;</p><p>The&nbsp;<strong>third hurdle lies in creating the proper organizational, managerial, and social conditions</strong> that foster knowledge creation, transfer, and institutionalization while also managing external factors&nbsp;</p></blockquote><h3><strong>Revisiting current nonproliferation policies</strong></h3><blockquote><p>One of the gravest consequences of the biothreat narrative has been to&nbsp;<strong>focus attention and nonproliferation policies almost exclusively on frustrating material procurement</strong>. To be sure, these policies, including export control and UN Resolution 1540, are essential elements of nonproliferation and should be continued. However, material resources are not the key barriers to bioweapons development. It is important, therefore, to&nbsp;<strong>reorient current and future policies toward preventing the acquisition of expertise</strong>. Since&nbsp;<strong>proximity, direct contact between scientists, cooperation, and the stability and continuity of scientific work are essential to scientific progress</strong>,&nbsp;<strong>nonproliferation and counterproliferation efforts should focus on disrupting these factors</strong>.</p></blockquote><h3><strong>Nonproliferation value of Biological Weapons Convention (BWC) verification</strong></h3><blockquote><p>The BWC is an essential nonproliferation tool, not only because of its undeniable&nbsp;<strong>normative value but also because it can be used to directly impede knowledge acquisition</strong>. But to fully use the nonproliferation power of the BWC, the international community must revive the idea of a formal verification mechanism to the treaty. (...)&nbsp;</p><p>To be sure, the verification measures as proposed in 2001 would not have caught a proliferator red-handed. But&nbsp;<strong>the value lies in their ability to disrupt the continuity of bioweapons work and delay progress</strong>. (...) Thus,&nbsp;<strong>interruptions caused by inspections, or their expectation, can set back ongoing experiments or development work</strong>, particularly when they occur at sensitive stages (...) Changes to experimental protocols are done on the fly, and if they are not recorded, they may be lost in the confusion of a move, a temporary interruption, cleanup, or the hiding of documents and materials, thus preventing staff members from resuming work where they had left off. <strong>If the interruption is long lasting, knowledge can be lost for good&nbsp;</strong></p></blockquote><h3><strong>Counterproliferation options</strong></h3><blockquote><p>Disruptions of a program\u2019s scientific stability and continuity can be achieved in several ways. (...) <strong>the threat of military or police operations in nearby areas</strong> can keep the suspect country or group permanently fearful of detection, obliging the program to move repeatedly, conceal its activities, or stop work entirely, if only temporarily.</p><p>Second,&nbsp;<strong>sabotage, a strategy used in the past to target equipment, can also effectively disrupt scientific work</strong> (...) Sabotage can be particularly damaging in the bioweapons field to the extent that it affects production and scale-up equipment. Equipment malfunction during these stages not only halts the accumulation of knowledge when theoretical concepts are tested during production but also could destroy a batch of bacteria or viruses undergoing production. Both outcomes would result in major program delays.&nbsp;</p><p><strong>Disrupting team composition</strong> can also produce program delays and knowledge loss. Because teams take a long time to jell and work effectively, forcing changes in their composition can disrupt cohesiveness and delay work, as well as foment distrust among members, particularly in the context of a hostile environment. (...)&nbsp;</p><p><strong>Playing on a program\u2019s fear of detection or a mole within the organization</strong> can also constitute an efficient strategy to push the program toward an organizational model that limits or altogether prevents communications between knowledge reservoirs</p><p><strong>Compelling the suspect program to locate the various stages of a bioweapon\u2019s life cycle at different sites and limiting connections between them</strong> can further reinforce organizational impediments. The threat of police or military activity and the possibility of international inspections can be equally effective at compelling the suspect group or country to retreat to an adverse organizational model that shatters a program into pieces, spreading it to different locations while compartmentalizing its component parts. With reduced direct interactions, the transfer of tacit knowledge and task coordination are compromised.</p></blockquote><h3><strong>Rethinking bioweapons threat assessment</strong>&nbsp;</h3><blockquote><p>The starting point of any bioweapons threat assessment should be an evaluation of the potential for a state or terrorist group to manipulate and process successfully fragile microorganisms. To that end,&nbsp;<strong>data collection and analysis efforts should first of all attempt to determine whether the individuals involved have sufficient knowledge</strong>.</p></blockquote><h3><strong>Types of individuals involved in bioweapons programs</strong></h3><blockquote><p>roughly three categories of individuals may be involved in a nascent bioweapons program: the novice, the sub-expert, and the expert.</p><ol><li><strong>A novice is a person with a generic educational background</strong> in the discipline but no specific or practical expertise. Aum Shinrikyo\u2019s program was staffed with novices. (...)</li><li><strong>The sub-expert is a person with a specific expertise</strong>\u2014say virology or bacteriology\u2014and advanced theoretical knowledge but no practical expertise in developing biological weapons. Most scientists in the Iraqi and South African programs belonged to this category. (...)&nbsp;</li><li><strong>The expert is an individual with advanced theoretical knowledge and practical expertise</strong> in a domain directly applicable to bioweapons work, and possibly even bioweapons expertise. The American and Soviet programs both included this category of scientists. (...)&nbsp;</li></ol><p><strong>These distinctions are important because they reveal how different people learn and use their knowledge</strong>\u2014that is, what their absorptive capacity is and, consequently, how quickly their work progresses (...) The level of expertise also determines a scientist\u2019s/technician\u2019s ability to use outside assistance or technology and adapt it within his or her own context.</p></blockquote><h3><strong>Potential for knowledge transfer</strong></h3><blockquote><p><strong>because expertise in one domain does not necessarily transfer to another domain</strong>, it is important to investigate whether individuals working in a bioweapons program have expertise that corresponds to the actual work they are doing, and whether the program has access to the whole gamut of knowledge required to ensure passage from one stage to the next in a bioweapons life cycle. (...)&nbsp;</p><p>Therefore,&nbsp;<strong>the further removed the resident expertise is from the work being conducted, the more difficult and lengthy is the acquisition of knowledge</strong>. In this context, even experts in one discipline might have to take the same learning path as sub-experts or novices if their expertise does not fit the work being conducted. (...)&nbsp;</p><p>If one has familiarity with one type of biological organism, this can help facilitate some aspects of the learning process, but&nbsp;<strong>it will not eliminate the need for trial-and-error experimentation on the new organism</strong>.</p></blockquote><h3><strong>Brain drain prevention programs</strong></h3><blockquote><p>Brain drain prevention programs were launched in the 1990s as a result of the breakup of the Soviet Union, which unleashed new threats of proliferation of nuclear, chemical, and biological technology, material, and expertise. Spearheaded by the United States,&nbsp;<strong>the international community designed and implemented assistance programs to secure weapons facilities and their dangerous material, and offer jobs to weapons scientists to prevent them from offering their services to other states or terrorist groups</strong>. The Department of Defense&nbsp;<strong>Cooperative Threat Reduction (CTR) Program</strong> was and probably remains the largest nonproliferation program in the Soviet Union. Although it first focused on nuclear and chemical proliferation, it expanded its reach to include bioweapons facilities and scientists in the late 1990s. The program has been quite successful at securing bioweapons facilities and their collections of pathogens, as well as improving the safety of laboratory work at these facilities.</p></blockquote><h3><strong>Flaws of brain drain prevention programs</strong></h3><blockquote><p>On the brain drain front, however, there remain reasons for concern about the effectiveness of these nonproliferation activities, primarily due to the way brain drain programs are designed and implemented. (...) Three design flaws have marred the effectiveness of the CTR Program.</p><p>First, most of the research projects funded under the CTR Program maintain bioweapons scientists at their former facilities, where they work on biodefense-oriented projects that involve many of the same dangerous pathogens that former bioweapons scientists worked on in Soviet times. In addition, these scientists often work with the same Soviet-era colleagues. These two factors&nbsp;<strong>allow them to maintain many of the tacit skills and communal knowledge developed under the Soviet bioweapons program instead of facilitating its erosion</strong>. (...)&nbsp;</p><p>Second, the CTR Program is facility based, meaning it only supports scientists working at certain bioweapons facilities. Once these scientists leave their former institutes (...) they cease to qualify for this support, even though a covert program could advantageously use their expertise. The facility-based approach also has the major disadvantage of not distinguishing between scientists and technicians who might actually pose a threat and those whose expertise would not benefit a covert program. (...)&nbsp;</p><p>Finally, the program focuses on facilities previously believed to be part of the core Soviet bioweapons infrastructure,&nbsp;<strong>at the risk of neglecting facilities located in the other two circles, such as the anti-plague system</strong>. Anti-plague scientists may pose as much of a threat as those employed in core facilities</p></blockquote><h3><strong>Suggested improvements to the Cooperative Threat Reduction program</strong></h3><blockquote><p>the CTR Program should modify its current approach, which emphasizes the expansion of the program to as many facilities as possible, to one that engages the facilities and individuals that pose the greatest threat. (...) In general,&nbsp;<strong>the CTR Program should de-emphasize biodefense projects and create incentives for scientists to exit the bioweapons field, in order to reduce the overall number of individuals able to maintain their bioweapons-specific skills</strong>.</p></blockquote><h3><strong>Restrictions on scientific publications</strong></h3><blockquote><p>written documents are decidedly incomplete reservoirs of knowledge that&nbsp;<strong>rarely allow replication of past work without the intervention of the original authors</strong>, particularly when the work is conducted at a different location and with different material and equipment. (...)&nbsp;</p><p>Therefore,&nbsp;<strong>restricting scientific publication does not support, but actually works against, nonproliferation goals</strong>. It also perpetuates the false belief that the fast pace of new scientific developments, aided by a so-called revolution in biotechnology, will eclipse dependence of locally based scientific skills. (...) Apart from the obvious negative consequence for public health\u2014restricting the spread of scientific data can impede public health authorities\u2019 ability to prepare against and respond to a localized outbreak or pandemic\u2014<strong>publication restrictions fuel suspicions that the United States is using this data for military purposes</strong>.</p></blockquote><h3><strong>The role of new biotechnologies</strong></h3><blockquote><p><strong>new technologies do not, by themselves, allow replication of past work, or transform an untrained individual into a bioterrorist or bioweaponeer overnight</strong>. In fact, empirical studies and interviews with bench scientists indicate that new technologies are not necessarily easy to use, even by trained scientists. They require their users not only to possess prior base knowledge but also to acquire new expertise to solve novel problems created by the use of the technology. (...) Thus, even new-generation technologies require prior expertise and the acquisition of new skills to interpret and troubleshoot problems that are certain to arise. (...)</p><p>In the bioweapons field,&nbsp;<strong>unless future technologies can render biomaterials behavior predictable and controllable</strong>, and allow scientists to transition easily from work with one agent to another,&nbsp;<strong>the role of expertise and its socio-organizational context will remain critically important barriers to bioweapons development</strong>.</p></blockquote><h3><strong>United Nations Security Council resolution 1540 and the BWC</strong></h3><blockquote><p>Making contributions to the development and use of a bioweapons program a crime against humanity could serve as a stronger deterrent. Criminalization of bioweapons development at the national level is a requirement under UN Resolution 1540, and several countries have already enacted legislation making it a crime for terrorists to develop, use, or acquire mass destruction weapons, including biological weapons. (...)&nbsp;</p><p><strong>However, both the BWC and UN Resolution 1540 suffer from insufficient implementation</strong>. For example, the content of the legislation reported by individual countries to the UN Resolution 1540 Committee is unequal, as is enforcement of the legislation at the national level. Yet 1540 Committee personnel do not have the mandate to evaluate this legislation or issue a template of what constitutes exemplary legislation.</p></blockquote><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxkk1qfldd9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxkk1qfldd9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I read chapters 1-3 and 7 but not chapters 4-6, which respectively deal with the Soviet, American, and several small-scale biological weapons programs.</p></div></li></ol>", "user": {"username": "Darius_Meissner"}}, {"_id": "FZ2BMwSYhkdBWmTTA", "title": "Good Futures Initiative: Winter Project Internship ", "postedAt": "2022-11-27T23:27:27.267Z", "htmlBody": "<p>TLDR: I'm launching <a href=\"https://eaberkeley.com/good-futures-initiative\">Good Futures Initiative, a winter project internship</a> to sponsor students to take on projects to upskill, test their fit for career aptitudes, or do impactful work over winter break. You can read more on our website and<strong>&nbsp;</strong><a href=\"https://airtable.com/shrNPb8brxTeVmWjq\"><strong>apply here</strong></a><strong> by December 11th</strong> if interested!&nbsp;</p><h1>Good Futures Initiative</h1><p>The Good Futures Initiative is a 4.5 week internship in which students can use their winter break to lead high-EV projects. Projects could take many forms, but each project produces a final product while accomplishing one of these three goals:</p><ol><li>Skill up the intern in order for them to work on AI Safety or Biosecurity in the future.</li><li>Let the intern explore an&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/my-current-impressions-on-career-choice-for-longtermists#_Communicator__aptitudes\"><u>aptitude</u></a> for an impactful career.</li><li>Create impact directly.&nbsp;</li></ol><p>Good Futures takes place remotely from December 18th-January 25th, with a minimum of 12 hours of work per week. Accepted applicants will receive a $300 stipend and up to $1000 in funding for additional time or project fees. I expect to accept ~12 interns. The final number will depend largely on my capacity, but I may offer a lower-effort version of the program for promising applicants who I can\u2019t fully fund/support (with a cohort for weekly check-ins and invites to guest speaker events).</p><h2><u>Example projects</u></h2><p>&nbsp;These project examples are far from perfect. At the start of the internship, I'd work with each intern to be sure they're doing the best project fit for their goals. That being said, I\u2019m excited by projects similar to (and better than!!) these.&nbsp;&nbsp;</p><ul><li><u>Skilling up</u> by working on AI Safety technical projects that have been posted by existing researchers, with the goal of creating a lesswrong post detailing your findings. For an example of a potential project to work on, Sam Bowman posted the following project:<ul><li>Consider questions where the most common answer online is likely to be false (as in TruthfulQA). If you prompt GPT-3-Instruct (or similar) with questions and correct answers in one domain/topic, then ask it about another domain/topic, will it tend to give the correct answer or the popular answer? As you make the domains/topics more or less different, how does this vary?</li></ul></li><li><u>Exploring an aptitude</u> for communications by creating 2 articles on longtermist ideas and submitting them to 10 relevant magazines for publishing.&nbsp;</li><li><u>Create impact</u> by translating 3 relevant research papers from AGISF into Mandarin and posting them somewhere where they can be accessed by ML engineers in China.&nbsp;</li></ul><p>In addition to leading a focused project, interns will have weekly one-on-one progress check-ins with me (accountability), guest speaker events (expertise), and a meeting with a cohort of ~5 other interns working on projects (community).&nbsp;</p><p>Our projects are student-directed. Although there will be guest speakers who have expertise in various topics, weekly advising/mentorship will be focused on helping students learn to self-sufficiently lead projects and build skills, rather than technical help executing the projects. E.g.: Accountability, increasing ambition, figuring out how to increase a project\u2019s EV, making sure interns focus on the right metrics each week. Students are encouraged to apply for technical projects that will help them upskill/test their fit for technical work and reach out to additional mentors during the internship.</p><h2>Rationale</h2><p>This internship fills a few gaps the EA community has in the process of getting students/recent grads to seriously pursue high-impact work.&nbsp;</p><ul><li>Students have a lot of time over winter break, but few obvious opportunities for impactful work, structured aptitude testing, or focused skilling-up.</li><li>There are a lot of students or recent graduates interested in switching to a more impactful career, but aren't sure of the best way to do this. This program works with these students to design next-step plans and make sure they're executed.&nbsp;</li><li>People who want to use their winter break for impact usually lack access to structure, community, mentorship, accountability, and financial support.&nbsp;</li><li>It\u2019s easier to make sure you complete your goals if you\u2019re getting regular feedback and accountability, but there are few available mechanisms to do this.&nbsp;</li></ul><h1>What to Know Before Applying&nbsp;</h1><p>This internship has a focus on supporting students interested in reducing existential risk. Other project topics/aptitude testing for impactful careers will be considered, but the projects need to meet the same bar for effectiveness.&nbsp;</p><p>Since this internship is aiming to help people better understand their aptitudes and skills in order to pursue high-impact work in the future, it\u2019s very helpful for the admissions process for us to have an understanding of why a person wants to pursue a project. You\u2019re encouraged to email alarichardson@berkeley.edu<a href=\"http://calendly.com/arisr\"><u>&nbsp;</u></a>to talk about your ideas if you have a project to propose. I might request a meeting with you to get a better understanding. Alternatively, you can meet with me (Aris Richardson) at EAGx Berkeley to discuss your project ideas in person!&nbsp;</p><p>Applicants will fill out this&nbsp;<a href=\"https://docs.google.com/document/d/1x0lzbhxHyiN_amwdg9ZlMZ-kHaX_0028/edit?usp=sharing&amp;ouid=104630059843183609226&amp;rtpof=true&amp;sd=true\"><u>project proposal form</u></a> and turn it in as part of the application. There\u2019s a project type called \u201cProfessor Bertozzi\u2019s\u201d \u2013 this is a project that\u2019s separate and available to UC Berkeley students who have already applied for the project, so please ignore this.&nbsp;</p><p>Non-students can apply, but this internship is generally designed for students and recent graduates.&nbsp;</p><p>Finally, if you're in doubt about whether you're \"good enough\" to apply but are hoping to use your winter for impact, just apply! I even have an option in the application for people to apply for accountability even if they aren't accepted into the full internship. (This accountability would likely mean that an applicant joins a group of other students to check in with weekly during the winter.)</p><h1>How you can help!</h1><p>There are many ways researchers, community builders, and other experts can be helpful in making this a great learning experience for the interns if they\u2019d like to!</p><p>I\u2019m still seeking:</p><ul><li>Guest speakers on project management, their own research agendas, etc.</li><li>Experts who would be interested in mentoring students (from as little as a one-off half-hour meeting to weekly check-ins with students)&nbsp;</li><li>Recommendations for more impactful projects students can work on (if the project is already on an AIS list, I\u2019ve likely seen it!)</li></ul><p>If you\u2019re a researcher working on existential risk interested in helping with any of the above, I\u2019d love to hear from you! For example, you could let me know if you\u2019re interested in having a student assist you in your research or take on an easier project that you wish someone would do. You could provide mentorship in whatever capacity works best for you.&nbsp;</p>", "user": {"username": "Aris Richardson"}}, {"_id": "LWN6qFhCtPDEJJpeG", "title": "Cost-effectiveness of operations management in high-impact organisations", "postedAt": "2022-11-27T10:33:07.882Z", "htmlBody": "<h1>Summary</h1><p>Following up on the <a href=\"https://forum.effectivealtruism.org/posts/noDYmqoDxYk5TXoNm/usd5k-challenge-to-quantify-the-impact-of-80-000-hours-top\"><u>challenge to quantify the impact of 80,000 hours' top career paths</u></a> introduced by Nu\u00f1o Sempere, I have estimated the cost-effectiveness of <a href=\"https://80000hours.org/articles/operations-management/\"><u>operations management in high-impact organisations</u></a>&nbsp;(OM), which arguably include <a href=\"https://80000hours.org/job-board/top-orgs/\"><u>80,000 Hours\u2019 top-recommended organisations</u></a>.</p><p>The results for the mean cost-effectiveness of various metrics in <a href=\"https://en.wikipedia.org/wiki/Basis_point\"><u>bp</u></a>/<a href=\"https://en.wikipedia.org/wiki/Giga-%23:~:text%3DGiga%2520(%252F%25CB%2588%25C9%25A1%25C9%25AA%25C9%25A1,)%252C%2520meaning%2520%2522giant%2522.\"><u>G</u></a>$ in terms of <a href=\"https://forum.effectivealtruism.org/topics/existential-risk\"><u>existential risk</u></a>&nbsp;reduction are summarised in the table below for my preferred method.&nbsp;I present all results with 3 digits, but I think their&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/credal-resilience\"><u>resilience</u></a> is such that they only represent order of magnitude estimates (i.e. they may well be wrong by a factor of 10^0.5 = 3).&nbsp;</p><p>The full results are in <a href=\"https://docs.google.com/spreadsheets/d/1NDrDsMngpGyoQvSu8CpDTgqnYHiqK-ZiL5kFpo7NycM/edit?usp=sharing\">this</a> Sheet, and the calculations in <a href=\"https://colab.research.google.com/drive/1CP51w0JvKW-0ZFHQQu65Pf4K2YIW1AkJ?usp%3Dsharing\"><u>this</u></a> Colab<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzcgh48wsr9\"><sup><a href=\"#fnzcgh48wsr9\">[1]</a></sup></span>.</p><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">Mean cost-effectiveness (bp/G$) of\u2026</th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Method 3 with truncation</p></th></tr></thead><tbody><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Global health and development</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.431</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Longtermism&nbsp;and catastrophic risk prevention</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.95</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Animal welfare</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.62</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Effective altruism infrastructure</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.20</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">The effective altruism community</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.55</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Operations management in high-impact organisations</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>7.01</p></td></tr></tbody></table></figure><h2>Acknowledgements</h2><p>Thanks to Abraham Rowe, Dan Hendrycks, Luke Freeman, Matt Lerner, Nu\u00f1o Sempere, Sawyer Bernath, Stien van der Ploeg, and Tamay Besiroglu.</p><figure class=\"image image_resized\" style=\"width:62.86%\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1671057647/mirroredImages/LWN6qFhCtPDEJJpeG/emihd0wq8xmcvifl4wft.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1fafdf3104b39eedc5d55a81645951aa8a28c8c3899104fb.png/w_110 110w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1fafdf3104b39eedc5d55a81645951aa8a28c8c3899104fb.png/w_220 220w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1fafdf3104b39eedc5d55a81645951aa8a28c8c3899104fb.png/w_330 330w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1fafdf3104b39eedc5d55a81645951aa8a28c8c3899104fb.png/w_440 440w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1fafdf3104b39eedc5d55a81645951aa8a28c8c3899104fb.png/w_550 550w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1fafdf3104b39eedc5d55a81645951aa8a28c8c3899104fb.png/w_660 660w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1fafdf3104b39eedc5d55a81645951aa8a28c8c3899104fb.png/w_770 770w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1fafdf3104b39eedc5d55a81645951aa8a28c8c3899104fb.png/w_880 880w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1fafdf3104b39eedc5d55a81645951aa8a28c8c3899104fb.png/w_990 990w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/1fafdf3104b39eedc5d55a81645951aa8a28c8c3899104fb.png/w_1024 1024w\"><figcaption>An oil painting by Matisse of operations management in high-impact organisations. Generated by OpenAI's DALL-E.</figcaption></figure><h1>Methods</h1><p>I estimated the cost-effectiveness<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe94lfyg635m\"><sup><a href=\"#fne94lfyg635m\">[2]</a></sup></span>&nbsp;from the product between:</p><ul><li>The cost-effectiveness of the high-impact organisations, which I assumed equal to that of the effective altruism community.</li><li>The multiplier of OM, which I defined as the ratio between the cost-effectiveness of OM and the high-impact organisations.</li></ul><p>This method assumes the cost-effectiveness distribution of the high-impact organisations is represented by the one theorised for the effective altruism community in the next section. Moreover, the cost-effectiveness estimates are only accurate to the extent that future opportunities are as valuable as recent ones.</p><p>The calculations are in <a href=\"https://colab.research.google.com/drive/1CP51w0JvKW-0ZFHQQu65Pf4K2YIW1AkJ?usp%3Dsharing\"><u>this</u></a> Colab<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzcgh48wsr9\"><sup><a href=\"#fnzcgh48wsr9\">[1]</a></sup></span>.</p><h2>Cost-effectiveness of the effective altruism community</h2><p>I calculated the cost-effectiveness of the effective altruism community from the mean cost-effectiveness weighted by cumulative spending between 1 January 2020 and 15 August 2022 of 4 cause areas:</p><ul><li>Global health and development.</li><li>Longtermism&nbsp;and catastrophic risk prevention.</li><li>Animal welfare.</li><li>Effective altruism infrastructure.</li></ul><p>These are the areas for which Tyler Maule collected data <a href=\"https://docs.google.com/spreadsheets/d/1gN_oR1-nk08DaSxvm1vEQCzpPkwCkv7ftWmKbvYzw_Y/edit?usp%3Dsharing\"><u>here</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefivxgagy642\"><sup><a href=\"#fnivxgagy642\">[3]</a></sup></span>&nbsp;(see EA Forum post <a href=\"https://forum.effectivealtruism.org/posts/ZbaDmowkXbTBsxvHn/historical-ea-funding-data\"><u>here</u></a>). I adjusted the 2020 and 2021 values for inflation using the calculator from <a href=\"https://www.in2013dollars.com/\"><u>in2013dollars</u></a>.</p><p>I computed the cost-effectiveness of each area using 3 methods. All rely on distributions which are either <a href=\"https://en.wikipedia.org/wiki/Truncated_distribution\"><u>truncated</u></a>&nbsp;to the 99 % <a href=\"https://en.wikipedia.org/wiki/Confidence_interval\"><u>confidence interval</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7cxaped0syc\"><sup><a href=\"#fn7cxaped0syc\">[4]</a></sup></span>&nbsp;(CI) or not truncated, in order to understand the effect of outliers. The parameters of the pre-truncation distributions, which are the final distributions for the non-truncation cases, are provided below.</p><h3>Method 1</h3><p>I defined the cost-effectiveness of longtermism&nbsp;and catastrophic risk prevention as a truncated <a href=\"https://en.wikipedia.org/wiki/Log-normal_distribution\"><u>lognormal distribution</u></a>&nbsp;with pre-truncation 5th and 95th percentiles equal to 1 and 10 <a href=\"https://en.wikipedia.org/wiki/Basis_point\"><u>bp</u></a>/<a href=\"https://en.wikipedia.org/wiki/Giga-%23:~:text%3DGiga%2520(%252F%25CB%2588%25C9%25A1%25C9%25AA%25C9%25A1,)%252C%2520meaning%2520%2522giant%2522.\"><u>G</u></a>$ in terms of <a href=\"https://forum.effectivealtruism.org/topics/existential-risk\"><u>existential risk</u></a>&nbsp;reduction. These&nbsp;are the lower and upper bounds proposed <a href=\"https://forum.effectivealtruism.org/posts/pGaesfn4R9xWK4Rmk/01-fund-ideation-and-proposal\"><u>here</u></a>&nbsp;by Linchuan Zhang.</p><p>I assumed the ratio between the cost-effectiveness of i) longtermism&nbsp;and catastrophic risk prevention and ii) global health and development to be a truncated lognormal distribution with pre-truncation 5th and 95th percentiles equal to 10 and 100. These are the lower and upper bounds guessed <a href=\"https://forum.effectivealtruism.org/posts/cjH2puDzAFrtrrThQ/despite-billions-of-extra-funding-small-donors-can-still\"><u>here</u></a>&nbsp;by Benjamin Todd for the ratio between the cost-effectiveness of the <a href=\"https://funds.effectivealtruism.org/funds/far-future\"><u>Long-Term Future Fund</u></a>&nbsp;(LTFF) and <a href=\"https://funds.effectivealtruism.org/funds/global-development\"><u>Global Health and Development Fund</u></a>&nbsp;(search for \u201c10-100x more cost-effective\u201d).</p><p>I considered the ratio between the cost-effectiveness of i) animal welfare and ii) global health and development to be a truncated lognormal distribution with pre-truncation 5th and 95th percentiles equal to 270 <a href=\"https://en.wikipedia.org/wiki/Micro-\"><u>\u03bc</u></a>&nbsp;and 211. I computed these multiplying:</p><ul><li>The 5th and 95th percentiles of 0.0436 and 34.1 k I estimated <a href=\"https://forum.effectivealtruism.org/posts/nDgCKwjBKwFvcBsts/corporate-campaigns-for-chicken-welfare-are-10-000-times-as\"><u>here</u></a>&nbsp;for the ratio between the cost-effectiveness of corporate campaigns for chicken welfare and GiveWell\u2019s Maximum Impact Fund<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhkjayhc0sum\"><sup><a href=\"#fnhkjayhc0sum\">[5]</a></sup></span>, which is now designated <a href=\"https://www.givewell.org/top-charities-fund\"><u>Top Charities Fund</u></a>.</li><li>A factor of 1.07 <a href=\"https://en.wikipedia.org/wiki/Milli-\"><u>m</u></a>&nbsp;to adjust the moral weight downwards, which I calculated from the reciprocal of the product between:<ul><li>The mean moral weight of chickens relative to humans of 2.41 I obtained in the analysis mentioned just above.</li><li>The ratio of 389 between the number of neurons of humans and <a href=\"https://en.wikipedia.org/wiki/Red_junglefowl\"><u>red junglefowls</u></a>&nbsp;(similar to chickens), which I took from <a href=\"https://en.wikipedia.org/wiki/List_of_animals_by_number_of_neurons\"><u>Wikipedia</u></a>.</li></ul></li></ul><p>This adjustment is analogous to assuming the mean moral weight is directly proportional to the number of neurons.</p><p>I set the cost-effectiveness of effective altruism infrastructure to the mean cost-effectiveness weighted by cumulative spending between 1 January 2020 and 15 August 2022 of the other 3 areas.</p><h3>Method 2</h3><p>I obtained the cost-effectiveness of each area based on the 27 <a href=\"https://80000hours.org/2018/10/2018-talent-gaps-survey/%23ea-leaders-believe-that-giving-focused-on-the-long-term-future-and-the-ea-community-is-more-effective-than-that-on-global-development-or-animal-welfare\"><u>answers</u></a>&nbsp;regarding the mean cost-effectiveness of the <a href=\"https://funds.effectivealtruism.org/\"><u>Effective Altruism Funds</u></a>&nbsp;given in the <a href=\"https://80000hours.org/2018/10/2018-talent-gaps-survey/\"><u>EA talent needs survey - 2018</u></a>. Such answers are in the table below, whose last column was calculated by me.</p><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"2\">Fund</th><th style=\"padding:5pt;text-align:center\" colspan=\"4\" rowspan=\"1\"><p>Mean cost-effectiveness relative to the Effective Altruism Infrastructure Fund (%)</p></th></tr><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10th percentile</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Median</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>90th percentile</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Geometric mean between the 10th and 90th percentiles</p></th></tr></thead><tbody><tr><th style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Global Health and Development Fund</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>63</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>7.94</p></td></tr><tr><th style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Long-Term Future Fund</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>16</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>167</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>283</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>67.3</p></td></tr><tr><th style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Animal Welfare Fund</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>107</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>17.9</p></td></tr><tr><th style=\"padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Effective Altruism Infrastructure Fund</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>100</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>100</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>100</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>100</p></td></tr></tbody></table></figure><p>I defined the cost-effectiveness of longtermism and catastrophic risk prevention as in method 1.</p><p>For the other areas, I assumed a truncated lognormal distribution with pre-truncation 10th and 90th percentiles of the area relative to those of longtermism and catastrophic risk prevention based on the 10th and 90th percentiles in the table above:</p><ul><li>For global health and development, 6.25 % (= 1/16) and 22.3 % (= 63/283).</li><li>For animal welfare, 18.8 % (= 3/16) and 37.8 % (= 107/283).</li><li>For effective altruism infrastructure, 625 % (= 100/16) and 35.3 % (= 100/283).</li></ul><h3>Method 3</h3><p>I defined the cost-effectiveness of each area from the mean between those of methods 1 and 2. My best guesses regard the truncation case of this method.</p><h2>Multiplier of operations management in high-impact organisations</h2><p>I defined the multiplier of OM as the median&nbsp;of the 11 distributions described in the table below, and also experimented with truncating to the 99 % CI the component distributions of each of them. I used the median with the intention of following Jaime Sevilla\u2019s <a href=\"https://forum.effectivealtruism.org/posts/acREnv2Z5h4Fr5NWz/my-current-best-guess-on-how-to-aggregate-forecasts\"><u>best guess on how to aggregate forecasts</u></a>:</p><ul><li>The assumptions going into each of the estimates are apparently not mutually exclusive.</li><li>There are outliers:<ul><li>The <a href=\"https://en.wikipedia.org/wiki/Interquartile_range\"><u>interquartile range</u></a>&nbsp;of the mean multipliers is 23.0 (= 30.0 - 6.99), which is the difference between the mean multiplier of the 9th and 5th estimates.</li><li>Consequently, the 4th and 8th estimates are outside of the <a href=\"https://en.wikipedia.org/wiki/Outlier%23Tukey%27s_fences\"><u>Tukey\u2019s fences</u></a>, as their mean multipliers are higher than the 3rd quartile by more than 1.5 times the interquartile range (1.36 k &gt; 136 &gt; 64.5 = 30.0 + 1.5*23.0).</li></ul></li><li>However, these are not necessarily \u201cpoorly calibrated\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefa6gxhavi2uo\"><sup><a href=\"#fna6gxhavi2uo\">[6]</a></sup></span>, so I opted not to exclude them.</li><li>According to Jaime\u2019s flowchart, the 3 choices above justify using the median<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflrsj102q7n\"><sup><a href=\"#fnlrsj102q7n\">[7]</a></sup></span>.</li></ul><p>I obtained the distributions via asking i) 75 people working at <a href=\"https://80000hours.org/job-board/top-orgs/\"><u>80,000 Hours\u2019 top-recommended organisations</u></a>&nbsp;(on October 30 and 31), and ii) 259 people in the Slack \u201cEA Forecasting &amp; Epistemics\u201d (on November 2) for the multiplier of OM of their organisations and the effective altruism community. You can see <a href=\"https://docs.google.com/document/d/1eB2jzpeqlcQ2p-vgmJe1CJNi4-R6ODUEmosZaHbp9bM/edit?usp%3Dsharing\"><u>here</u></a>&nbsp;the list of emails I contacted, and the messages regarding i) and ii) (see \u201cEmails\u201d and \u201cSlack message\u201d, respectively).</p><p>I should emphasise the multiplier of OM may depend a lot on the organisation (e.g. its size, maturity, cause area, and what it understands as operations<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflrxxyupjfrl\"><sup><a href=\"#fnlrxxyupjfrl\">[8]</a></sup></span>), specific position (e.g. seniority), and personal fit<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref27u0x689wl5\"><sup><a href=\"#fn27u0x689wl5\">[9]</a></sup></span>. Consequently, aggregating all estimates as I did has serious limitations.</p><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;text-align:center\" colspan=\"2\" rowspan=\"1\"><p>Multiplier of OM for own organisations (N = 7)</p></th></tr><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Distribution (without truncation)</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean (5th to 95th percentile)</p></th></tr></thead><tbody><tr><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\"><p>Product between<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefy2vjdy4cao\"><sup><a href=\"#fny2vjdy4cao\">[10]</a></sup></span>:</p><ul><li>Lognormal<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpwfz4fxh4t\"><sup><a href=\"#fnpwfz4fxh4t\">[11]</a></sup></span>&nbsp;with 5th and 95th percentiles 0.25 and 30.</li><li>Reciprocal of lognormal<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpwfz4fxh4t\"><sup><a href=\"#fnpwfz4fxh4t\">[11]</a></sup></span>&nbsp;with 5th and 95th percentiles 0.6 and 1.3.</li></ul></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>9.19 (0.274 to 35.1)</p></td></tr><tr><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Lognormal with 5th and 95th percentiles 0.75 and 3.5.</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.81 (0.750 to 3.50)</p></td></tr><tr><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\"><p>Product between<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdvrregl8pyf\"><sup><a href=\"#fndvrregl8pyf\">[12]</a></sup></span>:</p><ul><li>Lognormal with 5th and 95th percentiles 5.6 and 28.</li><li>Reciprocal of lognormal with 5th and 95th percentiles 50 and 75.</li><li>Reciprocal of lognormal with 5th and 95th percentiles 0.1 and 10.</li><li>Lognormal with 5th and 95th percentiles 20 and 90.</li></ul></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>29.1 (0.672 to 112)</p></td></tr><tr><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Lognormal with 25th and 75th percentiles 100 and 1 k.</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.36 k (19.1 to 5.25 k)</p></td></tr><tr><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Normal<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpwfz4fxh4t\"><sup><a href=\"#fnpwfz4fxh4t\">[11]</a></sup></span>&nbsp;with mean and standard deviation 7 and 83.</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>6.99 (-129 to 144)</p></td></tr><tr><td><p>Product between<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1mgev3qxmaj\"><sup><a href=\"#fn1mgev3qxmaj\">[13]</a></sup></span>:</p><ul><li>Normal with 5th and 95th percentiles 90 and 110.</li><li>Reciprocal of normal with 5th and 95th percentiles 50 and 70.</li><li>Reciprocal of the sum between:<ul><li>Normal with 5th and 95th percentiles 3.5 and 4.</li><li>Reciprocal of normal with 5th and 95th percentiles 3.25 and 3.6.</li></ul></li></ul></td><td style=\"text-align:center\">0.420 (0.339 to 0.512)</td></tr><tr><td><p>Product between<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyijhq1i3sqi\"><sup><a href=\"#fnyijhq1i3sqi\">[14]</a></sup></span>:</p><ul><li>Lognormal with 5th and 95th percentiles 0.25 and 2.</li><li>Reciprocal of lognormal with 5th and 95th percentiles 10 and 25.</li><li>Lognormal with 5th and 95th percentiles 30 and 70.</li></ul></td><td style=\"text-align:center\">2.69 (0.609 to 6.89)</td></tr></tbody></table></figure><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;text-align:center\" colspan=\"2\" rowspan=\"1\"><p>Multiplier of OM for the effective altruism community (N = 4)</p></th></tr><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Distribution (without truncation)</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean (5th to 95th percentile)</p></th></tr></thead><tbody><tr><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Lognormal with 5th and 95th percentiles 0.75 and 3.5.</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.81 (0.750 to 3.50)</p></td></tr><tr><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\"><p>Product between<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdvrregl8pyf\"><sup><a href=\"#fndvrregl8pyf\">[12]</a></sup></span>:</p><ul><li>Normal with 5th and 95th percentiles -0.87 and 29.</li><li>Reciprocal of lognormal with 5th and 95th percentiles 20 and 60.</li><li>Reciprocal of lognormal with 5th and 95th percentiles 0.2 and 10.</li><li>Lognormal with 5th and 95th percentiles 20 and 60.</li></ul></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>22.5 (-0.354 m to 88.8)</p></td></tr><tr><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Lognormal with 25th and 75th percentiles 10 and 100.</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>136 (1.90 to 524)</p></td></tr><tr><td style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Normal<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpwfz4fxh4t\"><sup><a href=\"#fnpwfz4fxh4t\">[11]</a></sup></span>&nbsp;with mean and standard deviation 30 and 161.</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>30.0 (-235 to 295)</p></td></tr></tbody></table></figure><p>The low number of estimates is evidence of:</p><ul><li>The difficulty and lack of quantification of the marginal cost-effectiveness of positions. I guess I would receive more estimates for the multiplier of OM if these could be readily obtained from internal data.</li><li>Me having framed the questions poorly.</li></ul><p>In addition, what OM refers to is somewhat unclear. Based on what 80,000 Hours describes <a href=\"https://80000hours.org/articles/operations-management/\"><u>here</u></a>, I think it can refer to both operations more broadly, or to senior operations positions which are further&nbsp;down the career path.</p><p>I also thought about estimating the multiplier based on the number of&nbsp;vacancies and candidates for operations management and all positions, but decided not given their unclear relationship with value. As vacancies decrease and candidates increase for a given position, the difference between the factual and counterfactual decreases, but the value of the factual increases.</p><h1>Results</h1><p>The tables below have the results for the mean, 5th percentile, and 95th percentile of the multiplier of OM and cost-effectiveness metrics. <a href=\"https://docs.google.com/spreadsheets/d/1NDrDsMngpGyoQvSu8CpDTgqnYHiqK-ZiL5kFpo7NycM/edit?usp%3Dsharing\"><u>This</u></a>&nbsp;Sheet contains&nbsp;more results (see tab \u201cTOC\u201d).</p><h2>Multiplier of operations management</h2><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">Multiplier of OM\u2026</th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5th percentile</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>95th percentile</p></th></tr></thead><tbody><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Without truncation</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.55</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.30</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>13.2</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">With truncation</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.53</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.31</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>13.0</p></td></tr></tbody></table></figure><h2>Cost-effectiveness</h2><h3>Method 1</h3><p><strong>Without truncation</strong></p><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">Cost-effectiveness (bp/G$) of\u2026</th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5th percentile</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>95th percentile</p></th></tr></thead><tbody><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Global health and development</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.163</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0196</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.509</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Longtermism&nbsp;and catastrophic risk prevention</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.04</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.00</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Animal welfare</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>41.1</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.85 \u03bc</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.42</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Effective altruism infrastructure</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5.61</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.283</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.41</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">The effective altruism community</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5.61</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.283</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.41</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Operations management in high-impact organisations</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>22.5</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.643</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>20.6</p></td></tr></tbody></table></figure><p><strong>With truncation</strong></p><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">Cost-effectiveness (bp/G$) of\u2026</th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5th percentile</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>95th percentile</p></th></tr></thead><tbody><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Global health and development</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.156</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0208</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.481</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Longtermism&nbsp;and catastrophic risk prevention</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.95</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.03</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>9.71</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Animal welfare</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.95</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.67 \u03bc</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.64</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Effective altruism infrastructure</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.31</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.291</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.14</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">The effective altruism community</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.31</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.291</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.14</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Operations management in high-impact organisations</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">5.92</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.666</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>18.7</p></td></tr></tbody></table></figure><h3>Method 2</h3><p><strong>Without truncation</strong></p><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">Cost-effectiveness (bp/G$) of\u2026</th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5th percentile</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>95th percentile</p></th></tr></thead><tbody><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Global health and development</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.762</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0522</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2.66</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Longtermism&nbsp;and catastrophic risk prevention</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.04</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.00</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Animal welfare</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.35</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.170</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.18</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Effective altruism infrastructure</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5.14</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2.35</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>9.39</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">The effective altruism community</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.85</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.766</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.80</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Operations management in high-impact organisations</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">8.42</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">1.54</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">26.0</td></tr></tbody></table></figure><p><strong>With truncation</strong></p><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">Cost-effectiveness (bp/G$) of\u2026</th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5th percentile</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>95th percentile</p></th></tr></thead><tbody><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Global health and development</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.705</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0549</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2.53</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Longtermism&nbsp;and catastrophic risk prevention</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.95</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.03</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>9.71</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Animal welfare</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.29</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.177</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.01</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Effective altruism infrastructure</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5.10</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2.39</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>9.23</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">The effective altruism community</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.79</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.773</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.59</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Operations management in high-impact organisations</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">8.10</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">1.56</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">24.7</td></tr></tbody></table></figure><h3>Method 3</h3><p><strong>Without truncation</strong></p><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">Cost-effectiveness (bp/G$) of\u2026</th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5th percentile</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>95th percentile</p></th></tr></thead><tbody><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Global health and development</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.463</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0660</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.43</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Longtermism&nbsp;and catastrophic risk prevention</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.04</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.00</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10.0</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Animal welfare</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>21.2</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.101</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.11</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Effective altruism infrastructure</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5.37</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.60</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5.76</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">The effective altruism community</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.73</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.567</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.58</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Operations management in high-impact organisations</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">15.5</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">1.17</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">23.8</td></tr></tbody></table></figure><p><strong>With truncation</strong></p><figure class=\"table\"><table><thead><tr><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">Cost-effectiveness (bp/G$) of\u2026</th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5th percentile</p></th><th style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>95th percentile</p></th></tr></thead><tbody><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Global health and development</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.431</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0676</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.36</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Longtermism&nbsp;and catastrophic risk prevention</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.95</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.03</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>9.71</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Animal welfare</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.62</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.104</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.49</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Effective altruism infrastructure</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.20</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.62</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5.48</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">The effective altruism community</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.55</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.574</p></td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.27</p></td></tr><tr><th style=\"padding:5pt\" colspan=\"1\" rowspan=\"1\">Operations management in high-impact organisations</th><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">7.01</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">1.19</td><td style=\"padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\">21.6</td></tr></tbody></table></figure><h1>Discussion</h1><h2>Multiplier of operations management</h2><p>The mean of the multiplier of OM for the non-truncation and truncation cases are 4.55 and 4.53. I thought organisations would organise themselves such that the expected (marginal) cost-effectiveness would be similar for all positions, so I was somewhat surprised to get values 5 times as high as 1.</p><p>The <a href=\"https://en.wikipedia.org/wiki/P-value\"><u>p-values</u></a>&nbsp;for the null hypothesis that the OM follows distributions with the same shape as the ones I obtained, but with a mean of 1, are 1.27 % and 1.16 % for the non-truncation and truncation cases<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefybsm20ppm2\"><sup><a href=\"#fnybsm20ppm2\">[15]</a></sup></span>. So one can be reasonably confident that the multiplier is higher than 1, but only if the 11 answers I got are representative of the effective altruism community, which is far from certain.</p><p>The mean multiplier of OM for the truncation case is 99.5 % the one for the non-truncation case. This means the outliers of each of the individual estimates practically do not affect the results.</p><h2>Cost-effectiveness</h2><p>For the truncation case, the mean cost-effectiveness metrics as a fraction of that of longtermism and catastrophic risk prevention for methods 1, 2 and 3 are:</p><ul><li>For global health and development, 3.96 %, 17.8 % and 10.9 %.</li><li>For animal welfare, 49.3 %, 32.7 % and 41.0 %.</li><li>For effective altruism infrastructure, 33.0 %, 1.29 and 81.0 %.</li><li>For the effective altruism community, 33.0 %, 45.2 % and 39.1 %.</li><li>For OM, 1.50, 2.05 and 1.77.</li></ul><p>Consequently, for the truncation case:</p><ul><li>Longtermism and catastrophic risk prevention is the most effective area for methods 1 and 3, and the 2nd most effective behind effective altruism infrastructure for method 2.</li><li>Global health and development is the least effective area for all methods.</li><li>OM is more effective than all areas for all methods. Its mean cost-effectiveness is 1.77 times as high as that of longtermism and catastrophic risk prevention for method 3.</li></ul><p>For the non-truncation case:</p><ul><li>Animal welfare is the most effective area for methods 1 and 3, and the 2nd least effective in front of global health and development for method 2.</li><li>Global health and development remains the least effective area for all methods.</li><li>OM remains more effective than all areas for all methods. Its mean cost-effectiveness is 3.83 times as high as that of longtermism and catastrophic risk prevention for method 3.</li></ul><p>I believe the results for the truncation case are more accurate because it is hard to represent outliers well based on subjective 90 % CIs. For example, I think the cost-effectiveness of animal welfare for the non-truncation case is too heavy-tailed, with its mean being 9.98 k (= 41.1/0.00411) times its median. The heavy-tailedness of this same metric for the truncation case seems more reasonable, with its mean being 474 (= 1.95/0.00411) times its median.</p><p>The mean cost-effectiveness of OM for the truncation case as a fraction of that for the non-truncation case is:</p><ul><li>For method 1,&nbsp;26.3 %.</li><li>For method 2,&nbsp;96.2 %.</li><li>For method 3,&nbsp;45.3 %.</li></ul><p>This means the outliers have a material effect for methods 1 and 3, but not for 2.</p><p>The 5th percentile, median, and 95th percentile of the cost-effectiveness of OM for method 3 with truncation are 17.0 %, 58.1 % and 3.09 times the mean of 7.01 bp/G$. I expected the distribution to be more heavy-tailed, but I arguably had in mind the wider distribution of potential applicants instead of the narrower one of those selected for working in the positions.</p><h2>Further work</h2><p>Some potential avenues for further work are, in my descending order of importance:</p><ul><li>Determining and quantifying the effect of the major drivers of the multiplier of OM, such as the size, maturity, and cause area of the organisation, and scope, seniority and personal fit to the specific position.</li></ul><ul><li>Collecting additional estimates for the multiplier of OM, as a sample size of 11 may well not be representative.</li></ul><ul><li>Thinking about ways to estimate the multiplier of OM based on metrics which organisations have readily available (e.g. number of opportunities and applicants).</li><li>Understanding how the multiplier of OM will vary in the future. In general, I wonder about:<ul><li>How much the ranking of <a href=\"https://80000hours.org/career-reviews/\"><u>80,000 Hours\u2019 highest-impact career paths</u></a>&nbsp;is going to change in the future.</li><li>The extent to which expected future variations of the effectiveness of these career paths have already been taken into account, and integrated into the current ranking.</li></ul></li><li>To follow up on the potentially outdated <a href=\"https://80000hours.org/2018/10/2018-talent-gaps-survey/\"><u>EA talent needs survey - 2018</u></a>&nbsp;used in method 2, asking the leaders of organisations aligned with effective altruism about the cost-effectiveness of the 4 <a href=\"https://funds.effectivealtruism.org/\"><u>EA Funds</u></a>. For example, one could request estimates for the 90 % CI:<ul><li>Either in terms of increasing the expected value of the future.</li><li>Or as a multiple of the mean cost-effectiveness of the LTFF, and this mean&nbsp;in terms of increasing the expected value of the future, similarly to what Linchuan Zhang did <a href=\"https://forum.effectivealtruism.org/posts/cKPkimztzKoCkZ75r/how-many-ea-2021-usds-would-you-trade-off-against-a-0-01\"><u>here</u></a>.</li></ul></li><li>Reflecting about how much weight to give to methods 1 and 2 in method 3, instead of defaulting to giving the same weight to both.</li><li>Defining the significance level of the truncation case in a systematic way. I selected 99 % because its complementary of 1 % is one order of magnitude below 10 %, which is the complementary of 90 %, and most distributions I modelled are based on 90 % CIs.</li><li>Assessing the influence of the <a href=\"https://forum.effectivealtruism.org/topics/ftx-crisis\"><u>FTX crisis</u></a>&nbsp;on the results/interpretation of my analysis, which was conducted before it started. I expect:<ul><li>The cost-effectiveness of longtermism and catastrophic risk prevention, and effective altruism infrastructure to increase relative to global health and development, and animal welfare<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref75t4890l9oe\"><sup><a href=\"#fn75t4890l9oe\">[16]</a></sup></span>.</li><li>The cost-effectiveness of the effective altruism community to increase<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpkopa6w75s\"><sup><a href=\"#fnpkopa6w75s\">[17]</a></sup></span>.</li><li>The multiplier of OM to decrease in the short-term, due to less funding being available to start and scale projects.</li></ul></li></ul><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzcgh48wsr9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzcgh48wsr9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For 10 M random samples, each truncation and non-truncation case takes me 5 min to run and save the results.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne94lfyg635m\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe94lfyg635m\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;In this text, cost-effectiveness refers to marginal cost-effectiveness.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnivxgagy642\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefivxgagy642\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This is a link to my copy, which contains data last updated on August 15. You can find Tyler\u2019s Sheet <a href=\"https://docs.google.com/spreadsheets/d/1IeO7NIgZ-qfSTDyiAFSgH6dMn1xzb6hB2pVSdlBJZ88/edit?usp%3Dsharing\"><u>here</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7cxaped0syc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7cxaped0syc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;If X and X_pre_trunc are the truncated and pre-truncation distributions, and p is the probability of X_pre_trunc being between the minimum and maximum of X, the probability of X being between a and b is 1/p times as large as that of X_pre_trunc being between a and b, which are 2 values between the minimum and maximum of X.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhkjayhc0sum\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhkjayhc0sum\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;These 2 values consider a wide moral weight distribution whose 95th percentile is 60 k (= 17.2 / (270 \u03bc)) times as large as the 5th percentile.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fna6gxhavi2uo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefa6gxhavi2uo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;According to Jaime:</p><blockquote><p>When the data includes poorly calibrated outliers, if it's possible exclude them and take the geometric mean. If not, we should use a pooling method resistant to outliers. The median is one such popular aggregation method.</p></blockquote></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlrsj102q7n\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflrsj102q7n\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The median significantly attenuates the effect of the outliers. For the truncation (non-truncation) case, the mean multiplier with all estimates is&nbsp;1.54 (1.97) times that without the 4th and 8th estimates using the median, but&nbsp;11.0 (12.5) times using the mean.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlrxxyupjfrl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflrxxyupjfrl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;According to Stien van der Ploeg, <a href=\"https://animalcharityevaluators.org/\"><u>Animal Charity Evaluators</u></a>\u2019 Executive Director:</p><blockquote><p>Some organisations consider any non-program related positions to fall under operations, including communications, strategy, HR, finance, and fundraising roles. Other groups only consider specific administrative jobs like finance, personnel, and organisational support as operations, and some interpret it even narrower.</p></blockquote></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn27u0x689wl5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref27u0x689wl5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The mean person working in OM has a much better fit than the respective mean applicant, but there may still be material variation amongst workers.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fny2vjdy4cao\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefy2vjdy4cao\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The 1st/2nd distribution represents the marginal impact/cost per unit time of OM relative to all positions.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpwfz4fxh4t\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpwfz4fxh4t\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The respondent mentioned this type of distribution was an approximation.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndvrregl8pyf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdvrregl8pyf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The 1st/2nd distribution represents the marginal impact/cost per unit time of OM, and the 3rd/4th that of all positions.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1mgev3qxmaj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1mgev3qxmaj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The 1st distribution represents the marginal impact per unit time of OM as a multiple of the mean marginal impact of all positions, and the 2nd/3rd the marginal cost per unit time of OM / all positions.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyijhq1i3sqi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyijhq1i3sqi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The 1st/2nd distribution represents the marginal impact/cost per unit time of OM, and the 3rd/4th that of all positions.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnybsm20ppm2\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefybsm20ppm2\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Calculated in J2 of the last 2 tabs of the <a href=\"https://docs.google.com/spreadsheets/d/1NDrDsMngpGyoQvSu8CpDTgqnYHiqK-ZiL5kFpo7NycM/edit?usp%3Dsharing\"><u>Sheet</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn75t4890l9oe\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref75t4890l9oe\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;According to the <a href=\"https://docs.google.com/spreadsheets/d/1gN_oR1-nk08DaSxvm1vEQCzpPkwCkv7ftWmKbvYzw_Y/edit?usp%3Dsharing\"><u>data</u></a>&nbsp;collected by Tyler Maule, the spending as a fraction of the total of the <a href=\"https://forum.effectivealtruism.org/topics/ftx-foundation\"><u>FTX Foundation</u></a>&nbsp;between January 1 and August 15 on longtermism and catastrophic risk prevention, and effective altruism infrastructure was 73.5 % and 26.5 %.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpkopa6w75s\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpkopa6w75s\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;According to the data collected in July 2021 by Benjamin Todd <a href=\"https://forum.effectivealtruism.org/posts/zA6AnNnYBwuokF8kB/is-effective-altruism-growing-an-update-on-the-stock-of%23How_many_funds_are_committed_to_effective_altruism_\"><u>here</u></a>, the \u201cFTX team\u201d represented 35.8 % (= 16.5/46.1) of the funds committed to effective altruism. Assuming the cost-effectiveness is inversely proportional to the committed funds, losing those from FTX leads to it being 1.56 (= 1/(1 - 35.8 %)) times as high.</p></div></li></ol>", "user": {"username": "vascoamaralgrilo"}}, {"_id": "Foh2mCycudKgDNZqC", "title": "Come get malaria with me?", "postedAt": "2022-11-29T21:15:46.427Z", "htmlBody": "<p>I promise I'm not going to start spamming the forums every week to badger you about getting a different exotic disease (see the post about <a href=\"https://forum.effectivealtruism.org/posts/kKidKRiCcZ5uGJ6w5/stop-thinking-about-ftx-think-about-getting-zika-instead\">Zika)</a>. But I was accepted into <a href=\"https://www.medschool.umaryland.edu/cvd/trials/Malaria-TravSPZ/\">this study</a> in Baltimore,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrx6abjhx5n\"><sup><a href=\"#fnrx6abjhx5n\">[1]</a></sup></span>&nbsp;which you can sort of think of as a part-time job fighting malaria from January to early March-ish.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref465l7u2ggka\"><sup><a href=\"#fn465l7u2ggka\">[2]</a></sup></span>&nbsp;I figured some of you may be interested as well. (Please let me know if you sign up for pre-screening! I am always happy to talk about things in more detail if you have questions.)</p><p>If you're not in the DMV, 1Day Sooner keeps track of potentially high-impact studies on our website and via our newsletter; <a href=\"https://www.1daysooner.org/volunteer-hub\">sign up</a> if you want to hear about hot, single challenge trials recruiting in YOUR area in the future.</p><p>The following is a condensed version of what's outlined in <a href=\"https://docs.google.com/document/d/1GPsK2cNXJZyRQhjOfRra0j82RCywNC9rJQ10zhtRxnc/edit#\">this informal document</a>. Obligatory disclosure: Neither I nor my org, 1Day Sooner, represent the study. I'm just excited about it :)</p><p><strong>&nbsp;Why would an EA consider this? </strong>Malaria is bad and the vaccine in this trial could result in nontrivial decreases in malaria mortality. What it comes down to is whether the costs \u2014 especially time commitment \u2014 make sense for you specifically. &nbsp;As the expanded <a href=\"https://docs.google.com/document/d/1GPsK2cNXJZyRQhjOfRra0j82RCywNC9rJQ10zhtRxnc/edit#\">document</a> discusses, the risks of serious complications are very, very low.&nbsp;</p><p>You'll be screened to make sure you're not at any elevated risk, and treatment will be initiated very quickly after you contract malaria (if you do at all). So if you <i>do </i>feel like you have the bandwidth for a part-time malaria-fighting job (remote work capability pretty much necessary), this is a good tangible way to make a difference. Also, you'll get paid. And you'll become friends with me, and I am very fun to be around, in my opinion.</p><p><strong>30-second trial summary:</strong> A malaria vaccine candidate with solid chance of eventual deployment in pregnant women needs to undergo this challenge trial being held by U Maryland \u2014 Baltimore's Center for Vaccine Development. It's outpatient. The burden of time will very likely be more than the burden of actually being sick. I will be in it, and other EAs and 1Day Sooner volunteers have expressed interest. Compensation runs up to $3,845. 1Day Sooner can help ease burdens of participation, especially transport from DC.&nbsp;</p><p><strong>Slightly expanded summary:</strong></p><ul><li>A promising malaria vaccine, PfSPZ, needs to be tested as a key step in licensure as a traveler's vaccine, which in turn will support eventual deployment among pregnant women.&nbsp;<ul><li>This vaccine will not be the final cure humanity has been waiting for. It is most promising for use during pregnancy.&nbsp;</li><li>There is never a guarantee a vaccine candidate will be successful, nor successfully deployed. It may well be that PfSPZ works well, but in a few years another vaccine turns out to be even better.&nbsp;</li></ul></li><li>The primary burden is time rather than discomfort, i.e., being sick with malaria for at most a few days, but also lots of blood draws. I have a rough estimate of hours spent in <a href=\"https://docs.google.com/spreadsheets/d/1XDptar0eqltF_AnqtEvK2lPHUEDcbRa1h-MC8dpgkhI/edit#gid=0\">this spreadsheet</a>.&nbsp;<ul><li>Low estimate for time spent if you are <strong>from DC</strong> (transit, visits, other lost productive time): 60-70 hours. High estimate: 90-100. &nbsp;</li><li>For Baltimoreans, probably more like 45-65 hours.</li><li>A few of these hours can be productive, like on a train or waiting around at some of the longer visits.</li></ul></li><li>Vaccination begins in January (specific dates to be announced shortly). There are three doses spaced out across one month. The vaccine has already been tested rather extensively for safety, it is very well tolerated. Three weeks after the final dose, we will be challenged with malaria. One-fourth of the participants will get a placebo injection.</li><li>One week after the malaria challenge, we will begin going into the clinic in Baltimore for short, daily blood tests in the morning. Treatment will be administered ASAP after malaria is detected, definitely within ~18-24 hours maximum after detection, if not sooner.</li><li>I and one other 1Day Sooner volunteer are already registered. 6 others have expressed serious interest (4 EAs, two others). To make things easier, we will be arranging an AirBnb. Details will be finalized as enrollment is solidified.&nbsp;</li></ul><p>Again, for even more info, see this <a href=\"https://docs.google.com/document/d/1GPsK2cNXJZyRQhjOfRra0j82RCywNC9rJQ10zhtRxnc/edit#\">document</a>. If you'd like, sign up for a pre-screening phone call <a href=\"https://www.medschool.umaryland.edu/cvd/trials/Malaria-TravSPZ/\">here</a>, and let me know if you do! Otherwise, I'm happy to answer any questions to the best of my ability. As always, the doctors and researchers involved in the study will be the final word, and you'll be briefed by them before you are allowed to enroll.&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrx6abjhx5n\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrx6abjhx5n\">^</a></strong></sup></span><div class=\"footnote-content\"><p>As mentioned in the Zika post, 1Day employees are not <i>required </i>to get exotic diseases as a condition of employment, because that would be insane, and also probably illegal. I want to do this of my own accord, I swear.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn465l7u2ggka\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref465l7u2ggka\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Total duration is 6-8 months, but that includes a very small number of follow up visits months after challenge. The majority of visits will take place within about an 8-12 week window starting in January.</p></div></li></ol>", "user": {"username": "jeberts"}}, {"_id": "WAdhvskTh2yffW9gc", "title": "Carl Djerassi (1923\u20132014)", "postedAt": "2022-11-29T20:36:59.749Z", "htmlBody": "<figure class=\"image image_resized\" style=\"width:42.16%\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1669754425/mirroredImages/WAdhvskTh2yffW9gc/bj3wvxpfdala6qreblja.jpg\" alt=\"Carl Djerassi: Chemist, Writer\"><figcaption>I don't always invent life-changing medicines, but when I do</figcaption></figure><p>Carl Djerassi helped invent the synthetic hormone norethindrone, one of the <a href=\"https://en.wikipedia.org/wiki/WHO_Model_List_of_Essential_Medicines\">500 most important</a> medicines (actually <a href=\"https://clincalc.com/DrugStats/Top300Drugs.aspx\">top 50</a> by prescription count). A large supply is a basic requirement of every health system in the world.&nbsp;</p><p>Norethindrone is important for two reasons. First, it treats menstrual disorders and endometriosis, together <a href=\"https://www.healthdata.org/gbd/2019\">0.3%</a> of the global burden of disease. More famously, it was a component of The Pill.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3ipqpgveva2\"><sup><a href=\"#fn3ipqpgveva2\">[1]</a></sup></span>&nbsp;People mix up the timelines, which is why he is sometimes called the 'Father of the Pill'. <a href=\"http://www.shoppbs.pbs.org/wgbh/amex/pill/timeline/timeline2.html\">But</a> \"<i>neither Djerassi nor the company he works for, Syntex, had any interest in testing it as a contraceptive</i>\" and it was only used for birth control 12 years after.</p><p>As usual in industrial chemistry, Djerassi got no royalties from the blockbuster medicine he helped develop - but, surprise ending! - he bought cheap shares in Syntex and got rich when it became one of the most important medicines in history for two reasons.</p><p>He also synthesized the <a href=\"https://en.wikipedia.org/wiki/Tripelennamine\">third-ever</a> practical antihistamine, and applied new instruments in 1,200 papers on the structure of many important steroids. He also worked on <a href=\"https://en.wikipedia.org/wiki/Dendral\">one of the first</a> AI programs to do useful work in science.</p><h2>Achievements</h2><p><i>Epistemic status: little better than a guess.</i></p><p>Not many inventions are fully counterfactual; most simple, massively profitable things which get invented would have been invented by someone else a bit later. So the appropriate unit for lauding inventors is <i>years saved</i>. And if I put a number on that I'd just be making it up.</p><p>Here are the numbers I made up:</p><ul><li><a href=\"https://clincalc.com/DrugStats/Drugs/EthinylEstradiolNorethindrone\">About 4</a> <a href=\"https://clincalc.com/DrugStats/Drugs/Norethindrone\">million</a> US users, so <a href=\"https://www.wolframalpha.com/input?i=4+million+%2F+US+population+*+world+population\">maybe</a> up to 94 million world users at present. No sense of the endometriosis / contraception split.&nbsp;</li><li>Call it 600 million users, <a href=\"https://www.who.int/news-room/fact-sheets/detail/endometriosis#:~:text=Endometriosis%20is%20a%20disease%20where,and%20girls%20globally%20(2).\">10%</a> endometriosis use case.</li><li>For menstrual disorders:&nbsp;<ul><li>on the market 65 years and counting.&nbsp;</li><li>Counterfactual: on the market 3 years before the next oral progestogen was.</li><li>It was the first practical oral progestogen, so we should compare to the injectable alternatives<ul><li>About <a href=\"https://pubmed.ncbi.nlm.nih.gov/30109720/\">1/6</a> of Americans hate needles so much that they refuse treatment.</li><li>Attrition and missed doses for needle treatments is higher than pill treatments.</li></ul></li><li>Endometriosis is about <a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0210089\">0.25 - 0.35</a> QALY loss. So if it's 30% effective, around &nbsp;$30 / QALY, an amazing deal.</li></ul></li><li>For easy contraception:&nbsp;<ul><li>on the market 59 years and counting.</li><li>The big gains (besides autonomy) are averting unintended pregnancies, abortions, and pregnancy-related deaths.</li><li>Modern cost-effectiveness in Ethiopia is <a href=\"https://pubmed.ncbi.nlm.nih.gov/34116422/\">$96 / QALY</a>.</li><li>There's probably some additive effect for endometriosis sufferers (who would want contraception anyway).</li></ul></li><li>A full account would guess the Pill's effect on the sexual revolution and cultural attitudes toward women. But I've reached my limit. (You might also consider the role of the Pill in the ongoing decline of church authority: \"<a href=\"https://www.pbs.org/wgbh/americanexperience/features/pill-timeline/#:~:text=In%20spite%20of%20the%20Pope's,dosage%20oral%20contraceptives%20are%20introduced.\">1980</a>: <i>In spite of the Pope's ruling against the Pill and birth control, almost 80% of American Catholic women use contraceptives, and only 29% of American priests believe it is intrinsically immoral.</i>\")</li><li>How many years did he bring the invention forward? Call it 5.</li><li>Then split the credit three ways with Luis Miramontes and George Rosenkranz.</li></ul><p>So (largely made-up numbers) it looks like millions of QALYs for the treatment overall, and tens of thousands counterfactually for Djerassi.<br>&nbsp;</p><h2>Artist</h2><p>After surviving cancer, he decided to become a writer.&nbsp;</p><blockquote><p><i>I was very depressed, and for the first time thought about mortality. Strangely enough I had not thought about death before... I realized that who knows how long I would live? In cancer they always talk about five years: if one can survive five years then presumably the cancer had been extirpated. And I thought: gee, had I known five years earlier that I would come down with cancer, would I have led a different life during these five last years? And my answer to myself was yes. I said, well, Carl Djerassi, now you know it... I decided I wanted to live another intellectual life: a very different one... So, by 1989, when I really started reducing the size of my research group on a substantial scale I wrote the first autobiography. I wrote my first novel...</i></p></blockquote><p>It's extremely rare for any successful academic to shutter their lab. (They claw too long to build it.)</p><blockquote><p><i>But suicide is a death that has a purpose, and the person who commits suicide usually sends out a message... the survivors ought to be able to figure out what had prompted this irrevocable step... So, this was my answer in the context of my daughter\u2019s death and why I founded an artist\u2019s colony in her memory... I wanted to create again something living out of death.</i></p></blockquote><p>&nbsp;</p><hr><p>You can see one of his plays <a href=\"https://www.youtube.com/watch?v=zdsyW3d4XrI\">here</a>. It's ok.&nbsp;</p><blockquote><p><a href=\"https://www.theguardian.com/stage/2014/apr/29/carl-djerassi-inventor-pill-sex-lives-philosophers-foreplay\">Most</a> of [Djerassi's] plays are directly scientific. When playwrights use science \u2013 he cites Michael Frayn and his old friend Tom Stoppard \u2013 they usually do so as metaphor, not, as Djerassi intends, as a subject in its own right.</p></blockquote><p>(I would say when playwrights <a href=\"https://www.nybooks.com/articles/2001/02/08/heisenberg-in-copenhagen-an-exchange/\">abuse</a> <a href=\"https://www.goodreads.com/review/show/408971325\">science</a>.)</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3ipqpgveva2\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3ipqpgveva2\">^</a></strong></sup></span><div class=\"footnote-content\"><p>but owing to 12 years of delay the substance was actually the 'world's second-ever reversible birth control pill'</p></div></li></ol>", "user": {"username": "technicalities"}}]