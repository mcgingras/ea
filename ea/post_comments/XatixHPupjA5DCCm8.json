[{"_id": "bKfjAxjwiupbAgp4k", "postedAt": "2023-12-29T08:27:36.779Z", "postId": "XatixHPupjA5DCCm8", "htmlBody": "<p>It's somewhat striking that you frame your top-level advice as a comparative:</p><blockquote><p>I recommend everyone cut this habit down ~90% in aggregate for topics they deem important, replacing the great majority of second-order evaluations with first-order evaluations.</p></blockquote><p>People surely differ in their current behaviour, and need different adjustments. So why not simply specify what you think the optimal ratio of first- to second-order evaluations is?</p>", "parentCommentId": null, "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "HbpFm9E7gRz4yWNLu", "postedAt": "2023-12-29T08:45:14.448Z", "postId": "XatixHPupjA5DCCm8", "htmlBody": "<p>My take: not infrequently, as here, comparatives are <i>more </i>precise than first-order evaluations.</p><p>You're calling attention to a dimension that people may not have thought about much, and certainly don't have established metrics for. If you said \"people should be 9/10 on the use of first-order evaluations and 3/10 on the use of second-order evaluations\", you don't know how people will interpret that. It's well within the realm of possibility that some readers will nod along and say \"yes that's how I do things already\", even when you would assess their actions quite differently.</p><p>By using a comparative, you get the benefit of a common reference point -- how much things are already being done. People will have a sense of this even if they don't know how to measure it. You get to specify that people should cut it down by 90%, which is concrete and can surface disagreements.</p><p>I do happen to think you're quite wrong in suggesting cutting it down by ~90%, although I agree with the directional nudge vs current practice. I guess that at the moment second-order comparisons comprise the large majority of communication, and it would be better if they comprised a slightly smaller majority -- perhaps tripling the amount of use first-order evaluations get.</p>", "parentCommentId": "bKfjAxjwiupbAgp4k", "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "J5L48gngD7meYHHXt", "postedAt": "2023-12-29T11:00:29.835Z", "postId": "XatixHPupjA5DCCm8", "htmlBody": "<p>Interesting take. I don't like it.&nbsp;</p><p>Perhaps because I like saying overrated/underrated.</p><p>But also because overrated/underrated is a quick way to provide information. \"Forecasting is underrated by the population at large\" is much easier to think of than \"forecasting is probably rated 4/10 by the population at large and should be rated 6/10\"</p><p>Over/underrated requires about 3 mental queries, \"Is it better or worse than my ingroup thinks\" \"Is it better or worse than my ingroup thinks?\" \"Am I gonna have to be clear about what I mean?\"</p><p>Scoring the current and desired status of something requires about 20 queries \"Is 4 fair?\" \"Is 5 fair\" \"What axis am I rating on?\" \"Popularity?\" \"If I score it a 4 will people think I'm crazy?\"...</p><p>Like in some sense your right that % forecasts are more useful than \"More likely/less likely\" and sizes are better than \"bigger smaller\" but when dealing with intangibles like status I think it's pretty costly to calculate some status number, so I do the cheaper thing.</p><p>&nbsp;</p><p>Also would you prefer people used over/underrated less or would you prefer the people who use over/underrated spoke less? Because I would guess that some chunk of those 50ish karma are from people who don't like the vibe rather than some epistemic thing. And if that's the case, I think we should have a different discussion.</p><p>I guess I think that might come from a frustration around jargon or rationalists in general. And I'm pretty happy to try and broaden my answer from over/underrated - just as I would if someone asked me how big a star was and I said \"bigger than an elephant\". But it's worth noting it's a bandwidth thing and often used because giving exact sizes in status is hard. Perhaps we shouldn't have numbers and words for it, but we don't.</p>", "parentCommentId": null, "user": {"username": "nathan"}}, {"_id": "vZKubeXopkbqes3z2", "postedAt": "2023-12-29T16:33:41.814Z", "postId": "XatixHPupjA5DCCm8", "htmlBody": "<p>(I am pretty unsure I understood this correctly, so this comment might be a mistake, posting anyway as it might be clarifying for others as well if so)</p><p>It seems to me that there are two dimensions here:</p><p>(a) whether or not a statement is comparative (b) whether or not a statement is confounded by an unobservable</p><p>Comparative statements can be confounded when the comparison standard is not made explict, which seems to be your main critique. If I understand you correctly, you see the main response in non-comparative first order evaluations.</p><p>But shouldn't, in many cases, the solution to that be better explicated and precise comparative statements (e.g. <i>\"I think forecasting is X times better than commonly assumed where my assumption of commonly assumed is based on Y?\"</i>) rather than a non-comparative first-order evaluation of how good forecasting is in objective standards?<br><br>It seems to me that a big advantage of comparative statements is that (i) usually decisions require comparative statements and, if those are not available, non-comparative estimates willl then often be compared (introducing confounding in terms of whether different estimates were made with roughly comparable methods and standards) and also that (ii) many situations only allow for comparative statements and allow for more robustness on comparative grounds rather than trying to get to accurate first-order evaluations.&nbsp;<br><br>E.g. it seems to me that almost all credible knowledge in longtermism comes from comparative statements where there are vast uncertainties on the absolute first-order goodness of many things, but -- relatively speaking -- much more certainty on the relative priority and, luckily, that is also what matters most when making decisions. E.g. it seems pretty impossible to estimate the absolute goodness of reducing existential risk from source X and source Y, but we can say relatively meaningful things about the priority of working on X or Y. Would getting to more precise comparisons on the level of comparative statements also be part of your suggested project here?<br><br>&nbsp;</p>", "parentCommentId": null, "user": {"username": "jackva"}}, {"_id": "nkbps9qdvAhogDhd7", "postedAt": "2023-12-29T16:34:22.872Z", "postId": "XatixHPupjA5DCCm8", "htmlBody": "<p>I am glad somebody wrote this post. I often have the inclination to write posts like these, but I feel like advice like this is sometimes good and sometimes bad and it would be disingenuous for me to stake out a claim in any direction. Nonetheless, I think it\u2019s a good mental exercise to explicitly state the downsides of comparative claims and the upsides of absolute claims, and then people in the comments will (and have) assuredly explain the opposite.</p>\n", "parentCommentId": null, "user": {"username": "RedStateBlueState"}}, {"_id": "npk27nruny2N2DyMd", "postedAt": "2023-12-30T13:47:46.033Z", "postId": "XatixHPupjA5DCCm8", "htmlBody": "<p>I feel that often saying X is overrated/underrated is a lazy way for people (including me sometimes) to increase/decrease X's status without making the effort to state concretely their position on X (which opens them up to more criticism and might require introspection and more careful reasoning rather than purely evaluating vibes)&nbsp;</p>", "parentCommentId": null, "user": {"username": "Quadratic Reciprocity"}}, {"_id": "xfgZLGiuawZykH6PP", "postedAt": "2023-12-30T17:56:35.255Z", "postId": "XatixHPupjA5DCCm8", "htmlBody": "<p>Hi Owen,</p><p>My interpretation is that Gregory is arguing for greater precision in comparative statements, rather than arguing against comparisons in general.</p>", "parentCommentId": "HbpFm9E7gRz4yWNLu", "user": {"username": "vascoamaralgrilo"}}, {"_id": "nZz2qbLiko6MW3Krc", "postedAt": "2023-12-31T16:28:11.822Z", "postId": "XatixHPupjA5DCCm8", "htmlBody": "<p>I agree that \"underrated/overrated\" or similar directional commentary is often a better way to convey information. Not least because the directional comment sometimes<i> is</i> information (e.g. there's a source of systematic error which biases the results) whereas an attempt to estimate a magnitude of the adjustment necessary is just a guess. And using vague verbal qualifiers (x is <i>very</i> large, the error is <i>minimal</i>) instead of a made-up figure much more accurately conveys that something is opinion or methodological critique rather than new data.</p><p>Using an actual figure where it exists is obviously good epistemics, but use of guesstimates risks anchoring truth-seekers to your guesses. Setting the expectation that anyone who participates to supply numbers is worse, as it sets a high bar to commentary (really I should be able to say a field is \"neglected\" without specifying how much funding it deserves and how it should be spent!) and can be used to insulate from criticism. \"If you think I've inflated my outlying estimate you should tell me exactly how much you think each figure should be so I can attack <i>your</i> lack of evidence instead\" seems like a more problematic rhetorical technique than understating just how extreme your enthusiasm for something is in order to help reach consensus.&nbsp;</p><blockquote><p>Also would you prefer people used over/underrated less or would you prefer the people who use over/underrated spoke less? Because I would guess that some chunk of those 50ish karma are from people who don't like the vibe rather than some epistemic thing. And if that's the case, I think we should have a different discussion.</p><p>I guess I think that might come from a frustration around jargon or rationalists in general</p></blockquote><p>As an outsider (other outside perspectives exist!) I'd say there's probably more frustration with rationalists/EAs often appearing to like the vibe of <i>artificially precise</i> numerical claims about things which are weakly evidenced or completely subjective...</p><p>Reality is concrete but the artistic merit of Buffy or moral weight for livestock isn't (even if it is an occasionally useful concept for modelling/ranking priorities), and I'm not sure \"people should rate forecasting at 8/10\" actually conveys any information at all. The illusion of precision is overrated ;-)</p>", "parentCommentId": "J5L48gngD7meYHHXt", "user": {"username": "David T"}}, {"_id": "CijT6Ave5m5R9F6e9", "postedAt": "2023-12-31T19:42:08.326Z", "postId": "XatixHPupjA5DCCm8", "htmlBody": "<p>As an example, could you give X/10 ratings to the idea of relative and absolute ratings?</p>", "parentCommentId": null, "user": {"username": "Larks"}}, {"_id": "FjbnFThjsBQwgXXJR", "postedAt": "2024-01-09T09:01:23.540Z", "postId": "XatixHPupjA5DCCm8", "htmlBody": "<p>I think overrated-underrated is useful because it's trying to say whether we should be doing more or less of X on the margin. Often it's much more useful to know whether something is good on the current margin rather than on average.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Nathan_Barnard"}}]