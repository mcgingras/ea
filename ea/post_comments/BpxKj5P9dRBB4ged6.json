[{"_id": "gEjthiTyHEpFxBz6y", "postedAt": "2023-08-05T18:09:33.437Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>I'm really sorry you're experiencing this. I think it's something more and more people are contending with, so you aren't alone, and I'm glad you wrote this. As somebody who's had bouts of existential dread myself, there are a few things I'd like to suggest:</p><ol><li>With AI, we fundamentally do not know what is to come. We're all making our best guesses -- as you can tell by finding 30 different diagnoses! This is probably a hint that we are deeply confused, and that we should not be too confident that we are doomed (or, to be fair, too confident that we are safe).</li><li>For this reason, it can be useful to practice thinking through the models on your own. Start making your own guesses! I also often find the technical and philosophical details beyond me -- but that doesn't mean we can't think through the broad strokes. \"How confident am I that instrumental convergence is real?\" \"Do I think evals for new models will become legally mandated?\" \"Do I think they will be effective at detecting deception?\" At the least, this might help focus your content consumption instead of being an amorphous blob of dread -- I refer to it this way because I found the invasion of Ukraine sent me similarly reading as much as I could. Developing a model by focusing on specific, concrete questions (e.g. What events would presage a nuclear strike?) helped me transform my anxiety from \"Everything about this worries me\" into something closer to \"Events X and Y are probably bad, but event Z is probably good\".</li><li>I find it very empowering to work on the problems that worry me, even though my work is quite indirect. AI safety labs have content writing positions on occasion. I work on the 80,000 Hours job board and we list <a href=\"https://jobs.80000hours.org/?refinementList[tags_area][0]=AI safety %26 policy\">roles in AI safety</a>. Though these are often research and engineering jobs, it's worth keeping an eye out. It's possible that proximity to the problem would accentuate your stress, to be fair, but I do think it trades against the feeling of helplessness!</li><li><a href=\"https://fscsmn.org/email-article/very-applicable-to-today-written-by-cs-lewis-in-1948/\">C. S. Lewis has a take</a> on dealing with the dread of nuclear extinction that I'm very fond of and think is applicable: <i>\u2018How are we to live in an atomic age?\u2019 I am tempted to reply: \u2018Why, as you would have lived in the sixteenth century when the plague visited London almost every year...\u2019&nbsp;</i></li></ol><p>&nbsp;</p><p>I hope this helps!</p>", "parentCommentId": null, "user": {"username": "Ideopunk"}}, {"_id": "yKwvxy9BPeCrQfMdB", "postedAt": "2023-08-05T18:16:54.119Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>Rereading your post, I'd also strongly recommend prioritizing finding ways to not spend all free time on it. Not only do I think that that level of fixating is one of the worst things people can do to make themselves suffer, it also makes it very hard to think straight and figure things out!</p>\n<p>One thing I've seen suggested is dedicating time each day to use as research time on your questions. This is a compromise to free up the rest of your time to things that don't hurt your head. And hang out with friends who are good at distracting you!</p>\n", "parentCommentId": "gEjthiTyHEpFxBz6y", "user": {"username": "Ideopunk"}}, {"_id": "MzuDvZ7aBKbyZ3bcx", "postedAt": "2023-08-05T18:37:45.309Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>Perhaps it would be useful to talk to someone alive in 1960 about how they carried about their lives under the constant threat of nuclear war?&nbsp;</p>", "parentCommentId": null, "user": {"username": "just_a_dude"}}, {"_id": "yEtaendHccQxX8hKK", "postedAt": "2023-08-05T22:03:31.001Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>You might appreciate Julia Wise's <a href=\"https://forum.effectivealtruism.org/posts/aeAHECQMLHCGroAkC/finding-equilibrium-in-a-difficult-time\">finding equilibrium in a difficult time</a>. The post was about how to relate to the world at the start of covid (notably, a global pandemic that &gt;99% of people survived, despite large human costs to both lives and livelihoods). But it can apply just as easily to AI doom fears.<br>&nbsp;</p><blockquote><p>This is a historic event. I find it kind of comforting to know that other people have been through similar historic events. Other people throughout the centuries have experienced epidemics and have worried, argued about what to do, and done their best to take care of each other.</p><p><a href=\"https://www.thegospelcoalition.org/article/cs-lewis-coronavirus/\"><u>C.S. Lewis</u></a> wrote in 1948:</p><p>\"In one way we think a great deal too much of the atomic bomb. \u201cHow are we to live in an atomic age?\u201d I am tempted to reply: \u201cWhy, as you would have lived in the sixteenth century when the plague visited London almost every year, or as you would have lived in a Viking age when raiders from Scandinavia might land and cut your throat any night; or indeed, as you are already living in an age of cancer, an age of syphilis, an age of paralysis, an age of air raids, an age of railway accidents, an age of motor accidents.\u201d</p><p>\"In other words, do not let us begin by exaggerating the novelty of our situation. Believe me, dear sir or madam, you and all whom you love were already sentenced to death before the atomic bomb was invented: and quite a high percentage of us were going to die in unpleasant ways. We had, indeed, one very great advantage over our ancestors\u2014anesthetics; but we have that still. It is perfectly ridiculous to go about whimpering and drawing long faces because the scientists have added one more chance of painful and premature death to a world which already bristled with such chances and in which death itself was not a chance at all, but a certainty.</p><p>\"<strong>This is the first point to be made: and the first action to be taken is to pull ourselves together. If we are all going to be destroyed by an atomic bomb, let that bomb when it comes find us doing sensible and human things\u2014praying, working, teaching, reading, listening to music, bathing the children, playing tennis, chatting to our friends over a pint and a game of darts\u2014not huddled together like frightened sheep and thinking about bombs. They may break our bodies (a microbe can do that) but they need not dominate our minds.</strong>\"</p></blockquote><p>(<strong>emphasis</strong> mine)</p>", "parentCommentId": null, "user": {"username": "Linch"}}, {"_id": "o7BfN9nQJPLJwGhWm", "postedAt": "2023-08-05T23:15:38.190Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>I have a masters degree in machine learning and I've been thinking a lot about this for like 6 years, and here's how it looks to me:</p><ul><li>AI is playing out in a totally different way to the doomy scenarios Bostrom and Yudkowsky warned about</li><li>AI doomers tend to hang out together and reinforce each other's extreme views</li><li>I think rationalists and EAs can easily have their whole lives nerd-sniped by plausible but ultimately specious ideas</li><li>I don't expect any radical discontinuities in the near-term future. The world will broadly continue as normal, only <i>faster.</i></li><li>Some problems will get worse as they get faster. Some good things will get better as they get faster. Some things will get weirder in a way where it's not clear if they're better or worse.</li><li>Some bad stuff will probably happen. Bad stuff has always happened. So it goes.</li><li>It's plausible humans will go extinct from AI. It's also plausible humans will go extinct from supervolcanoes. So it goes.</li></ul><blockquote><p>I\u2019m paralysed by the thought that I really can\u2019t <i>do</i> anything about it.</p></blockquote><p>IMO, a lot of people in the AI safety world are making a lot of preventable mistakes, and there's a lot of value in making the scene more legible. If you're a content writer, then honestly trying to understand what's going on and communicating your evolving understanding is actually pretty valuable. Just write more posts like this.</p>", "parentCommentId": null, "user": {"username": "Hamish Doodles"}}, {"_id": "QsKo9rTy9ixHoBdCL", "postedAt": "2023-08-05T23:52:36.191Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>Hi bethhw!</p><p>Thanks for taking the time to write up this post. Many of us have gone through similar things and can relate to the struggle you are experiencing.</p><p><strong>Regarding the \"I can't do anything about it\" part</strong>:&nbsp;</p><ol><li>I see this meme a lot in the AI safety community. I think it's a function of a) the underlying complexity of the problem and b) the reverance we have for some of the people working on this, with a dash of c) \"my academic background is completely irrelevant\" and d) \"it's too late for me to build the skills I need to contribute\" thrown in there.</li><li>I won't argue against a) and b) - the problem IS hard and the people working on it ARE often very impressive with regards to their intellectual chops.</li><li>But c) and d) are a completely different story, and I want to push back hard against them. People routinely underestimate how many different skills a given field can benefit from. AI Safety needs cognitive scientists, STEM people, <a href=\"https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards\">historians</a>, <a href=\"https://pauseai.info/action\">activists</a>, political scientists, <a href=\"https://www.youtube.com/RationalAnimations\">artists</a>, journalists, <a href=\"https://www.safe.ai/careers\">content editors</a>, <a href=\"https://far.ai/post/2023-03-office-manager/\">Office Managers</a>, educators, <a href=\"https://arkose.org/operations-lead\">finance specialists, PAs</a>- if you truly think your background is irrelevant, send me a DM and I'm happy to take bets on whether I can find a position that would benefit from your skillset. ;-)&nbsp;<br>(<i>Anecdotally, I used to be a teacher, and I'm now working on </i><a href=\"https://forum.effectivealtruism.org/posts/idrBxfsHkYeTtpm2q/seeking-paid-case-studies-on-standards\"><i>case studies for AI Standards</i></a><i>, field-building and </i><a href=\"https://erafellowship.org/\"><i>Research Management</i></a><i>. It turned out people really appreciate it when you can explain something in clear terms, organize processes well and help others to engage with important but thorny ideas.</i>)</li></ol><p><br><strong>On building skills</strong>: The field is so young and nascent that literally <a href=\"https://www.lesswrong.com/posts/uqTJ7mQqRpPejqbfN/nobody-s-on-the-ball-on-agi-alignment\">nobody is \"on the ball\"</a> and while this is deeply concerning from an x-risk perspective, it is good news for you - there is a limited number of key concepts and models to understand. For many people, it's is not too late to learn about these things and to build skills, and there are many <a href=\"https://aisafetyfundamentals.com/\">resources and programs</a> to support this.</p><p>Last but not least: Reach out to me if you'd like to discuss your options or just want to talk to a kind voice. I'd be happy to. :)</p>", "parentCommentId": null, "user": {"username": "Moritz von Knebel"}}, {"_id": "SNJGitJWKiTbijWra", "postedAt": "2023-08-06T02:11:44.396Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>I think it's great that you're asking for support rather than facing existential anxiety alone, and I'm sorry that you don't seem to have people in your life who will take your worries seriously and talk through them with you. And I'm sure everyone responding here means well and wants the best for you, but joining the Forum has filtered us\u2014whether for our worldviews, our interests, or our susceptibility to certain arguments. If we're here for reasons other than AI, then we probably don't mind talk of doom or are at least too conflict-averse to continually barge into others' AI discussions.</p><p>So I would caution you that asking this question here is at least a bit like walking into a Bible study and asking for help from people more righteous than you in clarifying your thinking about God because you're in doubt and perseverating on thoughts of Hell. You don't have to listen to any of us, and you wouldn't have to even if we really were all smarter than you.</p><p>You point out the XPT forecasts. I think that's a great place to start. It's hard to argue that a non-expert ought to defer more to AI-safety researchers than to either the superforecasters or the expert group. Having heard from XPT participants, I don't think the difference between them and people more pessimistic about AI risk has to do with facility with technical or philosophical details. This matches my experience reading deep into existential risk debates over the years\u2014they don't know anything I don't. They mostly find different lines of argument more or less persuasive.</p><p>I don't have first-hand advice to give on living with existential anxiety. I think the most important thing is to take care of yourself, even if you do end up settling on AI safety as your top priority. A good therapist might have helpful ideas regarding rumination and feelings of helplessness, which aren't required responses to any beliefs about existential risk.&nbsp;</p><p>I'm glad to respond to comments here, but please feel free to reach out privately as well. (That goes for anyone with similar thoughts who wants to talk to someone familiar with AI discussions but unpersuaded about risk.)</p>", "parentCommentId": null, "user": {"username": "Muireall"}}, {"_id": "YwADFJCXTyHY8mzp9", "postedAt": "2023-08-06T08:20:53.535Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<blockquote><p>Nor can I speak to any of my friends or family about it, because they think the whole thing is ridiculous, and I\u2019ve put myself in something of a boy who cried wolf situation by getting myself worked up over a whole host of worst-case scenarios over the years.</p></blockquote><p>This seems important to me, having people to talk to.</p><p>How about sharing that you have uncertainty and aren't sure how to think about it, or something like that? Seems different from \"hey everyone, we're definitely going to die this time\" and also seems true to your current state (as I understand it from this post)</p>", "parentCommentId": null, "user": {"username": "hibukki"}}, {"_id": "58yJvYgMWkcLJEg2t", "postedAt": "2023-08-06T14:09:09.732Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>I think this is an extremely good post laying out why the public discussion on this topic might seem confusing:</p><p><a href=\"https://www.lesswrong.com/posts/BTcEzXYoDrWzkLLrQ/the-public-debate-about-ai-is-confusing-for-the-general\">https://www.lesswrong.com/posts/BTcEzXYoDrWzkLLrQ/the-public-debate-about-ai-is-confusing-for-the-general</a></p><p>It might be somewhat hard to follow, but this little prediction market is interesting (wouldn't take the numbers too seriously):</p><figure class=\"media\"><div data-oembed-url=\"https://manifold.markets/Jotto999/humanity-starts-interfacing-with-al\">\n\t\t\t\t<div class=\"manifold-preview\">\n\t\t\t\t\t<iframe src=\"https://manifold.markets/embed/Jotto999/humanity-starts-interfacing-with-al\">\n\t\t\t\t</iframe></div>\n\t\t\t</div></figure><p>In December of last year it seemed plausible to many people online that by now, August 2023, the world would be a very strange, near-apocalyptic place full of inscrutable alien intelligences. Obviously, this is totally wrong. So it could be worth comparing others' \"vibes\" here to your own thought process to see if you're overestimating the rate of progress.</p><p>Paying for GPT-4 if you have the budget may also be helpful to calibrate. It's magical, but you run into embarrassing failures pretty quickly, which most commentators tend to talk about rarely.</p>", "parentCommentId": null, "user": {"username": "anonymous6"}}, {"_id": "TzSCvhnGkmMe3Zc7j", "postedAt": "2023-08-06T14:43:14.735Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<blockquote><p>At this point, I have no idea what to believe. I don\u2019t know if this is the case of the doomiest voices being the loudest, while the world is actually populated with academics, programmers and researchers who form the silent, unconcerned majority - or whether we genuinely are all screwed.</p></blockquote><p>My sense is that this is broadly true, at least in the sense of 'unconcerned' meaning 'have a credence in AI doom of max 10% and often lower'. All the programmers and academics working on AI presumably don't think they're accelerating or enabling the apocalypse, otherwise they could stop - these are highly skilled software engineers who would have no trouble finding a new job.&nbsp;</p><p>Also, every coder in the world knows that programs often don't do what you think they're going to do, and that as much as possible you have to break them into components and check rigorously in lab conditions how they behave before putting them in the wild. Of course there are bugs that get through in every program, and of course there are ways that this whole picture could be wrong. Nonetheless, it gives me a much more optimistic sense of 'number of people (implicitly) working on AI safety' than many people in the EA movement seem to have.</p>", "parentCommentId": null, "user": {"username": "Arepo"}}, {"_id": "tjFC5wgp7p4jCC4z8", "postedAt": "2023-08-06T15:02:42.005Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>My answer might be useless, but I somewhat went through the same. Purely from my side, after a week it was gone, as I was just temporarily overwhelmed.&nbsp;</p><p>I also hold the opinion that Eliezer Yudkowsky might be doing important work (I am not educated enough to know what that valuable work is), but I think he should stop being anywhere near a spotlight. He might seem like one of the key people within EA, he certainly did seem to me when I discovered EA, but he is awful at PR. There are loads of skeptics around, and he is not the only one to represent the EA.</p><p>On the other hand maybe EY is a blessing in disguise because he creates so much fear, and actually helps the AI safety area. I don't think there is any harm done in exploring that area after all!</p><p>However, also bear in mind that even the \u201csenior\u201d EAs, are still people and their opinions might mean nothing. As an example Will MacAskill expressed this \"I think existential risk this century is much lower than I used to think \u2014 I used to put total risk this century at something like 20%; now I\u2019d put it at less than 1%\" <a href=\"https://forum.effectivealtruism.org/posts/oPGJrqohDqT8GZieA/ask-me-anything?commentId=HcRNG4yhB4RsDtYit\"><u>https://forum.effectivealtruism.org/posts/oPGJrqohDqT8GZieA/ask-me-anything?commentId=HcRNG4yhB4RsDtYit</u></a>. Well thanks a lot Will, because that fear of a 20% chance of death almost forced me into changing a career, which would have been useless now, and I don't think Will would do anything to help me fix such a mistake once I would switch.</p>", "parentCommentId": null, "user": {"username": "withTheWind813"}}, {"_id": "jpxDkSyzvcK9zoQeg", "postedAt": "2023-08-06T21:06:36.128Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>&gt;It's plausible humans will go extinct from AI. It's also plausible humans will go extinct from supervolcanoes.&nbsp;<br><br>Our primitive and nontechnological ancestors survived tens of millions of years of supervolcano eruptions (not to mention mass extinctions from asteroid/comet impacts) and our civilization's ability to withstand them is unprecedentedly high and rapidly increasing. That's not plausible, it's enormously remote, well under 1/10,000 this century.</p>", "parentCommentId": "o7BfN9nQJPLJwGhWm", "user": {"username": "CarlShulman"}}, {"_id": "3b2LSdx2ASJHH4gTo", "postedAt": "2023-08-07T05:17:59.072Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>I agree with what I think you intend to say, but in my mind plausible = any chance at all.</p>\n", "parentCommentId": "jpxDkSyzvcK9zoQeg", "user": {"username": "NickLaing"}}, {"_id": "oEHNx8LfNBEfPFzJA", "postedAt": "2023-08-07T09:12:55.559Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>This is what I meant, yeah.</p><p>There's also an issue of \"low probability\" meaning fundamentally different things in the case of AI doom vs supervolcanoes.</p><p>P(supervolacano doom) &gt; 0 is a frequentist statement. \"We know from past observations that supervolcano doom happens with some (low) frequency.\" This is a fact about the territory.</p><p>P(AI doom) &gt; 0 is a Bayesian statement. \"Given our current state of knowledge, it's possible we live in a world where AI doom happens.\" This is a fact about our map. Maybe some proportion of technological civilisations do in fact get exterminated by AI. But maybe we're just confused and there's no way this could ever actually happen.</p>", "parentCommentId": "3b2LSdx2ASJHH4gTo", "user": {"username": "Hamish Doodles"}}, {"_id": "3HwhcA6b947BJPRfu", "postedAt": "2023-08-07T09:14:54.084Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>\"would caution you that asking this question here is at least a bit like walking into a Bible study and asking for help from people more righteous than you in clarifying your thinking about God because you're in doubt and perseverating on thoughts of Hell. You don't have to listen to any of us, and you wouldn't have to even if we really were all smarter than you.\"</p>\n<p>This is #wisdom love it.</p>\n", "parentCommentId": "SNJGitJWKiTbijWra", "user": {"username": "NickLaing"}}, {"_id": "HHFnzcgJGpqGgDh89", "postedAt": "2023-08-07T14:18:04.573Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>I just wanted to thank everyone who commented for your thoughtful responses. They really helped me think through this issue a bit more. I really appreciate this community and will definitely be sticking around!</p>\n", "parentCommentId": null, "user": {"username": "bethhw"}}, {"_id": "Db7mB3zmyrTgJige2", "postedAt": "2023-08-07T15:49:41.523Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>What.</p><p>Supervolcano doom probabilities are more <i>resilient </i>because the chain of causation is shorter and we have a natural history track record to back up some of the key points in the chain. But the difference are a matter of degree, not kind. It is very much not the case that we've had a long-term track record of human civilizations that died to supervolcanoes to draw from; almost every claim about the probability of human extinction is ultimately a claim about (hopefully improving) models, not a sample of long-run means.</p>", "parentCommentId": "oEHNx8LfNBEfPFzJA", "user": {"username": "Linch"}}, {"_id": "GqrcDHkszGdrchniW", "postedAt": "2023-08-07T16:47:59.021Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>could be could be</p>", "parentCommentId": "Db7mB3zmyrTgJige2", "user": {"username": "Hamish Doodles"}}, {"_id": "qz6FhwWtFbmkCXgxZ", "postedAt": "2023-08-08T18:15:43.235Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>Unfortunately, I do not have time for a long answer, but I can understand very well how you feel. Stuff that I find helpful is practising mindfulness and/or stoicism and taking breaks from internet. You said that you find it difficult to make future plans. In my experience, it can calm you down to focus on your career / family / retirement even if it is possible that AI timelines are short. If it turns out that fear of AI is the same as fear of grey goo in the 90s, making future plans is better anyway.</p>\n<p>You may find this list of mental health suggestions helpful:</p>\n<p><a href=\"https://www.lesswrong.com/posts/pLLeGA7aGaJpgCkof/mental-health-and-the-alignment-problem-a-compilation-of\">https://www.lesswrong.com/posts/pLLeGA7aGaJpgCkof/mental-health-and-the-alignment-problem-a-compilation-of</a></p>\n<p>Be not afraid to seek help if you get serious mental health issues.</p>\n", "parentCommentId": null, "user": {"username": "Frank_R"}}, {"_id": "SRMhdJ4uFpyaesbp2", "postedAt": "2023-08-27T23:40:41.295Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>Hi, thanks for your piece. You write beautifully and content writing is actually needed in AI alignment. Maybe we can help you to find a meaningful career that you're happy with? It would be great to have a chat, if you're up for that. Kind regards, Rochelle (rochelle@ashgro.org)</p>", "parentCommentId": null, "user": {"username": "rharris"}}, {"_id": "MWFrJY5x8ZupLdfe4", "postedAt": "2023-08-30T15:55:19.053Z", "postId": "BpxKj5P9dRBB4ged6", "htmlBody": "<p>Hi Rochelle, thanks for this, I appreciate it! I\u2019ve dropped you an email :)</p>\n", "parentCommentId": "SRMhdJ4uFpyaesbp2", "user": {"username": "bethhw"}}]