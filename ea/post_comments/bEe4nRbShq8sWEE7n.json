[{"_id": "xT5jxt8uLRN5JpmaT", "postedAt": "2023-11-11T10:07:40.793Z", "postId": "bEe4nRbShq8sWEE7n", "htmlBody": "<p>I feel very confused as to how I should update based on these results, how the ranking was made and what the ranking means.</p>\n<p>A few concrete questions</p>\n<ul>\n<li>are credits tracking cost-effectiveness on the current margin or something else?</li>\n<li>is a project with 2 credits twice as [cost-effective] as a project with 1 credit?</li>\n</ul>\n<p>Is the qualitative summary a pretty good depiction of the main points that contributed to that project's scores?</p>\n<p>E.g.</p>\n<blockquote>\n<p>AI Safety Support\nAI Alignment Slack: Invaluable for information distribution. One evaluator mentioned the numerous times that they found out about opportunities through this Slack.</p>\n</blockquote>\n<blockquote>\n<p>Lots of Links page: \u201cThe best collection of resources we currently have,\u201d but with a big difference between the quality and the impact score: \u201cIt could be better organized and more up to date (even at a time when it was still maintained).\u201d</p>\n</blockquote>\n", "parentCommentId": null, "user": {"username": "calebp"}}, {"_id": "Ry7tknw9JJZdJMdTJ", "postedAt": "2023-11-11T11:04:13.859Z", "postId": "bEe4nRbShq8sWEE7n", "htmlBody": "<p>First it could make sense not to focus too much on the credits. The ranking has to bottom out somewhere, and that's where the credits come into it, to establish a track record for our donors. The ranking itself is better thought of as the level of endorsement of a project weighed by the track record of the endorsing donors.</p><p>We're still thinking about how we want to introduce funding goals and thus some approximation of short-term <i>marginal</i> utility. At the moment all projects discount donations at the same rate. Ideally we'd be able to use something like the S-Process to generate marginal utility curves that discount the score \u201cpayout\u201d that donors can get. I've experimented with funding goals around $100k per project, and 10x sharper discounts afterwards, but it hadn't made enough of a difference that would've legitimized the increased complexity and assumptions. Maybe we'll revive that feature as a configurable funding goal at some point. But there is also the fundamental problem that we don't have access to complete lists of donations, so less popular, less well-maintained projects would seemingly have higher marginal utility just because their donation records are more incomplete. That would be an annoying incentive to introduce. Those problems paired with the minor, unconvincing results of my experiments have caused me not to prioritize this yet.</p><p>But when it comes to the credits, the <a href=\"https://docs.google.com/document/d/1tCD66uTEyXXtb-OjKp3VkKjlysh6vCxtIF2tUPVSaUc/edit\">instructions to the evaluators</a> are probably a good guide:&nbsp;</p><ol><li>\u201cImagine that you\u2019re given a budget of 1,000 impact credits to allocate across projects (not artifacts). (a) Please allocate them to the projects in proportion to how impactful you think they were. (b) There\u2019s no transaction cost and no change in marginal utility (the first credit is worth the same as the last to a project). (c) We\u2019ll \u2026 average your scores, multiply the averages with the number of evaluators, normalize, and then allocate that product to minimize the impact of recusals.\u201d</li><li>And further down: \u201cNote that this is a purely retroactive evaluation. (a) You can&nbsp;<strong>ignore the tractability</strong> of producing an output since they\u2019ve all been produced. (b) Likewise please&nbsp;<strong>ignore the cost</strong> at which the output was produced. (c) Do&nbsp;<strong>consider neglectedness</strong>, though, and consider how likely some equivalent output would\u2019ve been produced anyway had it not been for the given project. (d) Consider the&nbsp;<i><strong>ex ante</strong></i><strong> expected utility</strong>. A bullshit project mustn\u2019t get a high score because it somehow got unpredictably lucky. (<a href=\"https://forum.effectivealtruism.org/posts/7kqL4G5badqjskYQs/toward-impact-markets-1#Impact_and_Profit_Distribution_Mismatch\"><u>Fictional</u></a>&nbsp;<a href=\"https://docs.google.com/document/d/1fQIbl6vi8rs68uj96Zg0zdcwMmx4IdPdrA_ClfmxydI/edit\"><u>examples</u></a>.)\u201d</li></ol><p>So like everything in our evaluation, the credits are retroactive too, so they are not about the current margin. One reason to ignore costs is that we don't have the data, though we might request or estimate it next time around. But the other reason is that the donors to overly expensive projects have already gotten \u201cpunish\u201d for their nonoptimal investment through the opportunity cost that they've paid. Intuitively it seems to me like it would be double-counting to also reduce the credits that they receive.</p>", "parentCommentId": "xT5jxt8uLRN5JpmaT", "user": {"username": "Telofy"}}, {"_id": "ENH3zpmbAFkkzqSrk", "postedAt": "2023-11-11T18:59:41.064Z", "postId": "bEe4nRbShq8sWEE7n", "htmlBody": "<p>So is it reasonable to interpret your process as saying FAR was similarly impactful to AI safety events over the last year?</p>\n", "parentCommentId": "Ry7tknw9JJZdJMdTJ", "user": {"username": "calebp"}}, {"_id": "5J5rxPFLgPks2u9DB", "postedAt": "2023-11-11T20:24:06.070Z", "postId": "bEe4nRbShq8sWEE7n", "htmlBody": "<p>AI Safety Events is one of the projects where we expanded the time window because they were on a hiatus in earlier 2023. The events that got evaluated were from 2022. Otherwise yes. (But just to be clear, this is about the retroactive evaluation results mentioned at the bottom of the post.)</p>", "parentCommentId": "ENH3zpmbAFkkzqSrk", "user": {"username": "Telofy"}}]