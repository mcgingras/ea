[{"_id": "GXgKdozfdyxSoTrcG", "postedAt": "2022-09-07T14:22:32.719Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>re hiring thread: I at least am still subscribed to the  \"Who's hiring\" thread and I read every comment.</p>\n<p>re agreement karma: I still really don't like it and find it very confusing ):</p>\n<p>I can't imagine a case where I strongly disagree with something, but want to increase its visibility to others, nor a case where I want to decrease visibility (e.g. because something is demagogic) but still want to signal that I agree with the conclusion.</p>\n", "parentCommentId": null, "user": {"username": "Guy Raveh"}}, {"_id": "JBr4kHKi97h8zx8G5", "postedAt": "2022-09-07T14:46:12.253Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>I think your comment is a good example (and from the votes it looks like I'm not the only one). You're making a good faith, sensible argument for a position I don't hold - I think the disagreement karma is a big improvement.&nbsp;<br><br>I think your comment deserves an upvote for contributing to the discussion, but I disagree and wanted to indicate that.</p>", "parentCommentId": "GXgKdozfdyxSoTrcG", "user": {"username": "alexrjl"}}, {"_id": "4rprctcpdHvFz8eDD", "postedAt": "2022-09-07T14:53:18.664Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>I love these changes, especially dis/agree voting! Thank you!</p>\n", "parentCommentId": null, "user": {"username": "starmz12345@gmail.com"}}, {"_id": "6dDwqtCwKBp3rm3Aa", "postedAt": "2022-09-07T15:21:17.829Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>Easy answer, any uncomfortable/repungant conclusion would fall under: upvote on karma but downvote on disagree/agree.</p>\n<p>One example is this uncomfortable conclusion:</p>\n<p><a href=\"https://forum.effectivealtruism.org/posts/t3Spus6mhWPchgjdM/valuing-lives-instrumentally-leads-to-uncomfortable\">https://forum.effectivealtruism.org/posts/t3Spus6mhWPchgjdM/valuing-lives-instrumentally-leads-to-uncomfortable</a></p>\n<p>One of the most important skills in life is to separate uncomfortable/repugnant conclusions from their truth values. In other words, just because a conclusion is uncomfortable/repungant does not equal that the conclusion is false, and vice versa, comfortable conclusions do not equal true conclusions.</p>\n", "parentCommentId": "GXgKdozfdyxSoTrcG", "user": {"username": "Sharmake"}}, {"_id": "L4dbwmdKRuJsmhPdB", "postedAt": "2022-09-07T20:13:41.068Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>A repugnant conclusion is only as true as the assumptions that went into it and the inference rules that chain it to them. I would agree with (and upvote) a comment that says \"your assumptions ABC imply conclusion X which is horrible, so they can't be right as stated\", and would disagree with (and downvote) a comment that says \"Not only are you right about ABC, but we should even act according to conclusion X that they imply, even if it would seem horrible to some\".</p>\n<p>Edit: I forgot to add that, while it's a minor point in your comment, I really disagree that that's \"one of the most important skills in life\". Some applications might be important, e.g. \"believing your plan is going to fail early enough to pivot to something else\", but there are quite a few more important ones.</p>\n", "parentCommentId": "6dDwqtCwKBp3rm3Aa", "user": {"username": "Guy Raveh"}}, {"_id": "kvnGYGPjM7WoQdx3W", "postedAt": "2022-09-07T20:22:13.233Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>I'm really enjoying the irony. But still in the vast majority of cases my regular and agreement votes would go the same way. I downvote comments when I think they cause harm or promote bad ideas (which necessarily means I disagree with them), and strongly downvote them when they promote outright <em>dangerous</em> ideas.</p>\n", "parentCommentId": "JBr4kHKi97h8zx8G5", "user": {"username": "Guy Raveh"}}, {"_id": "wTjkbe9depAkh6EB9", "postedAt": "2022-09-07T21:29:03.870Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>Love the new voting axis.</p><p>Would it be possible to add a forum-wide search/sorting option for comments that score unusually high on the negative product of agreement and karma? It would help with finding posts that people really appreciate but still disagree with.</p><p>Usually, karma is strongly correlated with agreement on some level, even in this system. So if a comment has high disagreement and high karma, the karma has been deconfounded--it seems much more likely that people have updated on it or otherwise thought the arguments have gone underappreciated. And if a high proportion of people updated on it, then it's more likely that I will too.</p><p>Finding <a href=\"https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities?commentId=9ZhXbv8p2fr8mkXaa\">comments like this</a> is a great way for me increase my exposure to good arguments I haven't encountered before.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvultf40f9b\"><sup><a href=\"#fnvultf40f9b\">[1]</a></sup></span>&nbsp;If this sorting option existed, it would be the primary benefit of the agreement axis for me.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvultf40f9b\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvultf40f9b\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In general, I think research communities should prioritise the flow of information that <i>updates</i> people's models of things (i.e. gears-level/<strong>model-building evidence</strong> as opposed to testimonial evidence). This is a departure from academic \"veritistic\" social epistemology, where the explicit aim is usually to increase average epistemic accuracy by making people update on testimony correctly. But most research in EA, I think, isn't bottlenecked by more accurate beliefs (selecting the best-fit beliefs out of prevailing options). Instead, I think EA is bottlenecked by new insights and models, and you increase the rate of those by having more people exposed to gears-level evidence.</p></div></li></ol>", "parentCommentId": null, "user": {"username": "Emrik"}}, {"_id": "EgnFE9Nuwki6isL7M", "postedAt": "2022-09-07T21:29:08.801Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>I am looking forward to someone creating a <a href=\"https://effectivealtruismdata.com/\">wacky dashboard</a> where we can learn who are the most-upvoted but also most-disagreed-with posters on the Forum. &nbsp;If we think EA is getting too insular / conformist, maybe next time instead of a Criticism &amp; Red-Teaming contest, we could give out an EA Forum Contrarianism Prize! &nbsp; :P</p>", "parentCommentId": "4rprctcpdHvFz8eDD", "user": {"username": "Jackson Wagner"}}, {"_id": "YebhZPgzzRr9btqdM", "postedAt": "2022-09-07T21:43:43.486Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>Can you give an example of a comment you really disagreed with, yet made you change your beliefs?</p>\n", "parentCommentId": "wTjkbe9depAkh6EB9", "user": {"username": "Guy Raveh"}}, {"_id": "eE5N8GFcivHqMAhWu", "postedAt": "2022-09-07T21:51:44.568Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>(<a href=\"https://slatestarcodex.com/2018/10/30/sort-by-controversial/\">related post</a>)</p>", "parentCommentId": "EgnFE9Nuwki6isL7M", "user": {"username": "Linch"}}, {"_id": "kycHxYhZngjzumQzm", "postedAt": "2022-09-07T21:55:24.525Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<blockquote><p>and strongly downvote them when they promote outright <i>dangerous</i> ideas.</p></blockquote><p>This seems like a pretty dishonest action to me fwiw, unless you're referring to technical information hazards (in which case reporting the comment is also appropriate).<br><br>Though perhaps I'm misunderstanding you.</p>", "parentCommentId": "kvnGYGPjM7WoQdx3W", "user": {"username": "Linch"}}, {"_id": "xRF7M4szziSmsv5iX", "postedAt": "2022-09-07T21:58:33.851Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>There are many that I can't recall, but these two comments made by <a href=\"https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities?commentId=9ZhXbv8p2fr8mkXaa\">Matthew Barnett</a> and <a href=\"https://www.lesswrong.com/posts/d4YGxMpzmvxknHfbe/conversation-with-eliezer-what-do-you-want-the-system-to-do?commentId=zXiu7ExWSKvfcrkge\">Paul Christiano</a> are two examples. I mildly disagree the former, and I strongly disagree with the latter, but still found both of them very helpfwl.</p>", "parentCommentId": "YebhZPgzzRr9btqdM", "user": {"username": "Emrik"}}, {"_id": "pwKf4v5gpCQkDXgMz", "postedAt": "2022-09-07T22:07:22.540Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>Why dishonest? What do you take a strong downvote to mean? I think I'm <em>really</em> misunderstanding most people here's notion about the role of upvoted and downvotes.</p>\n<p>As examples for both my stated actions, if a user wrote \"you're suggesting something that Trump wanted to do, so I think it's bad\" I'd downvote that comment; If a user wrote \"The public doesn't know what's good for them, we should eventually find a way to do good without ever having to answer to politicians\", I'd think that's the kind of arrogance that's outright dangerous and should be contained, and I'd therefore strongly downvote it.</p>\n<blockquote>\n<p>unless you're referring to technical information hazards</p>\n</blockquote>\n<p>It's a separate discussion that I'm planning to write a post about (but probably never will \ud83d\ude05) - but I think EAs widely overestimate the size of the space of infohazards, and almost no comment a sane person could make would ever be one. I further think this is dangerous in itself, as it builds on a wrong belief that we're better equipped to tackle problems than bad actors are to rediscover them.</p>\n<p>So if someone wrote a detailed recipe for a novel pathogen, yeah I'd report them. Anything less than that, not really.</p>\n", "parentCommentId": "kycHxYhZngjzumQzm", "user": {"username": "Guy Raveh"}}, {"_id": "FQEcawsDB5kdLhNXY", "postedAt": "2022-09-08T02:02:57.414Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>(I think it's likely that I misunderstood at least some of the other arguments in this thread).&nbsp;</p><p>I think good arguments with uncomfortable/repugnant conclusions should be a) upvoted to the extent that they are good arguments and b) agreed or disagreed with to the extent that we believe the conclusions are true.</p><p>&nbsp;(and we may believe the bottom-line conclusions to be false for reasons that are outside the scope of the presented arguments).&nbsp;<br><br>I think we should be very willing to accept uncomfortable/repugnant conclusions to the extent that we believe they're true. Our movement is effective <i>altruism</i>, not effective <i>feel-good-about-ourselves</i>ism. Since we probably live in the midst of <a href=\"https://forum.effectivealtruism.org/posts/Dtr8aHqCQSDhyueFZ/the-possibility-of-an-ongoing-moral-catastrophe-summary\">multiple unknown moral catastrophes</a>, one of the most important things we can do (other than averting imminent existential risk) is to carefully figure out which are the avertable moral catastrophes we currently live in. This search probably means evaluating the evidence we have, and seek out new evidence, and look at the world with deliberation, care, and good humor. In comparison, I expect moral disgust to be substantially less truth-tracking in comparison, and on the margins even net negative.</p><p>Losing access to our ability to think clearly is just really costly<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgv0djf4xgll\"><sup><a href=\"#fngv0djf4xgll\">[1]</a></sup></span>. I'm not saying that we shouldn't give this up at any price. But we should at least set the price to be very very high, and not be willing to sacrifice clear thinking quite so easily.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngv0djf4xgll\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgv0djf4xgll\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;(\"At first they came for our epistemology. And then they...well, we don't know what happened next\")</p></div></li></ol>", "parentCommentId": "6dDwqtCwKBp3rm3Aa", "user": {"username": "Linch"}}, {"_id": "Ti8dtrb6MHgQkJs6W", "postedAt": "2022-09-08T02:49:58.606Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>I don't understand your logic at all. How is it contributing from your POV?</p>", "parentCommentId": "JBr4kHKi97h8zx8G5", "user": {"username": "Patricio"}}, {"_id": "veJenkKyx73xr8dre", "postedAt": "2022-09-08T09:03:49.085Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<blockquote><p>in the vast majority of cases my regular and agreement votes would go the same way</p></blockquote><p>I think that's fine, and you can just do this :) If a feature isn't useful to you, you don't have to use it.</p>", "parentCommentId": "kvnGYGPjM7WoQdx3W", "user": {"username": "OllieBase"}}, {"_id": "PesGMY42s6YzJhyQi", "postedAt": "2022-09-08T22:57:02.701Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>Excellent. Agree/disagree voting is not only great, it's one of the easiest ways to explain how EA and LW try to improve on the epistemics of internet discourse to outsiders who are otherwise relatively uninterested in what we do. I have seen people's eyes light up when they hear about it.</p>", "parentCommentId": null, "user": {"username": "AllAmericanBreakfast"}}, {"_id": "xvFmLcexiQeYyBHwp", "postedAt": "2022-09-09T07:28:21.099Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<blockquote><p>Copy-pasting footnotes from a Google Document</p></blockquote><p>Great to hear this feature now exists! (At least if it's fairly easy to use - I haven't tried it yet.)</p><p>Fwiw, this seems like a big enough deal to me and various EA researchers I know that I think it'd be worth having a separate post or other announcement about that, to increase how many people learn about it. I think many experienced Forum users won't read this whole post nor re-read the Forum user manual, so they may by default for a while continue using less convenient approaches to footnotes or sometimes not bothering to post footnote-heavy things to the Forum.</p><p>(But I'll also go ahead and announce that part of this post to Rethink Priorities staff now, to at least make that group aware of this.)</p>", "parentCommentId": null, "user": {"username": "MichaelA"}}, {"_id": "GutF8RDo8DoajWEYZ", "postedAt": "2022-09-10T22:17:31.280Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>I'm not sure how much of a pain this would be implementation-wise (or stylistically), but I'd be curious to see agree/disagree voting for posts (rather than just comments). After all, arguments for having this type of voting for comments seem to roughly generalize to posts, e.g. it seems useful for readers to be able to quickly distinguish between (i) critical posts that the community tends to appreciate and agree with, and (ii) critical posts that the community tends to appreciate but disagree with.</p>\n", "parentCommentId": null, "user": {"username": "Mauricio"}}, {"_id": "mrf7Cn5KPYjXkyPdF", "postedAt": "2022-09-12T04:45:40.633Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>Found <a href=\"https://forum.effectivealtruism.org/posts/Y3sWcbcF7np35nzgu/without-specific-countermeasures-the-easiest-path-to-1?commentId=KYfiKcMrdiH5GzjgS#_Naive_safety_effort__assumption__Alex_is_trained_to_be__behaviorally_safe_\">this</a>, a good example</p>", "parentCommentId": "GXgKdozfdyxSoTrcG", "user": {"username": "edoarad"}}, {"_id": "bFCA5PCcHyGoSAPBq", "postedAt": "2022-09-15T00:44:01.593Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>Strong agree - there's plenty of posts that I think are rigorous, well-written, interesting etc., but disagree with their conclusion or general stance. It might also offer a more useful (and maybe less spicy)'sort by controversial' function, where you can see posts that are highly upvoted but torn on agreement.</p>\n", "parentCommentId": "GutF8RDo8DoajWEYZ", "user": {"username": "BenStewart"}}, {"_id": "77qx43vawauqotvcr", "postedAt": "2022-09-17T09:18:33.093Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>The curation discussion made me think of <a href=\"https://forum.effectivealtruism.org/posts/7mTTzXutkgkzJuM3e/thomas-kwa-s-shortform?commentId=ALEFMbGpaWrYKCvBq\">this</a> recent shortform post: \"EA forum content might be declining in quality. Here are some possible mechanisms: [...]\"</p>\n<p>It seems like there has been an <a href=\"https://forum.effectivealtruism.org/s/s5zDhfyRPvrpeuRf8/p/4WxHNBf5LeM9gQneT\">effort</a> to get people less intimidated about posting to the Forum.  I think this is probably good -- intimidation seems like a somewhat bad way to achieve quality control.  However, with less intimidation and higher post volumes, we're leaning harder on upvotes &amp; downvotes to direct attention and achieve quality control.  Since our system is kind of like reddit's [I believe reddit is the only major social media site that's primarily driven by upvotes+downvotes rather than followings and/or recommendations], the obvious problems to fear would be the ones you see when subreddits get larger:</p>\n<ul>\n<li>\n<p>People who disagree with the current consensus get dogpiled with downvotes and self-select out of the community</p>\n</li>\n<li>\n<p>Memes get more upvotes than in-depth content since they are more accessible and easier to consume</p>\n</li>\n</ul>\n<p>(My sense is that these are the 2 big mechanisms behind the common advice to seek out niche subreddits for high-quality discussion -- let me know if you're a redditor and you can think of other considerations.)</p>\n<p>Anyway, this leaves me feeling positive about two-factor voting, including on toplevel posts.  It seems like a good way to push back on the \"self-selection for agreement\" problem.</p>\n<p>It also leaves me feeling positive about curation as a way to push back on the \"popcorn content\" problem.  In fact, I might take curation even further.  Brainstorming follows...</p>\n<p>Imagine I am a forum user thinking about investing several weeks or months writing an in-depth report on some topic.  Ian David Moss <a href=\"https://forum.effectivealtruism.org/posts/6whiBq7czKJk4Bx29/a-forum-post-can-be-short?commentId=KyvjohBPDnw7jDjda\">wrote</a>:</p>\n<blockquote>\n<p>...it's pretty demotivating when a post that reflects five months and hundreds of hours of work is on the front page for less than a day. I feel like there's something wrong with the system when I can spend five minutes putting together a linkpost instead and earn a greater level of engagement.</p>\n</blockquote>\n<p>Curation as described in the OP helps a bit, because there's a chance someone will notice my post while it's on the frontpage and suggest it for curation.  But imagine I could submit an abstract/TLDR to a curator asking them to rate their interest in curating a post on my chosen topic.  After I finish writing my post, I could \"apply for curation\" and maybe have some back-and-forth with a curator to get my post good enough.  Essentially making curation on the forum work a bit like publication in an academic journal.  While I'm dreaming, maybe someone could be paid to fact-check/red team my post before it goes live (possibly reflected in a separate quality badge, or maybe this should actually be a prereq for curation).</p>\n<p>I think academic journals and online forums have distinct advantages.  Academic journals seem good at incentivizing people to iron out boring details.  But they lack the exciting social nature of an online forum which gets people learning and discussing things for fun in their spare time.  Maybe there's a way to combine the advantages of both, and have an exciting social experience that also gets boring details right.  (Of course, it would be good to avoid academic publishing problems too -- I don't know too much about that though.)</p>\n<p>Another question is the role of Facebook.  I don't use it, and I know it has obvious disadvantages, but even so it seems like there's an argument for making relevant Facebook groups the designated place for less rigorous posts.</p>\n", "parentCommentId": null, "user": {"username": "John_Maxwell_IV"}}, {"_id": "6v269nwBfwopKHB6v", "postedAt": "2022-10-09T13:34:16.039Z", "postId": "2JQQZevGENbChSA8k", "htmlBody": "<p>Thanks for the updates!</p><p>Regarding <a href=\"https://forum.effectivealtruism.org/posts/2JQQZevGENbChSA8k/agree-disagree-voting-and-other-new-features-september-2022#Copy_pasting_footnotes_from_a_Google_Document\">Copy-pasting footnotes from a Google Document</a>, I think it would be nice if after the copy-pasting:</p><ul><li>Nested bullet points were not converted to non-nested bullet points.</li><li>The text in the cells of the headers of tables were not converted to sections which appear on the left navigation panel.</li><li>The footnote links were not broken.</li></ul>", "parentCommentId": null, "user": {"username": "vascoamaralgrilo"}}]