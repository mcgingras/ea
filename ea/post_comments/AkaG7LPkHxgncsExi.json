[{"_id": "YpwHvMqd9zCo2jz9f", "postedAt": "2023-05-11T05:58:13.528Z", "postId": "AkaG7LPkHxgncsExi", "htmlBody": "<p>I would be very curious for Gregory's take on whether he thinks EAs are too epistemically immodest still!</p>\n", "parentCommentId": null, "user": {"username": "Cullen_OKeefe"}}, {"_id": "5sFsJZ54TGdjBc5fr", "postedAt": "2023-05-11T10:19:24.782Z", "postId": "AkaG7LPkHxgncsExi", "htmlBody": "<p>Interesting. I think there are two related concepts here, which I'll call individual modesty and communal modesty. Individual modesty, meaning that an individual would defer to the perceived experts (potentially within his community) and communal modesty, meaning that the community defers to the relevant external expert opinion. I think EAs tend to have fairly strong individual modesty, but occasionally our communal modesty lets us down.&nbsp;<br><br>With most issues that EAs are likely to have strong opinions on, here are a few of my observations:<br><br>1. <strong>Ethics:</strong> I'd guess that most individual EAs think they're right about the fundamentals- that consequentialism is just better than the alternatives. I'm not sure whether this is more communal or individual immodesty.<br>2. <strong>Economics/ Poverty:</strong> I think EAs tend to defer to smart external economists who understand poverty better than core EAs, but are less modest when it comes to what we should prioritise based on expert understanding.&nbsp;<br>3. <strong>Effective Giving:</strong> Individuals tend to defer to a communal consensus. We're the relevant experts here, I think.<br>4. <strong>General forecasting/ Future:</strong> Individuals tend to defer to a communal consensus. We think the relevant class is within our community, so we have low communal modesty.&nbsp;<br>5. <strong>Animals: </strong>We probably defer to our own intuitions more than we should. Or Brian Tomasik. If you're anything like me, you think: \"he's probably right, but I don't really want to think about it\".<br>6. <strong>Geopolitics:</strong> I think that we're particularly bad at communal modesty here - I hear lots of bad memes (especially about China) that seem to be fairly badly informed. But it's also difficult to work out the relevant expert reference class.&nbsp;<br>7. <strong>AI (doom): </strong>Individuals tend to defer to a communal consensus, but tend to lean towards core EA's 3-20% rather than core-LW/Eliezer's 99+%. People broadly within our community (EA/ rationalists) genuinely have thought about this issue more than anyone else, but I think there's a debate whether we should defer to our pet experts or more establishment AI people.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Dzoldzaya"}}, {"_id": "iEZG4jCh4iKxoRskZ", "postedAt": "2023-05-12T11:57:10.941Z", "postId": "AkaG7LPkHxgncsExi", "htmlBody": "<blockquote>\n<p>Since A\u2019s and B\u2019s guesses are identically accurate, it seems most sensible to take the average in order to be closest to the truth. And even if you were A or B, if you want to be closest to the truth, you should do the same.</p>\n</blockquote>\n<p>Why not add them together, and declare yourself 90% sure that it is an oak tree?</p>\n<p>Or rather, since simply adding them together may get you outside the [0, 1] range, why not convert it to log odds, subtract off the prior to obtain the evidence, and add the evidence together, add back in the prior, and then convert it back to probabilities?</p>\n", "parentCommentId": null, "user": {"username": "tailcalled"}}]