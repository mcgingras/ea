[{"_id": "wZr83vKXNJrDpSvs5", "postedAt": "2022-10-10T23:19:20.686Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>This post seems to be getting a lot of downvotes. But its arguments seem reasonably well thought out and its obvious that the author is reasonably knowledgeable about the relevant topics. So it's not clear where the downvotes are coming from. Why does this post merits this much negative attention?<br><br>I saw on the LessWrong crosspost someone commented that this post was downvoted so much because of the title. But c'mon guys.... we shouldn't downvote things based on the title. This is basic stuff. Besides, I find it hard to believe that a pro-AI post with this title would be so heavily downvoted. Like, if the post was titled \"The probability that AGI will be developed by 2043 is 1\" someone might critique the title in the comments, or something, but I find it hard to believe it would be given the same treatment as this post (i.e. I find it hard to believe that it would be downvoted to the depths of hell).</p><p>I encourage anyone who takes issue with this post to explain why before downvoting. Because this is one of the few well-thought out posts on this forum that is critical of mainstream AI timelines. For it to get this many downvotes for seemingly no reason is a bad look. Seriously. It makes it look like EA has an axe to grind with AI skeptics (which is increasingly the impression I've been getting...). &nbsp;It seems like every AI post is either unrealistically alarmist or about PR strategies to convince people to also be unrealistically alarmist (which is suspicious, because if the arguments for AI's alleged danger were good arguments, then you'd think that a marketing campaign would be unnecessary).</p>", "parentCommentId": null, "user": null}, {"_id": "Jy3Lcbvi6o9dQC7r6", "postedAt": "2022-10-11T01:56:45.127Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>This observation might have been made in one of the papers under discussion, but:</p><blockquote><p>Gary Marcus who argues that, in order to make further progress, AI needs to combine symbolic and DL solutions into <a href=\"https://nautil.us/deep-learning-is-hitting-a-wall-238440/\"><i>hybrid systems</i></a>. As a rebuttal to <a href=\"https://www.noemamag.com/what-ai-can-tell-us-about-intelligence/\">Marcus, Jacob Browning and Yann LeCun argue</a> that there is no need for such hybrids because symbolic representations can \"emerge\" from neural networks. They argue that \"the neural network approach has traditionally held that we don\u2019t need to hand-craft symbolic reasoning but can instead learn it: Training a machine on examples of symbols engaging in the right kinds of reasoning will allow it to be learned as a matter of abstract pattern completion.</p></blockquote><p>I would say that \"human intelligence\" has been substantially boosted by the invention of programmable computers and formal mathematical systems. Both of these inventions situate the rules for symbol manipulation mostly outside of the human brain. Thus it seems like you could say humans + computers are a \"hybrid system\", and that humans are much more responsible for the non-symbolic part of the system than for the symbolic parts.</p><p>Regarding the post: joint probabilities over sequences of characters are perfectly capable of encoding mappings from strings specifying grammars to classifiers that assess whether a certain sequence obeys the grammar or not. Are you saying that DL-based language models can't do this, even in principle? This seems wrong to me.</p>", "parentCommentId": null, "user": {"username": "David Johnston"}}, {"_id": "YBXsEKyXoXC7B8o5B", "postedAt": "2022-10-11T02:18:17.849Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>Thanks David. Indeed, I completely agree that humans use external symbolic systems to enhance their ability to think. Writing is a clear example. Shopping lists too.</p><p>And to answer your last question - indeed I am saying exactly that DL based language models CAN do this. i.e. they can classify grammatical strings. But by doing this they act as a tool that can perhaps simplify the task. The correct way to check the grammar of a Python string is to look up the BNF. But you can also take shortcuts especially with simple strings.</p>", "parentCommentId": "Jy3Lcbvi6o9dQC7r6", "user": {"username": "cveres"}}, {"_id": "5vXWmm8jKSoJhiNt8", "postedAt": "2022-10-11T02:24:57.516Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>Thank you. &nbsp;I was also very confused and disappointed, especially because the downvotes did not come with comments. In fact from my follow up post you will see that I have been begging for someone to tell me what's wrong with the argument. Yann LeCun and Christopher Manning on Twitter have not been able to.&nbsp;</p><p>So I am happy with substantive and convincing counter arguments, which I will of course try to answer. In the best tradition of the scientific method.</p>", "parentCommentId": "wZr83vKXNJrDpSvs5", "user": {"username": "cveres"}}, {"_id": "8vGwAHppaw9TrDztv", "postedAt": "2022-10-11T02:28:11.641Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>What I'm saying is that a joint probability can encode \"how to check a Python string against the relevant grammar\". Learning such a joint probability (a procedure which may not involve actually seeing any Python strings) seems difficult, but seeming difficulty isn't nearly enough to convince me that it's impossible.</p>", "parentCommentId": "YBXsEKyXoXC7B8o5B", "user": {"username": "David Johnston"}}, {"_id": "eBfZsJrRRQ9hRdMwq", "postedAt": "2022-10-11T03:49:02.990Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>Right .. but I see that as a problem if you claim that Python doesn't have a relevant grammar. Of course everyone knows it has a grammar so no one claims this. But people DO claim that natural language does not have a grammar. This is what I have a problem with. If they said natural language has a grammar and \"neural networks can check a natural language string against the relevant grammar\", I would have no problems. But then these people would not be in a position to claim that they have discovered something new about language, just like we are not in a position to claim that we have discovered anything about Python. &nbsp;</p>", "parentCommentId": "8vGwAHppaw9TrDztv", "user": {"username": "cveres"}}, {"_id": "FGuBLngeLBvt955Ed", "postedAt": "2022-10-13T00:15:57.165Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>Yeah, I've downvoted it because of the title. Assigning a probability of zero or one is bad news for epistemological worth.</p>\n", "parentCommentId": "wZr83vKXNJrDpSvs5", "user": {"username": "Sharmake"}}, {"_id": "n4Lm3kiSGxe3TEP54", "postedAt": "2022-10-13T01:59:59.295Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>To put it more bluntly, this is infinitely wrong, such that we can immediately conclude either clickbait happened, or he literally doesn't understand why overconfidence is so bad. And both are worthy of strong downvotes. I notably do not see the alignment community, or most anti-AGI risk arguments being this bad.</p>\n", "parentCommentId": "wZr83vKXNJrDpSvs5", "user": {"username": "Sharmake"}}, {"_id": "vAmvMoPB5YA7KShm6", "postedAt": "2022-10-13T02:15:20.061Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>Sorry I was trying for a dramatic title. I miscalculated with the audience. My arguments are, however, sincere. I will change my title&nbsp;</p>", "parentCommentId": "n4Lm3kiSGxe3TEP54", "user": {"username": "cveres"}}, {"_id": "kg94ninPZaGy2YFFE", "postedAt": "2022-10-13T02:16:57.917Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>I learnt my lesson. No flamboyant titles.</p>", "parentCommentId": "FGuBLngeLBvt955Ed", "user": {"username": "cveres"}}, {"_id": "ho8AKj8tGjZzywx5L", "postedAt": "2022-10-13T12:48:54.613Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>Thank you, I've removed the downvotes despite still disagreeing. This is much, much less clickbaity.</p>\n", "parentCommentId": "vAmvMoPB5YA7KShm6", "user": {"username": "Sharmake"}}, {"_id": "ThsBDmGsnMMyanHGp", "postedAt": "2022-10-13T21:48:44.764Z", "postId": "FdAfhdsSGKxP6axZY", "htmlBody": "<p>Thank you for pointing out my miscalculation.</p>", "parentCommentId": "ho8AKj8tGjZzywx5L", "user": {"username": "cveres"}}]