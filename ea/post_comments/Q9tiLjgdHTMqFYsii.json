[{"_id": "ZFRXaK2i7DhaKN8wk", "postedAt": "2023-02-28T19:38:04.714Z", "postId": "Q9tiLjgdHTMqFYsii", "htmlBody": "<p>Thanks for writing this.&nbsp;</p><p>The top image is a nice example of good science commication we could do more of.&nbsp;</p><p>It is:</p><ul><li>Simple (it's a big squiggly monster with a smily face mask)</li><li>Conveys an important idea (LLMs might seem friendly, but we don't understand how they work and if you dig a bit they are utterly alien to us, providing strange and scary answers</li><li>High fidelity (this image has already been remixed 1000s of times &nbsp;and it still always conveys it's central idea)</li><li>Emotionally resonant (\"on this is concerning, what should we do about it\")</li></ul><p>(And it was it was initially created by EA twitter's very own Tetraspace)<br><img src=\"https://res.cloudinary.com/cea/image/upload/v1677613085/mirroredImages/ZFRXaK2i7DhaKN8wk/akvnvw6z5a5zjiiyy9sf.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1677613086/mirroredImages/ZFRXaK2i7DhaKN8wk/oetmyuwnohylas6ktczj.png 120w, https://res.cloudinary.com/cea/image/upload/v1677613086/mirroredImages/ZFRXaK2i7DhaKN8wk/cp5wry760p9kjxif6anj.png 240w, https://res.cloudinary.com/cea/image/upload/v1677613086/mirroredImages/ZFRXaK2i7DhaKN8wk/uwxusmivvarle9vcvvxz.png 360w, https://res.cloudinary.com/cea/image/upload/v1677613086/mirroredImages/ZFRXaK2i7DhaKN8wk/kkhfj9ys7phod5aujgcw.png 480w, https://res.cloudinary.com/cea/image/upload/v1677613085/mirroredImages/ZFRXaK2i7DhaKN8wk/dfxe21lzb2lijotvjtsu.png 600w, https://res.cloudinary.com/cea/image/upload/v1677613085/mirroredImages/ZFRXaK2i7DhaKN8wk/gfixhohmddx3wto6ciop.png 720w, https://res.cloudinary.com/cea/image/upload/v1677613086/mirroredImages/ZFRXaK2i7DhaKN8wk/xongz92ar3mycmwcpwo5.png 840w, https://res.cloudinary.com/cea/image/upload/v1677613086/mirroredImages/ZFRXaK2i7DhaKN8wk/xtwvbacnqauarvxfnwbn.png 960w, https://res.cloudinary.com/cea/image/upload/v1677613086/mirroredImages/ZFRXaK2i7DhaKN8wk/kvzpvb2uvn1vc5c5wawp.png 1080w, https://res.cloudinary.com/cea/image/upload/v1677613085/mirroredImages/ZFRXaK2i7DhaKN8wk/v5ryx7ct11ahaxxdltxo.png 1188w\"></p><p><a href=\"https://twitter.com/TetraspaceWest/status/1608966939929636864?s=20\">https://twitter.com/TetraspaceWest/status/1608966939929636864?s=20</a>&nbsp;</p><p>Holden and Yudkowsky are both very good at making complicated ideas into simple sharable ones - paperclips, King Lear problem.&nbsp;</p><p>If you find you have a talent for explaining things (or doodling) you might do well to make memes like this. Who knows where they will end up. (I am assuming that explaining things well is net good but I guess it has very large variance)</p><figure class=\"image image_resized\" style=\"width:45.95%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1677624916/mirroredImages/ZFRXaK2i7DhaKN8wk/abe5lxswpuemqpe1bgdd.jpg\" alt=\"Image\"></figure>", "parentCommentId": null, "user": {"username": "nathan"}}, {"_id": "zXdPWkm4uzk4LRcyK", "postedAt": "2023-02-28T20:15:10.885Z", "postId": "Q9tiLjgdHTMqFYsii", "htmlBody": "<p>Hard agree, the shoggoth memes are great.</p>", "parentCommentId": "ZFRXaK2i7DhaKN8wk", "user": {"username": "Writer"}}, {"_id": "ufXaaqAKQF6inQMs6", "postedAt": "2023-03-01T09:04:11.202Z", "postId": "Q9tiLjgdHTMqFYsii", "htmlBody": "<p>I agree with everything, and still want to point out that not so long later, Musk decided to try removing the \"woke\" part, so maybe he shared this meme for different reasons than you or me would share it</p><p>&nbsp;</p><h1><a href=\"https://www.theinformation.com/articles/fighting-woke-ai-musk-recruits-team-to-develop-openai-rival\">Fighting \u2018Woke AI,\u2019 Musk Recruits Team to Develop OpenAI Rival</a></h1>", "parentCommentId": "ZFRXaK2i7DhaKN8wk", "user": {"username": "hibukki"}}, {"_id": "93sgY5DG2YjPmRyN6", "postedAt": "2023-03-01T10:48:30.304Z", "postId": "Q9tiLjgdHTMqFYsii", "htmlBody": "<p>This article is evidence that Elon Musk will focus on the \"wokeness\" of ChatGPT, rather than do something useful about AI alignment. But still, we should keep in mind that news are very often incomplete or simply just plain false.&nbsp;<br><br>Also, I can't access the article.&nbsp;<br><br>Related: I've recently created a prediction market about whether Elon Musk is going to do something positive for AI risk (or at least not do something counterproductive) according to Eliezer Yudkowsky's judgment: <a href=\"https://manifold.markets/Writer/if-elon-musk-does-something-as-a-re?r=V3JpdGVy\">https://manifold.markets/Writer/if-elon-musk-does-something-as-a-re?r=V3JpdGVy</a></p>", "parentCommentId": "ufXaaqAKQF6inQMs6", "user": {"username": "Writer"}}, {"_id": "gXtMPeNDE4om5r7XZ", "postedAt": "2023-03-01T14:27:52.380Z", "postId": "Q9tiLjgdHTMqFYsii", "htmlBody": "<p>+1 for creating that market! &nbsp;:)</p>", "parentCommentId": "93sgY5DG2YjPmRyN6", "user": {"username": "hibukki"}}, {"_id": "F9XCYAzjqsqao5kCA", "postedAt": "2023-03-02T06:13:00.281Z", "postId": "Q9tiLjgdHTMqFYsii", "htmlBody": "<p>I strongly agree that current LLM's don't seem to pose a risk of a global catastrophe, but I'm worried about what might happen when LLM's are combined with things like digital virtual assistants who have outputs other than generating text. Even if it can only make bookings, send emails, etc., I feel like things could get concerning very fast.</p><p>Is there an argument for having AI fail spectacularly in a small way which raises enough global concern to slow progress/increase safety work? I'm envisioning something like a LLM virtual assistant which leads to a lot of lost productivity and some security breaches but nothing too catastrophic, which makes people take AI safety seriously, slowing progress on more advanced AI, perhaps.</p><p>A complete spitball.</p>", "parentCommentId": null, "user": {"username": "MichaelDello"}}, {"_id": "ZsnFiZ42kcFiiD9eN", "postedAt": "2023-03-02T10:51:32.244Z", "postId": "Q9tiLjgdHTMqFYsii", "htmlBody": "<blockquote><p>Is there an argument for having AI fail spectacularly in a small way which raises enough global concern to slow progress/increase safety work?</p></blockquote><p>Given that AI is being developed by companies running on a \"move fast and break things\" philosophy, a spectacular failure of some sort is all but guaranteed.&nbsp;</p><p>It'd have to bigger than mere lost productivity to slow things down though. Social media algorithms arguably already have a body count (via radicalisation), and those have not been slowed down.&nbsp;</p>", "parentCommentId": "F9XCYAzjqsqao5kCA", "user": {"username": "titotal"}}, {"_id": "cg5K8tW3JXdZDG3hm", "postedAt": "2023-03-03T02:24:14.278Z", "postId": "Q9tiLjgdHTMqFYsii", "htmlBody": "<p>Very fair response, thanks!</p>", "parentCommentId": "ZsnFiZ42kcFiiD9eN", "user": {"username": "MichaelDello"}}]