[{"_id": "jLdT7qKeouZNPzEAu", "postedAt": "2022-09-09T16:08:42.659Z", "postId": "DKe5eQhJoLNMWgaQv", "htmlBody": "<p>As someone who leans deontological these days (and contractualist in particular), I really appreciated this post!&nbsp;<br><br>Honestly quite baffled by the original argument, and it definitely makes me less inclined towards longtermist philosophy and the thinking associated with it. &nbsp;To me it's clear that identity-causing acts do not cause harm in a way that one is responsible for it, in the same way that unintentionally delaying a robbery does not cause harm in a way that one is responsible for it, so the paralysis argument feels extremely weird to me.<br><br>I think there are good arguments for doing a lot more than we currently do to prevent the foreseeable suffering of future people, but this is not one of those arguments, much less an argument for something like strong longtermism.</p>", "parentCommentId": null, "user": {"username": "xuan"}}, {"_id": "MKoSz4qqBcyRukKgK", "postedAt": "2022-10-05T16:25:04.424Z", "postId": "DKe5eQhJoLNMWgaQv", "htmlBody": "<p>Thanks for writing this!</p>\n<p>Another possible response is that ahead of time, each possible contingent individual may have an extraordinarily weak claim against you for possible harms to them, because they almost certainly won't exist. But I'd guess this isn't enough to capture the ex ante badness of bringing into existence an unknown individual who will probably have a bad life (e.g. factory farmed animals), so one of your other options or something else seems necessary anyway. Also, it may lead to some pretty odd dynamic inconsistency or other seemingly irrational behaviour like trying to avoid finding out who will be harmed in cases of many individuals at small individual risk of harm but large collective risk of at least one individual being harmed.</p>\n", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "uARwpdDb4Ckan7tqs", "postedAt": "2022-10-05T16:43:28.245Z", "postId": "DKe5eQhJoLNMWgaQv", "htmlBody": "<p>Do you think working to reduce s-risks instead of extinction risks is compatible with the arguments they make? That would still count as longtermist.</p>\n", "parentCommentId": null, "user": {"username": "MichaelStJules"}}, {"_id": "5Ehc6nouhgsR6br2b", "postedAt": "2022-12-14T15:44:37.142Z", "postId": "DKe5eQhJoLNMWgaQv", "htmlBody": "<p>Another neglected way out is to precisify our notion of <strong>causality</strong> used in DDA (and in ordinary language) so as to include conceptions of <i>explanation</i> and <i>credit attribution</i>, thus exempting liability for random effects. MacAskill and Mogensen come close to contemplating this point in section 3.3, but then they focus on the <i>Arms Trader&nbsp;</i>example, which is close to a strawman here, and conclude:</p><blockquote><p>We grant that it sometimes sounds wrong to say that you do harm to another when you initiate a causal sequence that ends with that person being harmed through the voluntary behavior of some other agent. But so far as we can see, this is entirely explained in terms of pragmatic factors like those discussed earlier: that is, in terms of conversational implicatures that typically attach to locutions associated with the \u2018doing\u2019 side of the doing/allowing distinction.</p></blockquote><p>The problem with the voluntary behavior of others is not that it would necessarily exempt you of responsibility, but that it would often make your action causally irrelevant. We can say \u201cAgent X\u2019s action<i> a</i> caused event <i>e</i>\u201d is ambiguous between:&nbsp;</p><ol><li>X\u2019s action belongs to the causal chain that led to <i>e</i>, and</li><li>in addition to (i), <i>a&nbsp;</i>increased the probability of <i>e </i>happening.</li></ol><p>(i) is not a very useful notion of causality \u2013 basically every state of the world causes the next states (in the corresponding lightcone), because every event has repercussions.</p><p>Thus when we say that carbon emissions (caused climate change) caused floods in Lisbon in the last few days, we are not stating the obvious fact that, because of the chaotic nature of long-term climate trends, any different world history would have implied distinct rain patterns. We are rather saying that carbon emissions (and global warming) made such extreme events more likely. Also, this is not straightforwardly connected to predictability, as something might be hard to predict, but easy to explain in hindsight.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; It\u2019s kind of intuitive that we normally use a more refined notion of causality in practical reason; so, though we might blame an arms trader, we don\u2019t even consider blaming all supply chains that made some murders possible. Thus, when we say that all of my actions will cause the identity of some future people, we are talking about (i). But the relevant notion of causality for DDA is (ii); in this sense, I may cause the identity of <strong>some </strong>future people by making some genetic pools more likely than their alternatives (for instance, by having kids, by working with fertilization, etc.). So, my mother's school teacher didn't cause my birth in anyway; my mother's marrying my father did it, though.</p>", "parentCommentId": null, "user": {"username": "Ramiro"}}]