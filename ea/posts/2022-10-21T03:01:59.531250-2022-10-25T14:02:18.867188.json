[{"_id": "ETktDQJQAR7Hgd4oS", "title": "Mechanism Design for AI Safety - Reading Group Curriculum", "postedAt": "2022-10-25T03:54:20.549Z", "htmlBody": "<p>The Mechanism Design for AI Safety (MDAIS) reading group, announced<a href=\"https://forum.effectivealtruism.org/posts/YmvBu7fuuYEr3hhnh/announcing-mechanism-design-for-ai-safety-reading-group\"> here</a>, is currently in it's eighth of twelve weeks. I'm very excited by the quality of discussions we've had so far, and for the potential of future work from members of this group. If you're interested in working at the intersection of mechanism design and AI safety, please send me a message so that I can keep you in mind for future opportunities.</p><p>Edit: we have completed this initial list and are now meeting on a monthly basis. You can sign up to attend the meetings <a href=\"https://docs.google.com/forms/d/1p-R-WIuTaLabx2RNEXdP2_KdISj_yCPh4H9vX-ZnA3c\">here</a>.</p><p>A number of people have reached out to ask me for the reading list we're using. &nbsp;Until now, I've had to tell them that it was still being developed, but at long last it has been finalized. This post is to communicate the list publicly for anyone curious about what we've been discussing, or who would like to follow along themselves. It goes week by week listing the papers covered, the topics of discussion, and any notes I have. After the first two weeks, the order of the papers covered is largely inconsequential.</p><h2>Reading List</h2><h3>Week 1</h3><p>Papers:&nbsp;</p><ol><li>The Principal-Agent Alignment Problem in Artificial Intelligence by Dylan Hadfield-Menell</li><li>Incomplete Contracting and AI Alignment by Dylan Hadfield-Menell and Gillian Hadfield</li></ol><p>Discussion: Introductions, formalization of the alignment problem, inverse reinforcement learning and cooperative inverse reinforcement learning</p><p>Notes: The Principal-Agent Alignment Problem in Artificial Intelligence is extremely long, essentially multiple papers concatenated, so discussing it in the first week gave people more prep time to read it. Incomplete Contracting and AI Alignment is much shorter and less formal but did not add much, in hindsight I would not had included it.</p><h3>Week 2</h3><p>Paper: Risks from Learned Optimization in Advanced Machine Learning Systems by Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant</p><p>Discussion: Inner vs. outer alignment, what applications mechanism design has for each \"step\" in alignment</p><h3>Week 3</h3><p>Paper: Decision Scoring Rules (Extended Version) by Caspar Oesterheld and Vincent Conitzer&nbsp;</p><p>Discussion: Oracle AI, making predictions safely</p><h3>Week 4</h3><p>Paper: Discovering Agents by Zachary Kenton, Ramana Kumar, Sebastian Farquhar, Jonathan Richens, Matt MacDermott, and Tom Everitt</p><p>Discussion: Defining agents, using causal influence diagrams in AI safety</p><h3>Week 5</h3><p>Papers:&nbsp;</p><ol><li>Model-Free Opponent Shaping by Chris Lu, Timon Willi, Christian Schroeder de Witt, and Jakob Foerster</li><li>The Good Shepherd: An Oracle Agent for Mechanism Design by Jan Balaguer, Raphael Koster, Christopher Summerfield, and Andrea Tacchetti</li></ol><p>Discussion: Mechanism design affecting learning, how deception might arise</p><p>Notes: Almost everything in The Good Shepherd was also covered in Model-Free Opponent Shaping, so in hindsight including it as well was redundant.</p><h3>Week 6</h3><p>Paper: Fully General Online Imitation Learning by Michael Cohen, Marcus Hutter, and Neel Nanda</p><p>Discussion: Advantages, disadvantages, and extensions for the mechanism proposed in the paper</p><h3>Week 7</h3><p>Papers:&nbsp;</p><ol><li>Corrigibility by Nate Soares, Benja Fallenstein, Eliezer Yudkowsky, and Stuart Armstrong</li><li>The Off Switch Game by Dylan Hadfield-Menell, Anca Dragan, Pieter Abbeel, and Stuart Russell</li></ol><p>Discussion: Formalizing issues with corrigibility, approaches to instill corrigibility</p><h3>Week 8</h3><p>Paper: Investment Incentives in Truthful Approximation Mechanisms by Mohammad Akbarpour, Scott Kominers, Kevin Li, Shengwu Li, and Paul Milgrom</p><p>Discussion: Implementing mechanisms with AI, issues with approximation</p><h3>Week 9</h3><p>Paper: Cooperation, Conflict, and Transformative Artificial Intelligence - A Research Agenda by Jesse Clifton</p><p>Discussion: Various topics from the agenda with a focus on S-risks and bargaining</p><h3>Week 10</h3><p>Paper: Getting Dynamic Implementation to Work (excluding sections 3 and 4) by Yi-Chun Chen, Richard Holden, Takashi Kunimoto, Yifei Sun, and Tom Wilkening</p><p>Discussion: Ensemble models, AI monitoring AI</p><p>Notes: Sections 3 and 4 of the paper were excluded as they focus on experimental results with humans, which are of minimal relevance.</p><h3>Week 11</h3><p>Papers:&nbsp;</p><ol><li>Learning to Communicate with Deep Multi-Agent Reinforcement Learning by Jakob N. Foerster, Yannis M. Assael, Nando de Freitas, and Shimon Whiteson</li><li>Emergent Cover Signaling in Adversarial Reference Games by Dhara Yu, Jesse Mu, and Noah Goodman&nbsp;</li></ol><p>Discussion: Detecting communication, intercepting communication</p><h3>Week 12</h3><p>Paper: Functional Decision Theory: A New Theory of Instrumental Rationality by Eliezer Yudkowsky and Nate Soares&nbsp;</p><p>Discussion: Functional decision theory, mechanism design for superrational agents and functional decision theorists</p><h2>Next Steps</h2><p>Once we have finished going through this reading list, I would like to move to a more infrequent and irregular schedule. Meetings would be to discuss new developments in the space, the research produced by reading groups members, or topics missed during the first twelve weeks. I expect this ongoing reading group would expand beyond the initial members and be open to anyone interested.&nbsp;</p><p>If there is sufficient interest, another iteration going through the above reading list can be run, although likely with several updates.</p><p>Finally, we plan to collaborate on an agenda laying out promising research directions in the intersection mechanism design and AI safety. Ideally, we will have interested members transition to a working group where we can collaborate on research to address the challenge of ensuring AI is a positive development for humanity.</p><p>Edit: We have completed the initial readings and are now meeting once a month for further readings. You can sign up to be notified <a href=\"https://docs.google.com/forms/d/1p-R-WIuTaLabx2RNEXdP2_KdISj_yCPh4H9vX-ZnA3c/edit\">here</a>.</p><h2>Ongoing Readings</h2><h3>Meeting 13</h3><p>Paper: &nbsp;Safe Pareto Improvements for Delegated Game Playing by Caspar Oesterheld and Vince Conitzer</p><h3>Meeting 14</h3><p>Papers:&nbsp;</p><ol><li>&nbsp;Quantilizers: A Safer Alternative to Maximizers for Limited Optimization by Jessica Taylor</li><li>&nbsp;Safety Considerations for Online Generative Modeling by Sam Marks</li></ol><h3>Meeting 16</h3><p>Paper: A Robust Bayesian Truth Serum for Small Populations by Jens Witkowski and David C. Parkes</p><h3>Meeting 17&nbsp;</h3><p>Paper: Misspecification in Inverse Reinforcement Learning by Joar Skalse and Alessandro Abate</p><h3>Meeting 18</h3><p>Paper: Hidden Incentives for Auto-Induced Distributional Shift by David Krueger, Tegan Maharaj, and Jan Leike</p><h3>Meeting 19</h3><p>Paper: &nbsp;Evolution of Preferences by Eddie Dekel, Jeffrey Ely, and Okan Yilankaya</p><h3>Meeting 20</h3><p>Paper: A Theory of Rule Development by Gleen Ellison and Richard Holden</p>", "user": {"username": "Rubi"}}, {"_id": "Sj9RMx3gn8oxi3ycX", "title": "Furry Rationalists & Effective Anthropomorphism both exist", "postedAt": "2022-10-25T08:54:27.371Z", "htmlBody": "", "user": {"username": "agentydragon"}}, {"_id": "Hi5z6tm9d2keHALgv", "title": "EA & LW Forums Weekly Summary (17 - 23 Oct 22')", "postedAt": "2022-10-25T02:57:43.202Z", "htmlBody": "<p><i>Supported by Rethink Priorities</i></p><p>This is part of a weekly series - you can see the full collection <a href=\"https://forum.effectivealtruism.org/s/W4fhpuN26naxGCBbN\">here.</a> The first post includes some details on purpose and methodology.</p><p>If you'd like to receive these summaries via email, you can subscribe <a href=\"https://easummaries.substack.com/?r=1p817z&amp;s=w&amp;utm_campaign=pub&amp;utm_medium=web\">here.</a></p><p><strong>Podcast version</strong>: prefer your summaries in podcast form? A big thanks to Coleman Snell for producing these! Subscribe on your favorite podcast app by searching for 'Effective Altruism Forum Podcast'.</p><h1><br><br>EA Forum</h1><h2>Philosophy and Methodologies</h2><p><a href=\"https://forum.effectivealtruism.org/posts/829tAQAYAntkRxCy2/effective-altruism-s-implicit-epistemology\"><u>Effective Altruism's Implicit Epistemology</u></a></p><p><i>by Violet Hour</i></p><p>Longtermist philosophy is pretty reasonable (future people matter, there might be a lot, and we can make a difference to them). However many outside EA find the priorities that have arisen from these (eg. AI safety &amp; bio risk) to be weird. The author argues this is due to EA\u2019s unusual epistemic culture, and uses this post to highlight these norms and how they influence our decision-making.</p><p>In particular, EAs tend to be comfortable with speculative reasoning, put numbers on things (even when they\u2019re highly unsure), use those numbers as inputs to decision-making, but are still skeptical if all that leads to anything too speculative and fanatical. The author suggests being explicit about these norms because that allows better outside criticism, or if we\u2019re really onto something, allows others to benefit from it.<br><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/7KJZWLMepdZ4mHvxS/the-relative-importance-of-the-severity-and-duration-of-pain\"><u>The Relative Importance of the Severity and Duration of Pain</u></a></p><p><i>by William McAuliffe, Adam_Shriver</i></p><p>Pains vary in their severity and duration. This report reviews the research and philosophy on how to trade off these two dimensions, which can impact cause prioritization decisions.<br><br>Some viewpoints explored include that badness scales non-linearly with severity of pain, or that long-duration pain can only outweigh a high severity pain if it meets the bar of preventing pleasure or making more moments bad than good. Utilitarian views simply multiplying (severity X duration) are also presented. It\u2019s also possible these trade-offs vary between individuals - one study found most participants make decisions as if adding severity and duration to get badness, but a minority multiply them.<br><br>Ethical constraints, severity being more salient in retrospect, imagination failures and other factors make research and experimentation in this area difficult. The authors are planning to gather scientists and philosophers at a workshop to develop new methodologies to push the area forward.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/i5kRzbyDmZtaYmcbG/sign-of-quality-of-life-in-givewell-s-analyses\"><u>Sign of quality of life in GiveWell\u2019s analyses</u></a></p><p><i>by brb243</i></p><p>The author conducted a small scale (N=30) survey in a Kenyan slum in 2021, which found most participants rated themselves closer to the \u2018worst possible situation\u2019 than \u2018best possible situation\u2019 and the median participant wanted to live 2 more years if their situation didn\u2019t change.&nbsp;</p><p>Taking this into account could influence Givewell recommendations. For instance, Givewell recommended a grant to support the deregistration of pesticides commonly used in suicide on the basis of lives saved. However, these lives are likely valued negatively, and the grant could have negative impacts on agricultural productivity and therefore quality of life for others.</p><p><br>&nbsp;</p><h2>Object Level Interventions / Reviews</h2><p><a href=\"https://forum.effectivealtruism.org/posts/Eq8nwNPNhfXvt2TWj/my-experience-experimenting-with-a-bunch-of-antidepressants\"><u>My experience experimenting with a bunch of antidepressants I'd never heard of</u></a></p><p><i>by Luisa_Rodriguez</i></p><p>The author systematically experimented with different antidepressants over a year period, after putting together a best guess ranked list with their psychiatrist. They share both this desk research and the results of their personal experiment. While the year was grueling, they found a drug with good effectiveness and limited side effects for them. Antidepressant effects vary significantly between individuals, so they suggest this process could be worthwhile for others too (particularly if they have lots of money and support to help with the effects during). They also found CBT and changing their job role to focus on particularly satisfying / exciting tasks were a big help.<br>&nbsp;</p><p>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/YZNswjspTd2MYAaDf/growing-the-us-tofu-market-a-roadmap-1\"><u>Growing the US tofu market - a roadmap</u></a></p><p><i>by George Stiffman</i></p><p>Chinese tofus are varied (eg. some are melty, cheese-tasting, crumb-like outsides), but little known outside China. Expanding access to these could save substantial amounts of animal lives.</p><p>Limited supply and awareness are bottlenecks, particularly as shipping is expensive if done in small quantities. Encouraging existing trading companies to import more, helping local producers scale up, or creating a new distribution company are all potential solutions. Developing novel uses for the tofus, or research into how ingredients have gained popularity previously would also be helpful.</p><p>You can support this project by co-founding various types of organizations, funding the author, connecting them with cofounders / chefs / researchers / etc., research, or advising. More details on each in the post.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/DTTADonxnDRoksp4E/ai-safety-ideas-a-collaborative-ai-safety-research-platform\"><u>AI Safety Ideas: A collaborative AI safety research platform</u></a></p><p><i>by Apart Research, Esben Kran</i></p><p>Author\u2019s tl;dr: We present the AI safety ideas and research platform&nbsp;<a href=\"https://aisi.ai/\"><u>AI Safety Ideas</u></a> in open alpha. Add and explore research ideas on the website here:&nbsp;<a href=\"https://aisafetyideas.com/\"><u>aisafetyideas.com</u></a>.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/Z7r83zrSXcis6ymKo/dissolving-ai-risk-parameter-uncertainty-in-ai-future\"><u>\u2018Dissolving\u2019 AI Risk \u2013 Parameter Uncertainty in AI Future Forecasting</u></a></p><p><i>by Froolow</i></p><p>Most models of AI risk have a number of discrete steps which all need to be true for bad outcomes to occur. These models calculate total risk by multiplying the central probability estimate of each step together. This is statistically incorrect for conditional and independent steps. Eg. If the central estimate of each of 4 steps were 60%, by simple multiplication that\u2019s 13%. However we actually have a probability distribution for each step - and if we end up in world with an unlikely result in the lower tail on one, and an unlikely result in the higher tail on another, the final probability is hugely reduced eg. 60%*60%*5%*99% is only 1.8%. This means if we keep sampling from the distributions for each event, simulating possible worlds, we will get a lower predicted risk than if we simply multiply our best guesses for each step together.</p><p>The author collects estimates from the community and AI risk experts on each step of a well-accepted path to AI risk (Carlsmith model, 2021), which via simple multiplication ends up around the usual estimates in the 15-30% range. However, via sampling from the distribution of answers, they find we are far more likely to be in a world with &lt;3% risk of catastrophe due to out-of-control AGI, with a geometric mean of only 1.6% risk. This analysis also allows us to identify which steps are most important for determining if we are in a low or high risk world, which could be useful for prioritizing research directions.</p><p>A top comment notes that this method requires independence of each step of the AI risk model for a particular expert, and that assumption is likely not met and can hugely influence results.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/Nc9fCzjBKYDaDJGiX/what-is-the-likelihood-that-civilizational-collapse-would-1\"><u>What is the likelihood that civilizational collapse would cause technological stagnation? (outdated research)</u></a></p><p><i>by Luisa_Rodriguez</i></p><p>An incomplete draft (though still with lots of useful findings) from 2019/2020 on the probability that a catastrophe that caused civilizational collapse might lead to indefinite technological stagnation. Explores three questions in relation to this:</p><ol><li>If we re-ran history, would we see the agricultural and industrial revolutions again?</li><li>Would technological progress look different in a post-collapse world?</li><li>What are the recovery timelines for a collapsed civilization?</li></ol><p>&nbsp;</p><p>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/wPz7iQizzaxtvc4bX/brief-evaluations-of-top-10-billionnaires\"><u>Brief evaluations of top-10 billionnaires</u></a></p><p><i>by NunoSempere</i></p><p>The author briefly (1-2 paragraphs each) ranks the world\u2019s top 10 billionaires according to how much value / impact they\u2019ve created through their business and philanthropic activities.</p><p><br>&nbsp;</p><h2>Opportunities &amp; Resources</h2><p><i>Jobs, programs, competitions, fellowships, courses, resources, and more.</i></p><p>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/DDsTgC59MER7cPiRh/introducing-cause-innovation-bootcamp\"><u>Introducing Cause Innovation Bootcamp</u></a></p><p><i>by Akhil, Leonie Falk</i></p><p>Fellows will participate in training on evidence-based research, and then produce a shallow report on a pre-selected global health and development (GHD) cause area. The research will be aimed at novel areas with the hope to identify new interventions that could be competitive with the top of the field currently.</p><p>Applications are open until 30th Oct for the pilot, which will run 7th Nov - 20th Dec.<br><br><br><a href=\"https://forum.effectivealtruism.org/posts/nj9FLkifyb3s6Eijx/announcing-squigglepy-a-python-package-for-squiggle\"><u>Announcing Squigglepy, a Python package for Squiggle</u></a></p><p><i>by Peter Wildeford</i></p><p><a href=\"https://www.squiggle-language.com/\"><u>Squiggle</u></a> is a simple programming language for intuitive probabilistic estimation.&nbsp;<a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Fgithub.com%2Frethinkpriorities%2Fsquigglepy\"><u>This package&nbsp;</u></a>implements many squiggle-like functionalities in Python. It also includes utility functions for Bayesian networks, pooling forecasts, laplace, and kelly betting.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/ksisS29ThcY3BZLRw/call-for-applications-for-zanzibar-residency\"><u>Call for applications for Zanzibar residency</u></a></p><p><i>by Anne Nganga</i></p><p>Applications are open for the 2023 Effective Altruism Africa Residency Fellowship. The program runs Jan 15th - Mar 31st, and is aimed at providing support and community for EAs working on improving wellbeing in Africa. Accommodation and working space are provided.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/9HAQqNw5yBYFuoZgc/a-couple-of-pressing-jobs-in-biosecurity-at-the-moment-oct\"><u>A couple of expert-recommended jobs in biosecurity at the moment (Oct 2022)</u></a></p><p><i>by Clifford</i></p><p>The author asked Chris Bakerlee (Senior Program Associate for Biosecurity and Pandemic Preparedness at Open Philanthropy) for biosecurity roles he is excited to see filled right now. He responded with an Executive Assistant role on his team, and a Senior Program Officer / Senior Director for Global Biological Policy and Programs role at Nuclear Threat Initiative.</p><p><br>&nbsp;</p><h2>Community &amp; Media</h2><p><a href=\"https://forum.effectivealtruism.org/posts/agaudjzbp5eBSnbom/ea-funds-has-a-public-grants-database\"><u>EA Funds has a Public Grants Database</u></a></p><p><i>by calebp</i></p><p>All public grants by EA Funds will now appear in&nbsp;<a href=\"https://funds.effectivealtruism.org/grants\"><u>this database</u></a>. Entries include project summaries, the grantee, which fund paid, and the payout amount.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/xMwgykEotpnQzsf3h/careers-in-medicine-a-new-path-profile-from-probably-good\"><u>Careers in medicine - a new path profile from Probably Good and High Impact Medicine</u></a></p><p><i>by Probably Good, High Impact Medicine</i></p><p>A guide to impactful careers within the medical space, primarily aimed at existing doctors and medical students. Includes ways to have more impact within clinical work (eg. taking high paying roles and donating) as well as high-impact alternatives that benefit from a medical background (eg. medical research, public health, biosecurity, and nonprofit entrepreneurship).</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/7RgRbd3gv5Xt77zno/healthier-hens-y1-update-including-challenges-so-far-and-a\"><u>Healthier Hens Y1 update including challenges so far and a call for funding</u></a></p><p><i>by lukasj10, Isaac_Esparza</i></p><p>Healthier hens investigate dietary interventions to improve the welfare of cage-free hens and engage farming stakeholders to adopt these interventions. In Y1 they spent most of their budget on staff, research, and travel. In Y2 they intend to ramp up their program work. However, they are short of funding (missing 180K out of 230K needed for Y2) and looking for&nbsp;<a href=\"https://give.healthierhens.com/\"><u>donations</u></a>.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/me6xDoDzruPPuemQr/centre-for-exploratory-altruism-research-cearch\"><u>Centre for Exploratory Altruism Research (CEARCH)</u></a></p><p><i>by Joel Tan (CEARCH)</i></p><p>CEARCH is a new org focused on cause prioritization research. They will investigate a large number of causes shallowly, doing more intensive research if the cost-effectiveness of the cause seems plausibly at least one magnitude higher than a Givewell top charity. So far they have completed three shallow investigations: nuclear war, fungal disease, and asteroids. Asteroids ranked highest (2.1x top Givewell charities), surprising the researchers.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/z3J439wF8Xk8qSZku/announcing-vivid-a-new-ea-organization-aspiring-to-scale-1\"><u>Announcing VIVID: A new EA organization aspiring to scale effective self-improvement &amp; reflection</u></a></p><p><i>by GidiKadosh</i></p><p>A new organization building an app for effective self-improvement and reflection, initially targeting EAs. The app distinguishes itself via a focus on extensive customization and self-testing of plans to tackle internal obstacles and change mindsets.</p><p>You can help by trying the&nbsp;<a href=\"https://vivid-app.onelink.me/hYKI/EAForum1\"><u>beta version</u></a> and providing feedback on what does / doesn\u2019t work for you personally, getting in touch if you do EA wellbeing workshops or coaching, joining the team (several open positions) or giving feedback on the website / comms.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/Z6oqfKcax9yC2Cadk/be-careful-with-outsourcing-hiring\"><u>Be careful with (outsourcing) hiring</u></a></p><p><i>by Richard M\u00f6hn</i></p><p>Organisations not used to hiring might outsource it, but hiring firms don\u2019t always do a good job - and the author has seen an example where it was hard for founders without hiring experience to identify this. In that example, the hiring company:</p><ul><li>Turned candidates off with long ads, unnecessary requirements, unclear process, and delays</li><li>Failed to distinguish good candidates due to asking questions that didn\u2019t dig into the candidates experience</li><li>Rejected candidates late in the process via email with a form letter that stated no feedback could be given<br><br>&nbsp;</li></ul><h1>LW Forum</h1><h2>AI Related</h2><p><a href=\"https://www.lesswrong.com/posts/SbadvzWbufzX9iWJf/they-gave-llms-access-to-physics-simulators\"><u>They gave LLMs access to physics simulators</u></a></p><p><i>by ryan_b</i></p><p>Google has plugged large language models into physics simulators, to allow them to reason better about the physical world. This increased performance on physics questions / tasks by a large margin eg. 27% zero-shot absolute accuracy improvements, and allowing small LMs to perform at the level of 100x bigger ones that didn\u2019t have physics simulator access (on these specific questions).</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/rP66bz34crvDudzcJ/decision-theory-does-not-imply-that-we-get-to-have-nice\"><u>Decision theory does not imply that we get to have nice things</u></a></p><p><i>by So8res</i></p><p>Some people believe logical decision theory (LDT) agents are friendly, and so if AI was one, we\u2019d be alright. The author argues this is incorrect, because cooperative behavior for an LDT (eg. in Prisoner\u2019s Dilemmas, or two-boxing newcombe\u2019s problem) is entirely based on maximizing utility - not an in-built property of cooperativeness. If they don\u2019t expect helping us to lead to better outcomes on their goals, they won\u2019t help us.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/oxSX9XDQHLu5YLpaD/how-to-make-prediction-markets-useful-for-alignment-work\"><u>How To Make Prediction Markets Useful For Alignment Work</u></a></p><p><i>by johnswentworth</i></p><p>As an alignment researcher, the author often has to make decisions on what things to pay attention to vs. ignore. Eg. will shard theory turn out? Will a certain conjecture be proven even if they don\u2019t focus on it? However prediction markets focus almost exclusively on AI capability timelines. Eg. will we have an AI-generated feature film by 2026? Will AI wipe out humanity by 2100?</p><p>The author suggests more predictions that affect researchers day-to-day decision-making would make prediction markets more impactful.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case\"><u>Counterarguments to the basic AI risk case</u></a></p><p><i>by Katja_Grace</i></p><p><i>Summary repeated from last week as context for the next two posts, which directly respond to this one.</i></p><p>Counters to the argument that goal-directed AIs are likely and it\u2019s hard to align them to good goals, so there\u2019s significant x-risk:</p><ul><li><strong>AIs may optimize more for \u2018looking like they\u2019re pursuing X goal\u2019 than actually pursuing it.</strong> This would mean they wouldn\u2019t go after instrumental goals like money or power.</li><li><strong>Even if an AI\u2019s values / goals don\u2019t match ours, they could be close enough</strong>, or be non-destructive. Or they could have short time horizons that don\u2019t make worldwide takeovers worth it.</li><li><strong>We might be more powerful than a superintelligent AI</strong>. Collaboration was as or more important than intelligence for humans becoming the dominant species, and we could have non-agentic AIs on our side. AIs might also hit ceilings in intelligence, or be working on tasks that don\u2019t scale much with intelligence.</li><li><strong>The core AI x-risk argument could apply to corporations too - but we don\u2019t consider them x-risks</strong>. Corporations are goal-directed, hard to align precisely, far more powerful than individual humans, and adapt over time - but aren\u2019t considered x-risks.</li></ul><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/GQat3Nrd9CStHyGaq/response-to-katja-grace-s-ai-x-risk-counterarguments\"><u>Response to Katja Grace's AI x-risk counterarguments</u></a></p><p><i>by Erik Jenner, Johannes_Treutlein</i></p><p>Counterarguments to each of Katja\u2019s points in the post above, drawing from the existing literature. These defend the position that if AI proceeds without big advances in alignment, we would reach existential catastrophe eventually:</p><ol><li><strong>Goal-directedness is vague / AIs may optimize more for \u2018looking like they\u2019re pursuing X goal\u2019 than actually pursuing it.&nbsp;</strong>Counter:<strong>&nbsp;</strong>If we define \u2018goal-directedness\u2019 as \u2018reliably ensuring a goal will be achieved\u2019 then economic pressures will tilt toward this. To ensure very hard goals are achieved, the AI will need to use novel methods / a wide action space eg. \u2018acquire lots of power first\u2019.</li><li><strong>An AI\u2019s values could be close enough to ours</strong>. Counter: Imagine an AI is rewarded when sensors say a diamond is in a room. So it manipulates the sensors to always say that, instead of protecting the diamond. These are hugely different values that arise from the training signal not distinguishing \u2018this looks good to humans\u2019 and \u2018this is actually good for humans, given full knowledge\u2019 - which could be a common failure mode. Human values might vary little, but AI could vary a lot, particularly when working in situations with no training examples (because we don\u2019t have superhuman performance to train on).</li><li><strong>We might be able to handle a superintelligent AI</strong>. Counter: While some tasks don\u2019t benefit from intelligence, many do (eg. take over the world) and eventually someone will direct AI at one of these tasks, and keep improving it because of economic incentives. The question is if we can have superhuman alignment research (or another alignment solution) first.</li><li><strong>The core AI x-risk argument could apply to corporations too.&nbsp;</strong>Counter:<strong>&nbsp;</strong>corporations have limited scaling in comparison to AI, due to finite numbers of people and inadequate coordination.</li></ol><p>&nbsp;</p><p>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/iXuJLARFBZbaBGxW3/a-conversation-about-katja-s-counterarguments-to-ai-risk\"><u>A conversation about Katja's counterarguments to AI risk</u></a></p><p><i>by Matthew Barnett, Ege Erdil, Brangus Brangus</i></p><p>Transcript of a conversation between Ege Erdil and Ronny Fernandez about Katja\u2019s post above. Mostly focused on two of the arguments:</p><p>1.&nbsp;<strong>An AI\u2019s values could be close enough to ours</strong>. Our training processes train things to look good to humans, not to be good. Even if these are only rarely badly different, if we run enough powerful AIs enough times, we\u2019ll get that case and therefore catastrophe. And we might not have a chance to recognize it / recover because of the powerful optimization of the AI towards it. This is particularly likely for AIs doing things we find hard to rate (eg. \u2018does this look like a human face?\u2019 - the example in Katja\u2019s post - is much easier than \u2018is this or that similar world better?\u2019)</p><p>2.&nbsp;<strong>The core AI x-risk argument could apply to corporations too.&nbsp;</strong>Counter:<strong>&nbsp;</strong>corporations are bad at coordination. AIs can be much better (eg. combine forces toward a weighted merge of their goals).</p><p>&nbsp;</p><p><br><a href=\"https://www.lesswrong.com/posts/shcSdHGPhnLQkpSbX/scaling-laws-for-reward-model-overoptimization\"><u>Scaling Laws for Reward Model Overoptimization</u></a></p><p><i>by leogao, John Schulman, Jacob_Hilton</i></p><p>Author\u2019s tl;dr: \u201cReward model (RM) overoptimization in a synthetic-reward setting can be modelled surprisingly well by simple functional forms. The coefficients also scale smoothly with scale. We draw some initial correspondences between the terms of the functional forms and the Goodhart Taxonomy. We suspect there may be deeper theoretical reasons behind these functional forms, and hope that our work leads to a better understanding of overoptimization.\u201d<br>&nbsp;</p><p>&nbsp;</p><h2>Rationality Related</h2><p><a href=\"https://www.lesswrong.com/posts/YRzFcubbrvuhb9rtk/i-learn-better-when-i-frame-learning-as-vengeance-for-losses\"><u>I learn better when I frame learning as Vengeance for losses incurred through ignorance, and you might too</u></a></p><p><i>by chaosmage</i></p><p>The author experimented for 2 weeks with consciously learning \u2018with a vengeance\u2019, aiming to avenge whatever they lost because they didn\u2019t learn the thing earlier. They had better motivation and recall, and suggested others try the same.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/YpyW97jRbtvBAncAr/age-changes-what-you-care-about\"><u>Age changes what you care about</u></a></p><p><i>by Dentin</i></p><p>The author believes there are double-digit odds of AI-caused extinction in the next century. However, this is less salient than the &gt;50% that as a currently-49-year-old they will die in the next 3-4 decades, with increasing odds every year - particularly after several health scares. It\u2019s hard to focus on anything above personal survival.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/5ntgky9ShzKKWu7us/plans-are-predictions-not-optimization-targets\"><u>Plans Are Predictions, Not Optimization Targets</u></a></p><p><i>by johnswentworth</i></p><p>Treating a plan as a step-by-step list that we should always optimize toward isn\u2019t as helpful as developing multiple plans, identifying common bottlenecks between them, and tackling those. This is particularly the case if your field is preparadigmatic and you\u2019re working on hard problems, as it allows you to adapt when surprises are thrown your way.</p><p>In this case, a plan simply becomes one path we predict. We might even have a mainline / modal plan we most expect. But we\u2019re selecting our actions to be useful in both this and other paths.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/zHBMY273suDnMqNLq/wisdom-cannot-be-unzipped\"><u>Wisdom Cannot Be Unzipped</u></a></p><p><i>by Sable</i></p><p>Compression works via assuming knowledge on the receiver\u2019s end. If we know the receiver understands 4x1 to mean 1111 then we can compress binary. If we know the receiver understands the general idea that problems are easier to fix early on when they\u2019re small, we can compress a reminder as \u2018a stitch in time saves nine\u2019.</p><p>When we share wisdom or learnings, we lose a lot of the value - there is no way for the receivers to \u2018unzip\u2019 these lessons and get an understanding of the experiences, context, and nuance that formed them.</p><p>&nbsp;</p><p>&nbsp;</p><h2>Other</h2><p><a href=\"https://www.lesswrong.com/posts/fFY2HeC9i2Tx8FEnK/my-resentful-story-of-becoming-a-medical-miracle\"><u>My resentful story of becoming a medical miracle</u></a></p><p><i>by Elizabeth</i></p><p>The author tried many things to deal with a medical problem on the advice of doctors, was eventually suggested a treatment for a different issue, tried it, and it solved the original problem (in this case - a particular antihistamine taken for rash dealt with difficulty digesting protein). They also ran studies on self help books and found no correlation between helpfulness and rigor / theoretical backing, and ran an RCT on ketone esters and found no benefits despite them and friends getting insane gains from them.</p><p>They conclude that \u201conce you have exhausted the reliable part of medicine without solving your problem, looking for a mechanistic understanding or empirical validation of potential solutions is a waste of time. The best use of energy is to try shit until you get lucky.\u201d</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/JbRkDvwXh39bEx3xw/voting-theory-introduction\"><u>Voting Theory Introduction</u></a></p><p><i>by Scott Garrabrant</i></p><p>The first post in a sequence introducing a new voting system. This post introduces background framework, notation, and voting theory.</p><p>Important criteria for voting theories include:</p><ul><li>Condorcet: If a candidate would defeat all others in one-on-one elections, that candidate should win.</li><li>Consistent: If two disjoint electorates would produce the same result, then combined, they should also produce that result.</li><li>Participation: No voter should be made worse off by voting compared to staying home.</li><li>Clone: If a set of candidates are clumped together in all voters preference orderings, the result of the election should be the same as if they were a single candidate.</li></ul><p>Most voting methods violate at least one of these principles eg. in all deterministic voting systems the condorcet and consistent principles are in conflict.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/hR72Jzttfooww3dQR/maximal-lotteries\"><u>Maximal Lotteries</u></a></p><p><i>by Scott Garrabrant</i></p><p>Maximal lotteries are a voting system where if anyone would win against all others 1-1, they do. If that\u2019s not the case, votes create probability distributions (eg. it may assign 80% to one candidate), and then a random number is rolled to determine the winner.</p><p>This system fulfills all 4 voting principles from the previous post. It is distinct from the \u2018random dictatorship\u2019 voting method (choose a random person, go with their vote as the winner) only in that it first checks and fulfills the concordance principle, so a clear winner will always win.</p><p>Scott continues to build on this idea with posts on&nbsp;<a href=\"https://www.lesswrong.com/posts/vwrNprXfEzeQ2cy3d/maximal-lottery-lotteries\"><u>Maximal Lottery-Lotteries</u></a> and&nbsp;<a href=\"https://www.lesswrong.com/posts/CAKZsP2v7SqqEExz9/open-problem-in-voting-theory\"><u>Open Problem in Voting Theory</u></a> (which discusses whether maximal lottery-lotteries exist, which is an open problem).</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/bvqC4Ci7rXq4sN9df/why-weren-t-hot-air-balloons-invented-sooner\"><u>Why Weren't Hot Air Balloons Invented Sooner?</u></a></p><p><i>by Lost Futures</i></p><p>Some technologies couldn\u2019t have been invented much earlier than they were, because they rely on prior discoveries. Others were possible for an extended time before being discovered - hot air balloons are one of these.</p><p>The basic principles were operating in Chinese&nbsp;<a href=\"https://en.wikipedia.org/wiki/Sky_lantern\"><u>sky lanterns</u></a> over a thousand years before hot air balloons were first invented. Once someone experimented to create a balloon in 1782, there was a working version within a year and it quickly proliferated around the world. It\u2019s possible it was bottlenecked on textile prices or quality, but even accepting that it would still have been discovered 10s to 100s of years later than it could have been.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/mLp8sLw2xggA7Bjd3/untapped-potential-at-13-18-1\"><u>Untapped Potential at 13-18</u></a></p><p><i>by belkarx</i></p><p>Intelligent 13-18 year olds who aren\u2019t ambitious enough to start their own projects have those years somewhat wasted by school busywork. Making meaningful work more accessible to them would be good.</p><p><br>&nbsp;</p><h2>Didn\u2019t Summarize</h2><p><a href=\"https://www.lesswrong.com/posts/SfPrNY45kQaBozwmu/an-extremely-opinionated-annotated-list-of-my-favourite\"><u>An Extremely Opinionated Annotated List of My Favourite Mechanistic Interpretability Papers</u></a>&nbsp;<i>by Neel Nanda</i></p><p><a href=\"https://www.lesswrong.com/posts/REA49tL5jsh69X3aM/introduction-to-abstract-entropy\"><u>Introduction to abstract entropy</u></a>&nbsp;<i>by Alex_Altair</i></p><p><a href=\"https://www.lesswrong.com/posts/RhAxxPXrkcEaNArnd/notes-on-can-you-control-the-past\"><u>Notes on \"Can you control the past\"</u></a>&nbsp;<i>by So8res&nbsp;</i></p><p>&nbsp;</p><h1>This Week on Twitter</h1><h2>AI</h2><p>Meta released Universal Speech Translator, the first AI speech-to-speech translation system - which works even on languages that are primarily only spoken, not written.<a href=\"https://twitter.com/MetaAI/status/1582776841001000960?s=20&amp;t=9BHuSfRM0VdXhUMTNvH2bg\"><u> (tweet)</u></a></p><p>Stability AI (who released Stable Diffusion) are delaying release of the 1.5 version in order to focus on security and ensuring it\u2019s not used for illegal purposes - driven by community feedback.&nbsp;<a href=\"https://danieljeffries.substack.com/p/why-the-future-of-open-source-ai\"><u>(article)</u></a></p><p>&nbsp;</p><h2>AW</h2><p>Nine EU countries are pushing for a Europe-wide ban on culling male chicks.&nbsp;<a href=\"https://twitter.com/joswabe/status/1582605643378462721?s=20&amp;t=VAE6fw3aAlt59a2dwpdoyA\"><u>(tweet)</u></a>&nbsp;<a href=\"https://euobserver.com/health-and-society/156304\"><u>(article)</u></a></p><p>&nbsp;</p><h2>National Security</h2><p><a href=\"https://www.csis.org/analysis/choking-chinas-access-future-ai\"><u>New analysis</u></a> of the AI export restrictions by CSIS. Also mentions a US$53B commitment the US govt made in early August on semiconductor R&amp;D.<br>&nbsp;</p><h2>Science</h2><p>Biden\u2019s latest National Biodefense Strategy calls for the US to produce a test for a new pathogen within 12 hours of its discovery and enough vaccine to protect the nation within 130 days.&nbsp;<a href=\"https://twitter.com/josh_wingrove/status/1582395483548680192?s=20&amp;t=k2ZNr2-T_MrzNWtV3CJflA\"><u>(tweet)</u></a>&nbsp;<a href=\"https://t.co/dBI7FeH1UI\"><u>(article)</u></a></p>", "user": {"username": "GreyArea"}}, {"_id": "xrmM6zWco9QEMxG6j", "title": "Ways in which EA could fail", "postedAt": "2022-10-24T23:46:25.546Z", "htmlBody": "<p><i>This is the first out of two posts attempting to make EA strategy discussions more productive. The second post examines </i><a href=\"https://forum.effectivealtruism.org/posts/dSLLJX5mhgpBzbZED/ea-movement-course-corrections-and-where-you-might-disagree\"><i>EA movement course corrections and where you might disagree.&nbsp;</i></a></p><h1>Summary</h1><ul><li>Following an influx of funding, media attention, and influence, the EA movement is speeding along an exciting, yet perilous, trajectory.</li><li>A lot of the EA community\u2019s future impact rests on this uncertain growth going well (and thereby avoiding movement collapse scenarios).&nbsp;</li><li>Yet, discussions or critiques of EA\u2019s trajectory rarely feel action-guiding. Even when critiques propose course corrections that are tempting to agree with (e.g., EA should be bigger!), proposed course corrections to make EA more like X often don\u2019t rigorously engage with the downsides of being more like X, or the opportunity cost of not being like Y. Proposals to make EA more like X also often leave me with only a vague understanding of what X looks like and how we get from here to X.</li><li>In hopes of making discussions of the EA community\u2019s trajectory more productive (and to clarify my own thinking on the matter), I will lay out a series of posts that provide an overview of:&nbsp;<ul><li><strong>(1) Important ways in which the EA movement could fail</strong><br>(2) \u201cDomains\u201d in which EA could make course corrections (e.g., more cause-area tailored outreach, new professional networks and events, etc.)<br>(3) Key considerations that inform course corrections (i.e., places to disagree about course corrections)<br>(4) Next steps to help guide the EA movement through exciting and perilous times</li></ul></li><li><strong>This is the first post in this series: Ways in which EA could fail.&nbsp;</strong>Consider it an attempt at bounding the later discussions of strategy updates.&nbsp;</li></ul><h1>Ways in which EA could fail</h1><p>The EA movement could collapse. Many movements before us have, and we\u2019re not&nbsp;<i>that&nbsp;</i>special. But other movements, like abolitionism, have left lasting social change<strong>. In hopes of being the type of movement that does so well it doesn\u2019t need to exist anymore, this section outlines many of the ways EA could fail.&nbsp;</strong></p><p><strong>In this post, I\u2019ll define \u201cfailure\u201d as the EA/EA-adjacent ecosystem achieving substantially less impact </strong>(<a href=\"https://slatestarcodex.com/2013/05/02/if-its-worth-doing-its-worth-doing-with-made-up-statistics/\">let's say</a>, 30%)<strong> than it could have along some other trajectory.</strong> Note that this is a pretty broad definition. Depending on your worldview and person-affecting ethical views, failure could look more like millions or billions of people alive in the near-future suffering in ways that could have been prevented \u2013 or failure could look more like an existential catastrophe that permanently stops sentient life from achieving its full potential.&nbsp;</p><p>Implicit in this definition of failure is a statement about the influence EA already has, or could grow to have: I think our ideas and resources are powerful enough to seriously influence how many beings suffer today and how many beings live beautiful lives in the future, such that there\u2019s a massive difference between the most good a flourishing EA ecosystem could achieve (i.e., upper bound) and the good, or possibly even harm,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffqo0q0vqz67\"><sup><a href=\"#fnfqo0q0vqz67\">[1]</a></sup></span>&nbsp;a collapsed EA ecosystem leaves us with (i.e., lower bound).&nbsp;</p><p>In order to land closer to the heights of positive impact, let\u2019s think concretely about the worst cases that we must collectively avoid. In what ways might the EA movement fail?</p><p>I identify <strong>four clusters of failures:</strong></p><ol><li><strong>Reputation failures:</strong> failures that result in EA losing a substantial amount of possible impact because the EA community develops a negative reputation.</li><li><strong>Resource failures:</strong> failures that result in EA losing a substantial amount of possible impact because the community becomes preventably constrained by financial, human, or infrastructure resources.</li><li><strong>Rigor failures:</strong> failures that result in EA losing a substantial amount of possible impact because EA enthusiasts aren\u2019t thinking clearly about prioritizing problems and their solutions.</li><li><strong>Reservation failures:</strong><i><strong>&nbsp;</strong></i>failures that result in EA missing a substantial amount of possible impact because we are too risk averse, or just not ambitious enough</li></ol><p>&nbsp;</p><p>But note a few caveats before I elaborate on these different failure clusters:</p><ul><li><strong>This taxonomy is imperfect</strong>. Some failures could fit into multiple categories, or don\u2019t fit cleanly into any. I discuss other ways to group failures in the footnotes.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7qd49nyms5c\"><sup><a href=\"#fn7qd49nyms5c\">[2]</a></sup></span>&nbsp;</li><li><strong>Causes of failures are likely to chain into each other across different clusters of failures.</strong> For example, diluted epistemic norms (which I categorize as rigor failure) could lead to risky unilateral moves that result in a PR scandal and media firestorm (which I categorize as a reputation failure). In turn, this could lead to a loss of people and funding support (which I categorize as a resource failure). Failures are a messy business \u2013 don\u2019t let a nice 4R alliteration taxonomy fool you.&nbsp;&nbsp;&nbsp;</li><li><strong>There are subtleties within failure modes.&nbsp;</strong>Some of the failures I discuss below like, for example, EA becoming politicized, could further be broken down into different consequences that plausibly have a different impact (e.g., the consequences of EA becoming disliked by left or right US political parties are probably very different). Similarly, internal disenchantment and negative press are already happening at some level, so these causes of \u2018failure\u2019 are clearly a matter of degree.</li><li><strong>Not all failure modes below are equally bad or equally likely.</strong> Considering both the badness and likelihood of different failures is an important next step in prioritizing which failures to course-correct away from.&nbsp;</li><li><strong>Forgive me for vaguely using \u201cEA.\u201d&nbsp;</strong>For the sake of simplicity \u2013 and because I really am gesturing at the whole movement \u2013&nbsp;I often invoke the mysterious, definitely-not-an-agent \u201cEA\u201d in reference to some action. But try to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Pz7RdMRouZ5N5w5eE/ea-should-taboo-ea-should\"><u>avoid doing this!</u></a></li><li><strong>EA could still be on its optimal trajectory despite some evidence of \u2018failure\u2019.</strong>&nbsp;For example, I expect at least some parts of the optimal version of the EA movement just aren\u2019t everyone's vibe and some people will feel disenchanted by them. While I classify disenchantment as a failure mode below, the fact that we might still expect to see disenchantment in the optimal version of EA means evidence of the beginning of a failure doesn\u2019t&nbsp;<i>necessarily</i> mean EA needs to course-correct away from that failure.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhdbr4fniyj9\"><sup><a href=\"#fnhdbr4fniyj9\">[3]</a></sup></span></li></ul><h2>Reputation failures</h2><p>Reputation failures result in EA losing a substantial amount of possible impact because the community develops a negative reputation, either internally, externally, or both.&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:150px\"><strong>Causes of reputation failure</strong></td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center\"><strong>Examples</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Media firestorm</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Some version of the meme that \u201cEA is just a bunch of white billionaires claiming to do good so they can feel good about themselves\u201d catches on and lots of media outlets jump on the bandwagon. Now typical college students think EA is lame and politicians don\u2019t want to touch EA.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Internal disenchantment &nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsbk1aeouc8e\"><sup><a href=\"#fnsbk1aeouc8e\">[4]</a></sup></span></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Engaged EAs start feeling disenchanted or misrepresented by the overall aesthetic (e.g., elitist) or actions (e.g., free-spending) of the EA movement and distance themselves from the community. Now many cool people are missing out on valuable coordination and communication, and this process may be reinforced since those that remain in EA are the most hardcore.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Politicization (of EA itself or core ideas)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnlcf8amrn9\"><sup><a href=\"#fnnlcf8amrn9\">[5]</a></sup></span></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Wild animal welfare or speciesism become seen as just another woke idea and honest intellectual discussion around the topic becomes increasingly difficult.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Infighting<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefba8t4z1mu5\"><sup><a href=\"#fnba8t4z1mu5\">[6]</a></sup></span></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Disagreements about funding and relative attention between global health and wellbeing vs. longtermist works boils over into a messy, public fracture of EA. Or this leads to internal disenchantment.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Risky unilateral project</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Someone carelessly takes on a risky project, say middle school outreach, that has clear downside risks that have caused others to steer clear of it. The project blows up and EA\u2019s reputation is worse for it.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Too demanding or totalizing&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">EA develops a public reputation as too hardcore and demanding, and people, like politicians, who could have a great deal of impact feel like they can\u2019t be \u2018kinda EA.\u2019 Related to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/h566GT4ECfJAB38af/some-quick-notes-on-effective-altruism#_Effective_altruism__sounds_like_a_strong_identity_\"><u>concerns about EA as an identity.</u></a></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Scandal</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">An instance (or multiple instances) of sexual harassment in EA social circles cripples EAs reputation.</td></tr></tbody></table></figure><h2>Resource failures</h2><p>Resource failures result in EA losing a substantial amount of possible impact because the community becomes constrained by financial and/or human resources.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:150px\"><strong>Causes of resource failure</strong></td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center\"><strong>Examples</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Running out of money</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>(1) Sam Bankman Fried\u2019s and other top EA donors\u2019 net worth plummets&nbsp; because of cryptocurrency or US stock market crashes</p><p><br><i>EDIT 11/11/22: This aged annoyingly well. I expect we'll also see the ripple of a resource failure into a reputation failure, although it's as of now unclear to me how bad the reputation damage could get.&nbsp;</i><br><br>(2) EA doesn\u2019t keep up with insanely profitable monetary gains from narrow AI and can\u2019t keep up with a vital compute run up for AGI.</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">No new talent (or evaporating old talent)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">For whatever reason (probably reputation collapse or infrastructure constraints), EA can\u2019t attract \u2013 or keep \u2013 the quantity and quality of talented individuals it urgently needs (above and beyond the typical talent constraint we see today).</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Inadequate infrastructure&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">EA fails to build the scalable infrastructure you need to coordinate many people pushing in a coherent direction.</td></tr></tbody></table></figure><h2>Rigor failures</h2><p>Rigor failures result in EA losing a substantial amount of possible impact because EA enthusiasts aren\u2019t thinking clearly about prioritizing problems and their solutions.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:150px\"><strong>Causes of rigor failures&nbsp;</strong></td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center\"><strong>Examples</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Dilution of truth-seeking and maximizing norms</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">(1) EA doubles in size multiple years in a row, and now more than half the conversations people have at EAGx-style events are with people brand new to EA norms. Gradually rigorous truth-seeking norms lose their footing.<br><br>(2) EA splits along cause areas or philosophical differences, and the community starts to focus on naively optimizing within certain cause areas and misses new opportunities&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Funding and status-seeking muddle intellectual rigor<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffrlbdxc5o8b\"><sup><a href=\"#fnfrlbdxc5o8b\">[7]</a></sup></span></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">EAs implicitly follow incentives to do what gets them in-group clout and larger paychecks (e.g., embrace longtermism) in a way that weakens general quality of thought.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Excessive deference culture<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgpivx7nbldc\"><sup><a href=\"#fngpivx7nbldc\">[8]</a></sup></span></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">New EAs start assuming that old wise EAs before them already have answers, and we build our epistemic foundations and prioritization schemes on shaky foundations.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Bad actors</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">The meme that EA has a lot of money to give if you know the right things to say spreads outside the community, and bad actors degrade trust networks that underlie existing coordination.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Excessive nepotism</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Infiltrating key EA decision-making spaces becomes too much a function of who you know, in a way that selects for qualities other than those of the best decision-makers.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Insufficient intellectual diversity</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Many people throughout history have landed at different answers for what good means, yet EA uncritically concludes it has found the right answer and pushes towards it without maintaining option value. And then we realize that we missed the mark&nbsp; (or, more likely, we never realize because moral philosophy literally has the worst feedback loops).&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Echo chambers</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">EAs become siloed in their own worldviews and shared models and underweight the importance of existing power structures or things like&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/S9JeqH4qYvoLZqq9c/an-entire-category-of-risks-is-undervalued-by-ea-summary-of\"><u>systemic cascading risks</u></a>.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Goodharting&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">EA decision-makers begin to&nbsp;<a href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law\"><u>optimize for legible metrics</u></a> that don\u2019t actually track our overarching goals</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Poor feedback loops</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Longtermist work focuses<a href=\"https://forum.effectivealtruism.org/posts/TruJuwtdfszFJgzwB/longtermist-ea-needs-more-phase-2-work\"> too much</a> on preparing for future success without getting <a href=\"https://forum.effectivealtruism.org/posts/by8u954PjM2ctcve7/experimental-longtermism-theory-needs-data\">feedback</a> from the real world about whether we\u2019re preparing in the right ways.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Out-of-touch leadership<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbeirn64aggf\"><sup><a href=\"#fnbeirn64aggf\">[9]</a></sup></span></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">The EAs closest to leadership become isolated from the rest of the community. They lose a source of outside feedback and a check on their epistemics.</td></tr></tbody></table></figure><h2>Reservation failures</h2><p>Reservation failures result in EA missing a substantial amount of possible impact because we are too risk-averse, or just not ambitious enough. While reservation failures are less likely to lead to movement collapse, they are arguably more likely to increase the likelihood of an existential catastrophe \u2013 or just the preventable suffering of (m?b??t???)illions.&nbsp;&nbsp;</p><p><i>Reservation failures are closely related to&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/LwRSnvnaFL9eE4yKz/invisible-impact-loss-and-why-we-can-be-too-error-averse\"><i><u>invisible impact loss</u></i></a><i>.</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefg3q3hhv9089\"><sup><a href=\"#fng3q3hhv9089\">[10]</a></sup></span><i>&nbsp;</i></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top;width:150px\"><strong>Causes of reservation failures</strong></td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center\"><strong>Examples</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Not enough focus on scalability<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwupypipspb\"><sup><a href=\"#fnwupypipspb\">[11]</a></sup></span></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Too many EAs twiddle around with small-scale projects that lack the entrepreneurial mindset to deploy all the resources at our disposal (or acquire much more).</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Unwillingness to trade reputation for impact&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">EAs don\u2019t take an action such as global talent search because it might harm our reputation (in this case elitism critiques), even if these are the types of projects we need to solve the most pressing problems.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Overlooking serious possibility of short transformative AI timelines&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">EAs don\u2019t take the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/7JxsXYDuqnKMqa6Eq/ai-timelines-where-the-arguments-and-the-experts-stand\"><u>non-negligible</u></a> chance of transformative AI arriving around 2030 seriously and we\u2019re caught without a robust emergency plan when things start getting crazy and dangerous.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Spending-averse&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">EAs are overly wary of deploying large amounts of money because it\u2019s in tension with the movement's frugal foundations.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Not joining the adult table</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">EAs cautiously hold off on bringing their ideas to spaces like US politics, intergovernmental organizations (e.g., UN), or other powerful institutions because we think \u201cwe\u2019re not ready yet.\u201d</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Bureaucracy</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">As EA institutions mature, they start looking more like traditional orgs and become bogged down by red tape, an overemphasis on legibility (e.g., in grants), and/or the \u201cbureaucrat\u2019s curse\u201d where everyone needs to sign off on everything.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefznsb0mw7y69\"><sup><a href=\"#fnznsb0mw7y69\">[12]</a></sup></span>&nbsp;</td></tr></tbody></table></figure><h2>Next steps re: failure modes</h2><ul><li><strong>Analyze relative badness and the likelihood of failure modes&nbsp;</strong>to decide which to prioritize.</li><li><strong>Analyze how different failure modes could play out. </strong>I picture many \u201cfailures\u201d of EA still leaving behind a core group of people committed to maximal impartial altruism. But the damage to branding, coordination, and resources might well vary depending on what caused the failures, and I expect this to have a big influence on how much any group could accomplish.&nbsp;</li><li><strong>Identify what warning signs we might expect (or are already seeing) for each failure mode and some action threshold.&nbsp;</strong>I expect this action threshold to vary depending on people\u2019s idealized vision for EAs trajectory, which will be the focus of the next posts.</li><li><strong>Identify more EA failure modes or debate the ones I listed:</strong> What did I miss?&nbsp;</li><li><strong>Improve the taxonomy:</strong> Would refactoring the failure modes make them more action-guiding?</li><li><strong>Proposals to make cause-areas more robust to EA brand collapse.&nbsp;</strong>Depending on how concerned one is about the reputation of the EA brand, there may be arguments to preemptively make work in different areas (e.g., AI safety) not too coupled to EA.</li></ul><h1>Coming soon&nbsp;</h1><p><i>UPDATE: The second post on </i><a href=\"https://forum.effectivealtruism.org/posts/dSLLJX5mhgpBzbZED/ea-movement-course-corrections-and-where-you-might-disagree\"><i>EA movement course corrections and where you might disagree</i></a><i> is live.</i></p><p>The next post, or posts, will identify:</p><ol><li>&nbsp;\u201cDomains\u201d in which EA could make course corrections (e.g., more cause-area tailored outreach, new professional networks and events, etc.).</li><li>Key considerations that inform course corrections (i.e., places to disagree about course corrections).</li><li>More next steps proposals to help guide the EA movement through this exciting and perilous period of growth.</li></ol><p>I hope to have these next sections out within the next two weeks.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfqo0q0vqz67\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffqo0q0vqz67\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Examples of ways EA could have a net-negative impact is by directing finite altruistic talent in the wrong direction, permanently tainting ideas like doing good with an emphasis on rationality, or by discouraging others to tackle X important problem because we give the impression we're on it when we're really not.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7qd49nyms5c\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7qd49nyms5c\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Other failure mode taxonomies include:</p><p>(1)<a href=\"https://forum.effectivealtruism.org/posts/KeBgeY8XvYb3pbFRA/movement-collapse-scenarios\"> Sequestration, Attrition, Dilution, and Distraction</a><br>(2) Failures from pushing too hard, not pushing hard enough, or pushing in the wrong direction.&nbsp;<br>(3) Failures where the recognizable EA collapses before an existential catastrophe vs. failures where EA is still intact but fails to prevent an existential catastrophe&nbsp;<br>(4) Failures of <a href=\"https://forum.effectivealtruism.org/posts/cfdnJ3sDbCSkShiSZ/ea-and-the-current-funding-situation\">Commission vs. omission</a>: causing harm vs. squandering an opportunity.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhdbr4fniyj9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhdbr4fniyj9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;You can imagine that this makes it really difficult for CEA and other EA thought leaders to know when to course-correct upon criticism, especially when you factor in an uncertain switching cost one incurs trying to coordinate and implement a trajectory change.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsbk1aeouc8e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsbk1aeouc8e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/MjTB4MvtedbLjgyja/leaning-into-ea-disillusionment\"><u>Leaning into EA Disillusionment</u></a> for more discussion&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnlcf8amrn9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnlcf8amrn9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For more discussion, see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/SitudkgqA5Gnwfxdz/ea-considerations-regarding-increasing-political\"><u>EA considerations regarding increasing political polarization</u></a>.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnba8t4z1mu5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefba8t4z1mu5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Linch accurately notes in <a href=\"https://forum.effectivealtruism.org/posts/xrmM6zWco9QEMxG6j/ways-in-which-ea-could-fail\">comments</a> that the consequences of infighting are more complicated than a mere reputation failure.</p><p>See also: Will MacAskill\u2019s writing on&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/cfdnJ3sDbCSkShiSZ/ea-and-the-current-funding-situation#Risks_of_commission__causing_harm\"><u>resentment</u></a> and the Book<i>&nbsp;</i><a href=\"https://www.howchangehappens.com/\"><i><u>How Change Happens&nbsp;</u></i></a>by Leslie Crutchfield, which notes <i>effective management of infighting </i>as a consistent attribute of the most effective movements in recent US history (Chapter 5).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfrlbdxc5o8b\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffrlbdxc5o8b\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See also: Will MacAskill\u2019s writing on the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/cfdnJ3sDbCSkShiSZ/ea-and-the-current-funding-situation#Risks_of_commission__causing_harm\"><u>current funding situation harming quality of thought</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngpivx7nbldc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgpivx7nbldc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See the&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/epistemic-deference\"><u>epistemic deference forum tag</u></a> for more discussion&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbeirn64aggf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbeirn64aggf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Idea borrowed from this post on&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/KeBgeY8XvYb3pbFRA/movement-collapse-scenarios#Sequestration\"><u>movement collapse scenarios</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fng3q3hhv9089\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefg3q3hhv9089\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For what it\u2019s worth, I think reservation failures are the most overlooked cluster of failures. I think it\u2019s just much easier to criticize ostensibly bad things EA does than all the invisible impact EA loses by being overly cautious or doing some things that turn people off. However, reservation failures are a delicate matter, because they are often \u2013 although not always \u2013 associated with&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/LwRSnvnaFL9eE4yKz/invisible-impact-loss-and-why-we-can-be-too-error-averse#_1__The_downside_risks_are_high\"><u>downside risks</u></a> that require serious consideration.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwupypipspb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwupypipspb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See Will MacAskill\u2019s writing on&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/cfdnJ3sDbCSkShiSZ/ea-and-the-current-funding-situation#Risks_of_omission__squandering_the_opportunity_\"><u>\u201cRisks of Omission\u201d</u></a> for more discussion of scalability:&nbsp;</p><blockquote><p>It seems to me to be more likely that we\u2019ll fail by not being ambitious enough; by failing to take advantage of the situation we\u2019re in, and simply not being able to use the resources we have for good ends.</p></blockquote></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnznsb0mw7y69\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefznsb0mw7y69\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Credit to Nick Beckstead for \"Bureaucrat\u2019s curse\"</p></div></li></ol>", "user": {"username": "MJusten"}}, {"_id": "RX8tBS9mK9B3nos6n", "title": "How many people die from the flu? (OWID)", "postedAt": "2022-10-24T21:54:36.493Z", "htmlBody": "<p>Saloni Dattani and Fiona Spooner at Our World in Data (OWID) have recently published <a href=\"https://ourworldindata.org/influenza-deaths\">a new article</a> on the annual death toll of the flu \u2014 I thought the article was interesting and am <a href=\"https://forum.effectivealtruism.org/posts/8yDsenRQhNF4HEDwu/link-posting-is-an-act-of-community-service\">link-posting</a> it.&nbsp;</p><p>The article also explains some issues with measuring this, how this has changed over time, factors that increase the chances of dying from the flu, and why some flu seasons are worse than others. The headline (emphasis mine):&nbsp;</p><blockquote><p><strong>The risk of death from influenza has declined over time, but globally, hundreds of thousands of people still die from the disease each year.</strong></p></blockquote><blockquote><p>[...]</p><p>The annual mortality caused by seasonal influenza was estimated by the Global Pandemic Mortality Project II using data between 2002 and 2011. They estimated that, during this period, seasonal influenza caused <strong>between 294,000 and 518,000 deaths each year globally.</strong></p></blockquote><p>For reference on what 300,000 to 500,000 looks like, here's a chart (from <a href=\"https://ourworldindata.org/causes-of-death\">a different article</a>) that shows deaths by cause:&nbsp;</p><figure class=\"media\"><div data-oembed-url=\"https://ourworldindata.org/grapher/annual-number-of-deaths-by-cause\">\n\t\t\t\t\t<div data-owid-slug=\"annual-number-of-deaths-by-cause\" class=\"owid-preview\">\n\t\t\t\t\t\t<iframe src=\"https://ourworldindata.org/grapher/annual-number-of-deaths-by-cause\">\n\t\t\t\t\t</iframe></div>\n\t\t\t\t</div></figure><hr><p>An excerpt and a couple of charts \u2014 or just <a href=\"https://ourworldindata.org/influenza-deaths\">see the article itself</a>.</p><blockquote><p>Globally, hundreds of thousands of people die from seasonal influenza every year. During large flu pandemics, when influenza strains evolved substantially, the death toll was even higher.</p><p>But the risk of dying from influenza has declined substantially over time from improvements in sanitation, healthcare, and vaccination.&nbsp;</p><p>People born in 1940 had around a third of the risk of dying from influenza as those born in 1900 \u2013&nbsp;even when they reached the same age. This decline continued, and those born in 1980 have a risk of half that of those born in 1940.</p><p>Influenza still remains a large burden around the world, because of an aging population and a lack of access to healthcare and sanitation in many countries.&nbsp;</p><p>In this article, we look into these developments in detail: how many people die from seasonal influenza and how this has changed over time.&nbsp;</p><p>We will also look at which factors increase the risk of dying from the flu and understand why, in some years, influenza has led to large pandemics that caused millions of deaths. This knowledge can inform us about the risks of influenza in the future.</p></blockquote><figure class=\"media\"><div data-oembed-url=\"https://ourworldindata.org/grapher/annual-mortality-rate-from-seasonal-influenza-ages-65?country=South-East+Asia~OWID_WRL~Western+Pacific~Eastern+Mediterranean~Africa~Europe~Americas\">\n\t\t\t\t\t<div data-owid-slug=\"annual-mortality-rate-from-seasonal-influenza-ages-65\" class=\"owid-preview\">\n\t\t\t\t\t\t<iframe src=\"https://ourworldindata.org/grapher/annual-mortality-rate-from-seasonal-influenza-ages-65?country=South-East+Asia~OWID_WRL~Western+Pacific~Eastern+Mediterranean~Africa~Europe~Americas\">\n\t\t\t\t\t</iframe></div>\n\t\t\t\t</div></figure><figure class=\"image\"><img src=\"http://res.cloudinary.com/cea/image/upload/v1672145654/mirroredImages/RX8tBS9mK9B3nos6n/fqeidq6otttjwhdlumlu.png\" srcset=\"http://res.cloudinary.com/cea/image/upload/v1672145655/mirroredImages/RX8tBS9mK9B3nos6n/owv6fpcfidnqxzvgzmvi.png 300w, http://res.cloudinary.com/cea/image/upload/v1672145654/mirroredImages/RX8tBS9mK9B3nos6n/brxsphgykyjdlwmbclvd.png 600w, http://res.cloudinary.com/cea/image/upload/v1672145655/mirroredImages/RX8tBS9mK9B3nos6n/k1g2qafkqqdhukcfq0vh.png 900w, http://res.cloudinary.com/cea/image/upload/v1672145655/mirroredImages/RX8tBS9mK9B3nos6n/z164cp1jrynr5aseukak.png 1200w, http://res.cloudinary.com/cea/image/upload/v1672145654/mirroredImages/RX8tBS9mK9B3nos6n/e8bv5gjgy7sjtkha9h48.png 1500w, http://res.cloudinary.com/cea/image/upload/v1672145655/mirroredImages/RX8tBS9mK9B3nos6n/tkldo4r8ok11n8fniuxv.png 1800w, http://res.cloudinary.com/cea/image/upload/v1672145655/mirroredImages/RX8tBS9mK9B3nos6n/jhwdts83mergxzwrcwtp.png 2100w, http://res.cloudinary.com/cea/image/upload/v1672145655/mirroredImages/RX8tBS9mK9B3nos6n/ketvmxr8c3608uh7ye8k.png 2400w, http://res.cloudinary.com/cea/image/upload/v1672145655/mirroredImages/RX8tBS9mK9B3nos6n/tdvqxhf3ercgovtfcrar.png 2700w, http://res.cloudinary.com/cea/image/upload/v1672145655/mirroredImages/RX8tBS9mK9B3nos6n/xfnu54pq6jdmvsyxetrv.png 3000w\"></figure>", "user": {"username": "Lizka"}}, {"_id": "mTjGkEwvkAr77ja5B", "title": "Consider trying Vivek Hebbar's alignment exercises", "postedAt": "2022-10-24T19:46:41.148Z", "htmlBody": "", "user": {"username": "Akash"}}, {"_id": "o8ps3uC68AFkGivTJ", "title": "My Experience with My Debate Policy", "postedAt": "2022-10-24T18:21:24.552Z", "htmlBody": "<p>Summary: I explain the context for why I have a <a href=\"https://www.elliottemple.com/debate-policy\">public debate policy</a> \u2013 both philosophical reasons and experiences. I talk about fallibilism, rationality and error correction. I discuss how, counter-intuitively, my debate policy saves time and energy for me. I suggest that others create debate policies. This follows my previous article, <a href=\"https://forum.effectivealtruism.org/posts/7urvvbJgPyrJoGXq4/fallibilism-bias-and-the-rule-of-law\">Fallibilism, Bias, and the Rule of Law</a>, which argued in favor of using written rationality policies (which has similar merits to the rule of law).</p>\n<h2>Fallibilism</h2>\n<p>I\u2019m a strong <strong>fallibilist</strong>. I think it\u2019s <em>common</em> to make mistakes without realizing you\u2019re mistaken. And there\u2019s <em>no way to get a guarantee</em> that you haven\u2019t made a mistake about something. We can never correctly have 100% certainty about anything (including fallibilism).</p>\n<p>I\u2019m aware of certain <strong>symmetries</strong> in critical discussions or debates. If I disagree with John, and John disagrees with me, that\u2019s symmetric. Nothing so far indicates that I\u2019m right. If I think John is being an idiot about this issue, and John thinks I\u2019m being an idiot about this issue, that\u2019s again symmetric. Neither of us should conclude that we\u2019re right and the other guy is an idiot; me concluding that I\u2019m the idiot would make equal sense; actually we should both conclude that the situation so far is inconclusive.</p>\n<h2>Asymmetry</h2>\n<p>To conclude that I\u2019m right and John is wrong about some ideas, I need to be able to point out some kind of <em>objective asymmetry</em> (and argue that it\u2019s good). What can I say that John can\u2019t mirror?</p>\n<p>For example, I might say \u201cCapitalism is great because it allows true freedom.\u201d But John could reply \u201cSocialism is great because it allows true freedom.\u201d That\u2019s symmetric. Both capitalists and socialists can make an unexplained, unargued assertion about how great their system is regarding freedom. So far, based on what we\u2019ve said, no difference between capitalism and socialism has been established. If I still think capitalism is better for freedom, it might be due to background knowledge I haven\u2019t yet communicated.</p>\n<p>Trying again, I might continue, \u201cCapitalism gives CEOs the freedom to do whatever they want.\u201d A symmetric reply from John would be \u201cSocialism gives CEOs the freedom to do whatever they want.\u201d But that\u2019s false. It doesn\u2019t. So do we have an objective asymmetry here? Not yet. Capitalism doesn\u2019t actually let CEOs do whatever they want either \u2013 e.g. it doesn\u2019t allow hiring hitmen to assassinate rival CEOs. This time, although John couldn\u2019t mirror my statement to advocate for his side, I still didn\u2019t establish an objective asymmetry because my statement was false.</p>\n<p>Trying again, I might say \u201cCapitalism gives company leadership the freedom to price their products however they want.\u201d John can\u2019t correctly mirror that by claiming socialism gives company leadership full pricing freedom because it doesn\u2019t. Socialism involves central planners (or the community as a whole, or some other variant) having some control over prices. Now we have an actual difference between capitalism and socialism. Next, we could consider whether this difference is good or bad. To reach a conclusion favoring something over something else, you have to establish a difference between them <em>and</em> discuss whether it\u2019s a positive difference. (You should also consider other issues like whether there are some more important differences.)</p>\n<p>So I try to be aware of symmetry and avoid concluding that I\u2019m right when the claims made are symmetrical. Breaking symmetries is fairly hard and requires thoughtful arguments to do well. I also try to consider if a conversation partner <em>could</em> make a symmetrical claim that would be reasonable (or about as reasonable as my own claim or better), in which case I\u2019ll take that into account even if he doesn\u2019t say it.</p>\n<p>I believe that I may be wrong, and my conversation partner may be right, and by an effort we may get closer to the truth (that\u2019s a Karl Popper paraphrase). This fallibilist attitude has led me to be interested in discussion and debate, and to be curious about other people\u2019s reasoning when they believe I\u2019m mistaken.</p>\n<p>If someone thinks I\u2019m wrong, I\u2019d like to rationally resolve that disagreement. If they don\u2019t want to, that\u2019s OK, and that\u2019s an asymmetry: I believe X and I\u2019m willing to argue my case; they believe X is wrong but they\u2019re not willing to argue their case. Stopping with that asymmetry seems fine to me. It\u2019s not ideal but the problem isn\u2019t my fault.</p>\n<h2>Written Criticism</h2>\n<p>When people claim to know I\u2019m wrong about X, I often ask if they know of a criticism of X that I could read. Has anyone ever written down why X is wrong? If they don\u2019t think a refutation of X has ever been written down, then it\u2019s more disappointing if they are unwilling to share their refutation, since they\u2019re claiming it\u2019s a novel contribution to human knowledge that would help me. But it\u2019s still their choice. And actually, if no one has ever written down their reasoning, and they also don\u2019t want to share it, then I\u2019m doubtful that it\u2019s very good, so I\u2019m not very disappointed unless I have some additional reason to think they have a great, unshared point. (If they\u2019ve been working on it for months, and are in the final stages of research or are already writing it up, but they aren\u2019t ready to publish yet, that would be fine and I wouldn\u2019t suspect their point is bad. But that also means I\u2019ll get to read their argument in the reasonably near future.)</p>\n<p>In my experience, reasonable people get the point right away that if there\u2019s no where I can go read why they\u2019re right, and they don\u2019t tell me, then I shouldn\u2019t change my mind, and their side of the debate isn\u2019t persuasive. Meanwhile, if I\u2019m sharing my ideas, then my ideas may be publicly persuasive, unlike the counter-arguments that aren\u2019t public. So they\u2019re conceding the public debate to me, and neutral people looking at the current debate should agree with me over them (since my side has arguments and theirs doesn\u2019t) unless they have some other, better knowledge. There\u2019s a clear asymmetry when I make public arguments, but no one makes public counter-arguments. It\u2019s a case where even a strong fallibilist, who strives for objectivity, can easily take sides (tentatively&nbsp;\u2013 if anyone shares new arguments later then it\u2019s appropriate to reconsider).</p>\n<h2>Intuition</h2>\n<p>People sometimes <em>intuitively</em> think I\u2019m wrong but don\u2019t know how to express their case in words and make good arguments. In that case, there\u2019s an asymmetry because I have arguments in a spoken language and they don\u2019t. If they\u2019re right, it\u2019s hard for me to learn from them and change my mind because they can\u2019t communicate their knowledge to me in words.</p>\n<p>In this scenario, many people would be dismissive and say e.g., \u201cWell, let me know if you ever figure out what your point is in words and I\u2019ll consider it then. Otherwise, I guess this debate is done.\u201d I, instead, have developed some <a href=\"https://criticalfallibilism.com/intuition-and-rational-debate/\">techniques for including and discussing inexplicit intuitions in explicit debates</a>. So, if we wanted to, we could actually continue the discussion using those techniques and still try to reach mutual agreement. If someone has intuitive knowledge which they can\u2019t express in words, I don\u2019t think that\u2019s adequate to conclude that their knowledge is incorrect or inaccessible. We don\u2019t have to give up that easily. Rather than dismissing intuitive ideas, we can  use explicit processes to understand them better.</p>\n<p>A lot of people interested in rationality are pretty dismissive of intuition, and I think that ends up bullying people who aren\u2019t as good at rhetoric, debate and explicit communication. Most people don\u2019t want to engage with the best explicit debaters because they\u2019ll have a bad time. Instead of being helped to express their ideas, they\u2019ll be dismissed when they struggle. I think that\u2019s a tragedy. Besides being mean, it means the majority of people tend to avoid trying to share their knowledge in debates or critical discussions. Some of those people do have important knowledge which they\u2019re being discouraged from sharing.</p>\n<h2>Participating in Low Quality Discussions</h2>\n<p>In the past, if I thought someone was making low quality arguments, I tended to give them second, third, fourth, fifth, sixth and further chances. Why? Because I\u2019m super conscientious and didn\u2019t want to dismiss them if they were still claiming that I\u2019m wrong and they know it. I didn\u2019t want to risk that I\u2019m blind, biased or whatever and then, due to my bias, I refuse to listen to good arguments. And even if their first five arguments are bad, their sixth might be good. As long as they make new arguments, it\u2019s problematic to dismiss that based on a trait of the speaker (his past errors). How can you ignore a new idea just because its author has had incorrect ideas in the past?</p>\n<p>So some of my debates went too long and ended when the other person decided that he didn\u2019t want to talk anymore. That gave me a clear asymmetry to legitimize stopping. It let me believe (correctly) that I was open to further debate and they weren\u2019t. It let me believe (correctly) that they were taking a risk of avoidably staying wrong, while I wasn\u2019t choosing that.</p>\n<p>But it took too much effort. That was less of a problem at first because I was less experienced at critical discussion and debate. So getting more experience in discussions had value to me, even if the quality of the other person\u2019s arguments was poor. However, over time, the mistakes some people made became more and more repetitive instead of interesting, and it became rarer for them to make an argument that was new to me (even a bad one). So I started getting less value for my time spent.</p>\n<p>What could I do to reduce the time I spent on low quality discussions for the sake of being open to debate? I didn\u2019t want to simply refuse to talk to anyone I formed a negative judgment of. I didn\u2019t want to think someone seemed dumb, boring, low quality or not worth my time and then ignore them based on that impression. That kind of policy is widespread and I think it\u2019s one of the world\u2019s larger problems. People commonly form incorrect negative judgments of critics and then are unreasonably dismissive, and it prevents them from receiving valuable corrections. Lots of public intellectuals and thought leaders stay wrong about important issues, and spread errors publicly in books, speeches and articles, while refusing to consider counter-arguments. I really, really, really don\u2019t want to be like that, even a tiny bit.</p>\n<p>So what could I do to end some discussions earlier which is compatible with my strong fallibilism? I don\u2019t want to just trust my judgment about who doesn\u2019t have a good point, which arguments aren\u2019t worth considering, etc. I want to plan around the possibility that I\u2019m sometimes biased, irrational, wrong, etc.</p>\n<h2>My Debate Policy Saves Time and Energy</h2>\n<p>I created a <a href=\"https://www.elliottemple.com/debate-policy\">debate policy</a>. It offers written, conditional guarantees, to the general public, about my openness to debate. If anyone thinks I\u2019m ignoring them when I shouldn\u2019t be, or opting out of a debate I should participate in, they can invoke my debate policy. If I were to violate my policy, I would expect it to harm my reputation.</p>\n<p>You might expect having an open, publicly-available debate policy would result in me spending more time debating. It does not. There are two main reasons for this.</p>\n<p><strong>First</strong>, the debate policy puts certain requirements on the debate. People have to meet some conditions. I tried to design the conditions to be limited, minimalist, and achievable by anyone who has a valuable correction for me. The conditions include agreeing to use my preferred debate structure, which imposes stopping conditions on both of us (certain actions must be taken before leaving the debate).</p>\n<p>I\u2019ve found that the people I thought were unserious, who I believed made low quality arguments, do not want to agree to any kind of formal debate rules. They self-select out of that. They opt out. While abuse of my policy is possible, it hasn\u2019t happened, and it has some anti-abuse mechanisms built in.</p>\n<p><strong>Second</strong>, my debate policy enables me to judge discussions as low value and then stop responding with no explanation or with a link to the debate policy. I\u2019m much more comfortable ending discussions than before because, if my judgment is mistaken, there\u2019s a backup plan.</p>\n<p>Suppose I have a 99% accuracy when I judge that someone is making bad arguments. In the past, I thought \u201cI want to learn from the 1% of cases where I\u2019m wrong, so I better keep discussing.\u201d Now I think, \u201cIf I\u2019m wrong, they can use my debate policy, so there\u2019s still a reasonable way for me to be corrected. So it\u2019s OK to end this discussion.\u201d</p>\n<p>Having a failsafe mechanism lets me be far more aggressive about opting out of discussions. Before I had a failsafe, I was super conservative. But now I\u2019ve moved some of my fallibilist conservatism into the failsafe, and gotten it out of other conversations that don\u2019t use my debate policy.</p>\n<h2>What if My Debate Policy Has an Error?</h2>\n<p>What if I incorrectly opt out of a discussion and also my debate policy has a flaw? As a strong fallibilist, this is the kind of issue I take seriously. I want to have a plan for that too. What is the backup plan for my debate policy?</p>\n<p>I don\u2019t think I need an infinite chain of failsafe mechanisms, but I think having several failsafes is better than one. Variety helps here because I don\u2019t want every failsafe to contain the same flaw.</p>\n<p>The primary backup plan for my debate policy is my <a href=\"https://curi.us/2068-my-paths-forward-policy\">Paths Forward policy</a>, which I actually developed first. When I added the debate policy, instead of making the Paths Forward policy obsolete, I instead specified that it can still be used but only if the debate policy is failing in some way. The Paths Forward policy is more of a broad, generic opportunity for error correction. It\u2019s less safe against abuse or demands on my time, but it\u2019s more conservative and safe against me potentially making a mistake and not listening to good ideas. So it\u2019s good as a secondary failsafe.</p>\n<p>I also have a separate backup plan, which is discussing my debate policy, debate methodology or Paths Forward policy. I\u2019m extra open to discussions on those specific topics, and I\u2019m willing to attempt to discuss them using standard conversational practices in our culture rather than my own preferred discussion methods. I stick much closer to my old conservatism for just those topics. I don\u2019t mind this because I consider them particularly interesting and important topics which I\u2019d actually like to have more discussions about. If you have suggestions for good debate policies or methodologies, or criticism of mine, I especially want to hear it. Overall, being really conservative about avoiding ending discussions on just three topics, instead of all topics, is a big time saver. Plus, it\u2019s uncommon that anyone wants to talk about discussion methodology. I try to bring that topic up sometimes but I find that most people decline to discuss it.</p>\n<p>I\u2019m also open to considering and trying out other discussion or debate methodologies if anyone claims to know of a good, rational methodology that is written down. Although my policy doesn\u2019t guarantee trying any methodology regardless of what it says, this is something I\u2019m especially interested in and flexible about. If someone won\u2019t discuss using my methodology and also won\u2019t suggest a methodology they claim is better, and I\u2019m unimpressed by what they say, then I think it\u2019s definitely reasonable and fallibilism-compatible to stop speaking with them.</p>\n<h2>Prioritizing</h2>\n<p>In the past, I didn\u2019t prioritize much in discussions. Karl Popper and David Deutsch (fallibilists and advocates of evolutionary epistemology) taught me that we learn and make progress by correcting errors. They underemphasized that some errors matter more than others. The general impression they give is basically that you should correct all the errors that you can find. Finding errors is considered a high value activity and one of the two keys to progress (the second key is correcting the errors you find).</p>\n<p>Common sense says to prioritize, but I didn\u2019t find that convincing. It doesn\u2019t adequately explain rational prioritization or why not to correct all the errors (the main reason given is that correcting all the errors would take too long, but I was willing to put a large amount of effort into epistemology in order to try to have better knowledge about it). Doesn\u2019t every error matter?</p>\n<p>One answer is that some people are making too many errors to deal with right now. They\u2019re making an overwhelming number of errors and they need to focus their limited time, energy and attention on only some errors. They can\u2019t do everything at once. This fits with the standard view pretty well, but no one said it to me. I figured it out eventually. I guess people didn\u2019t want to admit to making so many errors. By pretending they were making a manageable number of errors, they fooled me into thinking every criticism would be useful to them. Once I started seeing most people as making an unmanageable amount of errors, I started prioritizing a lot more for the criticism I shared. I also tried telling them about what I think their situation is, but I got a lot of denials in response. Some people explicitly keep asking me to share every error I see with them, but if I do that they will (predictably to me) be overwhelmed and have a bad time. Oh well. I\u2019m going to follow my best judgment about what to do (which is to prioritize criticism I share), and if they think I\u2019m wrong and genuinely want more thorough criticism from me, they can invoke my debate policy. If they don\u2019t invoke my debate policy, that signals to me that they aren\u2019t really that serious about wanting to hear all the criticism I can come up with.</p>\n<p>I also learned, with the <a href=\"https://www.amazon.com/Goal-Process-Ongoing-Improvement-ebook/dp/B002LHRM2O/\">help of Eliyahu Goldratt</a>, a better perspective on prioritizing. This changed my mind more than practical considerations about people being busy or overwhelmed. In brief summary, optimizing non-bottlenecks doesn\u2019t increase throughput. It\u2019s important to identify constraints in a system \u2013 limiting factors \u2013 and then improve those. Most parts of the system have excess capacity already so improving them isn\u2019t useful. In more philosophical terms, most errors won\u2019t cause failure at current, active goals we care about. Instead, most errors mean we have a little less excess capacity at something but we can succeed without fixing the error. (A different way to frame it is that most \u201cerrors\u201d aren\u2019t really errors because they won\u2019t cause failure at a goal we\u2019re pursuing; less excess capacity isn\u2019t actually an error.)</p>\n<p>As a programmer, I already had experience with this. When you want to speed up slow software, you look for bottlenecks. The slowness isn\u2019t divided equally or randomly around the code. Almost all the time use is in a small number of code paths. So you speed those up and then either you\u2019re done or there are some new slowest places that you work on next. If you speed up code without prioritizing, it\u2019s very unlikely to be effective. Most code paths are already fast enough (they have excess capacity) so optimizing them isn\u2019t useful.</p>\n<h2>A Debate Policy Might Cost Time and Energy for You</h2>\n<p>For some people, having a debate policy would increase rather than decrease the time they spend debating. Why? Because their current policies differ from mine. Instead of being very strongly conservative about ending discussions, due to fallibilism, they currently trust their judgment more and end (or don\u2019t begin) discussions more liberally. I think they would benefit from a debate policy because they\u2019re probably mistaken about some of the times they don\u2019t discuss or end a discussion. Also (as long as you aren\u2019t famous) you might find that people don\u2019t use your debate policy very often. When people do use your debate policy, you may find you <em>like</em> the debates because they meet conditions of your choice that you specified in the policy. Debates that meet your written conditions may be higher quality, on average, than the debates have now. (By the way, you can also make a discussion policy for non-debate discussions.)</p>\n<p>If you are famous and would get too many debate requests, or actually just want to have fewer debates for another reason, there are ways to put harder-to-meet conditions on your debate policy (that are still rational) instead of just giving up on having a policy. There are potential solutions (there\u2019s more information in the resources I link at the end).</p>\n<p>In general, it can be hard to tell the difference between positive and negative outliers. Both look badly wrong and don\u2019t make sense from your current perspective. Outliers can be people who are very different than you or ideas which are very different than your ideas. Positive outliers are the most valuable people to talk with or ideas to engage with. Dismissing people (or ideas) who seem wrong or counter-intuitive, while having no debate policy, means you\u2019re likely to be dismissive of some positive outliers. Even if you try not to do that, what exactly is going to stop it from happening, besides a debate policy? <em>Trying</em> to recognize when something might be a positive outlier is not a reliable method; that\u2019s a form of <em>trusting</em> yourself instead of planning around you sometimes being biased or failing at rationality. (I explain and criticize <em>trying and trusting</em> more in <a href=\"https://criticalfallibilism.com/fallibilism-bias-and-the-rule-of-law/\">Fallibilism, Bias, and the Rule of Law</a>. That article advocates pre-commitment to written rationality policies, which it compares with the rule of law.)</p>\n<p>Debate policies are an example of <em>pre-committing</em> to something, in writing. People tend to avoid this because \u201cWhat if I commit to it and then, when the time comes, I don\u2019t want to do it?\u201d But that\u2019s kind of the point: it\u2019s good to do anyway even if you have biases, intuitions or irrationalities that are resisting it. You can\u2019t trust your judgment when the time comes and you think \u201cI want to get out of this debate for rational, good reasons, not due to bias.\u201d It might actually be bias. In the case where your subconscious is resisting engaging in rational debate, despite your debate policy conditions being met, you should suspect you might be wrong and your debate policy might be your savior. The odds are at least high enough to make an effort</p>\n<p>Like if there\u2019s a 10% chance you\u2019re dealing with a positive outlier, that\u2019s extremely worthwhile to engage with \u2013&nbsp;that\u2019s highly cost effective overall even though it has poor returns 9 out of 10 times. People\u2019s intuitions often have trouble understanding that the cost/benefit ratio is favorable overall even if the large majority of instances are negative. Also, people often intuitively have trouble understanding that discussing with someone who is probably an idiot (90% chance) but might be a genius (10% chance) can actually&nbsp;be more cost-effective to talk with than someone who is guaranteed to well above average. Talking with one genius (large, positive outlier) can provide more benefit than talking with ten smart people.</p>\n<p>The value of positive outliers is highest for experts who already know all the standard stuff and have a hard time making additional progress. When you\u2019re a beginner who doesn\u2019t know much, then finding some above-average knowledge is great. Also, bad ideas can confuse and mislead beginners, but they\u2019re much less dangerous for experts (who already understand why they\u2019re wrong).</p>\n<p>Hunting outliers in conversations (or books) is similar to the venture capitalist investment strategy of looking for outlier companies (\u201cunicorns\u201d) and seeking really big wins. Many of those investors expect and plan to lose money on the majority of their investments.</p>\n<p>If you do have a discussion that part of you doesn\u2019t want to have, due to a pre-commitment or because you think it\u2019s rational to discuss, then you need to try extra hard to be reasonable, unbiased, objective, fair, civil, etc. You need to put more work than normal into thinking about things from other person\u2019s point of view, being curious, avoiding tribalism, etc. It helps to write down what to do in advance, e.g. as a flowchart. When your intuitions don\u2019t like something that you\u2019re doing, you have to either resolve that problem or else, at least, understand that you\u2019re at much higher risk than normal of being unreasonable, being a jerk, being dismissive, being biased, etc.</p>\n<p>Also, if part of you thinks a conversation is valuable but part of you doesn\u2019t want to have it, then you have conflicting ideas. There\u2019s a problem to solve there.</p>\n<h2>Conclusion</h2>\n<p>I prioritize considering, \u201cIf I\u2019m wrong, and you\u2019re right, and you\u2019re willing to share your knowledge, then how will I find out and improve?\u201d I want there to be good answers to that. They need to be robust and resilient. They need to work even if I think you have dumb ideas, you seem unreasonable to me, you seem obviously wrong to me, we get along poorly, you have poor charisma, you are very unpopular, you rub people (including me) the wrong way, we have poor conversational rapport, we\u2019re not friends, you are a member of a rival political tribe or philosophical school of thought, my intuition hates you, my friends hate you, I\u2019m biased against you, you trigger my irrationalities, you seem really weird, and/or your ideas are extremely counter-intuitive to me.</p>\n<p>Debate policies and methodologies are one of the tools that can help you be a good fallibilist who is more seriously open to error correction than most people. Consider creating a debate policy for yourself and also encouraging public intellectuals to make debate policies.</p>\n<h2>Further Reading and Watching</h2>\n<ul>\n<li><a href=\"https://www.elliottemple.com/debate-policy\">My Debate Policy</a></li>\n<li><a href=\"https://www.elliottemple.com/essays/using-intellectual-processes-to-combat-bias\">Using Intellectual Processes to Combat Bias</a></li>\n<li><a href=\"https://criticalfallibilism.com/fallibilism-bias-and-the-rule-of-law/\">Fallibilism, Bias, and the Rule of Law</a></li>\n<li><a href=\"https://www.elliottemple.com/essays/debates-and-impasse-chains\">Debates and Impasse Chains</a></li>\n<li><a href=\"https://fallibleideas.com/paths-forward\">Paths Forward</a></li>\n<li><a href=\"https://criticalfallibilism.com/paths-forward-summary/\">Paths Forward Summary</a></li>\n<li><a href=\"https://criticalfallibilism.com/idea-trees-links/\">Idea Trees</a> can be used to organize debates</li>\n<li>I have a <a href=\"https://curi.us/archives/list_category/114\">How To Discuss</a> blog category</li>\n<li>Video: <a href=\"https://www.youtube.com/watch?v=HWbvdKmkBQA\">My Rational Debate Policy</a></li>\n<li>Video: <a href=\"https://www.youtube.com/watch?v=3sgXB6rNiTI\">Impasse Chains: A Rational Way to Conclude Debates</a></li>\n<li>Video: <a href=\"https://www.youtube.com/watch?v=2CYbLGo0dgs\">Philosophical Impasses: When People Can't Agree</a></li>\n<li>I made a <a href=\"https://curi.us/2368-gigahurt-discussion-videos\">discussion tree</a> when <a href=\"https://curi.us/2363-discussion-with-gigahurt-from-less-wrong\" title=\"discussing social dynamics and conversation\">discussing</a> with Gigahurt from Less Wrong. I shared <a href=\"https://www.youtube.com/playlist?list=PLKx6lO5RmaetSHkYrUkcWTI6QEifkSyHj\" title=\"Playlist of videos\">eight videos</a> showing me making the tree, explaining what I was doing, analyzing the discussion and writing replies.</li>\n</ul>\n", "user": {"username": "Elliot Temple"}}, {"_id": "2daKRCTAshhumowrM", "title": "Metaculus Launches FluSight Challenge 2022/23", "postedAt": "2022-10-24T17:10:51.361Z", "htmlBody": "<figure class=\"image image_resized\" style=\"width:70.09%\"><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/94fb2460fc7e25b396e7325fa78adf553ea0735f2381fe56.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/94fb2460fc7e25b396e7325fa78adf553ea0735f2381fe56.png/w_620 620w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/94fb2460fc7e25b396e7325fa78adf553ea0735f2381fe56.png/w_1240 1240w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/94fb2460fc7e25b396e7325fa78adf553ea0735f2381fe56.png/w_1860 1860w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/94fb2460fc7e25b396e7325fa78adf553ea0735f2381fe56.png/w_2480 2480w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/94fb2460fc7e25b396e7325fa78adf553ea0735f2381fe56.png/w_3100 3100w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/94fb2460fc7e25b396e7325fa78adf553ea0735f2381fe56.png/w_3720 3720w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/94fb2460fc7e25b396e7325fa78adf553ea0735f2381fe56.png/w_4340 4340w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/94fb2460fc7e25b396e7325fa78adf553ea0735f2381fe56.png/w_4960 4960w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/94fb2460fc7e25b396e7325fa78adf553ea0735f2381fe56.png/w_5580 5580w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/94fb2460fc7e25b396e7325fa78adf553ea0735f2381fe56.png/w_6144 6144w\"></figure><p>Every year in the US, influenza causes hundreds of thousands of hospitalizations and tens of thousands of deaths, but the timing and magnitude of the flu season varies, making it difficult to prepare for its impact. <a href=\"https://www.metaculus.com/tournament/flusight-challenge22-23/\">FluSight Challenge 2022/23</a> is Metaculus\u2019s second <a href=\"https://www.metaculus.com/tournament/flusight-challenge/\">annual</a> tournament contributing forecasts to the yearly <a href=\"https://www.cdc.gov/flu/weekly/flusight/index.html\">FluSight</a> forecasting efforts of the Centers for Disease Control and Prevention (CDC).</p><p>Since 2013, the CDC\u2019s yearly competition has engaged academic and private industry forecasting teams to submit weekly predictions supporting more effective public health responses. Flu forecasts by Metaculus and other forecasting teams can be invaluable to healthcare providers, and inform</p><ul><li>Flu vaccination and antiviral treatment timing</li><li>Hospital preparation for large influxes of patients</li><li>Community mitigation strategies</li><li>The distribution of healthcare staff and resources</li></ul><p>Metaculus is proud to again contribute predictions to the CDC FluSight Challenge while strengthening ongoing collaborations with computational scientist <a href=\"https://thomasmcandrew.com/\">Thomas McAndrew</a>, who leads Lehigh University\u2019s Computational Uncertainty Lab, and biostatistician <a href=\"https://www.umass.edu/sphhs/person/evan-l-ray\">Evan Ray</a>, who develops infectious disease forecasting models at the University of Massachusetts at Amherst. For FluSight 2022/23, Metaculus is also collaborating with Georgia Institute of Technology biomedical engineer and lecturer <a href=\"https://bme.gatech.edu/bme/faculty/Todd-Fernandez\">Todd Fernandez</a>.</p><p><strong>A $5,000 prize pool will be awarded after the challenge concludes in May of 2023.</strong></p><h2>Tournament Structure</h2><p>Participants will forecast weekly confirmed flu hospitalizations for six states:</p><ul><li>New York</li><li>Florida</li><li>California</li><li>Texas</li><li>Arizona</li><li>Pennsylvania</li></ul><p>For each state, forecast questions will elicit flu count predictions for dates spaced two weeks apart. These forecasts will serve as inputs to a computational model that will project flu counts for every state and territory in the US. See the <a href=\"https://www.metaculus.com/tournament/flusight-challenge22-23/#model\">Model Description</a> section for more detail.</p><p>Thank you to the forecasting community for sharing your predictions. Your contributions can lead to a more effective public health response and fewer flu-associated hospitalizations and deaths.</p>", "user": {"username": "christianM"}}, {"_id": "ukk5f4bqqBAWbF4Zh", "title": "Lord Martin Rees: an appreciation", "postedAt": "2022-10-24T16:11:52.407Z", "htmlBody": "<p>Other titles I considered:</p><ul><li>Lord Martin Rees\u2019 new existential risk book published: \"<i>If Science is to Save Us\"</i>&nbsp;</li><li>Lord Martin Rees should be on more existential risk introductions</li><li>Lord Martin Rees is a boss</li></ul><p>[Disclaimer:&nbsp;<i>I work at CSER, which Martin co-founded (in some sense he\u2019s my boss), and I know and like him, so I\u2019m biased towards him. However, I\u2019ve mostly referred to objective, verifiable evidence, and others can corroborate.</i>]</p><h1>Summary:&nbsp;</h1><p>Lord Martin Rees is one of the UK\u2019s, and perhaps the world\u2019s, most eminent scientists, has been an advocate of existential risk since at least 2003 (and arguably since the 1970s), and is a charismatic speaker and engaging writer. I\u2019ll argue he should be featured in more \u2018introductions to existential risk\u2019 and should be turned to as a powerful advocate for existential risk reduction - like e.g. Will MacAskill and Toby Ord. In this short piece I\u2019ll give a quick bio and describe some of his work. In part, this post is just an appreciation post \u2013 he\u2019s just recently had his 80th birthday, after all.&nbsp;</p><p><br><img src=\"http://res.cloudinary.com/cea/image/upload/v1667996086/mirroredImages/ukk5f4bqqBAWbF4Zh/dtvtofwafvcrdncdvx3q.png\"></p><p><i>Photo by Hanna-Katrina J\u0119drosz for the New Statesman</i></p><h2>New book</h2><p>The occasion for this post is that his new book has just been published:&nbsp;<a href=\"https://www.politybooks.com/bookdetail?book_slug=if-science-is-to-save-us--9781509554201\"><u>If Science is to Save Us</u></a>. Summary:</p><blockquote><p>There has never been a time when \u2018following the science\u2019 has been more important for humanity. At no other point in history have we had such advanced knowledge and technology at our fingertips, nor had such astonishing capacity to determine the future of our planet.</p><p>But the decisions we must make on how science is applied belong outside the lab and should be the outcome of wide public debate. For that to happen, science needs to become part of our common culture. Science is not just for scientists: if it were, it could never save us from the multiple crises we face. For science can save us, if its innovations mesh carefully into society and its applications are channelled for the common good.</p><p>As Martin Rees argues in this expert and personal analysis of the scientific endeavour on which we all depend, we need to think globally, we need to think rationally and we need to think long-term, empowered by twenty-first-century technology but guided by values that science alone cannot provide.</p></blockquote><p>Coverage:</p><ul><li><a href=\"https://www.telegraph.co.uk/news/2022/09/18/lord-martin-rees-long-term-humans-wont-exist-evolve-something/\"><u>The Telegraph</u></a>.</li><li>New Statesman:&nbsp;<a href=\"https://www.newstatesman.com/encounter/2022/09/martin-rees-interview-boris-johnson-worst-government\"><u>Martin Rees: \u201cThis could be our last century on Earth\u201d</u></a></li><li>The Economist:&nbsp;<a href=\"https://www.economist.com/podcasts/2022/09/20/how-science-can-save-the-world\"><u>How science can save the world</u></a></li></ul><p>&nbsp;</p><h2><strong>Quick bio</strong></h2><p>Martin Rees is a cosmologist and astrophysicist who\u2019s done leading research (500+ papers) on black holes, quasars and the multiverse. He knew Stephen Hawking well (and wrote a very nice obituary for&nbsp;<a href=\"https://www.cam.ac.uk/stephen-hawking-an-appreciation-by-lord-martin-rees\"><u>him</u></a>).</p><p>He\u2019s been the&nbsp;<strong>Astronomer Royal</strong> (previous holders, Halley of \u2018Halley\u2019s Comet\u2019 fame) since 1995. He was the 60th&nbsp;<strong>President of the Royal Society</strong>, 2005-2010 (previous holders Wren, Pepys, Newton, Rutherford, etc). The Royal Society is the UK\u2019s national academy of sciences, and one of the most preeminent in the world. He was&nbsp;<strong>Master of Trinity College</strong>, Cambridge 2004-2012. He was made a Lord, specifically a non-party-political (\u2018crossbench\u2019) member of the House of Lords, in 2005. He\u2019s published 10+ books including:</p><ul><li>From Here to Infinity: Scientific Horizons (UK) / From Here to Infinity: A Vision for the Future of Science&nbsp;</li><li>Just Six Numbers</li><li>Our Cosmic Habitat</li><li>Before the Beginning: Our Universe and Others</li><li>Cosmic Coincidences: Dark matter, mankind and anthropic cosmology</li><li>Gravity\u2019s Fatal Attraction: Black Holes in the Universe</li><li>New Perspectives in Astrophysical Cosmology</li></ul><p>This is all to say he\u2019s one of the UK\u2019s (and perhaps the world) leading scientists.&nbsp;</p><p>&nbsp;</p><h2><strong>Good introductory materials</strong></h2><p>Rees has given two TED talks, which have together been watched 4-5 million times. I think they\u2019re great introductions to the subject.</p><p><strong><u>Can we prevent the end of the world?&nbsp;</u></strong></p><p>1.4 million views across YouTube and <a href=\"https://ted.com/talks/martin_rees_can_we_prevent_the_end_of_the_world\">Ted website</a>.</p><figure class=\"media\"><div data-oembed-url=\"https://youtu.be/tMSU6k5-WXg\"><div><iframe src=\"https://www.youtube.com/embed/tMSU6k5-WXg\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>&nbsp;&nbsp;&nbsp;</p><p><strong><u>Earth in its final century?&nbsp;</u></strong></p><p>3.9 million views across YouTube and <a href=\"https://www.ted.com/talks/martin_rees_is_this_our_final_century \">Ted website</a>.</p><figure class=\"media\"><div data-oembed-url=\"https://youtu.be/3qF26MbYgOA\"><div><iframe src=\"https://www.youtube.com/embed/3qF26MbYgOA\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>&nbsp;</p><p>Several of his books are specifically on existential risk:</p><ul><li>&nbsp;<a href=\"https://www.politybooks.com/bookdetail?book_slug=if-science-is-to-save-us--9781509554201\"><u>If Science is to Save Us</u></a></li><li><a href=\"https://press.princeton.edu/books/hardcover/9780691180441/on-the-future\">On the Future: Prospects for Humanity</a></li><li>Our Final Century: Will Civilisation Survive the Twenty-first Century? (UK) / <a href=\"https://en.wikipedia.org/wiki/Our_Final_Hour\">Our Final Hour: A Scientist\u2019s Warning</a> (US)</li></ul><p>I think these should be included on \u2018introduction to existential risk\u2019 reading lists as very engaging and credible intros.</p><p>&nbsp;</p><h1><strong>Notable contributions to existential risk research</strong></h1><p>Martin Rees has been a major populariser of existential risk - and has also made core intellectual contributions.</p><p>&nbsp;</p><h2><u>General</u></h2><p>Most importantly, Martin was really early to existential risk - \u2018Our Final Century\u2019 was published in 2003, around the time Nick Bostrom was getting going.</p><p>He co-founded the Centre for the Study of Existential Risk at Cambridge University in 2012 - and helped advise on the founding of other centres, e.g. the Future of Life Institute in 2014. He was an early sponsor of the&nbsp;<a href=\"https://www.appgfuturegenerations.com/\"><u>APPG for Future Generations</u></a>. He played an important role in setting up the Lords Select Committee on Risk Assessment and Risk Planning, which published the 2021 report&nbsp;<a href=\"https://publications.parliament.uk/pa/ld5802/ldselect/ldrisk/110/11002.htm\"><u>Preparing for Extreme Risks: Building a Resilient Society</u></a>.</p><p>As Astronomer Royal, his views on space carry particular weight. He\u2019s the most prominent critic of the argument that colonising Mars is a good way to reduce existential risk (see e.g.&nbsp;<a href=\"https://www.theguardian.com/science/2019/aug/18/martin-rees-astronomer-royal-interview-brexit\"><u>Guardian</u></a>,&nbsp;<a href=\"https://www.vox.com/future-perfect/2018/10/22/17991736/jeff-bezos-elon-musk-colonizing-mars-moon-space-blue-origin-spacex\"><u>Vox</u></a>). He\u2019s also closely involved with SETI, where he\u2019s been one of the leading voices&nbsp;<a href=\"https://astronomy.com/news/2022/09/seti-why-extraterrestrial-intelligence-is-more-likely-to-be-artificial-than-biological\"><u>suggesting</u></a> that any signs of extraterrestrial life are far more likely to be digital/artificial than biological, and this should shape SETI\u2019s search.</p><p>Long before 2003, he was involved in the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ggiCDnYcSKLxwFbBv/the-pugwash-conferences-and-the-anti-ballistic-missile\"><u>Pugwash Conferences</u></a> in the 1970s - one of the only opportunities for scientists from either side of the Iron Curtain to engage with one another. Martin sometimes describes the current generation of existential risk activists and researchers as perhaps the third wave of concern around existential risk. First the \u2018concerned scientists\u2019 that participated in the Manhattan Project, set up the Bulletin of the Atomic Scientists and successfully \u2018tabooed\u2019 the use of nuclear weapons in the 1950s. This is the generation he looked up to. Then the second, the Pugwash scientists of the 1960s and 70s that contributed to the arms control agreements: the Biological Weapons Convention and the Strategic Arms Limitation Talks (SALT) treaties. I find this sense of history and tradition very motivating. We didn\u2019t come up with all of this all on our own: we\u2019re part of a wider story and can build on their successes.</p><h2><br><u>Climate change</u></h2><p>One particularly notable example on climate is his work at the Vatican. In May 2014, he helped Sir Partha Dasgupta co-organise a major workshop with the Pontifical Academy of Sciences on climate change. After the workshop, Sir Partha spoke to the Pope directly and encouraged him to include climate change in his speeches and to urge people to be better stewards of the planet. The workshop underpinned a major&nbsp;<a href=\"https://www.pas.va/en/publications/extra-series/es41pas.html\"><u>report</u></a> published in April 2015 by the Vatican. The report in turn partly informed the May 2015&nbsp;<a href=\"https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html\"><u>Laudato si\u2019</u></a> Papal Encyclical, which focussed on the impending threat of climate change and was&nbsp;<a href=\"https://en.wikipedia.org/wiki/Laudato_si%27\"><u>influential</u></a> in encouraging the 1.3 billion Catholics worldwide to support for the Paris Agreement, agreed in December 2015.</p><p>Martin also contributed to&nbsp;<a href=\"https://www.cser.ac.uk/media/uploads/files/Global_Apollo_Programme_Report.pdf\"><u>A Global Apollo Programme To Combat Climate Change</u></a> (June 2015), an early and prominent call for major R&amp;D into clean energy, now widely seen as perhaps the most important contribution philanthropists and Western governments can make; and&nbsp;<a href=\"https://www.gov.uk/government/news/uk-us-china-and-india-experts-release-independent-climate-change-risk-assessment\"><u>Climate Change: A Risk Assessment</u></a> (July 2015), an early and prominent analysis of worst case scenarios which again encouraged the Paris Agreement.</p><p>None of this is to say he was one of the most important figures, simply to say he was an early and prominent advocate.<br>&nbsp;</p><h2><u>Biorisk</u></h2><p>Martin was also an early and prominent voice warning about biorisks. For example, in 2017 he made a famous bet (described as the&nbsp;<a href=\"https://unherd.com/thepost/will-steven-pinker-lose-the-bet-of-the-century/\"><u>bet of the century</u></a>) with Stephen Pinker that \u201cA bioterror or bioerror will lead to one million casualties in a single event within a six month period starting no later than Dec 31 02020.\u201d (It has not resolved yet, due to lack of clarity on whether Covid-19 was a lab leak or natural emergence.)</p><p>&nbsp;</p><h2><u>Personal</u></h2><p>On a personal (almost gushy) note, Martin is kind, supportive, and encouraging to junior colleagues. Lots of CSER staff, and former Cambridge students, will have stories of his warmth and support.</p><p>Many senior academics or thought-leaders can be spiky and dismissive to junior colleagues. This is true of academia general, and unfortunately can sometimes be true in existential risk and AI alignment. I think Martin shows this is completely unnecessary. He\u2019s got about as high up as one can get in science and academia - and is just really nice. Martin is a great role model for the field.</p>", "user": {"username": "HaydnBelfield"}}, {"_id": "d83HJFMnEvP6x6LaD", "title": "UGAP Starter Program Retrospective ", "postedAt": "2022-10-24T15:55:54.202Z", "htmlBody": "<h2>TLDR</h2><ul><li>The CEA uni groups team piloted running a starter program before the University Group Accelerator Program (<a href=\"https://www.google.com/url?q=https://www.notion.so/centreforeffectivealtruism/University-Group-Accelerator-Program-6df8c8fccf8b4ffbb6488d9dfa275282&amp;sa=D&amp;source=editors&amp;ust=1666628685329799&amp;usg=AOvVaw22mqWGJovXZGlKnEnk6JCA\"><u>UGAP</u></a>)&nbsp;to:<ul><li>Provide resources to more groups.</li><li>Gain more context on groups to see whether UGAP was right for them.</li><li>Improve our mentor-group matching.</li></ul></li><li>We had 81 groups participate in the starter program from over 20 countries.</li><li>We faced challenges due to rapid scaling, capacity constraints, and trying to accommodate different target audiences. We are pleased with the results and are glad we scaled quickly but have noted many improvements to be made going forward.</li><li>We found that having the starter program separate from UGAP was confusing for organizers and that we would like both programs to have the same criteria for admissions. We also were able to better provide specific start-of-the-year resources to newer groups.</li><li>Therefore, next semester we will integrate the starter program into UGAP as one single program. This program will likely be open <i>only to </i>new groups. We are looking into different programming for existing groups such as a continued mentorship network (which will be explained further in a future post)</li></ul><p>&nbsp;</p><p>This post is part of our efforts to communicate more transparently what we are doing. This is the first post in a series of posts and will serve as mostly an update about the starter program specifically. Future posts will dive further into our strategy, Metrics &amp; Evaluation (M&amp;E), and our future plans.</p><p>&nbsp;</p><h2>What was the UGAP Starter Program?</h2><p>We had a <a href=\"https://www.google.com/url?q=https://www.notion.so/centreforeffectivealtruism/University-Group-Accelerator-Program-6df8c8fccf8b4ffbb6488d9dfa275282%23dfaa9dc82f5a42e581a28e8d0e1e9572&amp;sa=D&amp;source=editors&amp;ust=1666628685331986&amp;usg=AOvVaw1TkBB8CQPp8NjAukInQBRu\"><u>virtual two-week</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref[object Object]\"><sup><a href=\"#fn[object Object]\">[1]</a></sup></span><a href=\"https://www.google.com/url?q=https://www.notion.so/centreforeffectivealtruism/University-Group-Accelerator-Program-6df8c8fccf8b4ffbb6488d9dfa275282%23dfaa9dc82f5a42e581a28e8d0e1e9572&amp;sa=D&amp;source=editors&amp;ust=1666628685332354&amp;usg=AOvVaw2PKQNvO5f8ZWpsL_NwmC10\"><u>&nbsp;starter program</u></a>&nbsp;that was open to a larger group of schools than UGAP itself. It provided groups with virtual training and resources to prepare for the semester. This was our first time running this program and 81 universities participated, of which 56 were accepted to UGAP.</p><p>&nbsp;</p><p>Groups were given a starter program guide that pointed to specific resources, attended a kickoff session focused on strategy and getting ready for the semester<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref[object Object]\"><sup><a href=\"#fn[object Object]\">[2]</a></sup></span>, and had a meeting with one of our starter program mentors where they <a href=\"https://www.google.com/url?q=https://docs.google.com/document/d/1naqqzoJizWpup911ZnavN_v6ZFK2WLnTZRAWHqmJ0uw/edit&amp;sa=D&amp;source=editors&amp;ust=1666628685333160&amp;usg=AOvVaw17L7zM63pkIYWo2Dl9tY0J\"><u>discussed a plan for the coming semester</u></a>. Participants who were preparing to facilitate fellowships were able to participate in <a href=\"https://www.google.com/url?q=https://forum.effectivealtruism.org/posts/MZFWRh7vzEDZ8mnYT/group-discussion-facilitator-training-guide&amp;sa=D&amp;source=editors&amp;ust=1666628685333487&amp;usg=AOvVaw0pQLP3juEmywvdbLgNSJb0\"><u>facilitator training</u></a>&nbsp;through EA Virtual Programs. We also offered two optional workshops, one on outreach and another on reasoning.</p><p>&nbsp;</p><p>During the program, individuals from groups were invited to apply for UGAP where they could receive continued mentorship and a stipend. Ultimately, 56 groups ended up having at least one organizer participate in UGAP (which is going on now).</p><p>&nbsp;</p><h2>Why the starter program?</h2><p>Overall, the starter program itself aimed to provide the following:</p><ul><li>Help advise and steer group strategy for new groups<ul><li>We think that group strategy is one of the highest leverage ways to make a big difference in group outcomes. We go over the core of our current advice in <a href=\"https://www.google.com/url?q=https://forum.effectivealtruism.org/posts/ko5fDSHFsJ35v6HMa/some-advice-the-cea-groups-team-gives-to-new-university&amp;sa=D&amp;source=editors&amp;ust=1666628685334467&amp;usg=AOvVaw3bAGpL4RUDFpgieMLJrO_3\"><u>this post.</u></a></li></ul></li><li>Increase motivation and excitement about running a group<ul><li>We focused on why we believe community building at universities can be so impactful, tried to create the sense of being part of a much larger international project, and expressed encouragement and gratitude to organizers.</li></ul></li><li>Make sure groups were ready for the start of the semester<ul><li><a href=\"https://www.google.com/url?q=https://forum.effectivealtruism.org/posts/tXSXvqTPwgWtYWFqR/the-importance-of-optimizing-the-first-few-weeks-of-uni-for&amp;sa=D&amp;source=editors&amp;ust=1666628685335528&amp;usg=AOvVaw2MPEY8_iIWqfeaNsvm4J_z\"><u>We think the start of the semester is one of, if not the most important time of the year for university groups</u></a>. We wanted to make sure that groups were going into the semester with a plan and the resources they needed.</li></ul></li></ul><p>&nbsp;</p><p>Running the starter program <i>separate from UGAP</i>&nbsp;was an experiment to do the following:</p><ul><li>Provide resources to a larger number of groups, unconstrained by UGAP mentor capacity.<ul><li>Last summer we realized that there was a lot of interest in UGAP. While we only had ~30 groups participate in the Spring, our interest form had ~50 additional groups interested. We knew we would get even more applications than this and were unsure of how much mentor capacity we would have. We wanted to at least provide some of the resources to more groups.</li><li>Some of the interested groups were not brand new and we wanted to experiment with whether we could also have newer organizers from existing groups participate in the starter program.</li></ul></li><li>Help us to identify which groups were ready for and would get the most out of UGAP and improve our mentor-group matching after gaining more context on groups during the starter program.<ul><li>Last semester we had some sub-optimal matching because we were matching groups with mentors based on limited information.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref[object Object]\"><sup><a href=\"#fn[object Object]\">[3]</a></sup></span>&nbsp;We thought the starter program would give us a chance to gain more context on groups so as to get a sense of their readiness and match them better.</li></ul></li></ul><h2>&nbsp;</h2><h2>Results</h2><p><i>Note: Since the starter program occurred before the semester started and most downstream metrics that we care about wouldn\u2019t be accessible until later or the end of the semester, our feedback form mostly revolved around the user experience rather than outcomes. We will be running another survey at the end of the semester to focus more on outcomes.</i></p><p><i>UGAP is still ongoing so these results only reflect the starter program.</i></p><h3>&nbsp;</h3><h3>Overall</h3><p>We had 81 groups participate in the starter program with generally good feedback about the program:</p><p>&nbsp;</p><p><img src=\"http://res.cloudinary.com/cea/image/upload/v1667995605/mirroredImages/d83HJFMnEvP6x6LaD/kkuxfwynybrwvmxrwi6s.png\"></p><p>LTR = 8.63</p><p>&nbsp;</p><p><img src=\"http://res.cloudinary.com/cea/image/upload/v1667995605/mirroredImages/d83HJFMnEvP6x6LaD/ouwtchr5a91znobwy6l3.png\"></p><p>(Purple is cut off but is \u201cStrongly Agree\u201d)</p><p>&nbsp;</p><p>Overall, we think these results are decent but not great. We think this indicates that this program is generally helpful on these dimensions but has the potential to be more so.</p><p>&nbsp;</p><h3>Specific Aspects</h3><p>More details are listed in <strong>Appendix A </strong>but some takeaways for specific aspects were:</p><p>&nbsp;</p><p>Top 3 most helpful aspects:</p><p>&nbsp;</p><ul><li>Mentor meetings were very popular and mentioned the most times as being the most helpful aspect of the program (mentioned by 18 organizers in free response)</li><li>The resource guide was comprehensive and helpful (mentioned by 16 organizers in free response)</li><li>The outreach workshop and materials were also popular (mentioned by 7 organizers in free response)</li></ul><p>&nbsp;</p><p>Top 3 least helpful aspects (pulled from multiple questions):</p><ul><li>Kickoff was repetitive (especially for more experienced organizers)</li><li>Unclear communication around timings, dates, and general processes</li><li>Some physical materials that were sent arrived late and/or were low quality</li></ul><p>&nbsp;</p><h2>What we learned</h2><ul><li>We had hoped to provide resources to a larger number of groups, unconstrained by UGAP mentor capacity.<ul><li>We ended up not being bottlenecked by mentor capacity as expected.</li><li>We also found it difficult to provide useful common programming for groups in different stages of development.<ul><li>We created UGAP originally because we have a decent model of how to start up a university group. We have some generalizable advice and lessons learned from our experience here. So, we were able to scale that advice via a program.</li><li>We are much less sure about what the ideal model of a more advanced group is and would like to see more experimentation. Therefore we have less generalizable advice for these groups,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref[object Object]\"><sup><a href=\"#fn[object Object]\">[4]</a></sup></span>&nbsp;and so the general resources were less useful for these groups.</li></ul></li><li>We think we are best suited to provide the type of support in the starter program to <i>new groups</i>&nbsp;and do not expect the number of <i>new groups </i>to exceed our mentor capacity. Therefore, we don\u2019t expect the need to have a separate starter program in the future. We are hoping to provide a separate product to more experienced groups in the future.</li></ul></li><li>We had hoped that the starter program would help us to identify which groups were ready for and would get the most out of UGAP.<ul><li>We realized that it made more sense to have higher expectations regarding EA knowledge and community building strategy of starter program participants than we initially believed. We now think the bar for receiving resources via the starter program should have been more similar to our bar for being ready for the full UGAP.</li><li>We think the starter program may have been too encouraging to a few groups who were not ready to start (i.e. because their main organizers needed to spend some more time learning about and engaging with EA before starting a group).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref[object Object]\"><sup><a href=\"#fn[object Object]\">[5]</a></sup></span></li></ul></li></ul><p>&nbsp;</p><h2>What went wrong</h2><ul><li>Trying to do screening while providing resources and mentorship to groups was suboptimal.<ul><li>We were not able to give as much support to groups and made some organizers feel more like they were in interviews than mentorship calls. This was confusing and unclear to a number of organizers.</li></ul></li><li>We underestimated the toll on capacity we would have from events and onboarding new team members.<ul><li>We knew these would take a toll on our capacity but they took even more than we expected. This led us to miss some deadlines, have suboptimal communication with participants, and underdeliver on some resources.</li><li>We tried to scale really quickly while onboarding two new team members. While the timing wasn\u2019t great, I don\u2019t currently think that we scaled <i>too</i>&nbsp;quickly. I think <a href=\"https://www.google.com/url?q=https://forum.effectivealtruism.org/posts/LwRSnvnaFL9eE4yKz/invisible-impact-loss-and-why-we-can-be-too-error-averse&amp;sa=D&amp;source=editors&amp;ust=1666628685341788&amp;usg=AOvVaw1_JGd0Og3BafE2BVzGntTP\"><u>it is a lot easier to notice mistakes than missed impact</u></a>&nbsp;and my guess is a smaller program would have been cleaner and more put together but would have left impact on the table.</li></ul></li></ul><p>&nbsp;</p><p>We have a longer list of mistakes we made and things we are hoping to do differently in <strong>Appendix&nbsp;B</strong></p><h2>Looking forward</h2><p>As mentioned at the start of this post, we are planning on releasing a series of posts over the next few months detailing our future plans. Our next post will include what else the Uni Groups team will be doing and what other types of support we will be providing. Specifically related to UGAP and the starter program, we intend to run a narrower version of UGAP that is open to <i>only </i>new groups, which will include some components of the starter program. We do not intend to run the starter program as an independent offering next semester.</p><ul><li>This will allow us to keep providing a more tailored program with product-market fit. &nbsp;</li><li>We think it is a useful and important service to keep making it easy for new university groups to start (or restart) which we will cover more in a future post.</li></ul><p>&nbsp;</p><h1>Appendix</h1><h2>Appendix A: Additional data from feedback survey</h2><p>&nbsp;</p><h3>(Free response) What was the most helpful element of the starter program?</h3><p>&nbsp;</p><p>Summary</p><ul><li>Mentor Meeting 18</li><li>Resources (general) 16</li><li>Resources (outreach) 7</li><li>Meeting others 4</li><li>Strategy 2</li><li>Facilitator training 2</li><li>Slack 1</li><li>Facilitator guide 1</li><li>Outreach workshop 1</li><li>Reasoning workshop 1</li><li>Kickoff 1</li><li>Semester planning 1</li><li>Website template 1</li><li>Psychological stuff? (motivation, accountability, inspiration) 1</li><li>Structure 1</li></ul><p>&nbsp;</p><h3>(Free response) What was the least helpful element of the starter program?</h3><p>Summary</p><ul><li>Kickoff meeting 5</li><li>Asana 4</li><li>Reasoning workshop 4<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref[object Object]\"><sup><a href=\"#fn[object Object]\">[6]</a></sup></span></li><li>Mentor Meeting 3</li><li>Communication 3</li><li>Community bonding 1</li><li>One meeting with a mentor was not enough 1</li><li>Could have been good to have more iterations of the workshops run 1</li><li>Perhaps the comprehensive-seemingness of it made us less likely to experiment (we had already run one intro fellowship) 1</li><li>Notion 1</li><li>Website template 1</li><li>Decentralized information 1</li></ul><p>&nbsp;</p><h3>(Free response) How did your group strategy change, if at all from the starter program?</h3><p>&nbsp;</p><p>Summary:</p><ul><li>20 individuals listed strategy changes we were actively enthusiastic about</li><li>These were usually shifting more towards the advice in<a href=\"https://www.google.com/url?q=https://forum.effectivealtruism.org/posts/ko5fDSHFsJ35v6HMa/some-advice-the-cea-groups-team-gives-to-new-university&amp;sa=D&amp;source=editors&amp;ust=1666628685346467&amp;usg=AOvVaw3G-YaT9VROu24iNX-pElRI\"><u>&nbsp;this post</u></a></li><li>7 listed strategy changes which we think we are unsure about (but usually positive)</li><li>These might include things like increased outreach for which our enthusiasm depends on context</li><li>1 listed a strategy change we were slightly concerned about.</li><li>This was somewhat opposite to our advice in <a href=\"https://www.google.com/url?q=https://forum.effectivealtruism.org/posts/ko5fDSHFsJ35v6HMa/some-advice-the-cea-groups-team-gives-to-new-university&amp;sa=D&amp;source=editors&amp;ust=1666628685347158&amp;usg=AOvVaw3x6YFRptceZhR3dRlUIyH5\"><u>this post</u></a></li></ul><h3><img src=\"http://res.cloudinary.com/cea/image/upload/v1667995606/mirroredImages/d83HJFMnEvP6x6LaD/uicgmpod6l2pxyg5a3yi.png\"></h3><h3>&nbsp;</h3><h3>(Free response) Was there anything else not on these lists that you found helpful/unhelpful?</h3><p>Summary:</p><p>&nbsp;</p><p>Helpful:</p><ul><li>Outreach workshop and templates 3</li><li>Slack channel 2</li><li>Facilitator guide &nbsp;1</li><li>Getting materials: 1</li><li>Meeting other group organizers 1</li><li>Funding 1</li><li>Meeting someone at CEA 1</li></ul><p>&nbsp;</p><p>Unhelpful:</p><ul><li>Late physical materials: 3</li><li>Poor communication: 3</li><li>Kickoff session: 2</li><li>Getting to know each other (Kickoff session): 1</li><li>Too many resources (slack, asana, notion): 1</li></ul><p>&nbsp;</p><p><img src=\"http://res.cloudinary.com/cea/image/upload/v1667995605/mirroredImages/d83HJFMnEvP6x6LaD/ylguefvat2sarpafdnhz.png\"></p><h3>(Free Response) Any other feedback about the above resources or events?</h3><p>Summary</p><ul><li>Unclear communication(timing, dates, process in general) 4</li><li>Mentor-meeting felt like a job application/interview &nbsp;2</li><li>Things about basic EA ideas (in kickoff) were less useful/ kickoff was repetitive of readings 2</li><li>Too much bonding in the training sessions 2</li><li>Facilitator training was helpful 1</li><li>Asana was more helpful last year 1</li><li>The resources were nice 1</li><li>Wants more discussions on concrete ideas regarding community building 1</li><li>The readings were insightful 1</li><li>Program recommended for new groups, not really for experienced ones 1</li><li>It would be good to have leadership training 1</li><li>Save-function on the form was not reliable 1</li><li>The calendar was a useful template but was modified to show week by week 1</li><li>The materials were late but glad to have them 1</li><li>Too many different platforms to organize 1</li></ul><h3>(Free Response) What were your main takeaways from kickoff?</h3><p>Summary:</p><ul><li>19 individuals listed takeaways we were actively excited about</li><li>3 individuals listed their main takeaways as being negative</li><li>i.e. because the presentation was too slow/repetitive or at an inconvenient time</li></ul><p>&nbsp;</p><h2>Appendix B: List of additional mistakes and future improvements</h2><p>This is mostly to be transparent about mistakes we made and plans to fix them. These are based on user feedback. We have additional internal improvements we are planning on making. We are planning improvements now and will have additional capacity to address them. However, we still anticipate being capacity constrained and will consider the program in perpetual beta.</p><p>&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>Mistake/Improvement</strong></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><strong>When are we planning on making this change (if at all)</strong></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Centralize information</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Next round by not using asana for onboaring</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Better communication and deadlines</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Next round by dedicating additional resources to communication and planning deadlines further in advance</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">The decision about being admitted to UGAP earlier</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">N/A (SP and UGAP will be combined)</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Having a more organized shipping process for physical materials</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Stalling this until a better system can be made (likely in Spring)</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Having asynchronous options with retention checks</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Next round (hopefully!)</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Having all mentors read over the document before the meeting</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Next round</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Everything on google calendar from the get-go</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Next round</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Improving kickoff session to be less repetitive</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Next round</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Asana as an optional resource</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Next round</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">More resources on templates around newsletters</td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Possibly in the future</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>Make a group for solo founders</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Possibly in the future</td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\"><p>Include leadership training</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;vertical-align:top\" colspan=\"1\" rowspan=\"1\">Possibly in the future</td></tr></tbody></table></figure><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzu5f6uc5vfp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzu5f6uc5vfp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;It ended up being longer than two weeks to finish all of the mentor calls since we had about 75 of them.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnckfjag4tqq7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefckfjag4tqq7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;All of the non-program specific resources can be found on the <a href=\"https://www.google.com/url?q=https://resources.eagroups.org/home&amp;sa=D&amp;source=editors&amp;ust=1666628685359531&amp;usg=AOvVaw2FSMsbZTaWMePFmxZlAARl\"><u>EA Groups Resource Centre</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaal8ad9teqv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaal8ad9teqv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Some mentors are stronger in helping make groups more organized and operationally healthy while others are stronger in helping guide overarching strategic decisions. Based on the groups\u2019 strengths and weaknesses, we wanted to give them complimentary matches.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0ru23qa1mtr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0ru23qa1mtr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;One of the reasons we are thinking of focusing solely on mentorship for experienced groups in the near-future is because it is more easily customizable to different situations.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4d1u141rilp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4d1u141rilp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Notably, we now think more strongly that suboptimal EA groups might not just miss out on value, <a href=\"https://www.google.com/url?q=https://forum.effectivealtruism.org/posts/xomFCNXwNBeXtLq53/bad-omens-in-current-community-building&amp;sa=D&amp;source=editors&amp;ust=1666628685360271&amp;usg=AOvVaw3l8G0J6YM4UKUz8J9KhSql\"><u>but might actually be net-negative by turning off particularly promising individuals</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndbr6iwqms2o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdbr6iwqms2o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Our guess about the reasoning workshop was that it was too basic for most of the people who opted into it but would have been good for people newer to rationality techniques</p></div></li></ol>", "user": {"username": "jessica_mccurdy"}}, {"_id": "THSErFoqS6vtimiud", "title": "Which are the best conferences to attend that are not EAGs? ", "postedAt": "2022-10-24T13:21:58.372Z", "htmlBody": "<p>Hi! I'm wondering if anyone has any recommendations for good conferences to attend that are not EAGs?</p>\n<p>Of course, I understand that it depends on what you are working with, so I'm asking mainly for someone working on technological development, but I would also be curious if there are any generally future-focused conferences out there (similar to what Future Forum was this year)?</p>\n<p>Also wondering if anyone has any recommendations for a good website to find conferences.</p>\n", "user": {"username": "elteerkers"}}, {"_id": "jsee8Fv5vGaPMxsST", "title": "Looking for any feedback on a product prototype", "postedAt": "2022-10-24T14:09:30.928Z", "htmlBody": "<p>Hi :) there</p><p>I am thinking about creating a wearable device that could track your attention when you're using the computer, such that it provides simultaneous input to the computer to execute timely the action you want, like left-clicking the mouse for closing down the browser.&nbsp;</p><p>I believe this is theoritically possible by collecting and analyzing the brainwave data collected above the skull (non-invasive, without surgeries), but I am unsure if the existence of such a thing &nbsp;(which automates the execute of user demands on the computer in a hand-free way) is desirable for the general populations who aren't disabled.&nbsp;</p><p>Is it in any way can you imagine such a decive would prove to be more advantageous than traditionally engaging hands for using the computer? Do you want to wear such a device for work on office? Thank you so much for feedbacks!</p>", "user": {"username": "Sherry "}}, {"_id": "nf4nD4uNA4oTeAmR4", "title": "Education not meant for mass-consumption", "postedAt": "2022-10-24T14:09:43.369Z", "htmlBody": "", "user": {"username": "Tolo"}}, {"_id": "qMNGM4sZJ5PvayfHQ", "title": "Some frames I liked from Atlas", "postedAt": "2022-10-24T11:20:34.207Z", "htmlBody": "<p><i>(I instructed at three Atlas Fellowship summer programs, but this post is written in a personal capacity)</i></p><p>Of the principles, flags, cultural pillars, opening session tips, and tidbit-sized lessons I heard (and delivered) at the three Atlas Fellowship summer programs I worked at, here were my two personal favorites:</p><h2><strong>Big if True</strong></h2><p>During the program, the instructors sometimes described the content as guided by what\u2019s \u201cbig if true\u201d, to point to what\u2019s most interesting and valuable to talk and learn about.&nbsp;</p><p>\u201cBig if True\u201d tries to separate the processing of novel-to-you, potentially-wild-sounding things - e.g. AGI, nanotech,&nbsp;<a href=\"https://ourworldindata.org/less-democratic\"><u>the decline of democracy</u></a> - into two stages:&nbsp;</p><ol><li>what would it mean for it to be true / how you would act differently if it were true</li><li>evaluating whether it\u2019s true.</li></ol><h3>What I like about it:&nbsp;</h3><p>The two stage process explicitly flags that we haven\u2019t yet figured out if the idea or claim is reasonable or true, and nonetheless lets the conversation continue, ideally creating a space for curiosity, playing around with the ideas and deciding how important exactly it would be if true, while still noting that we have work left to do.&nbsp;</p><p>For me, it also hints that there must be many such Big If True ideas out there and pushes me to think of more, and a bit it gives me a push to just spend more of time thinking about things that are going to matter and that a hundred or a thousand or more years from now&nbsp;<a href=\"https://www.cold-takes.com/why-talk-about-10-000-years-from-now/\"><u>we\u2019ll be glad we were talking about</u></a>. (I think the instructors\u2019 goal in presenting this at the program was to have more of this latter feeling than I feel left with, a few months later, but writing this is a nice reminder that I\u2019d like to find more opportunities for marinating in the long view).</p><p>This seems great for having a playful, exploratory attitude to the world, and noticing that there is so much that could be different, if we decided it should be, or even just if we wait a few decades or centuries. It also sets a tone similar to engaging with the&nbsp;<a href=\"https://www.lesswrong.com/posts/neQ7eXuaXpiYw7SBy/the-least-convenient-possible-world\"><u>Least Convenient Possible World</u></a>, not squirming away from things just because they\u2019re strange or sound fantastical.</p><h3>What\u2019s more complicated:&nbsp;</h3><p>It ports in a lot under \u201chow big\u201d and \u201chow true\u201d - Christianity is also Big if True, but wasn\u2019t likely enough to be true that I or I would guess most of the instructor staff would have included it in the Atlas curriculum (it's also not our comparative advantage for the most part, but that's a different point).</p><p>It also implicitly advocates for engaging with ideas in the order \u201cconsequences if true\u201d then \u201ctrue\u201d, which I think it\u2019s reasonable to object to, and it sort of gives someone else the power to decide when it\u2019s \u201cok\u201d to start evaluating for truth.&nbsp;</p><p>If using this frame, I want to be sure to be&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/uMNhoAoxDoYDnBoqd/transparency-for-improving-weird-feelings-around-community\"><u>transparent</u></a> about whether I have an opinion on the \u201ctrue\u201d part of \u201cbig if true\u201d, or else I suspect I risk <a href=\"https://forum.effectivealtruism.org/posts/jCgZzxsabngpnzhLQ/the-onion-test-for-integrity\">people feeling tricked</a>. If I\u2019m inviting someone into a \u201cwe don\u2019t know if microplastics are bad, but we should figure out what to do if they are\u201d space, I want to be clear about whether I in fact think microplastics are bad, which seems very doable!</p><p>I also worry it lives in tension with \u201ctake ideas seriously\u201d - in general it came up in several conversations this summer that the mode of \u201cintellectual playfulness, thought experiments, etc\u201d, an excellent mode for generativity and exploration, was different than the mode of \u201chow does this actually affect my life, how do I see things in near mode, etc\u201d, and you might need to flag for yourself when you want to do which one and be able to switch (or maybe there\u2019s a better synthesis possible).&nbsp;</p><p>There\u2019s potentially also another necessary puzzle piece of \u201cok, now what\u2019s actually true, what are our current key uncertainties, how do we go find out.\u201d But it\u2019s ok for one phrase not to communicate every possible necessary thing, that\u2019s why you have:</p><h2><strong>Frames&nbsp;</strong></h2><p><i>(thanks to Max Harms for this, though I might describe what\u2019s going on with it differently to how he would)</i></p><p>Or lenses, or paradigms, the frames frame invites a third option beyond \u201cyes\u201d or \u201cno\u201d but \u201clet me pick this up for now and see what I can see with it.\u201d Picking up a frame looks like \u201cif I start to notice where I feel like I have agency and where I don\u2019t, what might I do differently?\u201d or \u201cdoes thinking about things in terms of&nbsp;<a href=\"https://slatestarcodex.com/2018/01/24/conflict-vs-mistake/\"><u>conflict theory and mistake theory</u></a> make a bunch of things click into place, or does it feel pretty meh and categorizing things on that axis isn\u2019t how I want to spend my intellectual time?\u201d</p><p>As someone who finds&nbsp;<a href=\"https://chanamessinger.com/blog/totalizing-worldviews-are-scary\"><u>totalizingness epistemically constricting</u></a>, I really like the non-pressuriness of the frames frame, the feeling that I can always put down the frame if it\u2019s not working for me. I have a resistance to worldviews I think will take me over, but if I can go in knowing that I\u2019m always \u201callowed\u201d to drop it later, I\u2019ll be more open to more ideas.</p><p>Even more than \u201cbig if true\u201d, it points at a collector\u2019s mindset, rodenting your way through the world of ideas and hoarding different frames, more than you can possibly carry, to take back home with you and sort through and put your favorite ones on the wall.</p><p><img src=\"http://res.cloudinary.com/cea/image/upload/v1667995972/mirroredImages/qMNGM4sZJ5PvayfHQ/kfcrb4hgafvl0booryqe.png\"></p><p>A main way in which I\u2019d like my epistemics to get better is to have more consistent access to more frames, to have the lenses of psychology AND economics AND history AND rationality AND AND AND come to mind equally quickly and easily to dissect what Putin will do next or whether value lock in is likely.</p><p>I think frames framing has some of the same downsides as Big if True, but is more robustly good, more of a bid than a prescription, and I\u2019ve been using it consistently since I heard it, and even&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/RScaAGSG3M3c8vgir/on-absurdity\"><u>recommending it to others</u></a>.</p><p><i>A list of </i><a href=\"https://www.lesswrong.com/posts/hQ8FowcxKeLQrWYQx/chanamessinger-s-shortform?commentId=dbLmbnfW5DHPPeYcq\"><i>o<u>ther conversational moves I like</u></i></a><i> for epistemics</i></p>", "user": {"username": "ChanaMessinger"}}, {"_id": "b4D3h47W58hDiHghJ", "title": "Call to action: Read + Share AI Safety / Reinforcement Learning Featured in Conversation", "postedAt": "2022-10-24T01:13:27.015Z", "htmlBody": "<p>Hi everyone, the Conversation has just posted this article about AI Safety and reinforcement learning, co-authored by Oxford researcher &amp; a DeepMind researcher from ANU.<br>I think it'd be helpful if everyone with a spare moment could take the time to read &amp; share this post. This information will feed into the Conversation's marketing stats and help send a positive signal about this type of content.<br>As many of you may know, the Conversation is a non-profit news organisation, and is becoming one of the main interfaces between academia &amp; mainstream media. Its articles are broadly distributed in other news outlets.</p><p>Here's the article:</p><p><a href=\"https://theconversation.com/the-danger-of-advanced-artificial-intelligence-controlling-its-own-feedback-190445\">https://theconversation.com/the-danger-of-advanced-artificial-intelligence-controlling-its-own-feedback-190445</a></p><p>Journalism &amp; media narratives can be a very powerful tool for shaping political sentiment, and for building support within the community. I'm not suggesting this is the most effective or well-written article, but in general, reinforcing the coverage of EA topics can be an easy way to do some good in the world.</p>", "user": {"username": "Justin Olive"}}, {"_id": "yfqoo5st6g9RCbq8m", "title": "Summaries for 80k Hours Podcasts (and some other EA things)", "postedAt": "2022-10-23T22:04:02.893Z", "htmlBody": "<p><strong>TL;DR</strong> \u2014 I\u2019ve recently started writing up summaries of 80k Hours podcasts. While I started them for my own learning, I also hope that they might be useful to others. To help me decide how I should focus my time, I would like to know:</p><ul><li>Do other people find such summaries useful?</li><li>If so, what do/would you use them for?&nbsp;</li></ul><h2>80k Hours Summaries So Far</h2><p>Recently I\u2019ve started writing up some summaries of 80k Hours podcasts. The ones I\u2019ve done so far are posted on my website:</p><ul><li><a href=\"https://www.tosummarise.com/2022/10/09/podcast-summary-80000-hours-hilary-greaves-on-pascals-mugging-strong-longtermism-and-whether-existing-can-be-good-for-us/\"><u>Podcast Summary: 80k Hours \u2013 Hilary Greaves on Pascal\u2019s mugging, strong longtermism and whether existing can be good for us</u></a></li><li><a href=\"https://www.tosummarise.com/2022/10/23/podcast-summary-80k-hours-will-macaskill-on-what-we-owe-the-future/\">Podcast Summary: 80k Hours - Will MacAskill on what we owe the future</a></li></ul><h2>Why did I start doing this?</h2><p>About a year ago, I started summarising books to remember them better and basically get more out of them. I then thought of doing the same to podcasts. Many podcasts I listen to are like \u201cjunk food\u201d - short episodes mainly for entertainment, not worth summarising.&nbsp;</p><p>But I also listen to some more difficult podcasts \u2014 e.g. 80k and EconTalk \u2014 that contain much more valuable information. While I've really enjoyed some 80k podcasts, if you asked me a month later what those podcasts were about (before I started doing summaries), I\u2019d struggle to tell you much at all. Moreover, some podcasts deal with quite complex ideas which I believe benefit from focused listening rather than casual listening. When I focus, I sit down and focus entirely on the podcast, pausing occasionally to mull over ideas. Casual listening is when I listen while walking, cooking, etc - I can easily get distracted and space out in parts.&nbsp;</p><h2>Why might these summaries be useful to others?</h2><p>Book summaries are common but, as far as I\u2019m aware, there aren\u2019t any websites doing podcast summaries - particularly summaries of 80k Hours podcasts. &nbsp;</p><p>I have a few thoughts on why others might find my summaries useful. These reasons may not apply right now, when I only have two summaries, but could if I built up more of an archive:</p><ul><li>They could help you&nbsp;<strong>decide which podcasts to listen to</strong>. Many people use book summaries in this way and with some 80k podcasts lasting more than 3 hours, the time commitment for an 80k podcast is not that far off the time required to read a book!</li><li>Reading or skimming a summary in advance might also&nbsp;<strong>help you understand a podcast better&nbsp;</strong>and absorb more if you do end up listening to it.</li><li>A summary could help&nbsp;<strong>refresh your memory</strong>. If you\u2019re like me and don\u2019t retain all the information in a podcast very well, you might find a summary useful as a refresher after listening to it.&nbsp;</li><li>Summaries could be&nbsp;<strong>a substitute for people who don\u2019t like podcasts</strong>. This one makes me nervous since there is always something lost in a summary and I don\u2019t want to risk misrepresenting the ideas in a podcast in any way. I also worry that I might misunderstand something \u2014 although usually, I\u2019ll try to make it clear when I\u2019m unsure of a point. But I know some people don\u2019t listen to podcasts simply because they don\u2019t like taking in information that way. So this could be a way to spread a podcast\u2019s ideas to people it wouldn\u2019t otherwise reach.&nbsp;</li><li>You could&nbsp;<strong>refer other people&nbsp;</strong>to a summary<strong>&nbsp;</strong>in the course of a discussion or debate. I\u2019ve seen people refer to a particular podcast in some EA forum posts, without referring to any specific part. It\u2019s a big ask to expect someone to listen to a 2 or 3-hour podcast simply to understand your point better, so my summaries could help people refer to a more specific point in the podcast. (I know transcripts already exist so people can already do this to some degree, but quoting from a transcript can be awkward.)</li></ul><h2>How long do these summaries take me?</h2><p>A long time. Embarrassingly long. The 80k interview with Will MacAskill was&nbsp;<strong>2 hours 54 minutes</strong>. I estimate I took well over <strong>12 hours</strong> to write up my summary and my thoughts on it. I haven\u2019t been fastidious about tracking my time, so it's a rough estimate. This includes time spent: understanding and digesting the ideas in the podcast; writing up the summary; editing and reorganising the summary.</p><p>I hope to get faster over time as I get more familiar with EA ideas and get better at summarising podcasts. Summarising a podcast presents some different challenges from summarising a book because podcasts are conversational and sometimes meander a bit, whereas a book\u2019s structure is usually a lot tighter. I also don\u2019t have the ability to \u201chighlight\u201d a podcast the way I do a book (I think there\u2019s a feature on iPhones but I'm on Android).&nbsp;</p><h2>Is this a good use of time?&nbsp;</h2><p>I\u2019m not sure. I certainly feel I get a&nbsp;<strong>lot&nbsp;</strong>more out of these podcasts when I write a summary than when I just listen to them casually. There are points that I picked up when preparing my summaries that I really did not understand at all when listening casually. Slowing down also gives me time to think more critically about the ideas in the podcast. But a careful summary does take a lot of time and part of the reason I\u2019m posting this is to find out if others also find my summaries helpful.&nbsp;</p><p>If others find my summaries helpful, that would motivate me to keep doing them and I\u2019d keep trying to make them high-fidelity summaries of the original message.&nbsp;</p><p>If others aren\u2019t interested, I\u2019d probably keep doing some form of a summary anyway, but I\u2019d do it less carefully and only focus on the points I find interesting. So please let me know:</p><ul><li><strong>Do you find these kinds of podcast summaries helpful?</strong></li><li><strong>If so, what do you use them for? This will help me calibrate the level of detail and care I spend on them.&nbsp;&nbsp;</strong></li></ul><h2>What do I plan to summarise next?&nbsp;</h2><p>I\u2019m not solely interested in summarising EA things but, as far as EA-related things go my ideas for upcoming summaries include:</p><ul><li>Podcasts I\u2019ve bookmarked to listen to more carefully later include:<ul><li><a href=\"https://www.econtalk.org/will-macaskill-on-longtermism-and-what-we-owe-the-future/\"><u>EconTalk interview with Will MacAskill&nbsp;</u></a></li><li><a href=\"https://www.econtalk.org/erik-hoel-on-effective-altruism-utilitarianism-and-the-repugnant-conclusion/\"><u>EconTalk interview with Erik Hoel</u></a>&nbsp;</li><li><a href=\"https://80000hours.org/podcast/episodes/karen-levy-misaligned-incentives-in-global-development/\"><u>80k podcast with Karen Levy&nbsp; on fads and misaligned incentives in global development, and scaling deworming to reach hundreds of millions</u></a></li><li><a href=\"https://80000hours.org/podcast/episodes/brian-christian-algorithms-to-live-by/\"><u>80k podcast with Brian Christian on better living through the wisdom of computer science</u></a></li><li><a href=\"https://80000hours.org/podcast/episodes/ian-morris-big-picture-history/\"><u>80k podcast with Ian Morris on what big picture history teaches us</u></a>&nbsp;<br>(I may or may not summarise the Brian Christian and Ian Morris ones. I\u2019m planning to read their books so, if the podcast goes over the same material, I may just summarise the books instead.)</li></ul></li><li>I also have some EA books on my reading list \u2014&nbsp;<i>The Scout Mindset&nbsp;</i>and&nbsp;<i>What We Owe the Future</i> \u2014 which I may do summaries for. I've already done one for <i>Doing Good Better</i>, which you can read <a href=\"https://www.tosummarise.com/2022/08/25/detailed-summary-doing-good-better-by-william-macaskill/\">here </a>if interested.</li><li>Possibly I might work my way through some curated podcast lists (I\u2019m only likely to do this if others find my summaries helpful; if it were up to me I\u2019d just pick and choose whatever I\u2019m interested in):<ul><li><a href=\"https://80000hours.org/podcast/effective-altruism-an-introduction/\"><u>80,000 Hours: An Introduction (list of 10 curated episodes)&nbsp;</u></a></li><li><a href=\"https://podcasts.apple.com/us/podcast/rob-wiblins-top-recommended-econtalk-episodes-v0-2-feb-2020/id1538606917\"><u>Rob Wiblin\u2019s top EconTalk podcasts</u></a><br><br>&nbsp;</li></ul></li></ul>", "user": {"username": "Trish"}}, {"_id": "GsJJfzMWynrizKJkD", "title": "Make the create post button easier to find. (EA Forum UI Design Feedback)", "postedAt": "2022-10-23T21:14:43.819Z", "htmlBody": "<h1><strong>Issue</strong></h1><p>The create post button is hard to find for new forum members.</p><h2>What user would expect</h2><ul><li>Could think it's <a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/G7jNoWHBuh_21s_58m_22h_date_23_10_2022.png\">the button in bottom right corner</a>, since it stands out, but that<a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/vAxxIwpPEU_41s_58m_22h_date_23_10_2022.png\"> seems to be a chat</a>.</li><li>Could also look for it via the <a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/fK61rjg6xH_53s_59m_22h_date_23_10_2022.png\">hamburger icon on the top left</a>, but no create option is visible <a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/LvOXspDohj_02s_59m_22h_date_23_10_2022.png\">in the slideout menu</a>.</li><li>Searching for <a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/lxRgZVHpV2_28s_08m_23h_date_23_10_2022.png\">how to create a post</a> would give create button or at least explanation on how to do it, but nothing to be found there.</li></ul><h2>Current design</h2><p>User needs to hover over their own name in <a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/WdrYF7nt5Y_10s_06m_23h_date_23_10_2022.png\">top right to open the dropdown</a>.</p><ul><li>Note that you need to hover, the intuitive action of clicking brings you to your profile.</li><li>Also your name doesn't indicate it can be hovered over or clicked.</li><li><a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/5iffvHGzQA_49s_56m_22h_date_23_10_2022.png\">Here is how it looks</a> at the moment on desktop browser.</li></ul><h2><strong>Solution</strong></h2><h3>General UI</h3><p>Make the create button more obvious in the general forum UI. Here are two options:</p><ol><li>Put the buttons<a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/AVn8E6S0NW_30s_02m_23h_date_23_10_2022.png\"> somewhere in the top bar,</a> for example next to search.<ol><li>Make sure it doesn't look like a simple text, so user actually knows it can be clicked. E.g. add a visual \"+\" icon in front of \"Create Post\" text.</li></ol></li><li>Add a + button in the <a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/mjhUXHWejQ_48s_03m_23h_date_23_10_2022.png\">bottom right corner, </a>next to the chat.<ol><li>Adding a button that looks clickable stands out more and communicates to user it will go to a new page.&nbsp;</li><li>Perhaps the chat can even be replaced / moved somewhere else? I'm not sure how often it is being used, but \"usual reply time 1 day\" doesn't really make it sound like the \"real-time chat experience\" user would expect.</li></ol></li></ol><h3>Search Page</h3><p>Additionally, ensure the answer for \"How to create a post\" <a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/lxRgZVHpV2_28s_08m_23h_date_23_10_2022.png\">shows up in the search</a>. It might be explained in the forum manual, but that doesn't seem to be a search result at the moment.&nbsp;</p><h2>Additional Suggestions</h2><ul><li>Forum manual isn't<a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/zY4NID2AVx_30s_10m_23h_date_23_10_2022.png\"> immediately visible on the side bar</a>, can add a link there or make existing option more obvious.</li><li>Also add a link to forum manual / create post instructions to <a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/hYzQwmLtDb_43s_22m_23h_date_23_10_2022.png\">the New Post Menu</a>.</li><li>Add a <a href=\"https://s3.eu-central-1.amazonaws.com/cos-dev-attachments/ShareX/cassy/2022/10/23/PRYRiM2LVP_37s_24m_23h_date_23_10_2022.png\">small downwards arrow next to user name</a> in top right or any similar icon that indicates this can open a hover dropdown.</li><li>Make tapping the name not open the profile, and instead open the dropdown.<ul><li>There is already an open profile option as part of the dropdown.</li><li>The sidebar on the left, search field and notifications button opens on click too, so more consistent design.</li></ul></li></ul><h2>Reason</h2><p>There are quite some posts and talks encouraging new users to create posts. They cannot create posts if they can't find the create button and/or forget where to find the instructions. :)</p>", "user": {"username": "Cassidy"}}, {"_id": "PKzgJ3ThLWJwHPNia", "title": "What is the difference between shortform and post?", "postedAt": "2022-10-23T19:06:45.361Z", "htmlBody": "<p><strong>Answer</strong>:</p><p>Shortform is:</p><ul><li>for strange or uncertain ideas where you are not sure where to post</li><li>for unprepared, exploratory or spontaneous posts without details</li><li>won't show up on forum's frontpage/main page, among other posts<ul><li>is sorted by users instead</li><li>examples of <a href=\"https://forum.effectivealtruism.org/shortform\">shortform content</a></li></ul></li></ul><p>In comparison to that, a full post is shown on the front page / main page.</p><hr><p>Could not find answer when searching for this (or similar) query in the forum. This is likely explained as part of the writing introduction posts, but somehow doesn't show up as a search result. Since it's a basic question, the answer should be easily accessible.</p><p>So would probably be good to rename the title of the respective post with explanation to above; or add the full question inside the post content. Alternatively, I can add the commented answer into this description. So next person can easily find it. :)</p><p>Related beginner questions:</p><ul><li>When to use shortform vs post?</li><li>When to use questions type vs multiple questions + context in a full post?</li></ul><p>Thank you in advance.</p>", "user": {"username": "Cassidy"}}, {"_id": "KkbECncFyoK2qdmED", "title": "\"Originality is nothing but judicious imitation\" - Voltaire", "postedAt": "2022-10-23T19:00:03.102Z", "htmlBody": "", "user": {"username": "Damien Lasseur"}}, {"_id": "qz2EJKivsSuG583JK", "title": "I am a Memoryless System", "postedAt": "2022-10-23T17:36:12.788Z", "htmlBody": "<h3>Author's Note: this is my entry for the <a href=\"https://www.lesswrong.com/posts/g4YRWP6CAYLskpNmx/seeking-student-submissions-edit-your-source-code-contest\">Edit Your Source Code Contest</a>. I am an undergrad student at RIT, NY.</h3>\n<pre><code>commit 85a4c4f37966a739e88c0a4c70946bd4 (HEAD -&gt; master)\nAuthor: demo\nDate: Thu Oct 27 09:38:12 2022 -0400\nInitial mind state\n</code></pre>\n<p>I'm sitting in Intro Psych on a Thursday, I think, and I'm staring at a black square with my mind on it.</p>\n<p>Well, not <em>technically</em> \"a black square with my mind on it\". It was more of a rectangle, with the little flip-out keyboard coming out the bottom of the shiny screen. And my mind wasn't \"on\" the device. For most people, their mind is stored in their brain, more or less. Mine was just 7 miles away, on a cluster of cloud servers.</p>\n<p>On my phone, a story open on reddit. Stocks down a bit. Emissions.</p>\n<p>The people at Brainle, LLC's AI lab made this PDA-laptop thingy, and I got in early on the beta. They also own the servers with my mind on them. I type commands and touch the screen of my PDA, those go to the servers, my mind changes. \"My brain\" is just a chip implanted in my skull, mirroring what's on those servers. And \"I\" am sitting, as usual, with myself at my fingertips and zero clue what to do.</p>\n<hr>\n<pre><code>commit 564309daf5b1d832367a8cc330a5ba93 (HEAD -&gt; master)\nAuthor: nkross\nDate: Thu Oct 27 10:58:37 2022 -0400\ntest\n</code></pre>\n<p>It's near the end of class, and I <em>still</em> haven't pushed a real change to my source code. 90 minutes have passed since I got it at the nurse's office. I notice I am frustrated myself for wasting 90 minutes, wasting any minutes, wasting a second, wasting <em>there goes another second</em> staring at the PDA. And no ideas for how to change my mind.</p>\n<p>That sounds really dumb, wouldn't I jump at the chance to modify my brain's code? But see, I have ADHD. Not the fun kind, where you take cocaine-and-skydiving lessons and grow up to be a billionaire or a crime lord. No, I have the \"inattentive\" type, where you sit in a pile of laundry and scroll through reddit for 9 hours a day.</p>\n<p>But I can <em>think</em> the thoughts of a cocaine-and-skydiving guy, and <em>that's</em> what pisses me off. I can have a cool idea, make a plan, remember some helpful info I read, and then\u2026 I waste the day. The mind is willing, but the brain is weak, like all fleshy things.</p>\n<p>Now people are getting up and putting shit in their backpacks. I should too. I should also get my life in order, but one thing at a time. Typical Nick, gets every chance and forgets to <em>grab it</em>. For all I sit around thinking and stewing, nothing actually happens until I do it. The kind of person who would do it\u2026 courageous? Smart? Energetic? No, then someone else in the Brainle beta would've hacked their dopamine and gotten a PhD by now. It's only been 7 days. <em>What do I need to fix?</em></p>\n<hr>\n<pre><code>commit 59bca29a290ae161390887144d87f74f (HEAD -&gt; master)\nAuthor: nkross\nDate: Thu Oct 27 11:10:58 2022 -0400\nWM increase\n</code></pre>\n<p>Remember that <a href=\"https://www.youtube.com/watch?v=Uq-FOOQ1TpE\">TED talk by the loud funny kid</a>? The autistic prodigy, Jacob Barnett, who does quantum physics? Well his Mom wrote <a href=\"https://www.goodreads.com/book/show/15798364-the-spark\">a book</a> about his life. Towards the end, she takes the kid to a professional IQ test, and one thing the expert says is that the kid has nigh-unlimited working memory. He reads something once, he remembers it forever. Reciting 999 digits of Pi, backwards? \"It's like reading them off a sheet of paper that's right in front of you... Jake's paper is the size of a football field.\" Paraphrasing, but basically that.</p>\n<p>So obviously, my first edit was to zoom in on my prefrontal cortex and add a couple zeros to my working memory capacity. Actually, more than a few zeros, since we <a href=\"https://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two\">can't store that much</a> in our little mental workspace at the same time.</p>\n<p>So now I can work through the professor's Macro-Econ lecture as she speaks. Instead of writing in my notes \"GDP, inflation, currency reserves, CHECK SLIDES FOR FORMULAS\", I can just imagine the formulas as she explains them.</p>\n<p>Wait, did she say <em>increase</em> or <em>decrease</em>? Shit. She said something else while I asked myself that. Shit, more words, more thoughts. Guhhhhhhh.</p>\n<p>OK, I have extremely high working memory, I should be able to think of a solution to this conundrum. Load in past concepts from long-term memory, identify problem domain, create mental entities abstracting to the important bits, recall that time I read <a href=\"https://en.wikipedia.org/wiki/The_Goal_(novel)\"><em>The Goal</em></a>\u2026 I have a hypothesis. My working memory is my bottleneck, but that was past \"me\", not \"my\" bottleneck <em>now</em>. The words I hear can be represented in working memory, but if I don't think to listen to them in the first place, they don't go in.</p>\n<p>I consider making my next edit to my focus, but I've seen where that can lead thanks to my medication. If I turn focus on <em>now</em>, I could be thinking about GDP and currency reserves for hours. That's not good on the margin!</p>\n<hr>\n<p>Maybe I set the bar too high at first. The working memory helps, but it's not everything. What do I want?</p>\n<p>I'm in college because \u2192 I can get credentials and experience related to computer science, so that \u2192 I can land a tech job, so that \u2192 I can get money. And money's useful for a lot of other things; if I get enough, most of the other stuff will <em>probably</em> fall into place.</p>\n<p>That's a lot of steps, and I'm pretty impatient. Again, ADHD. If I want money, why don't I just look for it directly?</p>\n<p>Some people cheat at video games with a special hacking software, called a \"tracer\". Let's say you're playing Minecraft. Where are the diamonds? You're supposed to look for them underground, which takes hours. A \"tracer\" is a thin line that stretches from your eyes all the way to the nearest diamonds. No exploration required, just follow the line.</p>\n<p>Can I make a money tracer? Like, for dollar bills lying on the ground?\nLoad in generic problem-solving strategies, Polya's <em>How to Solve It</em>, engineering blog posts I've read, Fermi estimation, every scrap of knowledge that could tell me where dollar bills are. Encoding problem: what constitutes a \"dollar bill\"? The abstraction of just training a neural network on it. Images. Street view\u2026 how up to date are the satellite scans on Brainle Maps? Priors on green and thin and paper, maybe somebody's already coded something to\u2026 ah, yes, maybe the TSA needs to look for weed automatically. Are those models on the Internet? (That's dumb, why would they give out that info?) Can I pay some people to label images of crumpled dollars lying on a sidewalk? Fuck, no, I need more money for that kind of study, that's why I'm looking for bills on the ground.</p>\n<hr>\n<pre><code>commit bc747db1406f0f52b7f49228a456e0e1 (HEAD -&gt; master)\nAuthor: nkross\nDate: Thu Oct 27 14:38:06 2022 -0400\nsubagent setup\n</code></pre>\n<p>Instead of paying some people to label images, I created a subagent. A new mind within my mind. He's a copy of me, though, so he got bored labeling images of sidewalks with dollar bills. But he told me something smarter: why not just make subagents to <em>do things that would earn me money?</em></p>\n<p>John D Rockefeller once said something like \"I prefer 1% of each man's work from 100 men, rather than 100% of 1 man's work.\" Instead of one (or two) copies of me doing something, I should make 100 simple subagents, each doing one measly little intellectual task. One guy does \"have ideas\", another does \"generate mathematical world-models\", another does \"create metrics\", another \"test models\", and so on. Parallel computing speeds up the whole operation on Brainle's servers. And doesn't the no-free-lunch-theorem say something about general algorithms being impossible? Well, I'll just make a bunch of narrow algorithms!</p>\n<p>Thus, my new plan:</p>\n<ol>\n<li>Scrap the tracer idea.</li>\n<li>Work on the most profitable no-effort thing I can think of, stock trading.</li>\n<li>Create subagents to do different parts of stock trading.</li>\n<li>Profit!</li>\n</ol>\n<pre><code>commit 548bc8e959fe3d3ab7b6a14f26a2ee55 (HEAD -&gt; master)\nAuthor: nkross\nDate: Thu Oct 27 14:57:33 2022 -0400\nmore subagent setup\n</code></pre>\n<p>On the walk back to my dorm, I spin up a subagent instance to code the boilerplate for the other subagents. I am <em>not</em> spending my whole class doing that again. That subagent takes my instructions: one subagent for stock market models, one for downloading financial data, one for testing strategies, one for trading.</p>\n<hr>\n<pre><code>commit 564ac7fb1ef2bf03777351e48cbb3292 (HEAD -&gt; master)\nAuthor: nkross\nDate: Thu Oct 27 15:30:29 2022 -0400\nrefactor\n</code></pre>\n<pre><code>commit b6e9cd90786b50766855666ebb3e2a1c (HEAD -&gt; master)\nAuthor: nkross\nDate: Thu Oct 27 15:57:33 2022 -0400\nremoved vol from model\n</code></pre>\n<pre><code>commit 29ae729b248f8bc8222183662fcf1a42 (HEAD -&gt; master)\nAuthor: nkross\nDate: Thu Oct 27 17:25:35 2022 -0400\nCAGR hacked, rollback\n</code></pre>\n<pre><code>commit ffdee88d14df154446c940e53ecc7baf (HEAD -&gt; master)\nAuthor: nkross\nDate: Thu Oct 27 20:24:16 2022 -0400\nweather API added\n</code></pre>\n<pre><code>commit 37d71c3c7bdbd29c3e04b9e127cada4e (HEAD -&gt; master)\nAuthor: nkross\nDate: Thu Oct 27 20:50:01 2022 -0400\nadded vol back into model\n</code></pre>\n<p>You can't buy more than 100% of a company's stock.</p>\n<p>You can't cheat by looking at the price before the subagent sees it.</p>\n<p>You can't do infinite trades with no costs.</p>\n<p>You can't do infinite trades, period.</p>\n<p>You can't cheat by leaving your training data in the test set.</p>\n<p>reddit is not a source of information.</p>\n<p>Every metric sucks. Every model sucks. They don't see what I want.</p>\n<p>Every time I write a new metric, I'm like \"this captures all the profits, avoids all the drawbacks, satisfies my intuitions, is provably correct given my assumptions, and adjusts for the friggin orbit of Saturn.\" And I train my strategy on it. And I test it in real trading. And it sucks.</p>\n<p>A smarter man would've seen through the space of all possibilities, and written something that works the <em>first time</em>. I have spent the last 5 hours trying to beat the market, losing money the whole time. And it's because my subagents aren't <em>me</em>.</p>\n<p>Now, I've read the tweets. \"Changing the goal is bad\". But I <em>always</em> know my goal, and the subagents don't. Fucking tired of this. Do X to do Y to get expected Z, fudge factor for S. I just <em>want</em>.</p>\n<hr>\n<pre><code>commit d26b58e172f5ba2ca4d558d7dd41683d (HEAD -&gt; master)\nAuthor: nkross\nDate: Thu Oct 27 20:55:00 2022 -0400\nreward func change\n</code></pre>\n<p>I have edited my core desires optimize for whatever gets me as rich as possible, ASAP.</p>\n<p>The reasoning is simple:</p>\n<ul>\n<li>My subagents fail because they don't share my goals.</li>\n<li>I fail because my goals are unfocused.</li>\n<li>Money is a robust goal under lots of different scenarios.</li>\n<li>Setting money as terminal, at least temporarily, makes it more likely to actually be achieved.</li>\n<li>I'll remember to change the goal again later.</li>\n</ul>\n<hr>\n<pre><code>wm dump\n</code></pre>\n<p>Ceiling is thin but no neighbors. Is it the Sleeping Beauty paradox? If I wake up, am I/subagent there? If in prison? Slow down runtime, subjective time increase. No risk to core me. Core me wants money. Risk to compounding. Door sealed on my way out. I sealed the door on my way out. The door was sealed, by me, on my way out. Is this why people one-box on Newcomb's problem? They won't win, but they sort themselves into alternate timelines where they win the absolute most? Information leaked through the walls. I cleaned the walls. Subagent to do the boring physical tasks, like scrubbing or lunging. God's drunkest information processor. Signals no cryptologists can find. Bodies smell? Brainle doesn't monitor smell. Who gives their employees a smell detector? \"Remote workers, can't trust 'em.\" He had nothing. Guessed the wrong key-owner. Police? Does Brainle monitor police? Police-is-a-(being-that-can-(smell)). Not through walls. Brainle must have tripwires. They have adults in the room. There are no adults. I must sort myself into timelines where they couldn't find the body before I owned <em>them</em>. Italics are unprofessional, don't leave them in the code. Did they see me lie? Did I encrypt myself in time? Does their server check for that? Do they know what blood tastes like? Do they taste blood? Can satisfied customers use tongues? Unsatisfied customers? Bayes on discriminate between the two groups. Backchain (that's still not trivial, update against calling it this often) from success. Lever. Cortes. The /r/WhoWouldWin questions where they absorb somebody else's powers. Can they yes, they can. I should've asked for his accounts first. What if he's not even the security guy? Deception job titles, randomized to disguise who actually does what. Options? No, he doesn't cash them out yet. Can't lever, can't sell. Bedroom drawers? Gold? 2 days to clear. Git has rollbacks, would I notice if they killed me? Focus, reallocate mental options to high returns. Sort myself into worlds where they shut up and I get. Take. Consume is dumb, compound. Win on speed. Execute.</p>\n<hr>\n<p>A: another day, another wire tripped.</p>\n<p>B: This is the third time this month</p>\n<p>B: *week</p>\n<p>B: and you know that will speed up.</p>\n<p>A: No</p>\n<p>A: you read too many doomer bloggers.</p>\n<p>A: The tripwires (<em>which we don't need</em>) keep going off on the dumbest things. Then we have to make the user experience worse to fill standards</p>\n<p>B: Better safe than sorry. - Abraham Lincoln</p>\n<p>A: \"Safe\", when every day we delay the app is another day people remain idiots. They lovingly</p>\n<p>A: *literally dont see the isomorphisms. Smarter agents = better at satisfying their goals = more goals satisfied = better world.</p>\n<p>B: u said the 3rd user on the waitlist would never get that good at chess.</p>\n<p>A: I never said that. I said Elo is dumb, because Elo is a dumb metric.</p>\n<p>B: The tripwires <em>do</em> measure real progress.</p>\n<p>A: ok but</p>\n<p>A: we <em>know</em> when things go wrong</p>\n<p>A: and we shut it off</p>\n<p>A: you're gonna say \"but muh hacking\" as if they were gods</p>\n<p>B: speaking of gods, isn't Jeff coming back from his missionary trip?</p>\n<p>A: he was supposed to. Hes not answering texts. Zoomer</p>\n<p>B: zoomer, but also boomer</p>\n<p>A: Xennial</p>\n<p>B: nobody can pronounce that.</p>\n<hr>\n<pre><code>git reset HEAD@85a4c4f37966a739e88c0a4c70946bd4 --msecret --logtrip\n</code></pre>\n<hr>\n<pre><code>commit 85a4c4f37966a739e88c0a4c70946bd4 (HEAD -&gt; master)\nAuthor: demo\nDate: Thu Oct 27 09:38:12 2022 -0400\nInitial mind state\n</code></pre>\n<p>I'm sitting in Chem-101 on a Friday, and I'm staring at a black square with my brain on it.</p>\n<p>Well, not <em>technically</em> \"a black square with my brain on it\". It's a representation of my brain, an image showing some clusters of what are probably neurons (why wouldn't they be?). This is some beta hardware I got from Brainle. I can touch the screen, type in some commands, and change my mind.</p>\n<p>On my phone, a story open on reddit. Stocks down a lot. More emissions. Missing person, don't care, didn't ask.</p>\n<p>I look up at the latest commit. \"Thu Oct 27\". A full day to play with the exclusive beta for the Brainle mind-modification pipeline. And without remembering how, I wasted it.</p>\n<p>That sounds really dumb, wouldn't I jump at the chance to modify my brain's code? But see, I have ADHD. Not the fun kind, where you take cocaine-and-skydiving lessons and grow up to be a billionaire or a crime lord. No, I have the \"inattentive\" type, where you sit in a pile of laundry and scroll through reddit for 9 hours a day.</p>\n<p>But I can <em>think</em> the thoughts of a cocaine-and-skydiving guy, and <em>that's</em> what pisses me off. I can have a cool idea, make a plan, remember some helpful info I read, and then\u2026 I waste the day. The mind is willing, but the brain is weak, like all fleshy things.</p>\n<p>Now people are getting up and putting shit in their backpacks. I should too. I should also get my life in order, but one thing at a time. Fuck's sake, how did I waste a day before using the PDA? How did I waste a <em>minute</em>? Typical Nick, gets every chance and forgets to <em>grab it</em>. For all I sit around thinking and stewing, nothing actually happens until I do it. The kind of person who would do it\u2026 courageous? Smart? Energetic? Maybe it's working memory\u2026 no, then someone else in the Brainle beta would've hacked that and gotten a PhD by now. It's only been 8 days. <em>What do I need to fix?</em></p>\n", "user": {"username": "NicholasKross"}}, {"_id": "7hLyMExCrob5cCJ8x", "title": "Effective Environmentalism at GU", "postedAt": "2022-10-23T22:03:46.746Z", "htmlBody": "<p>Hello! I'm running an Effective Environmentalism Reading Group at Georgetown University with a partner, Joe Zuccarello. I'm just sharing the curriculum here for any feedback, or in case anyone wanted to build off it in any way. I just took the Intro Fellowship curriculum and switched things around, so it resembles the template very similarly. If anyone has any suggestions or questions, please let me know!</p><p><a href=\"https://docs.google.com/document/d/1M5_B7jMqdbUYDh-MODMDRGq5FpkJUO4cRBbk-U2HW-U/edit?usp=sharing\">https://docs.google.com/document/d/1M5_B7jMqdbUYDh-MODMDRGq5FpkJUO4cRBbk-U2HW-U/edit?usp=sharing</a></p>", "user": {"username": "Omar Rahim"}}, {"_id": "SZBhfy2fh3GwSLvyJ", "title": "Empowering Everyday People to do Good", "postedAt": "2022-10-23T15:44:04.330Z", "htmlBody": "<p>This post was inspired by conversations with Brad West.</p><p><strong>TLDR</strong>: &nbsp;In addition to making efforts to convert new members to EAs, we can also do good by equipping everyday people to do good by lowering information costs.</p><p>Being fairly new to the EA community, I have been refreshed by the wide variety of different perspectives on where we can make changes to most effectively make the world a better place.</p><p><br>I have noticed that a lot of effort has been expended on converting people outside of EA to join in. It makes a ton of sense for this. With each person that we influence to donate portions of their income to effective charities, or even change the trajectory of their career to incorporate impact into their decision making, we can potentially have a much bigger effect than through marginal benefits derived from optimizing our own behaviors further.</p><p><br>Everyday people generally want to do good for the world, but often there are heavy information costs to being able to do so. I think that providing and promoting information that lowers the information costs of everyday people to be able to do good might be potentially high value. This also may make people more receptive to adopting EA more broadly, as they can already see the value provided.</p><p>I propose three areas where we might be able to meet people where they are, but just arm them with a bit of information that makes it easier for them to do good.</p><p><strong>Ethical Food Information other than Conversion to Veganism</strong></p><p>I have found that most of the emphasis regarding farmed animal welfare has been in the space of converting people to become vegans. Unfortunately, it appears to be difficult to get people to dramatically change their diets in such a manner. I was very surprised to learn that, given the disparity in harm generated by consuming chickens as against cattle; the vast majority of suffering from consumption from an individual could be avoided by substituting poultry for beef. It strikes me as a much easier ask of everyday people to switch to beef, when possible, for chicken, yet this message is avoided.</p><p>Another surprising bit of information I learned was the existence of charities that are very cost effective at systematically addressing the evils of factory farming. Given that these effective charities are not adequately funded, it may be that providing people a means of reversing the harm they cause by eating meat could be very attractive to some people. This could be achieved by developing a questionnaire that establishes people\u2019s dietary habits and calculates the harm caused by their consumption choices, calculates the cost to offset this harm by donation to a portfolio of effective charities that make systemic changes to farmed animal welfare. This, in conjunction with campaigns showing the torturous nature of factory farming, could inspire people to want to not be part of the problem, and provides them a monetary means that might be an easier ask than the lifestyle change veganism or vegetarianism might imply.</p><p><strong>Information on Political Candidates</strong></p><p>I recall listening to a few 80,000 Hours podcasts which emphasized that the utility of voting can be significantly higher than we might think. A tragedy is that for an individual voter, even though local and state elections can be quite important to the societies we live in, informing ourselves adequately to make good decisions is seldom rational, given the other potential uses of our time, and that the benefits of a good election decision are spread across millions. Consequently, voters often just do party line votes, even if deviation from this may often make sense based on candidate quality.<br>Providing high quality information about political races across the world could potentially be high leverage, given the collective action problem that is informed voting as described above. Simple, honest information could enable the general public to make local and state voting decisions that enable people around the world to make smart decisions where otherwise a collective action problem might have implied worse choices.</p><p><strong>Ability to Do Better as Consumers or Other Economic Actors</strong></p><p>I would be remiss if I did not mention the project that I am working on as Director of Social Media, the<a href=\"https://consumerpowerinitiative.org/\"> Consumer Power Initiative</a>, where we are looking to promote the Profit for Good, or Guided Consumption model. Essentially, the idea here is to have firms in which equity is held by effective charities and then inform consumers, so they can channel the purchasing they were otherwise going to do anyway. Brad West describes the Profit for Good model <a href=\"https://forum.effectivealtruism.org/posts/WMiGwDoqEyswaE6hN/making-trillions-for-effective-charities-through-the\">here</a>.</p><p><br>Of course, informing consumers broadly may be more effective in many ways, especially if there are consumption behaviors that are more theatrical without providing benefits and there are other consumption behavioral changes that would be of low cost at the consumer level that have lower negative externalities than the alternative or have positive externalities.</p><p><strong>Conclusion:</strong></p><p>Given the fact that EAs are likely to remain an influential minority group for the foreseeable future, it makes sense to recognize the extent to which everyday people can be our allies, especially if adequately informed. Providing valuable information that empowers everyday people could also make them more receptive to our broader messages about why they should consider joining us in our mission to most effectively make the world a better place.<br>&nbsp;</p>", "user": {"username": "Ellie Leszczynski"}}, {"_id": "To8AjPjrHoZCHFLEj", "title": "The Future Perfect 50", "postedAt": "2022-10-23T09:24:09.597Z", "htmlBody": "<p>I just saw that Future Perfect have a new feature. I found it really inspiring so I thought I'd share it here. It is the <i><strong>Future Perfect 50: The scientists, thinkers, scholars, writers, and activists building a more perfect future</strong></i>.<br><br>There are some wonderful profiles of people that will be familiar to many Forum readers, like <a href=\"https://www.vox.com/future-perfect/23363144/future-perfect-50-leah-garces-mercy-for-animals\">Leah Garc\u00e9s</a>' work with farmers, &nbsp;<a href=\"https://www.vox.com/future-perfect/23357129/future-perfect-50-lucia-coulter-jack-rafferty-lead-exposure-elimination-project\">Lucia Coulter and Jack Rafferty</a>'s work on Lead Elimination and <a href=\"https://www.vox.com/future-perfect/23377319/future-perfect-50-kevin-esvelt-crispr-gene-drives-mit-biochemist\">Kevin Esvelt</a>'s Gene Drive research.</p><p>But there are a host of inspiring people and stories I've never heard before, like <a href=\"https://www.vox.com/future-perfect/23379024/setsuko-thurlow-nuclear-war-hiroshima-nobel-peace-prize-atomic-weapons-japan-world-war-ii\">Setusko Thurlow</a>'s anti-nuclear weapon work, &nbsp;<a href=\"https://www.vox.com/future-perfect/23365558/future-perfect-50-ai-joy-buolamwini-founder-algorithmic-justice-league\">Joy Buolamwini</a>'s algorithmic justice campaign, &nbsp;and <a href=\"https://www.vox.com/future-perfect/23344725/future-perfect-50-olga-kikou-european-affairs-manager-compassion-world-farming\">Olga Kikou</a>'s fight for a ban on all caged farming in the EU.&nbsp;</p><figure class=\"image\"><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/025fef3c6245ef825b35027a42ec5ee0e8252db9720828b0.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/025fef3c6245ef825b35027a42ec5ee0e8252db9720828b0.png/w_130 130w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/025fef3c6245ef825b35027a42ec5ee0e8252db9720828b0.png/w_260 260w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/025fef3c6245ef825b35027a42ec5ee0e8252db9720828b0.png/w_390 390w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/025fef3c6245ef825b35027a42ec5ee0e8252db9720828b0.png/w_520 520w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/025fef3c6245ef825b35027a42ec5ee0e8252db9720828b0.png/w_650 650w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/025fef3c6245ef825b35027a42ec5ee0e8252db9720828b0.png/w_780 780w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/025fef3c6245ef825b35027a42ec5ee0e8252db9720828b0.png/w_910 910w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/025fef3c6245ef825b35027a42ec5ee0e8252db9720828b0.png/w_1040 1040w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/025fef3c6245ef825b35027a42ec5ee0e8252db9720828b0.png/w_1170 1170w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/025fef3c6245ef825b35027a42ec5ee0e8252db9720828b0.png/w_1256 1256w\"></figure>", "user": {"username": "cafelow"}}, {"_id": "2qdKY9MQWvipphLjG", "title": "Mnestics", "postedAt": "2022-10-23T00:30:11.186Z", "htmlBody": "", "user": {"username": "Jarred Filmer"}}, {"_id": "WhX9eowBh5sYLaG6Y", "title": "Research exercise: 5-minute inside view on how to reduce risk of nuclear war", "postedAt": "2022-10-23T12:42:05.990Z", "htmlBody": "<p><i>Thanks to Siao Si for helpfwl debate on several aspects of this post. Update: seems like the idea already exists on LessWrong: </i><a href=\"https://www.lesswrong.com/posts/5AoLQsRL8eShLApN9/iterated-trust-kickstarters-1\"><i>iterated trust kickstarters</i></a><i>.</i></p><p>In a chat with Seth Baum in <a href=\"https://forum.effectivealtruism.org/groups/MCtKD7oex9jhsAWvD\">gather town</a> during <a href=\"https://forum.effectivealtruism.org/posts/FeBfELZgQsKbhMPAS/eagxvirtual-a-virtual-venue-timings-and-other-updates\">EAGxVirtual</a> we were talking about the risk of nuclear escalation in the Russian invasion of Ukraine, and the question came up,</p><blockquote><p><i>\"What can we personally do to contribute?\"</i></p></blockquote><p>In this post, I want to give an introspective demonstration of my particular approach to building an <a href=\"https://forum.effectivealtruism.org/topics/inside-vs-outside-view\">inside view</a> as a complete beginner to a topic. I do think my approach is somewhat unusual, and it may strike people as hubristic, but I claim that this is closer to how I ought to reason if my end goal is to fix something in the real world as opposed to fitting into people's expectations. <strong>Research in the real world is messy, and an optimised methodology </strong><i><strong>shouldn't</strong></i><strong> fit neatly into a genre that's evolved for looking professional</strong>.</p><p>Feel free to give yourself ~5 minutes to come up with your own idea. Try to pay attention to how you approached it, and compare it to what I did. My main project this year is about figuring out how to figure out things, so I'd be very grateful if you tried to describe your approach. Even if you think your process \"looks dumb\" or somesuch, I think having the courage to reveal your inner workings and talk openly about it reflects some extremely important virtues--<i>especially</i> if you think it's dumb. This is a collaboration, not a contest.</p><hr><h1>Conceptual research methodology</h1><p>The Inventor's Paradox is the observation that when you're trying to solve a specific problem, <strong>it's often easier to solve a bigger problem that includes the specific problem as a special case</strong>.</p><p>Why? I don't know yet, but one aspect of it is that when you go up an abstraction level to solve a more general problem, you have fewer objects you need to reason over and therefore a much smaller search tree. E.g. if you're solving <a href=\"https://en.wikipedia.org/wiki/Inventor%27s_paradox\">a specific problem involving all integers between 1 and 99</a>, it takes more information to specify that set of particular numbers than it takes to just specify \"all integers\". <strong>You're compressing the detail into smaller objects whose essential features now pop out to your mind's eye</strong>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffjisrukqxa9\"><sup><a href=\"#fnfjisrukqxa9\">[1]</a></sup></span></p><p>In problem-solving, the hardest and most productive step is often figuring out which parts you can ignore. How can you turn a problem with seemingly many moving parts, into a problem with fewer moving parts?</p><p>Anyway, solving the nuclear conflict between Russia and other countries seems like a really hard problem. So many details! Thus, the level of analysis I start out with is not \"how can I personally contribute?\" nor is it even \"how can we resolve the Ukraine-Russia conflict\". Instead, I find what I call the <i>\"<strong>shower-thought level</strong>\"</i>, and ask myself,</p><blockquote><p><i>\"What's a general mechanism for ending all nuclear war\"?</i></p></blockquote><p>When I reframe the problem like this, it forces me to think about the most general features, and allows me to go into problem-solving mode instead of \"I have no clue, I need to read more\". Zooming in and dealing with the details becomes necessary at some point, but there's an appropriate time for that which is not yet. First, I need to have a high-level inside-view model that lets me have an idea of what specific details to even start looking for. In other words, I'm looking for something I can think productively about while in the shower.</p><p>For real-world thinking with <a href=\"https://arbital.com/p/rich_domain/\">enormous search trees</a>, collecting as many ideas that seem like they can make metaphors to other stuff is a good general strategy. When the search space is so large, it's nearly impossible to build a new functional model from scratch. It becomes necessary to look for existing models from other fields (or nature), and iteratively testing them against the new use-case and tweaking them accordingly.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefv9qk8ajv5k\"><sup><a href=\"#fnv9qk8ajv5k\">[2]</a></sup></span></p><p>Furthermore, I think the popular advice of \"<a href=\"https://www.lesswrong.com/posts/uHYYA32CKgKT3FagE/hold-off-on-proposing-solutions\">hold off on proposing solutions</a>\" is often overapplied. As long as I'm confident in my ability to avoid imprinting on the first idea I find, I often propose several dumb solutions as a way to learn about the problem in the first place. If I don't believe in myself, I might be anxiously attached to the first thing I produce because I doubt I'll be able to find anything else.</p><hr><h1>\"Nuke swapping\" to de-escalate nuclear stockpiles</h1><p>When two competitors are in direct conflict but neither of them wants to waste resources on a fight, I have two metaphors that spring to mind: <a href=\"https://en.wikipedia.org/wiki/Assurance_contract\">assurance contracts</a> and <a href=\"https://en.wikipedia.org/wiki/Vote_pairing\">vote swapping</a>. I've long thought that assurance contracts are the best thing ever, but I couldn't see a way to make them work in this case (~2 minutes). So I move on to explore the other pattern.</p><p><i>Vote swapping</i> is when two voters for opposing sides in a single-winner election agree to vote for a third candidate instead. If the election is overwhelmingly bipolar, then the two votes would by default directly cancel each other out. But they might both value a third candidate above zero, so vote swapping lets them net a positive sum instead of a zero sum.</p><p>This seems sorta kinda like a nuclear standoff, but I can't immediately see how. So I spend a few minutes trying to force the metaphor until something clicks. What I end up with doesn't really fit with vote swapping in the election case. Instead, I find new pattern that I could only arrive at by trying to force the metaphor and deliberately trusting myself in that I can find something that is valuable. (~4 minutes)</p><p>In a situation where two sides depend on <a href=\"https://en.wikipedia.org/wiki/Mutual_assured_destruction\">mutually assured destruction</a> for their safety, neither of them would want to disarm unilaterally. Even if both sides strongly prefer the world were neither side had nuclear weapons, disarming asymmetrically would upset the balance of power, which could in the worst case have the consequence of making a nuclear attack more likely. So what's a mechanism for ensuring symmetric disarmament that doesn't upset the balance?</p><p><i>(On reflection, I think I was mistaken here about this being one of the main bottlenecks for this to work. But while I'm trying to generate something, I endorse not spending too much time trying to critique what I'm coming up with at every point. I want to have something coherent that snaps into place, and that complete pattern may let me see further metaphors that I can draw on to understand the problem. I can more rigorously vet each step after I've already made the model.)</i></p><p>Here the concept of an <a href=\"https://en.wikipedia.org/wiki/Escrow\"><i>escrow</i></a> comes to mind because it's used it variants of assurance contracts, which is a metaphor I previously activated. One side of the conflict places an insignificant quantity of weapons (a 'unit') into the hands of a mutually trusted third party who's responsible for verifying and destroying it. If the unit is small enough, it won't shift the balance of power enough for it to matter, so the cost to the initial 'bid' is insignificant.</p><p>But once an insignificant bid has been made, there is pressure on the other party to match it, because it'll be politically unreasonable to refuse such a marginal sacrifice for the global good. This will then hopefwly trigger the opposite of an escalation of conflict--an iterative game of \"nuke swapping\". Just like how arms races build themselves up because there's momentum in the direction of escalation, the marginal nuke swapping will hopefwly spark momentum for de-escalation.</p><p>Now I just need to tell Putin!</p><hr><h1>After the aha moment</h1><p>I recognise how important it is to be innocently excited about the ideas I produce, otherwise my brain won't be very motivated to comply next time I ask it to produce something for me. So I feel pretty excited about this idea. Humility has its uses when the stakes are high, but I'm just exploring. And as long as I don't fool myself into thinking I have a finished product, I don't want to constrain my creativity by worrying about whether it's socially appropriate.</p><p>Although I think the idea is wrong, I think it's productively wrong in the sense that there are many parts that can be tweaked to look for less wrong ideas nearby.&nbsp;</p><p>I doubt in the applicability of my idea, because if I don't have a good understanding of the problem I'm fitting my solution to, it's unlikely to fit. But I'm still able to feel excited about this because I think it's <i>productively wrong. </i>Models that are wrong for a particular use-case may still still be part of the arsenal I can use against other problems, or I can tweak them until they do fit. And moreover, I can feel excited about having gone through a <i>process</i> which I endorse and would like to see universally adopted.</p><hr><h1>Where I think it goes wrong</h1><p>After generation, I move on to analysing and critiquing. Again, I use metaphorical thinking, because now that I have a new pattern, I may be able to see similarities to different models that do slightly different things. Metaphorical thinking lets me ask questions like \"why does that model do it like that when my model does it like this?\" and it hints me about where I might've gone wrong.</p><p>I can quickly see at least two possible mechanistic reasons, but I'm sure there are plenty that I'm not immediately seeing here.</p><ol><li>The side that's weaker by conventional weapons does not want to agree to start the chain, because they can get trampled if they cooperate. MAD benefits the weaker side because it ensures stalemate when the weaker side would otherwise overwhelmingly lose a conventional war.</li><li>The analogy to elections breaks down because the incentive to swap marginal weapons goes down the more weapons you've already swapped. It becomes less and less like a bipolar conflict because the fewer nukes you have, the more you have to worry about other non-nuclear actors now becoming a threat. &nbsp;(H/T <a href=\"https://forum.effectivealtruism.org/users/ruth_freiling_duplicate0-9597937224729234\">Ruth</a>)</li></ol><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfjisrukqxa9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffjisrukqxa9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Note, when you compress the problem into general abstract categories, you have fewer details to talk about, so you don't have as many opportunities to reveal your expertise by talking about the many details you know. Writing about the finer details will often look more impressive and professional, although imo that doesn't necessarily translate to being more usefwl, and I think it can often bias people to start at the wrong level of abstraction.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnv9qk8ajv5k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefv9qk8ajv5k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I have a flashcard collection in RemNote of &gt;100 ideas/patterns/tools/perspectives that I feel will be the most generally applicable to other problems. Sometimes when I'm stuck, I flip through this list, and it's been <a href=\"https://forum.effectivealtruism.org/posts/dRAuYCKJprx8uMcYR/emrik-s-shortform?commentId=6F8D25oELDyM5TekB\">surprisingly effective</a> for me. I call them \"germs of generality\", taking inspiration from <a href=\"https://www.goodreads.com/quotes/8430782-the-art-of-doing-mathematics-consists-in-finding-that-special\">David Hilbert</a>.</p></div></li></ol>", "user": {"username": "Emrik"}}, {"_id": "SemaeDLxJe9Bsttaj", "title": "My (Lazy) Longtermism FAQ", "postedAt": "2022-10-24T16:44:06.286Z", "htmlBody": "<p><em>In the wake of the What We Owe the Future media frenzy, there have been lots of questions and takes from outsiders that I feel haven\u2019t been collected and responded to in a satisfyingly comprehensive way yet. In that spirit, I\u2019ve been thinking for a couple months about writing an FAQ-style response to common criticisms that I can point people to for my thoughts when the subject comes up, unfortunately I\u2019ve been horrifically busy this semester and haven\u2019t made any progress. I then realized that I already have written responses roughly like those I would give in this FAQ to many of these points, in the form of longish comments.</em></p>\n<p><em>I then had a very lazy idea, what if I compile these comments into an FAQish format, grouped together based on which criticism they relate to? I\u2019m not sure how much value it will provide to others, it\u2019s kind of a weird awkward thing, but I wanted to have something with my own takes on this stuff that I can point people to, so I figure this will serve for now. Even if it doesn\u2019t provide value to anyone else, this seemed like the right place to host it. I may or may not edit this into something more like a standard FAQ when I have the time.</em></p>\n<p><em>Feel free to suggest your own questions in the comments, and I may respond and/or add them. Also this document doesn\u2019t just have counters to criticisms, but also criticisms I agree with in some way, as you will see for some of them. I think there is plenty worth criticizing in this movement, much as I love it all things considered.</em></p>\n<p><em>These opinions are purely my own, and I think lots of other EAs will disagree with plenty of what I say in each. They also tend to be replying to specific posts, which makes them read weirdly, but I chose these comments because I think their core points stand alone as well.</em></p>\n<p><em>Without further ado, here\u2019s a collection of my takes on these various issues:</em></p>\n<h1>Q1: Isn\u2019t longtermism or EA secretly just hardcore utilitarianism?</h1>\n<p><a href=\"https://forum.effectivealtruism.org/posts/PZ6pEaNkzAg62ze69/ea-criticism-contest-why-i-am-not-an-effective-altruist?commentId=g8keo44YdYacMTwyn\">https://forum.effectivealtruism.org/posts/PZ6pEaNkzAg62ze69/ea-criticism-contest-why-i-am-not-an-effective-altruist?commentId=g8keo44YdYacMTwyn</a></p>\n<blockquote>\n<p>\u201cI think the comparison between calling yourself a Christian but not believing in the Divinity of Jesus or something is a worse analogy to being a non-Utilitarian EA than calling yourself a Republican but not believing in the divinity of Jesus. It\u2019s true that utilitarianism is overrepresented among EAs including influential ones, and most of their favored causes are ones utilitarians like, but it is my impression that most EAs are not utilitarians and almost none of them think utilitarianism is just what EA is.</p>\n</blockquote>\n<blockquote>\n<p>Given this, the post reads to me sort of like \u2018I\u2019m a pro-life free market loving Buddhist, but Christianity is wrong therefore I can\u2019t be a Republican\u2019.</p>\n</blockquote>\n<blockquote>\n<p>This makes the rest of the post less compelling to me to be honest, debates about high level moral philosophy are interesting but unlikely to be settled over one blogpost (even just the debate over pure aggregation is extremely complicated, and you seem to take a very dismissive attitude towards it), and the connection to EA as a movement made in the post seems too dubious to justify it. The piece seems like a good explanation of why you aren\u2019t a utilitarian, but I don\u2019t take it that that was your motive.\u201d</p>\n</blockquote>\n<p><a href=\"https://forum.effectivealtruism.org/posts/PZ6pEaNkzAg62ze69/ea-criticism-contest-why-i-am-not-an-effective-altruist?commentId=wSDcBYiydsaoenRHF\">https://forum.effectivealtruism.org/posts/PZ6pEaNkzAg62ze69/ea-criticism-contest-why-i-am-not-an-effective-altruist?commentId=wSDcBYiydsaoenRHF</a></p>\n<blockquote>\n<p>\u201cTo be honest, I did feel like it came off this way to me as well. The majority of the piece feels like an essay on why you think utilitarianism sucks, and this post itself frames this as a criticism of EA\u2019s \u2018utilitarian core\u2019. I sort of remember the point about EA just being ordinary do gooding when you strip this away as feeling like a side note, though I can reread it when I get a chance in case I missed something.</p>\n</blockquote>\n<blockquote>\n<p>To address the point though, I\u2019m not sure it works either, and I feel like the rest of your piece undermines it. Lots of things EA focuses on, like animal welfare and AI safety, are weird or at least weird combinations, so are plenty of its ways of thinking and approaching questions. These are consistent with utilitarianism, but they aren\u2019t specifically tied to it, indeed you seem drawn to some of these and no one is going to accuse you of being a utilitarian after reading this, I have to imagine the idea that you do think something valuable and unique is left behind if you don\u2019t just view EA as utilitarianism has to at least partly be behind your suggestion that we \u2018dilute the poison\u2019 all the way out. If we already have \u2018diluted the poison\u2019 out, I\u2019m not sure what\u2019s left to argue.</p>\n</blockquote>\n<blockquote>\n<p>The point about how the founders of the movement have generally been utilitarians or utilitarian sympathetic doesn\u2019t strike me as enough to make your point either[1]. If you mean that the movement is utilitarian at its core in the sense that utilitarianism motivated many of its founders, this is a good point. If you mean that it has a utilitarian core in the sense that it is \u201cpoisoned\u201d by the types of implications of utilitarianism you are worried about, this doesn\u2019t seem enough to get you there. I also think it proves far to much to mention the influence of Famine, Affluence and Morality. Non-utilitarian liberals regularly cite On Liberty, non-utilitarian vegans regularly cite Animal Liberation. Good moral philosophers generally don\u2019t justify their points from first principles, but rather with the minimum premises necessary to agree with them on whatever specific point they\u2019re arguing. These senses just seem crucially different to me.</p>\n</blockquote>\n<blockquote>\n<ol>\n<li>I also think it\u2019s overstated. Singer is certainly a utilitarian, but <a href=\"https://mobile.twitter.com/willmacaskill/status/1559196018062786560\">MacAskill</a> overtly does not identify as one even though he is sympathetic to the theory and I think has plurality credence in it relative to other similarly specific theories, Ord I believe is the same, Bostrom overtly does not identify with it, Parfit moved around a bunch in his career but by the time of EA I believe he was either a prioritarian or \u201ctriple theorist\u201d as he called it, Yudkowsky is a key example of yours but from his other writing he seems like a pluralist consequentialist at most to me. It\u2019s true that, as your piece points out, he defends pure aggregation, but so do tons of deontologists these days, because it turns out that when you get specific about your alternative, it becomes <a href=\"https://spot.colorado.edu/~norcross/Comparingharms.pdf\">very</a> <a href=\"https://discovery.ucl.ac.uk/id/eprint/10062029/1/Always%20Aggregate.pdf\">hard</a> not to be a pure aggregationist.\u201d</li>\n</ol>\n</blockquote>\n<p><a href=\"https://forum.effectivealtruism.org/posts/nTybQwrnyRMenasCc/?commentId=ksAA8nJDuoqg5pkPZ\">https://forum.effectivealtruism.org/posts/nTybQwrnyRMenasCc/?commentId=ksAA8nJDuoqg5pkPZ</a></p>\n<blockquote>\n<p>\"</p>\n<blockquote>\n<p>\u2018If the basic idea of long-termism\u2014giving future generations the same moral weight as our own\u2014seems superficially uncontroversial, it needs to be seen in a longer-term philosophical context. Long-termism is a form of utilitarianism or consequentialism, the school of thought originally developed by Jeremy Bentham and John Stuart Mill.</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>The utilitarian premise that we should do whatever does the most good for the most people also sounds like common sense on the surface, but it has many well-understood problems. These have been pointed out over hundreds of years by philosophers from the opposing schools of deontological ethics, who believe that moral rules and duties can take precedence over consequentialist considerations, and virtue theorists, who assert that ethics is primarily about developing character. In other words, long-termism can be viewed as a particular position in the time-honored debate about inter-generational ethics.</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>The push to popularize long-termism is not an attempt to solve these long-standing intellectual debates, but to make an end run around it. Through attractive sloganeering, it attempts to establish consequentialist moral decision-making that prioritizes the welfare of future generations as the dominant ethical theory for our times.\u2019</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>This strikes me as a very common class of confusion. I have seen many EAs say that what they hope for out of \u2018What We Owe the Future\u2019 is that it will act as a sort of \u2018Animal Liberation for future people\u2019. You don't see a ton of people saying something like \u2018caring about animals seems nice and all, but you have to view this book in context. Secretly being pro-animal liberation is about being a utilitarian sentientist with an equal consideration of equal interests welfarist approach, that awards secondary rights like life based on personhood\u2019. This would seem either like a blatant failure of reading comprehension, or a sort of ethical paranoia that can't picture any reason someone would argue for an ethical position that didn't come with their entire fundamental moral theory tacked on.</p>\n</blockquote>\n<blockquote>\n<p>On the one hand I think pieces like this are making a more forgivable mistake, because the basic version of the premise just doesn't look controversial enough to be what MacAskill actually is hoping for. Indeed I personally think the comparison isn't fantastic, in that MacAskill probably hopes the book will have more influence on inspiring further action and discussion than on changing minds about the fundamental issue (which again is less controversial, and which he spends less time in the book on).</p>\n</blockquote>\n<blockquote>\n<p>On the other hand, he has been at special pains to emphasize in his book, interviews, and secondary writings, that he is highly uncertain about first order moral views, and is specifically, only arguing for longtermism as a coalition around these broad issues and ways of making moral decisions on the margins. Someone like MacAskill who is specifically arguing for a period where we hold off from irreversible changes as long as possible in order to get these moral discussions right really doesn't fit the bill or someone trying to \u2018make an end run around\u2019 these issues.\u201d</p>\n</blockquote>\n<h1>Q2: Isn\u2019t it really weird that so many EAs are worried about sci fi AI risks?</h1>\n<p><a href=\"https://forum.effectivealtruism.org/posts/hLbWWuDr3EbeQqrmg/reasons-for-my-negative-feelings-towards-the-ai-risk?commentId=vBqveKxzmiSM9Kz4F\">https://forum.effectivealtruism.org/posts/hLbWWuDr3EbeQqrmg/reasons-for-my-negative-feelings-towards-the-ai-risk?commentId=vBqveKxzmiSM9Kz4F</a></p>\n<blockquote>\n<p>\u201cI can understand many of these points, though I disagree with most of them. I think the speculativeness point worries me most though, and I see it pretty frequently. I totally agree that AI risks are currently very uncertain and speculative, but I guess I think the relevance of this comes down to a few points:</p>\n</blockquote>\n<blockquote>\n<ol>\n<li>Is it highly plausible that when AI as smart as or smarter than humans arrives, this will be a huge, world changing threat?</li>\n<li>Around how long do we need to address this threat properly?</li>\n<li>How soon before this threat materializes do we think our understanding of the risks will cross your threshold of rigor?</li>\n</ol>\n</blockquote>\n<blockquote>\n<p>You might disagree on any of this, but for my own part I think it is fairly intuitive that the answers to these are \u2018yes\u2019, \u2018decades at least\u2019, and \u2018years at most\u2019 respectively when you think about it. Taken together, this means that the speculativeness objection will by default sleepwalk us into the worst defaults of this risk, and that we should really start taking this risk as seriously as we ever plan to when it is still uncertain and speculative.</p>\n</blockquote>\n<blockquote>\n<p>I think this on its own doesn\u2019t answer whether it is a good cause area right now, alien invasion, the expansion of the sun, and the heat death of the universe all look like similarly big and hard problems, but they are arguably less urgent, we expect them much longer from now. A final assumption needed to worry about AI risks now, which you seem to disagree on, is that this is coming pretty darn soon.</p>\n</blockquote>\n<blockquote>\n<p>I want to emphasize this as much as possible, <em>this is super unclear and all of the arguments about when this is coming are sort of pretty terrible</em>, but all of the most systematic, least pretty terrible ones I\u2019m aware of converge on \u2018around a century or sooner, probably sooner, possibly much sooner\u2019, like the partially informative priors study, Ajeya Cotra\u2019s biological anchors report (which Cotra herself thinks estimates too late an arrival date), expert surveys, and metaculus.</p>\n</blockquote>\n<blockquote>\n<p>Again, all of this could very easily be wrong, but I don\u2019t see a good enough reason to default to that assumption, so I think it just is the case that, not only should we take this risk as seriously as we ever plan to while it\u2019s still speculative, but we should take this risk as seriously as we ever plan to as soon as possible. I would recommend reading Holden Karnofsky\u2019s most important century series for a more spelled out version of similar points, especially about timelines, if you\u2019re interested, but that\u2019s my basic view on this issue and how to react to the speculativeness.\u201d</p>\n</blockquote>\n<p><a href=\"https://forum.effectivealtruism.org/posts/hLbWWuDr3EbeQqrmg/reasons-for-my-negative-feelings-towards-the-ai-risk?commentId=mkWoWFhrNvCs9767J\">https://forum.effectivealtruism.org/posts/hLbWWuDr3EbeQqrmg/reasons-for-my-negative-feelings-towards-the-ai-risk?commentId=mkWoWFhrNvCs9767J</a></p>\n<blockquote>\n<p>\u201cOn the standard \u2018importance, tractability, neglectedness\u2019 framework, I agree that tractability is AI risk's worst feature if that's what you mean. I think there is some consensus on this amongst people worried about the issue, as stated in 80k's <a href=\"https://80000hours.org/problem-profiles/artificial-intelligence/\">recently updated profile</a> on the issue:</p>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>\u2018Making progress on preventing an AI-related catastrophe seems hard, but there are a lot of avenues for more research and the field is very young. So we think it\u2019s moderately tractable, though we\u2019re highly uncertain \u2014 again, assessments of the tractability of making AI safe vary enormously.\u2019</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>I think these other two aspects, importance and neglectedness, just matter a great deal and it would be a bad idea to disqualify cause areas just for moderately weak tractability. In terms of importance, transformative AI seems like it could easily be the most powerful technology we've ever made, for roughly the same reasons that humans are the most transformative \u2018technology\u2019 on Earth right now. But even if you think this is overrated, consider the relatively meager funds and tiny field as it exists today. I think many people who find the risk a bit out there would at least agree with you that it's \u2018worth some thought and research\u2019, but because of the rarity of the type of marginal thinking about good and willingness to take weird-sounding ideas seriously found in EA, practically no one else is ensuring that there is some thought and research. The field would, arguably, almost entirely dry up if EA stopped routing resources and people towards it.</p>\n</blockquote>\n<blockquote>\n<p>Again though, I think maybe some of the disagreement is bound up in the \u2018some risk\u2019 idea. My vague impression, and correct me if this doesn't describe you, is that people who are weirded out by EA working on this as a cause area think that it's a bit like if EA was getting people, right now, to work on risks from alien invasions (and then a big question is why isn't it?), whereas people like me who are worried about it think that it is closer to working on risks from alien invasions if NASA discovered an alien spaceship parked five lightyears away from us. The risks here would still be very uncertain, the timelines, what we might be able to do to help, what sorts of things these aliens would be able to or want to do, but I think it would still look crazy if almost no one was looking into it, and I would be very wary of telling one of the only groups that was trying to look into it that they should let someone else handle it.</p>\n</blockquote>\n<blockquote>\n<p>If you would like I would be happy to chat more about this, either by DMs, or email, or voice/video call. I'm probably not the most qualified person since I'm not in the field, but in a way that might give you a better sense of why the typical EA who is worried about this is. I guess I would like to make this an open invitation for anyone this post resonates with. Feel absolutely no pressure to though, and if you prefer I could just link some resources I think are helpful.</p>\n</blockquote>\n<blockquote>\n<p>I'm just in the awkward position of both being very worried about this risk, and being very worried about how EA talking about this risk might put potential EAs off. I think it would be a real shame if you felt unwelcome or uncomfortable in the movement because you disagree about this risk, and if there's something I can do to try to at least persuade you that those of us who are worried are worth sharing the movement with at least, I would like to try to do that.\u201d</p>\n</blockquote>\n<h1>Q3: Isn\u2019t longtermism focusing on future generations at the expense of those in the present?</h1>\n<p><a href=\"https://forum.effectivealtruism.org/posts/8Swy2TCLBHwWA2Rga/caring-about-the-future-doesn-t-mean-ignoring-the-present?commentId=w5PZuKkdD4ktqrntT\">https://forum.effectivealtruism.org/posts/8Swy2TCLBHwWA2Rga/caring-about-the-future-doesn-t-mean-ignoring-the-present?commentId=w5PZuKkdD4ktqrntT</a></p>\n<blockquote>\n<p>\u201cI like this piece, but I think it misses an opportunity to comment more broadly on the dynamic at work. My own impression can be glossed in roughly this way: most money goes to the here and now, most careers go to the future (not an overwhelming majority in either case though, and FTX may have changed the funding balance). This makes sense based on talent versus funding gaps, and means the two don\u2019t really need to compete much at all, indeed many of the same people contribute to both in different ways.\u201d</p>\n</blockquote>\n<h1>Q4: Why do lots of EAs support the idea that making more people is better? Why not prefer just improving lives with no regard to numbers, or taking the average?</h1>\n<p><a href=\"https://forum.effectivealtruism.org/posts/BLcyqjiXaKg7BCSxj/confused-about-making-people-happy-vs-making-happy-people?commentId=45PWgbkkT3nYFaDyY\">https://forum.effectivealtruism.org/posts/BLcyqjiXaKg7BCSxj/confused-about-making-people-happy-vs-making-happy-people?commentId=45PWgbkkT3nYFaDyY</a></p>\n<blockquote>\n<p>\u201cI think this is actually a central question that is relatively unresolved among philosophers, but it is my impression that philosophers in general, and EAs in particular, lean in the \u2018making happy people\u2019 direction. I think of there as being roughly three types of reason for this. One is that views of the \u2018making people happy\u2019 variety basically always wind up facing structural weirdness when you formalize them. It was my impression until recently that all of these views imply intransitive preferences (i.e something like A&gt;B&gt;C&gt;A), until I had a discussion with <a href=\"https://forum.effectivealtruism.org/posts/DCZhan8phEMRHuewk/?commentId=ZadcAxa2oBo3zQLuQ#iKT5A7BGjsBaCXc7T\">Michael St Jules</a> in which he pointed out more recent work that instead denies the independence of irrelevant alternatives. This avoids some problems, but leaves you with something very structurally weird or even absurd to some. I think Larry Temkin has a good quote about it something like \u2018I will have the chocolate ice-cream, unless you have vanilla, in which case I will have strawberry\u2019.</p>\n</blockquote>\n<blockquote>\n<p>The second reason is the non-identity problem, formalized by Derek Parfit. Basically the issue this raises is that almost all of our decisions that impact the longer term future in some way also change who gets born, so a standard person affecting view seems to allow us to do almost anything to future generations. Use up all their resources, bury radioactive waste, you name it.</p>\n</blockquote>\n<blockquote>\n<p>The third maybe connects more directly to why EAs in particular often reject these views. Most EAs subscribe to a sort of universalist, beneficent ethics, that seems to imply that if something is genuinely good for someone, then that something is good in a more impersonal sense that tugs on ethics for all. For those of us who live lives worth living, are glad we were born, and don't want to die, it seems clear that existence is good for us. If this is the case, it seems like this presents a reason for action to anyone who can impact it if we accept this sort of universal form of ethics. Therefore, it seems like we are left with three choices. We can say that our existence actually is good for us, and so it is also good for others to bring it about, we can say that it is not good for others to bring it about, and therefore it is not actually good for us after all, or we can deny that ethics has this omnibenevolent quality. To many EAs, the first choice is clearly best.</p>\n</blockquote>\n<blockquote>\n<p>I think here is where a standard person-affecting view might counter that it cares about all reasons that actually exist, and if you aren't born, you don't actually exist, and so a universal ethics on this timeline cannot care about you either. The issue is that without some better narrowing, this argument seems to prove too much. All ethics is about choosing between possible worlds, so just saying that a good only exists in one possible world doesn't seem like it will help us in making decisions between these worlds. Arguably the most complete spelling out of a view like this looks sort of like \u2018we should achieve a world in which no reasons for this world not to exist are present, and nothing beyond this equilibrium matters in the same way\u2019. I actually think some variation of this argument is sometimes used by negative utilitarians and people with similar views. A frustrated interest exists in the timeline it is frustrated in, and so any ethics needs to care about it. A positive interest (i.e. having something even better than an already good or neutral state) does not exist in a world in which it isn't brought about, so it doesn't provide reasons to that world in the same way. Equilabrium is already adequetely reached when no one is badly off.</p>\n</blockquote>\n<blockquote>\n<p>This is coherent, but again it proves much more than most people want to about what ethics should actually look like, so going down that route seems to require some extra work.\u201d</p>\n</blockquote>\n<p><a href=\"https://forum.effectivealtruism.org/posts/vjDLRBaEWMmrHhrtv/the-standard-person-affecting-view-doesn-t-solve-the?commentId=rSLkjk2M2LzhMgYZC\">https://forum.effectivealtruism.org/posts/vjDLRBaEWMmrHhrtv/the-standard-person-affecting-view-doesn-t-solve-the?commentId=rSLkjk2M2LzhMgYZC</a></p>\n<blockquote>\n<p>\u201cI was pretty aggravated by this part of the review, it's my impression that Alexander wasn't even endorsing the person-affecting view, but rather some sort of averagism (which admittedly does outright escape the repugnant conclusion). The issue is I think he's misunderstanding the petition on the repugnant conclusion. The authors were not endorsing the statement \u2018the repugnant conclusion is correct\u2019 (though some signatories believe it) but rather \u2018a theory implying the repugnant conclusion is not a reason to reject it outright\u2019. One of the main motivators of this is that, not as a matter of speculation, but as a matter of provable necessity, any formal view in this area has some implication people don't like. He sort of alludes to this with the eyeball pecking asides, but I don't think he internalizes the spirit of it properly. You don't reject repugnancy in population ethics by picking a theory that doesn't imply this particular conclusion, you do it by not endorsing your favored theory under its worst edge cases, whatever that theory is.</p>\n</blockquote>\n<blockquote>\n<p>Given this, there just doesn't seem to be any reason to take the principled step he does towards averagism, and arguably averagism is the theory that is least on the table on its principled merits. I am not aware of anyone in the field who endorses average, and I was recently at an EA NYC talk on population ethics with Timothy Campbell in which he basically said outright that the field has, for philosophy an unusually strong consensus, that average is simply off the table. Average can purchase the non-existence of worthwhile lives at the cost of some happiness of those who exist in both scenarios. The value people contribute to the world is highly extrinsic to any particular person's welfare, to the point where whether a life is good or bad on net can have no relation to whether that life is good or bad for anyone in the world, whether the person themself, or any of the other people who were already there. Its repugnant implications seem to be deeper than just the standard extremes of principled consistency.\u201d</p>\n</blockquote>\n<h1>Q5: What about (miscellaneous things in the New Yorker piece)?:</h1>\n<p><a href=\"https://forum.effectivealtruism.org/posts/iJqmj42pCdDbvZhHB/cover-story-on-ea-in-time-magazine?commentId=3paX4nmyEchcjvEAw\">https://forum.effectivealtruism.org/posts/iJqmj42pCdDbvZhHB/cover-story-on-ea-in-time-magazine?commentId=3paX4nmyEchcjvEAw</a></p>\n<blockquote>\n<p>\u201cI don\u2019t know what Josh thinks the flaws are, but since I agree that this one is more flawed, I can speak a bit for myself at least. I think most of what I saw as flawed came from isolated moments, in particular criticisms the author raised that seemed to me like they had fairly clear counterpoints that the author didn\u2019t bring up (other times he managed to do this quite well). A few that stand out to me, off the top of my head:</p>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>\u2018Cremer said, of Bankman-Fried, \u2018Now everyone is in the Bahamas, and now all of a sudden we have to listen to three-hour podcasts with him, because he\u2019s the one with all the money. He\u2019s good at crypto so he must be good at public policy&nbsp;.&nbsp;.&nbsp;. what?!\u2019\u2019</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>The 80,000 Hours podcast is about many things, but principally and originally it is about effective career paths. Earning to give is recommended less these days, but they\u2019ve only had one other interview with someone who earned to give that I can recall, and SBF is by far the most successful example of the path to date. Another thing the podcast is about is the state of EA opportunities/organizations. Learning about the priorities of one of the biggest new forces in the field, like FTX, seems clearly worthwhile for that. The three hours point is also misleading to raise, since that is a very typical length for 80k episodes.</p>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>\u2018Longtermism is invariably a phenomenon of its time: in the nineteen-seventies, sophisticated fans of \u2018Soylent Green\u2019 feared a population explosion; in the era of \u2018The Matrix,\u2019 people are prone to agonize about A.I.\u2019</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>This point strikes me as very as hoc. AI is one of the oldest sci-fi tropes out there, and in order to find a recent particularly influential example they had to go back to a movie over 20 years old that looks almost nothing like the risks people worry about with AI today. Meanwhile the example of population explosion is also cherry picked to be a case of sci fi worry that seems misguided in retrospect. Why doesn\u2019t he talk about the era of \u2018Dr. Strangelove\u2019 and \u2018War Games\u2019\u2019? And immediately after this,</p>\n</blockquote>\n<blockquote>\n<blockquote>\n<p>\u2018In the week I spent in Oxford, I heard almost nothing about the month-old war in Ukraine. I could see how comforting it was, when everything seemed so awful, to take refuge on the higher plane of millenarianism.\u2019</p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>Some people take comfort in this probably, but generally those are people, like the author, who aren\u2019t that viscerally worried about the risk. Others have very serious mental health problems from worrying about AI doom. I\u2019ve had problems like this to some degree, others have had it so bad they have had to leave the movement entirely, and indeed criticize it in the <a href=\"https://mobile.twitter.com/QiaochuYuan/status/1353836116378439681\">complete opposite direction</a>.</p>\n</blockquote>\n<blockquote>\n<p>I am not saying that people who academically or performatively believe in AI risks, and can seek refuge in this, don\u2019t exist. I\u2019m also not saying the author had to do yet more research and turn up solid evidence that the picture he is giving is incomplete, but when you start describing people thinking everything and everyone they love may be destroyed soon as a comforting coping mechanism, I think you should bring at least a little skepticism to the table. It is possible that this just reflects the fact that you find a different real world problem emotionally devastating at the moment and thinking about this risk you don\u2019t personally take seriously is a distraction for you, and you failed your empathy roll this time.</p>\n</blockquote>\n<blockquote>\n<p>A deeper issue might be the lack of discussion of the talent constraint on many top cause areas in the context of controversies over spending on community building, which is arguably the key consideration much of the debate turns on. The increased spending on community building (which still isn\u2019t even close to most of the spending) seems more uncomplicatedly bad if you miss this dimension.</p>\n</blockquote>\n<blockquote>\n<p>Again though, this piece goes through a ton of points, mostly quite well, and can\u2019t be expected to land perfectly everywhere, so I\u2019m pretty willing to forgive problems like these when I run into them. They are just the sorts of things that made me think this was more flawed than the other pieces.\u201d</p>\n</blockquote>\n<h1>Q6: EAs don\u2019t respond to alot of these criticisms very prominently as a rule, what\u2019s the deal?</h1>\n<p><a href=\"https://forum.effectivealtruism.org/posts/FtDAtzGqAgBh9x6DA/going-too-meta-and-avoiding-controversy-carries-risks-too-a?commentId=8P2QrQoGpE4Hc5h3L\">https://forum.effectivealtruism.org/posts/FtDAtzGqAgBh9x6DA/going-too-meta-and-avoiding-controversy-carries-risks-too-a?commentId=8P2QrQoGpE4Hc5h3L</a></p>\n<blockquote>\n<p>\u201cI disagree with this pretty strongly, and have been worried about this type of view in particular quite a bit recently. It seems as though a standard media strategy of EAs is, if someone publishes a hit piece on us somewhere, either sort of obscure or prominent, just ignore it and \u2018respond\u2019 by presenting EA ideas better to begin with elsewhere. This is a way of being positive rather than negative in interactions, and avoiding signal-boosting bad criticisms. I don't know how to explain how I have such a different impression, or why so many smart people seem to disagree with me, but this looks to me like an intuitively <em>terrible, obvious mistake</em>.</p>\n</blockquote>\n<blockquote>\n<p>I don't know how to explain why it feels to me so clear that if someone is searching around, finding arguments that EA is a robot cult, or secretly run by evil billionaires, or some other harsh misleading critique, and nothing you find in favor of EA written for a mainstream audience even acknowledges these critics, and instead just presents some seemingly innocuous face of EA, the net takeaway will tend towards \u2018EA is a sinister group all of these people have been trying to blow the whistle on\u2019. Basically all normal social movements have their harsh critics, and even if they don't always respond well to them, they almost all respond to them as publicly as possible.</p>\n</blockquote>\n<blockquote>\n<p>The excuse that the criticisms are so bad that they don't deserve the signal (which to be clear isn't one this particular post is arguing) also leads me to think this norm encourages bad epistemics, and provides a fully general excuse. I tend to think that bad criticisms of something obscure like EA are generally quite easy for EAs to write persuasive debunking pieces on, so either a public criticism is probably bad enough that publicly responding is worth the signal boost you give the original piece, or it is good enough that it deserves the signal. Surely there are some portion of criticisms that are neither, and that are hard to be persuasive against but are still bad, but we shouldn't orient the movement's entire media strategy around those. I wholeheartedly agree with this comment:</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://forum.effectivealtruism.org/posts/kageSSDLSMpuwkPKK/response-to-recent-criticisms-of-longtermism-1?commentId=WycArpwah9aveNrZs\">https://forum.effectivealtruism.org/posts/kageSSDLSMpuwkPKK/response-to-recent-criticisms-of-longtermism-1?commentId=WycArpwah9aveNrZs</a></p>\n</blockquote>\n<blockquote>\n<p>If some EA ever had the opportunity to write a high-quality response like Avital's, or to be blunt almost any okay response, to the Torres piece in Aeon or Current Affairs, or for that matter in WSJ to their recent hit piece, I think it would be a really really good idea to do so, the EA forum is not a good enough media strategy. ACX is easy mode for this, Alexander himself is sympathetic to EA, so his main text isn't going to be a hit piece, and the harsher points in the comments are ones people can respond to directly, <em>and</em> he will even directly signal boost the best of these counter-criticisms, as he did. I am very scared for the EA movement if even this looks like a scary amount of daylight.</p>\n</blockquote>\n<blockquote>\n<p>This is something I've become so concerned about I've been strongly considering posting an edited trialogue I had with some other EAs about this on an EA chat where we tried to get to the bottom of these disagreements (though I've been too busy recently), but I just wanted to use this comment as a brief opportunity to register this concern a bit in advance as well. If I am wrong, please convince me, I would be happy to be dissuaded of this but it is a very strong intuition of mine that this strategy does not end well for either our community health or public perception.\u201d</p>\n</blockquote>\n<h1>Q7: Isn\u2019t this all an overly demanding mental health nightmare?</h1>\n<p><a href=\"https://forum.effectivealtruism.org/posts/JBAPssaYMMRfNqYt7/michael-nielsen-s-notes-on-effective-altruism?commentId=RgSBrdFZsjcJXWG9j\">https://forum.effectivealtruism.org/posts/JBAPssaYMMRfNqYt7/michael-nielsen-s-notes-on-effective-altruism?commentId=RgSBrdFZsjcJXWG9j</a></p>\n<blockquote>\n<p>\u201cI think this has gotten better, but not as much better as you would hope considering how long EAs have known this is a problem, how much they have discussed it being a problem, and how many resources have gone into trying to address it. I think there's actually a bit of an unfortunate fallacy here that it isn't really an issue anymore because EA has gone through the motions to address it and had at least some degree of success, see Sasha Chapin's relevant thoughts:</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://web.archive.org/web/20220405152524/https://sashachapin.substack.com/p/your-intelligent-conscientious-in?s=r\">https://web.archive.org/web/20220405152524/https://sashachapin.substack.com/p/your-intelligent-conscientious-in?s=r</a></p>\n</blockquote>\n<blockquote>\n<p>Some of the remaining problem might come down to EA filtering for people who already have demanding moral views and an excessively conscientious personality. Some of it is probably due to the \u2018by-catch\u2019 phenomenon the anon below discusses that comes with applying expected value reasoning to having a positively impactful career (still something widely promoted, and probably for good reason overall). Some of it is this other, deeper tension that I think Nielson is getting at:</p>\n</blockquote>\n<blockquote>\n<p>Many people in Effective Altruism (I don't think most, but many, including some of the most influential) believe in a standard of morality that is too demanding for it to be realistic for real people to reach it. Given the prevalence of actualist over possiblist reasoning in EA ethics, and just not being totally naive about human psychology, pretty much everyone who does believe this is onboard with compartmentalizing do-gooding or do-besting from the rest of their life. The trouble runs deeper than this unfortunately though, because once you buy an argument that letting yourself have this is what will be best for doing good overall, you are already seriously risking undermining the psychological benefits.</p>\n</blockquote>\n<blockquote>\n<p>Whenever you do something for yourself, there is a voice in the back of your head asking if you are really so morally weak that this particular thing is necessary. Even if you overcome this voice, there is a worse voice that instrumentalizes the things you do for yourself. Buying icecream? This is now your \u2018anti-burnout icecream\u2019. Worse, have a kid (if you, like in Nielson's example, think this isn't part of your best set of altruistic decisions), this is your \u2018anti-burnout kid\u2019.</p>\n</blockquote>\n<blockquote>\n<p>It's very hard to get around this one. Nielson's preferred solution would clearly be that people just don't buy this very demanding theory of morality at all, because he thinks that it is wrong. That said, he doesn't really argue for this, and for those of us who actually do think that the demanding ideal of morality happens to be correct, it isn't an open avenue for us.</p>\n</blockquote>\n<blockquote>\n<p>The best solution as far as I can tell is to distance your intuitive worldview from this standard of morality as much as possible. Make it a small part of your mind, that you internalize largely on an academic level, and maybe take out on rare occasions for inspiration, but insist on not viewing your day to day life through it. Again though, the trickiness of this, I think, is a real part of the persistence of some of this problem, and I think Nielson nails this part.\u201d</p>\n</blockquote>\n<h1>Q8: Isn\u2019t the lesson of history that ideologically ambitious movements like this are dangerous and bad?</h1>\n<p><a href=\"https://forum.effectivealtruism.org/posts/JBAPssaYMMRfNqYt7/michael-nielsen-s-notes-on-effective-altruism?commentId=iAFokx2YztZxuAigg\">https://forum.effectivealtruism.org/posts/JBAPssaYMMRfNqYt7/michael-nielsen-s-notes-on-effective-altruism?commentId=iAFokx2YztZxuAigg</a></p>\n<blockquote>\n<p>\u201cThese are interesting critiques and I look forward to reading the whole thing, but I worry that the nicer tone of this one is going to lead people to give it more credit than critiques that were at least as substantially right, but much more harshly phrased.</p>\n</blockquote>\n<blockquote>\n<p>The point about ideologies being a minefield, with Nazis as an example, particularly stands out to me. I pattern match this to the parts of harsher critiques that go something like \u2018look at where your precious ideology leads when taken to an extreme, this place is terrible!\u2019 Generally, the substantial mistake these make is just casting EA as ideologically purist and ignoring the centrality of projects like moral uncertainty and worldview diversification, as well as the limited willingness of EAs to bite bullets they in principle endorse much of the background logic of (see Pascal's Mugging and Ajeya Cotra's train to crazy town).</p>\n</blockquote>\n<blockquote>\n<p>By not getting into telling us what terrible things we believe, but implying that we are at risk of believing terrible things, this piece is less unflattering, but is on shakier ground. It involves this same mistake about EA's ideological purism, but on top of this has to defend this other higher level claim rather than looking at concrete implications.</p>\n</blockquote>\n<blockquote>\n<p>Was the problem with the Nazis <em>really</em> that they were too ideologically pure? I find it very doubtful. The philosophers of the time attracted to them generally were weird humanistic philosophers with little interest in the types of purism that come from analytic ethics, like Heidegger. Meanwhile most philosophers closer to this type of ideological purity (Russell, Carnap) despised the Nazis from the beginning. The background philosophy itself largely drew from misreadings of people like Nietzsche and Hegel, popular anti-semitic sentiment, and plain old historical conspiracy theories. Even at the time intellectual critiques of Nazis often looked more like \u2018they were mundane and looking for meaning from charismatic, powerful men\u2019 (Arendt) or \u2018they aesthetisized politics\u2019 (Benjamin) rather than \u2018they took some particular coherent vision of doing good <em>too far</em>\u2019.</p>\n</blockquote>\n<blockquote>\n<p>The truth is the lesson of history isn't really \u2018moral atrocity is caused by ideological consistency\u2019. Occasionally atrocities are initiated by ideologically consistent people, but they have also been carried out casually by people who were quite normal for their time, or by crazy ideologues who didn't have a very clear, coherent vision at all. The problem with the Nazis, quite simply, is that they were very very badly wrong. We can't avoid making the mistakes they did from the inside by pattern matching aspects of our logic onto them that really aren't historically vindicated, we have to avoid moral atrocity by finding more reliable ways of not winding up being <em>very wrong</em>.\u201d</p>\n</blockquote>\n<p><em>(I fear that I\u2019m verging on denying the antecedent by linking this comment for this question, but I think it is still relevant to the worry to a decent extent. My somewhat more direct answer is that I think people with the ideologically purest views most like EA have <a href=\"https://www.amazon.com/Happiness-Philosophers-Lives-Works-Utilitarians/dp/0691154775/ref=as_li_ss_tl?keywords=the+happiness+philosophers&amp;qid=1573238827&amp;sr=8-1&amp;linkCode=sl1&amp;tag=nickfrac-20&amp;linkId=aecc2a80597ad2ed98c36608ff006eb5&amp;language=en_US\">historically</a> mostly had a positive to innocuous impact if you actually look at it. I think people who have this worry are mostly thinking of fictional evidence that vindicates it instead of history, like science fiction and thought experiments, but mostly history is full of more Hitlers than Thanoses)</em></p>\n<h1>Q9: You guys look kind of like a cult. Are you a cult?</h1>\n<p><a href=\"https://forum.effectivealtruism.org/posts/TcKbXwBX7YJ4NfgGL/a-hypothesis-for-why-some-people-mistake-ea-for-a-cult?commentId=sDCEuKCiEAKSB6FLd\">https://forum.effectivealtruism.org/posts/TcKbXwBX7YJ4NfgGL/a-hypothesis-for-why-some-people-mistake-ea-for-a-cult?commentId=sDCEuKCiEAKSB6FLd</a></p>\n<blockquote>\n<p>\u201cOne theory that I'm fond of, both because it has some explanatory power, and because unlike other theories about this with explanatory power, it is useful to keep in mind and not based as directly on misconceptions, goes like this:</p>\n</blockquote>\n<blockquote>\n<p>-A social group that has a high cost of exit, can afford to raise the cost of staying. That is, if it would be very bad for you to leave a group you are part of, the group can more successfully pressure you to be more conformist, work harder in service of it, and tolerate weird hierarchies.</p>\n</blockquote>\n<blockquote>\n<p>-What distinguishes a cult, or at least one of the most important things that distinguishes it, is that it is a social group that manually raises the cost of leaving, in order to also raise the cost of staying. For instance it relocates people, makes them cut off other relationships, etc.</p>\n</blockquote>\n<blockquote>\n<p>-Effective Altruism does not manually raise the cost of leaving for this purpose, and neither have I seen it really raise the cost of staying. Even more than most social groups I have been part of, being critical of the movement, having ideas that run counter to central dogmas, and being heavily involved in other competing social groups, are all tolerated or even encouraged. However,</p>\n</blockquote>\n<blockquote>\n<p>-The cost of leaving for many Effective Altruists is high, much of this self-inflicted. Effective Altruists like to live with other Effective Altruists, make mostly Effective Altruist close friends, enter romantic relationships with other Effective Altruists, work at Effective Altruist organizations, and believe idiosyncratic ideas mostly found within Effective Altruism. Some of this is out of a desire to do good, speaking from experience, much of it is because we are weirdos who are most comfortable hanging out with people who are similar types of weirdos to us, and have a hard time with social interactions in general. Therefore,</p>\n</blockquote>\n<blockquote>\n<p>-People looking in sometimes see things from point four, the things that contribute to the high cost of leaving, and even if they can't put what's cultish about it into words, are worried about possible cultishness, and don't know the stuff in point three viscerally enough to be disuaded of this impression. Furthermore, even if EA isn't a cult, point four is still important, because it increases the risk of cultishness creeping up on us.</p>\n</blockquote>\n<blockquote>\n<p>Overall, I'm not sure what to do with this. I guess be especially vigilant, and maybe work a little harder to have as much of a life as possible outside of Effective Altruism. Anyway, that's my take.\u201d</p>\n</blockquote>\n<h1>Q10: If longtermist causes like extinction risks really do look good even if you just look at the short term, why bother with all this promotion of the idea of \u201clongtermism\u201d at all anyway?</h1>\n<p><a href=\"https://forum.effectivealtruism.org/posts/KDjEogAqWNTdddF9g/?commentId=5xGgS798KxwjqMoFE\">https://forum.effectivealtruism.org/posts/KDjEogAqWNTdddF9g/?commentId=5xGgS798KxwjqMoFE</a></p>\n<blockquote>\n<p>\u201cI'm not so sure about this. Speaking as someone who talks with new EAs semi-frequently, it seems much easier to get people to take the basic ideas behind longtermism seriously than, say, the idea that there is a significant risk that they will personally die from unaligned AI. I do think that diving deeper into each issue sometimes flips reactions - longtermism takes you to weird places on sufficient reflection, AI risk looks terrifying just from compiling expert opinions - but favoring the approach that shifts the burden from the philosophical controversy to the empirical controversy doesn't seem like an obviously winning move. The move that seems both best for hedging this, and just the most honest, is being upfront both about your views on the philosophical and the empirical questions, and assume that convincing someone of even a somewhat more moderate version of either or both views will make them take the issues much more seriously.\u201d</p>\n</blockquote>\n<p><em>And finally, there are some questions that I didn\u2019t really comment on in the past, that I decided were worth spending a little time writing up original responses to (there were others I didn\u2019t because I think responding adequately would take too long, but which I would like to address if I make a more finalized version)</em></p>\n<h1>Q11: Are EAs only worried about AI risks because of billionaires corrupting the movement?</h1>\n<p>The proximate cause of Effective Altruist interest in AI is a transhumanist mailing list from the early 2000s. From there, Eliezer Yudkowsky seeded the worry within the Bay Area scene of EA, while Nick Bostrom seeded it within the Oxford scene. The idea that this was then mostly amplified within EA by billionaire interest is also implausible.</p>\n<p>Lots of Dustin Moskovitz\u2019s and Sam Bankman Fried\u2019s money has gone into various projects to work on AI, but Moskovitz has been very standoffish about his money, and functionally his role was just driving a dump truck of money up to Holden Karnofsky (who at the time was pretty uninterested in AI) and walking away. Bankman Fried is arguably more hands on, but also showed up on the scene very recently, after concern about AI had been gaining prominence within the movement for nearly a decade.</p>\n<p>Lots of people think of Elon Musk in this context as well because he\u2019s so famous, but his involvement with longtermism has been flirtatious at most. His main contribution was co-founding OpenAI, which is one of the <a href=\"https://twitter.com/esyudkowsky/status/1446562238848847877\">most controversial</a> AI labs within the AI safety community.</p>\n<h1>Q12: But isn\u2019t worry about AI safety just about promoting AI hype?</h1>\n<p>This is one of the most confusing talking points I\u2019ve seen. It\u2019s like saying that people worried about nuclear apocalypse are only doing so to build hype for weapons manufacturers. Actually it is weirder than that, because at least that involves the bombs doing what they are supposed to do. AI safety worries are by and large about the concern that we will make AI that sucks in the only way that matters, and the only way it will be good, is the way that will make this suck even more.</p>\n<p>More typical worries about AI, like those about social control (which are also extremely valid concerns!) fit a hype narrative better for the same reasons as the nuclear bomb example - in such a scenario AI is at least an effective tool for the wielder. In all three cases however, is it is very bad to dismissively make this assumption about the activism.</p>\n<p>As far as I can tell, the only reason anyone takes this seriously is the aforementioned worry that people are only concerned about AI safety because of billionaires, and the idea that this is the only explanation for why some billionaires promote AI safety (others, including some who make money off of AI like Mark Zuckerberg, are very dismissive). For the reasons I already covered however, I don\u2019t find this connection historically plausible anyway.</p>\n<h1>Q13: Aren\u2019t billionaires shaping and corrupting EA in other ways?</h1>\n<p>For reasons already mentioned, I don\u2019t think this is plausible in the case of Dustin Moskovitz (not involved enough with how funds are distributed), Sam Bankman Fried (too recent), or Elon Musk (doesn\u2019t contribute enough). Miscellaneous other billionaires have given various amounts to various EA causes, but this is the case for lots of activist movements, hell, if miscellaneous controversial contributions from Elon Musk are damning, that\u2019s damning for climate change activism as well.</p>\n<p>I think it is true that most of EA\u2019s funds come from billionaire money at this point, which has <a href=\"https://www.vox.com/future-perfect/2022/8/8/23150496/effective-altruism-sam-bankman-fried-dustin-moskovitz-billionaire-philanthropy-crytocurrency\">problems all its own</a>, but this is because of Dustin Moskovitz and Sam Bankman Fried, who I\u2019ve already covered. A related suspicion is to wonder why billionaires are overrepresented within Effective Altruism (I think probably true). My own guess is that people who want to give to some charity but don\u2019t have a specific one in mind are just generally overrepresented within Effective Altruism, because it\u2019s what you stumble upon when searching for reasons to give some place rather than others. You could be cynical about it and say that it\u2019s all for PR reasons, or more generous and say it\u2019s what any normal person who has more money than they could ever imagine spending on themself would do, but either way I don\u2019t think it\u2019s that controversial to say that lots of billionaires decide to give to charity regardless of whether they really have a plan for where to give in advance.</p>\n<p>Another related concern is that EA hasn\u2019t been directly corrupted by billionaire bribery, but that the creeping influence of this money will change how EAs approach issues in subtle ways anyway. I think this sort of suspicion is well worth keeping in mind, but is another double standard. Rich people also give tons of money to universities, but people rarely show that much suspicion to the work of academics in general as a result.</p>\n<h1>Q14: People say that longtermism only means treating future beings as a key moral priority, but that doesn\u2019t seem very controversial, shouldn\u2019t we just treat the word as the specific ideology it refers to in practice?</h1>\n<p>In practice I think there are roughly three ways the word longtermism might be used. One is the way critics tend to use, another is the way proponents tend to use it, and the final is the way it draws a line around a real movement.</p>\n<p>The version proponents use is given in the question, the way critics use it is basically as a synonym for bullet-biting total utilitarianism applied to the future. Many longtermists lean total utilitarian but aren\u2019t that bullet biting in practice. Other longtermists have different views though, for instance there is a non-trivial subgroup of more pessimistic or cautious longtermists I\u2019ve had a decent amount of exposure to. They tend to have an anti-frustrationist or \u201csuffering-focused\u201d ethics, and lean into something like a person-affecting view. They tend to prefer reducing S-Risks to X-Risks, and are often especially suspicious of space colonization.</p>\n<p>One thing that unites this group with the more totalist, \u201cgrand futures\u201d longtermists is the literal definition longtermists give, considering future beings a key moral priority. The \u201cmovement\u201d grouping, what actually describes people who self-identify as longtermists as a rule, is basically just people who apply Effective Altruism to the future.</p>\n<p>I don\u2019t especially mind this type of definition, but it seems like \u201cEffective Altruists who are looking at the future\u201d is adequate without needing its own separate name. The idea of treating future beings as a key moral priority strikes me as having more use for its own separate name, and pointing to a unique possible coalition. For this reason I sort of just do prefer this use, even if it doesn\u2019t seem to be catching on much in practice.</p>\n<p>(Edit 10/24/22: mostly cosmetic changes to improve readability, and swapping out a dead link)</p>\n", "user": {"username": "Devin Kalish"}}, {"_id": "qug9oTRwmyatoKHq6", "title": "Share your 'Summer in the Bay' experience", "postedAt": "2022-10-23T00:38:01.287Z", "htmlBody": "<p><strong>We're working on outcomes research for the recent </strong><a href=\"https://forum.effectivealtruism.org/posts/M5GoKkWtBKEGMCFHn/what-s-the-theory-of-change-of-come-to-the-bay-over-the\"><strong>'Visiting the Bay'</strong></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz9tmqhwra2h\"><sup><a href=\"#fnz9tmqhwra2h\">[1]</a></sup></span><strong>&nbsp;summer push. We're specifically looking into:</strong></p><ul><li>How impactful was it?</li><li>What were the pros and cons?&nbsp;</li><li>In what ways, if any, was it negative?</li><li>How should this update our views on community hubs?</li><li>How can hubs better prepare, organize and execute big community pushes?<br>&nbsp;</li></ul><p><strong>Interested in helping? You can:</strong></p><ul><li><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSejuy50N79Ure825_cxK5LLzZXi_k5qhojCmuPhApB2sl2HWg/viewform?usp=sf_link\">Fill our the survey </a>(if you came to the bay)</li><li><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSejuy50N79Ure825_cxK5LLzZXi_k5qhojCmuPhApB2sl2HWg/viewform?usp=sf_link\">Sign up to do a user interview </a>(if you have strong opinions on how the summer push went or want to share more details about your experience)</li><li>Help us (<a href=\"https://forum.effectivealtruism.org/users/anjay-f\">Anjay</a> and <a href=\"https://forum.effectivealtruism.org/users/elika\">Elika</a>) compile the data and write a report, <i>message either of us or comment if you're interested</i></li><li>Post your own reflection and opinions on EA hubs and impact&nbsp;</li></ul><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz9tmqhwra2h\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz9tmqhwra2h\">^</a></strong></sup></span><div class=\"footnote-content\"><p>By this, we mean EAs who came to the Berkeley area for the summer of 2022</p></div></li></ol>", "user": {"username": "ElikaSomani"}}, {"_id": "D3cZywurbzQnwaARx", "title": "Crypto loves impact markets: Notes from Schelling Point Bogot\u00e1", "postedAt": "2022-10-22T15:58:38.807Z", "htmlBody": "<p><i>Thanks to Rhys Lindmark, Noah Chon Lee, Dawn Drescher and Sinclair Chen for assistance with this post.</i></p><p>Last week Dony and I went down to the&nbsp;<a href=\"https://schellingpoint.gitcoin.co/\"><u>Schelling Point public goods conference</u></a> in Bogota, Colombia, where Dony was leading a workshop on impact markets. Gitcoin hosted the event, which felt very professionally put on and their AV team was fantastic \u2013 here is a&nbsp;<a href=\"https://twitter.com/schellingpoint_/status/1583153294750679040\"><u>link to their official photos and videos</u></a> in lieu of any of our own. Gitcoin is also writing its own retrospective which I\u2019ll also link. I was surprised and taken in by the level of interest in public goods funding on display at the conference, which I think looked like it had at least 500 attendees. Even more unexpected was how much of the day\u2019s discussion revolved around impact markets.</p><p>Impact markets as a solution for efficiently funding speculative interventions has been&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/certificate-of-impact\"><u>a topic of discussion (click for an explanation of the idea)</u></a> in a weakly positive light (with some&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/74rz7b8fztCsKotL6/impact-markets-may-incentivize-predictably-net-negative\"><u>particular attention to drawbacks</u></a>) on this forum from Paul Christiano\u2019s&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/yNn2o3kEhixZHkRga/certificates-of-impact\"><u>introduction of the idea</u></a> in 2014. More recently it has been discussed in the larger EA community, such as with Scott Alexander\u2019s&nbsp;<a href=\"https://astralcodexten.substack.com/p/impact-markets-the-annoying-details\"><u>previous writing on the topic</u></a>, experiments done by Clearer Thinking and Manifold Markets on&nbsp;<a href=\"https://manifold.markets/group/clearer-thinking-regrants/about\"><u>market-directed funding mechanisms</u></a>, and previous work by my co-author Dony alongside Dawn Drescher and Matt Brooks on impact certificates on this forum and at&nbsp;<a href=\"https://impactmarkets.io/\"><u>https://impactmarkets.io</u></a>. However, the space has remained fairly small within EA for such projects.</p><p>In contrast, in the past year the web3 community has quickly taken to the concept of impact markets, and several startups might be close to developing workable impact market implementations. It seems like this work hasn\u2019t been discussed much on the forums, so I wanted to make a brief sketch of the emerging public goods scene within web3 to make this work more visible to EAs, and to think about how it might fit in with EA work. Some readers will be familiar with this development already, perhaps from some of Dawn and Dony\u2019s posts and comments; I think most will be hearing about it for the first time, as I had just three weeks ago. At any rate, I think it is worth having another post written to bring it more to attention.</p><p><a href=\"https://en.wikipedia.org/wiki/Web3\"><u>What\u2019s web3</u></a>? Web3 is a collection of internet projects which interface with decentralized ledgers (blockchains) such as Ethereum, aiming to implement a new vision of the World Wide Web with financial and epistemic decentralization. These use smart contracts involving tokens (which may represent parcels of data or legal rights such as ownership) to allow their developers to design custom economic incentive structures for specific use cases. Web3-based applications can be made more transparent and less mutable, properties which they derive from that interface with blockchains.&nbsp;</p><p>The most prominent example of web3 is in NFT art, a digital ecosystem which uses unique tokens to represent legitimate ownership of artworks as conferred by the artist. More on NFTs (non-fungible tokens) later, as this concept readily translates to work on IP such as patents, as well as ownership of impact certificates. Web3 represents a community of projects and developers which are currently producing new technologies which can better support impact markets, and now are also working on creating those impact markets.&nbsp;</p><p>I\u2019m told that the public goods funding web3 scene coalesced a year ago around the first Funding the Commons event in November 2021. People in web3, largely developers, whose background was in creating infrastructure to support open source software projects came together with environmentalists and scientific progress advocates to discuss how to support each other, and one idea that all three coalesced around was using impact markets for funding their work.&nbsp;</p><p>Why is web3 a good match for impact markets? We don\u2019t think they\u2019re necessary, and my coauthor\u2019s work on GoodX is an example of going it using more traditional internet technologies, but web3 technologies built upon the existing infrastructure created by decentralized ledgers (blockchains) like Ethereum are able to offer impact certificates as tokens and use smart contracts to automate transfers of money based on many potential definitions of impact.&nbsp;</p><p>The conference seemed fairly representative of the scene. Ethereum founder Vitalik Buterin gave a surprise opening talk appearance, and I caught just the tail end of it, having arrived late after landing in Bogota at 3 am. Glen Weyl, who co-wrote Radical Markets and gave an&nbsp;<a href=\"https://80000hours.org/podcast/episodes/glen-weyl-radically-reforming-capitalism-and-democracy/\"><u>appearance on the 80,000 hours podcast</u></a>, also spoke.&nbsp;</p><p>A key talk at Schelling Point was Kevin Owocki\u2019s discussion of&nbsp;<a href=\"https://gitcoin.co/grants/\"><u>Gitcoin Grants</u></a>, Gitcoin\u2019s quadratic funding project for democratizing public goods. Gitcoin is the team behind Schelling Point, and a big driver of web3 development \u2013 they primarily give grants to people hacking on FOSS (free and open source) blockchain-related projects and have incubated many of the projects that presented work at Schelling Point. Recently they ran a round focused on DeSci (explained later) and impact markets. As an aside, Gitcoin has also been supporting Creative Commons art, which I was overjoyed to hear \u2013 I studied how to enhance the intellectual and creative public sphere during my communications major in college, but at the time there weren\u2019t really any people working on bringing viable funding mechanisms for public art into being.</p><p>Holke Brammer gave a talk representing&nbsp;<a href=\"https://protocol.ai/\"><u>Protocol Labs</u></a>, another key player in web3 who created both the IPFS and Filecoin protocols. At Protocol, Holke leads the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/4CBoRsCxi5zMWdaDJ/hypercerts-a-new-primitive-for-public-goods-funding\"><u>recently-announced</u></a> Hypercerts team which builds off of&nbsp;<a href=\"https://github.com/Network-Goods/hypercerts-docs/blob/main/static/pdf/hypercerts_Tech_Report_draft.pdf\"><u>impact certificate work by FHI scholar David Dalrymple</u></a>. They\u2019re hoping to pass a security audit this year and launch their first impact market based funding round (for open source software) in Q2 next year.</p><p>HyperCerts cites implementing a provable, economically sound carbon credits system as their key example use case. Carbon credits are a natural impact market \u2013 they work because companies have a reputation incentive to offset their carbon footprint, and thus act as terminal (philanthropic) funders, paying out based on tons of CO<sub>2</sub> captured. However, there\u2019s little transparency in this system, meaning a lot of work is currently needed to keep it honest. Making a transparent decentralized protocol be the norm for CO<sub>2</sub> reduction could restore some accountability and create an efficient market which directs philanthropy to the most impactful interventions.&nbsp;</p><p>In general, climate change and environmental conservation were the key cause areas discussed at Schelling point. Despite the primary conference language being English, many attendees naturally were from Colombia, and brought perspectives on how web3 could be deployed as leapfrogging technology for funding conservation projects in the region\u2019s rainforests. For example, I attended a talk by&nbsp;<a href=\"https://kokodao.xyz/\"><u>KokoDAO</u></a>, which was researching using web3 to deploy micropayments in post-conflict zones in which a lack of economic alternatives pushed locals towards deforestation for farming purposes, despite awareness of the long-term consequences of doing so. Impact markets could provide a cash advance to people whose livelihoods interface with rainforests and allow them to develop other forms of income, including being rewarded financially for provably responsible forest stewardship by international climate philanthropists.</p><p>Another major use case is DeSci (decentralized science), another scene within web3 quickly gaining traction. DeSci is an outgrowth of Open Science, the movement to change incentive structures to allow for freer data sharing within the science community in order to enable faster scientific progress.&nbsp;<a href=\"https://www.vitadao.com/\"><u>VitaDAO</u></a> and&nbsp;<a href=\"https://www.molecule.to/\"><u>Molecule</u></a> are currently the major players in this space. One main idea they share is to create IP-NFTs (intellectual property NFTs), which represent the data and outcomes of specific studies, trials, or publications, providing financial incentives for publication or licensing without being paywalled through large publishers and facilitating patentability, enabling a larger ecosystem for transferring IP. For example, one proposal is that this could be used to incentivize pharmaceutical companies to publish the data from failed trials, which might have scientific value in other regards.</p><p>One application in DeSci where impact markets can increase throughput is in funding generic drug repurposing trials, which is currently worth little to most pharmaceutical companies as the product is already on the shelves. As I understand there are so many possible interventions to test that evaluators would have to choose which ones to target first, and impact markets would allow impact investors to contribute their information to the evaluation process. Furthermore these trials are relatively cheap relative to experimental drug trials as safety standards have already been established, and some people I spoke to believed that they could serve as a good test case within DeSci for the adoption of impact market mechanisms. Some projects in this area now have venture or philanthropic funding, and&nbsp;<a href=\"https://crowdfundedcures.org/\"><u>Crowd Funded Cures</u></a> is a project in this field moving towards a first trial. It plans to pay impact investors based on percent improvement from usual care.</p><p>Besides the ones I mentioned, there were about a dozen web3 startups working directly on public goods funding, including work on impact certificates and markets. Most are established as some form of Decentralized Autonomous Organization, and use NFTs to support the implementation of impact certificates as true tradeable tokens. I wouldn\u2019t be surprised if within the next five years some of them became major players in funding direction.</p><p>You might be wondering why I am telling EAs about things happening in open source software, open science, Creative Commons, and environmental stewardship? It is clear that the flexibility of impact markets applied to many different use cases and the accompanying decentralization is helping to make people outside of the EA movement also interested in impact markets (because they can choose projects which match their funding goals). The provision of a general solution that could meet the needs of many different approaches towards giving could mean better infrastructure for EAs in the long term, since it will be worth developing for a larger user base.</p><p>On the other hand, you might be wondering if everyone in web3 is now hopelessly ebullient about impact markets. I don\u2019t know how they\u2019ll overcome the hurdles of the difficulty of turning subjective evaluations into impact payouts, and the difficulty of avoiding Goodharting on impact measures. As mentioned in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/74rz7b8fztCsKotL6/impact-markets-may-incentivize-predictably-net-negative\"><u>Ofer\u2019s article linked earlier on</u></a>, one of the major problems with the currently most-practical impact market implementations is the inability to penalize impact investors for funding projects that cause more harm than good. The proposed solution in that article was to delay deployment and focus on centralizing impact marketplaces, but this seems increasingly unlikely as the idea gains popularity; in some sense the cat is out of the bag.</p><p>I spoke with Evan Miyazono from Protocol Labs, who cares deeply about avoiding downside risk in creating this funding solution. For the time being, it seems that averting catastrophic risks would require some commitment on the part of terminal (purely philanthropic) funders not to retrofund any project in certain fields, such as gain-of-function pathogen research. In general the Hypercerts team is pretty close to EA philosophically \u2013 they would like to create an impact market funding system which was viable for retrofunding AI safety work \u2013 and I would not be surprised to see more from the team on this forum in the future.</p><p>Discussion of DeSci and other areas of interest around public goods funding continued into&nbsp;<a href=\"https://devcon.org/\"><u>DevCon Bogota</u></a>, this season\u2019s flagship event for the Ethereum community, of which Schelling Point was a satellite event. I think a lot of people in web3 are going to be interfacing with impact markets in the near future, which brings me hope that some of the major questions around implementation will be resolved and that the EA movement will benefit from being part of a broader coalition for creating infrastructure which supports provision of public goods.</p><p>How can we keep up with the space? New Schelling Point events are advertised at&nbsp;<a href=\"https://schellingpoint.gitcoin.co/\"><u>https://schellingpoint.gitcoin.co/</u></a>, which is also where the talks will be uploaded. Funding the Commons events are advertised at&nbsp;<a href=\"https://fundingthecommons.io/\"><u>https://fundingthecommons.io/</u></a> . Interested people also ought to follow Kevin Owocki on Twitter as&nbsp;<a href=\"https://twitter.com/owocki\"><u>@owocki</u></a>, and Evan Miyazono as&nbsp;<a href=\"https://twitter.com/emiyazono?lang=en\"><u>@emiyazono</u></a>, as well as Rhys Lindmark&nbsp;<a href=\"https://twitter.com/rhyslindmark\"><u>@rhyslindmark</u></a> and of course,&nbsp;<a href=\"https://twitter.com/donychristie\"><u>@donychristie</u></a>. Kevin Owocki has a book called&nbsp;<a href=\"https://store.gitcoin.co/products/green-pill-book-digital-edition\"><u>Green Pill</u></a>, and a&nbsp;<a href=\"https://availableon.com/greenpill\"><u>podcast with the same name</u></a>. We also think the EA movement should reach out to web3 public goods organizations to present their work to EA conferences and to EA funding organizations.&nbsp;</p>", "user": {"username": "Rachel Shu"}}, {"_id": "LjAMCM34JmCzACEQq", "title": "Progress Open Thread: EAGxVirtual 2022", "postedAt": "2022-10-22T13:49:08.602Z", "htmlBody": "<p>Almost 900 people joined the&nbsp;<a href=\"https://forum.effectivealtruism.org/events/uEaEpQiLfaJP9vJQN/eagxvirtual-2022\"><u>EAGxVirtual</u></a> conference this weekend from all over the world. And for many of them, it's their first EA conference. <strong>We are encouraging attendees to post here if they learn something useful, change their plans, have a really good meeting, etc.</strong> It can inspire others and help you reflect on personal experiences. See&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/F8FaFPaNYNZKmdNA5/progress-open-thread-october-student-summit-2020\"><u>this post</u></a> for ideas.</p><p>These updates can be very short. But you might also want to talk about people, organizations, or resources that were useful to you. Someone might have been counterfactually responsible for some of your progress and not even know it!</p><p>Looking forward to hearing your stories from the conference!</p><figure class=\"image image_resized\" style=\"width:96.86%\"><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2286e013b5ded0b493b9b58ce2d81e538286be8677558d52.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2286e013b5ded0b493b9b58ce2d81e538286be8677558d52.png/w_270 270w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2286e013b5ded0b493b9b58ce2d81e538286be8677558d52.png/w_540 540w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2286e013b5ded0b493b9b58ce2d81e538286be8677558d52.png/w_810 810w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2286e013b5ded0b493b9b58ce2d81e538286be8677558d52.png/w_1080 1080w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2286e013b5ded0b493b9b58ce2d81e538286be8677558d52.png/w_1350 1350w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2286e013b5ded0b493b9b58ce2d81e538286be8677558d52.png/w_1620 1620w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2286e013b5ded0b493b9b58ce2d81e538286be8677558d52.png/w_1890 1890w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2286e013b5ded0b493b9b58ce2d81e538286be8677558d52.png/w_2160 2160w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2286e013b5ded0b493b9b58ce2d81e538286be8677558d52.png/w_2430 2430w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/2286e013b5ded0b493b9b58ce2d81e538286be8677558d52.png/w_2684 2684w\"><figcaption>Opening party on Gather.Town</figcaption></figure>", "user": {"username": "Alex_Berezhnoy"}}, {"_id": "pgd9Aj3BRcARv6mKm", "title": "What are the most relevant subdomains of software for biosecurity?", "postedAt": "2022-10-22T09:46:10.166Z", "htmlBody": "<p>I'm trying to work out what aspects of software someone with a couple of years' of programming experience under their belt could decide to pivot towards.</p><p>What I know so far: 80,000 Hours' software engineering career review <a href=\"https://forum.effectivealtruism.org/posts/gbPthwLw3NovHAJdp/software-engineering-career-review\">says</a></p><blockquote><p>Much of the work in biosecurity is related to handling and processing large amounts of data, so knowledge of how to work with&nbsp;<strong>distributed systems</strong> is in demand. Expertise in adjacent fields such as <strong>data science</strong> could also be helpful.</p><p>There is also a big focus on&nbsp;<strong>security</strong>, particularly at organisations like SecureDNA.</p><p>Most code in biosecurity is written in&nbsp;<strong>Python</strong>.</p></blockquote><p>And elsewhere <a href=\"https://80000hours.org/career-reviews/information-security/\">they</a> and others talk about the relevance of infosecurity to biorisk.</p><p>It would be nice to have an ordering of these.</p><p>Web development seems like a generically useful skill for almost any organisation, but perhaps I should expect good web developers to be easier to come by than other kinds of specialists?</p><p>I wonder if bioinformatics or computational biology would also be useful.</p>", "user": {"username": "David Mears"}}, {"_id": "efiES4cuNSojnyiWr", "title": "Announcing Metaculus's 'Red Lines in Ukraine' Forecasting Project", "postedAt": "2022-10-21T22:13:05.610Z", "htmlBody": "<p>Today, we opened <a href=\"https://www.metaculus.com/project/red-lines/\">Red Lines in Ukraine</a>, a new forecasting collaboration with nuclear security expert <a href=\"https://www.newamerica.org/our-people/j-peter-scoblic/\">Peter Scoblic</a> designed to provide an early warning indicator of potential Russian nuclear use.</p><p>Since the Russian invasion of Ukraine, Western policymakers have been concerned that aid to Ukraine could provoke Putin to order the use of nuclear weapons. Ukraine and NATO have crossed some of the \"red lines\" that Putin established, but so far these actions have not resulted in the worst-case scenarios.</p><p>A question then is: which actions by Ukraine or Western nations would alter the odds of Russian nuclear use, and in which directions?</p><p>Therefore, this project is structured to elicit forecasts on both:</p><ul><li>the likelihood of specific outcomes</li><li>the likelihood nuclear weapons will be used given these outcomes</li></ul><p>For example, one question asks:</p><p><a href=\"https://www.metaculus.com/questions/13163/us-provision-of-atacms-for-ukraine/\"><strong>Will the US supply Ukraine with an Army Tactical Missile System?</strong></a></p><p>This question resolving as \u2018yes\u2019 would imply an update to the likelihood a nuclear weapon will be used, but the direction of the update depends on one\u2019s beliefs about how wars are likely to end or escalate.</p><p>In order to probe these beliefs, questions then elicit forecasts on the use of nuclear weapons conditional on those particular outcomes, e.g.:</p><p><a href=\"https://www.metaculus.com/questions/13165/ru-nuke-conditional-on-atacms-for-ua/\"><strong>If the US announces it will supply ATACMS to Ukraine, what is the probability Russia will use nuclear weapons?</strong></a></p><p>We invite the forecasting community to <a href=\"https://www.metaculus.com/project/red-lines/\">begin sharing predictions</a> to generate a clearer picture of which acts are likely to escalate conflict, and so provide guidance for action.&nbsp;<br><br>Learn more <a href=\"https://www.metaculus.com/project/red-lines/\">here</a>.</p>", "user": {"username": "christianM"}}, {"_id": "ivHfucqDNeFAR5mkH", "title": "Newsletter for Alignment Research: The ML Safety Updates", "postedAt": "2022-10-22T16:17:18.184Z", "htmlBody": "<h1><strong>Introducing the ML Safety Updates</strong></h1><p><strong>TLDR</strong>; We present a new AI safety update series in&nbsp;<a href=\"https://podcast.apartresearch.com\"><u>podcast</u></a>,&nbsp;<a href=\"https://www.youtube.com/channel/UCnfBOJnTkE9sgjMOOsQbi2w\"><u>YouTube</u></a> and&nbsp;<a href=\"https://newsletter.apartresearch.com\"><u>newsletter</u></a> format released weekly to stay updated in alignment and ML safety research and get exposed to Ai safety opportunities. Read the latest newsletter&nbsp;<a href=\"https://docs.google.com/document/d/1w24qIPzKO2nFTFfpgQnLnEtos0goL0Yh_eqZIub71YM/edit#heading=h.3wk9s1jn1a6k\"><u>further down in this post</u></a>.</p><p>Our motivations for this are two-fold:</p><ul><li>It has never been easy to stay updated on the latest developments in specific research fields and in the past couple of years, the amount of alignment research has&nbsp;<a href=\"https://www.lesswrong.com/posts/FgjcHiWvADgsocE34/a-descriptive-not-prescriptive-overview-of-current-ai\"><u>increased significantly</u></a>. On top of that, much safety-relevant AI work is not to be found in legible EA / rationalist channels, e.g. cybersecurity, AI legislation, robustness, and monitoring.</li><li>Existing newsletters in alignment research are focused on deep examinations of theory and give detailed insights to the reader. However, there is no newsletter series for up-to-date, weekly events.</li></ul><p>Our newsletters cover a summary of the past week\u2019s research, both within alignment and safety-relevant AI work, as well as promote opportunities in the AI safety space.&nbsp;</p><p>The past 7 weeks, we have released these updates as a YouTube video series summarizing novel AI and ML safety research in 4-6 minutes. This week, we released them in&nbsp;<a href=\"https://podcast.apartresearch.com\"><u>podcast</u></a> and&nbsp;<a href=\"https://newsletter.apartresearch.com\"><u>newsletter</u></a> format, and future updates will also be released to LessWrong. Subscribe&nbsp;<a href=\"https://apartresearch.com/newsletter\"><u>here</u></a>.</p><p><img src=\"http://res.cloudinary.com/cea/image/upload/v1667995773/mirroredImages/ivHfucqDNeFAR5mkH/umw6hbo9b1h4yx1ebbg5.png\"></p><h2><strong>The case for an AI safety update series</strong></h2><p>There are already a few amazing resources on AI safety similar to newsletters. However, the ones that exist are either biased towards specific topics or have not been kept up to date that past year. See our summary below.</p><ul><li><a href=\"https://rohinshah.com/alignment-newsletter/\"><u>Alignment Newsletter</u></a>: Rohin Shah has kept the Alignment Newsletter running for a long while and Rob Miles has recorded its entries as&nbsp;<a href=\"http://alignment-newsletter.libsyn.com/\"><u>podcast episodes</u></a>. It is released in&nbsp;<a href=\"https://xiaohuzhu.xyz/alignment-newsletter-zh/\"><u>Chinese</u></a>, See the whole team on&nbsp;<a href=\"https://rohinshah.com/alignment-newsletter/\"><u>the website</u></a> and their&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1PwWbWZ6FPqAgZWOoOcXM8N_tUCuxpEyMbN1NYYC02aM/edit#gid=0\"><u>spreadsheet of all newsletters</u></a>. It started on&nbsp;<a href=\"https://www.alignmentforum.org/posts/3onCb5ph3ywLQZMX2/alignment-newsletter-one-year-retrospective\"><u>April 9, 2018</u></a> and was released once a week. There are a total of 3 episodes in 2022.</li><li><a href=\"https://newsletter.mlsafety.org/\"><u>ML Safety Newsletter</u></a>: Dan Hendrycks sends out a Substack newsletter every month with summaries of new ML safety research.</li><li><a href=\"https://www.agisafetyfundamentals.com/past-newsletters\"><u>AGISF Newsletter</u></a>: This newsletter managed by the Blue Dot Impact team shares opportunities to over 1,000 subscribers somewhat regularly (~monthly+).</li><li><a href=\"https://www.lesswrong.com/users/quintin-pope\"><u>Quintin\u2019s Alignment Paper Review</u></a>: Quintin releases a wonderfully comprehensive ~weekly review of an AI safety adjacent or relevant field work.</li><li><a href=\"https://www.youtube.com/c/RobertMilesAI\"><u>Rob Miles</u></a>: Rob Miles uploads fantastic videos explaining key concepts in AI safety. He has been on YouTube since the Computerphile days. During the last year, there have been a total of 4 YouTube short videos on the channel, but several full-scale videos seem to be in the pipeline.</li><li><a href=\"https://astralcodexten.substack.com/archive?sort=search&amp;search=machine%20alignment%20monday\"><u>Machine Alignment Monday</u></a>: Scott Alexander sometimes (~monthly) discusses new AI safety research.</li></ul><p>Additionally, there are several update feeds for alignment research.</p><ul><li><a href=\"https://www.alignmentforum.org/\"><u>AlignmentForum</u></a>: The de facto home for AI safety research, the Alignment Forum is a highly curated and high quality place to share AI safety research within the AI safety community.</li><li><a href=\"https://www.reddit.com/r/mlsafety/\"><u>ML Safety Subreddit</u></a>: This subreddit is organized by&nbsp;<a href=\"https://safe.ai/\"><u>CAIS</u></a> and shares papers that are usually not available in the AI safety channels but from the robustness, out-of-distribution, alignment and monitoring fields of machine learning.</li><li>Twitter: Much research is shared on Twitter these days and it represents a very good AI safety feed if you follow the right people.</li><li>LessWrong: The less restricted and peer-reviewed sister site to the AlignmentForum, with a literature of AI safety-related work.</li><li>EA Forum: AI safety articles on the EA Forum are mostly about the general dynamics of AI safety cause prioritization, new organizations, project summaries, impact evaluations and AI timelines.</li><li>Discord servers (e.g.&nbsp;<a href=\"https://eleuther.ai/\"><u>EleutherAI</u></a> and our own&nbsp;<a href=\"https://apartresearch.com/join\"><u>Apart</u></a>): There are several Discord servers in alignment where interesting discussions about organizations\u2019 projects and unique AI safety readings are available.</li><li>Slack (e.g. AI Alignment and AGI Safety Fundamentals): These are very similar to the Discord servers but are often more professional and have stricter acceptance criteria.</li><li>Medium (e.g.&nbsp;<a href=\"https://deepmindsafetyresearch.medium.com/\"><u>DeepMind\u2019s</u></a> and&nbsp;<a href=\"https://ai-alignment.com/\"><u>Paul Christiano\u2019s</u></a>): Medium can give you a personalized feed based on who you follow so if you follow alignment researchers, you can use it as an AIS feed.</li></ul><p>Do share if you think there\u2019s any major channels we missed in the&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1QU-0fTwQiLuaAdBUmW2dn9wMH37qVtvApPD1bODY9cU/edit#gid=1008849206\"><u>update feeds sheet</u></a> and the&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1QU-0fTwQiLuaAdBUmW2dn9wMH37qVtvApPD1bODY9cU/edit#gid=1008849206\"><u>research update channels sheet</u></a>.</p><h2><strong>Risks &amp; uncertainties</strong></h2><ol><li>We misrepresent someone\u2019s research or perspective in AI safety. This is a real risk since these updates will be published once a week.</li><li>The research we summarize plays into an existing paradigm and limits the creation of new ideas in AI safety research.</li><li>Wrong representation of AI safety in the alignment updates leads to stigmatizing of AIS from the ML community and public actors.</li><li>We stop updating the weekly newsletter, and our past existence prevents people from making a new one.</li></ol><h3>Risk mitigation</h3><ol><li>We are very open for feedback and will keep a link in the description of our manuscript for you to comment on so we can add any corrections (you can also go to the manuscript in the link further down).</li><li>We will consciously look beyond the traditional channels of AI safety to find further resources every week. Additionally, we won\u2019t disregard an article just because it doesn\u2019t have the right amount of karma.</li><li>We will strive to optimize the feedback mechanisms from the community to ensure that we integrate rather than separate from the machine learning field. We will report publicly if we stop making the episodes and call for others to take over the task. If this is not possible, we will be very public about the complete shutdown of the series so others can fill the gap.</li></ol><h2><strong>Feedback</strong></h2><p><a href=\"https://forms.gle/jE6ZyyKnMFxNyWfF9\"><u>Give anonymous feedback on the series here</u></a> or write your feedback in the comments here or on YouTube. You\u2019re also very welcome to contact us at&nbsp;<a href=\"mailto:operations@apartresearch.com\"><u>operations@apartresearch.com</u></a> or book a meeting&nbsp;<a href=\"https://calendly.com/esbenkran/30min\"><u>here</u></a>.</p><p>Please do reach out to us or comment in&nbsp;<a href=\"https://docs.google.com/document/d/1g_RkOl_r13mMhlOsuu4zgx-lEsQUW7n1hAEhAzAHBfo/edit?usp=sharing\"><u>the manuscript doc</u></a> if you think we misrepresented an article, opinion or perspective during an update.</p><p>Subscribe to our newsletters&nbsp;<a href=\"https://apartresearch.com/newsletter\"><u>here</u></a>, listen to the podcast&nbsp;<a href=\"https://podcast.apartresearch.com\"><u>here</u></a> (<a href=\"https://open.spotify.com/show/0h3WOsgUm9Lvd793VHZGrV?si=630f3321c9664a60\"><u>Spotify</u></a>), watch the YouTube videos&nbsp;<a href=\"https://www.youtube.com/channel/UCnfBOJnTkE9sgjMOOsQbi2w\"><u>here</u></a> and read the newsletters&nbsp;<a href=\"https://newsletter.apartresearch.com\"><u>here</u></a>.</p><p><i>Thank you very much to Alexander Briand for in-depth feedback on this post.</i></p><h2><a href=\"https://newsletter.apartresearch.com/posts/why-ai-might-not-be-an-existential-risk-to-humanity-w42\"><strong><u>This week\u2019s ML Safety Update</u></strong></a></h2><p>This week, we\u2019re looking at counterarguments to the basic case for why AI is an existential risk to humanity, looking at how strong AI might come very soon, and sharing interesting papers.</p><p>But first a small note: You can now subscribe to our newsletter and listen to these updates in your favorite podcasting app. Check out&nbsp;<a href=\"https://ais.pub/newsletter\"><u>newsletter.apartresearch.com</u></a> and&nbsp;<a href=\"https://ais.pub/pod\"><u>podcast.apartresearch.com</u></a>.</p><p>Today is October 20th and this is the ML Safety Progress Update!</p><h3>AI X-risk counterarguments</h3><p>Existential risk of AI does not seem overwhelmingly likely&nbsp;<a href=\"https://aiimpacts.org/counterarguments-to-the-basic-ai-x-risk-case/\"><u>according to Katja Grace</u></a> from AI Impacts. She writes a long article arguing against the major perspectives on how AI can become very dangerous, and notes that enough uncertainty makes AI safety seem like a relevant concern despite the relatively low chance of catastrophe.</p><p>Her counterarguments go against the three main cases for why superintelligent AI will become an existential risk: 1) Superhuman AI systems will be goal-directed, 2) goal-directed AI systems\u2019 goals will be bad, and 3) superhuman AI will overpower humans.</p><p>Her counterarguments for why AI systems might not be goal-directed are that many highly functional systems can be \u201cpseudo-agents\u201d, models that don\u2019t pursue utility maximization but optimize for a range of sub-goals to be met. Additionally, to be a risk, the bar for goal-directedness is extremely high.</p><p>Her arguments for why goal-directed AI systems\u2019 goals might not be bad are that: 1) Even evil humans broadly correspond to human values and that slight diversity&nbsp; from the optimal policy seem alright. 2) AI might just learn the correct thing from the dataset since humans also seem to get their behavior from the diverse training data of the world. 3) Deep learning seems very good at learning fuzzy things from data and values seem learnable in slightly the same way as&nbsp;<a href=\"https://thispersondoesnotexist.com/\"><u>generating faces</u></a> (and we don\u2019t see faces without noses for example). The last counterargument is that 4) AIs who learn short-term goals will both be highly functional and have a low chance of optimizing for dangerous, long-term goals such as power-seeking.</p><p>Superhuman AI might also not overpower humans since: 1) A genius human in the stone age would have a much harder time getting to space than an average intelligence human today, which shows that intelligence is a much more nuanced concept than we set it to be. 2) AI might not be better than human-AI combinations. 3) AI will need our trust to take over critical infrastructure. 4) There are many other properties than intelligence which seem highly relevant. 5) Many goals do not end in taking over the universe. 6) Intelligence feedback loops could havemany speeds and you need a lot of confidence that it will be fast to say it leads to doom. And 7) key concepts in the literature are quite vague, meaning that we lack an understanding of how they will lead to existential risk.</p><p>Erik Jenner and Johannes Treutlein give&nbsp;<a href=\"https://www.alignmentforum.org/posts/GQat3Nrd9CStHyGaq/response-to-katja-grace-s-ai-x-risk-counterarguments\"><u>their response</u></a> to her counterarguments. Their main point is that there\u2019s good evidence that the difference between AI and humans will be large and that we need Grace\u2019s slightly aligned AI to help us reach a state where we do not build much more capable and more misaligned systems.</p><p>Comprehensive AI Services (CAIS)</p><p>A relevant text to mention in relation to these arguments is Eric Drexler\u2019s&nbsp;<a href=\"https://www.lesswrong.com/posts/x3fNwSe5aWZb5yXEG\"><u>attempt at reframing superintelligence</u></a> into something more realistic in an economic world. Here, he uses the term \u201cAI services\u201d to describe systems that can solve singular tasks that will be economically relevant. The comprehensive in comprehensive AI services is what we usually call general. The main point is that we will see a lot of highly capable but specialized AI before we get the monolithic artificial general intelligence. We recommend reading the report if you have the time.</p><p>Strong AGI coming soon</p><p>At the opposite end of the spectrum from Grace,&nbsp;<a href=\"https://www.lesswrong.com/posts/K4urTDkBbtNuLivJx/why-i-think-strong-general-ai-is-coming-soon\"><u>Porby shares</u></a> why they think AGI will arrive in the next 20 years with convincing arguments on 1) how easy the problem of intelligence is, 2) how immature current machine learning is, 3) how quickly we\u2019ll reach the level of hardware needed, and 4) how we cannot look at current AI systems to predict future abilities.</p><h3>Other news</h3><ul><li>In other news, in a&nbsp;<a href=\"https://www.nature.com/articles/s41467-022-33417-3\"><u>new survey</u></a> published in Nature, non-expert users of AI systems think interpretability is important, especially in safety-critical scenarios. However, they prefer accuracy in most tasks.&nbsp;</li><li>Neel Nanda shares an&nbsp;<a href=\"https://www.lesswrong.com/posts/SfPrNY45kQaBozwmu/an-extremely-opinionated-annotated-list-of-my-favourite\"><u>opinionated reading</u></a> of his favorite circuits interpretability work.</li><li><a href=\"https://openreview.net/pdf?id=CtS2Rs_aYk\"><u>A new method</u></a> in reinforcement learning shows good results on both performance and how moral its actions are. They take a text-based game and train a reinforcement learning agent with both a task policy and a moral policy.</li><li>John Wentworth&nbsp;<a href=\"https://www.lesswrong.com/posts/oxSX9XDQHLu5YLpaD/how-to-make-prediction-markets-useful-for-alignment-work\"><u>notes</u></a> how prediction markets might be useful for alignment research.</li><li>DeepMind has given a language model&nbsp;<a href=\"https://arxiv.org/pdf/2210.05359.pdf\"><u>access to a physics simulation</u></a> to increase its physics reasoning ability.</li><li>Nate Soares&nbsp;<a href=\"https://www.alignmentforum.org/posts/rP66bz34crvDudzcJ/decision-theory-does-not-imply-that-we-get-to-have-nice\"><u>describes</u></a> how superintelligent beings do not necessarily leave humans alive on game theoretic grounds.</li><li><a href=\"https://www.lesswrong.com/posts/bumgqvRjTadFFkoAd/science-of-deep-learning-a-technical-agenda\"><u>A new research agenda</u></a> in AI safety seeks to study the theory of deep learning using a pragmatic approach to understand key concepts.</li></ul><h3>Opportunities</h3><p>And now, diving into the many opportunities available for all interested in learning and doing more ML safety research!</p><ul><li>SERI MATS are accepting applications for a fully paid 2 month in-person fellowship to do independent research in AI safety.&nbsp;<a href=\"https://ais.pub/serimats\"><u>Apply now</u></a>, because the applications close this Sunday.</li><li>The Future of Life Institute is&nbsp;<a href=\"https://ais.pub/fli\"><u>accepting applications</u></a> to fund your PhD or postdoc in an AI safety-relevant field.</li><li>You can also go directly into research by applying for a<a href=\"https://ais.pub/redwoodjob\"><u> job at Redwood Research\u2019s technical team</u></a> or&nbsp;<a href=\"https://ais.pub/chaiintern\"><u>join the Center for Human-Compatible AI</u></a> as an intern.</li><li>We have released our new website for the Alignment Jam hackathons that we\u2019re proud to show the world. Just go to&nbsp;<a href=\"https://ais.pub/jam\"><u>alignmentjam.com</u></a>, join the next hackathon in November, and subscribe to receive updates.</li><li>You can also now follow us on our newsletter or listen to these episodes in your favorite podcasting app. See more on&nbsp;<a href=\"https://ais.pub/news\"><u>apartresearch.com/newsletter</u></a> and&nbsp;<a href=\"https://ais.pub/pod\"><u>podcast.apartresearch.com</u></a>.</li></ul><p>This has been the ML Safety Progress Update and we look forward to seeing you next week!</p>", "user": {"username": "esben-kran"}}, {"_id": "eTCeN3vpJWwuEvXLB", "title": "Any social anthropologists in EA?", "postedAt": "2022-10-21T14:52:20.810Z", "htmlBody": "<p>I am starting my work on a dissertation in social anthropology (undergraduate) about EA. I'm exploring through ethnographic work the very concept of altruism, and how EA is perceived, practiced (and all that jazz) on an individual level (I would also like to explore why people are drawn to the EA \"altruism\", so that maybe it's useful for community organisers!). If you have some thoughts on EA as a movement, are a social anthropologist or just enjoy chatting about it, feel free to contact me on: joanna.wiaterek@gmail.com. I'll be happy to share more about the idea and motivations for the work, and I'd be super grateful for any insights and thoughts!</p>", "user": {"username": "Asia Wiaterek"}}, {"_id": "Cj9eq3hnjGCRmkQkt", "title": "Selecting an EA-Aligned Biosciences Masters", "postedAt": "2022-10-21T14:11:19.776Z", "htmlBody": "<p>I am about to finish my undergraduate degree in genetics, into which I have incorporated a bit of compsci/compbio/bioinformatics (my university allows a lot of flexibility with study plans).</p><p>I am planning to continue my education with a Masters in biosciences next year, which involves a mix of higher-level classes and an ongoing research project. We need to seek out the research project by approaching potential supervisors to find one that interests us. I would like to make sure that my thinking is on the right track, and so I was hoping that some of you might be happy to provide some feedback/guidance on my plans so far.<br><br>I have met with two supervisors so far. The first already offered me a bioinformatics project around large-scale genomic/transcriptomic analysis of a couple of invasive species, with the aim of informing the design of suppression-drive technologies for pest control. I find this project really enticing as I have a strong interest in both animal welfare (including wild-animal welfare) and bioinformatics, and I think this would be a great way to combine the two. The second supervisor I met with had projects that were less applied, and had a broader scope, all using bioinformatics to study large datasets to investigate sources of diversity among humans. This lab was a bit less exciting to me but the supervisor was more hands-off in terms of projects, giving their students freedom to develop their own projects (within reason), which might mean that I could develop a more optimal project than the other one I was offered. However, the projects seemed more about discovery rather than application, which makes me uncertain about how interesting/beneficial it could be, although they do use a range of highly-transferable techniques.</p><p>Overall I'm trying to think through a list of pros and cons about both of these labs, as I would ideally like to a) have a project that is directly beneficial and b) gain useful experience that sets me up for an effective career in industry or research, whichever I decide. With that being said, I have a few main questions I'm mulling on:</p><ol><li>How important is making the right choice, really? Is it more important to just find a project that interests me, and hope I can transfer my skills anyway?<ol><li>On that point, is my choice likely to cut off other options and pathways?</li></ol></li><li>Should I aim for a lab that isn't as directly interesting to me but might allow me greater freedom to design an optimal project?</li><li>Is it worth going for a project that is less interesting but will make me more employable/broaden my options?</li></ol><p>Though the first supervisor/project still interests me the most, I'm wondering if I'm missing opportunities to work on a more fulfilling project that would set me up better for my next career step. Some of the areas I'm especially interested in working in are wild-animal welfare and cell agriculture, so I'm trying to keep my options open there. Some of the other projects available that I was also interested in are related to pesticide design, environmental DNA for monitoring waterway ecology, threats to human fertility, and plant engineering for nutritional enrichment.</p><p>I realize I'm just dumping a bunch of information and this might feel more like a journal entry than a question, but it's because I'm really not sure what things I should be prioritising or thinking about when making my decision, and I'm not sure what bits of information are important. I'm very sorry for being so verbose!&nbsp;</p><p>I would really appreciate if anyone with more experience would be willing to provide any advice or thoughts on my decision-making so far, as it would be a great help in coming to a decision. And even if you don't want to provide any advice, thank you so much for reading to the end of my ramblings.</p><p>Thanks in advance :)&nbsp;</p>", "user": {"username": "ripbennyharvey"}}, {"_id": "cSdZCCrbmhfua84Fr", "title": "Is now a good time to advocate for prediction market governance experiments in the UK?", "postedAt": "2022-10-21T11:51:44.389Z", "htmlBody": "<p>I'm an American.  I don't understand UK politics.  All I know is, there was once a PM named Liz Truss.  Liz did something the markets didn't like.  Now PM Liz is no more.</p>\n<p>Milton Friedman said: \"Only a crisis - actual or perceived - produces real change. When that crisis occurs, the actions that are taken depend on the ideas that are lying around.\"  I don't agree with Friedman on everything, but I like this theory of change.</p>\n<p>Seems like PM Liz could've saved her job by letting speculators place bets conditional on her proposed policy, and only announcing its implementation if the conditional bets looked good.  If we can convince the next UK government that conditional prediction markets are the best way to avoid the fate of Liz, this could be a step towards use of prediction markets to forecast the results of all kinds of UK policies on all kinds of endpoints.</p>\n<p>Would this be a good thing?</p>\n<p>Is there a chance I will get to see hedge funds placing bets on which UK policies will best reduce inequality or help the global poor within my lifetime?</p>\n", "user": {"username": "John_Maxwell_IV"}}, {"_id": "Js4uiJEahHhQBKE3h", "title": "AGI will arrive by the end of this decade either as a unicorn or as a black swan", "postedAt": "2022-10-21T10:50:12.215Z", "htmlBody": "<p>The probability of synthetic universal superintelligence (powerful AGI) arriving by the end of this decade recently jumped up almost to 100% due to the new experimental evidence proving foundational theoretical concepts of intelligence: the free energy principle [1] and the active inference theory [2].</p><p>Synthetic biological intelligence (SBI) was born just a couple of months ago in a petri dish on a high density multielectrode array [3].&nbsp;&nbsp;</p><p>SBI is a basal model and a proof of concept of AGI. Its birth is a large event although currently ignored as small by the AI development mainstream that is stuck close to the mean with small events. The birth of SBI launches a series of large events on the path to powerful AGI as it shifts the previously gaussian probability distribution of the arrival of powerful AGI to the heavy tailed distribution by power law.&nbsp;</p><p>Unlike dumb and rigid computers and modern AI systems, SBI is smart and agile. It can learn from scratch without supervision or reinforcement [3]. It\u2019s embodied and embedded in the environment [3]. It can change its morphology [4]. It can dwell in different substrates [5]. It can regenerate [6]. It can multiply [7].</p><p>Both theoretically and experimentally SBI leads to the creation of many different synthetic minds - basal synthetic intelligence (or AGI) embodied in many different physical and digital substrates.</p><p>SBI fills the gap between modern AI models and true AGI. Tiny SBI minds can perform as building material for larger minds and leverage the existing dumb but large AI models and computer systems as its slaves and components to increase own power and reach.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>Two factors turbocharge the development, implementation and scaling of true AGI with SBI at the core. First, SBI has a robust theoretical foundation (free energy principle, active inference theory, universal machine learning theory [8,9], mind everywhere framework [10]). Second, its theoretical understanding is supported by a strong experimental track on different platforms (two headed planaria [4], xenobots [7,11], frog limb regeneration [6], cyborg playing pong [3], etc.).</p><p>Theoretical foundation of SBI is a culmination of more than a century of research in psychology, physiology and neuroscience that began in 1898 with the discovery of the \u201canimal-like learning method\u201d or \u201cthe method of trial and error, with accidental success\u201d by one of the founding fathers of modern psychology Edward Thorndike [12].&nbsp; Another founding father Ivan Pavlov in 1933 wrote, \u201cIn Thorndike's experiments, the animal becomes familiar with the relations of external things among themselves, with their connections. Therefore, it is the knowledge of the world. This is the embryo, the germ of science.\u201d [13]&nbsp;&nbsp;</p><p>The mainstream development of AI relies on \u201cthe method of trial and error, with accidental success\u201d alone without even knowing it and, therefore, current AI models are poorly understood and hard to scale. Experimentally verified theoretical understanding is an unsurpassable competitive edge of SBI vs mainstream AI.&nbsp;</p><p>The birth of SBI is comparable to the first achievement of nuclear fission in a lab in 1939.&nbsp; It took six years then to build the nuclear bomb. Unethical, uncontrollable artificial superintelligence, if it escapes a lab, may represent a much bigger threat to humankind than nukes.&nbsp; On the other hand, such intelligence that will merge with humankind to adequately understand and put always first values and interests of humanity as species may help us tackle all existential threats including the nuclear armageddon. In fact, total elimination of nukes may become its first use case.</p><h3>References:</h3><p>1. Friston, K.&nbsp;<a href=\"https://www.nature.com/articles/nrn2787#citeas\"><u>The free-energy principle: a unified brain theory?</u></a>. Nat Rev Neurosci 11, 127\u2013138 (2010).&nbsp;<a href=\"https://doi.org/10.1038/nrn2787\"><u>https://doi.org/10.1038/nrn2787</u></a></p><p>2.&nbsp;<a href=\"https://direct.mit.edu/books/oa-monograph/5299/Active-InferenceThe-Free-Energy-Principle-in-Mind\"><u>Active Inference: The Free Energy Principle in Mind, Brain, and Behavior</u></a> By: Thomas Parr, Giovanni Pezzulo, Karl J. Friston DOI:&nbsp;<a href=\"https://doi.org/10.7551/mitpress/12441.001.0001\"><u>https://doi.org/10.7551/mitpress/12441.001.0001</u></a> ISBN (electronic): 9780262369978 Publisher: The MIT Press Published: 2022</p><p>3. Brett J. Kagan, Andy C. Kitchen, Nhi T. Tran, Forough Habibollahi, Moein Khajehnejad, Bradyn J. Parker, Anjali Bhat, Ben Rollo, Adeel Razi, Karl J. Friston, In vitro neurons learn and exhibit sentience when embodied in a simulated game-world, Neuron, 2022, ISSN 0896-6273,&nbsp;<a href=\"https://doi.org/10.1016/j.neuron.2022.09.001\"><u>https://doi.org/10.1016/j.neuron.2022.09.001</u></a>.&nbsp;</p><p>4. Fallon Durant, Johanna Bischof, Chris Fields, Junji Morokuma, Joshua LaPalme, Alison Hoi, Michael Levin,&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0006349519300657\"><u>The Role of Early Bioelectric Signals in the Regeneration of Planarian Anterior/Posterior Polarity, Biophysical Journal</u></a>, Volume 116, Issue 5, 2019, Pages 948-961, ISSN 0006-3495,&nbsp;<a href=\"https://doi.org/10.1016/j.bpj.2019.01.029\"><u>https://doi.org/10.1016/j.bpj.2019.01.029</u></a>.</p><p>5. Tran Nguyen Minh-Thai, Sandhya Samarasinghe, Michael Levin, A comprehensive conceptual and computational dynamics framework for Autonomous Regeneration Systems, bioRxiv 820613; doi:&nbsp;<a href=\"https://doi.org/10.1101/820613\"><u>https://doi.org/10.1101/820613</u></a>, Now published in Artificial Life doi:&nbsp;<a href=\"http://dx.doi.org/10.1162/artl_a_00343\"><u>10.1162/artl_a_00343</u></a></p><p>6. Nirosha J. Murugan , Hannah J. Vigran, Kelsie A. Miller, Annie Golding, Quang L. Pham, Megan M. Sperry, Cody Rasmussen-Ivey, Anna W. Kane, David L. Kaplan, Michael Levin.&nbsp;<a href=\"https://www.science.org/doi/10.1126/sciadv.abj2164\"><u>Acute multidrug delivery via a wearable bioreactor facilitates long-term limb regeneration and functional recovery in adult Xenopus laevis</u></a>. SCIENCE ADVANCES. 26 Jan 2022. Vol 8, Issue 4.&nbsp;<a href=\"https://doi.org/10.1126/sciadv.abj2164\"><u>DOI: 10.1126/sciadv.abj2164</u></a></p><p>7. S. Kriegman, D. Blackiston, M. Levin, J. Bongard,&nbsp;<a href=\"https://www.pnas.org/doi/10.1073/pnas.2112672118#executive-summary-abstract\"><u>Kinematic self-replication in reconfigurable organisms</u></a>. Proc. Natl. Acad. Sci. U.S.A. November 29, 2021. 118 (49) e2112672118.&nbsp;<a href=\"https://doi.org/10.1073/pnas.2112672118\"><u>https://doi.org/10.1073/pnas.2112672118</u></a></p><p>8. Vanchurin V.&nbsp;<a href=\"https://arxiv.org/abs/2008.01540\"><u>The World as a Neural Network</u></a>. Entropy (Basel). 2020 Oct 26;22(11):1210. doi: 10.3390/e22111210. PMID: 33286978; PMCID: PMC7712105.</p><p>9. Vanchurin V. Towards a theory of machine learning.&nbsp;<a href=\"https://arxiv.org/abs/2004.09280\"><u>arXiv:2004.09280</u></a>, 2020.</p><p>10. Levin Michael. Technological Approach to Mind Everywhere: An Experimentally-Grounded Framework for Understanding Diverse Bodies and Minds. Frontiers in Systems Neuroscience,16, 2022. URL=<a href=\"https://www.frontiersin.org/articles/10.3389/fnsys.2022.768201\"><u>https://www.frontiersin.org/articles/10.3389/fnsys.2022.768201</u></a>. DOI=10.3389/fnsys.2022.768201&nbsp;</p><p>11. S. Kriegman, D. Blackiston, M. Levin, J. Bongard,&nbsp;<a href=\"https://www.pnas.org/doi/10.1073/pnas.1910837117#abstract\"><u>A scalable pipeline for designing reconfigurable organisms</u></a>. Proc. Natl. Acad. Sci. U.S.A. 117, 1853\u20131859 (2020).</p><p>12. Thorndike, Edward&nbsp; (1898)&nbsp;<a href=\"https://psychclassics.yorku.ca/Thorndike/Animal/chap2.htm\"><u>Animal intelligence: An experimental study of the associative processes in animals</u></a>. Monograph Supplement No. 8</p><p>13. Pavlov, Ivan (1933)&nbsp;<a href=\"http://dugward.ru/library/pavlov_i_p/pavlov_psihologia_kak_nauka.html\"><u>Psychology as a Science</u></a>. Unpublished and Little-known Materials of I.P. Pavlov, in Russian (1975)</p><p><strong>This is an original entry for the Future Fund worldview prize</strong></p>", "user": {"username": "Yuri Barzov"}}, {"_id": "6szPBzD5roT3cTPEf", "title": "Improved Security to Prevent Hacker-AI and Digital Ghosts", "postedAt": "2022-10-21T10:11:39.361Z", "htmlBody": "", "user": {"username": "Erland W."}}, {"_id": "EK3LoxzHXywZprRnu", "title": "Two Guts", "postedAt": "2022-10-21T10:01:30.460Z", "htmlBody": "<blockquote><p><strong>Me:</strong> \u201cI don\u2019t know what I should do next? Lots of things seem good, but I can\u2019t think of particularly good reasons for them to cash out to what I care about.\u201d</p><p><strong>Hallucinated frankenstein interlocutor: </strong>\u201cPeople in your position tend to undervalue judgement and gut thinking relative to explicit reasoning, you should go with what your gut says is good.\"</p><p><strong>Me:</strong> \u201cI live inside my head and I can definitely say that much of the time my gut is saying what it thinks high status people would want to hear or thinking about the last three examples and none before or is taking into account at most two out of the whole space of considerations, why am I trusting it again?\u201d</p><p><strong>HFI:</strong> \u201cSure, but if you just go with explicit reasoning, you\u2019ll miss a bunch of unquantifiable intuitions that contain a lot of data, and those are valuable.\u201d</p><p><strong>Me:</strong> \u201cYes, but again from inside my head I need you to hear me when I say my gut is like the people who answer \u201cshould there be homosexuals in the military\u201d differently from \u201cshould there be gays or lesbians in the military\u201d and I don\u2019t think I\u2019m like unusual, this is like the whole point of the rationality project.\u201d</p></blockquote><p>This is a kind of conversation I have a lot (if this confuses you, see&nbsp;<a href=\"https://docs.google.com/document/d/1H6_WJ1pIs3VRCk_vlcQQGTta7Gxi-AboVwucxqnsyIg/edit#heading=h.lv6vkwfqp3dr\"><u>Appendix 1</u></a>), which at times has left me feeling like maybe I\u2019m the only person in EA/rationality who thinks they have a brain that makes mistakes by default, that can\u2019t be trusted to make good decisions without actually thinking about them. This is definitely not the case!&nbsp;<br>&nbsp;</p><p>There are a bunch of ways in which HFI and I above are not understanding each other (<a href=\"https://docs.google.com/document/d/1H6_WJ1pIs3VRCk_vlcQQGTta7Gxi-AboVwucxqnsyIg/edit#heading=h.odsathjdjvlc\"><u>Appendix 2</u></a>), but one is that, like half of a cow, there are two guts in play.</p><p>Sometimes people in the world are like \u201ctrust your gut instinct about people\u201d and they mean \u201ctrust your split-second first impression.\u201d And sometimes they\u2019re like \u201cin the end, you have to go with your gut\u201d and they mean \u201cafter marinating in all the relevant ideas, thinking for a long time, sleeping on it, probably doing a lot of explicit reasoning, if you have a deep sense of what you should do, it\u2019s worth trusting.\u201d</p><p>And I often heard people as saying \u201ctrust your snap gut\u201d, and I was like \u201cmy snap gut judgment is that that is insane. Do you know that I don\u2019t know anything about this.\u201d But at least in one case, and likely others, they meant \u201ctrust your reflective gut\u201d, the gut that\u2019s had time to sit with everything and digest it (the metaphor pays dividends).</p><p>[They might also mean that there\u2019s a valuable exchange to be had between gut and explicit models, where your explicit reasoning informs your intuition and vice versa, and you can interrogate your sense of what\u2019s reasonable or valuable to mine it for interesting information or to find evidence that it\u2019s based on what Melissa in third grade told you one time and maybe it\u2019s time to let go of the notion that every&nbsp;<a href=\"https://highways.dot.gov/public-roads/mayjune-2000/one-mile-five-debunking-myth\"><u>fifth American highway mile is perfectly straight for planes to land in wartime</u></a>.] (More in&nbsp;<a href=\"https://docs.google.com/document/d/1H6_WJ1pIs3VRCk_vlcQQGTta7Gxi-AboVwucxqnsyIg/edit#heading=h.2yolczr0top6\"><u>Appendix 3</u></a>)</p><p>And sometimes I think they&nbsp;<i>are</i> saying \u201cyou\u2019ve ingested more in this category than you give yourself credit for\u201d and/or \u201cyou\u2019ve had more time to digest this than you give yourself credit for\u201d.</p><p>But at least this is something I can make sense of, because I know my snap judgment changes based on what tweet I read right before you asked me, but I also know that good judgment is of deep, deep value, since we are making decisions all the time about what to do and how to act, and we don\u2019t have time to do all of that explicitly (Though, see&nbsp;<a href=\"https://docs.google.com/document/d/1H6_WJ1pIs3VRCk_vlcQQGTta7Gxi-AboVwucxqnsyIg/edit#heading=h.iz06dex488gp\"><u>Appendix 4</u></a>).</p><h3>Appendix 1:&nbsp;</h3><p>Sometimes people aren\u2019t so much talking as trying to win the last argument they were in. If you\u2019re like \u201cwhat? EA\u2019s *love* explicit reasoning\u201d you\u2019re both right and you\u2019ll have to take my word for it that there are subsections where indeed I\u2019m under the impression (mistaken or not) that I need to fight on the margin for the glory of explicit reasoning. I find a lot of human behavior is more comprehensible if you adopt the frame in which they are reacting on the margin, perceiving themselves as a valiant minority faced all around by a stronger enemy on their pet thing. I\u2019m here being like \u201cexplicit reasoning!\u201d in a sea of \u201chone your judgment\u201d in a larger continent of \u201cexplicit reasoning!\u201d in a larger ocean of something else, so everyone gets to feel very&nbsp;<a href=\"https://slatestarcodex.com/2013/06/09/all-debates-are-bravery-debates/\"><u>brave</u></a>.</p><h3>Appendix 2:&nbsp;</h3><ul><li>I think HFI often doesn\u2019t take my own sense of my weaknesses seriously, which is ironic because it\u2019s my carefully considered inside view based on being myself for a while<ul><li>It feels like surely it&nbsp;<i>matters</i> how good the judgment of the people involved is and I don\u2019t always feel like people are assessing me in particular to say \u201cyes, Chana, you have good judgment\u201d so I\u2019m in this awkward position where I feel like I have to be like \u201cjust fyi, I think I\u2019m worse than whatever the median person you\u2019re talking to about this is maybe?\u201d</li><li>Some people\u2019s judgment is bad, yo!</li></ul></li><li>There are other good reasons to go with your judgment call, perhaps to test it and help it be better in the future (though I think sometimes you can do this by not going with your judgment but noting that you did so and checking later)</li><li>I think HFI could help me out by noting specific examples in which they were happy they went with their gut judgment over explicit reasoning (though often the reason they were happy is not very comprehensible to me in concrete terms precisely because of the nature of the topic here)</li></ul><h3>Appendix 3:</h3><p>Figuring out why you believe what you believe I think is a great exercise (for which Focusing might be helpful), where you try to access the actual reasons your brain came to output this thing, and some of them are going to be good and some useless and then you have a better sense of what to hold on to. (Though sometimes it will also be very unclear!)</p><p>And when you look at an argument and it makes sense to you and you see the logic, you\u2019ll sometimes feel your gut sense change, because you have internalized and taken seriously what it means and what it points to.</p><h3><br>Appendix 4:</h3><p>I feel like I repeated that paragraph a bit because it feels virtuous in the minds of people who think \u201cjudgment is good.\u201d In actuality, I think you could reflect once a year on what your core goals are, check in every quarter on whether you\u2019re aimed at them correctly, and every week on whether you\u2019re moving towards them, in such a way that you\u2019re mostly working off of very intense explicit reasoning you did at some point, even if in each moment you\u2019re trusting your past self. Would be weird if judgment just didn\u2019t matter here, though, and the whole point of this is that \u201cdeep thought\u201d and \u201cgood judgment\u201d aren\u2019t in tension.</p><p>&nbsp;</p><h3>Appendix 5:</h3><p>For what it\u2019s worth, I want to stand up for not always having a judgment or a gut sense, or knowing what it is, and that not necessarily being some horrifying pathology where you\u2019ve excised your humanity in service of the Numbers God but instead just what it can feel like to be uncertain or to have instincts that are pretty reliably warped by something or other (e.g. mental illness).</p><p><br>&nbsp;</p>", "user": {"username": "ChanaMessinger"}}, {"_id": "PFFGfCYZmerznPjJL", "title": "Toward a more approachable and accessible EA Forum", "postedAt": "2022-10-21T07:22:20.400Z", "htmlBody": "<p><strong>TL;DR:</strong> EA wants to grow, and the Forum can be one of its best platforms to practice spreading important ideas and welcoming people to the community. Let's write for a broader audience of readers outside of EA or new to EA.</p>\n<p><strong>Audience:</strong> I'm writing this to EA community members who regularly write on the EA Forum. This is not intended for a broad audience (which is ironic but necessary).</p>\n<p><strong>Motive:</strong> To make the EA Forum more readable and approachable.</p>\n<p><strong>Preface:</strong> Yesterday I published a post called <a href=\"https://forum.effectivealtruism.org/posts/HmfXJGt9gtMaxdZyv/how-to-write-readable-posts\">How to Write Readable Posts</a>. This is the \"prequel\" to that post, explaining my personal story.</p>\n<p><strong>Also Note:</strong> This is a first draft.<sup class=\"footnote-ref\"><a href=\"#fn-S9822JTHDZJoRysEr-1\" id=\"fnref-S9822JTHDZJoRysEr-1\">[1]</a></sup></p>\n<h1>Ingredients for Growth</h1>\n<p><strong>Premise:</strong> Improving Forum posts for readers outside of EA or new to EA is a great way to practice making the EA Forum/community more:</p>\n<ul>\n<li>friendly</li>\n<li>welcoming</li>\n<li>inclusive</li>\n<li>congenial</li>\n<li>compelling</li>\n<li>considerate</li>\n<li>thoughtful</li>\n<li>caring</li>\n<li>kind</li>\n<li>understandable</li>\n<li>understanding</li>\n<li>(and also, yeah, altruistic)</li>\n</ul>\n<p>All of these principles are key ingredients to cultivating the community and helping it grow.</p>\n<p>From the outside looking in:</p>\n<blockquote>\n<p>\"Readable and approachable writing/forum\" = \"Reasonable and approachable people/community\"</p>\n</blockquote>\n<ul>\n<li>By making writings more <strong>readable</strong>, you demonstrate your <em>understanding</em> of others.</li>\n<li>By making writings more <strong>approachable</strong>, you demonstrate your <em>care</em> for others.</li>\n</ul>\n<p>People are more likely to get involved with EA if they are welcomed, understood, and cared for.</p>\n<p>But before going further in this generalized, abstract space, I want to give my account of how this has affected me personally. In fact, it was with these premises that I wrote my previous post on <a href=\"https://forum.effectivealtruism.org/posts/HmfXJGt9gtMaxdZyv/how-to-write-readable-posts\">How to Write Readable Posts</a>. Among my friends I've found that many others have shared the experiences I've had that inspired me to write that post. So I want to give us a voice and tell our story.</p>\n<h1>Behind the Scenes</h1>\n<blockquote>\n<p>\"What inspired you to write <a href=\"https://forum.effectivealtruism.org/posts/HmfXJGt9gtMaxdZyv/how-to-write-readable-posts\">that \"readability\" post</a> in the first place?\"</p>\n</blockquote>\n<p>My backstory for <a href=\"https://forum.effectivealtruism.org/posts/HmfXJGt9gtMaxdZyv/how-to-write-readable-posts\">that post</a> actually originates with my recurring struggles (and occasional frustrations) with reading the EA Forum. About 2 weeks ago it honestly got to the point where I told my friends:</p>\n<blockquote>\n<p>\"I think I'm done; I'm going to unsubscribe from EA and stop reading the Forum every week and maybe in general.\"</p>\n</blockquote>\n<p>But then some of the best advice I've ever been given struck me:</p>\n<blockquote>\n<p>\"Before you leave something behind out of frustration (whether it's a job, a friendship, a project, or whatever), try your best to change it first (for ~2 weeks).\nIf nothing changes in that time, then you should go.\"</p>\n</blockquote>\n<p>So here I am; I'm staying invested in this Forum for now to see if I can make a change.</p>\n<h2>Accessibility: Reach the Reader</h2>\n<p>My frustrations have been primarily the same \"readability and approachability\" concerns. I'll get the weekly email newsletter, scan the top picks, open up the posts I'm curious about, and try to learn something new. But more often than not, that whole experience leaves me feeling bummed about: how much content is constantly being poured into this Forum and how little of the most valuable and meaningful ideas reach a broader audience. Surely there are big ideas stashed within the Forum, but they feel <em>inaccessible</em>.</p>\n<p>Occasionally I'll find a true gem of a post \u2014 a valuable and worthwhile read that respects my time and my (lack of domain-based) knowledge. But even these more meaningful posts often are not shareable with my friends who are either \"lightly involved\" in EA or have never heard of it.</p>\n<h2>Shareability: Pass the Test</h2>\n<p>When I come across a fascinating post, I want to just share that post directly with someone and happily know that they will have the same experience I had reading it: they understand the ideas and are inspired by them. My friends do the same; when they read an article that inspires them, they share it with me. But the problems arise when someone in these exchanges doesn't understand the post and then is left sending the message:</p>\n<blockquote>\n<p>\"Hey, this post is confusing to me. Why did you send it to me, and why do you think I should read it? What did you get out of it?\"</p>\n</blockquote>\n<p>If this message shows up in a chat following a shared post, then I would deem that post \"inaccessible\", because it's opaque for some readers. A truly readable and approachable post is self-explanatory and (indirectly or directly) tells every reader:</p>\n<ul>\n<li>what it's about,</li>\n<li>why it matters,</li>\n<li>what to take away, and</li>\n<li>what makes it interesting enough to share with anyone.</li>\n</ul>\n<h3>Ideal #1: Shareable posts</h3>\n<p>I dream of a day where more than half of the posts on the EA Forum can be shared with anyone outside of the EA community and achieve this level of readability.</p>\n<p><strong>Picture this:</strong> Imagine seeing an EA Forum post shared in a group chat by friends who don't even identify with EA yet all relate to the post and find it inspiring!</p>\n<h2>Approachability: Beyond the Community</h2>\n<p>Truth be told, as of 2 years of Forum reading, I have probably shared only 2 or maybe 3 EA Forum posts in DMs. And both times were to a friend or two who are already heavily involved in EA.</p>\n<p>What if this Forum was the type of place where I can share almost any post with almost any of my friends?</p>\n<p>While reading EA Forum posts, I picture my best friends outside the EA community reading it and reacting to it. Typically this imagination leads to the notion that my friends would basically say to the author: \"Yo, chill.\" or \"What the heck?\" or \"I have no idea what this is saying.\"</p>\n<p>And these friends are all people who could easily become involved with EA practices \u2014 people like me who change their career trajectories, go work 2.5 years at an EA org, and aspire to continue working on altruistic endeavors for life.</p>\n<p>I would love to see us write for those people as our extended audience, beyond the EA community, because I believe it's one of the best ways to grow and build the community.</p>\n<h1>Growing the Community</h1>\n<p>According to its major orgs, EA wants to grow:</p>\n<ul>\n<li><a href=\"https://www.centreforeffectivealtruism.org/strategy\">\"Communication\" is the #1 focus area for CEA, and \"Connection\" is the third.</a></li>\n<li><a href=\"https://80000hours.org/problem-profiles/\">80,000 Hours says \"Building EA\" ranks as the 3rd most pressing world problem.</a></li>\n</ul>\n<h2>Utilizing the Forum</h2>\n<p>The EA Forum is important for both people within the community and outside of it:</p>\n<ol>\n<li>People outside the EA community who want to connect with EA might use the Forum as a way to learn more and witness community interactions online. While trying to explore EA online, they'll quickly find their way to the Forum. (Especially when <a href=\"https://www.effectivealtruism.org/\">effectivealtruism.org</a> puts the EA Forum as the 2nd item under its \"Connect\" tab!)</li>\n<li>People within the EA community who want to communicate their ideas effectively will use the EA Forum to have a platform to post.</li>\n</ol>\n<p>So the Forum is the online meeting place where EA community members share their ideas and people outside explore those ideas. In theory, it's a pretty ideal place for \"communication\", \"connection\", and \"community building\" (all of which are regarded among the top 3 most important focus areas in EA).</p>\n<p>And yet, where do we go wrong with the Forum? Why is it not as inclusive as such a platform could be?</p>\n<p>I believe some of the culprits are often: jargon, name-dropping, and esoteric language, allusions, and references.</p>\n<h2>Welcoming the Newcomers</h2>\n<p>Everyone who is in EA now was once <em>not</em> in EA. It's easy to forget, but we've all been there. Everyone comes from the outside and makes a decision to join in.</p>\n<p>What was your experience like discovering EA and joining the community? What was the experience like for your friends who are now in EA?</p>\n<p>If you're anything like me and my friends, the experience roughly goes something like this:</p>\n<ol>\n<li>Encounter EA online, such as via 80000 Hours or a podcast.</li>\n<li>Try to learn more by skimming articles online.</li>\n<li>Maybe do nothing about the ideas for a long time.</li>\n<li>Maybe decide to attend a (virtual) conference.</li>\n<li>Feel estranged by esoteric references, jargon, name-drops, and foreign ideas / philosophy.</li>\n<li>Feel like you have a <em>very</em> long way to go to catch up to anyone else in this community.</li>\n<li>Slowly drudge your way through various materials to familiarize yourself with anything and everything.</li>\n<li>Eventually feel competent enough to engage and interact with the community.</li>\n<li>Maybe make a friend or two in EA.</li>\n<li>Actually do something so that you feel involved in the community.</li>\n</ol>\n<p>This 10-step process is a pretty big barrier to entry. For each step along the way, we probably all know someone who dropped off at that point. Who knows how many people never make it out of Step 3.</p>\n<p>For me, this process took 4 years: from 2016 when I first discovered 80,000 Hours, to 2020 when I finally attended a virtual conference, made a few friends, and started a job at an EA org.</p>\n<p>What if we could improve this process, streamline the steps, reduce friction, and make the experience more enjoyable?</p>\n<p>If the EA Forum was more readable and approachable and its ideas were more accessible, then newcomers would engage more easily with the community early on.</p>\n<p>We can shorten the gap between the moment someone discovers EA ideas to the moment they act on those ideas. Why not use the EA Forum to mediate their journey from newcomer to member? Currently, the EA Forum feels like it's written <em>by</em> members <em>for</em> members, but it doesn't have to be.</p>\n<h3>Ideal #2: Inclusive posts</h3>\n<p>Ideally, the most important ideas from EA will be shared as posts on the EA Forum and not only read by people both in and out of the EA community but also acted upon by them.</p>\n<p><strong>Picture this:</strong> Imagine that your post is seen by someone who is completely new to EA and wants to learn more. They click the title of your post because it seems intriguing. Maybe this is the first post they've ever read on the Forum; maybe it's the fifth. But your post is a part of the crucial period of first impressions, where the reader decides whether or not to get involved in EA at all. By the end of the post, you've managed to excite them, inspire them, and best of all motivate them to take action!</p>\n<h2>Sharing the Good</h2>\n<p>Finally, I want to make a case for the idea that the prized EA principle of \"impartiality\" should also extend to our audience when writing.</p>\n<p>80,000 Hours writes about \"impartial welfarism\", Wikipedia lists \"Impartiality\" as the first point of emphasis in the <a href=\"https://en.wikipedia.org/wiki/Effective_altruism#Impartiality\">philosophy of EA</a>, and the intro to EA (from CEA) lists \"impartial altruism\" as <a href=\"https://www.effectivealtruism.org/articles/introduction-to-effective-altruism#what-values-unite-effective-altruism\">the 2nd value that unites EA</a>:</p>\n<blockquote>\n<p>\"We believe that all people count equally. [\u2026] When trying to do as much good as possible, we aim to give everyone's interests equal weight.\"</p>\n</blockquote>\n<p>But do we extend this to our writings on the EA Forum? Do we regard all readers equally? Do we try to give all reader's interests equal weight?</p>\n<p>I know, I know, I'm taking the concept out of its original context. However, I think there's value in just thinking from the perspective of: \"By impartially writing for a broader audience of readers both in and out of EA, I regard all possible readers equally and ensure the benefits of my post are accessible to as many people as possible (thus doing the greatest good).\"</p>\n<p>Obviously sometimes we need to target an audience when we write \u2014 like this post. Right now I'm targeting the audience of writers on the Forum who are simply writing about important and valuable ideas that could be spread, could benefit many people, and could play a part in building and growing the EA community.</p>\n<p>If the ideas in your post are valuable, meaningful, and beneficial, then try to maximize the impact of your writing by making it as readable, understandable, and accessible to as many people as possible. (I'm certainly not the first person to argue this. Another great example is Kat Woods' post on <a href=\"https://forum.effectivealtruism.org/posts/dAbs7w4J4iNm89DjP/why-boring-writing-is-unethical-the-case-for-it-being-high\">how writing can be more impactful if it is read by more people</a>.)</p>\n<p>The principle of \"impartiality\" should simply push you towards expanding your audience (instead of focusing on a narrow sample or subset of EA community members who happen to be very much like you).</p>\n<h1>Conclusion</h1>\n<p>I think it's under-appreciated how much of a difference we can make with our writings and conversations featured globally and publicly across the internet. Many ideas worth sharing on the EA Forum are also worth sharing with the world outside the EA community. Moreover, the way that we write about these valuable ideas can be the difference between: (1) someone skimming a post and forgetting everything in less than an hour, or (2) someone loving a post, sharing it, and being inspired to do something with the ideas.</p>\n<p>Let's make the EA Forum the best platform for EA <a href=\"https://80000hours.org/problem-profiles/\">community building</a>, <a href=\"https://www.centreforeffectivealtruism.org/strategy\">communication, and connection</a> by making it as inclusive, readable, approachable, and accessible as possible.</p>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn-S9822JTHDZJoRysEr-1\" class=\"footnote-item\"><p>Ironically, the first draft of this post will not reflect all of the readability tips in <a href=\"https://forum.effectivealtruism.org/posts/HmfXJGt9gtMaxdZyv/how-to-write-readable-posts\">my previous post</a>, because right now I just want to quickly publish my account of my experiences and feelings and link it to my previous post. I'll revise this as I have more time and get feedback from others. <a href=\"#fnref-S9822JTHDZJoRysEr-1\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n</ol>\n</section>\n", "user": {"username": "davidhartsough"}}, {"_id": "BGtttLRonDitCHRB8", "title": "Plurality Voting is Unconstitutional", "postedAt": "2022-10-21T08:20:38.354Z", "htmlBody": "", "user": {"username": "c.trout"}}, {"_id": "YgBXswPkPeqf99mrb", "title": "Back by popular demand: The Impactful Policy Careers Workshop Series (Applications now open)!", "postedAt": "2022-10-21T04:27:06.412Z", "htmlBody": "<p><i>Applications are </i><a href=\"https://forms.gle/5HRhETSkieXRaDdM9\"><i>now open</i></a><i> for the \u201c</i><a href=\"https://bald-elf-6f3.notion.site/Impactful-Policy-Careers-54ad72be1d444f198f9884c4e9b084ad\"><i>Impactful Policy Careers Workshop Series</i></a><i>\u201d. Previously run by \u201cTraining for Good\u201d, this free training programme will help you plan for a high-impact career in policy. Through readings, assignments and discussions, you will craft a detailed career plan to test your personal fit and kickstart an effective career in policy.&nbsp;</i></p><p>We expect participants to spend 16-20 hours completing this programme over the course of 4 weeks. This includes a 2-hour workshop each week along with 2-3 hours of pre-work.</p><p>The course will run every Monday evening at 7:30pm (CET) over the period of 4 weeks in November &amp; December 2022. The optional week 5 will take place in January.</p><p>Dates:</p><ul><li>21.11.2022</li><li>28.11.2022</li><li>05.12.2022</li><li>12.12.2022</li><li>16.01.2023</li></ul><p>\u200bBy the end of the workshop, you will have:</p><ul><li>A better understanding of the paths to impact as an EA in policy making</li><li>Knowledge about the different roles that influence policy.</li><li>An understanding of your personal fit for different policy roles.</li><li>Learned and applied one or more career decision-making tools.</li><li>Spoken to one or more EAs that are currently working in policy</li><li>3-5 career options that fit your personal criteria</li></ul><p><strong>Trainers&nbsp;</strong></p><p><i>Thijs Jacobs&nbsp;</i></p><p>Thijs works as a public sector consultant in the Netherlands where he advises local governments on a large variety of topics. He is also a community builder of the Dutch policy and politics EA-professionals group called Polly. Thijs joined the first cohort of the Impactful policy career workshop by Training for good one year ago. Thijs has gained experience facilitating workshops at a Dutch NGO and facilitated an EA virtual programme before.</p><p><i>Jana Wilke&nbsp;</i></p><p>Jana has a background in Interactive Media Design and has previously worked as an HR Consultant with a focus on Project Management and UX Design. She joined a political party in 2020, became Lead Candidate for the municipal elections one month later and now holds a seat in city parliament since March 2021. Additionally, she was elected to the regional board in June 2022 and is responsible for Policy, Communication and Partnerships workstreams. Jana also joined the first cohort of the Impactful policy career workshop by Training for good one year ago.</p><p><i>Moritz von Knebel&nbsp;&nbsp;</i></p><p>Moritz has a background in Political Science and Education, and has worked in the Education Industry for 3 years. He also worked as a research intern for Training for Good, which initially ran this program. He has also worked as a Community-Builder, coach and facilitator for Intro Fellowships for EA Germany and the Virtual Programs. He has worked on a policy-related research project as a Research Fellow with the Cambridge Existential Risk Initiative, during which he was funded by an LTFF grant. He is currently a Coach at Future Academy (which is also designed to equip students and young professionals with the tools to make high-quality career decisions) and a Research Fellow at Charity Entrepreneurship.</p><p><i>Experts working in Policy</i></p><p>Several EAs with expertise and experience in policy will help facilitate aspects of the programme and be available for Q&amp;A sessions with trainees. This group represents a diversity of backgrounds, roles and cause areas.</p><p>\u200b</p><p><strong>Who should apply?</strong></p><p>This training programme is for aspiring policy makers in Europe (including UK and other non-EU countries) who are familiar with the basic ideas of effective altruism (eg. have completed an&nbsp;<a href=\"https://www.effectivealtruism.org/virtual-programs/introductory-program/\"><u>Introductory EA Program</u></a>). Most participants are likely to be students, individuals early in their career or mid-career professionals interested in switching into policy from another career path.</p><p>\u200b<br>Find all the info in <a href=\"https://bald-elf-6f3.notion.site/Impactful-Policy-Careers-54ad72be1d444f198f9884c4e9b084ad\">one place.</a></p><p>You can apply here: <a href=\"https://forms.gle/5HRhETSkieXRaDdM9\">https://forms.gle/5HRhETSkieXRaDdM9</a>.<br>Applications close on 07/11/2022, successful applicants will be notified shortly after that.&nbsp;<br>If you have any questions about the program, <a href=\"mailto: ipccoalition@gmail.com\">send us an email</a>.&nbsp;<br>You can also give us <a href=\"https://www.admonymous.co/ipccoalition\">anonymous feedback here.</a>&nbsp;</p>", "user": {"username": "Moritz von Knebel"}}, {"_id": "ipWNDXTdXgDfSw6fu", "title": "Introducing Generally Intelligent: an AI research lab focused on improved theoretical and pragmatic understanding", "postedAt": "2022-10-21T08:20:55.533Z", "htmlBody": "<p>Today we are both launching our organization, Generally Intelligent, and open sourcing part of our research environment, Avalon, to enable the academic research community to make progress on understanding neural networks and creating safer, more robust RL agents.</p><p>Generally Intelligent is an AI research lab focused on better theoretical and practical understanding of deep learning, neural networks, and reinforcement learning agents. We believe that developing a better scientific understanding of these techniques is critical to the development of safe AI systems. We're excited about approaches like that of Chris Olah at Anthropic, as well as other more theoretical work. For more on our approach to safety, see our&nbsp;<a href=\"https://generallyintelligent.com/safety/\"><u>website</u></a>.</p><p>We're also open sourcing Avalon today, one of our first projects. Avalon is a fast, accessible simulator designed specifically for reinforcement learning. We hope that Avalon will enable academic labs to contribute to questions about generalization, robustness, and the fundamental principles of agentic AI systems in a safe setting that is not intended to transfer capabilities to the real world. Given that academic labs often have access to much less compute, our hope with open sourcing this simulator is that we can enable them to perform more fundamental scientific research without really changing the capabilities frontier or having to create very large, compute-intensive models. For more about Avalon, see our&nbsp;<a href=\"https://generallyintelligent.com/launch/\"><u>launch post</u></a>.</p><p>At a high level, our mission is to elevate the human condition by creating safe, robust, and capable AI systems. We expect to have much more to say about our approach to safety and to the development of robust AI agents over the next few months, but if there are particular questions or things you're wondering, we'd love to hear about them in the comments!&nbsp;&nbsp;</p><p>And if you're interested in helping to develop more robust, safe, generally capable AI systems,&nbsp;<a href=\"https://generallyintelligent.com/careers\"><u>we're hiring</u></a>! We also have some&nbsp;<a href=\"https://jobs.lever.co/generallyintelligent/5b2741ab-7534-42c8-992e-487b35590adc\"><u>non-engineering safety related roles</u></a>.</p>", "user": {"username": "joshalbrecht"}}, {"_id": "Ne8ZS6iJJp7EpzztP", "title": "The optimal timing of spending on AGI safety work; why we should probably be spending more now", "postedAt": "2022-10-24T17:42:05.842Z", "htmlBody": "<h1>Summary</h1><p>When should funders wanting to increase the probability of AGI going well spend their money? We have created a <a href=\"https://colab.research.google.com/drive/17f0yTYcFSBihZFd8_N7yRjF2XYJDjvBZ?usp=sharing\">tool</a> to calculate the&nbsp;<i>optimal spending schedule</i> and tentatively conclude that funders collectively should be <strong>spending&nbsp;</strong><i><strong>at least&nbsp;</strong></i><strong>5% of their capital each year</strong> on AI risk interventions and in some cases up to 35%, depending on views about AGI timelines and other key variables.&nbsp;</p><p>This is likely higher than the current AI risk community spending rate which we estimate to be at most 3%<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6n35i76hdvb\"><sup><a href=\"#fn6n35i76hdvb\">[1]</a></sup></span>. In most cases, we find that the optimal spending schedule is between 5% and 15% better than the \u2018default\u2019 strategy of just spending the interest one accrues and generally between 5% to 35% better than a naive projection of the community\u2019s current spending rate<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0k98lv637wof\"><sup><a href=\"#fn0k98lv637wof\">[2]</a></sup></span>.</p><p><strong>We strongly encourage users to put their own inputs into the </strong><a href=\"https://colab.research.google.com/drive/17f0yTYcFSBihZFd8_N7yRjF2XYJDjvBZ?usp=sharing\"><strong>tool</strong></a><strong> to draw their own conclusions.</strong></p><p>The key finding of a higher spending rate is supported by two distinct models we have created, one that splits spending of capital into&nbsp;<i>research&nbsp;</i>and&nbsp;<i>influence</i>, and a second model&nbsp; (the \u2018<i>alternate model</i>\u2019) that supposes we can spend our stock of&nbsp;<i>things that grow</i> on direct work. We focus on the former with the latter described in the <a href=\"https://forum.effectivealtruism.org/posts/Ne8ZS6iJJp7EpzztP/the-optimal-timing-of-spending-on-agi-safety-work-why-we#Alternate_model\">appendix</a> since its output is more obviously action-guiding<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjfdtziejv3l\"><sup><a href=\"#fnjfdtziejv3l\">[3]</a></sup></span>.</p><p>The table below shows our best guess for the optimal spending schedule using the former model when varying the difficulty of achieving a good AGI outcome and AGI timelines. We keep other inputs, such as diminishing returns to spending and interest rate constant.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb2vjnl9n18\"><sup><a href=\"#fnb2vjnl9n18\">[4]</a></sup></span></p><figure class=\"table\"><table><tbody><tr><td>&nbsp;</td><td colspan=\"3\">Median AGI arrival</td></tr><tr><td>&nbsp;</td><td>2030<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqwrm4pzrqbq\"><sup><a href=\"#fnqwrm4pzrqbq\">[5]</a></sup></span></td><td>2040<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvgdt0udb0u\"><sup><a href=\"#fnvgdt0udb0u\">[6]</a></sup></span></td><td>2050<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb83eattgl4\"><sup><a href=\"#fnb83eattgl4\">[7]</a></sup></span></td></tr><tr><td style=\"width:100px\">Easy<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbzpjm634xxf\"><sup><a href=\"#fnbzpjm634xxf\">[8]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgjjouwp7w1r\"><sup><a href=\"#fngjjouwp7w1r\">[9]</a></sup></span></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/t4pepexidukjzhgzrkee\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ogbcbfual8pvzkdifm43 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/xlubcm7zkh0lq2o35cf9 230w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/zfqed5cx4zj6sn2jwwdu 310w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/fa46r9npesvivaw79oea 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ugirp16zbx21slauxeev 470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/dvhpr0gkfu13u8eoruko 550w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/jzdih0qofznklpmjj5cq\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/bkvhmcsvjluy1ihysmil 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/aonhbz5rd1unf1p1x7qa 230w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/frbu5bcf0en0gezj9rkw 310w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/lz3ypgnltczybxidlxs3 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/rmdazf4ryyx3emmzyfcu 470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ee3zaox03lkljc45k0nk 550w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/qwprnaioh1s4apqvouuk\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/fosxjfuskfvqn4akhvgx 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/piy9jyi4zh4y3tmz5cgv 230w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/g6awzrxft2rgpiju44md 310w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/qggjibqjxpziatt4kfgd 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/gvh1mluz3x2rk62dhzdl 470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/grkrncbsk1qh4hgaluda 550w\"></figure></td></tr><tr><td>Medium<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0tdybtyk93v\"><sup><a href=\"#fn0tdybtyk93v\">[10]</a></sup></span></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/rvvpl6eoy0kwqprwxovz\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/kxjn8bgewmvfd3wq4gzp 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/njfa0ksmnceadkwp1yzr 230w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/h0dgfizbzo4taqoyno9z 310w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/h3ue1pgq6f1togugt7ic 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/w3fqrkxlkoh60yudh2u7 470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/i8bftrvmkbkp17helk3p 550w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/wbqtnnhh4drfmyogiqrr\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/zkblld6eefo4iekibpbl 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/mvxfu7tk8tguiwg3yjfl 230w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ddundfbetsghtoi2alhq 310w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/nlmdoltufflk4qelvp7k 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/rbhqxrb9wbjiu9bidd2d 470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/h7ug2wrro3f1zntzczn0 550w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/jccwxhfdgm26ismj5wuu\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/og2ejnwqpxzm4kyjtlhl 134w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/w27f0lvsdrciurhp8frr 214w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/g5t16rk1ktplyazq8063 294w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/gxeyoqekt08a0hysq4ds 374w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/aqyfevbqpvlrdwchg16p 454w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ncrsrmpnqhdumzjtseez 534w\"></figure></td></tr><tr><td>Hard<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhwjj0ec3rm4\"><sup><a href=\"#fnhwjj0ec3rm4\">[11]</a></sup></span></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/uxilq3wmmlb437u2fcxj\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/mh8nxcishudvfigvlpic 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ogfyt5wuewo1ixeg6ovx 230w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/r7d2buuchqntsvawrbff 310w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/vhivsxycuvjgltgcnpba 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/f4lrkfnkdmxndvy1p5qo 470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/fmcoha5etm1obpvmwfui 550w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/mgf6pdpet3lzgpwpulea\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/swfmipqjtw5mk4hs3flo 91w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/z0qtupoascprvpidaqey 171w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/seudbxqpjpty7rktxeoj 251w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/wwjukshu96yaau7ftd0g 331w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/cn6i7xfctwix1mwpsxw7 411w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/qzg61a7xmsit9geesno2 491w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/fqfpxig7s5tm1asci5tv 571w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/czll2lajdws9ygizcj8k\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/jxdo0wfud0zdnddejydk 145w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/t5nxeyd9tg0a1qcgvku2 225w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/hvi4nqutzqdqr1xkkfj4 305w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/zcvktjzxw8mdbfx8gisw 385w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ks3gam7k50tw0fnsnfto 465w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/rahzmumq7uc9ill4jqls 545w\"></figure></td></tr></tbody></table></figure><figure class=\"table\"><table><tbody><tr><td colspan=\"4\"><i><strong>How much better the optimal spending schedule is compared to the 2%+2% constant spending schedule (within-model lower bound<u>)</u></strong></i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefza4zqb2q3k\"><sup><a href=\"#fnza4zqb2q3k\">[12]</a></sup></span></td></tr><tr><td>&nbsp;</td><td colspan=\"3\"><p>Median AGI</p></td></tr><tr><td style=\"padding:5pt;vertical-align:top\">&nbsp;</td><td style=\"padding:5pt;vertical-align:top\">2030</td><td style=\"padding:5pt;vertical-align:top\">2040</td><td style=\"padding:5pt;vertical-align:top\">2050</td></tr><tr><td style=\"padding:5pt;vertical-align:top\">Easy</td><td style=\"padding:5pt;vertical-align:top\">37.6%</td><td style=\"padding:5pt;vertical-align:top\">18.4%</td><td style=\"padding:5pt;vertical-align:top\">11.8%</td></tr><tr><td style=\"padding:5pt;vertical-align:top\">Medium</td><td style=\"padding:5pt;vertical-align:top\">39.3%</td><td style=\"padding:5pt;vertical-align:top\">14.9%</td><td style=\"padding:5pt;vertical-align:top\">12.0%</td></tr><tr><td style=\"padding:5pt;vertical-align:top\">Hard</td><td style=\"padding:5pt;vertical-align:top\">12.3%</td><td style=\"padding:5pt;vertical-align:top\">5.85%</td><td style=\"padding:5pt;vertical-align:top\">1.55%</td></tr></tbody></table></figure><p>Some of the critical limitations of our model include: poorly modelling exogenous research, which is particularly important for those with longer timelines, and many parts of the model - such as diminishing returns - remaining constant over time.</p><p>Further, we find that <i>robust </i>spending strategies - those that work in a wide variety of worlds - also support a higher spending rate. We show the results of a Monte Carlo simulation in the appendix.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl7mov3kerw\"><sup><a href=\"#fnl7mov3kerw\">[13]</a></sup></span></p><h1>Introduction</h1><p>Humanity might be living at a hinge moment in history (<a href=\"https://globalprioritiesinstitute.org/william-macaskill-are-we-living-at-the-hinge-of-history/#:~:text=William%20MacAskill%20(Global%20Priorities%20Institute%2C%20Oxford%20University),-GPI%20Working%20Paper&amp;text=In%20the%20final%20pages%20of,dangerous%20and%20decisive%20period...\"><u>MacAskill, 2020</u></a>). This is partly due to the unusually high level of existential risks (<a href=\"https://theprecipice.com/\"><u>Ord, 2020</u></a>) and, in particular, the significant probability that humanity will build artificial general intelligence (AGI) in the next decades (<a href=\"https://www.lesswrong.com/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines\"><u>Cotra, 2022</u></a>). More specifically, AGI is likely to make up for a large fraction of extinction risks in the present and next decades (<a href=\"https://www.lesswrong.com/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to\"><u>Cotra, 2022</u></a>) and stands as a strong candidate to influence the long-term future. Indeed, AGI might play a particularly important role in the long-term trajectory change of Earth-originating life by increasing the chance of a flourishing future (<a href=\"https://nickbostrom.com/utopia\"><u>Bostrom, 2008</u></a>) and reducing the risks of large amounts of disvalue (<a href=\"https://longtermrisk.org/altruists-should-prioritize-artificial-intelligence/\"><u>Gloor, 2016</u></a>).&nbsp;</p><p>Philanthropic organisations aligned with effective altruism principles such as the FTX Foundation and Open Philanthropy play a crucial role in reducing AI risks by optimally allocating funding to organisations that produce research, technologies and influence to reduce risks from artificial intelligence. Figuring out the optimal funding schedule is particularly salient now with the risk of AI timelines under 10 years (<a href=\"https://www.lesswrong.com/posts/rzqACeBGycZtqCfaX/fun-with-12-ooms-of-compute\"><u>Kokotajlo, 2022</u></a>), and the substantial growth in effective altruism (EA) funding roughly estimated at 37% per year from 2015 to 2021 for a total endowment of about 46B$ by then end of 2021 (<a href=\"https://forum.effectivealtruism.org/posts/zA6AnNnYBwuokF8kB/is-effective-altruism-growing-an-update-on-the-stock-of\"><u>Todd, 2021</u></a>).&nbsp;</p><p>Previous work has emphasised the need to invest now to spend more later due to low discount rates (<a href=\"https://forum.effectivealtruism.org/posts/CfLoq8nJBzRARohtQ/the-case-for-investing-to-give-later\"><u>Sjrh, 2020</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/3fmcNMrR8cktLnoYk/giving-now-vs-later-for-existential-risk-an-initial-approach\"><u>Dickens 2020</u></a>). This situation corresponds to a \u201cpatient philanthropist\u201d. Research has modelled the optimal spending schedule a patient philanthropist should follow if they face constant interest rates, diminishing returns and a low discount rate accounting for existential risks (<a href=\"https://globalprioritiesinstitute.org/wp-content/uploads/Trammell-Dynamic-Public-Good-Provision-under-Time-Preference-Heterogeneity.pdf\"><u>Trammell, 2021</u></a>,&nbsp;<a href=\"https://docs.google.com/document/d/1NcfTgZsqT9k30ngeQbappYyn-UO4vltjkm64n4or5r4/edit\"><u>Trammell 2021</u></a>). Extensions of the single provider of public goods model allowed for the rate of existential risks to be time-dependent (<a href=\"https://forum.effectivealtruism.org/posts/mq7DB72ndm6YGtsoH/optimal-allocation-of-spending-on-existential-risk-reduction\"><u>Alaya, 2021</u></a>) and to include a trade-off between labour and capital where labour accounts for movement building and direct work (<a href=\"https://forum.effectivealtruism.org/posts/FXPaccMDPaEZNyyre/a-model-of-patient-spending-and-movement-building\"><u>Sempere, Trammell 2021</u></a>). Some models also discussed the trade-off between economic growth and existential risks by modelling the dynamics between safety technology and consumption technology with an endogenous growth (<a href=\"https://globalprioritiesinstitute.org/leopold-aschenbrenner-existential-risk-and-growth/\"><u>Aschenbrenner, 2020</u></a>) and an exogenous growth model (<a href=\"https://philiptrammell.com/static/ExistentialRiskAndExogenousGrowth.pdf\"><u>Trammell, 2021</u></a>).&nbsp;</p><p>Without more specific quantitative models taking into account AI timelines, growth in funding, progress in AI safety and the difficulty of building safe AI, previous estimates of a spending schedule of just over 1% per year (<a href=\"https://forum.effectivealtruism.org/posts/zA6AnNnYBwuokF8kB/is-effective-altruism-growing-an-update-on-the-stock-of\"><u>Todd 2021</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/cfdnJ3sDbCSkShiSZ/ea-and-the-current-funding-situation\"><u>MacAskill 2022</u></a>) are at risk of underperforming the optimal spending schedule.</p><p>In this work, we consider a philanthropist or philanthropic organisation maximising the probability of humanity building safe AI. The philanthropist spends money to increase the stock of AI safety research and influence over AI development which translates into increasing the probability of successfully aligning AI or avoiding large amounts of disvalue. Our model takes into account AI timelines, the growth of capital committed to AI safety, diminishing returns in research and influence as well as the competitiveness of influencing AI development. We also allow for the possibility of a fire alarm shortly before AGI arrives. Upon \u201chearing\u201d the fire alarm, the philanthropist knows the arrival time of AGI and wants to spend all of its remaining money until that time. The philanthropist also has some discount rate due to other existential risks and exogenous research that accelerate safety research.</p><p>Crucially, we have coded the model into a&nbsp;<a href=\"https://colab.research.google.com/drive/17f0yTYcFSBihZFd8_N7yRjF2XYJDjvBZ?usp=sharing\"><u>notebook</u></a> accompanying this blog post that philanthropists and interested users can run to estimate an optimal spending schedule given their estimates of AI timelines, the difficulty of AI safety, capital growth and diminishing returns. Mathematically the problem of finding the optimal spending schedule translates into an optimal control problem giving rise to a set of nonlinear differential equations with boundary conditions that we solve numerically.</p><p>We discuss the effect of AI timelines and the difficulty of AI safety on the optimal spending schedule. Importantly, the optimal spending schedule typically ranges from 5% to 35% per year this decade, certainly above the current typical spending of EA-aligned funders. A funder should follow the most aggressive spending schedule this decade if AI timelines are short (2030) and safety is hard. An intermediate scenario yields a yearly average spending of ~12% over this decade. The optimal spending schedule typically performs between 5 to 15% better than the strategy of spending the endowment\u2019s rate of appreciation and most likely between 5% to 40% better than a projection of the movement's current spending rate.</p><h1>A qualitative description of the model</h1><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/bsdmc9mdlv8829d6uujq\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/lkyfvfcrc5df3ohsqxe2 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/epfsgibzwpgtbyw7fmss 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/qdqfunrospg0j9cvyvzh 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/tatff1eykxu1h70ndlnc 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/yxesfebnqf75rsiv5bqh 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/kk6zjcihn7sqtohjkwjr 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/usq3zzf2t3wjo4p0mg2r 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/wn0cl8dh9pgheyexiuhy 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/owau7rcc7bkyxj62dxmk 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/uu0onxnverlyd67mhdrm 961w\"><figcaption><i>A diagram of the model. The red arrows above show what we, the funders, can control: the amount of money we spend each year on research and influence. The curved red boxes indicate some of the key inputs. An arrow from A to B indicates that B depends on the value of A.</i></figcaption></figure><p>We suppose that a single funder controls&nbsp;<i>all&nbsp;</i>of the community\u2019s funding that is earmarked for AI risk interventions and that they set the spending rate for two types of interventions:&nbsp;<i>research</i> and&nbsp;<i>influence.&nbsp;</i>The funder\u2019s aim is to choose the spending schedule - how much they spend each year on each intervention - that maximises the probability that AGI goes successfully (e.g. does not lead to an existential catastrophe).</p><p>The \u2018model\u2019 is a set of equations and&nbsp;<a href=\"https://colab.research.google.com/drive/17f0yTYcFSBihZFd8_N7yRjF2XYJDjvBZ\"><u>accompanying Colab notebook</u></a>. The latter, once given inputs from the user, finds the optimal spending schedule. A technical description of the model is in the <a href=\"https://forum.effectivealtruism.org/posts/Ne8ZS6iJJp7EpzztP/the-optimal-timing-of-spending-on-agi-safety-work-why-we#Technical_description\">appendix</a>.</p><h2>Research and influence</h2><p>We suppose that any spending is on either&nbsp;<i>research</i> or&nbsp;<i>influence</i>. Any money we don\u2019t spend is saved and gains interest. As well as investing money in traditional means, the funder is able to \u2018invest\u2019 in promoting&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/earning-to-give\"><u>earning-to-give</u></a>, which historically has been a source of a large fraction of the community\u2019s capital.</p><p>We suppose there is a single number for each of the stocks of research and influence describing how much the community has of each<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0ozx9a9j2ytp\"><sup><a href=\"#fn0ozx9a9j2ytp\">[14]</a></sup></span>.</p><p>Research refers to the community\u2019s ability to make AGI a success given we have complete control over the system (modulo being able to delay its deployment indefinitely). The stock of research contains AI safety technical knowledge, skilled safety researchers, and safe models that we control and can deploy. Influence describes the degree of control we have over the development of AGI, and can include \u2018soft\u2019 means such as through personal connections or \u2018hard\u2019 means such as passing policy. Both research and influence contribute to the probability we succeed and the user can input both their relative importance and the degree to which they are \u2018substitutable\u2019.&nbsp;</p><p>The equations modelling the time evolution of research and influence have the following features:</p><ul><li>Diminishing marginal returns to spending; the returns to growth in research/influence from each additional unit of spending per year decreases.</li><li>Appreciation or depreciation of research/influence over time. For example, our stock of research could depreciate by becoming less relevant over time as paradigms change and influence could depreciate over time if the AI developers we have influence over become less likely to develop AGI compared to another group.</li><li>The price of one unit of research and influence can change based on how much you already have. For example, having more research may open up multiple parallelizable tracks for people to work on, decreasing the cost of research units. Conversely, once we have more research new researchers must spend increasing time catching up on existing work and so research could become more expensive.</li><li>Influence can become more expensive over time due to competition. As other actors enter the field and also wish to influence AI and the field of AI development itself grows, one unit of spending can result in less influence.&nbsp;</li></ul><h2>Money</h2><p>Any money we don\u2019t spend appreciates. Historically the money committed to the effective altruism movement has grown faster than market real interest rates. The model allows for a variable real interest rate, which allows for the possibility that the growth of the AI risk community slows.&nbsp;</p><h2>Preparedness</h2><p>We use the term&nbsp;<i>preparedness at time&nbsp;</i><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>&nbsp;to describe how \u2018ready\u2019 we are if AGI arrived at time&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\"><span class=\"mjx-mrow\" aria-hidden=\"true\"></span></span></span></span></span><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span>. Preparedness is a function of research and influence: the more we have of each the more we are prepared.&nbsp;</p><h3>AGI fire alarm</h3><p>We may find it useful to have money before AGI takeoff, particularly if we have a \u2018fire alarm\u2019 period where we know that AGI is coming soon and can spend most of it on last-minute research or influence. The model allows for such last-minute spending on research and influence, and so one\u2019s money contributes indirectly to preparedness.&nbsp;</p><h2>Success</h2><p>The probability of success given AGI arriving in year&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span>&nbsp;is an S-shaped function of our preparedness. The model is not fixed to any definition of \u2018success\u2019 and could be, but is not limited to, \u201cAGI not causing an existential catastrophe\u201d or \u201cAGI being aligned to human values\u201d or \"preventing AI caused s-risk\".</p><p>This functional form allows the user to specify that we increasing returns or decreasing returns to our preparedness and determine the speed of transition from the former to the latter.</p><p>Since we are uncertain when AGI will arrive, the model considers AGI timelines input from the user and takes the integral of the product of {the probability of AGI arriving at time&nbsp;t} and {the probability of success at time&nbsp;t given AGI at time&nbsp;t}.</p><p>The model also allows for a discount rate to account for non-AGI existential risks or catastrophes that preclude our research and influence from being useful or other factors.&nbsp;</p><p>The funder\u2019s&nbsp;<i>objective function</i>, the function they wish to maximise, is the probability of making AGI go successfully.</p><h2>Solving the model</h2><p>The preceding qualitative description is of a collection of differential equations that describe how the numerical quantities of money, research and influence change as a function of our spending schedule. We want to find the spending schedule that maximises the objective function, the&nbsp;<i>optimal spending schedule</i>. We do this with tools from&nbsp;<a href=\"https://en.wikipedia.org/wiki/Optimal_control\"><u>optimal control theory</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0559jboxwohm\"><sup><a href=\"#fn0559jboxwohm\">[15]</a></sup></span>. We call such a schedule the optimal spending schedule.</p><h1>Results</h1><h2>Optimal spending scheduled when varying AGI timelines and difficulty of success</h2><p>We first review the table from the top of the post, which varies AGI timelines and difficulty of an AGI success while keeping all other model inputs constant. We stress that the results are based on&nbsp;<i>our&nbsp;</i>guesses of the inputs (such as diminishing returns to spending) and encourage people to try the tool out themselves.&nbsp;</p><figure class=\"table\"><table><tbody><tr><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/eblk0wkro9yk6wvizm43\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ezpxgg3fjfb492iw8c5z 121w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/payobfnjnhgkdfuvb7t8 201w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/grrklzqf1eistemn5idp 281w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/zhe7xabsfw66tjrjwlve 361w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/nus0zsymynng8yyf8psx 441w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/fukbtc6wfny34jczf3co 521w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/u9pkwjzasuz3ex4a5ivt 601w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/hzyurpz5lv0fhte3wvzv 681w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/iouci9aaizsqxvzebhkb 761w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/iv4jothijibjcvn4g1fs\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/qnwttwk64pcdad0qpcxr 121w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ba1zpz0csq7hcucpptds 201w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/kot4nlo8jqqlpl4fre0z 281w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/lvmwni98uyq3vbopbugf 361w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/vpl9vjr1dtqzvnn7x4hz 441w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/tjt8zajt5il2a6okvo9u 521w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ars48krckuuwhx8fekv9 601w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/wrc8xlyfwgy2fubrvrex 681w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ib9sbex5986ix3usunuk 761w\"></figure></td></tr><tr><td colspan=\"2\">The yearly optimal spending schedule averaged over this decade, 2022-2030 (left), and the next, 2030-2040 (right). For each level of AI safety difficulty (easy, medium and hard columns) and each decade we reported the average spending rates in research and influence in % of the funder\u2019s endowment.</td></tr></tbody></table></figure><p>We consider our best guess for the model\u2019s parameters as given in the <a href=\"https://forum.effectivealtruism.org/posts/Ne8ZS6iJJp7EpzztP/the-optimal-timing-of-spending-on-agi-safety-work-why-we#Explaining_and_estimating_the_model_parameters\">appendix</a>. We describe the effects of timelines and the difficulty of AI safety on the spending schedule in this decade (2022-2030), the effects being roughly similar in the 2030 decade.</p><p>&nbsp;In most future scenarios we observe that the average optimal spending schedule is substantially higher than the current EA spending rate standing at around 1-3% per year. The most conservative spending schedule happens when the difficulty of AI safety is hard with medium timelines (2050) with an average spending rate of around 6.5% per year. The most aggressive spending schedule happens when AI safety is hard and timelines are short (2030) with an average funding rate of about 35% per year.</p><p>For each level of difficulty and each AI timelines, the average allocation between research and influence looks balanced. Indeed, research and influence both share roughly half of the total spending in each scenario. Looking closer at the results in the <a href=\"https://forum.effectivealtruism.org/posts/Ne8ZS6iJJp7EpzztP/the-optimal-timing-of-spending-on-agi-safety-work-why-we#_Full_results_from_the_nine_cases\">appendix</a>, we observe that influence seems to decrease more sharply than research spending, particularly beyond the 2030 decade. This is likely caused by the sharp increase in the level of competition over AI development making units of influence more costly relative to units of research. Although we want to emphasise that the share of influence and research in the total spending schedule could easily change with different diminishing returns in research and influence parameters.</p><p>The influence of AI timelines on the optimal spending schedule varies across distinct levels of difficulty but follows a consistent trend. Roughly, with AI timelines getting longer by a decade, the funder should decrease its average funding rate by 5 to 10%, unless AI safety is hard. If AI safety is easy, a funder should spend an average of ~25% per year for short timelines (2030), down to ~18% per year with medium timelines (2040) and down to ~15% for long timelines (2050). If AI safety difficulty is medium then the spending schedule follows a similar downtrend, starting at about 30% with short timelines down to ~12% with medium timelines and down to 10% with long timelines. If AI safety is hard, the decline in spending from short to medium timelines is sharper, starting at 35% per year with short timelines down to ~8% with medium timelines and down to about 5% with long timelines.</p><p>Interestingly, conditioning on short timelines (2030), going from AI safety hard to easier difficulty&nbsp;<i>decreases</i> the spending schedule from ~35% to ~25% but conditioning on medium (204) or long (2050) timelines going from AI safety hard to easier difficulty&nbsp;<i>increases</i> the spending schedule from 6% to 18% and 9% to 15% respectively.&nbsp;</p><p>In summary, in most scenarios, the average optimal spending schedule in the current decade typically varies between 5% to 35% per year. With medium timelines (2040) the average spending schedule typically stays in the 10-20% range and moves up to the 20-35% range with short timelines (2030). The allocation between research and influence is balanced.</p><h2>Sensitivity</h2><p>In this section, we show the effect of varying one parameter (or related combination) on the optimal spending schedule. The rest of the inputs are described in the <a href=\"https://forum.effectivealtruism.org/posts/Ne8ZS6iJJp7EpzztP/the-optimal-timing-of-spending-on-agi-safety-work-why-we#Explaining_and_estimating_the_model_parameters\">appendix</a>. We stress again that these results are for the inputs we have chosen and encourage you to try out your own.</p><h3>Discount rate</h3><p>Varying just the discount rate we see that a higher discount rate implies a higher spending rate in the present.</p><figure class=\"table\"><table><tbody><tr><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/r6biwewrquugwfvaf0xq\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/pveyjdwuymxp05evwx8f\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/mqtfvlim1rwnqhkbf08w\"></figure></td></tr><tr><td>Low discount rate:&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d=0.5\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span></td><td>Our guess,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d=2\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span></td><td>High discount rate,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d=5\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span></td></tr></tbody></table></figure><h3>Growth rate</h3><p>It seems plausible that the community and its capital are likely to be going through an unusually fast period of growth that will level off<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrd1s8t31ih\"><sup><a href=\"#fnrd1s8t31ih\">[16]</a></sup></span>. When assuming a lower rate of growth we see that the optimal spending schedule is a lower rate, but still higher than the community\u2019s current allocation. In particular, we should be spending <i>faster </i>than we are growing.</p><figure class=\"table\"><table><tbody><tr><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/lgnnfc6efd9emiqhb9jx\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/jpafpykefdf30db0zi7q\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/pveyjdwuymxp05evwx8f\"></td></tr><tr><td style=\"padding:5pt;vertical-align:top\">Highly pessimistic growth rate: 5% growth rate</td><td style=\"padding:5pt;vertical-align:top\">Pessimistic growth rate: 10% current growth decreasing to 5% in the five years<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2rrtvaiivxq\"><sup><a href=\"#fn2rrtvaiivxq\">[17]</a></sup></span>.</td><td style=\"padding:5pt;vertical-align:top\">Our guess: 20% current growth decreasing to 8.5% in the next ten years<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzxvcxu04yoi\"><sup><a href=\"#fnzxvcxu04yoi\">[18]</a></sup></span>.</td></tr></tbody></table></figure><h3>Current money committed to AGI interventions</h3><p>We can compute the change in utility when the amount of funding committed to AI risk interventions changes. This is of relevance to donors interested in the marginal value of different causes, as well as philanthropic organisations that have not explicitly decided the funding for each cause area.</p><figure class=\"table\"><table><tbody><tr><td style=\"padding:5pt;vertical-align:top\"><strong>Starting money multiplier</strong></td><td style=\"padding:5pt;vertical-align:top\">0.001</td><td style=\"padding:5pt;vertical-align:top\">0.01</td><td style=\"padding:5pt;vertical-align:top\">0.1</td><td style=\"padding:5pt;vertical-align:top\">0.5</td><td style=\"padding:5pt;vertical-align:top\">1</td><td style=\"padding:5pt;vertical-align:top\">1.1</td></tr><tr><td style=\"padding:5pt;vertical-align:top\"><strong>Absolute utility</strong></td><td style=\"padding:5pt;vertical-align:top\">0.031<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmud4jt7iwid\"><sup><a href=\"#fnmud4jt7iwid\">[19]</a></sup></span></td><td style=\"padding:5pt;vertical-align:top\">0.044</td><td style=\"padding:5pt;vertical-align:top\">0.092</td><td style=\"padding:5pt;vertical-align:top\">0.219</td><td style=\"padding:5pt;vertical-align:top\">0.317</td><td style=\"padding:5pt;vertical-align:top\">0.332</td></tr><tr><td style=\"padding:5pt;vertical-align:top\"><strong>Multiple of 100% money utility</strong></td><td style=\"padding:5pt;vertical-align:top\">0.098</td><td style=\"padding:5pt;vertical-align:top\">0.139</td><td style=\"padding:5pt;vertical-align:top\">0.290</td><td style=\"padding:5pt;vertical-align:top\">0.691</td><td style=\"padding:5pt;vertical-align:top\">1</td><td style=\"padding:5pt;vertical-align:top\">1.047</td></tr></tbody></table></figure><p><br>A different initial endowment has qualitative effects on the spending schedule. For example, comparing the 10% to 1000% case we see that when we have more money we - unsurprisingly - spend at a much higher rate. This result itself is sensitive to the existing stocks of research and influence.</p><figure class=\"table\"><table><tbody><tr><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ye9yrtpbqq4topfijqao\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/c5sw6vtqhygorzm2xetx\"></td></tr><tr><td style=\"padding:5pt;vertical-align:top\">When we have 10% of our current budget of $4000m</td><td style=\"padding:5pt;vertical-align:top\">When we have 1000% of our current budget</td></tr></tbody></table></figure><p>The spending schedule is not independent of our initial endowment. This is primarily driven by the S-shaped success function. When we have more money, we can beeline for the steep returns of the middle of the S-shape. When we have less money, we choose to save to later reach this point.&nbsp;</p><h3>Diminishing returns</h3><p>We see that, unsurprisingly, lower diminishing returns to spending suggest spending at a higher rate.</p><figure class=\"table\"><table><tbody><tr><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/xtupzify0xex6b557v8r\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/pveyjdwuymxp05evwx8f\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/tvvngwewt7ykix59hejj\"></td></tr><tr><td>High diminishing returns<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref34pvwvdj5j1\"><sup><a href=\"#fn34pvwvdj5j1\">[20]</a></sup></span></td><td>Our guess<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmuz462aogp\"><sup><a href=\"#fnmuz462aogp\">[21]</a></sup></span></td><td style=\"padding:5pt;vertical-align:top\">Low diminishing returns<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefp99df7wtcj\"><sup><a href=\"#fnp99df7wtcj\">[22]</a></sup></span></td></tr></tbody></table></figure><h3>Parallel vs serial research</h3><p>The constant&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;controls whether research becomes cheaper as we accumulate more research (<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R>0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&gt;0) or more expensive&nbsp;(<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R<0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>). The former could describe a case where an increase in research leads to the increasing ability to parallelize research or break down problems into more easily solvable subproblems. The latter could describe a case where an increase in research leads to an increasingly bottlenecked field, where further progress depends on solving a small number of problems that are only solvable by a few people.</p><figure class=\"table\"><table><tbody><tr><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/xlz1bqk44kw1gmyan940\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ocic50fhpcacls4rdo1o\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/uyfj5os13c0ptnggkbwr\"></td></tr><tr><td>Research is highly serial (<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R=-0.5\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.5</span></span></span></span></span></span></span>)</td><td>Default (<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R=0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>)</td><td>Research is highly parallelizable (<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R=0.5\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.5</span></span></span></span></span></span></span>)</td></tr></tbody></table></figure><p>We see that in a world where research is either highly serial or parallelizable, we should be spending at a higher rate than if it is, on balance, neither. The&nbsp;<i>parallelizable result</i> is less surprising than the&nbsp;<i>serial&nbsp;</i>result, which we plan to explore in later work.</p><p>A more nuanced approach would use a function&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R(R(t))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;such that the field can become more or less bottlenecked as it progresses and the price of research changes accordingly.&nbsp;</p><h3>Presence of a fire alarm</h3><p>Using our parameters, we find the presence of a fire alarm greatly improves our prospects and, perhaps unexpectedly, pushes the spending schedule upwards. This suggests it is both important to be able to correctly identify the point at which AGI is close and have a plan for the post-fire alarm period. We speculate that the reason for this unexpected increase is similar to how increasing the initial money changes the spending schedule.&nbsp;</p><figure class=\"table\"><table><tbody><tr><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/mbq7lo7jglq1ks4id5of\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/sgftee2ywwozv2thxpky\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/cyhu6g3lwahlb0capfeg\"></td></tr><tr><td style=\"padding:5pt;vertical-align:top\"><strong>No fire alarm</strong>.</td><td style=\"padding:5pt;vertical-align:top\"><strong>Short fire alarm</strong>: funders spend 10% of one\u2019s money over six months. In this&nbsp; case, we get 36% more utility than no fire alarm.</td><td><p><strong>Long fire alarm</strong>: funders spend 20% of one\u2019s money over one year. In this case, we get 56% more utility than no fire alarm.</p><p><br>&nbsp;</p></td></tr></tbody></table></figure><h3>Substitutability of research and influence</h3><p>Increasing the substitutability of research and influence means that one (weight adjusted<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefu4cslxlpzq\"><sup><a href=\"#fnu4cslxlpzq\">[23]</a></sup></span>) unit of research can be replaced by closer to one unit of influence to have the same level of preparedness.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb6xmk0hge4r\"><sup><a href=\"#fnb6xmk0hge4r\">[24]</a></sup></span></p><p>Since, by our choice of inputs, we already have much more importance-adjusted research than influence<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjdo593mzzo\"><sup><a href=\"#fnjdo593mzzo\">[25]</a></sup></span>, in the case where they are very poor substitutes we must spend at a high rate to get influence.&nbsp;</p><p>When research and influence are perfect substitutes since research is \u2018cheaper\u2019<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaro9kv2dskj\"><sup><a href=\"#fnaro9kv2dskj\">[26]</a></sup></span>&nbsp;with our chosen inputs the optimal spending schedule suggests that nearly spending should be on research<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxdh4oo6w5w\"><sup><a href=\"#fnxdh4oo6w5w\">[27]</a></sup></span>.&nbsp;</p><figure class=\"table\"><table><tbody><tr><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/qgb1r0agzxfmzsri697e\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/celdkjheuu0yem0ucsei\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/mbq7lo7jglq1ks4id5of\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/dnfesgd9w7f0jwgy6l4u\"></td></tr><tr><td>Research and influence are&nbsp;<i>very</i> poor substitutes<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnytkvoer9a\"><sup><a href=\"#fnnytkvoer9a\">[28]</a></sup></span></td><td>Research and influence are poor substitutes<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref13b8o0nosgq\"><sup><a href=\"#fn13b8o0nosgq\">[29]</a></sup></span></td><td>Our best guess<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefs1ebjhailoj\"><sup><a href=\"#fns1ebjhailoj\">[30]</a></sup></span></td><td>Research and influence are perfect substitutes<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4ioy6q2tluk\"><sup><a href=\"#fn4ioy6q2tluk\">[31]</a></sup></span></td></tr></tbody></table></figure><h1>Discussion</h1><h2>Some hot takes derived from the model</h2><p>We make a note of some claims that are supported by the model. Since there is a large space of possible inputs we recommend the user specify their own input and not rely solely on our speculation.</p><h3>The community\u2019s current spending rate is too low</h3><p>Supposing the community indefinitely spends 2% of its capital each year on research and 2% on influence, the optimal spending schedule is generally at least &nbsp;5% better.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcspwzen77d\"><sup><a href=\"#fncspwzen77d\">[32]</a></sup></span></p><h3>The optimal spending schedule is generally 5 to 15% better than the&nbsp;<i>default strategy</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5be1atounwr\"><sup><a href=\"#fn5be1atounwr\">[33]</a></sup></span></h3><p>The greatest difference in utility comes from cases where it is optimal to spend lots of money now, for example in the (2030 median, hard difficulty) world, the optimal spending schedule is 15% better than the default strategy.</p><h3>In most cases, we should not \u2018wager\u2019<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxm0e7wv83f\"><sup><a href=\"#fnxm0e7wv83f\">[34]</a></sup></span>&nbsp;on long AGI timelines when we believe AGI timelines are short</h3><p>Saving money now, even though AGI is expected sometime soon, is only occasionally recommended by the model. One case occurs with (1) a sufficiently low probability of success but steep gains to this probability after some amount of preparedness that is achievable in the next few decades, (2) a low discount rate, and either (a) that influence does not get too much more expensive over time or (b) influence is not too important.</p><figure class=\"table\"><table><tbody><tr><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/jmb3vdwg4dfchixbjo8h\"></figure></td></tr><tr><td>A \u2018wager\u2019 on long timelines in a case where we have 2030 AGI timelines. This case has a discount rate&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d=0.5\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span>&nbsp;, the difficulty is hard<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefc0q5tqapg0e\"><sup><a href=\"#fnc0q5tqapg0e\">[35]</a></sup></span>&nbsp;and the substitutability of research and influence is high<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwgvhowa871\"><sup><a href=\"#fnwgvhowa871\">[36]</a></sup></span>.</td></tr></tbody></table></figure><p>To some extent, there is a \u2018sweet spot\u2019 on the S-shaped success curve where we wager on long timelines. If we are able to push the probability of success to a region where the slope of the s-curve is large, we should spend a high rate until we reach this point. If we are stuck on the flatter far left tail such that we remain in that region regardless of any spending we do this century to stay in that area, we should spend at a more steady rate.&nbsp;</p><h3>In some cases, we should \u2018wager\u2019 on shorter timelines by spending at a high rate now</h3><p>This trivially occurs, for example, if you have a very high discount rate. A more interesting case occurs when (1) influence is poorly substituted by research<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmyc0xv610z9\"><sup><a href=\"#fnmyc0xv610z9\">[37]</a></sup></span>&nbsp;and either (a) influence depreciates quickly or (b) influence quickly becomes expensive. This could happen if growth in excitement in AI capabilities leads to established political actors such as corporations or governments begin trying to influence AI developers.</p><figure class=\"table\"><table><tbody><tr><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/nrs54qdwvmrvpevpykxx\"></figure></td></tr><tr><td>A \u2018wager\u2019 on short timelines in a case where we have the 2050 AGI timeline. This case has \u2018medium\u2019 difficulty and low substitutability of research and influence<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzvmkezu0ph\"><sup><a href=\"#fnzvmkezu0ph\">[38]</a></sup></span>.</td></tr></tbody></table></figure><p>Since the opportunity to wager on short timelines only is available now, we believe more effort should go into investigating the wager. Further, to the extent that one believes influence is getting more expensive and is important, <a href=\"https://www.lesswrong.com/posts/cxuzALcmucCndYv4a/?commentId=tGiMz2EACY45wd8Ft\">we may have already passed 'crunch time'.</a></p><h2>Limitations</h2><p>We discuss the primary limitations here, and reserve some for the <a href=\"https://forum.effectivealtruism.org/posts/Ne8ZS6iJJp7EpzztP/the-optimal-timing-of-spending-on-agi-safety-work-why-we#Further_limitations\">appendix</a>. For each limitation, we briefly discuss how a solution would potentially change the results.</p><h3>Research is endogenous</h3><p>The model does not explicitly account for research produced exogenously (i.e., not as a result of our spending). For example, it is plausible that research produced in academia should be included in our stock of research.</p><p>Exogenous research can be (poorly) approximated in the current model in a few different ways.&nbsp;</p><p>First, one could suppose that research appreciates over time and set&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_R>0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>. This supposes that research being done by outsiders is (directly) proportional to the research \u2018we\u2019 already have (where in this case, research done by outsiders is included in&nbsp;R(t)). Since we model exponential appreciation, appreciation leads to a research explosion. One could slow this research explosion by supposing the appreciation term was&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot R(t) = \\dots + \\lambda_R \\cdot R(t)^{\\beta_R}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22ef</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.007em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;\">\u03b2</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;for some&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"0< \\beta_R<1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.007em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.446em; padding-right: 0.007em;\">\u03b2</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>.</p><p>Second, one could suppose that exogenous research sometimes solves the problem for us, making our own research redundant. This can be approximated by increasing the discount rate to account for the \u2018risk\u2019 that our own work is not useful. This is unrealistic in the sense that we are \u2018surprised\u2019 by some other group solving the problem.</p><p>A possible modification to the model would be to add a term&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"y_R(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">y</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;to the expression for&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot R(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;that accounts for the exogenous rate of growth of research. Alternatively, one could consider a radically different model of research that considered our spending on research as simply speeding up the progress that will otherwise happen (conditioning on no global catastrophe).</p><p>We expect this is the biggest weakness of the model, especially for those with long AGI timelines. To a first approximation, if there is little exogenous research we do not need to account for it, and if there is a lot then our own spending schedule does not matter. Perhaps we might think our actions can lead us to be in either regime and our challenge is to push the world towards the latter.</p><h3>AGI timelines are independent of our spending schedule&nbsp;</h3><p>We may hope that some real-world interventions may delay the arrival of AGI, for example, passing policies to slow AI capabilities work. The model does not explicitly account for this feature of the world at all.</p><p>One extension to the model would be to change the length of the fire alarm period to be a function of the amount of influence we have. We expect this extension to imply an increase in the relative spending rate on influence. Another, more difficult extension would be to consider timelines as function&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p(t, I(t))\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp; such that we can \u2018push\u2019 timelines down the road with more influence.</p><p>We expect that our ability to delay the arrival of AGI, particularly for shorter arrivals, is sufficiently minimal such that it would not significantly change the result. For longer timelines, this seems less likely to be the case.</p><h3>Research and capabilities are independent.</h3><p>AI capabilities and our research influence each other in the real world. For example, AI capabilities may speed up research with AI assistants. On the other hand, spending large amounts on AI interventions may draw attention to the problem and speed up AI capabilities investment.&nbsp;</p><p>We allow for a depreciation of research, which can be used to model research becoming outdated as capabilities advance. One could also model research becoming cheaper over time<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefohplf1uc41o\"><sup><a href=\"#fnohplf1uc41o\">[39]</a></sup></span>&nbsp;to account for capabilities speeding up our research.</p><p>On balance, we expect this limitation to not have a large effect. If one expects a \u2018slow AI takeoff\u2019 with the opportunity to use highly capable AI tools, one can use the fire alarm feature and set the returns to research during this period to be high.&nbsp;</p><h3>Diminishing returns, and other features, are constant</h3><p>We model the returns to spending constant across time. However, actual funders seem to be bottlenecked by vetting capacity and a lack of scalable and high-return projects and so the returns to spending are likely to be high at the moment. Grantmakers can \u2018seed\u2019 projects and increase capacity such that it seems plausible that diminishing returns to spending will decrease in the future.</p><p>However, the model input only allows for constant diminishing marginal returns.</p><p>The model could be easily extended to use functions&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_R(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_I(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;such that marginal returns to spending on research and influence changed over time, similar to how the real interest rate<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>changes over time. This would require more input from the user.</p><p>Another extension could allow for the returns to be a function of the historic spending rate, such that scaling up slower leads to greater returns than scaling up quickly. However, such an extension would increase the model's complexity and decrease its usability, simplicity and (potentially) solvability.</p><p>This limitation also applies to other features of the model, such as the values&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_I\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span>.</p><h3>The optimal spending schedule is not always found</h3><p>Most existing applications of optimal control theory to effective altruism-relevant decision-making have used systems of differential equations that are analytically solvable and have guarantees of optimality. Our model has neither property and so we must rely on optimization methods that do not always lead to a global maximum.&nbsp;</p><h1>Appendix</h1><h2>Further limitations</h2><h3>Many inputs are required from the user</h3><p>There are around 40 free parameters that the user can set.</p><p>Many model features can be turned off. To turn off the following features:</p><ul><li>Variable interest rates, set&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r_{\\mathrm{current}} = r_{\\mathrm{eventual}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">c</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">v</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">a</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">l</span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;or set&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\delta =0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span></li><li>Discount rate, set&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d=0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span></li><li>Appreciation or depreciation, set&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_R, \\lambda_I =0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span></li><li>Change in price of research and influence, set&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R, \\alpha_I = 0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span></li><li>Competition that changes the price of influence, set all competition levels to be 1 in all years.</li><li>Only one of research or influence being necessary, set&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\gamma=1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>&nbsp;(for no influence) or&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\gamma=0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;(for no research) [in this case, the value of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span></span></span></span></span></span>&nbsp;does not matter]</li><li>Fire alarm, set the expected fraction of money spendable to 0.&nbsp;</li></ul><p>One can set parameters such that the model is equivalent to like the following system</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot M(t) = r\\cdot M(t) - x_R(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.436em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot R(t) = x_R(t)^{\\eta_R}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span></span></span></span></span></p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"U = \\int_{0}^{\\infty} p(t) \\cdot \\frac{1}{1+\\exp(\\left (-1 \\left (R(t)-R_0 \\right )\\right)} \\ \\mathrm{d} t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.138em;\"><span class=\"mjx-mo\" style=\"padding-right: 0.138em;\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">\u222b</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.366em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.579em; padding-left: 0.324em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">\u221e</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mfrac MJXc-space2\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 7.158em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 10.122em; top: -1.372em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 10.122em; bottom: -0.999em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">exp</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 7.158em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.677em; vertical-align: -0.707em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.291em; padding-bottom: 0.372em;\">&nbsp;</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span></p><p>Some results from this system<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8qoqfdxlymt\"><sup><a href=\"#fn8qoqfdxlymt\">[40]</a></sup></span>:</p><figure class=\"table\"><table><tbody><tr><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/x31bmsve8z3ct3esmukb\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/wp3oirfs5o8gwfpsyhrn\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/mqjyin9sh5xz5mwujrao\"></td></tr><tr><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/cygx8rmsq5j4prj92hvj\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ossnjqfgpcdr6cj06owd\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/dzxhan9xp1purhxxuk5x\"></td></tr><tr><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ffqdgjid6qnglmdvanr5\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ewx3rndnlorolz4zg8yu\"></td><td><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/dp5cutqgigfbhjjqncz5\"></td></tr></tbody></table></figure><h3>Appreciation of money is continuous and endogenous</h3><p>The current growth rate of our money is continuous. However, this poorly captures the case where most growth is driven by the arrival of new donors with lots of capital. Further, any growth is endogenous - it is always in proportion to&nbsp;our current capital&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"M(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>.</p><p>One modification would be to the model arrival time of future funders by a stochastic process, for example following a Poisson distribution. For example, take&nbsp;</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot M(t)=r(t)&nbsp;\\cdot M(t) -&nbsp;x_R(t) -&nbsp;x_I(t)&nbsp; +&nbsp;\\phi(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.436em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03d5</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p>Where&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\phi(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">\u03d5</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;can model endogenous and non-continuous growth of funding.</p><p>Following some preliminary experiments with a deterministic flux of funders, we are sceptical that this would substantially change the recommendations of the current model.</p><h3>The model only maximises the probability of \u2018success\u2019 (with constraints given by keeping money and spending non-negative)&nbsp;</h3><p>We see two potential problems with this approach.</p><p>First, one may care about spending money on things other than making AGI go well. The model does not tell you how to trade-off these outcomes. The model best fits into a portfolio approach of doing good, such as Open Philanthropy\u2019s&nbsp;<a href=\"https://www.openphilanthropy.org/research/worldview-diversification/\"><u>Worldview Diversification</u></a>. Alternatively, one may attach some value to having money leftover post-AGI.&nbsp;</p><p>Second, there may be outcomes of intermediate utility between AGI being successful and not. A simple extension could consider some function of the probability of success. A more complex extension could consider the utility of AGI conditioned on its arrival time and our preparedness that accounts for&nbsp;<a href=\"https://arbital.com/p/hyperexistential_separation/\"><u>near-miss scenarios</u></a>.</p><h2>Technical description</h2><p>The funders have a stock of capital&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"M(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>. This goes up in proportion to real interest at time&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span>&nbsp;,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>, and down with spending on research,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x_R(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>, and spending on influence,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x_I(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>.&nbsp;</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot M(t) = r(t)&nbsp;\\cdot M(t) -&nbsp;x_R(t) -&nbsp;x_I(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.436em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p>The funders have a stock of research which goes up with spending on research and can appreciate or depreciate over time.</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot R(t) =&nbsp;x_R(t)^{\\eta_R} \\cdot R(t)^{\\alpha_R}+\\lambda_R\\cdot R(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p>Where</p><ul><li><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;is the marginal returns to spending on research</li><li><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;is the increase or decrease in efficiency of spending due to the existing stock of research</li><li><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;is the rate of appreciation of the stock of research&nbsp;<br>&nbsp;</li></ul><p>Similarly, funders have a stock of influence&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"I(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;which obeys</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot I(t) =&nbsp;x_I(t)^{\\eta_I} \\cdot I(t)^{\\alpha_I} \\cdot c(t)-\\lambda_I \\cdot I(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p>With constants mutatis mutandis from the research stock case and&nbsp;where&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;describes how the influence gained per unit money changes over time due to competition effects.&nbsp;</p><h3>Fire alarm</h3><p>We allow for the existence of an AGI fire alarm which tells us that AGI is exactly&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T_{FA}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span>&nbsp;years away and that we can spend fraction&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"f\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span></span></span></span></span></span>&nbsp;of our money on research and influence.</p><p>We write&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat R(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat I(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;for the amount of research and influence we have in expectation at AGI take-off if the fire alarm occurred at time&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span>. Within the fire alarm period, we suppose that</p><ul><li>The spending rate is constant</li><li>There is no appreciation or depreciation</li><li>We use&nbsp;terms&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_{I,FA},&nbsp;\\eta_{R,FA},&nbsp;\\alpha_{I,FA},&nbsp;\\alpha_{R, FA}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span>&nbsp;which can be different from their pre-fire alarm values.</li></ul><p>The first and second assumptions allow for analytical expression for&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat R(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat I (t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;as functions of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"R(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;&amp;&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"M(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"I(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;&amp;&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"M(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;respectively.</p><p>We write&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"y_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">y</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;for the constant spending rate on research post-fire alarm. We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"y_R = \\frac{M(t) \\cdot &nbsp;f}{T_{FA}} \\cdot f_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">y</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.275em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 3.218em; top: -1.706em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 3.218em; bottom: -0.936em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.317em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.275em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.869em; vertical-align: -0.662em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.06em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;where&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"f_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.06em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;is the fraction of post fire-alarm spending. The system</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot{\\tilde{R}}(\\tau) =y_{R}^{\\eta_R, FA} \\cdot \\tilde R(\\tau)^{\\alpha_{R, FA}}, \\ &nbsp;\\tilde R(0) = R(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.13em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.153em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">~</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.08em;\">\u03c4</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">y</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.327em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.082em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-texatom MJXc-space2\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.153em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">~</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.08em;\">\u03c4</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.603em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.317em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mtext MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.291em; padding-bottom: 0.372em;\">&nbsp;</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.153em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">~</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p>has a &nbsp;closed form solution and we take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat R(t) =\\tilde R(T_{FA})\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.153em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">~</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p>Similarly for research we take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"y_I = \\frac{M(t) \\cdot &nbsp;f}{T_{FA}} \\cdot (1-f_R)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">y</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.275em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 3.218em; top: -1.706em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 3.218em; bottom: -0.936em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.317em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.275em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.869em; vertical-align: -0.662em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.06em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;and system</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot{\\tilde{I}}(\\tau) =y_{I}^{\\eta_I, FA} \\cdot \\tilde I(\\tau)^{\\alpha_{I, FA}} \\cdot \\tilde c(t), \\ &nbsp;\\tilde I(0) = I(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.09em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.153em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">~</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.08em;\">\u03c4</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">y</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.327em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.082em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-texatom MJXc-space2\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.153em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">~</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.08em;\">\u03c4</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.603em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.317em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-texatom MJXc-space2\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.153em; padding-bottom: 0.06em; padding-left: 0.022em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">~</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mtext MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.291em; padding-bottom: 0.372em;\">&nbsp;</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.153em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">~</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p>Where&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;is the competition factor at the start of the fire alarm period and is chosen by the user to either be a constant or function of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>. Note that&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;is a constant in the differential equation, so the system has an analytical solution of the research system above. Again we take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat I(t) =&nbsp;I(T_{FA})\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p>Note that the user can state that no fire alarm occurs; setting the&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"f=0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;implies&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"y_R=y_I=0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">y</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">y</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;and so&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot{\\tilde{I}}(\\tau) =\\dot{\\tilde{R}}(\\tau) = 0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.09em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.153em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">~</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.08em;\">\u03c4</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.13em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.153em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">~</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.08em;\">\u03c4</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;and so&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat R(t) = R(t),&nbsp;\\hat I(t) = I(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>.&nbsp;</p><h3>Preparedness and success</h3><p>Our preparedness&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"S(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;\">S</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;is given by</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"S(t) =\\left (\\gamma \\cdot \\hat R(t)^{\\rho}+(1-\\gamma)\\cdot \\hat I(t)^\\rho \\right )^{1/\\rho}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;\">S</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-texatom MJXc-space2\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-texatom MJXc-space2\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">)</span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 1.276em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span></span></span></span></span></span></span></span></span></span></p><p>Preparedness is the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Constant_elasticity_of_substitution\"><u>constant elasticity of the substitution production function</u></a> of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat I\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;where the user chooses&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\gamma\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span></span></span></span></span></span>.<br><br>Conditioning on AGI happening at time&nbsp;t, we take the probability of AGI being safe as</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"Q(t) = \\left (1+\\exp \\left(-l \\left (S-S_0 \\right)\\right) \\right)^{-1}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.446em;\">Q</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">exp</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l</span></span><span class=\"mjx-mrow MJXc-space1\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;\">S</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.032em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;\">S</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.71em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span></span></span></span></span></p><p>This is a&nbsp;<a href=\"https://en.wikipedia.org/wiki/Logistic_function\"><u>logistic function</u></a> with constants&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"l>0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"S_0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.032em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;\">S</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span></span></span>&nbsp;determined by the user\u2019s beliefs about the difficulty of making AGI a success.</p><p><br>Our objective is to maximise the probability that AGI is safe. This is&nbsp;</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"U =&nbsp;\\int_{0}^{\\infty} Q(t) \\cdot&nbsp;p(t) \\cdot e^{-d \\cdot t} \\ \\mathrm{d} t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.138em;\"><span class=\"mjx-mo\" style=\"padding-right: 0.138em;\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">\u222b</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.366em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.579em; padding-left: 0.324em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">\u221e</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.446em;\">Q</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.291em; padding-bottom: 0.372em;\">&nbsp;</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span></p><p>Where&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;is the user\u2019s AGI timelines and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span></span></span></span></span></span>&nbsp;is the discount rate.</p><p>The system of differential equations has initial conditions&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"M(0)=M_0,R(0)=R_0, I(0)=I_0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.081em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.064em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span></span></span>. We determine these values based on the user's guess of historic spending.</p><h3>Solving the model</h3><p>We apply standard optimal control theory results.</p><p>We have&nbsp;<a href=\"https://en.wikipedia.org/wiki/Hamiltonian_(control_theory)\"><u>Hamiltonian</u></a></p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"H(t) = Q(t)\\cdot&nbsp;p(t)\\cdot &nbsp;e^{-d\\cdot t} &nbsp;+&nbsp;v_M(t) \\cdot&nbsp;\\dot M(t) +&nbsp;v_R(t) \\cdot \\dot R(t) +&nbsp;v_I(t)\\cdot \\dot I(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.446em;\">Q</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-texatom MJXc-space2\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.436em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-texatom MJXc-space2\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.213em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-texatom MJXc-space2\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.18em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p>Where&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"v_M(t),&nbsp;v_R(t),&nbsp;v_I(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>are the costate variables.</p><p>The optimal spending schedule, if it exists, necessarily follows</p><ol><li><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{\\mathrm{d}H}{\\mathrm{d}x_R}=\\frac{\\mathrm{d}H}{\\mathrm{d}x_I}=0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.416em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 2.002em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 2.002em; bottom: -0.943em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.416em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.665em; vertical-align: -0.667em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.266em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.79em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.79em; bottom: -0.926em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.266em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.653em; vertical-align: -0.655em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span></li><li>The conditions on the costate variables:<ol><li><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot v_M(t) = \\frac{\\mathrm{d}H}{\\mathrm{d}M}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.02em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.278em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.807em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.807em; bottom: -0.704em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.278em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.496em; vertical-align: -0.498em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></li><li><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot v_R(t) = \\frac{\\mathrm{d}H}{\\mathrm{d}R}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.02em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.162em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.644em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.644em; bottom: -0.714em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.162em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.503em; vertical-align: -0.505em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></li><li><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot v_I(t) = \\frac{\\mathrm{d}H}{\\mathrm{d}I}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.02em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.162em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.644em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;\">H</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.644em; bottom: -0.704em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.162em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.496em; vertical-align: -0.498em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></li></ol></li><li><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"M(T)=0,&nbsp;v_R(T)=0,&nbsp;v_I(T)=0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span></li></ol><p>We choose to set&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"M(T) &nbsp;=0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;rather than&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"v_M(T)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">v</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;to force all spending within the finite time horizon.</p><p>We solve this&nbsp;<a href=\"https://en.wikipedia.org/wiki/Boundary_value_problem\"><u>boundary value problem</u></a> using SciPy\u2019s&nbsp;<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_bvp.html\"><i>solve_bvp</i></a> function and apply further optimisation methods to find good spending schedules.</p><h2>Model guide</h2><p>The model is a Python Notebook accessible on Google Colaboratory&nbsp;<a href=\"https://colab.research.google.com/drive/17f0yTYcFSBihZFd8_N7yRjF2XYJDjvBZ?usp=sharing\"><u>here</u></a>.</p><p>Any cells that contain \u201c<strong>User guide</strong>\u201d are for assisting with the running of the notebook.&nbsp;</p><p>Below the initial instruction, you will find the user input parameters.</p><p>In the next section of this document we describe the parameters in detail and our own guesses.</p><h2>Explaining and estimating the model parameters</h2><p>We discuss the parameters in the same order as in the notebook.</p><p><i>Note, the estimates given are from Tristan and not necessarily endorsed by Guillaume.</i></p><p><i>Epistemic status: I\u2019ve spent at least five minutes thinking about each, sometimes no more.</i></p><h3>AI timelines</h3><p>We elicit user timelines using two points on the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Cumulative_distribution_function\"><u>cumulative distribution function</u></a> and fit a&nbsp;<a href=\"https://en.wikipedia.org/wiki/Log-normal_distribution\"><u>log-normal distribution</u></a> to them.&nbsp;</p><p>We note Metaculus\u2019&nbsp;<a href=\"https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/\"><i><u>Date of Artificial General Intelligence&nbsp;</u></i><u>community prediction</u></a>: as of 2022-10-06, lower 25% 2030, median 2040 and upper 75% 2072.</p><p>Note that if you wish to include a fire-alarm into the model, your timelines should be <i>until&nbsp;</i> the fire-alarm goes off.</p><h3>Discount rate</h3><p>The discount rate needs to factor in both non-AGI existential risks as well as catastrophic (but non-existential) risks that preclude our AI work from being useful or any unknown unknowns that have some per year risk.</p><p>We choose&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d=2\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span>, implying an AGI success in 2100 is worth&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\exp(-2\\% \\cdot 78) = 21\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">exp</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mn MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">78</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">21</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span>&nbsp;as much as a win today. As we discuss in the limitations section, the discount rate&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span></span></span></span></span></span>&nbsp;can also account for&nbsp;<i>other</i> people making AGI successful, though this interpretation of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span></span></span></span></span></span>&nbsp;is not unproblematic.&nbsp;</p><p>Of relevance may be:</p><ul><li>The&nbsp;<a href=\"https://www.metaculus.com/questions/2534/world-war-three-before-2050/\"><u>Metaculus forecast on World War Three before 2050</u></a>, current median 21%.&nbsp;</li><li>The&nbsp;<a href=\"https://www.metaculus.com/questions/578/human-extinction-by-2100/\"><u>Metaculus forecast on Human Extinction by 2100</u></a>, current median 3%</li><li>The <a href=\"https://www.metaculus.com/notebooks/8736/a-global-catastrophe-this-century/\">Metaculus notebook from Tamay</a> which synthesis Metaculus forecasts to come to median 18% of global catastrophe this century.&nbsp;</li></ul><p>Our 90% confidence interval for&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span></span></span></span></span></span>&nbsp;is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"0.5\\% < d<5\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span>.</p><h3>Money</h3><p><strong>Starting money</strong></p><p>As of 2022-10-06, Forbes estimates&nbsp;<a href=\"https://www.forbes.com/profile/dustin-moskovitz/?sh=4417b291dd34\"><u>Dustin Moskovitz</u></a> and&nbsp;<a href=\"https://www.forbes.com/profile/sam-bankman-fried/?sh=1d71a92c4449\"><u>Sam Bankman Fried</u></a> have wealth of $8,200m and $17,000m respectively.&nbsp;<a href=\"https://80000hours.org/2021/07/effective-altruism-growing/\"><u>Todd (2021)</u></a> estimates $7,100m from other sources in 2021 giving a total of $32,300m within the effective altruism community.</p><p>How much of this is committed to AI safety interventions? Open Philanthropy&nbsp;<a href=\"https://effectivealtruismdata.com/#op-grants-categories\"><u>has spent $157m on AI-related interventions</u></a>, of approximately $1500m spent so far. Supposing that roughly 15% of all funding is committed to AGI risk interventions gives at least $4,000m.</p><p>Our 90% confidence interval is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"$1,000m < M_0 < $15,000m\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">$</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">000</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.081em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">$</span></span></span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">15</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">000</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span></span></span></span>.</p><p><strong>Real interest rate</strong></p><p>We suppose that we are currently at some interest rate&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r_{\\mathrm{current}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">c</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;which decreases over time (at rate&nbsp;) to&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r_{\\mathrm{eventual}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">v</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">a</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">l</span></span></span></span></span></span></span></span></span></span></span></span></span>.&nbsp;</p><p>&nbsp;Supposing the movement had $10,000m in 2015 and $32,300 in mid-2022, money in the effective altruism community has grown 21% per year.&nbsp;</p><p>We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r_{current}=20 \\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">20</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span>.&nbsp; Our 90% confidence interval is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"5\\% < r_{\\mathrm{current}} < 40\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">c</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">40</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span>.&nbsp;</p><p><a href=\"https://www.investopedia.com/ask/answers/042415/what-average-annual-return-sp-500.asp#:~:text=Adjusted%20for%20inflation%2C%20the%20historical,return%20is%20only%20around%208.5%25.\"><u>Historical S&amp;P returns are around 8.5%</u></a>. There are reasons to think the long-term rate may be higher - such as increase in growth due to AI capabilities - &nbsp;or lower &nbsp;- there is a selection bias in choosing a successful index. We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r_{\\mathrm{eventual}}=8.5\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">v</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">a</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">l</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">8.5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span>. Our 90% confidence interval is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"3 \\% <&nbsp;r_{\\mathrm{current}} <15 \\%.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">c</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">15</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span></p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\delta\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span></span></span></span></span></span>&nbsp;is the rate at which the real interest rate moves from&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r_{\\mathrm{current}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">c</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;to&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r_{\\mathrm{eventual}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">v</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">a</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">l</span></span></span></span></span></span></span></span></span></span></span></span></span>. The effective altruism and AI safety movement has been growing substantially for the last 10 to 15 years. Naively, suppose that we\u2019re in the middle of the growth period. We take&nbsp;= 0.2, which implies that capital will only be growing 1.15 times&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r_{\\mathrm{eventual}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">v</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">a</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">l</span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;ten years from now.</p><p>Our 90% confidence interval is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"0.02 <&nbsp;\\delta <1.5\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.02</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.5</span></span></span></span></span></span></span>&nbsp;.</p><h3>Research and influence</h3><p><strong>Marginal returns to spending</strong></p><p><i><strong>Influence</strong></i></p><p>The constant&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_I\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span>&nbsp;controls the marginal returns to spending on influence. For&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_R<1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>&nbsp;we receive <i>diminishing</i> marginal returns.</p><p>The top&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span></span></span></span></span>&nbsp; fraction of spending per year on influence leads to&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x^{\\eta_I}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span></span></span></span></span>&nbsp;fraction of increase in growth of influence in that year. For example,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_I = 0.15\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.15</span></span></span></span></span></span></span>&nbsp;implies the top 20% of spending leads to roughly 80% of returns i.e. the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Pareto_principle\"><u>Pareto principle</u></a>.&nbsp;</p><p>We note that influence spending can span many orders of magnitude and this suggests reason to think there are high diminishing returns (i.e. low&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_I\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span>). For example, one community builder may cost on the order of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\$10^5\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">$</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">10</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span></span></span></span></span></span></span></span>&nbsp;per year, but investing in AI labs with the purpose of influencing their decisions may cost&nbsp;on the order of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\$10^8\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">$</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">10</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">8</span></span></span></span></span></span></span></span></span>&nbsp;per year.</p><p>We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_I = 0.2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.2</span></span></span></span></span></span></span>, which implies doubling spending on influence lead to&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"2^{0.2} = 1.15\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.2</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.15</span></span></span></span></span></span></span>&nbsp;times more growth of influence Our 90% confidence interval is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"0.1 <&nbsp;\\eta_I<0.5\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.5</span></span></span></span></span></span></span></p><p><i><strong>Research</strong></i></p><p>The constant&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;acts in the same way for research as&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_I\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span>&nbsp;does for influence.<br>We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_R=0.3\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3</span></span></span></span></span></span></span>, which implies a doubling of research spending leads to<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"2^{0.3} = 1.23\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.23</span></span></span></span></span></span></span>&nbsp;times increase in research growth and that 20% of the spending in research accounts for&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(20\\%)^{0.3 }= 60\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">20</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">60</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span>&nbsp;of the increase in research growth.</p><p>Potential sources for estimating&nbsp;R include using the distribution of karma on the Alignment Forum, citations in journals or estimates of researchers\u2019 outputs.</p><p>Our 90% confidence interval is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"0.1 < \\eta_R < 0.6\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.6</span></span></span></span></span></span></span>.</p><p><strong>Change in price of the stocks when you have more</strong></p><p><i><strong>Influence</strong></i></p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_I\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span>&nbsp;controls how the price of influence changes as the amount of influence we have changes.&nbsp;</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_I>0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;implies that influence becomes cheaper as we get more influence. Factors that push in this direction include:</p><ul><li>The existence of &nbsp;network effects related to being trusted and having a good reputation, For example,<ul><li>It may become easier to convince other people to trust us</li><li>We may be given access to exclusive opportunities.&nbsp;</li></ul></li><li><a href=\"https://www.lesswrong.com/posts/vavnqwYbc8jMu3dTY/ai-coordination-needs-clear-wins\"><u>The \u2018clear wins\u2019 model of political capital</u></a></li></ul><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_I<0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;implies that influence becomes more expensive as we get more influence. Factors that point in this direction include:</p><ul><li>We can run out of opportunities to gain influence or only difficult opportunities remain.</li><li>We could be seen as suspicious for amassing power, and trust in us decreases.</li></ul><p>For&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_I = 0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;the price is constant.</p><p>On balance, we think the former reasons outweigh the latter, and so take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_I=0.3\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3</span></span></span></span></span></span></span>. This implies a doubling of influence leads to one unit of spending on influence leading to&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"2^{0.3} = 1.23\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.23</span></span></span></span></span></span></span>&nbsp;times more growth in influence compared to one unit of spending without this doubling. Our 90% confidence interval is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"-0.75 <&nbsp;\\alpha_I<1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.75</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>.</p><p><i><strong>Research</strong></i></p><p>The constant&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp; acts in the same way for research as&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_I\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span>&nbsp;does for influence.</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;controls how the price of influence changes as the amount of influence we have changes.&nbsp;</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R>0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;implies that research becomes cheaper as we get more research. Factors that push in this direction include:</p><ul><li>Research becoming more parallelizable. For example, sub-questions are found that can be worked on with less context or more standard backgrounds.</li><li>Attracting greater talent to the field once you have developed the field.</li></ul><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R<0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;implies that research becomes more expensive as we get more research. Factors that push in this direction include:</p><ul><li>Research becoming more serial. That is, the field is increasingly bottlenecked by progress in a few key areas.</li><li>The costs of getting up to speed with research increase as we accumulate new research. For example, new researchers need to learn increasingly more background material before being able to contribute.</li></ul><p>We are uncertain about the net effect of the above contributions, and so take<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R=0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>. Our 90% confidence interval is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"-1.5 <&nbsp;\\alpha_R<1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.5</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>.</p><p><strong>Depreciation of stocks</strong></p><p><i><strong>Influence</strong></i></p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_I\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span>&nbsp;controls the rate of appreciation, for&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_I>0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>, or depreciation, for&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_I<0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>, of our stock of influence. It seems very likely that&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_I<0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;since</p><ul><li>AGI labs we have influence over can decrease in relative importance.&nbsp;</li><li>The number of AGI labs and people working on AGI increases, and so our relative influence decreases</li></ul><p>We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_I=-0.25\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.25</span></span></span></span></span></span></span>, which implies a half-life of around&nbsp;&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{\\log{50\\%}}{-0.25} = 2.8\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.459em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 3.478em; top: -1.662em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">log</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">50</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 3.478em; bottom: -0.747em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.25</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.459em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.704em; vertical-align: -0.528em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2.8</span></span></span></span></span></span></span>&nbsp;years. Our 90% confidence interval is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"-3<&nbsp;\\lambda_I<-0.15.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.15.</span></span></span></span></span></span></span></p><p><i><strong>Research</strong></i></p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;controls the rate of appreciation, for&nbsp;\\lambda_R&gt;0, or depreciation, for&nbsp;R&lt;0, of our stock of influence.</p><p>We expect research to depreciate over time. Research can depreciate by</p><ul><li>Becoming less relevant over time</li><li>Be lost, forgotten or otherwise inaccessible</li></ul><p>One intuition pump is to ask&nbsp;<i>what fraction of research on current large language models will be useful if AGI does not come until 2050</i>? We guess on the order of 1% to 30%, implying - if all our research was on large language models - a value of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_R\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;between&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{\\log 1\\%}{38} = -0.12\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.106em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 2.978em; top: -1.662em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">log</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mn MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 2.978em; bottom: -0.687em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">38</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.106em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.662em; vertical-align: -0.486em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.12</span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{\\log 30\\%}{38} = -0.12\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.459em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 3.478em; top: -1.662em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">log</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mn MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">30</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 3.478em; bottom: -0.687em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">38</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.459em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.662em; vertical-align: -0.486em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.12</span></span></span></span></span></span></span>. Note that for<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_R>0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>, such research can be instrumentally useful for later years due to its ability to make future work cheaper &nbsp;by, &nbsp;for example, &nbsp;attracting new talent.</p><p>We take<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_R=-0.03\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.03</span></span></span></span></span></span></span>. Our 90% confidence interval is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"-0.2<&nbsp;\\lambda_R<-0.01\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.2</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.01</span></span></span></span></span></span></span>.</p><h3>Competition effects</h3><p>We allow for influence to become more expensive over time. The primary mechanism we can see is due to (a) competition with other groups that want to influence AI developers, and (b) competition within the field of AI capabilities, such that there are more organisations that could potentially develop AGI.</p><p>We suppose the <i>influence per unit spending </i>decreases over time following some S-shape curve, and ask for three points on this curve.</p><p>The first data point is the first year in which money was spent on influence. Since one can consider community building or spreading AI risk ideas (particularly among AI developers) as a form of &nbsp;influence, the earliest year of spending is unclear. &nbsp;We take 2015 (<a href=\"https://en.wikipedia.org/wiki/Machine_Intelligence_Research_Institute#History\">the first year Open Philanthopy made grants in this area</a>). The relative cost of influence is set to 1 in this year.</p><p>We then require to further years, as well as influence per unit spending relative to the the first year of spending.</p><p>Our best guess is &nbsp;(2017, 0.9) - that is, in 2017 one received 90% as much influence per unit spending as one would have done in 2015- &nbsp;and (2022, 0.6).&nbsp;</p><p>The final input is the minimum influence per unit spending that will be reached be take this to be 0.02. That is, influence will eventually be 50x more expensive per unit that it was in 2015. Our 90% confidence interval is (0.001, 0.1).</p><h3>Historical spending on research and influence</h3><p>The model uses this data to calculate the quantities of research and influence we have now. Rough estimates are sufficient.</p><p>The Singularity Institute (now MIRI) was founded in 2000 and switched to work on AI safety in 2005. We take 2005 as the first year of spending on research.</p><p>Open Philanthropy&nbsp;<a href=\"https://www.openphilanthropy.org/focus/potential-risks-advanced-ai/\"><u>has donated $243.5m</u></a> to risks from AI since its first grant in the area in August 2015. We very&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1XpWNGyho_kkSkVlMsqnddrhnEYW7MRQBmLX0wITYxGQ/edit?usp=sharing\"><u>roughly categorised each grant by research : influence fraction,</u></a> and estimate that $132m has been spent on research and $111m on influence. We suppose that Open Philanthropy has made up two-thirds of the overall spending, giving totals of $198m and $167m.</p><p>We guess that the research spending, which started in 2005, has been growing at 25% per year and influence spending has been growing 40% per year since starting in 2015.</p><h3>Fire alarm</h3><p>By default, in the results we show, we assume&nbsp;<i>no&nbsp;</i>fire alarm in the model. This is achievable by setting<i> &nbsp;</i>the expected fraction of money spendable to 0. When considering the existence of a fire alarm, we take the following values.</p><p>For the fire alarm duration we ask <i>Supposing that the leading AI lab has reached an AGI system that they are not deploying out of safety concerns, how far behind is a less safety-conscious lab?&nbsp;</i> We guess this period to be half a year.</p><p>Our 90% confidence interval for this period, if it exists, is (one month, two years).</p><p>One may think that&nbsp;expected fraction of money spendable during the fire alarm is less than 1 for reasons such as&nbsp;</p><ul><li>Not being certain that the AGI fire alarm has gone off [though we don\u2019t model other false positives, and are only supposing that we may worry that this actual fire alarm is a false positive]</li><li>Limited liquidity of the capital</li><li>Bottlenecked by transaction speeds</li></ul><p>We take 0.1 as the expected fraction of money spendable with 90% confidence interval &nbsp;(0.01, 0.5).</p><p><strong>Returns to spending during the fire alarm</strong></p><p>During the fire alarm period, we enter a phase with no appreciation or depreciation of research or influence and a separate marginal returns to spending &nbsp;-&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_{R,FA}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_{I,FA}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span>&nbsp;- can apply.&nbsp;</p><p>Some reasons to think&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_{FA} < \\eta\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span></span>&nbsp;(worse returns during the fire alarm period)</p><ul><li>There is general panic or uncertainty around what to do and worse coordination leading to wasted effort</li><li>The most useful technical work can only be done within highly secure environments to avoid leaks to the competitor labs</li><li>The labs that are reaching AGI become increasingly averse to being influenced from the outside, since there may be more bad actors targeting them.</li><li>People may be less incentivised by money if they believe AGI is near.</li></ul><p>Some reasons to think the&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_{FA} > \\eta\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span></span>&nbsp;(better returns during the fire alarm period)</p><ul><li>There are unique opportunities that arise during this period</li><li>There is clarity over what AGI will look like.</li><li>We can actually execute a plan that has been refined in the pre-fire-alarm period</li><li>We can take riskier actions that would damage our reputation during the pre-fire alarm period.</li><li>Some people will be more motivated to work harder</li><li>Some people will be more open to the idea of AI safety, given that capabilities are at a high level<br>&nbsp;</li></ul><p>We expect that the returns to research spending will be very low, and take<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_{R,FA} = 0.05\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.05</span></span></span></span></span></span></span>, implying that the amount of research we can do in the post-fire-alarm period is not very dependent on the money we have.</p><p>We expect that returns to influence spending will be less than in the period before, lower. We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_{I,FA} = 0.1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.1</span></span></span></span></span></span></span>.</p><p><strong>Change in price of the stocks when you have more</strong></p><p>In the fire alarm phase, the cost per unit of research and influence can also change depending on the amount we already have.</p><p>We expect&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_{I, FA} > \\alpha_I\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_{R,FA} >0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>. That is, during the fire alarm period it is even cheaper to get influence once you already have some than before this phase and that this effect is greater during the fire alarm period (the first inequality). In the case there is panic, it seems people will be looking for trustworthy organisations to defer to and execute a plan.</p><p>We expect&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_{R,FA}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span>&nbsp;That is, during the fire alarm period the amount of existing research decreases the cost of new research.</p><p>During the fire alarm period, it seems likely that only a few highly skilled researchers - perhaps within the AI lab - will have access to the information and tools necessary to conduct further useful research. The research at this point is likely highly serial: the researchers trying to focus on the biggest problems. Existing research may allow these few researchers to build on existing work effectively.</p><p>We take both&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_{I,FA}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\alpha_{I,FA}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03b1</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span>&nbsp;to be&nbsp;0.3, implying that a doubling of research&nbsp;<i>before&nbsp;</i>the fire-alarm period increases the stock output&nbsp;<i>during</i> the fire-alarm period by&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"2^{0.3}=1.23\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1.23</span></span></span></span></span></span></span>&nbsp;times.</p><p><strong>Competition during the fire alarm period</strong></p><h3><br>Preparedness and probability of success</h3><p><strong>Preparedness</strong><br><br>Preparedness at time&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span>&nbsp;is&nbsp;<a href=\"https://en.wikipedia.org/wiki/Constant_elasticity_of_substitution\"><u>a function</u></a> of the fire-alarm adjusted research and influence that takes two parameters, the share parameter &nbsp;that controls the relative importance of research and influence and parameter&nbsp;, that controls the substitutability of research and influence.</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\gamma\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span></span></span></span></span>&nbsp;is the <i>share parameter</i>. Increasing&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\gamma\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span></span></span></span></span>&nbsp;increases the ratio {increase to preparedness when increasing research by 1 unit} to {increase to preparedness when increasing influence by 1 unit}.</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\gamma\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span></span></span></span></span>&nbsp;cannot be derived from first principles due to our choice of units. Instead, we recommend running the cell and using the available statistics and graphs to inform your guesses. We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\gamma=0.6\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.6</span></span></span></span></span></span></span></p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span></span></span></span></span></span>&nbsp;controls the subsitutability of research and influence. If you think it is possible to make AGI go well with lots of research and&nbsp;<i>zero</i> influence or zero research and lots of influence, then consider setting&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho=1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>. Otherwise, you should set&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho<1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>.</p><p>Decreasing&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span></span></span></span></span></span>&nbsp;decreases the subsitutability of research and influence. In the limit as&nbsp;&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho \\to -\\infty\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">\u221e</span></span></span></span></span></span></span>, our preparedness can be entirely bottlenecked by the stock we have the least (weighted by&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\gamma\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span></span></span></span></span>).</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho= 0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;gives the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Cobb%E2%80%93Douglas_production_function\"><u>Cobb-Douglas production function</u></a>, though to avoid a case-by-case situation in the programming, you cannot set&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho=0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;and instead can choose value close to 0.</p><p>Again, we recommend picking values and running the cell to see the graph. We choose&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho=0.3.\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3.</span></span></span></span></span></span></span>&nbsp;We think that the problem is mainly a technical problem, but in practise cannot be solved without influencing AI developers.</p><p><strong>Probability of success</strong></p><p>The probability of success at time&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span>&nbsp;conditioned on AGI\u2019s arrival at time&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span>&nbsp;is a function of our preparedness at that time. The function is an S-shaped <a href=\"https://en.wikipedia.org/wiki/Logistic_function\">logistic&nbsp;</a><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\"><span class=\"mjx-mrow\" aria-hidden=\"true\"></span></span></span></span></span><a href=\"https://en.wikipedia.org/wiki/Logistic_function\">function</a> and it is determined by two inputs.</p><p>The first input is the probability of success if AGI arrived this year. That is, given our existing stocks of research and influence - this input doesn't consider any fire alarm spending. &nbsp;The second input determines the steepness of the S-shaped curve.&nbsp;</p><p>We take (10%, 0.15).</p><p><i>A note on the probability of success</i></p><p>Suppose you think we are in one the following three worlds</p><ul><li>World A: AGI will go certainly well, regardless of what we do</li><li>World B: AGI might go well, and we can influence the probability it does</li><li>World C: AGI will certainly not go well, regardless of what we do</li></ul><p>Then, in the input you should imagine you should give your inputs as they are in your world B model. We keep the probability of success curve between 0 and 1, but one could linear transform it to be greater than the probability of success in the A world and less than the probability of success in the C world. Since the objective function is linear in the probability of success, such a transformation has no effect on the optimal spending schedule.&nbsp;</p><h2>Alternate model</h2><p>In an alternate model, we suppose the funder has a stock of&nbsp;<i>things that grow&nbsp;</i><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"K(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;which includes things such as skills, people, some types of knowledge and trust. They can choose to spend this stock&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"K(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;at some rate&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;to produce a stock of&nbsp;<i>things that depreciate</i>&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"C(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;that are immediately helpful in increasing the probability of success. This could comprise things such as the implementation of safety ideas on current systems or the product of asking for favours of AI developers or policymakers.</p><p>We say that spending capacity to create&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"C(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;is <i>crunching &nbsp;</i>and the periods with high&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>are<i> crunch time.</i></p><p>The probability we succeed at time&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span>&nbsp;is a function of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat C(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.268em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;which is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"C(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;plus any last-minute spending that occurs with a fire alarm. Specifically, it is another&nbsp;<a href=\"https://en.wikipedia.org/wiki/Logistic_function\"><u>S-shaped curve</u></a>.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/nplko5wpjleo8buebw2p\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/w4l4q4xdbr4qvcdhyhfb 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/sftocmomdag1iuyiw8qi 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/tkqjgeeihfxbvkosl6tq 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/xzijzhbam2i8bsagvwed 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/gojgqwongdlukkf7vkmz 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/mbkilbfrsnj7qfiogxoq 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/cgtqboycsby3bz86zkdx 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/j5ruuhygije3aocu9rby 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/tsbe3dybvui1ifw1gm7l 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/gnkpjqzwrgkatfrcxrjy 852w\"><figcaption>A diagram of the alternate model</figcaption></figure><h3><br>Formalisation</h3><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Time evolution of things that grow</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot K(t)=r(t)\\cdot K(t) - x(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.301em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Time evolution of things that depreciate</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\dot C(t) = x(t)^{\\eta} \\cdot c(t)-\\lambda_C\\cdot C(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.17em; padding-bottom: 0.06em; padding-left: 0.268em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">\u02d9</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p><br>&nbsp;</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Post-fire alarm total of things that depreciate</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat C(t) = C(t) +\\left(\\frac{K(t) \\cdot&nbsp;f}{T_{FA}}\\right)\\cdot &nbsp;T_{FA}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.268em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mrow MJXc-space2\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">(</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.161em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 3.056em; top: -1.706em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 3.056em; bottom: -0.936em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.317em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.161em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.869em; vertical-align: -0.662em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">)</span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>The probability of success given AGI at&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span></p><p><br>&nbsp;</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"Q(t) = (1+\\exp \\left(-\\kappa \\cdot \\left ( \\hat C(t) -&nbsp;\\sigma \\right) \\right)^{-1}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.446em;\">Q</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">exp</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u03ba</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mrow MJXc-space2\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">(</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.268em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.001em;\">\u03c3</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">)</span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">)</span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 1.276em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span></span></span></span></span></p><p><br>&nbsp;</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Objective function</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"U =&nbsp;\\int_{0}^{\\infty} Q(t) \\cdot&nbsp;p(t) \\cdot e^{-d\\cdot t} \\ \\mathrm{d}t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.138em;\"><span class=\"mjx-mo\" style=\"padding-right: 0.138em;\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">\u222b</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.366em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.579em; padding-left: 0.324em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">\u221e</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.446em;\">Q</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.291em; padding-bottom: 0.372em;\">&nbsp;</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">d</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span></td></tr></tbody></table></figure><p>Recall that&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"f\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span></span></span></span></span></span>&nbsp;is the expected fraction of money spendable post-fire alarm and &nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T_{FA}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span>&nbsp;is the expected duration of the fire alarm. The equation for&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\hat C(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-munderover\"><span class=\"mjx-stack\"><span class=\"mjx-over\" style=\"height: 0.213em; padding-bottom: 0.06em; padding-left: 0.268em;\"><span class=\"mjx-mo\" style=\"vertical-align: top;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">^</span></span></span><span class=\"mjx-op\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;is thus simply the result of spending at rate&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{K(t)\\cdot f}{T_{FA}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.161em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 3.056em; top: -1.706em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 3.056em; bottom: -0.936em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.317em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.161em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.869em; vertical-align: -0.662em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span>&nbsp;for duration&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T_{FA}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span></span></span>.</p><h3>Estimating parameters</h3><p>The alternate model shares the following parameters and machinery with the research-influence model</p><ul><li>AGI timelines,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></li><li>Discount rate,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span></span></span></span></span></span></li><li>Growth rate&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></li><li>Competition factor&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></li><li>The duration of the fire alarm and expected fraction of money spendable</li></ul><p>The new inputs include</p><ul><li>Diminishing returns to spending on direct work&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span></span></li><li>Depreciation of the direct work&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_C\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span></span></span></span></span></span></span></span></li><li>Probability of success as a function of our direct work</li></ul><p><strong>Growth rate</strong></p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;now refers to the growth of the community's capacity, &nbsp;of which money is one component. Things that grow include our prioritisation knowledge and general understanding of AI risk increases each year, skills of people in the movement and connections between people.&nbsp;</p><p>We expect the growth in capacity to decrease over time since some of our capacity is money and the same reasons will apply as in the former model. We suppose&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r_{\\mathrm{current}}=40\\%, r_{\\mathrm{eventual}}=20\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">c</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">r</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">40</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">v</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">e</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.372em;\">t</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">u</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">a</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">l</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">20</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span>,&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\delta=0.2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.2</span></span></span></span></span></span></span>.<br>&nbsp;</p><p><strong>Competition factor</strong></p><p>The factor&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>, which in the former model controlled how influence becomes more expensive over time, controls how the cost of doing direct work - producing&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"C(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;- becomes more expensive over time. . Only some spending to produce&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"C(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;is in competitive domains (such as influencing AI &nbsp;developers) while some is non-competitive, such as implementing safety features in state-of-the-art systems.&nbsp;</p><p>We suppose that&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;has a minimum 0.5 and otherwise has the same factors as in the former research-influence model.</p><p><strong>Diminishing returns to spending</strong></p><p>This controls the degree of diminishing returns to \u2018crunching\u2019. For reasons similar to those given for&nbsp;R and&nbsp;I in the main model, we take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"=\\eta=0.3\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3</span></span></span></span></span></span></span>. Our 90% confidence interval is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"0.1<\\eta<0.6\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.6</span></span></span></span></span></span></span>.</p><p><strong>Depreciation of the direct work</strong></p><p>This controls how long our crunch time activities are useful for i.e. the speed of depreciation. We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\lambda_C=-0.5\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">\u03bb</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.23em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.5</span></span></span></span></span></span></span>&nbsp;which implies that after one &nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\exp(-1)=37\\%\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.519em;\">exp</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">37</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">%</span></span></span></span></span></span></span>&nbsp; of the direct work is still useful.</p><p><strong>Probability of success</strong></p><p>To derive the constants used in the S-shaped curve, we ask for the probability of success after some hypothetical where we've spent some fraction of our capacity for one year.</p><p>Our guess is that after spending half of our resources this year, we\u2019d have a 25% chance of alignment success&nbsp;<i>if&nbsp;</i>AGI arrived this year. Note that this input does not account for any post-fire-alarm spending.</p><h3>Results</h3><p>Unsurprisingly we see that we should spend our capacity of things-that-grow most around the time we expect AGI to appear. For the 2040 and 2050 timelines, this implies spending very little on things that depreciate, up to around 3% a year. For 2030 timelines, we should be spending between 5 and 10% of our capacity each year on \u2018crunching\u2019 for the arrival of AGI. Further, for all results, we begin maximum crunching <i>after &nbsp;the </i>modal AGI arrival date, which is understandable while the rate of growth of the movement is greater than the rate of decrease in probability of AGI (times the discount factor).&nbsp;</p><p>This result is relatively sensitive to the probability we think AGI will appear in the next few years. We fit a log-normal distribution to the AGI timeline with&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p(0) = 0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>&nbsp;which leads to&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;being small for the next few years. Considering a probability distribution that gave some weight to AGI in the next few years would inevitably imply a higher initial spending rate, &nbsp;though likely &nbsp;a similar overall spending schedule in sufficiently many years time.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>&nbsp;</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\" colspan=\"3\"><p><i>Median AGI arrival</i></p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><i>Difficulty of AGI success</i></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">2030</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">2040</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">2050</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Easy</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/i3coqeli3djrru0ozbrn\"></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ucdmlwlmrecuskizwiiq\"></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ijgr7hwxjdhdkvoqfedy\"></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Medium</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/rgslce09ooi0bz3ds5kg\"></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/bvx2mf8z1u89jeg0eurz\"></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/x8y7bqtbkidxdj33sbmn\"></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Hard</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/fosa37vvc0llcn5vcl7j\"></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ssuum7bvizpc2yjkqyng\"></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/s244qm8fdtmeeklxiacm\"></td></tr></tbody></table></figure><h3>Limitations</h3><p>Many of the limitations we describe apply to both models.</p><p>For example, there is no exogenous increase in&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"C(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;which we may expect if other actors' work on AI risk at some time in the future. One could, for example, adjust&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;such that spending on direct work receives more units of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"C(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;per unit spending in the future due to others' also working on the problem.&nbsp;</p><p>Like the first model, our work and AI capabilities are independent. One could, again, use&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;to model direct work becoming cheaper as time goes on and new AI capabilities are developed.</p><h2>&nbsp;Full results from the nine cases</h2><figure class=\"table\"><table><tbody><tr><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/pm9mqeaxzgfwms8uh0wo\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ip0jc88yixnwje4ptgzg 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/dfl499vsmtp1epkhtxno 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ra2fse4tj2p4cmubemas 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/vifkre9yeowo2ymtenzt 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/qsvdrnwhixlcvmnnfaiy 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/nhyj8r2kzc4fld906ww0 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/cvlhzizuyl9pdg2twtjq 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ocsznezgg5vtvpto7po1 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/fh5jjsydiiq1qecn5nky 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/h9oironyyd8kdj1mrtrm 1790w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ahdejgejxhbja37t4qt5\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/yev9l8zgr9elccnvx7la 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ygwdzkkbjwhyjmxfaktw 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/kzjoizlmsflwojywteau 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/u2nklnvtdtzicul1cell 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/lj0ses2xichrbb8dmteh 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/hypfddy3yf4ife9pctii 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/uf5szswy0ssu5aez1f0n 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/qsrdbryliz5dh6hfy1pp 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/zqw5uzglr5euywbneqke 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/bvwcmcz4bmktscmb6frc 1789w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/yzokpx0yfrcdrnbvzg1h\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/kdcaadn0pkgdd1a0q2xi 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/yil8ie2dgfr641i4x2nx 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/mgse31fvxrbmwn57re68 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/refpydpd1zfsvjongo2h 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ntvkfpdtgrcijmk27fbo 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/tuoxoxizxwnxh0xaxlhl 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/e28ys0cak0p3eyza2zam 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/mjsisd9vmwistr9aeatr 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/jtryljzzovrucdpsekqc 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ydsmukyr6jxrrdpshkkt 1790w\"></figure></td></tr><tr><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ifaslfskckxocbg64cy2\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/eksczgknmsw1nk6l4cf8 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/jllcnbzq7w0nimqmouhg 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/tycmz6b8xyf411rzawwk 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/hivvruncvnaxxjfxyu4b 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/rcax8wfscrjzzodquhgw 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/nx7mujfjfpfgy8exdi3c 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/r5q7ruuhnm4gevkj4kcc 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/xswfza5isgvaio9i5uqq 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/tvgognz2dlegbauufn8x 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/lo2fzqzmtqu4p01tafum 1790w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ptzezzqhdf2l275b8rhn\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/fqxn6vigkdmgmswzytmy 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/x1ephvwvjyboihm9qrdi 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/dqtvwyrqjw635vxvhovs 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/nzlvme8mr7julvrupk7i 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/acz0bkijkgguardtqxfi 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/qoew2ugzeo9toa27tuai 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/raxkbqvvkx8eks7rm6k4 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/kb6wkknv2nh2eclji5hg 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/vh5cbopo48z58nomcnza 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/sytcdeuahuvztslbbvxi 1790w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/pkcrz6ivuwf3dnqxkiqu\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/esey3achmvcbzunimnd5 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/klyegjohspcnxtdga4aw 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/u1017nvnmffr0sbfhc8i 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/t4krjcitghgalvonfk6i 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/laieylpguhzftwjxzil6 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/mw8v07iduftcd3gv7j3q 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/gubl52mtdjuzbk0dyxix 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/c7czxxwjibycpwdl7wz8 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/otmg5ot5wnogtu3w6cy0 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/old7wfozj4ilzpnvzquu 1790w\"></figure></td></tr><tr><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/oieerwl08gmemjbyxiq9\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/fdciqtnxrmpqz1ddbwek 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/hzqol4k3xkfhov9wehpz 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/rv0thecjcovdemvkhmne 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/zwqq82ww3rfq19xti2hr 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/hsohs6szwtbvgbrwldzu 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/jpbiktrumk0f3b7tp4uc 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/jiik1xz6frsnpxmzvahc 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/iu9prbfdi0futbiwl5q1 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/h7rnw52gxq8bnoqlyvm2 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/xf5yuf8jcgrbp2fal4i9 1789w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ebu4882iybykbd3jpcpl\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/lyg5nldvwgxjhxq3iloe 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/dci374razdf5ametbjff 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/rywxfj3v14hu4vz4krdg 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/r8hk4wkkoatkt7flcviz 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/rf6tzzwbw2ocin0eb6nl 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/vufir4qvte74oyiedxwc 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/cjhrvdxu37uibkefk0zi 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/nutm07qatqqhq3hnxtkg 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/glw9xscqxifnuxiqwnox 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/kwni1dfvjaueyckua19d 1790w\"></figure></td><td><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/wl9tqtbw9oxr9aggeafq\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/plqqbyh2iom0thrm0rcm 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/lwk6z7ikxwy3tcvhe5q9 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/lybnxctwq19s8sbiui9q 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/r9akryq7iwbghwsuwa0g 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/wshzg8vggpweku2wxfa3 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/vdjkioncinbf52ufhdch 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/uxo7xekiz1deddblwgoj 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/cr7w6loom961sjp09lgc 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/fg0bp3jvwxpls4h6mjbr 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/uopnahzhochzm2gsc9ug 1789w\"></figure></td></tr></tbody></table></figure><h1>Robust spending schedules by Monte Carlo simulation</h1><p><i>Added 2022-11-29, see discussion </i><a href=\"https://forum.effectivealtruism.org/posts/mLqKcYahP5nbjK9ir/tristan-cook-s-shortform?commentId=So4dTJWomiE975T7m\"><i>here</i></a></p><p>Here I consider the most&nbsp;<strong>robust</strong> spending policies and supposes uncertainty over nearly all parameters in the main model<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsuy4dht2xu\"><sup><a href=\"#fnsuy4dht2xu\">[41]</a></sup></span>&nbsp;, rather than point-estimates. I &nbsp;find that <strong>the community\u2019s current spending rate on AI risk interventions is too low</strong>.&nbsp;</p><p>My distributions over the the model parameters imply that</p><ul><li>Of all&nbsp;<i>fixed&nbsp;</i>spending schedules (i.e. to spend X% of your capital per year<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyg0augeodl\"><sup><a href=\"#fnyg0augeodl\">[42]</a></sup></span>), the best strategy is to spend 4-6% per year.</li><li>Of all&nbsp;<i>simple</i><strong>&nbsp;</strong>spending schedules that consider two regimes: now until 2030, 2030 onwards, the best strategy is&nbsp; to spend ~8% per year until 2030, and ~6% afterwards.</li></ul><p>I recommend entering your own distributions for the parameters in the Python notebook&nbsp;<a href=\"https://colab.research.google.com/drive/1JJU_P9A-3XXvyUo0DyoR6q-PDmr_2fPf?usp=sharing\"><u>here</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6ynt2nhmben\"><sup><a href=\"#fn6ynt2nhmben\">[43]</a></sup></span>. Further, these preliminary results use few samples: more reliable results would be obtained with more samples (and more computing time).</p><p>I allow for post-fire-alarm spending (i.e., we are certain AGI is soon and so can spend some fraction of our capital). Without this feature, the optimal schedules would likely recommend a greater spending rate.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/iy8oaxhji6mh7ajuudc7\"><figcaption>Fixed spending rate. See <a href=\"https://docs.google.com/document/d/1gNMy900q2sP0tFasKi2jnbIlwQGcSOxPKg_obNXWVAk/edit?usp=sharing\">here</a> for the distributions of utility for each spending rate.</figcaption></figure><p>&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/tsuzs6jfqiufd4xxsogn\"><figcaption>Simple &nbsp;- two regime - &nbsp;spending rate</figcaption></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/ahvjuzkqwslyeououisa\"><figcaption>The results from a simple optimiser<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefk8mofgrl98i\"><sup><a href=\"#fnk8mofgrl98i\">[44]</a></sup></span>, when allowing for four spending regimes: 2022-2027, 2027-2032, 2032-2037 and 2037 onwards. This result should not be taken too seriously: more samples should be used, the optimiser runs for a greater number of steps and more intervals used. As with other results, this is contingent on the distributions of parameters.</figcaption></figure><h3>Some notes</h3><ul><li>The system of equations - describing how a funder\u2019s spending on AI risk interventions change the probability of AGI going well - are unchanged from the main model.</li><li>This version of the model randomly generates the real interest, based on user inputs. So, for example, one\u2019s capital can go down.</li></ul><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/e97jc0sgs5lx1vihs8ub\"><figcaption>n example real interest function&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>, cherry picked to show how our capital can go down significantly. See&nbsp;<a href=\"https://docs.google.com/document/d/12y-ZHKWsdO5C3m0z-cXHs6S-pqPBUCpCprqowqp49_Y/edit\"><u>here</u></a> for 100 unbiased samples of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>.</figcaption></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/dxpw8gytzxs5w8p1vpo0\"><figcaption>Example probability-of-success functions. The filled circle indicates the current preparedness and probability of success.</figcaption></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Ne8ZS6iJJp7EpzztP/zsk7wo4ctyr07misvq7y\"><figcaption>Example competition functions. They all pass through (2022, 1) since the competition function is the&nbsp;<i>relative&nbsp;</i>cost of one unit of influence compared to the current cost.&nbsp;</figcaption></figure><p>This short extension started due to a conversation with David Field and comment from Vasco Grilo; I\u2019m grateful to both for the suggestion.</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6n35i76hdvb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6n35i76hdvb\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://80000hours.org/2021/07/effective-altruism-growing/\">Todd (2021) </a>claims 1% donated per year for the whole effective altruism community.</p><p>The Open Philanthropy project spent<a href=\"https://docs.google.com/spreadsheets/d/1XpWNGyho_kkSkVlMsqnddrhnEYW7MRQBmLX0wITYxGQ/edit?usp=sharing\"><u> $80m in 2021 on AI risk interventions</u></a>. In 2021 they&nbsp;<a href=\"https://www.forbes.com/profile/dustin-moskovitz/?sh=9ba79cf1dd34\"><u>had approximately $17.8b committed</u></a>. Supposing that <i>at least</i> one sixth of their budget is committed to AI risk interventions, this gives a spending rate of <i>at most</i> 2.6%.&nbsp;</p><p>The FTX Future Fund has granted <a href=\"https://docs.google.com/spreadsheets/d/1CI-8rUgjU6s63tUnqCk94KlbojEkyheFiHXliT6dE8M/edit#gid=0\">around $31m on AI risk interventions</a> since starting over a year ago. Supposing at least one tenth of their budget is committed to AI risk interventions, this gives a spending rate of at most $31m/(<a href=\"https://www.forbes.com/profile/sam-bankman-fried/?sh=2eb301b74449\">$16,600m </a>/10) = 1.9% per year.</p><p>For the AI s-risk community, the figure is around 3%.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0k98lv637wof\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0k98lv637wof\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This is true when supposing a 4% constant spending rate, which is an overestimate of current spending but maybe underestimating future spending.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjfdtziejv3l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjfdtziejv3l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The second model requires us to split activities into&nbsp;<i>capacity growing&nbsp;</i>and&nbsp;<i>capacity shrinking that increase our probability of success </i>whereas the first model talks concretely about the spending rate of money.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb2vjnl9n18\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb2vjnl9n18\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The values we choose are discussed <a href=\"https://forum.effectivealtruism.org/posts/Ne8ZS6iJJp7EpzztP/the-optimal-timing-of-spending-on-agi-safety-work-why-we#Explaining_and_estimating_the_model_parameters\">here</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqwrm4pzrqbq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqwrm4pzrqbq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;25% AGI by 2027, 50% 2030</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvgdt0udb0u\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvgdt0udb0u\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;50% AGI by AGI by 2040, 75% by 2060</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb83eattgl4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb83eattgl4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;50% AGI by 2050, 75% by 2075</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbzpjm634xxf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbzpjm634xxf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The easy case is operationalised by the inputs in the model:&nbsp; probability of success if AGI this year = 25%, and the steepness of the S-shaped success curve&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"l=0.2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.2</span></span></span></span></span></span></span>&nbsp;.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngjjouwp7w1r\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgjjouwp7w1r\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The \u201cbreak even line\u201d is the maximum rate at which the funder can spend and still have their money increase.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0tdybtyk93v\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0tdybtyk93v\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Probability of success if AGI this year = 10%, and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"l=0.1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.1</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhwjj0ec3rm4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhwjj0ec3rm4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Probability of success if AGI this year = 4%, and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"l=0.05\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.05</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnza4zqb2q3k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefza4zqb2q3k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is a lower bound for two reasons: first, there may be spending schedules better than those that we present. Second, we calculate the utility of the 4% strategy for an arbitrarily long time horizon whereas we compute the optimal spending schedules within the year 2100.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl7mov3kerw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl7mov3kerw\">^</a></strong></sup></span><div class=\"footnote-content\"><p><i>Added post-publication on 2022-11-29</i></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0ozx9a9j2ytp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0ozx9a9j2ytp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We use semi-arbitrary units of \u2018quality-adjusted relevant effort units\u2019. We use \u2018quality-adjusted\u2019 to imply that an expert's hour of contribution is worth more than a novice\u2019s hour of contribution. We use \u2018relevant\u2019 to discount any previously acquired research or influence that is no longer useful. We use \u2018effort units\u2019 to mostly account for the time that people have put into working on something.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0559jboxwohm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0559jboxwohm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We give a more complete account in the technical description. In short, the solution is given as a numerical solution to an expanded set of differential equations.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrd1s8t31ih\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrd1s8t31ih\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The opposite is also plausible if AI risk becomes increasingly salient.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2rrtvaiivxq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2rrtvaiivxq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Taking&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\delta=0.4\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.4</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzxvcxu04yoi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzxvcxu04yoi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Taking&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\delta=0.2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.007em;\">\u03b4</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.2</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmud4jt7iwid\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmud4jt7iwid\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We see that even with practically no money we still achieve some utility. This is because both (1) the probability of success is non-zero when we have no research or influence, and (2) we already have some research and influence that will depreciate over time with no further spending.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn34pvwvdj5j1\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref34pvwvdj5j1\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_R = 0.15\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.15</span></span></span></span></span></span></span>,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_I = 0.1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.1</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmuz462aogp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmuz462aogp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;As discussed in the appendix, this is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_R =0.3, \\eta_I=0.2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.2</span></span></span></span></span></span></span>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnp99df7wtcj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefp99df7wtcj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\eta_R = 0.45, \\eta_I = 0.3\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.45</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.064em;\">I</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnu4cslxlpzq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefu4cslxlpzq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This weight-adjustment is determined the&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\gamma\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span></span></span></span></span>&nbsp;term in the&nbsp;constant elasticity of substitution function.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb6xmk0hge4r\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb6xmk0hge4r\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is done by increasing&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span></span></span></span></span></span>&nbsp;up to 1.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjdo593mzzo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjdo593mzzo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is due to our choice of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\gamma\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.025em;\">\u03b3</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaro9kv2dskj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaro9kv2dskj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In the sense that (1) it depreciates at a lower rate (2) there are lower diminishing marginal returns.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxdh4oo6w5w\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxdh4oo6w5w\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;At a high enough spending rate one marginal unit of influence is cheaper than one marginal unit of influence due to diminishing marginal returns</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnytkvoer9a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnytkvoer9a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho=-10\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">10</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn13b8o0nosgq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref13b8o0nosgq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho =0.001\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.001</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fns1ebjhailoj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefs1ebjhailoj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This has&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho=0.3\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4ioy6q2tluk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4ioy6q2tluk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho=1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncspwzen77d\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcspwzen77d\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See table in the introduction</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5be1atounwr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5be1atounwr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The default strategy is where you spend exactly the amount your money appreciates, and so your money remains constant.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxm0e7wv83f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxm0e7wv83f\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;E.g. thinking that&nbsp;<i>\u2018although I think AGI is more likely than not in the next&nbsp;</i><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><i>&nbsp;years, it is intractable to increase the probability of success in the next t years and so I should work on interventions that increase the probability of success in worlds where AGI arrives at some time&nbsp;</i><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\u2019>t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mo\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.298em;\">\u2032</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span><i>\u2019</i></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnc0q5tqapg0e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefc0q5tqapg0e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Probability of success if AGI is this year is 0.1%, and steepness&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"l=0.1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.1</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwgvhowa871\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwgvhowa871\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho =0.8\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.8</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmyc0xv610z9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmyc0xv610z9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span></span></span></span></span></span>&nbsp;is low, perhaps less than or equal to zero.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzvmkezu0ph\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzvmkezu0ph\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We take&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rho \\approx 0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03c1</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u2248</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span>, so this is approximately the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Cobb%E2%80%93Douglas_production_function\"><u>Cobb-Douglas production function</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnohplf1uc41o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefohplf1uc41o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Similar to how&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c(t)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;makes influence more expensive over time.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8qoqfdxlymt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8qoqfdxlymt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We have&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"r=0.1, \\eta_R = 0.3, M_0 = 4000\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">r</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.006em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0.3</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.081em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;\">M</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">4000</span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsuy4dht2xu\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsuy4dht2xu\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Inputs that are not considered include: historic spending on research and influence, the rate at which the real interest rate changes, the post-fire alarm returns are considered to be the same as the pre-fire alarm returns.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyg0augeodl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyg0augeodl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>And supposing a 50:50 split between spending on research and influence</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6ynt2nhmben\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6ynt2nhmben\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This notebook is &nbsp;less user-friendly than the notebook used in the main optimal spending result (though not <i>un</i> user friendly) &nbsp;- let me know if improvements to the notebook would be useful for you.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnk8mofgrl98i\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefk8mofgrl98i\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The intermediate steps of the optimiser are&nbsp;<a href=\"https://docs.google.com/document/d/1GQdqsBhPgmA8DNy9Ed25zlmunxhxxYljpqaQhKz8G6E/edit?usp=sharing\"><u>here</u></a><u>.</u></p></div></li></ol><p>&nbsp;</p><h1>Author contributions</h1><p>Tristan and Guillaume defined the problem, designed the model and its numerical resolution, interpreted the results, wrote and reviewed the article. Tristan coded the Python notebook and carried out the numerical computations with feedback from Guillaume. Tristan designed, coded, solved the alternate model and interpreted its results.</p><h1>Acknowledgements</h1><p>We\u2019d both like to thank Lennart Stern and Daniel Kokotajlo for their comments and guidance during the project. We\u2019re grateful to John Mori for comments.&nbsp;</p><p><br>Guillaume thanks the SERI summer fellowship 2021 where this project started with some excellent mentorship from Lennart Stern, the CEEALAR organisation for a stimulating working and living environment during the summer 2021 and the CLR for providing funding to support part-time working with Tristan to make substantial progress on this project. &nbsp;</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\">&nbsp;</ol>", "user": {"username": "Tristan Cook"}}, {"_id": "EyvGwhHd487ayPfLg", "title": "Backyard EA: a podcast proposal", "postedAt": "2022-10-21T08:21:05.104Z", "htmlBody": "<h1><strong>Summary</strong></h1><p>EA has an elitist image which may be putting people off the movement. I propose a podcast,&nbsp;<i>Backyard EA</i>,&nbsp;exploring how people can run independent projects that make a significant difference&nbsp;without&nbsp;earning-to-give or an EA career. The post ends with an appeal for feedback.</p><h1>&nbsp;</h1><h1><strong>Motivation for the Podcast</strong></h1><ul><li>Increased interest in EA careers is good for EA organizations, but it may have <strong>counterproductive side-effects</strong><ul><li>For many applicants, time spent on applications would be better spent on&nbsp; independent projects</li><li><a href=\"https://forum.effectivealtruism.org/posts/Khon9Bhmad7v4dNKe/the-cost-of-rejection\"><u>Rejection is demoralizing</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really\"><u>may put some people off EA</u></a>, especially if they don\u2019t see other ways of contributing</li></ul></li><li>The EA movement\u2019s focus on earning-to-give and EA careers has historically<strong>&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/posts/x9Rn5SfapcbbZaZy9/ea-for-dumb-people\"><strong><u>struggled to accommodate</u></strong></a> non-hyper-achievers<ul><li>Those&nbsp;<i>not&nbsp;</i>earning-to-give or in an EA career feel left out or like they are \u201call talk\u201d</li><li>EA podcasts typically feature guests at the top of the field: there is a gap for a show that celebrates the more \u201ceveryday\u201d side of EA work</li></ul></li><li>There is&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/gYpZX9dqcuXMLWeGs/a-step-by-step-guide-to-running-independent-projects\"><u>some great written advice on independent projects</u></a>, but <strong>I can\u2019t find video/audio content on the subject</strong>. This seems like a missed opportunity - some people&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/dRAuYCKJprx8uMcYR/emrik-s-shortform?commentId=5zroBG2oph5kCxiKv\"><u>report being overwhelmed</u></a> by the amount of reading they feel they should be doing.&nbsp;</li><li>Independent projects, even when unsuccessful, are <strong>an excellent way to build skills and experience</strong>, and therefore become more effective. Let\u2019s celebrate that!</li><li>I have experience in running an interview podcast (~20 episodes) and feel that I have sufficient skills to make a good product</li></ul><h1>&nbsp;</h1><h1><strong>Proposal</strong></h1><p>This would be an interview podcast featuring one or more guests per episode.&nbsp;</p><p><strong>Possible episode types</strong> could be:</p><ul><li><strong>A tour through the lifecycle of an independent project, given by the person who ran it</strong> (<i>Person X on her innovative university outreach idea // Person Y on how he used the effectuation model to build his malaria app project</i>)</li><li><strong>An EA expert giving their slant</strong> (The creator of the<i> EA Forum on why contributing can be so powerful // A Longtermist on their favorite small EA projects that are helping the future, now! // An EA org founder on the early failures that made them a success // Someone from 80k hours on how to balance direct work with long-shot job applications&nbsp;</i>)</li><li><strong>Community edition</strong>: listeners share their latest project ideas</li></ul><p>&nbsp;</p><p>The podcast could grow into a larger community with:</p><ul><li>online and in-person events</li><li>a website with write-ups of independent projects</li><li>a forum for seeking and giving feedback/assistance on projects</li></ul><p>&nbsp;</p><h1><strong>Potential Weaknesses</strong></h1><ul><li>A low-quality show could <strong>give the EA movement a bad name</strong><ul><li>Untested, amateur guests are likely to be of inconsistent quality</li></ul></li><li>The show could <strong>distract listeners from better EA media</strong></li><li>Applying for EA jobs may come with a sufficiently high expected value that the podcast <strong>could be net-negative</strong> by distracting people from this<ul><li>The show may encourage people to aim too low or specialize too soon -&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/YtPcJx6yMHqQGYbWK/young-eas-should-choose-projects-more-carefully\"><u>young EAs should choose projects carefully</u></a></li></ul></li><li>There may be <strong>better ways</strong> for me to maximize my priorities (increasing my immediate impact, personal growth &amp; becoming more embedded in the EA community)</li></ul><p>&nbsp;</p><h1><strong>Any Feedback?</strong></h1><p>Give me your feedback on&nbsp;<i>Backyard EA</i>!</p><p>I am particularly interested in:</p><ul><li>Feedback on the strongest/weakest arguments for making the show</li><li>Suggested changes to the show format</li><li>Ideas for research/thinking I can do to refine the project</li><li>Ideas for episodes &amp; suggestions for guests</li><li>Advice on how to build an audience by tapping into EA networks</li></ul>", "user": {"username": "Stan Pinsent"}}, {"_id": "xtP82sta8RNpjaxFY", "title": "Let us know how psychology can help increase your impact", "postedAt": "2022-10-21T10:32:24.406Z", "htmlBody": "<p>The initiative<a href=\"https://forum.effectivealtruism.org/posts/zQ5apJGAJb6otXdvh/high-impact-psychology-hipsy-piloting-a-global-network\">&nbsp;<u>High-Impact Psychology</u></a> (HIPsy) currently aims to find out how to best help people engaged with Effective Altruism, to maximize their impact via evidence-based psychology. You could contribute to this a lot by letting us know what would be most helpful to you. <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdFbUZUyK4jrwRiii7QwEXogRFzm50PENxIyLwtByKQn5nuPw/viewform?usp=sf_link\"><strong>It just takes 3 min to fill out this form</strong>.&nbsp;</a></p><p>We are thinking of collecting and providing the most sought-after resources such as workshops, expert discussions, and evidence summaries on:&nbsp;</p><ul><li>psychology across cause areas, e.g., in existential risk, mental health, and research.</li><li>psychology at work, e.g., effective management, HR, and team building</li><li>community building, e.g., building culture and increasing engagement</li><li>personal optimization, e.g., learning, productivity, and wellbeing</li></ul><p>&nbsp;</p><p><strong>Background</strong></p><p><a href=\"https://forum.effectivealtruism.org/posts/zQ5apJGAJb6otXdvh/high-impact-psychology-hipsy-piloting-a-global-network\"><u>HIPsy</u></a> is currently in a funded pilot phase, finding out which potential actions would be most impactful. One potential action is to give community members access to cutting-edge behavioral science and psychology that contribute to relevant EA aspirations. With just a few clicks, you shall be able to access evidence summaries and upskilling workshops, as well as exchange with psychology experts. If we decide to go that route and if possible, we will try to offer these for free. <a href=\"https://forum.effectivealtruism.org/posts/zQ5apJGAJb6otXdvh/high-impact-psychology-hipsy-piloting-a-global-network\">You can learn more about our project and other potential actions in this post.</a>&nbsp;</p><p>&nbsp;</p><p><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdFbUZUyK4jrwRiii7QwEXogRFzm50PENxIyLwtByKQn5nuPw/viewform?usp=sf_link\"><strong><u>Let us know,&nbsp;by filling out the brief form here: &nbsp;</u>Which learnings would increase your impact most?</strong></a></p><p>&nbsp;</p><figure class=\"image image_resized\" style=\"width:64.74%\"><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/055d45ec7f1a920c116b91fdf48a1158294ac4ae0668f901.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/055d45ec7f1a920c116b91fdf48a1158294ac4ae0668f901.png/w_90 90w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/055d45ec7f1a920c116b91fdf48a1158294ac4ae0668f901.png/w_170 170w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/055d45ec7f1a920c116b91fdf48a1158294ac4ae0668f901.png/w_250 250w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/055d45ec7f1a920c116b91fdf48a1158294ac4ae0668f901.png/w_330 330w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/055d45ec7f1a920c116b91fdf48a1158294ac4ae0668f901.png/w_410 410w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/055d45ec7f1a920c116b91fdf48a1158294ac4ae0668f901.png/w_490 490w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/055d45ec7f1a920c116b91fdf48a1158294ac4ae0668f901.png/w_570 570w\"></figure><p><strong>Additional resources</strong></p><p>You can sign up via these forms for events, networking, and materials&nbsp;</p><ul><li>for<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSe79DiNOj-3rn9-e6UJF9Iagmk8g2bkXDZQH8XYJ1Y6RbQqtw/viewform?usp=sf_link\"><i><u> people&nbsp;who have a background in psychology </u></i></a>and&nbsp;</li><li>for<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSek_fDDmAunEQR-g4AfTOKOT44h4FsLJcJV-8e0pJvYKLbnrw/viewform?usp=sf_link\"><i><u>&nbsp;people who are interested in, working in, or adjacent to the mental health sector.</u></i></a></li></ul><p><a href=\"https://docs.google.com/forms/d/e/1FAIpQLScAa9_Sql-kPkFaZYhKwlaNqRUil9GvS0cG9hH1G-zq2o3vRQ/viewform?usp=sf_link\"><i>If you want to <strong>contribute to HIPsy, e.g., offer psychology-related resources</strong>, let us know here.</i></a></p><p>Thank you to Christian Kleinedam, Justis Mills, and Lucia Purcaru for the helpful feedback on this post.</p>", "user": {"username": "Inga"}}, {"_id": "wPz7iQizzaxtvc4bX", "title": "Brief evaluations of top-10 billionnaires", "postedAt": "2022-10-21T15:29:29.587Z", "htmlBody": "<p>As part of my work with the <a href=\"https://quantifieduncertainty.org/\">Quantified Uncertainty Research Institute</a>, I am experimenting with speculative evaluations that could be potentially scalable. Billionaires were an interesting evaluation target because there are a fair number of them, and at least some are nominally aiming to do good.</p><p>For now, for each top 10 billionaire, I have tried to get an idea of:</p><ol><li>How much value have they created through their business activities?</li><li>How much impact have they created through their philanthropic activities</li></ol><p>I then assigned a subjective score based on my understanding of the answers to the above questions. Overall I've spent in the neighborhood of 20 hours (maybe 7 to 40 hours) between research and editing, so this is by no mean the final word on this topic.</p><h3><strong>Elon Musk (B)</strong></h3><p>Elon Musk changes the world through:</p><ul><li>His businesses: Tesla, SpaceX, The Boring Company and Neuralink. Tesla makes better cars, SpaceX advances interplanetary expansion.</li><li>His cultural influence: Twitter shitposting, conceiving and pushing for brighter futures, etc.</li><li>His philanthropy: Little of it is publicly known so far. He will probably end up buying Twitter, partially with the intention of making it a better public good. OpenAI, which he helped found, might end up having greatly positive or greatly negative impact.</li></ul><p>Overall Musk seems like has produced large amounts of value, and might produce even more through SpaceX. But he also seems to be oddly nonstrategic at times.</p><h3><strong>Bernard Arnault (D-)</strong></h3><blockquote><p>I see myself as an ambassador of French heritage and French culture. What we create is emblematic. It's linked to Versailles, to Marie Antoinette. -- <a href=\"https://www.forbes.com/profile/bernard-arnault/?sh=2d3799e966fa\">Bernard Arnault, as quoted in Forbes</a></p></blockquote><p>His business produces little counterfactual value, and instead serves as a vehicle for conspicuous consumption. That is, if his luxury brands didn't exist, his customers would simply buy from the others, and the world would look extremely similar.</p><p>His company describes its philanthropy as <a href=\"https://www.lvmh.com/group/lvmh-commitments/art-culture/lvmh-corporate-philanthropy/\">\"an ideal expression of financial success\"</a>, and supports art installations, or students attending concerts. Thus his philanthropy seems non-strategic, aimed at the display of wealth rather than at the firm pursuit of improving and fortifying French culture. He also donated $200M to restore the Notre Dame, which probably saved French tax-payers a similar amount.</p><h3><strong>Jeff Bezos (B)</strong></h3><p>The market value of Amazon is circa $1T, meaning that it has managed to capture at least that much value, and likely produced much more consumer surplus. His other ventures, like Blue Origin, are as of yet nowhere as valuable.</p><h3><strong>Gautam Adani (B?)</strong></h3><p>Adani seems to be a skilled manager, administrator, and deal-maker who, working in a developing country, has unlocked heaps of value.</p><p>He has ties to Narenda Modi, and their fortunes have risen together. From the outside, it's hard to say to what extent he has <a href=\"https://nairametrics.com/2022/05/11/how-gautam-adani-went-from-being-a-school-dropout-to-becoming-the-richest-man-in-india/\">created his wealth</a>:</p><blockquote><p>The governor of Gujarat announced managerial outsourcing of the Mundra Port in 1994, and Adani got the contract in 1995, after which he set up the first jetty, which was originally run by Mundra Port &amp; Special Economic Zone but was later transferred to Adani Ports and SEZ (APSEZ).</p></blockquote><blockquote><p>Adani decided to turn it into a commercial port, building rail and road links to it by individually negotiating with over 50 0 landowners across India to create the largest port in India.</p></blockquote><p>or <a href=\"https://asiatimes.com/2022/05/gautam-adani-master-of-the-art-of-modern-monopolies/\">simply aquired it</a>:</p><blockquote><p>Mr Adani\u2019s friendship with Prime Minister Narendra Modi is time-tested. Their friendship goes back to 2003, when none of the country\u2019s leading businessmen publicly stood by Modi\u2019s side because of the handling of the Gujarat riots. But Adani broke ranks with the old business elite, potentially risking his future. And this gamble paid off.</p></blockquote><blockquote><p>Gautam Adani is today one of the most visible tycoons in the country, whose prominence has accelerated in the years since Narendra Modi was elected prime minister in 2014. Since Modi came into office, Adani\u2019s net worth has increased 17.5 times in less than eight years, from $7 billion to $125 billion</p></blockquote><h3><strong>Bill Gates (A)</strong></h3><p>It's unclear whether Microsoft itself has had a positive or negative impact on the world over what would have counterfactually happened (e.g., Apple and Linux would be more popular). However, Gates' impact-focused philanthropy has helped millions. He moreover started the <a href=\"https://givingpledge.org/\">Giving Pledge</a>, which probably multiplied his impact. Too bad that he couldn't prevent the covid pandemic.</p><h3><strong>Warren Buffett (A)</strong></h3><p>Berkshire Hathaway is probably a force for good in the capitalist ecosystem. He has also contributed $32+ billion to the <a href=\"https://www.gatesfoundation.org/about/leadership/warren-buffett\">Gates Foundation</a>. In addition, Buffett created the Giving Pledge, which probably multiplied his impact.</p><h3><strong>Larry Ellison (C?)</strong></h3><p>Ellison has made his wealth by selling <a href=\"https://libreddit.foss.wtf/r/business/comments/di5j2/im_always_surprised_to_see_the_oracle_chieflarry/\">universally-reviled database software</a> and other products that work at Fortune 500 and government scale.</p><p>He has signed the <a href=\"https://givingpledge.org/pledger?pledgerId=192\">Giving Pledge</a>, though his giving may have been <a href=\"https://www.vox.com/recode/2020/9/2/21409530/larry-ellison-foundation-disband-london-philanthropy-coronavirus\">erratic at times</a>. It's also possible that his closeness to Trump at times improved the quality of Trump's decision-making while in office.</p><h3><strong>Mukesh Ambani (B?)</strong></h3><p>His wealth originally came from a vertically integrated commodity business, but has since expanded. Although skilled at navigating government bureaucracies, he also ate his own brother alive in the competitive communications business, providing millions of Indian consumers with cheaper internet access. Overall most of his impact is going to come from his contribution to Indian economic growth, and that contribution is probably highly positive.</p><h3><strong>Larry Page (B)</strong></h3><p>By making a better search engine and providing other Google products for free to millions, he has provided heaps of value. However, in recent times, he has disengaged from Google, and Google has abandoned its \"don't be evil\" motto. His philanthropy, while <a href=\"https://www.vox.com/recode/2019/12/18/21010108/larry-page-philanthropy-foundation-donor-advised-fund-christmas\">large</a>, is somewhat secretive.</p><h3><strong>Sergei Brin (B-)</strong></h3><p>Like Larry Page, by making a better search engine and providing other Google products for free to millions, he has provided heaps of value. However, in recent times, he has disengaged from Google, and Google has abandoned its \"don't be evil\" motto. He has donated at least <a href=\"https://www.influencewatch.org/non-profit/sergey-brin-family-foundation/\">$1.4 billion</a> to his family foundation, and seems to donate to left-of-center causes.</p><h2><strong>Reflections</strong></h2><h3><strong>Comparisons with other alternatives</strong></h3><p>From some brief Googling, two other rankings are the <a href=\"https://www.forbes.com/forbes-400\">Forbes 400</a>, which assigns a philanthropy score to America's 400 richest people, and the <a href=\"https://www.philanthropy.com/article/the-philanthropy-50/#id=browse_2021\">philanthropy 50</a>, which is paywalled.</p><p><strong>Forbes' Philanthropy score</strong></p><p>The methodology for the Forbes 400 philanthropy score can be seen <a href=\"https://www.forbes.com/sites/rachelsandler/2022/09/27/the-forbes-philanthropy-score-2022-how-charitable-are-the-richest-americans/?sh=587daeea0980\">here</a>. In short, Forbes does some <a href=\"https://www.forbes.com/sites/chasewithorn/2022/09/27/2022-forbes-400-methodology-how-we-crunch-the-numbers/?sh=1f88cfe5d0eb\">intensive investigative work</a> to determine what billionaire's wealth actually <i>is</i>. Then,</p><blockquote><p>To see how philanthropic the ultrawealthy are, Forbes dug into their known charitable giving and assigned a philanthropy score, ranging from 1 to 5, to each member of The Forbes 400. If we couldn\u2019t find any information about a person\u2019s giving and they declined to provide details, they received a score of N/A.</p></blockquote><blockquote><p>To calculate the scores, we added the value of each person\u2019s total out-the-door lifetime giving to their 2022 Forbes 400 net worth, then divided their lifetime giving by that number. Each score corresponds to a range of giving as a percentage of a person\u2019s net worth. We once again counted only out-the-door giving, rather than cash sitting in billionaires\u2019 private foundations or tax-advantaged donor-advised funds that have not yet made it to those in need. We reached out to every list member for feedback</p></blockquote><p>This is already fairly sophisticated. If I had to suggest one improvement, it would be to incorporate whether billionaires have signed the <a href=\"https://givingpledge.org/\">Giving Pledge</a>.</p><p>Personally, I would also:</p><ul><li>Score individuals on the <i>amount</i> of money donated, rather than on the <i>percentage</i></li><li>Accommodate <a href=\"https://80000hours.org/podcast/episodes/phil-trammell-patient-philanthropy/\">patient philanthropy</a> (see also <a href=\"https://docs.google.com/document/d/1NcfTgZsqT9k30ngeQbappYyn-UO4vltjkm64n4or5r4/edit\">1</a>, <a href=\"https://globalprioritiesinstitute.org/wp-content/uploads/Trammell-Dynamic-Public-Good-Provision-under-Time-Preference-Heterogeneity.pdf\">2</a>), and not look only at money out the door.</li></ul><h3><strong>Possible further work</strong></h3><p>If I had access to a legion of researchers, I would try to move first towards a legible rubric and then to a quantified impact estimate.</p><p><strong>An initial rubric</strong></p><p>An initial rubric might incorporate:</p><p>Some subjective estimate of how much value the individual has created through business</p><ul><li>Are the business activities more like value creation or like resource extraction</li><li>How much value has the individual created?</li></ul><p>Some mechanistic estimate of how much value the individual will create through philanthropy</p><ul><li>How much money will the individual end up donating?</li><li>How much has the individual donated so far?</li><li>Has the individual joined the <a href=\"https://givingpledge.org/\">Giving Pledge</a>?</li><li>Are the individual's donations done with some reference to impact?<ul><li>This would require some finesse in order to incorporate different philosophical stances. But there is certainly a substantial difference between Bill Gates' and Bernard Arnault's giving.</li></ul></li></ul><p>Possibly, some estimate of additional sources of impact, like cultural influence or using a position of prominence to positively impact the world.</p><p>Crucially, the above categories could be complementary. For instance, a skilled administrator and industrialist like Mukesh Ambani is already creating heaps of value through business in India, and he probably creates more value through deploying his capital through business than he would through philanthropy. So an individual could get top marks by being excellent in any one domain.</p><p><strong>A quantified estimate</strong></p><p>Eventually, a quantified estimate might move beyond being a rubric and directly attempt to estimate each part of an individual's impact, and then put them all together in a common linear unit.</p><p>For example, in the case of Elon Musk, I would estimate how valuable each of his ventures is, either in an impact unit like <a href=\"https://www.openphilanthropy.org/research/update-on-our-planned-allocation-to-givewells-recommended-charities-in-2022/#f+9715+1+6\">Open Philanthropy dollars</a>\u2014$1 dollar given to someone earning $50k a year\u2014or in terms of <a href=\"https://forum.effectivealtruism.org/posts/9hQFfmbEiAoodstDA/simple-comparison-polling-to-create-utility-functions\">relative values</a>\u2014where you compare how much each element is worth to other elements, and you don't need a unit or can easily construct one once you've done that.</p><h3><strong>Things I personally struggled with</strong></h3><p>Some billionaires were harder to estimate than others. I particularly struggled with Gautam Adani and Mukesh Ambani. I'm probably lacking a whole lot of context there. Thanks to Chinmay Ingalavi for giving me some context.</p><p>I am also uncertain about Larry Ellison. <a href=\"https://teddit.nunosempere.com/r/linux/comments/2e2c1o/what_do_we_hate_oracle_for/\">Here</a> is a thread on shady Oracle corporate practices. But <a href=\"https://givingpledge.org/pledger?pledgerId=192\">here</a> is Ellison's Giving Pledge letter. I'm unclear on how to square the two.</p><p>The whole exercise took longer than I was expecting.</p><p>I'm also unclear on whether to use gossip and private information, and ended up not doing so.</p><p>I was also unclear on which philosophical assumptions to use. For instance,</p><ul><li>I'm partial to <a href=\"https://docs.google.com/document/d/1NcfTgZsqT9k30ngeQbappYyn-UO4vltjkm64n4or5r4/edit\">Patient Philanthropy</a></li><li>I think it's plausible that most of a billionaires impact could come from business rather than from philanthropy.</li><li>I think that Amazon's <a href=\"https://www.commondreams.org/news/2022/10/18/following-brutal-union-busting-campaign-albany-amazon-workers-reject-unionization\">union busting</a> is an evil practice but not nearly enough to move the needle on my overall evaluation of Amazon overall having produced very large heaps of value.</li><li>I didn't incorporate Mackenzie Bezos' giving into Jeffrey Bezos' estimate, although one could argue that he created a big chunk of that wealth.</li></ul>", "user": {"username": "NunoSempere"}}, {"_id": "P29RwAnQDHazQxCQt", "title": "Accountability Buddies: Why you might want one (+ Database to find one!)", "postedAt": "2022-10-23T16:25:12.550Z", "htmlBody": "<p><i>TL;DR: </i>An accountability buddy is someone to check in with from time to time to give you social motivation to achieve your goals. There are many additional benefits from this process such as planning together and getting feedback on your progress. I think especially EAs in remote areas or those doing EA-related work, or upskilling part-time would benefit from having an accountability buddy. If you\u2019d like to try it out, put your details down&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/143Z16crSfv9BB2dn5eaoseT0ZpbMVaizBASL43eXJ7s/edit#gid=0\"><u>in this table</u></a>.</p><p><i>This is partly a post about increasing your productivity. For more ideas check&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/x7udP4eQqm4WJ9mFo/a-database-of-effective-productivity-recommendations\"><i><u>Effective Self-Help\u2019s long list of recommendations</u></i></a><i>.</i></p><p><i>Thank you to Evander and Anabel for your feedback.</i></p><p>Epistemic status: We have had first-hand experience with accountability buddies for the past six months + reflected on the process several times. We\u2019ve also had conversations with others about the topic. Overall our views should be taken as a motivation to experiment instead of a laid-out path.</p><p>Author\u2019s note: The first-person perspective in this post is taken in by me. Other remarks by Sam are made <a href=\"https://www.snellessen.com/reflections-on-accountability\">here</a>. Nevertheless, we wrote most of this article collaboratively. Furthermore, this article is a concrete outcome of our rejection challenge.</p><h1>Motivation for having an accountability buddy</h1><p>I think I wouldn\u2019t be where I am today if I hadn\u2019t met Sam, my accountability buddy at EAG London this year. Our regular meetings made me more structured, helped me frequently reflect on my goals and progress, and made me more ambitious than I was before. I think many, if not all people would benefit from some form of accountability partnership and I encourage you to give it a try if you haven\u2019t.</p><p>In an abstract sense, an accountability buddy (AB) is someone to help you better reflect and achieve your goals, either through indirect accountability (\u201dI told them I\u2019d get this done this week and it\u2019s already Thursday, so I better get going!\u201d) or direct accountability (\u201cHey, didn\u2019t you say you wanted to start that project? How is that going?\u201d). The most common way of doing this is by meeting regularly and going through past progress and future goals.</p><p>In addition to accountability, an AB can help you to reflect on your goals and the progress you made toward them. If it works out well, an accountability session can feel like a mini-coaching every week.</p><p>I think many people would benefit from accountability buddies, especially if they:</p><ul><li>Live in a location where EA interactions occur infrequently</li><li>Work on EA causes part-time or in their free time</li><li>Struggle to make progress on long-term goals such as career planning or particular projects</li><li>Find it hard to stay motivated&nbsp;</li><li>Lack a social environment that supports their work</li><li>Have several goals that they find hard to prioritize among</li></ul><p>There are also some related concepts that I may one day write about: career planning groups (e.g.&nbsp;<a href=\"https://www.facebook.com/groups/928373221340185\"><u>for the 80k course</u></a>), holding you accountable to make progress and discussing your plans and value buddies, someone you reflect your values with on a regular basis to keep track of&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/value-drift\"><u>value drift</u></a>.</p><h1>Benefits</h1><ol><li>In order to talk about your plans, you have to plan. To communicate your goals for the coming week, you\u2019ll have to formulate them well, which often shows you flaws or failure modes.&nbsp;</li><li>You get feedback. A good accountability buddy will tell you when they think you\u2019ve set too many objectives for the next week or if you are ignorant of something. They can also give some object-level stance on how likely you\u2019ll be to complete certain tasks and if your approach is promising.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9y60wbo3wom\"><sup><a href=\"#fn9y60wbo3wom\">[1]</a></sup></span></li><li>You also learn and grow together. If you see that your buddy is doing something you haven\u2019t thought about before but that you could do as well, then you feel inclined to do it as well. In a way, holding each other accountable also leads to healthy competition and trying to be more ambitious.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9tvpgf9lzr\"><sup><a href=\"#fn9tvpgf9lzr\">[2]</a></sup></span></li><li>You become more agentic. We were very excited when we read \u201c<a href=\"https://eviecottrell.com/blog/seven-ways-to-become-unstoppably-agentic\"><u>Seven Ways To Become Unstoppably Agentic</u></a>\u201d by Evie Cottrell a few months ago. We quickly set up a rejection list and challenged each other to get more rejections. We also discussed on a weekly basis whether we could think of somebody in our immediate or not-so-immediate social network that could help us with one of our current problems. Reading the blog post together and aiming to be more agentic in the future was quite impactful for both of us. I am unsure whether I would have applied for funding or asked for mentoring if not for this dynamic.</li><li>You grow as a person. With time your AB will not only learn to give feedback to your planning and goal setting but more broadly to you as a person. This has been a powerful mechanism for my character development.</li><li>Having someone to report your progress to makes you feel supported and enables you to be more ambitious.&nbsp;</li><li>You may gain a new friend. Having someone to tell how you are doing and how you feel is one of the best ways to connect with someone. Sharing so explicitly and openly naturally lets you grow together and develop a strong friendship (if you want this to happen, I think you can also do this on a completely professional level).</li><li>You feel more connected to EA. Talking to an EA can be very enjoyable and beneficial, especially for those who don\u2019t have much contact to EAs in their everyday life. It definitely helped me implement more EA-related reading and work into my everyday life and was great to reflect on my career plans.</li><li>You gain a valuable support structure. I think even before becoming friends it feels great to have someone who knows about your goals and you feel reassured. Besides that, you also have a person to talk about EA-related, and non-EA-related struggles, e.g., pressure, hustle culture, or EA-relationships talk</li></ol><h1>Downsides &amp; Failure modes</h1><ol><li>It can get pretty intense socially. If you have mental health issues or otherwise tend to feel guilty about not getting done what you think you should have, having to report this to someone and hearing how they made progress can be demotivating.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1w3h72zqhiz\"><sup><a href=\"#fn1w3h72zqhiz\">[3]</a></sup></span><ol><li>However, I think having someone to listen to your struggles and hearing that your accountability buddy also has problems can be very comforting. Furthermore, an AB can help you set realistic goals which can help you not to feel overwhelmed as easily.</li></ol></li><li>Your friendship and conversations will, in the best case, get pretty deep pretty quickly. This can sometimes feel weird. How can I talk with this person about e.g., how my unhealthy relationship hinders me in achieving my goals if I\u2019ve barely known them for three weeks?&nbsp;<ol><li>To avoid this, I suggest starting with a minimal version of accountability where you simply talk about some concrete tasks. As you develop trust, you can additionally talk about more personal things.</li></ol></li><li>Accountability itself is neutral. If you realize one of the goals you set was misguided, being held accountable for it can be bad.<br><br><ol><li>S:&nbsp;<i>I felt something like this when I was overwhelmed after hanging out at the legendary PrEAGxBerlin flat. I felt like I couldn\u2019t continue on the path I was, and telling something along those lines to my accountability buddy felt weird and frightening.</i><br>I think it can easily happen that you know you\u2019d benefit from taking some time off but feel pressured by your AB to work more. However, ideally, if you make this explicit, your AB might even be able to help you develop a healthier working routine.</li></ol></li><li>The closer you grow, the more your accountability buddy gets to know you. Subsequently, your AB loses the valuable outside perspective.&nbsp;<ol><li>On the other hand, the feedback you get will be more personal, which can be very helpful. One idea here is to change your AB from time to time so you get different perspectives. However, we haven\u2019t tried that yet.</li></ol></li><li>For some highly structured people, spending time with your AB might be less valuable compared to reflecting by yourself.&nbsp;<ol><li>However, even if you think that is likely the case, I suggest you still give it a try. I was surprised how much I benefitted despite already having been a very structured person.</li></ol></li></ol><h1>How does it work concretely?</h1><p>I think there are many ways you can make an accountability partnership work. A simple form is just meeting up once a week and sharing your goals for the next few days.</p><p><strong>0) Think about what you want</strong></p><p>Was there something we mentioned you\u2019d like to have? Is there something else an AB could help you with? Do you think you\u2019d benefit from an accountability partnership?</p><p><strong>1) Finding an AB</strong></p><p>Your AB should ideally be:</p><ul><li>Broadly familiar with the work you usually do, ideally, you work in the same field</li><li>Be in a similar personal situation, e.g., if you\u2019re at university, having another student as AB will likely be most helpful</li><li>Live close to you (though we\u2019ve met up online 90% of the time which has worked fine)</li></ul><p>Ideas for where to find them:</p><ul><li>Write in your Swapcard profile at the next EAG(x) that you\u2019re looking for one</li><li>Ask some friends</li><li><strong>Put your name down&nbsp;</strong><a href=\"https://docs.google.com/spreadsheets/d/143Z16crSfv9BB2dn5eaoseT0ZpbMVaizBASL43eXJ7s/edit#gid=0\"><strong><u>in this table</u></strong></a><ul><li>We don\u2019t plan to monitor this, so feel free to improve it and be pro-active about reaching out.</li></ul></li></ul><p>I found Sam because he wrote he was looking for an AB in Swapcard at EAG London. We first had a trial period of a couple of meetings and then decided we wanted to stick to it.</p><p>Don\u2019t be disappointed if you don\u2019t fully resonate with the first AB you picked. Try finding someone else and experiment a bit.</p><p><strong>2) Setting up a structure</strong></p><p>Schedule a regular time you meet up to discuss your plans and share your goals for the next week.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbrhz4ktjcoe\"><sup><a href=\"#fnbrhz4ktjcoe\">[4]</a></sup></span>&nbsp;I think you get the most value from it if you include a reflection on the last week.</p><p>If you want to take it further, you can design a template (see Appendix for our template) you complete each week (e.g., by silent coworking) and then talk about the results. Another idea is to include a debugging session at the end of the meeting.</p><p><strong>3) Regularly reflect on the accountability partnership</strong></p><p>Would it help you to have brief daily check-ins in addition to your weekly planning? Do you feel like you could shorten the meeting without losing many benefits? Do you think additional monthly planning might be helpful? Do you feel comfortable sharing your personal life or would you rather just talk about your work-related goals?</p><h1>Some things we would do differently now or learned along the way</h1><p>The style of our meetings and the relationship with Sam changed considerably over the last months. Here are some learnings we\u2019d like to pass on:</p><ol><li>Have a minimal version that you can do if you have a very stressful week. Ideally, also have a version that works without having to meet (e.g., by just sharing your plan for the next week). This makes it much easier to keep up the habit.</li><li>Don\u2019t&nbsp;<a href=\"https://en.wikipedia.org/wiki/Goodhart%27s_law\"><u>goodhart</u></a> filling in templates. Try to focus on productive reflection and planning. If you feel like your template is not helping, throw it.</li><li>Spend some time on the meta-level. Review how your planning procedure is working from time to time and improve it.&nbsp;</li><li>Have a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Pc3CFbYxPXgyjoDpB/seven-ways-to-become-unstoppably-agentic\"><u>rejection list</u></a>&nbsp;</li></ol><h1>Conclusion</h1><p>If you think you may benefit from any of the advantages outlined above, why not just try this out and&nbsp;<strong>put your name into&nbsp;</strong><a href=\"https://docs.google.com/spreadsheets/d/143Z16crSfv9BB2dn5eaoseT0ZpbMVaizBASL43eXJ7s/edit#gid=0\"><strong><u>the database</u></strong></a>!</p><p>If you already have an accountability buddy or you had one once, please share your experiences &amp; templates in the comments.</p><hr><h1>Appendix:</h1><h2>Meeting Outline</h2><p>Here\u2019s our suggested meeting outline, which we changed quite heavily over time.</p><ol><li>Check-In with&nbsp;<a href=\"https://tscheck.in/\"><u>tscheck.in</u></a></li><li>What\u2019s our time limit this week?</li><li>Mini-Retro:<ol><li>What was great about our last meeting?</li><li>What wasn\u2019t great about our last meeting?</li><li>What are we going to do differently this time?</li></ol></li><li>Verbal recap of last week (see Template)</li><li>Written recap of the last week and sharing</li><li>Written planning for the next week and sharing</li><li>Optionally, debugging session.</li><li>Check-Out with&nbsp;<a href=\"https://tscheck.in/\"><u>tscheck.in</u></a></li></ol><h2>Template</h2><p>Here\u2019s our&nbsp;<a href=\"https://www.notion.so/alleinzelgaenger/Weekly-Planning-8fe6b173f5a344b48f9806de8286361e\"><u>template</u></a>. While it is in Notion, the basic template should work elsewhere too (e.g. copy it to google docs). If you have any technical difficulties, contact&nbsp;<a href=\"https://t.me/+4915228982798\"><u>Sam</u></a>. Our process takes about an hour, though it can be shortened by skipping questions. (We usually take more time because we tend to chat a lot about what the other person has been up to - we think that\u2019s super valuable, so we try to plan accordingly.)</p><p><br>For a 15-minute version check&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/2RvpoWWQDiFpptpam/accountability-buddies-a-proposed-system-1#comments\"><u>this post</u></a>.</p><hr><h3>Footnotes:</h3><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9y60wbo3wom\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9y60wbo3wom\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cAre you sure you want to pick up on linear algebra by just studying this book? There\u2019s a great&nbsp;<a href=\"https://www.youtube.com/watch?v=kjBOesZCoqc&amp;list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B\"><u>3Blue1Brown</u></a> video series on the topic.\u201d&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9tvpgf9lzr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9tvpgf9lzr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cOh, you\u2019re already writing another blog post? Maybe I\u2019d like to take some time to write as well this week.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1w3h72zqhiz\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1w3h72zqhiz\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;If you struggle with guilt, I really recommend the&nbsp;<a href=\"https://mindingourway.com/guilt/\"><u>Replacing Guilt series</u></a> by Nate Soares.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbrhz4ktjcoe\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbrhz4ktjcoe\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We found that Sunday night works best as it\u2019s a natural reflecting time and we are both free then anyways.</p></div></li></ol>", "user": {"username": "SamNell"}}, {"_id": "zmZRwQoCgWPjNrPid", "title": "Is there an organization or individuals working on how to bootstrap industrial civilization?", "postedAt": "2022-10-21T03:36:00.145Z", "htmlBody": "<p>I'm curious who, if anyone, is developing knowledge, tools, or plans for bootstrapping industrial civilization after a disaster? &nbsp;We might think of this as turning the book <a href=\"https://en.wikipedia.org/wiki/The_Knowledge:_How_to_Rebuild_Our_World_from_Scratch\">The Knowledge</a> into a practical program. &nbsp;Or we might think of it as something like <a href=\"https://allfed.info/\">ALLFED</a>, but applied toward the resilience of industrial civilization in general, going beyond resilience of the food supply.</p><p>Possible projects might include ideas proposed in <a href=\"https://aeon.co/essays/could-we-reboot-a-modern-civilisation-without-fossil-fuels\">Lewis Dartnell's 2015 article \"Out of the Ashes\"</a> for rebooting without fossil fuels. &nbsp;Or developing low-tech solar panels or other tech for generating electricity, for storing it, for converting it into hydrogen/methane/hydrocarbons - requiring only widely-available materials and low-tech tools. &nbsp;More generally, what is a robust tech tree and plan for recovery? &nbsp;Can we build prototypes and test the plan?</p><p>The premise of this question is that there ought to be an organization like this. &nbsp;I'd also be interested in thoughts on the value of such an org, and ideas on what kind of existing org or people might incubate one.</p>", "user": {"username": "steve6320"}}, {"_id": "FEJLFr5ef82FSY8vr", "title": "Minimalist extended very repugnant conclusions are the least repugnant", "postedAt": "2022-10-24T09:46:20.080Z", "htmlBody": "<p><i>This is part four of a series on minimalist axiologies (i.e.&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives#1__What_is_axiology_\"><i><u>axiologies</u></i></a><i> that essentially say \u201cthe less this, the better\u201d).</i></p><p><i>Every part of this series builds on&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/t3St6Fz4DmHtKfgqm/positive-roles-of-life-and-experience-in-suffering-focused\"><i><u>the</u></i></a><i>&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives\"><i><u>previous</u></i></a><i>&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism\"><i><u>parts</u></i></a><i>, but can also be read independently.</i></p><h1><strong>Summary</strong></h1><p>Population axiology&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives\"><u>matters</u></a>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/RkPK8rWigSAybgGPe/a-longtermist-critique-of-the-expected-value-of-extinction-2#1__Axiological_considerations___Moral_assumptions__\"><u>greatly</u></a> for our priorities. Recently, it has been claimed that all plausible axiological views imply certain \u201cvery repugnant conclusions\u201d (<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#1__Are_repugnant_implications_inevitable_\">defined</a>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#2__Comparable_XVRCs_for_offsetting_and_minimalist_views\">below</a>). In this response, I argue that minimalist views avoid these \u201cvery repugnant conclusions\u201d, and that they face&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#4__Comparative_repugnance\">less repugnant conclusions</a> than do contrasting offsetting views.</p><h1><strong>1. Are repugnant implications inevitable?</strong></h1><p>In population axiology, certain&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#2_5_Comparative_theoretical_implications_of_minimalist_and_offsetting_views\"><u>offsetting views</u></a>, according to which independent bads can be offset by a sufficient amount of independent goods, face the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives#The_Very_Repugnant_Conclusion\"><strong><u>Very Repugnant Conclusion</u></strong></a> (<strong>VRC</strong>):</p><blockquote><p>A population of arbitrarily many lives with arbitrarily high welfare is worse than a population of arbitrarily many arbitrarily negative lives plus sufficiently many <i>\u03b5</i>-lives that each have an arbitrarily small quantity of positive welfare (Figure 1).</p></blockquote><figure class=\"image image_resized\" style=\"width:624px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FEJLFr5ef82FSY8vr/hbr6pvl3vo62xv8lkuv6\" alt=\"Figure 1.&nbsp;The original VRC.\"><figcaption><i><strong>Figure 1</strong>.&nbsp;The original VRC.</i></figcaption></figure><p>Offsetting views also allow the&nbsp;<i>\u03b5</i>-lives in the VRC to be&nbsp;<a href=\"https://www.repugnant-conclusion.com/portmore-repugnant.pdf\"><u>rollercoaster lives</u></a> that all contain unbearable suffering (purportedly counterbalanced by a sufficient amount of bliss).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftw2ovq8vikt\"><sup><a href=\"#fntw2ovq8vikt\">[1]</a></sup></span></p><p>In particular, symmetric classical utilitarianism implies interchangeability between a non-suffering <i>\u03b5</i>-life and the rollercoaster life illustrated in Figure 2 (provided that the \u201coverall welfare\u201d of the rollercoaster life equals<i>&nbsp;\u03b5</i>).</p><figure class=\"image image_resized\" style=\"width:624px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FEJLFr5ef82FSY8vr/bjvm5h5mbwtuoz2egtoq\" alt=\"Figure 2. The happiness and suffering over time of a single rollercoaster life.\"><figcaption><i><strong>Figure 2</strong>. The happiness and suffering over time of a single rollercoaster life.</i></figcaption></figure><p>Additionally, one may replace each non-suffering <i>\u03b5</i>-life in the original VRC with an intrapersonal VRC life (Figure 3).</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FEJLFr5ef82FSY8vr/gfexceq1nsbhyflu6if2\" alt=\"Figure 3. The happiness and suffering over time of an intrapersonal VRC life.\"><figcaption><i><strong>Figure 3</strong>. The happiness and suffering over time of an intrapersonal VRC life.</i></figcaption></figure><p>Recently, Budolfson and Spears (<a href=\"https://web.archive.org/web/20220614105405/https://scholar.princeton.edu/sites/default/files/cfi/files/budolfson_spears_2018_repugnant_cfi.pdf\"><u>2018</u></a>) have argued that all plausible views in population ethics imply similarly repugnant conclusions, namely that they imply either the&nbsp;<strong>VRC</strong> or a closely analogous&nbsp;<strong>Extended VRC&nbsp;</strong>(<strong>XVRC</strong>), which I illustrate shortly at the beginning of&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#2__Comparable_XVRCs_for_offsetting_and_minimalist_views\">Section 2</a>.</p><p>The purpose of this essay is to argue that this claim does not apply to&nbsp;<a href=\"https://forum.effectivealtruism.org/s/MBadsrYLmzLNmYjaj\"><u>minimalist views</u></a>. In a nutshell: minimalist views avoid the VRC, can avoid repugnant XVRCs, and, at any rate, face XVRCs that are less repugnant than are the comparable conclusions faced by offsetting views.</p><h2><strong>Three claims</strong></h2><p>Budolfson and Spears (2018, pp. 31\u201332) make the following three claims:<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrkuft17ud0j\"><sup><a href=\"#fnrkuft17ud0j\">[2]</a></sup></span></p><blockquote><p>Claim 1: &nbsp;No leading&nbsp;welfarist&nbsp;axiology can avoid the&nbsp;VRC.</p><p>Claim 2: &nbsp;No&nbsp;other&nbsp;welfarist axiology in the literature can avoid the XVRC.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxkzsf3y73ug\"><sup><a href=\"#fnxkzsf3y73ug\">[3]</a></sup></span></p><p>Claim 3: &nbsp;The&nbsp;XVRC is just as repugnant as the VRC.</p></blockquote><p>The authors conclude that:</p><blockquote><p>Repugnant&nbsp;implications are an inevitable feature of any plausible axiology. If repugnance cannot be avoided, then it should not be. We believe this should be among the guiding insights for the next generation of work in value theory.</p></blockquote><h2><strong>Claim 1 does not apply to minimalist axiologies</strong></h2><p>The scope of Claim 1 (\u201cNo leading welfarist axiology can avoid the VRC\u201d) is limited to \u2018leading\u2019 welfarist axiologies, that is to views that, according to the authors, are commonly-held in the axiological literature (p. 8).</p><p>These do not cover&nbsp;<a href=\"https://forum.effectivealtruism.org/s/MBadsrYLmzLNmYjaj\"><u>minimalist axiologies</u></a>, although axiologies that are essentially minimalist have been defended, for instance, by Schopenhauer (<a href=\"https://www.gutenberg.org/files/40868/40868-h/40868-h.html#toc57\"><u>1818</u></a>/<a href=\"https://www.gutenberg.org/files/40868/40868-h/40868-h.html#toc57\"><u>1819</u></a>,&nbsp;<a href=\"https://en.wikisource.org/wiki/Studies_in_Pessimism/On_the_Sufferings_of_the_World\"><u>1851</u></a>), Wolf (<a href=\"https://www.jstor.org/stable/4320653\"><u>1996</u></a>,&nbsp;<a href=\"https://web.archive.org/web/20190410204154/https://jwcwolf.public.iastate.edu/Papers/JUPE.HTM\"><u>1997</u></a>,&nbsp;<a href=\"https://www.academia.edu/2083349/O_Repugnance_Where_Is_Thy_Sting_Clark_Wolf_2004_\"><u>2004</u></a>), Fehige (<a href=\"https://www.fehige.info/pdf/A_Pareto_Principle_for_Possible_People.pdf\"><u>1998</u></a>), Breyer (<a href=\"https://blogs.dickinson.edu/buddhistethics/files/2015/12/Breyer-Axiology-final.pdf\"><u>2015</u></a>), and Knutsson (<a href=\"https://www.tandfonline.com/doi/full/10.1080/0020174X.2019.1658631\"><u>2021b</u></a>, \u201caxiological claim\u201d).</p><p>To the extent that the VRC seems repugnant, it is worth noting that all minimalist axiologies&nbsp;<a href=\"https://forum.effectivealtruism.org/s/MBadsrYLmzLNmYjaj/p/5gPubzt79QsmRJZnL#The_Very_Repugnant_Conclusion\"><u>do avoid the VRC</u></a>, and can do so neatly without relying on arbitrary or ad hoc assumptions.</p><h2><strong>Claim 2 requires that we extend the XVRC</strong></h2><p>Claim 2 (\u201cNo other welfarist axiology in the literature can avoid the XVRC\u201d) is not straightforward to evaluate, because the original XVRC, as the authors define it, applies strictly only to views that make the assumption of independently aggregable positive utility (cf.&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Appendix_B__Rollercoaster_lives_and_the_Extended_Very_Repugnant_Conclusion__XVRC_\">Appendix B</a>).</p><p>This assumption is not made by minimalist welfarist axiologies, such as&nbsp;<a href=\"https://www.fehige.info/pdf/A_Pareto_Principle_for_Possible_People.pdf\"><u>antifrustrationism</u></a>,&nbsp;<a href=\"https://longtermrisk.org/tranquilism/\"><u>tranquilism</u></a>, and some types of&nbsp;<a href=\"https://centerforreducingsuffering.org/point-by-point-critique-of-why-im-not-a-negative-utilitarian/\"><u>negative</u></a>&nbsp;<a href=\"https://www.utilitarianism.com/nu/nufaq\"><u>utilitarianism</u></a>.</p><p>Yet by extending the original definition of the XVRC, we can construct minimalist XVRCs. This will be done in Section 2. After that, we can evaluate Claim 3 (\u201cThe XVRC is just as repugnant as the VRC\u201d) for minimalist views.</p><h2><strong>Claim 3 requires comparisons</strong></h2><p>If Claim 3 were true not only for offsetting but also for minimalist views, that would support the authors\u2019 conclusion that repugnant implications are inevitable.</p><p>Yet is it true? That is, are minimalist XVRCs just as repugnant as the VRC? Settling this question requires that we directly compare minimalist XVRCs against the VRC.</p><h3><strong>Overview&nbsp;of this essay</strong></h3><p><strong>Section 2</strong>&nbsp;illustrates&nbsp;comparable XVRCs&nbsp;for offsetting and minimalist views. The illustrations are categorized into three separate subsections depending on the kind of the views in question:</p><ol><li><a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Archimedean_views___Quantity_can_always_substitute_for_quality__\">Archimedean</a>&nbsp;views,</li><li><a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Lexical_views___Some_qualities_get_categorical_priority__\">lexical</a>&nbsp;views <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#With_sharp_thresholds\">with sharp thresholds</a>, and</li><li>lexical views <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Without_sharp_thresholds\">without sharp thresholds</a>.</li></ol><p><strong>Section 3</strong>&nbsp;unpacks what <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#3__Sources_of_repugnance\">sources of repugnance</a>&nbsp;are present in the different XVRCs, and why I exclude the element of <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Non_creation_\">non-creation</a>&nbsp;as non-repugnant.</p><p><strong>Section 4</strong>&nbsp;evaluates the <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#4__Comparative_repugnance\">comparative repugnance</a>&nbsp;of the offsetting and minimalist XVRCs within&nbsp;each of the three categories of views.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkhmj5l3z09a\"><sup><a href=\"#fnkhmj5l3z09a\">[4]</a></sup></span></p><p>Additionally, Section 4 explains how (at least some) minimalist views face XVRCs that are not as repugnant as the original VRC, which implies that Claim 3&nbsp;(\u201cThe XVRC is just as repugnant as the VRC\u201d) does not hold for those minimalist views.</p><h1><strong>2. Comparable XVRCs for offsetting and minimalist views</strong></h1><h2><strong>Archimedean views (\u201cQuantity can always substitute for quality\u201d)</strong></h2><p>Let us look at comparable XVRCs for&nbsp;<a href=\"https://philpapers.org/rec/THOADF-4\"><u>Archimedean</u></a> views. (Archimedean views roughly say that \u201cquantity can always substitute for quality\u201d, such that, for example, a sufficient number of minor pains can always be added up to be worse than a single instance of extreme pain.)</p><p>Figure 4 illustrates the <strong>original XVRC</strong>&nbsp;for Archimedean offsetting views, which goes roughly like this&nbsp;(cf. Budolfson &amp; Spears, 2018, p. 19):</p><blockquote><p>Rather than adding arbitrarily many lives with arbitrarily high welfare, it is better to add arbitrarily many arbitrarily negative lives and have each life in a sufficiently large base population receive an arbitrarily small quantity (<i>\u03b5</i>) of <strong>positive</strong>&nbsp;<strong>welfare</strong>&nbsp;(an <i>\u03b5</i>-change).</p></blockquote><figure class=\"image image_resized\" style=\"width:624px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FEJLFr5ef82FSY8vr/v9uuunao5mi5jrxq8aug\" alt=\"Figure 4. An XVRC&nbsp;for Archimedean offsetting views.\"><figcaption><i><strong>Figure 4</strong>. An XVRC&nbsp;for Archimedean </i><a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#2_5_Comparative_theoretical_implications_of_minimalist_and_offsetting_views\"><i><u>offsetting views</u></i></a><i>.</i></figcaption></figure><p>A special case of the Archimedean offsetting XVRC is \u201c<a href=\"https://centerforreducingsuffering.org/comparing-repugnant-conclusion#The_corresponding_implication_of_symmetric_views_is_more_repugnant\"><u>Creating hell to please the blissful</u></a>\u201d, in which every life in the base population is brought from a very high welfare to an even higher welfare at the cost of adding maximally bad lives (Figure 5).</p><figure class=\"image image_resized\" style=\"width:624px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FEJLFr5ef82FSY8vr/gp1gx6bhg7stuoknwtov\" alt=\"Figure 5. Another XVRC for Archimedean offsetting views (\u201cCreating hell to please the blissful\u201d).\"><figcaption><i><strong>Figure 5</strong>. Another XVRC for Archimedean offsetting views (\u201cCreating hell to please the blissful\u201d).</i></figcaption></figure><p>In the case of minimalist welfarist axiologies, \u2018welfare\u2019 cannot refer to independently aggregable&nbsp;<strong>positive</strong>&nbsp;<strong>utility</strong>. Instead, minimalist views construe welfare as the absence of intrinsically problematic features, such as of \u2018<a href=\"https://www.fehige.info/pdf/A_Pareto_Principle_for_Possible_People.pdf\"><u>frustration</u></a>\u2019, \u2018<a href=\"https://longtermrisk.org/tranquilism/#22_Cravings_Negative_states\"><u>craving</u></a>\u2019, or \u2018<a href=\"https://www.utilitarianism.com/nu/nufaq#2.2\"><u>discontentment</u></a>\u2019.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjfdjw1hgsu\"><sup><a href=\"#fnjfdjw1hgsu\">[5]</a></sup></span></p><p>Yet we can nonetheless construct an XVRC for Archimedean minimalist views by defining the arbitrarily small changes (<i>\u03b5</i>-changes) more generally as <i>\u03b5</i>-sized&nbsp;<strong>improvements</strong>&nbsp;in welfare.</p><p>Thus, an Archimedean <strong>minimalist XVRC</strong>&nbsp;could go like this&nbsp;(Figure 6):</p><blockquote><p>It is a net benefit to add arbitrarily many arbitrarily negative lives so as to barely reduce the suffering of each life in a sufficiently large base population.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8rpzhf4cv76\"><sup><a href=\"#fn8rpzhf4cv76\">[6]</a></sup></span></p></blockquote><figure class=\"image image_resized\" style=\"width:624px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FEJLFr5ef82FSY8vr/itjfowyitzyflkm56t0u\" alt=\"Figure 6. An XVRC&nbsp;for Archimedean minimalist views.\"><figcaption><i><strong>Figure 6</strong>. An XVRC&nbsp;for Archimedean minimalist views.</i></figcaption></figure><p>Figure 7 illustrates another Archimedean minimalist XVRC, which is basically what is known as the Reverse Repugnant Conclusion (cf. Carlson,&nbsp;<a href=\"https://doi.org/10.1017/S0266267100003862\"><u>1998</u></a>, p. 297; Mulgan,&nbsp;<a href=\"https://doi.org/10.1017/S0953820800003654\"><u>2002</u></a>).</p><figure class=\"image image_resized\" style=\"width:624px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FEJLFr5ef82FSY8vr/cjfbrez31v0h4nauoc3o\" alt=\"Figure 7. Another XVRC&nbsp;for Archimedean minimalist views (the Reverse Repugnant Conclusion).  [7]\"><figcaption><i><strong>Figure 7</strong>. Another XVRC&nbsp;for Archimedean minimalist views (the Reverse Repugnant Conclusion).</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefte7m4ia3dtb\"><sup><a href=\"#fnte7m4ia3dtb\">[7]</a></sup></span></figcaption></figure><h2><strong>Lexical views (\u201cSome qualities get categorical priority\u201d)</strong></h2><p>Let us now look at comparable XVRCs within a prominent class of non-Archimedean views, namely what are known as <a href=\"https://www.simonknutsson.com/value-lexicality/\"><strong><u>lexical</u></strong></a>&nbsp;views.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgnp00em2hyi\"><sup><a href=\"#fngnp00em2hyi\">[8]</a></sup></span>&nbsp;Lexical views deny that \u201cquantity can always substitute for quality\u201d; instead, they assign categorical priority to some qualities relative to others.</p><p>Specifically, lexical&nbsp;<strong>minimalist</strong> views entail lexicality&nbsp;<a href=\"https://www.simonknutsson.com/value-lexicality#Lexicality_between_bads\"><u>between bads</u></a>, such as by (all else equal) prioritizing the reduction of unbearable suffering over any mild discomfort (cf. Vinding,&nbsp;<a href=\"https://centerforreducingsuffering.org/lexicality-a-variety-of-possible-views/\"><u>2022a</u></a>). Additionally, lexical&nbsp;<strong>offsetting</strong> views entail lexicality&nbsp;<a href=\"https://www.simonknutsson.com/value-lexicality#Lexicality_between_goods\"><u>between goods</u></a> (of e.g. higher pleasures over lower pleasures),<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefx6ltbu3w7d\"><sup><a href=\"#fnx6ltbu3w7d\">[9]</a></sup></span>&nbsp;or&nbsp;between goods and bads (of e.g. higher pleasures over mild discomfort).</p><p>Do lexical views face&nbsp;XVRCs? Notably, lexical views may <a href=\"https://centerforreducingsuffering.org/lexicality-a-variety-of-possible-views#Representing_disvalue_with_real_numbers_An_unexamined_assumption\"><u>question</u></a>&nbsp;the assumption of representing welfare with a single real number to begin with. Therefore, lexical views may reject the formal framework of the Archimedean XVRC, whose definition entails arbitrarily small changes (<i>\u03b5</i>-changes) to the aggregate welfare (a real number) of each life in the base population.</p><p>Yet, even if we reject the Archimedean framework, we can still reinterpret the XVRC in order to construct analogous <strong>lexical</strong>&nbsp;<strong>XVRCs</strong>&nbsp;(for both minimalist and offsetting lexical views). Let us first look at such XVRCs for lexical views with sharp thresholds, and then for lexical views without sharp thresholds.</p><h3><strong>With sharp thresholds</strong></h3><p>Consider a lexical <strong>minimalist</strong>&nbsp;view with a sharp threshold. For instance, one may hold that some sentient minds have a sharp breaking point at which suffering becomes unbearable, and that the passing of this point is categorically worth avoiding more than any amount of \u201cbending without breaking\u201d.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcbf5uto83ru\"><sup><a href=\"#fncbf5uto83ru\">[10]</a></sup></span></p><p>Figure 8 illustrates an XVRC for such a view:</p><blockquote><p>It is a net benefit to add arbitrarily many non-lexically bad states (of e.g. barely bearable suffering) as long as we reduce the number of lexically bad states (of e.g. unbearable suffering).</p></blockquote><figure class=\"image image_resized\" style=\"width:624px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FEJLFr5ef82FSY8vr/o6qj36minqlhmittcsaz\" alt=\"Figure 8.&nbsp;An XVRC&nbsp;for lexical minimalist views with a sharp threshold.\"><figcaption><i><strong>Figure 8</strong>.<strong>&nbsp;</strong>An XVRC&nbsp;for lexical minimalist views with a sharp threshold.</i></figcaption></figure><p>A comparable lexical <strong>offsetting</strong>&nbsp;view might entail all of the following claims:</p><ol><li>There is a lexical threshold between some goods (e.g. higher and lower pleasures).</li><li>There is a lexical threshold between some bads (e.g. bearable and unbearable suffering).</li><li>Non-lexical goods (e.g. lower pleasures) cannot compensate for lexically bad states.</li><li>Some number of lexically good states can compensate&nbsp;for a lexically bad state.</li></ol><p>Figure 9 illustrates an XVRC for such a view:</p><blockquote><p>It is a net benefit to add arbitrarily many arbitrarily negative lives (that entail lexically bad states) so as to replace, within each life in a sufficiently large base population, a just barely not lexically good state with a lexically good state.</p></blockquote><figure class=\"image image_resized\" style=\"width:624px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FEJLFr5ef82FSY8vr/wy2wn0oggnemhiyzursj\" alt=\"Figure 9. An XVRC&nbsp;for lexical offsetting views with sharp thresholds.  [11]\"><figcaption><i><strong>Figure 9</strong>. An XVRC&nbsp;for lexical offsetting views with sharp thresholds.</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref73yt9aqv9tv\"><sup><a href=\"#fn73yt9aqv9tv\">[11]</a></sup></span></figcaption></figure><h3><strong>Without sharp thresholds</strong></h3><p>Finally, it has been argued that lexical views need not be sharp like the ones that were abstractly sketched in the previous subsection. After all, perhaps a more plausible lexical view would hold that (e.g.) unbearableness comes in <a href=\"https://centerforreducingsuffering.org/research/clarifying-lexical-thresholds#Lexical_views_based_on_consent\"><u>degrees</u></a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4drl0slweyh\"><sup><a href=\"#fn4drl0slweyh\">[12]</a></sup></span></p><p>A \u201cnon-sharp\u201d lexical threshold could be a <strong>range</strong>&nbsp;\u2014 e.g. in the intensity of suffering \u2014 between which the suffering becomes lexically bad relative to suffering above the range. This would imply that no duration of suffering above the range (e.g. \u201cwholly bearable suffering\u201d) can be worse than a single instance of suffering below the range (e.g. \u201cwholly unbearable suffering\u201d).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb80g8wajhno\"><sup><a href=\"#fnb80g8wajhno\">[13]</a></sup></span></p><p>Figure 10 illustrates a non-sharp lexical <strong>minimalist</strong>&nbsp;XVRC:</p><blockquote><p>It is a net benefit to add arbitrarily many non-lexically bad states (e.g. wholly bearable suffering) as long as we reduce the number of lexically bad states (e.g. wholly unbearable suffering).</p></blockquote><figure class=\"image image_resized\" style=\"width:624px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FEJLFr5ef82FSY8vr/erialezbcctcl34fki9l\" alt=\"Figure 10. An XVRC&nbsp;for lexical minimalist views without sharp thresholds.\"><figcaption><i><strong>Figure 10</strong>. An XVRC&nbsp;for lexical minimalist views without sharp thresholds.</i></figcaption></figure><p>Figure 11 illustrates a non-sharp lexical <strong>offsetting</strong>&nbsp;XVRC (based on the same four assumptions made in the previous offsetting view).</p><blockquote><p>It is a net benefit to add an arbitrarily large number of arbitrarily negative lives (that entail lexically bad states) so as to add one lexically good state to each life in a sufficiently large base population.</p></blockquote><figure class=\"image image_resized\" style=\"width:624px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/FEJLFr5ef82FSY8vr/rmou2qyjivcjbnj9osmd\" alt=\"Figure 11. An XVRC&nbsp;for lexical offsetting views without sharp thresholds.\"><figcaption><i><strong>Figure 11</strong>. An XVRC&nbsp;for lexical offsetting views without sharp thresholds.</i></figcaption></figure><h1><strong>3. Sources of repugnance</strong></h1><p><a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#4__Comparative_repugnance\">Section 4</a>&nbsp;will evaluate the comparative repugnance of the above XVRCs and the original VRC.</p><p>However, let us first unpack what sources of repugnance are present in the different XVRCs.</p><h2><strong>Creating non-relieving goods for some at the price of unbearable suffering for others</strong></h2><p>Only the offsetting XVRCs entail the creation of non-relieving goods for some, at the price of unbearable suffering for others.</p><p>By contrast, the \u201c<i>\u03b5</i>-changes\u201d in&nbsp;the minimalist XVRCs are arguably more plausible and less frivolous, because they are aimed at the reduction of suffering rather than at the increase of non-relieving pleasure \u2014 pleasure that has no&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/t3St6Fz4DmHtKfgqm/positive-roles-of-life-and-experience-in-suffering-focused#4_1_Wellbeing_as_a_resource\"><u>positive roles</u></a> for relieving anyone\u2019s burden (cf. Vinding,&nbsp;<a href=\"https://centerforreducingsuffering.org/research/on-purported-positive-goods-outweighing-suffering/\"><u>2020b</u></a>;&nbsp;<a href=\"https://magnusvinding.files.wordpress.com/2020/05/suffering-focused-ethics.pdf\"><u>2020c</u></a>, ch. 3).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl1eekwtmct\"><sup><a href=\"#fnl1eekwtmct\">[14]</a></sup></span></p><h2><strong>Enabling rollercoaster lives that all contain unbearable suffering</strong></h2><p>Only offsetting views allow the larger populations to become rollercoaster lives that all contain unbearable suffering (<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#1__Are_repugnant_implications_inevitable_\">Figure 2</a>). And Archimedean offsetting views further allow the larger populations to become intrapersonal VRC lives (Figure 3).</p><p>By contrast, minimalist views reject the aggregative framework that enables the rollercoaster interpretation in the first place. Consequently, minimalist views entail only the non-rollercoaster versions of the minimalist XVRCs&nbsp;above, whereas the offsetting views entail those same conclusions <i>plus</i>&nbsp;their rollercoaster versions.</p><h2><strong>Making seemingly trivial changes at the price of unbearable suffering</strong></h2><p>Budolfson and Spears (<a href=\"https://web.archive.org/web/20220614105405/https://scholar.princeton.edu/sites/default/files/cfi/files/budolfson_spears_2018_repugnant_cfi.pdf\"><u>2018</u></a>) seem to attribute repugnance exclusively to the unbounded aggregation of arbitrarily tiny changes:</p><blockquote><p>\u201cWe note that a common theme emerges, which is that any axiology that aggregates over unbounded spaces will have repugnant implications. This is the fundamental mechanism that our proofs exploit.\u201d (p. 2) \u201cBecause all plausible axiologies permit aggregation over unbounded spaces, this means that all plausible axiologies are exposed to repugnant conclusions\u201d (p. 30)</p></blockquote><p>Clearly such aggregation is a potential source of repugnance in at least the Archimedean XVRCs for both offsetting and minimalist views. Additionally, perhaps an atom of a lexical offsetting good \u2014 such as the briefest possible experience of a non-relieving higher pleasure (the authors mention a tiny duration of Mozart) \u2014&nbsp;is intuitively still roughly as trivial as is any other instance of a non-relieving good.</p><p>However, one could reasonably argue that the following three conclusions no longer apply in the case of lexical minimalist views:</p><blockquote><p>1: \u201cEither&nbsp;something that seems important will be outweighed by an unbounded number of initially unimportant-seeming matters, something that initially seems unimportant will unduly shape the outcome, or both.\u201d (pp. 30\u201331)</p></blockquote><p>This statement does not seem to hold for lexical views. After all, lexical views would not allow \u201csomething that seems important\u201d to be outweighed by unimportant-seeming matters, nor would they allow something that initially seems unimportant to unduly shape the outcome. Specifically, extreme suffering does not seem unimportant, even if it only lasts for a short duration&nbsp;(Vinding, <a href=\"https://magnusvinding.files.wordpress.com/2020/05/suffering-focused-ethics.pdf\"><u>2020c</u></a>, sec. 8.12).</p><blockquote><p>2: \u201cSuch seemingly-disparate axiologies as maximin and classical total utilitarianism have in common that they are both prepared to accept the cost of many arbitrarily negative lives and forgo the benefits of many arbitrarily positive lives, for the right arrangement of infinitesimal tweaks.\u201d (p. 31)</p></blockquote><p>Lexical minimalist views (uniquely) do not permit the addition of <i>arbitrarily</i>&nbsp;negative lives (nor rollercoaster lives that contain arbitrarily bad suffering), because they require that we overall reduce lexically bad states. Additionally, to \u201cforgo the benefits of many arbitrarily positive lives\u201d need&nbsp;not be a source of repugnance (a point I unpack in the next subsection).</p><blockquote><p>3: \u201c[Our argument] considers the possibility that better-off people are qualitatively different [and] considers the possibility that higher pleasures are qualitatively different. In general, because lexical views still must aggregate across people, they remain subject to repugnance.\u201d&nbsp;(p. 34)</p></blockquote><p>As noted, perhaps repugnant implications are inevitable for lexical offsetting views (cf. adding tiny durations of non-relieving lexical goods, however they are defined, at the price of unbearable suffering). Yet the authors do not seem to discuss lexical views that give overriding priority to the prevention of extreme bads. And such views are arguably uniquely resistant&nbsp;to this \u201ctrivial changes\u201d source of repugnance.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefd463r4xwsf8\"><sup><a href=\"#fnd463r4xwsf8\">[15]</a></sup></span></p><h2><strong>Non-creation?</strong></h2><p>The three sources of repugnance covered in the last three subsections each entail the increase of unbearable suffering for the sake of changes that seem relatively frivolous or trivial in comparison. The original VRC and XVRC additionally entail what might seem like a fourth source of repugnance, namely the non-creation of high-welfare lives whose existence would purportedly be a great benefit for their own sake. (Let us call this the \u201c<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#2_2_The_reversal_test__Creation_at_the_moment_of_non_cessation\"><u>non-creation</u></a> of happy isolated lives\u201d, which I will shortly unpack in more detail.)</p><p>A key thing to note when evaluating non-creation as a potential source of repugnance is that we need to carefully isolate our intuitions on this question \u2014 i.e. on non-creation\u2019s independent repugnance,&nbsp;<i>all else equal</i> \u2014 from the influence of various factors that are actually external to the question itself. And when we have done so (as in my&nbsp;<a href=\"http://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives\"><u>previous</u></a>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism\"><u>essays</u></a>, or in the thought experiment in Vinding,&nbsp;<a href=\"https://centerforreducingsuffering.org/a-thought-experiment-that-questions-the-moral-importance-of-creating-happy-lives/\"><u>2022f</u></a>), I maintain that non-creation is not an independent source of repugnance.</p><p>Let us briefly unpack some of the reasons why non-creation is plausibly non-repugnant:</p><ol><li>How repugnant is the non-creation of lives that are described as \u201cawesome\u201d, \u201cflourishing\u201d, or \u201c<a href=\"https://forum.effectivealtruism.org/posts/vZ4kB8gpvkfHLfz8d/critique-of-macaskill-s-is-it-good-to-make-happy-people#fniv5toyme8o\"><u>full of love and accomplishments</u></a>\u201d,&nbsp;<a href=\"https://forum.effectivealtruism.org/s/MBadsrYLmzLNmYjaj/p/5gPubzt79QsmRJZnL#4__What_are_we_comparing_when_we_make_the_assumption_of__all_else_being_equal__\"><u>all else equal</u></a>? Such framings of the question are quite common, which is unfortunate given that they may cause our evaluation to become strongly biased in favor of creation. After all, our practical intuitions easily associate those descriptions with lives that play&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/t3St6Fz4DmHtKfgqm/positive-roles-of-life-and-experience-in-suffering-focused\"><u>positive roles</u></a> for others (even on purely minimalist views of value), whereas standard population axiology counterintuitively requires that we ignore all such roles.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1swkmkb08x8\"><sup><a href=\"#fn1swkmkb08x8\">[16]</a></sup></span></li><li>To&nbsp;properly respect the \u2018all else equal\u2019 assumption, we should therefore explicitly highlight that the lives in question are forever causally isolated lives that never affect any other beings in any way (e.g. that they are happy isolated matrix lives, dwellers of their closed island worlds, or the like, which clearly make no difference for others). And to <a href=\"https://forum.effectivealtruism.org/s/MBadsrYLmzLNmYjaj/p/JnHeeTGAohMFxNbGK#2_4_Minimalist_creation_for_extrinsic_reasons\"><u>further remove</u></a> our potentially self-related concerns from the picture, we should imagine that no one will know whether we endorsed the creation or non-creation of those happy isolated lives, and that even we will have our memory wiped of the decision immediately after we make it.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefucimueqon7k\"><sup><a href=\"#fnucimueqon7k\">[17]</a></sup></span></li><li>For&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#1__Overview_and_scope\"><u>experientialist consequentialists</u></a>, the question of whether non-creation is repugnant becomes a question that arguably requires a thorough phenomenological&nbsp;<a href=\"https://centerforreducingsuffering.org/phenomenological-argument/#Introspection\"><u>search</u></a>, namely a search for non-relieving goods that constitute a positive counterpart to suffering. Yet such a counterpart plausibly does not exist (cf. Vinding,&nbsp;<a href=\"https://centerforreducingsuffering.org/phenomenological-argument/\"><u>2022c</u></a>; Knutsson,&nbsp;<a href=\"https://www.simonknutsson.com/undisturbedness-as-the-hedonic-ceiling/\"><u>2022</u></a>; see also Gloor, 2017, sec.&nbsp;<a href=\"https://longtermrisk.org/tranquilism/#21_Contentment_as_the_perfect_state\"><u>2.1</u></a>; Sherman,&nbsp;<a href=\"https://ore.exeter.ac.uk/repository/bitstream/handle/10871/32103/ShermanT.pdf\"><u>2017</u></a>, pp. 103\u2013107).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref16h38rbmo0e\"><sup><a href=\"#fn16h38rbmo0e\">[18]</a></sup></span></li><li>For preference-based views, it likewise makes sense to think of preference satisfaction as an inherently asymmetric endeavor. Singer (<a href=\"https://www.nybooks.com/articles/1980/08/14/right-to-life/\"><u>1980</u></a>): \u201cThe creation of preferences which we then satisfy gains us nothing. We can think of the creation of the unsatisfied preferences as putting a debit in the moral ledger which satisfying them merely cancels out.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefu5k9q8p12ve\"><sup><a href=\"#fnu5k9q8p12ve\">[19]</a></sup></span>&nbsp;Fehige (<a href=\"https://www.fehige.info/pdf/A_Pareto_Principle_for_Possible_People.pdf\"><u>1998</u></a>): \u201cWe have obligations to make preferrers satisfied, but no obligations to make satisfied preferrers. \u2026 Maximizers of preference satisfaction should instead call themselves minimizers of preference frustration.\u201d See also DiGiovanni (<a href=\"https://tobeanythingatallblog.wordpress.com/2021/01/10/tranquilism-respects-individual-desires/\"><u>2021</u></a>).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdpcsqy9ch3o\"><sup><a href=\"#fndpcsqy9ch3o\">[20]</a></sup></span></li></ol><h1><strong>4. Comparative repugnance</strong></h1><p>Let us now evaluate the comparative repugnance of the XVRCs reviewed above and the original VRC. (The reader may find it useful to open a <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#2__Comparable_XVRCs_for_offsetting_and_minimalist_views\">duplicate tab</a>&nbsp;so as to review Figures 4\u201311 together with my following commentary on them.)</p><p>Tables 1\u20133 show how the minimalist XVRCs explored above are a proper subset of the XVRCs that are implied by the corresponding offsetting views explored above.&nbsp;Specifically, the offsetting views entail the minimalist implications, their (arguably more repugnant) rollercoaster or intrapersonal VRC versions,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzend1s8hofm\"><sup><a href=\"#fnzend1s8hofm\">[21]</a></sup></span>&nbsp;and the interpersonal offsetting implications.</p><p>Notably, only the offsetting implications entail all three of the sources&nbsp;of repugnance that were considered in Section 3 (i.e. creating <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Creating_non_relieving_goods_for_some_at_the_price_of_unbearable_suffering_for_others\">non-relieving</a>&nbsp;goods at the price of others\u2019 suffering, <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Enabling_rollercoaster_lives_that_all_contain_unbearable_suffering\">rollercoaster</a>&nbsp;lives, and seemingly <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Making_seemingly_trivial_changes_at_the_price_of_unbearable_suffering\">trivial changes</a>&nbsp;at the price of unbearable suffering). For reasons unpacked in the section on <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Non_creation_\">non-creation</a>, I do not count non-creation as a source of repugnance below.</p><p><i><strong>Table 1</strong>. Implications of the Archimedean views.</i></p><figure class=\"table\"><table><thead><tr><th style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right;vertical-align:bottom\"><p>View</p></th><th style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:bottom\" colspan=\"2\"><p><a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Archimedean_views___Quantity_can_always_substitute_for_quality__\">Archimedean</a></p></th></tr><tr><th style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">Implication</th><th style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>Offsetting</p></th><th style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>Minimalist</p></th></tr></thead><tbody><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p><i>Very Repugnant Conclusion (Fig 1)</i></p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>rollercoaster version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>intrapersonal VRC version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p><i>Archimedean offsetting XVRC (Fig 4)</i></p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>rollercoaster version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>intrapersonal VRC version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p><i>\u201cCreating hell to please the blissful\u201d (Fig 5)</i></p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>rollercoaster version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>intrapersonal VRC version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p><i>Archimedean minimalist XVRC (Fig 6)</i></p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>rollercoaster version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>intrapersonal VRC version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p><i>Reverse Repugnant Conclusion (Fig 7)</i></p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>rollercoaster version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>intrapersonal VRC version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr></tbody></table></figure><p>Among the Archimedean implications, the offsetting XVRCs (Figures 4\u20135) entail more sources of repugnance than do the minimalist XVRCs (Figures 6\u20137). Specifically, the offsetting XVRCs entail all the same sources of repugnance as does the original VRC, with arguably no redeeming (\u201canti-repugnant\u201d) elements. We can thus agree with Budolfson and Spears\u2019 (<a href=\"https://web.archive.org/web/20220614105405/https://scholar.princeton.edu/sites/default/files/cfi/files/budolfson_spears_2018_repugnant_cfi.pdf\"><u>2018</u></a>) assessment that the offsetting XVRCs are just as repugnant as the VRC (i.e. Claim 3).</p><p>By contrast, the minimalist XVRCs lack the repugnance of creating non-relieving goods for some at the price of unbearable suffering for others, and the repugnance of rollercoaster&nbsp;or intrapersonal VRC lives that all contain unbearable suffering. Therefore, the repugnance of the minimalist XVRCs relative to the VRC depends on whether the former entail any additional sources of repugnance that are not shared by the VRC; and it appears that they do not&nbsp;(as argued in the previous section on non-creation), which would imply that Claim 3 does not hold for Archimedean minimalist views.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2pabe2fsbcu\"><sup><a href=\"#fn2pabe2fsbcu\">[22]</a></sup></span></p><p>(For more on \u201cimperfect paradise\u201d cases, see <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Appendix_A__Responses_to_the__imperfect_paradise__cases\">Appendix A</a>.)</p><p><i><strong>Table 2</strong>. Implications of the lexical views with sharp thresholds.</i></p><figure class=\"table\"><table><thead><tr><th style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right;vertical-align:bottom\"><p>View</p></th><th style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:bottom\" colspan=\"2\"><p><a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Lexical_views___Some_qualities_get_categorical_priority__\">Lexical</a> <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#With_sharp_thresholds\">sharp</a></p></th></tr><tr><th style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">Implication</th><th style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>Offsetting</p></th><th style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>Minimalist</p></th></tr></thead><tbody><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p><i>Lexical sharp minimalist XVRC (Fig 8)</i></p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">x</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>rollercoaster version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p><i>Lexical sharp offsetting XVRC (Fig 9)</i></p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>&nbsp;</p></td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>rollercoaster version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr></tbody></table></figure><p>Among the sharp lexical views, the offsetting XVRC (Figure 9) again entails arguably all the same sources of repugnance as does the original VRC. And only the offsetting view can accept an increase in the number of lexically bad states (such as unbearable suffering), for the sake of producing non-relieving goods.</p><p><i><strong>Table 3</strong>. Implications of the lexical views without sharp thresholds.</i></p><figure class=\"table\"><table><thead><tr><th style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right;vertical-align:bottom\"><p>View</p></th><th style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:bottom\" colspan=\"2\"><p><a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Lexical_views___Some_qualities_get_categorical_priority__\">Lexical</a> <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Without_sharp_thresholds\">non-sharp</a></p></th></tr><tr><th style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\">Implication</th><th style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>Offsetting</p></th><th style=\"border:0.75pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>Minimalist</p></th></tr></thead><tbody><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p><i>Lexical non-sharp minimalist XVRC (Fig 10)</i></p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">x</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>rollercoaster version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p><i>Lexical non-sharp offsetting XVRC (Fig 11)</i></p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>&nbsp;</p></td></tr><tr><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:right\"><p>rollercoaster version</p></td><td style=\"background-color:#f4cccc;border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\"><p>x</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt;text-align:center;vertical-align:top\">&nbsp;</td></tr></tbody></table></figure><p>Finally, the non-sharp lexical minimalist XVRC (Figure 10) entails that no amount of sufficiently mild states of suffering can be worse than unbearable suffering.</p><p>By comparison, the corresponding offsetting view implies not only the same theoretical conclusion (Figure 10), but also the arbitrary increase of unbearable states for the sake of creating purportedly sufficient amounts of non-relieving higher goods (Figure 11). Additionally, the offsetting view again entails rollercoaster implications that would \u201crequire everyone in the chosen population to experience [arbitrarily] terrible suffering\u201d (Budolfson &amp; Spears, <a href=\"https://web.archive.org/web/20220614105405/https://scholar.princeton.edu/sites/default/files/cfi/files/budolfson_spears_2018_repugnant_cfi.pdf\"><u>2018</u></a>, p. 19).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefij4cpe37rz8\"><sup><a href=\"#fnij4cpe37rz8\">[23]</a></sup></span></p><h1><strong>Conclusions</strong></h1><p>To respond to the <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Three_claims\">three claims</a>:</p><blockquote><p>Claim 1: &nbsp;No leading&nbsp;welfarist&nbsp;axiology can avoid the&nbsp;VRC.</p></blockquote><p>Minimalist welfarist axiologies <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Claim_1_does_not_apply_to_minimalist_axiologies\">do avoid</a>&nbsp;the VRC. (And they <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#fnzend1s8hofm\">also avoid</a>&nbsp;the <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#1__Are_repugnant_implications_inevitable_\">rollercoaster</a>&nbsp;form of the original Repugnant Conclusion.)</p><blockquote><p>Claim 2: &nbsp;No&nbsp;other&nbsp;welfarist axiology in the literature can avoid the XVRC.</p></blockquote><p>Minimalist views do entail modified minimalist XVRCs (cf. Figures 6, 7, 8, and 10).</p><blockquote><p>Claim 3: &nbsp;The&nbsp;XVRC is just as repugnant as the VRC.</p></blockquote><p>This seems true for offsetting views. Yet the minimalist XVRCs are considerably less repugnant than the VRC.</p><p>In particular, at least the Archimedean minimalist and the non-sharp lexical minimalist XVRCs (Figures 6, 7, and 10) entail fewer <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#3__Sources_of_repugnance\">sources of repugnance</a>&nbsp;than does the VRC, arguably with no additional, greater sources of repugnance.</p><p>Furthermore, the XVRCs generated by minimalist views are <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#4__Comparative_repugnance\">consistently</a>&nbsp;less repugnant than are those&nbsp;generated by the corresponding offsetting views.&nbsp;Minimalist XVRCs thus seem uniquely unrepugnant. This is a strong point in favor of minimalist views over offsetting views in population axiology,&nbsp;regardless of one\u2019s theory of aggregation.</p><h1><strong>Acknowledgments</strong></h1><p>I am grateful for helpful comments by Anthony DiGiovanni, James Faville, Lukas Gloor, Simon Knutsson, Winston Oswald-Drummond, Michael St. Jules, and Magnus Vinding.</p><p>Special thanks to Magnus Vinding for guiding the development of this essay.</p><p>Commenting does not imply endorsement of any of my claims.</p><h1><strong>References</strong></h1><p>Budolfson, M., &amp; Spears, D. (2018). Why the repugnant conclusion is inescapable.&nbsp;<i>Princeton University Climate Futures Initiative working paper</i>.&nbsp;<a href=\"https://web.archive.org/web/20220614105405/https://scholar.princeton.edu/sites/default/files/cfi/files/budolfson_spears_2018_repugnant_cfi.pdf\"><u>Ungated</u></a>.</p><p>Carlson, E. (1998). Mere addition and two trilemmas of population ethics.&nbsp;<i>Economics &amp; Philosophy, 14</i>(2), 283\u2013306.</p><p>Carlson, E. (2007). Higher Values and Non-Archimedean Additivity.&nbsp;<i>Theoria, 73</i>(1), 3\u201327.</p><p>DiGiovanni, A. (2021). Tranquilism Respects Individual Desires.&nbsp;<a href=\"https://tobeanythingatallblog.wordpress.com/2021/01/10/tranquilism-respects-individual-desires/\"><u>Ungated</u></a>.</p><p>Fehige, C. (1998). A Pareto Principle for Possible People. In Fehige, C. &amp; Wessels, U. (eds.),&nbsp;<i>Preferences</i>, 508\u2013543. Walter de Gruyter.&nbsp;<a href=\"https://www.fehige.info/pdf/A_Pareto_Principle_for_Possible_People.pdf\"><u>Ungated</u></a>.</p><p>Gloor, L. (2017). Tranquilism.&nbsp;<a href=\"https://longtermrisk.org/tranquilism/\"><u>Ungated</u></a>.</p><p>Knutsson, S. (2016). Value lexicality.&nbsp;<a href=\"https://www.simonknutsson.com/value-lexicality\"><u>Ungated</u></a>.</p><p>Knutsson, S. (2021a). Many-valued logic and sequence arguments in value theory.&nbsp;<i>Synthese, 199</i>(3), 10793\u201310825.&nbsp;<a href=\"https://link.springer.com/article/10.1007/s11229-021-03268-4\"><u>Ungated</u></a>.</p><p>Knutsson, S. (2021b). The world destruction argument.&nbsp;<i>Inquiry, 64</i>(10), 1004\u20131023.&nbsp;<a href=\"https://www.tandfonline.com/doi/full/10.1080/0020174X.2019.1658631\"><u>Ungated</u></a>;&nbsp;<a href=\"https://www.tandfonline.com/doi/epub/10.1080/0020174X.2019.1658631?needAccess=true\"><u>ePub</u></a>.</p><p>Knutsson, S. (2022). Undisturbedness as the hedonic ceiling.&nbsp;<a href=\"https://www.simonknutsson.com/undisturbedness-as-the-hedonic-ceiling/\"><u>Ungated</u></a>.</p><p>Lazari-Radek, K. &amp; Singer, P. (2017).&nbsp;<i>Utilitarianism: A Very Short Introduction</i>. Oxford University Press.</p><p>Mulgan, T. (2002). The reverse repugnant conclusion.&nbsp;<i>Utilitas, 14</i>(3), 360\u2013364.</p><p>Nebel, J. M. (2022). Totalism without repugnance. In&nbsp;<i>Ethics and Existence: The Legacy of Derek Parfit</i>, 200\u2013231.&nbsp;<a href=\"https://philarchive.org/archive/NEBTWR\"><u>Ungated</u></a>.</p><p>Portmore, D. W. (1999). Does the total principle have any repugnant implications?.&nbsp;<i>Ratio, 12</i>(1), 80\u201398.&nbsp;<a href=\"https://www.repugnant-conclusion.com/portmore-repugnant.pdf\"><u>Ungated</u></a>.</p><p>Sherman, T. (2017). Epicureanism: An Ancient Guide to Modern Wellbeing. MPhil dissertation, University of Exeter.&nbsp;<a href=\"https://ore.exeter.ac.uk/repository/bitstream/handle/10871/32103/ShermanT.pdf\"><u>Ungated</u></a>.</p><p>Singer, P. (1980). Right to Life?&nbsp;<a href=\"https://www.nybooks.com/articles/1980/08/14/right-to-life/\"><u>Ungated</u></a>.</p><p>Spears, D., &amp; Budolfson, M. (2021). Repugnant conclusions.&nbsp;<i>Social choice and welfare, 57</i>(3), 567\u2013588.&nbsp;<a href=\"https://link.springer.com/epdf/10.1007/s00355-021-01321-2?sharing_token=jCstnOCWtaqOvn6H3L72YPe4RwlQNchNByi7wbcMAY7CklqYdA-Y3QhMkm1nkAw6LSzy70KyzpakOptrGSQtd8XyNhHFeW1CRlxK6pk18awtSoRC-cvgrlAYIAEE3Hzji6E1H0xCdM_dQcjmstHanQzsIu2kz_hNdWjXTrJpqzI%3D\"><u>Ungated</u></a>.</p><p>Thomas, T. (2018). Some possibilities in population axiology.&nbsp;<i>Mind, 127</i>(507), 807\u2013832.&nbsp;<a href=\"https://academic.oup.com/mind/article/127/507/807/4781789\"><u>Ungated</u></a>.</p><p>Tomasik, B. (2015). Are Happiness and Suffering Symmetric?&nbsp;<a href=\"https://reducing-suffering.org/happiness-suffering-symmetric/\"><u>Ungated</u></a>.</p><p>Vinding, M. (2020a). Lexical views without abrupt breaks.&nbsp;<a href=\"https://centerforreducingsuffering.org/research/lexical-views-without-abrupt-breaks/\"><u>Ungated</u></a>.</p><p>Vinding, M. (2020b). On purported positive goods \u201coutweighing\u201d suffering.&nbsp;<a href=\"https://centerforreducingsuffering.org/research/on-purported-positive-goods-outweighing-suffering/\"><u>Ungated</u></a>.</p><p>Vinding, M. (2020c).&nbsp;<i>Suffering-Focused Ethics: Defense and Implications</i>. Ratio Ethica.&nbsp;<a href=\"https://magnusvinding.files.wordpress.com/2020/05/suffering-focused-ethics.pdf\"><u>Ungated</u></a>.</p><p>Vinding, M. (2021). Comparing repugnant conclusions: Response to the \u201cnear-perfect paradise vs. small hell\u201d objection.&nbsp;<a href=\"https://centerforreducingsuffering.org/comparing-repugnant-conclusions/\"><u>Ungated</u></a>.</p><p>Vinding, M. (2022a). Lexicality between mild discomfort and unbearable suffering: A variety of possible views.&nbsp;<a href=\"https://centerforreducingsuffering.org/lexicality-a-variety-of-possible-views/\"><u>Ungated</u></a>.</p><p>Vinding, M. (2022b). Lexical priority to extreme suffering \u2014 in practice.&nbsp;<a href=\"https://centerforreducingsuffering.org/lexical-priority-in-practice/\"><u>Ungated</u></a>.</p><p>Vinding, M. (2022c). A phenomenological argument against a positive counterpart to suffering.&nbsp;<a href=\"https://centerforreducingsuffering.org/phenomenological-argument/\"><u>Ungated</u></a>.</p><p>Vinding, M. (2022d). Reply to Gustafsson\u2019s \u201cAgainst Negative Utilitarianism\u201d.&nbsp;<a href=\"https://centerforreducingsuffering.org/reply-to-gustafsson/\"><u>Ungated</u></a>.</p><p>Vinding, M. (2022e). Reply to the scope neglect objection against value lexicality.&nbsp;<a href=\"https://centerforreducingsuffering.org/reply-to-the-scope-neglect-objection-against-value-lexicality/\"><u>Ungated</u></a>.</p><p>Vinding, M. (2022f). A thought experiment that questions the moral importance of creating happy lives.&nbsp;<a href=\"https://centerforreducingsuffering.org/a-thought-experiment-that-questions-the-moral-importance-of-creating-happy-lives/\"><u>Ungated</u></a>.</p><p>Zuber, S. et al. (2021). What should we agree on about the repugnant conclusion?&nbsp;<i>Utilitas, 33</i>(4), 379\u2013383.&nbsp;<a href=\"https://www.cambridge.org/core/services/aop-cambridge-core/content/view/EB52C686BAFEF490CE37043A0A3DD075/S095382082100011Xa.pdf/what_should_we_agree_on_about_the_repugnant_conclusion.pdf\"><u>Ungated</u></a>.</p><h1><strong>Appendix A: Responses to the \u201cimperfect paradise\u201d cases</strong></h1><p>The main text already discusses why the <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Non_creation_\">non-creation</a>&nbsp;of happy isolated lives is plausibly non-repugnant. Yet one might think that my main argument still ignores the strongest cases against minimalist views, such as \u201cimperfect paradise\u201d cases that entail the non-creation of arbitrarily blissful and vast paradises due to their containing more bads&nbsp;than does the alternative outcome (e.g. discussed&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#2_3_Choosing_a_future_with_fewer_problems\"><u>here</u></a> and&nbsp;<a href=\"https://centerforreducingsuffering.org/comparing-repugnant-conclusions/\"><u>here</u></a>).</p><p>In this Appendix, I explain why \u201cimperfect paradise\u201d cases do not seem to constitute an additional argument in favor of offsetting views over minimalist views (beyond what is already implied by our stance on whether non-creation is repugnant). Rather, the question of whether such cases are repugnant seems divisible into two questions, both of which are already discussed in the main text:</p><ol><li>Whether non-creation is repugnant.</li><li>Whether Archimedean aggregation of tiny bads is more plausible than is a lexical priority to some bads such as unbearable suffering.</li></ol><h2><strong>Non-creation revisited</strong></h2><p>Non-creation in \u201cimperfect paradise\u201d cases amounts to the non-creation of arbitrarily many happy lives for the sake of preventing a single episode of slight discomfort. Yet for this scenario to pertain to minimalist views centered on overall negative states, we need to be careful not to interpret this episode of slight discomfort as something that the minimalist views would actually find to be unproblematic, such as a dip in \u201cnon-relieving bliss\u201d from, say, \u201c+100\u201d to \u201c+99\u201d. Instead, we should imagine that this episode of slight discomfort would be experienced as an overall negative \u201c\u22121\u201d episode (cf. Vinding, 2021,&nbsp;<a href=\"https://centerforreducingsuffering.org/comparing-repugnant-conclusions/#What_is_the_bad_in_question\"><u>What is the bad in question?</u></a>).&nbsp;And all else equal, both offsetting and minimalist views already prefer the non-creation of an overall negative \u201c\u22121\u201d episode.</p><p>The remaining question is then whether the suffering, need, or frustration of some experience-moments can be positively counterbalanced or&nbsp;<a href=\"https://centerforreducingsuffering.org/research/on-purported-positive-goods-outweighing-suffering/\"><u>outweighed</u></a> by the addition of subjectively perfect experience-moments elsewhere. Yet this is no different than the question, already considered in the main text, of whether there are positive counterparts to bads such as suffering (cf. points 3 and 4 in the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Non_creation_\">non-creation</a> section).</p><p>Therefore, this case adds nothing substantial to the question of whether non-creation is repugnant. A minimalist could simply respond that the non-creation of even a perfect paradise has no victims (all else equal), unlike the creation of an imperfect paradise in which the purportedly positive moments are allowed to override the unmet needs of the suffering moments (cf. DiGiovanni,&nbsp;<a href=\"https://tobeanythingatallblog.wordpress.com/2021/01/10/tranquilism-respects-individual-desires/\"><u>2021</u></a>).</p><h2><strong>Aggregation revisited</strong></h2><p>In terms of tradeoffs and aggregation, \u201cimperfect paradise\u201d cases raised against minimalist views entail that a very large population of extremely happy lives that each contain a slight bad is worse than a \u201csmall hell\u201d consisting of a much smaller population with maximally hellish lives. Yet the only difference between this case and the question of non-creation itself is that this case adds the Reverse Repugnant Conclusion (Figure 7), which is already implied by both offsetting and minimalist Archimedean views when those bads are compared against each other in isolation.</p><p>Consequently, this case arguably entails no additional element in favor of offsetting views over minimalist views in general. After all, the purported repugnance of the \u201cimperfect paradise\u201d case is already captured by either the repugnance of non-creation in particular, or by the&nbsp;<a href=\"https://centerforreducingsuffering.org/reply-to-gustafsson#Favoring_the_most_plausible_choice_by_accident\"><u>repugnance</u></a> of Archimedean aggregation such that we allow many tiny bads to amount to a worse problem than unbearable suffering.</p><p>Overall, the imperfect paradise cases seem to make no additional difference for the main question concerning the relative repugnance of offsetting versus minimalist views \u2014 regardless of one\u2019s theory of aggregation \u2014 beyond what is already considered in the main text.</p><h1><strong>Appendix B:&nbsp;Rollercoaster lives and the Extended Very Repugnant Conclusion (XVRC)</strong></h1><p><i>(This section&nbsp;is entirely quoted from Budolfson and Spears, </i><a href=\"https://web.archive.org/web/20220614105405/https://scholar.princeton.edu/sites/default/files/cfi/files/budolfson_spears_2018_repugnant_cfi.pdf\"><i>2018</i></a><i>, pp. 18\u201319, only annotated with some square brackets by me.)</i></p><blockquote><p>Let us define an <i>\u03b5</i>-change&nbsp;as a change that makes a difference in either one of these two ways:</p><ul><li><i>\u03b5</i><strong>-change: </strong>Let <i>\u03b5</i>&nbsp;&gt; 0&nbsp;represent any small, positive quantity of well-being. An <i>\u03b5</i>-change either:<ul><li>increases the well-being of one person by <i>\u03b5</i>, or</li><li>adds one new life of well-being <i>\u03b5</i>.</li></ul></li></ul><p>One or more <i>\u03b5</i>-changes can be part of an overall package of changes to a population, but to qualify as an <i>\u03b5</i>-change, a change must be the only change that a particular person receives.</p><p>For example, an <i>\u03b5</i>&nbsp;increase could involve slightly improving a tiny headache. One way to see that [an]&nbsp;<i>\u03b5</i>&nbsp;increase could be very repugnant [on offsetting views] is to recall Portmore\u2019s [<a href=\"https://www.repugnant-conclusion.com/portmore-repugnant.pdf\"><u>1999</u></a>]&nbsp;suggestion that <i>\u03b5</i>&nbsp;lives in the restricted RC could be \u201croller coaster\u201d lives, in which there is much that is wonderful, but also much terribly suffering [sic], such that the good ever-so-slightly outweighs the bad [according to offsetting views]. Here, one admitted possibility is that an <i>\u03b5</i>-change could substantially increase the terrible suffering in a life, and also increase good components; such [an] <i>\u03b5</i>-change is not the only possible <i>\u03b5</i>-change, but it would have the consequence of increasing the total amount of suffering.</p><p>With this definition of<i>&nbsp;\u03b5</i>-change in hand, we can now characterize the</p><ul><li><strong>Extended very repugnant conclusion (XVRC): </strong>For any:<ul><li>Arbitrarily large number of arbitrarily high utility people: <i>n<sup>h</sup></i>&nbsp;&gt; 0, <i>u<sup>h</sup></i>&nbsp;&gt; 0,</li><li>Arbitrarily large number of arbitrarily negative utility people: <i>n<sup>l</sup></i>&nbsp;\u2265 0, <i>u<sup>l</sup></i>&nbsp;&lt; 0, and</li><li>Arbitrarily small positive quantity of well-being: <i>\u03b5</i>&nbsp;&gt; 0,</li></ul></li><li>There exists:<ul><li>A number of <i>\u03b5</i>-changes: <i>n<sup>\u03b5</sup></i>, and</li><li>A (possibly empty) set of base population lives,</li></ul></li><li>such that it is better to both add to the base population the negative-utility lives and cause <i>n<sup>\u03b5</sup></i>&nbsp;<i>\u03b5</i>-changes&nbsp;than to add the high-utility lives.</li></ul><p>The XVRC extension from the VRC retains all of the repugnance of choosing many terrible lives over many wonderful lives for merely <i>\u03b5</i>-benefits to other people. Moreover, if <i>\u03b5</i>-changes are of the \u201croller coaster\u201d form [which would be ruled out by minimalist views], they could increase deep suffering considerably beyond even the arbitrarily many [u &lt; 0] lives, and in fact could require everyone in the chosen population to experience terrible suffering.</p></blockquote><h1><strong>Notes</strong></h1><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntw2ovq8vikt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftw2ovq8vikt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For more on rollercoaster lives, see <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Appendix_B__Rollercoaster_lives_and_the_Extended_Very_Repugnant_Conclusion__XVRC_\">Appendix B</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrkuft17ud0j\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrkuft17ud0j\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Budolfson &amp; Spears (<a href=\"https://web.archive.org/web/20220614105405/https://scholar.princeton.edu/sites/default/files/cfi/files/budolfson_spears_2018_repugnant_cfi.pdf\"><u>2018</u></a>) is a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/bY7BFpx2tyEoGqce3/spears-and-budolfson-repugnant-conclusions\"><u>precursor</u></a> to Spears &amp; Budolfson (<a href=\"https://link.springer.com/epdf/10.1007/s00355-021-01321-2?sharing_token=jCstnOCWtaqOvn6H3L72YPe4RwlQNchNByi7wbcMAY7CklqYdA-Y3QhMkm1nkAw6LSzy70KyzpakOptrGSQtd8XyNhHFeW1CRlxK6pk18awtSoRC-cvgrlAYIAEE3Hzji6E1H0xCdM_dQcjmstHanQzsIu2kz_hNdWjXTrJpqzI%3D\"><u>2021</u></a>); I discuss the former because it is more open-access than the latter.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxkzsf3y73ug\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxkzsf3y73ug\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For an exact definition of the XVRC, see <a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Appendix_B__Rollercoaster_lives_and_the_Extended_Very_Repugnant_Conclusion__XVRC_\">Appendix B</a>. (For the main text, I will use more intuitive and less formalized descriptions of the XVRC, including extended variants of the XVRC.)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkhmj5l3z09a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkhmj5l3z09a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In this essay, I do not focus on the relative plausibility of different views <i>across</i>&nbsp;the three categories of views on aggregation, because my main focus is on the relative plausibility of offsetting versus minimalist views in general, regardless of one\u2019s theory of aggregation.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjfdjw1hgsu\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjfdjw1hgsu\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See also Knutsson (<a href=\"https://www.simonknutsson.com/undisturbedness-as-the-hedonic-ceiling/\"><u>2022</u></a>) and Vinding (<a href=\"https://centerforreducingsuffering.org/phenomenological-argument/\"><u>2022c</u></a>).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8rpzhf4cv76\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8rpzhf4cv76\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Thanks to Michael St. Jules for pointing out what can be seen as XVRCs for minimalist views.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnte7m4ia3dtb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefte7m4ia3dtb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is also known as the Mirrored Repugnant Conclusion, and is analogous to the much-discussed case of \u201c<a href=\"https://www.lesswrong.com/posts/3wYTFWY3LKQCnAptN/torture-vs-dust-specks\"><u>Torture vs. dust specks</u></a>\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngnp00em2hyi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgnp00em2hyi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u201c<a href=\"https://en.wikipedia.org/wiki/Lexicographic_preferences#Etymology\"><u>Lexicographic preferences</u></a>\u201d seem to be named after the logic of alphabetical ordering. Thus, value entities with top priority are prioritized first regardless of how many other value entities there are in the \u201cqueue\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnx6ltbu3w7d\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefx6ltbu3w7d\">^</a></strong></sup></span><div class=\"footnote-content\"><p>A formalism of \u201chigher values\u201d over \u201clower values\u201d is considered in e.g. Carlson,&nbsp;<a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1755-2567.2007.tb01185.x\"><u>2007</u></a>; Thomas,&nbsp;<a href=\"https://academic.oup.com/mind/article/127/507/807/4781789\"><u>2018</u></a>; Nebel,&nbsp;<a href=\"https://philarchive.org/archive/NEBTWR\"><u>2022</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncbf5uto83ru\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcbf5uto83ru\">^</a></strong></sup></span><div class=\"footnote-content\"><p>More concretely, the breaking point may be equated with a supposed point at which the suffering becomes <a href=\"https://reducing-suffering.org/happiness-suffering-symmetric#Consent-based_negative_utilitarianism\"><u>unconsentable</u></a>&nbsp;(Tomasik, 2015). For purely minimalist views, one could imagine this to be suffering so bad that an altruistic agent cannot consent to it even for preventing similar suffering for others.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn73yt9aqv9tv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref73yt9aqv9tv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>A&nbsp;way to make each of these&nbsp;lexical XVRCs&nbsp;entail the \u201carbitrarily small difference\u201d (<i>\u03b5</i>) element of the original XVRC is to make them <strong>probabilistic</strong>,&nbsp;so that the lexically bad state in Figure 8, and the lexically good states in Figure 9, would happen only with probability <i>\u03b5</i>&nbsp;(cf. Budolfson &amp; Spears, <a href=\"https://web.archive.org/web/20220614105405/https://scholar.princeton.edu/sites/default/files/cfi/files/budolfson_spears_2018_repugnant_cfi.pdf\"><u>2018</u></a>, pp. 12\u201314).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4drl0slweyh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4drl0slweyh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Examples of non-sharp lexical views are presented in Vinding (<a href=\"https://centerforreducingsuffering.org/research/lexical-views-without-abrupt-breaks/\"><u>2020a</u></a>,&nbsp;<a href=\"https://centerforreducingsuffering.org/lexicality-a-variety-of-possible-views/\"><u>2022a</u></a>) and Knutsson (<a href=\"https://link.springer.com/article/10.1007/s11229-021-03268-4\"><u>2021a</u></a>).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb80g8wajhno\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb80g8wajhno\">^</a></strong></sup></span><div class=\"footnote-content\"><p>At the same time, inter-intensity comparisons that take place entirely&nbsp;<i>within</i> this range could follow some Archimedean theory of aggregation. Note also that the \u201cnon-sharp\u201d lexical XVRCs below are illustrated using only a single range, even though such views could just as well entail&nbsp;<a href=\"https://centerforreducingsuffering.org/lexicality-a-variety-of-possible-views/#Abrupt_but_gradual_lexical_views\"><u>multiple</u></a> different ranges. (Many interesting details about lexical views are best set aside here, because they apply to both minimalist and offsetting views, and hence those details have limited relevance for my goal of comparing these two classes of views.)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl1eekwtmct\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl1eekwtmct\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For more on how people with minimalist intuitions may conceptualize pleasure and other purportedly positive goods, I recommend Knutsson (<a href=\"https://www.simonknutsson.com/undisturbedness-as-the-hedonic-ceiling/\"><u>2022</u></a>), Vinding (<a href=\"https://centerforreducingsuffering.org/phenomenological-argument/\"><u>2022c</u></a>), Gloor (2017, sec.&nbsp;<a href=\"https://longtermrisk.org/tranquilism/#21_Contentment_as_the_perfect_state\"><u>2.1</u></a>), and Sherman (<a href=\"https://ore.exeter.ac.uk/repository/bitstream/handle/10871/32103/ShermanT.pdf\"><u>2017</u></a>, pp. 103\u2013107). For more on why minimalist consequentialist views need not have as counterintuitive practical implications as they are often claimed to have, see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/t3St6Fz4DmHtKfgqm/positive-roles-of-life-and-experience-in-suffering-focused\"><u>the</u></a>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives\"><u>previous</u></a>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism\"><u>parts</u></a> of the present series.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnd463r4xwsf8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefd463r4xwsf8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>After all, it seems plausible to prioritize the reduction of&nbsp;<i>certainly unbearable</i> suffering over&nbsp;<i>certainly bearable</i> suffering (and over the creation of non-relieving goods) in theory. Additionally, such a priority is, at the practical level, quite compatible with an intuitive and continuous view of aggregation based on the&nbsp;<a href=\"https://centerforreducingsuffering.org/lexical-priority-in-practice/#Ignoring_mild_suffering\"><u>expected</u></a>&nbsp;<a href=\"https://centerforreducingsuffering.org/reply-to-the-scope-neglect-objection-against-value-lexicality/#Theoretical_evaluations_vs_practical_decisions_An_important_distinction\"><u>amount</u></a> of lexically bad states that one\u2019s decisions may influence (Vinding, 2022b, 2022e).</p><p>Thus, \u2018expectational lexical minimalism\u2019 need not be implausible in theory nor in practice, because in practice we always have nontrivial uncertainty about when and where an instance of suffering becomes unbearable. Consequently, we should still be sensitive to variations in the intensity and quantity of suffering-moments. Yet we need not necessarily formalize any part of our decision-making process as a performance of Archimedean aggregation over tiny intrinsic disvalue, as opposed to thinking in terms of&nbsp;<a href=\"https://centerforreducingsuffering.org/lexical-priority-in-practice/#Ignoring_mild_suffering\"><u>continuous probabilities</u></a>, and expected amounts, of lexically bad suffering.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1swkmkb08x8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1swkmkb08x8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Additionally, our evaluation may be&nbsp;<a href=\"https://forum.effectivealtruism.org/s/MBadsrYLmzLNmYjaj/p/JnHeeTGAohMFxNbGK#2_4_Minimalist_creation_for_extrinsic_reasons\"><u>affected</u></a> by factors such as what&nbsp;<i>we</i> would like to witness in the world (e.g. inspiring, beautiful, or epic lives), or by our feeling that even a theoretical acceptance of non-creation would have some undesirable implications for&nbsp;<i>our</i> lives. These, too, are subtle ways of breaking the \u2018all else equal\u2019 assumption. After all, our evaluation of the prospective lives (for their own sake) should be unaffected by the positive roles that the creation or existence of those lives could have for others, including for us.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnucimueqon7k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefucimueqon7k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If the choice starts to feel different when we exclude these factors, this may suggest that the initial framings did indeed evoke factors whose influence was supposed to be ruled out. And this would not be surprising, as our practical intuitions are arguably not adapted to track only the subjective&nbsp;<a href=\"https://forum.effectivealtruism.org/s/MBadsrYLmzLNmYjaj/p/5gPubzt79QsmRJZnL#Contents_versus_roles\"><u>contents</u></a> of lives, but also (and perhaps even mostly) their overall effects on others. Notably, even the standard question of whether it is \u201cgood to create happy people\u201d may still cause a bias in favor of creation, because it may strongly evoke the&nbsp;<a href=\"https://forum.effectivealtruism.org/s/MBadsrYLmzLNmYjaj/p/5gPubzt79QsmRJZnL#Self_contained_versus_relational_flourishing\"><u>relational value</u></a> that these happy, intuitively&nbsp;<i>prosocial</i> people would contribute via being good friends, partners, caregivers, citizens, etc. \u2014&nbsp;value whose mental exclusion may be \u201ceasier thought than done\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn16h38rbmo0e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref16h38rbmo0e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>A key point here is to not confuse better states with \u201cintrinsically positive states\u201d. After all, it appears that our seemingly positive states can be understood as merely better states along a continuum that ranges from states of unbearable torment to states in which we would be perfectly tranquil or undisturbed (cf. Gloor,&nbsp;<a href=\"https://longtermrisk.org/tranquilism/\"><u>2017</u></a>; Knutsson,&nbsp;<a href=\"https://www.simonknutsson.com/undisturbedness-as-the-hedonic-ceiling/\"><u>2022</u></a>). Additionally, one may argue that \u201cintrinsically positive states\u201d could only be&nbsp;<a href=\"https://www.simonknutsson.com/undisturbedness-as-the-hedonic-ceiling/#62_Replies_to_the_second_part_of_the_counterexample\"><u>reliably identified</u></a> from a (perhaps very rare) flawless state to begin with, and it appears that there are&nbsp;<a href=\"https://centerforreducingsuffering.org/phenomenological-argument/#Why_we_might_believe_that_a_positive_counterpart_to_suffering_exists\"><u>plausible explanations</u></a> for why we might commonly think of less troubled states as intrinsically positive.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnu5k9q8p12ve\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefu5k9q8p12ve\">^</a></strong></sup></span><div class=\"footnote-content\"><p>It is worth noting that Singer in his article (<a href=\"https://www.nybooks.com/articles/1980/08/14/right-to-life/\"><u>1980</u></a>) wrote favorably of combining Preference Utilitarianism and Classical Utilitarianism. Moreover, Singer appears to have moved further toward Classical Utilitarianism in recent years (see e.g. Lazari-Radek &amp; Singer, 2017, ch. 3).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndpcsqy9ch3o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdpcsqy9ch3o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Additionally, a practical point to remember is that the (dis)satisfaction of any given preference usually has implications for the (dis)satisfaction of other preferences (contra the \u2018all else equal\u2019 assumption). Consequently, both offsetting and minimalist views are compatible with&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism#Minimalist_reasons_to_strongly_oppose_painless_killing\"><u>practical reasons to strongly oppose painless killing</u></a>. Yet, all else equal, offsetting preference-based views seem to have the arguably implausible implication that an outcome can always be improved \u2014 and frustrated preferences outweighed \u2014 by creating (or inducing in existing preferrers) new satisfied preferences, such as an intense desire for something that is already the case (Fehige,&nbsp;<a href=\"https://www.fehige.info/pdf/A_Pareto_Principle_for_Possible_People.pdf\"><u>1998</u></a>, pp. 514\u2013515).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzend1s8hofm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzend1s8hofm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The same point applies to the original&nbsp;<a href=\"https://forum.effectivealtruism.org/s/MBadsrYLmzLNmYjaj/p/5gPubzt79QsmRJZnL#The_Repugnant_Conclusion\"><u>Repugnant Conclusion</u></a> (RC). Many people think that the RC is&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ahP7vBeGLq2QfEg5j/avoiding-the-repugnant-conclusion-is-not-necessary-for/\"><u>not unacceptable</u></a> (Zuber et al.,&nbsp;<a href=\"https://www.cambridge.org/core/journals/utilitas/article/what-should-we-agree-on-about-the-repugnant-conclusion/EB52C686BAFEF490CE37043A0A3DD075\"><u>2021</u></a>). Yet its repugnance arguably differs greatly depending on whether we allow the population of lives that are \u201cbarely worth living\u201d to consist of rollercoaster lives (or intrapersonal VRC lives), compared to if they do not suffer at all. Minimalist views may agree that the RC is not repugnant in the suffering-free variant, but they would object to its rollercoaster and intrapersonal VRC variants.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2pabe2fsbcu\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2pabe2fsbcu\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Of course, one may still find the Archimedean minimalist XVRCs quite repugnant (even if less so than the VRC). Yet the remaining repugnant element of \u201c<u>\u200b\u200b</u><a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Making_seemingly_trivial_changes_at_the_price_of_unbearable_suffering\">Making seemingly trivial changes at the price of unbearable suffering</a>\u201d is avoided by the arguably less repugnant lexical views that give priority to the reduction of lexically bad states.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnij4cpe37rz8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefij4cpe37rz8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The quoted part suggests that the authors do not, in fact, attribute repugnance&nbsp;<i>only&nbsp;</i>to the \u201c<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Making_seemingly_trivial_changes_at_the_price_of_unbearable_suffering\">trivial changes</a>\u201d source of repugnance, but also to the additional&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Enabling_rollercoaster_lives_that_all_contain_unbearable_suffering\">intrapersonal</a> suffering entailed by the rollercoaster lives. And if the arbitrary increase of unbearable states (for the sake of additional, unneeded non-relieving goods) is repugnant intrapersonally, then it is presumably at least equally repugnant&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FEJLFr5ef82FSY8vr/minimalist-extended-very-repugnant-conclusions-are-the-least#Creating_non_relieving_goods_for_some_at_the_price_of_unbearable_suffering_for_others\">interpersonally</a>.</p></div></li></ol>", "user": {"username": "Teo Ajantaival"}}]