[{"_id": "78y3vWCSAcKSKHE85", "postedAt": "2021-11-05T10:10:38.724Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>Great post!&nbsp;</p><p>I love Taleb but he embarrasses me, so it's nice to find a dialectical role for him in my head.</p><p>I think I've met a few people who can do both modes, and they're all deeply impressive people. What in late Jobs do you see as sane assessment? Always seemed like a wild half-charlatan half-prophet to me.</p>", "parentCommentId": null, "user": {"username": "technicalities"}}, {"_id": "MKwAzn9QzFrBjf8gw", "postedAt": "2021-11-05T11:05:06.322Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>I was writing a LessWrong post on what I called \"generators\" and \"evaluators\" of ideas a few years ago, but never finished it. \"Evaluators\" &nbsp;and \"assessors\" seem similar. The main difference was that I didn't postulate that \"generators\" are disagreeable, unlike your \"disagreeables\".</p><p>This post by the cognitive scientist Hugo Mercier may also be of relevane: <a href=\"http://cognitionandculture.net/blogs/hugo-mercier/why-assholes-are-more-likely-to-be-wrong/\">\"Why assholes are more likely to be wrong\"</a>.</p>", "parentCommentId": null, "user": {"username": "Stefan_Schubert"}}, {"_id": "euvN6N4BdedooDKeB", "postedAt": "2021-11-05T14:17:06.111Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>I agree with the general point that idea generators are often overconfident and poorly calibrated, but I'm not super excited about conflating that with being <i>disagreeable</i>. There's something there, in that being impatient with the failings of others can be a good impetus to create something better, but I think there are also plenty of generators who aren't highly disagreeable, and <i>if</i> that's the case it seems bad for the dichotomy as formulated here to catch on.</p><p>One example archetype of a generator who isn't disagreeable is someone who is both very intelligent and very enthusiastic/excitable. This person will generate lots of cool new ideas they're super excited about, and will likely still be overconfident and poorly calibrated, without feeling particularly motivated to yell about other people's bad ideas.</p>", "parentCommentId": null, "user": {"username": "willbradshaw"}}, {"_id": "k6pt5DwrypRaqi8h6", "postedAt": "2021-11-05T16:52:24.238Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>Disclaimer: I have disagreeable tendencies, working on it but biased. I think you're getting at something useful, even if most people are somewhere in the middle. I think we should care most about the outliers on both sides because they could be extremely powerful when working together.</p><p>I want to add some **speculations** on these roles in the context of the level at which we're trying to achieve something: individual or collective.</p><p>When no single agent can understand reality well enough to be a good principal, it seems most beneficial for the collective to consist of modestly polarized agents (this seems true from most of the literature on group decision-making and policy processes, e.g. <a href=\"https://www.emerald.com/insight/content/doi/10.1108/S0733-558X20210000076004/full/html\">Adaptive Rationality, Garbage Cans, and the Policy Process | Emerald Insight</a>).</p><p>This means that the EA network should want people who are confident enough in their own world views to explore them properly, who are happy to generate new ideas through epistemic trespassing, and to explore outside of the Overton window etc. Unless your social environment productively reframes what is currently perceived as \"failure\", overconfidence seems basically required to keep going as a disagreeable.</p><p>By nature, overconfidence gets punished in communities that value calibration and clear metrics of success. Disagreeables become poisonous as they feel misunderstood and good assessors become increasingly conservative. The succesful ones of the two characters build up different communities in which they are high status and extremize one another.</p><p>To succeed altogether, we need to walk the very fine line between productive epistemic trespassing and conserving what we have.</p><p>Disagreeables can quickly lose status with assessors because they seem insufficiently epistemically humble or outright nuts. Making your case against a local consensus costs you points. Not being well calibrated on what reality looks like costs you points.</p><p>If we are in a sub-optimal reality, however, effort needs to be put into defying the odds and change reality. To have the chutzpah to change a system, it helps to ignore parts of reality at times. It helps to believe that you can have sufficient power to change it. If you're convinced enough of those beliefs, they often confer power on you in and of themselves.</p><p>Incrementally assessing baseline and then betting on the most plausible outcomes also deepens the tracks we find ourselves on. It is the safe thing to do and stabilizes society. Stability is needed if you want to make sure coordination happens. Thus, assessors rightly gain status for predicting correctly. Yet, they also reinforce existing narratives and create consensus about what the future could be like.</p><p>Consensus about the median outcome can make it harder to break out of existing dynamics because the barrier to coordinating such a break-out is even higher when everyone knows the expected outcome (e.g. odds of success of major change are low).</p><p>In a world where ground truth doesn't matter much, the power of disagreeables is to create a mob that isn't anchored in reality but that achieves the coordination to break out of local realities.</p><p>Unfortunately, to us who have insufficient capabilities to achieve their aims - to change not just our local social reality but the human condition - creating a cult just isn't helpful. None of us have sufficient data or compute to do it alone.</p><p>To achieve our mission, we will need constant error correction. Plus, the universe is so large that information won't always travel fast enough, even if there was a sufficiently swift processor. So we need to compute decentrally and somehow still coordinate.</p><p>It seems hard for single brains to be both explorers and stabilizers simultaneously, however. So as a collective, we need to appropriately value both and insure one another. Maybe we can help each other switch roles to make it easier to understand both. Instead of drawing conclusions for action at our individual levels, we need to aggregate our insights and decide on action as a collective.</p><p>As of right now, only very high status or privileged people really say what they think and most others defer to the authorities to ensure their social survival. At an individual level, that's the right thing to do. But as a collective, we would all benefit if we enabled more value-aligned people to explore, fail and yet survive comfortably enough to be able to feed their learnings back into the collective.</p><p>This is of course not just a norms questions, but also a question of infrastructure and psychology.</p>", "parentCommentId": null, "user": {"username": "konrad"}}, {"_id": "5soXYk6bJojCa8EjT", "postedAt": "2021-11-05T16:57:58.295Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>This clustering is based on anecdotal data; I wouldn't be too surprised if it were wrong. I'd be extremely curious for someone to do a cluster analysis here and see if there are any real clusters here.</p><p>I feel like I've noticed a distinct cluster of generators who are disagreeable, and have a hard time thinking of many who are agreeable. Maybe you could give some examples that come to mind to you? Anders Sandberg comes to my mind, and maybe some futurists and religious people.&nbsp;</p><p>My hunch is that few top intellectuals (that I respect) would score in the 70th percentile or above on the big 5 agreeableness chart, but I'm not sure. It's an empirical question.</p><p>I don't remember hearing about a generators/evaluators dichotomy before, that you &amp; Stefan mention. I like that dichotomy too, it's quite possible it's better than the one I raise here.</p>", "parentCommentId": "euvN6N4BdedooDKeB", "user": {"username": "oagr"}}, {"_id": "RYHFe7DG7W7ixpDCt", "postedAt": "2021-11-05T17:02:32.419Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>I like that naming setup. I considered using the word \"evaluators\", but decided against it because I've personally been using \"evaluator\" to mean something a bit distinct.&nbsp;</p>", "parentCommentId": "MKwAzn9QzFrBjf8gw", "user": {"username": "oagr"}}, {"_id": "EsHzDRjwstyyZHgbh", "postedAt": "2021-11-05T17:04:57.048Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>I think that Jobs, later on (after he re-joined Apple), was just a great manager. This meant he considered a whole lot of decisions and arguments, and generally made smart decisions upon reflection.<br><br>I think he (and other CEOs) are wildly inaccurate with how they portray themselves to the public. However, I think they can have great decision making in company-internal decisions. It's a weird, advantageous, inconsistency.&nbsp;<br><br>This book goes into some detail:<br>https://www.amazon.com/Becoming-Steve-Jobs-Evolution-Visionary-ebook/dp/B00N6PCWY8/ref=sr_1_3?keywords=steve+jobs&amp;qid=1636131865&amp;rnid=2941120011&amp;s=books&amp;sr=1-3</p>", "parentCommentId": "78y3vWCSAcKSKHE85", "user": {"username": "oagr"}}, {"_id": "zaEfJLazwJngHYGxJ", "postedAt": "2021-11-05T18:25:04.568Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>Scott Garrabrant has discussed this (or some very similar distinction) in some <a href=\"https://www.greaterwrong.com/posts/WsvpkCekuxYSkwsuG/overconfidence-is-deceit/comment/isXCLgu5WAhhHMrTj\">LessWrong</a> <a href=\"https://www.greaterwrong.com/posts/MnFqyPLqbiKL8nSR7/my-experience-at-and-around-miri-and-cfar-inspired-by-zoe/comment/xnSMpL4Xyv3sj9goh\">comments</a>. There's also been a lot of discussion about <a href=\"https://www.lesswrong.com/tag/babble-and-prune\">babble and prune</a>, which is basically the same distinction, except happening inside a single mind instead of across multiple minds.</p>\n", "parentCommentId": null, "user": {"username": "riceissa"}}, {"_id": "i5KHiePiACPxTwrML", "postedAt": "2021-11-05T19:25:21.821Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>Thanks a lot for the post! This felt like one of the rare posts that clearly defines and articulates a thing that feels intuitively true, but which I've never properly thought about before.</p>\n", "parentCommentId": null, "user": {"username": "Neel Nanda"}}, {"_id": "BDo9adfiKpjkSuRtG", "postedAt": "2021-11-05T22:16:19.063Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>Good find, I didn't see that discussion before.&nbsp;<br><br>For those curious; Scott makes the point that it's good to separate \"idea generation\" from \"vetted ideas that aren't wrong\"; and that's it's valuable to have spaces where people can suggest ideas without needing them to be right. I agree a lot with this.</p><blockquote><p>I have this model where in a healthy society, there can be contexts where people generate all sorts of false beliefs, but also sometimes generate gold (e.g. new ontologies that can vastly improve the collective map). If this context is generating a sufficient supply of gold, you DO NOT go in and punish their false beliefs. Instead, you quarantine them. You put up a bunch of signs that point to them and say e.g. \u201c80% boring true beliefs 19% crap 1% gold,\u201d then you have your rigorous pockets watch them, and try to learn how to efficiently distinguish between the gold and the crap, and maybe see if they can generate the gold without the crap. However sometimes they will fail and will just have to keep digging through the crap to find the gold.</p></blockquote>", "parentCommentId": "zaEfJLazwJngHYGxJ", "user": {"username": "oagr"}}, {"_id": "CpLcvGCLm86mmRLko", "postedAt": "2021-11-05T22:30:34.808Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>Thanks for the comment (this could be it's own post). This is a lot to get through, so I'll comment on some aspects.</p><blockquote><p>I have disagreeable tendencies, working on it but biased</p></blockquote><p>I have some too! I think there are times when I'm fairly sure my intuitions lean overconfident in a research project (due to selection effects, at least), but it doesn't seem worth debiasing, because I'm going to be doing it for a while no matter what, and not writing about its prioritization. I feel like I'm not a great example of a disagreeable or an assessor, but I sometimes can lean one way in different situations.</p><blockquote><p>Instead of drawing conclusions for action at our individual levels, we need to aggregate our insights and decide on action as a collective.</p></blockquote><p>I would definitely advocate for the appreciation of both disagreeables and assessors. I agree it's easy for assessors to team up against disagreeables (for examples, when a company gets full of MBAs), particularly when they don't respect them.&nbsp;</p><p>Some Venture Capitalists might be examples of assessors who appreciate and have learned to work with disagreeables. I'm sure they spend a lot of time thinking, \"Person X seems slightly insane, but no one else is crazy enough to make a startup in this space, and the downside for us is limited.\"</p><blockquote><p>As of right now, only very high status or privileged people really say what they think and most others defer to the authorities to ensure their social survival.</p></blockquote><p>This clearly seems bad to me. For what it's worth, I don't feel like I have to hide <i>that much</i> that I think, though maybe I'm somewhat high status. Sadly, I know that high-status people sometimes can say even less than low-status people, because they have more people paying attention and more to lose. I think we really could use improved epistemic setups somehow.</p>", "parentCommentId": "k6pt5DwrypRaqi8h6", "user": {"username": "oagr"}}, {"_id": "YvxiiKuQSbg3tP3ke", "postedAt": "2021-11-06T14:21:14.985Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>Spencer Greenberg also comes to mind; he once noted that his agreeableness is in the <a href=\"https://us7.campaign-archive.com/?e=4c655d9232&amp;u=9b65e8f8f700bd2ce8ffb9131&amp;id=60b7e7d767\">77th percentile</a>. I'd consider him a generator.</p>", "parentCommentId": "5soXYk6bJojCa8EjT", "user": {"username": "Simon_Grimm"}}, {"_id": "4edTarGCcPC3k2XsK", "postedAt": "2021-11-06T20:28:39.507Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>Great post. Reminds me of Eric Weinstein on excellence vs. genius: <a href=\"https://youtu.be/bsgWSPWX-6A?t=553\">https://youtu.be/bsgWSPWX-6A?t=553</a></p>\n", "parentCommentId": null, "user": {"username": "yhoiseth"}}, {"_id": "cLDLQZuxuAGjtpic5", "postedAt": "2021-11-07T16:32:20.061Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>At the very least I think we can be more confident in the generators/evaluators (or /assessors) dichotomy, than in the further claim that the former tend to be disagreeable.</p><p>I'm coming at this from science, where lot of top generators have a strong \"this is so cool!\" sort of vibe to them \u2013 they have a thousand ideas and can't wait to try them out. Don't get me wrong, I think disagreeable generators play an important role in science too, but it's not my go-to image of a generator in that space.</p><p>[Wild speculation] It's plausible to me that this varies by field, based on the degree to which that field tends to strike out into new frontiers of knowledge vs generate new theories for things that are already well-studied. In the latter case, in order for new ideas to be useful, the previous work on the topic needs to be wrong in some way \u2013 and if the people who did the previous work are still around they'll probably want to fight you. So if you want to propose really new ideas in those sorts of fields you'll need to get into fights \u2013 and so generators in these fields will be disproportionately disagreeable. Whereas if everyone agrees that there are oodles of things in the field that are criminally understudied, you can potentially get quite a long way as a generator before you need to start knocking down other people's work.</p><p>Obviously if this theory I just made up has any validity, it will be more of a spectrum than a binary. But this sort of dynamic might be at play here.</p>", "parentCommentId": "5soXYk6bJojCa8EjT", "user": {"username": "willbradshaw"}}, {"_id": "DpHuyE5ovtkP2rJoq", "postedAt": "2021-11-08T14:50:26.688Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>The distinction reminds me of the foxes vs hedgehogs model from Superforecasting / Tetlock. Hedgehogs being \"great idea thinkers\" seeing everything in the light of that one great idea they're following, whereas foxes are more nuanced, taking in many viewpoints and trying to converge on the most accurate beliefs. I <i>think </i>he mentioned in &nbsp;the book that while foxes tend to make much better forecasters, hedgehogs are not only more entertaining but also good in coming up with good questions to forecast in the first place.</p><p>An entirely different thought: The Laws of Human Nature by Robert Greene was the first audible book I returned without finishing. It was packed with endless \"human archetypes\" described in great detail, making some rather bold claims about what \"this type\" will do in some given situation. You mention in the footnotes already that people who dislike e.g. personality profiling tools might not like this post. And it did indeed somewhat remind me of that book, but maybe your \"assessor\" way of describing the model, as opposed to Greene's very overconfident seeming way of writing, made this seem much more reasonable. There seems to be a fine line between actually useful models of this kind which have some predictive power (or at least allow thoughts to be a bit tidier), and those that are merely peculiarly entertaining, like Myers-Briggs. And I find it hard to tell from the outside on which side of that line any given model falls.&nbsp;</p>", "parentCommentId": null, "user": {"username": "markus_over"}}, {"_id": "y3uEyaPAYeRwkEhBT", "postedAt": "2021-11-08T15:31:27.391Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<blockquote><p>There seems to be a fine line between actually useful models of this kind which have some predictive power (or at least allow thoughts to be a bit tidier), and those that are merely peculiarly entertaining, like Myers-Briggs. And I find it hard to tell from the outside on which side of that line any given model falls.&nbsp;</p></blockquote><p>I have mixed feelings here. I think I'm more sympathetic to Myers-Briggs when used correctly, than other people. There definitely seems to be <i>some</i> signal that it categorizes (some professions are highly biased towards a narrow part of the spectrum). It doesn't seem all too different to categorizing philosophy as \"continental\" vs. \"analytical\". It's definitely not the <i>best</i> categorization, there are some flawed assumptions baked into it (either/or, as opposed to a spectrum, most famously), the org that owns it seems pretty weird, and lots of people make overconfident statements around it, but I think it can serve a role when used correctly.</p><p>Anyway, I imagine what we'd really want is a \"Big 5 of Intellectuals\" or similar. For that, it would be great for someone to eventually do some sort of cluster analysis.<br>&nbsp;</p><p>I don't necessarily recommend that the disagreeables/assessors terminology takes off; I'd prefer it if this can be used for discussion that finds something better. &nbsp;</p>", "parentCommentId": "DpHuyE5ovtkP2rJoq", "user": {"username": "oagr"}}, {"_id": "TaEuwBTraqxbXtCgc", "postedAt": "2021-11-11T02:56:54.443Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>Thanks for the post - I can see what you're getting at, but this doesn't feel like two clearly distinct categories to me. The first person I thought to try and apply this to had strong traits from both columns, for example. As a similar but more available example, where would you fit Bryan Caplan here? He's disagreeable without being angry, and is trying hard not to be wrong while happily telling others why they are.&nbsp;<br><br>I'm not sure whether my intuition here is that these can both be strong/weak in the same person, that there's more of a spectrum, or that they're a set of characteristics that may or may not cluster the way you've described. I'm not really sure what shape you meant for this to take, or how well it applies in these intermediate cases.</p>", "parentCommentId": null, "user": {"username": "AbigailT"}}, {"_id": "8u4Mv2Zesm9YnpXJA", "postedAt": "2021-11-11T22:04:30.041Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>I'd note that I expect these clusters (and I suspect they're clusters) to be a minority of intellectuals. They stand out a fair bit to me, but they're unusual.&nbsp;<br><br>I agree Bryan Caplan leans disagreeable, but is less intense than others. I found The Case Against Education and some of his other work purposefully edgy, which is disagreeable-type-stuff, but at the same time, I found his interviews to often be more reasonable.&nbsp;<br><br>I would definitely see the \"disagreeable\" and \"assessor\" archetypes as a spectrum, and also think one person can have the perks of both.</p>", "parentCommentId": "TaEuwBTraqxbXtCgc", "user": {"username": "oagr"}}, {"_id": "nND7jFDZEieMoxgBu", "postedAt": "2021-11-12T00:41:05.516Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>Dr. Greger from NutritionFacts.org also seems like an agreeable generator. Actually he may be disagreeable in that he's not shy about pointing out flaws in studies and others' conceptions, but he does it in an enthusiastic, silly and not particularly abrasive way.</p><p>It's interesting that some people may still disagree often but not be doing it in a disagreeable manner.</p>", "parentCommentId": "5soXYk6bJojCa8EjT", "user": {"username": "Evan R. Murphy"}}, {"_id": "Z3N8xhLy3J8WqNPgi", "postedAt": "2021-11-12T00:44:44.378Z", "postId": "PwH5hKfAdwYGE8Jdh", "htmlBody": "<p>Albert Einstein also comes to mind as an agreeable generator. I haven't read his biography or anything, but based on the collage of stories I've heard about him, he never seemed like a very disagreeable person but obviously generated important new ideas.</p>", "parentCommentId": "5soXYk6bJojCa8EjT", "user": {"username": "Evan R. Murphy"}}]