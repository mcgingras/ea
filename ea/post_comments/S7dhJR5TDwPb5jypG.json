[{"_id": "adXmStRYN6Bp3uMdC", "postedAt": "2022-09-02T05:42:05.787Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>This is a fantastic resource, and I'm really glad to have it!&nbsp;<br><br>My own path has been a little more haphazard - I completed Level 2 (Software Engineering) years ago, and am currently working on AI safety (1), mathematics (3) and research engineering ability (4) simultaneously. Having just completed the last goal of 4 (Completing 1-3 RL projects) I was planning to jump right into 6 at this point, since transformers haven't yet appeared in my RL perusal, but I'm now rethinking those plans based on this document - perhaps I should learn about transformers first.<br><br>All in all, the first four levels (The ones I feel qualified to write about, having gone through some or all of them) seem extremely good.&nbsp;<br><br>The thing that most surprised me about the rest of the document was Level 6. Specifically, the part about being able to reimplement a paper's work in 10-20 hours. This seems pretty fast compared to other resources I've seen out there, though most of these resources are RL-focused. &nbsp;For instance, <a href=\"http://amid.fish/reproducing-deep-rl\">this post</a> (220 hours). <a href=\"https://www.lesswrong.com/posts/nzmCvRvPm4xJuqztv/deepmind-is-hiring-for-the-scalable-alignment-and-alignment\">This post from DeepMind</a> about job vacancies a few months ago also says:<br><br>\"As a rough test for the Research Engineer role, if you can reproduce a typical ML paper in a few hundred hours and your interests align with ours, we\u2019re probably interested in interviewing you.\"<br><br>Thus, I don't think it's necessary to be able to replicate a paper in 10-20 hours. Replicating papers is a great idea according to my own research, but I think that one can be considerably slower than that and still be at a useful standard.<br><br>If you have other sources that suggest otherwise I'd be very interested to read them - it's always good to improve my idea of where I'm heading towards!&nbsp;<br><br>&nbsp;</p>", "parentCommentId": null, "user": {"username": "Jay Bailey"}}, {"_id": "47EtMFKPZeLgRqP2N", "postedAt": "2022-09-02T05:59:35.805Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>Thanks, that's a good point! I was very uncertain about that, it was mostly a made-up number. I do think the time to implement an ML paper depends wildly on how complex the paper is (e.g. a new training algorithm paper necessitates a lot more time to test it than a post-hoc interpretability paper that uses pre-trained models) and how much you implement (e.g. rewrite the code but don't do any training vs evaluate the key result to get the most important graph vs try to replicate almost all of the results).</p><p>I now think my original 10-20 hours per paper number was probably an underestimate, but it feels really hard to come up with a robust estimate here and I'm not sure how valuable it would be, so I've removed that parenthetical from the text.</p>", "parentCommentId": "adXmStRYN6Bp3uMdC", "user": {"username": "Gabe Mukobi"}}, {"_id": "ei5j8PbSQvvKYPASR", "postedAt": "2022-09-02T06:06:52.159Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>Thanks for sharing your experiences, too! As for transformers, yeah it seems pretty plausible that you could specialize in a bunch of traditional Deep RL methods and qualify as a good research engineer (e.g. very employable). That's what several professionals seem to have done, e.g. <a href=\"https://80000hours.org/articles/ml-engineering-career-transition-guide/#case-study-daniel-zieglers-ml-self-study-experience\">Daniel Ziegler</a>.</p><p>But maybe that's changing, and it's worth it to start learning things. It seems like most of the new RL papers incorporate some kind of transformer encoder in the loop, if not basically being a straight-up <a href=\"https://www.youtube.com/watch?v=w4Bw8WYL8Ps&amp;list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&amp;index=4\">Decision Transformer</a>.</p>", "parentCommentId": "adXmStRYN6Bp3uMdC", "user": {"username": "Gabe Mukobi"}}, {"_id": "EpwkpTdy4QNtDsj3j", "postedAt": "2022-09-02T08:37:37.759Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>The HuggingFace RL course might be an alternative in the Deep Learning - RL discussion above: <a href=\"https://github.com/huggingface/deep-rl-class\">https://github.com/huggingface/deep-rl-class</a></p>\n", "parentCommentId": null, "user": {"username": "PabloAMC"}}, {"_id": "yQmECxExAck9cggqe", "postedAt": "2022-09-02T14:15:35.477Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>Interesting. Do you have any good examples?</p>", "parentCommentId": "ei5j8PbSQvvKYPASR", "user": {"username": "Jay Bailey"}}, {"_id": "Hc2wexm6BSFz4v6Pk", "postedAt": "2022-09-02T16:37:56.360Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>Good find, added!</p>", "parentCommentId": "EpwkpTdy4QNtDsj3j", "user": {"username": "Gabe Mukobi"}}, {"_id": "ubPAihHhwSGJD3mdJ", "postedAt": "2022-09-02T16:47:24.645Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>Sure!</p><ul><li><a href=\"https://www.deepmind.com/publications/a-generalist-agent\">A Generalist Agent (deepmind.com)</a></li><li><a href=\"https://say-can.github.io/\">SayCan: Grounding Language in Robotic Affordances (say-can.github.io)</a></li><li><a href=\"https://www.deepmind.com/blog/from-motor-control-to-embodied-intelligence\">From motor control to embodied intelligence (deepmind.com)</a></li><li><a href=\"https://arxiv.org/abs/2209.00588\">Transformers are Sample Efficient World Models (arxiv.org)</a></li><li><a href=\"https://arxiv.org/abs/2106.01345\">Decision Transformer: Reinforcement Learning via Sequence Modeling (arxiv.org)</a></li></ul>", "parentCommentId": "yQmECxExAck9cggqe", "user": {"username": "Gabe Mukobi"}}, {"_id": "gsGyRxvsjz3ktGRXK", "postedAt": "2022-09-03T16:35:22.729Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<blockquote><p><i>Many thanks to Jakub Nowak, Peter Chatain, Thomas Woodside, Erik Jenner, Jacy Reese Anthis, <strong>Ludwig Wittgenstein</strong>, and Konstantin Pilz for review and suggestions!</i></p></blockquote>", "parentCommentId": null, "user": {"username": "Emrik"}}, {"_id": "gqoBuj43a3jLzfcy2", "postedAt": "2022-09-03T16:54:39.265Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>Oh lol I didn't realize that was a famous philosopher until now, someone commented from a Google account with that name! Removed Ludwig.</p>", "parentCommentId": "gsGyRxvsjz3ktGRXK", "user": {"username": "Gabe Mukobi"}}, {"_id": "TGL5Z6X3QhMoCRcXf", "postedAt": "2022-09-03T17:01:57.283Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>I didn't mean for you to remove it! I was just happy to see that he still has some influence from beyond the grave.</p>", "parentCommentId": "gqoBuj43a3jLzfcy2", "user": {"username": "Emrik"}}, {"_id": "QxDmMwfPwvFWjHshm", "postedAt": "2022-09-08T09:42:01.705Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>Great list!</p><p>Probably an important skillset that's missing is working with cloud computing services, which you may need if you want to train models that require more resources than what your local machine/Google Colab provides</p>", "parentCommentId": null, "user": {"username": "jmsdao"}}, {"_id": "8g6C36MwsHmvDzEM7", "postedAt": "2022-09-10T02:33:07.899Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>Thanks! Forgot about cloud computing, added a couple of courses to the Additional Resources of <a href=\"https://forum.effectivealtruism.org/posts/S7dhJR5TDwPb5jypG/levelling-up-in-ai-safety-research-engineering#Level_4__Deep_Learning\">Level 4: Deep Learning</a>.</p>", "parentCommentId": "QxDmMwfPwvFWjHshm", "user": {"username": "Gabe Mukobi"}}, {"_id": "N4CtKEKtg5yag7hDt", "postedAt": "2022-09-30T08:41:54.624Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>For Level 3: Machine Learning, <a href=\"https://gwthomas.github.io/docs/math4ml.pdf\">this document </a>might be useful. It provides a quick summary/recap of a lot of the math required for ML.</p>", "parentCommentId": null, "user": {"username": "lukasberglund"}}, {"_id": "WoiPevoYDKxqRGMPa", "postedAt": "2022-09-30T18:17:25.241Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>Epistemic status: a few projects in ML, technically \"a professional ML engineer\" right now but I don't think I'm good enough to get hired by one of the big EA-ML orgs right now.</p><p>Two points re the start of your math sequence</p><ol><li>A lot of calculus is geared toward engineers and the way engineering is taught, leaving a gap in the basic language of mathematics that IME can be filled by <strong>discrete math</strong>. This pays dividends when you're reading wikipedia and research papers later. It doesn't take long to get ahold of sets and logic with trevtutor.&nbsp;</li><li>Single variable calculus may require exercises. I find it really odd that you think 3b1b gets the job done- it probably doesn't. Luckily, single variable calculus is well before you've maxed out khanacademy's wonderful exercises widget. Some ways of doing the rote calculations is a waste of time (like professors who don't seem to realize that if you've derivative'd one polynomial you've taken every polynomial), but the rote computations really pay dividends in your overall sophistication level (from the symbolic find-and-replace game to mystery solving even to thinking on your feet about applications.</li></ol>", "parentCommentId": null, "user": {"username": "quinn"}}, {"_id": "RPijry7v44Aotey2C", "postedAt": "2022-10-12T04:38:21.659Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>Thanks Gabriel-- super useful step-by-step guide, and also knowledge/skill clarification structure! I usually gesture around vaguely when talking about my skills (I lose track of how much I know compared to others-- the answer is I clearly completed Levels 1-3 then stopped) and trying to hire other people with related skills. It feels useful to be able to say to someone e.g. \"For this position, I want you to have completed Level 1 and have a very surface level grasp of Levels 2-4\"!</p>", "parentCommentId": null, "user": {"username": "Vael Gates"}}, {"_id": "CNPhKwDcK2WgdsF5s", "postedAt": "2022-10-13T05:09:46.769Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>Ha thanks Vael! Yeah, that seems hard to standardize but potentially quite useful to use levels like these for hiring, promotions, and such. Let me know how it goes if you try it!</p>", "parentCommentId": "RPijry7v44Aotey2C", "user": {"username": "Gabe Mukobi"}}, {"_id": "63fSxzLdAHD9CfHMz", "postedAt": "2023-01-10T13:54:26.543Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>That's a great resource to navigate my self study in ML! Thank you for compiling this list.</p><p>I wonder if a pull request to some popular machine learning library or tool counts as a step towards AI Safety Research. &nbsp;Say, a PR implements some safety feature for PyTorch, e.g. in &nbsp;interpretability, adversarial training, or other. Would it go to Level 6 as it is reimplementing papers? Making PR is, arguable, takes more efforts than just reimplementating a paper as it needs to fit into a tool.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Artyom K"}}, {"_id": "q4SJMCDEkdsAim5mu", "postedAt": "2024-01-26T16:40:27.101Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>This is a great resource, and one I've been using myself, even though I'm a software engineer, I've been doing the Python FreeCodeCamp courses because I love FCC and I don't use Python daily at work.<br><br>I think there should be a Slack workspace or a Discord server for people doing this - I've felt that getting the maths in or the pre-requisite Machine Learning concepts is not a matter of just watching a few YouTube videos.</p>", "parentCommentId": null, "user": {"username": "Joseph Quevedo"}}, {"_id": "99woxm9SSnX87Cd6p", "postedAt": "2024-02-04T00:37:04.403Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>I am currently going through the <a href=\"https://www.freecodecamp.org/learn/data-analysis-with-python\">Data Analysis with Python</a> course on FreeCodeCamp.<br><br>I have to say, just watching a video and then answering a question is not very interactive, and has made it hard for me to keep engaging with the course.<br><br>When I was doing the certification projects for Scientific Computing with Python in December, I was interested in progressing with my project. Still, lately, I've been dreading or uninterested in watching one more video of this guy going through a Jupyter notebook.<br><br>Another thing I disliked about it is that the \"exercises\" already have the answers in them.<br><br>I searched for this link in Reddit and found <a href=\"https://www.reddit.com/r/Python/comments/10a1zir/comment/j4275ev\">someone</a> recommending a <a href=\"https://jovian.com/learn/data-analysis-with-python-zero-to-pandas\">FreeCodeCamp course on Data Analysis with Python with Jovian</a>, it supposedly being more interactive (you do have to pay for submitting assignments), but I was able to see the assignments, so it might be useful in case someone wants more practice and hands-on things to do.<br><br>I think I won't switch courses halfway, I don't want to get stuck in tutorial hell.</p>", "parentCommentId": null, "user": {"username": "Joseph Quevedo"}}, {"_id": "nPmcJ22zufgvvuXfe", "postedAt": "2024-03-08T00:40:24.216Z", "postId": "S7dhJR5TDwPb5jypG", "htmlBody": "<p>So I finished the Data Analysis with Python course on FCC. I have to say, the certification projects may have some library usages that were not displayed on the videos for the course (as of today). One example is scikit's linregress: you won't see an explanation on that, but you'll be required to do a linear regression, good luck if you have no math background in functions.</p>", "parentCommentId": "99woxm9SSnX87Cd6p", "user": {"username": "Joseph Quevedo"}}]