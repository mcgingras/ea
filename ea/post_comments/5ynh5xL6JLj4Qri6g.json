[{"_id": "jZ5aAkyvFy6xo7B5r", "postedAt": "2018-02-22T19:43:44.035Z", "postId": "5ynh5xL6JLj4Qri6g", "htmlBody": "<p>Hi Gordon, I don't have accounts on LW or Medium so I'll comment on your original post here.</p>\n<p>If possible, could you explain like I'm five what <em>your</em> working definition of the AI alignment problem is?</p>\n<p>I find it hard to prioritize causes that I don't understand in simple terms.</p>\n", "parentCommentId": null, "user": {"username": "oge"}}, {"_id": "su9xRTh7SaHiaMREd", "postedAt": "2018-02-23T19:14:55.149Z", "postId": "5ynh5xL6JLj4Qri6g", "htmlBody": "<p>I think the ELI5 on AI alignment is the same as it has been: make nice AI. Being a little more specific I like Russell's slightly more precise formulation of this as &quot;align AI with human values&quot;, and being even more specific (without jumping to mathematical notation), I'd say we want to design AI that value what humans value and for us to believe these AI share our values.</p>\n<p>Maybe the key thing I'm trying to get at though is that alignable AI will be phenomenally conscious, or in ELI5 terms as much people as anything else (humans, animals, etc.). So then my position is not just &quot;make nice AI&quot; but &quot;make nice AI people we can believe are nice&quot;.</p>\n", "parentCommentId": "jZ5aAkyvFy6xo7B5r", "user": {"username": "gworley3"}}, {"_id": "kPMPjGRSk8MpxMdgT", "postedAt": "2018-02-26T01:25:56.621Z", "postId": "5ynh5xL6JLj4Qri6g", "htmlBody": "<p>I'm skeptical of your specific views on qualia, etc. (but I haven't read your arguments yet, so I withhold judgment.) </p>\n<p>Despite that skepticism, this seems like a promising area to explore at least.</p>\n<p>I agree with your #5.</p>\n", "parentCommentId": null, "user": {"username": "kokotajlod"}}, {"_id": "AD7o6s79krZmbaouR", "postedAt": "2018-02-26T19:01:26.633Z", "postId": "5ynh5xL6JLj4Qri6g", "htmlBody": "<p>Thanks, Gordon.  </p>\n<p>&quot;Make nice AI people we can believe are nice&quot; makes sense to me; I hadn't been aware of the &quot;...we can believe are nice&quot; requirement.</p>\n", "parentCommentId": "su9xRTh7SaHiaMREd", "user": {"username": "oge"}}, {"_id": "oerjvL3qsHqW4ArFQ", "postedAt": "2018-02-26T19:05:22.329Z", "postId": "5ynh5xL6JLj4Qri6g", "htmlBody": "<p>For what it's worth I started out being very much in the analytic philosophy camp and thought qualia sounded like nonsense for a long time because much of the discussion of the idea avoids giving a precise description of what qualia are. But over time I switched sides, if you will, because I was forced into it by trying to parsimoniously explain reality with empiricist epistemology. For this reason I generally prefer to talk about noemata (a term I gave technical meaning to avoid confusion with existing ideas) rather than qualia for this reason: it avoids the way &quot;qualia&quot; has become associated with all kinds of confusion.</p>\n", "parentCommentId": "kPMPjGRSk8MpxMdgT", "user": {"username": "gworley3"}}]