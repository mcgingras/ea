[{"_id": "Feoy2C7cfvvDxrZJY", "postedAt": "2022-10-23T18:12:00.120Z", "postId": "To8AjPjrHoZCHFLEj", "htmlBody": "<p>I do feel like having people who are very strongly pushing the state of AGI forward and who are major contributors to existential risk via their actions in that space (most notably <a href=\"https://www.vox.com/future-perfect/23375219/future-perfect-50-demis-hassabis-deepmind\">Demis Hassabis</a>) on that list, while also rewarding people who are trying to reduce existential risk by putting them on that list, sure makes me feel like the list isn't generated via a very consistent set of criteria.&nbsp;</p><p>I also more broadly feel sad that one would put AI capabilities research on this list, given that I think it's quite bad for the world.</p>", "parentCommentId": null, "user": {"username": "Habryka"}}]