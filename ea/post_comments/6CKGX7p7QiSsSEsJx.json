[{"_id": "qWEjwmQjz5b8Skoc2", "postedAt": "2023-12-18T06:50:24.699Z", "postId": "6CKGX7p7QiSsSEsJx", "htmlBody": "<p>You could be rigth, but conscience is totally noumenal, so we really can not know.&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/nY7oAdy5odfGqE7mQ/freedom-under-naturalistic-dualism\">https://www.lesswrong.com/posts/nY7oAdy5odfGqE7mQ/freedom-under-naturalistic-dualism</a></p><p>It is obivous that Chalmers is rigth in some way as long as life is simply an state of matter, so when you understand what determines the emergence of epiphenomenal conscience, you can replicate it in other substrate. But we can only experiment with our own conscience. We attribute conscience to others only because we are conscient and the rest of humans are so similar to us that it is almost impossible there are not. &nbsp;So here are metaphysical difficulties in any experimental agenda when physical similarity is lost, and as long as we dont know why we are conscient, we really dont know what to replicate.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Arturo Macias"}}, {"_id": "FLCwoRMQ7MC8KAHs5", "postedAt": "2023-12-18T14:39:16.402Z", "postId": "6CKGX7p7QiSsSEsJx", "htmlBody": "<p><strong>Executive summary:</strong> Chalmers argues for the possibility of artificially conscious systems, but his fading qualia thought experiment rests on unjustified assumptions about the functional equivalence of biological neurons and silicon chips.</p><p><strong>Key points:</strong></p><ol><li>Chalmers claims that systems with identical functional organization will have identical consciousness (organizational invariance), arguing against the possibility of absent qualia in functionally equivalent systems.</li><li>Chalmers' fading qualia argument assumes the very neuronal-silicon equivalence it aims to demonstrate, rendering it circular.</li><li>Biological neurons involve unique metabolic processes tied to consciousness, meaning silicon chips are not functionally equivalent substrates.</li><li>Therefore, Chalmers' organizational invariance principle and argument against absent qualia fail.</li><li>This lowers confidence in the possibility of artificially conscious systems, given current silicon-based AI architectures.</li><li>The issue has ethical implications, potentially reducing expected value estimates of digitally conscious lives.</li></ol><p>&nbsp;</p><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}]