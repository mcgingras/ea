[{"_id": "o4GnkxZ52DjFw5gsJ", "postedAt": "2023-12-01T18:20:12.775Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>Do you think you could linkpost your article to Lesswrong too?&nbsp;</p><p>I know this article mainly focuses on EA values, but it also overlaps with a bunch of stuff that LW users like to research and think about (e.g. in order to better understand the current socio-political and and geopolitical situation with AI safety).&nbsp;</p><p>There's a lot of people on LW who mainly spend their days deep into quantitative technical alignment research, but are surprisingly insightful and helpful when given a fair chance to weigh in on the sociological and geopolitical environment that EA and AI safety take place in, e.g. <a href=\"https://www.lesswrong.com/posts/ahNcJGNtTX8JvMy93/dialogue-on-the-claim-openai-s-firing-of-sam-altman-and\">johnswentworth's participation in this dialogue</a>.&nbsp;</p><p>Normally the barriers to entry are quite high, which discourages involvement from AI safety's most insightful and quantitative thinkers. Non-experts typically start out, by default, with really bad takes on US politics or China (e.g. believing that the US military just hands over the entire nuclear arsenal to a new president every 4-8 years), and people have to call them out on that in order to preserve community epistemics.&nbsp;</p><p>But it also keeps alignment researchers and other quant people separated from the people thinking about the global and societal environment that EA and AI safety take place in, which currently needs as many people as possible understanding the problems and thinking through viable solutions.</p>", "parentCommentId": null, "user": {"username": "trevorw96"}}, {"_id": "cNoN776JhKjq2sYxK", "postedAt": "2023-12-01T22:13:26.921Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>The Nuclear football is a lie?!! TIL</p>\n", "parentCommentId": "o4GnkxZ52DjFw5gsJ", "user": {"username": "Daryl D'Souza"}}, {"_id": "2qwKWFMfMykgzAFeE", "postedAt": "2023-12-01T22:23:16.434Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>You're welcome to re-post it there, if you think it might be of interest to the LW crowd! :-)</p>", "parentCommentId": "o4GnkxZ52DjFw5gsJ", "user": {"username": "RYC"}}, {"_id": "m66Fo5cs5uffsv77q", "postedAt": "2023-12-02T00:26:51.119Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>From an evolution / selfish gene's perspective, the reason I or any human has morality is so we can win (or at least not lose) our local <a href=\"https://www.lesswrong.com/posts/y5jAuKqkShdjMNZab/morality-is-scary\">virtue/status game</a>. Given this, it actually seems pretty wild that anyone (or more than a handful of outliers) tries to be impartial. (I don't have a good explanation of how this came about. I guess it has something to do with philosophy, which I also <a href=\"https://www.lesswrong.com/posts/MAhueZtNz5SnDPhsy/metaphilosophical-mysteries\">don't understand the nature of</a>.)</p>\n<p>BTW, I wonder if EAs should take the status game view of morality more seriously, e.g., when thinking about how to expand the social movement, and predicting the future course of EA itself.</p>\n", "parentCommentId": null, "user": {"username": "Wei_Dai"}}, {"_id": "wpmWhwHMKadm3iBt6", "postedAt": "2023-12-02T04:51:06.824Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>Do you have research underpinning these statements? You are an expert in the field of behavior so I would be interested in anything that can back this up. Perhaps also if anything like this is echoed in various EA-related surveys?</p><blockquote><p>Few people who give to charity make any serious effort to do <i>the most good they can</i> with the donation. Few people who engage in political activism are seriously trying to do they most good they can with their activism. Few people pursuing an \u201cethical career\u201d are trying to do the most good they can with their career.&nbsp;</p></blockquote><p>The reason I am asking is that this is counter to my own experience with non-EA altruists. And I think if you are wrong, there might be hope for growing the EA movement much larger as people already agree with us - we then \"just\" need to show them that we have also been thinking about this and might have a few research outputs they might want to look at before making a donation or career move.</p>", "parentCommentId": null, "user": {"username": "Ulrik Horn"}}, {"_id": "DtLbuYWvJhmPpCPrB", "postedAt": "2023-12-02T08:55:03.476Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>Have you ever done something good, helped someone or took part in an organised event, and afterwards wanted to tell your friends about it, but in the end decided there was nothing to tell or that others would see it as bragging? What did you decide to do then?</p><p>As a matter of principle, all charitable activities should stem from an inner need to help poor and needy people and should be selfless. We do not seek profit in them and that is precisely why they are so noble.</p><p><br>Hence, there is sometimes a conviction that such activities should not be spoken of loudly, or boasted about, because the search for applause, in a way, crosses out this idea of selfless help. Quiet and even anonymous help is much better perceived. It would best meet the above standards.</p><p><br>On the other hand, those who are flaunting helping others are sometimes seen as self-interested, seeking fame and recognition, as if taking advantage of others' suffering. At the very least, such accusations are easy to encounter, especially online. How much are they right? We will take a closer look.</p><p>&nbsp;</p><p>When I recently decided to take in war refugees under my roof, and later became involved in organising aid to the wider community, exactly this issue came to mind. Is it appropriate for me to speak out about it? I'm sure someone will pick up on the fact that it's applause-seeking. Do I want to deal with it? Maybe it is better to do everything quietly, with close friends from whom I can expect understanding?</p><p><br>However, I quickly came to the conclusion that if I had the opportunity to reach a wider audience, I could help more than if I didn't take that opportunity. I decided that it was better to endure criticism but ultimately do more good than to chicken out and achieve far less.</p><p>Having said that, I fully understand the dilemma of \"tell the story of the good I've done, or keep it to myself?\". After all, I have spoken more than once about the fact that, for example, we should not say of ourselves that we are gentlemen or ladies, because it is for others to judge by our behaviour and character. It is our surroundings that give us that designation. It is the same with being a hero helping those in need.</p><p><br>And arguably it may seem nobler for a person to act charitably without receiving anything in return than for one who gains something in the process, but even if that were the case, I emphasise that it is a difference in gradation, not a division between good and bad! Also, someone who derives something for himself from helping those in need is acting nobly. In the end, the most important thing is that the person in need has gained something. That is what counts most here. By focusing on the people helping, we unfortunately lose the right perspective.</p><p><br>Moreover, there is no denying that, de facto, almost all of us gain from charity. Isn't it the case that when you donate money to an important cause you feel better at heart? When you help carry out renovations in the home of a person with a disability, don't you feel the satisfaction of energy and time well spent? When you take in a refugee under your roof, don't you feel the joy of making the world a little better? The only one who does not gain is someone who is completely insensitive and probably the one who donates money to a random institution without even knowing what purpose it will be used for.</p><p><br>We all also gain a little peace of mind, enjoy the gratitude shown to us and find it nice when those around us appreciate us for it. Is this unethical? Not at all!</p><p>&nbsp;</p><p>So why are we afraid to praise a good deed? I feel that the problem may grow out of the fact that we increasingly treat popularity like currency. For we live in a world where fame can be a value in itself. And if we perceive it that way, people who 'boast about charity' gain something tangible in our eyes, as if someone is paying them to do good.</p><p><br>We are used to seeing empty celebrity, contemptuously called celebrity, who represents nothing, but gathers attention and gains wealth. So we begin to abhor all popularity and accidentally throw the baby out with the bathwater.</p><p><br>Because, in fact, popularity, fame and the ability to reach a wide audience can be an invaluable tool for promoting good attitudes. This is all the more important when we think that the entire media landscape is overrun by consumerism and entertainment. This is the only way to convince others that people are still good, willing to help and remember those in need. That doing good is important and worth promoting, even advertising. And if someone can show this as a fashionable and cool thing to do, so much the better! After all, this is the main way of educating the younger generation and instilling the right role models.</p><p><br>If the only people who could be loud were those who have nothing of value to contribute, where would we go?</p><p>&nbsp;</p><p>So remember that each of us can add our brick to the building of this house. If you think yours doesn't matter, you need to know that grassroots initiatives have enormous power. So what if some foundation hires a popular actor to promote some charity? For most of us, these are institutions from another reality. On the other hand, we will perceive in a completely different way a colleague from the school bench or the office next door who helps, even though it is not his job at all.</p><p><br>Someone who does not do charity work will then think \"why?\", \"why?\", \"who does it at all?\", \"what can be gained?\" and so on. This is how break-outs are created.</p><p><br>You don't have to immediately be an advocate for a cause. You can simply bear witness to your commitment so that the trail is not left only by critics and passive people. Help others build a real picture of the world around you, because it's actually better than you might expect from information gleaned from social media. It's worth redressing these proportions.</p><p>&nbsp;</p><p>Every good gesture deserves praise, but it can be presented in a variety of ways, including some that will be questionable to say the least. As I encourage praise for the good done, let's do it constructively and consider how to do it sensitively.</p><p><br>Don't exploit others - that is, don't use the image of the people you are helping or private information about them if they clearly do not wish it. However, do not ask permission to do so yourself. A very good example is the First Job Programme Foundation's initiative called the Clothes Bank. In the autumn, as part of this project, I had the pleasure of conducting a training session for young men from children's homes. At the time, we talked to the organisers about the possibilities of promoting the action and everyone was in full agreement that photos showing the metamorphoses of these young people would be great to advertise the action, but no one was going to do it, even with their permission. We simply felt that it would be unfair to the people involved themselves. After all, such initiatives can be promoted in many different ways and they don't necessarily have to be the simplest ones.</p><p><br>Don't make a hero of yourself - the fact that you are helping makes you a more noble person, but you don't actually have to say it outright. That would not be the best testimony. Everyone will know how to judge you themselves. Instead, focus on your feelings. For there is a huge difference between 'I am a hero' and 'I feel like a hero'. Pay attention to the subtleties of language when you talk about such things. By the way, it is those feelings of fulfilment that accompany us when we do something good that are the greatest reward, and it is worth highlighting this when promoting similar deeds.</p><p><br>Don't criticise others - if you feel that society is not involved enough in a cause you have just contributed to, try not to jump on the ignorance of those around you. Negative emotions are not going to convince anyone, although I understand that they may accompany you. If this is the case, try to wait a bit until you've cooled down, and then talk about the whole thing in a spirit that can positively or constructively encourage others to participate.</p><p><br>&nbsp;</p><p><br>Charitable or philanthropic actions make you a good person. Remember that no one can tell you how specifically to help, because only you know how much you can afford both in terms of energy, finances or time, as well as mental strength. And you don't have to tell anyone about your commitment. It is your free choice.</p><p><br>But don't let anyone tell you that you shouldn't help or talk about it in public if you want to do it and you think it's the right thing to do. Because, in fact, by skilfully 'bragging', you may inadvertently multiply your good deed, encouraging many others to do the same.</p>", "parentCommentId": null, "user": {"username": "KaliCorte"}}, {"_id": "EPrE3yFQ8KjYwWiKX", "postedAt": "2023-12-02T10:24:27.147Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>What might EAs taking the status game view more seriously look like, more concretely? I'm a bit confused since from my outside-ish perspective it seems the usual markers of high status are already all there (e.g. institutional affiliation, large funding, [speculatively] <a href=\"https://forum.effectivealtruism.org/posts/h2N9qEbvQ6RHABcae/a-critical-review-of-open-philanthropy-s-bet-on-criminal\">OP's CJR work</a>, etc), so I'm not sure what doing more on the margin might look like. Alternatively I may just be misunderstanding what you have in mind.&nbsp;</p>", "parentCommentId": "m66Fo5cs5uffsv77q", "user": {"username": "Mo Nastri"}}, {"_id": "pSgt9prE95CaQrQCL", "postedAt": "2023-12-02T13:27:07.374Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>One, be more skeptical when someone says they are committed to impartially do the most good, and keep in mind that even if they're totally sincere, that commitment may well not hold when their local status game changes, or if their status gradient starts diverging from actual effective altruism. Two, form a more explicit and detailed model of how status considerations + philosophy + other relevant factors drive the course of EA and other social/ethical movements, test this model empirically, basically do science on this and use it to make predictions and inform decisions in the future. (Maybe one or both of these could have helped avoid some of the mistakes/backlashes EA has suffered.)</p>\n<p>One tricky consideration here is that people don't like to explicitly think about status, because it's generally better for one's status to appear to do everything for its own sake, and any explicit talk about status kind of ruins that appearance. Maybe this can be mitigated somehow, for example by keeping some distance between the people thinking explicitly about status and EA in general. Or maybe, for the long term epistemic health of the planet, we can somehow make it generally high status to reason explicitly about status?</p>\n", "parentCommentId": "EPrE3yFQ8KjYwWiKX", "user": {"username": "Wei_Dai"}}, {"_id": "dfTHsesPNjDNGsisv", "postedAt": "2023-12-02T14:57:25.360Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>Oh, I'm not a social scientist. It's just an inference to the best explanation in response to commonly observed behaviour, e.g. all those who \"go and donate to local children\u2019s hospitals and puppy shelters, while showing no interest in learning about neglected tropical diseases or improving factory-farmed animal welfare.\"</p><p>That said, just because the EA project is (currently) unusual doesn't mean that we can't hope that that might change! &nbsp;Sometimes people initially fail to pursue a goal simply because it hasn't even occurred to them, or they haven't thought about it in the right way to see why it's actually pretty appealing. &nbsp;So introducing the ideas, and making clear their intrinsic appeal, could still potentially sway many people who didn't <i>previously</i> have the EA project among their goals.</p>", "parentCommentId": "wpmWhwHMKadm3iBt6", "user": {"username": "RYC"}}, {"_id": "5bfwhtLqBZFSet2Jc", "postedAt": "2023-12-02T16:02:56.548Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>Hey Wei, I appreciate you responding to Mo, but I found myself still confused after reading this reply. This isn't purely down to you - a lot of LessWrong writing refers to <i><strong>'</strong>status', but they never clearly define what it is or where the evidence and literature for it is.</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffn1o5quyedh\"><sup><a href=\"#fnfn1o5quyedh\">[1]</a></sup></span><i>&nbsp;</i>To me, it seem to function as this magic word that can explain anything and everything. The whole concept of <i>'status' </i>as I've seen it used in LW seems incredibly susceptible to being part of 'just-so' stories.</p><p>I'm highly sceptical of this though, like I don't know what a 'status gradient' is and I don't think it exists in the world? Maybe you mean an abstract description of behaviour? But then a 'status gradient' is just describing what happened in a social setting, rather than making scientific predictions. Maybe it's instead a kind of non-reductionist sense of existing and having impact, which I do buy, but then things like 'ideas','values', and 'beliefs' should also exist in this non-reductionist way and be as important for considering human action as <i>'status' </i>is.</p><p>It also tends to lead to using explanations like this:</p><blockquote><p>One tricky consideration here is that people don't like to explicitly think about status, because it's generally better for one's status to appear to do everything for its own sake</p></blockquote><p>Which to me is dangerously close to saying <i>\"if someone talks about status, it's evidence it's real. If they don't talk about it, then they're self-deceiving in a Hansion sense, and this is evidence for status\" </i>which sets off a lot of epistemological red-flags for me</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfn1o5quyedh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffn1o5quyedh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In fact, one of the most cited works about it isn't a piece of anthropology or sociology, <a href=\"https://www.goodreads.com/en/book/show/306940\">but a book about Improv acting</a>???</p></div></li></ol>", "parentCommentId": "pSgt9prE95CaQrQCL", "user": {"username": "JWS"}}, {"_id": "wwZW6TvHdEm8papro", "postedAt": "2023-12-02T17:57:11.096Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>A resource I keep coming back to is the 2010 <a href=\"https://thegiin.org/assets/binary-data/RESOURCE/download_file/000/000/96-1.pdf\">Money for good</a> study from Hope Consulting. They found that only about 3% of people donate based on organizations' relative performance (see slide 41).</p>\n<p>At the time that study came out, I figured the best thing for EA was to lean into that 3%. Is that still true? As the movement has grown, I'm not really sure.</p>\n", "parentCommentId": "wpmWhwHMKadm3iBt6", "user": {"username": "Ian Turner"}}, {"_id": "CShmmHD6aPHemM6tG", "postedAt": "2023-12-02T19:05:20.780Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<blockquote>\n<p>a lot of LessWrong writing refers to 'status', but they never clearly define what it is or where the evidence and literature for it is</p>\n</blockquote>\n<p>Two citations that come to mind are Geoffrey Miller's Virtue Signaling and Will Storr's The Status Game (maybe also Robin Hanson's book although its contents are not as fresh in my mind), but I agree that it's not very scientific or well studied (unless there's a body of literature on it that I'm unfamiliar with), which is something I'd like to see change.</p>\n<blockquote>\n<p>Maybe it's instead a kind of non-reductionist sense of existing and having impact, which I do buy, but then things like 'ideas','values', and 'beliefs' should also exist in this non-reductionist way and be as important for considering human action as 'status' is.</p>\n</blockquote>\n<p>Well sure, I agree with this. I probably wouldn't have made my suggestion if EAs talked about status roughly as much as ideas, values, or beliefs.</p>\n<blockquote>\n<p>Which to me is dangerously close to saying \"if something talks about status, it's evidence it's real. If they don't talk about it, then they're self-deceiving in a Hansion sense, and this is evidence for status\" which sets off a lot of epistemological red-flags for me</p>\n</blockquote>\n<p>It seems right that you're wary about this, but on reflection I think the main reason I think status is real is not because people talk or don't talk about it, but because I see human behavior that seems hard to explain without invoking such a concept. For example, why are humans moral but our moralities vary so much across different communities? Why do people sometimes abandon or fail to act according to their beliefs/values without epistemic or philosophical reasons to do so? Why do communities sometimes collectively become very extreme in their beliefs/values, again without apparent epistemic or philosophical justification?</p>\n", "parentCommentId": "5bfwhtLqBZFSet2Jc", "user": {"username": "Wei_Dai"}}, {"_id": "kqvFDtrzWggawpvhB", "postedAt": "2023-12-03T09:00:32.430Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<blockquote><p>From an evolution / selfish gene's perspective, the reason I or any human has morality is so we can win (or at least not lose) our local <a href=\"https://www.lesswrong.com/posts/y5jAuKqkShdjMNZab/morality-is-scary\">virtue/status game</a>.&nbsp;</p></blockquote><p>If you're talking about status games at all, then not only have you mostly rounded the full selective landscape off to the organism level, you've also taken a fairly low resolution model of human sociality and held it fixed (when it's properly another part of the phenotype). Approximations like this, if not necessarily these ones in particular, are of course necessary to get anywhere in biology - but that doesn't make them any less approximate.</p><p>If you want to talk about the evolution of some complex psychological trait, you need to provide a <i>very</i> clear account of how you're operationalizing it and explain why your model's errors (which definitely exist) aren't large enough to matter in its domain of applicability (which is definitely not everything). I don't think rationalist-folk-evopsych has done this anywhere near thoroughly enough to justify strong claims about \"the\" reason moral beliefs exist.</p>", "parentCommentId": "m66Fo5cs5uffsv77q", "user": {"username": "prisonpent"}}, {"_id": "ttEacdp7cypN7gYdD", "postedAt": "2023-12-03T18:48:12.965Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>I agree that was too strong or over simplified. Do you think there are other evolutionary perspectives from which impartiality is less surprising?</p>\n", "parentCommentId": "kqvFDtrzWggawpvhB", "user": {"username": "Wei_Dai"}}, {"_id": "H95woPjkYLaTB9udk", "postedAt": "2023-12-03T22:07:13.808Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>I don't think it's possible to give an evolutionary account of impartiality in isolation, any more than you can give one for algebraic geometry or christology or writing or common-practice tonality. The underlying capabilities (e.g. intelligence, behavioral plasticity, language) are biological, but the particular way in which they end up expressed is not. We might find a thermodynamic explanation of the origin of self-replicating molecules, but a thermodynamic explanation of the reproductive cycle of ferns isn't going to fit in a human brain. You have to move to a higher level of organization to say anything intelligible. Reason, similarly, is likely the sort of thing that admits a good evolutionary explanation, but individual instances of reason<i>ing</i> can only really be explained in psychological terms.</p>", "parentCommentId": "ttEacdp7cypN7gYdD", "user": {"username": "prisonpent"}}, {"_id": "S77gpKmxojnbv4Pbv", "postedAt": "2023-12-03T23:52:21.922Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>I have asked a question previously that you have not responded to yet:<br>&nbsp;</p><p>\"Does a positive obligation exist to procreate?<br><br>While controversies surround total utilitarianism and the Repugnant Conclusion, what about the ethical implications of sperm donation? Given that it typically entails negligible costs and results in creating content lives in developed nations, could sperm donation be considered a moral duty? Despite concerns about overpopulation and its impact on climate change, could individual actions be akin to a Prisoner's Dilemma, where meaningful change requires large-scale government intervention and individual actions do not matter at all on a large scale?<br><br>Regarding meat consumption, when does the act of creating life outweigh the potential for negative consequences, such as dietary choices? If refraining from creating life is justified on the basis of potential meat consumption (as seen in vegan antinatalist perspectives), does it logically follow that it is morally acceptable to kill non-vegans due to their meat consumption?<br><br>Finally, you said that saving a life is more important than creating one, though creating one has some relevance. So how many lives created is equal to one life saved? What is the break-even point?</p><p><br>Thanks.\"</p>", "parentCommentId": null, "user": {"username": "dstudioscode"}}, {"_id": "qNytpWfjtePPEEGih", "postedAt": "2023-12-04T02:57:10.069Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>It seems like you're basically saying \"evolution gave us reason, which some of us used to arrive at impartiality\" which doesn't seem very different from my thinking which I alluded to in my opening comment (except that I used \"philosophy\" instead of \"reason). Does that seem fair, or am I rounding you off too much, or otherwise missing your point?</p>\n", "parentCommentId": "H95woPjkYLaTB9udk", "user": {"username": "Wei_Dai"}}, {"_id": "AtTyfSsdvCnT8TfAS", "postedAt": "2023-12-04T05:22:34.765Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>Yes and no: \"evolution gave us reason\" is the same sort of coarse approximation as \"evolution gave us the ability and desire to compete in status games\". What we really have is a sui generis thing which can, in the right environment, approximate ideal reasoning or Machiavellian status-seeking or coalition-building or utility maximization or whatever social theory of everything you want to posit, but which most of the time is trying to split the difference.&nbsp;</p><p>People support impartial benevolence because they think they have good pragmatic reasons to do so <i>and</i> they think it's correct <i>and</i> it has an acceptable level of status in their cultural environment <i>and </i>it makes them feel good<i> and</i> it serves as a signal of their willingness to cooperate <i>and</i> and and and. Of course the exact weights vary, and it's pretty rare that every relevant reason for belief is pointing exactly the same way simultaneously, but we're all responding to a complex mix of reasons. Trying to figure out exactly what that mix is for one person in one situation is difficult. Trying to do the same thing for everyone all at once in general is impossible.&nbsp;</p>", "parentCommentId": "qNytpWfjtePPEEGih", "user": {"username": "prisonpent"}}, {"_id": "BXCBccoRufAsjkXS6", "postedAt": "2023-12-04T09:57:05.252Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<blockquote><p>why are humans moral but our moralities vary so much across different communities? Why do people sometimes abandon or fail to act according to their beliefs/values without epistemic or philosophical reasons to do so? Why do communities sometimes collectively become very extreme in their beliefs/values, again without apparent epistemic or philosophical justification?</p></blockquote><p>I think \"status\" plays some part in the answers to these, but only a fairly small one.&nbsp;</p><p>Why do moralities vary across different communities? Primarily because they are raised in different cultures with different prevalent beliefs. We then modify those beliefs from the baseline as we encounter new ideas and new events, and often end up seeking out other people with shared values to be friends with. But the majority of people aren't just pretending to hold those beliefs to fit in (although that does happen), the majority legitimately believe what they say.&nbsp;</p><p>Why do communities get extreme? Well, consult the literature on radicalisation, there are a ton of factors. A vivid or horrible event or ongoing trauma sometimes triggers an extreme response. Less radical members of groups might leave, making the average more radical, so even more moderates leave or split, until the group is just radicals.&nbsp;</p><p>As to why we fail to act according to their values, people generally have competing values, including self-preservation and instincts, and are not perfectly rational. Sometimes the primal urge to eat a juicy burger overcomes the calculated belief that eating meat is wrong.&nbsp;</p><p>These are all amateur takes, a sociologist could probably answer better.&nbsp;</p>", "parentCommentId": "CShmmHD6aPHemM6tG", "user": {"username": "titotal"}}, {"_id": "njx8b3MHBimnmGw5z", "postedAt": "2023-12-04T13:10:48.082Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>See also 'How Donors Choose Charities' (<a href=\"https://kar.kent.ac.uk/36115/1/Breeze%20HDCC%20VSR%20July2103%20published%20version.pdf\">Breeze, 2013</a>), where even unusually engaged donors are explicit about basing their donations on personal preference and often donating quite haphazardly, with little deliberation.</p><p>See also 'Impediments to Effective Altruism' (<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3224734\">Berman et al, 2018</a> [<a href=\"https://journals.sagepub.com/doi/10.1177/0956797617747648\">full paper</a>]), where people endorsed making charitable decisions based on subjective preferences and often did not elect to donate to the most effective charities, even when this information was available.<br><br>See also this review by <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S1364661321000905\">Caviola et al (2021)</a>.</p>", "parentCommentId": "wwZW6TvHdEm8papro", "user": {"username": "David_Moss"}}, {"_id": "LjkH8y5tPpG3BGXc3", "postedAt": "2023-12-04T19:05:48.904Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>I've only skimmed this article, but also <a href=\"https://academic.oup.com/jpart/article-abstract/32/1/97/6311293?redirectedFrom=fulltext&amp;login=true\">Coupet and Schehl (2021)</a> claims \"Much of the nonprofit performance theory suggests that donors are unlikely to base donation decisions on nonprofit production\".</p>", "parentCommentId": "wwZW6TvHdEm8papro", "user": {"username": "Ben Stevenson"}}, {"_id": "DnheTvixu7K5WvuGL", "postedAt": "2024-01-01T15:50:08.413Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>This post seems to confuse Effective Altruism, which is a methodology, for a value system. Valuing the 'impartial good' or ' general good' is entirely independent of wanting to do 'good' effectively, whatever you may find to be good.<br><br>You articulate this confusion most clearly in the paragraph starting \"Maybe it would help to make the implications more explicit.\" You make two comparisons of goals that one can choose between (shrimp or human, 10% chance of a millions lives, or 1000 lives for sure). But the value of the options is not dictated by effective altruism; this depends on ones valuation of shrimp vs human life in the first case, and ones risk profile in the second.</p>", "parentCommentId": null, "user": {"username": "Anonymous000"}}, {"_id": "B6nz4rTY36erR6GKX", "postedAt": "2024-01-02T14:29:02.083Z", "postId": "YKidYukDhKLBtDqsh", "htmlBody": "<p>You're welcome to disagree with me about whether what's most distinctive about EA is its values or its methodology, but it's gratuitous to claim that I am \"confusing\" the two just because you disagree. (One might say that you are confusing disagreement with confusion.)</p><p>A simple reason why EA can't just be a value-neutral methodology: that leaves out the \"altruism\" part. Effective Nazism is not a possible sub-category of EA, even if they follow an evidence-based methodology for optimizing their Nazi goals.</p><p>A second reason, more directly connected to the argument of this post: there's nothing especially distinctive about \"trying to achieve your goals effectively\". Cause-agnostic beneficentrism, by contrast, is a very distinctive value system that can help distinguish the principled \"core\" of EA from more ordinary sorts of (cause-specific) do-gooding.</p><blockquote><p>But the value of the options is not dictated by effective altruism; this depends on ones valuation of shrimp vs human life in the first case, and ones risk profile in the second.</p></blockquote><p>This is a misunderstanding of my view. I never suggested that EA \"dictates\" how to resolves disputes about the impartial good. I merely suggested that it (at core; one might participate in some sub-projects without endorsing the core principles) involves a <i>commitment</i> to being guided by considerations of the impartial good. &nbsp;The idea that value \"depends on one's valuation\" is a fairly crude and contestable form of anti-realism. Obviously if it's possible for one's valuations to be mistaken, then one should instead be guided by the <i>correct</i> way to balance these competing interests.</p>", "parentCommentId": "DnheTvixu7K5WvuGL", "user": {"username": "RYC"}}]