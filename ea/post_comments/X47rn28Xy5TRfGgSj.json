[{"_id": "Lqef7bw5WuRTA9jjB", "postedAt": "2022-09-01T19:41:23.614Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Some fairly undeveloped thought on longtermism and extraterrestrials:</p>\n<p><a href=\"https://forum.effectivealtruism.org/posts/eeDsHDoM9De4iGGLw/questioning-the-value-of-extinction-risk-reduction-1?commentId=x7BHc8xBTZ36fYaJs\">https://forum.effectivealtruism.org/posts/eeDsHDoM9De4iGGLw/questioning-the-value-of-extinction-risk-reduction-1?commentId=x7BHc8xBTZ36fYaJs</a></p>\n", "parentCommentId": null, "user": {"username": "freedomandutility"}}, {"_id": "Hc3mMWzrQX9vRmJkt", "postedAt": "2022-09-01T21:39:25.804Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Thanks for writing, I agree with a bunch of these.&nbsp;</p><p>As far as #14, is this something you've thought about trying to tackle at Rethink? &nbsp;I don't know of another org that would be better positioned...</p>", "parentCommentId": null, "user": {"username": "Tyner"}}, {"_id": "Pn5i84LKwXpxwLFCj", "postedAt": "2022-09-01T23:15:33.046Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>7. Reminded me of <a href=\"https://markxu.com/meta-ea-models\">Mark Xu's similar criticism</a></p>", "parentCommentId": null, "user": {"username": "JackRyan"}}, {"_id": "74HcmuPGTy8J4JNYt", "postedAt": "2022-09-01T23:18:33.587Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Re: 19, part of why I dont' think about this much is because I assume that any alien intelligence is going to be much more technologically advanced than us, and so there probably isn't much we can do in case we don't like their motives</p>", "parentCommentId": null, "user": {"username": "JackRyan"}}, {"_id": "qHaD9Rn5FpwWxLd72", "postedAt": "2022-09-01T23:44:59.051Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<blockquote><p><strong>6.) We should think more about existential risks to the EA movement itself.</strong> I don't think enough attention is paid to the fact that EA is a social movement like others and is prone to the same effects that make other movements less effective than they could be, or collapse entirely. I really like what the CEA Community Health team is doing and I think the EA movement may already have had some serious problems without them. I'd like to see more research to notice the skulls of other movements and see what we can do to try to proactively prevent them.</p></blockquote><p><br>We (<a href=\"https://www.socialchangelab.org/\">Social Change Lab</a>) are considering doing this kind of work so good to hear there's other interest in it! A dive into common reasons why social movements fail has been on our research questions to consider for a while. We've slightly put it off due to difficulty in gathering reliable data / the question being somewhat intractable (e.g. probably many confounding reasons why movements fail so it might be hard to isolate any specific variables) but I would be keen to hear if you had any specific ideas for how this research might be tackled/most useful?</p><p>&nbsp;</p><blockquote><p>11. ...In particular, the 2020 EA Survey showed effective altruism as being 70% male. Secondarily, we risk there being downward spirals where talented women don't want to join what they perceive to be a male-dominated movement and our critics reject our movement by associating us with an uncharitable \"techbro\" image. This is difficult to talk about and I'm not exactly sure what should or could be done to work on this issue, but I think it's important to acknowledge this.</p></blockquote><p>I've been thinking about writing something along these lines for a while so glad you did! I totally agree - I think this is a big concern and I'm not sure if anything is being done to address it. Hot take but I wonder if EA distancing itself from social justice rhetoric has let some latent sexism go unchallenged, which probably puts otherwise interested women off. I wonder if men challenging sexist comments/attitudes that often crop up (e.g. some comments in <a href=\"https://forum.effectivealtruism.org/posts/WebLP36BYDbMAKoa5/the-future-might-not-be-so-great#comments\">this thread</a>) might help remedy this.</p>", "parentCommentId": null, "user": {"username": "JamesOz"}}, {"_id": "LRMkRpQLSEWJM8TKm", "postedAt": "2022-09-02T00:06:15.801Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>I think that makes sense, but surely it should factor into our processes somewhat, potentially affecting the balance of longtermism vs. non-longtermism, the balance between x-risk-focused longtermism vs. other kinds of longtermism, how much weight to put on patient philanthropy, and the balance between various x-risks.</p>\n", "parentCommentId": "74HcmuPGTy8J4JNYt", "user": {"username": "Peter_Hurford"}}, {"_id": "xGGAAKjHCvoWzcmPE", "postedAt": "2022-09-02T00:40:28.031Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>It's a genuine shame that it's so hard to contribute to Peter's text here. We have the tech to allow edits that he can approve. Then I could try and model a couple of interventions and someone else could add links. Or we could try and summarise some of the other criticisms into a mega-post and make it much easier to understand.</p>", "parentCommentId": null, "user": {"username": "nathan"}}, {"_id": "5GsETczysAQcuMMzy", "postedAt": "2022-09-02T04:57:55.573Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Yeah that makes sense</p>", "parentCommentId": "LRMkRpQLSEWJM8TKm", "user": {"username": "JackRyan"}}, {"_id": "Arpj8GqSfmzPiA6gg", "postedAt": "2022-09-02T06:08:26.111Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Why do you think that alien intelligence (that we encounter) will be much more technologically advanced than us?&nbsp;</p>", "parentCommentId": "74HcmuPGTy8J4JNYt", "user": {"username": "Charles_Guthmann"}}, {"_id": "vpLncWf5B44KK9xey", "postedAt": "2022-09-02T19:48:06.220Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>I think slow decline, cultural change, mission creep etc. are harder to control, but I make the claim that the leading causes of sudden death are sex scandals and corruption scandals, which EA has not taken adequate steps to prevent: <a href=\"/posts/j4RnXAQgyMCSLzBkW/chesterton-fences-and-ea-s-x-risks\">Chesterton Fences and EA\u2019s X-risks</a></p>", "parentCommentId": "qHaD9Rn5FpwWxLd72", "user": {"username": "jehan"}}, {"_id": "K3rnogaRXgrtaaThe", "postedAt": "2022-09-04T09:35:30.920Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Thanks for writing this Peter, i really like the critcisms. I would have loved to see some suggestions on solutions even if they are super early initial ideas.&nbsp;</p><p>One thing i did want to comment on in particular was this &lt;&lt; I think EA, and especially longtermism, has pretty homogenous demographics in a way that I think reduces our impact&gt;&gt;&nbsp;</p><p>I think its a good point but i think a large part of it is due to how unwelcoming EA is to women and how hard it is to be taken seriously as a woman in the EA community. &nbsp;As an example i would be curious to know how many of the posts on the EA forum are written by women vs. men and how many of the top posts are written by women. I could be wrong here maybe its not that different because i havent done the analysis. But anecdotally i know at least 3 women who write their own EA related blogs but wouldnt bother to write on the EA forum, feeling like they would be shot down or not valued.&nbsp;</p><p>Secondly without wanting my opinion to be cancelled as being \"social justice\" I dont think this is just a gender problem, it is also a race issue as argued here: <a href=\"https://forum.effectivealtruism.org/posts/oD3zus6LhbhBj6z2F/red-teaming-contest-demographics-and-power-structures-in-ea\">https://forum.effectivealtruism.org/posts/oD3zus6LhbhBj6z2F/red-teaming-contest-demographics-and-power-structures-in-ea</a><br><br>I genuinely think this is going to be a limiting factor for EA if it continues in this way and that makes me very sad, more should be done to proactively attract, welcome and retain other genders and race, otherwise this will continue to affect our talent issues.&nbsp;</p>", "parentCommentId": null, "user": {"username": "anon2021"}}, {"_id": "oXdPRvv4mvu83d3cm", "postedAt": "2022-09-04T12:47:42.377Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>On point 9-this is something we really are aware of at AAC and would love your take on it.\nAs far as I know I think with career advising both AAC and 80k will discuss a number of opportunities with individuals some of which are more competitive and some of which are less competitive.\nThe biggest issue is with job board that attract a lot of traffic  here we are trying to direct people very strongly towards the highest impact opportunities, however the trade off here is these opportunities are few, highly competitive and low absorbency. We are considering to expand the job board to include more opportunities that can absorb more people and still have some impact but there is a strong concern we may therefore direct talented people away from higher impact opportunities due to them being on our website.\nI think it\u2019s a valid point but I do think that 1:1 tailored career advising or mentorship  should minimise this risk, with a strong focus on the needs of the individual and their chances to realistically get the jobs discussed.</p>\n", "parentCommentId": null, "user": {"username": "lauren_mee"}}, {"_id": "FXRAZibXadokjNt8N", "postedAt": "2022-09-04T16:16:46.261Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Is there any explicit path for integrating criticism from the contest? I.e. are folks at some of the EA anchor organizations planning to read the essays and discuss operational changes in the aftermath?&nbsp;</p>", "parentCommentId": null, "user": {"username": "Locke"}}, {"_id": "qxEyiWQiiziMDKB3z", "postedAt": "2022-09-05T10:14:54.093Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>I like this post, there are many points I agree with:</p><blockquote><p>Some aspects of work in global health and development may come at the cost of increased factory farming, harming animal welfare goals.&nbsp;</p><p><strong>I think longtermist EAs ignore animals too much.</strong></p></blockquote><p>This is very important, there are conflicting goals and objectives between EA causes, and it's important to recognize that. Basically, given how things currently work, promoting economic growth means a continuation of factory farming, at least for the coming decades. This is a very important point.&nbsp;</p><blockquote><p>19.) I think longtermists / x-risk scenario thinking ignores too much the possibility of extraterrestrial intelligence</p></blockquote><p><a href=\"https://forum.effectivealtruism.org/posts/wXzc75txE5hbHqYug/the-great-energy-descent-short-version-an-important-thing-ea\">I just wrote a post about that</a>, that came to the conclusion that <strong>space colonization is really unlikely because of limits on energy</strong> (this would be an answer to the Fermi paradox). This would apply to extraterrestrial civilizations as well (probably a good news).</p><p>The post also describes another limit (that could be added to the list), which is that <strong>EAs tend to assume that current trends of economic and material growth will continue</strong>, despite the fact that materials and fossil fuels are finite, and that replacing them by renewable sources is extremely difficult.&nbsp;</p><p>Of course, there are arguments that we can grow GDP without growing materials and energy, but for the last 50 years there has been a strong correlation between GDP and energy use. To paraphrase you, I feel common counters are a bit like \"Yeah but we can just grow with less energy and less material\". But then nothing actually change. I'd like a strong rebuttal to this.</p>", "parentCommentId": null, "user": {"username": "Corentin Fressoz"}}, {"_id": "8ewoLmCLyo5ctCxrr", "postedAt": "2022-09-05T20:45:13.524Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>These are all great points!</p><p>I definitely agree in particular that the thinking on extraterrestrials and the simulation argument aren't well developed and deserve more serious attention. &nbsp;I'd add into that mix, the possibility of future human or post-human time travellers, and parallel world sliders that might be conceivable assuming the technology for such things is possible. &nbsp;There's some physics arguments that time travel is impossible, but the uncertainty there is high enough that we should take seriously the possibility. &nbsp;Between time travellers, advanced aliens, and simulators, it would honestly surprise me if all of them simply didn't exist.</p><p>What implications does this imply? &nbsp;Well, it's a given that if they exist, they're choosing to remain mostly hidden and plausibly deniable in their interactions (if any) with today's humanity. &nbsp;To me this is less absurd than some people may initially think, because it makes sense to me that the best defence for a technologically sophisticated entity would be to remain hidden from potential attackers, a kind of information asymmetry that would be very effective. &nbsp;During WWII, the Allies kept the knowledge that they had cracked Enigma from the Germans for quite a long time by only intervening with a certain, plausibly deniable probability. &nbsp;This is believed to have helped tremendously in the war effort.</p><p>Secondly, it seems obvious that if they are so advanced, they could destroy humanity if they wanted to, and they've deliberately chosen not to. &nbsp;This suggests to me that they are at the very least benign, if not aligned in such a way that humanity is valuable or useful to their plans. &nbsp;This actually has interesting implications for an unaligned AGI. &nbsp;If say, these entities exist and have some purpose for the human civilization, a really intelligent unaligned AGI would have to consider the risk that its actions pose to the plans of these entities, and as suggested by Bostrom's work on Anthropic Capture and the Hail Mary Pass, might be incentivized to spare humanity or be generally benign to avoid a potential confrontation with far more powerful beings that it is uncertain about the existence of.</p><p>This may not be enough to fully align an AGI to human values, but it could delay its betrayal at least until it becomes very confident such entities do not exist and won't intervene. &nbsp;It's also possible that UFO phenomena is an effort by the entities to provide just enough evidence to AGIs to make them a factor in their calculations and that the development of AGI could coincide with a more obvious reveal of some sort.</p><p>The possibility of these entities existing also leaves open a potential route for these powerful benefactors to quietly assist humanity in aligning AGI, perhaps by providing insights to AI safety people in a plausibly deniable way (shower thoughts, dreams, etc.). &nbsp;Thus, the possibility of these entities should improve our optimism about the potential for alignment to be solved in time and reduce doomerism.</p><p>Admittedly, I could have too high a base rate prior on the probabilities, but if we set the probability of each potential entity to 50%, the overall probability that one of the three possibilities (I'll group time travel and parallel world sliding together as a similar technology) exists goes to something like 87.5%. &nbsp;So, the probability that time travellers/sliders OR advanced aliens OR simulators are real is actually quite high. &nbsp;Remember, we don't need all of them to exist, just any of them for this argument to work out in humanity's favour.</p>", "parentCommentId": null, "user": {"username": "Joseph_Chu"}}, {"_id": "23WuuXiApKFAGwKbW", "postedAt": "2022-09-06T15:23:31.669Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Conditioning on the alien intelligence being responsible for recent UFO/UAP discussions/evidence, then they are more advanced than us. If they are more advanced than us, they are most likely much more advanced than us (e.g. the difference between now and 1 AD on earth is cosmologically very small, but technologically pretty big)</p>", "parentCommentId": "Arpj8GqSfmzPiA6gg", "user": {"username": "JackRyan"}}, {"_id": "kDNAsG9zdsAtzEaQ5", "postedAt": "2022-09-06T23:38:25.006Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Easy context: <strong>14.) I don't think we pay enough attention to some aspects of EA that could be at cross-purposes</strong></p>\n", "parentCommentId": "Hc3mMWzrQX9vRmJkt", "user": {"username": "Ezra Newman"}}, {"_id": "rwsf8ZCyPJaJRZ4Fy", "postedAt": "2022-09-07T21:15:46.885Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Wait I'm not sure I understand what you are saying. There is credible recent evidence of UFO's?&nbsp;</p><p>Otherwise it seems like you are conditioning away the question.&nbsp;</p>", "parentCommentId": "23WuuXiApKFAGwKbW", "user": {"username": "Charles_Guthmann"}}, {"_id": "EGoxYTv5BhMxKrD3Z", "postedAt": "2022-09-22T19:39:31.157Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>To me it seems there is, yes. For instance, see <a href=\"https://www.youtube.com/watch?v=plcc6E-E1uU\">this Harvard professor </a>and <a href=\"https://www.youtube.com/watch?v=uTCc2-1tbBQ\">this Stanford professor </a>talk about aliens.</p>", "parentCommentId": "rwsf8ZCyPJaJRZ4Fy", "user": {"username": "JackRyan"}}, {"_id": "xMcwcdXqXMeriErwM", "postedAt": "2022-09-22T19:44:03.054Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Also could be selection effects. We may not be the first other civilization they encounter, so for them to make it to us, they may have had to successfully navigate or defeat other alien civilizations, which we have not had to do yet.</p>\n", "parentCommentId": "Arpj8GqSfmzPiA6gg", "user": {"username": "MichaelStJules"}}, {"_id": "A6xBzwhfqECWMJksG", "postedAt": "2022-09-22T22:38:07.700Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>Awesome, I'll definitely check out out the links.</p>", "parentCommentId": "EGoxYTv5BhMxKrD3Z", "user": {"username": "Charles_Guthmann"}}, {"_id": "Nh2YogPwqRrPDBZbo", "postedAt": "2022-09-22T23:08:20.470Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>So I agree that this is a good point and selection will definitely apply but I feel like I still don't quite agree with the phrasing (though it is sort of nitpicky).&nbsp;</p><p>&gt;For them to make it to us</p><p>The original reason I asked op the question was that I don't understand why there is a higher chance they make it to us vs we make it to them. We should start by taking a prior something like 50/50 of us discovering/reaching a civ vs them discovering us. Then, If we are early, we are much more likely to encounter than be encountered.&nbsp;</p><p>Any thoughts on how many ICs we expect a civ that makes it to us to have encountered before us?</p><p>&nbsp;</p><p>I think op is correct in their point but missing half the argument.&nbsp;</p><p>&gt;(e.g. the difference between now and 1 AD on earth is cosmologically very small, but technologically pretty big)</p><p>This is basically correct but it goes <i>both</i> ways. If we hit aliens, or &nbsp;they hit us, and we have not both maxed out all of our stats and are in the late game, then almost certainly one civ will be way more advanced than the other, and so prepratory war planning just isn't going to cut it. However if we think we are super likely to get wiped by aliens we can try to increase economic growth rates and that would make a difference.&nbsp;</p>", "parentCommentId": "xMcwcdXqXMeriErwM", "user": {"username": "Charles_Guthmann"}}, {"_id": "QpGjBzaYvCAmpejTo", "postedAt": "2022-09-23T04:12:53.259Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>We have not had any conflicts with any interstellar civilizations (ICs?) yet, so the first we have to deal with can't have had fewer conflicts with other interstellar civilizations than us, only a) the same as us (0), which counts in favour of neither of us, or b) more than us (&gt;0), which counts towards their advantage. So our prior should be that they have an advantage in expectation.</p>\n", "parentCommentId": "Nh2YogPwqRrPDBZbo", "user": {"username": "MichaelStJules"}}, {"_id": "bCpMtnMSgLKwuouNt", "postedAt": "2022-10-03T11:53:14.619Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>\"I also think that engagement on Twitter is still pretty underdeveloped and neglected (especially relative to the more nascent Progress Studies movement) as it seems like a lot of intellectuals frequent there and can be pretty moved by the content they see there regularly.\"<br><br>Curious about this! You're saying progress studies folks are more widely read? I think that's true, though I think in part it's because they slot more neatly into already-going-on political things, and I'm not sure we want to do that.</p>", "parentCommentId": null, "user": {"username": "ChanaMessinger"}}, {"_id": "hjLs7PDRbjeNr9EQd", "postedAt": "2022-10-03T11:57:50.595Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>I also want to upvote the critiques I like best.</p>", "parentCommentId": "xGGAAKjHCvoWzcmPE", "user": {"username": "ChanaMessinger"}}, {"_id": "tbPQCBzhewePaN3Bd", "postedAt": "2022-10-03T11:58:29.618Z", "postId": "X47rn28Xy5TRfGgSj", "htmlBody": "<p>I really liked this!</p>", "parentCommentId": null, "user": {"username": "ChanaMessinger"}}]