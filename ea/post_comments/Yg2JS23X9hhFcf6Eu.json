[{"_id": "izdakZLatXzmHFwzF", "postedAt": "2024-03-08T07:05:24.369Z", "postId": "Yg2JS23X9hhFcf6Eu", "htmlBody": "<p>Nice!\nI was surprised that more present-day harms were not more front of mind for respondents (e.g. job losses, AI pornography, and racial and gender bias were far below preventing catastrophic outcomes). Interesting.</p>\n", "parentCommentId": null, "user": {"username": "Oscar Delaney"}}, {"_id": "SWyY9JB4E7dpcuN6M", "postedAt": "2024-03-08T14:31:31.668Z", "postId": "Yg2JS23X9hhFcf6Eu", "htmlBody": "<p><strong>Executive summary:</strong> A survey of Australians found high levels of concern about risks from AI, especially catastrophic risks, and strong support for government action to regulate AI and prevent dangerous outcomes.</p><p><strong>Key points:</strong></p><ol><li>Australians are most concerned about AI systems acting in unsafe, untrustworthy ways not aligned with human values. Other priority risks include job loss, cyber attacks, autonomous weapons, and infrastructure failures.</li><li>Australians are skeptical of AI development overall, with opinions divided on whether it will be net positive or negative.</li><li>Preventing dangerous and catastrophic outcomes from AI is seen as the #1 priority for Australian government action on AI. Other priorities include mandatory safety audits, corporate liability for harms, and preventing human extinction.</li><li>90% support a national government body to regulate AI, and 80% think Australia should lead international AI governance.</li><li>AI is seen as a major existential risk, judged as the 3rd most likely cause of human extinction after nuclear war and climate change. 1 in 3 think AI-caused extinction is at least moderately likely in the next 50 years.</li><li>The findings suggest the Australian government should broaden its AI risk considerations, establish a national AI regulator, require safety audits and corporate liability, and prioritize preventing catastrophic risks from frontier AI systems.</li></ol><p>&nbsp;</p><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}, {"_id": "QzXP6Zvgpp9PRvk5D", "postedAt": "2024-03-08T14:57:17.552Z", "postId": "Yg2JS23X9hhFcf6Eu", "htmlBody": "<p>Thanks for sharing. This is a very insightful piece. Im surprised that folks were more concerned about larger scale abstract risks compared to more well defined and smaller scale risks (like bias). I'm also surprised that they are this pro regulation (including a Sox months pause). Given this, I feel a bit confused that they mostly support the development of AI and I wonder what had most shaped their view.</p>\n<p>Overall, I mildly worry that the survey led people to express more concern than they feel. Because this seems surprisingly close to my perception of the views of many existential risks \"experts\". What do you think?</p>\n<p>Would love to see this for other countries too. How feasible do you think that would be?</p>\n", "parentCommentId": null, "user": {"username": "SebastianSchmidt"}}, {"_id": "YkKt4nEuv4Xk683iF", "postedAt": "2024-03-08T18:51:11.130Z", "postId": "Yg2JS23X9hhFcf6Eu", "htmlBody": "<p>Great that you got it into The Conversation! And appreciate the key takeaways box at the start here</p>", "parentCommentId": null, "user": {"username": "bec_hawk"}}, {"_id": "unpjtoiMWrnAs5uSt", "postedAt": "2024-03-10T04:15:47.416Z", "postId": "Yg2JS23X9hhFcf6Eu", "htmlBody": "<p>Thanks Seb. I'm not that surprised\u2014public surveys in the <a href=\"https://forecastingresearch.org/s/XPT.pdf\">Existential Risk Persuasion tournament were pretty high (5% for AI).</a> I don't think most people are good at calibrating probabilities between 0.001% and 10% (myself included).</p><p>I don't have strong hypotheses why people 'mostly support' something they also want treated with such care. My weak ones would be 'people like technology but when asked about what the government should do, want them to keep them safe (remove biggest threats).' For example, Australians support <a href=\"https://poll.lowyinstitute.org/charts/acquiring-nuclear-powered-submarines/\">getting nuclear submarines</a> but also support the ban on <a href=\"https://icanw.org.au/new-poll-results/\">nuclear weapons</a>. I don't necessarily see this as a contradiction\u2014\"keep me safe\" priorities would lead to both. I don't know if our answers would have changed if we made the trade-offs more salient (e.g., here's what you'd lose if we took this policy action prioritising risks). Interested in suggestions for how we could do that better.</p><p>It'd be easy for us to run in other countries. We'll put the data and code online soon. If someone's keen to run the 'get it in the hands of people who want to use it' piece, we could also do the 'run the survey and make a technical report one'. It's all in R so the marginal cost of another country is low. We'd need access to census data to do the <a href=\"https://aigovernance.org.au/survey/sara_technical_report.html#we-analysed-the-data-using-a-new-approach-called-multiple-regression-with-post-stratification-mrp\">statistical adjustment to estimate population agreement</a> (but that should be easy to see if possible).</p>", "parentCommentId": "QzXP6Zvgpp9PRvk5D", "user": {"username": "mnoetel"}}, {"_id": "BhsYGf2t49caLdRyZ", "postedAt": "2024-03-11T06:17:33.288Z", "postId": "Yg2JS23X9hhFcf6Eu", "htmlBody": "<p>Just FYI, the <a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Faigovernance.org.au%2Fsurvey\">link</a> at the top doesn't work for me.</p>", "parentCommentId": null, "user": {"username": "Peterslattery"}}, {"_id": "GqCJBZTjpwwpxTGG8", "postedAt": "2024-03-11T21:55:06.070Z", "postId": "Yg2JS23X9hhFcf6Eu", "htmlBody": "<p>Thanks. Hmm. The vibe I'm getting from these answers is P(extinction)&gt;5% (which is higher than the XST you linked).</p>\n<p>Ohh that's great. We're starting to do significant work in India and would be interested in knowing similar things there. Any idea of what it'd cost to run there?</p>\n", "parentCommentId": "unpjtoiMWrnAs5uSt", "user": {"username": "SebastianSchmidt"}}, {"_id": "Cm74pWfaH98iMdzcg", "postedAt": "2024-03-25T04:40:11.128Z", "postId": "Yg2JS23X9hhFcf6Eu", "htmlBody": "<p>Thanks Peter. Fixed!</p>\n", "parentCommentId": "BhsYGf2t49caLdRyZ", "user": {"username": "mnoetel"}}]