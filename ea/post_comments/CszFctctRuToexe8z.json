[{"_id": "wCtMivt4dWds5Cm4Z", "postedAt": "2024-02-09T11:03:25.473Z", "postId": "CszFctctRuToexe8z", "htmlBody": "<p>Thanks for sharing this! I'm going to use this thread as a chance to flag some other recent updates (no particular order or selection criteria \u2014 just what I've recently thought was notable or recently mentioned to people):&nbsp;</p><ol><li><a href=\"https://subscriber.politicopro.com/article/2024/02/california-proposes-sweeping-safety-measure-for-ai-00140493\">California proposes sweeping safety measure for AI</a> \u2014 State Sen. Scott Wiener wants to require companies to run safety tests before deploying AI models. (link goes to \"Politico Pro\"; I only see the top half)<ol><li>Here's also <a href=\"https://x.com/Scott_Wiener/status/1755650108287578585?s=20\">Senator Scott Wiener's Twitter thread on the topic</a> (note the endorsements)</li><li>See also the <a href=\"https://forum.effectivealtruism.org/topics/california-effect\">California effect</a></li></ol></li><li><a href=\"https://thehill.com/homenews/media/4444138-trump-ai-dangerous-bartiromo-fox-business/\">Trump: AI \u2018maybe the most dangerous thing out there\u2019</a> (seems mostly focused on voting-related robocalls/deepfakes and digital currency)</li><li>Jacobin publishes an article on AI existential risk (<a href=\"https://x.com/jacobin/status/1755385956792668331?s=20\">Twitter</a>)</li></ol>", "parentCommentId": null, "user": {"username": "Lizka"}}]