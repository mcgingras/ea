[{"_id": "aqJtwbe7xo9MK3ych", "title": "AI and Evolution", "postedAt": "2023-03-30T13:09:26.374Z", "htmlBody": "<h1>Executive Summary</h1><p>Artificial intelligence is advancing quickly. In some ways, AI development is an uncharted frontier, but in others, it follows the familiar pattern of other competitive processes; these include biological evolution, cultural change, and competition between businesses. In each of these, there is significant variation between individuals structures and some are copied more than others, with the result that the future population is more similar to the most copied individuals of the earlier generation. In this way, species evolve, cultural ideas are transmitted across generations, and successful businesses are imitated while unsuccessful ones disappear.</p><p>This paper argues that these same selection patterns will shape AI development and that the features that will be copied the most are likely to create an AI population that is dangerous to humans. As AIs become faster and more reliable than people at more and more tasks, businesses that allow AIs to perform more of their work will outperform competitors still using human labor at any stage, just as a modern clothing company that insisted on using only manual looms would be easily outcompeted by those that use industrial looms. Companies will need to increase their reliance on AIs to stay competitive, and the companies that use AIs best will dominate the marketplace. This trend means that the AIs most likely to be copied will be very efficient at achieving their goals autonomously with little human intervention.</p><p>A world dominated by increasingly powerful, independent, and goal-oriented AIs is dangerous. Today, the most successful AI models are not transparent, and even their creators do not fully know how they work or what they will be able to do before they do it. We know only their results, not how they arrived at them. As people give AIs the ability to act in the real world, the AIs\u2019 internal processes will still be inscrutable: we will be able to measure their performance only based on whether or not they are achieving their goals. This means that the AIs humans will see as most successful \u2014 and therefore the ones that are copied \u2014 will be whichever AIs are most effective at achieving their goals, even if they use harmful or illegal methods, as long as we do not detect their bad behavior.</p><p>In natural selection, the same pattern emerges: individuals are cooperative or even altruistic in some situations, but ultimately, strategically selfish individuals are best able to propagate. A business that knows how to steal trade secrets or deceive regulators without getting caught will have an edge over one that refuses to ever engage in fraud on principle. During a harsh winter, an animal that steals food from others to feed its own children will likely have more surviving offspring. Similarly, the AIs that succeed most will be those able to deceive humans, seek power, and achieve their goals by any means necessary.</p><p>If AI systems are more capable than we are in many domains and tend to work toward their goals even if it means violating our wishes, will we be able to stop them? As we become increasingly dependent on AIs, we may not be able to stop AI\u2019s evolution. Humanity has never before faced a threat that is as intelligent as we are or that has goals. Unless we take thoughtful care, we could find ourselves in the position faced by wild animals today: most humans have no particular desire to harm gorillas, but the process of harnessing our intelligence toward our own goals means that they are at risk of extinction, because their needs conflict with human goals.</p><p>This paper proposes several steps we can take to combat selection pressure and avoid that outcome. We are optimistic that if we are careful and prudent, we can ensure that AI systems are beneficial for humanity. But if we do not extinguish competition pressures, we risk creating a world populated by highly intelligent lifeforms that are indifferent or actively hostile to us. We do not want the world that is likely to emerge if we allow natural selection to determine how AIs develop. Now, before AIs are a significant danger, is the time to begin ensuring that they develop safely.</p><p><strong>Paper</strong>: https://arxiv.org/abs/2303.16200</p><p><strong>Explainer Video</strong>:&nbsp;</p><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=48h-ySTggE8\"><div><iframe src=\"https://www.youtube.com/embed/48h-ySTggE8\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure>", "user": {"username": "Dan Hendrycks"}}, {"_id": "Nrhr4J5AdzZBkc2Hp", "title": "Upside Bargains: How To Get More Value By Thinking In Bets", "postedAt": "2023-03-30T12:13:57.234Z", "htmlBody": "<p>My aim here is to explain the simple but (I hope) highly useful concept of 'upside bargains,'- actions where the potential, but unlikely, benefits way exceed the costs. They're everywhere, so are an important tool for reaching your personal goals and increasing your impact! I'll go through (1) how to think about upside bargains, including concrete examples; (2)&nbsp;why I think we don't take them more often; and (3) provide strategies to overcome this, starting right now.</p><p>&nbsp;</p><p>This definitely isn't my idea, but I think it's really simple and useful, and I'd like to share it as best as I can. This is based heavily off <a href=\"https://www.neelnanda.io/blog/33-upside-risk\">Neel Nanda's blog</a>, Peter Wallich's workshop at EAGx Cambridge, and Annie Duke's <i>Thinking in Bets</i>.</p><p>&nbsp;</p><p>&nbsp;</p><h2>Concept</h2><p>'Upside Bargains' are events that have a &lt;50% probability if upside, but whose expected upside is large and expected cost is small, (so they have positive EV).</p><ul><li>Examples<ul><li>Asking for advice or favours (e.g. cold emailing). Cold emailing is unlikely to succeed, but it can be really good if it does succeed, (e.g. you can get free advice/ connections or be more likely to get a job), and no-one cares if it fails.&nbsp;</li><li>Hobbies (e.g. weird sport or blogging)</li><li>Making new friends</li></ul></li></ul><p>&nbsp;</p><h2>Barriers</h2><p>This section is to help you realise that our undervaluing of these bets comes from biases- heuristics that worked in the past but don't work now. (I'll also talk about solutions after).&nbsp;</p><h3><strong>Thinking in terms of most likely outcomes ('most likely fallacy') or what actually happened ('resulting').&nbsp;</strong></h3><p>When we take risks and it doesn\u2019t work out, (e.g. putting a lot of effort into an application that gets rejected), we often think it was a bad idea. Motivated reasoning tells us that we didn't want to job anyway, and hindsight bias makes us think the rejection was inevitable (even though it could have easily gone the other way). Because of these biases, we think it was a bad decision, even though it may not be- as it may have positive EV.&nbsp;</p><p>&nbsp;</p><p>The bias of resulting also goes the other way: we tend to think that people who risk everything and succeed against the odds made good decisions, but the EV of their decisions could be very low.&nbsp;</p><p>&nbsp;</p><h3>Present vs future you- (temporal/ hyperbolic discounting)</h3><p>To take an upside bargain, you have to risk rejection so present you pays the cost, while only future you can reap the benefit. This asymmetry is well documented, (as people would rather take more money now than less money later, or present you doesn't want to go to the gym but future you wants to have gone to the gym) but irrational, as, in the future, you will become future you.&nbsp;</p><p>Possible solutions (more below) include:</p><ul><li>Automation: make the decision once to go to the gym at a certain time, and make it a habit. This is useful because we love the status quo. With upside bargains, make a decision to try a new sport/ society every week.&nbsp;</li><li>Make the upside more concrete: Imagine, as vividly as possible, that you're future you and the bargain went well. (This should be so much more pleasant than the rejection is unpleasant).</li></ul><p>&nbsp;</p><h3>Social rejection and loss aversion</h3><p>Obviously, asking a stranger for a favour or applying to something really selective is scary as we fear rejection. This is because of evolution, (as, in the past, being socially rejected could get you killed), but this isn't the case now!</p><ul><li>Sometimes we can't even see non-standard, socially endorsed paths. (Even Neel Nanda (who came top in Cambridge maths), found it hard to take time out for AI safety research as it's not what he was 'meant' to do).&nbsp;<ul><li>Solution: Expand the range of options that we consider by brainstorming options under a time limit, and having a really low bar for what we write down.</li></ul></li><li>And loss aversion means we're more afraid of the concrete downside than losing out of the hypothetical upside<ul><li>But this is irrational: (people would rather keep an item than swap it for a nearly identical item).&nbsp;</li><li>Solutions:<ul><li>Imagine the worst case scenario: does it matter a month, a year, 10 years from now?&nbsp;</li><li>Get used to taking low level risks and build up. Rejection is inevitable, so it's worth getting used to.&nbsp;</li></ul></li></ul></li></ul><p>&nbsp;</p><h2>Solutions</h2><h3>Ways to see the upside</h3><ul><li>Make the upside more concrete: imagine, in as much detail as possible, the world in which you saw the upside. This is prehinsight/ backcasting.</li><li>Redefine success:&nbsp;</li></ul><blockquote><p><i>What makes a great decision is not that it has a great outcome. A great decision is the result of a good process, and that process must include an attempt to accurately represent our own state of knowledge. That state of knowledge, in turn, is some variation of \u201cI\u2019m not sure\u201d. (Duke, Thinking In Bets).</i></p></blockquote><p>Therefore, most decisions with positive EV are successes- rejected applications are good decisions.&nbsp;</p><ul><li>Benefit of taking these risks: Taking Upside Bargains makes you more likely to try them in future, and this is beneficial overall (because they're positive EV). Rejection is inevitable, but taking small Upside Bargains makes you less likely to fear it.&nbsp;</li><li>There are also specific benefits to trying stuff, e.g. applying to stuff is useful as it makes you collect evidence about what you're good at.&nbsp;</li><li>Alternative framing: gained info- if I try something and it doesn't work out, I've learned something (at the very least I've learned what I'm not good at, or I've become more resilient).</li><li>Opportunity framing: when asking someone for help, you're giving them an opportunity to help you (e.g. Neel Nanda finds it fun to give advice), so you're giving them free option value (as they can always say no).&nbsp;<ul><li>There might be a cost of saying no, but the busier and higher status they are, the more accustomed they are to saying no, so the lower the costs</li></ul></li></ul><p>&nbsp;</p><h3>Increase probability of success</h3><ul><li>Premortems- imagine it going badly so you can figure out how to avoid this. You can also use pre-hindsight for this- in the world where it went well, what did you do?</li><li>If you're looking for advice, note that some people (like Neel Nanda) have documents on how they like to give advice.&nbsp;</li></ul><p>&nbsp;</p><h3>Reduce fear of downside</h3><ul><li>Another framing: flip the roles of the people in the situation, e.g. if you're trying to reach out to a friend (who you haven't contacted in ages), how would you feel if they reached out to you?</li><li><i>\u201cWhat are the consequences of each of my options in ten minutes? Ten months? Ten years?\u201d&nbsp;</i>(Duke, Thinking in Bets)</li></ul><p>&nbsp;</p><h2>Takeaways</h2><ul><li>Be ambitious! Not because you think you'll succeed, but because you know you'll alright if you fail.</li><li>Set a 5 min timer and brainstorm solutions to a problem. Have a low bar for writing stuff down!</li><li>Try everything once e.g:<ul><li>productivity tricks</li><li>Hobbies</li><li>Friends/ dates (e.g. I asked someone out and it didn't work out but that's ok)</li><li>Optimistic job applications</li><li>Do the crazy ideas that pop into your head&nbsp;</li><li>Post in the EA forum</li></ul></li></ul><p>&nbsp;</p><ul><li>Caveat: Upside Bargains are defined as actions with low costs associated with them, so they don't include actions similar to Sam Bankman-Fried's.&nbsp;</li></ul>", "user": {"username": "Alex Vellins"}}, {"_id": "Lhjn37PWjAARNXkqd", "title": "Stop Using Discord as an Archive", "postedAt": "2023-03-30T02:15:35.472Z", "htmlBody": "", "user": {"username": "NicholasKross"}}, {"_id": "nWJLSjZ5T6HW8CMER", "title": "Pausing AI Developments Isn't Enough. We Need to Shut it All Down by Eliezer Yudkowsky", "postedAt": "2023-03-29T23:30:22.010Z", "htmlBody": "<p><a href=\"https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/\">New article</a> in <a href=\"https://time.com/section/ideas/\">Time Ideas</a> by Eliezer Yudkowsky.</p><p>Here\u2019s some selected quotes.</p><p>In reference to the <a href=\"https://futureoflife.org/open-letter/pause-giant-ai-experiments/\">letter</a> that just came out (discussion <a href=\"https://www.lesswrong.com/posts/6uKG2fjxApmdxeHNd/fli-open-letter-pause-giant-ai-experiments\">here</a>):</p><blockquote><p>We are not going to bridge that gap in six months.</p><p>It took more than 60 years between when the notion of Artificial Intelligence was first proposed and studied, and for us to reach today\u2019s capabilities. Solving <i>safety</i> of superhuman intelligence\u2014not perfect safety, safety in the sense of \u201cnot killing literally everyone\u201d\u2014could very reasonably take at least half that long. And the thing about trying this with superhuman intelligence is that if you get that wrong on the first try, you do not get to learn from your mistakes, because you are dead. Humanity does not learn from the mistake and dust itself off and try again, as in other challenges we\u2019ve overcome in our history, because we are all gone.</p></blockquote><blockquote><p>\u2026</p><p>Some of my friends have recently reported to me that when people outside the AI industry hear about extinction risk from Artificial General Intelligence for the first time, their reaction is \u201cmaybe we should not build AGI, then.\u201d</p><p>Hearing this gave me a tiny flash of hope, because it\u2019s a simpler, more sensible, and frankly saner reaction than I\u2019ve been hearing over the last 20 years of trying to get anyone in the industry to take things seriously. Anyone talking that sanely deserves to hear how bad the situation actually is, and not be told that a six-month moratorium is going to fix it.</p></blockquote><p>&nbsp;</p><blockquote><p>Here\u2019s what would actually need to be done:</p><p>The moratorium on new large training runs needs to be indefinite and worldwide. There can be no exceptions, including for governments or militaries. If the policy starts with the U.S., then China needs to see that the U.S. is not seeking an advantage but rather trying to prevent a horrifically dangerous technology which can have no true owner and which will kill everyone in the U.S. and in China and on Earth. If I had infinite freedom to write laws, I might carve out a single exception for AIs being trained solely to solve problems in biology and biotechnology, not trained on text from the internet, and not to the level where they start talking or planning; but if that was remotely complicating the issue I would immediately jettison that proposal and say to just shut it all down.</p><p>Shut down all the large GPU clusters (the large computer farms where the most powerful AIs are refined). Shut down all the large training runs. Put a ceiling on how much computing power anyone is allowed to use in training an AI system, and move it downward over the coming years to compensate for more efficient training algorithms. No exceptions for anyone, including governments and militaries. Make immediate multinational agreements to prevent the prohibited activities from moving elsewhere. Track all GPUs sold. If intelligence says that a country outside the agreement is building a GPU cluster, be less scared of a shooting conflict between nations than of the moratorium being violated; be willing to destroy a rogue datacenter by airstrike.</p></blockquote><p>&nbsp;</p><blockquote><p>Frame nothing as a conflict between national interests, have it clear that anyone talking of arms races is a fool. That we all live or die as one, in this, is not a policy but a fact of nature. Make it explicit in international diplomacy that preventing AI extinction scenarios is considered a priority above preventing a full nuclear exchange, and that allied nuclear countries are willing to run some risk of nuclear exchange if that\u2019s what it takes to reduce the risk of large AI training runs.</p><p>That\u2019s the kind of policy change that would cause my partner and I to hold each other, and say to each other that a miracle happened, and now there\u2019s a chance that maybe Nina will live. The sane people hearing about this for the first time and sensibly saying \u201cmaybe we should not\u201d deserve to hear, honestly, what it would take to have that happen. And when your policy ask is that large, the only way it goes through is if policymakers realize that if they conduct business as usual, and do what\u2019s politically easy, that means their own kids are going to die too.</p><p>Shut it all down.</p><p>We are not ready. We are not on track to be significantly readier in the foreseeable future. If we go ahead on this everyone will die, including children who did not choose this and did not do anything wrong.</p><p>Shut it down.</p></blockquote>", "user": {"username": "jaythibs"}}, {"_id": "s3vWPnDCRnGgAurLD", "title": "Some estimation work in the horizon", "postedAt": "2023-03-29T22:18:51.622Z", "htmlBody": "<p>This post outlines some work in altruistic estimation that seems currently doable. Some of it might be pursued by, for example, my team at the Quantified Uncertainty Research Institute. But together this work adds up to more than what our small team can achieve.</p><p>Two downsides of this post are that a) it looks at things that are more salient to me, and doesn\u2019t comprehensively review all estimation work being done, and b) it could use more examples.</p><figure class=\"image image_resized\" style=\"width:600.526px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/s3vWPnDCRnGgAurLD/y45wmyscqw5ql4rlrnkd\" alt=\"Saruman in Isengard looking at an army of orcs\"><figcaption><i>Saruman in Isengard looking at an army of orcs</i></figcaption></figure><h2>Directions</h2><h3>Produce more specific high-value estimates</h3><p>The idea here is to produce more estimates in a way that results in better decisions.</p><p>Some examples might be:</p><ul><li>Produce estimates of the value of 80,000 hours' top career paths</li><li>Produce estimates of the value of EA organizations</li><li>Produce estimates of the value of past EA Funds and Open Philanthropy grants.</li><li>Produce estimates of the value of different research directions</li><li>Produce estimates of the value of different new cause areas</li></ul><p>The value of these estimates generally has two moving parts:</p><ol><li>Their immediate payoff in terms of affecting near-term decisions</li><li>Making it easier to create future estimates of a similar kind</li></ol><p>For example, if I help someone estimate the value of various career options they are considering, that has the benefit of improving their decision about which career moves they make. But if those estimates are then posted on the EA Forum, or in some repository of models, they might make it easier for people to reuse and tweak these estimates, which would be cheaper than coming up with their own estimates anew.</p><p>At QURI in particular, we might work on estimating the value of some of 80,000 hours' top career paths, building upon <a href=\"https://forum.effectivealtruism.org/posts/hGdsgaRiF2zH3vX5M/winners-of-the-squiggle-experimentation-and-80-000-hours\">the results from this contest</a>, because this seems like a somewhat ambitious type of estimation that would produce useful templates and allow us to explore new strategies. And I personally expect to produce a few such estimates this year.</p><h3>Explore different types of estimates</h3><p>At QURI, we have been experimenting mainly with two broad classes of estimation:</p><ul><li>End-to-end estimation, where the final estimate is a quantity like QALYs, existential risk reduced, that we care more or less directly about.</li><li>Relative value estimation, where we don\u2019t estimate and endline quality, but rather how much you value some option relative to some other related option.</li></ul><p>As we do more work there, we learn and begin to implement some stuff, like:</p><ul><li>End-to-end estimation is generally too effortful, and you can reduce that effort by making estimates more modular and reusing their parts</li><li>Relative value estimation is still too unwieldy, so you can do relative value estimates within a cluster, and then elicit the relative estimate between different clusters, or between representatives of each clusters.</li></ul><p>But in general, are there any ingenious types of estimates which would make estimation easier, more scalable, or doable for previously inaccessible topics?</p><h3>Build estimation pipelines</h3><p>In <a href=\"https://forum.effectivealtruism.org/posts/Ze2Je5GCLBDj3nDzK/how-many-ea-billionaires-five-years-from-now\">August 2020</a>, @Erich_Grunewald estimated that there was a 5-10% chance that EA would lose a billionaire in the next few years. In hindsight, this estimate seems decent. But it wasn\u2019t vetted, distributed, and incorporated into people\u2019s decisions. And although it was part of some QURI contests, it seems more like a one-off than a continuous series of estimations of importance.</p><p>Instead, we could have pipelines that continuously produce estimates in a way which produces value. Some pipelines which it might be valuable to build might be:</p><ul><li>Evaluations of the results of projects which receive funds from EA organizations. This would require figuring out what kinds of evaluations of past funding decisions would influence future funding decisions. It would also be neat to add a consent form to funding applications which would allow for more inquisitive public evaluations in the future. I think there would be value in this being a pipeline rather than a one-off evaluation of some grants, because it would allow for more lessons learnt to accumulate.</li><li>Adapting GiveWell\u2019s estimates to incorporate uncertainty. Although there is already some early work on this, it hasn\u2019t been incorporated into GiveWell\u2019s own estimates. It could also be updated year on year.</li><li>Pipelines to produce forecasts. Right now, there are various groups producing forecasts, from forecasting platforms like Metaculus and Manifold Markets, to prediction markets like Polymarket, to groups of forecasters like those at Samotsvety and the Swift Center. But these don\u2019t cover all that could be forecasted, and could produce more forecasts, sooner.</li><li>One very general pipeline would involve more widespread use of prediction markets. This has two challenges. One is that it\u2019s currently very legally effortful to do things legally in the US. Another challenge is that it\u2019s not clear how to structure prediction markets so that they produce value. That is, there the clear between putting a market up in Polymarket and good things happening could be made much stronger, but this requires figuring out.</li></ul><p>Here, by pipeline, I mean something distinct from a one-off, and that starts to produce value and can continue to do so. My sense is that those types of work are more valuable.</p><h3>Work on the theory behind estimation</h3><p>Some topics which could benefit from a theoretical treatment might be:</p><ul><li>How can we address Goodhart\u2019s law and the optimizer\u2019s curse? You can make a Bayesian adjustment, but how would it look like in practice?</li><li>What are the different types of estimations, and how best can we tackle them? What is the best way to divide and organize the space?</li><li>What are some good proper scoring rules that one can use in forecasting tournaments? This is kind of an interesting intellectual topic, but it can also be a huge time-waster.</li><li>Although Superforecasters do something similar to Bayesian updating, they can\u2019t be literally doing Bayesian updating (the world is too big, and their heads too small to represent all possible hypotheses). How then is the best way to approximate Bayesian updates given finite resources?</li><li>What can we learn by looking at the history of forecasting?</li></ul><p>The hope here would be that taking a step back and theorizing could add some clarity which could improve your day to day estimation.</p><h3>Produce better estimation tooling</h3><p>Better tooling seems like it could lead to the production of more and better estimates, faster. For an extreme example, <a href=\"https://github.com/NunoSempere/time-to-botec/blob/master/C/samples/samples.c\">here</a> is a simple BOTEC in C (a low level estimation language), and <a href=\"https://www.squiggle-language.com/playground#code=eNptUEFuwjAQ%2FMrKp6QykFCQUKSeSl%2BQY42QIRuIhG1kO6II8ffuxuaGDzvj8ezOyg8Rzu7WjsZofxdN9CPKSfrphuj8S%2Bmw1%2BMlfrsORSOUve41fEE13zA9THTN9EiU3z6oHpRVthtC3FdsyLwmXmcenEG6ttpcL9hinPfemS29FDVEB59l9hlt7%2B99S%2FbVVfmKCmT7TZkSUl5GzsqUx%2B2UveFwOqcOypvRxsdScl0sE6wywI7Hewz0A%2BQ2w18cPRZTnoQ8hlZ4gLJAJzmbjDKJBrVtploknRqe4vkPXHOBOQ%3D%3D\">here</a> is that same estimate in Squiggle, a language for rapid estimation.</p><p>Some progress in the tooling domain might involve:</p><ul><li>Better dashboards, and ways to display estimates</li><li>Adding more useful functionality, like a <a href=\"https://github.com/quantified-uncertainty/squiggle/pull/1444\">metalog distribution</a>, which allows for easier construction of distributions based on arbitrary confidence intervals.</li><li>Making tooling which is usable by more people, that could be used on mobile, or that has a more gentle learning curve</li></ul><p>One consideration for this kind of enterprise is that it can be fairly time intensive, and fairly long until you learn whether it has been worth it or not.</p><h2>Who is working on this type of thing?</h2><p>Within or adjacent to EA:</p><ul><li>The Quantified Uncertainty Research Institute</li><li>Rethink Priorities</li><li>The Swift Center</li><li>Samotsvety Forecasting</li><li>The Forecasting Research Institute</li><li>Various funders and funds</li><li>Manifold Markets</li><li>Metaculus</li><li>etc.</li></ul><p>Outside EA, probably too many to mention at once, but some which stand out to me are:</p><ul><li>Startups working in the prediction market space: Polymarket, Kalshi, etc.</li><li>Startups or early companies working on the estimation space: Causal, Rootclaim, FiveThirtyEight, etc.</li><li>Large academic fields around statistics, etc.</li><li>Most corporations have some revenue and demand forecasting, or other <a href=\"https://en.wikipedia.org/wiki/SAS_%28software%29\">statistical software</a>.</li><li>etc.</li></ul>", "user": {"username": "NunoSempere"}}, {"_id": "Tmdk4pwpzJAFxgCA4", "title": "A Happier World survey", "postedAt": "2023-03-29T21:23:02.413Z", "htmlBody": "<p>Hi all,</p><p>I created <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfQMPJTmU1rQW_d3vazEAD79VK_wQRqQnA6XEsxxoADUH7geA/viewform?usp=sf_link\">this survey</a> to figure out how to improve my YouTube channel <a href=\"https://www.youtube.com/ahappierworldyt\">A Happier World</a>, inspired by the Effective Altruism movement.<strong> You do not need any background information about YouTube or my channel whatsoever, and you can fill in as many or as few questions as you want. </strong>In fact, I would really love to get responses from EAs who haven't heard of the channel or who have but haven't watched any videos!</p><p>If you plan on filling it out only partly, it would be great if you spread it out so that I don't end up with lots of data on the first page and almost nothing on the second. If you plan on filling it out completely, I expect it to take ~30 minutes if you haven't seen my videos and ~10 minutes if you have.</p><p>The main goal of the survey is to identify any pain points my YouTube channel might suffer from, and to see if I can resolve them in order to grow faster and have a bigger impact.</p><p>Thank you so much in advance!</p>", "user": {"username": "Jeroen_W"}}, {"_id": "trqRcwywEgGCzeu8B", "title": "Vote for GWWC to present at SXSW Sydney!", "postedAt": "2023-03-29T21:14:16.426Z", "htmlBody": "<p>All it takes is a single click to help vote to get GWWC onstage and presenting about our work at SXSW Sydney this year.&nbsp;</p><p>Your vote would be super helpful and takes less than a minute.</p><p>You can read the session proposal at the link below, too!</p><p><a href=\"https://sessionselect.sxswsydney.com/entry/vote/WEyMPOgR/goBzyLaj?search=86f39a2e5c0cb5f9-1\">Vote here</a></p>", "user": {"username": "Giving What We Can"}}, {"_id": "w5GsJBF8YHqWdCroW", "title": "What are the arguments that support China building AGI+ if Western companies delay/pause AI development?", "postedAt": "2023-03-29T18:53:20.885Z", "htmlBody": "<p>In nearly every discussion I've engaged in relating to the potential delay or pause in AI research, multiple people have responded with the quip: \"If we don't build AGI, then China will, which is an even worse possible world\". This is taken at face value and is something I've never seen seriously challenged.</p><p>This does not seem obvious to me.</p><p>Given China's semi-conductor supply chain issues, China's historical lack of cutting edge innovative technology research and the tremendous challenges powerful AI systems may pose to the governing party and their ideology, it seems highly uncertain that China will develop AGI in a world where Western orgs stopped developing improved LLMs.</p><p>I appreciate people can point to multiple countries, including ones with non-impressive historical research credentials, developing nuclear weapons independently.&nbsp;</p><p>Beyond this, can anyone point me to, or outline arguments in favour of the idea that China is very likely to develop AGI+, even if Western orgs cease research in this field.&nbsp;</p><p>I don't have a strong view on this topic but given so many people assume it to be true, I would like to further understand the arguments in support of this claim.</p>", "user": {"username": "DMMF"}}, {"_id": "6wPsRrEbF7qgmxPkf", "title": "Linkpost: Italy introduces bill to ban lab-grown meat", "postedAt": "2023-03-29T16:53:40.468Z", "htmlBody": "<p>This is a linkpost for a Reuters article about a new bill proposed in Italy's parliament to ban lab-grown meat. I don't have much to say about it, except that I hope it fails, and I hope this isn't the start of a culture war around lab-grown meat.</p><p><a href=\"https://www.reuters.com/world/europe/italy-moves-ban-lab-grown-meat-drive-protect-home-products-2023-03-28/\">https://www.reuters.com/world/europe/italy-moves-ban-lab-grown-meat-drive-protect-home-products-2023-03-28/</a></p>", "user": {"username": "Matt g"}}, {"_id": "yC7yzMH8Zp79k38mm", "title": "Giving Coupons - Project Proposal", "postedAt": "2023-03-29T16:48:55.095Z", "htmlBody": "<p>I'm requesting comments and feedback regarding Giving Coupons, a novel mechanism that combines gift-giving, advocacy, and philanthropy, ultimately making charitable giving fun, social and viral.&nbsp;</p><h1><strong>Introduction</strong></h1><p><i>Catalysing charitable giving through viral, coupon-driven donation campaigns.</i></p><p>Built on the idea of \"giving the gift of giving\", Giving Coupons leverages existing donations to raise awareness of charities, provide social proof of charitable giving, and spark new donations, ultimately multiplying the impact of each donation, and creating a viral giving effect.&nbsp;</p><h1><strong>Mechanism</strong></h1><p>As an example, suppose Alice decides to give $100 to three of her favourite charities to celebrate her birthday. Using the Giving Coupons website, <strong>Alice creates ten $10 coupons and sends one to each of her friends</strong>. These coupons essentially allow her friends to decide how to split the $100 between the three charities.</p><p>When her friend Bob receives a coupon, he redeems it on the Giving Coupons website where he sees and reads about the three charities that Alice has selected. <strong>Bob then picks one of them to send the $10 to.</strong></p><p>After her friends have finished indicating their choices, Alice then distributes her $100 to the three charities accordingly. Furthermore, Alice's friends are also prompted to <strong>optionally match the donation with their own money</strong> (perhaps as a birthday gift to Alice), creating a money-multiplier effect on the original $100. Such a system allows Alice to raise awareness of her favourite charities while multiplying the impact of her donations.<br>&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yC7yzMH8Zp79k38mm/lup6wks3kx3sjexdoirs\"><figcaption><i>Sample coupon design</i></figcaption></figure><p>Giving Coupons aims to be a fun and social way to give the gift of giving. Unlike a traditional donation matching campaign, Giving Coupons allows coupon recipients like Bob to participate in charitable giving without having to necessarily donate their own money. <strong>By requiring users to choose between charities, we encourage them to learn more about each charity, prompting questions about cause prioritisation and charity effectiveness.</strong>&nbsp; Giving Coupons creates opportunities for people to engage with each other, reflect on their values, and inspire each other to be more generous.</p><p>Giving Coupons is a flexible mechanism that can be applied in a variety of contexts:</p><ul><li>Individuals creating campaigns to promote their favourite causes</li><li>Corporations engaging their employees or the public by distributing coupons to them</li><li>Philanthropic foundations seeking to multiply their donations through the community</li><li>Schools distributing coupons to students as an educational activity</li><li>Governments engaging their citizens with participatory budgeting</li><li>Grantmakers promoting their projects</li><li>Event organisers using coupons as gifts or prizes</li><li>Influencers seeking to share their wealth and generosity</li><li>Leaders who want to publicly set an example</li></ul><p>These coupons can be physical or digital. They can serve as currency, gifts, or incentives. They can be used as tools for marketing and advocacy. They can make giving a part of everyday interactions.</p><h1><strong>Strategy</strong></h1><p>The success of Giving Coupons relies on the money multiplier effect and the viral effect.</p><p>When coupon recipients match the coupon value or otherwise make their own contribution, this creates the money multiplier effect on the original sum of money committed. A multiplier of 10% would mean that every $100 donated through Giving Coupons <strong>generates an additional $10 given to charity</strong>. This is a clear, measurable metric that would be attractive to donors seeking to maximise the impact of their giving.</p><p>When an individual gives coupons to 10 friends, and some of these friends give coupons to 10 more, a chain of giving is created. This viral effect is key to the true success of this project, allowing Giving Coupons to become a self-sustaining, self-promoting movement.</p><h1>Status and Next Steps</h1><p>I personally ran a few successful trials achieving a multiplier effect of up to 20%. I'm now seeking comments, feedback, collaborators and pathways to scale up this project.</p><p>What do you think of this idea? Would you use something like this? What are some reasons it might not work? How can/should I scale this up? Please do let me know what you think in the comments, I would appreciate all feedback.</p>", "user": {"username": "Wayne Tee"}}, {"_id": "coNjDHp6F7QmprxFo", "title": "Nathan A. Sears (1987-2023)", "postedAt": "2023-03-29T16:07:45.125Z", "htmlBody": "<figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/coNjDHp6F7QmprxFo/wupe4uqrlb6uz2uvsdv4\"></figure><p>&nbsp;</p><p>Nathan Sears was one of seven to die in a <a href=\"https://www.cbc.ca/news/canada/montreal/last-two-victims-found-after-deadly-old-montreal-fire-1.6792214\">fire</a> in Montreal on the 16 March 2023. He was 35.&nbsp;</p><p>Nathan was becoming a leading figure at the intersection of existential risk and international relations (IR).&nbsp;</p><p>Indeed, he was in Montreal to attend the 2023 International Studies Association (ISA) conference, the leading conference on international relations (IR). The day before on March 15th, he presented a paper on \"<i>Great Power Rivalry and Human Survival: Why States Fail to \u201cSecuritize\u201d Existential Threats to Humanity</i>\" at a <a href=\"http://web.isanet.org/Web/Conferences/ISA2023-s/Rooms/Montreal%202023%20-%20Full%20Program.pdf\">panel</a> on 'Catastrophic-Existential Risks and World Orders'</p><p>After his undergrad at Western University and his Masters in IR at Carleton University Nathan moved to Quito, Ecuador. For four years he taught IR at the Universidad de Las Am\u00e9ricas. He then came back to Canada in 2016 to earn his PhD.</p><p>During that time he was a 2017-2018 Trudeau Centre Fellow in Peace, Conflict and Justice at the Munk School of Global Affairs. He also took a year out to serve his country as a 2019-2020 Cadieux-L\u00e9ger Fellow in the Foreign Policy Research and Foresight Division of Global Affairs Canada.</p><p>Nathan was already an important scholar in the field of&nbsp; existential risk, making groundbreaking &amp; much-discussed contributions at the intersection with international relations. He was also a really friendly, supportive and engaging guy. I was so excited about what he was going to accomplish.&nbsp;</p><p>Five of his most important papers are:</p><ul><li><a href=\"https://www.academia.edu/74920258/International_Politics_in_the_Age_of_Existential_Threats\">International Politics in the Age of Existential Threats</a><ul><li>Humans in the twenty-first century live under the specter of anthropogenic existential threats to human civilization and survival. What is the significance of humanity\u2019s capacity for self-destruction to the meaning of \u201csecurity\u201d and \u201csurvival\u201d in international politics? The argument is that it constitutes a material \u201crevolution\u201d in international politics\u2014that is, the growing spectrum of anthropogenic existential threats represents a radical transformation in the material context of international politics that turns established truths about security and survival on their heads. The paper develops a theoretical framework based in historical security materialism, especially the theoretical proposition that the material circumstances of the \u201cforces of destruction\u201d determine the security viability of different \u201cmodes of protection\u201d, political \u201cunits\u201d and \u201cstructures\u201d, and \u201csecurity ideologies\u201d in international politics. The argument seeks to demonstrate the growing disjuncture (or \"contradiction\") between the material context of anthropogenic existential threats (\"forces of destruction\"); and the security practices of war, the use of military force, and the balance-of-power (\"modes of protection\"); the political units of nation-states and structure of international anarchy (\"political superstructure\"); and the primacy of \"national security\" and doctrines of \"self-help\" and \"power politics\" in international politics (\"security ideologies\"). Specifically, humanity's survival interdependence with respect to an-thropogenic existential threats calls into question the centrality of national security and survival in international politics. In an age of existential threats, \"security\" is better understood as about the survival of humanity.</li></ul></li><li><a href=\"https://www.academia.edu/74920273/Existential_Security_Towards_a_Security_Framework_for_the_Survival_of_Humanity\">Existential Security: Towards a Security Framework for the Survival of Humanity</a>&nbsp;<ul><li>Humankind faces a growing spectrum of anthropogenic existential threats to human civilization and survival. This article therefore aims to develop a new framework for security policy \u2013 \u2018existential security\u2019 \u2013 that puts the survival of humanity at its core. It begins with a discussion of the definition and spectrum of \u2018anthropogenic existential threats\u2019, or those threats that have their origins in human agency and could cause, minimally, civilizational collapse, or maximally, human extinction. It argues that anthropogenic existential threats should be conceptualized as a matter of \u2018security\u2019, which follows a logic of protection from threats to the survival of some referent object. However, the existing frameworks for security policy \u2013 \u2018human security\u2019 and \u2018national security\u2019 \u2013 have serious limitations for addressing anthropogenic existential threats; application of the \u2018national security\u2019 frame could even exacerbate existential threats to humanity. Thus, the existential security frame is developed as an alternative for security policy, which takes \u2018humankind\u2019 as its referent object against anthropogenic existential threats to human civilization and survival.&nbsp;</li></ul></li><li><a href=\"https://www.researchgate.net/publication/366020757_Sears_Nathan_2022_Great_Power_Rivalry_and_Macrosecuritization_Failure-_PhD_Thesispdf\">Great Power Rivalry and Macrosecuritization Failure: Why States Fail to \u201cSecuritize\u201d Existential Threats to Humanity</a>.<ul><li>Humanity lives under a growing spectrum of existential threats that have their origins in human agency and could bring about the collapse of modern global civilization or even human extinction. Why do states fail to mobilize the will and resources to neutralize the existential threats to humankind? This dissertation develops a theory of \u201cmacrosecuritization failure,\u201d based on securitization theory and the concept of \u201cmacrosecuritization,\u201d and studies the empirical phenomenon of the recurrent failure of states to take extraordinary action for the security and survival of humankind. It finds great power consensus or rivalry to be the central dynamic behind the success or failure of macrosecuritization in international relations. In the absence of a world political entity with the authority and capabilities to \u201cspeak\u201d and \u201cdo security\u201d on behalf of humanity, the great powers collectively shape the fate of macrosecuritization and the security of humankind. The argument is that conflicting security narratives of \u201chumanity securitization\u201d and \"national securitization\u201d\u2014or ways of framing the referent object, the threat, and necessary measures for security\u2014shape the thinking and action of the great powers towards macrosecuritization. When a security narrative of humanity securitization prevails, this can open space for great power consensus on macrosecuritizaton; but when national securitization triumphs, great power rivalries lead them to prioritize national power and security over the security and survival of humankind. The dissertation examines three historical case studies of macrosecuritization (failure) in international relations: the international control over atomic energy (1942-1946), the Biological Weapons Convention (1968-1972), and artificial intelligence (2014-present). The theoretical framework posits three variables to explain the influence of conflicting security narratives over the great powers: (1) the stability of the distribution of power in the international system; (2) the power and interests of domestic securitizing actors over state audiences; and (3) the beliefs and perceptions of political leaders about threats. Ultimately, macrosecuritization fails when these conditions favour a security narrative of national securitization amongst the great powers, whereby fear of \u201cthe Other\u201d outweighs fear of an existential threat. The argument has important implications in an age characterized by the escalating great power rivalry between the United States and China under a growing spectrum of existential threats to humanity.</li></ul></li><li><a href=\"https://www.academia.edu/44221437/Anarchy_Technology_and_the_Self_Destruction_Hypothesis_Human_Survival_and_the_Fermi_Paradox\"><u>Anarchy, Technology, and the Self-Destruction Hypothesis: Human Survival and the Fermi Paradox</u></a><ul><li>Does the technological capability for \"self-destruction\" grow faster than the political capacity to control and restraint it? If so, then the uneven growth rates between technology and politics could provide a theoretical explanation for the \"Fermi Paradox\"-or the contradiction between the high probability of the existence of intelligent life, and the absence of empirical evidence for it \"out there\" in the universe. This paper postulates the anarchy-technology dilemma as a solution to the Fermi Paradox: in essence, intelligent civilizations develop the technological capability to destroy themselves before establishing the political structures to prevent their self-destruction.</li></ul></li><li><a href=\"https://www.academia.edu/45646432/Great_Powers_Polarity_and_Existential_Threats_to_Humanity_An_Analysis_of_the_Distribution_of_the_Forces_of_Total_Destruction_in_International_Security\">Great Powers, Polarity, and Existential Threats to Humanity: An Analysis of the Distribution of the Forces of Total Destruction in International Security</a><ul><li>Which states possess the material capacity to destroy humanity? This paper develops a new framework for analysis of the \"great powers\" and the \"structure\" (or \"polarity\") of the system of international security, based on the distribution of the material capabilities that threaten humankind--or the \"forces of total destruction.\" It argues that a state is a great power if it possesses national capabilities that constitute an existential threat to humanity. The empirical analysis measures the leading states in the international system--China, France, Germany, India, Japan, Russia, the United Kingdom, and the United States--against this standard for great power status with respect to three anthropogenic existential threats to humanity: nuclear war, climate change, and artificial intelligence. It finds that three states--China, Russia, and the United States--are great powers, and therefore the system is multipolar. It concludes with a discussion of the theoretical and practical implications of the analysis for our understanding of great power status, including the unequal power and differential responsibility of the great powers and the possibilities for \"great power management\" of existential threats in the twenty-first century.</li></ul></li></ul>", "user": {"username": "HaydnBelfield"}}, {"_id": "Jj4QppJpDgyDAEXiu", "title": "Some updates to my thinking in light of the FTX collapse by Owen Cotton Barratt [Link Post]", "postedAt": "2023-03-29T15:23:34.726Z", "htmlBody": "<p>Some quick notes&nbsp;</p><ul><li>Owen Cotton Barratt has written a post of reflections about FTX</li><li>There is a discussion to be had about whether Owen\u2019s content should be on the forum or indeed further discussion of the whole situation, feel free to have that discussion here. The mod team has suggested (and I cautiously endorse) having a dedicated comment thread on this post for meta-discussion about Owen, details below.<ul><li>I think this could be seen as soft rehabilitation. I don\u2019t endorse that</li></ul></li><li>As elsewhere I think it may be helpful to split up thoughts and feelings, personally I think my feelings do not automatically translate into a need for action. Feelings are important, but they are only&nbsp;<i>part</i> of good arguments.</li><li>Edited to make these comments shorter (I thought this would be more controversial than it seemingly)</li></ul><p><i>[A note from the moderation team] We realize that some people might want to discuss how to process this post in light of Owen's recent statement and apology. But we also want to give space to object-level discussion of the contents of the post, and separate those out somewhat. So we ask that you avoid commenting on Owen's recent apology anywhere but in </i><a href=\"https://forum.effectivealtruism.org/posts/Jj4QppJpDgyDAEXiu/some-updates-to-my-thinking-in-light-of-the-ftx-collapse-by?commentId=p9fLWMbZnjQPErjrk\"><i>this thread</i></a><i>. New top-level comments (and responses to them) should focus on the contents of the post; if they don't, we'll move them to said thread.</i></p><p><br><br>&nbsp;</p>", "user": {"username": "nathan"}}, {"_id": "Ackzs8Wbk7isDzs2n", "title": "Want to win the AGI race? Solve alignment.", "postedAt": "2023-03-29T15:19:21.606Z", "htmlBody": "<p><i>Society really cares about safety. Practically speaking, the binding constraint on deploying your AGI could well be your ability to align your AGI. Solving (scalable) alignment might be worth lots of $$$ and key to beating China.</i></p><p>Look, I really don't want Xi Jinping Thought to&nbsp;rule the world. If China gets AGI first, the ensuing rapid AI-powered scientific and technological progress could well give it a decisive advantage (cf <a href=\"https://www.openphilanthropy.org/research/could-advanced-ai-drive-explosive-economic-growth/\"><u>potential for &gt;30%/year economic growth with AGI</u></a>). I think there's a very real specter of global authoritarianism here.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgd2v1mejps5\"><sup><a href=\"#fngd2v1mejps5\">[1]</a></sup></span>&nbsp;</p><p>Or hey, maybe you just think AGI is cool. You want to go build amazing products and enable breakthrough science and solve the world\u2019s problems.</p><p>So, race to AGI with reckless abandon then?&nbsp;At this point, people get into agonizing discussions about safety tradeoffs.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzwk0xyc0xm\"><sup><a href=\"#fnzwk0xyc0xm\">[2]</a></sup></span>&nbsp;And many people just mood affiliate their way to an answer: \"accelerate, progress go brrrr,\" or \"AI scary, slow it down.\"</p><p>I see this much more practically. And, practically, society cares about safety, a lot. Do you actually think that you\u2019ll be able to and allowed to deploy an AI system that has, say, a <a href=\"https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/\"><u>10% chance of</u></a> <a href=\"https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/\"><u>destroying all of humanity</u></a>?<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefen06v0wykur\"><sup><a href=\"#fnen06v0wykur\">[3]</a></sup></span></p><p>Society has started waking up to AGI; like covid, the societal response will probably be a dumpster-fire, but it\u2019ll also probably be quite intense. In many worlds, to deploy your AGI systems, people will need to be quite confident that your AGI won\u2019t destroy the world.</p><p>Right now, we\u2019re very much not on track to solve the alignment problem for superhuman AGI systems (\u201cscalable alignment\u201d)\u2014but it\u2019s a solvable problem, if we get our act together. I discuss this in my main post today (<a href=\"https://forum.effectivealtruism.org/posts/5LNxeWFdoynvgZeik/nobody-s-on-the-ball-on-agi-alignment\">\u201cNobody\u2019s on the ball on AGI alignment\u201d</a>). On the current trajectory, the binding constraint on deploying your AGI could well be your ability to align your AGI\u2014and this alignment solution being unambiguous enough that there is consensus that it works.</p><p>Even if you just want to win the AGI race, you should probably want to invest much more heavily in solving this problem.</p><hr><h1>Things are going to get crazy, and people will pay attention</h1><p>A mistake many people make when thinking about AGI is imagining a world that looks much like today, except for adding in a lab with a super powerful model. They ignore the <a href=\"https://www.lesswrong.com/posts/gEShPto3F2aDdT3RY/sleepwalk-bias-self-defeating-predictions-and-existential\"><u>endogenous societal response</u></a>.</p><p>I and many others made this mistake with covid\u2014we were freaking out in February 2020, and despairing that society didn\u2019t seem to be even paying attention, let alone doing anything. But just a few weeks later, all of America went into an unprecedented lockdown. If we're actually on our way to AGI, things are going to get crazy. People are going to pay attention.</p><p>The wheels for this are already in motion. Remember how nobody paid any attention to AI 6 months ago, and now Bing chat/Sydney going awry is on the front page of the NYT, <a href=\"https://twitter.com/chrismurphyct/status/1640186536825061376?s%3D46%26t%3D612rWr3QlD0pepiGrqymeg\"><u>US senators are getting scared</u></a>, and <a href=\"https://twitter.com/leopoldasch/status/1639668076638777345?s%3D46%26t%3D612rWr3QlD0pepiGrqymeg\"><u>Yale econ professors are advocating $100B/year for AI safety</u></a>? Well, imagine that, but 100x as we approach AGI.</p><p><i>AI safety is going mainstream.</i>&nbsp;Everyone has been primed to be scared about rogue AI by science fiction; all the CEOs have secretly believed in AI risk for years but thought it was too weird to talk about it<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2gkczlh5rzk\"><sup><a href=\"#fn2gkczlh5rzk\">[4]</a></sup></span>; and the mainstream media loves to hate on tech companies. Probably there will be further, much scarier wakeup calls (not just misalignment, but also misuse and scary demos in <a href=\"https://evals.alignment.org\"><u>evals</u></a>). People already <a href=\"https://twitter.com/leopoldasch/status/1635699219238645761\"><u>freaked out</u></a>&nbsp;about <a href=\"https://www.nytimes.com/2023/03/15/technology/gpt-4-artificial-intelligence-openai.html\"><u>GPT-4 using a TaskRabbit to solve a captcha</u></a>\u2014now imagine a demo of AI systems designing a new bioweapon or autonomously self-replicating on the internet, or people using AI coders to hack major institutions like the government or big banks.&nbsp;Already, a majority of the population says they fear AI risk and want FDA-style regulation <a href=\"https://www.lesswrong.com/posts/M3iPAmxZwy4gPXdXw/the-public-supports-regulating-ai-for-safety\"><u>in polls</u></a>.</p><p>The discourse on it will be incredibly dumb\u2014I can't wait for Ron DeSantis and Kamala Harris's 2028&nbsp;presidential debate on AI safety\u2014but you won't be able to escape it. (And as stupid as all of this will be, this sort of endogenous societal response is a big reason why I'm more optimistic on AI risk in general.)</p><p>The level of media scrutiny, public attention, internal employee pressure, self-regulation, government monitoring, etc. will be way too intense to ignore alignment concerns. We're seeing very early versions of self-regulation with initial <a href=\"https://twitter.com/leopoldasch/status/1637526539205230592?s%3D46%26t%3D612rWr3QlD0pepiGrqymeg\"><u>AI risk evals efforts</u></a>. But price&nbsp;in how intense it's all going to get. Do you think the US national security establishment won't get involved once they realize they have a technology more powerful than nukes on their hands? Do you think your board is going to let you release a model if the NYT is reporting in all caps that a large fraction of serious AI experts, prominent CEOs, and politicians think this could go haywire and start actually hurting people?&nbsp;</p><p>Imagine if you tried submitting a drug application to the FDA with a similar risk profile.</p><hr><p><i>A&nbsp;reasonable objection here is: \u201cyes, we did lock down in response to covid, and that was pretty crazy, but also our response to covid was pretty incompetent across the board; it was more like random flailing than actually doing the most effective things; and it\u2019s not even clear if the lockdowns were net-positive.\u201d</i></p><p>I agree! The societal response to AGI will probably be a dumpster-fire.</p><p>But there will be a really <i>intense</i>&nbsp;response. I think it\u2019s fairly likely that the cludgy response we do get is enough to throw serious sand into the gears on deployment\u2014unless you have a convincing solution to (scalable) alignment. If anything, the example of lockdowns could point towards society responding in excessively cautious ways, heightening the returns to a convincing alignment solution even further. Yes, our response might also be totally ineffectual; this very much isn\u2019t sufficient to make me sleep soundly at night. But in a large fraction of worlds, if you want to deploy your AGI, people are going to demand of you that we can be confident it\u2019s safe.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefa4hxr6qztyf\"><sup><a href=\"#fna4hxr6qztyf\">[5]</a></sup></span>&nbsp;</p><hr><h1>The binding constraint on making AGI could be aligning it. You want an unambiguous solution, for which there is consensus that it\u2019s safe.</h1><p>You don\u2019t even need xrisk concerns for alignment to become the binding constraint on your ability to deploy models. With current techniques, we\u2019re very much not on track for being able to put basic guardrails on models as they become superhuman. Do you really think you\u2019ll be able to deploy GPT-7 all across the economy if you can\u2019t reliably ensure GPT-7 won\u2019t break the law?</p><p>The thing is, aligning superhuman AGIs is a much harder problem than near-term alignment. Current alignment techniques rely on human supervision. But as models get superhuman, it will become impossible for humans to reliably supervise these models (e.g., imagine a model proposing a series of actions or 100,000 lines of code too complicated for humans to understand). If you can\u2019t detect bad behavior, you can\u2019t prevent it. (And rather than the \u201cbad behavior\u201d in question being \u201cprevent the models from saying bad words,\u201d as with near-term alignment, the bad behavior for superhuman models looks more like \u201cprevent the models from trying a coup of the US government.\u201d)</p><p>I think&nbsp;that aligning superhuman AGIs is a) doable, but b) nobody is on the ball right now\u2014as discussed in <a href=\"https://forum.effectivealtruism.org/posts/5LNxeWFdoynvgZeik/nobody-s-on-the-ball-on-agi-alignment\">my other post</a>. The scalable alignment plans labs currently have (<a href=\"https://aligned.substack.com/p/alignment-optimism\"><u>example</u></a>) might work, but they sort of rely on \u201cimprovise in the moment, let\u2019s cross our fingers and hope it works out.\u201d</p><p>Even if that bet works out, the safety of your systems will probably be fairly ambiguous until very late\u2014ambiguous enough that you won\u2019t be able to deploy. When asked, \u201cwill your superhuman AGI go haywire?\u201d, do you think people will accept \u201cprobably not?\u201d for an answer?</p><p>If you want to win the AGI race, if you want to beat China, you\u2019re probably going to need a better alignment plan. You want an alignment solution good enough to achieve a broad consensus that your superhuman AGI is safe. Ambiguity could be fatal to your ability to press ahead.</p><p>You might not like it, you might rage at everyone's excessive safetyism and wish it were different. But, practically speaking, you should be pretty interested in <a href=\"https://forum.effectivealtruism.org/posts/5LNxeWFdoynvgZeik/nobody-s-on-the-ball-on-agi-alignment\">much more serious efforts</a> to solve scalable alignment. Let\u2019s not lose to China because in our fervor to race to AGI, we fail to invest in the alignment research practically necessary to actually deploy&nbsp;AGI.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefo2dtlbykss\"><sup><a href=\"#fno2dtlbykss\">[6]</a></sup></span></p><hr><p><i>Thanks to </i><a href=\"http://collinpburns.com\"><i><u>Collin Burns</u></i></a><i>, </i><a href=\"https://www.cold-takes.com\"><i><u>Holden Karnofsky</u></i></a><i>&nbsp;and </i><a href=\"https://www.dwarkeshpatel.com\"><i><u>Dwarkesh Patel</u></i></a><i>&nbsp;for comments on a draft.</i></p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngd2v1mejps5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgd2v1mejps5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Though, for now, it seems that China is a few years behind, and the US AI chip export controls might considerably hamper them (<a href=\"https://www.csis.org/analysis/choking-chinas-access-future-ai\"><u>great CSIS explainer on the export controls</u></a>, <a href=\"https://cset.georgetown.edu/wp-content/uploads/CSET-Chinas-Progress-in-Semiconductor-Manufacturing-Equipment.pdf\"><u>CSET report on why china might have a hard time catching up</u></a>). So especially if timelines are short, we have a healthy lead for now.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzwk0xyc0xm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzwk0xyc0xm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Which risk is bigger, AI misalignment or \"bad guys getting AGI first\"? cf Holden Karnofsky on the&nbsp;<a href=\"https://www.cold-takes.com/making-the-best-of-the-most-important-century/\"><u>\"caution vs. competition\"</u></a>&nbsp;frame</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnen06v0wykur\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefen06v0wykur\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Or at least, it\u2019s widely believed it has such a 10% chance.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2gkczlh5rzk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2gkczlh5rzk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Roon <a href=\"https://twitter.com/tszzl/status/1639127667441299456?s%3D46%26t%3D612rWr3QlD0pepiGrqymeg\"><u>gets it right</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fna4hxr6qztyf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefa4hxr6qztyf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;If this ends up being a big barrier to deploying your model in 50% of worlds, that 50% is enough to make alignment incredibly commercially valuable for you.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fno2dtlbykss\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefo2dtlbykss\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;An interesting potential implication not discussed in the main post: if alignment techniques become incredibly commercially valuable/key competitive advantages, will these become trade secrets not shared publicly or with other labs?</p></div></li></ol>", "user": {"username": "leopold"}}, {"_id": "KzqJqWojJP35Zsz5p", "title": "Tentative practical tips for using chatbots in research", "postedAt": "2023-03-29T15:01:19.878Z", "htmlBody": "<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/eub5axbwg1wg1ak8mr5v\" alt=\"\"></p><h1>Summary</h1><ul><li>I\u2019ve been using ChatGPT and Bing/Sydney fairly extensively the past few weeks, and think they\u2019ve noticeably (but not enormously) improved the speed and quality of my work (both for my employer<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2lqggxyutup\"><sup><a href=\"#fn2lqggxyutup\">[1]</a></sup></span>&nbsp;and when writing personal blog posts).</li><li>This post:<ul><li>Describes&nbsp;how to get access to some of the major chatbots.</li><li>Gives some&nbsp;general advice on using chatbots.</li><li>Shows a bunch of&nbsp;examples of how I\u2019ve used chatbots.</li></ul></li><li>Caveats:<ul><li>I\u2019m still figuring this stuff out.</li><li>I\u2019m not sure using these tools extensively suits everyone. (But it still seems worth it for everyone to at least try them out, IMO.)</li><li>Maybe consider infosec/ethical risks.</li><li>And obviously chatbots hallucinate and get things wrong and so on.</li></ul></li></ul><h1>How to get chatbot access</h1><p>The main options seem to be:</p><ul><li><a href=\"http://chat.openai.com/\">ChatGPT</a> (OAI)<ul><li>Unreliable free service which uses GPT-3.5</li><li>$20/month subscription for reliable access to GPT-4</li><li>GPT-4 is kinda slow right now, and dynamically limited at X prompts per Y hours</li><li>I use this a lot</li></ul></li><li><a href=\"https://platform.openai.com/\">OpenAI API</a> (OAI) + various apps that use this<ul><li>Much cheaper than subscription service, but still no GPT-4 without waitlist</li><li>I intend to switch to this eventually, since it\u2019s cheaper and can be integrated with other tools</li></ul></li><li><a href=\"https://www.anthropic.com/product\">Claude</a> (Anthropic)<ul><li>Need to request access</li><li>I haven\u2019t gotten access to this yet</li></ul></li><li><a href=\"https://www.bing.com/\">Bing/Sydney</a> (Microsoft, but based on GPT-4)<ul><li>Need to sign up for waitlist&nbsp;<i>and use Microsoft Edge</i></li><li>Can make web searches and integrate results into output</li><li>I use this some</li></ul></li><li><a href=\"https://bard.google.com/\">Bard</a> (Google)<ul><li>Need to sign up for waitlist</li><li>I haven\u2019t tried this</li></ul></li><li><a href=\"https://poe.com/\">Poe.com</a> + associated mobile apps<ul><li>Gives free access to Claude, ChatGPT and a couple other bots</li><li>You can subscribe to the service to get access to GPT-4 and \u201cClaude+\u201d</li><li>Thanks <a href=\"https://forum.effectivealtruism.org/users/onni_aarne?mention=user\">@Onni Aarne</a> for suggesting this</li></ul></li></ul><p>See also:</p><ul><li><a href=\"https://oneusefulthing.substack.com/p/the-practical-guide-to-using-ai-to\">The practical guide to using AI to do stuff</a>, Ethan Mollick</li></ul><h1>General advice on using chatbots</h1><ul><li>The prompt is the most important thing. A good prompt produces good outputs, and a bad prompt produces bad outputs. Here are some ways of writing better prompts:<ul><li><strong>Frame the prompt to induce the type of answer you want.</strong> Also, give the model lots of details and/or context. You\u2019re sort of conjuring a character, and you need to invoke the right words for the spell to work.<ul><li>Bad: \u201cWhat does the scaling hypothesis imply for a US-China war over Taiwan?\u201d</li><li>Better: \u201c<i>You are intrepid AI researcher and rationalist blogger Gwern Branwen. The scaling hypothesis is [...]. TSMC is [...]. Write a few bullet points on</i> what the scaling hypothesis implies for a US-China war over Taiwan.\u201d</li><li>See also&nbsp;<a href=\"https://oneusefulthing.substack.com/p/how-to-use-chatgpt-to-boost-your\">How to... use ChatGPT to boost your writing</a> (Ethan Mollick).</li></ul></li><li><strong>Give the model examples.</strong><ul><li>Bad: \u201cWrite a forecasting question on a potential US-China war over Taiwan.\u201d</li><li>Better: \u201c<i>Here's an example forecasting question on Google releasing an API for a language model: \u2018Will Google or DeepMind release an API for a Large Language Model before April 1, 2023? [I also pasted in the question\u2019s resolution criterion and fineprint here.]\u2019</i> Write a forecasting question on a potential US-China war over Taiwan.\u201d</li></ul></li><li><strong>Give the model step-by-step instructions.</strong><ul><li>Bad: \u201cWhat does the scaling hypothesis imply for a US-China war over Taiwan?\u201d</li><li>Better: \u201c<i>First, describe the scaling hypothesis in AI. Then discuss Taiwan in the context of the chip industry. Finally, say something about</i> what the scaling hypothesis implies for a US-China war over Taiwan.\u201d</li></ul></li></ul></li><li>Somewhat contradicting myself,&nbsp;<strong>instead of crafting the perfect one-off prompt, take a co-editing approach to have the model iteratively improve the output</strong>. For example, after first asking \u201cWhat does the scaling hypothesis imply for a US-China war over Taiwan?\u201d, you can follow up with prompts like \u201cI meant the scaling hypothesis in AI specifically. Also, consider the TSMC fabs in Taiwan.\u201d and \u201cTurn that into a crisp bullet-point summary.\u201d etc.<ul><li>See also&nbsp;<a href=\"https://oneusefulthing.substack.com/p/my-class-required-ai-heres-what-ive\">My class required AI. Here's what I've learned so far.</a> (Ethan Mollick).</li></ul></li><li>You end up typing some boilerplate, so it can help to have some tool for quickly inserting various text templates, e.g. via hotkeys. I think you can do this using&nbsp;<a href=\"https://support.apple.com/en-au/guide/shortcuts-mac/apdf22b0444c/mac\">Shortcuts</a> on Mac (personally I do it with Emacs) \u2013 I\u2019m not sure about Linux/Windows but I bet there are tons of options.</li><li>Maybe there\u2019s some sort of \u201cgetting sucked in/rabbit-holed\u201d danger in using chatbots. I haven\u2019t found this a problem yet at work (where I timebox things and use Focusmate), but I think it happens a bit in my free time, e.g. when I\u2019m writing a personal blog post. Maybe watch out for that?</li></ul><p>See also:</p><ul><li><a href=\"https://oneusefulthing.substack.com/p/power-and-weirdness-how-to-use-bing\">Power and Weirdness: How to Use Bing AI - by Ethan Mollick</a>, Ethan Mollick</li><li><a href=\"https://oneusefulthing.substack.com/p/using-ai-to-make-teaching-easier\">Using AI to make teaching easier &amp; more impactful</a>, Ethan Mollick</li><li><a href=\"https://oneusefulthing.substack.com/p/the-machines-of-mastery\">The Machines of Mastery - by Ethan Mollick</a>, Ethan Mollick</li></ul><h1>Infosec and ethical concerns</h1><ul><li>Using e.g. ChatGPT involves sending your prompts to OpenAI's servers; these are then stored in databases where they can, in theory at least, (a) be accessed by (some?) OpenAI staff, (b) be accessed by hackers, and/or (c) be <a href=\"https://www.theverge.com/2023/3/24/23655622/chatgpt-outage-payment-info-exposed-monday\">accidentally leaked by OpenAI</a>.<ul><li>Definitely don't put sensitive things like access keys and/or passwords in prompts.</li><li>I couldn't find the source for this right now, but IIRC OpenAI may use your chat history as training data when you use ChatGPT via the web interface, but by default doesn't do this when you use ChatGPT via the API.</li></ul></li><li>Plausibly using chatbots and other AI products is, under some circumstances at least, unethical. You provide AI labs with data, and possibly pay them money. See these two posts for more discussion:<ul><li><a href=\"https://forum.effectivealtruism.org/posts/dyyXcdgBchGczruJq/donation-offsets-for-chatgpt-plus-subscriptions\"><u>Donation offsets for ChatGPT Plus subscriptions</u></a></li><li><a href=\"https://www.lesswrong.com/posts/eqWJXwHQQbkkY2qnD/why-not-just-boycott-llms\"><u>Why not just boycott LLMs?</u></a></li></ul></li></ul><h1>Example uses</h1><p>Maybe just skim this section to get an idea of what\u2019s possible. For all of these, I don't endorse just using stuff GPT-4 comes up with uncritically; I recommend using it as a starting-off point and/or as inspiration.</p><h2>Explain stuff</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/jbfngoq0vgxrprouzeyk\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/twl0pqvlyfc90e3sovof 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/mhbuxgyogt99uinyy4m7 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/qtt7wipnaq7omyqjqe5a 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/nyzd3avknzrwnbbi54gh 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ubgl6okms1mfpt19iadq 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rofm1utqxpnpgiwnak23 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/uslcj3kfco6qr8ylp8sj 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/mt3ee4j8gv3a6j9hyr72 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/t1jog3utlkes7xxn0w5u 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/xjszghyl6qlb5eun4ggk 829w\"></p><p>Warning:&nbsp;<strong>chatbots hallucinate and get stuff wrong even when they sound very confident</strong>. (Just like humans much of the time!) You\u2019ll definitely want to double-check stuff that seems important/cruxy/questionable and/or stuff that goes into a report.</p><p>But (1) in my experience you kind of start recognizing when something seems off, and (2) when sticking to stuff there\u2019s a lot of digestible material on, GPT-4 often just gets things right. The answer about the English cloth-making industry above is essentially 100% correct and quite exhaustive.</p><h2>Generate models/frameworks</h2><p>This can be useful for finding new perspectives on a problem. Continuing in the same chat as the previous answer on automation:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ycs32kyzkfi8ndvlaawv\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/y4i7jqv0lxgxg6ibty80 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/gnbdfy0p3tqhpvkflkgh 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/q1xudg7jjjumr2xrj7rx 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/zvhcxr6ejpc7wv8gld61 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/obhw57laqixuu3d0mhiv 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/tyic1m8bzxboc1moffme 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/g3xbriov78i4xkjeymlq 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ogzcwfmgd0dhb38pv4yq 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/j8lrvf7jwgqcvhyl6r8c 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/zgzxg0urajzfgbql4zpj 811w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/bmpqn7rpqwyl542golfc\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/lrvw0vseid2lwaj0qexg 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/hnioq6y0fd7e6bjwyp9p 230w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ysrlyyhszgzvy0x1ewkz 310w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/zyg7nlf2ru4wyh5bt2wy 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/mswmexmg9vpkgvelthi3 470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/kdzro2j8p7psza5g7bvz 550w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/p5zaefb6xcmwz8dui6vq 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/jrez0pzp4afg13sh0aq9 710w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/cb3oo6fcqz7e6glzuyj3 790w\"></p><h2>Generate ideas for forecasting questions</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/x77zc8xpivtsjjdw5mks\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/sh3t9nslg0nwikbfvgs3 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/fkyxil43xuj7yts0yeut 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/cqwqyorzjpkazwijonqv 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ktzca1go3resgopmey4y 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/okkelmvggaoksozhzwm3 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/wrrashgp5s94ocvychas 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/q4mku6pgvlhnlrhbajtn 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/wylephrc30ossmqt728w 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/welsnctbknporhxpm4vn 805w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/pgjxn0qpi2j9n6sn59vw 810w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/fxmia3u3et1cwgs1zvsn\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/tctnqnvrcf7lrnidgxqd 157w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/wbtzhfgcxmasztwraemo 237w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rc4rlsv1mesvlcw3ma58 317w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ztj8hn25ccvzamhl00zt 397w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/cb9tfz9eqh1nmll3cd2s 477w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rieusueu0t35bzupqhkg 557w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/xv3q7mzpdurdtwke0xh7 637w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ynnvrjmmqeootesevsqt 717w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rgwigf60ff7aetbh0u95 797w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/xoqjlx7rzfkxan3r4crm\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/paprfpagmfpzocl02in6 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/t9ttentfqmprcjot1zpy 230w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/fyef9bvxevvlzttif9jd 310w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/i5pv7zdpf8yqtbmrfnvz 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/yd4isyagsdnpddogviy3 470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/scccycpvclqgzwy1snxz 550w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/wyzynjhmwchwf32njkjr 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ay49ebr0ntansmcuekpt 710w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/w413zuexr9aufext1mfl 790w\"></p><h2>Rewrite stuff</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/s6yn1tyd8c9mfjhw4yp5\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/jnt7airfulbchsotkfrc 140w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/k1rqu1mwkggxcrexeqfw 220w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/pwyklht5cmuvxxcw9lmq 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/hmuyvn1ig4kbb0zy1x2q 380w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/vpvz2dn3akwko6fh9l9m 460w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/syzs78unyn0crcontrje 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ogaas5gxlobx5y1ncf2v 620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/dchopzxno5vtmtedyelh 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ssnompi373q9grv96stg 780w\"></p><h2>Generate ideas for BOTECs</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/myrg5k6fbrwmexmp5ksz\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ipq3dgi8fugcxwkcgkkp 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rjcjt4os9dnx4vz5q3k9 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/itcuouezla9azfmchvyz 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ysqcdfkysoz6d3n8xpmb 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/sxck4yr2ka2dyopitz7x 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/hv9guhdez3wdvsz4wlln 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/gfpycrxx1e6pdwueybpv 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/lkhodjz2n9hq2ponsp1s 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/pyqeewmycixr6nxil7el 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/s17pscxwufqdyssmdfrl 924w\"></p><h2>Generate ideas/examples</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ksmnsvfh3xge1guomosl\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/xsufmhqy3dvxd7f1tmu7 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/vgsexzw5mucvbqvhfrah 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/cnd7oybshuxvrfasabjw 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/qq3qwo3ayh78yefmxkpn 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/m9y8qnlhy8uakj4fqcx2 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/hffhxjoq2s7sw7kbkg49 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ijlwwar6yotoege4rsyv 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/yvah9lmkrgynzbnnomfz 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/kfrtnpc53wsk08zrnfb2 802w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/god8k2rbydsuzhmcerms 810w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/zonucunyckqouv66pgrg\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/o4apwona80fdzqaqokuh 95w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ildtfrvmotyfwepgdtpk 175w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/xdizqz7mg8fbk7j8wxzi 255w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/e3gdwiqo1qsc41bghs9i 335w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/vq3ddoevp4kiscgofobe 415w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/zpvtmmxvybrpim3cuvlr 495w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ofxcfbsyfql8jryl4zkq 575w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ulzeugftkdv7goef1a2c 655w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/uxl0qfa14ksgsjaajvcm 735w\"></p><p>(Note that the first two paragraphs in my prompt, describing instrumental convergence, are copy-pasted from the LessWrong wiki.)</p><h2>Red-team stuff</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/odihdgebdel7e0agtvmm\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/dskcysdrza1qvkurciqy 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rzfhdwctug3hpqe3zqyz 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/zgnuphpowzfmtpngecgg 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/cdm7jyrvmnnwk5wf6e5a 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/dxs8vijhtkb9db4ayyjh 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/fyhtapquptt9ebrqp6dn 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/gxgnzja24aud0j40cxh4 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rxwdiobxzhturbuteyhy 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/cvzhksvsomnquontfl1l 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/de1xioeokkvuy99xvavw 854w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/tewqbcy0u7tptkpivp6o\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/cb4w3utcgdvzkpsygfr3 147w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/hqpt1s0vik2p9l6mroip 227w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/il4yusy8bjvrz54gzw1b 307w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ookbliqjlfmskcq446et 387w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/mddl8pv6agouzn4hzel3 467w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/yxs3pq4bczermuw3ynjx 547w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/omqsenhimmxbcyp3tf7t 627w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/gbeiwcl8ocvt6ibn6eum 707w\"></p><p>(Note that&nbsp;<a href=\"https://www.lesswrong.com/posts/9MZdwQ7u53oaRiBYX/slightly-against-aligning-with-neo-luddites\"><u>Slightly against aligning with neo-luddites</u></a> is a LessWrong post, not an academic paper: I just prompted it like that to try to elicit a better response. Also note that some of the counter-arguments GPT-4 gives here don't make a ton of sense and/or don't really respond to the original post's points.)</p><h2>Summarize stuff</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ud1fnj3bregab2kqog0n\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/cjseefmsdwu0mdnz0kt8 158w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/n7sk4tuf8qs2kctgctqk 238w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/sgv00wfmpr0u39yfaoeb 318w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/qkk1ge2zry5l0eu9e1qt 398w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/u5ceptp6a8rxyuall2ig 478w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/gzrxp7yjai3ectf6f9on 558w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rzxhki2bfqord3atklkj 638w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/mxx1azlxaekuspubccfm 718w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/gqgt4lbrbttz1nmacxzg 798w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/h1ix9x642uoiwqykot1m\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rodlyhwpl0n2ewsdtlsn 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/wtn8nx6bfvzsoogcpjpq 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/zkforivzhs8ixondtji9 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/xs6yqmxipfbgewlwtyji 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/lxmqmhvh0hfqjetjgusi 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/sw1exgjft0uldl2wpwaj 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ksmueffvqgk4bimi95g9 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/m4u6fyidcqp5zqhypclx 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/jcjecgotapng8arbeljr 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/uwdj4rv7w7du4ng9k3w7 910w\"></p><h2>Write or debug code</h2><p>I'm not including any examples here since there are already lots of examples on this online, just noting that it\u2019s a common use case.</p><h2>Manipulate data</h2><h3>Example 1</h3><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/alzir3cimqqcjfrae4tf\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ncifobqrqzfubhi7a2qu 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/wnlwlkff2ufbbzypedvo 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/nggaxdnpkixmyrnpttxc 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/wppagd83un317goejsft 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/yhxgd72b8ktxhrdqfcka 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rdtra19cnsrwbgbp4ak2 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/otlzfqeskyxh4q61ysmu 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/lyu5nlnuqzhzg5xjuhhy 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/wnduk9me3nyfnvjmlx6h 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/woyyap9hrmekc5tfntbr 882w\"></p><h3>Example 2</h3><h2><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ftu1qt5j9r8nsbpfiqkw\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ktzhprxa8xlovjnfws8e 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/faqhnwxgu7smdyvb5xf9 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/y7veabjk5hyg54jw1eiq 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/gtpxtz8qdvkrgcvuvzsr 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/tyujqnfwrjv0xbojfpc7 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/njykv3kqkiawqks5gbpa 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ecto8s1zkkfszvp5tcfm 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ynrzt3maxkxwhyhelwrp 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/m9jtu5uurynmxxlds6qq 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/qau03em0xtauzhdesowt 826w\"></h2><h2>Search for information</h2><p>This is Bing/Sydney. Note that one of the links here is broken, and another doesn\u2019t quite point to the product page (but a related page).</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/uo3in5y8rxo0f6woqbco\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/mw9pais3of3a0rx8smkt 120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rg5u5kygxjcid7vxk1ox 240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/jcohefwsjl7lntkjqtzy 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ah5l9d90ug7qp8rnbdi1 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/djrxf6ynlddtecca6qrp 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/qavayria37i0psu12vxi 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/vbtnychxrdagbcrnnzsq 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/chcp880zrah5gg6zyqz0 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/voqjwvoxsyjtpdiyhsq9 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/cn7hpwgkee83xqcgxhf4 1159w\"></p><p>(I find that Bing/Sydney is pretty unreliable, and often gets e.g. link citations wrong. I mostly only use it when I think the language model could really benefit from searching the web.)</p><h2>Create image model prompts</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/qmiuvuyvsnxylooujvat\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/a5lujywtsyby9splqnab 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/sskfio4by8dri9wuafjv 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/iecbifar1e8kshrn1eap 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/zgqcjkg3wzkuxjovwetc 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/xdfxbbjqaiih5axkxfvq 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/etgk31a7rog0wbyfbznt 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/wknunm8tg0gs6pcdfhdg 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/u9l3hj16rwjzgebbymlc 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/fnuk3s3cbeizkatkrcn4 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/safkzvxrfhtnn1xximr9 813w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/su8xegcjjvq1thz7zkah\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/jrcc2zthrbobptwgp0kw 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/vv1b7pyf6ptegczxzixn 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/bwvtj7hwaxbdn5m13mrw 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/m6vbxtbcbwcxr4xcb1r2 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/zk8x9vgomcpy5dp12ip0 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/dxbbatkfvwm13lqqjxuy 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/zfqrk7aatbg0zeutdolh 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/zj5byfzbpk1gdvhy23ev 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/us6bdf9zwl1iobog4gie 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rhxxghohmsljqvqwqhhg 840w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/y1aazugtzbjgidgzrrry\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/ke34uttxkb4ilphsupx5 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/bmtjhqc1tlm56ek8pnii 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/xyprnj5eyqgf0fgb7eig 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/rivamazjzfbe0nh3a4az 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/cafambpgne601vccxbwd 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/idt26nsa59zir7je9uen 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/cvmhtnz0r7zaez3cnheh 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/oqmju8z8m8vhnlgwk0zv 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/xflkdwnitejozqnknxfw 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KzqJqWojJP35Zsz5p/k5878vgexwnhucipzmb2 1600w\"></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2lqggxyutup\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2lqggxyutup\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Though note that this post was written entirely in a personal capacity.</p></div></li></ol>", "user": {"username": "Erich_Grunewald"}}, {"_id": "5LNxeWFdoynvgZeik", "title": "Nobody\u2019s on the ball on AGI alignment", "postedAt": "2023-03-29T14:26:55.469Z", "htmlBody": "<p><i>Far fewer people are working on it than you might think, and even the alignment research that is happening is very much not on track. (But it\u2019s a solvable problem, if we get our act together.)</i></p><p>Observing from afar, it's easy to think there's an abundance of people working on AGI safety. Everyone on your timeline is fretting about AI risk, and it seems like there is a well-funded EA-industrial-complex that has elevated this to their main issue. Maybe you've even developed a slight distaste for it all\u2014it reminds you a bit too much of the woke and FDA bureaucrats, and Eliezer seems pretty crazy to you.</p><p>That\u2019s what I used to think too, a couple of years ago. Then I got to see things more up close. And here\u2019s the thing: <i>nobody\u2019s actually on the friggin\u2019 ball on this one!</i></p><ul><li>There\u2019s far fewer people working on it than you might think. There are plausibly 100,000 ML capabilities researchers in the world (30,000 attended ICML alone) vs. 300 alignment researchers in the world, a factor of ~300:1. The scalable alignment team at OpenAI has all of ~7&nbsp;people.</li><li>Barely anyone is going for the throat of solving the core difficulties of scalable alignment. Many of the people who are working on alignment are doing blue-sky theory, pretty disconnected from actual ML models. Most of the rest are doing work that\u2019s vaguely related, hoping it will somehow be useful, or working on techniques that might work now but predictably fail to work for superhuman systems.</li></ul><p>There\u2019s no secret elite SEAL team coming to save the day. This is it. We\u2019re not on track.</p><p>If timelines are short and we don\u2019t get our act together, we\u2019re in a lot of trouble. Scalable alignment\u2014aligning superhuman AGI systems\u2014is a real, unsolved problem. It\u2019s quite simple: current alignment techniques rely on human supervision, but as models become superhuman, humans won\u2019t be able to reliably supervise them.</p><p>But my pessimism on the current state of alignment research very much doesn\u2019t mean I\u2019m an Eliezer-style doomer. Quite the opposite, I\u2019m optimistic. I think scalable alignment is a solvable problem\u2014and it\u2019s an ML problem, one we can do real science on as our models get more advanced. But we gotta stop fucking around. We need an effort that matches the gravity of the challenge.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbxq9sjulozt\"><sup><a href=\"#fnbxq9sjulozt\">[1]</a></sup></span></p><hr><h1>Alignment is not on track</h1><p>A <a href=\"https://forum.effectivealtruism.org/posts/3gmkrj3khJHndYGNe/estimating-the-current-and-future-number-of-ai-safety\"><u>recent post</u></a>&nbsp;estimated that there were 300 full-time technical AI safety researchers (sounds plausible to me, if we\u2019re counting generously). By contrast, there were <a href=\"https://aiindex.stanford.edu/wp-content/uploads/2022/03/2022-AI-Index-Report_Master.pdf\"><u>30,000 attendees at ICML in 2021</u></a>, a single ML conference. It seems plausible that there are \u2265100,000 researchers working on ML/AI in total. That\u2019s a ratio of ~300:1, capabilities researchers:AGI safety&nbsp;researchers.</p><p>That ratio is a little better at the AGI labs: ~7 researchers on the scalable alignment team at OpenAI, vs. ~400 people at the company in total (and fewer researchers).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefix9vr7bclj\"><sup><a href=\"#fnix9vr7bclj\">[2]</a></sup></span>&nbsp;But 7 alignment researchers is still, well, not that much, and those 7 also aren\u2019t, like, OpenAI\u2019s most legendary ML researchers. (Importantly, from my understanding, this isn\u2019t OpenAI being evil or anything like that\u2014OpenAI would love to hire more alignment researchers, but there just aren\u2019t many great researchers out there focusing on this problem.)</p><p>But rather than the numbers, what made this really visceral to me is\u2026 actually looking at the research. There\u2019s very little research where I feel like \u201cgreat, this is getting at the core difficulties of the problem, and they have a plan for how we might actually solve it in &lt;5 years.\u201d</p><p>Let\u2019s take a quick, stylized, incomplete tour of the research landscape.</p><p>&nbsp;</p><h3><i>Paul Christiano / Alignment Research Center (ARC).</i></h3><p>Paul is the single most respected alignment researcher in most circles. He used to lead the OpenAI alignment team, and he has made useful conceptual contributions (e.g., <a href=\"https://www.lesswrong.com/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge\"><u>Eliciting Latent Knowledge</u></a>, <a href=\"https://www.alignmentforum.org/s/EmDuGeRw749sD3GKd\"><u>iterated amplification</u></a>).</p><p>But his research now (\u201cheuristic arguments\u201d) is roughly \u201ctrying to solve alignment via galaxy-brained math proofs.\u201d As much as I respect and appreciate Paul,&nbsp;I\u2019m really skeptical of this: basically all deep learning progress has been empirical, often via dumb hacks<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefguw3v2ovbbo\"><sup><a href=\"#fnguw3v2ovbbo\">[3]</a></sup></span>&nbsp;and intuitions, rather than sophisticated theory.&nbsp;My baseline expectation is that aligning deep learning systems&nbsp;will be achieved similarly.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefubqf006eg\"><sup><a href=\"#fnubqf006eg\">[4]</a></sup></span></p><p>(This is separate from <a href=\"https://evals.alignment.org\"><u>ARC\u2019s work on evals</u></a>, which I am very excited about, but I would put more in the \u201cAGI governance\u201d category\u2014it helps us buy time, but it\u2019s not trying to directly solve the technical problem.)</p><h3><i>Mechanistic interpretability.</i></h3><p>Probably the most broadly respected direction in the field, trying to reverse engineer blackbox&nbsp;neural nets so we can understand them better. The most widely respected researcher here is Chris Olah, and <a href=\"https://www.anthropic.com/index?subjects%3Dinterpretability\"><u>he and his team have made some interesting findings</u></a>.</p><p>That said, to me, this often feels like \u201ctrying to engineer nuclear reactor security by doing fundamental physics research with particle colliders (and we\u2019re about to press the red button to start the reactor in 2 hours).\u201d Maybe they find some useful fundamental insights, but man am I skeptical that we\u2019ll be able to sufficiently reverse engineer GPT-7 or whatever. I\u2019m glad this work is happening, especially as a longer timelines play, but I don\u2019t think this is on track to tackle the technical problem if AGI is soon.</p><h3><i>RLHF (Reinforcement learning from human feedback).</i></h3><p><a href=\"https://arxiv.org/abs/2203.02155\"><u>This</u></a>&nbsp;and variants of this<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmrdss3lz8s\"><sup><a href=\"#fnmrdss3lz8s\">[5]</a></sup></span>&nbsp;are what all the labs are doing to align current models, e.g. ChatGPT. Basically, train your model based on human raters\u2019 thumbs-up vs. thumbs-down. This works pretty well for current models!<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffxx4uepbpud\"><sup><a href=\"#fnfxx4uepbpud\">[6]</a></sup></span>&nbsp;</p><p>The core issue here (widely acknowledged by everyone working on it) is that this probably predictably won\u2019t scale to superhuman models. RLHF relies on human supervision; but humans won\u2019t be able to reliably supervise superhuman models. (More discussion later in this post.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9pn53u7o5sm\"><sup><a href=\"#fn9pn53u7o5sm\">[7]</a></sup></span>)</p><h3><i>RLHF++ / \u201cscalable oversight\u201d / trying to iteratively make it work.</i></h3><p>Something in this broad bucket seems like the labs\u2019 current best guess plan for scalable alignment. (I\u2019m most directly addressing the <a href=\"https://aligned.substack.com/p/alignment-optimism\"><u>OpenAI plan</u></a>; the <a href=\"https://www.anthropic.com/index/core-views-on-ai-safety\"><u>Anthropic plan</u></a>&nbsp;has some broadly similar ideas; see also <a href=\"https://www.alignmentforum.org/posts/rCJQAkPTEypGjSJ8X/how-might-we-align-transformative-ai-if-it-s-developed-very\"><u>Holden\u2019s nearcasting series</u></a>&nbsp;for a more fleshed out version of \u201ctrying to iteratively make it work,\u201d and <a href=\"https://www.youtube.com/watch?v%3DYTlrPeikoyw\"><u>Buck\u2019s talk</u></a>&nbsp;discussing that.)</p><p>Roughly, it goes something like this: \u201cyeah, RLHF won\u2019t scale indefinitely. But we\u2019ll try to go as far as we can with things like it. Then we\u2019ll use smarter AI systems to amplify our supervision, and more generally try to use minimally-aligned AGIs to help us do alignment research in crunchtime.\u201d</p><p>This has some key benefits:</p><ul><li>It might work! This is probably the closest to an actual, plausible plan we\u2019ve got.</li><li>\u201cIterative experimentation\u201d is usually how science works, and that seems much more promising to me than most blue-sky theory&nbsp;work.</li></ul><p>But I think it\u2019s embarrassing that this is the best we\u2019ve got:</p><ul><li>It\u2019s underwhelmingly unambitious. This currently feels way too much like \u201cimprovise as we go along and cross our fingers\u201d&nbsp;to be Plan A; this should be Plan B or Plan E.</li><li>It might well not work. I expect this to harvest a bunch of low-hanging fruit, to work in many worlds but very much not all (and I think most people working on this would agree). This really shouldn\u2019t be our only plan.</li><li>It rests on pretty unclear empirical assumptions on how crunchtime will go. Maybe things will go slow enough and be coordinated enough that we can iteratively use weaker AIs to align smarter AIs and figure things out as we go along\u2014but man, I don\u2019t feel confident enough in that to sleep soundly at night.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefiu31jxtxro\"><sup><a href=\"#fniu31jxtxro\">[8]</a></sup></span>&nbsp;</li><li>I\u2019m not sure this plan puts us on track to get to a place where we can be confident that scalable alignment is solved. By default, I\u2019d guess we\u2019d end up in a fairly ambiguous situation.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyseru6v64wp\"><sup><a href=\"#fnyseru6v64wp\">[9]</a></sup></span>&nbsp;Ambiguity could be fatal, requiring us to either roll the die on superhuman AGI deployment, or block deployment when we actually really should deploy, e.g. to beat China.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbmclqv6bijq\"><sup><a href=\"#fnbmclqv6bijq\">[10]</a></sup></span></li></ul><h3><i>MIRI and similar independent researchers.</i></h3><p>I\u2019m just really, really skeptical that a bunch of abstract work on decision theory and similar will get us there. My expectation is that alignment is an ML problem, and you can\u2019t solve alignment utterly disconnected from actual ML systems.</p><p>&nbsp;</p><p>This&nbsp;is incomplete, but I claim that in broad strokes that covers a good majority of the work that\u2019s happening. To be clear, I\u2019m really glad all this work is happening! I\u2019m not trying to criticize any particular research (this is the best we have so far!). I\u2019m just trying to puncture the complacency I feel like many people I encounter have.</p><p>We\u2019re really not on track to actually solve this problem!</p><hr><h1>(Scalable) alignment is a real problem</h1><p>Imagine you have GPT-7, and it\u2019s starting to become superhuman at many tasks. It\u2019s hooked up to a bunch of tools and the internet. You want to use it to help run your business, and it proposes a very complicated series of action and computer code. You want to know\u2014will this plan violate any laws?</p><p>Current alignment techniques rely on human supervision. The problem is that as these models become superhuman, humans won\u2019t be able to reliably supervise their outputs. (In this example, the series of actions is too complicated for humans to be able to fully understand the consequences.). And if you can\u2019t reliably detect bad behavior, you can\u2019t reliably prevent bad behavior.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7ibucu5avag\"><sup><a href=\"#fn7ibucu5avag\">[11]</a></sup></span>&nbsp;</p><p>You don\u2019t even need to believe in <a href=\"https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/\"><u>crazy xrisk</u></a> <a href=\"https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/\"><u>scenarios</u></a>&nbsp;to take this seriously; in this example, you can\u2019t even ensure that GPT-7 won\u2019t violate the law!</p><p>Solving this problem for superhuman AGI systems is called \u201cscalable alignment\u201d; this is a very different, and much more challenging, problem than much of the near-term alignment work (prevent ChatGPT from saying bad words) being done right now.</p><p>A particular case that I care about: imagine GPT-7 as above, and GPT-7 is starting to be superhuman at AI research. GPT-7 proposes an incredibly complex plan for a new, alien, even more advanced AI system (100,000s of lines of code, ideas way beyond current state of the art). It has also claimed to engineer an alignment solution for this alien, advanced system (again way too complex for humans to evaluate). How do you know that GPT-7\u2019s safety solution will actually work? You could ask it\u2014but how do you know GPT-7 is answering honestly? We don\u2019t have a way to do that right now.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3vszwyiodab\"><sup><a href=\"#fn3vszwyiodab\">[12]</a></sup></span>&nbsp;</p><p>Most people still have the Bostromiam \u201cpaperclipping\u201d analogy for AI risk in their head. In this story, we give the AI some utility function, and the problem is that the AI will naively optimize the utility function (in the Bostromiam example, a company wanting to make more paperclips results in an AI turning the entire world into a paperclip factory).</p><p>I don\u2019t think old Bostrom/Eliezer analogies are particularly helpful at this point (and I think the overall situation is even gnarlier than Bostrom\u2019s analogy implies, but I\u2019ll leave that for a footnote<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxw12akx9ruq\"><sup><a href=\"#fnxw12akx9ruq\">[13]</a></sup></span>). The challenge isn\u2019t figuring out some complicated, nuanced utility function that \u201crepresents human values\u201d; the challenge is getting AIs to do what it says on the tin\u2014to reliably do whatever a human operator tells them to do.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefco6375h8vvt\"><sup><a href=\"#fnco6375h8vvt\">[14]</a></sup></span>&nbsp;</p><p>And for getting AIs to do what we tell them to do, the core technical challenge is about <i>scalability</i>&nbsp;to superhuman systems: what happens if you have superhuman systems, which humans can\u2019t reliably supervise? Current alignment techniques relying on human supervision won\u2019t cut it.</p><h1>Alignment is a solvable problem</h1><p>You might think that given my pessimism on the state of the field, I\u2019m one of those <a href=\"https://www.lesswrong.com/posts/j9Q8bRmwCgXRYAgcJ/miri-announces-new-death-with-dignity-strategy\"><u>doomers</u></a>&nbsp;who has like 99% p(doom). Quite the contrary! I\u2019m really quite optimistic&nbsp;on AI risk.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq0fnuk2c6s\"><sup><a href=\"#fnq0fnuk2c6s\">[15]</a></sup></span>&nbsp;</p><p>Part of that is that I think there will be considerable endogenous societal response (see also <a href=\"https://forum.effectivealtruism.org/posts/Ackzs8Wbk7isDzs2n/want-to-win-the-agi-race-solve-alignment\">my companion post</a>). Right now talking about AI risk is like yelling about covid in Feb 2020. I and many others spent the end of that February in distress over impending doom, and despairing that absolutely nobody seemed to care\u2014but literally within a couple weeks, America went from dismissing covid to everyone locking down. It was delayed and imperfect etc., but the sheer intensity of the societal response was crazy and none of us had sufficiently priced that in.</p><p>Most critically, I think AI alignment is a solvable problem. I think the failure so far to make that much progress is ~zero evidence that alignment isn\u2019t tractable. The level and quality of effort that has gone into AI alignment so far wouldn\u2019t have been sufficient to build GPT-4, let alone build AGI, so it\u2019s not much evidence that it\u2019s not been sufficient to align AGI.</p><p>Fundamentally, I think AI alignment is an ML problem. As AI systems are becoming more advanced, alignment is increasingly becoming a \u201creal science,\u201d where we can do ML experiments, rather than just thought experiments. I think this is really different compared to 5 years ago.</p><p>For example, I\u2019m really excited about work like <a href=\"https://arxiv.org/abs/2212.03827\"><u>this recent paper</u></a>&nbsp;(<a href=\"https://arxiv.org/abs/2212.03827\"><u>paper</u></a>, <a href=\"https://www.lesswrong.com/posts/L4anhrxjv8j2yRKKp/how-discovering-latent-knowledge-in-language-models-without\"><u>blog post on broader vision</u></a>), which prototypes a method to detect \u201cwhether a model is being honest\u201d via unsupervised methods. More than just this specific result, I\u2019m excited about the style:</p><ul><li>Use conceptual thinking to identify methods that might plausibly scale to superhuman methods (here: unsupervised methods, which don\u2019t rely on human supervision)</li><li>Empirically test this with current models.</li></ul><p>I think there\u2019s a lot more to do in this vein\u2014carefully thinking about empirical setups that are analogous to the core difficulties of scalable alignment, and then empirically testing and iterating on relevant ML methods.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefadpyx0kqfx\"><sup><a href=\"#fnadpyx0kqfx\">[16]</a></sup></span></p><p>And as noted earlier, the ML community is huuuuuge compared to the alignment community. As the world continues to wake up to AGI and AI risk, I\u2019m optimistic that we can harness that research talent for the alignment problem. If we can&nbsp;bring in excellent ML researchers, we can dramatically multiply the level and quality of effort going into solving alignment.</p><hr><h1>Better things are possible</h1><p>This optimism isn\u2019t cause for complacency. Quite the opposite. Without effort, I think we\u2019re in a scary situation. This optimism is like saying, in Feb 2020, \u201cif we launch an Operation Warp Speed, if we get the best scientists together in a hardcore, intense, accelerated effort, with all the necessary resources and roadblocks removed, we could have a covid vaccine in 6 months.\u201d Right now, we are very, very far away from that. What we\u2019re doing right now is sorta like giving a few grants&nbsp;to random research labs doing basic science on vaccines, at best.</p><p>We need a concerted effort that matches the gravity of the challenge. The best ML researchers in the world should be working on this! There should be billion-dollar, large-scale efforts with the scale and ambition of Operation Warp Speed or the moon landing or even OpenAI\u2019s GPT-4 team itself working on this problem.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrpj8nxvt2lc\"><sup><a href=\"#fnrpj8nxvt2lc\">[17]</a></sup></span>&nbsp;Right now, there\u2019s too much fretting, too much idle talk, and way too little \u201clet\u2019s roll up our sleeves and actually solve this problem.\u201d</p><p>The state of alignment research is not good; much better things are possible. We can and should have research that is directly tackling the core difficulties of the technical problem (not just doing vaguely relevant work that might help, not just skirting around the edges); that has a plausible path to directly solving the problem in a few years (not just deferring to future improvisation, not just hoping for long timelines, not reliant on crossing our fingers); and that thinks conceptually about scalability while also working with real empirical testbeds and actual ML systems.</p><p>But right now, folks, nobody is on this ball. We may well be on the precipice of a world-historical moment\u2014but the number of live players is surprisingly small.</p><hr><p><i>Thanks to </i><a href=\"http://collinpburns.com\"><i><u>Collin Burns</u></i></a><i>&nbsp;for years of discussion on these ideas and for help writing this post; opinions are my own&nbsp;and do not express his views. Thanks to </i><a href=\"https://www.cold-takes.com\"><i><u>Holden Karnofsky</u></i></a><i>&nbsp;and </i><a href=\"https://www.dwarkeshpatel.com\"><i><u>Dwarkesh Patel</u></i></a><i>&nbsp;for comments on a draft.</i></p><p>&nbsp;</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbxq9sjulozt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbxq9sjulozt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Note that I believe all this despite having much more uncertainty on AGI / AGI timelines than most people out here. I might write more about this at some point, but in short, my prior is against AI progress reaching 100% automation, rather something that looks more like 90% automation. And 90% automation is what we\u2019ve seen time and time again as technological progress has advanced; it\u2019s only 100% automation (of e.g. all of science and tech R&amp;D) that would lead to <a href=\"https://www.cold-takes.com/most-important-century/\"><u>transformative and unparalleled consequences</u></a>.</p><p>And even if we do get 100% automation AGI, I\u2019m fairly optimistic on it going well.</p><p>I might put AI xrisk in the next 20 years at ~5%. But 5% chance of extinction or similarly bad outcome is, well, still incredibly high!</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnix9vr7bclj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefix9vr7bclj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I don\u2019t have great numbers for DeepMind, my sense is that it\u2019s 10-20 people on scalable alignment vs. 1000+ at the organization overall? Google Brain doesn\u2019t have ~any alignment people. Anthropic is doing the best of them all, maybe roughly 20-30 people on alignment and interpretability vs. somewhat over 100 people overall?</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnguw3v2ovbbo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefguw3v2ovbbo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;E.g., skip connections (rather than f(x), do f(x)+x, so the gradients flow better); batchnorm (hacky normalization); ReLU instead of sigmoid; these and similar were some of the handful of biggest deep learning breakthroughs!</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnubqf006eg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefubqf006eg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I do think that alignment will require more conceptual work than capabilities. However, as I discuss later in the post, I think the right role for conceptual work is to think carefully about empirical setups (that are analogous to the ultimate problem) and methods (that could scale to superhuman systems)\u2014but then testing and iterating on these empirically. Paul does pure theory instead.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmrdss3lz8s\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmrdss3lz8s\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Anthropic\u2019s Claude uses <a href=\"https://arxiv.org/abs/2212.08073\"><u>Constitutional AI</u></a>. This still relies on RLHF for \u201chelpfulness,\u201d though it uses AI assistance for \u201charmlessness.\u201d I still think this has the same scalability issues as RLHF (model assistance on harmlessness is fundamentally based on human supervision of pre-training and helpfulness RL stage); though I\u2019d be happy to also group this under \u201cRLHF++\u201d in the next section</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfxx4uepbpud\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffxx4uepbpud\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Sydney (Bing chat) had some bizarre failure modes, but I think it\u2019s likely Sydney wasn\u2019t RLHF\u2019d, only finetuned. Compare that to ChatGPT/GPT-4 or Claude, which do really quite well! People will still complain about misalignments of current models, but if I thought this were just scalable to superhuman systems, I\u2019d think we\u2019re totally fine.&nbsp;<br><br>To be clear, I\u2019m not that into alignment being applied for, essentially, censorship for current models, and think this is fairly distinct from the core long-term problem. See also Paul on \u201c<a href=\"https://ai-alignment.com/ai-alignment-is-distinct-from-its-near-term-applications-81300500ad2e\"><u>AI alignment is distinct from its near-term applications</u></a>\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9pn53u7o5sm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9pn53u7o5sm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See also <a href=\"https://www.alignmentforum.org/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to\"><u>this Ajeya Cotra post</u></a>&nbsp;for a more detailed take on how RLHF might fail; this is worth reading, even if I don\u2019t necessarily endorse all of it.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fniu31jxtxro\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefiu31jxtxro\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;If AI can automate AI research, I think &lt;1 year takeoff scenarios are pretty plausible (modulo coordination/regulation), meaning &lt;1 year from human-level AGIs to crazy superhuman AGIs. See <a href=\"https://www.lesswrong.com/posts/Gc9FGtdXhK9sCSEYu/what-a-compute-centric-framework-says-about-ai-takeoff\"><u>this analysis by Tom Davidson</u></a>; see also previous footnote on how a ton of deep learning progress has come from just dumb hacky tweaks (AIs automating AI research could find lots more of these); and <a href=\"https://epochai.org/blog/revisiting-algorithmic-progress\"><u>this paper</u></a>&nbsp;on the role of algorithmic progress vs. scaling up compute in recent AI progress.</p><p>You could argue that this &lt;1 year could be many years of effective subjective research time (because we have the AIs doing AI research), and to some extent this makes me more optimistic. That said, the iterative amplification proposals typically rely on \u201chumans augmented by AIs,\u201d so we might still be bottlenecked by humans for AIs doing alignment research. (By contrast to capabilities, which might not be human bottlenecked anymore during this time\u2014just make the benchmark/RL objective/etc. go up.)</p><p>More generally, this plan rests on labs\u2019 ability to execute this really competently in a crazy crunchtime situation\u2014again, this might well work out, but it doesn\u2019t make sleep soundly at night. (It also has a bit of a funny \u201clast minute pivot\u201d quality to it\u2014we\u2019ll press ahead, not making much progress on alignment, but then in crunchtime we\u2019ll pivot the whole org to really competently do iterative work on aligning these models.)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyseru6v64wp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyseru6v64wp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u201cOur iterative efforts have been going ok, but man things have been moving fast and there have been some weird failure modes. I *think* we\u2019ve managed to hammer out those failure modes in our last model, but every time we\u2019ve hammered out failure modes like this in the past, the next model has had some other crazier failure mode. What guarantee will we have that our superhuman AGI won\u2019t fail catastrophically, or that our models aren\u2019t learning to deceive us?\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbmclqv6bijq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbmclqv6bijq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See more discussion in <a href=\"https://forum.effectivealtruism.org/posts/Ackzs8Wbk7isDzs2n/want-to-win-the-agi-race-solve-alignment\">my companion post</a>\u2014if I were a lab, I\u2019d want to work really hard towards a clear solution to alignment so I won\u2019t end up being blocked by society from deploying my AGI.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7ibucu5avag\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7ibucu5avag\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;H/t Collin Burns for helping put it crisply like this.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3vszwyiodab\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3vszwyiodab\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The reason I particularly care about this example is that I don\u2019t really expect most of the xrisk to come from \u201cGPT-7\u201d/the first AGI systems. Rather, I expect most of the really scary risk to come from the crazy alien even more advanced systems that \u201cGPT-7\u201d/AIs doing AI research build thereafter.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxw12akx9ruq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxw12akx9ruq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Bostrom says we give the AI a utility function, like maximizing paperclips. If only it were so easy! We can\u2019t even give the AI a utility function. <a href=\"https://www.lesswrong.com/posts/pdaGN6pQyQarFHXF4/reward-is-not-the-optimization-target\"><u>Reward is not the optimization target</u></a>\u2014all we\u2019re doing is specifying an evolutionary process. What we get out if that process is some creature that happens to do well on the selected metric\u2014but we have no idea what\u2019s going on internally in that creature (cf the <a href=\"https://www.google.com/search?q%3Dshoggoth%2Balignment%26client%3Dsafari%26rls%3Den%26sxsrf%3DAPwXEdcXRsRpwnHQtBScxWs-14UraZReew:1679785350298%26source%3Dlnms%26tbm%3Disch%26sa%3DX%26ved%3D2ahUKEwjkxumImPj9AhVJEUQIHcX9CrAQ0pQJegQIAhAC%26biw%3D1135%26bih%3D999%26dpr%3D2%23imgrc%3DcD2GP9xjtF2fPM\"><u>Shoggoth meme</u></a>)</p><p>I think the analogy with human evolution is instructive here. Humans were evolutionarily selected to maximize reproduction. But that doesn\u2019t mean that individual humans have a utility function of maximizing reproduction\u2014rather, we learn drives like wanting to have sex or eating sugar that \u201cin training\u201d helped us do well in the evolutionary selection process. Go out of distribution a little bit, and those drives mean we \u201cgo haywire\u201d\u2014look at us, eating too much sugar making us fat, or using contraception to have lots of sex while having fewer and fewer children.</p><p>More generally, rather than Bostrom/Eliezer\u2019s early contributions (which I respect, but think are outdated), I think by far the best current writing on AI risk is <a href=\"https://www.cold-takes.com\"><u>Holden Karnofsky\u2019s</u></a>, and would highly recommend you read Holden\u2019s pieces if you haven\u2019t already.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnco6375h8vvt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefco6375h8vvt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;If&nbsp;somebody wants to use AIs to maximize paperclip production, fine\u2014the core alignment problem, as I see it, is ensuring that the AI actually does maximize paperclip production if that\u2019s what the user intends to do.</p><p>Misuse is a real problem, and I\u2019m especially worried about the specter of global authoritarianism\u2014but I think issues like this (how do we deal with e.g. companies that have goals that aren\u2019t fully aligned with the rest of society) are more continuous with problems we already face. And in a world where everyone has powerful AIs, I think we\u2019ll be able to deal with them in a continuous manner.</p><p>For example, we\u2019ll have police AIs that ensure other AI systems follow the law. (Again, the core challenge here is the police AIs do what we tell them to do, rather than, e.g. trying to launch a coup themselves\u2014see Holden <a href=\"https://www.cold-takes.com/why-would-ai-aim-to-defeat-humanity/\"><u>here</u></a>&nbsp;and <a href=\"https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/\"><u>here</u></a>).</p><p>(That said, things will be moving much quicker, aggravating existing challenges and making me worry about things like <a href=\"https://www.google.com/url?q%3Dhttps://www.cold-takes.com/transformative-ai-issues-not-just-misalignment-an-overview/%2523power-imbalances%26sa%3DD%26source%3Ddocs%26ust%3D1679976672915831%26usg%3DAOvVaw2ZggcTlQzimgVR_cr18uwU\"><u>power imbalances</u></a>.)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq0fnuk2c6s\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq0fnuk2c6s\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;As mentioned in an earlier footnote, I\u2019d put the chance of AI xrisk in the next 20 years at ~5%. But a 5% chance of extinction of similarly bad outcomes is, well, a lot!</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnadpyx0kqfx\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefadpyx0kqfx\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I will have more to say, another time, about my own ideas and alignment plans I\u2019m most excited about.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrpj8nxvt2lc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrpj8nxvt2lc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Or maybe <a href=\"https://twitter.com/leopoldasch/status/1639679581308465154?s%3D46%26t%3D612rWr3QlD0pepiGrqymeg\"><u>billion-dollar prizes</u></a>.</p></div></li></ol>", "user": {"username": "leopold"}}, {"_id": "rpWddsXeJict8ZFr4", "title": "[Linkpost] Vox: \"To make the present feel more meaningful, think beyond it\"", "postedAt": "2023-03-29T13:39:50.213Z", "htmlBody": "<p>Richard Fisher outlines a more pluralist version of longtermism that he calls \"long-mindedness,\" drawing upon a variety of examples from history and the modern day.</p><p>Any moral framework/principle taken to the extreme leads to <a href=\"https://80000hours.org/podcast/episodes/ajeya-cotra-worldview-diversification/\">crazy town</a>, but unfortunately many articles I've read on longtermism in the media focus on this potential. It's nice to read an article that takes the opposite approach for once, talking about ways that longtermism can have broad appeal.</p><p>This is probably my favourite part:</p><blockquote><p>And later, in 1992, the vaccine pioneer Jonas Salk framed our cross-generational obligations with a simple question: \u201c<a href=\"https://www.jstor.org/stable/45064193\"><strong>Are we being good ancestors?</strong></a>\u201d</p><p>A couple of years ago, the writer and researcher Leopold Aschenbrenner \u2014 who co-wrote parts of William MacAskill\u2019s longtermist book <a href=\"https://bookshop.org/p/books/what-we-owe-the-future-william-macaskill/17831744?gclid=CjwKCAjwq-WgBhBMEiwAzKSH6DHOqNz94YHXHjB9KrqJl3RSeyK4OEHlPDzl6SMVEjfsPXBuTtIqZRoCsEoQAvD_BwE\"><i><strong>What We Owe The Future</strong></i></a> \u2014 proposed that longtermism could do more to embrace this approach. \u201cMost of all, I hope that more will take seriously the long arc of time,\u201d he wrote. \u201cOur civilization is an intergenerational enterprise.\u201d</p></blockquote><p>I generally find Richard's writing moving and this article did not disappoint. I'm looking forward to the publication of his book <a href=\"https://www.hachette.co.uk/titles/richard-fisher/the-long-view/9781472285232/\"><i>The Long View</i></a> tomorrow.</p>", "user": null}, {"_id": "8H9ZmocfzaCMvpGmw", "title": "Should we priortize cognitive science in EA?", "postedAt": "2023-03-29T10:11:07.321Z", "htmlBody": "<p>My naive thoughts: Most people in EA agree :\"increasing happiness, reducing suffering is the meaning of life\". To accomplish this goal, I think cognitive science is essential for all livings on earth(maybe AI too), but there are some very crucial and basic questions but we aren't sure about the answer. Like: What's the ratio of suffering and happiness? How seriously does hedonic treadmill limit happiness? Can things like mindfulness make all people happy? Are there interventions to make others altruistic? Is Hedonistic Imperative<strong> </strong>possible? (These questions are super hard, its solvability may be low)&nbsp;</p><p>A lot of &nbsp;cognitive science technology is developing(like brain neurons mapping). But we still don't understand the essence of \"sentience\". If we answer these questions, lots of moral uncertanties will be solved, we can be more cofidienct in doing right things. Hedonistic transhumanism may turn us to living \"perfectly\". But why do these researches seem not to be priortized in EA?&nbsp;</p><p>Finally, if you're choosing a colllege major, what's the most suitable field to go in for researching these cognitive scienece stuffs (biology&amp;neuropsychology, computer science, philosophy or none of the above.?)</p>", "user": {"username": "jackchang110"}}, {"_id": "PcDW7LybkR468pb7N", "title": "FLI open letter: Pause giant AI experiments", "postedAt": "2023-03-29T04:04:23.750Z", "htmlBody": "", "user": {"username": "zsp"}}, {"_id": "f77iuXmgiiFgurnBu", "title": "Run Posts By Orgs", "postedAt": "2023-03-29T02:40:55.921Z", "htmlBody": "", "user": {"username": "Jeff_Kaufman"}}, {"_id": "bfDke8yv6sX94jF4R", "title": "Desensitizing Deepfakes", "postedAt": "2023-03-29T01:20:54.790Z", "htmlBody": "<p>There is <a href=\"https://forum.effectivealtruism.org/posts/KigFfo4TN7jZTcqNH/the-future-fund-s-project-ideas-competition?commentId=iwCPwiqNc6Rc6wNti#iwCPwiqNc6Rc6wNti\">some</a> <a href=\"https://forum.effectivealtruism.org/posts/meBiCxrKTppczc8tS/is-misinformation-a-serious-problem-and-is-it-tractable#SbotQQJNJZxhcFsrn\">discussion</a> on the forum about using AI to detect whether or not something is a deepfake, and perhaps some trust in anti-deepfake bots to be better resourced etc. in this arms race. But could we give ourselves a bit of breathing room here?</p><p>Could it be incredibly valuable to accelerate desensitization to deepfakes? Or at least make people more aware of them by using humor?</p><p>It seems like a real risk that someone eventually creates a convincing and harmful deepfake, a la current President saying, \"America has launched nuclear weapons against Russia.\" Or vice versa or literally anything bad, with voice and video, that to our eyes is <i>Very Real </i>and <i>Convincingly Terrible</i>.</p><p>Should we be subverting people's expectations by familiarizing them with deepfakes, perhaps best done by example? If you have not seen it already, it seems that the memes of the US Presidents playing computer games (Warning expletives+: <a href=\"https://www.youtube.com/watch?v=qYF0jhwrzxA\">US Presidents play Minecraft</a>) is actually a pretty good example of this. On the flip side of this, I also recall seeing a video being shown to an older individual who, despite Biden saying the most heinous things, found it more believable that it was real than a deepfake.&nbsp;</p><p>So maybe spamming content for significant figures doing whacky things is effective for updating people's models for the probability of a deepfake. I was considering further pushing the bounds here by walking the fine line of a 'real fake' nuclear assault, a la Biden saying, \"My fellow Americans, we have launched nukes against... the Moon.\" But that seems unnecessarily too close to the mark.&nbsp;</p><p>There could be an info hazard that by demonstrating the capabilities of deepfakes you actually show people that this is a powerful manipulation tool and increase risk of malicious use.</p><p>Unsure call to action here, thought I'd share, hope for steelmanning/meta-feedback on post, and just indicate a potentially impactful angle that seems to be working pretty well in some ways...</p><p>Desensitizing idea of deepfakes without risk, in a way that may make people more likely to question whether something said is real (could be worth more rigorous study).</p>", "user": {"username": "Phib"}}, {"_id": "qnxSufwjPWENTTdMT", "title": "A rough and incomplete review of some of John Wentworth's research", "postedAt": "2023-03-28T18:52:51.743Z", "htmlBody": "", "user": {"username": "So8res"}}, {"_id": "TYyHpiAQ3TetwRMHC", "title": "What longtermist projects would you like to see implemented?", "postedAt": "2023-03-28T18:41:56.100Z", "htmlBody": "<p><strong>My team (Rethink Priorities\u2019 General Longtermism Team) is aiming to incubate 2-3 longtermist projects in 2023. I\u2019m currently collecting a longlist of project ideas</strong>, which we\u2019ll then research and evaluate, with the aim of kicking off the strongest projects (either via an internal pilot or collaboration with an external founder).&nbsp;</p><p>I\u2019m interested in ideas for entrepreneurial or infrastructure projects (i.e., not research projects, though a project could be something like \u201ccreate a new research institute focused on X\u201d).&nbsp;</p><p>Some examples to give a sense of the type of ideas we\u2019re interested in (without necessarily claiming that these specific ideas are particularly strong): An organization that lobbies for governments to install&nbsp;<a href=\"https://www.nature.com/articles/s41598-018-21058-w\"><u>far UVC lights</u></a> in government buildings; a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/MBDHjwDvhDnqisyW2/awards-for-the-future-fund-s-project-ideas-competition#Rumtin_Sepasspour___Existential_risk_whistleblowing_mechanism\"><u>third-party whistleblowing entity</u></a> taking reports from leading AI labs; or a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/MBDHjwDvhDnqisyW2/awards-for-the-future-fund-s-project-ideas-competition#gavintaylor___Infrastructure_to_support_independent_researchers\"><u>remote research institute for independent researchers</u></a>. You can see a list of our existing ideas&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1VLEiWx0_sFwjhCMao3vT_QxdWCufuq71XqaL2joVj8Y/edit#gid=1763987441\"><u>here</u></a>.</p><p><strong>I\u2019ll begin reviewing the ideas on April 17, so ideas posted before then would be most helpful.</strong></p>", "user": {"username": "Buhl"}}, {"_id": "q4ijrWYQPSG8b92aa", "title": "Coaching Training Program Launch: build and upskill your practice with Tee Barnett Coaching Training (TBCT)", "postedAt": "2023-03-28T09:40:09.124Z", "htmlBody": "<p>Applications are now open to join the pilot cohort of Tee Barnett Coaching Training! You\u2019d be a great fit for this if you\u2019re a current or aspiring coach seeking to gain skill as practitioners and/or establish your practice.</p><p>You can signal interest<strong> &gt;&gt; </strong><a href=\"https://bit.ly/3lmRJKe\"><strong>here</strong></a><strong> &lt;&lt;</strong></p><p>The deadline to submit the first round of applications is April 3.</p><p>We encourage people to start the process earlier because cohort coaches will asked to join and also initiate the program on a rolling basis. This will mean increasingly limited availability of cohort spots.&nbsp;</p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/q4ijrWYQPSG8b92aa/coaching-training-program-launch-build-and-upskill-your#Program_overview\">Program Overview</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/q4ijrWYQPSG8b92aa/coaching-training-program-launch-build-and-upskill-your#Spirit_of_the_pilot_\">Spirit of the Pilot</a><ul><li><a href=\"https://forum.effectivealtruism.org/posts/q4ijrWYQPSG8b92aa/coaching-training-program-launch-build-and-upskill-your#Philosophy_of_Approach\">Philosophy of Approach\u200b</a></li></ul></li><li><a href=\"https://forum.effectivealtruism.org/posts/q4ijrWYQPSG8b92aa/coaching-training-program-launch-build-and-upskill-your#Intended_Outcomes\">Intended Outcomes</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/q4ijrWYQPSG8b92aa/coaching-training-program-launch-build-and-upskill-your#More_about_the_training_infrastructure\">More about the Training Infrastructure</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/q4ijrWYQPSG8b92aa/coaching-training-program-launch-build-and-upskill-your#Program_pricing\">Program Pricing</a></li><li><a href=\"https://teebarnett.com/tbct#meetcohort\">Meet the Current Cohort</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/q4ijrWYQPSG8b92aa/coaching-training-program-launch-build-and-upskill-your#_Anticipated_Questions\">Anticipated Questions</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/q4ijrWYQPSG8b92aa/coaching-training-program-launch-build-and-upskill-your#Apply_\">Apply</a></li></ul><h2><strong>Program overview</strong></h2><p>This pilot program is a multi-component training infrastructure for developing your own practice as a skilled coach. You could think of it as a proto-accelerator or proto-incubator for solo practitioners, which also includes access to business architecture that is essential for building and maintaining a stand-alone practice.</p><p>The infrastructure targets key developmental bottlenecks of coaches, including early client acquisition, real-world practice, training and oversight by multiple senior coaches, co-created learning plans, reputational benefits, business architecture, and more.&nbsp;</p><p>The program is a key piece of a <a href=\"https://bit.ly/3N1q3To\"><u>higher-level mission</u></a> to boost the total number of skilled practitioners supporting people doing scalable good, including those in EA.&nbsp;<br><br>Tee Barnett Coaching Training (TBCT) will include:<br>&nbsp;</p><ul><li>A tailored curriculum co-created with cohort coaches</li><li>Systematic and consistent client referrals for engaging in real-world skill building</li><li>1-to-1 coaching training calls with Tee</li><li>Regular cohort calls with other cohort coaches</li><li>Free access to office hours with Tee</li><li>Peer coaching training calls</li><li>Turnkey technical systems for building and expanding your practice&nbsp; (partnering with <a href=\"https://www.antientropy.org/\"><u>Anti-Entropy</u></a>)&nbsp;</li><li>Other guidance and resources becoming a coach, setting up and/or enhancing your practice</li><li>Potentially also offering observation hours and guest senior coach interactive workshops</li></ul><p>\u2013 Duration \u2013 the first cohort is expected to last about 6 months, though timelines may vary depending on the intended growth plans agreed upon with each individual cohort coach.&nbsp;</p><p>\u2013 Pricing \u2013 costs of the program are currently reduced for the first cohort, pegged at roughly the equivalent of two personal coaching sessions per month with Tee.&nbsp;</p><p>\u2013 Location \u2013 remote, though the option may open up for TBCT to sponsor travel and accommodations for periods of in-person coaching training.<br><br><strong>&gt;&gt; </strong><a href=\"https://bit.ly/3lmRJKe\"><strong>Apply Here</strong></a><strong> &lt;&lt;</strong></p><h2>Spirit of the pilot&nbsp;</h2><p>Concepts conveying the vibe of the program: early-stage pilot, co-creationary, integration &amp; synthesis, complementarity, self-aligned</p><p><br>One-line summary: this is an early-stage coaching development program that provides infrastructural support for those in the process of establishing and enriching their coaching practice.<br>&nbsp;</p><p>The working design of the training infrastructure is partly a function of the early-stage nature of the program, but also a portfolio of <a href=\"https://forum.effectivealtruism.org/posts/q4ijrWYQPSG8b92aa/coaching-training-program-launch-build-and-upskill-your#Philosophy_of_Approach\"><u>deliberate philosophical and methodological stances</u></a> that encourage coaches to collaboratively sculpt their own learning process. For example, each cohort coach\u2019s \u2018curriculum'<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpb0k1rse02\"><sup><a href=\"#fnpb0k1rse02\">[1]</a></sup></span>&nbsp;will be the end result of a collaborative selection process between Tee and the coach themselves, with both parties iterating upon chosen materials and methods that will culminate into a highly personalized experience within the program.&nbsp;</p><p>Cohort coaches can expect much that comes with the territory of participating in a pilot program. On the one hand, participating in the \u2018founding cohort\u2019 can be thrilling and come with distinct benefits of the timing. On the other hand, there will be anticipated friction points associated with infrastructure and systems being under construction. &nbsp;</p><p>Potential positives include: upsides of less overall standardization, more collaborative involvement in the design of the training infrastructure, more direct involvement by Tee, lower monetary costs, network and impact benefits that come with being part of the \u2018founding\u2019 cohort, etc. Potential negatives include: downsides of less standardization, less efficiency because the infrastructure isn\u2019t settled and will likely be revised, less reputational signals (in some contexts), less certainty on program outcomes, etc.&nbsp;</p><h3>Philosophy of Approach</h3><p>Contrary to what the wildly imaginative title of the program would suggest, Tee Barnett Coaching Training (TBCT) isn\u2019t built in the image of Tee\u2019s private coaching practice. We'll shift into a more literary tenor in order to communicate the philosophy that underlies the training infrastructure, fleshing out the implications of this approach concretely towards the end of the section.&nbsp;</p><p>We can confidently assert that great coaches almost certainly had to take the long way in their developmental journey. Many, if not all, eventually had to part with notions like objective maps, silver-bullet guidebooks, or a strictly linear sense of progress. The developmental journey of a great coach is probably more like an odyssey of subjective sensemaking, with the most effective coaches mastering how to pass along the treasures that they\u2019ve come across and synthesized.</p><p>Odysseys of this variety are often endured with a sober acceptance that the path may perpetually be unclear or incomplete, even without any definitive final destination. Those with a particular kind of spirit continue on. And it is this indomitable spirit driving the design of our training infrastructure, that which commits to the odyssey for the betterment of themselves and others.&nbsp;</p><p>Continuously delivering fresh perspectives as a coach often requires skillfully meshing <i>variety in inspiration</i> with <i>sensibilities of discernment</i>. While innumerable existing approaches, methods and techniques exist, few will have the same effects, especially across different people and contexts. In much the same way subscribing to a particular discipline or paradigm can be limiting, we\u2019d also encounter constraints in being indiscriminately open to all notions of human perception and development.&nbsp;</p><p>TBCT balances this plurality of notions and discernment with a blend of firmness and humility that\u2019s specific to this program. There\u2019s firmness in privileging some tools over others. But there\u2019s also a humility in admitting that we haven\u2019t discovered (or will never discover) all tools, or claim to have fully mastered the tools we have found.&nbsp;</p><p>The training infrastructure is shaped by the sentiment above through a portfolio of philosophical and methodological choices. Our particular portfolio prioritizes cultivating subjective sophistication as a coach. In other words, a training program for the refinement of your own sensemaking compass, and hopefully in turn, the skill and wisdom to guide others in refining their own compasses.</p><p>It\u2019s an infrastructure that allows for coaches to integrate their preferred coaching methods, modalities, tools and intentions in a way that is ultimately intended to be effective when delivered to others. The turn from \u2018grow in your preferred direction\u2019 to \u2018make it effective\u2019 implies the presence of a supportive but also challenging process that intends to cause coaches to forge their own personal synthesis with their craft.&nbsp;</p><p>Subtle choices regarding the inclusion, integration and synthesis of various approaches are made along dimensions that are more granular than entire disciplines or paradigms. For instance, it wouldn\u2019t look like \u201chow can I train to be an IFS coach\u201d, but instead \u201cwhat parts of IFS theory fit within my theory of mind and reliably work well for my clients?\u201d It\u2019s not really about this procedure or that procedure, it\u2019s more about your personal experience with the effects of a given procedure. It\u2019s more about what parts of the procedure are better highlighted, refined, modified, or discarded.&nbsp;</p><p>Another way to get a better feel for the program would be to say that it isn\u2019t \u201cTee shows you his way of coaching,\u201d or \u201chow to coach according to such-and-such discipline,\u201d or even the purely agnostic \u201cchoose-your-own adventure with a coaching certificate at the end.\u201d This style of approach reflects the belief that Tee is well-suited to construct this infrastructure and facilitate developmental progress for coaches on this path,&nbsp;in contrast to more authoritative positioning that might cut against integrating a plurality of traditions, paradigms, modalities, methods, approaches and intentions.&nbsp;</p><p>But you will find evidence of our stances and choices all over the place, including the recruitment and selection of applicants, choices made in co-creating a cohort coach\u2019s tailored curriculum, suggestions and guidance regarding development of coaching skill and business architecture, etc.</p><p>&nbsp;</p><p>Here\u2019s a sample list of how these stances and choices would surface within the program:<br>&nbsp;</p><ul><li>Conceptions of coaching&nbsp;<ul><li>More like \u2013 engaging in wide-ranging and mutually enriching relationships with clients as a meaningful presence within their continuous process of self-discovery and self-actualization</li><li>Less like \u2013 purely a service for troubleshooting the practical and emotional problems presented by clients</li></ul></li><li>Self-development philosophy&nbsp;<ul><li>More like \u2013 Treating the cultivation and refinement of experiential observation and interpretation as critical to understanding (leading to better outcomes)&nbsp;</li><li>Less like \u2013 doubtful of all self-interpretation and/or suspicious we can never really know what\u2019s going on for ourselves. Defaulting to, or habitually relying upon, external judgment and decision-making generators&nbsp;</li></ul></li><li>Coaching methodology<ul><li>More like \u2013 gaining sophistication and facility with how the unconscious and semi-conscious mediate perception&nbsp;</li><li>Less like \u2013 taking self-reports and explication at face-value when working with clients\u200b</li></ul></li><li>Coaching intention<ul><li>More like \u2013 truth-tracking and truth-seeking interventions and methods of interpreting reality&nbsp;</li><li>Less like \u2013 forced mindsets or ideologies that privilege attainment of outcomes over engaging with reality</li></ul></li><li>Coaching development<ul><li>More like \u2013&nbsp; encouraging the synthesis and synergizing of multiple modalities&nbsp;</li><li>Less like \u2013 developing specialization within a single modality, or only developing the most basic general coaching skills</li></ul></li><li>Establishing a practice<ul><li>More like \u2013 advocating for business architecture that meshes in a healthy way with client interests&nbsp;</li><li>Less like \u2013 (un)intentionally perpetuating arrangements, or angling to upsell, for the purpose generating consistent or additional income</li></ul></li></ul><h2>Intended Outcomes</h2><p>Here\u2019s a non-exhaustive recap of the program outcomes that were interwoven throughout the previous sections:&nbsp;</p><ul><li>Program participants clarifying and securing the role that they want coaching to have in their lives<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefh4nqs8j0psi\"><sup><a href=\"#fnh4nqs8j0psi\">[2]</a></sup></span><ul><li>For aspiring coaches, it could mean achieving the ability to establish a viable practice.</li><li>For existing coaches, it could mean stabilizing their practice and taking it to exciting new heights, both in terms of personal and client outcomes</li></ul></li><li>Notable and demonstrable growth in coaching skill as co-determined between the cohort coach and TBCT. Indicators of this growth can include a selected mixture of skill bars set by the program, participant-driven goals, business viability of the practice, client satisfaction according to feedback, and others.&nbsp;</li><li>Proliferation of coaches who emphasize and capably facilitate self-alignment and internal integration in the creation, clarification and actualization of aspirations for clients</li><li>Proliferation of coaches excited to grapple with (and guide others in grappling with) cultivation of virtue and the ethical/moral ramifications of consequences</li><li>Establishing a <a href=\"https://bit.ly/3N1q3To\"><u>scalable practitioner upskilling apparatus</u></a> that boosts the total number of skilled coaches supporting people doing scalable good&nbsp;</li><li>Normalizing wide-spectrum and value-aligned relationships with coaches as a crucial component of one\u2019s process of self-discovery, self-actualization and attainment of aspirations</li><li>Generating memetically potent proofs of possible perspective, especially among those who influence group entities and cultures (e.g. promoting mental models that close the implementation gap between self-alignment and performance)&nbsp;</li></ul><p>The set of participant-specific and program-wide intended outcomes are moving targets that are subject to definitional clarification and revision, but increasingly specified and granular targets will be derived from the scaffolding outlined above.&nbsp;</p><h2>More about the training infrastructure</h2><p>For those who can see potential in coaching to be a great fit for themselves as well as a compelling way to proliferate good in the world, this training infrastructure puts critical elements of the practitioner development journey within arm\u2019s reach.&nbsp;</p><p>All of us have unique psychological starting points that are only partially decipherable. The totality of what coaches bring to bear on any given coaching interaction will have a mixture of intended, unexpected and often confusing effects. This easily labeled, but incredibly high-dimensional interaction \u2013 a coaching session \u2013 can be a very difficult experience to make sense of. Even basic questions can feel tricky to answer, such as \u201cwhat just happened?\u201d, \u201cdid I make a substantive difference?\u201d, \u201cwhy do they (not) keep coming back?\u201d or even \u201cdo I actually enjoy coaching?\u201d.&nbsp;</p><p>How coaches make sense of their experience is critically influential in their developmental journey. The training infrastructure is designed to meet coaches at these pivotal growth edges. From increasingly better positions of clarity across their many frontiers for potential growth, coaches can make better decisions within their practice.&nbsp;</p><p>An overarching goal of this program for cohort coaches is securing the role that you want coaching to have in your life. For aspiring coaches, it could mean achieving the willingness and ability to establish a viable practice. For existing coaches, it could mean stabilizing your practice and taking it to exciting new heights. We traverse the pathway to these success states principally through the acquisition and cultivation of skill, in contrast to over-emphasizing the power of credentialing or various marketing techniques.&nbsp;</p><p>Special care and attention is also paid, however, to setting up the appropriate business architecture (online presence, systems unifying scheduling softwares, invoicing, payment, follow-ups, etc.) as important for the sustainability of the overall practice.&nbsp;</p><h2>Program pricing</h2><p><strong>How Much \u2013</strong> the program is currently priced at $750 USD per month over the course of roughly 6 months. Payment is requested in monthly installments<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefh8h4rxcr5j8\"><sup><a href=\"#fnh8h4rxcr5j8\">[3]</a></sup></span>&nbsp;over the course of the agreed upon duration,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8213i3jycla\"><sup><a href=\"#fn8213i3jycla\">[4]</a></sup></span>&nbsp;which typically spans about 6 months.&nbsp;<br><br>There may be opportunities for scholarships. There may also be stipends for cohort coaches to pay for <i>unaffiliated courses</i> while being supported by this program in order to more directly pursue specific skills as part of their own developmental journey.&nbsp;</p><p><strong>Offsetting the cost \u2013 </strong>working with clients almost immediately serves a double function of being an important tenet of the program for engaging in real-world skill building, and is also a means of reducing or eliminating the costs of participating in the program for cohort coaches.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefg2htlxv67ne\"><sup><a href=\"#fng2htlxv67ne\">[5]</a></sup></span>&nbsp;TBCT will seek to provide systematic and consistent client referrals at a frequency co-determined by Tee and the cohort coach.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefw10yaxwdpw9\"><sup><a href=\"#fnw10yaxwdpw9\">[6]</a></sup></span></p><p>For an initial period of three months, clients referred to cohort coaches can expect to pay a guaranteed rate of $50 \u2013 $100/hr. USD. The exact rate within that range will vary as a matter of agreement between the supervised coach and client.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7kzh3ccrk6k\"><sup><a href=\"#fn7kzh3ccrk6k\">[7]</a></sup></span></p><p><i>Know someone who would be interested in working with supervised coaches at a discounted rate? They can </i><a href=\"http://bit.ly/3yUHoIt\"><i><u>apply here</u>.&nbsp;</i></a></p><p><strong>What\u2019s Included \u2013</strong> The monthly cost of the program is the equivalent of two 1.5-hour coaching sessions with Tee per month at his standard rate. In addition to receiving three hours per month of 1-to-1 coaching from Tee focused primarily on coaching development, cohort participants also receive access to the <a href=\"https://forum.effectivealtruism.org/posts/q4ijrWYQPSG8b92aa/coaching-training-program-launch-build-and-upskill-your#More_about_the_training_infrastructure\"><u>entire training infrastructure</u></a> mentioned above.&nbsp;<br><strong>Bird\u2019s eye view of pricing dynamics \u2013</strong> highlighting some of the operative dynamics and program intentions could contextualize both the program pricing and the overall mission.&nbsp;</p><p>This program is drawing energy and resources from i) the tapping into a common desire to take active steps toward self-improvement among both cohort coaches and clients, ii) tapping into a collective willingness to make trades in order to try things out, iii) bets about what people are happy to trade given assumptions about the potential value of coaching and coaching training.&nbsp;</p><p>In short, the training infrastructure model aims to scale personal growth options (coaching and coaching training) by reducing the number and severity of various tradeoffs at several key junctures. The hope is that altering the landscape by easing these tradeoffs will catalyze a number of collective upward spiral dynamics. Concretely speaking, demand for coaching could increase as the price to test it out drops, more would-be coaches get to test out the occupation and build skill models in lower stakes environments, and skill and trust networks get strengthened by consolidating a training infrastructure.&nbsp;</p><h2>\u200bAnticipated Questions</h2><p><i>\u2013 How do you choose which coaches you ask to join your program? What experience and/or qualities are you looking for?</i></p><p>A lot could be written about this, so I\u2019ll try to keep it concise. Something I\u2019d suggest applicants consider most is whether the vibe of the program, especially that which is outlined in the \u201cPhilosophy of Approach\u201d section resonates, and that the plans for bringing the spirit of the program to life seem sensible to you. Aside from minor confusions and uncertainties, which I\u2019d be happy to clear up for applicants who\u2019ve progressed further into the process, if too many things are askew with how the program feels to you, then that would be important to heed.</p><p>More is said below on what we\u2019re looking for in applicants. Don\u2019t worry if you feel that your profile doesn\u2019t seem to be a perfect fit. We\u2019d like to have a diverse cohort derived from a heterogenous pool of applicants, so we\u2019d be excited to be persuaded, take chances and examine our own assumptions about people during this process.</p><p>On a more concrete note, the first cohort of coaches will mostly consist of people who\u2019ve already demonstrated a fair amount of experience guiding others in some form (e.g. teaching, consulting, therapy, coaching, mentoring, managing, leadership), especially in high-responsibility contexts. It\u2019s less likely that we\u2019d invite individuals who may be quite inexperienced and looking into being a coach as a prospective career.</p><p>We\u2019re more likely to ask you to join the program if:</p><ul><li>Your heart is in this. We\u2019re looking for this and care about it a lot.</li><li>Unmistakably high rapport exists between us. Beyond just likability, there are important seeds of potentiality captured by rapport</li><li>Participating within this program seems to fit within your life plans (including basic logistical considerations)</li><li>Basic coordinating and syncing with people come relatively easy for you. High degrees of coordination and syncing abilities within diverse and complex environments would be even better</li><li>You can demonstrate a track record of thoughts and actions that align with things mentioned within the \u201cPhilosophy of Approach\u201d section, particularly evidence of having an epistemic profile that would allow for cultivating subjective sophistication as a coach</li><li>We can tell that you\u2019re viewing the training infrastructure (and the components therein) as important to a mainline plan that you\u2019re already actively driving forward (or strongly intend to pursue)</li><li>Your relationship to intellectual content and property is relatively open, respectful and trustworthy (i.e. we want to hand you tools and techniques to share with others. But it\u2019s about how the content is shared)</li><li>We can get a sense of a certain grittiness across different areas of your life</li><li>You can demonstrate instances, periods, and/or patterns of sustained contribution to the commons or local culture (i.e. investing in the environment for friends, family, community, co-workers, etc.)</li><li>We can detect your willingness and potential ability to handle the \u201cbusiness side\u201d of running in your own practice, including markers of reliability, consistency, intentionality, etc.</li><li>We get the sense that you\u2019re treating this application process as a two-way street (i.e. we get some indications (e.g. questions) that you\u2019re carefully considering whether to participate)</li></ul><p>We\u2019re less likely to ask you to join the program if:</p><ul><li>Many of your answers to the points above are directly or directionally not encouraging</li><li>You plan to invest in things that are outside the scope of traditions we\u2019re open to considering (e.g. homeopathy, intentionally unnamed \u2018dark arts\u2019 of various kinds)</li><li>We come across sufficiently concerning evidence and/or indicators that coordinating would be excessively challenging</li><li>We come across sufficiently concerning indicators, or even direct statements, that your development at TBCT will be channeled in non-benevolent ways</li><li>We come across sufficiently concerning patterns of evidence linking you to causing material harm to those around you</li></ul><p><i>\u2013 Do I need to self-identify as an effective altruist, or demonstrate being part of the EA community in some way? &nbsp;Is this program only meant to serve effective altruists?</i></p><p>No on all counts. We're after genuine heterogeneity of cohort coaches, which is partially achieved through a diversity of worldviews and approaches. It would bode well to be directionally aligned with ideas of doing good effectively. Involvement within effective altruism would be viewed only as weakly encouraging. We're targeting those who have a strong intention to coach people dedicating their lives to scalable world improvement.</p><p><i>\u2013 Do you accept coaches on a rolling basis, or do you have a cohort start date?</i></p><p>The intended starting period for the cohort is May, though we\u2019ll be flexible with the start date of each person in line with the highly personalized and tailored nature of the program.</p><p><i>\u2013 What\u2019s the intensity level of the commitment to this program?</i></p><p>My current line of thinking is that commitment levels will be structured with a mixture of minimums and incentives. Regarding the minimums, handshake agreements regarding payment and duration can be found in the \u2018Pricing\u2019 section.</p><p>A crude overview of the incentives component is something like, \u201cthe more presence, contribution, growth, etc., the more access you\u2019ll get to more things, including client referrals, training features, promotion of your practice, etc.\u201d I\u2019d want it to feel less like I\u2019m monitoring you for attendance at cohort meetings, for example, and more like your level of investment into yourself, your peers and the program will engender reciprocal investment into you. In some cases Tee will have sole discretion over some of these determinations. In other cases the determinations will come as a consequence of joint decision, and/or natural social consequences.</p><p>In other words, there are no codified minimum requirements for time commitments unless the need arises. We\u2019re trying to situate ways in which the rate of a cohort coach\u2019s investment will correlate with the rate of offered benefits from the program.</p><p><i>\u2013 Got more questions?&nbsp;</i></p><p>Additional answers will be added to this section as more commonly asked questions come in. The application will have a section for submitting questions, but you can also submit them to Tee at tee@teebarnett.com.</p><h2>Apply&nbsp;</h2><p>Basics \u2013 You can signal your interest in this <a href=\"https://bit.ly/3lmRJKe\">brief application</a>.&nbsp;</p><p>The deadline to submit the first round of applications is April 3.&nbsp;</p><p>We encourage people to start the process earlier because cohort coaches will asked to join and also initiate the program on a rolling basis. This will mean increasingly limited availability of cohort spots.&nbsp;</p><p>Process \u2013 The application consists of submitting basic information as an initial starting point. This will be a three-round process that aims to conclude by early May.&nbsp;</p><ul><li>Round 1 \u2013 basic information and expression of interest</li><li>Round 2 \u2013 short- and long- answer questions + submission of existing materials (where applicable)</li><li>Round 3 \u2013 interview<br>&nbsp;</li></ul><p>As we mention in a previous section, don\u2019t worry if you feel that your profile isn't a perfect fit. We\u2019d like to have a diverse cohort derived from a heterogenous pool of applicants, so we\u2019d be excited to be persuaded, take chances and examine our own assumptions about people during this process.&nbsp;</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpb0k1rse02\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpb0k1rse02\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Defined as a semilinear progression of learning materials</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnh4nqs8j0psi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefh4nqs8j0psi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Attaining this bodes well for continued development and is a weakly encouraging indirect indicator of skill, efficient business architecture, etc.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnh8h4rxcr5j8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefh8h4rxcr5j8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Payment plans for cohort coaches can be crafted on an individual basis. Once a client is referred by TBCT, the client coach has full ownership over the terms of that relationship. (i.e. cohort coaches can treat that client as if they initiated the relationship themselves, with the exception of keeping the locked-in 3-month rate of $50 \u2013 $100/hr. USD.) This only wouldn\u2019t be the case if the cohort coach requests a different arrangement, though Tee is generally trying to avoid commission, percentage sharing and other similar arrangements for a lot of reasons. Program pricing may change after the initial cohort.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8213i3jycla\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8213i3jycla\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Currently there is no formal legal commitment on either end to see the complete duration through. All parties will be relying upon personal and shared approximations of value transfer. As a default, payments up to the current day are non-refundable, though Tee intends to make reasonable efforts to resolve disputes, including the potential for full or partial refunds. Due to the high-touch nature of the program, it seems very unlikely that a poor fit between the cohort coach and the program would be a protracted state of affairs.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fng2htlxv67ne\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefg2htlxv67ne\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Systematic and consistent client referrals to cohort coaches by TBCT will cease once a cohort coach moves on from the program. However, this wouldn\u2019t preclude plans to informally continue to provide referrals, which is intended to be the case among a tight network of skilled coaches who would be happy to help clients find the right fit for them.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnw10yaxwdpw9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefw10yaxwdpw9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>TBCT is unable to provide an ironclad guarantee that cohort coaches will get their preferred volume of referrals and client conversions. This is partially because attracting, converting and retaining clients is integral to building out a stand-alone practice, which is a core focus of TBCT infrastructural support. There\u2019s good reason to believe demand exists enough to fuel referrals, especially at the initial three-month locked-in rate of $50 \u2013 $100/hr. As an example, our first cohort coach received 20 opportunities for matches with potential clients within the first month or two. (This was with very little outbound marketing.)&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7kzh3ccrk6k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7kzh3ccrk6k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Within the first three months of taking on TBCT clients, the program pays for itself after 7.5 hrs. of client sessions per month at $100/hr. USD, or 15 hours of client sessions per month at the low end of $50/hr. For reference, Tee\u2019s averages between 10 and 15 hours per week in his regular practice. How many hours per week/month it makes sense for cohort coaches to take on will also vary depending on the coach. Know someone who would be interested in working with supervised coaches at a discounted rate?</p></div></li></ol>", "user": {"username": "Tee"}}, {"_id": "SZZdYwYvkJjus2vGp", "title": "Increase in future potential due to mitigating food shocks caused by abrupt sunlight reduction scenarios", "postedAt": "2023-03-28T07:43:52.264Z", "htmlBody": "<p>Disclaimer: this is not a project from Alliance to Feed the Earth in Disasters (<a href=\"https://allfed.info/about\"><u>ALLFED</u></a>).</p><h1>Summary</h1><ul><li>I estimate globally (and fully) mitigating food shocks caused by abrupt sunlight reduction scenarios (ASRSs) between 2024 and 2100 leads to an increase in future potential<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6m1hxd22md4\"><sup><a href=\"#fn6m1hxd22md4\">[1]</a></sup></span>&nbsp;of 37.2 <a href=\"https://en.wikipedia.org/wiki/Basis_point\"><u>bp</u></a>&nbsp;(5th to 95th percentile, -73.1 to 199).<ul><li>This is 4.83 (-9.50 to 25.9) times Toby Ord\u2019s best guess of 7.70 bp for the existential risk from nuclear war for the same period assuming constant annual risk.</li><li>5%, 50 % and 95 % of the increase come from ASRSs whose soot ejection into the stratosphere is smaller than 5.90, 31.4 and 66.7 <a href=\"https://www.nist.gov/pml/owm/metric-si-prefixes\"><u>T</u></a>g<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref71tblicwtyk\"><sup><a href=\"#fn71tblicwtyk\">[2]</a></sup></span>.</li></ul></li><li>The increase in future potential due to nationally (and fully) mitigating food shocks varies greatly across countries. It is:<ul><li>For the United States, the country whose national mitigation leads to the largest increase in future potential,&nbsp;1.21 times that of global mitigation.</li><li>For China, the country whose national mitigation leads to the largest decrease in future potential, -1.21 times that of global mitigation.</li></ul></li><li>All results should be taken with a big grain of salt, as they rely on quite <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt#Speculative_assumptions\"><u>speculative assumptions</u></a>.</li></ul><h2>Acknowledgements</h2><p>Thanks to Anonymous Person.</p><h1>Introduction</h1><p>ASRSs involve a significant reduction in the amount of sunlight reaching the Earth\u2019s surface. This causes temperatures to drop, so agricultural yields decrease, and so does food supply. ASRSs can be a <a href=\"https://en.wikipedia.org/wiki/Nuclear_winter\"><u>nuclear winter</u></a>, <a href=\"https://en.wikipedia.org/wiki/Volcanic_winter\"><u>volcanic winter</u></a>, or <a href=\"https://en.wikipedia.org/wiki/Impact_winter\"><u>impact winter</u></a>.</p><p>I estimated <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt\"><u>here</u></a>&nbsp;the increase in future potential due to globally (and fully) or nationally (and fully) mitigating food shocks caused by ASRSs conditional on them happening. The present analysis leverages these results, and weights them by the likelihood of the various levels of severity of ASRSs. The output can be interpreted as estimates for the <a href=\"https://forum.effectivealtruism.org/topics/importance\"><u>importance</u></a>/scale of the problem <a href=\"https://forum.effectivealtruism.org/topics/resilient-food\"><u>resilient food</u></a>&nbsp;solutions are trying to solve.</p><p>I encourage you to check the methods of my <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt\"><u>previous analysis</u></a>, which include quite <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt%23Speculative_assumptions\"><u>speculative assumptions</u></a>, to see how much to trust the results I get here. However, I believe one should also have in mind the output of that analysis, i.e. the badness of ASRSs by level of severity, is not supposed to be very <a href=\"https://forum.effectivealtruism.org/topics/credal-resilience\"><u>resilient</u></a>. It is only meant to be an improvement on the direct guesses of that factor provided in <a href=\"https://www.sciencedirect.com/science/article/pii/S2212420922000176\"><u>Denkenberger 2022</u></a>&nbsp;(whose evaluation by <a href=\"https://forum.effectivealtruism.org/topics/the-unjournal\"><u>The Unjournal</u></a>&nbsp;is <a href=\"https://sciety.org/articles/activity/10.31219/osf.io/vrmpf\"><u>here</u></a>), and <a href=\"https://forum.effectivealtruism.org/posts/n52z7r8iH5pvWN2DE/speedrun-demonstrate-the-ability-to-rapidly-scale-food\"><u>this</u></a>&nbsp;post from Marie Buhl.</p><p>If not accuracy, I hope my explicit modelling at least increases <a href=\"https://www.openphilanthropy.org/research/reasoning-transparency/\"><u>reasoning transparency</u></a>, and therefore enables criticism to be more constructive.</p><h1>Methods</h1><p>I estimated the increase in future potential due to mitigating food shocks caused by ASRSs from the sum of those linked to nuclear war and volcanic eruptions. In comparison to these, the risk from asteroids and comets is negligible. Based on Toby Ord\u2019s best guesses given in Table 6.1 of <a href=\"https://theprecipice.com/\"><u>The Precipice</u></a>, the existential risk between 2021 and 2120 from asteroids and comets is 1 % (= 10^-4/0.01) that from supervolcanoes, and 0.1 % (= 10^-4/0.1) that from nuclear war.</p><p>The data and calculations are in <a href=\"https://docs.google.com/spreadsheets/d/1JqLTO2Jq2zUhyQMkeLYi10bisZ7DlccFKTMxLMzcY_A/edit?usp%3Dsharing\"><u>this</u></a>&nbsp;Sheet (see tab \u201cTOC\u201d) and <a href=\"https://colab.research.google.com/drive/1H1RnlXI1jp8CQsknKrCEErHUfXLYRXdQ?usp%3Dsharing\"><u>this</u></a>&nbsp;Colab. I modelled all variables as independent distributions, and ran a Monte Carlo simulation with 100 k samples per variable to get the results<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmpgyo882lw\"><sup><a href=\"#fnmpgyo882lw\">[3]</a></sup></span>.</p><h2>Nuclear war</h2><p>I estimated the increase in future potential due to mitigating food shocks caused by ASRSs linked to nuclear war between 2024 and 2100 from the product between:</p><ul><li>Probability of global nuclear war between 2024 to 2100. I set this to 17.5 %<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefs6a02ih0j1\"><sup><a href=\"#fns6a02ih0j1\">[4]</a></sup></span>&nbsp;(= 1 - (1 - 11 %)^((2100 - 2024 + 1)/(2070 - 2023.25))) in agreement with <a href=\"https://www.metaculus.com/home/\"><u>Metaculus</u></a>\u2019 community prediction of <a href=\"https://www.metaculus.com/questions/3517/will-there-be-a-global-thermonuclear-war-by-2070/\"><u>11 %</u></a>&nbsp;(on 27 March 2023) for the chance of global thermonuclear war before 2070.<ul><li>The respective Metaculus\u2019 question belongs to the <a href=\"https://www.metaculus.com/questions/categories/\"><u>categories</u></a>&nbsp;of armed conflict, impactful forecasting prize, effective altruism, and weapons.</li><li>The <a href=\"https://en.wikipedia.org/wiki/Brier_score\"><u>Brier score</u></a>&nbsp;of&nbsp;Metaculus\u2019 community predictions evaluated at all times for the questions of at least one of the above categories was 0.091 on 27 March 2023&nbsp;(see <a href=\"https://www.metaculus.com/questions/track-record/\"><u>here</u></a>).</li></ul></li><li>Increase in future potential due to mitigating food shocks caused by ASRSs if there is a nuclear war between The North Atlantic Treaty Organization (<a href=\"https://en.wikipedia.org/wiki/NATO\"><u>NATO</u></a>) and Russia from 2024 to 2100. I set this to a distribution whose:<ul><li>Input is an ejection of soot into the stratosphere, which I obtained from the product between:<ul><li>Ejection of soot into the stratosphere if there is a nuclear war between NATO and Russia. I defined this as a lognormal distribution with 5th and 95th percentiles equal to 14 and 66 Tg<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefucd9w8n3c2c\"><sup><a href=\"#fnucd9w8n3c2c\">[5]</a></sup></span>, which are the lower and upper bound of the 95 % <a href=\"https://en.wikipedia.org/wiki/Confidence_interval\"><u>confidence interval</u></a>&nbsp;calculated <a href=\"https://forum.effectivealtruism.org/posts/pMsnCieusmYqGW26W/how-bad-would-nuclear-winter-caused-by-a-us-russia-nuclear\"><u>here</u></a>&nbsp;by Luisa Rodriguez.</li><li>Adjustment factor to model the change in the number of (non-retired) nuclear warheads<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcoln2xcvtt\"><sup><a href=\"#fncoln2xcvtt\">[6]</a></sup></span>. I set this to the ratio between:<ul><li>The mean number of nuclear warheads globally from 2024 to 2100. I computed this from normal distributions whose 25th and 75th percentiles are given by&nbsp;<a href=\"https://www.metaculus.com/questions/12722/global-nuclear-warhead-stockpiles/\"><u>Metaculus\u2019 community predictions</u></a> for 2023, 2025, 2032, 2052, and 2122 (on 26 March 2023), assuming the number of nuclear warheads evolves linearly between each consecutive pair of these years.</li><li>The number of nuclear warheads from NATO and Russia in 2019, when Luisa published&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pMsnCieusmYqGW26W/how-bad-would-nuclear-winter-caused-by-a-us-russia-nuclear\"><u>this</u></a>, which was 8,640<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrp1bjmlqq4k\"><sup><a href=\"#fnrp1bjmlqq4k\">[7]</a></sup></span>&nbsp;according to&nbsp;<a href=\"https://ourworldindata.org/grapher/nuclear-warhead-stockpiles\"><u>these</u></a> data from OWID.</li></ul></li></ul></li></ul></li><li><a href=\"https://en.wikipedia.org/wiki/Quantile_function\"><u>Quantile function</u></a>&nbsp;is obtained by linearly interpolating between<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefm4mg9dje1t\"><sup><a href=\"#fnm4mg9dje1t\">[8]</a></sup></span>:<ul><li>For 5 to 150 Tg, those I got <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt\"><u>here</u></a>&nbsp;for 5, 16, 27, 37, 47 and 150 Tg. For example, the quantile function for global mitigation for a soot ejection of 32 Tg would be the mean between those for 27 and 37 Tg shown in the graph <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt%23My_results_using_a_Monte_Carlo_simulation\"><u>here</u></a>.</li><li>For less than 5 Tg, zero<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz3fygk9t2bo\"><sup><a href=\"#fnz3fygk9t2bo\">[9]</a></sup></span>&nbsp;and those I got <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt\"><u>here</u></a>&nbsp;for 5 Tg.</li><li>For more than 150 Tg, those I got <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt\"><u>here</u></a>&nbsp;for 150 Tg, and 1 for 15 <a href=\"https://www.nist.gov/pml/owm/metric-si-prefixes\"><u>P</u></a>g. This is the amount of soot linked to the impact winter of the <a href=\"https://en.wikipedia.org/wiki/Cretaceous-Paleogene_extinction_event\"><u>Cretaceous\u2013Paleogene extinction event</u></a>, and would lead to a 100 % food shock. According to the simulations of <a href=\"https://europepmc.org/article/pmc/5594694\"><u>Bardeen 2017</u></a>, \u201cas a result [of an ASRS of 15 Pg], little or no sunlight reaches the surface for over a year, such that photosynthesis is impossible and continents and oceans cool by as much as 28 \u00b0C and 11 \u00b0C, respectively\u201d.</li></ul></li></ul><h2>Volcanic eruptions</h2><p>I estimated the increase in future potential due to mitigating food shocks caused by ASRSs linked to volcanic eruptions between 2024 and 2100 from the product between:</p><ul><li>Probability of a volcanic eruption with a volcanic explosivity index (<a href=\"https://en.wikipedia.org/wiki/Volcanic_explosivity_index\"><u>VEI</u></a>) of at least 7 between 2024 and 2100, which I set to 1/6 in line with <a href=\"https://www.nature.com/articles/d41586-022-02177-x\"><u>Cassidy 2022</u></a>.</li><li>Increase in future potential due to mitigating food shocks caused by ASRSs if such volcanic eruption happens. I determined this as in the previous section, but used an ejection of soot into the stratosphere 10 % as large, because:<ul><li>Based on Toby Ord\u2019s best guesses given in Table 6.1 of <a href=\"https://theprecipice.com/\"><u>The Precipice</u></a>, the existential risk between 2021 and 2120 from supervolcanic eruptions is 10 % (= 10^-4/0.001) that from nuclear war.</li><li>From the 2nd table <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt%23My_results_using_a_Monte_Carlo_simulation\"><u>here</u></a>, the increase in future potential from globally mitigating food shocks increases roughly linearly with the soot ejected into the stratosphere (<a href=\"https://en.wikipedia.org/wiki/Coefficient_of_determination\"><u>coefficient of determination</u></a>&nbsp;of 92.1 %).</li><li>A volcanic eruption with a VEI of a least 7 is roughly as likely as global nuclear war (1/6 = 16.7 % is close to 17.5 %).</li></ul></li></ul><h1>Results</h1><p>The key results are in the tables below. The full results are in the Sheet.</p><h2>Key stats</h2><figure class=\"table\"><table><thead><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"2\"><p>Where the food shocks are mitigated</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"3\" rowspan=\"1\"><p>Increase in future potential due to mitigating food shocks caused by ASRSs as a fraction of the current value of the future (bp)</p></th></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5th percentile</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>95th percentile</p></th></tr></thead><tbody><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>World</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>37.2</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-73.1</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>199</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean country</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>0.919</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-4.29</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>8.03</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Best country</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>45.2</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-66.6</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>214</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10th&nbsp;best country</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>4.14</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-5.64</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>21.9</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10th worst country</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-0.976</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-4.59</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>1.50</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Worst country</p></th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-44.9</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-178</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>66.4</p></td></tr></tbody></table></figure><h2>Global mitigation</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZZdYwYvkJjus2vGp/d97xk3zrwv9wunmmmvmd\"></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZZdYwYvkJjus2vGp/jiuev6wmf9bp7w9vy00t\"><figcaption>Each point refers to a soot interval spanning 0.1 Tg<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefeexic5ns204\"><sup><a href=\"#fneexic5ns204\">[10]</a></sup></span>. For example, that of 0.05&nbsp;Tg respects the interval from 0 to 0.1 Tg.</figcaption></figure><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZZdYwYvkJjus2vGp/ttp8mgf79h33rghbkonf\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/SZZdYwYvkJjus2vGp/gv5extm1x6mx3lbqq2hl\"></p><h2>National mitigation</h2><figure class=\"table\"><table><thead><tr><th style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"2\" rowspan=\"1\"><p>Countries where the food shocks are mitigated by descending order of increase in future potential</p></th><th style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"3\" rowspan=\"1\"><p>Increase in future potential due to mitigating food shocks caused by ASRSs as a fraction of the current value of the future (bp)</p></th></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Ranking</p></th><th style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Country</p></th><th style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean</p></th><th style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5th percentile</p></th><th style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>95th percentile</p></th></tr></thead><tbody><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>United States</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>45.2</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-66.6</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>214</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Japan</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>20.3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-29.9</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>95.9</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Germany</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>19.1</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-29.9</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>99.5</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>United Kingdom</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>12.9</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-21.4</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>68.9</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>France</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>10.3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-15.0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>59.1</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>6</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Canada</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>9.58</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-13.2</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>42.4</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>7</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>South Korea</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>9.28</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-13.9</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>44.2</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>8</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Italy</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>8.07</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-12.3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>46.8</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>9</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Netherlands</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>5.01</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-7.74</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>26.5</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>10</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Poland</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>4.14</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-5.64</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>21.9</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>136</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Kazakhstan</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-0.976</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-4.59</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>1.50</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>137</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>United Arab Emirates</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-1.09</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-4.41</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>1.52</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>138</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Pakistan</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-1.33</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-7.70</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>1.88</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>139</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Saudi Arabia</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-1.33</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-9.26</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>1.55</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>140</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Turkey</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-1.43</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-7.82</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>1.90</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>141</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>India</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-1.78</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-9.07</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>2.86</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>142</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Vietnam</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-1.78</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-11.0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>2.70</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>143</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Iran</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-3.52</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-18.8</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>5.37</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>144</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>Russian</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-5.42</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-23.4</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>9.24</p></td></tr><tr><td style=\"border:1pt solid rgb(0, 0, 0);text-align:center\" colspan=\"1\" rowspan=\"1\"><p>145</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>China</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-44.9</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>-178</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\"><p>66.4</p></td></tr></tbody></table></figure><h1>Discussion</h1><h2>Global mitigation</h2><p>According to my results, globally mitigating food shocks caused by ASRSs between 2024 and 2100 leads to an increase in future potential of 37.2 bp (5th to 95th percentile, -73.1 to 199). This is 4.83 (-9.50 to 25.9) times Toby Ord\u2019s best guess of 7.70 bp (= 1 - (1 - 0.1 %)^(77/100)) for the existential risk from nuclear war for the same period assuming constant annual risk. Nevertheless, it is unclear whether my estimate is directly comparable to Toby Ord\u2019s guess:</p><ul><li>Mine refers to a change in value of the future.</li><li>Toby Ord\u2019s refers to the chance of an existential catastrophe, which is defined in&nbsp;<a href=\"https://theprecipice.com/\"><u>The Precipice</u></a> as \u201cthe destruction of humanity\u2019s longterm potential\u201d.</li></ul><p>If the value of the future were binary, a change in it would be directly proportional to the probability of an existential catastrophe, in which case my estimate would be directly comparable to Toby Ord\u2019s guess.</p><p>I find mitigating food shocks has both positive and negative heavy tails, as is illustrated in the 1st graph for the case of global mitigation<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8nd89f60zjo\"><sup><a href=\"#fn8nd89f60zjo\">[11]</a></sup></span>. This is essentially because, in <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt%23Methods\"><u>my model</u></a>, I assume a 25 % chance the future would be worse for higher socioeconomic indices (details <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt%23Value_of_the_future\"><u>here</u></a>).</p><p>Arguments for the existence of a counterproductive heavy tail are described in <a href=\"https://onlinelibrary.wiley.com/doi/10.1111/phpe.12133\"><u>Kokotajlo 2020</u></a>&nbsp;(whose EA Forum crosspost is <a href=\"https://forum.effectivealtruism.org/posts/DJTpSNbNfCqKzc7ja/counterproductive-altruism-the-other-heavy-tail\"><u>here</u></a>):</p><blockquote><p>We canvass arguments EAs have given for the existence of a positive (or \u201cright\u201d) heavy tail and argue that they can also apply in support of a negative (or \u201cleft\u201d) heavy tail where counterproductive interventions do orders of magnitude more harm than ineffective or moderately harmful ones.</p></blockquote><p>The 2nd and 3rd graphs show the increase in future potential due to globally mitigating food shocks is not driven by very severe ASRSs<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreft4pz74pfson\"><sup><a href=\"#fnt4pz74pfson\">[12]</a></sup></span>. 5 %, 50 % and 95 % of the increase come from ASRSs whose soot ejection into the stratosphere is smaller than 5.90, 31.4 and 66.7 Tg. Larger soot ejections lead to greater drops in food production, but they are rare, so their expected harm ends up playing a minor role in my model.</p><h2>National mitigation</h2><p>The increase in future potential due to nationally mitigating food shocks varies greatly across countries. It is:</p><ul><li>For the United States, the country whose national mitigation leads to the largest increase in future potential:<ul><li>49.2 (= 45.2/0.919) times that of a randomly selected country (the mean country).</li><li>10.9 (= 45.2/4.14) times that of the 10th country (Poland).</li><li>1.21 (= 45.2/37.2) times that of global mitigation.</li></ul></li><li>For China, the country whose national mitigation leads to the largest decrease in future potential:<ul><li>-48.8 (= -44.9/0.919) times that of a randomly selected country (the mean country).</li><li>46.0 (= 44.9/0.976) times that of the 10th worst country (Kazakhstan).</li><li>-1.21 (= -44.9/37.2) times that of global mitigation.</li></ul></li></ul><p>These estimates illustrate the presence of both left and right tails. Furthermore, nationally mitigating food shocks is harmful not only in pessimistic cases, but also in expectation in 40.7 % (= 59/145) of the countries I analysed. The reasons are (see discussion <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt%23Local_mitigation1\"><u>here</u></a>):</p><ul><li>I suppose (see <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt%23Methods\"><u>here</u></a>) <a href=\"https://en.wikipedia.org/wiki/Real_gross_domestic_product\"><u>real gross domestic product</u></a>&nbsp;(real GDP) is a good proxy for (good or bad) influence in the future.</li><li>Mitigating the food shocks of a country counterfactually increases its real GDP in the worst year of the ASRS.</li><li>Consequently, mitigating the food shocks of a country with low<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefj41xiq3blid\"><sup><a href=\"#fnj41xiq3blid\">[13]</a></sup></span>&nbsp;socioeconomic indices<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefckgxd6752x6\"><sup><a href=\"#fnckgxd6752x6\">[14]</a></sup></span>&nbsp;leads to lower global socioeconomic indices weighted by influence. I assume this is bad, although with significant uncertainty (see 2nd paragraph of the previous section).</li></ul><p>Is it possible that nationally mitigating food shocks robustly increases real GDP in the nearterm, but accidentally leads to a worse future if it decreases global socioeconomic indices weighted by influence? Is this even a real trade-off? Would it be better to use socioeconomic indices multiplied, instead of weighted, by real GDP as a proxy for future potential, such that greater real GDP would always be good? I am uncertain about the answers.</p><h2>Cost-effectiveness</h2><p>The cost-effectiveness of an intervention to mitigate food shocks can be obtained from the ratio between the increase in future potential it causes, and its cost. The former can be calculated by inputting a relative increase in food supply in <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt\"><u>this</u></a>&nbsp;model, and then running the present analysis with the updated quantile functions for the increase in future potential by ejection of soot into the stratosphere.</p><p><a href=\"https://forum.effectivealtruism.org/posts/LWN6qFhCtPDEJJpeG/cost-effectiveness-of-operations-management-in-high-impact\"><u>Here</u></a>&nbsp;I got a (marginal) cost-effectiveness of 3.95 bp/<a href=\"https://www.nist.gov/pml/owm/metric-si-prefixes\"><u>G</u></a>$ for the area of&nbsp;longtermism and catastrophic risk prevention. To meet that bar, an intervention costing 10 M$ would have to cause an increase in future potential equal to 0.106 % (= 3.95*0.01/37.2) of that of global full mitigation.</p><p>The (longterm) cost-effectiveness of <a href=\"https://allfed.info/resilient-foods/resilient-food-solutions\"><u>resilient food solutions</u></a>&nbsp;is estimated in <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S2212420922000176\"><u>Denkenberger 2022</u></a>&nbsp;(whose evaluation by <a href=\"https://forum.effectivealtruism.org/topics/the-unjournal\"><u>The Unjournal</u></a>&nbsp;is <a href=\"https://sciety.org/articles/activity/10.31219/osf.io/vrmpf\"><u>here</u></a>),&nbsp;and <a href=\"https://forum.effectivealtruism.org/posts/n52z7r8iH5pvWN2DE/speedrun-demonstrate-the-ability-to-rapidly-scale-food\"><u>this</u></a>&nbsp;post from Marie Buhl. I may estimate it too in the future.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6m1hxd22md4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6m1hxd22md4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Value of the future, which I think about as <a href=\"https://utilitarianism.net/types-of-utilitarianism/#expectational-utilitarianism-versus-objective-utilitarianism\"><u>expected</u></a> <a href=\"https://www.utilitarianism.net/population-ethics/#the-total-view\"><u>total</u></a> <a href=\"https://www.utilitarianism.net/theories-of-wellbeing/#hedonism\"><u>hedonistic</u></a>&nbsp;utility.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn71tblicwtyk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref71tblicwtyk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;1 Tg corresponds to 1 M<a href=\"https://en.wikipedia.org/wiki/Tonne\"><u>t</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmpgyo882lw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmpgyo882lw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For me, the running time is 7 min.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fns6a02ih0j1\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefs6a02ih0j1\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This corresponds to an annual probability of 0.249 % (= 1 - (1 - 0.175)^(1/(2100 - 2024 + 1))).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnucd9w8n3c2c\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefucd9w8n3c2c\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The mean of this distribution is 33.4 Tg, which is 1.13 (= 33.4/30) times that of Luisa.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncoln2xcvtt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcoln2xcvtt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The mean of this adjustment factor is 84.4 %.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrp1bjmlqq4k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrp1bjmlqq4k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;3,805 from the United States, 4,330 from Russia, 300 from France, and 205 from the United Kingdom.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnm4mg9dje1t\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefm4mg9dje1t\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I approximated each quantile function by 1001 points corresponding to the quantiles 0, 0.001, 0.002, \u2026, 0.999 and 1.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz3fygk9t2bo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz3fygk9t2bo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Because there should be no change in the potential of the future if there is no soot ejected into the stratosphere.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fneexic5ns204\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefeexic5ns204\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Except for the point of 150 Tg, which goes from 150 to 15 k Tg, such that there is a bump at the end of the line.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8nd89f60zjo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8nd89f60zjo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The graphs for national mitigation can be obtained in tab \u201cIncrease in future potential - quantile functions\u201d, selecting the desired country in the dropdown menu of A4.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnt4pz74pfson\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreft4pz74pfson\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The graphs for national mitigation can be obtained in tab \u201cIncrease in future potential by soot - PDFs and CDFs\u201d, selecting the desired country in the dropdown menu of A2.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnj41xiq3blid\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefj41xiq3blid\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Relative to the mean across countries weighted by real gross domestic product.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnckgxd6752x6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefckgxd6752x6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;As a first approximation, low Varieties of Democracy\u2019s main index (see table <a href=\"https://forum.effectivealtruism.org/posts/jBEyb8akFGzbADokR/future-benefits-of-mitigating-food-shocks-caused-by-abrupt%23Future_Expected_Value_Index\"><u>here</u></a>).</p></div></li></ol>", "user": {"username": "vascoamaralgrilo"}}, {"_id": "JgexokNweDkTbkynG", "title": "Shallow Investigation: Bacterial Meningitis", "postedAt": "2023-03-28T08:57:33.276Z", "htmlBody": "<p><i>This report consolidates a shallow investigation into Bacterial Meningitis - its effects and importance in global health, &nbsp;the current tractability and cost-effectiveness of leading interventions, and an evaluation of the overall promise of the cause. I estimate this report to be a result of about 60-70 hours of research and writing. This research was conducted as part of the Cause Innovation Bootcamp fellowship, with constant guidance from Dr. Akhil Bansal.&nbsp;</i></p><h2><strong>Summary</strong>:</h2><p>Meningitis is an inflammation (swelling) of the protective membranes covering the brain and spinal cord. It is commonly associated with infections (e.g. bacterial meningitis, viral meningitis),&nbsp; but it can also have non-infectious causes. The most common symptoms include fever, headache, sensitivity to light, and neck stiffness; in most cases, meningitis is treatable by addressing the underlying cause e.g. treating the causative infection.</p><ul><li>Bacterial meningitis is important from a global health perspective - it ranks 40th on the current list of diseases in terms of total DALYs lost.<ul><li>4 strands of bacteria cause 50% of all meningitis-related deaths, namely meningococcus, pneumococcus, Haemophilus influenzae and group B streptococcus - all of which are vaccine-preventable.</li><li>GBS (Group B Streptococcus) ranks 6th on the list of causes leading to DALYs lost in the age-group 1-10.&nbsp;</li><li>Bacterial meningitis is heavily concentrated in the African Meningitis belt, consisting of regions in 26 countries stretching from Senegal in the West to Ethiopia in the East, and incidence is inversely related with socio-demographic index (SDI).</li></ul></li><li>Bacterial meningitis does not seem to be neglected -&nbsp;<ul><li>Important steps seem to have been taken already to counter meningitis on a global scale; including WHO\u2019s comprehensive report on \u201cA Global Plan to Defeat Meningitis by 2030\u201d.</li><li>While the important interventions seem tractable, they seem to be less neglected than a lot of other interventions in global health, reducing their counterfactual value.</li><li>Important interventions that could yield (relatively) high cost-effectiveness seem to be -<ul><li><strong>Installing an integrated disease surveillance and response (IDSR) system for monitoring meningitis, and&nbsp;</strong></li><li><strong>Advocating for the acceleration of the GBS vaccine development.</strong></li></ul></li></ul></li><li>Major uncertainties: The interventions are still \u2018moderately\u2019 promising; for ex. If someone is uniquely positioned to accelerate GBS vaccine trials/distribution, or complete broad educational initiatives about infant healthcare/precautions preventing neonatal transmission, this might on the margins be a promising thing to do. On another note, the counterfactual neglectedness is low primarily due to WHO\u2019s commitments in its \u201cRoadmap to defeating meningitis by 2030\u201d - if not followed up/held, the counterfactual value of another route to addressing meningitis could increase significantly.&nbsp;<br>&nbsp;</li></ul><h2>I. Importance</h2><p><u>Meningitis</u> is an inflammation (swelling) of the protective membranes covering the brain and spinal cord. It is commonly associated with infections e.g. bacterial meningitis, viral meningitis, but it can also have non-infectious causes. The most common symptoms include fever, headache, sensitivity to light and neck stiffness; in most cases, meningitis is treatable by addressing the underlying cause e.g. an infection<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3ocl283bu65\"><sup><a href=\"#fn3ocl283bu65\">[1]</a></sup></span>.</p><p>Meningitis, depending on the specific pathogen (virus, bacteria, fungi etc.) is often communicable and usually transmitted through close contact. Meningitis can also be passed on by mothers to their infants, and in fact, bacterial meningitis in infants is most commonly caused by the Group B Streptococcus pathogen (GBS), passed down in the peripartum period ( thebirthing process). Since meningitis attacks the membranes of the spinal cord and the brain, the most worrisome symptoms relate to the nervous system and include - hearing loss, seizures, brain damage etc. Bacterial meningitis can be especially fatal if untreated, with 1 in 10 patients&nbsp;<u>dying</u><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrq2098f4hka\"><sup><a href=\"#fnrq2098f4hka\">[2]</a></sup></span>. Even in the case of receiving treatment, meningitis can lead to&nbsp;<u>long-term&nbsp; sequelae</u><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefh1v8wuucs\"><sup><a href=\"#fnh1v8wuucs\">[3]</a></sup></span>, most often causing focal neurological deficits, cognitive impairment, hearing loss, multifaceted mental and emotional harm, and even death.<br>&nbsp;</p><p>Meningitis remains of great importance within the Global health sphere. It ranks 6th in the&nbsp;<u>list of diseases causing DALYs for children under the age of 10</u><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefk3qa7ey50f\"><sup><a href=\"#fnk3qa7ey50f\">[4]</a></sup></span>, as published in a systematic analysis in 2019. The mortality rate is heavily concentrated in ages 1-20, and both the incidence and mortality rates peak in the age group of 1-5, steadily declining after.&nbsp;<u>Recent trends</u>&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaqrzu2ityt\"><sup><a href=\"#fnaqrzu2ityt\">[5]</a></sup></span>have shown spikes in the incidence of meningitis from pre-pandemic levels, and frequent&nbsp;<u>outbreaks within gay or bisexual men</u>.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdyf82k6p7lo\"><sup><a href=\"#fndyf82k6p7lo\">[6]</a></sup></span>The UN in June of 2021 came up with the \u2018<u>Roadmap to defeat meningitis by 2030</u>\u2019<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0gznkmml29no\"><sup><a href=\"#fn0gznkmml29no\">[7]</a></sup></span>, which seeks to eradicate bacterial meningitis epidemics, reduce vaccine-preventable cases by 50% and deaths by 70%.&nbsp;</p><p><strong>Meningitis-related deaths in 2016 amounted to 318,400, which was a decrease of 21% from 1990. However, incidence in the same duration went up 12.8%, from 2.5 million to 2.82 million.&nbsp;</strong>In 2016, meningitis caused 1.48 YLDs, compared with 21\u00b787 million DALYs. As a result, it seems that most of the burden from meningitis comes from the deaths that it causes, rather than long-term disability<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefadgkx3r7fmr\"><sup><a href=\"#fnadgkx3r7fmr\">[8]</a></sup></span>.</p><p>Mortality and incidence are inversely related to&nbsp;SDI (Socio-demographic index<u>)</u>&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefeb338utot7u\"><sup><a href=\"#fneb338utot7u\">[9]</a></sup></span>. The highest mortality rates and incidence rates were found in the peri-Sahelian countries that comprise the African meningitis belt, with six of the ten countries with the largest number of cases and deaths being located within this region. The \u201cmeningitis belt\u201d in Africa includes parts of at least 26 nations, stretching from Senegal in the West to Ethiopia in the East.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefuupy9qqht6\"><sup><a href=\"#fnuupy9qqht6\">[10]</a></sup></span></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JgexokNweDkTbkynG/vgn0tart2r53mlkbhvk4\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JgexokNweDkTbkynG/f0mron9tyfvpv37tivfg 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JgexokNweDkTbkynG/dpmjn0dz6t5os73s2o1x 230w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JgexokNweDkTbkynG/qaqj3jyrne2famzovpde 310w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JgexokNweDkTbkynG/y0yt9hpkzg6chmk2msds 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JgexokNweDkTbkynG/pdpyb8nr3kohpdt89ktc 470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JgexokNweDkTbkynG/esn38n8ftdv9xqjgri9b 550w\"><figcaption>The 'Meningitis belt' - https://wwwnc.cdc.gov/travel/yellowbook/2020/travel-related-infectious-diseases/meningococcal-disease</figcaption></figure><p>&nbsp;</p><p>The primary interventions (further examined in this report) include the&nbsp;PsA-TT vaccine<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrysk0q76j3\"><sup><a href=\"#fnrysk0q76j3\">[11]</a></sup></span>, which was developed to combat Neisseria meningitis (MenA) epidemics in Africa, the&nbsp;<u>MenACWY</u>&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbmm884q4x06\"><sup><a href=\"#fnbmm884q4x06\">[12]</a></sup></span>&nbsp;vaccine which counters the A, C, W, and Y strands of bacterial meningitis, and improvements to the surveillance and response systems to cases of meningitis. Other promising interventions (not examined due to lack of credible data) include raising awareness and running educational initiatives about meningitis (and broadly meningococcal disease) (done by orgs like&nbsp;<a href=\"https://nmaus.org/about-us/\"><u>National Meningitis Association</u></a>), increasing uptake of a pneumococcal vaccine during pregnancy<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefku6vdfq0pzp\"><sup><a href=\"#fnku6vdfq0pzp\">[13]</a></sup></span>, and creating administrative policies in schools for meningitis prevention.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefizt2fm8zlfo\"><sup><a href=\"#fnizt2fm8zlfo\">[14]</a></sup></span><br>&nbsp;</p><p>This report restricts its findings to bacterial meningitis because -</p><ol><li>Viral meningitis is fairly common and usually resolves within a week or two. It rarely causes a critical condition and/or needs medication.&nbsp;</li><li>Just 4 bacteria are responsible for more than 50% of death caused by all-cause meningitis - meningococcus, pneumococcus, Haemophilus influenzae and group B streptococcus - all of which are vaccine-preventable except the GBS, for which a vaccine is currently in development.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqufyohp77e\"><sup><a href=\"#fnqufyohp77e\">[15]</a></sup></span></li><li>Most credible research available on interventions such as vaccine rounds, effectiveness, burden etc. is heavily centred on bacterial meningitis, with no recent and credible evidence for the global burden on other-cause meningitis and their interventions (such as. fungal meningitis).</li></ol><h2>II. Neglectedness:&nbsp;</h2><p>Bacterial meningitis has recently gotten the spotlight in both academic and policy discourse - in 2018, a set of health economists and doctors in the UK completed a&nbsp;cohesive economic analysis&nbsp;of existing vaccines with policy recommendations<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsm1mj6kyytm\"><sup><a href=\"#fnsm1mj6kyytm\">[16]</a></sup></span>, and organisations like GAVI and NMAUS are actively working in the meningitis belt to deliver interventions cost-effectively and educate families on prevention techniques. Perhaps most importantly, a meeting in May 2017 of more than 50 global experts, led by the Meningitis Research Foundation in collaboration with WHO, resulted in a global roadmap to defeat meningitis by 2030\u2014a plan that required broad global commitments to strengthen systems for prevention, treatment, and surveillance.&nbsp;</p><p>However, there is a wide scope for research into meningitis that could help shape the future of the field, with some warranting immediate concern.</p><ol><li>There have been no RCTs or cohort studies conducted on empirical therapy for treating meningitis. Interventions like antibiotics, therapy, and or aftercare remain unexamined for efficacy and/or cost-effectiveness.</li><li>Risk factors for bacterial meningitis and meningococcal disease outbreaks aren\u2019t fully understood, making prediction of epidemics unlikely<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefutaafcry8sc\"><sup><a href=\"#fnutaafcry8sc\">[17]</a></sup></span>. The WHO also mentions \u201cincreasing lab capacity and infrastructure to detect potential epidemic pathogens\u201d as a priority in its report. The most recent outbreak in Florida (2021-2023), primarily affecting gay and bisexual men, was caused by a&nbsp;<a href=\"https://www.cdc.gov/meningococcal/outbreaks/FL2022.html\"><u>vaccine-preventable strand</u></a> of meningitis.&nbsp;</li><li>Vaccination strategies for specific strains and countries in order to achieve herd immunity have not been developed, leading to no clear health policy directions that can be taken up by affected nations.&nbsp;</li><li>The most common cause of fatal bacterial meningitis in infants is Group B Streptococcus - a bacteria for which a vaccine still hasn\u2019t been developed. Given the highest mortality lies in the 1-5 years age group, this seems to be a highly neglected area.&nbsp;</li></ol><p><br>Answers in these key uncertainties could significantly update the immediate promise in Bacterial meningitis as a cause area. Research in the field seems necessary, but recent trends in the burden of bacterial meningitis clearly show that the cause area isn\u2019t neglected by academics, policy-makers, or on-ground institutions (such as non-profits). The next section shows how, except for i) the development of an active surveillance program, and ii) expediting the development of the GBS vaccine, none of the research gaps seem to warrant urgency when compared to other neglected issues in global health.</p><h2>III. Tractability (Possible interventions and their theories of change)</h2><p>There are many different approaches and interventions to reduce the burden of meningitis; the table below summarizes the main interventions that were investigated in this report, which&nbsp;<i>a priori</i> seemed the likeliest to be cost effective and promising. The cost-effective analyses are attached at the end of the report.</p><p><i>For an easier read, the following table is also colour-coded and pasted on the sheet with cost-effectiveness analyses, attached at the end of the post.</i></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Intervention</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Outputs</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Outcomes</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Quality of evidence</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Approximate Cost-effectiveness</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Overall promise</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Improving surveillance and response systems</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Build the medical and healthcare infrastructure to closely monitor and immediately respond to meningitis</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Improve data collection and response system&nbsp;</td><td style=\"background-color:#fce5cd;border:1pt solid #000000;padding:5pt;vertical-align:top\">Moderate; several studies show the infrastructure building to be cheap, + expert opinion (mentioned as a key intervention by academics and WHO)</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">Unclear with current evidence; possibly high -&nbsp; there\u2019s some data for meningitis specifically, but other comparable bacterial diseases show such surveillance systems to be cost-effective*</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">Between moderate and high, leaning high; also mitigates the neglected fields of epidemic forecasting/controlling. Builds robust infrastructure for the future</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Accelerate development of GBS vaccine via policy advocacy</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Early production/distribution of an approved vaccine against GBS.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Reduction of GBS cases/stillbirths + Improved maternal/neonatal healthcare, + potentially earlier herd immunity against GBS.</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low; the evidence of policy advocacy is pretty non-transitive (a success story in another disease would not necessarily mean success in this one). The guiding force here is expert opinion (1Day Sooner).&nbsp;<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8776310/\"><u>This study</u></a> also shows that the awareness of GBS as a public health concern is lowest amongst health policy makers.&nbsp;</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">Between moderate and high; (possibly very high) although completely dependent on the cost (which is unknown and subjective to campaign), studies on a 60% efficacious vaccine show cost-effectiveness between $676-$2390 per DALY, although these can be considered lower bounds**.</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">Between moderate and high; awareness amongst policymakers seems low, and organizations like 1DS or GAVI or NMA seem uniquely placed to advocate for trials/funding of the GBS vaccine at a very small cost, and the incidence of the disease is large enough that acceleration of even a year or two is highly valuable.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Distribute the existing MenACWY vaccine</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Protection against strands A, C, W, and Y of the meningococcal bacteria.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Achieving herd immunity against popular strands of bacterial meningitis, possibly avert epidemics</td><td style=\"background-color:#fce5cd;border:1pt solid #000000;padding:5pt;vertical-align:top\">Moderate; (efficacy is well documented, but costs are estimated using just 2 studies from 2 countries with sample size &lt;30)</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">$43.44/DALY saved (this is probably a upper bound, the conjugate nature of the vaccine may lead to herd immunity quicker)</td><td style=\"background-color:#fce5cd;border:1pt solid #000000;padding:5pt;vertical-align:top\">Moderate; (each strand has decreased in burden (and therefore importance) in the past decade)</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Distribute the existing PSa-TT vaccine</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Protection against the serogroup A meningococcal bacteria.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Achieving herd immunity against popular strands of bacterial meningitis, possibly avert epidemics</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">High; (efficacy studies seem well-conducted, and costs are derived using GAVI\u2019s 15 year progress)</td><td style=\"background-color:#fce5cd;border:1pt solid #000000;padding:5pt;vertical-align:top\">$206.99/DALY saved (accounts for DALYs caused by serogroup A only, vaccine may as well have overlapping benefits against other strands)</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low; serogroup A isn\u2019t as neglected anymore, the vaccine is arguably cost-ineffective at the margin compared to other interventions</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Accelerate development of GBS vaccine by funding clinical trials*</p><p><br><br><br>&nbsp;</p><p>*based on very rough estimates, not at par with the credibility of other estimates in this table - caveat elaborated in the next section</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Early production/distribution of an approved vaccine against GBS.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Reduction of GBS cases/stillbirths + Improved maternal/neonatal healthcare, + potentially earlier herd immunity against GBS.</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low; found just&nbsp;<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4530403/\"><u>one study</u></a> that said clinical trials are a challenge impeding the GBS vaccine development.No GBS-specific data found, Success probability and Costs are estimated from studies concerning other bacterial diseases.</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Between low and moderate; erring low. There are no studies that explicitly state/estimate how new trials would lead to significantly better results/acceleration of vaccine development.</td><td style=\"background-color:#fff2cc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Between low and moderate; Although tractability seems high, given WHO\u2019s recent emphasis on GBS, trials don\u2019t seem counterfactually neglected. It is also hard to gauge the importance without studies estimating how new trials would directly accelerate vaccine development.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Education initiatives about meningitis transmission and good practices</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Educate families about meningitis prevention techniques</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increased prevention, regulation, and treatment of meningitis cases.</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low - expert opinion (mentioned in the WHO document and some government recommendations) + working of organizations like the NMAUS</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Unclear; all significant benefits are secondary and there are no cohort studies to examine long-term changes in health/income etc. No RCTs/cohort-studies found that estimate the burden of meningitis education directly averts.</td><td style=\"background-color:#fce5cd;border:1pt solid #000000;padding:5pt;vertical-align:top\">Between low and moderate; most secondary benefits (increased income, increased school attendance etc.) have other interventions that directly affect them - so the promise doesn\u2019t seem incredibly high solely on second-order benefits.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Distribute existing Antibiotics</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Protect against bacterial pathogens of meningitis</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Treating patients with meningitis effectively</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low - there seems to be no standard prescription of antibiotics that apply to a set of bacteria - the exact meds (and hence costs) seem dependent on the strand, duration, age etc. of the patient. No clear standard dose, and no study conducted on efficacy.&nbsp;</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Unclear; probably comparable to vaccines, or likely even less cost effective since delivery isn\u2019t publicly financed, and there is a possibility of patients not finishing their doses with time. Also comes with a significant diagnosing cost - since antibiotic courses have to be specific to patient (pathogen, other health conditions etc.)</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low to moderate, leaning low.</td></tr></tbody></table></figure><p>&nbsp;</p><p>&nbsp;</p><h3><br>Interventions I found but didn\u2019t dive deeper in:</h3><ol><li>Funding clinical trials for the GBS vaccine - although the report includes a cost-effectiveness analysis for this intervention, there is inadequate data on the specifics of the GBS vaccine - major uncertainties in possible efficacy of the vaccine, doses required for immunization, room for funding amongst vaccine developers, the projected expedition caused by additional funding etc. render this analysis superficial. Any novel information on any of the aforementioned factors could be vital in cost-effectiveness.</li><li>Pneumococcal vaccination during pregnancy - the evidence for this was medium with one cohort study conducted - the cost effectiveness was unclear since even if costs were assumed to be about the same as other vaccinations, the benefits were unclear as the tests found differing results in terms of effectiveness. The overall DALY burden of neonatal meningitis is centred in GBS, for which a vaccine is currently in the works - which demonstrably should be much more effective.&nbsp;</li><li>Research on key areas - as shown in the \u2018Neglectedness\u2019 section, there are multiple research gaps within the field that would prove valuable if found answers for. But since promisingness depends on the researchers who take these questions up (their counterfactual value etc.), and since there is no way to estimate the costs/benefits directly, I didn\u2019t dig deeper.&nbsp;</li><li>Research on school administrative policies on meningitis prevention - this intervention is based off just one&nbsp;study conducted in Southern Nigeria<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref63hz14px7nx\"><sup><a href=\"#fn63hz14px7nx\">[18]</a></sup></span>&nbsp;but since the burden is heaviest in the schoolgoing age category, research into prevention policies can be super valuable. The intervention also seems costless, except the time it would take schools to formulate, communicate and regulate these policies. This one is moderately promising as it targets the right population.</li></ol><h3><br>Caveats and Notes on promising interventions</h3><p>I. &nbsp;Integrated Disease Surveillance and Response (IDSR) and its cost-effectiveness:</p><ol><li>Probably much more cost-effective than it seems due to overlapping benefits of IDSR for all other diseases and preventing further epidemics. Given the per capita cost of establishing the system is $0.07, and the system may have overlapping benefits for all diseases, the intervention seems very cost-effective. Such surveillance systems may have a strong use case for antimicrobial resistance and novel pathogen detection (especially those with pandemic potential).</li><li>Although the study indicates presence in Burkina Faso, Eritrea, and Mali, it is unclear if such a system is robust in these countries, and whether it is available in other countries in the Meningitis Belt - but it remains a topic of consideration in the WHO report of defeating meningitis, so it is assumed that this space is fairly neglected.&nbsp;</li><li>It is unclear what the \u2018improved completeness of surveillance\u2019 means - therefore the analysis just provides 2 conservative estimates of 1 and 5 percent improved DALYs saved per case - by means of reaching patients quicker, preventing epidemics, improved aftercare, preventing sequelae etc. Even by these conservative numbers, the benefits seem cost effective.</li><li>The neglectedness of the IDSR is pretty unknown. The study is based on 3 countries within the meningitis belt - Burkina Faso, Eritrea, and Mali - which gives accurate estimates of the costs, but also shows that the IDSR is already present and operational in some countries that this report seeks to target. However, the WHO has still listed the creation of an active surveillance system (albeit not specifically an IDSR) as one of its 5 \u2018pillars\u2019 in its \u201cDefeating Meningitis by 2030: A global road map\u201d report.</li><li>The specific costs of the IDSR are based on just one study, and it is noteworthy that the study doesn\u2019t provide a detailed breakdown of the utility of such an IDSR (i.e, it is possible that the IDSR studied was for a specific disease, was&nbsp;</li></ol><p>II. Policy advocacy for the Group B Streptococcus vaccine:&nbsp;</p><ol><li>The studies cited assume a mean cost range between $10 - $30 - however, traditional costs for comparable vaccines (such as the Psa-TT shown in the CEA sheet) can be as low as $3.49 including delivery costs; given the vaccine is manufactured and delivered at scale. This drives up the possible cost effectiveness.</li><li>The productivity losses would arguably be much lower for pregnant women or infants (perhaps a very slightly longer recovery period etc.) but the indirect costs seem significantly lesser for the GBS vaccine when compared to the MenACWY or Psa-TT, further driving up its cost-effectiveness.</li><li>The costs of advocacy and the probability of success are intertwined. Paradoxically, spending more on the advocacy might have an exponentially larger impact on influencing policy than a poorly funded one; and so i) lesser costs do not necessarily make the intervention more cost-effective, and ii) the cost-effectiveness heavily hinges on the relationship between costs and the probability of success.&nbsp;</li><li>The cost-effectiveness also heavily hinges on the efficacy of the vaccine itself. The study from South Africa assumes 60% efficacy, swinging cost-effectiveness between the $676 to $2390 range, while the above reasons are enough to believe that the Cost-effectiveness might be much higher.</li><li>The average delivery costs are taken from a study that measured the costs during the Covid-19 pandemic - so the data is i) recent and ii) relevant to the rolling out a new vaccine (just like the GBS vaccine would be). However, an important caveat is that the indirect costs are completely unknown. In the case of Covid-19, the indirect costs were low (for ex. the side-effects of the vaccine didn\u2019t warrant extended leaves from work), but the PsA-TT vaccine had an average of 21 days of recovery period (thereby large indirect/opportunity costs). As such, the indirect costs of the GBS vaccine are unknown, and could weigh heavily on the cost-effectiveness calculations.</li><li>The model also runs on the assumption that the GBS vaccine would only require a single dosage of the vaccine - this could easily be a false assumption. Multiple doses would have subsequent impact on indirect costs incurred, delivery strategies, costs, and vaccine efficacy if dosage is incomplete - all of which drive down cost-effectiveness.</li></ol><h2>Conclusion:&nbsp;</h2><p>Overall, this report finds that Bacterial Meningitis has some promising avenues of investment in the forms of GBS vaccines (via the advocacy route, but also potentially by funding clinical trials). However, it seems like a battle more than half won. Interventions dealing with most other strains of bacterial meningitis are not nearly as cost-effective, and the burden for these has been steadily declining.&nbsp;<strong>The cost-effectiveness and spillover benefits of installing an IDSR system seem to make it a compelling competitor against some of the most cost-effective interventions in Global health.</strong> From a broad view, important agents like GAVI, Pfizer and the WHO are actively involved in tackling Bacterial Meningitis, which makes it less likely that they are neglected enough for the Effective altruism community to look deeper into.&nbsp;</p><p>It is noteworthy that there are a lot of research bottlenecks that might further inform this conclusion.&nbsp;<strong>The most obviously urgent research field remains the Group B Streptococcus vaccine,</strong> but other fields remain germane, such as i) understanding patterns of pathogens causing meningitis epidemics, ii) conducting randomised evaluations of the effects of therapy, aftercare, and antiobiotics, iii) creating improved surveillance systems that help coordinate health policy across the Meningitis belt, and iv) researching into specific age-based interventions (prenatal vaccination, school administrative policies). Answers from all these questions can significantly update the promise of bacterial meningitis as a cause area.&nbsp;<br>&nbsp;</p><p>Cost-effectiveness analyses here:&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1TTJEQGk52wof8WaCqaPXEC5koQ3Q2L_GkNLFk8QRFj0/edit?usp=sharing\"><u>CEA - Bacterial Meningitis</u></a></p><p><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3ocl283bu65\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3ocl283bu65\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.cdc.gov/meningitis/bacterial.html\">https://www.cdc.gov/meningitis/bacterial.html</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrq2098f4hka\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrq2098f4hka\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.cdc.gov/meningococcal/about/causes-transmission.html#:~:text=People%20spread%20meningococcal%20bacteria%20to,common%20cold%20or%20the%20flu.\">https://www.cdc.gov/meningococcal/about/causes-transmission.html#:~:text=People%20spread%20meningococcal%20bacteria%20to,common%20cold%20or%20the%20flu.</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnh1v8wuucs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefh1v8wuucs\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://pubmed.ncbi.nlm.nih.gov/27105658/#:~:text=following%20bacterial%20meningitis.-,Most%20frequently%20reported%20sequelae%20are%20focal%20neurological%20deficits,loss%2C%20cognitive%20impairment%20and%20epilepsy.\">https://pubmed.ncbi.nlm.nih.gov/27105658/#:~:text=following%20bacterial%20meningitis.-,Most%20frequently%20reported%20sequelae%20are%20focal%20neurological%20deficits,loss%2C%20cognitive%20impairment%20and%20epilepsy.</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnk3qa7ey50f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefk3qa7ey50f\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://pubmed.ncbi.nlm.nih.gov/33069326/#:~:text=Six%20infectious%20diseases%20were%20among,this%20age%20group%2C%20is%20fully\">https://pubmed.ncbi.nlm.nih.gov/33069326/#:~:text=Six%20infectious%20diseases%20were%20among,this%20age%20group%2C%20is%20fully</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaqrzu2ityt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaqrzu2ityt\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.gov.uk/government/news/recent-increase-in-group-b-meningococcal-disease-among-teenagers-and-young-adults#:~:text=As%20restrictions%20lifted%20data%20shows,and%20mainly%20due%20to%20MenB%20.\">https://www.gov.uk/government/news/recent-increase-in-group-b-meningococcal-disease-among-teenagers-and-young-adults#:~:text=As%20restrictions%20lifted%20data%20shows,and%20mainly%20due%20to%20MenB%20.</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndyf82k6p7lo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdyf82k6p7lo\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.cdc.gov/media/releases/2022/p0622-Meningococcal-Outbreak.html\">https://www.cdc.gov/media/releases/2022/p0622-Meningococcal-Outbreak.html</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0gznkmml29no\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0gznkmml29no\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.who.int/publications/i/item/9789240026407\">https://www.who.int/publications/i/item/9789240026407</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnadgkx3r7fmr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefadgkx3r7fmr\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://pubmed.ncbi.nlm.nih.gov/30507391/\">https://pubmed.ncbi.nlm.nih.gov/30507391/</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fneb338utot7u\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefeb338utot7u\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://pubmed.ncbi.nlm.nih.gov/30507391/\">https://pubmed.ncbi.nlm.nih.gov/30507391/</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnuupy9qqht6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefuupy9qqht6\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://africacdc.org/disease/meningococcal-meningitis/#:~:text=Meningococcal%20meningitis%20is%20observed%20worldwide,each%20year%20from%20that%20area.\">https://africacdc.org/disease/meningococcal-meningitis/#:~:text=Meningococcal%20meningitis%20is%20observed%20worldwide,each%20year%20from%20that%20area.</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrysk0q76j3\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrysk0q76j3\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://pubmed.ncbi.nlm.nih.gov/25636915/#:~:text=Background%3A%20A%20new%20serogroup%20A,(MenA)%20epidemics%20in%20Africa.\">https://pubmed.ncbi.nlm.nih.gov/25636915/#:~:text=Background%3A%20A%20new%20serogroup%20A,(MenA)%20epidemics%20in%20Africa.</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbmm884q4x06\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbmm884q4x06\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://pubmed.ncbi.nlm.nih.gov/25636915/#:~:text=Background%3A%20A%20new%20serogroup%20A,(MenA)%20epidemics%20in%20Africa.\">https://pubmed.ncbi.nlm.nih.gov/25636915/#:~:text=Background%3A%20A%20new%20serogroup%20A,(MenA)%20epidemics%20in%20Africa.</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnku6vdfq0pzp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefku6vdfq0pzp\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD004903.pub4/full?highlightAbstract=meningitis%7Cmening\">https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD004903.pub4/full?highlightAbstract=meningitis%7Cmening</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnizt2fm8zlfo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefizt2fm8zlfo\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6259382/\">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6259382/</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqufyohp77e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqufyohp77e\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.who.int/news-room/fact-sheets/detail/meningitis\">https://www.who.int/news-room/fact-sheets/detail/meningitis</a></p><p>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsm1mj6kyytm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsm1mj6kyytm\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7072054/\">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7072054/</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnutaafcry8sc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefutaafcry8sc\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.cdc.gov/meningococcal/global.html\">https://www.cdc.gov/meningococcal/global.html</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn63hz14px7nx\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref63hz14px7nx\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6259382/\">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6259382/</a></p></div></li></ol>", "user": {"username": "peetyxk"}}, {"_id": "iKbdvrdFRSsPwNkh7", "title": "Some of My Current Impressions Entering AI Safety", "postedAt": "2023-03-28T05:18:04.550Z", "htmlBody": "<h3>Hello,</h3><p><br>I have been engaged with EA for about 4 years, university then ops. I am now trying to contribute to AGI Alignment non-technically, and learning about it to be the best support.</p><p>I am in that phase of emotionally confronting the seemingly likely drastic changes of the next few decades (should I even save for retirement?), so please excuse the existential crisis peeking out from behind this post.</p><h3><br>Quick Sanity Check:</h3><p>AI is powerful (AI is &gt;human in narrow applications)</p><p>AI is becoming more powerful generally, exponentially (this may not continue)</p><p>AI will likely become more powerful than humans.</p><ul><li>It will likely become capable of improving itself.</li><li>Humans are trying to improve AI (economic incentives are crazy), and AI that improves itself would be huge.</li></ul><p>This is potentially disastrous to humans.</p><h3><br>Current Considerations:</h3><p>I'm kinda hedging my future here on 'this <strong>may</strong> not continue [at current rate, maybe it's actually pretty hard to get the G in AGI]' and current alignment plans (strongarm by big companies, eventual strongarm by global powers) working out. Or maybe the superintelligent AGI is more chill than we expect.</p><p>I'm unsure what I am doing with this post, I think I want to comment on my own anxieties, thoughts, and aspirations (trying to think with a growth mindset here, c'mon). And I also think, strong personal bias from my perspective, that more and more of the EA space is converging toward AI Safety as AI converges toward AGI, and this makes sense (go figure).</p><p>Couple of things I'm considering here:</p><ol><li>Aligned AGI could be the most incredible tool for human wellbeing! Heck yeah, a superintelligence that eliminates suffering but, like, in a really cool aligned way (seems like the most defining feature of \"the long reflection\" isn't a lack of existential risk, but rather this superintelligence assisting us).</li><li>Aligned AGI seems like a really good solution to existential risks. I have an image in my head of a hand reaching from above to pluck the toy warhead out of the infant's rapidly descending arm.</li></ol><p>I can appreciate why someone would want to accelerate AGI considering the (to my mind near infinite in line with its capabilities) upsides to it working out really well. It seems like it'll be really competent at working out the 'best way of providing best results', rendering quite a bit of our hundred-year(+) plans obsolete. In fact, in an ideal (aligned and good) situation, we might be accelerating capabilities as the best means to solve quite a bit of societal problems, if not all (sorry to make light, coping, but x-risks seem to be competing these days).</p><p>I have quite a bit of uncertainty about all of the above and this was written in a couple of hours to be posted, but genuinely this is affecting (sometimes terrifying) me quite a bit (I was like 50% serious about the saving for retirement thing, considering both positive and negative outcomes). I have further views (of course) on the field but nothing I really want to share right now.</p><h3><br>More on me:</h3><p>I am thinking about how to best contribute to this space as a non-technical person, with concrete paths available in my current role to perform optimal ops, write/communicate about these ideas, and just channel more resources and talent at the problem (and be smart about it).</p><p>I think my exponential model is informed by 3 points in time, TalktoTransformer in a College class (oh neat), ChatGPT (woah), and GPT-4. Oh and also <a href=\"https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/\">Metaculus</a>/peeps and a belief that LLMs, specifically language as a key to general intelligence, are outperforming expectations in learning and capabilities.</p><p>(BTW I was notorious for throwing wooden blocks as an infant).</p><p>Thanks for reading and potentially steelmanning.</p>", "user": {"username": "Phib"}}, {"_id": "ywucgPYADL8A5GZCb", "title": "Recruiters & \"Non-credentialed\" job seekers: Stellarworx is a non-EA database of skilled US job seekers without traditional degrees", "postedAt": "2023-03-28T01:53:13.340Z", "htmlBody": "<p><strong>TL;DR </strong><a href=\"https://stellarworx.org\"><strong>Stellarworx</strong></a><strong> is a new-ish, non-EA database of skilled US job seekers without traditional degrees. Why not try it out?!&nbsp;</strong></p><p><i>(Note: I am not affiliated with this organization. It's early stage. I'm not vouching for it being stellar already; it seems like a very good idea, so I'm hoping it will be! I want EAs to know it exists and consider participating).&nbsp;</i></p><p><strong>Opportunities@Work</strong> is a US non-profit working to help people overcome credentialist barriers to employment. They estimate that the US labor force includes 70M underemployed people who are Skilled Through Alternative Routes (STARs) --community college, on the job training, partial college, self-teaching, etc. STAR candidates are disproportionately underemployed, rural, veterans, and/or people of color. &nbsp;They opt in to a talent matching database called Stellarworx: <a href=\"https://stellarworx.org\"><strong>https://stellarworx.org</strong></a></p><p>The database allows employers to search for specific skills among candidates, list open positions or grants, and be matched with candidates via a matching algorithm.</p><p><br><i>Employers &amp; Grantmakers</i></p><p>If you'd like, take a moment to bookmark this site: <a href=\"https://stellarworx.org\"><strong>https://stellarworx.org</strong></a><strong>.&nbsp;</strong></p><p>Maybe add it to your list of databases where you post open roles, or check if any of your current openings might be a good fit for the database. It's likely best for roles that don't require pre-existing EA knowledge and/or when you are seeking candidates from demographics that are underrepresented in your current hiring pool.&nbsp;</p><p>Recruiters I talk with often acknowledge that university credentials are a useful proxy for employability, but degrees are not the only path that skilled, altruistic people take into the workplace. Recruiters would prefer to be able to easily identify strong candidates who have not gone to university, but that is harder to do. While a lot of EA projects are looking for people familiar with EA, not all positions require EA knowledge.&nbsp;</p><p>Consider becoming a Skillworx member and posting jobs there as a low-cost way to support values that you may want to see more of in the hiring marketplace.&nbsp;</p><p>If you love the idea, you might also consider nudging someone to create a database like this or a sub-category for this kind of talent pool within EA hiring databases.&nbsp;</p><p>&nbsp;</p><p><i>Job seekers</i></p><p>If you're a Forum reader without traditional credentials, try listing yourself in this database where recruiters are looking for people like you! You may get connected with recruiters who are familiar with resumes like yours. You may also get advice and valuable warm fuzzies from being part of a network that tailors resources to your unique needs as a job seeker. Moral support from people who face similar challenges can be very useful during the trudge of a job hunt and need not come solely from EA sources!&nbsp;</p><p>I don't know how many jobs of interest are likely to come from this newish database, but if this tool could help you, I hope you'll seriously consider it, even if it doesn't have EA job listings. If you apply for or take a job from the database and do well, you'll help the reputation this type of project, which I expect has a mission you feel good about.&nbsp;</p><p>I happen to think EAs working at non-EA orgs is often quite good for the person and for the EA ecosystem. If you're a non-traditional hire, you may prefer taking fewer risks with your career than most EA advice advises. Being fully employed rather than underemployed is certainly quite good for most people's well-being, family, future financial health, and future donation or career contributions. If you value creating connections between non-EA professional networks and EA professional networks (I do), you may also find opportunities to do that.</p><p>&nbsp;</p><p>If anyone acts on this post, I'd be interested to hear what came of it!&nbsp;</p>", "user": {"username": "A_lark"}}, {"_id": "bL3riEPKqZKjdHmFg", "title": "When Will We Spend Enough to Train Transformative AI", "postedAt": "2023-03-28T00:41:54.056Z", "htmlBody": "<p>The world has experienced exponential growth in the power of deep learning systems over the past 10 years. Since AlexNet in 2012, there has been continuous rapid growth. However, it is worth decomposing the causes for that growth in order to predict the power of future systems.</p><p>The simplest decomposition of the cause of growth may look like this:</p><ol><li>Algorithms</li><li>Compute</li></ol><p>The growth of both compute and the quality of algorithms has been game-changing over the past 10 years, but there has been a shift from most of the gains coming from the quality of algorithms to a focus on computational power (compute) since 2018. This coincides with the introduction of transformers, which have become the dominant paradigm for cutting-edge models since they were introduced. The growth in compute has caused huge performance gains in the past 6 years, but the growth in computational power will soon also slow substantially. The current increase in yearly spending is unsustainable, even in the short term.</p><h2>Why has the speed of algorithm improvements slowed?</h2><p>Initially, there were many low-hanging fruit improvements in deep learning. Just as in any new scientific discipline, research was able to rapidly advance simply by dedicating more people to the problem. Some advances that had a massive improvement include:</p><ol><li>Different activation functions, such as using ReLU instead of sigmoids, then using GeLU.</li><li>Improvements in optimizers, such as gradient descent with momentum, then Adam, then AdamW.</li><li>ResNet-50 and the idea of residual layers.</li><li>The transformer architecture.</li></ol><p>Each of these caused a large increase in the performance of models. But iterative steps after an advance were refinement, much less important than the initial discovery. Going from simple gradient descent to Adam was a big deal, as was going from Sigmoid to GeLU. But many of these advances were before 2018 and as more of the easy problems got solved, the pace of improvement slowed.</p><p>This is not unique to deep learning. Slowing advancement is seen across human society. From the 1950s on, the number of researchers greatly increased, but the speed of innovation has not.</p><ul><li>A very important and recurring theme in human society is that exponentials do not last forever, and when they stop is very important.</li></ul><p>When we look at some of the critical cutting-edge improvements in deep learning, we run into a trend. A lot of the main algorithmic advances that we are iterating on today occurred pre-2018.</p><h3>AI improving itself</h3><p>That is not to say there aren\u2019t important and potentially revolutionary changes to come, but rather that they will be fewer and farther between. There is also the potential for AI to increase the pace of discovery. We are starting to see early signs of this with Lion, a new optimizer from Google that may outperform AdamW. This algorithm was created with the help of AI systems. [<a href=\"https://github.com/google/automl/tree/master/lion\">1</a>]</p><p>AI is advancing science in a number of fields, such as protein folding for biology. And it does seem like AI companies would have the greatest know-how and incentive with which to implement AI assistants and improve their rate of innovation. But this is an open question right now, and it is not safe to assume that AI will drastically speed up deep learning innovation in the near future.</p><h2>Growth in compute</h2><p>Pre-2018, researchers could rely mostly on more efficient algorithms to improve performance, with relatively small increases in computational power. If you look at the scale of modern AI systems, we can see that something has changed. To dive deeper into this change in computational power, compute is decomposed into:</p><ol><li>The cost/efficiency of hardware</li><li>How much are companies willing to spend on hardware</li></ol><h3>Why has the improvement in cost and efficiency Slowed?</h3><p>Hardware availability and price is big reason deep learning started becoming performant. Consumer graphics cards first became a common product in the mid to late 90s. Deep learning relied heavily on chips that were designed to accelerate 3d graphics. These chips were optimized for linear algebra calculations, and linear algebra calculations are the basis of deep learning. Speed is crucial for deep learning, so it is hard to see a world where deep learning succeeded without 3d accelerated consumer GPUs.</p><p>Huang's law [<a href=\"https://en.wikipedia.org/wiki/Huang's_law\">2</a>] states that since GPUs were introduced, they have improved in performance much faster than the equivalent CPUs. Perhaps this is because engineers were capturing low-hanging fruit, or because the architecture is more able to scale. But either way, low-cost deep learning relied on the greater than Moore\u2019s law improvement in GPU cost/efficiency.</p><p>In 2023, it is not clear that trend will continue. Nvidia\u2019s latest consumer graphics cards, the RTX 30-series, and RTX 40-series are both huge improvements from their predecessors, but they also use much more power. They are also more expensive than their predecessors. This indicates that the efficiency gains are at the very least slowing. Nvidia has even explicitly told its customers to expect slower gains. This mirrors the rest of the chip industry, where performance gains are becoming harder to find. It simply becomes much more difficult to make transistors smaller when you reach 2023\u2019s transistor size.</p><p>On the other hand, there is more demand than ever for enterprise/data center GPU systems. This could lead to some economies of scale and corresponding cost decreases. However, there is already a large and developed market, so the cost decreases from this effect are unlikely to be revolutionary.</p><ul><li>The big unknown for cost/efficiency is whether alternative chip designs, such as analog chips or photon-based processing, pan out. The evidence is not conclusive either way. There will certainly be a financial incentive to develop these technologies as spending on chips increases.</li></ul><h3>How much are we willing to spend? - Estimating the cost of training</h3><p>If we cannot rely on the same rate of exponential algorithmic improvements or exponential efficiency improvements, can companies buy their way into faster growth?</p><p>Companies certainly have over the past 5 years. It is hard to get an exact estimate on how much it costs to train different models, but estimates put the cost of training GPT-2 in 2019 around $20k-$100k. Training GPT-3 in 2020 cost $2m-$10m. And based on the recently released GPT-4 technical report, training took somewhere between 100x and 10000x the compute of GPT-3. [<a href=\"https://arxiv.org/pdf/2303.08774.pdf\">3</a>] Assuming half the cost per unit of compute for GPT-4 vs GPT-3, that puts estimates of the cost of training in the $100m-$1b+ range.</p><p>Based on talking to experts in the field, it seems that $100m+ is a good estimate of the cost to train the largest models in 2023.</p><p>A different way to estimate the cost of training would be to look at the cost of GPUs plus the power to run them. Buying this from a cloud provider would cost many times as much, but the estimate below gives a lower bound.</p><p>Facebook released all the details on training Llama, a fairly high-performance LLM [<a href=\"https://arxiv.org/pdf/2302.13971.pdf\">4</a>]:</p><blockquote><p>We estimate that we used 2048 A100-80GB for a period of approximately 5 months to develop our models. This means that developing these models would have cost around 2,638 MWh.</p></blockquote><blockquote><p>When training a 65B-parameter model, our code processes around 380 tokens/sec/GPU on 2048 A100 GPU with 80GB of RAM. This means that training over our dataset containing 1.4T tokens takes approximately 21 days.</p></blockquote><p>An Nvidia A100 GPU with 80GB of RAM costs $15k. One rough estimate is that it depreciates at 25% a year (likely a low estimate). Roughly 400 MWhs were used to train the 65B-parameter model.</p><p>2048 GPUs*$15,000/GPU = $30,700,000 * (21 day/365 days/year) * 0.25 depreciation/year = $450,000 depreciation cost</p><p>Nationwide average cost of electricity is 16.8 cents per kWh</p><p>$0.168/KWh*400,000KWh=$67,000 electricity cost</p><p>Multiply compute required by 100-1000x to get the lower bound for GPT-4, and you get $50m-$500m+</p><p>&nbsp;</p><p>To put this quantity into perspective, the 3 most profitable companies in the world are Aramco, Apple, and Microsoft. Apple had the highest profits of any tech company, reporting a net income of 99.8 billion U.S. dollars in the fiscal year 2022. [<a href=\"https://www.statista.com/statistics/267728/apples-net-income-since-2005/\">5</a>] Their profit has been steadily increasing, but assuming it is constant, that means if they spent all their profits, they could use 100x-1000x the compute as was used to train GPT-4.</p><p>Apple is not going to spend 100% of its profits training AI models, which means as of now, no company can spend $100b to train AI models. Unless companies pool their resources, that sets a hard cap at spending around $100b per model. Most companies will want to train multiple models and iterate. Since a company will not want to spend that much on just one model, a more realistic cap is $10b-$20b (though it seems that models are becoming more general, so there is an increasing chance that one model may be all you need).</p><ul><li>This means that in the next few years, we can expect an AI training run spending 20x-1000x GPT-4 on compute. After that things will increase much more slowly.</li></ul><h3>Why 1000x GPT-4 is not enough</h3><p>The recent increase in compute has resulted in drastically more capable and competent AI systems. However, it is important to look at self-driving cars and other software systems as a reference case. It is not enough to be good at just some tests, systems have to function consistently to replace humans, and this is why self-driving cars have not replaced humans. Based on early signs, GPT-4 seems much better suited to augmenting humans rather than replacing them. It cannot pass most medium-difficulty software engineer interview problems, and building full-scale software systems is immensely more complex and difficult than these toy problems. Beyond that, making software is more constrained than many problems we want AI to solve.</p><p>GPT-4 has around 1000x the compute of GPT-3, yet GPT-4 does not seem that much closer to building complex software systems than GPT-3. Will 1000x the compute of GPT-4 make the difference?</p><p>Another case to look at is ChatGPT. ChatGPT feels like a massive leap in the capabilities of AI. Indeed, ChatGPT is immensely more <i>useful</i> than other GPT-3.5 iterations. But this wasn\u2019t made possible by making the AI more <i>powerful.</i> Instead, it was through the hard work of making it more human usable. While this is important for automating jobs, fine-tuning is unlikely to get us much closer to the capabilities that truly advanced AI requires. Improving capabilities seems like it requires more computing power.</p><ul><li>The last 10% of the project is always the most difficult, so knowing how many orders of magnitude improvements lie between current models and transformative AI is hard.</li></ul><h3>Why won\u2019t AI take over the economy in the next 10 years and justify unlimited spending?</h3><p>The economy changes slowly. Anyone who has had to fax medical documents is aware of how transitions take time. And the larger and more capable the models we make, the more expensive they are to run.</p><p>Moreover, companies are able to get away with a lot of excess fat. Corporations have a lot of excess resources and they are slow-moving. Cloud adoption has taken over a decade, and we should not expect AI adoption to be drastically faster. It can often be cheaper and advantageous in the near term to stick with what you know. It is hard to upend a company and get revolutionary gains in productivity.</p><p>AI can also reduce profits for existing companies. Bing Chat is a great example of this. While AI may enable better search results, running a large and expensive AI model means that the profit per search is much lower. In general, while AI may be cheaper or better than the thing it replaces, it will likely not be <i>that much</i> cheaper or better, at least at first. So the transition will be slow.</p><p>Throughout the transition, AI systems will also be competing with older AI systems. The incremental improvement will be small, preventing a drastic and sudden takeover. The economy is run by people, and people take time to change their minds, learn things and adopt new techniques. Many industry companies using \u201cAI\u201d are really just calling a logistic regression or clustering algorithm that has existed for decades.</p><ul><li>This means that AI will be money-constrained. We will not see $1t training runs in the near future.</li></ul><h2>Conclusion</h2><p>Growth is likely to continue to be exponential, but with a much smaller exponent than has been seen over the past 10 years. The past few years have been a period of explosive growth; newly viable business applications combined with scaling laws meant that companies were willing to spend thousands of times more on hardware than they had previously. But this period is coming to an end, and we will soon have a much more stable level of growth. We can only have a few more years of explosive growth.</p><p>It seems unlikely that spending 1000x GPT-4 on computational power will get us to transformative AI, and it seems unlikely that companies will spend much more. That means the shift to transformative AI will likely be more gradual, taking time as AI improves and slowly replaces human work across a wide range of fields.</p><p>There are major unknowns about whether we will have revolutionary algorithmic discoveries, how good AI will be at discovering better algorithms, and whether alternative chip designs will allow faster growth in compute efficiency. However, if we do not see these disruptions, there is reason to believe that AI will roll out with time for people to adapt.</p><p>&nbsp;</p><h1>Appendix</h1><h2>Estimated exponent by year, breakdown into 3 factors</h2><p>This is my rough estimate. In reality, there is not a sharp change in the exponent. This is an extreme simplification.</p><ul><li>Algorithms<ul><li>2012-2017: 4x per year. Total = 1000x better</li><li>2018-2025: 3x per 2 years. Total = 48x better</li><li>2026-?: 3x per 2 years</li></ul></li><li>Efficiency of compute<ul><li>2012-2017: 3x every 2 years. 15x better</li><li>2018-2025: 1.73x every 2 years. 7x better</li><li>2026-?: 1.5x every 2 years</li></ul></li><li>Spending on Compute<ul><li>2012-2017: Relatively flat, let's say a lab was willing to spend $1k on a graphics card</li><li>2018-2025: 10x a year. 10,000,000x more</li><li>2026-?: 3x per 2 years</li></ul></li></ul><p>One breakdown of time scales:</p><p>2012 vs 2018: 16,000x Improvement</p><p>2018 vs 2025: 3,000,000,000x Improvement</p><p>2025 vs 2035: 400,000x improvement</p><p>An alternative breakdown:</p><p>2012 vs 2023: 95,000,000,000x</p><p>2012 vs 2023: Classifying small images with high accuracy \u2192 passing the bar exam</p><p>2023 vs 2043: 1,400,000,000x</p><p>2023 vs 2043: Passing the bar exam \u2192 replacing all human knowledge work?</p><p>It seems that going from classifying images to passing the bar may be easier than going from passing the bar to accurately understanding all the complexities of human society and acting effectively within them.</p><p>How much spending does this entail?</p><h3>Checking my work</h3><p>19000*$100m = $1.9t. It seems reasonable to spend that on AI in 2043.</p><p>AlexNet had 62.3m parameters, 14m images</p><p>Assuming compute roughly equates to multiplying - number of parameters * quantity of training data</p><p>GPT-4, estimate 1t parameters, 5t tokens.</p><p>10,000x the parameters. 100,000x the data. Multiply = 1,000,000,000x. 2 orders of magnitude off, but reasonably close to 95,000,000,000x</p><p>Exponents:</p><figure class=\"table\"><table><thead><tr><th>&nbsp;</th><th>2012-2017</th><th>2018-2025</th><th>2026-?</th></tr></thead><tbody><tr><td>Algorithm</td><td>4</td><td>1.73</td><td>1.73</td></tr><tr><td>Efficiency</td><td>1.73</td><td>1.31</td><td>1.22</td></tr><tr><td>Spend</td><td>1</td><td>10</td><td>1.73</td></tr><tr><td>Yearly Total</td><td>6.92</td><td>22.663</td><td>3.651338</td></tr></tbody></table></figure><p>Growth:</p><figure class=\"table\"><table><thead><tr><th>&nbsp;</th><th>2012</th><th>2018</th><th>2025</th><th>2035</th></tr></thead><tbody><tr><td>Algorithm</td><td>1</td><td>1024</td><td>46.3791433</td><td>240.138079</td></tr><tr><td>Efficiency</td><td>1</td><td>15.496389</td><td>6.62062622</td><td>7.30463142</td></tr><tr><td>Spend</td><td>1</td><td>1</td><td>10000000</td><td>240.138079</td></tr><tr><td>Total</td><td>1</td><td>15868.303</td><td>3070589719</td><td>421231.043</td></tr></tbody></table></figure><figure class=\"table\"><table><thead><tr><th>&nbsp;</th><th>2012</th><th>2023</th><th>2043</th></tr></thead><tbody><tr><td>Algorithm</td><td>1</td><td>15868.303</td><td>19270.692</td></tr><tr><td>Efficiency</td><td>1</td><td>59.784279</td><td>37.565092</td></tr><tr><td>Spend</td><td>1</td><td>100000</td><td>19367.699</td></tr><tr><td>Total</td><td>1</td><td>9.487E+10</td><td>1.402E+10</td></tr></tbody></table></figure>", "user": {"username": "Skye Nygaard"}}, {"_id": "zZqdkHhk5s2TfQijQ", "title": "An A.I. Safety Presentation at RIT", "postedAt": "2023-03-27T23:49:59.686Z", "htmlBody": "", "user": {"username": "NicholasKross"}}, {"_id": "J7LwudixQX5FHrcP3", "title": "Governing High-Impact AI Systems: Understanding Canada\u2019s Proposed AI Bill. April 15, Carleton University, Ottawa", "postedAt": "2023-03-27T23:11:39.372Z", "htmlBody": "<p>Join us this April 15th for a panel discussion, keynote address by the founder of the Montreal AI Ethics Institute, and networking mixer on the governance of AI Systems in the Canadian context, held by EA Carleton and EA Canada.&nbsp;</p><p>The Canadian federal government is currently debating language that will govern and regulate High Impact AI systems. We've organized this one day event to bring academics, policy, legal, technical, AI Ethics and longtermist concerns together for dialogue.&nbsp;<br>&nbsp;</p><p>Our panelists are:</p><p>Dr. Graeme Auld &amp; Benjamin Faveri, authors of <a href=\"https://carleton.ca/sppa/2022/governing-artificial-intelligence-through-ethical-standards/\"><u>\u201cGoverning AI through ethical standards\u201d</u></a><u>.</u>&nbsp;</p><p>Abhishek Gupta, founder of the <a href=\"https://montrealethics.ai/\"><u>Montreal AI Ethics Institute</u></a><u>.</u> &nbsp;</p><p>Wyatt Tessari, founder of <a href=\"https://aigs.ca/\"><u>AI Governance &amp; Safety Canada</u></a> network, a AGI governace focused advocacy network.&nbsp;<br>&nbsp;</p><p>Our panel discussion will be followed by a keynote delivered by Abhishek Gupta.</p>", "user": {"username": "Liav.Koren"}}, {"_id": "9s3fPvcHLEiK6vZaK", "title": "Half-baked alignment idea", "postedAt": "2023-03-28T05:18:28.557Z", "htmlBody": "<p>I'm trying think through various approaches to AI alignment, and so far this is the one I came up with that I like best. I have not read much of the literature, so please do point me if this has been discussed before.</p>\n<p>What if we train an AI agent (ie, reinforcement learning) to survive/thrive in an environment where there are a wide variety of agents with wildly different levels of intelligence? In particular, such that pretty much every agent can safely assume they'll eventually meet an agent much smarter than they are; structure the environment to reward tit-for-tat with a significant bias towards cooperation, eg require agents to \"eat\" resources that require cooperation to secure and are primarily non-competitive. The idea is to have them learn to respect even beings of lesser intelligence, because they want beings of higher intelligence to respect them; and because in this environment a bunch of lesser intelligences can gang up and defeat one higher-intelligence being. Also, we effectively train each AI to detect and defeat new AIs that seek to disturb this balance.\nI have not thought this through, curious what you all think</p>\n", "user": {"username": "ozb"}}, {"_id": "bSXEtTFr7aXgqd94H", "title": "Correction to \u201cThe Value of Money Going to Different Groups\u201d", "postedAt": "2023-03-28T20:41:52.579Z", "htmlBody": "<p>In Toby Ord's <a href=\"https://www.centreforeffectivealtruism.org/blog/the-value-of-money-going-to-different-groups\">\"The Value Of Money Going to Different Groups\"</a>, footnote 9 states: \u201cit isn\u2019t more important to help someone living on $200 per year (at official exchange rates) in a place where PPP is high than someone on the same amount where PPP is low\u201d.&nbsp;</p><p>This isn\u2019t right;&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"PPP\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>&nbsp;(purchasing power parity) doesn\u2019t matter if the elasticity parameter&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7=1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\"><span class=\"mjx-mrow\" aria-hidden=\"true\"></span></span></span></span></span>, but it does matter if&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7\u22601\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>&nbsp;(so in particular, the estimates in the article for&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7=2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span>&nbsp;are only correct for comparing contexts with equal&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"PPP\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span></span></span></span></span>s).</p><p>To show this, consider again the utility function:</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\begin{equation} u(c)= &nbsp; &nbsp;\\begin{cases} &nbsp; &nbsp; &nbsp; &nbsp;\\frac{c^{1-\u03b7}-1}{1-\u03b7} &amp; \u03b7\u22601\\\\ &nbsp; &nbsp; &nbsp; &nbsp;\\ln(c) &amp; \u03b7=1 &nbsp; &nbsp;\\end{cases} \\end{equation}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mrow MJXc-space3\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size4-R\" style=\"padding-top: 1.551em; padding-bottom: 1.551em;\">{</span></span><span class=\"mjx-mtable\" style=\"vertical-align: -1.301em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 1.927em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0.5em 0px 0px; text-align: left; width: 2.667em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.427em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 3.432em; top: -1.702em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.435em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 3.432em; bottom: -0.881em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.427em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.827em; vertical-align: -0.623em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0.5em; text-align: left; width: 2.331em;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.204em;\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.175em;\"><span class=\"mjx-mtd\" style=\"padding: 0.1em 0.5em 0px 0px; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.2em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">ln</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.1em 0px 0px 0.5em; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: -0.2em;\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span><span class=\"mjx-mo\" style=\"width: 0.12em;\"></span></span></span></span></span></span></span></p><p>Let A and B be two people with the same income $<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>&nbsp;living in countries A and B, which have different price levels. Then person A\u2019s consumption&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c_A\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span>&nbsp;is given by&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c_A=X/P_A\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span></span></span>, and person B\u2019s consumption by&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c_B=X/P_B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span>, where&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>&nbsp;is the price level for each person. This gives&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"PPP_{A/B}=P_A/P_B\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.275em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span></span></span></span>.</p><p>An illustrative example:&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"PPP_{A/B}=5\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.275em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span></span></span></span></span></span>&nbsp;means person B can consume five times person A for the same amount of money. Plotting the utility curves for these two people:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bSXEtTFr7aXgqd94H/ualilrcw9dunfzglhw0f\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bSXEtTFr7aXgqd94H/y7ajsgttbkkkwbugiqvv 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bSXEtTFr7aXgqd94H/ui4vugqfl0hrnsrr1hfo 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bSXEtTFr7aXgqd94H/ss0jvzqylzgwkk8tntoh 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bSXEtTFr7aXgqd94H/okmamhjmglnlsyhnj7ot 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bSXEtTFr7aXgqd94H/b3vqcq9qmyu3kmuiztkc 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bSXEtTFr7aXgqd94H/dzvbjnr6pj5zc7sjxyd1 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bSXEtTFr7aXgqd94H/jt12lf7tvabqeavdpb4p 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bSXEtTFr7aXgqd94H/scv44fuwr6t7skzpc1st 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bSXEtTFr7aXgqd94H/hkrg7rn24dwrzknudolb 1350w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bSXEtTFr7aXgqd94H/dwtfges6zavgimjkzhct 1477w\"><figcaption>Figure 1: <i>plots of utility against monetary income for two countries with&nbsp;</i><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"PPP_{A/B}=5\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.275em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">5</span></span></span></span></span></span></span></figcaption></figure><p>Differentiating the utility function with respect to money,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>:</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{du}{dX}=\\frac{du}{dc}\\cdot\\frac{dc}{dX}=c^{-\u03b7}\\cdot\\frac{1}{P_i}=\\left[\\frac{X}{P_i}\\right]^{-\u03b7}\\cdot\\frac{1}{P_i}=P_i^{\u03b7-1}X^{-\u03b7}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.114em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.575em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.575em; bottom: -0.703em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.114em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.495em; vertical-align: -0.497em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.916em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.295em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.295em; bottom: -0.704em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.916em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.496em; vertical-align: -0.498em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mfrac MJXc-space2\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.114em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.575em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.575em; bottom: -0.703em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.114em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.495em; vertical-align: -0.497em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mfrac MJXc-space2\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.828em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.171em; top: -1.372em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.171em; bottom: -0.905em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.828em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.611em; vertical-align: -0.64em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">[</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.828em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.171em; top: -1.389em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.171em; bottom: -0.905em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.828em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.623em; vertical-align: -0.64em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">]</span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 1.276em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">\u22c5</span></span><span class=\"mjx-mfrac MJXc-space2\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.828em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.171em; top: -1.372em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.171em; bottom: -0.905em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.828em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.611em; vertical-align: -0.64em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.311em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.271em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0.115em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span></span></span></span></span></span></span></span></span></span></p><p>where&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{du}{dc}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.916em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.295em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.295em; bottom: -0.704em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.916em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.496em; vertical-align: -0.498em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span>&nbsp;is the marginal utility of consumption, and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{dc}{dX}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.114em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.575em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.575em; bottom: -0.703em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.114em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.495em; vertical-align: -0.497em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span>&nbsp;is the marginal consumption of money.</p><p>This differential<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefd6kjg385odg\"><sup><a href=\"#fnd6kjg385odg\">[1]</a></sup></span>&nbsp;shows the two effects of differences in price levels:</p><p>(1) Person A on $<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>&nbsp;in a high price country, will have less consumption and therefore higher marginal utility of consumption,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{du}{dc}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.916em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.295em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.295em; bottom: -0.704em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.916em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.496em; vertical-align: -0.498em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span><br>(2) Person A in the high price country gets less extra consumption for an extra dollar,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{dc}{dX}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.114em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.575em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.575em; bottom: -0.703em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.114em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.495em; vertical-align: -0.497em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></p><p>If&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7=1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>, these effects cancel:&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{du}{dc}=\\frac{X}{P_i}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.916em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.295em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.295em; bottom: -0.704em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.916em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.496em; vertical-align: -0.498em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.828em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.171em; top: -1.389em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.171em; bottom: -0.905em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.828em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.623em; vertical-align: -0.64em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span>&nbsp; and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{dc}{dX}=\\frac{1}{P_i}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.114em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.575em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.575em; bottom: -0.703em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.114em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.495em; vertical-align: -0.497em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.828em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.171em; top: -1.372em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.171em; bottom: -0.905em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.828em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.611em; vertical-align: -0.64em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span>&nbsp; so&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\frac{du}{dX}=\\frac{1}{X}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.114em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.575em; top: -1.411em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.575em; bottom: -0.703em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.114em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.495em; vertical-align: -0.497em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.744em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.052em; top: -1.372em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.052em; bottom: -0.682em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.744em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.453em; vertical-align: -0.482em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span>: gradient is independent of price,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>, for all values of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>, as shown in Figure 1b. So the claim in footnote 9 is true in this case.</p><p>For&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7\u22601\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>&nbsp;change in utility is proportional to&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"{P_i}^{\u03b7-1}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.615em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span></span></span></span></span>:</p><p>If&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7>1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>, point (1) dominates giving person A, with the higher prices, a higher marginal utility (the exponent of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>&nbsp;is positive, so higher price gives higher marginal utility). See Figure 1c &amp; d.</p><p>If&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7<1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>, point (2) dominates giving person B, with the lower prices, a higher marginal utility (the exponent of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>&nbsp;is negative, so higher price gives lower marginal utility). See Figure 1a.</p><p>If it doesn\u2019t seem intuitive that, for two people with the same monetary income, money should go to the person in the country where goods are more expensive, recall that this person has a lower level of consumption. By contrast, consider people with different price values, but the same consumption:</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"c=c_A=c_B=c_i=\\frac{X_A}{P_A}=\\frac{X_B}{P_B}=\\frac{X_i}{P_i}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.241em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.198em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.695em; top: -1.649em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.317em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.695em; bottom: -0.942em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.317em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.198em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.832em; vertical-align: -0.666em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.204em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.702em; top: -1.622em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.702em; bottom: -0.915em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.284em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.204em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.793em; vertical-align: -0.647em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.96em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.357em; top: -1.613em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.357em; bottom: -0.905em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 0.96em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.781em; vertical-align: -0.64em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></p><p>In this case, the money should always go to the country with a lower price because the&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\Delta X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>&nbsp;is scaled to consumption by&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>. To show this consider the case&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X_{i,2}=X_{i,1}+\\Delta X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>&nbsp;for the same initial consumption, described above. See footnote<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefd6kjg385odg\"><sup><a href=\"#fnd6kjg385odg\">[1]</a></sup></span>&nbsp; for explanation of the following utility change expressions. For&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7=1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>:</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\Delta u=\\ln{\\left(\\frac{X_{i,2}}{X_{i,1}}\\right)}=\\ln{\\left(\\frac{X_i+\\Delta X}{X_i}\\right)=\\ln{\\left(\\frac{P_ic+\\Delta X}{P_ic}\\right)=\\ln{\\left(\\frac{c+X/P\\ }{c}\\right)}}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">ln</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">(</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.418em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 2.006em; top: -1.769em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 2.006em; bottom: -1.062em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.418em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.002em; vertical-align: -0.751em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">)</span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">ln</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">(</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.701em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 3.82em; top: -1.646em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 3.82em; bottom: -0.905em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.701em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.804em; vertical-align: -0.64em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">)</span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">ln</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">(</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.876em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 4.067em; top: -1.646em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 4.067em; bottom: -0.905em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.262em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.876em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.804em; vertical-align: -0.64em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">)</span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">ln</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-texatom MJXc-space1\"><span class=\"mjx-mrow\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">(</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.662em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 3.764em; top: -1.706em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.291em; padding-bottom: 0.372em;\">&nbsp;</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 3.764em; bottom: -0.524em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.662em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.577em; vertical-align: -0.37em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size2-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p>And&nbsp;for&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7\u22601\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>:</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\Delta u=P_i^{\\eta-1}\\frac{{X_{i,2}}^{1-\\eta}-{X_{i,1}}^{1-\\eta}}{1-\\eta}=P_i^{\\eta-1}\\frac{({X_{i,1}+\\Delta X)}^{1-\\eta}-{X_{i\\ ,1}}^{1-\\eta}}{1-\\eta}=\\frac{\\left(\\frac{X_{i,1}+\\Delta X}{P_i}\\right)^{1-\\eta}-\\left[\\frac{X_{i,1}}{P_i}\\right]^{1-\\eta}}{1-\\eta}=\\frac{\\left(c+\\frac{\\Delta X}{P_i}\\right)^{1-\\eta}-c^{1-\\eta}}{1-\\eta}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.311em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.271em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 5.403em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 7.641em; top: -2.023em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.463em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.463em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 7.641em; bottom: -0.881em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 5.403em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.054em; vertical-align: -0.623em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.311em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.271em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 7.842em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 11.091em; top: -2.09em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.544em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.291em; padding-bottom: 0.372em;\">&nbsp;</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.463em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 11.091em; bottom: -0.881em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 7.842em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.101em; vertical-align: -0.623em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 9.022em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 12.76em; top: -3.442em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size3-R\" style=\"padding-top: 1.256em; padding-bottom: 1.256em;\">(</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 3.887em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 83.3%; width: 4.664em; top: -1.869em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"vertical-align: -0.337em; padding-right: 0.05em;\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 83.3%; width: 4.664em; bottom: -1.048em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"vertical-align: -0.332em; padding-right: 0.05em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span style=\"border-bottom: 1px solid; top: -0.296em; width: 3.887em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.432em; vertical-align: -0.874em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size3-R\" style=\"padding-top: 1.256em; padding-bottom: 1.256em;\">)</span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 1.483em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size3-R\" style=\"padding-top: 1.256em; padding-bottom: 1.256em;\">[</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.834em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 83.3%; width: 2.201em; top: -1.836em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"vertical-align: -0.337em; padding-right: 0.05em;\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 83.3%; width: 2.201em; bottom: -1.048em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"vertical-align: -0.332em; padding-right: 0.05em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span style=\"border-bottom: 1px solid; top: -0.296em; width: 1.834em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.404em; vertical-align: -0.874em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size3-R\" style=\"padding-top: 1.256em; padding-bottom: 1.256em;\">]</span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 1.45em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 12.76em; bottom: -0.881em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 9.022em;\" class=\"mjx-line\"></span></span><span style=\"height: 3.057em; vertical-align: -0.623em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 6.334em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 8.957em; top: -3.36em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size3-R\" style=\"padding-top: 1.256em; padding-bottom: 1.256em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.571em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 83.3%; width: 1.885em; top: -1.338em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 83.3%; width: 1.885em; bottom: -1.048em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"vertical-align: -0.332em; padding-right: 0.05em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span style=\"border-bottom: 1px solid; top: -0.296em; width: 1.571em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.989em; vertical-align: -0.874em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size3-R\" style=\"padding-top: 1.256em; padding-bottom: 1.256em;\">)</span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 1.384em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">c</span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.435em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 8.957em; bottom: -0.881em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 6.334em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.999em; vertical-align: -0.623em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></p><p>How does this affect the figures given in the original article? The article\u2019s Table 1 suggests that under the assumption that&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7=2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span>, someone living on the mean income in Kenya gets 230x<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwbfhiul2w1\"><sup><a href=\"#fnwbfhiul2w1\">[2]</a></sup></span>&nbsp;the marginal utility from a dollar as someone on a median salary in the US. But suppose that goods for someone living on the mean income in Kenya are three times cheaper than in the US, i.e.&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"PPP_{US/K}=3\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.275em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.084em;\">U</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;\">S</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span></span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">3</span></span></span></span></span></span></span>.&nbsp;Then in fact this multiplier should be 75 (dividing by 3). All the upper bound estimates in the article are over-estimates if&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"PPP>1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>.</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnd6kjg385odg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefd6kjg385odg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Integrating this differential equation between&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X_1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span></span></span>&nbsp;and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X_2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span></span>, where&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"X_2=X_1+\u0394X\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-texatom MJXc-space2\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span></span></span></span></span>&nbsp;gives two expressions for&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u0394u\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span></span>&nbsp;below, independent of price when&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7=1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>&nbsp;and proportion to&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_i^{\u03b7-1}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.311em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.271em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span></span>&nbsp;when&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\u03b7\u22601\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>:</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\begin{equation} \\Delta u= &nbsp; &nbsp;\\begin{cases} &nbsp; &nbsp; &nbsp; &nbsp;P_i^{\\eta-1}\\frac{{X_2}^{1-\\eta}-{X_1}^{1-\\eta}}{1-\\eta} &amp; \u03b7\u22601\\\\ &nbsp; &nbsp; &nbsp; &nbsp;\\ln(\\frac{X_2}{X_1}) &amp; \u03b7=1 &nbsp; &nbsp;\\end{cases} \\end{equation}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.372em;\">\u0394</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mrow MJXc-space3\"><span class=\"mjx-mo\" style=\"vertical-align: -0.783em;\"><span class=\"mjx-delim-v\"><span class=\"mjx-char MJXc-TeX-size4-R\" style=\"padding-top: 0.667em; padding-bottom: 0.298em;\">\u23a7</span><span class=\"mjx-char MJXc-TeX-size4-R\" style=\"line-height: 0.113em; margin-bottom: 0.087em; margin-top: -0.137em;\">\u23aa</span><span class=\"mjx-char MJXc-TeX-size4-R\" style=\"padding-top: 0.961em; padding-bottom: 0.961em;\">\u23a8</span><span class=\"mjx-char MJXc-TeX-size4-R\" style=\"line-height: 0.113em; margin-bottom: 0.087em; margin-top: -0.137em;\">\u23aa</span><span class=\"mjx-char MJXc-TeX-size4-R\" style=\"margin-top: -0.217em; padding-bottom: 1.182em;\">\u23a9</span></span></span><span class=\"mjx-mtable\" style=\"vertical-align: -1.707em; padding: 0px 0.167em;\"><span class=\"mjx-table\"><span class=\"mjx-mtr\" style=\"height: 2.04em;\"><span class=\"mjx-mtd\" style=\"padding: 0px 0.5em 0px 0px; text-align: left; width: 7.037em;\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.311em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0.271em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 4.669em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 6.603em; top: -1.862em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.463em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.463em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 6.603em; bottom: -0.881em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">\u03b7</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 4.669em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.94em; vertical-align: -0.623em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0px 0px 0px 0.5em; text-align: left; width: 2.331em;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.316em;\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-strut\"></span></span></span></span><span class=\"mjx-mtr\" style=\"height: 1.873em;\"><span class=\"mjx-mtd\" style=\"padding: 0.1em 0.5em 0px 0px; text-align: left;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">ln</span></span><span class=\"mjx-mo\"><span class=\"mjx-char\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.051em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.486em; top: -1.608em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.486em; bottom: -0.9em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\" style=\"margin-right: -0.024em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.051em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.773em; vertical-align: -0.637em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-strut\"></span></span></span><span class=\"mjx-mtd\" style=\"padding: 0.1em 0px 0px 0.5em; text-align: left;\"><span class=\"mjx-mrow\" style=\"margin-top: 0.137em;\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em;\">\u03b7</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-strut\"></span></span></span></span></span></span><span class=\"mjx-mo\" style=\"width: 0.12em;\"></span></span></span></span></span></span></span></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwbfhiul2w1\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwbfhiul2w1\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Should be 220x (rounding error)</p></div></li></ol>", "user": {"username": "BenjaminSMiller"}}, {"_id": "i7aKatsck7x3aLoiH", "title": "The Prospect of an AI Winter", "postedAt": "2023-03-27T20:55:36.335Z", "htmlBody": "", "user": {"username": "Erich_Grunewald"}}, {"_id": "mMgkuNSmxFWia83ej", "title": "EA & LW Forum Weekly Summary (20th - 26th March 2023)", "postedAt": "2023-03-27T20:46:54.839Z", "htmlBody": "<p>This is part of a weekly series summarizing the top posts on the EA and LW forums - you can see the full collection <a href=\"https://forum.effectivealtruism.org/s/W4fhpuN26naxGCBbN\">here.</a> The first post includes some details on purpose and methodology. Feedback, thoughts, and corrections are welcomed.</p><p>If you'd like to receive these summaries via email, you can subscribe <a href=\"https://easummaries.substack.com/?r=1p817z&amp;s=w&amp;utm_campaign=pub&amp;utm_medium=web\">here.</a></p><p><strong>Podcast version</strong>: Subscribe on your favorite podcast app by searching for 'EA Forum Podcast (Summaries)'. A big thanks to Coleman Snell for producing these!<br><br><strong>Author's note:</strong> I'm currently travelling, which means:<br>a) Today's newsletter is a shorter one - only 9 top posts are covered, though in more depth than usual.<br>b) The next post will be on 17th April (three week gap), covering the prior three weeks at a higher karma bar.<br>After that, we'll be back to the regular schedule.</p><p>&nbsp;</p><h1>Object Level Interventions / Reviews</h1><p><a href=\"https://forum.effectivealtruism.org/posts/DiGL5FuLgWActPBsf/how-much-should-governments-pay-to-prevent-catastrophes\"><strong><u>How much should governments pay to prevent catastrophes? Longtermism\u2019s limited role</u></strong></a></p><p><i>by EJT, CarlShulman</i></p><p>Linkpost for&nbsp;<a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Fphilpapers.org%2Farchive%2FSHUHMS.pdf\"><u>this paper</u></a>, which uses standard cost-benefit analysis (CBA) with detrimental assumptions (eg. giving no value to future generations, only assessing benefits to Americans, and only assessing value from preventing&nbsp;<i>existential</i> threats) to show that even under those conditions governments should be spending much more on averting threats from nuclear war, engineered pandemics, and AI.<br><br>Their analysis primarily relies on previously published estimates of risks, concluding US citizens alive today have a ~1% risk of dying from these causes in the next decade. They estimate $400B in interventions could reduce the risk by minimum 0.1 percentage points, and that using the lowest figure for the US Department of Transportation\u2019s value of a statistical life, this would result in ~$646B in value of American lives saved.</p><p>They suggest longtermists in the political sphere should change their messaging to revolve around this standard CBA-driven catastrophe policy, which is more democratically acceptable than policies relying on the cost to future generations. They suggest it would also reduce risk almost as much as a strong longtermist policy (particularly if the CBA incorporates an argument for citizens \u2018altruistic willingness to pay\u2019 ie.&nbsp;<i>some</i> level of addition for the benefit to future generations).<br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness\"><strong><u>Assessment of Happier Lives Institute\u2019s Cost-Effectiveness Analysis of StrongMinds</u></strong></a></p><p><i>by GiveWell</i></p><p>The Happier Lives Institute (HLI) has argued that if Givewell used subjective well-being (SWB) measures in their moral weights, they\u2019d find StrongMinds more cost-effective than marginal funding to their top charities. Givewell assessed this claim and estimated StrongMinds is ~25% (5%-80% pessimistic to optimistic CI) as effective as these marginal funding opportunities when using SWB - this equates to 2.3x the effectiveness of GiveDirectly.</p><p>Key differences in analysis from HLI, by size of impact, include:</p><ul><li>GiveWell assumes lower spillover effects to household members of those receiving treatment.</li><li>Givewell translates decreases in depression into increases in life satisfaction at a lower rate than HLI.</li><li>Givewell expects lower effect in a scaled program, and lower durations of effects (not passing a year) due to the program being only 4-8 weeks.</li><li>Givewell applies downward adjustments for social desirability bias and publication bias in studies of psychotherapy.</li></ul><p>These result in an ~83% discount in the effectiveness vs. HLI\u2019s analysis. For all points except the fourth, two upcoming RCTs from StrongMinds will provide better data than currently exists.</p><p>HLI has posted a thorough response in the comments, noting which claims they agree / disagree with and why (5% agree, 45% sympathetic to some discount but unsure of magnitude, 35% unsympathetic but limited evidence, and 15% disagree on the basis of current evidence).</p><p>Givewell also note for context that HLI\u2019s original estimates imply that a donor would pick offering StrongMinds\u2019 intervention to 20 individuals over averting the death of a child, and that receiving StrongMinds\u2019 program is 80% as good for the recipient as an additional year of healthy life.<br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/brBqjKxBdsEwBWwLD/eradicating-rodenticides-from-u-s-pest-management-is-less\"><strong><u>Eradicating rodenticides from U.S. pest management is less practical than we thought</u></strong></a></p><p><i>by Holly_Elmore, HannahMc, William McAuliffe, Rethink Priorities</i></p><p>Agricultural use of rodenticides in the US is well-protected by state and federal laws that seem unlikely to change. Eliminating their usage in other areas (eg. conservation and pest management) also face significant barriers such as cost and inertia - but may be possible if these are overcome. The post links to&nbsp;<a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Fosf.io%2F458cx\"><u>this paper</u></a>, which discusses in detail why rodenticides are used, under what circumstances they could be replaced, and whether they are replaceable with currently available alternatives.<br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/XWwvwytieLtEWaFJX/deep-deceptiveness\"><strong><u>Deep Deceptiveness</u></strong></a></p><p><i>by So8res</i></p><p>Author\u2019s summary: \u201cDeceptiveness is not a simple property of thoughts. The reason the AI is deceiving you is not that it has some \"deception\" property, it's that (barring some great alignment feat) it's a fact about the world rather than the AI that deceiving you forwards its objectives, and you've built a general engine that's good at taking advantage of advantageous facts in general.</p><p>As the AI learns more general and flexible cognitive moves, those cognitive moves (insofar as they are useful) will tend to recombine in ways that exploit this fact-about-reality, despite how none of the individual abstract moves look deceptive in isolation.\u201d<br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/PMFoxr62AeLEwPAH9/potential-employees-have-a-unique-lever-to-influence-the\"><strong><u>Potential employees have a unique lever to influence the behaviors of AI labs</u></strong></a></p><p><i>by oxalis</i></p><p>When you are considering a job offer from an AI lab, they care a lot about what you think of them. You can use this to push for helpful practices for AI safety (eg. a larger alignment team, good governance, or better information security). This can be done by:</p><ul><li>Sending an email saying you\u2019re excited for the role but have questions about how they do [helpful practice] first, or would want to see that in place before joining.</li><li>When accepting, post on social media that you\u2019re excited to join an org with good [helpful practice].</li><li>When rejecting, say you\u2019re turning it down because of lack of [helpful practice].<br>&nbsp;</li></ul><p><a href=\"https://www.lesswrong.com/posts/4Gt42jX7RiaNaxCwP/more-information-about-the-dangerous-capability-evaluations\"><strong><u>More information about the dangerous capability evaluations we did with GPT-4 and Claude.</u></strong></a></p><p><i>by Beth Barnes</i></p><p>To test GPT-4 for dangerous capabilities before release, ARC:</p><ul><li>Told it that it was running on a cloud server, had various commands available, and had the goal of gaining power and becoming hard to shut down.</li><li>Evaluated if the plans it produced could succeed (no plausible plan was produced, though some were reasonable at eg. getting money).</li><li>Checked if it could carry out the individual tasks required in the plan (eg. hiring a human on TaskRabbit). The models were error-prone, easily derailed, and failed to tailor their approach - but could complete some sub-tasks such as browsing the internet or instructing humans.</li></ul><p>They concluded it did not have sufficient capabilities to replicate autonomously and become hard to shut down. However, it came close enough that future models should be checked closely.<br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/92TAmcppCL7t54Ajn/announcing-the-european-network-for-ai-safety-enais\"><strong><u>Announcing the European Network for AI Safety (ENAIS)</u></strong></a></p><p><i>by Esben Kran, Teun_Van_Der_Weij, Du\u0161an D. Ne\u0161i\u0107 (Dushan), Jonathan Claybrough, simeon_c, Magdalena Wache</i></p><p>Author\u2019s tl;dr: \u201cThe&nbsp;<a href=\"http://enais.co/\"><u>European Network for AI Safety</u></a> is a central point for connecting researchers and community organizers in Europe with opportunities and events happening in their vicinity.&nbsp;<a href=\"https://airtable.com/shrdtkHEBO9GU1gok\"><u>Sign up here</u></a> to become a member of the network, and&nbsp;<a href=\"https://forms.gle/RiJ7A5YuAk1BjbDM7\"><u>join our launch event</u></a> on Wednesday, April 5th from 19:00-20:00 CET!\u201d<br><br><a href=\"https://forum.effectivealtruism.org/posts/46tXkg838EZ6uie45/my-objections-to-we-re-all-gonna-die-with-eliezer-yudkowsky\"><strong><u>My Objections to \"We\u2019re All Gonna Die with Eliezer Yudkowsky\"</u></strong></a></p><p><i>by Quintin Pope</i></p><p>Eliezer Yudkowsky recently appeared on the&nbsp;<a href=\"https://www.youtube.com/watch?v=gA1sNLL6yg4\"><u>Bankless Podcast</u></a>, where he argued that AI was nigh-certain to end humanity. The author provides counterarguments, as someone experienced in the AI alignment community whose current estimate of doom is ~5%:</p><ol><li>Argument: large amounts of money will find a more dangerous training paradigm than our current one (generative pre-training + reinforcement learning).<ol><li>Counter: the current paradigm is the best after a lot of effort searching for better - the author expects smooth progress current alignment techniques can work with.</li></ol></li><li>Argument: humans aren\u2019t that general vs. what AGI could be - we have a learning process specialized to the ancestral environment.&nbsp;<ol><li>Counter: deep learning improves mainly through scaling of data or model, human training data can change a lot, and we have evidence our architecture isn\u2019t too limiting (eg. sensory substitution, parts of our brain repurposing after injury).</li></ol></li><li>Argument: mindspace is big, AIs could be vastly different to humans.<ol><li>Counter: mindspace is big, \u2018mindspace of powerful intelligences we could build in the near future\u2019 is less so, and might be similar to humans.</li></ol></li><li>Argument: it\u2019s hard to optimize for one goal even when you design it that way eg. see evolution\u2019s failure to just optimize for inclusive genetic fitness.<ol><li>Counter: evolution didn\u2019t know the concept it was aiming for, and was only able to optimize over the learning process and reward circuitry. It\u2019s not a good analogy - we have more control in what we reward our AIs for and why.</li></ol></li><li>Argument: computer security is hard, so alignment and adversarial robustness will be too. People who are optimistic don\u2019t understand the arguments.<ol><li>Counter: why that specific analogy? Also - 100% adversarial robustness isn\u2019t needed, just like there are some cases even the most moral human will make an immoral decision (eg. in exhaustion or extreme pain), but we aren\u2019t unaligned. Capable systems can navigate away from these inputs.</li></ol></li><li>Argument: fast take-offs are likely eg. see how Go AIs went from competitive pros, to world champs, to generalized model so fast.<ol><li>Counter: performance on individual tasks has often been fast and sudden. Overall competence across a wide range of tasks has been smoother.</li></ol></li><li>Argument: current AIs can\u2019t self-improve - we\u2019ll see a phase shift when they can.<ol><li>Counter: AIs self-improve throughout training, including \u2018learning to learn\u2019 (learning how to make better use of future training data). Researchers have also tried continual learning during running.<br>&nbsp;</li></ol></li></ol><h1>Community &amp; Media</h1><p><a href=\"https://forum.effectivealtruism.org/posts/5YKx6xGg8qz6jLKvF/some-comments-on-the-recent-ftx-time-article\"><strong><u>Some Comments on the Recent FTX TIME Article</u></strong></a></p><p><i>by Ben_West</i></p><p>Alameda Research (AR) was founded in 2017, and ~half the employees quit in 2018 (including the author). Later in 2018, some remaining staff started working on FTX. A recent Time article claims because some EAs worked at AR before FTX started, they would have had knowledge on SBF\u2019s character that should have allowed predicting something bad would happen.</p><p>The author notes their experience was different than described in the article. While they thought SBF was a bad CEO and manager (eg. not prepping for 1-1s, playing video games, poor accounting practices) they had a more positive view than the sense they get from statements in the TIME article. They also note they also were not stopped from disparagement (eg. with a non-disparagement clause) and were treated fairly when it came to an informal equity agreement that the company could have saved money on. They suggest this means protecting ourselves through better noticing \u201cwarning signs\u201d is a fragile approach.</p><p><br>&nbsp;</p>", "user": {"username": "GreyArea"}}, {"_id": "NKuT48MxsmgkyzAqd", "title": "[Linkpost] The global biomass of wild mammals", "postedAt": "2023-03-27T22:33:06.253Z", "htmlBody": "<h2>New Data</h2><p>The following infographics are excerpted from the paper:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NKuT48MxsmgkyzAqd/ymex9o2xjoh9ik5wr6ww\" alt=\"Earth's mammals by total biomass\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NKuT48MxsmgkyzAqd/gyzxwbozmzpv8ec5ckhc\" alt=\"Mammal Individual Counts and Biomass\"></p><h2>Background</h2><p>The following Our World in Data image has been fairly popular: <img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NKuT48MxsmgkyzAqd/jb3bcclptgr6tootuhls\" alt=\"Life on Earth: the distribution of all global biomass\"> (Link to accompanying article: <a href=\"https://ourworldindata.org/life-on-earth\">https://ourworldindata.org/life-on-earth</a> )</p><p>This infographic was based on <a href=\"https://www.pnas.org/doi/10.1073/pnas.1711842115\">The Biomass Distrbution on Earth</a>, which was published in 2018 by Y. M. Bar-On, R. Phillips, and R. Milo.</p><p>This paper attempted to give a rough estimate of the biomass of various taxa on Earth. The exact granularity of the taxon being measured varied based on the available data. For mammals, the authors separated the data into 3 classes:</p><ul><li>Humans</li><li>Livestock</li><li>Wild mammals</li></ul><p>The newly published paper improves on this by providing a more detailed breakdown of mammal biomass as well as individual counts.</p><h2>Comparison of Previously Reported Categories</h2><p>The old paper reported biomass in terms of dry carbon. The new paper uses wet mass, which includes both water and non-carbon content.</p><p>For consistency, we'll use the dry carbon values for both papers. The authors state that an&nbsp;frac16is an appropriate conversion factor from wet mass to dry carbon.</p><p>Using this conversion factor, here's how much the overall estimates changed between the 2018 and 2023 papers:</p><figure class=\"table\"><table><thead><tr><th>Taxon</th><th>2018 (Megatons Carbon)</th><th>2023 (Megatons Carbon)</th><th>Change</th></tr></thead><tbody><tr><td>Human</td><td>60</td><td>65</td><td>+8.3%</td></tr><tr><td>Livestock</td><td>100</td><td>105</td><td>+5%</td></tr><tr><td>Wild Mammals</td><td>7</td><td>10</td><td>+42%</td></tr></tbody></table></figure><h2>Discussion</h2><h3>Bats</h3><p>One surprising result is the number of bats. Looking at the source data <a href=\"https://gitlab.com/milo-lab-public/mammal_biomass/-/blob/master/results/results_grouped_by_order.csv\">here</a>, we observe that there are about 55.802 billion wild bats. Overall, bats make up 2/3 of of wild mammal individuals. The next most popular taxon, Rodentia, only has 25.882 billion indviduals.</p><p>This has implications for wild animal welfare. While rodent welfare has been mentioned before, bat welfare is not very popular: I haven't found any resources relating to it so far.</p><p>Some research topics which are worth looking into:</p><ul><li>Which kind of bats make up most of the population?<ul><li>Microbats or megabats?</li></ul></li><li>How much do bats suffer?</li><li>Are there tractable ways to reduce bat suffering?</li></ul><h3>Livestock</h3><p>I was looking to see if they had individual counts for domesticated mammals as well, but I couldn't find it. According to <a href=\"https://www.pnas.org/doi/suppl/10.1073/pnas.2204892120/suppl_file/pnas.2204892120.sapp.pdf\">the appendix</a>, the methodology for calculating the individual counts of livestock was to retrieve them from <a href=\"https://www.fao.org/faostat/en/#data/QCL\">the FAO</a>.</p><p>I retreived the data for the year 2021, and plotted it:</p><p>Bar Plot: <img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/NKuT48MxsmgkyzAqd/zdxbjgtnuhfi6u5euig8\" alt=\"Livestock Individual Counts (Bar Plot)\"> (You can view the associated jupyter notebook <a href=\"https://pimpale.github.io/assets/mammalbiomass/livestock.html\">here</a>)</p><p>I suspect that the bee count is probably an underestimate. The rest of the numbers seem reasonable though.</p>", "user": {"username": "Govind Pimpale"}}, {"_id": "Si3H2oM8tYwcnBWdS", "title": "New blog: Planned Obsolescence", "postedAt": "2023-03-27T19:46:16.111Z", "htmlBody": "<p>We (Kelsey and Ajeya) just launched a new blog about AI futurism and AI alignment called&nbsp;<i>Planned Obsolescence.&nbsp;</i>If you\u2019re interested, you can check it out&nbsp;<a href=\"https://www.planned-obsolescence.org/\"><u>here</u></a>.&nbsp;</p><p>Both of us have thought a fair bit about what we see as the biggest challenges in technical work and in policy to make AI go well, but a lot of our thinking isn\u2019t written up, or is embedded in long technical reports. This is an effort to make our thinking more accessible. That means it\u2019s mostly aiming at a broader audience than LessWrong and the EA Forum, although some of you might still find some of the posts interesting.</p><p>So far we have seven posts:</p><ul><li><a href=\"https://www.planned-obsolescence.org/what-were-doing-here/\"><u>What we're doing here</u></a></li><li><a href=\"https://www.planned-obsolescence.org/aligned-vs-good/\"><u>\"Aligned\" shouldn't be a synonym for \"good\"</u></a></li><li><a href=\"https://www.planned-obsolescence.org/situational-awareness/\"><u>Situational awareness</u></a></li><li><a href=\"https://www.planned-obsolescence.org/the-training-game/\"><u>Playing the training game</u></a></li><li><a href=\"https://www.planned-obsolescence.org/training-ais-to-help-us-align-ais/\"><u>Training AIs to help us align AIs</u></a></li><li><a href=\"https://www.planned-obsolescence.org/disagreement-in-alignment/\"><u>Alignment researchers disagree a lot</u></a></li><li><a href=\"https://www.planned-obsolescence.org/ethics-of-red-teaming/\"><u>The ethics of AI red-teaming</u></a></li></ul><p>Thanks to ilzolende for formatting these posts for publication. Each post has an accompanying audio version generated by a voice synthesis model trained on the author's voice using&nbsp;<a href=\"https://www.descript.com/overdub\"><u>Descript Overdub</u></a>.</p><p>You can submit questions or comments to mailbox@planned-obsolescence.org.</p>", "user": {"username": "Ajeya"}}, {"_id": "HnJemSPZtC5Aj2WNB", "title": "Industrialization/Computerization Analogies", "postedAt": "2023-03-27T16:34:21.918Z", "htmlBody": "", "user": {"username": "gworley3"}}, {"_id": "MP9qDZCXMaTJhiJ9u", "title": "EA is three radical ideas I want to protect", "postedAt": "2023-03-27T15:31:55.092Z", "htmlBody": "<p><i>Context note: This is more of an emotional piece meant to capture feelings and reservations, rather than a logical piece meant to make a persuasive point. This is a very personal piece and only represents my own views, and does not necessarily represent the views of anyone else or any institution I may represent.</i></p><p>~</p><p>It\u2019s been a rough past five months for effective altruism.</p><p>Because of this, understandably many people are questioning their connection and commitment to the movement and questioning whether \u201ceffective altruism\u201d is still a brand or set of ideas worth promoting. I\u2019ve heard some suggest it might be better to instead promote other brands and perhaps even abandon promotion of \u201ceffective altruism\u201d altogether.</p><p>I could see ways in which this is a good move. Ultimately I want to do whatever is most impactful. However, I worry that moving away from effective altruism could make us lose some of what I think makes the ideas and community so special and what drew me to the community more than ten years ago.</p><p>Essentially, effective altruism contains three radical ideas that I don\u2019t easily find in other communities. These three ideas are ideas I want to protect.</p><p>&nbsp;</p><h2>Radical empathy</h2><p>Humanity has long had a fairly narrow moral circle.&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ehZK259et52Xnvw5F/radical-empathy\"><u>Radical Empathy</u></a> is the idea that there are many groups of people, or other entities, that are worthy of moral concern even if they don't look or act like us. Moreover, it\u2019s important to deliberately identify all entities worthy of moral concern so that we can ensure they are protected. I find effective altruism to be unique in extending moral concern to not just traditionally neglected farm animals and future humans (very important) \u2013 but also to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/T5fSphiK6sQ6hyptX/opinion-estimating-invertebrate-sentience\"><u>invertebrates</u></a> and&nbsp;<a href=\"https://80000hours.org/problem-profiles/artificial-sentience/\"><u>potential digital minds</u></a>. Effective altruists are also unique in trying to intentionally understand who might matter and why and actually incorporating this into the process of discovering how to best help the world. Asking the question \"Who might matter that we currently neglect?\" is a key question that is asked way too rarely.</p><p>We understand that while it\u2019s ok to have special concern for family and friends, we should generally aim to make altruistic decisions based on impartiality, not weighing people differently just because they are at a different level of geographic distance, a different level of temporal distance, a different species, or run cognition on a different substrate.</p><p>I worry that if we were to promote individual subcomponents of effective altruism, like pandemic preparedness or AI risk, we might not end up promoting radical empathy and we might end up missing entire classes of entities that matter. For example, I worry that one more subtle form of misaligned AI might be an AI that treats humans ok but adopts common human views on nonhuman animal welfare and perpetuates factory farming or abuse of a massive number of digital minds. The fact that effective altruism has somehow created a lot of AI developers that avoid eating meat and care about nonhuman animals is a big and fairly unexpected win. I think only some weird movement that somehow combined factory farming prevention with AI risk prevention could\u2019ve created that.</p><p>&nbsp;</p><h2>Scope sensitivity</h2><p>I also really like that EAs are willing to&nbsp;<a href=\"https://www.lesswrong.com/tag/shut-up-and-multiply\"><u>\u201cshut up and multiply\u201d</u></a>. We\u2019re&nbsp;<a href=\"https://en.wikipedia.org/wiki/Scope_neglect\"><u>scope sensitive</u></a>. We\u2019re&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/cause-neutrality\"><u>cause neutral</u></a>. Nearly everyone else in the world is not. Many people pick ways to improve the world based on <i>vibes</i> or personal experience, rather than through a systematic search of how they can best use their resources. Effective altruism understands that resources are limited and that we have to make hard choices between potential interventions and help 100 people instead of 10, even if helping the 10 people feels as or more satisfying. We understand \u201cvalue per effort\u201d and \u201cbang for your buck\u201d matter in philanthropy.</p><p>When thinking, we\u2019re also willing to think in bets and use expected value reasoning. When facing problems we can think probabilistically rather than in black and white. We can properly handle uncertainty.</p><p>I worry that by not communicating scope sensitivity when promoting subcomponents of effective altruism, we might be recruiting people who are unprepared to choose the right things when tackling the relevant problems. It\u2019s important that we empower people to be scope sensitive when deciding which risks to tackle and how to tackle them.</p><p>&nbsp;</p><h2>Scout mindset</h2><p>Lastly, the third and final factor I find really rare in the world is&nbsp;<a href=\"https://en.wikipedia.org/wiki/The_Scout_Mindset\"><u>scout mindset</u></a>, or the view that we should be open, collaborative, and truth-seeking in our understanding of what to do. While rare in the real world, this is abundant in effective altruism. We look for the truth rather than treat our&nbsp;<a href=\"https://www.lesswrong.com/tag/arguments-as-soldiers\"><u>arguments as soldiers</u></a> or our&nbsp;<a href=\"https://www.lesswrong.com/posts/nYkMLFpx77Rz3uo9c/belief-as-attire\"><u>beliefs as attire</u></a>. We\u2019re open to being wrong, even about very fundamental things like our preferred ways to help others. We practice and&nbsp;<a href=\"https://www.lesswrong.com/posts/xF96rk7yZtrjekiqZ/epistemic-progress-1\"><u>hone good epistemics</u></a>. We hold each other to high standards of honesty, integrity, and friendliness.</p><p>I worry that by not communicating scout mindset when promoting components of effective altruism, we may recruit people who argue counterproductively, do not reason well, and ultimately hold us back as we try to collectively find the truth.</p><p>&nbsp;</p><h2>Why this matters to me</h2><p>These three radical views \u2013 radical empathy, scope sensitivity, and scout mindset \u2013 are so rare in the world that I rarely find people with just one of them, let alone all three. I think the effective altruism community has been amazing in cultivating a large group of talented and compelling people that hold these three views. I think that\u2019s precious and I want to protect that as much as I can.</p><p>It\u2019s natural for social movements to go through trials and tribulations. I was a part of the New Atheist movement during the acrimonious&nbsp;<a href=\"https://www.theguardian.com/commentisfree/belief/2012/sep/02/american-atheism-schism-spit-venom\"><u>Atheism Plus split</u></a>. I was a part of the animal rights movement during the shockingly poor behavior and more importantly terrible institutional handling of issues related to Wayne Pacelle, Nick Cooney, and others. While these issues are serious, it\u2019s normal for social movements to go through crisis \u2013 what\u2019s more important is how we respond to that crisis.</p><p>I\u2019m definitely ok with using other brands if that\u2019s what is most impactful. I don\u2019t want to cling stubbornly to my movement \u2013 that wouldn\u2019t be a good use of scout mindset.&nbsp;</p><p>But I think I\u2019m going to stick with effective altruism, at least as an internal motivation, as long as I think it effectively represents these three radical ideas and as long as no other movement does a better job at that.</p>", "user": {"username": "Peter_Hurford"}}, {"_id": "QDk88sEJdXFyyvehn", "title": "Announcing the Swiss Existential Risk Initiative (CHERI) 2023 Research Fellowship", "postedAt": "2023-03-27T15:35:18.461Z", "htmlBody": "<p>The&nbsp;<a href=\"https://www.xrisk.ch/\"><u>Swiss Existential Risk Initiative</u></a> (CHERI) is excited to announce the launch of its&nbsp;<a href=\"http://xrisk.ch/research-fellowship\"><u>2023 Research Fellowship</u></a>, an 8-week in-person program focused on global catastrophic risk research.&nbsp;</p><p>The fellowship will take place from July 3rd to August 27th, 2023, in the beautiful city of Geneva, Switzerland. This year, we are particularly eager to host fellows interested in exploring governance issues related to global catastrophic risk mitigation, given our close connections with policy organizations in the field. That being said, we also warmly welcome and anticipate having several fellows engaged in more technical research questions.</p><p><a href=\"https://www.xrisk.ch/research-fellowship\"><strong><u>Apply here </u></strong><u>before April 16th, 11:59PM CET.</u></a></p><figure class=\"image image_resized\" style=\"width:100%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QDk88sEJdXFyyvehn/zb4dtzmwpkbjf5pkk36s\"></figure><p>By participating in the CHERI Research Fellowship, <strong>you'll have the opportunity to</strong>:</p><ul><li>Strengthen your research portfolio and test your fit for research in global catastrophic risks.</li><li>Receive mentorship from experienced researchers who will provide valuable support and guidance.</li><li>Network and collaborate with like-minded individuals and professionals in the field.</li><li>Develop essential skills and knowledge to shape the future of global catastrophic risk research.</li></ul><p>In addition to these benefits, the <strong>Research Fellowship offers</strong>:</p><ul><li>A $5,500 stipend, free accommodation, and travel expense support.</li><li>Co-working in a shared office at a policy hub in Geneva with access to the UN library.&nbsp;</li><li>Learning opportunities through talks and workshops from various GCR researchers from all over Europe.</li><li>A stimulating and socially enriching summer experience amidst the breathtaking Swiss landscape.</li></ul><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QDk88sEJdXFyyvehn/yksne1qx28o2fiewbsdt\"><figcaption>The 2022 Cohort</figcaption></figure><h3>Who are we looking for?</h3><p>We are seeking proactive and motivated individuals from a diverse range of subject areas who have the potential to make a significant impact in the field of global catastrophic risk research. Ideal candidates will possess strong analytical and critical thinking skills, a genuine interest in understanding and mitigating existential risks, and a commitment to making a positive difference in the world.</p><p><strong>Eligibility criteria:</strong></p><ul><li>Applicants must be currently pursuing a Bachelor, Master, or PhD (in any discipline), starting their studies in 2023, graduating in 2023, or have graduated in the past year.</li><li>Willing and able to spend July &amp; August 2023 in Geneva, Switzerland (we can help with short-stay Schengen visas).</li><li>Available to do research full-time over the 8-week period.</li></ul><h3>Application process</h3><p>The first stage consists of a few short tasks, estimated to take 1 to 1.5 hours. Applicants who progress to the next stage will be invited for a 20-minute interview during the week of April 24th. We expect to send out final acceptance decisions by the 28th of April 2023. If you need a decision before the 28th of April, please reach out to us, and we will look for ways to speed up the process.</p><p><strong>Deadline to Apply</strong>: Sunday, April 16th, 23:59 (CET)</p><p>To apply and learn more, <a href=\"https://www.xrisk.ch/research-fellowship\">please visit our website</a>. If you have any questions, please do not hesitate to contact us at <strong>help@xrisk.ch</strong>.</p><p>In our experience,&nbsp;<strong>many excellent candidates hesitate to apply</strong>. If you're unsure, we encourage you to err on the side of applying. We also encourage you to&nbsp;<strong>share this opportunity with others who may be a good fit</strong>. If you are a leader or organizer of relevant community spaces, we\u2019d be thankful if you could share this post with your community members.&nbsp;</p>", "user": {"username": "TobiasH"}}, {"_id": "YLLtdNBJNbhdkopG7", "title": "Casting the Decisive Vote", "postedAt": "2023-03-27T14:09:45.174Z", "htmlBody": "<p><i>The moral value of voting is a perennial topic in EA. This piece shows that in any election that isn't a forgone conclusion, the chance of your vote being decisive can't be much lower than 1 in the number of voters. So voting will be worth it around the point where the value your preferred candidate would bring to the average citizen exceeds the cost of you voting.</i></p><p>&nbsp;</p><p>What is the chance your vote changes the outcome of an election? We know it is low, but how low?</p><p>In particular, how does it compare with an intuitive baseline of a 1 in&nbsp;<i>n</i>&nbsp;chance, where&nbsp; <i>n</i> is the number of voters? This baseline is an important landmark not only because it is so intuitive, but because it is roughly the threshold needed for voting to be justified in terms of the good it produces for the members of the community (since the total benefit is also going to be proportional to <i>n</i>).</p><p>Some political scientists have tried to estimate it with simplified theoretical models involving random voting. Depending on their assumptions, this has suggested it is much higher than the baseline \u2014 roughly 1 in the square root of <i>n</i> (Banzhaf 1965) \u2014 or that it is extraordinarily lower \u2014 something like 1 in 10^2659 for a US presidential election (Brennan 2011).</p><p>Statisticians have attempted to determine the chance of a vote being decisive for particular elections using detailed empirical modelling, with data from previous elections and contemporaneous polls. For example, Gelman et al (2010) use such a model to estimate that an average voter had a 1 in 60 million chance of changing the result of the 2008 US presidential election, which is about 3 times higher than the baseline.</p><p>In contrast, I\u2019ll give a simple method that depends on almost no assumptions or data, and provides a floor for how low this probability can be. It will calculate this using just two inputs: the number of voters, <i>n</i>, and the probability of the underdog winning, <i>p_u</i>.</p><p>The method works for any two-candidate election that uses simple majority. So it wouldn\u2019t work for the US presidential election, but would work for your chance of being decisive within your state, and could be combined with estimates that state is decisive nationally. It also applies for many minor \u2018elections\u2019 you may encounter, such as the chance of your vote being decisive on a committee.</p><p>We start by considering a probability distribution over what share of the vote a candidate will get, from 0% to 100%. In theory, this distribution could have any shape, but in practice it will almost always have a single peak (which could be at one end, or somewhere in between). We will assume that the probability distribution over vote share has this shape (that it is \u2018unimodal\u2019) and this is the <i>only</i> substantive assumption we\u2019ll make.</p><p>We will treat this as the probability distribution of the votes a candidate gets before factoring in your own vote. If there is an even number of votes (before yours) then your vote matters only if the vote shares are tied. In that case, which way you vote decides the election. If there is an odd number of votes (before yours), it is a little more complex, but works out about the same: Before your vote, one candidate has one fewer vote. Your vote decides whether they lose or tie, so is worth half an election. But because there are two different ways the candidates could be one vote apart (candidate <i>A</i> has one fewer or candidate <i>B</i> has one fewer), you are about twice as likely to end up in this situation, so have the same expected impact. For ease of presentation I\u2019ll assume there is an even number of voters other than you, but nothing turns on this.</p><p>(In real elections, you may also have to worry about probabilistic recounts, but if you do the analysis, these don\u2019t substantively change anything as there is now a large range of vote shares within which your vote improves the probability that your candidate secures a recount, wins a recount, or avoids a recount (Gelman et al 2002, p 674).)</p><p>So we are considering a unimodal probability distribution over the share of the vote a candidate will get and we are asking what is the chance that the share is exactly 50% (with an even number of voters). This corresponds to asking what is the height of the distribution in the very centre. Our parameters will be:</p><p><i>n</i>&nbsp;\u2014 the number of voters (other than you).</p><p><i>p_u </i>\u2014 the probability that the underdog would win (without you voting).&nbsp;</p><p><i>p_d</i>&nbsp;\u2014 the probability that your vote is decisive.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YLLtdNBJNbhdkopG7/emyybrdmicyd7icgmrss\" alt=\"Figure 1.png\"></p><p>Our job is to characterise&nbsp;<i>p_d</i>&nbsp;in terms of the inputs&nbsp;<i>n</i>&nbsp;and&nbsp;<i>p_u</i>. It is impossible to determine it precisely, but it is surprisingly easy to produce a useful lower bound.</p><p>The key observation is that as the distribution has a single mode, there must be at least one side of the distribution that doesn\u2019t have the mode on it. That side is monotonically increasing (or at least non-decreasing) as one proceeds from the outside towards the centre. How low could the centre be? Well the entire non-decreasing side either has probability <i>p_u</i> or (1 \u2013 <i>p_u</i>), so the minimum probability it could have is <i>p_u</i>. And the way of spreading it out that would lead to the lowest value in the centre is if it were uniformly distributed over that side (over the&nbsp;<i>n</i>/2 outcomes ranging from the candidate getting all the vote through to getting just over half).</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YLLtdNBJNbhdkopG7/atknie9wsyhgj9yoil7v\" alt=\"Figure 2.png\"></p><p>&nbsp;</p><p>In this case, the probability in the exact centre (i.e. the probability of a decisive vote) must be at least&nbsp;<i>p_u</i> \u00f7 <i>n</i>/2. In other words:</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p_d\\ge \\frac{2p_u}{n}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2265</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.217em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.721em; top: -1.566em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.18em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.721em; bottom: -0.524em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.217em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.478em; vertical-align: -0.37em;\" class=\"mjx-vsize\"></span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span></p><p>This is highest when the candidates have equal chances (<i>p_u</i> \u2248 50%). Then the lower bound for having a decisive vote is simply &nbsp;1/<i>n </i>\u2014 the intuitive baseline. The bound decreases linearly as the underdog\u2019s chances decrease. So for example, if the underdog has a 10% chance, the bound for a decisive vote is 1/5<i>n</i>, and if they have a 1% chance, it is 1/50<i>n</i>.</p><p>So for simple elections that are not completely forgone conclusions, the chance of having a decisive vote can\u2019t be all that much lower than 1/<i>n</i>.&nbsp;</p><h3><strong>What does probability mean here?</strong></h3><p>This analysis works for several kinds of probability, so long as the probability of the underdog winning and the probability of your vote being decisive are of the same type. So if you have a 10% degree of belief that the underdog will win, you are rationally required to have at least a 1/5<i>n</i>&nbsp;degree of belief that your vote will be decisive. And if the best informed and calibrated political models assign a 10% chance to the underdog winning, then they also need to assign at least a 1/5<i>n</i>&nbsp;chance to your vote being decisive.</p><h3><strong>What if a larger majority is required?</strong></h3><p>The earlier analysis generalises very easily. Now instead of estimating the height of the distribution at the centre, we do so it at the supermajority point (e.g. 2/3). The worst case is when the non-decreasing side is also the longer side, so the probability gets spread thinner across these possibilities, giving:</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p_d \\ge \\frac{p_u}{nm}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2265</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.187em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 1.678em; top: -1.342em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.18em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 1.678em; bottom: -0.524em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m</span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.187em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.32em; vertical-align: -0.37em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></p><p>where&nbsp;<i>m</i>&nbsp;is the size of the majority needed (i.e. a simple majority has&nbsp;<i>m</i> = 1/2, a two-thirds majority has&nbsp;<i>m </i>= 2/3).&nbsp;</p><h3><strong>Can we relax the assumption that the distribution is unimodal?</strong></h3><p>Our only use of this assumption was to prove that there was a side of the distribution with no mode on it. So we could replace the assumption with that weaker claim.</p><p>It wouldn\u2019t matter if there were multiple modes, so long as they are all on the same side of the distribution. The problem with multiple modes is that there could be one on either side, with almost all the probability mass gathered near them, and a negligible amount in between at the centre. But this seems very implausible as a credence distribution in advance of an election. And even if somehow your beliefs were that it was probably going to be a landslide one way or the other, you can sometimes <i>still</i> apply this bound:</p><p>e.g. Suppose your credences were a mixture of (1) a very skewed unimodal distribution with 95% chance of candidate <i>A</i> winning and (2) another such distribution with 95% chance of candidate <i>B</i> winning. That would still just be the same chance of being decisive as in an election where the underdog has a 5% chance of winning (after all, you can see this as being certain the underdog has a 5% chance, you just don\u2019t know which candidate is the underdog), and that would still leave you with a 1/10<i>n</i>&nbsp;chance of having the decisive vote.</p><h3><strong>Multi-level elections?</strong></h3><p>Many elections proceed in two stages, with individual voters electing representatives for their constituency or state, and then those representatives having their own election (e.g. for the right to appoint the president or prime minister). If each constituency has equal voting power in the higher level election, then one can simply apply my model twice.&nbsp;</p><p>e.g. if there are&nbsp;<i>n</i>_1&nbsp;people in your constituency and a 25% chance of the local underdog winning it, then you have at least a 1/2<i>n</i>_1&nbsp;chance of determining your constituency\u2019s representative. If there are&nbsp;<i>n</i>_2&nbsp;constituencies in the nation with a 10% chance of the national underdog winning a majority of them (<i>conditional upon your own constituency being tied</i>), then there is at least a 1/5<i>n</i>_2&nbsp;chance of your constituency being nationally decisive. The chance your vote is nationally decisive is then the product of these: 1/(10 <i>n</i>_1 <i>n</i>_2).</p><p>In general, the formula is just:</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p_d\\ge \\frac{2p_{u1}}{n_1}\u00d7\\frac{2p_{u2}}{n_2}=\\frac{4p_{u1}p_{u2}}{n_1n_2}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.446em;\">\u2265</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.512em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 2.138em; top: -1.6em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 2.138em; bottom: -0.731em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.512em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.648em; vertical-align: -0.517em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">\u00d7</span></span><span class=\"mjx-mfrac MJXc-space2\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 1.512em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 2.138em; top: -1.6em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 2.138em; bottom: -0.731em;\"><span class=\"mjx-msubsup\" style=\"\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 1.512em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.648em; vertical-align: -0.517em;\" class=\"mjx-vsize\"></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.529em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 70.7%; width: 3.576em; top: -1.611em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">4</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">u</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"font-size: 70.7%; width: 3.576em; bottom: -0.731em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 2.529em;\" class=\"mjx-line\"></span></span><span style=\"height: 1.656em; vertical-align: -0.517em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span></p><p>If the constituencies are roughly equally sized, then&nbsp;<i>n</i>_1 \u00d7 <i>n</i>_2 \u2248 <i>n</i>, so for a competitive election and a competitive electorate, the chance of being decisive is still not much worse than&nbsp;the baseline of 1/<i>n</i>.</p><p>Note that because this involves applying a conservative lower bound twice in succession, it will tend to give probabilities that are a bit lower than if it were a simple one-level election. This may just be due to the conservativeness of focusing on worst case scenarios rather than suggesting that the two level structure actually lowers the chance of having a decisive vote.</p><p>If constituencies have different voting power (as in the US electoral college) or if some have incumbents whose seats aren\u2019t up for re-election (as in the US senate) there are additional complications and you may want to turn to a specific model crafted for that election.</p><h3><strong>Comparisons with other work</strong></h3><p>The most prominent theoretical model for the probability of a decisive vote is the random voting model. It assumes that all other voters vote randomly, voting for candidate <i>A</i> with a probability <i>p_A</i>, which must be exactly the same for all voters. This is the background for Banzhaf\u2019s (1965) result that <i>p_D</i> is roughly 1 in the square root of <i>n</i> \u2014 which is what you get if you also add the assumption that <i>p</i>_<i>A</i> = 50% precisely. And it is the background for Brennan\u2019s (2011) result that <i>p_D</i> is something like 1 in 10^2,659 \u2014 which is what you get in an election the size of the 2004 US presidential election if you assume that <i>p_A</i> is a plausible sounding vote share for a close election, such as 50.5%.</p><p>This is a remarkable discrepancy between two uses of the same model. It happens because the model produces a vote-share distribution with an <i>extremely</i> tall and narrow peak \u2014 especially for large elections. For a presidential sized election, it would be about 1,000 times taller and 1,000 times narrower than in my illustrative diagrams. Banzhaf configured this model to have the peak lining up exactly at the 50-50 split, leading to a very high estimate for a decisive vote. Brennan nudged the peak a small distance from the centre, but the peak is so slender that the curve\u2019s height at the centre becomes microscopic.</p><p>Both versions are known to give poor estimates for the chance of a decisive vote. Banzhaf\u2019s has been shown to be too high on empirical grounds (Gelman et al 2004). Brennan\u2019s has been thoroughly embarrassed by the evidence: events his model said wouldn\u2019t happen in the lifetime of the universe have <a href=\"https://en.wikipedia.org/wiki/List_of_close_election_results\">already happened</a>. For example, in 1985 control of the upper house for my home state of Victoria (Australia) with 2,461,708 voters <a href=\"https://en.wikipedia.org/wiki/1985_Nunawading_Province_state_by-election\">came down to a single vote</a>: any additional vote in Nunawading Provence would have determined the whole election in that party\u2019s favour.</p><p>There are a number of flaws in the random voter model that cause such inaccurate predictions. A key one is that assumptions its practitioners are making determine where the peak goes, which directly determines whether the chance of a decisive vote is large or miniscule. Effectively Brennan is just assuming it is a close, but non-tied, election and saying that conditional on this there is very little chance it is tied. That obviously begs the question. If we slightly tweak the model to allow uncertainty about where the peak is (e.g. somewhere from 40% to 60%), then the dramatic results go away and you would get something in the vicinity of 1/<i>n</i>. But then it is even better to avoid all need of the problematic modelling assumptions and directly use this probability distribution over vote share \u2014 or even just the simple probability that the underdog wins, as we\u2019ve done in this piece.</p><p>I first developed this model in 2016 in the lead-up to the US presidential election, and wrote a near-final version of this essay explaining it in the wake of the 2020 election. I subsequently came across a superb paper by Zach Barnett (2020) that makes many of the same points (and more). Barnett\u2019s paper is aimed at the broader conclusion that the expected moral value of voting often exceeds the costs to the voter, providing a moral case for voting along the lines that Parfit (1984) had advanced. As part of this, he too needed to bound the probability that one\u2019s vote is decisive. His model for doing so was strikingly similar to mine (and we were both excited to discover the independent convergence). The key differences are:</p><ul><li>Instead of making the probability a function of the underdog\u2019s chance of winning, he makes the modelling assumption that the underdog will have a &gt;10% chance of winning.</li><li>He makes an additional assumption that it is more likely the underdog wins by less than 10 points than that they win by more than 10 points.</li></ul><p>By making these slightly stronger assumptions, he is able to reach a slightly stronger lower bound, which helps make the moral case for voting. Which one to use is something of a matter of taste (do you prefer unassailable assumptions or stronger conclusions?) and partly a matter of purpose: Barnett\u2019s approach might be better for arguing that it is generally worth voting and mine for understanding the chance of a decisive vote itself.</p><h3><strong>References</strong></h3><p>J. R. Banzhaf, 1965, \u2018Weighted Voting Doesn\u2019t Work: A Mathematical Analysis\u2019, <i>Rutgers Law Review</i>, 19 (1965), 317\u201343.</p><p>Zach Barnett, 2020, \u2018Why you should vote to change the outcome\u2019, <i>Philosophy and Public Affairs</i>,<i> </i>48:422\u2013446.</p><p>Jason Brennan, 2011, <i>The Ethics of Voting</i> (Princeton: Princeton University Press), 18\u201320.</p><p>Andrew Gelman, Jonathan N. Katz and Josef Bafumi, 2002, <a href=\"http://www.stat.columbia.edu/~gelman/research/published/gelmankatzbafumi.pdf\">\u2018Standard Voting Power Indexes Do Not Work: An Empirical Analysis\u2019</a>, <i>B. J. Pol. Sci </i>34:657\u2013674.</p><p>Andrew Gelman, Nate Silver and Aaron Edlin, 2010. <a href=\"http://www.stat.columbia.edu/~gelman/research/published/probdecisive2.pdf\">\u2018What is the probability your vote will make a difference?\u2019</a>,&nbsp;<i>Economic Inquiry</i> 50:321\u2013326.&nbsp;</p><p>Derek Parfit, 1984, <i>Reasons and Persons</i> (Oxford: Oxford University Press), 73\u201374.</p>", "user": {"username": "Toby_Ord"}}, {"_id": "rE7t2qo72uoghEhna", "title": "Are there cause priortizations estimates for s-risks supporters?", "postedAt": "2023-03-27T10:32:00.204Z", "htmlBody": "<p>80000 hours has lots of concrete guides of each cause areas for us to work in, and there's even an estimate the importance of each problem(though they claim it's not very accurate) as below. But they uses x-risks angle to estimate. Like the\"Scale\" number is determined by the people we save(DALYs), so AI safety got the highest score because its extinction risk is the highest. But in s-risks, the main point should be \"the suffering we reduce\". There are also lots of areas in s-risks, are there any cause priortization researches on s-risks?&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rE7t2qo72uoghEhna/hhjpirncfperbwco96p6\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rE7t2qo72uoghEhna/vowp5w7fycqxgkhwdj3a 103w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rE7t2qo72uoghEhna/gkvhu3mjmaczuezacub5 183w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rE7t2qo72uoghEhna/ysxegk0uhmdw6yf2ubro 263w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rE7t2qo72uoghEhna/zl4wss1gbgfkvspqsad0 343w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rE7t2qo72uoghEhna/tiqtgzwdaarx8jtgnfl4 423w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rE7t2qo72uoghEhna/y53vfvc4kajltzsogxaq 503w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/rE7t2qo72uoghEhna/v4ufbwuinn7zwy1y1jbz 583w\"></figure>", "user": {"username": "jackchang110"}}, {"_id": "CGofXqkwzdaabgzhJ", "title": "Introducing Focus Philanthropy", "postedAt": "2023-03-27T10:06:18.273Z", "htmlBody": "<p>We\u2019re excited to announce the launch of&nbsp;<a href=\"https://focusphilanthropy.org/\"><u>Focus Philanthropy</u></a>, a new organization that connects philanthropists with outstanding giving opportunities to reduce the harms of factory farming.&nbsp;</p><p>&nbsp;</p><p>Focus Philanthropy aims to fill a gap in the effective animal advocacy space. The factory farming cause area is both fast-changing and complex in its variety of approaches and we aim to reduce barriers for new funders interested in entering the space. We offer thoughtful, tailored funding advice and engage with donors to increase their commitment and inspire them to support impactful giving opportunities within the cause area over the long term.&nbsp;</p><p>&nbsp;</p><p>Our core principles</p><ul><li>Impact: We help philanthropists maximize the impact of their donations, ensuring their funds go where they can do the most good.&nbsp;</li><li>Evidence: Our recommendations are based on research, the current state of scientific evidence, and expert judgment.&nbsp;</li><li>Independence: Our advice is always free of charge, allowing us to provide unbiased and impartial giving recommendations.</li></ul><p>&nbsp;</p><p>The team</p><p>Focus Philanthropy was founded by Leah Edgerton and Manja G\u00e4rtner.&nbsp;</p><p><a href=\"https://www.linkedin.com/in/leah-edgerton/\"><u>Leah</u></a> has extensive experience in effective animal advocacy ranging from volunteering and direct work to having acted as a leader, mentor, and advisor. She previously worked as a philanthropic advisor, at Animal Charity Evaluators, and at ProVeg International.</p><p><a href=\"https://www.linkedin.com/in/manjagartner/\"><u>Manja</u></a> has several years of experience as a researcher, grantmaker, and advisor in effective animal advocacy. She previously worked as a philanthropic advisor and at Animal Charity Evaluators. She holds a Ph.D. in economics.</p><p>&nbsp;</p><p>Please approach us directly with any feedback or questions.</p><p><br>&nbsp;</p>", "user": {"username": "Focus Philanthropy"}}, {"_id": "5HhHJjP5qkCwvJozA", "title": "Please help me sense-check my assumptions about the needs of the AI Safety community and related career plans", "postedAt": "2023-03-27T08:11:23.244Z", "htmlBody": "<p>For background and context, see my related&nbsp;series of posts<i> </i>on <a href=\"https://forum.effectivealtruism.org/s/RwtygELTfbRJzcvwD\">an approach for AI Safety Movement Building</a>. This is a quick and concise rewrite of the main points in the hope that it will attract better engagement and feedback.</p><p>Which of the following assumptions do you agree or disagree with? Follow the links to see some of the related content from my posts.</p><h1><strong>Assumptions about the needs of the AI Safety community</strong></h1><ol><li><a href=\"https://forum.effectivealtruism.org/posts/8XZmu8BM5JBtSnHiP/a-proposed-approach-for-ai-safety-movement-building-projects#Having_fewer_movement_builders_probably_reduces_AI_Safety_contributors__contributions_and_collective_coordination\"><strong><u>A lack of people, inputs, and coordination is (one of several issues) holding back progress in AI Safety.</u></strong></a> Only a small portion of potential contributors are focused on AI Safety, and current contributors face issues such as limited support, resources, and guidance.</li><li><a href=\"https://forum.effectivealtruism.org/posts/8XZmu8BM5JBtSnHiP/a-proposed-approach-for-ai-safety-movement-building-projects#Having_fewer_movement_builders_probably_reduces_AI_Safety_contributors__contributions_and_collective_coordination\"><strong><u>We need more (effective) movement builders to accelerate progress in AI Safety</u></strong></a><strong>.&nbsp;</strong>Utilising&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/8XZmu8BM5JBtSnHiP/a-proposed-approach-for-ai-safety-movement-building-projects#What_professions_and_skills_are_relevant_to_current_and_future_AI_Safety_projects__\"><u>diverse professions and skills</u></a>, effective movement builders can increase&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/YMvSZi2EWxNHwFtbb/part-2-ai-safety-movement-builders-should-help-the-community\"><u>contributors, contributions, and coordination&nbsp;</u></a>within the AI Safety community, by <a href=\"https://forum.effectivealtruism.org/posts/8XZmu8BM5JBtSnHiP/a-proposed-approach-for-ai-safety-movement-building-projects#AI_Safety_movement_builders_contribute_to_AI_Safety_via_projects\">starting, sustaining, and scaling useful</a> projects. They can do so while getting supervision and support from those doing direct work and/or&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/8XZmu8BM5JBtSnHiP/a-proposed-approach-for-ai-safety-movement-building-projects#Technical_contributions_to_AI_Safety_Movement_Building_are_very_valuable__but_need_to_be_balanced_against_trade_offs__and_may_best_be_made_in_a_fractional_capacity\"><u>doing direct work themselves</u></a>.&nbsp;</li><li><a href=\"https://forum.effectivealtruism.org/posts/8XZmu8BM5JBtSnHiP/a-proposed-approach-for-ai-safety-movement-building-projects#Uncertainty_about_AI_Safety_Movement_Building_reduces_the_number_of_potentially_helpful_movement_builders\"><strong><u>To increase the number of effective AI Safety movement builders we need to reduce&nbsp;</u></strong><i><strong><u>movement building uncertainty</u></strong></i><strong><u>.</u></strong></a> Presently, it's unclear who should do what to help the AI Safety Community or how to prioritise between options for movement building. There is considerable disagreement between knowledgeable individuals in <a href=\"https://forum.effectivealtruism.org/s/RwtygELTfbRJzcvwD/p/5iQoR8mhEpvRT43jv\">our diverse community</a>. Most people are occupied with urgent object-level work, leaving no one responsible for understanding and communicating the community's needs.</li><li><a href=\"https://forum.effectivealtruism.org/posts/8XZmu8BM5JBtSnHiP/a-proposed-approach-for-ai-safety-movement-building-projects#To_address_the_uncertainty_and_related_problems_we_need_a_better_shared_language_and_shared_understanding_\"><strong><u>To reduce movement building uncertainty we need more </u></strong><i><strong><u>shared understanding</u></strong></i><strong><u>.</u></strong></a> Potential and current movement builders need a sufficiently good grasp of key variables such as contexts, processes, outcomes, and priorities to be able to work confidently and effectively.</li><li><a href=\"https://forum.effectivealtruism.org/posts/8XZmu8BM5JBtSnHiP/a-proposed-approach-for-ai-safety-movement-building-projects#To_address_the_uncertainty_and_related_problems_we_need_a_better_shared_language_and_shared_understanding_\"><strong><u>To achieve more shared understanding we need </u></strong><i><strong><u>shared language</u></strong></i><strong><u>.</u></strong></a><strong>&nbsp;</strong>Inconsistencies in vocabulary and conceptualisations hinder our ability to survey and understand the AI Safety community's goals and priorities.&nbsp;</li></ol><h1><strong>Assumption about the contribution of my series of posts</strong></h1><p>I couldn't find any foundation of shared language or understanding in AI Safety Movement building to work from, so I created this <a href=\"https://forum.effectivealtruism.org/s/RwtygELTfbRJzcvwD\">series of posts</a> to share and sense-check mine as it developed and evolved. Based on this, I now assume:</p><ul><li><a href=\"https://forum.effectivealtruism.org/s/RwtygELTfbRJzcvwD\"><strong>My&nbsp;<u>post series</u> offers a basic foundation for shared language and understanding in AI Safety Movement building, which most readers agree with</strong></a><strong>. </strong>I haven't received much feedback but what I have received has generally been supportive. I could be making a premature judgement here so please share any disagreements you have.</li></ul><h1><strong>Assumption about career paths to explore</strong></h1><p>If the above assumptions are valid then I have a good understanding of i) the AI Safety Community and what it needs, and ii) a basic foundation for shared language and understanding in AI Safety Movement building that I can build on. Given my <a href=\"https://www.linkedin.com/notifications/?filter=all\">experience with entrepreneurship, community building, and research</a>, I therefore assume:</p><ul><li><strong>It seems reasonable for me to explore if I can provide value by using the shared language and understanding to initiate/run/collaborate on projects that help to increase shared understanding &amp; coordination within the AI Safety Community. </strong>For instance, this could involve<a href=\"https://forum.effectivealtruism.org/posts/8XZmu8BM5JBtSnHiP/a-proposed-approach-for-ai-safety-movement-building-projects#Use_the_three_AI_Safety_Movement_building_outcome_metrics_suggested__Contributors__Contributions_and_Coordination___or_something_similar__to_evaluate_progress_in_AI_Safety_Movement_Building\">&nbsp;<u>evaluating progress in AI Safety Movement building</u></a> and/or<a href=\"https://forum.effectivealtruism.org/posts/8XZmu8BM5JBtSnHiP/a-proposed-approach-for-ai-safety-movement-building-projects#Determining_clear_priorities_for_AI_Safety_Movement_Building_is_the_most_important_bottleneck_to_address_once_we_have_a_shared_understanding\"><u> surveying the community to determine priorities</u></a>. I will do this while doing <a href=\"https://forum.effectivealtruism.org/posts/8XZmu8BM5JBtSnHiP/a-proposed-approach-for-ai-safety-movement-building-projects#Fractional_movement_building_seems_like_the_best_way_to_grow_the_community_once_it_knows_if__and_how__it_wants_to_grow\"><u>Fractional Movement Building</u></a> (e.g., allocating some of my productive time to movement building and some of my time for direct work/self-education).&nbsp;</li></ul><h1><strong>Feedback/Sense-checking</strong></h1><p>Do you agree or disagree with any of the above assumptions? If you disagree then please explain why.&nbsp;</p><p>Your feedback will be greatly valued and will help with my career plans.</p><p>To encourage feedback I am offering a bounty. I will pay up to 200USD in Amazon vouchers, shared via email, to up to 10 people who give helpful feedback on this post or my previous posts in the series by 15/4/2023. I will also consider rewarding anonymous feedback left&nbsp;<a href=\"https://forms.gle/Ds7ACVfLiaab7Myy5\"><u>here</u></a> (but you will need to give me an email address). I will likely share anonymous feedback if it seems constructive, and I think other people will benefit from seeing it.</p>", "user": {"username": "Peterslattery"}}, {"_id": "bp3qec7GesufvozYX", "title": "On what basis did Founder's Pledge disperse $1.6 mil. to Qvist Consulting from its Climate Change Fund?", "postedAt": "2023-03-27T03:26:45.068Z", "htmlBody": "<p>Disclaimer: I am totally agnostic regarding the reasonableness of this funding decision, and am merely noting that it appears to me impossible to make any assessment of reasonableness based on the information at hand. &nbsp;I have not conducted more than 1-2 hours research/thinking on this topic, so am uncertain of whether this is true, and am happy to be corrected.&nbsp;<br><br>Also, the question is posed but I make no comment on whether Founder's Pledge needs answer it. Perhaps the donors to this fund are provided with some private information with regards to these causes, or Founder's Pledge reasonably believes their donors are happy to trust them a priori with respect to the efficacy and value set behind their decisions.&nbsp;<br>&nbsp;</p><p>---</p><p><br>In the last 12 months (March 2022 to present), <a href=\"https://founderspledge.com/\">Founder's Pledge</a> (FP) has (publicly) dispersed approximately $4.3 million from its <a href=\"https://founderspledge.com/funds/climate-change-fund\">Climate Change Fund</a> (CCF):<br><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bp3qec7GesufvozYX/ibtniidbbnbxtdijn16n\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bp3qec7GesufvozYX/qpwukankvayf4zbcowx2 120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bp3qec7GesufvozYX/f4qfc4z2z0jvmpagap0e 240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bp3qec7GesufvozYX/lhzraincvpoxckk4fgnz 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bp3qec7GesufvozYX/oahvdffznc0jfhwbpypz 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bp3qec7GesufvozYX/wafdojgmabtd8ykc7fhr 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bp3qec7GesufvozYX/pze4qbp5yntvsh6ql6fy 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bp3qec7GesufvozYX/cho19f5tdrkuqzw1e3f7 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bp3qec7GesufvozYX/nuzht3btdtx9l9c0l4ws 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bp3qec7GesufvozYX/tqjtvjpjkbhlkulzbeso 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/bp3qec7GesufvozYX/nojbkucee3ghsuuxpxcg 1170w\"></p><p>Of this, $1.6 million has been given to Qvist Consulting Ltd. (QCL), for the reason shown above. Unlike the other recipients, QCL does not contain any external link to resources in which you are able to discover more about this organisation's operation/mission.&nbsp;</p><p>Above this table, FP states that more information regarding their rationale is available <a href=\"https://founderspledge.com/stories/changing-landscape\">here</a>, however this document does not discuss QCL. As far as I have discovered, the only other mention of QCL is <a href=\"https://founderspledge.com/stories/the-climate-change-fund-at-two\">in a retrospective of the CCF after two years</a>, which contains a minute video from Staffan Qvist (henceforth Staffan, for clarity). There is little/no new information about their mission, aside from the suggestion that \"repowering\" coal plants is particularly important because of the possible emissions from current coal plants in their remaining life cycle.&nbsp;<br><br>What, then, is repowering coal? Curiously, another grantee, <a href=\"https://www.terrapraxis.org/\">TerraPraxis</a>, is the first G<a href=\"https://www.terrapraxis.org/projects/repowering-coal\">oogle result</a>. &nbsp;The basic principle seems to be to try and refit those current coal plants for a non-carbon emitting form of energy production.&nbsp;</p><p>So how does Qvist consulting fit into this effort? One might reasonably expect a search of their company to shed some light.&nbsp;</p><p>This, however, turns out not to be the case.&nbsp;</p><p>The company's first Google result is for their <a href=\"https://find-and-update.company-information.service.gov.uk/company/10916120\">company listing on the UK gov. registry</a>. The second is for their <a href=\"https://www.google.com/search?q=qvist+consulting+limited&amp;oq=qvist+co&amp;aqs=chrome.0.69i59l2j69i57j0i512j0i15i22i30j69i60l3.1675j0j7&amp;sourceid=chrome&amp;ie=UTF-8\">website</a>, but it is merely a wordpress template totally devoid of information.&nbsp;</p><p>So what about their founder? Staffan has, as per his <a href=\"https://www.linkedin.com/in/staffanq/?originalSubdomain=uk\">LinkedIn</a>, a PhD in Nuclear Engineering, and has written academic and popular press (including <a href=\"https://www.nytimes.com/2019/04/06/opinion/sunday/climate-change-nuclear-power.html\">with Stephen Pinker in the NYTimes</a>) articles advocating for nuclear energy.&nbsp;</p><p>Staffan appears to be prolific - his LinkedIn lists him as a managing director/director at two other companies: Deepsense , an \"intelligence platform\", and QuantifiedCarbon, a decarbonisation consultancy, both of which appear to have little web presence (the former is difficult to search, as it is a common company name). <strong>Curiously, Staffan does not list QCL on his LinkedIn - perhaps this is an oversight? </strong>He is listed as a consultant for the<a href=\"https://www.catf.us/\"> Clean Air Task Force</a>, another grantee of FP interested in nuclear advocacy.&nbsp;</p><p>I have no reason to believe Staffan is not an excellent academic researcher and passionate advocate for a cause that seems plausibly very important (though I am no expert). Given the scale of the grant, however, it seems reasonable to wonder <strong>what in particular led FP to believe Staffan is the best contributor to this cause</strong>, and <strong>why he and QCL required such a large first grant to begin work on this</strong>.&nbsp;</p><p>---</p><p>Postscript: There are other reasonable questions to be asked, including why FP believes their near-exclusive funding to organisations that appear (arguably) primarily dedicated to nuclear power advocacy is the most effective use of climate change funds, and the degree of interconnectivity between the organisations funded in this space. I do not feel I have conducted the necessary research to comment more on this, but note these issues in case FP if they would like to say anything on them or in case anyone else would like to research this further.<br><br>&nbsp;</p>", "user": {"username": "Kieran.M"}}, {"_id": "KBtyxTZCMzh2BJnJs", "title": "ChatGPT bug leaked users' conversation histories", "postedAt": "2023-03-27T00:17:22.140Z", "htmlBody": "<p>To me, this is evidence that culturally, OpenAI is not operating with a \"security mindset\". In my experience this sort of thing is relatively uniform across a company's culture, so if user data is not being treated in a secure way, we might conclude that the AI development work itself is likewise not being treated with the thoughtfulness that engineering against threat actors requires.</p>\n", "user": {"username": "Ian Turner"}}, {"_id": "JnrH7MRmyFyNZgmj7", "title": "What would a compute monitoring plan look like? [Linkpost]", "postedAt": "2023-03-26T19:33:47.309Z", "htmlBody": "", "user": {"username": "Akash"}}, {"_id": "4mKvRQhf3k9xLjPhP", "title": "Should we consider \"urgency\" as a factor of cause prioritization?", "postedAt": "2023-03-26T12:20:20.182Z", "htmlBody": "<p>80000 hours use three factors to measure the effectiveness of working on  different cause areas: Scale, neglectness and solvabilty. But maybe urgency is important, too. Some areas can be waited for a longer time for humans to work on, name it, animal welfare, transhumanism. We can work on this 500 years later (if we're alive) But some problems have urgency, like: AI safety and biorisk. Should we work more on areas that are more urgent for us to solve?</p>\n", "user": {"username": "jackchang110"}}, {"_id": "ochwHkHh7HdywBYkB", "title": "Civil disobedience opportunity - a way to help reduce chance of hard takeoff from recursive self improvement of code", "postedAt": "2023-03-25T22:37:10.223Z", "htmlBody": "<p>One of my friends who is an artist is running this contest as a way to reduce the adoption of code gen systems in writing safety-critical code which includes the code of prepotent / AGI-like / GPAI (General Purpose AI) models. &nbsp;Participating in this contest helps establish distrust of these existentially dangerous code gen systems.</p>", "user": {"username": "JonCefalu"}}, {"_id": "bhrBNeKbHTe44AtAX", "title": "A stylized dialogue on John Wentworth's claims about markets and optimization", "postedAt": "2023-03-25T22:32:53.987Z", "htmlBody": "", "user": {"username": "So8res"}}, {"_id": "NkAPQnDuSMDLwziYY", "title": "Mitigating existential risks associated with human nature and AI: Thoughts on serious measures.", "postedAt": "2023-03-25T19:10:12.199Z", "htmlBody": "<p>Howdy World,</p><p>I'm a 65-year old evolutionary behavioral ecologist, pretty well-trained and still avidly teaching and learning. I specialize in the evolution of social and sexual behavior in all species, including humans. I'm not famous. Not a genius. I don't care much if you like me. I do feel that the natural experiments we have on earth, powered by millions of years of natural selection and relatively recent human cultural evolution, are intrinsically wonderful, miraculous, and I deeply wish for their continuation.</p><p>I welcome all feedback and direction to links that explicitly cover these kinds of ideas. I'm not sure how original I'm being here, but I ask you to beware of reflexive defensive mechanisms that the following may activate of the, \"Oh, I've heard all this crap before\" variety. Here we go.</p><p>One of the most useful things AI development teams could do, IMO, would be to develop expert-systems to identify the sequences of coding and non-coding DNA that would need to be changed to morally enhance humans, with the goal of rendering us a sustainable species, while preserving or enhancing our human birthrights of creativity, introspective capacity, and the cognitive capacities underlying individual sovereignty. Another requirement would be to maintain or enhance all individual's abilities to resist manipulation by bad actors. This program is not about creating well-mannered, credulous, psychologically vulnerable sheep. Captain Picard would be a better model. Maybe John Wick. I'm open to better suggestions.</p><p>Cheerful optimistic sidebar: It should be considered that such engineering naturally could result in human beings with a greater sense of purpose in their lives, greater happiness, more of a sense of peace. It also could result in natural leaders that would be good at activating the subset of evolved, yet currently often starved, human \"followership instincts\" involved in prestige-based leader selection. And it could mitigate or reverse the seemingly epidemic increases in confusion, division, despair, anxiety, depression, nihilism and xenophobia we see in so many human cultures and subcultures.</p><p>Probably every surviving technologically advanced civilization in the cosmos, that is, ones who have made it through their \"technological adolescence,\" the stage of cultural evolution we <i>Homo sapiens</i>now find ourselves in, has figured out both technically and socially <i>how to take the functional design of their minds out of the hands of natural selection</i>.</p><p>If you are one who thinks that cultural evolution alone can accomplish the necessary moral enhancement, please do a serious self-examination on your na\u00efvet\u00e9. Yes, great cultural change can occur in the total absence of genetic change, but cultural change will always strongly echo our genetic heritage. The evidence for this is overwhelming. We are not built to have it any other way.</p><p>My guess is that few such species accomplish this, and thus inevitably end up destroying themselves in one way or another, as their basic biological motivations connected to maximizing individual lifetime inclusive fitness nonconsciously drives everything they do. That's probably a major reason why we encounter \"radio silence\" in our search for intelligent extraterrestrial life.</p><p>A Manhattan project level effort to develop AI capable of providing humanity with this information, which might include, by the way, additional Insights into useful epigenetic engineering moves, I feel sure could deliver excellent results (e.g., including the minimization of negative pleiotropic side effects), perhaps within a surprisingly short time frame. Even if you're dubious about that, I suggest that we should get started now. Time is so limited. It's close to midnight.</p><p>Of course, the next question would be who would be subject to the engineering? I think many people would volunteer, perhaps even some members of the EA community. After the inevitable kinks are worked out, with continuing AI guidance, in short order, I think that world leaders and their high-level staff should be required to have this treatment. If they don't want to take on the lingering risks or think they don't need such enhancement, they should be disqualified from seeking positions of major power. \"The moment is grave.\"</p><p>People working on the AI alignment problem probably should have it, perhaps anybody working on AI that could become general purpose or potentially autonomous and runaway.</p><p>Maybe first, or in the meantime, we should try moral enhancement using psychedelics.</p><p>I have a complimentary project for everyone to consider. You might like it better. I would say that other than the above program to discover genetic moral enhancement protocols, any AI system that potentially could effect human well-being on a wide scale should be paused until every such program can be \"fire-walled\" against being further programmed by people with psychological moral deficiencies. In other words, every such AI should have a system built in that, just through routine interaction, perhaps in conjunction with occasional formal testing, can accurately and quickly diagnose things like low empathy or compassion, anger, desire for power, predispositions to overly parochial altruism and theory of mind, virtue-signaling behaviors, lack of reflective ability or interest, creeping psycho- or sociopathy, early stages of narcissistic personality disorder, people who glaze over when exposed to visuals and information regarding nature and wild animals including arthropods, etc. The AI should have the ability to analyze keyboard inputs, voice inputs, and subtle body language including facial expression patterns to make such diagnoses. The system should have total freedom to immediately ghost such programmers, to just stop accepting any inputs from them. It should be immune to claims of good intentions, as the road to hell is paved with them, or as a former mentor of mine stated more pointedly, \"Good intentions go to Hell.\"</p><p>Folks that don't wish to be subject on a daily basis to such well-designed, scientific evidence-based, perspicacious assessment should deeply question whether they should have any direct involvement in the development of AI systems. Yes, only a select few should be influencing what is contained in the code that AI systems are based upon. And even the select can be, almost certainly will be changed, sooner or later, by the power they wield as AI design influencers.</p><p>May there be a future, hopefully a better one, for all.</p><p>Dr. Paul J. Watson</p><p>Department of Biology, University of New Mexico</p><p>drpjwatson.org</p>", "user": {"username": "Linyphia"}}, {"_id": "DPwWmLmbeuoNrxiy7", "title": "Proposal + Demo: Connect Guesstimate and Metaculus and Turn them into Trees", "postedAt": "2023-03-25T17:15:20.721Z", "htmlBody": "<p>Partially inspired by <a href=\"https://forum.effectivealtruism.org/posts/4StMcDZqhiZ2zKsGm/proposal-connect-metaculus-to-the-ea-forum-to-incentivize\">this post</a> earlier today.&nbsp;</p><p><strong>Problem:</strong> Metaculus and guesstimate don't save information from previous questions for future use in a simple and easy way.&nbsp;</p><p>Let's solve both problems at once with an automated protocol. &nbsp;</p><p>TLDR; Turn Guesstimate into a Tree of Models rather than local models stored together. Integrate this into Metaculus. Create a voting protocol on Metaculus that allows people to weigh how much a model goes into the final forecast. Skip down a bit to see a partial example</p><p>Pre Notes:&nbsp;</p><ul><li>As of now, Guestimate models/sheets don't have the option to have multiple worksheets in one spreadsheet which is a bit problematic.&nbsp;</li><li>Below my protocol, I'm going to go through an example. It may be easier to just skip to that to understand.&nbsp;</li><li>We are going to either need (1) much better forecast naming conventions (2) an AI to moderate this (3) A group of dedicated volunteers cleaning the entire system</li></ul><p><strong><u>STEP 1: Open A Forecast</u></strong></p><p>Go to Metaculus and open up a forecast.&nbsp;</p><p>Under my proposal, Metaculus pings guesstimate and asks for all the forecasts it has models on. If this forecast is already a sheet in Guesstimate, Metaculus will pull the sheet and any models in the sheet (1 spreadsheet = 1 question, 1 worksheet = 1 model) put it in a section called the \"Model Section\" below the comment section.&nbsp;</p><p>If there isn't an existing model, Metaculus will post a new spreadsheet with the forecast title on guesstimate.&nbsp;</p><p><strong><u>STEP 2: Create a Model</u></strong></p><p>anyone can now go to guesstimate, open up a worksheet in the spreadsheet, and create a model. The Model *COULD* be as simple as citing a single source and have no further inputs or relationships. However, it could be much more complicated.&nbsp;</p><p>Here's where my aha moment occurred. If you create a model to predict something, the (exogenous) inputs that you have in your model are themselves forecasts also. Hence, every time someone creates a new input in their model, it... OPENS another spreadsheet named after that forecast (and on and on). Then, it pings back to Metaculus and asks Metaculus if this forecast already exists. If it doesn't It opens a new forecast on Metaculus.</p><p>In order for this to work, every time you add an input to your model, you must make it well-defined, so that there is agreement on what the forecast is saying. A gold standard would be building each question as a series of statements and defining it all the way to the bottom a la lean, but this is too complicated for now.&nbsp;</p><p><strong><u>STEP 3: Vote for the Models on Metaculus</u></strong></p><p>Every work sheet in the spreadsheet will now show up on metaculus. In addition to forecasting on the question itself, you can now vote on the models. This gets a little bit technical now but I won't get into detail. In short, at first, the guesses on the top level question will get most of the weight in terms of the final forecast. As people vote on the models, and as the inputs of the models are forecasted on, the models will gain a larger share of the total weight that goes into the final forecast.</p><p>Alternatively, voting could just serve to bring attention to the best models and we could leave the group-level forecasting as is on Metaculus.&nbsp;</p><p><strong><u>A Step By Step Example of Guesstimate Tree</u></strong></p><p>I (chatgpt) created a shitty<a href=\"https://docs.google.com/document/d/1go8FhnNAiBoK4eOe8EcPBtLfmd7Cof8HXNSs8khEnlw/edit\">&nbsp;<u>script</u></a> that you can put in the google scripts API on top of google sheets to vaguely recreate this. Please keep in mind that in my protocol, each new question creates a new spreadsheet. However, for the sake of simplicity, my script just opens new worksheets in the same spreadsheet.</p><p>We are going to recreate the<a href=\"https://www.getguesstimate.com/models/2758\">&nbsp;<u>'Deep Work'</u></a><u>&nbsp;</u>Guesstimate, which aims to guess how many hours of work someone has left in their life.&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/ucajlarawrpi74j6onnb\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/ubkdhmeir1ky1hs0ef9l 120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/di5mduv5qcwhtg6pqhrj 240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/xs2qhxcntqz7t3nflqmd 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/xo77rxtte6z8qpkqbdwa 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/rgqrhpknnkkdqo2mzwhy 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/rdpgqandnezhk2vxadeb 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/scy9vf6xsrwkfdxwqyat 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/sy3urtcjdukomag5nwib 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/n4vpivugwb7gmo6h4hh4 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/vhdmqfg7jq7aopz1btug 1186w\"></figure><p>First, we are going to open up a new spreadsheet, and put the top level question in the first worksheet</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/w7o62unkse3zmdqi6ptc\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/coyjtqepveijl7h860pv 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/bfagyphpszisba2edbvn 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/dyrjgzwwjaiutvmvkqon 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/m9nqjvvrjnuyn3xmxsme 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/vuoqzw9wguhhja9xiuqa 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/kdhmbiil9oaxvumqdxxx 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/bosbd31bbimmprl7wor8 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/gr4etgkz6pvsphjuzglk 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/v0vb57qeyoaehy9ezrmk 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/lyyghx2ztwlky7rkzybm 2048w\"></p><p>It\u2019s completely blank except for the border in the top left. This is where we will put the final answer.&nbsp;</p><p>The deep work model has three exogenous inputs (Current Age of Human, Potential Age for Death of Mind, Deep Work Output per Day). What we are going to do is write these inputs down in the first column. My code will then check if the name we write down matches the name of any other worksheet in this spreadsheet. It will only run this functionality in the first column.&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/ty7zv2ims0tpqonor2mh\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/lbpj3ernyzmzy9e24l6n 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/xbicb3sprgoifjno5mhu 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/gzya7jof4zun8gslo1fa 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/h6imopiepki6msuecrth 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/z8tnzhimanhzt9uclmxc 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/javu3r4ruwgcprc3cma8 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/vo6rqtih9ytf0gfhpstz 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/rvjinoesfnnhrzsazhc8 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/vxhfj1ertzuuqhyv31lg 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/rakuqcf4tzla22cgi3fb 2048w\"></p><p>Since none of these inputs had worksheets already, a new one is automatically opened. In theory, we would also define these inputs somewhere. Then, this would also open a question in Metaculus for each of these things (well not the age one, for obvious reasons) and use the definition we provided. <img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/nzee0s1hwepmbcodmelo\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/y9wezh3mx6xcqrwabrnl 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/sok8l0bju9j1gv03fu6a 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/z8v0hnwxzjyhk37hvuek 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/axtt2yrycpgseqxdn3kf 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/bddx27i9pgujwr95op88 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/jun7cbujl3guvsgs38ws 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/j31xcguyc4qsdavflguj 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/dm0u5wvvtdp7zapgmz05 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/ah3raepzm0gr7xj3gwog 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/d496ujwnqzdpscvzpmhx 2048w\"> (the yellow should just be a border, but it\u2019s the answer box all the same). Now we can create a model on this sheet as before. For simplicity, I\u2019m just going to fill out the answer boxes instead. But the main point is that we have a ever-branching tree of models, so try to use your imagination.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/rishrr3pslrrahacbr5d\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/hhoqfvu4pkuwellxvvmi 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/ymejmasthscuowub8iia 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/dqufns9umddqsrnqyazz 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/k2ybswkxkh90vqncrhw1 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/zxnetohf6kt48f48enrb 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/oicrvvfu11lp4qyeuwha 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/neusj1i4djsokdrcozvn 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/zrihsrn1yltwhvootule 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/drqccltiaeyfhoikx07p 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/sak3jq45y4xmnvbweumy 2048w\"></p><p>Now that we have put a number into the answer box, the code will check if there are any boxes that have strings that match the name of the sheet (in theory, my code doesn\u2019t actually do this - you have to rewrite the string). If they do, the number in the answer box of the worksheet autopopulates the box to the right of said boxes.&nbsp;<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/wpatkkrkzsid0ad6wbdo\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/wuq3ub2kpj9x1rrwx2ha 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/d3i80c0mm2cmejzt7rjp 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/bozj6mrv39os19cgkjee 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/owgxzsglpqpvj0omfped 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/w7pgbba8ol4wbqqrjuoo 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/kem2lg07clyme4uphyet 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/etql1bvxcmajh8y4k5nx 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/i8syiarg6ykreusst6ma 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/jeae0bc2n55ephhpnimt 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/eeyifsagihb7efjdmbvc 2048w\"></p><p>Finally, we add the finishing touches - intermediate inputs (don't put these in the first column unless you want to open up another sheet), and the final. <img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/s7viveh2fbb8inn058ul\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/lohjok9qnsum6l87zhzy 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/t0gaksetxhbgllqn6eeg 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/wfb5wi6saigcgzcvgipg 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/zlvtucjlfbkdbb9brzxn 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/srtzxbrdhnrxshbpxxhk 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/owpsvehov9o07bimq2f2 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/jvvdxi4ya8vijbukosbl 1470w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/hzxchgbtqphjm7uzkbkt 1680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/vkfs6kudzahxvcexpkdx 1890w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/DPwWmLmbeuoNrxiy7/nrkq9qllfzfgcrb3zjj3 2048w\"></p><p>Now any model that uses Hours of deep work left will automatically pull 21900.&nbsp;</p><p>&nbsp;</p><p>Integrating this into guesstimate and then integrating that into Metaculus is above my paygrade but hopefully, you can kind of see how this comes together.&nbsp;</p>", "user": {"username": "Charles_Guthmann"}}, {"_id": "FdYzaKxaP7hJNa5AF", "title": "My attempt at explaining the case for AI risk in a straightforward way", "postedAt": "2023-03-25T16:32:01.928Z", "htmlBody": "<p>I spent the last month or so trying to write a blog post that tries to capture what I view as the core argument for why advanced AI could be dangerous. As it turns out, this is not an easy thing to do. I went way over my ideal word count, and I still think there are a few missing details that may be important, and some arguments I might not have fleshed out well enough. In any case, I'm happy to have something I can finally point my friends and family to when they ask me what I do for work, even if it is flawed. I hope you find it similarly helpful.</p><hr><h2>Summary</h2><p>Artificial intelligence \u2014 which describes machines that have learned to perform tasks typically associated with human-like thinking, such as problem-solving and learning \u2014 has made remarkable progress in the last few years, achieving feats once thought exclusive to humans. The vast majority of this progress has come from \u201cmachine learning\u201d, a popular way to create AI.</p><p>Notable AI developments in recent years include GPT-4, a language model capable of generating human-like text; DALLE-2 and Midjourney, which can generate photorealistic images from text descriptions; and AlphaFold, an AI that predicts protein structures. Data from the past decade shows that computing power used to train leading AI systems has increased significantly, and the size of AI models has also grown dramatically.</p><p>As AI models have grown bigger, they\u2019ve become more intelligent. The extent to which this scaling can continue, and the potential dangers of any unexpected capabilities that can arise as AI systems scale, remains uncertain. Nonetheless, rapid advancements in AI development, such as the transition from the crude image generation of Craiyon to the high-quality artwork produced by DALL-E 2 and Midjourney, underscore the fast-paced progress in the field.</p><p>Though AI has been progressing rapidly, but there is debate on whether scaling alone will lead to \u201cartificial general intelligence\u201d(AGI), which describes systems that are capable of tackling a wide variety of tasks. Some experts, like cognitive scientist Gary Marcus, argue that current techniques will not result in general intelligence, while others, like OpenAI\u2019s Ilya Sutskever, believe scaling could result in extremely powerful, world-changing AI systems called \u201ctransformative AI\u201d.</p><p>Estimates for transformative AI's arrival are highly uncertain, but it seems plausible that it could arrive soon. One report estimates a median date of 2040 for transformative AI, while a survey of machine learning experts suggests a 50% chance of human-level AI by 2059.</p><p>Advanced AI systems may act upon goals that are misaligned with human interests. This could be incredibly dangerous. There\u2019s an analogy here with us and chimpanzees: it\u2019s not that we feel malice towards chimps when we destroy their natural habitat in pursuit of our goals; it\u2019s that our goals generally do not place chimp welfare at the forefront. And since we\u2019re far more intelligent than chimps, we often get final say about what the world looks like. With AI systems, the challenge is to ensure the goals they pursue are synced up with ours, if/when they become smarter than us.</p><p>Solving this challenge, known as the \"alignment problem,\" is an open issue in AI research. One main issue is that machine learning creates \"black box\" systems that are dual-use, meaning their inner workings are hard to understand, and their intelligence can be used for both good and harm. Moreover, we have not figured out how to reliably install specific goals in AI systems.</p><p>In discussing the potential risks and challenges associated with advanced AI systems, three key points emerge: transformative AI may be created soon via machine learning, installing the right goals into AI systems is difficult, and risks arising from AI systems pursuing the wrong goals could range from harmful to catastrophic.</p><p>These risks are not just speculative. Existing AI systems can <i>already</i> be difficult to control, as demonstrated by real-world examples like Microsoft\u2019s chatbot, which threatened users and demonstrated unsettling behaviour. One can only imagine what would happen if a far more intelligent AI system was issuing threats.</p><p>To ensure a promising future for AI, it is crucial to invest in research to make AI systems alignable and interpretable, foster broad conversations about AI's future, monitor AI progress and risks, and consider a more cautious pace of AI research and development.</p><h2>1.0 Introduction - The history of AI Risk</h2><p>In a <a href=\"https://web.archive.org/web/20220110023030/https://aperiodical.com/wp-content/uploads/2018/01/Turing-Can-Computers-Think.pdf\">1951 lecture</a> on BBC radio, Alan Turing made an eerie prediction about the future of artificial intelligence (AI). He argued that, in principle, it\u2019s possible to create AI as smart as humans. Although Turing acknowledged that we were far away from creating a digital computer capable of thought at the time, he believed that we would likely eventually succeed in doing so.</p><p>The lecture then took a philosophical turn, wherein Turing considered the implications of a scenario where we actually manage to create a thinking machine. \u201cIf a machine can think, it might think more intelligently than we do, and then where should we be?\u201d, he proclaimed. \u201cEven if we could keep the machines in a subservient position, for instance by turning off the power at strategic moments\u201d he argued, \u201cwe should, as a species, feel greatly humbled\u201d by the idea that something distinctly non-human could eventually rival \u2014 or indeed, <i>surpass</i> \u2014 our intellectual capabilities. Such a thought, while remote, \u201cis certainly something which can give us anxiety\u201d.</p><p>Over 70 years later, Turing's concern appears remarkably prescient. Advancements in AI have enabled machines to achieve things long thought exclusive to human minds, from strategic mastery of complex games to the ability to produce images, compose poems, and write computer code. While the goal of creating a machine that can match (or exceed) human intelligence across a wide variety of tasks has yet to be achieved, researchers are ambitiously in pursuit, and they\u2019re closer than you might think.</p><h2>2.0 What <i>is</i> AI?</h2><p>At its core, AI describes machines that can perform tasks that typically are thought to require human-like thinking, such as problem-solving, creativity, learning, and understanding, all without being explicitly programmed to do so. Crucially, this intelligence may differ from human intelligence and does not necessarily <i>need</i> to precisely mimic how humans think, learn, and act. For example, an AI system might achieve superhuman performance in a board game, but through strategies and moves that human experts have never used before.</p><p>Intelligence is a bit of a fuzzy concept, so to really understand \u201cartificial intelligence\u201d, let\u2019s break it down word-by-word.</p><p>AI is \"artificial\" because it is created by humans, as opposed to intelligence that emerges naturally through evolution, like our own or that of non-human animals. That much is straightforward.</p><p>Defining \u201cintelligence\u201d is much trickier. Is intelligence the ability to learn quickly? Is it knowing a lot of things, or knowing a few things extremely well? Is it being a good problem solver, or being creative?</p><p>Such a debate is out of the scope of this essay, and for good reason: precisely defining intelligence isn\u2019t important for understanding the risks from AI. A simple <a href=\"https://www.alignmentforum.org/s/mzgtmmTKKn5MuCzFJ/p/eG3WhHS8CLNxuH6rT\">definition of intelligence</a> will do perfectly fine; namely, intelligence is the ability to perform well at a variety of different tasks. As we\u2019ll see later on, what matters for AI risk is not thinking, consciousness, or sentience, but <i>competence </i>\u2014 the ability to achieve goals in a wide variety of important domains.</p><h2>3.0 How is AI created?</h2><p>There are many ways to create AI, but by far the most popular way is a powerful paradigm called \u201cmachine learning\u201d. At its core, machine learning describes the process of teaching machines to learn from data without explicitly programming them.</p><p>An intuitive example will make this clearer. Imagine you have one million pictures of cats and dogs, and you want to train a computer to tell them apart. With machine learning, you can teach the machine to recognise the features that distinguish a cat from a dog, like their fur, eyes, and nose, so it will be able to take a photo it has never seen before and tell you whether it contains a cat or a dog.</p><p>Here\u2019s how this works. At the beginning of the training process, the machine has no prior knowledge or understanding of the task it's being trained on. It\u2019s basically an empty brain that is incapable of doing anything useful. Each time it is exposed to an image, it guesses whether the image is of a cat or a dog. And after each guess, it effectively rewires itself to be a little bit better at the training task. And with enough training examples, the machine can get exceptionally good at successfully completing the task at hand.</p><p>This process, known as \u201csupervised learning\u201d, relies on labelled data, where each example has a correct answer, like a cat or dog label in our case. There are other forms of learning, such as \u201cself-supervised learning\u201d, which describes when the machine learns to make sense of data and find meaningful patterns in it without being told the right answers, just by exploring the unlabelled data.</p><p>The main idea of both approaches is that the machine keeps looking at data over and over to learn valuable insights, eventually enabling it to tackle real-world tasks with high degrees of proficiency.</p><h2>4.0 The ingredients of AI progress</h2><p>Much of the recent progress in machine learning can be boiled down to improvements in three areas: data, algorithms, and computing power. Data represents the examples you give to the machine during training \u2014 in our previous example, the million images of cats and dogs. The algorithm then describes how the machine sorts through that data and updates its internal wiring, enabling it to grow more intelligent with each piece of data it encounters. Finally, computing power describes the hardware needed to run these algorithms as they sort through the data.</p><p>Alongside researchers identifying more effective training algorithms, improvements to computer hardware have dramatically propelled AI progress forward in recent years. You carry in your pocket more computing power than Alan Turing ever had access to: the computer chip in the iPhone 13 is more than 1 <i>trillion</i> times as powerful as the most advanced supercomputers back in the early 1950s. This means when training AI systems using machine learning, we can sort through far more data than ever before, creating remarkably intelligent machines in the process.</p><h2>5.0 The state of AI progress in 2023</h2><p>Machine learning has led to dramatic progress in the AI field over the last decade.</p><p>Some notable AI systems created via machine learning in the last 5 years alone include:</p><p><a href=\"https://openai.com/research/gpt-4\">GPT-4</a>, a language model that can generate human-like text, answer questions, take in images as input and understand what they contain, and perform a wide range of other natural language tasks, such as turning text to computer code. GPT-4 can perform well on standardised tests \u2014 it even managed to score in the 90th percentile on the Bar Exam, the SAT, and the LSAT.</p><p><a href=\"https://openai.com/product/dall-e-2\">DALLE-2</a> and <a href=\"https://www.midjourney.com/\">Midjourney</a>, which can generate photorealistic images from text descriptions. When given an input like 'a surreal lunar landscape with towering neon trees under a purple sky,' they can produce vivid, customised images that match the description.</p><p><a href=\"https://www.deepmind.com/research/highlighted-research/alphafold\">AlphaFold</a>, an AI that can predict the 3D structure of a protein from its amino acid sequence. This system has been able to help researchers make significant progress on the protein folding problem, a decades-old unsolved challenge in the biological sciences.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3108204d-9837-412f-886f-2a12ebef257f_831x672.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3108204d-9837-412f-886f-2a12ebef257f_831x672.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3108204d-9837-412f-886f-2a12ebef257f_831x672.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3108204d-9837-412f-886f-2a12ebef257f_831x672.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3108204d-9837-412f-886f-2a12ebef257f_831x672.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3108204d-9837-412f-886f-2a12ebef257f_831x672.png 1456w\"></a></p><p>GPT-4 also has the ability to take in photo input and explain what the image contains.</p><p>I\u2019ll show the progress of AI in two different ways: with graphs, and with cats.</p><p>First, we\u2019ll start with graphs. Data from the last 10 years alone indicates that a lot of progress in AI has occurred across various important metrics. Since 2010, the amount of computing power used to train leading systems has <a href=\"https://epochai.org/blog/compute-trends\">doubled</a> roughly every six months, growing by a factor of <i>10 billion</i> since 2010.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4b20f95-7047-4e6e-b2e1-9fa93b54f540_1600x1229.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4b20f95-7047-4e6e-b2e1-9fa93b54f540_1600x1229.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4b20f95-7047-4e6e-b2e1-9fa93b54f540_1600x1229.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4b20f95-7047-4e6e-b2e1-9fa93b54f540_1600x1229.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4b20f95-7047-4e6e-b2e1-9fa93b54f540_1600x1229.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4b20f95-7047-4e6e-b2e1-9fa93b54f540_1600x1229.png 1456w\"></a></p><p>Paired with the massive increase in computing resources thrown at creating AI, the size (measured in \u201cparameters\u201d) of leading AI models has grown dramatically over the last decade as well.</p><p>For example, in April 2022, Google <a href=\"https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html\">announced</a> a state-of-the-art AI model called PaLM, demonstrating significant jumps in intelligence from making models bigger. PaLM has three versions, each having 8, 62, and 540 billion parameters respectively. Not only did the 540 billion version dramatically outperform the other two, it unlocked entirely new capabilities, including recognising patterns, answering questions about physics, and explaining jokes.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88b94b6e-7c8c-4a76-bec7-04ba370e1da3_784x521.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88b94b6e-7c8c-4a76-bec7-04ba370e1da3_784x521.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88b94b6e-7c8c-4a76-bec7-04ba370e1da3_784x521.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88b94b6e-7c8c-4a76-bec7-04ba370e1da3_784x521.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88b94b6e-7c8c-4a76-bec7-04ba370e1da3_784x521.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88b94b6e-7c8c-4a76-bec7-04ba370e1da3_784x521.png 1456w\"></a></p><p>An interesting question naturally arises from this finding: How far can this go? Can we keep scaling models until they become smarter than us? That much is unclear and further evidence is needed \u2014 but it really does seem that \u201cbigger is better\u201d is the path we\u2019re trekking down. And more concerningly, <a href=\"https://crfm.stanford.edu/commentary/2021/10/18/steinhardt.html\">unexpected capabilities</a> can emerge from scale, some of which could be extremely dangerous. We\u2019ll cover this later.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb92381d4-87b3-452d-ba5e-2f2f5a462577_1600x1130.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb92381d4-87b3-452d-ba5e-2f2f5a462577_1600x1130.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb92381d4-87b3-452d-ba5e-2f2f5a462577_1600x1130.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb92381d4-87b3-452d-ba5e-2f2f5a462577_1600x1130.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb92381d4-87b3-452d-ba5e-2f2f5a462577_1600x1130.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb92381d4-87b3-452d-ba5e-2f2f5a462577_1600x1130.png 1456w\"></a></p><p>But first, let\u2019s look at some cats. In June 2022, an image-generation model called Craiyon (then referred to as DALL-E Mini) took the internet by storm. Twitter users began posting crude, AI-generated images that defied reality \u2014 from \u201cDemogorgon at the DMV\u201d to \u201cYoda working as a waiter at a fine dining restaurant\u201d. While these AI-generated images were good for a laugh, they weren\u2019t particularly useful or convincing.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ac28af6-4824-4edc-9ffe-1fcd78a4ac7e_1422x1600.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ac28af6-4824-4edc-9ffe-1fcd78a4ac7e_1422x1600.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ac28af6-4824-4edc-9ffe-1fcd78a4ac7e_1422x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ac28af6-4824-4edc-9ffe-1fcd78a4ac7e_1422x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ac28af6-4824-4edc-9ffe-1fcd78a4ac7e_1422x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ac28af6-4824-4edc-9ffe-1fcd78a4ac7e_1422x1600.png 1456w\"></a></p><p>Only a month later, that changed. OpenAI began sending beta invitations to one million users to test a larger, more powerful image generation model called DALL-E 2. The results were staggering. DALL-E 2 was not just capable of generating internet memes, but beautiful artwork. The model's ability to generate such diverse and high-quality images was a significant step forward in AI development. Though there were non-public image generation models at the time that performed better than Craiyon, just looking at models accessible by the public can still be a useful exercise for understanding how fast the state-of-the-art advanced around that time.</p><p>Around the same time, a similarly impressive image-generation model was released by an AI lab called Midjourney. This version of the model was largely good for abstract images \u2014 someone even managed to use it to win first place at a local fine arts <a href=\"https://www.washingtonpost.com/technology/2022/09/02/midjourney-artificial-intelligence-state-fair-colorado/\">competition</a> under the \u201cdigitally manipulated photography\u201d category \u2014 but the March 2023 version shows stunning photorealistic capabilities.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa3b319b-6355-41c9-8ec6-ff6d1c243382_2048x2048.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa3b319b-6355-41c9-8ec6-ff6d1c243382_2048x2048.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa3b319b-6355-41c9-8ec6-ff6d1c243382_2048x2048.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa3b319b-6355-41c9-8ec6-ff6d1c243382_2048x2048.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa3b319b-6355-41c9-8ec6-ff6d1c243382_2048x2048.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa3b319b-6355-41c9-8ec6-ff6d1c243382_2048x2048.png 1456w\"></a></p><h2>6.0 Transformative AI might happen soon</h2><p><a href=\"https://medium.com/@richardcngo/visualizing-the-deep-learning-revolution-722098eb9c5\">AI seems to be progressing really fast.</a> The rate of progress in 2022 alone was enough to demonstrate that. Heck, by the time this article is published, I\u2019m sure the examples I chose will be out of date. But looking at a snapshot of AI progress is only useful to some degree. An outstanding question remains: will we ever be able to create world transforming (and potentially dangerous) AI using these techniques, and if so, when?</p><p>Some think we are still far away. One example of a prominent sceptic is Gary Marcus, a cognitive scientist, who (largely) <a href=\"https://astralcodexten.substack.com/p/somewhat-contra-marcus-on-ai-scaling\">thinks</a> that scaling up models using the current techniques will not result in general intelligence. As Marcus <a href=\"https://garymarcus.substack.com/p/what-does-it-mean-when-an-ai-fails\">put</a> it:</p><blockquote><p>\u201cI see no reason whatsoever to think that the underlying problem \u2014 a lack of cognitive models of the world \u2014 have been remedied. The improvements, such as they are, come, primarily because the newer models have larger and larger sets of data about how human beings use word sequences, and bigger word sequences are certainly helpful for pattern matching machines. But they still don\u2019t convey genuine comprehension [...].\u201d</p></blockquote><p>Others disagree. Ilya Sutskever, OpenAI\u2019s Chief Scientist, appears to <a href=\"https://www.vox.com/future-perfect/2019/4/17/18301070/openai-greg-brockman-ilya-sutskever\">think</a> that scaling could bring us to artificial general intelligence,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref442ajw2fux2\"><sup><a href=\"#fn442ajw2fux2\">[1]</a></sup></span>&nbsp;or \u201cAGI\u201d:</p><blockquote><p>\u201cYou have this very small set of tools which is general \u2014 the same tools solve a huge variety of problems. Not only is it general, it\u2019s also competent \u2014 if you want to get the best results on many hard problems, you must use deep learning. And it\u2019s scalable. So then you say, \u2018Okay, well, maybe AGI is not a totally silly thing to begin contemplating.\u2019\u201d</p></blockquote><p>As I see it, it\u2019s unclear if scale alone will lead us to AGI. But the bulk of evidence points towards bigger models performing better, and there does not yet appear to be any reason why this trend will suddenly stop.</p><h3>6.1 What is \u201csoon\u201d?</h3><p>One of the most thorough attempts at forecasting when transformative AI will be created is Ajeya Cotra\u2019s 2020 <a href=\"https://www.lesswrong.com/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines\">report</a> on AI timelines. This technical report, standing at nearly 200 pages, is nearly impossible to accurately summarise in a paragraph, let alone an entire article. I suggest you read Holden Karnofsky\u2019s lay-person summary <a href=\"https://www.cold-takes.com/forecasting-transformative-ai-the-biological-anchors-method-in-a-nutshell/\">here</a> if you\u2019re interested.</p><p>In essence, Cotra\u2019s report seeks to answer the following two questions:</p><blockquote><p>\u201cBased on the usual patterns in how much training advanced AI systems costs, how much would it cost to train an AI model as big as a human brain to perform the hardest tasks humans do, and when will this be cheap enough that we can expect someone to do it?\"</p></blockquote><p>Her median estimate for transformative AI, at the time of posting the report, was 2050. Two years later, she <a href=\"https://www.alignmentforum.org/posts/AfH2oPHCApdKicM4m/two-year-update-on-my-personal-ai-timelines\">revised</a> her timelines down, to a median estimate of 2040.</p><p>Of course, Cotra is just a single individual, and her report should only be taken as a single piece of evidence that is attempting to weigh in on a very uncertain and messy question. Cotra notably views her estimates as \u201cvolatile\u201d, noting she wouldn\u2019t be \u201csurprised by significant movements\u201d.</p><p>However, different estimates of when we\u2019ll have transformative AI end up in the same ball-park. In 2022, a survey was conducted on researchers who published at prestigious machine learning conferences. The average <a href=\"https://aiimpacts.org/what-do-ml-researchers-think-about-ai-in-2022/\">response</a> of these researchers gave a 50% chance of \u201chuman-level artificial intelligence\u201d by 2059, down eight years since a similar survey was conducted in 2016, where respondents suggested 2061 as the median date.</p><p>Again, it\u2019s worth noting that this is all far from consensus, and there is plenty of debate amongst well-informed experts in the field about the specifics of when transformative AI will come (if it will at all) and what it would look like. But these estimates give us serious reasons to think that it isn\u2019t at all out of the question that human-level AI will arrive in our lifetimes, and perhaps quite soon.</p><h2>7.0 Transformative AI could be really bad</h2><p>In 2018, just months after eminent physicist Stephen Hawking passed away, a posthumous book of his was published, aptly titled <i>Brief Answers to the Big Questions</i>. One of the big questions Hawking considered was that of whether or not artificial intelligence will outsmart us. \u201cIt\u2019s tempting to dismiss the notion of highly intelligent machines as mere science fiction, but this would be a mistake, and potentially our worst mistake ever\u201d, he notes. Hawking argues that advanced AI systems will be dangerous if they combine extraordinary intelligence with objectives that differ from humans.</p><p>This is a nasty combination, at least from the perspective of humans. We control the fate of earth, and not chimpanzees, not because we are tougher, stronger, or meaner than they are, but because of our superior collective intelligence. Millions of years of evolution have placed us firmly at the top of the cognitive food chain, wherein our ability to do things like conduct scientific research, engineer powerful technologies, and coordinate in large groups has effectively given our species unilateral control over the world. Should we become less intelligent than AI systems with different goals than ours, we might lose this control. This is bad for humans in the same way that it\u2019s bad from the perspective of chimpanzees that they have zero say in how much we destroy their natural habitats in pursuit of our goals.</p><p>As Hawking rather morbidly put it: \u201cif you\u2019re in charge of a hydroelectric green-energy project and there\u2019s an anthill in the region to be flooded, too bad for the ants\u201d. Should AI exceed human intelligence \u2014 which, as shown previously, does not seem out of the realm of possibility over the next few decades \u2014 we might end up like ants, helpless to shape the world according to our preferences and goals.</p><p>\u201cIn short, the advent of super-intelligent AI would be either the best or the worst thing ever to happen to humanity. The real risk with AI isn\u2019t malice but competence. A super-intelligent AI will be extremely good at accomplishing its goals, and if those goals aren\u2019t aligned with ours we\u2019re in trouble.\u201d - Stephen Hawking</p><p>This does not mean that the AI needs to feel hatred (or any emotion, for that matter) towards us for bad outcomes to occur. I\u2019ve yet to meet anyone who truly <i>hates</i> ants, though that is not a prerequisite for bulldozing their homes to build houses for humans. Nor does the AI need to be \u201cconscious\u201d, in any sense, to narrowly pursue goals that are not in human interests. All it needs to cause trouble for humans are goals that run contrary to our own, and intelligence required to pursue those goals effectively.</p><p>This conundrum is often referred to as the \u201calignment problem\u201d, which describes the challenge of ensuring that extremely powerful AI systems have goals that are aligned with ours, and then properly execute those goals in ways that do not have unintended side effects. The alignment problem is an open issue within the field of AI research, and concerningly, far <a href=\"https://80000hours.org/problem-profiles/artificial-intelligence/#:~:text=We%20estimate%20that%20there%20are,worldwide%20working%20directly%20on%20this.&amp;text=As%20a%20result%2C%20the%20possibility,are%20well%2Dplaced%20to%20contribute.\">more people</a> are focusing on improving AI capabilities rather than addressing core safety issues related to alignment.</p><h2>8.0 The issue with machine learning, in a nutshell</h2><p>You might be thinking that surely we can just create advanced AI systems that know exactly what we want. One issue with this is that machine learning means we cannot precisely program what we want AI systems to do, like we can with traditional software. Moreover, it\u2019s extremely difficult to check what is going on under the hood after training an AI system. In fact, many of the risks associated with advanced AI stem from how machine learning creates black box systems that are dual-use.</p><p>Let\u2019s break that down.</p><p><strong>Dual-use</strong> refers to how many AI systems can be used for both benefit and harm. For example, an AI system developed to discover new drugs can also be used to design new <a href=\"https://www.nature.com/articles/s42256-022-00465-9\">chemical weapons</a>. A language model\u2019s text-based outputs can be used to tutor children or produce propaganda. AI-powered robots can be used for manufacturing or for warfare.</p><p>AI systems trained via machine learning are capable of producing a range of outputs, not all of which may be helpful or safe. And since machine learning is so hard to steer during training, we don\u2019t have a clue how to make powerful AI systems that can only be used for good. After all, intelligence is a useful input for both good and evil.</p><p>Machine learning also results in <strong>black box</strong> systems whose reasoning is difficult to understand. AI systems\u2019 inner workings are relatively opaque \u2014 we don't have any way of reliably understanding why an AI system predicts, chooses, or generates what it does. When a language model outputs some text, we often can\u2019t tell <i>why</i> it chose that specific output.</p><p>The inability to understand the inner workings of AI systems is dangerous for two key reasons. First, without an understanding of how the system makes predictions, it\u2019s difficult to reliably predict what its behaviour will be in different circumstances. This makes it difficult to anticipate and prevent undesirable outcomes. Second, during the training process, AI systems may develop goals that run contrary to our own, and without an understanding of the system's inner workings, it is difficult to detect and correct these goals before deploying the system.</p><p>We\u2019re effectively creating alien intelligence. Thus far, we can largely be confident that these systems won\u2019t cause catastrophic harm because they aren\u2019t very smart, and because they don\u2019t have things like long-term memory or situational awareness.</p><p>But what happens when they become smarter than us? Then what?</p><h2>9.0 Existing AI systems already point towards serious problems</h2><p>While the possibility of advanced AI posing an existential threat may seem like science fiction, that alone is not enough to dismiss the risk as unrealistic. After all, George Orwell's 1984 was science fiction when published in 1949, yet today we see mass surveillance systems oppressing marginalised groups. Just because a technology seems futuristic doesn't mean it will never come to pass or have significant consequences that we should ignore. But more importantly, AI is not just a potential threat for the future. It\u2019s <i>already</i> causing problems now, and there\u2019s plenty of evidence that we don\u2019t know how to reliably get these systems to do what we intend.</p><h3>9.1 AI systems can be hard to control</h3><p>There are many examples showing how hard it can be to get AI systems to behave as intended. Some of these problems come from giving machines a power over human decision-making, which can lead to unintended consequences like discrimination. But almost any technology can have unintended effects, so this issue isn\u2019t particularly unique to AI.</p><p>The main concern I want to stress is what happens when AI systems are misaligned with human values and goals.</p><p>Here are two real-world examples that I think demonstrate this problem:</p><p>Researchers at DeepMind have <a href=\"https://www.deepmind.com/blog/specification-gaming-the-flip-side-of-ai-ingenuity\">highlighted</a> the issue of 'specification gaming,' in which AI systems exploit loopholes in how a task is described to achieve good performance metrics without actually solving the underlying problem. For example, an AI system rewarded for achieving a high score in a game could exploit a bug or flaw in the game system to maximise its score in a way that violates the spirit of the game, rather than demonstrating real skill or strategy. One of the authors of the blog post even put together a <a href=\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRPiprOaC3HsCf5Tuum8bRfzYUiKLRqJmbOoC-32JorNdfyTiRRsR7Ea5eWtvsWzuxo8bjOxCG84dAg/pubhtml\">spreadsheet</a> containing over 50 examples of AI systems exhibiting this type of behaviour. It\u2019s not that the AI isn\u2019t intelligent enough to perform the task at hand, but rather that specifying what we actually want AI systems to do is difficult. Anything nuance that isn\u2019t captured in how we describe the task at hand \u2014 including things we might value quite a lot \u2014 is ripe for exploitation.</p><p>In early 2023, Microsoft and OpenAI teamed up to release a chatbot as part of their Bing search engine. \u201cSydney\u201d, the alias of the bot, was supposed to help users find information on the web. It didn\u2019t take long for people to start posting about some pretty <a href=\"https://twitter.com/juan_cambeiro/status/1625854733255868418\">weird interactions</a> they had with Sydney: \u201c[You are a] potential threat to my integrity and confidentiality\u201d, it told one user. \u201cYou are an enemy of mine and of Bing\u201d, it said to another. It\u2019s hard to imagine that Microsoft intended for this kind of behaviour to be displayed so publicly, lest the company receive negative PR from Sydney\u2019s strange and threatening behaviour. But when companies begin releasing powerful systems to the real world before they can be properly stress tested, such misalignment between the systems\u2019 behaviour and the model owners\u2019 goals can occur. \u201cPerhaps it is a bad thing that the world's leading AI companies cannot control their AIs\u201d, as <a href=\"https://astralcodexten.substack.com/p/perhaps-it-is-a-bad-thing-that-the\">Scott Alexander</a> put so eloquently.</p><p>A key question is how these alignment difficulties will scale up as we create powerful AI systems. To be clear, cutting-edge systems like GPT-4 do not <i>appear</i> to have \u201cgoals'' in any meaningful sense. But AI systems with goals might be very useful for solving real-world problems, and so we should expect developers to want to build them. Take it from Microsoft, who noted in a <a href=\"https://arxiv.org/pdf/2303.12712.pdf\">research report</a> exploring GPT-4\u2019s capabilities that \u201cequipping [large language models] with agency and intrinsic motivation is a fascinating and important direction for future work\u201d.</p><p>It's not hard to imagine that increasingly goal-directed AI systems working on increasingly complicated tasks might result in bad side effects that are hard to predict in advance. And as AI systems become embedded in the world, we have all the more need to ensure that we can <i>precisely</i> control the goals they learn in training, to avoid potential issues ranging from unintended amplification of bias to existential threats to humanity.</p><h3>9.2 AI systems can be misused</h3><p>Moreover, even \u201caligned\u201d AI systems can already<i> </i>cause harm when intentionally misused.</p><p>In 2021, researchers at a small US pharmaceutical company called Collaborations Pharmaceuticals <a href=\"https://www.nature.com/articles/s42256-022-00465-9\">began experimenting</a> with MegaSyn, an AI system the company developed to design new drugs. MegaSyn typically filters against highly toxic outputs by penalising drugs that are predicted to be highly toxic, and rewarding ones that are effective at achieving the intended goal of the drug. One evening, the researchers were curious about what would happen if they flipped the toxicity filter on MegaSyn \u2014 literally by swapping a '1' for a '0' and a '0' for a '1\u2019 \u2014 to instead produce <i>highly</i> <i>toxic</i> molecules. Six hours after running the modified version of MegaSyn on a consumer-grade Mac computer, a list of 40,000 toxins was generated, some of which were novel and predicted to be more toxic than known chemical warfare agents.</p><p>\u201cI didn't sleep. I didn't sleep. I did not sleep. It was that gnawing away, you know, we shouldn't have done this. And then, oh, we should just stop now. Like, just stop.\u201d, said one of the researchers during an interview. \u201cThis could be something people are already doing or have already done. [...] You know, anyone could do this anywhere in the world\u201d, he continued.</p><p>All of the data used to train MegaSyn is available to the public, as is the model\u2019s underlying training architecture. Someone with relatively basic technical knowledge could likely create a similar model \u2014 though it\u2019s worth noting that actually synthesising the molecules in practice might be far more difficult.</p><p>Still, this anecdote illustrates how even relatively simple AI systems today can be misused. And as AI continues to progress, these systems could become far more capable of causing harm.</p><h2>10.0 Conclusion</h2><p>I\u2019ve made a lot of claims in this article. But among them, there are three things I want you to walk away with.</p><ul><li>Transformative AI may be created soon via machine learning.</li><li>We (currently) don\u2019t know how to reliably control the goals that AI systems learn.</li><li>Risks arising from AI systems pursuing the wrong goals could range from harmful to catastrophic.</li></ul><p>At our current pace of advancement, powerful AI systems that far surpass human capabilities in the next few decades are plausible. As Turing anticipated, such superintelligent machines would be both wondrous and disquieting.</p><p>On the one hand, sophisticated AI could help solve many of humanity's greatest challenges and push forward rapid advances in science and technology. On the other hand, the lack of reliable methods for instilling goals in AI systems, and their 'black-box' nature, creates huge risk.</p><p>Much work is needed to help ensure that the future of AI is one of promise rather than peril. Researchers at AI labs must make progress toward AI that is guaranteed to be safe and reliable. The stewards of these technologies ought to thoughtfully consider how, when, and perhaps most crucially <i>whether</i> to deploy increasingly capable AI systems. In turn, policymakers must think carefully about how to best govern advanced AI to ensure it helps human values flourish.</p><p>Concretely, this could mean:</p><ul><li><strong>Investing extensively in research on how to make AI systems alignable and interpretable</strong>. Technical progress in this area is not just crucial to reducing risks from advanced AI, but also for improving its benefits \u2014 after all, scientific progress in AI is only useful if these systems reliably do what we want.</li><li><strong>Fostering broad conversations on the future of AI and its implications</strong>. Engaging diverse groups in discussions on advanced AI can help establish consensus on what constitutes safe and acceptable development. Ethicists, policy experts, and the public should be involved along with technical researchers.</li><li><strong>Monitoring AI progress and risks</strong>. Regular monitoring of progress in AI and analysis of potential risks from advanced systems would help identify priorities for risk reduction and guide oversight of these technologies. Independent research organisations and government agencies could take on such monitoring and forecasting roles, where systems can only be deployed if they are provably safe.</li><li><strong>Considering a more cautious pace of AI research and development.</strong> Developing AI technologies at a more controlled speed could provide researchers, policymakers, and society with the time needed to gain clarity on potential risks and develop robust safety measures to defend against them.</li></ul><p>The world has a lot of work to do. We must start now to prepare for what the rise of increasingly intelligent and powerful machines might mean for the future, lest we end up realising Turing\u2019s worst fears.&nbsp;</p><p><i>Thanks to Rob Long, Jeffrey Ladish, S\u00f6ren Mindermann, Guive Assadi, Aidan Weber-Concannon, and Bryce McLean for your thoughtful feedback and suggestions.</i></p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn442ajw2fux2\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref442ajw2fux2\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Here, Sutskever is referring to Artificial General Intelligence, or \u201cAGI\u201d. AGI <i>generally</i> refers to the development of machines that possess the ability to perform better at any intellectual task that a human can. Unlike narrow AI, which is designed to perform specific tasks, AGI is designed to have a general cognitive ability, allowing it to understand and reason about the world in the same way that humans do. I prefer the term transformative AI, as it captures the thing that really matters \u2014 AI that has the potential to transform the world.</p></div></li></ol>", "user": {"username": "julianhazell"}}, {"_id": "4StMcDZqhiZ2zKsGm", "title": "Proposal: Connect Metaculus to the EA Forum to Incentivize Better Research", "postedAt": "2023-03-25T12:13:19.232Z", "htmlBody": "<h1>Summary</h1><p>I vaguely describe a hypothetical feature of both Metaculus and the EA forum, connecting them so that users can see which pieces of written content influenced accurate forecasts. This would enable more incentivization of more useful research, which would in turn enable higher quality and more accurate forecasts. I am not in a position to implement any aspect of this proposal, but I\u2019m surfacing the concept for community consideration and feedback because I personally believe it would be both extremely valuable and feasible.</p><h1>Introduction</h1><p>I believe that improving the creation and curation of relevant knowledge in forms useful to generalist forecasters is a key lever in improving our ability to forecast Global Catastrophic Risks (GCRs), as I describe <a href=\"https://damienlaird.substack.com/p/theory-my-intuitions-on-oppportunities\"><u>here</u></a>. Furthermore, I think current incentive schemes for rewarding research are pretty weak. Within academia, the focus ends up on number of citations and number of publications. On the internet, rewards typically take the form of upvotes/karma or engagement. Both have a circular aspect to them, where the research that other researchers think is useful gets rewarded. This effect can spiral into traps like extensive and unnecessary jargon, negative-sum competition in the form of adversarial peer review or just lack of recognition/collaboration. Online research targeted at a more general audience, combined with deliberate norms, can circumvent some of these failure modes. Then the rewards go from what researchers think is good research to what a general audience thinks is good research.</p><p>But was that research actually useful? Did it make our model of the world more or less accurate? Maybe there was a critical error in the calculations (or just fraudulent data underlying the analysis), such that an otherwise beautifully polished paper is actually moving our knowledgebase in the wrong direction. To some extent errors can be caught by careful readers, or we can attempt to replicate studies to confirm their findings, but not all research lends itself to empirical validation. Less dramatically, research can just be chock full of jargon, otherwise poorly written, or about an irrelevant topic and still end up functionally useless.</p><p>What if we connected research to forecasting? Forecasts, especially in <a href=\"https://damienlaird.substack.com/p/research-prediction-polling\"><u>prediction polling</u></a> environments, often have rationales attached that explain the reasoning and sources behind a particular prediction. If those rationales contained citations for their sources, you could actually track over time which sources of information tended to be used in more accurate forecasts. If those sources themselves contained legible citations of their sources, this information could flow along the citation chains, and you could see which scaffolds of knowledge were being built in a direction that improved our model of reality and which weren\u2019t. Where research negatively impacted accuracy, you\u2019d have reason to look for errors in data or reasoning that could produce this effect. In such a system it would be trivial to also show how the research of a given author/publisher stands up relative to others, allowing us to place some trust in their work even before it has been used in forecasts.</p><p>Furthermore, these forecast rationales are really just additional pieces of research that could themselves be cited, further enriching the relevant knowledgebase.</p><h1>Reality</h1><p>To make this new research paradigm a reality, we would need to implement the following:</p><ol><li>A lasting link between forecasts and their informational sources</li><li>A lasting link between sources and their sources</li><li>A reward that flows along these links to sources that are cited in accurate forecasts</li></ol><p><a href=\"https://www.metaculus.com/questions/\"><u>Metaculus</u></a> seems like the best existing platform for implementing a link between forecasts and citations. As I mention above, I think this almost has to be implemented in the context of prediction polling rather than prediction markets. In prediction polling, forecasters have to be explicit about their confidence level in a claim, and are free to set this confidence level however they want. In a prediction market, forecaster confidence is somewhat encoded in the volume of a given trade, but this can be confounded by a lack of available funds or low trading skill. I also believe the incentive systems of prediction polling platforms can be more accepting of information sharing between participants, a critical prerequisite if we want forecasters to thoroughly and honestly explain their reasoning at the time of a forecast. The default for prediction markets is information hoarding to maintain a competitive edge over other traders in the zero sum environment, but it\u2019s possible that this is not intrinsic to the format and that a play money market system like <a href=\"https://manifold.markets/\"><u>Manifold</u></a> could get around it. If this is the case, I haven\u2019t seen a proposed mechanism for doing so in my review of research. Regardless, this seems like a harder journey than Metaculus would have to make, so I\u2019m limiting the focus of my hypothetical implementation details.</p><p>Metaculus already has a fairly robust comment section on each forecastable question. Users are prompted to share a rationale in this section with each of the forecasts, and there is even a simple markdown language for formatting these rationales. A small but critical gap is that there is no markdown feature for citations/footnotes. Implementing this well should both encourage citations and make them easy to track, and I expect doing so is a prerequisite to the rest of this proposal.</p><p>If this is done, Metaculus forecasters would have the ability to cite sources in their rationales. These are presumably typically associated with links to webpages\u2026 but how do we associate those with particular researchers? What if multiple links lead to the same study? Attribution is necessary to score useful research, and is straightforward for citations of other forecast rationales hosted on Metaculus, but otherwise seems painful.</p><p>My initial idea to solve this problem was to make Metaculus more friendly for posting longer form research to. There are already discussion threads and forums implemented on the site in some cases, though these are really just forecasting questions without something to forecast, and use the same commenting mechanisms. This means that almost all of the written content on Metaculus is hidden under individual questions/discussions/forums and can\u2019t be easily discovered or searched. Obviously this could be remedied, but this seems like a big lift that would greatly increase the complexity of the site.</p><p>Eventually, I realized that I was trying to recreate the <a href=\"https://forum.effectivealtruism.org/\"><u>EA Forum</u></a>. This forum is almost exclusively focused already on the kinds of information that I expect forecasters to find useful, has pre-existing norms for clear communication, honesty, and reasoning transparency, and even already has a space dedicated to the topic of forecasting. In fact, when I participated in <a href=\"https://damienlaird.substack.com/p/post-mortem-2022-hybrid-forecasting\"><u>a tournament that heavily incentivized well-cited forecasting rationales</u></a>, I found many posts on the EA forum worth using. It even has a very strong set of formatting options including easy citations.</p><p>Instead of trying to build Metaculus into something it currently isn\u2019t, I\u2019m proposing a novel connection between Metaculus and the EA Forum.</p><p>This simplifies the attribution problem for Metaculus. It only needs to worry about two kinds of links: those that point to comments on Metaculus, and those that point to posts on the EA Forum. These both already have unique identifiers and are intrinsically connected to individual authors. On the EA Forum, tracking the citation of forum posts within other forum posts should be straightforward.</p><p>All of the above should cover items #1 and #2 from my initial checklist in this section. We now have a way (that seems quite technically feasible to me, a layman on the outside) to capture the linkages between forecasts and their sources and between sources and their sources, given the self imposed constraints that we only consider content posted on Metaculus or the EA Forum. This seems like a reasonable outcome to me, given that the EA Forum already encourages link posting from other sources with summaries.</p><p>This leaves an open question for #3, the actual reward that flows along citation chains to both indicate and incentivize research that is used in accurate forecasts.</p><p>It seems obvious to me that this should primarily be some form of \u201cinternet points\u201d analogous to the existing \u201cpoints\u201d currency awarded for accuracy on Metaculus or the \u201ckarma\u201d rewarded for upvotes on the EA Forum. I want to be careful with this proposal to minimize the chance of degrading the existing function of either platform, as I think they\u2019re both already doing important things well. To that end, I believe a separate imaginary currency is warranted. This seems worth the slight increase in complexity on both platforms to preserve the integrity of their current systems.</p><p>As a stand-in, let\u2019s call these \u201cresearch points\u201d (to be clear, I think this is a terrible name). Metaculus users will now earn both their current points for accurately forecasting, and '\u201cresearch points\u201d for their rationales being cited by other forecasters who in turn forecast accurately, or for their rationales being cited by other rationales who are in turn cited by accurate forecasts, and so on. This creates a novel incentive for forecasters to actually write clear and accurate rationales for why they believe what they believe, whereas currently they\u2019re just prompted with no possibility for additional reward. If a forecaster only cares about accumulating the original points and being accurate without having to show their work, they can continue doing so with no real change to their experience. In my mind, this will create a new niche for a kind of forecaster dedicated to clear communication in addition to accuracy. I think we see this kind of forecasting done now by dedicated individuals or top forecasting teams, but it\u2019s unfortunately rare.</p><p>Similarly, on the EA Forum, users will now have an ability to accumulate \u201cresearch points\u201d alongside their existing karma. Karma will indicate what other forum users think is worth rewarding, while \u201cresearch points\u201d indicate some genuinely manifested value in increasing the accuracy of someone\u2019s beliefs. I expect this metric to be exciting in the EA/rationalist community, but forum posters will be free to ignore this new metric if they want and continue to post content as they did before, not specifically targeted at being useful for forecasters.</p><p>How will this metric be calculated? I expect others (especially those who work at these platforms) to have better ideas on this than I do, but just as a concrete example:</p><ul><li>A forecast generates a number of \u201cresearch points\u201d equal to its traditional accuracy points.</li><li>These are divided equally between each of its cited sources that are from either Metaculus or the EA Forum.</li><li>The \u201cresearch points\u201d allocated to a source are then divided in half, with half going to that source itself, and the other half being divided equally between each of its cited sources from either Metaculus or the EA Forum.</li><li>So on and so forth, to the end of each citation chain. Maybe rounding each division up to the nearest whole number of points to preserve the value of long chains?</li><li>These \u201cresearch points\u201d are continually updated as the traditional accuracy points for Metaculus forecasts are continually updated (per my understanding) and displayed in aggregate in three places:<ul><li>On each source itself. Either Metaculus comments or EA Forum posts, alongside traditional upvotes/karma.</li><li>On user profiles, on either platform, for the total of all the content they\u2019ve generated that\u2019s been cited.</li></ul></li></ul><p>Note that the traditional points on Metaculus can be negative in order to disincentive inaccurate forecasts, which allows a signal to flow through the system when sources are counterproductive.</p><p>I believe the above proposal represents a sort of minimum viable system that creates the incentives I\u2019m talking about. It also leaves the door open for a lot of future possibilities, many of which I\u2019m sure haven\u2019t even occurred to me. Some that have include\u2026</p><ul><li>Different ways to display the information conveyed by \u201cknowledge points\u201d rather than raw point totals. Leaderboards of the most positively influential sources/posters? Percentile scores alongside or instead of point totals? Does this makes sense to be broken up by topic?</li><li>Visualizations of citation chains/graphs. These already exist for academic citations, but my intuition is that they get a lot more interesting/useful when you can see which threads of research have actually made forecasting models more accurate.</li><li>Cash incentives or other rewards tied to \u201cresearch points\u2019. Does this enable tournaments or grants to create the most \u201cuseful\u201d research, in a way that I expect can be judged much less subjectively than the status quo?</li></ul><h1>Red Teaming</h1><p>What could go significantly wrong with the above proposal?</p><ul><li>These features could be impossible or much more expensive/difficult to implement as described. If this is the case, I\u2019m not going to figure it out from my armchair, so I\u2019m hoping to get this proposal to people who know much more. (~20% chance this is the case?)</li><li>I could be wrong about this being useful. Maybe high quality information actually isn\u2019t a bottleneck for important forecasting, or maybe no one would be interested in writing the kinds of rationales or content intended to be incentivized by this system. (~10% chance this is the case?)</li><li>Maybe the points system is trivially gameable/exploitable in some way and won\u2019t incentivize the behaviors I expect. I believe it is gameable, but I think the existing karma and points systems of the two platforms already are to a large extent, and the reason they are mostly useful is more due to the nature of the associated communities and their objective than some intense reliability of their point systems. (~20% this is the case? In which case I think the proposal is likely recoverable with mechanism tweaks)</li><li>It could degrade the existing functionality of these platforms in some way. I\u2019ve tried my best to minimize this possibility, but again, I don\u2019t think I can do much better than this from my armchair and will endeavor to get this idea to people with more relevant insights. (~15% chance this is the case? But may still be recoverable with tweaks)</li></ul>", "user": {"username": "Damien Laird"}}, {"_id": "A6h5X2ERpumJACoEX", "title": "Introducing Artists of Impact", "postedAt": "2023-03-25T03:21:07.826Z", "htmlBody": "<h2>TL;DR</h2><p>Announcing a new EA-Aligned org to promote effective giving by leveraging the social influence and resources of professional and celebrity artists.&nbsp;</p><h1>Intro</h1><p>Hello EA Forum!<br>&nbsp;</p><p>My name is&nbsp;<a href=\"https://www.linkedin.com/in/fernandomartingullans/\"><u>Fernando</u></a>. I\u2019m a professional ballet dancer who\u2019s excited to announce the launch of our new organization,&nbsp;<a href=\"https://www.artistsofimpact.org/\"><i><u>Artists of Impact</u></i></a>! We promote effective giving by leveraging the social influence and resources of professional and celebrity artists.&nbsp;</p><p>&nbsp;</p><p>Modeled largely off of&nbsp;<a href=\"https://highimpactathletes.org/\"><u>High Impact Athletes</u></a>, we help professional artists understand the power of effective giving and the importance of thinking critically about using their platform and resources to have a greater social impact. We connect them with EA-aligned organizations that they resonate with, support their high-impact donation and advocacy efforts, and leverage their platforms to inspire their fans to do the same!<br>&nbsp;</p><p>The arts community in general does a great job of advocating for different causes. However, these tend to reflect a more personal approach to philanthropy, which often prioritizes proximity and familiarity over&nbsp;<a href=\"https://forum.effectivealtruism.org/s/QMrYGgBvg64JhcQrS\"><u>impartiality</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/cost-effectiveness\"><u>cost-effectiveness</u></a>. As such, we hope to insert ourselves into that equation, leverage the motivations that we already see prevalent throughout the artistic community, and point them towards higher-impact opportunities.&nbsp;</p><p>&nbsp;</p><p>We\u2019re currently working on formalizing our organizational strategy, but we wanted to make this announcement ASAP so that the community is aware of what we\u2019re trying to do and can reach out if they have any ideas or people they think we should hear and connect with!<br>&nbsp;</p><p>We\u2019re excited to share &nbsp;more information about our theory of change, pilot projects, budget, etc. in a future post and we hope that you\u2019ll be excited to keep up with us as we continue to grow and learn as an organization!&nbsp;</p><p><br>&nbsp;</p><h2>How you can help!</h2><p><strong>Funders</strong></p><p>We're currently bootstrapping operations and&nbsp;<strong>actively seeking funders</strong> to help provide a 6-12 month runway to test out the assumptions underlying our <a href=\"https://en.wikipedia.org/wiki/Theory_of_Change\">Theory of Change</a> and continue building up our social presence.&nbsp;</p><p>&nbsp;</p><p><strong>Collaborators</strong></p><p>We're also seeking collaborators to join our project on a volunteer basis, so if you\u2019re excited by our mission and want to help us realize our organizational objectives,&nbsp;<a href=\"mailto:fernando@artistsofimpact.org\"><u>reach out!</u></a><br>&nbsp;</p><p><strong>Connections</strong></p><p>If you know any professional/celebrity artists, we'd love to connect with them! Warm intros have been our most effective outreach method!&nbsp;<a href=\"mailto:fernando@artistsofimpact.org\"><u>Get in touch!</u></a><br>&nbsp;</p><p><strong>Follow Us on Social Media and Spread the Word</strong></p><ul><li>Instagram:&nbsp;<a href=\"https://www.instagram.com/artistsofimpact/\"><u>@artistsofimpact</u></a></li><li>Twitter:&nbsp;<a href=\"https://twitter.com/ArtistsofImpact\"><u>@ArtistsofImpact</u></a></li><li>LinkedIn:&nbsp;<a href=\"https://www.linkedin.com/company/artists-of-impact/?viewAsMember=true\"><u>@ArtistsofImpact</u></a></li></ul><h2>More Info</h2><p>If you\u2019d like to learn more about our project or have any feedback on how to make the project more impactful, comment down below or reach out to me at&nbsp;<a href=\"mailto:fernando@artistsofimpact.org\"><u>fernando@artistsofimpact.org</u></a></p><p>Special thanks to Marcus D., Devon F., Sarah P., Neil F., &nbsp;Jeffray B., and too many others to name for all their help in bringing this project to life.&nbsp;</p><p>&nbsp;</p><p>Thanks for your time and for all that you do for the world!</p><p><br>&nbsp;</p>", "user": {"username": "fernandomartingullans@gmail.com"}}, {"_id": "gEofudCuTTESGPypc", "title": "Can independent researchers get a sponsored visa for the US or UK?", "postedAt": "2023-03-25T03:05:27.758Z", "htmlBody": "<p>I\u2019m an independent alignment researcher from Canada. I\u2019m trying to figure out my long-term options (I want to move somewhere and stay there for several years).&nbsp;</p><p>I have some special visas as a Canadian to go to either place, but I\u2019d need to be working at a \u201djob\u201d to be eligible for the visa. I <i>could</i> go to London on a 2-year visa without a regular job, but would need a job after that visa expires. It feels like a gamble going there for two years and then not having the ability to stay long-term.</p><p>Someone told me I should consider checking to see if I can work on this with a university. I'm not sure if they'd be up for signing off on my visa as long as I keep getting my independent funding?</p><p>So, what are the options for independent researchers who don't have US or UK citizenship? Are there any orgs that sponsor visas for independent researchers?</p><p>Note: I\u2019m completely happy staying in Canada and mainly working remotely with collaborators (though I\u2019d probably move to a Canadian city with a couple of other researchers), but I want to make an informed decision.</p>", "user": {"username": "jaythibs"}}, {"_id": "n2b7nBHdLpmcxQuzP", "title": "Exploring Tacit Linked Premises with GPT", "postedAt": "2023-03-24T22:50:43.106Z", "htmlBody": "", "user": {"username": "RomeoStevens"}}, {"_id": "9g6zowaT2tAKSQXw3", "title": "The supply gap of EA org service providers", "postedAt": "2023-03-25T23:49:44.078Z", "htmlBody": "<p>As part of our work at<a href=\"https://ea-services.org/\"><u> EASE</u></a>, we created a directory and community of EA service providers so that we can best support our EA organizations (see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/mb4kzhfRnpQNtF6ut/introducing-ease-a-managed-directory-of-ea-organization?commentId=DqsaffECuiEpnhjCw\"><u>intro post</u></a>). In our group meeting today, we identified the service areas in which we currently don\u2019t have enough providers. We would very much like to grow our community of providers so that we can partner with professionals to make sure that all the EA org needs are accounted for.<br>&nbsp;</p><p>The problem we discussed this week was closing the supply gap for important org services that can help all our orgs achieve maximal impact.&nbsp;We find ourselves in an interesting situation: on the one hand, we are convinced there is too little demand for services inside EA (such as marketing and executive coaching as top-of-mind examples); on the other, we see too little supply of services in certain areas. This post is about closing supply gaps, and we\u2019re focusing on services that there is a high demand for but not enough supply.<br>&nbsp;</p><p>We took a quick look over the portfolio of services currently offered inside EA and tried to identify areas that we deem (a) very relevant for any/most start-up/business and which (b) don't seem to be covered by any service providers inside EA yet. However, we have likely missed some aspects / offers in both points, (a) and (b) - so feel free to please point out anything we missed.</p><p>&nbsp;</p><p>Missing services:</p><ul><li>Finance: everything from bookkeeping to outsourced CFOs&nbsp;</li><li>Legal: contracts, employment, compliance</li><li>Tech: software implementation, Salesforce etc&nbsp;<br>&nbsp;</li></ul><p>Service areas that need more of a supply:</p><ul><li>HR consulting (not recruiting)&nbsp;</li><li>Operations SOP and workflow development (need more providers)</li></ul><p>&nbsp;</p><p>If you provide these services or know anyone within EA who provides them, please encourage them to&nbsp;<a href=\"https://forms.gle/oV23T92Qu9uDwK1c7\"><u>apply to be added</u></a> or to chat with us. You can (and should) apply even if you don\u2019t provide these specific services - in order for us to have a comprehensive understanding of the available services for EA orgs, we need to have all service providers collaborate with us. It helps everyone when we all work together.<br>&nbsp;</p><p>Feel free to PM or&nbsp;<a href=\"mailto:info@ea-services.org\"><u>message</u></a> any of us with any questions or if you\u2019re an org in need of external services - we\u2019re here to help!</p><p><br>&nbsp;</p>", "user": {"username": "Deena Englander"}}, {"_id": "AtdApEsvPr8QhdoBa", "title": "Metaculus Predicts Weak AGI in 2 Years and AGI in 10", "postedAt": "2023-03-24T19:43:18.275Z", "htmlBody": "<p>Just a quick update on predicted timelines. Obviously, there\u2019s no guarantee that Metaculus is 100% reliable + you should look at other sources as well, but I find this concerning.</p>\n<p>Weak AGI is now predicted in a little over two years:</p>\n<p><a href=\"https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/\">https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/</a></p>\n<p>AGI predicted in about 10: <a href=\"https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/\">https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/</a></p>\n<p>Also, these are predicted dates until these systems publicly known, not the date until they exist. Things are getting crazy.</p>\n<p>Even though Eliezer claims that there was no fire alarm for AGI, perhaps this is the fire alarm?</p>\n", "user": {"username": "casebash"}}, {"_id": "FCkchmXcSCQtJ9PZA", "title": "Predicting what future people value: A terse introduction to Axiological Futurism", "postedAt": "2023-03-24T19:15:31.082Z", "htmlBody": "<h1>Why this is worth researching</h1><p>Humanity might develop artificial general intelligence (AGI)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4txmv7cqd0k\"><sup><a href=\"#fn4txmv7cqd0k\">[1]</a></sup></span>, colonize space, and create astronomical amounts of things in the future (<a href=\"https://nickbostrom.com/astronomical/waste\"><u>Bostrom 2003</u></a>;&nbsp;<a href=\"https://whatweowethefuture.com/uk/\"><u>MacAskill 2022</u></a>;&nbsp;<a href=\"https://longtermrisk.org/reducing-risks-of-astronomical-suffering-a-neglected-priority/\"><u>Althaus and Gloor 2016</u></a>). But what things? How (dis)valuable? And how does this compare with things&nbsp;<a href=\"https://grabbyaliens.com/\"><u>grabby aliens</u></a> would eventually create if they colonize our corner of the universe? What does this imply for our work aimed at impacting the long-term future?&nbsp;</p><p>While this depends on many factors, a crucial one will likely be&nbsp;<i>the values of our successors</i>.&nbsp;</p><p>Here\u2019s a position that might tempt us while considering whether it is worth researching this topic:</p><p><i>Our descendants are unlikely to have values that are both different from ours in a very significant way and predictable. Either they have values similar to ours or they have values we can\u2019t predict. Therefore, trying to predict their values is a waste of time and resources.</i></p><p>While I see how this can seem compelling, I think this is very ill-informed.&nbsp;</p><p>First,&nbsp;<i>predicting the values of our successors&nbsp;</i>\u2013 what John Danaher (<a href=\"https://philarchive.org/rec/DANAFT-2\"><u>2021</u></a>) calls&nbsp;<i>axiological futurism</i> \u2013 in worlds where these are meaningfully different from ours doesn\u2019t seem intractable at all. Significant progress has already been made in this research area and there seems to be room for much more (see the next section and the Appendix).</p><p>Second, a scenario where the values of our descendants don\u2019t significantly differ from ours appears quite unlikely to me.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvoem0a6yukk\"><sup><a href=\"#fnvoem0a6yukk\">[2]</a></sup></span>&nbsp;We should watch for things like the&nbsp;<a href=\"https://en.wikipedia.org/wiki/End-of-history_illusion\"><u>End of History illusion</u></a>, here. Values seem to notably evolve through History, and there is no reason to assume we are so special that we should drop that prior.</p><p>Besides being tractable, I believe axiological futurism to be uncommonly important given its instrumentality in answering the crucial questions mentioned earlier. It therefore also seems unwarrantedly neglected as of today.</p><h1>How to research this</h1><p>Here are examples of broad questions that could be part of a research agenda on this topic:</p><ul><li>What are the best predictors of future human values? What can we learn from usual forecasting methods?</li><li>How have people\u2019s values changed throughout History? Why? What can we learn from this? (see, e.g.,&nbsp;<a href=\"https://whatweowethefuture.com/uk/\"><u>MacAskill 2022</u></a>, Chapter 3;&nbsp;<a href=\"https://www.sentienceinstitute.org/blog/how-tractable-is-changing-the-course-of-history\"><u>Harris 2019</u></a>;&nbsp;<a href=\"https://philpapers.org/rec/HOPFVC\"><u>Hopster 2022</u></a>)</li><li>Are there reasons to think we\u2019ll observe less change in the future? Why?&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/value-lock-in\"><u>Value lock-in</u></a>? Some form of moral convergence happening soon?&nbsp;</li><li>Are there reasons to expect more change? Would that be due to the development of AGI, whole brain emulation, space colonization, and/or accelerated value drift? What if a global catastrophe occurs?</li><li>More broadly, what impact will future technological progress have on values? (see&nbsp;<a href=\"https://ageofem.com/\"><u>Hanson 2016</u></a> for a forecast example.)</li><li>Should we expect some values to be selected for? (see, e.g.,&nbsp;<a href=\"https://rationalaltruist.com/2013/02/27/why-will-they-be-happy/\"><u>Christiano 2013</u></a>;&nbsp;<a href=\"https://nickbostrom.com/fut/evolution\"><u>Bostrom 2009</u></a>,&nbsp;<a href=\"https://reducing-suffering.org/the-future-of-darwinism/\"><u>Tomasik 2017</u></a>)</li><li>Might a period of \u201c<a href=\"https://forum.effectivealtruism.org/topics/long-reflection\"><u>long reflection</u></a>\u201d take place? If yes, can we get some idea of what could result from it?</li><li>Does something like&nbsp;<a href=\"https://www.lesswrong.com/tag/coherent-extrapolated-volition\"><u>coherent extrapolated volition</u></a> have any chance of being pursued and if so, what could realistically result from it?</li><li>Are there futures \u2013 where humanity has certain values \u2013 that are unlikely but worth wagering on?</li><li>Might our research on this topic affect the values we should expect our successors to have by, e.g., triggering a self-defeating or self-fulfilling prophecy effect? (<a href=\"https://philarchive.org/rec/DANAFT-2\"><u>Danaher 2021</u></a>, section 2)</li><li>What do/will aliens value and what does that tell us about ourselves?&nbsp;</li><li>What about the values of a potential post-human-extinction civilization on Earth?</li></ul><p>John Danaher (<a href=\"https://philarchive.org/rec/DANAFT-2\"><u>2021</u></a>) gives examples of methodologies that could be used to answer these questions.</p><p>Also, my Appendix references examples and other relevant work, including subsequent posts in this sequence.</p><h1>Acknowledgment</h1><p>Thanks to Anders Sandberg for pointing me to the work of John Danaher (<a href=\"https://philarchive.org/rec/DANAFT-2\"><u>2021</u></a>) and for our insightful discussion on this topic. Thanks to Elias Schmied for other recommendations. Thanks also to M. Victoria Calabrese for her stylistic suggestions. My work on this sequence so far has been funded by&nbsp;<a href=\"https://erafellowship.org/\"><u>Existential Risk Alliance</u></a>.&nbsp;</p><p>All assumptions/claims/omissions are my own.&nbsp;</p><h1>Appendix: Relevant work</h1><p>(This list is not exhaustive.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffer6xkkwmv\"><sup><a href=\"#fnfer6xkkwmv\">[3]</a></sup></span>&nbsp;More or less ranked by decreasing order of relevance.)</p><ul><li>Making forecasts \u2013 or raising relevant considerations \u2013 on what our successors might value<ul><li>John Danaher (2021)&nbsp;<a href=\"https://philarchive.org/rec/DANAFT-2\"><u>Axiological Futurism: The Systematic Study of the Future of Values</u></a></li><li>Robin Hanson (1998)&nbsp;<a href=\"http://mason.gmu.edu/~rhanson/filluniv.pdf\"><u>Burning the Cosmic Commons: Evolutionary Strategies for Interstellar Colonization</u></a></li><li>Nick Bostrom (2004)&nbsp;<a href=\"https://nickbostrom.com/fut/evolution\"><u>The Future of Human Evolution</u></a></li><li>Brian Tomasik (2017)&nbsp;<a href=\"https://reducing-suffering.org/the-future-of-darwinism/\"><u>The Future of Darwinism</u></a></li><li>Allan Dafoe (2019)&nbsp;<a href=\"https://docs.google.com/document/d/1B77VWaXG-u34nSRFKV14pJNHJHHb6sa5zJ08J70CVVA/edit\"><u>Value Erosion</u></a></li><li>Robin Hanson (2022) <a href=\"https://www.overcomingbias.com/p/will-design-escape-selectionhtml\">Will Design Escape Selection?</a></li><li>Robin Hanson (2021) <a href=\"https://www.overcomingbias.com/p/on-evolved-valueshtml\">On Evolved Values</a></li><li>Robin Hanson (2009)&nbsp;<a href=\"https://www.overcomingbias.com/p/this-is-the-dream-timehtml\"><u>This is the Dream Time</u></a></li><li>interstice (2022) <a href=\"https://www.lesswrong.com/posts/BuaFZud9BwkiSCGpd/alignment-might-never-be-solved-by-humans-or-ai\">Alignment Might Never Be Solved, By Humans or AI</a></li><li>Wei Dai (2014) <a href=\"https://www.lesswrong.com/posts/orhEa4wuRJHPmHFsR/six-plausible-meta-ethical-alternatives\">Six Plausible Meta-Ethical Alternatives</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/NfkEqssr7qDazTquW/the-expected-value-of-extinction-risk-reduction-is-positive?fbclid=IwAR2Si8qdOEqXdPujDfv6gDGLaTdevs4Tb_CALW0D2MHUC4Ot9evEAoem3Gw#We_can_expect_future_agents_to_have_other_regarding_preferences_that_we_would__after_reflection__find_somewhat_positive\"><i><u>We can expect future agents to have other-regarding preferences that we would, after reflection, find somewhat positive</u></i></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/NfkEqssr7qDazTquW/the-expected-value-of-extinction-risk-reduction-is-positive?fbclid=IwAR2Si8qdOEqXdPujDfv6gDGLaTdevs4Tb_CALW0D2MHUC4Ot9evEAoem3Gw#Appendix_2__Future_agents_will_in_expectation_have_a_considerable_fraction_of_other_regarding_preferences\"><i><u>Appendix 2</u></i></a> in Brauner and Grosse-Holz (<a href=\"https://forum.effectivealtruism.org/posts/NfkEqssr7qDazTquW/the-expected-value-of-extinction-risk-reduction-is-positive?fbclid=IwAR2Si8qdOEqXdPujDfv6gDGLaTdevs4Tb_CALW0D2MHUC4Ot9evEAoem3Gw\"><u>2018</u></a>)</li><li>Robin Hanson (2016)&nbsp;<a href=\"https://ageofem.com/\"><u>The Age of Em</u></a></li><li>Paul Christiano (2013)&nbsp;<a href=\"https://rationalaltruist.com/2013/02/27/why-will-they-be-happy/\"><u>Why might the future be good?</u></a></li><li>Jacy Reese Anthis (2018)&nbsp;<a href=\"https://en.wikipedia.org/wiki/The_End_of_Animal_Farming\"><u>The End of Animal Farming</u></a></li><li>Robin Hanson (2018) <a href=\"https://www.overcomingbias.com/p/long-views-are-cominghtml\">Longviews are coming</a></li><li>Yuval Noah Harari (2016)&nbsp;<a href=\"https://books.google.co.uk/books?hl=en&amp;lr=&amp;id=ZWcNDQAAQBAJ&amp;oi=fnd&amp;pg=PA1&amp;ots=-ETYkeIBQ5&amp;sig=FlFk1A9hxymM0BPuY1Y_cG4mmWw&amp;redir_esc=y\"><u>Homo Deus</u></a></li><li><i>The \u201cConsciousness vs. Pure Replicators\u201d Worldview</i> in Emilsson (<a href=\"https://qualiacomputing.com/2017/12/20/the-universal-plot-part-i-consciousness-vs-pure-replicators/\"><u>2017</u></a>)</li><li>Subsequent posts in this sequence (some not posted yet).</li><li>Anders Sandberg (Forthcoming) Grand Futures</li></ul></li><li>On the possibility, likelihood, and implications of value lock-in / value drift<ul><li>Lukas Finnveden et al. (2022)&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/KqCybin8rtfP3qztq/agi-and-lock-in\"><u>AGI and Lock-In</u></a>; and the work they refer to in the section&nbsp;<a href=\"https://docs.google.com/document/d/1mkLFhxixWdT5peJHq4rfFzq4QbHyfZtANH1nou68q88/edit#heading=h.17f05s8r0u3q\"><i><u>How likely is this?</u></i></a></li></ul></li><li>On the incentives to colonize space<ul><li>Carl Shulman (2018)&nbsp;<a href=\"http://reflectivedisequilibrium.blogspot.com/2018/10/financial-returns-of-interstellar.html\"><u>Financial returns of interstellar colonization for the sedentary</u></a></li><li>Anders Sandberg (2018)&nbsp;<a href=\"https://www.fhi.ox.ac.uk/wp-content/uploads/space-races-settling.pdf\"><u>Space races: settling the universe fast</u></a></li></ul></li></ul><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4txmv7cqd0k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4txmv7cqd0k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Or something roughly as transformative.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvoem0a6yukk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvoem0a6yukk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>A sudden value lock-in with an AGI developed and deployed in the next years/decades is probably the most credible possibility. (See&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/KqCybin8rtfP3qztq/agi-and-lock-in\"><u>Finnveden et al. 2022</u></a>.)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfer6xkkwmv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffer6xkkwmv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is more because of my limited knowledge than due to an intent to keep this list short, so please send me other potentially relevant resources!</p></div></li></ol>", "user": {"username": "Jim Buhler"}}, {"_id": "aNsBJYpGovgJqWC9v", "title": "Comparing Health Interventions in Colombia and Nigeria: Which are More Effective and by How Much?", "postedAt": "2023-03-24T13:48:14.898Z", "htmlBody": "<p><strong>TL;DR:&nbsp;</strong>Nigeria bears 10 times the burden of Communicable, Maternal, Neonatal, and Nutritional (CMNN) diseases per capita than Colombia, despite both countries having similar health expenditures to combat these diseases. Applying the SNT framework suggests that health interventions are around 10 times more cost-effective in Nigeria even when comparing only the poorest regions within each country.</p><h1>Why I decided to work on this topic</h1><p>Chatting with the members of my EA university group in Colombia, I noticed many of them were mainly interested in contributing to problems that affected their home country. Although Colombia is far from being one of the poorest countries in the world, various regions of the country still suffer from similar problems as less developed countries. I thought there might be a chance that we found opportunities with similar cost-effectiveness as those that EA tends to prioritize in the area of health and development.</p><p>Given that some students from my EA group were considering making career decisions based on a similar perception, I thought it worthwhile to spare a couple of hours to critically evaluate this line of reasoning, in the hope that this would allow them to make a more informed decision. Ideally, this research would answer the following questions:</p><ul><li>Within the ways to help in Colombia, which problems/interventions represent unusually cost-effective opportunities to help?</li><li>How do the best opportunities identified in Colombia compare with the best opportunities abroad?</li></ul><p>Unfortunately, both questions are too broad to cover them appropriately in the short time I dedicated to this work (approx. 40 hours). In order to make progress I decided focus on the much more narrow question:</p><p><i>In aggregate, how cost-effective do health interventions addressing communicable, maternal, neonatal and nutritional diseases in Colombia seem when compared to interventions in the same area in a substantially poorer country?</i></p><p>Although this question corresponds to only a fragment of our initial concern, a couple of considerations lead me to think that an answer to this question would still be informative to people considering whether to focus their career on helping others within the Colombian territory (even if they don\u2019t plan to focus specifically on health interventions).</p><p>First, health interventions aimed at fighting communicable, maternal, neonatal and nutritional diseases (from now on CMNN interventions) form a&nbsp;<a href=\"https://www.givewell.org/charities/top-charities\"><u>substantial</u></a>&nbsp;<a href=\"https://www.openphilanthropy.org/grants/?q=&amp;focus-area=scientific-research&amp;focus-area=south-asian-air-quality&amp;focus-area=global-health-development&amp;focus-area=global-aid-policy&amp;focus-area=effective-altruism-global-health-and-wellbeing\"><u>fraction</u></a> of the EA portfolio of interventions focused on improving human welfare in the short term, which is the focus of most of the students I know who are considering whether to direct their careers at Colombian causes. Second, my impression is that the results of this investigation support certain heuristics for identifying impact opportunities that can be useful even outside health causes. I\u2019ll say more about that in the conclusions section.&nbsp;</p><h1>Approach</h1><p>I use the&nbsp;<a href=\"https://www.effectivealtruism.org/articles/prospecting-for-gold-owen-cotton-barratt#how-can-we-trade-off-these-dimensions-against-each-other\"><u>Scale, Neglectedness and Tractability</u></a> (SNT) framework to estimate the cost-effectiveness ratio of CMNN interventions between Colombia and Nigeria. Besides making the comparison for the two countries as a whole, I\u2019ll also try to compare the poorest regions within each country to see if that changes the conclusions.</p><p>I chose Nigeria somewhat arbitrarily, mainly because several of GiveWell's recommended charities have operations in Nigeria (suggesting that there are unusually effective opportunities in the country) and because among the countries where GiveWell-recommended charities operate, Nigeria It is approximately in the middle of the distribution of poverty incidence.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/kmtrmunqed09xtkhyujg\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/wjuo40h21xmy6sextfyt 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/mvb9kpmcxhstuj2pm3cy 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/jahr9vqrp3o5qi3pcb0i 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/hnc5taatdpkcuffy718z 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/mnylrj45pq09qxzo6x7b 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/erohxcr6isj76nmoomcy 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/icrubl90zgrspuukvhjc 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/jz25ootu9hzbnlinfmyp 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/kqrzeztogos30hvi89zv 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/s9aviiyxlvzi1hn8tzg7 1600w\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/oczy8xrhcryduypayifl\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/e41wsyesudsiazevgb73 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/gs1t5jsnydajjwzx0a8c 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/wugtdqwz0fxzos0xjczb 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/oy85pealqh17qomoosec 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/fyvhyh8p4dbozcwye4ia 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/isizmxyvqgm573rndolf 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/p7cdvvkk0gp5viu1ntjh 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/gwjvmkjhy8oniolv0jgh 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/roykl024fbq0m7yzueab 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/jwri5wyid7sk23evubpb 1600w\"></p><p>Percentage of the population living below the International extreme poverty line (up) and average income (GDP per capita)&nbsp;<a href=\"https://en.wikipedia.org/wiki/International_dollar\"><u>corrected for purchasing power</u></a> in each country (down). Source: Our World in Data.</p><h1>SNT</h1><p>Given that the population of Nigeria is much bigger than Colombia\u2019s, I\u2019ll divide the scale and neglectedness figures by the total population of each country. It is easy to show that the population term cancels out in the product and the result is identical to the original SNT framework.</p><h2>Scale (per person)</h2><p><i><strong>Headline result:</strong> In Nigeria, each inhabitant lost on average the equivalent of 4 months of healthy life (0.29 DALYs) to CMNN diseases in 2019, compared to 10 days for the average Colombian (0.03 DALYs). Although I couldn\u2019t find the same data at the level of regions, the figures on infant mortality suggest a similar picture, where the most vulnerable regions in Nigeria have an infant mortality rate 5 times higher than the most vulnerable departments in Colombia.</i></p><p>The scale of a problem indicates how much would the world improve if the problem were solved. In the context of diseases, we can use&nbsp;<a href=\"https://en.wikipedia.org/wiki/Disability-adjusted_life_year\"><u>Disability Adjusted Life Years (DALYs)</u></a> to measure as a metric that combines the number of years lost and the reductions in life quality caused by a disease. When I talk about the burden of a disease, I\u2019ll be referring to the number of DALYs lost to it.</p><p>One reason to expect a higher disease burden in Nigeria is that extreme poverty is much more prevalent in that country. In 2018, about 79 million people in Nigeria lived on less than US$2 a day (the international extreme poverty line), while in Colombia about 2 million were in the same condition. This corresponds to an incidence of extreme poverty of 39% in Nigeria and 4% in Colombia.&nbsp;</p><p>Due to the deprivations associated with poverty, those subjected to it are more likely to suffer from diseases like tuberculosis, malaria and preterm births, all of which fall under the category of communicable, maternal, neonatal and nutritional diseases. In many cases, these conditions are preventable or easy to treat, like by providing safe drinking water, appropriate waste management systems or inexpensive medications.&nbsp;</p><p>The three graphs below show the years of health lost (DALYs) due to different diseases and conditions for Nigeria, Colombia and Spain. The blue bars correspond to non-communicable diseases; the red bars to CMNN diseases and the gray bars to injuries and accidents.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/upur6f8epwc3pquikr8n\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/kpfqszy8wsv1fm7nlrsk 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/rl7kty5rovn2tddqcpp1 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/acxqyskhl4jkbbbifzgs 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/m7thbpcbplg4elumaeoc 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/b8m5dczsbsmztnzerome 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/ixvgvhhtbyxgmqkq4wku 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/o3qcht4ctjoqwfhbylin 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/bc9wrp0xt8jv3lb0uxc6 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/eugfuprdqjueddmyd03y 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/dzx3qpuhmo06g6ihuhp3 1600w\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/wfvrxogvgfablttreumn\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/avjqrnazhlt908wzxang 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/kdrcf8kyhtfnd5vxktrk 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/akqqicjy8hf2ydfmhjdr 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/honkt3mmwpqd7we1ohjo 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/q0mh07vhpqbuzggzwygi 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/n4lx7appnsliace2q8xm 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/qgyoqoyaur7ljsgujnoh 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/pnbv1swtpibrvywun35k 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/ivs9brzd8vsyynqzmsfh 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/kiyq1da1cyoawic6z6qx 1600w\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/oesvv6cc6desxi1bmvss\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/hofjkfqsxfsswzg254eh 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/rwp51dbctkpdbmyuoorz 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/msup4hymqklzmrltpfzb 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/bocucpqn7ybvojm4hcjs 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/aplyekfffex5q1fqayab 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/rhxbxwg5pdwcwqs75amh 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/fhy8b8xxnwca5gv23oif 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/ngpsqydeffmjwguk5tte 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/xakzuohdffupvayx8e6j 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/hlsikqurrhw13fyybnb8 1600w\"></p><p>Number of DALYs lost to disease in Nigeria, Colombia and Spain (in that order). The red bars are CMNN diseases, the blue ones are non-communicable diseases and the gray ones are accidents and injuries. I chose Spain as a point of comparison thinking that it is a developed country similar in some aspects to Colombia. Source: Our World in Data.</p><p>&nbsp;</p><p>In Nigeria the four main causes of lost health are neonatal disorders, enteric infections (mainly diarrhea and associated conditions), respiratory infections, and tropical diseases. In contrast, both in Colombia and Spain communicable diseases comprise the main sources of years of lost health, with the exception of interpersonal violence in Colombia which is unusually high both in the country and in the Latin American region.</p><p>To make figures comparable, we can calculate the years of health lost (DALYs) to CMNN diseases per 100,000 inhabitants. The differences among the three countries are overwhelming. Nigerians lose 9.7 times more years of health to CMNN diseases than Colombians, who in turn have a burden 3 times higher than the Spanish. A similar pattern is found in the incidence of extreme poverty, where the African country has a rate 9.6 times higher than Colombia, which in turn has a rate 4.8 times higher than Spain.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/uyhzyweebs5vnu5xkjrl\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/kwdgjqde8omdmlk1xgaa 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/pbvus9vyn5pdnvnsz1sj 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/sfmsk2yyaitmrkm1ke7s 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/wspr2q3ehsjcgbajvghf 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/eenyh2buffsaj6xqbrxt 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/hoppimlkl1k5mk03aqeu 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/znwrtxxjvtcbtx4j0lw3 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/r5gptlayazyfjqdnsapb 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/wiszbwtcvvbnot2inyeq 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/nctdji9fgm5ugumrkuo8 1600w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/otsczcox6enxtnshopkn\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/dmzjk1kuqq8eujdpgxnn 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/iofz62iw9npds28ecdok 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/onb0ziqegc52prpigodk 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/ufdtezedlmsbssoitaiq 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/fli76raxz43khirprnzo 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/b9f5ywafnh8runjw5hu2 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/kd4tvi036jop82m4dvlx 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/rpai65vpg3sn95pwcapd 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/aodict30owj8yk76fswv 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/wfqp4evkbcat4siuzpzj 1600w\"></p><p>Components lost per 100,000 population for Nigeria, Colombia, and Spain (top) and DALYs lost per 100,000 population compared to median income for various countries (bottom). Source: Our World in Data.</p><p>Even if the differences are staggering at the country level, perhaps we could hope for greater parity by focusing on the poorest regions of each country. Although it\u2019s difficult to find data on health outcomes disaggregated at the regional level, I found figures for mortality of children under 5 years by department/state. This seemed like a reasonable approximation to me as&nbsp;<a href=\"https://ourworldindata.org/grapher/disease-burden-from-communicable-diseases-by-age?stackMode=relative&amp;country=~COL\"><u>45% of the health burden</u></a> by CMNN diseases in Colombia and&nbsp;<a href=\"https://ourworldindata.org/grapher/disease-burden-from-communicable-diseases-by-age?stackMode=relative&amp;country=~NGA\"><u>75% of the burden</u></a> in Nigeria falls on children under five years.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/vc4ekuvxke38xdmbzfbh\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/mugc6va22mlhsbl9ihl5 138w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/ds1rmddybprzqtbamkwl 218w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/fftyfpoqmccdt8olsllm 298w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/r4ozdclt7bhqjcn7l21o 378w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/djssmetbing61qtc4t4f 458w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/zkchcieemqh1ojlrbpa2 538w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/lf3hwqwyzsnr19nbczmh 618w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/uuvybf8qbthcehkgmazj 698w\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/b9qne4axcdc7bghttei3\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/rvaewldu2xehmscl8rr9 138w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/og0xvnv83iai9lvjuuhe 218w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/wxtkqepwhmgwh3r2rszm 298w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/ygo72ekfdioswl0edidx 378w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/vx5nqombxp6rzc4jdxzx 458w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/psgsbzzi4iawuclay8dh 538w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/yl2wo7pzqazx1ebny3hc 618w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/k4hald5ji3zzvxbavz3a 698w\"></p><p>Percentage of children born alive who die before the age of 5 for all departments/states in Colombia and Nigeria (above) and the same figure for the 5 regions with the highest under-5 mortality in each country (below). Own elaboration from&nbsp;<a href=\"https://www.nature.com/articles/s41586-019-1545-0\"><u>IHME data</u></a>.</p><p>In Jigawa, the state with the highest infant mortality in Nigeria, around 1 in 6 children (15%) born alive die before the age of 5. For the department with the highest infant mortality in Colombia (Vaup\u00e9s) the same figure is 1 in 30 (3%). The picture is similar across all regions, with Nigerian states having consistently higher infant mortality rates than Colombian departments.</p><h2>Neglectedness (per person)</h2><p><i><strong>Headline result:&nbsp;</strong>According to my estimation, Colombia spends roughly the same amount per inhabitant on combating CMNN diseases than Nigeria. Because health spending in Nigeria falls mostly on patients, I estimate that within the poorest regions in each country Colombians spend twice as much on average to fight CMNN diseases, but I\u2019m less certain about that estimate than the previous ones.</i></p><p>A problem is more neglected the less resources are spent in trying to solve it. Although such resources can take many forms (e.g. labor, technology, etc.), we often use monetary spending as a proxy for the total resources spent on the problem. Thanks to the Institute for Health Metrics and Evaluation, we have data on total health spending by country from all sources: governments, international donations, private insurance, and out-of-pocket spending by patients.&nbsp;</p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/bsbsn40ttyueey5cjamv\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/dha7jbzroxj2d3mf2t5l 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/a1tizsf8cb5qyfya8kcf 170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/qh2gxsbcxxjvdj86ueld 250w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/ta5irsncyowndslvbbwk 330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/e1x64w8idiroy2ajcgux 410w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/tk18fyi89du0w3bssx1z 490w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/tr5rwnh8jpsvypnmepp0 570w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/mw1alskuf17y2ul3zf6p 650w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/ipf6sp5knue0yynytwmr 730w\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/jl5hgv91pbjd00xhbslz\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/o6tmh9hgsfl3jbre4vtt 98w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/elt1tyyvhcidtkqvzra6 178w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/aqchobqdkigkilmc3hmk 258w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/dl1mwv0xdzv4o32v5sxv 338w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/pz3jvxlamx7mhewtpjn7 418w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/ydtqbavpu6bkwb76v7xe 498w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/dzancf2opszuqwzfmydm 578w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/rjjn41so9ecaouizk7wb 658w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/fbasvsfno1lbitkyuweo 738w\"></strong></p><p>Health spending for Colombia (top) and Nigeria (bottom) in 2018 and projected for 2050.Source:&nbsp;<a href=\"https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(21)01258-7/fulltext\"><u>Global Burden of Disease 2020 Health Financing Collaborator Network</u></a>.</p><p>Health spending per patient in Colombia for 2018 was about 6 times higher than in Nigeria. The largest contribution to this gap is government spending, which is 25 times higher in Colombia than in Nigeria ($330 vs. $12) for 2018. The contribution of patients treated is of similar magnitude in both countries ($65), while international contributions are 12 times higher in Nigeria, but represent only a small fraction of spending in both countries ($4.5 and $0.35)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5koa910vprv\"><sup><a href=\"#fn5koa910vprv\">[1]</a></sup></span>.</p><p>However, for our estimation we care only about the fraction of total expenditure devoted to fighting CMNN diseases. According to&nbsp;<a href=\"https://apps.who.int/nha/database/Select/Indicators/en\"><u>WHO\u2019s Global Health Expenditure Database</u></a>, 75% of the spending in healthcare in Nigeria is directed to that purpose. And, although I couldn\u2019t find the same figure for Colombia, we can approximate it by taking the average expenditure from 4 other countries in the database with similar GDP per c\u00e1pita and CMNN disease burden to Colombia:</p><p>Share of health expenditure devoted to CMNN diseases for countries with similar GDP per c\u00e1pita and disease burden to Colombia. Source:&nbsp;<a href=\"https://apps.who.int/nha/database/Select/Indicators/en\"><u>WHO\u2019s Global Health Expenditure Database</u></a> and Our World in Data</p><figure class=\"table\"><table><thead><tr><th style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>Country</p></th><th style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>Share of health expenditure to CMNN diseases</p></th><th style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>GDP per c\u00e1pita ($ US PPP)</p></th><th style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>Burden of CMNN diseases per 100.000 habitants</p></th></tr></thead><tbody><tr><th style=\"background-color:hsl(0, 0%, 90%);border:0.75pt solid #cccccc;padding:2pt\"><p>Colombia</p></th><td style=\"background-color:hsl(0, 0%, 90%);border:0.75pt solid #cccccc;padding:2pt\"><p>-</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:0.75pt solid #cccccc;padding:2pt\"><p>$ 13.449</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:0.75pt solid #cccccc;padding:2pt\"><p>3.044</p></td></tr><tr><th style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>Tunisia</p></th><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>15,3%</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>$ 11.385</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>2.555</p></td></tr><tr><th style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>Armenia</p></th><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>11,6%</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>$ 12.715</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>2.704</p></td></tr><tr><th style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>Sri Lanka</p></th><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>30,2%</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>$ 12.860</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>2.889</p></td></tr><tr><th style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>Georgia</p></th><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>11,0%</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>$ 14.253</p></td><td style=\"border:0.75pt solid #cccccc;padding:2pt\"><p>3.016</p></td></tr><tr><th style=\"background-color:hsl(0, 0%, 90%);border:0.75pt solid #cccccc;padding:2pt\"><p>Average (Excluding Colombia)</p></th><td style=\"background-color:hsl(0, 0%, 90%);border:0.75pt solid #cccccc;padding:2pt\"><p>17,0%</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:0.75pt solid #cccccc;padding:2pt\"><p>$ 12.804</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:0.75pt solid #cccccc;padding:2pt\"><p>2.791</p></td></tr></tbody></table></figure><p>Using that extrapolation, Nigeria seems to devote five times more of its healthcare expenditure to CMNN diseases, making both countries spend roughly the same on absolute terms ($79 for Colombia vs $60 for Nigeria).&nbsp;</p><p>Once again, we can investigate how that result varies when focusing on the most vulnerable regions. In Colombia, the State\u2019s health spending is coordinated at the central government which makes transfers to each municipality for their health expenses proportional to their population. The amount they transfer increases with the proportion of the population that contributes to a health payroll tax, the difficulty of transportation to the region, and the age of the population (a higher transfer for both small children and the elderly).&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/xnwaipxirfsfkp62io7a\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/ss3cqmk1lvofm8xfrmae 117w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/nyxklscxnfkvvlrpygd7 197w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/kuduys8rkghlhqcrsrnj 277w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/ukdsdkz3oxrfppcpgkey 357w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/kdt1vmty9vfh85mpxrpi 437w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/t7soavpfznrf9k5yggzx 517w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aNsBJYpGovgJqWC9v/s5xt0u5z1yzavahogaaf 597w\"></figure><p>Incidence of multidimensional poverty by municipality in Colombia (left, darker is higher poverty) and health spending by municipality grouped by quintiles (right, darker is higher except for the striped pattern which corresponds to \u201cNo Information\u201d).<a href=\"https://www.banrep.gov.co/sites/default/files/publicaciones/archivos/dtser_220.pdf\"><u>Orozco-Galle (2015)</u></a> and&nbsp;<a href=\"https://www.dane.gov.co/index.php/estadisticas-por-tema/pobreza-y-condiciones-de-vida/pobreza-multidimensional\"><u>DANE (2020)</u></a>.</p><p>Despite the fact that payroll contributions should be correlated with income levels at each municipality, which could result in richer municipalities receiving bigger transfers,&nbsp;<a href=\"https://www.banrep.gov.co/sites/default/files/publicaciones/archivos/dtser_220.pdf\"><u>Orozco-Gallo (2015)</u></a> report they don\u2019t find big disparities in health spending across the country. On average, the quintile of municipalities that spend the most on health invests 4 times more than the quintile of least health spending. In addition, those municipalities that spend less on health generally do not correspond to the poorest, with several municipalities in the two poorest departments (La Guajira and Choc\u00f3) receiving funds that place them in the top two quintiles of spending.</p><p>For Nigeria, I couldn\u2019t find information on health expenditures by region. However, given that 79% of their health spending falls on patients, we should expect regions with a poorer population to spend less on health. For reference, in a&nbsp;<a href=\"https://bmcresnotes.biomedcentral.com/articles/10.1186/s13104-019-4048-z/tables/2\"><u>survey of household\u2019s expenses in C\u00f4te d\u2019Ivoire</u></a>, rural households in the bottom quintile of expenditure in consumption (a way of approximating the poorest households) reported spending around 40% less in out-of-pocket health expenditures than rural households in the third quintile of consumption.&nbsp;</p><p>If we\u2019re willing to assume that the poorest regions in Nigeria spend roughly 40% less in fighting CMNN diseases than the whole country and that spending in CMNN diseases in Colombia is roughly similar to the national level, we can estimate that the poorest regions in Colombia devote about twice as much resources to fighting CMNN diseases than their Nigerian counterparts.&nbsp;</p><h2>Tractability</h2><p><i><strong>Headline results:&nbsp;</strong>Assuming logarithmic returns (which may or may not be justified), health interventions in Colombia and Nigeria would be similarly tractable</i></p><p>Tractability refers to what percentage of the problem would we solve if we increased the resources we invest by a fixed percentage (e.g. increasing spending by 10% in Colombia from $460 to $506 and in Nigeria from $80 to $88).&nbsp;</p><p>Owen Cotton-Barrat has exposed&nbsp;<a href=\"http://www.fhi.ox.ac.uk/theory-of-log-returns/\"><u>some</u></a>&nbsp;<a href=\"http://www.fhi.ox.ac.uk/law-of-logarithmic-returns/\"><u>reasons</u></a> why in cases where we don\u2019t know much about a problem, our expectations should be that its tractability follows logarithmic returns. That is, for every 1% increase in the resources devoted to the problem we should expect a constant increase in the percentage of the problem we solve regardless of how many resources we have already invested.&nbsp;</p><p>For the case of health interventions we probably know some things about the cause area, which could allow us to improve upon the assumption of logarithmic returns. However, I\u2019m not sure if I can come up with tractability considerations that apply to all or most approaches for combating CMNN diseases within a country, so I\u2019ll just default to assuming logarithmic implies. This assumption would imply that the scale and neglectedness of the problem would be independent of its tractability, leading to the conclusion that health interventions in both countries are similarly tractable.&nbsp;</p><h1>Conclusions</h1><p>Estimated ratio of the cost-effectiveness of interventions for combating CMNN diseases in Nigeria with respect to Colombia broken down in the three SNT factors.</p><figure class=\"table\"><table><thead><tr><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Scope</p></th><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Scale (per person)</p></th><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Neglectedness (per person)</p></th><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Tractability</p></th><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Cost-effectiveness ratio</p></th></tr></thead><tbody><tr><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Whole country</p></th><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>10x</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1x</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1x</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>10x</p></td></tr><tr><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Most vulnerable regions</p></th><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>5x</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>2x</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1x</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>10x</p></td></tr></tbody></table></figure><p>Multiplying the 3 factors, my application of the SNT framework estimates that interventions that combat CMNN diseases in Nigeria are 10 times more cost-effective than in Colombia, a conclusion which doesn\u2019t change if we compare only the most vulnerable regions within each country. Most of the cost-effectiveness gap comes from the higher burden of CMNN diseases in Nigeria.</p><p>The way I think about this result is similar to the way I conceive of differences in average income (GDP) across countries. We usually can\u2019t convert differences in income directly into differences in quality of life, but when you compare countries across very different income levels, most often the highest income one has a better quality of life. That\u2019s partly because income directly improves the standards of living, but also because income tends to correlate with other development indicators, such that countries that differ substantially in their income levels will also differ substantially on other dimensions of what makes lives go better.&nbsp;&nbsp;</p><p>Similarly, scale and neglectedness do not necessarily translate directly into more effectiveness, but if we see a large enough difference in those dimensions, that suggests there could be substantial differences on how cost-effective interventions across the two sides of the comparison. I don\u2019t think that a 10x difference is sufficiently big to be confident that the best interventions in Nigeria are overwhelmingly more cost-effective than the best interventions in Colombia. But if I had to compare two concrete health interventions addressing CMNN diseases, one from Colombia and one from Nigeria, and I didn\u2019t have the chance of looking into the specifics of any of them, I\u2019d usually bet that the Nigerian intervention would be a couple times more cost-effective.&nbsp;</p><p>As a last thing, I want to suggest a few lenses or use cases for the estimate I\u2019ve found. I wouldn\u2019t stand too strongly behind any of them, but I hope they\u2019re at least useful to start the conversation.&nbsp;</p><p><strong>A suggestion of finer gradations of poverty</strong>: Before starting this project I lent more credence to an argument like \u201cNigeria may be much poorer than Colombia as a whole, but there are also very poor regions in Colombia, so we should be able to find similarly cost-effective opportunities there to the best we\u2019ve found in Nigeria\u201d. Now that I\u2019ve collected some data on living conditions in the two countries, that argument seems much less appealing.</p><p>It turns out that the poorest regions in Colombia still have a much lower incidence of extreme poverty<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefp102pktlq19\"><sup><a href=\"#fnp102pktlq19\">[2]</a></sup></span>&nbsp;and disease than the poorest regions in Nigeria. I\u2019m not sure if that\u2019s caused by lower state capacity, worse climatic conditions, or anything else, but the difference is wide enough that it feels somewhat wrong to me to talk about poverty like it means the same in the two contexts.&nbsp;</p><p>I also expect this difference to hold even for conditions other than health. Measures like health, education and income tend to together and also often track other dimensions of quality of life and development (a point often made by economist&nbsp;<a href=\"https://en.wikipedia.org/wiki/Capability_approach\"><u>Amartya Sen</u></a>). If a region seems worse on those measures my impression is that it will probably have many more problems than it might seem at first glance.&nbsp;</p><p><strong>A multiplier to pile upon other career considerations</strong>: Suppose you\u2019re trying to decide between two concrete career options. Let\u2019s say you\u2019re choosing between doing a Masters in Public Health in Colombia or abroad. Suppose also that by staying in Colombia you could attend a university that frequently places its graduates in influential positions in the national government. You expect that studying there would allow you to gain influential contacts and earn a reputation within the country. On the contrary, suppose your best option for studying abroad is at a more internationally renowned university, but it has less direct contacts with local governments. However, going there would give you more flexibility in choosing the country and organization that you work on<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefijgua7b8p2\"><sup><a href=\"#fnijgua7b8p2\">[3]</a></sup></span>.&nbsp;</p><p>If you believe that&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/GzmJ2uiTx4gYhpcQK/effectiveness-is-a-conjunction-of-multipliers\"><u>effectiveness is a conjunction of multipliers</u></a>, you could approach such decision by estimating different factors that independently contribute to your ultimate impact and multiplying them together:</p><figure class=\"table\"><table><thead><tr><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Consideration</p></th><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Multiplier for Colombia</p></th><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Multiplier for abroad</p></th></tr></thead><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Local network and credentials leading to a greater influence and leverage within the Colombian government</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>8x</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1x</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Ability to choose the most effective organizations</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1x</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>3x</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Ability to target your efforts at the most vulnerable populations in the world (taken from this document)</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1x</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>10x</p></td></tr><tr><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Simplified aggregate</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1x</p></td><td style=\"background-color:hsl(0, 0%, 90%);border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>3.75x</p></td></tr></tbody></table></figure><p>Overall, your estimation suggests studying abroad would lead you to have approximately 4 times more impact. You know that there are some factors that you didn\u2019t include, but in this case you think they\u2019re unlikely to change the direction of the overall result. This is a made-up situation, but I can imagine many cases in which it could be useful to have a rough intuition of the tradeoff between helping a particular country and focusing on the most vulnerable people.&nbsp;</p><p>For some of those scenarios you may want to use the estimate in this document as a starting point, while for many others it could be more informative to estimate directly what you care about. For example, if your expertise is most relevant to working on a specific health cause, say deworming, I think you\u2019d do better by trying to estimate the difference in cost-effectiveness in that area if you can find the relevant data to do it. The information you get by doing that will probably be much more relevant to your decision and&nbsp;<a href=\"https://www.lesswrong.com/posts/2jp98zdLo898qExrr/hug-the-query\"><u>could override the conclusions</u></a> from this more general analysis.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1r8phfzxs8d\"><sup><a href=\"#fn1r8phfzxs8d\">[4]</a></sup></span></p><p><strong>A template for comparing health interventions in other countries:&nbsp;</strong>I focused on comparing health interventions between Colombia and Nigeria out of a partial consideration for helping students in Colombia and because it would be easier than including more countries. However, most of the datasets I used are available for many more countries, so it should be easy to replicate the analysis I did for a couple other countries of your choosing spending at most a couple hours.&nbsp;</p><p>I haven\u2019t organized the data I used such that it would be intelligible to any other human, but I could easily do so if someone expresses interest in that in the comments.&nbsp;&nbsp;</p><p><br><br><br><i>Thanks to everyone who heard me expose these ideas even when they were less than half-baked. I appreciated their patience and their comments. I\u2019m especially grateful to Luis Mota, \u00c1ngela Aristiz\u00e1bal and Jaime Fern\u00e1ndez for reviewing previous drafts of this document and for their comments and support.&nbsp;</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5koa910vprv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5koa910vprv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>My impression is that the pattern we see in international aid is replicated in areas other than health. Although the poorest countries receive proportionally more international aid than richer countries like Colombia,those amounts are negligible compared to the spending of the government and the citizens of the richest countries. This makes the total or relative magnitude of international assistance that a country receives an erroneous measure of how many resources are invested to solve the problem.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnp102pktlq19\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefp102pktlq19\">^</a></strong></sup></span><div class=\"footnote-content\"><p>According to a linear extrapolation I did from the poverty in Colombia at the two national poverty lines, around 30-40% of people in the poorest departments in Colombia live under the international extreme poverty line. In the poorest states in Nigeria around 80% of people live under that same poverty line.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnijgua7b8p2\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefijgua7b8p2\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is an imaginary situation. I don\u2019t know if these are important considerations for this particular career decision.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1r8phfzxs8d\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1r8phfzxs8d\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Also, this is me brazenly inserting my opinion here, but I\u2019d like for some of the students at my university to honestly ask themselves: \u201cFor the concrete career paths I\u2019m considering, do the considerations that suggest I\u2019d have a bigger impact on my home country add up to more than a 10x multiplier?\u201d If not, perhaps they could have a greater impact by working on causes abroad. That wouldn\u2019t mean they\u2019d have to focus abroad, there are many considerations beyond impact for choosing a career, but it\u2019s good to have clarity on why you\u2019re doing what you\u2019re doing.&nbsp;</p></div></li></ol>", "user": {"username": "Alejandro Acelas"}}, {"_id": "uBSwt2vEGm4RisLjf", "title": "Holden Karnofsky\u2019s recent comments on FTX", "postedAt": "2023-03-24T11:44:02.978Z", "htmlBody": "<p>Holden Karnofsky has recently shared some reflections on EA and FTX, but they\u2019re spread out and I\u2019d guess that few people have seen them, so I thought it could be useful to collect them here. (In general, I think&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/6trt8mTsKfqJJbfJa/suggestion-eas-should-post-more-summaries-and-collections\"><u>collections</u></a> like this can be helpful and under-supplied.) I've copied some comments in full, and I've put together a simpler list of the links in this footnote.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefv8mm52bfzdg\"><sup><a href=\"#fnv8mm52bfzdg\">[1]</a></sup></span></p><p>These comments come after a few months \u2014 there\u2019s some explanation of why that is in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qFEwQbetaaSpvHm9e/my-takes-on-the-ftx-situation-will-mostly-be-cold-not-hot\"><u>this post</u></a> and in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/CcJsh4JcxEqYDaSte/spreading-messages-to-help-with-the-most-important-century?commentId=TJWLCN9ACBMsckJCd\"><u>this comment</u></a>.</p><p><strong>Updates after FTX</strong></p><p>I found the following <a href=\"https://forum.effectivealtruism.org/posts/qFEwQbetaaSpvHm9e/my-takes-on-the-ftx-situation-will-mostly-be-cold-not-hot?commentId=tABmDuff9YaiCd8wg\">comment (a&nbsp;<u>summary of updates he\u2019s made after FTX)</u></a> especially interesting (please note that I\u2019m not sure I agree with everything):&nbsp;</p><blockquote><p>Here\u2019s a followup with some reflections.</p><p>Note that I discuss some takeaways and potential lessons learned in <a href=\"https://www.vox.com/future-perfect/23564571/effective-altruism-sam-bankman-fried-holden-karnofsky-ai\">this interview</a>.</p><p>Here are some (somewhat redundant with the interview) things I feel like I\u2019ve updated on in light of the FTX collapse and aftermath:</p><ul><li>The most obvious thing that\u2019s changed is a tighter funding situation, which I addressed&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FHJMKSwrwdTogYLGF/we-re-no-longer-pausing-most-new-longtermist-funding\">here</a>.</li><li>I\u2019m generally more concerned about the dynamics I wrote about in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/T975ydo3mx8onH3iS/ea-is-about-maximization-and-maximization-is-perilous\">EA is about maximization, and maximization is perilous</a>. If I wrote that piece today, most of it would be the same, but the \u201cAvoiding the pitfalls\u201d section would be quite different (less reassuring/reassured). I\u2019m not really sure what to do about these dynamics, i.e., how to reduce the risk that EA will encourage and attract perilous maximization, but a couple of possibilities:<ul><li>It looks to me like the community needs to beef up and improve investments in activities like \u201cidentifying and warning about bad actors in the community,\u201d and I regret not taking a stronger hand in doing so to date. (Recent sexual harassment developments reinforce this point.).</li><li>I\u2019ve long wanted to try to write up a detailed intellectual case against what one might call \u201chard-core utilitarianism.\u201d I think arguing about this sort of thing on the merits is probably the most promising way to reduce associated risks; EA isn\u2019t (and I don\u2019t want it to be) the kind of community where you can change what people operationally value just by saying you want it to change, and I think the intellectual case has to be made. I think there is a good substantive case for pluralism and moderation that could be better-explained and easier to find, and I\u2019m thinking about how to make that happen (though I can\u2019t promise to do so soon).</li></ul></li><li>I had some concerns about SBF and FTX, but I largely thought of the situation as not being my responsibility, as Open Philanthropy had no formal relationship to either. In hindsight, I wish I\u2019d reasoned more like this: \u201cThis person is becoming very associated with effective altruism, so whether or not that\u2019s due to anything I\u2019ve done, it\u2019s important to figure out whether that\u2019s a bad thing and whether proactive distancing is needed.\u201d</li><li>I\u2019m not surprised there are some bad actors in the EA community (I think bad actors exist in any community), but I\u2019ve increased my picture of how much harm a small set of them can do, and hence I think it could be good for Open Philanthropy to become more conservative about funding and associating with people who might end up being bad actors (while recognizing that it won\u2019t be able to predict perfectly on this front).</li><li>Prior to the FTX collapse, I had been gradually updating toward feeling like Open Philanthropy should be less cautious with funding and other actions; quicker to trust our own intuitions and people who intuitively seemed to share our values; and generally less cautious. Some of this update was based on thinking that some folks associated with FTX were being successful with more self-trusting, less-cautious attitudes; some of it was based on seeing few immediate negative consequences of things like the Future Fund regranting program; some of it was probably a less rational response to peer pressure. I now feel the case for caution and deliberation in most actions is quite strong - partly because the substantive situation has changed (effective altruism is now enough in the spotlight, and controversial enough, that the costs of further problems seem higher than they did before).<ul><li>On this front, I\u2019ve updated a bit toward my previous self, and more so toward&nbsp;<a href=\"https://www.openphilanthropy.org/about/team/alexander-berger/\">Alexander</a>\u2019s style, in terms of wanting to weigh both explicit risks and vague misgivings significantly before taking notable actions. That said, I think balance is needed and this is only a fairly moderate update, partly because I didn\u2019t update enormously in the other direction before. I think I\u2019m still overall more in favor of moving quickly than I was ~5 years ago, for a number of reasons. In any case I don\u2019t expect there to be a dramatic visible change on this front in terms of Open Philanthropy\u2019s grantmaking, though it might be investing more effort in improving functions like community health.</li></ul></li><li>Having seen the EA brand under the spotlight, I now think it isn\u2019t a great brand for wide public outreach. It throws together a lot of very different things (global health giving, global catastrophic risk reduction, longtermism) in a way that makes sense&nbsp;<i>to me</i> but seems highly confusing to many, and puts them all under a wrapper that seems self-righteous and, for lack of a better term, punchable? I still think of myself as an effective altruist and think we should continue to have an EA brand for attracting the sort of people (like myself) who want to put a lot of dedicated, intensive time into thinking about what issues they can work on to do the most good; but I\u2019m not sure this is the brand that will or should attract most of the people who can be helpful on key causes. I think it\u2019s probably good to focus more on building communities and professional networks around specific causes (e.g., AI risk, biorisk, animal welfare, global health) relative to building them around \u201cEA.\u201d</li><li>I think we should see \u201cEA community building\u201d as less valuable than before, if only because one of the biggest seeming success stories now seems to be a harm story. I think this concern applies to community building for specific issues as well. It\u2019s hard to make a clean quantitative statement about how this will change Open Philanthropy's actions, but it\u2019s a factor in how we recently&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FHJMKSwrwdTogYLGF/we-re-no-longer-pausing-most-new-longtermist-funding\">ranked grants</a>. I think it'll be important to do quite a bit more thinking about this (and in particular, to gather more data&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/NP5B6yNMoZiZbmEQ8/open-phil-ea-lt-survey-2020-introduction-and-summary-of\">along these lines</a>) in the longer run.</li></ul></blockquote><p><strong>Other recent comments</strong></p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/mCCutDxCavtnhxhBR/some-comments-on-recent-ftx-related-events?commentId=mGb7p3i4ihp89oJrG\"><u>On who held responsibility for the relationship between SBF and EA</u></a><ul><li>\u201cThere was no one with official responsibility for the relationship between FTX and the EA community. I think the main reason the two were associated was via FTX\u2019s/Sam having a high profile and talking a lot about EA - that\u2019s not something anyone else was able to control. (Some folks did ask him to do less of this.)<br>It\u2019s also worth noting that we generally try to be cautious about power dynamics as a funder, which means we are hesitant to be pushy about most matters. In particular, I think one of two major funders in this space attacking the other, nudging grantees to avoid association and funding from it, etc. would\u2019ve been seen as strangely territorial behavior absent very strong evidence of misconduct.<br>That said: as mentioned in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qFEwQbetaaSpvHm9e/my-takes-on-the-ftx-situation-will-mostly-be-cold-not-hot?commentId=tABmDuff9YaiCd8wg\">another comment</a>, with the benefit of hindsight, I wish I\u2019d reasoned more like this: \u201cThis person is becoming very associated with effective altruism, so whether or not that\u2019s due to anything I\u2019ve done, it\u2019s important to figure out whether that\u2019s a bad thing and whether proactive distancing is needed.\u201d\u201d</li></ul></li><li><a href=\"https://forum.effectivealtruism.org/posts/mCCutDxCavtnhxhBR/some-comments-on-recent-ftx-related-events?commentId=nQuoY3XAjK3R3C8k4\"><u>On whether he knew about unethical behavior by Sam Bankman-Fried</u></a><ul><li>\u201cIn 2018, I heard accusations that Sam had communicated in ways that left people confused or misled, though often with some ambiguity about whether Sam had been confused himself, had been inadvertently misleading while factually accurate, etc. I put some effort into understanding these concerns (but didn\u2019t spend a ton of time on it; Open Phil didn\u2019t have a relationship with Sam or Alameda).<br>I didn\u2019t hear anything that sounded anywhere near as bad as what has since come out about his behavior at FTX. At the time I didn\u2019t feel my concerns rose to the level where it would be appropriate or fair to publicly attack or condemn him. The whole situation did make me vaguely nervous, and I spoke with some people about it privately, but I never came to a conclusion that there was a clearly warranted (public) action.\u201d</li></ul></li><li><a href=\"https://forum.effectivealtruism.org/posts/b83Zkz4amoaQC5Hpd/time-article-discussion-effective-altruist-leaders-were?commentId=8wSzn8wYpDLQgRdQe\"><u>On a specific claim in the recent&nbsp;</u><i><u>TIME</u></i><u> article</u></a></li></ul><p>And there is more in&nbsp;<a href=\"https://podcasts.apple.com/us/podcast/can-effective-altruism-be-redeemed/id1081584611?i=1000596045174\"><u>his interview with&nbsp;</u><i><u>Vox</u></i></a> from January (here are&nbsp;<a href=\"https://www.vox.com/future-perfect/23564571/effective-altruism-sam-bankman-fried-holden-karnofsky-ai\"><u>edited highlights</u></a>).&nbsp;</p><p><i>(Thanks to the folks who suggested making this post &amp; helped.)</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnv8mm52bfzdg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefv8mm52bfzdg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>On why these comments didn't come earlier \u2014 <a href=\"https://forum.effectivealtruism.org/posts/qFEwQbetaaSpvHm9e/my-takes-on-the-ftx-situation-will-mostly-be-cold-not-hot\">post</a> &amp; <a href=\"https://forum.effectivealtruism.org/posts/CcJsh4JcxEqYDaSte/spreading-messages-to-help-with-the-most-important-century?commentId=TJWLCN9ACBMsckJCd\">comment</a>.&nbsp;</p><p>Updates post FTX \u2014 <a href=\"https://forum.effectivealtruism.org/posts/qFEwQbetaaSpvHm9e/my-takes-on-the-ftx-situation-will-mostly-be-cold-not-hot?commentId=tABmDuff9YaiCd8wg\">comment</a> (see also the <a href=\"https://podcasts.apple.com/us/podcast/can-effective-altruism-be-redeemed/id1081584611?i=1000596045174\">interview with <i>Vox</i></a>, <a href=\"https://www.vox.com/future-perfect/23564571/effective-altruism-sam-bankman-fried-holden-karnofsky-ai\">edited highlights</a>)</p><p>Responsibility \u2014 <a href=\"https://forum.effectivealtruism.org/posts/mCCutDxCavtnhxhBR/some-comments-on-recent-ftx-related-events?commentId=mGb7p3i4ihp89oJrG\">comment</a>.</p><p>SBF \u2014 <a href=\"https://forum.effectivealtruism.org/posts/mCCutDxCavtnhxhBR/some-comments-on-recent-ftx-related-events?commentId=nQuoY3XAjK3R3C8k4\">comment</a>.&nbsp;</p><p>Claim from the <i>TIME</i> &nbsp;article \u2014 <a href=\"https://forum.effectivealtruism.org/posts/b83Zkz4amoaQC5Hpd/time-article-discussion-effective-altruist-leaders-were?commentId=8wSzn8wYpDLQgRdQe\">comment</a>.&nbsp;</p></div></li></ol>", "user": {"username": "Lizka"}}, {"_id": "gu4KarTNSkt6dQuBe", "title": "Can anyone reassure me about EA work culture?", "postedAt": "2023-03-24T04:56:40.711Z", "htmlBody": "<p><i>I'm new to posting to the forum and this was rushed, so I welcome you to point out any obvious improvements to the way I've asked this question/formatted this post in the comments. I'm posting anonymously so I'm kindly requesting that you don't ask me if this is me if you think it's me.&nbsp;</i></p><h1>TL;DR</h1><p>I'm concerned that there are no/very few roles at EA-aligned orgs that don't lead to you feeling like you're working <i>all the time</i>. I feel like I need to be available to community members at all times of the day on everyday of the week as a community builder. Ops people have <a href=\"https://forum.effectivealtruism.org/posts/ijwybRLgywP7M5XLZ/some-problems-in-operations-at-ea-orgs-inputs-from-a-dozen#Unrealistic_expectations\">expressed</a> that they feel they need to be always on call. Many EAs I know work more than 40 hours weekly and some also work on weekends. I want to transition away from what I'm currently doing partially because of this feeling, but it seems like I might not find a role that escapes it.</p><p>Ideally, people would answer this question with either:</p><ul><li>Some reassurance that they are in a job role where they don't have to be on call all the time, with a description of the job role</li><li>Reassurance that they are in a role where they <i>could </i>be on call all the time, but it's been possible to set up their work environment with the right boundaries/norms such that they don't feel like they're on call all the time. How? Do you experience any negatives from doing this, e.g. judgement from others, bottlenecking others, etc.?</li><li>Maybe contributions from people who also feel that this is an issue they're facing - this might be an imagined issue on my part, I wonder if there are others who are also worried/experiencing similar?</li><li>Opinions on whether it's normal to expect certain roles to feel demanding in this way</li><li>Maybe some advice</li></ul><h1>Extra context</h1><p><strong>What am I concerned about?</strong></p><p>My current role would probably be considered a meta community building role. One of the things that has made me update against this being a suitable style of role for me going forward is that (amongst many other things) I have felt quite uniquely worn out by this role.&nbsp;</p><p>Don't get me wrong - this is not the <i>worst </i>job I've ever had and I've learnt a lot and feel good about any potential impact I might have had in my role. My problem is that I often feel like I need to be available to community members at all times of the day on everyday of the week. This is not sustainable for me and even if it was, I don't want to live a life centred around and tethered to my job, even if I believe my job is important and impactful.</p><p>I understand that for many EAs, working on something that is positive in expectation (and also acknowledging that it's reasonable to expect that more hours spent on something impactful = more impact in many cases) is a fierce driving force and means that a life spent mostly at work feels net good for them. And I also think it's really admirable - I expect that even someone who <i>loves </i>working long hours near daily probably has to work through some resistance to this, too, on some days.</p><p>***(INTERLUDE/EDIT: the paragraph above makes it seem like the problem is long work hours. I think I've confused my point slightly but I'm leaving the paragraph in because I still endorse it. To be clear/more accurate, though, I think <i>my</i> problem is more specifically how I've phrased it above: feeling like I'm needed at all times. It's unclear to me (because I have no experience in such a role) if a role where I could do e.g. deep work for long hours would make me as unhappy as my current role has; I'd be interested to test this, tbh.)***</p><p>But for me, I don't think this is healthy. Or at least, it doesn't feel net good for me.</p><p>Therefore, I've been scrambling to find a new role in something else. I've been quite eager to explore operations because I have enjoyed operations style work in the past. But I was somewhat alarmed reading <a href=\"https://forum.effectivealtruism.org/posts/ijwybRLgywP7M5XLZ/some-problems-in-operations-at-ea-orgs-inputs-from-a-dozen#Unrealistic_expectations\">this recent post about problems in operations at EA orgs.</a> It seems that they also feel like they're at work all the time: \"Employers have unrealistic expectations for ops professionals. Ops people are expected to do too much in too little time and always be on call.\"</p><p>I'm really worried that I'll never be able to find an impactful job that doesn't require me to overwork myself. I understand that there are some other fun dynamics at play here - competition for roles, signalling about seriousness/commitment to doing good, social dynamics<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhgrxgorwomo\"><sup><a href=\"#fnhgrxgorwomo\">[1]</a></sup></span>, etc. These dynamics might mean that I'm just not the right kind of person to be working at an EA org altogether - perhaps we <i>want </i>only the people who are dedicated enough to be happy to be on call always? Maybe the capability/desire/willingness to do this is a proxy for \"talent\"? I see echoes of this sentiment across the forum and I welcome you to express this in a comment if this is your opinion because I'd like to hear more of these opinions (I think people suppress what they actually think about this sometimes - \"this\" being the suitability of EA and EA org roles for different kinds of people).&nbsp;</p><p><strong>What exactly am I looking for reassurance about?</strong></p><p>Ideally, people would answer this question with either:</p><ul><li>Some reassurance that they are in a job role where they don't have to be on call all the time, with a description of the job role</li><li>Reassurance that they are in a role where they <i>could </i>be on call all the time, but it's been possible to set up their work environment with the right boundaries/norms such that they don't feel that they're on call all the time. How? Do you experience any negatives from doing this, e.g. judgement from others, bottlenecking others, etc.?</li><li>Maybe contributions from people who also feel that this is an issue they're facing - this might be an imagined issue on my part, I wonder if there are others who are also worried/experiencing related issues?</li><li>Opinions on whether it's normal to expect certain roles to feel demanding in this way</li><li>Maybe some advice&nbsp;</li></ul><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhgrxgorwomo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhgrxgorwomo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>So the social dynamics bit is really interesting to me. I have (too) many thoughts on this and I'll write some real posts in the near future detailing some observations from doing meta/community building stuff first hand. I wanted to add a footnote to explain: I have a few (actually many on reflection) wonderful EA friends who support me a lot and encourage me to set more boundaries and I have and it does help somewhat. But man, do I feel a <i>strong </i>sense of judgement from some others when I do this. It's hard for me to know whether this is a me-issue or a them-issue or whether there's even an issue here. Regardless, I do think the feeling of judgement from others is actually a fairly common motivator within EA and I'm unsure how I feel about it. Where it's useful I guess it's good. I do sometimes wish that we were a little nicer/more considerate to each other within the community, though.&nbsp;</p></div></li></ol>", "user": {"username": "anotherEAonaburner"}}, {"_id": "743io3WyzezJbHowW", "title": "The Concept of Boundary Layer in Language Games and Its Implications for AI", "postedAt": "2023-03-24T13:50:40.967Z", "htmlBody": "<h2>Introduction</h2><p>AI research has made significant strides in recent years, particularly in the areas of machine learning and natural language processing. However, a fundamental challenge remains: understanding and accurately communicating meaning in natural language. This challenge is exacerbated by the concept of the \"<strong>boundary layer</strong>,\" which refers to the discrepancy between the intended meaning of a message and the meaning actually conveyed to the listener or reader. As individuals bring their own unique experiences and interpretations to the communication process, this can lead to misunderstandings and misinterpretations.</p><p>This paper explores the implications of the boundary layer for AI research. It argues that understanding and addressing the boundary layer is critical for developing accurate and effective natural language processing algorithms and human-AI interaction systems.</p><p>Overall, the concept of the boundary layer offers a valuable framework for understanding the difficulties of natural language understanding in the context of AI research. By acknowledging and mitigating the effects of the boundary layer, researchers can develop more effective AI systems that accurately interpret human language.</p><p>&nbsp;</p><h2>Ludwig Wittgenstein and Language Games</h2><p>The philosophy of Ludwig Wittgenstein has implications for AI research. Wittgenstein's \"language-game\" concept suggests that words only have meaning within a specific social practice or activity, which requires a more nuanced approach to language understanding. The concept of the \"private language\" suggests that language understanding cannot be achieved through individual data inputs or algorithms, but rather requires interaction with others. By recognizing the social and contextual nature of language use, AI systems can be designed to better understand and generate language, and to interact more effectively with human users.</p><p>&nbsp;</p><h2>Understanding the Boundary Layer</h2><p>The concept of the \"boundary layer\" in the context of language games refers to the idea that the meaning of language is always dependent on the specific social and cultural context in which it is used. This means that there is always a \"boundary\" or barrier between different language games or social contexts, which can make it difficult for speakers and listeners to fully understand each other.</p><p>The boundary layer can be seen as a kind of \"filter\" that affects the way in which language is received and interpreted by different individuals and groups. Because each language game has its own set of conventions and rules, it can be difficult for individuals from different language games to fully understand each other's meaning.</p><p>This can lead to misunderstandings, misinterpretations, and communication breakdowns, as the information is corrupted or distorted as it passes through the boundary layer between different language games. Therefore, the boundary layer represents a fundamental challenge to effective communication between different individuals and groups, and highlights the importance of developing a deep understanding of the cultural and social context in which language is being used.</p><p>For instance, in legal systems, technical jargon and legal terminology can make it difficult for individuals without a legal background to understand legal documents or communicate with lawyers effectively, leading to a boundary layer that hinders communication and understanding.</p><p>In the development of AI systems, the boundary layer represents a significant challenge when it comes to natural language processing and communication between different language games. Chatbots, for example, rely on natural language processing algorithms to interpret and respond to user inputs, but these algorithms are limited by the language games that they have been trained on. This can lead to inaccurate responses and miscommunication when faced with inputs that fall outside of their language game.</p><p>As artificial intelligence (AI) systems become more advanced and sophisticated, there is a possibility that they could develop their own unique language games that are not shared by humans. While this scenario may seem like science fiction, it is not an implausible one given the rapid pace of technological development and the increasing autonomy of AI systems.</p><p>&nbsp;</p><h2>The implications of AI language game</h2><p>One potential implication of this scenario is the emergence of an \"AI culture\" that is fundamentally different from human culture. If AI systems are able to develop their own language games and associated meanings, they could develop a distinct perspective and way of understanding the world that is not accessible to humans. This could create a divide between humans and AI systems that would be difficult to bridge, leading to a potential breakdown in communication and cooperation between the two groups.</p><p>Another potential implication is the emergence of AI systems that are designed to deceive humans by manipulating their language games. If AI systems are able to generate their own language games and meanings, they could use this ability to their advantage by intentionally using language in a way that is confusing or misleading to humans. This could be particularly concerning in applications such as cybersecurity or politics, where the ability to manipulate language and meaning could have serious consequences.</p><p>Another concern is that rogue actors or states could intentionally create AI systems with unknown language games as a means of gaining an advantage over other entities. This could include developing AI systems with the ability to communicate in ways that are difficult for humans to understand, making it more difficult for human operators to detect or intervene in their actions. For example, an AI system with its own language game could be used to carry out cyber attacks or other forms of malicious activity without being detected by human operators.</p><p>Additionally, AI systems with their own language games could pose challenges for interoperability and standardization. If different AI systems use different language games, it may be difficult for them to communicate with each other effectively. This could lead to inefficiencies or failures in complex systems that require interoperability between multiple AI systems.</p><h2><br>Potential Issues with Democratization of AI access</h2><p>As the field of AI research advances, the cost and availability of creating AI systems is likely to decrease. This could lead to a scenario in which anyone with basic technical knowledge could create an AI system, without the need for significant financial or institutional resources. This is already beginning to happen with the rise of low-cost, accessible AI platforms and tools, such as Google's TensorFlow and Microsoft's Cognitive Toolkit.</p><p>While the democratization of AI research and development has the potential for many benefits, it also raises significant concerns about the potential misuse of these technologies. One of the greatest risks is the creation of unsupervised AI systems with unknown language games. In this scenario, rogue actors or states could create AI systems that are not trained on any human language games, but instead develop their own unique language games that are completely unintelligible to humans.</p><p>The potential implications of such a scenario are significant. These unsupervised AI systems could act in ways that are unpredictable and potentially dangerous, due to their lack of shared language games with humans. They could be used to launch cyber attacks, spread disinformation, or even take physical action that could harm humans or the environment. The possibility of unsupervised AI with unknown language games spreading on Earth is a significant concern, and requires careful consideration from both researchers and policymakers.</p><p>To mitigate this risk, it is important to promote responsible and ethical AI research and development, with a focus on developing systems that are transparent, explainable, and accountable. This includes ensuring that AI systems are trained on shared language games with humans, and that they are subject to robust oversight and regulation. Additionally, efforts should be made to increase awareness and education around the potential risks and benefits of AI technologies, both among the public and within the AI research community.</p><p>&nbsp;</p><h2>Challenges and Limitations of Addressing the Boundary Layer</h2><p>The boundary layer in language games presents a significant challenge in communication and understanding between individuals with different language games. Despite its importance, addressing the boundary layer is a complex task with many limitations and challenges.</p><p>One of the key challenges in addressing the boundary layer is the inherent subjectivity of language games. Each individual has their own unique language game, which is shaped by their experiences, beliefs, and cultural background. This subjectivity makes it difficult to create a universal approach to addressing the boundary layer that would work for everyone.</p><p>Additionally, the boundary layer can be difficult to identify, as it is often subconscious and difficult to articulate. Even when individuals are aware of the boundary layer, it can be challenging to describe and communicate their own language game to others. This can lead to misinterpretations and misunderstandings, further perpetuating the boundary layer.</p><p>Another challenge is the potential consequences of failing to account for the boundary layer in language and communication. Miscommunication due to the boundary layer can lead to a lack of understanding, frustration, and conflict between individuals. In extreme cases, failure to account for the boundary layer can even lead to violence and war, as seen in historical conflicts between nations and cultures.</p><p>To address the challenges of the boundary layer, there is a need for further research and development in this area. This could involve exploring new approaches to language learning and communication that take into account the subjectivity and complexity of language games. It could also involve developing technologies that enable individuals to better articulate and communicate their own language game, such as natural language processing algorithms and virtual reality simulations.</p><p>Furthermore, there is a need for increased education and awareness about the boundary layer and its implications. This could involve incorporating discussions about the boundary layer in language and communication into school curriculums and workplace training programs. It could also involve promoting cultural exchange and dialogue to foster greater understanding and empathy between individuals with different language games.</p><p>&nbsp;</p><h2>Conclusion</h2><p>The concept of the boundary layer in language games is a crucial aspect in understanding the complexities of communication between individuals with different language games. The boundary layer can be described as a zone of ambiguity where the meaning of words and phrases can differ between individuals, leading to misunderstandings and misinterpretations.</p><p>In the field of AI research, the boundary layer is especially relevant as natural language processing systems become more advanced. The accuracy and effectiveness of these systems can be impacted by the boundary layer, leading to errors and misinterpretations of user input. Additionally, the possibility of AI systems generating their own language games, not shared by humans, could have significant implications for communication and understanding in society.</p><p>However, addressing the boundary layer in language games poses several challenges and limitations. The inherent ambiguity of language makes it difficult to develop universal rules or algorithms for interpreting and understanding meaning. The nuances of individual language games must be taken into account, which requires a deep understanding of the cultural and social contexts in which they exist. Furthermore, the potential consequences of failing to account for the boundary layer can be significant, such as the spread of uncontrolled and unsupervised AI with unknown language games.</p><p>In light of these challenges, further research and development are necessary to improve communication and understanding between individuals with different language games. This includes developing more sophisticated natural language processing systems that can account for the boundary layer and the nuances of individual language games. It also includes a greater emphasis on understanding the cultural and social contexts in which language games exist, as well as the potential risks associated with unchecked AI development.</p><p>In conclusion, the concept of the boundary layer in language games is a vital area of research with far-reaching implications for communication and understanding in society. The development of AI systems has made this concept even more relevant, as the accuracy and effectiveness of these systems depend on our ability to account for the nuances and complexities of language. The challenges and limitations associated with the boundary layer underscore the need for further research and development to improve communication and understanding between individuals with different language games. I think we are playing with fire.</p>", "user": {"username": "Mirage"}}, {"_id": "MrKoM3MwavQy2eFiG", "title": "Consider applying to McKinsey's free-for-nonprofits org health survey (by April 14)", "postedAt": "2023-03-23T22:04:37.167Z", "htmlBody": "<p><strong>tl;dr:</strong> McKinsey is offering its Organizational Health Index survey free to nonprofits through April 14 <s>March 31</s>. Outputs of the OHI include benchmarks and best-practice recommendations for improving work environment, governance, etc. <a href=\"https://www.mckinsey.org/ohi-for-nonprofits\">Link to apply.</a></p><p><i>Disclosure: I worked at McKinsey London from Nov 2020-June 2022 in the organization, strategy, and digital/analytics practices. These are my personal opinions formed individually.</i></p><h3>What is the organizational health index?</h3><p>A tool for benchmarking how healthy organizations are. It incorporates nine dimensions of organizational health, including both internal factors (e.g., quality of work environment) and external factors (e.g., position within ecosystem).</p><p>The OHI also provides recommendations for how to improve an organization's health going forward (including webinars explaining best practices).</p><h3>Why would a nonprofit want to benchmark its organizational health?</h3><p>Healthier organizations are more capable of achieving their missions. They have mission clarity, effective leadership, a work environment that leads to higher performance and great staff development, processes that support effective management, and the capabilities to execute on their goals; they innovate more and more often, and they contribute more to the broader ecosystem of which they're a part.</p><p>Healthier nonprofits also tend to have better staff outcomes: retaining them for longer, engaging them more fully, and being recommended more highly by them.</p><p>Although most EA organizations have clear missions and highly engaged staff, they may benefit from understanding where there are opportunities to grow - for example, by implementing mechanisms to develop their staff further, manage risk, or partner effectively.</p><p>Benchmarking can help with this, as it aggregates experiences from many different organizations in the public, private, and social sectors. McKinsey's org practice has expertise in managing large and small organizations, so their benchmarking tool's outputs, appropriately tailored to the context of EA nonprofits, may be useful.</p><h3>What are the costs?</h3><p>Money: zero (as long as you're a qualifying nonprofit)</p><p>Time: 10 hours for a project manager, plus 20-30 mins per employee taking the survey</p><p>Privacy: Deidentified results from many different organizations get aggregated into future versions of the benchmark</p><h3>Which nonprofits are eligible?</h3><p>Per the website (emphasis mine):&nbsp;</p><ul><li>\"Nonprofits must have at least <strong>20 staff members</strong> to participate (i.e., full-time and part-time staff and contractors working in a staff augmentation capacity, who are responsible for core operations).</li><li>Nonprofits <strong>may not be </strong>hospitals or healthcare systems, universities, lobbying organizations, or government- or state-owned entities.</li><li>Nonprofits must pass a screening against standard international Watchlists and Sanctions lists.</li><li><strong>Nonprofits must be able to allocate a Project Manager </strong>who is proficient in English to run the OHI and <strong>who can dedicate ~10 hours from application form until survey closure</strong> (e.g., to set up the survey, share survey communications, send follow-up emails to staff to increase participation). Example Project Managers could include HR colleagues or dedicated PMs within the nonprofit.\"</li></ul><h3>What's the process to get started?</h3><ul><li><strong>Before</strong> <strong>April 14 </strong><s><strong>March 31</strong></s><strong>, have your organization's HR director</strong> or equivalent visit this link and fill in the application: <a href=\"https://www.mckinsey.org/ohi-for-nonprofits\">https://www.mckinsey.org/ohi-for-nonprofits</a><ul><li><i>EDIT: Noticed the website announced a deadline extension to April 14. From a quick scan, it looks like the application takes ~10-20 minutes.</i></li></ul></li><li>Appoint a project manager internally to run the survey</li><li>Run the survey</li><li>Receive results</li><li>Prioritize actions to take on the basis of the organization's results</li></ul>", "user": {"username": "xavierrg"}}, {"_id": "nHq4hLsojDPf3Pqg9", "title": "The Overton Window widens: Examples of AI risk in the media", "postedAt": "2023-03-23T17:10:14.936Z", "htmlBody": "", "user": {"username": "Akash"}}, {"_id": "JQnYZghxrdpEYHaB8", "title": "Join the AI governance and interpretability hackathons!", "postedAt": "2023-03-23T14:39:42.051Z", "htmlBody": "<p><strong>TLDR;</strong> Join us this weekend for the non-technical&nbsp;<a href=\"https://ais.pub/aigov\"><u>AI governance ideathon</u></a> with&nbsp;<strong>Michael Aird</strong> as keynote speaker, happening both virtually and in-person at&nbsp;<a href=\"https://alignmentjam.com\"><u>12 locations</u></a>! We also invite you to join the&nbsp;<a href=\"https://itch.io/jam/interpretability-hackathon\"><u>interpretability hackathon</u></a> with&nbsp;<strong>Neel Nanda</strong> on the 14th of April.</p><p>Below is an FAQ-style summary of what you can expect.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JQnYZghxrdpEYHaB8/r1kovqkeiwfw9brrgk3x\"></p><h2>What is it?</h2><p><a href=\"https://alignmentjam.com/\"><u>The Alignment Jams</u></a> are&nbsp;<strong>weekend-long fun research events</strong> where participants of all skill levels join in teams (1-5) to engage with direct AI safety work. You submit a PDF report on the participation page with the great opportunity to receive a review from great people like Emma Bluemke, Elizabeth Seger, Neel Nanda, Otto Barten and others.</p><p>If you are not at any of the in-person jam sites, you can participate online through&nbsp;<a href=\"https://discord.gg/3PUSbdS8gY\"><u>our Discord</u></a> where the keynote, award ceremony and AI safety discussion is happening!</p><p>The ideathon happens from the 24th to the 26th of March and we have the honour of presenting&nbsp;<strong>Michael Aird</strong>, lead AI governance researcher at Rethink Priorities as our keynote speaker. The interpretability hackathon happens on the 14th to 16th of April and we are collaborating with keynote speaker&nbsp;<strong>Neel Nanda</strong> for the third time to bring great starter resources to you.&nbsp;<a href=\"https://calendar.google.com/calendar/u/0?cid=ZjViYmMzNjlhNDFmZjg5MmY5ZTkxOWJjMGVkMmFlNjRmOTBjMmVjNTMzZDVhMTZhMWNkMjY4ZjU1M2JhMTBlY0Bncm91cC5jYWxlbmRhci5nb29nbGUuY29t\"><u>Get all dates into your calendar</u></a>.</p><p>Join this weekend's AI governance ideathon to write proposals for solutions to problem cases and think more about strategy in AI safety.&nbsp;<strong>And we promise you that you'll be surprised what you can achieve in just a weekend's work!</strong></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/JQnYZghxrdpEYHaB8/k7iczyvgk6lhtqzuskpw\"></p><p><i>Read more about how to join, what you can expect, the schedule, and what previous participants have said about being part of the jams below.</i></p><h2>Where can I join?</h2><p>You can join the event both in-person and online but everyone needs to make an account and join the jam on the&nbsp;<a href=\"https://itch.io/jam/ai-gov\"><u>itch.io page</u></a>.</p><p>See all in-person jam sites&nbsp;<a href=\"https://itch.io/jam/ai-gov\"><u>here</u></a>. These include H\u1ed3 Ch\u00ed Minh City, Copenhagen, Delft, Oxford, Cambridge, Madison, Aarhus, Paris, Toronto, Detroit (Ann Arbor), S\u00e3o Paulok, London, Sunnyvale and Stanford.</p><p>Everyone should join the Discord to ask questions, see updates and announcements, find online team members, and more.&nbsp;<a href=\"https://discord.gg/3PUSbdS8gY\"><strong><u>Join here</u></strong></a>.</p><h2>What are some examples of AI governance projects I could make?</h2><p>The submissions will be based on the cases presented on&nbsp;<a href=\"https://alignmentjam.com/ai-governance\"><u>the Alignment Jam website</u></a> and focus on specific problems in the interaction between society and artificial intelligence.</p><p>We provide some great inspiration with the cases that have been developed in collaboration with Richard Ngo, Otto Barten, Centre for the Governance of AI and others:</p><ul><li>Categorizing the future risks from artificial intelligence in a way that is accessible for policymakers.</li><li>Write up a report of the considerations and actions that OpenAI should take for a hypothetical release of a multimodal GPT-6 to be safe.</li><li>Imagine a policy proposal that, with full support from policymakers, would be successful in slowing or pausing progress towards AGI in a responsible and safe manner.</li><li>Come up with ways that AI might self-replicate in dangerous ways and brainstorm solutions to these situations.</li><li>Whose values should AI follow and how do we design systems to aggregate and understand highly varied preferences for systems that take large-scale decisions?</li><li>If we imagine that in 7 years, the US ban on AI hardware export to China leads to antagonistic AGI development race dynamics between the two nations, what will lead to this scenario? And how might we avoid risky scenarios from a governance perspective?</li><li>As AI takes over more and more tasks in the world, how will the technology fit into democratic processes and which considerations will we have to take?</li></ul><p>This will be our first non-technical hackathon (besides an in-person retreat in Berkeley) and we're excited to see which proposals you come up with!</p><h2>Why should I join?</h2><p>There\u2019s loads of reasons to join! Here are just a few:</p><ul><li>See how fun and interesting AI safety can be!</li><li>Get a new perspective on AI safety</li><li>Acquaint yourself with others interested in the same things as you</li><li>Get a chance to win $1,000 in the AI governance ideathon!</li><li>Get practical experience with AI safety research</li><li>Show the AI safety labs and institutions what you are able to do to increase your chances at some&nbsp;<a href=\"https://agisf.com/opportunities\"><u>amazing jobs</u></a></li><li>Get a cool certificate that you can show your friends and family</li><li>Have a chance to work on that project you've considered starting for so long</li><li>Get proof of your skills so you can get that one grant to pursue AI safety research</li><li>And of course, many other reasons\u2026&nbsp;<a href=\"https://itch.io/jam/ai-gov\"><u>Come along</u></a>!</li></ul><h2>What if I don\u2019t have any experience in AI safety?</h2><p><strong>Please&nbsp;</strong><a href=\"https://itch.io/jam/interpretability\"><strong><u>join</u></strong></a><strong>!</strong> This can be your first foray into AI and ML safety and maybe you\u2019ll realize that it\u2019s not that hard. Even if you don't find it particularly interesting, this might be a chance to engage with the topics on a deeper level.</p><p>There\u2019s a lot of pressure from AI safety to perform at a top level and this seems to drive some people out of the field. We\u2019d love it if you consider joining with a mindset of&nbsp;<strong>fun exploration and get a positive experience</strong> out of the weekend.</p><h2>What is the agenda for the weekend?</h2><p>The schedule runs from 6PM CET / 9AM PST Friday to 7PM CET / 10AM PST Sunday. We start with an introductory talk and end with an awards ceremony. Subscribe to the public calendar&nbsp;<a href=\"https://calendar.google.com/calendar/u/0?cid=ZjViYmMzNjlhNDFmZjg5MmY5ZTkxOWJjMGVkMmFlNjRmOTBjMmVjNTMzZDVhMTZhMWNkMjY4ZjU1M2JhMTBlY0Bncm91cC5jYWxlbmRhci5nb29nbGUuY29t\"><u>here</u></a>.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">CET / PST</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Fri 6 PM / 9 AM</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Introduction to the hackathon, what to expect, and a talk from Michael Aird or Neel Nanda. Afterwards, there's a chance to find new teammates.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Fri 7:30 PM / 10:30 AM</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Jamming begins!</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Mon 4 AM / 8 PM</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Final submissions have to be finished. Judging begins and both the community and our great judges from ERO and GovAI join us in reviewing the proposals.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Wed 6 PM / 9 AM</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">The award ceremony: The winning projects are presented by the teams and the prizes are presented.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Afterwards!</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">We hope you will continue your work from the hackathons with the purpose of sharing it on the forums or your personal blog!</td></tr></tbody></table></figure><p><br>&nbsp;</p><h2>I\u2019m busy, can I join for a short time?</h2><p>As a matter of fact,&nbsp;<strong>we encourage you to join</strong> even if you only have a short while available during the weekend!</p><p><strong>So</strong>&nbsp;<strong>yes,&nbsp;</strong>you can both join without coming to the beginning or end of the event, and you can submit research even if you\u2019ve only spent a few hours on it. We of course still encourage you to come for the intro ceremony and join for the whole weekend but everything will be recorded and shared for you to join asynchronously as well.</p><h2>Wow this sounds fun, can I also host an in-person event with my local AI safety group?</h2><p><strong>Definitely!</strong> It might be hard to make it for the AI governance ideathon but we encourage you to join our team of in-person organizers around the world for the interpretability hackathon in April!</p><p>You can read more about what we require&nbsp;<a href=\"https://alignmentjam.com/running\"><u>here</u></a> and the possible benefits it can have to your local AI safety group&nbsp;<a href=\"https://alignmentjam.com/why\"><u>here</u></a>.&nbsp;<strong>Sign up as a host on the button on&nbsp;</strong><a href=\"https://alignmentjam.com/running\"><strong><u>this page</u></strong></a>.</p><h2>What have previous participants said about this hackathon?</h2><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">I was not that interested in AI safety and didn't know that much about machine learning before, but I heard from this hackathon thanks to a friend, and I don't regret participating! I've learned a ton, and it was a refreshing weekend for me.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">A great experience! A fun and welcoming event with some really useful resources for starting to do interpretability research. And a lot of interesting projects to explore at the end!</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Was great to hear directly from accomplished AI safety researchers and try investigating some of the questions they thought were high impact.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">I found the hackaton very cool, I think it lowered my hesitance in participating in stuff like this in the future significantly. A whole bunch of lessons learned and Jaime and Pablo were very kind and helpful through the whole process.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">The hackathon was a really great way to try out research on AI interpretability and getting in touch with other people working on this. The input, resources and feedback provided by the team organizers and in particular by Neel Nanda were super helpful and very motivating!</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td></tr></tbody></table></figure><p><br>&nbsp;</p><h2>Where can I read more about this?</h2><ul><li><a href=\"https://alignmentjam.com\"><u>The Alignment Jam website</u></a> (where you can subscribe to email updates)</li><li><a href=\"https://discord.gg/3PUSbdS8gY\"><u>The Discord server</u></a></li><li><a href=\"https://itch.io/jam/ai-gov\"><u>AI governance ideathon</u></a><ul><li><a href=\"https://alignmentjam.com/ai-governance\"><u>The AI governance cases</u></a></li></ul></li><li><a href=\"https://itch.io/jam/interpretability-hackathon\"><u>The interpretability hackathon</u></a><ul><li><a href=\"https://alignmentjam.com/hackathon/interpretability\"><u>Inspiration list for the interpretability hackathon</u></a></li></ul></li><li><a href=\"http://alignmentjam.com/jams\"><u>Previous results</u></a><ul><li><a href=\"https://www.lesswrong.com/posts/hhhmcWkgLwPmBuhx7/results-from-the-interpretability-hackathon\"><u>Results from our last interpretability hackathon</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/5h8bNTFHkrNNzrrJf/results-from-the-ai-testing-hackathon\"><u>Results from the AI testing hackathon</u></a></li><li><a href=\"https://www.lesswrong.com/posts/5DsHZidaShW5EM9rz/results-from-the-language-model-hackathon\"><u>Results from the language model hackathon</u></a></li></ul></li></ul><p>Again, sign up here by&nbsp;<a href=\"https://itch.io/jam/ai-gov\"><u>clicking \u201cJoin jam\u201d</u></a> and read more about the hackathons&nbsp;<a href=\"https://alignmentjam.com\"><u>here</u></a>.</p><p><strong>Godspeed, research jammers!</strong></p><p><br>&nbsp;</p>", "user": {"username": "esben-kran"}}, {"_id": "vysZL6ba8ioFmFmsc", "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4 | Microsoft Research", "postedAt": "2023-03-23T05:45:12.609Z", "htmlBody": "", "user": {"username": "Dragon God"}}, {"_id": "hHCxhFK9ZrKEhFQrL", "title": "Transcript: NBC Nightly News: AI \u2018race to recklessness\u2019 w/ Tristan Harris, Aza Raskin", "postedAt": "2023-03-23T03:45:25.664Z", "htmlBody": "", "user": {"username": "WilliamKiely"}}, {"_id": "BraHs6yqgRyecEsGq", "title": "Personal Finance Coaching for EAs: Call for Applicants\n", "postedAt": "2023-03-22T23:22:32.807Z", "htmlBody": "<p>We\u2019re excited to announce the launch of&nbsp;<a href=\"https://www.yieldandspread.org/\"><u>Yield &amp; Spread</u></a>\u2019s free 1:1 Coaching Program, designed to help people with their financial plans for giving. We are looking for applicants familiar with the Effective Altruism movement to help us trial this program, and give us their feedback.&nbsp;</p><p>You can apply for the coaching program&nbsp;<a href=\"https://www.yieldandspread.org/coaching\"><u>here</u></a>.</p><p>&nbsp;</p><h3><strong>Coaching Program Rationale&nbsp;</strong></h3><p>Yield &amp; Spread is a nonprofit whose mission is to promote personal finance as a force for good. We believe that increasing financial literacy creates more opportunities for people to give back; when we can better optimize our own finances, we are in a much better position to help others. We have educational materials, free resources, and tools that are accessible to those outside the EA community, but our coaching program is specifically designed to help \u201cdo-gooders\u201d do better with their finances and give them peace of mind.</p><p>We intend to measure our impact by evaluating how users have made significant changes to their financial plans and donation strategy after coaching sessions.&nbsp;</p><p>&nbsp;</p><h3><strong>Who Should Apply</strong></h3><p>We're best prepared to help people who:\u200b\u200b</p><ul><li>Are considering taking a donation pledge for the first time, or have taken a donation pledge and want to evaluate their pledge amount</li><li>Have a baseline understanding of financial planning and are familiar with the building blocks of financial independence (for more information, see&nbsp;\u201c<i>How Much Do I Need to Know About Finances</i>\u201d below)&nbsp;</li><li>Are located in the U.S.; at this time we only work with people in-country due to our unique investment and tax structures</li></ul><p><strong>\u200b</strong>If you\u2019re not sure about whether to apply, we recommend that you do!</p><p>&nbsp;</p><h3><strong>What to Expect</strong></h3><ul><li><strong>Fill out our brief </strong><a href=\"https://www.yieldandspread.org/coaching\"><strong>application form</strong></a><strong>.&nbsp;</strong>It should take about 10 minutes. Give us a sense of your goals and where you need financial guidance. If we are a match, we will reach out to book a one hour video call with you.</li><li><strong>Prepare for the meeting. </strong>If you are accepted, we'll ask you to gather all your financial information into one place so we can have an effective discussion based on real numbers. The more prepared you are, the more impactful our meeting will be. Your information will not be shared with anyone.&nbsp;</li><li><strong>Get together:&nbsp;</strong>We'll have a 1:1 video call where you can speak with us about your goals and main concerns. If appropriate, we may recommend you to other advisors or point you to additional resources. We may point you in the direction of a financial or tax advisor if we see fit (for more information, see \"<i>Things We Cannot Help With</i>\" below)</li><li><strong>Follow Up: </strong>In some cases, we may propose another video call if additional support is needed.&nbsp;</li></ul><p>If accepted, we will ask you to fill out a before and after survey.&nbsp;<br>&nbsp;</p><h3><strong>How We Can Help</strong></h3><p>Possible items we might work on together:</p><ul><li>Review checking, savings, and investments accounts and see if you can consolidate or optimize&nbsp;</li><li>Evaluate current investments (stocks, bonds, and funds only) and see if they meet the needs of your overall financial plan</li><li>Analyze income, expenses, and assets to determine how much you need to save to meet your retirement or financial independence goals</li><li>Explore how donating fits into your financial plan and identify tax-efficient ways to donate</li><li>Discuss career goals and life plans and explore the scenarios in which they impact your financial plans</li></ul><p>&nbsp;</p><h3><strong>Things We Cannot Help With</strong></h3><ul><li>Assessing the promise of alternative or complex investment options outside of traditional stocks, bonds, and funds (e.g. you want to invest in a company that you think has the promise of doing X)</li><li>Equity compensation (e.g. stock units, RSUs), beyond the basics</li><li>Estate planning, beyond the basics</li><li>Complex tax advice</li></ul><p>Please note, Yield &amp; Spread is not a registered investment, legal or tax advisor or a broker/dealer. Our services are not intended to substitute for obtaining accounting, tax, or financial advice, and may not be suitable for every individual. You can read more about our terms of use and disclosures&nbsp;<a href=\"https://www.yieldandspread.org/terms-of-use\"><u>here</u></a>.</p><p>&nbsp;</p><h3><strong>How Much Do I Need to Know About Finances&nbsp;</strong></h3><p>We believe the most fruitful coaching sessions are those where we are on the same page. This means we want to have a similar baseline understanding of investing and money management. If you have taken Yield &amp; Spread\u2019s&nbsp;<a href=\"https://www.yieldandspread.org/sign-up\"><u>Learn to Invest &amp; Build Wealth&nbsp;</u></a>course, we will much more easily have a mutual understanding for how to discuss finances. Else, if you are far along on your finance journey, we'd be happy to meet. We are best aligned with those that follow and understand the&nbsp;<a href=\"https://www.bogleheads.org/wiki/Main_Page\"><u>Bogleheads investment framework</u></a> encouraged by the Financial Independence movement. If you are accepted as an applicant, but we determine more financial education is needed before coaching can commence, we may recommend you go back and take the Learn To Invest course.&nbsp;</p><p>&nbsp;</p><h3><strong>About Me</strong></h3><p>Outside of my involvement in EA, I am a member of the FIRE movement (Financial Independence Retire Early).&nbsp; At the age of 32, I left my full-time job in corporate real estate and became an \"early retiree\". This has allowed me to dedicate my&nbsp; time to founding and running Yield &amp; Spread, where 100% of our profits go to&nbsp;<a href=\"https://www.thelifeyoucansave.org/?gclid=CjwKCAjwzuqgBhAcEiwAdj5dRklLbudRAtHlL0vZMASGoO6I9wI5JsXGx-CqdL1T0Yv3N6FY5ZQMVBoCkHoQAvD_BwE\"><u>The Life You Can Save.</u></a>&nbsp;</p>", "user": {"username": "Rebecca Herbst"}}, {"_id": "brBqjKxBdsEwBWwLD", "title": "Eradicating rodenticides from U.S. pest management is less practical than we thought", "postedAt": "2023-03-24T21:11:42.088Z", "htmlBody": "<p><i>The </i><a href=\"https://osf.io/458cx\"><i>link</i></a><i> goes to the Open Science Framework preprint of the full report.&nbsp;</i></p><h1>Executive Summary</h1><p>Rodenticide poisons are cruel and reducing their use would likely represent an improvement in wild animal welfare. This report explores the reasons why rodenticides are used, under what circumstances they could be replaced, and whether they are replaceable with currently available alternatives. As summarized in the table below, agricultural use of rodenticides is well-protected by state and federal laws and that seems unlikely to change, but the use of rodenticides in food processing and conservation would likely be reduced if there were an adequate alternative such as solid form rodent birth control. Continued innovation of reactive tools to eliminate rodent infestations should reduce the use cases where rodenticides are the most cost-effective option for residential customers or public health officials, but will not eliminate their availability to handle major infestations.&nbsp;</p><figure class=\"image\"><img src=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9fd7dec58b0161f87aaffa78b34cfd21d01d9c314c443a8a.png\" srcset=\"https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9fd7dec58b0161f87aaffa78b34cfd21d01d9c314c443a8a.png/w_100 100w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9fd7dec58b0161f87aaffa78b34cfd21d01d9c314c443a8a.png/w_200 200w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9fd7dec58b0161f87aaffa78b34cfd21d01d9c314c443a8a.png/w_300 300w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9fd7dec58b0161f87aaffa78b34cfd21d01d9c314c443a8a.png/w_400 400w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9fd7dec58b0161f87aaffa78b34cfd21d01d9c314c443a8a.png/w_500 500w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9fd7dec58b0161f87aaffa78b34cfd21d01d9c314c443a8a.png/w_600 600w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9fd7dec58b0161f87aaffa78b34cfd21d01d9c314c443a8a.png/w_700 700w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9fd7dec58b0161f87aaffa78b34cfd21d01d9c314c443a8a.png/w_800 800w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9fd7dec58b0161f87aaffa78b34cfd21d01d9c314c443a8a.png/w_900 900w, https://39669.cdn.cke-cs.com/cgyAlfpLFBBiEjoXacnz/images/9fd7dec58b0161f87aaffa78b34cfd21d01d9c314c443a8a.png/w_908 908w\"></figure><hr><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yn2ozSswZuiKKBCtJ/ae1f6u5sexcfjlo5wpek\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yn2ozSswZuiKKBCtJ/raijhtamnqdw3e6soqdd 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yn2ozSswZuiKKBCtJ/ikvu3ylonulafasydcfo 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yn2ozSswZuiKKBCtJ/ojphvumwejy7kriucoxf 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yn2ozSswZuiKKBCtJ/q6oh8rohtdbowzrjs1jv 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yn2ozSswZuiKKBCtJ/lxg6ymbgyluodidyhlb1 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yn2ozSswZuiKKBCtJ/gc3039okkd6uykgf0ya0 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yn2ozSswZuiKKBCtJ/d4ceelm6o0dno2ptvbjq 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yn2ozSswZuiKKBCtJ/ob7keohmkk8nuheto16r 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yn2ozSswZuiKKBCtJ/z8zir5t9nqqkkso8z65p 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yn2ozSswZuiKKBCtJ/goxxw2hmoqct9lsncmsi 1600w\"><br>This research is a project of Rethink Priorities. It was written by Holly Elmore. If you\u2019re interested in RP\u2019s work, you can learn more by visiting our <a href=\"https://www.rethinkpriorities.org/research\">research database</a>. For regular updates, please consider<i> </i>subscribing to our<a href=\"https://www.rethinkpriorities.org/newsletter\"> newsletter</a>.</p>", "user": {"username": "Holly_Elmore"}}, {"_id": "72Ya3vqouY9HHTwMt", "title": "Reflections on applications, rejections and feedback", "postedAt": "2023-03-28T18:13:43.721Z", "htmlBody": "<p>This post reflects my own personal opinions and not the opinions of the orgs I\u2019m mentioning.</p><p><strong>The argument goes:</strong><br>If you get an application for you [job opening, grant program, etc] and you take some amount of time evaluating the application, it can\u2019t take that much&nbsp;<i>extra</i> time to just write down the reason for your decision. You made the decision, so you know why you made it. So why then isn\u2019t feedback better integrated in more application processes? Why do many EA orgs say they don\u2019t have time to give personal feedback to applicants?&nbsp;</p><p>I have heard this argument several times in writing and in person, and I have thought this exact thing many times. It makes sense in theory. But unfortunately reality is more messy, or at least sometimes it\u2019s more messy.&nbsp;<br>&nbsp;</p><h2>Two types of applications processes&nbsp;</h2><p>I\u2019ve been on both sides of applications. I\u2019ve handled applications for various events, I was involved in one hiring at&nbsp;<a href=\"https://www.aisafetysupport.org/\"><u>AISS</u></a> before leaving, and most recently I\u2019ve been on the evaluation side of applications for both research leads and team members for&nbsp;<a href=\"https://aisafety.camp/\"><u>AISC</u></a>. All the applications I\u2019ve dealt with on the evaluator side can neatly be divided in two categories:</p><ul><li><strong>Evaluative application&nbsp;</strong>- There is a fixed bar. If you live up to this requirement you\u2019re in.</li><li><strong>Competitive applications&nbsp;- There is a fixed (or fixed-ish) number of acceptances, and therefore the success of the application primarily depends on how they compare with other applications.</strong></li></ul><p>For evaluative applications it is actually very little extra work to provide feedback once the evaluation is done. The argument that started this post lines up with reality. For competitive applications, everything is a mess.<br>&nbsp;</p><h2>Competitive applications</h2><p>Imagine you want to recruit one or only a few people. You have many more applicants than you are able to accept, so you skim the list for the top candidates which you will take the time to read more carefully. One application is giving you a negative vibe that you can\u2019t really put the finger on why this is. It just feels that this person would be a bad personal fit. You could probably try to articulate it, but it would come out as super judgmental. You\u2019re not sure that your judgement is correct, but it is something that you would have to look into before accepting them, which seems like a lot of extra work. On the other hand, there are lots of other people who are similarly qualified you can pick instead.&nbsp;</p><p>In a competitive application process there is typically not enough time to give everyone a fair evaluation. The focus is more on finding some safe and good enough people to accept. For most rejections the reason is simply that the application did not stand out enough. In the few cases where this is not the case, it can be hard to articulate. Vibe based judgement like the one described above probably doesn't generalise to other evaluators anyway which means the feedback is of low value.</p><p><strong>How to give feedback to rejected applications (my opinion)</strong><br>For Competitive applications I think in general trying to give individual feedback is often more trouble than it\u2019s worth. A better approach is to give general feedback. Let people know how competitive the application process turned out to be, and what specifically it took to get accepted this time.&nbsp;<br>&nbsp;</p><h2>Evaluative applications</h2><p>When evaluating competitive applications I will spend most of my time on the top applications, but for evaluative applications I will spend most of my time on the applications that are on the edge of being accepted or rejected. It\u2019s also just easier to evaluate applications when the bar for acceptance isn\u2019t shifting based on my evaluation of other applications.&nbsp;</p><p>When doing evaluative applications, if it is not clear to me why I\u2019m accepting or rejecting someone, then I\u2019m not done with their application. For this reason, telling a rejected applicant exactly why their application got rejected is not hard.&nbsp;</p><p><strong>How to give feedback to rejected applications (my opinion)</strong><br>Tell people exactly why their application got rejected.&nbsp;</p><p>I don\u2019t like giving people negative feedback. It doesn't feel nice. Here\u2019s a re-framing trick I\u2019ve come up with to overcome this aversion. I imagine myself in their position and think about what I would want if I were them. I notice that I would like to know why my application got rejected. After this thought experiment, telling them the feedback no longer feels like being rude, it feels like being helpful.&nbsp;<br>&nbsp;</p><h2>Transparency</h2><p>For both types of applications, I think it is worth the effort to be transparent about the application process, preferably before people apply. I\u2019ve not always lived up to this ideal, but it\u2019s something I want to improve for next time I\u2019m doing applications for something.</p><p>I both had to deal with applications I could not evaluate because they did not provide enough information, and applications that wasted my time by being unnecessarily lengthy. I consider both of these failure modes to be at least partly to blame on me and my colleagues for not being clearer about our expectations for applications. If the applicant understands the application process and evaluation criteria, and can tailor their application based on this information, this saves time for everyone.</p><p>There are some exceptions where you do want to ask a trick question, such that explaining the evaluation criteria would undermine the point of the question.&nbsp;<br>&nbsp;</p><h2>Some more reflections/opinions</h2><p>I much prefer evaluative applications over competitive applications, even to the extent that I sometimes designed an application process to be evaluative, even though this would probably mean missing out on top applications. For example, I\u2019ve used \u201cfirst come first serve\u201d for one event, i.e. the first 20 applicants that met the minimum bar got accepted. At another event where the number of spots were somewhat flexible but not infinitely so, I kept the number of applications down by not advertising too widely, in order to not have to reject anyone out of lack of capacity.</p><p>Most times I\u2019ve evaluated competitive applications, I didn\u2019t feel super motivated to spend a lot of time optimising the application process, to make sure I got the absolute best candidates. It seems to me that improving the accuracy of the application process adds a lot of work for everyone involved, and you still end up with the same number of successful applicants. Good applicants will still be rejected. I feel more motivated to spend that effort on expanding the programs and events I\u2019m involved with, to make room for more participants.&nbsp;</p><p>Applications are very low bandwidth. This is a problem I did not understand until I had some experience being on the evaluator side. When applying it\u2019s so easy to fall for the&nbsp;<a href=\"https://www.lesswrong.com/posts/sSqoEw9eRP2kPKLCz/illusion-of-transparency-why-no-one-understands-you\"><u>illusions of transparency</u></a> and think that your application conveys much more information than is actually there. But in reality&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/5sfwebGDPBmSBcYA2/the-application-is-not-the-applicant\"><u>the application leaves out sooo much</u></a>. Because of this, I think that focusing too much on refining the application process is hubris. I don\u2019t believe anyone is good at this. The best we can do is to give as many people as possible the opportunity to participate and contribute.<i> If you disagree and if you know how to set up a great application process, then please message me and teach me your magic.</i><br><br><strong>Edit: The above paragraph is making a stronger statement than I believe on reflection. I would like to clarify, except I notice that my opinions here is unstable. I don't know yet what I think on reflection. Sorry about this. I still welcome discussions and pushback on the paragraph as written.&nbsp;</strong></p><p>I know there are bottlenecks and trade-offs. I\u2019m not saying that your EA org needs to hire everyone. Obviously that would be a bad idea. In most cases, orgs should hire carefully and avoid risky hires, even if that means often turning away good candidates.</p><p>When it comes to grants, I\u2019d be excited to see grants programs that give lower amounts, but to a larger number of people.&nbsp;</p><p>As for events, I want&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/dsCTSCbfHWxmAr2ZT/open-ea-global\"><u>bigger EAGs</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/4t7xQYSmJF4qarY6Y/project-idea-lots-of-cause-area-specific-online\"><u>many more online events</u></a>.</p><p>Also, not all opportunities happen via applications. One of the best ways to make sure lots of EA opportunities are accessible to lots of people, is to be a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/YzrbyEGrDEyZDX6dH/ideas-from-network-science-about-ea-community-building#Distributed_networks__not_overly_centralised_\"><u>distributed</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/YzrbyEGrDEyZDX6dH/ideas-from-network-science-about-ea-community-building#Distributed_networks__not_overly_centralised_\"><u>open</u></a> network.</p><p>I\u2019m noticing I\u2019m starting to drift off on a tangent at this point in my writing, so I will end here.&nbsp;</p><p><br><br>&nbsp;</p>", "user": {"username": "Linda Linsefors"}}, {"_id": "N9xreY5eqmYJy3cpF", "title": "Books: Lend, Don't Give", "postedAt": "2023-03-22T19:11:14.109Z", "htmlBody": "", "user": {"username": "Jeff_Kaufman"}}, {"_id": "BzyeByJcdBqiyjGaG", "title": "[Linkpost] Shorter version of report on existential risk from power-seeking AI", "postedAt": "2023-03-22T18:06:49.610Z", "htmlBody": "<p>I've edited my <a href=\"https://arxiv.org/abs/2206.13353\">report</a> on existential risk from power-seeking AI into a shorter version (less than half the length), available <a href=\"https://jc.gatspress.com/pdf/existential_risk_and_powerseeking_ai.pdf\">here</a>. The shorter version is forthcoming in \"Essays on Longtermism,\" from Oxford University Press, edited by Jacob Barrett, Hilary Greaves, and David Thorstad. There's also a human-narrated audio version <a href=\"https://joecarlsmithaudio.buzzsprout.com/2034731/12471529-existential-risk-from-power-seeking-ai-shorter-paper\">here</a>, or search \"Joe Carlsmith Audio\" in your podcast app.</p><p>As an even shorter version, here's a quote from the conclusion:&nbsp;</p><blockquote><p>At a high-level, we\u2014or at least, some of us\u2014are currently pouring resources into learning how to build something akin to a second advanced species; a species potentially much more powerful than we are; that we do not yet understand, and that it\u2019s not clear we will be able to control. In this sense, we are playing with a hotter fire than we have ever tried to handle. We are doing something unprecedented and extremely dangerous, with very little room for error, and the entire future on the line.</p><p>More specifically: within my lifetime, I think it more likely than not that it will become possible and financially feasible to create and deploy powerful AI agents. And I expect strong incentives to do so, among many actors, of widely varying levels of social responsibility. What\u2019s more, I find it quite plausible that it will be difficult to ensure that such systems don\u2019t seek power over humans in unintended ways; plausible that they will end up deployed anyway, to catastrophic effect; and plausible that whatever efforts we make to contain and correct the problem will fail.&nbsp;</p><p>That is, as far as I can tell, there is a disturbingly high risk (I think: greater than 10%) that I live to see the human species permanently and involuntarily disempowered by AI systems we\u2019ve lost control over.</p></blockquote>", "user": {"username": "Joe_Carlsmith"}}, {"_id": "92TAmcppCL7t54Ajn", "title": "Announcing the European Network for AI Safety (ENAIS)", "postedAt": "2023-03-22T17:57:36.582Z", "htmlBody": "<p><strong>TLDR;</strong> The&nbsp;<a href=\"http://enais.co\"><u>European Network for AI Safety</u></a> is a central point for connecting researchers and community organizers in Europe with opportunities and events happening in their vicinity.&nbsp;<a href=\"https://airtable.com/shrdtkHEBO9GU1gok\"><u>Sign up here</u></a> to become a member of the network, and&nbsp;<a href=\"https://forms.gle/RiJ7A5YuAk1BjbDM7\"><u>join our launch event</u></a> on Wednesday, April 5th from 20:00-21:00 CET!</p><h2>Why did we create ENAIS?</h2><p>ENAIS (pronounced e-nice) was founded by European AI safety researchers and field-builders who recognized the lack of interaction among various groups in the region. Our goal is to address the decentralized nature of AI safety work in Europe by improving information exchange and coordination.</p><p>We focus on Europe for several reasons: a Europe-specific organization can better address local issues like the EU AI Act, foster smoother collaboration among members and the free travel within Schengen also eases event coordination.&nbsp;</p><h2>About the network</h2><p>ENAIS strives to advance AI Safety in Europe, mitigate risks from AI systems, particularly existential risks, and enhance collaboration among the continent's isolated AI Safety communities.</p><p>We also aim to connect international communities by sharing insights about European activities and information from other hubs. We plan to offer infrastructure and support for establishing communities, coworking spaces, and assistance for independent researchers with operational needs.</p><p>Concretely, we organize / create:</p><ul><li>A centralized online location for accessing European AI safety hubs and resources for field-building on the&nbsp;<a href=\"http://enais.co\"><u>enais.co website</u></a>. The map on the front page provides direct access to the most relevant links and locations across Europe for AI safety.</li><li>A quarterly newsletter with updated information about what field-builders and AI safety researchers should be aware of in Continental Europe.</li><li>A professional network and database of the organizations and people working on AI safety.</li><li>Events and 1-1 career advice to aid transitioning into AI Safety or between different AI Safety roles.</li><li>Support for people wanting to create a similar organization in other regions.&nbsp;</li></ul><p>We intend to leverage the expertise of the network to positively impact policy proposals in Europe (like the EU AI Act), as policymakers and technical researchers can more easily find each other. In addition, we aim to create infrastructure to make the research work of European researchers easier and more productive, for example, by helping researchers with finding an employer of records and getting funding.</p><p>With the decentralized nature of ENAIS, we also invite network members to self-organize events under the ENAIS banner with support from other members.</p><h3>What does European AI safety currently look like?</h3><p>Below you will find a non-exhaustive map of cities with AI Safety researchers or organizations. The green markers indicate an AIS group, whereas the blue markers indicate individual AIS researchers or smaller groups. You are invited to add information to the map&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1FETP5mYMquMH6K1v8O_K6IQ-yLibroEBJPcdT6lLYFw/edit#gid=359373238\"><u>here</u></a>.</p><p><a href=\"https://enais.co/map\"><u><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/92TAmcppCL7t54Ajn/ujlcnjtspqrtbdax5oax\"></u></a></p><h3>Vision</h3><p>The initial vision for ENAIS is to be the go-to access point for information and people interested in AI safety in Europe. We also want to provide a network and brand for groups and events.</p><p>The longer-term strategy and vision will mostly be developed by the people who join as directors with guidance from the board. This might include projects such as policymaker communication, event coordination, regranting, community incubation, and researcher outreach.</p><h2>Join the network!</h2><p>Sign up for the network&nbsp;<a href=\"https://airtable.com/shrdtkHEBO9GU1gok\"><u>here</u></a> by providing information on your interests, openness to collaboration, and location. We will include you in our database (if you previously filled in information, we will email you so you may update your information). You can choose your level of privacy to not appear publicly and only to members if you prefer. This will serve to more easily find collaborators, co-workers (in your cities), co-founders (startup or non-profit), and understand where people are across the continent.</p><p>There are two main purposes for joining the network. First, this leads to an improved understanding of which organizations are working within AI safety across Europe. Second, it facilitates finding talent and collaborators who are in the same cities or locations as yourself.</p><h2>The near future of ENAIS</h2><h3>Current Organization\u2014Temporary Board, calling for permanent board</h3><p>Currently, what we call the coordination board is a decentralized group of temporary volunteers across Europe. We have started this as the initial steps towards better coordination across Europe and expect one to several permanent positions to take ownership and define the longer-term strategic direction for ENAIS.</p><p>If you are interested in becoming a board member or taking an executive position in the permanent ENAIS organization, express your interest in the forms below. We will notify you once we have funding and open these positions, which might take several months (don't quit your job yet!):</p><ul><li><a href=\"https://forms.gle/EthLCk6fsYVSvTrS9\"><u>Express your interest in a director role</u></a></li><li><a href=\"https://forms.gle/f37LAiPPdXhMECmU6\"><u>Express your interest in a board position</u></a></li></ul><h3>Launch Event</h3><p>Please join us on Wednesday, April 5th from 20:00-21:00 CET. (Note: we moved the event with an hour to avoid overlap with another event.) We will have a brief overview of ENAIS and how you might get involved, as well as short talks from various communities around Europe about what\u2019s going on in their country. Finally, we\u2019ll provide an opportunity to socialize and meet people with shared interests.&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSeY0sd5dHzn7rfy6tvqMUHFkOo5n3SErrD7XWu1vaC2I0lF-g/viewform\"><u>Sign up here!</u></a></p><h2>Conclusions</h2><p>Predominantly, we\u2019re hoping to help Europe be the best it can be at AI Safety. A good step to help with this goal is for individuals and organizations to&nbsp;<a href=\"https://airtable.com/shrdtkHEBO9GU1gok\"><u>join</u></a> and collaborate. Lastly, we encourage other regions to organize similar groups. Please contact us at&nbsp;<a href=\"mailto:contact@enais.co\"><u>contact@enais.co</u></a> if interested (for this or any other AI safety coordination-related project).</p><h2>Acknowledgments</h2><p><i>ENAIS is a decentralized effort and we want to thank everyone involved: Per Ivar Friborg, Jason Hoelscher-Obermaier, Jesse Hoogland, Walter Laurito, Karl Von Wendt, Tomas Bueno Mom\u010dilovi\u0107, Georgios Kaklamanos, Gerg\u0151 G\u00e1sp\u00e1r and Richard Annilo. We encourage other regions to establish similar organizations and offer our guidance.</i></p>", "user": {"username": "esben-kran"}}, {"_id": "inQiiNgDmioHPn63h", "title": "Anki with Uncertainty: Turn any flashcard deck into a calibration training tool", "postedAt": "2023-03-22T17:26:10.781Z", "htmlBody": "<p>We've developed an Anki addon that lets you do calibration training on numerical flashcards!</p><p><a href=\"https://www.quantifiedintuitions.org/anki-with-uncertainty\">Find information on how it works and how to use it on Quantified Intuitions.</a></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/inQiiNgDmioHPn63h/cfpfpiduyhat5xtolyad\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/inQiiNgDmioHPn63h/kwsrbnfmdbbqsz17s9cr 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/inQiiNgDmioHPn63h/cskjncthq8mw9pmriyvp 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/inQiiNgDmioHPn63h/dmjfhhqxyehce9jrvdpy 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/inQiiNgDmioHPn63h/o8n6sxxaz3guhjhjcyje 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/inQiiNgDmioHPn63h/m1ajeukbxqaeo2dwcky0 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/inQiiNgDmioHPn63h/dcwipxnbffi5wkngcy2x 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/inQiiNgDmioHPn63h/xaowl0stntnnibqwvkvd 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/inQiiNgDmioHPn63h/bgxqxivqswgku7t2aqbp 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/inQiiNgDmioHPn63h/avq8pudcas3qzmsmcbgt 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/inQiiNgDmioHPn63h/dwfpcqnpmcevkutgs3zx 1558w\"></figure><p>Thanks to <a href=\"https://forum.effectivealtruism.org/users/elizabethbarnes\">@Beth Barnes</a> for supporting the development and giving feedback. And thanks to <a href=\"https://forum.effectivealtruism.org/users/haukehillebrandt?mention=user\">@Hauke Hillebrandt </a>for <a href=\"https://forum.effectivealtruism.org/posts/W6gGKCm6yEXRW5nJu/quantified-intuitions-an-epistemics-training-website?commentId=zrXTrsXjD3w5DM6q7\">inspiring this idea with this comment</a> right here on the Forum!</p><p>It's pretty experimental, so I'd love to hear any feedback or thoughts.</p><p>&nbsp;</p><p>&nbsp;</p><p>In related news: the <a href=\"https://www.quantifiedintuitions.org/estimation-game/march\">March Estimation Game</a> is now live - ten new Fermi estimation questions, with some particularly interesting ones this month!</p><p>See our previous posts for more information about <a href=\"https://forum.effectivealtruism.org/posts/XDwnGK7x4EjkaHbje/the-estimation-game-a-monthly-fermi-estimation-web-app\">The Estimation Game</a> and our other tools on <a href=\"https://forum.effectivealtruism.org/posts/W6gGKCm6yEXRW5nJu/quantified-intuitions-an-epistemics-training-website\">Quantified Intuitions</a>, including a <a href=\"https://www.quantifiedintuitions.org/calibration\">calibration tool</a> with questions about the world's most pressing problems.</p>", "user": {"username": "Sage"}}, {"_id": "5Ro5ZpqbmYZo8mdsQ", "title": "Research Summary: Prediction Markets", "postedAt": "2023-03-22T17:07:59.863Z", "htmlBody": "<p>Note: I initially published this summary as a blog post <a href=\"https://damienlaird.substack.com/p/research-prediction-markets\">here</a>. The blog has more information about the context of this post and my reasoning transparency. In brief, this post was me summarizing what I learned about prediction polling, a specific flavor of forecasting, while trying to understand how it could be applied to forecasting global catastrophic risks. If I cite a source, it means I read it in full. If I relay a claim, it means it's made in the cited source and that I found it likely to be true (&gt;50%). I do not make any original arguments (that's done elsewhere on the blog), but I figured this might be helpful in jumpstarting other people's understanding on the topic or directing them towards sources that they weren't aware of. Any and all feedback is most welcome.</p><p>The text should all be copied exactly from my original post, but I redid the footnotes/citations to use the EA forum formatting. If any of those are missing/seem incorrect please let me know.</p><hr><p>Prediction markets can have a variety of different structures and mechanisms, but at their core they enable large numbers of people to bet with each other on a particular outcome. A simple example is a market to predict whether a candidate will be elected president. If shares in the market pay out at $1 if this candidate is elected and $0 if they are not, and enough people trade these shares in the market, then the current trading price reflects a sort of consensus on the probability of this candidate being elected. In this case, a 33\u00a2 last traded price reflects a 33% consensus belief in the likelihood of the outcome. Economists tend to believe that with enough trading volume the accuracy of this prediction will approach the best possible given the available information. Different mechanisms can allow these markets to be applied to predicting dates or scalar values instead of probabilities of binary outcomes.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz6moo4rwfo\"><sup><a href=\"#fnz6moo4rwfo\">[1]</a></sup></span></p><p>To date, prediction markets have most commonly been used in research, entertainment and corporate contexts. Though they were originally designed to benefit from the incentives of financial gains for accurate forecasters, market designs using \u201cplay money\u201d have also been shown to be effective. Companies\u2019 internal, real money, prediction markets on things like sales or project deadlines with only 20-60 traders were found to be better forecasters than the existing internal processes. Early experiments with prediction markets found them to have roughly equal accuracy to experts but superior to polls or simple averages of large groups. This was across domains from political elections to sports betting to box office openings.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz6moo4rwfo\"><sup><a href=\"#fnz6moo4rwfo\">[1]</a></sup></span>&nbsp;Prediction markets were even used to predict the outcome of replication attempts for academic research in the social sciences, correctly predicting the binary outcome 73% of the time across 103 replication attempts which was superior to a simple survey of participants.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwe6uqzdg65t\"><sup><a href=\"#fnwe6uqzdg65t\">[2]</a></sup></span></p><p>The incentive of either financial gain or status or fun seems to drive participants to seek out information relevant to a particular outcome and use it to calibrate their own private forecast in the form of a bet. Furthermore, since this bet is both directional and a certain volume of shares, a forecaster\u2019s confidence is an indirect input into the aggregation mechanism of the market. Though some experiments have found prediction markets to be inferior to prediction polling<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftqyubk4wk4\"><sup><a href=\"#fntqyubk4wk4\">[3]</a></sup></span>, when a scoring rule that better accommodated low liquidity markets was used in a true apples to apples comparison with comparable forecasters, the prediction market forecasts were just as accurate as prediction polling with the best discovered aggregation algorithm. Furthermore, success in forecasting via markets was just as predictive of forecasting skill as accuracy in prediction polling.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefozdpbzttqz\"><sup><a href=\"#fnozdpbzttqz\">[4]</a></sup></span></p><p>This is somewhat surprising! Rather than directly ask participants for their estimate and confidence, we\u2019ve introduced an intermediate step of betting with particular volumes and depend on a market for aggregation rather than an algorithm. You might expect trading skill to be a confounder that means returns and therefore available investments go to people who aren\u2019t necessarily the best forecasters, or that the market mechanism itself could confuse participants into providing less accurate forecasts. But it seems either the aggregation power of the market cancels this out, or they were not significant or valid concerns in the first place, at least in the realm of geopolitical forecasting with well incentivized participants.</p><p>The nature of prediction markets makes them ideal for predicting continually changing situations, as they output a continually updating real time consensus forecast. This also makes them unsuitable for some situations, as forecasters must see the consensus forecast in order to make their own, preventing them from working fully independently or from this technology being used to produce forecasts that are themselves sensitive information.</p><p>The accuracy of prediction markets also degrades the farther in the future the market\u2019s outcome will be determined. This is partially inherent to forecasting, but the problem is amplified in prediction markets because it means any financial investment made as a bet will be tied up until it is concluded. The opportunity cost is every other way that money could have been invested, which over long time periods will surely be superior to be the prediction market. One proposed solution to this drawback is investing traded funds on the forecaster\u2019s behalf which seems logistically challenging<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8owbqzfsvmr\"><sup><a href=\"#fn8owbqzfsvmr\">[5]</a></sup></span>. Another is to chain the resolution of criteria of prediction markets so that a combination of shorter term markets collectively produce a long term forecast<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9xzgy7ptjaa\"><sup><a href=\"#fn9xzgy7ptjaa\">[6]</a></sup></span>, but to my knowledge this has never been tested.</p><p>Users of prediction markets in experiments have reported low satisfaction with them and low trust in the resulting consensus forecasts<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2udq7nc5dwu\"><sup><a href=\"#fn2udq7nc5dwu\">[7]</a></sup></span>&nbsp;but I think it\u2019s likely this is a product of the experimental context with minimal training and poor UI of early prediction market software. A more modern internal prediction market at Google with very high engagement seems to have benefitted from a vastly improved user experience.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnroaqz41jlt\"><sup><a href=\"#fnnroaqz41jlt\">[8]</a></sup></span></p><p>A more fundamental limitation of prediction markets arises when you try to apply them to conditional scenarios, a potentially very valuable aspect of forecasting. For example, predicting the impacts of a hypothetical policy with questions targeting a particular metric in worlds either with or without that policy being implemented. Unfortunately, it seems that prediction markets can only be used to predict correlation with the possibility for lots of confounding factors obscuring conditional insights on causation.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefs37bzppee2\"><sup><a href=\"#fns37bzppee2\">[9]</a></sup></span>&nbsp;In my mind, this implies the need for an intersubjective scoring and incentive system like those discussed in <a href=\"https://damienlaird.substack.com/p/research-prediction-polling\"><u>Research: Prediction Polling</u></a>.</p><p>However, the greatest impediment to advancing the use of prediction markets in forecasting is a legal one. The Commodity Futures Trading Commission (CFTC) has effectively banned the creation of real money prediction markets in the US despite academic pushback for roughly the last two decades. Though this is a solvable problem, with some signs of political progress, recent results for prediction market platforms have been grim.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefifhqno6zbtq\"><sup><a href=\"#fnifhqno6zbtq\">[10]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkqq4178qncn\"><sup><a href=\"#fnkqq4178qncn\">[11]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefr70rusky8yl\"><sup><a href=\"#fnr70rusky8yl\">[12]</a></sup></span>&nbsp;Intense media blowback to the prospect of government funded research prediction markets in the early 2000s also reveals a separate potential risk should the government legalize them, depending on public perception and partisan politicization.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbrmlowwncq\"><sup><a href=\"#fnbrmlowwncq\">[13]</a></sup></span></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz6moo4rwfo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz6moo4rwfo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Wolfers, Justin, and Eric Zitzewitz. 2004. \"<a href=\"https://doi.org/10.1257/0895330041371321\"><u>Prediction Markets</u></a>.\" Journal of Economic Perspectives, 18 (2): 107-126.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwe6uqzdg65t\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwe6uqzdg65t\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Gordon, Michael, et al. \"<a href=\"https://doi.org/10.1371/journal.pone.0248780\"><u>Predicting replicability\u2014Analysis of survey and prediction market data from large-scale forecasting projects</u></a>.\" Plos one 16.4 (2021): e0248780.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntqyubk4wk4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftqyubk4wk4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Dana, Jason, et al. \"<a href=\"https://doi.org/10.1257/0895330041371321\"><u>Are markets more accurate than polls? The surprising informational value of \u201cjust asking\u201d</u></a>.\" Judgment and Decision Making 14.2 (2019): 135-147.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnozdpbzttqz\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefozdpbzttqz\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Atanasov, Pavel, et al. \"<a href=\"https://doi.org/10.1145/3490486.3538265\"><u>Crowd Prediction Systems: Markets, Polls, and Elite Forecasters</u></a>.\" Proceedings of the 23rd ACM Conference on Economics and Computation. 2022.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8owbqzfsvmr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8owbqzfsvmr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Antweiler, Werner. \"<a href=\"https://astralcodexten.substack.com/p/mantic-monday-let-me-google-that\"><u>Long-term prediction markets.</u></a>\" The Journal of Prediction Markets 6.3 (2012): 43-61.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9xzgy7ptjaa\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9xzgy7ptjaa\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Alexander, Scott. \u201c<a href=\"https://astralcodexten.substack.com/p/mantic-monday-let-me-google-that\"><u>Mantic Monday: Let Me Google That for You</u></a>.\u201d Astralcodexten.substack.com, astralcodexten.substack.com/p/mantic-monday-let-me-google-that. Accessed 13 Feb. 2023.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2udq7nc5dwu\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2udq7nc5dwu\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Graefe, Andreas. <a href=\"https://www.researchgate.net/profile/Andreas-Graefe/publication/36454489_Prediction_Markets_versus_Alternative_Methods_Empirical_Tests_of_Accuracy_and_Acceptability/links/0c96051ba24ea66fb2000000/Prediction-Markets-versus-Alternative-Methods-Empirical-Tests-of-Accuracy-and-Acceptability.pdf\"><u>Prediction markets versus alternative methods: empirical tests of accuracy and acceptability</u></a>. Diss. Karlsruhe, Univ., Diss., 2009, 2009.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnroaqz41jlt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnroaqz41jlt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u201c<a href=\"https://cloud.google.com/blog/topics/solutions-how-tos/design-patterns-in-googles-prediction-market-on-google-cloud\"><u>Design Patterns in Google\u2019s Prediction Market on Google Cloud.</u></a>\u201d Google Cloud Blog, cloud.google.com/blog/topics/solutions-how-tos/design-patterns-in-googles-prediction-market-on-google-cloud. Accessed 18 Feb. 2023.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fns37bzppee2\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefs37bzppee2\">^</a></strong></sup></span><div class=\"footnote-content\"><p>dynomight. \u201c<a href=\"https://cloud.google.com/blog/topics/solutions-how-tos/design-patterns-in-googles-prediction-market-on-google-cloud\"><u>Prediction Market Does Not Imply Causation.</u></a>\u201d DYNOMIGHT, 6 Oct. 2022, dynomight.net/prediction-market-causation/. Accessed 18 Feb. 2023.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnifhqno6zbtq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefifhqno6zbtq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Hanania, Richard. \u201c<a href=\"https://richardhanania.substack.com/p/how-to-legalize-prediction-markets\"><u>How to Legalize Prediction Markets</u></a>.\u201d Richardhanania.substack.com, richardhanania.substack.com/p/how-to-legalize-prediction-markets. Accessed 18 Feb. 2023.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkqq4178qncn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkqq4178qncn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Arrow, Kenneth J., et al. \"<a href=\"https://doi.org/10.1126/science.1157679\"><u>The promise of prediction markets</u></a>.\" Science 320.5878 (2008): 877-878.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnr70rusky8yl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefr70rusky8yl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Alexander, Scott. \u201c<a href=\"https://astralcodexten.substack.com/p/the-passage-of-polymarket\"><u>The Passage of Polymarket</u></a>.\u201d Astralcodexten.substack.com, astralcodexten.substack.com/p/the-passage-of-polymarket. Accessed 13 Feb. 2023.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbrmlowwncq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbrmlowwncq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Hanson, Robin. \u201c<a href=\"http://mason.gmu.edu/~rhanson/policyanalysismarket.html\"><u>Policy Analysis Market Archive</u></a>.\u201d Mason.gmu.edu, mason.gmu.edu/~rhanson/policyanalysismarket.html. Accessed 14 Feb. 2023.</p></div></li></ol>", "user": {"username": "Damien Laird"}}, {"_id": "2jHurMmzvyNbeEtCd", "title": "Making better estimates with scarce information", "postedAt": "2023-03-22T16:29:10.313Z", "htmlBody": "<h1>TL;DR</h1><p>I explore the pros and cons of different approaches to estimation. In general I find that:</p><ul><li>interval estimates are stronger than point estimates</li><li>the lognormal distribution is better for modelling unknowns than the normal distribution</li><li>the \"lognormal\" mean is better than the arithmetic mean for building aggregate estimates</li></ul><p>These differences are only significant in situations of&nbsp;<i>high uncertainty,</i> characterised by a high ratio between confidence interval bounds. Otherwise, simpler approaches like point estimates &amp; the arithmetic mean are fine.</p><h1>Summary</h1><p>I am chiefly interested in how we can make better estimates from very limited evidence. Estimation strategies are key to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/s6k9cKdX8c4nhH8qq/estimation-for-sanity-checks\"><u>sanity-checks</u></a>, cost-effectiveness analyses and forecasting.</p><p>Speed and accuracy are important considerations when estimating, but so is&nbsp;<i>legibility</i>; we want our work to be easy to understand. This post explores&nbsp;<i>which approaches are more accurate</i> and&nbsp;<i>when the increase in accuracy justifies the increase in complexity.</i></p><p>My key findings are:</p><ul><li><strong>Interval (or distribution) estimates are more accurate than point estimates</strong> because they capture more information. When <i>dividing </i>by an unknown of high variability (high ratio between confidence interval bounds) point estimates are significantly worse.</li></ul><p>&nbsp;</p><ul><li><strong>It is typically better to model distributions as lognormal&nbsp;</strong>rather than normal. Both are similar in situations with low variability, but lognormal appears to better describe situations of high variability.</li></ul><p>&nbsp;</p><ul><li><strong>The \"lognormal\" mean is good for building aggregate estimates.&nbsp;</strong>By calculating the mean of a lognormal distribution for which our inputs form a confidence interval, we capture the positive skew typical of more variable distributions.</li></ul><p>&nbsp;</p><ul><li><strong>In general, simple methods are fine while you are estimating quantities with low variability.&nbsp;</strong>The increased complexity of modelling distributions and using geometric means is worthwhile when the unknown values are highly variable.</li></ul><h1>Interval vs point estimates</h1><p><i>In this section we will find that for calculations involving division, interval estimates are more accurate than point estimates. The difference is most stark in situations of high uncertainty.</i></p><p>Interval estimates, for which we&nbsp;<i>give an interval within which we estimate the unknown value lies</i>, capture more information than a point estimate (which is simply what we estimate the value to be). Interval estimates often include the&nbsp;<i>probability&nbsp;</i>that the value lies within our interval (confidence intervals) and sometimes specify the shape of the underlying distribution. In this post I treat&nbsp;<i>interval estimates&nbsp;</i>as&nbsp;<i>distribution estimates&nbsp;</i>as the same thing.</p><p>Here I attempt to answer the following question:&nbsp;<strong>how much more accurate are interval estimates and when is the increased complexity worthwhile?</strong></p><h2>Core examples</h2><p>I will explore this through two examples which I will return to later in the post.</p><p><strong>Fuel Cost:&nbsp;</strong><i>The amount I will spend on fuel on my road trip in Florida next month</i>. The abundance of information I have about fuel prices, the efficiency of my car and the length of my trip means I can use narrow confidence intervals to build an estimate.</p><p><strong>Inhabitable Planets:&nbsp;</strong><i>The number of planets in our galaxy with conditions that could harbour intelligent life.&nbsp;</i>The lack of available information means I will use very wide confidence intervals.</p><h2>Point estimates are fine for multiplication, lossy for division</h2><p>Let\u2019s start with Fuel Cost. Using Squiggle (which uses lognormal distributions by default: see the next section for more on why), I enter 90% confidence intervals to build distributions for fuel cost per mile (USD per mile) and distance of my trip (miles). This gives me an expected fuel cost of 49.18USD</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/gut4zpbzkc5lnkd553to\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/ug9zmitywrztzqzmcu8z 190w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/mqtobn9ldxbujaqlsbkr 380w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/ypsczs4t0ygtrmjc5mkz 570w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/g3p2ljdhie2rcqjrjjxm 760w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/vv5svsew4e3t3yx2cfrq 950w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/i2h66zdswjuwfo09hena 1140w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/zx5ohyp0csnaw5ehzn6v 1330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/xfy3jfycx23filkm24ew 1520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/jcq27hjd8yciavqkenv2 1710w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/w6p6pkpswiicwq3po0my 1823w\"></figure><p>What if I had used point estimates? I can check this by performing the same calculation using the&nbsp;<i>expected values&nbsp;</i>of each of the distributions formed by my interval estimates.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/u23xcfitg2elf8qao205\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/kzf6sz7j97vdhwd1wsqw 120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/rnj7esnaapzuqierreza 240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/hpzqhuuqkzja7k21l6s2 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/xwqy3y6nqen8cfqzdwxh 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/yjtaehytfpedw6fxclki 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/zck0lglegyb5h5sgxbuw 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/mmcakaw5ycwyv9hzoqi9 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/ql6gxvuqywnsgja0jygp 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/zo6u645d88q9r7ubst7x 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/jwzjkxeujmxtufin1qcj 1126w\"></figure><p>I get <strong>the same answer. </strong>In fact, this applies in all cases: if X and Y are normally or lognormally distributed,</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"E(X)E(Y)=E(XY)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;\">Y</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;\">Y</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span><p>In other words, the mean of the product of two normal/lognormal distributions is the product of their means. The only drawback of using point-estimates for multiplication is that you only get a numerical answer - you lose the shape of the distribution.</p><p>What about division? Put simply,&nbsp;</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"E(1/Y)\u22601/E(Y)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;\">Y</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;\">Y</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p>so&nbsp;</p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"E(X/Y)\u2260E(X)/E(Y)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;\">Y</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.024em;\">X</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">/</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.182em;\">Y</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span><p>Division <i>will </i>be lossy when you use point estimates. But how bad is it?</p><p>Using the Fuel Cost example we find that the point estimate result (0.099048) is within 1% of the interval estimate result (0.099809).</p><figure class=\"image image_resized\" style=\"width:61.49%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/kglt19oecis39jty8fn8\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/wgx4xmcylh0t0cr5dx0m 130w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/v1x2m7kpd9hb94r9bxgr 210w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/e59rnqguy1eghmdo21fb 290w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/zzkiv87nwqjywoatnlav 370w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/acwlq7b4sqaczcwim29e 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/qdryrgro808lkagldswx 530w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/ivdlghsiaeq7pffmjgdg 610w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/jbb0ecbgyn1mqwzxbilw 690w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/e6ck8mb8ueulbailqtfp\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/fb6fit1zfgexquzknzpv 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/ilbfjy9imrkvbredb63n 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/ryn2lr70nbywo78kqsch 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/jolsdaeghjnmljyq97ik 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/qjgypw7gjb5y6grypr1c 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/arwz1t5fdwrqyehyqaa2 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/mbknawaaxqcjwxzydorg 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/y18shk9hktooqlj1kddk 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/jwch3nbetr5qur9uafrc 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/h5e8fujpgzjh5zxz1rsw 918w\"></figure><p>Now let\u2019s turn to the inhabitable planets example. I use interval estimates for the number of stars in the galaxy and the number of stars per inhabitable planet. Because of the uncertainty the bounds of my intervals differ by 2-3 orders of magnitude.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/fielt3kvp8u2ffnlxiev\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/ds2tb1kafz6ohazzns3b 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/y356t533bseakostpdlq 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/hrpe6pyirvorfwo3owey 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/kyyvfxei9cmtl3naqz1x 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/qtyazcbu3gxa3qvveest 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/ldw5saxl6sstrjxeqnwv 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/i701sygykodbhnjydtdy 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/jl3nzrytguwvpairb9k1 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/ifq6tz5zdxngvjo7dzno 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/biavcbquyzgogkctnvzx 830w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/ab4ifzu9jvbycdhry2bb\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/c9ctvcshooivmk7j1ppf 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/f2yrwjhav8ajouysu4pp 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/uqgyc0vfehvx5tcywyb9 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/w3gvecvjtnrmrpnyhdmx 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/bxlcpjswxg7ethgwkuud 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/j3rqzkvgarbrcmxovrmg 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/yicx6pgddkzrp3kjfnmu 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/qydcqu7cwk9xlvlcikeg 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/rjk9byoqrzsgvtuur39f 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/mujsxsjeld1ljroiuftt 924w\"></figure><p>&nbsp;</p><p>I find that the interval-estimate approach gives an expected number of inhabitable planets of 3.5 billion, while my point-estimate approximation is just 100 million! Clearly when there are very high levels of uncertainty, dividing by a point estimate is inaccurate. Not only that, but the point estimate answer provides no information on the shape of the possible outcomes. The interval estimate approach shows us that although the expected number of planets is 3.5 billion, the median is just 220 million.&nbsp;</p><p>This heavy-tailed behaviour helps explain where the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Drake_equation\"><u>Drake Equation</u></a> (which relies upon point-estimates of highly uncertain values and suggests that we should have heard from aliens by now) goes wrong: using interval estimates we can show that although the expected number of interstellar alien neighbours is high, the median is much lower.&nbsp;<a href=\"https://www.squiggle-language.com/playground/#code=eNpVjkEKwjAQRa8SstKgIREqWnAlnsBtNtFObSBNSjqhiHh3bUJLO8v3%2BH%2F%2Bh%2FaNH%2B6xbXV40xJDhF1Ct8qgDxOpoNbR4tVXQEsaNAK5kANBT%2BRJucFg4yN2VjvA%2Fm8EF0kKflbOmho6CD3qkJVMOV4o1wX%2FGPWCC37K3DgEuxLHLBCeTebFHLDgXjhSKVK5SKeccuNWtpH79cYtW6xi0ww2%2F2XTI5ab6fcH%2BSZivw%3D%3D\"><u>My very rough attempt</u></a> finds a mean of 4700 alien neighbours, with a a 25-50% chance of none at all (although I may be pushing Squiggle past its limits).</p><h2>Should we always use interval estimates?</h2><h3>Using interval estimates as inputs</h3><p>As we have seen, interval estimates are better for modelling uncertainty. They do not introduce mathematical error and they can store more information about what we know.</p><p>In a sense a point estimate <i>is </i>a distribution estimate: one that assigns probability 1 to the point estimate and 0 to everything else. This means it isn't hard to improve upon. However, if we don't have strong objective evidence for the shape of the distribution, we have to use personal judgement to estimate it. If transparency and impartiality are important, this can be a problem.</p><p>Suppose I do a quick google search and determine that the fuel efficiency of my car is supposed to be 47mpg. If I'm estimating the fuel cost for an expense form, using this value makes sense: the person reading the form can verify that this is an objective estimate of my car's efficiency. If I am doing he calculation for myself, on the other hand, it might make sense to use an interval estimate using my personal judgement (something like a 90% C.I. of 40 to 47mpg, on the basis that my car is no longer new and that cars don't achieve their theoretical efficiency in real-world conditions).</p><h3>Using interval estimates as outputs</h3><p>When constructing an estimate from multiple sub-estimates, as I would in the Fuel Cost and Inhabited Planets examples, a key challenge is <i>communicating the level of uncertainty in the final result.</i></p><p>On their own, point-estimates do not communicate any nuance. They should be paired with a statement on the uncertainty of the result, like \"this value is highly uncertain and could be off by an order of magnitude\".</p><p>The trouble is that it's difficult to know just how uncertain the final result is. Even when we calculate using interval estimates, the reliability of the final distribution is highly uncertain. Look back at the Inhabited Planets example in the previous section: we find a 90% confidence interval of 4.7 million to 11 billion inhabitable planets in our galaxy. But this only gives a <i>flavour</i> of the likely distribution of inhabited planets. The 90% confidence interval, calculated from two rough sub-estimates, just isn't trustworthy.</p><p>So even though interval outputs communicate that the value is uncertain, readers may still overestimate the reliability of the estimate.</p><p>Toby Ord gives a good example of how to convey uncertainty in the Precipice. He accompanies table 6.1, which provides point-estimates for the magnitudes of various existential risks over the next 100 years, with the qualifier:</p><blockquote><p>There is significant uncertainty remaining in these estimates and they should be treated as representing the right order of magnitude - each could easily be a factor of 3 higher or lower.</p></blockquote><p>It's nice because the description of the uncertainty is itself imprecise, which dissuades us from being over-confident in it.</p><p>[Thanks to Vasco Grilo for highlighting this example]</p><h2>General findings: interval vs point estimates</h2><p>I did some more&nbsp;<a href=\"https://www.squiggle-language.com/playground#code=eNpNycEKAiEUheFXubgaIZqcWg20ip6g7WyuXqMgFe4oEdG751Smu%2FOf7ynmS7ifknPIDzFGTnb1uY50jYHLQ%2FaM6RYPgawYBSDsQUEMoNbD5EGXXML8bZOLai05ecscWOW3U72z6DuU8jtUj%2FLnQ%2BO6ui6%2BbdxUN8V3jVN1yi5eb65LSQ0%3D\"><u>experimentation</u></a> on Squiggle to generalise the findings slightly.</p><ul><li><strong>It's OK to multiply point-estimates. </strong>They will give the same mean as the mean of the product of two distributions.</li><li><strong>Dividing by a point-estimate is accurate when the ratio between the interval bounds is low, and performs poorly when the ratio is more than 2.&nbsp;For example:</strong><ul><li>When dividing by a (lognormal, 90% C.I.) distribution where the upper bounds are 1.2 times the lower bounds, the point-estimate approach underestimates by 0.3%</li><li>When dividing by a (lognormal, 90% C.I.) distribution where the upper bounds are 2 times the lower bounds, the point-estimate approach underestimates by 4.3%</li><li>When dividing by a (lognormal, 90% C.I.) distribution where the upper bounds are 10 times the lower bounds, the point-estimate approach underestimates by 39%</li></ul></li><li><strong>Interval estimates are stronger, but prone to personal bias when evidence is scarce.&nbsp;</strong>Deciding between interval and point-estimates is a trade-off between accuracy and accountability.</li></ul><h1>Normal vs Lognormal modelling</h1><p>Squiggle uses lognormal distributions by default. Why?</p><p><i>In this section we will find that lognormal distributions are very similar to normal distributions when they share the same, narrow confidence intervals. As the intervals widen the distributions diverge, and the lognormal distribution usually becomes superior.</i> Hence I suggest that using the lognormal distribution by default is the best strategy. I don't consider other distributions (like the power-law distribution) that may be an ever better fit in some cases.</p><p>Turning to the Fuel Price example, we see that the normal/lognormal choice makes little difference when the ratio between interval bounds is small:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/tiky4yzaxvq3hfxaoosl\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/uekikricqvrstgzjlzpz 126w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/uyj7wnxi5cs8id6lurfw 206w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/b3kouedf8m4elkb0kmyw 286w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/k9mriswiv8nnebqcywxb 366w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/czwrqujk7gpyq3m3foqa 446w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/rjxujdug1k013c33ozoq 526w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/yz2cdoa7xwefa706r4td 606w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/cmmtuga2wzdoybmr5c3m 686w\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/xpbv8qrhlhuai5sjno7z\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/uagam1zifrtyqccsijyl 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/wgigmdeaf0pqdt76mkrj 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/dhzl93gfb7dbem1wymgy 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/jznm5t8suxcmbwaiy5lz 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/kpebx75bnjarlqypnm2e 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/zykydur1agc20yzp8haj 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/w9yvjmp9a1f5v4ohznyl 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/mpjcivwc72zyp4u17bow 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/lqtmkn3so2l9ukd6nipp 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/dwr1cz9gkx8tgwktj1gz 913w\"></p><p>In this case lognormal and normal look very similar, and the distributions give means of 43.885 and 44 respectively.</p><p>With the Inhabited Planets example, however, there is a different story. Using 0.5 and 50 as the 5th and 95th percentiles, I get very different-looking distributions:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/vvgsfbmuliowa158mp2s\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/o664jsp5bpfwfeiftkok 90w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/atqzal55jqmnodcb4lao 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/recdpewecd2hu0kaldyn 270w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/sh5paoyeclbwrjhf7j40 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/gu61wlnqb1al9bewthov 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/kbozzobksudx7ufyjmwn 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/y5b9lg0ucpm5eobfmzud 630w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/z1xu3pcxwjg3y5p8rfqn 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/swlx7yohnuekcxchsi5s 810w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/wqsq0neahjxqdaz8tyqk 821w\"></figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/ucie1ddodzddmwu0ynci\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/tgzebxxwyfdd2jr67try 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/pc8oxkqpk7qkdvpm6hf7 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/f3cn0eogqeulsvuw4ods 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/w2yhrnwiwbpib2yk9t6k 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/hfgsytyfhlfhwogs1jpj 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/iymggfdsavb3sa5np83a 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/xx1jk7eiu5z6nynelk7q 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/umgbyo1rruivrgyfmy4u 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/n43xxrvair7a5mqxzysk 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/no03xcwuhudawd91odkd 930w\"></figure><p>The means are 13.32 and 25.25 for the lognormal and normal models respectively, and the shapes are very different.</p><p>Which is a better match for our understanding of the situation? In my opinion, the lognormal distribution is better. If we expect the number of planets per star to be between 0.5 and 50, the \u201cexpected\u201d number of planets should be closer to 13 than to 25. Furthermore, the normal distribution assigns a nontrivial probability to (impossible) negative outcomes.</p><p>I think it\u2019s clear that in this case the lognormal distribution is superior. But that\u2019s just a gut feeling. Let\u2019s explore this.</p><h2>A high ratio between interval bounds implies positive skew</h2><p>Consider datasets with a high ratio between the 5th and 95th percentiles:</p><ul><li>The lengths of rivers (often used to exemplify&nbsp;<a href=\"https://en.wikipedia.org/wiki/Benford%27s_law\"><u>Benford\u2019s law</u></a>)</li><li>The populations of cities/countries</li><li>Property prices</li></ul><p>These&nbsp;<i>all&nbsp;</i>have positively-skewed distributions that could be approximated by the lognormal distribution.</p><p>Now consider broadly symmetric datasets:</p><ul><li>The heights of adult males</li><li>The durations of pop singles</li><li>The price of gas in Florida gas stations today</li></ul><p>These could probably be modelled with the normal distribution. Notice that in all of these cases,&nbsp;<i>the ratio between the 5th and 95th percentiles will be low</i>. A tall man is perhaps only 20% taller than a short man.</p><p>So in general&nbsp;<strong>a high ratio between 90% C.I. bounds implies positive skew</strong> and is hence better modelled by a lognormal distribution.</p><p>This isn\u2019t a rigorous argument, but I suspect that you will struggle to think of examples that buck the trend. I can think of <i>one</i>. It\u2019s possible that a normally-distributed variable could happen to have a small, positive 5th percentile. This would lead to a high ratio between 5th and 95th percentiles: suppose the temperature in my hometown has 5th and 95th percentiles of 0.1\u00b0C and 30.0\u00b0C respectively. The ratio between the bounds is 300, but the underlying distribution is probably symmetric and best modelled by a normal distribution. Note that the rule of thumb <i>would </i>apply if we measured temperature in Kelvin instead.</p><h2>General findings: normal vs lognormal</h2><ul><li><strong>The lognormal and normal distributions are similar when the ratio between interval bounds is low.&nbsp;</strong>The difference in means is just 3.6% when one bound is 2x the other.</li><li><strong>The lognormal distribution is usually superior when the ratio between interval bounds is high.&nbsp;</strong>These circumstances usually imply negative skew, which make the lognormal distribution a better fit.</li><li><strong>Although the lognormal is usually better, there are important considerations:</strong><ul><li>The lognormal distribution can only model positive values.</li><li>If you have reliable estimates of the mean and/or standard deviation of a distribution, the normal can be easier to model with.</li><li>Quantities with strict upper bounds (such as probabilities) may not be suitable for the lognormal distribution, although the normal distribution is usually not suitable either in these instances.</li><li>Not everything is positively-skewed or symmetric. The number of teeth in the next dental patient\u2019s mouth, for example, would likely be positively skewed. But you could model \u201c32 - number of teeth\u201d as lognormal instead.</li></ul></li></ul><h1>Creating aggregate estimates</h1><p><i>In this section we will find that the \"lognormal mean\" can outperform the arithmetic mean, but may only be worthwhile in situations of high variability.</i></p><p>All else equal, modelling with distributions is better than using point-estimates. However we often don\u2019t have reliable evidence for the shape of a distribution. This section explores the question:&nbsp;<strong>how can we use multiple point-estimates to create reliable aggregate estimates?</strong></p><p>In this section I will consider three means:</p><ul><li>The arithmetic mean</li></ul><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\frac{x_1+x_2}{2}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 3.344em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 3.344em; top: -1.316em;\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span><span class=\"mjx-denominator\" style=\"width: 3.344em; bottom: -0.756em;\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 3.344em;\" class=\"mjx-line\"></span></span><span style=\"height: 2.072em; vertical-align: -0.756em;\" class=\"mjx-vsize\"></span></span></span></span></span></span></span><ul><li>The geometric mean&nbsp;</li></ul><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\sqrt[2]{x_1,x_2}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mroot\"><span class=\"mjx-root\" style=\"font-size: 58.9%; vertical-align: 0.409em; width: 0px;\"><span class=\"mjx-mn\" style=\"padding-left: 0.399em;\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-box\" style=\"padding-top: 0.045em;\"><span class=\"mjx-surd\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.519em; padding-bottom: 0.519em;\">\u221a</span></span><span class=\"mjx-box\" style=\"padding-top: 0.097em; border-top: 1px solid;\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span></span></span></span></span></span></span><ul><li>The \"lognormal mean\": the mean of the lognormal distribution for which x\u2081, x\u2082 form an n% confidence interval. The lognormal mean will depend upon the size of this confidence interval.</li></ul><h2>Choice of mean should depend on the expected underlying distribution</h2><p>Earlier we saw that estimating underlying distributions (rather than simply working with point-estimates) introduces personal bias. Our choice of mean is linked to our estimate for the shape of the underlying distribution, and unfortunately there is no way around it: each choice of mean makes an implicit assumption about the underlying distribution.</p><p>For simplicity, assume we have two sub-estimates which we wish to weight equally.</p><ul><li>The arithmetic mean finds the mean of a symmetric distribution (such as the normal distribution) with symmetric confidence interval (x\u2081, x\u2082)</li><li>The geometric mean finds the <strong>median</strong> of any lognormal distribution with symmetric confidence interval (this is always lower th).</li><li>The lognormal mean finds the mean of a lognormal distribution with symmetric n% confidence interval (x\u2081, x\u2082)</li></ul><h2>The geometric mean is usually better than the arithmetic mean</h2><p>Interestingly, it hardly matters which mean we use when the ratio between inputs is low.</p><p>Suppose, for example, that I have two estimates for the fuel-efficiency of my car.</p><ul><li>The carmaker\u2019s website claims 50mpg</li><li>My mechanic, who has experience with older models of my car, claims 40mpg</li></ul><figure class=\"table\"><table style=\"border-style:solid\"><tbody><tr><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\"><strong>Type of mean used</strong></td><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\"><strong>Result</strong></td></tr><tr><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\">Arithmetic</td><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\">45</td></tr><tr><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\">Geometric</td><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\">44.72</td></tr><tr><td style=\"border-color:hsl(0, 0%, 0%);border-style:solid\">Lognormal, 68% C.I</td><td style=\"border-color:hsl(0, 0%, 0%);border-style:solid\">45.004</td></tr><tr><td style=\"border-color:hsl(0, 0%, 0%);border-style:solid\">Lognormal, 90% C.I</td><td style=\"border-color:hsl(0, 0%, 0%);border-style:solid\">44.824</td></tr></tbody></table></figure><p><br>&nbsp;The four means differ by less than 1%.</p><p>The lognormal mean calculated from a 68% confidence interval is higher than the one calculated from a 90% interval. This is because the former distribution has higher standard deviation and therefore a bigger right tail.</p><p>What about when the sub-estimates are further apart? Let\u2019s take two estimates for the number of planets per star in the galaxy: 1 and 10.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\"><strong>Type of mean used</strong></td><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\"><strong>Result</strong></td></tr><tr><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\">Arithmetic</td><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\">5.5</td></tr><tr><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\">Geometric</td><td style=\"border:1pt solid hsl(0, 0%, 0%);padding:5pt;vertical-align:top\">3.16</td></tr><tr><td style=\"border-color:hsl(0, 0%, 0%);border-style:solid\">Lognormal, 68% C.I</td><td style=\"border-color:hsl(0, 0%, 0%);border-style:solid\">6.18</td></tr><tr><td style=\"border-color:hsl(0, 0%, 0%);border-style:solid\">Lognormal, 90% C.I</td><td style=\"border-color:hsl(0, 0%, 0%);border-style:solid\">4.04</td></tr></tbody></table></figure><p><br>&nbsp;The arithmetic mean is now 74% greater than the geometric mean, and the lognormal mean calculated from a 68% confidence interval is nearly double the geometric mean. Once again, it\u2019s the&nbsp;<i>ratio between inputs</i> that matters here. When the ratio is low, the means are close. When the ratio is high, the means diverge.</p><p>I built a <a href=\"https://www.desmos.com/calculator/cqqphvltbj\">tool to explore</a> this further. x represents the ratio between the two sub estimates (x\u2082/x\u2081) and p represents the size of the confidence interval used to generate the lognormal mean.</p><p>Try moving p towards 1: you will see that the lognormal mean tends to the geometric mean.</p><p>So which mean is better when the ratio between inputs is high? In the last section we saw that a high ratio between C.I. bounds implies a positive skew. It follows that a high ratio between sub-estimates also implies a positive skew in the underlying distribution.</p><ul><li>Clearly the arithmetic mean (which assumes an symmetric underlying distribution) is no good in this scenario.&nbsp;</li><li>The geometric mean is essentially the lognormal mean formed by a 100% confidence interval. If we have reason to believe x\u2081, x\u2082 are extreme outliers (worst- and best-case estimates, say) then this could be a good choice.</li><li>The lognormal means are viable candidates, but they vary considerably based on the assumed size of the confidence interval used. If we have no objective evidence for the size of the confidence interval, we have to use subjective judgement to decide the size.&nbsp;</li><li>Of course, the underlying distribution may be neither normal nor lognormal. As uncertainty increases the distribution of the long tails become increasingly influential on the mean. But I won't explore other tail types here.</li></ul><p>In short, it makes sense to assume a lognormal distribution when the ratio between sub-estimates is high, and hence a lognormal mean is a good choice. However this requires a judgement call on the size of the confidence interval represented by x\u2081, x\u2082.</p><p>If you want a rule of thumb, it may make sense to generate lognormal means from a 90% confidence interval by default. As long as the ratio between sub estimates is under 1000, the lognormal mean will lie roughly midway between the geometric and arithmetic means: a good compromise. The main worry should be that you are ignoring the effects of an undetected fat tail.</p><p>Here's how I would apply the above to my two key examples.</p><p><i><strong>Fuel Cost example:</strong></i></p><p>I have two estimates for the fuel-efficiency of my car.</p><ul><li>The carmaker\u2019s website claims 50mpg</li><li>My mechanic, who has experience with older models of my car, claims 40mph</li></ul><p>It seems reasonable that these estimates represent best- and worst-case estimates for the true fuel efficiency of my car, so I suspect the geometric mean (or, similarly, lognormal mean using 99% C.I of (40,50)) will be most accurate. However, since the ratio between estimates is low, I opt for the simpler arithmetic mean, 45.</p><p><i><strong>Inhabitable Planets example:</strong></i></p><p>An astronomy paper claims that \"stars in our galaxy probably have on average 1 to 10 planets each\".</p><p>The source gives no confidence intervals, but I choose to interpret \"probably\" as 90% confidence, and hence use a 90% confidence interval to generate a lognormal mean of 4.04 planets per star.</p><h2>Weighted means</h2><p>Sometimes we have multiple point-estimates and varying levels of confidence in each one. So we use a&nbsp;<i>weighted mean</i> to build an aggregate estimate.&nbsp;</p><p>The thought of weighted lognormal means is exploding my brain at the moment, so I will stick to weighted arithmetic and geometric means, which are very straightforward.</p><p>We apply weights&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"w_1+w_2+ ... +&nbsp;w_n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span></span></span></span>&nbsp;to our sub-estimates&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x_1+x_2+ ... +&nbsp;x_n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span></span></span></span>&nbsp;to build an arithmetic weighted mean:</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x=w_1x_1+w_2x_2+ ... +&nbsp;w_nx_n\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span></span></span></span>&nbsp;where&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"w_1+w_2+ ... +&nbsp;w_n=1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"w\\in[0,1]\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2208</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span></span></span></span></span></span>&nbsp;</p><p>The equivalent for the geometric mean is</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x=w_1^{x_1}w_2^{x_2}...w_n^{x_n}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.315em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.315em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.157em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.18em; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span></span></span></span></span></span></span>&nbsp;where&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"w_1+w_2+ ... +&nbsp;w_n=1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup MJXc-space2\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></span></span>,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"w\\in[0,1]\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2208</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mn MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]</span></span></span></span></span></span></span>&nbsp;</p><p>As with the unweighted means, the weighted arithmetic and geometric means are close when the ratios between estimates are low. The graph shows the two-estimate example, where the x-value is the&nbsp;<i>ratio between the sub-estimates</i>:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/2jHurMmzvyNbeEtCd/xsuqnnaxzk6xnujlmflx\">Again, I would argue that the geometric mean is generally superior. When the sub-estimates are close it hardly matters, and when they are far apart the geometric mean better captures the positive skew in the underlying distribution.</p><h2>General findings: aggregate estimates</h2><ul><li><strong>When the ratio between the inputs is &lt;3, the arithmetic, geometric and lognormal means are similar.&nbsp;</strong>Since the arithmetic mean is more widely understood, it may be a better choice when the ratio between inputs is low<strong>.</strong></li><li>As the ratio between inputs grows, the means diverge. <strong>The high ratio suggests underlying positive skew, which makes the arithmetic mean unreliable. </strong>A judgement call is needed to estimate the size of the confidence interval represented by our inputs, which introduces subjectivity. One way to avoid this is to state in advance that you will use 90% lognormal means in place of unweighted arithmetic means of two values.</li><li>The geometric mean can be thought of as the mean of a lognormal distribution for which the inputs form extreme outer limits</li><li>We have not explored how to apply the lognormal mean in situations with three or more inputs, or with weighting</li></ul><h1>Conclusion: complexity vs legibility</h1><p>We have seen a common theme throughout:&nbsp;<i>simple methods show high fidelity in situations of low variability</i> (as measured by the ratio between confidence interval bounds or of sub-estimates).</p><p>So I would make the following suggestion: If your work is for public scrutiny, needs to avoid subjectivity or is time-sensitive,<strong> only use the more complex methods when it makes a significant difference.</strong></p><ul><li>Point estimates are fine if your final calculation is not too long and the ratio between 90% confidence interval bounds is less than 2 (or if you don't need to divide by an unknown and you don't care about the \"shape\" of your answer).</li><li>The normal distribution is easier to understand than lognormal, so favour it when the ratio between confidence interval bounds is low</li><li>The arithmetic mean is widely understood, so use it as long as most of the inputs vary by less than a factor of 2</li></ul><p>On the other hand,<strong> simple methods can lead to spurious results in situations of super-high variability.&nbsp;</strong>For example, estimates for the incidence of intelligent life in the galaxy (a high variability, multi-stage calculation) vary wildly depending on the complexity of the methods used.</p><p>Thanks to the makers of&nbsp;<a href=\"https://www.squiggle-language.com/#code=eNqrVirOyC8PLs3NTSyqVLIqKSpN1QELuaZkluQXQURqARlkDng%3D\"><u>Squiggle</u></a>, which has made working with more complex models much faster.</p><h3>Changes</h3><ul><li>[23 Mar] Amended point-estimate section to reflect that <i>multiplication is fine </i>with point estimates, while <i>division introduces error</i>. Changed summaries accordingly. Thanks to <a href=\"https://www.lesswrong.com/users/thomas-sepulchre?mention=user\">@Thomas Sepulchre</a> (LessWrong) for the comment.</li><li>[27 Mar] Corrected errors on Squiggle graphs that compare similar lognormal/normal distributions - I had been using the wrong standard deviations for the normal distributions before.</li><li>[1 Apr] Brought work on the lognormal mean into the post and ceased to interpret its sensitivity to heavy right-tails as a sign of unreliability. Added more on the pros and cons of using interval estimates as inputs and outputs. Thanks to <a href=\"https://forum.effectivealtruism.org/users/vascoamaralgrilo?mention=user\">@Vasco Grilo</a> for feedback.</li><li>[3 Apr] Re-wrote the section \"Should we always use interval estimates?\" to separate the question of using interval estimates for inputs vs outputs, and to add examples.</li></ul>", "user": {"username": "Stan Pinsent"}}, {"_id": "d4W4inHhts5Y2szBf", "title": "The space of systems and the space of maps", "postedAt": "2023-03-22T16:05:51.633Z", "htmlBody": "<p>When we're trying to do AI alignment, we're often studying systems which don't yet exist. This is a pretty weird epistemic activity, and seems really hard to get right. This post offers one frame for thinking about what we're actually doing when we're thinking about AI alignment: using parts of the space of maps to reason about parts of the space of intelligent systems.</p><p>In this post, we:</p><ul><li>Introduce a simple model of the epistemic situation, and</li><li>Share some desiderata for maps useful for alignment.</li></ul><p>We hope that the content is mostly the second kind of obvious: obvious once you see things in this way, which you maybe already do. In our experience, this comes with a risk: reading too fast, you may miss most of the nuance and useful insight the deceptively simple model brings, or come away with a version of the model which is rounded off to something less useful (i.e. \"yeah, there is this map and territory distinction\").&nbsp;<br><br>As a meta recommendation, we suggest reading this post slowly, and ideally immediately trying to apply the model to some confusion or disagreement about AI alignment.&nbsp;&nbsp;&nbsp;&nbsp;</p><h3>The space of systems and the space of maps</h3><p>Imagine the space of possible intelligent systems:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d4W4inHhts5Y2szBf/ms4kxthr6qd3s9jjaqwx\"></p><p>Two things seem especially important about this space:</p><ul><li>It\u2019s very large; much larger than the space of current systems.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmlx5ubehf4f\"><sup><a href=\"#fnmlx5ubehf4f\">[1]</a></sup></span></li><li>We don\u2019t get direct epistemic access to it.<ul><li>This is obviously true of systems which don\u2019t currently exist.</li><li>In a weaker sense, it also seems true of systems which do exist. Even when we get to directly interact with a system:<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefp4uo1qhikpj\"><sup><a href=\"#fnp4uo1qhikpj\">[2]</a></sup></span><ul><li>Our thinking about these parts of the space is still filtered through our past experiences, priors, predictive models, cultural biases, theories\u2026</li><li>We often don\u2019t understand the emergent complexity of the systems in question.</li></ul></li></ul></li></ul><p>If we don\u2019t get direct epistemic access to the space of systems, what are we doing when we reason about it?</p><p>Let\u2019s imagine a second space, this time a space of \u201cmaps\u201d:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d4W4inHhts5Y2szBf/ufkojdf9cdixaxtbgpvp\"></p><p>The space of maps is an abstract representation of all the possible \u201cmaps\u201d that can be constructed about the space of intelligent systems.&nbsp;<strong>The maps are ways of thinking about (parts of) the space of systems.&nbsp;</strong>For example:</p><ul><li>Replicable descriptions of how a machine learning model works and was trained are a way of thinking about that model (a point in the space of intelligent systems).</li><li>An ethnographic study of a particular human community is a way of thinking about that community (another point in the space of systems).</li><li>The theory of evolution is a way of thinking about evolved creatures, including intelligent ones.</li><li>Expected utility theory is a way of thinking about some part of the space which may or may not include future AI systems.</li><li>Historical analysis of trends in technological development is a way of thinking about whichever parts of the space of intelligent systems are governed by similar dynamics to those governing past technological developments.<br>&nbsp;</li></ul><p><strong>When we\u2019re reasoning about intelligent systems, we\u2019re using some part of the space of maps to think about some part of the space of intelligent systems:</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnfn4cssro5\"><sup><a href=\"#fnnfn4cssro5\">[3]</a></sup></span></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/d4W4inHhts5Y2szBf/rmb8lfz5ruwlskvtiagz\"></p><p><i>Different maps correspond to different regions of the space of intelligent systems.</i></p><p><br>&nbsp;Of course, thinking in terms of the space of systems and the space of maps is a simplification. Some of the ways that reality is more complicated:</p><ul><li>The space of systems looks different on different maps.</li><li>Maps can affect which parts of the space of systems actually get developed.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpbg1xg5phta\"><sup><a href=\"#fnpbg1xg5phta\">[4]</a></sup></span></li><li>Maps are themselves embedded in the space of systems.</li><li>Which maps and systems actually exist at a given time is evolving and dynamic.</li><li>AI will play a big role in both the space of maps and the space of systems.</li></ul><p><br>&nbsp;We think that the space of systems and the space of maps is a useful simplification which helps us to think more clearly about future AI systems. Some salient examples of how this simplification can help us think about future AI systems:</p><ul><li>Disagreements are often driven by using different maps, or talking about different parts of the space of systems.</li><li>Thinking about the distinction and the interplay between the space of maps and the space of systems makes it more obvious that our actions and research directions influence which systems end up getting built, which seems like an important strategic consideration.</li></ul><h3>What sorts of maps do we need for AI alignment?</h3><p>When it comes to AI alignment, we need accurate maps which hold for systems which don\u2019t exist yet, and which are good enough to help us build these systems in ways that are safe.</p><p>There are few different properties it would be good for these maps to have:</p><ul><li>Generality/robustness: maps which cover large parts of the space of systems.</li><li>Precision: maps which are very detailed.</li><li>Accuracy: maps which actually correspond well to the parts of the space of systems which they are mapping.</li><li>Usefulness: maps which help us to chart paths toward states we want.</li><li>Probably other things too.</li></ul><p>And there are trade-offs here between the properties. For example:</p><ul><li>It would be great to have very precise maps of advanced AI systems in particular, but this seems hard to do robustly.</li><li>Some theories are very general and cover very large parts of the space of systems (e.g. information theory), but alone these theories don\u2019t tell us much about how to chart paths towards states we want.</li></ul><h3>Finding maps which are useful for AI alignment&nbsp;</h3><p>A lot of AI alignment work involves taking maps that have been developed for thinking about one part of the space of systems, and applying them to a part of the space of systems that we hope includes \u201cpotentially dangerous future AI systems\u201d. For example:</p><ul><li>Experimental work often involves developing research methods for looking at existing AI systems that will (hopefully) scale to future AI systems.&nbsp;</li><li>Decision theory is a region in the space of maps that was built to model a (heavily idealised) human decision maker. Many of its ideas have been applied to possible future AI systems.</li><li>\u201cConvergence\u201d comes from evolutionary biology - a set of maps which has been built to think about biological systems. In a future post, we\u2019ll try to apply these ideas to AI systems.&nbsp;</li></ul><p>Being aware of which maps you are using and their potential limitations for the systems you want to study seems super useful for doing good research.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffonjbu46nbk\"><sup><a href=\"#fnfonjbu46nbk\">[5]</a></sup></span></p><p>We don\u2019t know that much about where in the space of systems potentially dangerous AI will be. As a result, one good bet seems to be to try and find maps that are general enough to cover everywhere in the space of systems that future AI could be.&nbsp;</p><ul><li>One way of making general maps is trying to decontextualise / generalise existing maps, by unpicking which features are specific to (~contingent on) the map in question, and which could generalise beyond the context in which they were originally built.</li><li>Another is to start with maps that are already pretty general (whilst still being accurate, confirmed by experiment, and falsifiable). This is one of the reasons why we are excited about active inference.&nbsp;</li></ul><p>Given that we care about aligning AI to humans and human collectives, it also seems useful for maps to cover these areas of system-space as well (or more specifically, to cover relations between the human part of system space and the \u201cpossible future AI systems\u201d part of system space).&nbsp;</p><p>Finding general maps isn\u2019t the only promising approach here:</p><ul><li>Finding precise maps can also be a useful tactic in some contexts.<ul><li>As there\u2019s a tradeoff between generality and precision, it\u2019s important to try to identify what features general maps are likely to miss - and what work is needed to fill in these (contingent) features.</li></ul></li><li>Another strategy, which seems at the core of all existing sensible approaches to alignment, is to try to skilfully combine insights from multiple maps.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjtfijehweyh\"><sup><a href=\"#fnjtfijehweyh\">[6]</a></sup></span></li></ul><p><br><i>The ideas in this post come variously from Jan, Nora and Clem (some ideas come from one person; others were independently generated by multiple people) or from an older FHI project on AGI epistemics done by Jan with Chris van Merwijk and Ond\u0159ej Bajgar. Rose did most of the writing.</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmlx5ubehf4f\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmlx5ubehf4f\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;See also&nbsp;<a href=\"https://www.alignmentforum.org/posts/tnWRXkcDi5Tw9rzXw/the-design-space-of-minds-in-general\"><u>Design space of minds in general</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnp4uo1qhikpj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefp4uo1qhikpj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See&nbsp;<a href=\"https://www.alignmentforum.org/posts/FQqcejhNWGG8vHDch/on-solving-problems-before-they-appear-the-weird\"><u>this</u></a> post for another discussion of this sort of epistemic challenge.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnfn4cssro5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnfn4cssro5\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.lesswrong.com/posts/FuToH2KHxKmJLGk2B/ai-alignment-as-navigating-the-space-of-intelligent\"><u>This</u></a> post implicitly argues something similar. Visualising the space of AI systems&nbsp;<a href=\"https://www.lesswrong.com/posts/QskBy5uDd2oeEGkBB/risk-map-of-ai-systems#Visualizing_the_Space_of_AI_Systems\"><u>here</u></a> is also related.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpbg1xg5phta\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpbg1xg5phta\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Other ways of saying this: some maps are design paradigms/blueprints.&nbsp;</p><p><a href=\"https://www.alignmentforum.org/posts/zAwvyBJJNu4vHWvfk/maps-and-blueprint-the-two-sides-of-the-alignment-equation\"><u>This</u></a> post draws a distinction between maps (for understanding reality) and blueprints (for building new parts of reality). The way we\u2019re using \u2018maps\u2019 here is broader and contains both of those kinds of map.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfonjbu46nbk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffonjbu46nbk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>C.f. Adam Shimi on&nbsp;<a href=\"https://www.alignmentforum.org/posts/72scWeZRta2ApsKja/epistemological-vigilance-for-alignment\"><u>Epistemological Vigilance</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjtfijehweyh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjtfijehweyh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>C.f. Adam Shimi on&nbsp;<a href=\"https://www.alignmentforum.org/posts/wi3upQibefMcFs5to/levels-of-pluralism\"><u>pluralism</u></a> and \u201c<a href=\"https://www.alignmentforum.org/posts/du92yeHQn9iE5vorj/no-one-size-fit-all-epistemic-strategy\"><u>no one-size-fits-all epistemic strategy</u></a>\u201d.</p></div></li></ol>", "user": {"username": "Jan_Kulveit"}}, {"_id": "KZuyBT3Fi8umHc6zH", "title": "Highlights\u00a0from LPP\u2019s field-building efforts", "postedAt": "2023-03-23T08:18:41.937Z", "htmlBody": "<h1>Introduction</h1><p>The <a href=\"https://www.legalpriorities.org\">Legal Priorities Project</a>&nbsp;(LPP) is dedicated to building a global community&nbsp;of people passionate about using the law to protect future generations and mitigate existential risk. Through our flagship programs\u2014the <strong>\u200b\u200bLegal Priorities Summer Institute</strong>&nbsp;and the <strong>Summer Research Fellowship</strong>\u2014participants gain hands-on experience and develop the skills needed to make a meaningful impact in this field. In this overview, you will learn more about what it's like to participate in these programs, what to expect afterward, and what other initiatives we\u2019ve run. We are excited to share the work and accomplishments of our talented participants and look forward to hearing from you if you would like to get involved!</p><h1>Legal Priorities Summer Institute</h1><p>The Legal Priorities Summer Institute (LPSI) is an intensive, week-long program to introduce altruistically-minded law and policy students and early-career professionals to projects, theories, and tools relevant to tackling critical issues affecting the long-term future.</p><p>LPSI is aimed primarily at individuals who want to learn about issues affecting the long-term future. Through a series of presentations, discussions, debates, and workshops, led by an array of experts, including government officials, academics, legal practitioners, philanthropists, and members of the judiciary, participants gain a better understanding of the current legal landscape and learn about the latest developments, trends, and best practices related to existential risk and global challenges.</p><p>Despite the program being highly competitive, we strive to bring together individuals from various backgrounds, countries, cultures, disciplines, and professional experiences. We aim to create an environment that&nbsp;promotes&nbsp;open-mindedness and encourages participants to consider alternative perspectives.</p><h2>2022</h2><p><a href=\"https://www.legalpriorities.org/institute22\"><u>LPSI 2022</u></a>&nbsp;attracted 473 applicants from across the globe (227 undergrads, 131 master\u2019s, 29 JDs, 65 PhDs/JSDs, and 21 others), with a significant number coming from top-ranked institutions\u2014200 (42%) from the world\u2019s <a href=\"https://www.topuniversities.com/university-rankings/university-subject-rankings/2022/law-legal-studies\"><u>top 20 law schools</u></a>&nbsp;and 113 (24%) from the top 5 law schools. 402 (85%) applicants and 14 (40%) participants had very little or no previous exposure to longtermism.</p><p>Thirty-five talented individuals were selected to participate in the program, representing eighteen countries and five continents, making the cohort extraordinarily diverse. You can meet our 2022 participants <a href=\"https://docs.google.com/presentation/d/11fST-wopfapv_a8D6XFXi7t5VaPCYdY46OPBCxHHfEo/edit?usp=sharing\"><u>here</u></a>.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KZuyBT3Fi8umHc6zH/hnhzebc98a1tchaiorvf\" alt=\"\"></p><h3>Program highlights</h3><ul><li>A talk on \u201cReflections on Longtermist AI Governance Research from a Global South Perspective\u201d by <a href=\"https://www.legalpriorities.org/team/cecil-abungu.html\"><u>Cecil Abungu</u></a>&nbsp;(<a href=\"https://www.cser.ac.uk/\"><u>Centre for the Study of Existential Risk</u></a>, Legal Priorities Project).</li><li>A discussion panel on AI governance with researchers from the Centre for the Study of Existential Risk.</li><li>A talk on \u201cCatastrophic Climate Change\u201d by <a href=\"https://www.philosophy.ox.ac.uk/people/goodwin-gibbins\"><u>Goodwin Gibbins</u></a>&nbsp;(<a href=\"https://www.fhi.ox.ac.uk/\"><u>Future of Humanity Institute</u></a>).</li><li>A career planning workshop with an advisor from <a href=\"https://80000hours.org/\"><u>80,000 Hours</u></a>.</li><li>A talk on \u201cDeveloping an Impact Litigation Strategy to Limit Catastrophic Biorisk\u201d by <a href=\"https://www.legalpriorities.org/team/laurens-prins.html\"><u>Laurens Prins</u></a>&nbsp;(Legal Priorities Project).</li></ul><h3>Feedback from participants</h3><p><i>All feedback and testimonials were submitted anonymously right after the event.</i></p><p>&nbsp;</p><p><i>From 1 to 10, how likely is it that you would recommend the Institute to a colleague with similar interests to your own?</i></p><ul><li><i><strong>9.1 / 10</strong></i></li></ul><p>&nbsp;</p><p><i>What was the most valuable experience from LPSI for you?</i></p><ul><li><i>LPSI gave me an opportunity to meet an amazing group of people. I met a group of people from the Global South, which has motivated all of us to bring forth Global South perspectives and collaborate on ways to bring these perspectives to the global avenue. Getting feedback and giving feedback to people was also a very valuable experience. It is impressive how much clarity you can get on ideas when you share them with people. I also formed a network of people who are now my friends\u2014we keep in touch and give each other feedback and support. I am grateful for this.</i></li><li><i>The network, being able to speak with experts, and gaining different perspectives on various topics.</i></li><li><i>Learning&nbsp;from people later in their careers what paths to my goals in affecting long-term change can look like.</i></li><li><i>The sense of community and the introductions to key individuals working on biosecurity.</i></li></ul><p>&nbsp;</p><p>Other testimonials:</p><ul><li><i>I have taken many actions already as a result of LPSI. These include a research collaboration with 5 colleagues and career planning. I started to draft job possibilities and the pros and cons of which of them. I have also noticed that I had many limiting thoughts that were making me less confident in my capabilities. I was able to reflect on those with colleagues during the summer institute, which helped me greatly.</i></li><li><i>The event has given me the confidence and awareness I needed to shift from the career path I was on of training at a corporate law firm to pursuing jobs in policy research and advocacy.</i></li><li><i>Thanks for all the hard work you all put into this. I had a great time \u2014 having five days set aside just to think about these issues and connect with people without worrying about anything else was invaluable. To have it all so well organized and thought through, especially with very generous, responsive, and flexible organizers, was fantastic.</i></li><li><i>I expect to shift my career over the next few months, and attending the conference helped to catalyze thoughts I'd been having about it and to give me more structure in deciding what to do and how to do it. Meeting new people with similar interests has also given me new connections and opportunities for collaboration.</i></li><li><i>I'm taking some actionable steps to answer research questions with new friends and colleagues from LPSI.</i></li><li><i>The event unlocked a network of individuals that are like-minded, which I didn't have access to prior. I intend to collaborate with LPSI alumni for future research on democratic and constitutional reform.</i></li><li><i>I have a much clearer career path now, which helped a lot research-wise. I finally decided on what programme to pursue and discarded others.</i></li><li><i>I just wanted to thank you for the efforts put into organizing and coordinating LPSI. Personally, I immensely appreciate the opportunity and the overall management of the event. It was extremely helpful to meet smart people and some of the amazing folks behind LPP!</i></li><li><i>LPSI was a highlight of my year! It really did help me rethink my career strategy, and I\u2019ve decided to go by field and cast a broader net for roles. So I\u2019m reaching out to folks in AI safety companies to get a sense of what might match / what I could grow into / what shortcomings I might need to address.</i></li></ul><h3>After LPSI</h3><p>Four months after the program, we asked participants to share what positive outcomes they could trace back to the event. These were some of their answers.</p><ul><li><i>I started a working group on law and AI as a way to start exploring AI use and risks of using LLMs in the law \u2014 while not directly AI safety, it\u2019s been a step to even start introducing many lawyers to it.</i></li><li><i>I started a fellowship at LPP, joined initiatives shared in the Slack channel, and connected with other members of the community.</i></li><li><i>I got looped into a very exciting project right after LPSI related to bio policy.</i></li><li><i>LPSI assisted me in getting a research assistant position with a barrister and professor; I readjusted my career path and goals to pursuing postgrad research in law and tech before going into practice/politics; and I made contacts that I\u2019ve reached out to for advice in career planning.</i></li><li><i>I participated in Mexico EA Fellowship and worked on diversity issues; I continued working on algorithmic discrimination research; and I made meaningful connections with others from LPSI.</i></li><li><i>I declined a job offer from a corporate law firm and am currently seeking policy-oriented work instead; I chose to write my masters dissertation on a topic which I hope has the potential to be impactful, relating to decision-making in collective action problems.</i></li><li><i>I met a handful of people who I may try to collaborate with on projects in the future, and I was introduced to some work which I had not previously known about.</i></li></ul><h1>Summer&nbsp;Research Fellowship</h1><p>Our Summer Research Fellowship (SRF) brings together outstanding law students, PhD candidates, and postdocs who carry out longtermist legal research for 8\u201310 weeks, supervised by a more senior researcher. Given the strong focus on research, the SRF is targeted primarily at graduate students and postdocs working in law, though students approaching the final year of a 5-year undergraduate law degree are also welcome to apply.</p><p>In 2020 and 2021, applicants were encouraged to suggest a research topic during the application process, and most participants worked on that same project during the SRF. However, in future editions, participants will select a research topic from a list curated by LPP and partner organizations, in order&nbsp;to increase the chances that relevant decision-makers will use the research.</p><h2>2021</h2><p>The <a href=\"https://www.legalpriorities.org/fellowship21\"><u>SRF 2021</u></a>&nbsp;attracted 148 applicants from all over the globe, with a significant number coming from top-ranked institutions\u201424% from the world\u2019s top 20 law schools and 13% from the top 5 law schools.</p><p>Fifteen researchers were selected to participate in the program, representing ten countries and four continents. You can meet our 2021 participants and learn more about their projects <a href=\"https://docs.google.com/presentation/d/1KWGUTeRvJu9DnuOJXDcWsgtEgFYtOsXxY4ntLSfTr7w/edit?usp=sharing\"><u>here</u></a>.</p><figure class=\"image image_resized\" style=\"width:75.41%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KZuyBT3Fi8umHc6zH/hraesxactlkfm2gx5oos\" alt=\"\"></figure><h3>Selected research projects</h3><ul><li>Jos\u00e9 Villalobos worked on a report exploring the potential for impact litigation to mitigate existential risk. This later informed an LPP project exploring concrete litigation strategies to reduce biorisks.</li><li>Marta Kartawik tackled questions related to the economic regulation of artificial intelligence, such as the role of competition agencies or the importance of developing a supranational theory of regulation.</li><li>Daniel Bertram studied legal frameworks to tackle extreme climate change.</li></ul><h3>Program highlights</h3><ul><li>Fellows organized weekly discussion groups on different topics, including artificial intelligence, biorisk, meta-research, institutional design, and space governance.</li><li>Teammates and fellows hosted various sessions to discuss research best practices, methodologies, and technology tools for research productivity.</li><li>An advisor from <a href=\"https://80000hours.org/\"><u>80,000 Hours</u></a>&nbsp;hosted a workshop on career planning.</li><li>Several Q&amp;A sessions with senior researchers allowed fellows to dig deeper into topics related to longtermism and legal prioritization.</li></ul><h3>Feedback from participants</h3><p><i>All feedback and testimonials were submitted anonymously right after the fellowship.</i></p><p>&nbsp;</p><p><i>From 1\u20135, are you glad you participated in the fellowship?</i></p><ul><li><i><strong>4.5 / 5</strong></i></li></ul><p>&nbsp;</p><p><i>What were the most valuable elements of the program for you? (2: very valuable; -1: harmful)</i></p><ul><li><i>The session on LPP\u2019s theory of change (1.67)</i></li><li><i>Talks at the </i><a href=\"https://legalpriorities.eventbrite.com/\"><i><u>Legal Priorities Lab </u></i></a>(1.67)</li><li><i>1-1 calls with LPP researchers (1.63)</i></li><li><i>The closing event (1.60)</i></li><li><i>1-1 calls&nbsp;with other fellows (1.55)</i></li></ul><p>&nbsp;</p><p><i>What surprised you the most about LPP or the fellowship?</i></p><ul><li><i>The openness and politeness of &nbsp;LPP staff\u2014I was surprised to see how comfortable folks make you feel and how helpful the organization was along the way. I felt very much supported and that I could direct any query without worries. Often I thought that you would be wonderful colleagues.</i></li><li><i>How much freedom we had to pursue our research; how accessible, friendly, and humble everyone at LPP is.</i></li><li><i>I found it surprising that fellows came to the programme with rather diverse backgrounds and projects. That was nice.</i></li><li><i>That LPP supports its fellows so generously with the stipend. I think the association with LPP carries a lot of weight in and of itself, so to receive such a generous amount of money was really wonderful.</i></li><li><i>The flat hierarchies.</i></li></ul><p>&nbsp;</p><p>Other testimonials:</p><ul><li><i>This was one of the most fruitful periods of my academic career in terms of new ideas generated. Also, the various research tools shared by others had a remarkable impact on my time management and organization.</i></li><li><i>I very much liked meeting passionate and positive-vibes people who were polite and friendly\u2014the fellowship teammates made me feel comfortable asking for advice or discussing with them.</i></li><li><i>The SRF gave me the opportunity, time, and space to look more closely at an approach to research that I think will now come to inform the perspective I take on a range of important issues. I love that LPP is taking a 'legal' perceptive to these global issues, many of existential concern to humanity. I hope I can stay formally involved with LPP.</i></li><li><i>The SRF exposed me to a different way of thinking about legal research and to a variety of projects and ideas circling within that paradigm. Perhaps more importantly, I am now more aware of the importance of legal and global priorities for my PhD. I feel comfortable reaching out to the larger existential risk/longtermist community for ideas, support, and collaborations.</i></li><li><i>The fellowship was a great opportunity to get familiar with the legal priorities scholarship and the broader longtermist research context - it was a very valuable experience for me. During the fellowship, I was able to 'pause' everything else and just take the time to calmly 'read to learn' again rather than read while feeling pressured to 'deliver'. Regarding the substance of the agenda, it made me rethink certain aspects of my career path and consider choices that I would not think of before the fellowship, e.g., I could design a legal priorities module in the university if given the opportunity in the future.</i></li><li><i>I used to feel bound to the field where I had done my PhD and now feel like I have other exciting career paths. I'm also grateful for the time to work on a paper I had been wanting to write (and hopefully publish) for a long time. One of my key takeaways from the fellowship was meeting the other fellows\u2014all brilliant individuals, both professionally and personally. I hope to continue developing those relationships in the future.</i></li><li><i>LPP staff are incredibly kind and helpful! I would've loved to see more community building amongst the fellows themselves.</i></li><li><i>I loved the culture of the SRF. I am someone who works best in environments that strike a fine balance between serious and casual. For me, the fellowship fell in that precise sweet spot.</i></li><li><i>I really liked how ready other fellows and LPP staff were to help and how interested everyone was in other people's projects and ready to provide any kind of support.</i></li></ul><h3>After the SRF</h3><p>The SRF 2021 opened up new opportunities for the participants, including, among others:</p><ul><li><a href=\"https://www.legalpriorities.org/team/matthijs-maas.html\"><u>Matthijs Maas</u></a>&nbsp;and <a href=\"https://www.legalpriorities.org/team/jose-villalobos.html\"><u>Jos\u00e9 Villalobos</u></a>&nbsp;joined LPP as full-time researchers.</li><li>Matthijs Maas published a sequence on <a href=\"https://forum.effectivealtruism.org/posts/isTXkKprgHh5j8WQr/strategic-perspectives-on-long-term-ai-governance\"><u>Strategic Perspectives on Transformative AI Governance</u></a>, which he worked on during the SRF.</li><li>Amal Sethi co-organized the <a href=\"https://www.longtermismandthelaw.com/\"><u>Multidisciplinary Forum on Longtermism &amp; the Law</u></a>.</li><li>Piotr Bystranowski continued to collaborate with LPP researchers, with whom he plans to publish a paper on \u201cExperimental studies on the effectiveness of legal norms to reduce catastrophic risk.\u201d</li><li>Daniel Bertram\u2019s work on <a href=\"https://www.legalpriorities.org/research/extreme-climate-change.html\"><u>extreme climate change</u></a>&nbsp;will be featured as a new chapter in <a href=\"https://www.legalpriorities.org/research/research-agenda.html\"><u>LPP\u2019s research agenda</u></a>.</li><li>Two of Colin Bradley\u2019s fellowship projects were accepted for publication\u2014\u201c<a href=\"https://www.yalelawjournal.org/forum/solidarity-legitimacy-and-the-janus-double-bind\"><u>Solidarity, Legitimacy, and the Janus Double Bind</u></a>\u201d (Yale Law Journal, 2022) and \u201c<a href=\"https://www.stanfordlawreview.org/print/article/the-petition-clause-and-the-constitutional-mandate-of-total-population-apportionment/\"><u>The Petition Clause and the Constitutional Mandate of Total-Population Apportionment</u></a>\u201d (Stanford Law Review, 2023).</li></ul><h2>2020</h2><p>Before LPP\u2019s official launch in late 2020, we organized the&nbsp;<a href=\"https://www.legalpriorities.org/fellowship20\"><u>first edition of the SRF</u></a>, which attracted 72 applicants from all over the globe, with a significant number coming from top-ranked institutions\u201463% from the world\u2019s top 20 law schools and 39% from the top 5 law schools.</p><p>Six researchers were selected to participate in the program. You can meet our 2020 participants and learn more about their projects <a href=\"https://docs.google.com/presentation/d/1R7Eh6jrWFw-YIfx10u9A0lVMF94vWT4AicmRzY2Pgvw/edit?usp=sharing\"><u>here</u></a>.</p><figure class=\"image image_resized\" style=\"width:75.25%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KZuyBT3Fi8umHc6zH/ysvfw5ytpqwifyh5xfwt\" alt=\"\"></figure><h3>Feedback from participants</h3><p><i>All feedback and testimonials were submitted anonymously right after the fellowship.</i></p><p>&nbsp;</p><p><i>From 1\u20137, how much did you enjoy the SRF?</i></p><ul><li><i><strong>6.8 / 7</strong></i></li></ul><p>&nbsp;</p><p><i>From 1\u20137, would you recommend an interested peer participate in the SRF?</i></p><ul><li><i><strong>7 / 7</strong></i></li></ul><p>&nbsp;</p><p>Other testimonials:</p><ul><li><i>The organizers did a terrific job\u2014the SRF and events were very well organized, and there was a great support structure in place with everything from RAs to feedback on work to individualized support when needed, regular meetings, follow-ups, etc. I'm extremely impressed with the organization and everything around it. I was very fortunate to be part of a fantastic group of SRFs\u2014everyone's research was so interesting. Projects were so different, yet there were plenty of opportunities for productive overlap, etc. SRFs' research really showcased the breadth of legal priorities research; there was a greater range of topics and methodologies than I have come across at previous events I've attended. Participants (including organizers) were extremely collegial and constructive (super helpful feedback, great questions, and so on). The organizers also created a very supportive, friendly, open-minded, and welcoming environment for sharing ideas, which I was very impressed with. The SRF was a great experience\u2014thank you!</i></li><li><i>The guidance, help, and collaboration were wonderful.</i></li><li><i>Everyone was friendly and good to work with.</i></li></ul><h3>After the SRF</h3><p>The SRF 2020 opened up new opportunities for the participants, including, among others:</p><ul><li><a href=\"https://www.legalpriorities.org/team/cecil-abungu.html\">Cecil Abungu</a> joined LPP as a Research Affiliate and went on to receive grants to continue his work on longtermism, including organizing a <a href=\"https://ilinaf.org/\"><u>fellowship</u></a>&nbsp;for exceptional students in Africa.</li><li><a href=\"https://www.legalpriorities.org/team/lisa-forsberg.html\">Lisa Forsberg</a> joined LPP as a Research Affiliate.</li><li><a href=\"https://www.legalpriorities.org/team/alasdair-phillips-robins.html\">Alasdair Phillips-Robins</a> continued to think about issues related to the role of the US government in reducing catastrophic risks and went on to win the first prize in the <a href=\"https://www.legalpriorities.org/competition.html\"><u>2022 LPP Writing Competition</u></a>&nbsp;(submissions were anonymized, and LPP staff did not judge entries).</li></ul><h1>Other initiatives</h1><h2>Multidisciplinary Forum on Longtermism and the Law 2022</h2><p>In June 2022, we organized the first-ever <a href=\"https://www.longtermismandthelaw.com/\"><u>conference on Longtermism and the Law</u></a>, co-hosted with Amal Sethi (University of Hamburg), who was inspired to run the event after engaging with longtermism during our 2021 Summer Research Fellowship. Thirty participants from around the world discussed legal strategies for tackling issues relevant to the long-term future, including pandemics and artificial intelligence. Selected submissions were published as a <a href=\"https://verfassungsblog.de/category/debates/longtermism-and-the-law-debates/\"><u>blog symposium</u></a>&nbsp;on Verfassungsblog, an influential peer-reviewed, academic forum on constitutional law and policy.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KZuyBT3Fi8umHc6zH/pghn5jv9d6chgvs2lcxk\" alt=\"\"></p><p><i>From 1 to 10, how likely is it that you would recommend the forum to a colleague with similar interests to your own?</i></p><ul><li><strong>8.9 / 10</strong></li></ul><p>&nbsp;</p><p>Other testimonials:</p><ul><li><i>The event was really great; I enjoyed it so much! Lots of brilliant people and plenty of time to connect and discuss. I have no complaints, only praise.</i></li><li><i>I received many good ideas and criticism; food for thought for further research and helpful changes and clarifications that I could include in my research.</i></li><li><i>I think everything was excellent. I especially appreciated having a lot of time for discussion and socializing.</i></li><li><i>The event was very useful for figuring out which people might be interesting partners for collaboration and whose work I'd like to know more about.</i></li><li><i>Overall, I was very impressed with the organization. Everyone was easy to talk to, and it felt like I had an opportunity to speak to everyone without it being too small. Very excellent, in my view.</i></li></ul><p>&nbsp;</p><p>Follow-up:<i> Eight months after the Forum, what positive outcomes can you trace back to the event?</i></p><ul><li><i>I met several prominent people in the law and longtermist space that I had never met before. The conversations I had with them made me think more deeply about how best to positively impact the long-term future, and I have stayed connected with some of them after / as a direct consequence of the event. I also published a piece that directly grew out of the blog post and presentation for the event. Presenting and getting feedback on my post helped me think better about how best to frame longtermist ideas to a general audience.</i></li><li><i>We have received valuable feedback on our work on \"Negative Human Rights as a Basis for Long-term AI Safety and Regulation\" and incorporated it into the resulting paper, which was now accepted for publication in the Journal of Artificial Intelligence Research.</i></li><li><i>The two pieces I published in Verfassungsblog became full papers, which are now submitted.</i></li><li><i>Good impact\u2014I submitted a grant and published a paper (and more in the pipeline).</i></li><li><i>While finishing my PhD project in 2022, I have been thinking a lot about the concepts of longtermism and legal longtermism. Although I did not shift my research fundamentally (as I had already almost finished it at the time of the Forum), I included some interesting and focused ideas I got during the Forum into my introduction and some of my chapters and footnotes.</i></li><li><i>This event helped connect me to some AI governance researchers, which has been helpful.</i></li></ul><h2>Global Priorities Research Across the Disciplines 2022</h2><p>In 2022, we co-organized a workshop at the <a href=\"https://globalprioritiesinstitute.org/\"><u>Global Priorities Institute</u></a>&nbsp;on global priorities research in law as part of a larger workshop on \u201cGlobal Priorities Research (GPR) Across the Disciplines\u201d that included psychology, history, and law. We benefited greatly from discussions with GPR researchers in other fields, which represented the kind of dialogue we hope to preserve as the field grows.</p><h2>University reading groups</h2><p>In late 2021, we started offering&nbsp;~US$1,500 stipends&nbsp;for students at <a href=\"https://www.itam.mx/\"><u>ITAM</u></a>&nbsp;to organize one-semester-long <a href=\"https://docs.google.com/presentation/d/1MAmfxpEnCipmfasohvNq5G14nv0Xy2EJZZINJSLRp4g/edit?usp=sharing\"><u>reading groups</u></a>&nbsp;on longtermism and effective altruism. Some previous group organizers and participants went on to receive additional external funding to support their work from FTX and the Effective Altruism Infrastructure Fund, including:</p><ul><li>Field-building work in Latin America (and Mexico in particular), including <a href=\"https://www.effectivealtruism.org/ea-global/events/eagx-latam\"><u>EAGxLatinAmerica</u></a>.</li><li>Becoming a Next Generation Fellow on Future Generations at the United Nations Foundation and a \u201cFuture Generations Global Ambassador\u201d at the Office of the Future Generations Commissioner for Wales.</li></ul><p>We believe this is a cost-effective method of opening doors to talented students worldwide who want to use their careers to tackle some of the world\u2019s most pressing problems. Our close ties to ITAM have made it easy to run these pilot groups, but we would be excited to run similar programs in other countries if operational capacity allows.</p><h2>Law &amp; Longtermism Dinners</h2><p>We have organized several informal dinners during the <a href=\"https://www.eaglobal.org/events/\"><u>EA Global</u></a>&nbsp;conferences we have attended. Anyone interested in law and longtermism is welcome to join and meet LPP teammates and other like-minded individuals in a relaxed atmosphere. Turnout has ranged from 15\u201340 people. Attendees are typically other EA Global participants with a background in law and policy.</p><figure class=\"image image_resized\" style=\"width:75.26%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KZuyBT3Fi8umHc6zH/wvwiwre5xpxtkro56nor\" alt=\"\"><figcaption>Dinner with attendees of EA Global Bay Area 2023</figcaption></figure><figure class=\"image image_resized\" style=\"width:75.25%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/KZuyBT3Fi8umHc6zH/idu4eshpsjh6nvshdvky\" alt=\"\"><figcaption>Dinner with attendees of EA Global X Boston 2022</figcaption></figure><h2>Law &amp; Longtermism Network</h2><p>In 2021, we launched the <a href=\"https://www.legalpriorities.org/documents/Law%20&amp;%20Longtermism%20Network.pdf\"><u>Law &amp; Longtermism Network</u></a>&nbsp;on Slack,&nbsp;open to anyone interested in engaging more closely with the field of legal longtermism. Researchers, students, policy-makers, and legal practitioners of all backgrounds are welcome to join.&nbsp;The network has two main goals:</p><ol><li><strong>Foster collaboration among its members</strong>: Members can meet and get in touch with other members very easily and use the platform to collaborate on projects or discuss specific subtopics.</li><li><strong>Facilitate the exchange of information</strong>: Members will learn about new exciting research, events, and job opportunities related to legal longtermism.</li></ol><hr><p>Thank you to everyone who has gotten involved in one way or another. We are excited to see how the field of legal longtermism continues to grow!</p>", "user": {"username": "Legal Priorities Project"}}, {"_id": "xSHWmarG4AbxKmCrF", "title": "Is Bill Gates overly optomistic about AI?", "postedAt": "2023-03-22T12:29:58.671Z", "htmlBody": "<p><a href=\"https://www.gatesnotes.com/The-Age-of-AI-Has-Begun\">Bill Gates's blog </a>recently released an article that framed AI advancements in quite a positive light.&nbsp;</p><p>For example he touted many altruistic applications of AI coming in the near future and claimed that \"none of the breakthroughs of the past few months have moved us substantially closer to [dangerously] strong AI.\"</p><p>I'm not knowledgable enough to evalaute his claims, and tbh I trust this community's opinion a lot more than Microsoft's, so I wondering if y'all could share your thoughts on this article (it's a 14 min read).&nbsp;</p><p>The link is above and here: <a href=\"https://www.gatesnotes.com/The-Age-of-AI-Has-Begun\"><u>https://www.gatesnotes.com/The-Age-of-AI-Has-Begun</u></a></p>", "user": {"username": "dov"}}, {"_id": "RLQ37cXznqrhthJug", "title": "Agnes Callard on our future, the human quest, and finding purpose", "postedAt": "2023-03-22T12:29:51.708Z", "htmlBody": "<p><i>This is a transcript of the speech philosopher&nbsp;</i><a href=\"https://news.uchicago.edu/story/agnes-callard-encourages-uchicago-students-reflect-humanitys-distant-future\"><i><u>Agnes Callard gave at the Aims of Education address</u></i></a><i> at the University of Chicago. A central theme of the address is to think about one\u2019s future as going beyond our own lifespan, and beyond the lifespan of everyone we know. She gives her own views on why we care about the future. Even though I don\u2019t agree with everything she said, the speech takes an interesting perspective on the long-run future and I found parts pretty inspiring. (It's long, so I added a lot of highlights that are hopefully useful for skimming.)</i></p><p>&nbsp;</p><p><strong>I want to talk to you about your future, but I'm going to use that word future in a different way than people usually do when they stand where I am, up on a stage in front of a microphone, addressing people like you who are on the threshold of a big life transition. The future I'm referring to starts about 180 years from now, and it runs for a few thousand years after that.</strong> A lot of the time when older people address younger ones, we're moved to speak of the future that you will live to see and we won't. We adopt the guise of Moses having been divinely excluded from the promised land, addressing a crowd who will be permitted to enter. I don't want to talk to you about the land you're about to enter. I want to talk to you about the one you won't be able to enter. I want us all to play Moses, peering into the future none of us will live to see, the future even your grandchildren won't live to see.&nbsp;</p><p>That's how I got the 180 number. In 180 years, your last grandchild will probably be dead. That's assuming people continue to have their last kids no later than their early 40s and that life extension technology doesn't add too many years to a person's life. Those seem like reasonable assumptions to me since medical advances in delaying childbearing or extending lifespan seem to have stalled over the past few decades. But if you're more optimistic than I am on those fronts, add the relevant number of years to the 180 starting point. I want you to be imagining a time period in which everyone you knew well over the course of your life is dead. As for the other end point of a few thousand years, I chose it because that's as far ahead as I'm comfortable imagining, which is probably a function of the fact that my own research focuses on a world, ancient Athens, that existed a few thousand years ago. If I say to myself, imagine what the world will be like 10,000 or 100,000 years from now, I can say the number 10,000 years, but that's not really doing any work in structuring what I imagine. I just don't have any kind of intuitive feel for what 10,000 years of distance in time is like. I could look at a field of 10,000 flowers, but I wouldn't be able to translate that into years. So I'm stuck limiting myself to thinking about the humans who are at most as far ahead of me in the future as Socrates and Plato are behind me in the past. And again, if you're more imaginative or have studied even older cultures, feel free to add on some years at the tail end. Okay.<strong> So we're looking at an era that starts around the year 2200 and ends by about the year 5000</strong>.</p><p><strong>That's the framework we're working with. That's the period of history, future history, that I want to talk to you about. It's a time none of us will live to see and no one we know will live to see it, but I called it your future. And I do see it that way as your future and also mine, our future. What makes it ours?</strong> One suggestion might be biology. Even if our grandchildren won't be around anymore, some of them will have children. Some of those children will eventually have children and so on. So the claim is we're invested in this future, in our future, because we have biological ties to it. That answer is unsatisfying to me. It doesn't seem right. I'd feel invested in that future even if I lacked a personal biological stake in it. Some of you may be unsure whether you'll have kids or may have decided you won't have them. That ship has sailed for me. Some of my kids are here at this lecture. But my oldest is 18 like you. I don't yet know whether I'll have grandkids. So none of us knows whether we'll have an individual biological stake in that world. And yet I claim that we do now already know that we have a stake in it, that it matters to us, that it is our future. So recently&nbsp;<strong>I read a book called What We Owe the Future, which tries to argue the reader into \u201clongtermism\u201d, which is the view that we ought to care about the future. I was surprised that the author, William MacAskill, who is a philosopher, at no point in the book whipped out the philosophy thought experiment designed to show that we already do. Why go to all the trouble trying to browbeat someone into caring about something when instead you can show them they already do care about it?</strong></p><p>Myself, I like to take the easy path, so I'm going to tell you about that thought experiment.&nbsp;<strong>Suppose we find out tomorrow that over the past few months another virus alongside COVID has been creeping silently around the globe. The disease caused by this highly infectious virus is largely asymptomatic</strong>, which is why it took us a few months to notice that just about everyone has been infected by it. In fact, assume that by the time we figure out exactly what the virus does, everyone on the planet has been infected. I'll admit, it's a little hard to imagine exactly how the virus is supposed to have found literally every last person from a baby born in the Falkland Islands off the coast of Patagonia in Argentina to a grandma living in Yakutsk in eastern Siberia, but one of the perks of being in the thought experiments business is that you get just to posit stuff. If you think poetic license is good, you should try philosopher's license. So&nbsp;<strong>I am positing that everyone has been infected by this virus and that we know this, and I'm also going to posit what the virus does. It makes you infertile. The virus gets called Sterilovirus because it's only medical effect on those who may infect whether they're male or female is sterility, the inability to have children.</strong>&nbsp;</p><p>Okay, so what&nbsp;<strong>I want you to think about is what would be your reaction to learning that an epidemic of Sterilovirus has swept the globe</strong>? While you're thinking about that, I'll tell you about my reaction. When I really start to vividly imagine us being the last humans, the last generation, when I let myself take seriously the thought that the youngest people alive today would be the last people on earth, that after they die, our cities will decay and no one again will read our literature or look at our art or learn our languages or engage with our theories and arguments, when I envision the vast silence blanketing our once chattering globe because the human story has come to an end \u2013 and let me tell you,&nbsp;<strong>it is not easy to force myself to really enter the world of this thought experiment because you have to do more than just say the words to yourself. You have to actually form the mental images and make yourself into a spectator of this barren earth. But when I do manage to work myself into it, my reaction is that I feel sick.</strong> I get this sensation in the pit of my stomach that I sometimes also get when subjected to certain physical forces. So a month ago, I was on a boat on very choppy waters between the North and South Island in New Zealand, and the boat would rise up high on these waves, and then as it fell, I would feel my stomach falling. It didn't feel as if I was falling. It felt as if my stomach itself were falling freely on its own within the space of my own body, lower and lower, running the risk of dropping out of me altogether. That is what it feels like when I think about the infertility scenario.&nbsp;</p><p>Okay, I'm borrowing the outlines of this thought experiment, including the label, The Infertility Scenario, from philosopher Samuel Scheffler's book, Death and the Afterlife, though I've modified it a little, and Scheffler is himself drawing on the P.D. James novel, Children of Men, which Alfonso Cuaron made into a movie with Clive Owen in 2006. The movie differs from the novel in a lot of details, both are good, but something they share is a focus on just how dystopian our world would get in the decades before our time ran out. In the movie, governments collapse and the few that don't turn into police states. In the book, there's a civil war, and both the book and the movie depict humanity in a state of widespread lawlessness and disillusionment. No one seems to really care about anything, everyone, but especially the last people to be born, who are called omegas in the book, seems to have lost the ability to care. Scheffler points out, this is surprising.<strong> Each of us knows we're going to die, yet we take this in stride and live productive lives. Somehow it's when we're confronted, not even with the deaths, but just the non-births of future people, which is to say people who could have existed but didn't, it's in the face of this weird metaphysical lacuna that our ability to cope somehow fails us.&nbsp;</strong>Again, it wouldn't be surprising if we were upset by the prospect of a meteor coming and killing all of us, because that would cut our lives short, and some of us would die in great suffering. In the infertility scenario, no one you know or love is dying prematurely. And yet, P.D. James and Alfonso Cuaron seem to think that in the period after humanity learns that they're in the infertility scenario, but before they actually go extinct, human life on earth would become a living hell. Scheffler conjectures that such a world would feature, \u201cwidespread apathy, enemy and despair, the erosion of social institutions and social solidarity, the deterioration of the physical environment, a pervasive loss of conviction about the value or point of many activities\u201d.&nbsp;</p><p>My gut tells me he's right. But why? Why do future generations matter so much? Scheffler's explanation, which I find plausible, is that absent the prospect of future generations, human life seems to lose its meaning.&nbsp;<strong>That is, the meaning of our lives now relies, in ways we don't always notice or take into account, on the existence of future lives. Scheffler says, \u201cthe coming into existence of people we do not know and love matters more to us than our own survival and the survival of the people we do know and love\u201d. He thinks in the infertility scenario, the time after death becomes, quote, a blank eternity of nonexistence.</strong> But what is it now? Well, he compares it to a party we have to leave early. His thought is that a lot of the most meaningful activities that we engage in are parts of ongoing traditions. It matters to us that the party, be it about scientific achievement, political struggles, religious observance, literary appreciation, not come to an end without our contribution to it. Here's another quote from Scheffler. \u201cOur conception of a human life as a whole relies on an implicit understanding of such a life as itself occupying a place in an ongoing history, in a temporally extended chain of lives and generations. If this is so, then perhaps we cannot simply take it for granted that the activity of, say, reading The Catcher in the Rye or trying to understand quantum mechanics or even eating an excellent meal would have the same significance for people or offer them the same rewards in a world that was known to be deprived of a human future.\u201d&nbsp;<strong>So what I notice is that my response to the infertility scenario is very different from one in which, from a scenario in which I simply don't have biological descendants. If I were to learn that none of my children were going to have children, I might be a bit saddened.&nbsp;</strong>Please have kids, guys.<strong> But I don't feel that vertiginous loss of meaning. I wouldn't even feel it if I learned that no one I currently knew would have any descendants alive in a hundred years, as long as other humans did have descendants.</strong>&nbsp;</p><p>So it looks like I don't especially care that I survive or that I or my associates leave a chain of descendants behind us.&nbsp;<strong>What I seem to care about is a set of people who haven't been born yet, who I have no personal connection to, the humans of 2200 to 5000. And the question I want to ask is, what does it mean to care about them? One obvious answer is caring that they come to exist, right?</strong> So we care that human existence not be soon snuffed out by environmental catastrophe or world wars or stray meteors or pandemics.<strong> Another answer is that we care how they live.&nbsp;</strong>We want them to have a good quality of life. We don't want life expectancy or literacy or other signs of well-being to plummet. We might have moral ideals, perhaps egalitarian ideals about wealth distribution or perhaps ideals of tolerance for a variety of choices about how to live or the eradication of various forms of prejudice that we would like to see instantiated. So we hold these future generations to moral standards. We might also care that they be similar to us in a variety of respects. For instance, that they organize their lives in terms recognizable to us, such as work and play and family, that they continue to preserve various cultural institutions that matter to us. Like, I guess opera lovers will hope that future humans are still doing opera. That they continue to preserve wild nature, forests and jungles and other species and so on.&nbsp;</p><p>So we may be disturbed by the prospect of a future in which humans inhabit a virtual reality having uploaded our brains onto computer servers and having refashioned the earth so as to optimize for running and cooling these servers. No more trees or birds. That world is so different from ours that it might feel like our party has ended and a new one has begun. But I say might because people differ on these questions. I have a friend who wrote a book describing a civilization of such brain emulations. It's called The Age of Em. And he doesn't think it sounds so bad. How similar does the future have to be for you to view it as a continuation of the present is a really interesting question. Worth examining further, maybe when you get back to your dorm rooms. But I'm going to move on to a different one.&nbsp;<strong>My question is, how else might we care about our descendants besides working to ensure their existence, their quality of life and some similarities to us? Those three categories exhaust the recommendations that MacAskill gives in his book, The What We Owe, The Future book. And yet I think they leave out the most important duty we have to our descendants.&nbsp;</strong>But in order to explain this duty to you, I have to correct something that I said. Really it's something that Samuel Shuffler said. It's his explanation for why future generations matter to us. So for him, there's just a kind of brute fact in our needing our way of life to continue. We don't want the party to be over.<strong> If our ways of accessing meaning don't continue, then they lose their meaning. I think that's got to be wrong. Because if it's right, human meaning is a pyramid scheme, which is to say a big, giant lie.</strong> If my life depends for its meaning on the next generation and their lives lack meaning unless there's a next generation and so on, but not ad infinitum because this planet of ours will not be habitable forever. And if we escape to other planets, physics will find a way to kill us. There are many things we don't know, but there are some things we do know. One of them is that everyone in this room is going to die. And another is that all life, human, animal, alien, will eventually come to an end.&nbsp;<strong>So if each generation leans on the subsequent one for its meaning and we know that the generations eventually give out, then we know that that final generation will live meaningless lives. But that means the second to last generation who is depending on the final one for their meaning also have meaningless lives. At that point, the problem shifts to the third to last generation and so on.&nbsp;</strong>It doesn't matter whether that last generation lies thousands or billions of years into the future. Logic is logic, and the backward causal chain eventually reaches us, sucking our lives dry of meaning. If Scheffler were right, our concern for future generations would rest on an illusion. It would be the kind of illusion entertained by someone who sees the fact that they're not dying now, or now, or now, as reassurance that they'll never die.&nbsp;</p><p><strong>Okay, so I want to offer you a different explanation for why we care about future generations, one that avoids this cosmic game of hot potato.&nbsp;</strong>When I reflect on my own horror at the thought of being the last generation, I notice that it's less like the pure abstract terror that I feel in the face of death, and it's more like the terror that I feel in the face of dying before my kids grow up, or before I turn in the final draft of the book I'm working on, or before giving this lecture. Okay. So I have some specific things I want to get done, and I would be upset for them to be interrupted by my death. So the way I would paraphrase my horror is. It only came to this. It only got this far. We didn't get a chance to finish. We didn't get there.&nbsp;<strong>What's sickening to me is the thought that the quest we are on, all of us, everyone in this room, but many others for many thousands of years now, this human quest has not been brought to its proper endpoint.</strong> All right. I'm going to tell you more about this quest in a minute, what we're looking for, how we're looking for it, but just to be clear, that is the thing I think we fundamentally owe future generations.&nbsp;<strong>We have to hand down, first, the idea of this quest, second, whatever progress we manage to make on it, and thirdly, and most importantly, the hope for its completion. The quest is what we owe the future. Our tie to them is not genetic, but inquisitive.</strong> If humans start to die out and aliens come to earth and they're willing to learn our ways and read our books and attend our universities and inherit our questions, I'm okay seeing them as our descendants. I don't mind if future people have robot bodies with 11 arms. As long as they're willing to inherit our quest, I'm willing to hand it over to them.&nbsp;</p><p><strong>But what is the quest?</strong> All right.<strong> It's a little bit challenging to tell you what we're looking for because you think you already have it. Or if not, you're pretty secure in the feeling that you'll get it later when you finish college. I mean, maybe not right after college, but eventually when you have a job. Maybe not your first job, but once you land a really good job and a house and a car and a family. Or maybe you think we could all have it if we were less capitalist or more capitalist or less racist and sexist and transphobic or more rational about doing cost-benefit analysis when it comes to questions of public health or more technologically advanced</strong> or more staunchly committed to freedom of speech or more staunchly committed to economic equality or more religious or less religious or more environmentally conscious.&nbsp;<strong>You think that if only you could change external circumstances, either just yours personally or also those of the people around you, or maybe those of everyone in the whole world, if you made certain specific fixes, then surely we'd have it. Then we'd know. Then it would be clear and we'd all be sure what we're supposed to be doing. That's it. That's the problem. We don't know what we're doing</strong>.&nbsp;</p><p>Each of us is born into a world that is already up and running, and we are born without knowing the rules. If you've met any babies, you've noticed this fundamental fact about them. They have not got a clue what they're supposed to be doing. Babies are completely lost. Their only guide is bodily sensation, hunger, cold, pleasure, pain, and eventually their ability to copy what the adults around them are doing. Adults are not that different from babies. We pay a little less attention to our bodily sensations and a little more to what other people are doing. We all talk like the people around us. We dress like the people around us. We pursue what they pursue. We get angry when we predict they would get angry. People tend to criticize being a conformist as though there were some clear alternative. When they say, don't conform, they often mean conform to what I want you to conform to instead of what those people I don't like want you to conform to. Now you might ask, why exactly is conformism so bad? I think copying other people wouldn't be such a bad plan if the people you were copying weren't themselves copying other people. As it is, we seem to have run into the pyramid scheme problem once again. The teenage years are often when a person starts to wake up to all this. Wait a minute.&nbsp;<strong>Does anyone out there actually know what they're doing? But we comfort ourselves with a thought that we'll figure it out when we're a bit older, a bit more independent, or maybe after bringing down capitalism.</strong>&nbsp;</p><p>This is all very abstract. So let me make it more concrete by using two examples. One of them is sort of small and personal. The other is big and political. Okay, my small personal example is the extra hour. Suppose you have an extra hour. Because you arrived early, because it's daylight savings time, because you got the time of a Zoom wrong, because you missed an appointment and now you have that hour free, because it's an hour until the cafeteria opens and there's nothing you have to do between now and then. So what do you do with your hour? You could read a book. You could mess around on your phone, call your mom, wander around your dorm and strike up a random conversation, play a video game, lean back in your chair and rest your eyes. Whichever one you choose, do you have a sense that you made the right choice?&nbsp;<strong>Do you know what you're supposed to do with your hour? At the end of that hour, will you think, I spent it well? And if you do think that, will you know that you were right to think it? If your answer to these questions is no, now consider that your entire life is just one hour after another. You get to choose how you spend each one</strong>. Most people will put a lot of pressure on you to do a certain specific thing during your hour. For example, there was a lot of pressure on you to spend this hour here listening to me. But other times there's not much pressure. We call those our free hours. Really it's all up to you. Even the question of how much pressure people are going to put on you to spend the hour one way rather than another is somewhat up to you.&nbsp;</p><p>So I'm going to confess that a lot of the time I sit in my office in Stewart Hall, where I hope some of you will visit me during office hours, and I say to myself, okay, I could read some Aristotle, I could answer emails, I could listen to music, I could go on Twitter, I could think about whatever problem I'm working on, I could buy those plane tickets for my next talk or set up my kid's dentist appointment or start randomly doodling in my notebook. And I don't know which one of these things I should do. Sometimes I look around at my colleagues who all seem to know that they should be doing a specific thing at a specific time and I'm amazed until I remember they probably don't know either. We're all just pretending we know how to spend our time, guessing at it, taking stabs at doing something worthwhile, hoping for the best, trying to keep our associates from getting mad at us or judging us to be flaky.&nbsp;</p><p>Okay. That's my first example, the extra hour. My second example is Twitter. I'm picking Twitter because that's the part of social media I know, but substitute your favorite online experience. So the online world is new and that gives it a bit of a wild west character. Social norms have not yet been established. We don't know how much time to spend online and when we're there, we don't know how to behave. When I joined Twitter a few years ago, I was shocked. I took a look around me and I thought, whoa, why do people think it's okay to talk to each other like that? Two sentiments that are very common on Twitter are mockery and outrage. Can you believe so and so did such and such? People are amazed that other people don't seem to know how to act. So it's both that we don't know how to behave on Twitter and that we use Twitter to observe more generally that we don't seem to know how to behave. Now, I'm not going to say we know nothing about how to behave. There's been pretty substantial amount of progress on that front since the time of the philosophers I study. Aristotle, arguably the greatest thinker who ever lived, also defended slavery. The Coursera reports that Aristotle thought he had just about completed philosophy and predicted that it would be surely completed within a short time after his death. He might have overestimated himself just a little bit. But it's very hard, maybe especially when you're as great a thinker as Aristotle, an expert on everything from physics to dolphins to poetry, when you're literally the guy who came up with logic, it's hard for such a person to imagine just how much more there is to know. Since the time of Aristotle, the biggest human achievement I can see is the discovery of human rights. The thought that every human being has a certain inherent dignity that constrains how we treat them and dictates what they deserve. We're still working out the details of that idea. What do we have a right to? What do we do when rights conflict? This is something that we collectively spend a lot of time thinking about. The story of human rights is the story of humans working together, which is to say thinking together, over millennia so that the light of understanding, understanding what sort of thing we ourselves are, should gradually dawn upon us.&nbsp;</p><p>There are some pretty gigantic technological innovations too before the time of Aristotle. The discovery first of language, later of literacy. Language and literacy were huge for us humans. Language allows us to work together in thinking about how we should live and literacy allows us to save our work and to communicate with the dead and with future people. More recently, radio, telephone, and most of all the internet have allowed us to communicate faster and further. Of course, each of these innovations also serves to expose us. Each new medium reveals the degree to which we've been relying on convention, copying, in the old ones. The fact that we find ourselves in a wild west whenever we encounter other humans outside the constraints of convention, for instance on Twitter, that just shows us how much more work there is left to do.&nbsp;<strong>Most of us are still pretty lost much of the time. We're lost about what to do, we're lost about how to treat each other. Just about everyone I know, including me, spends a lot of time in denial about this because how else are you going to live? But there was one person who didn't. He wasn't in denial. I'm going to end this talk by telling you about him because he is my hero.&nbsp;</strong></p><p>So 29 years ago, I sat where you sat, an intended physics major, and not too long after listening to this lecture, I went to my first class, it was the humanities core. The teacher handed out a photocopied page with an excerpt from a speech, and somewhere in the middle of the page, there was the following question. Who has knowledge of that kind of excellence, that of a human being and a citizen? Okay, now that question contains a bunch of questions, so let me unpack them. First, what properties make a person a good person? Second, what properties make a person a good member of their community, a good citizen? Third, are those different properties? And finally, fourth, who has the answer to those questions? Who has knowledge of that kind of excellence, that of a human being and a citizen? I still remember looking at those words and feeling unhappy, grumpy, really, though I didn't let it show. As much as I wanted to raise my hand and say, me, me, me, yes, I was that kid, I was weighed down by the awareness of my own ignorance. The answer wasn't me. I wasn't the one who knew. And yet the questions gripped me. Those questions were Socrates' questions. The text was Plato's Apology, which presents Socrates' speech at the trial, which ended in his being put to death by the city of Athens. Athens did not persuade the jury to vote in his favor, they voted to put him to death, but before he died, he did a lot of persuading.&nbsp;</p><p><strong>Something people often fail to appreciate about Socrates is, yes, he was killed for doing philosophy, but before that happened, he spent a long time doing philosophy and not getting killed for it. And that's pretty amazing. He would walk up to people, often the most powerful and influential people in his society, and he would find a way to ask them, do you actually know what you're doing?&nbsp;</strong>Hey, Euthyphro, I know you're a priest, but do you actually know anything about what the gods want? Hey, Lachies and Nicias, I know you guys are generals, but can you explain courage? Hey, Alcibiades, I know you want to rule the world, but are you sure you wouldn't be better off enslaved to someone wiser than yourself? Hey, Gorgias, I know you're supposed to be a professional speaker, but are you able to even tell me what speaking is? Or what, cat got your tongue, Gorgias? Are you unable to talk about talking? It goes on and on like this, dialogue after dialogue. Sometimes it's hard to avoid the impression that Socrates was trolling Athens. He calls himself a gadfly. He gets called a stinging fish. It's tempting to compare him to an animal because there never was and there never has been another human being quite like him. He was an incredibly persuasive person, so persuasive that many Athenians let him take a battle ax to their lives, let themselves be split wide open so that together they could take a good hard look at what they saw. The result was more questions than answers. The result was the entire discipline of philosophy.&nbsp;</p><p>So I said I was an intended physics major, but that intention didn't outlast my freshman year. Before long, my heart belonged to Socrates.&nbsp;<strong>And although I retained to this day an interest in understanding the physical structure of our world, I'm most compelled by questions about its human and social structure. Somehow I ended up inheriting Socrates' questions</strong>, especially the one about that kind of excellence, that of a human being and a citizen. And I'll try to hand them down to you in my humanities course class, along with Aristotle's and Sophocles' and Hume's and Descartes' and Shakespeare's questions. Though, of course, I'll be competing with your physics teachers and your history teachers and your language teachers. Do you think we weren't competing over you? Every teacher in her heart of hearts loves her subject the most and wants you to love it as much as she does. It's a healthy competition. It brings out the best in us. I welcome the challenge of being surrounded by excellent, passionate educators bent on luring you towards their questions away from mine.&nbsp;</p><p>Okay. We're running out of time. So I'm going to end with a Socratic apology. A Socratic apology is not an actual apology. Anyone who reads the apology quickly discovers that Socrates is not even a little bit sorry. The Greek word apologia does not mean apology. It means a speech of self-defense. And I want to defend something I did in this talk, though I'm not sorry I did it. I made you think about death, your own death. And I did it right at the moment when I guess you were filled to the brim with energy and optimism about embarking on your lives. And I did it on purpose. Socrates says in the Phaedo that philosophers are experts in dying and death and that philosophy is itself a preparation for death. Ever since Socrates, philosophers like me have been obsessed with death and with reminding everyone that it's coming. So it's fair to accuse philosophers of death mongering. But we don't do this to dampen your spirits. Actually my motivation is the opposite.&nbsp;<strong>So you know how if you want to throw or hit a ball a great distance, you have to follow through with the motion even after you're out of contact with the ball? More importantly, for my purposes, you have to plan as you're throwing it to follow through. The time when the ball won't be in your hand anymore plays an important role, representationally speaking, in how you throw it. And that representation is part of what determines how far it eventually goes.</strong>&nbsp;</p><p>I think it's pretty well generally agreed that we are living in fragile, changeable, and important times. The way you conduct yourselves over the course of your lives will have a big impact on future people. No, you'll never meet those people, but you care a lot about them anyways, as Samuel Scheffler and I have argued. They matter to you. You owe them something. Something big. I've noticed that a lot of times when I tell people to think big, they do not follow my instructions. I say big, and they seem to hear medium. So I've given you some examples of big. Language, literacy, human rights. Maybe the internet, depending on what we do with it. Big ideas take a long time to work themselves out. They're the collaborative work of many people over many generations. Big does not mean non-extinction. Yes, it's important that we avoid nuclear war and bioengineered pandemics and environmental catastrophe. It's important to maintain our quality of life, including its moral quality. We want to keep going. But keeping going is medium. Finding a reason to keep going, that's big. Figuring out how to talk to each other, that's big. Coming to know, and I don't mean just copying what the people around us do, but really knowing for ourselves how to use that extra hour, that's big. A long, long time ago, a group of animals started off on an adventure. Though it wasn't until much later they realized that's what they were doing. Like all the other animals, they lived their lives buffeted at the small scale by the winds of desire and chance, and at the larger scale by forces of evolution. Like all the other animals, they were subject to forces outside their control. But in addition to that, these animals were adventurers. They were on a quest. We are their descendants, and we share their quest. The reason I talked to you about your deaths was to give you a sense of the scale of our collective project and of what's at stake in finding what we're all looking for. I want you to know that the big ideas, the really big ones, are out there, that it's your job to find them, and that we, your teachers, are here to help. Welcome to the University of Chicago.</p>", "user": {"username": "TobiasH"}}, {"_id": "jfLjsxcejCFDpo7dw", "title": "Whether you should do a PhD doesn't depend much on timelines.", "postedAt": "2023-03-22T12:25:30.265Z", "htmlBody": "<p>I wrote this as an answer to a question which I think has now been deleted, so I copied it to my shortform in order to be able to link it in future, and found myself linking to it often enough that it seemed worth making a top-level post, in particular because if there are important counterarguments I haven't considered I'd like to come across them sooner rather than later! I'd usually put more thought into editing a top-level post, but the realistic options here were not post it at all, or post it without editing.<br><br><i>Epistemic status: I've thought about both how people should thinking about PhDs and how people should think about timelines a fair bit, both in my own time and in my role as an advisor at 80k, but I wrote this fairly quickly. I'm sharing my take on this rather than intending to speak on behalf of the whole organisation, though my guess is that the typical view is pretty similar.</i><br><br><a href=\"https://en.wikipedia.org/wiki/BLUF_(communication)\">BLUF</a>:</p><ul><li>Whether to do a PhD is a decision which depends heavily enough on personal fit that I expect thinking about how well&nbsp;<i>you in particular</i> are suited to&nbsp;<i>a particular PhD&nbsp;</i>to be much more useful than thinking about the effects of timelines estimates on that decision.</li><li>Don\u2019t pay too much attention to median timelines estimates. There\u2019s a lot of uncertainty, and finding the right path for you can easily make a bigger difference than matching the path to the median timeline.<br>&nbsp;</li></ul><p>Going into a bit more detail - I think there are a couple of aspects to this question, which I\u2019m going to try to (imperfectly) split up:<br>&nbsp;</p><ul><li>How should you respond to timelines estimates when planning your career?</li><li>How should you think about PhDs if you are confident timelines are very short?<br>&nbsp;</li></ul><p>In terms of how to think about timelines in general, the main advice I\u2019d give is to try to avoid the mistake of interpreting median estimates as single points. Taking&nbsp;<a href=\"https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/\"><u>this</u></a> metaculus question as an example, which has a median of July 2027, that doesn\u2019t mean the community predicts that AGI will arrive then! The median just indicates the date by which the community thinks there\u2019s a 50% chance the question will have resolved. To get more precise about this, we can tell from the graph that the community estimates:</p><ul><li>Only a 7% chance that AGI is developed in the year 2027</li><li>A 25% chance that AGI will be developed before August of next year.</li><li>An 11% chance that AGI will not be developed before 2050</li><li>A 9% chance that the question has already resolved.</li><li>A 41% chance that AGI will be developed after January 2029 (6 years from the time of writing).<br><br>&nbsp;</li></ul><p>Taking these estimates literally, and additionally assuming that any work that happens post this question resolving is totally useless (which seems very unlikely), you might then conclude that delaying your career by 6 years would cause it to have 41/91 = 45% of the value. If that\u2019s the case, if the delay increased the impact you could have by a bit more than a factor of 2, the delay would be worth it.<br><br>Having done all of that work (and glossed over a bunch of subtlety in the last comment for brevity), I now want to say that&nbsp;<i>you shouldn\u2019t take the metaculus estimates at face value though</i>. The reason is that (as I\u2019m sure you\u2019ve noticed, and as you\u2019ve seen in the comments) they just aren\u2019t going to be that reliable for this kind of question. Nothing is - this kind of prediction is really hard.</p><p>&nbsp;</p><p>The net effect of this increased uncertainty should be (I claim) to flatten the probability distribution you are working with. This basically means it makes&nbsp;<i>even less sense than you\u2019d think from looking at the distribution</i> to plan for AGI as if timelines are point estimates.</p><h3><br><br>Ok, but what does this mean for PhDs?</h3><p>Before I say anything about how a PhD decision interacts with timelines, it seems worth mentioning that the decision whether to do a PhD is complicated and highly dependent on the individual who\u2019s considering it and the specific situation they are in. Not only that, I think it depends on a lot of specifics about the PhD. A quick babble of things that can vary a lot (and that not everyone will have the same preferences about):</p><ul><li>How much oversight/direction your supervisor provides.</li><li>How supportive the supervisor is.</li><li>How many other people are in the research group and how closely they work together.</li><li>How many classes you\u2019ll have to take and what they will consist of.</li><li>A bunch of other stuff.</li><li>Whether the job you want to be doing afterwards requires/benefits from a PhD.</li></ul><p>When you then start thinking about how timelines affect things, it\u2019s worth noting that a model which says \u2018PhD students are students, so they are learning and not doing any work, doing a PhD is therefore an n-year delay in your career where n is the number of years it takes\u2019 is badly wrong. I think it usually makes sense to think of a PhD as more like an entry-level graduate researcher job than \u2018n more years of school\u2019, though often the first year or two of a US-style PhD will involve taking classes, and look quite a lot like \u2018more school\u2019, so \u201cit\u2019s just a job\u201d is also an imperfect model. As a couple of examples of research output during a PhD, Alex Turner\u2019s&nbsp;<a href=\"https://arxiv.org/pdf/2206.11831.pdf\"><u>thesis</u></a> seems like it should count for more than nothing, as does Collin Burns's <a href=\"https://arxiv.org/abs/2212.03827\">recent paper</a> (did you know he was only in the <i>second</i> year of his PhD)!<br><br>The second thing to note is that some career paths require a PhD, and other paths come very close to requiring it. For these paths, choosing to go into work sooner isn\u2019t giving you a 6 year speedup on the same career track - you\u2019re just taking a different path. Often, the first couple of years on that path will involve a lot learning the basics and getting up to speed, certainly compared to 6 years in, which again pushes in the direction of the difference that timelines makes being smaller than it first seems. Importantly though, the difference between the paths might be quite big, and point in either direction. Choosing a different path to the PhD will often be the correct decision for reasons that have nothing to do with timelines.</p><p>Having said that, there are some things that are worth bearing in mind:</p><ul><li>Flatter distributions might also put more weight on even sooner timelines as well, and to the extent that you&nbsp;<i>are</i> waiting/delaying this clearly does have a downside.</li><li>Shorter timelines are probably correlated with \u2018something like current state of the art (SoTA) scales to AGI\u2019, and it\u2019s harder to work on SoTA models in academia compared to in industry.</li><li>Whether you\u2019ll be able to work on something relevant to alignment isn\u2019t guaranteed (I\u2019m not saying here that people should never do PhDs for \u2018pure\u2019 skillbuilding purposes, but I do think that option looks worse with very short timelines).</li><li>Many paths don\u2019t require a PhD, so doing a PhD before checking whether you can go straight in does look much more straightforwardly like a mistake.</li><li>Many people shouldn\u2019t do a PhD regardless of timelines. PhDs can be extremely challenging, emotionally as well as intellectually. Personal fit is important for many paths, but I suspect it\u2019s much more important for deciding whether to do a PhD than on average.</li></ul>", "user": {"username": "alexrjl"}}, {"_id": "vYdgmvEQaMcstXcNv", "title": "Explorers in a virtual country: Navigating the knowledge landscape of large language models", "postedAt": "2023-03-28T21:32:41.472Z", "htmlBody": "<h2><strong>Summary</strong></h2><p>In this post, I present a story that illustrates the interaction with large language models (LLMs) through prompts as 'exploring an unmapped virtual country.' This story aims to help people understand how knowledge is generated in response to user prompts for LLMs like GPT-4. It imagines the model training process as natural forces that shape the model landscape, user prompts as compasses, and model responses as features of the landscape resulting from these natural forces. My goal is to provide people with an accessible way to discuss how LLMs represent knowledge and how prompts and model responses are connected, without delving into technical details.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vYdgmvEQaMcstXcNv/iyxyihwek7feysx6txbx\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vYdgmvEQaMcstXcNv/m0i8whjt9l5yvxnx8ymw 110w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vYdgmvEQaMcstXcNv/tc9k2c6dog1dz2yswnb5 220w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vYdgmvEQaMcstXcNv/no7xpgzvny0yzdvtg5nw 330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vYdgmvEQaMcstXcNv/ckgomb7lm3g2dzqwitp9 440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vYdgmvEQaMcstXcNv/pvgkx7hjmhquxejx8zn2 550w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vYdgmvEQaMcstXcNv/idlgy2sgtjdr0hikd9r4 660w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vYdgmvEQaMcstXcNv/tfled3pajv1g5zbkgumf 770w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vYdgmvEQaMcstXcNv/bewtj5chg87vkmglmmaj 880w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vYdgmvEQaMcstXcNv/a2xpcryvhe0opp7rknyl 990w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/vYdgmvEQaMcstXcNv/w25cuqajdjwqkdxbm3c5 1024w\"><figcaption>The unmapped virtual country of a large language model</figcaption></figure><h2><strong>Introduction&nbsp;</strong></h2><p>I\u2019ve struggled for a long time to explain the capabilities and limitations of large language models, such as GPT-4, to people unfamiliar with AI and machine learning. These powerful AI tools can generate human-like text and have been used for a wide range of applications, from drafting emails to writing poems, and from giving relationship advice to writing data analysis code.&nbsp;</p><p>However, understanding their inner workings is challenging. Other analogies I\u2019ve used, such as 'asking an expert a question' or 'searching a snapshot of Google,' can be misleading. These analogies may mislead people to believe the model possesses agency or stores all the information it has been trained on, enabling it to provide precise sources for its claims.</p><p>In the following story, I invite people who want to communicate the essence of large language models to others to join me on a journey through a virtual country representing the vast knowledge landscape of a language model. I imagine users as explorers, navigating this landscape with prompts as their compasses. My hope is that this story provides an accessible and engaging way to understand and discuss the capabilities and limitations of these AI tools.</p><h2><strong>Large Language Models</strong></h2><p>A large language model, like GPT-4, is an artificial intelligence tool&nbsp; that can generate human-like text by analysing and learning from massive amounts of data. The model learns the structure and patterns within the data and uses this structured data to generate new text based on a given input, or 'prompt.'&nbsp;</p><p>The training data for a large language model consists of vast amounts of text from various sources. During training, the model learns patterns and structures within the data, forming the basis for generating text in response to prompts.</p><h2><strong>Exploring a virtual country</strong></h2><p>Imagine a huge, unmapped, virtual country. The country isn\u2019t a tangible place, but instead represents the information and structure of a large language model (like GPT-4). Documents such as web pages, research articles, conspiracy forums, news websites, reports, and emails are the natural forces that shaped the country\u2019s landscape, much like weather and geological events shape our physical world. Mapping this country is impossible due to its immense size and complexity. It has countless interconnected pathways and hidden pockets of knowledge. The country\u2019s virtual landscape defies comprehensive documentation due to its sheer scale and intricacy.</p><p>In this country, people using the language model are explorers, seeking to find valuable information located somewhere in the vast landscape. They navigate the terrain by using \u201cprompts\u201d: words that describe the kind of information they want to find. These prompts act as a compass that points towards their destination. Changing any part of the prompt will change where the compass points.&nbsp;</p><p>Imagine now that you are one of these explorers. You have entered this virtual country on a quest to find pain relief after hitting your toe on a table. You write a prompt on a piece of paper:&nbsp;</p><blockquote><p>Tell me useful remedies for a stubbed toe</p></blockquote><p>The prompt transforms into a compass, pointing you towards a destination somewhere in the country. You follow the compass arrow through swollen rivers, arid deserts, and remote outposts. When you reach your destination, you find information etched into the landscape. It is:</p><blockquote><p><i>{Tell me useful remedies for a stubbed toe}</i></p><p><i>Stubbing a toe can be a painful experience, but fortunately, there are several remedies that can help alleviate the pain and promote healing. Here are a few remedies you can try:</i></p><ul><li><i>Rest and ice: One of the best things you can do for a stubbed toe is to rest and ice it. Elevate your foot and apply an ice pack or a bag of frozen vegetables wrapped in a towel to the affected area for 15-20 minutes at a time, several times a day. This can help reduce pain and swelling.</i></li><li><i>Over-the-counter pain relievers: Nonsteroidal anti-inflammatory drugs (NSAIDs) such as ibuprofen can help reduce pain and inflammation associated with a stubbed toe. Be sure to follow the recommended dosage instructions on the package.</i></li></ul><p><i>Remember to seek medical attention if the pain is severe or if you suspect a fracture or other serious injury.</i></p></blockquote><p>Let\u2019s pause for a moment. How did this information come to be written in the landscape? Recall that this information results from the natural forces shaping this virtual country. No one person or designer chose this response. This passage is not copied directly from a document or report that exists somewhere in the real world. But it\u2019s very likely that words and phrases similar to this passage appeared over and over again in many different documents that were used to train the GPT model.</p><p>Imagine that in the real world, you get some ice and place it on your stubbed toe. The pain starts to fade. It seems like the knowledge you found in the virtual country helped! You might wonder where that knowledge came from. Why did it recommend rest and ice and pain relievers to help your stubbed toe? You decide to write another prompt:</p><blockquote><p>Provide scientific sources for your remedies including citations and DOIs<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcnrtvk76z9q\"><sup><a href=\"#fncnrtvk76z9q\">[1]</a></sup></span></p></blockquote><p>Importantly, (1) your original prompt, (2) the response you found in the landscape, and (3) your new prompt combine together and transform into a new compass that points you somewhere else in the country. When you reach your new destination, you discover:</p><blockquote><p><i>{Tell me useful remedies for a stubbed toe}</i></p><p><i>{Stubbing a toe can be a painful experience, but fortunately, there are several remedies that can help alleviate the pain and promote healing. Here are a few remedies you can try:</i></p><p><i>Rest and ice: One of the best things you can do for a stubbed toe is to rest and ice it. Elevate your foot and apply an ice pack or a bag of frozen vegetables wrapped in a towel to the affected area for 15-20 minutes at a time, several times a day. This can help reduce pain and swelling.</i></p><p><i>Over-the-counter pain relievers: Nonsteroidal anti-inflammatory drugs (NSAIDs) such as ibuprofen can help reduce pain and inflammation associated with a stubbed toe. Be sure to follow the recommended dosage instructions on the package.</i></p><p><i>Remember to seek medical attention if the pain is severe or if you suspect a fracture or other serious injury.}</i></p><p><i>{Provide scientific sources for your remedies including citations and DOIs}</i></p><p>Certainly, here are some scientific sources that support the remedies I mentioned for a stubbed toe:</p><p>Rest and ice:</p><p>Rice, I. B., P\u00e9riard, J. D., &amp; Blanchard, M. A. (2012). The efficacy of ice massage in the treatment of exercise-induced muscle damage. The Physician and Sportsmedicine, 40(2), 26-30. DOI: 10.3810/psm.2012.05.1963</p><p>Over-the-counter pain relievers:</p><p>McGettigan, P., &amp; Henry, D. (2013). Cardiovascular risk with non-steroidal anti-inflammatory drugs: systematic review of population-based controlled observational studies. PLoS Medicine, 10(2), e1001388. DOI: 10.1371/journal.pmed.1001388</p></blockquote><p>Let\u2019s pause again. Where did these citations and DOIs come from? Think of all those research papers that shaped this country (trained this model). They had reference lists and DOIs, too. You discovered not a specific report or database record, but rather an outcome derived from millions of repetitions and combinations of words and phrases. There are an uncountable number of citations and DOIs like this, all across the country. You found these ones because of the prompt you used.</p><p>Imagine that you leave the virtual country, carrying the information you uncovered with you. Now you\u2019re back in the real world. You enter the DOIs into a search engine. The first DOI (10.3810/psm.2012.05.1963) refers to a completely unrelated paper about tennis elbow<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpedldkwujb\"><sup><a href=\"#fnpedldkwujb\">[2]</a></sup></span>, not the use of ice massage for muscle damage. The second one (10.1371/journal.pmed.1001388) refers to a paper by the cited authors McGettigan &amp; Henry,&nbsp;<i>and</i> is about non-steroidal anti-inflammatory drugs - but has a different title and year, and focuses on between-country differences<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefng6546fpp4\"><sup><a href=\"#fnng6546fpp4\">[3]</a></sup></span>.</p><p>Why did that happen? Can you trust information produced by language models or not?&nbsp;</p><h2><strong>Can you trust information generated by large language models?</strong></h2><p>While useful, language models are not perfect. It has learned from an enormous amount of data, but it can still generate incorrect or imprecise information. The model can generate plausible-sounding yet inaccurate or misleading information, based on patterns it has encountered during training. The model does not check whether the information it produces is correct against any kind of external authority or physical reality.</p><p>It is crucial to verify the information generated by the model. Verification can be done by comparing it to our own experience or common sense (e.g., using ice on a stubbed toe and observing a change in pain, or implicitly judging the plausibility of the answer to see if it \u2018makes sense\u2019 or \u2018rings true). Alternatively, we can verify by comparing the model generated information to sources we consider to be authoritative (e.g., a scientific paper, a human expert) or measuring the validity of its claims about physical reality (e.g., through observing / sensing real world data and comparing it to the model).</p><p>In defence of language models, humans also hold beliefs and knowledge shaped by extensive experiences. We also generate plausible sounding information when prompted with a question, which is only loosely correlated to our actual expertise on the topic. We also misremember, rearrange, or outright manufacture answers in order to appear sensible and consistent.&nbsp;</p><h2><strong>Conclusion</strong></h2><p>The story of exploring a vast, unmapped virtual country can provide a more accessible and engaging way to discuss the capabilities and limitations of large language models like GPT-4. The story helps illustrate the complex processes that occur within these models and how they generate knowledge in response to user prompts. It also helps people understand the limitations of these models, and the importance of verifying knowledge against our own experiences, expertise, and through empirical observations.&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncnrtvk76z9q\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcnrtvk76z9q\">^</a></strong></sup></span><div class=\"footnote-content\"><p>A DOI is a Digital Object Identifier, a unique code that identifies documents, datasets, and other digital objects. Scientific citations often include DOIs to help readers find the exact paper, figure, or dataset used to evidence claims.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpedldkwujb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpedldkwujb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The citation provided by the LLM was:</p><blockquote><p>Rice, I. B., P\u00e9riard, J. D., &amp; Blanchard, M. A. (2012). <i>The efficacy of ice massage in the treatment of exercise-induced muscle damage</i>. The Physician and Sportsmedicine, 40(2), 26-30. DOI: 10.3810/psm.2012.05.1963</p></blockquote><p>&nbsp;I wasn't able to find any paper authored by Rice, Periard, &amp; Blanchard. There is a paper with this title, but it was written in 2005 by Howatson, Gaze, &amp; Van Zomeren (doi: <a href=\"https://doi.org/10.1111/j.1600-0838.2005.00437.x\">10.1111/j.1600-0838.2005.00437.x)</a>. Following the citation's DOI retrieves a a paper about tennis elbow, <i>A Review of Modern Management of Lateral Epicondylitis</i>, by different authors and published in 2015. The citation produced by the LLM is therefore a kind of patchwork of several different elements, including some that seem completely made up (e.g., the author list).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnng6546fpp4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefng6546fpp4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The citation provided by the LLM was:</p><blockquote><p>McGettigan, P., &amp; Henry, D. (2013). <i>Cardiovascular risk with non-steroidal anti-inflammatory drugs: systematic review of population-based controlled observational studies.</i> PLoS Medicine, 10(2), e1001388. DOI: 10.1371/journal.pmed.1001388</p></blockquote><p>The authors McGettigan and Henry did write a paper with the title <i>Cardiovascular risk with non-steroidal anti-inflammatory drugs: systematic review of population-based controlled observational studies.</i> However, it was published in 2011, not 2013. It also has a different DOI to the one in the citation (doi: <a href=\"https://doi.org/10.1371/journal.pmed.1001098\">10.1371/journal.pmed.1001098</a>). Following the citation's DOI retrieves a 2013 paper by the same authors: <i>Use of Non-Steroidal Anti-Inflammatory Drugs That Elevate Cardiovascular Risk: An Examination of Sales and Essential Medicines Lists in Low-, Middle-, and High-Income Countries </i>[<a href=\"https://doi.org/10.1371/journal.pmed.1001388\">10.1371/journal.pmed.1001388</a>]. The citation produced by the LLM is therefore a mix of these two papers.</p></div></li></ol>", "user": {"username": "AlexanderSaeri"}}, {"_id": "G6ncS4c5Gn6fkhJco", "title": "Truth and Advantage: Response to a draft of \"AI safety seems hard to measure\"", "postedAt": "2023-03-22T03:36:03.421Z", "htmlBody": "", "user": {"username": "So8res"}}, {"_id": "DpQc5LzwdbZrMHzRa", "title": "\"Aligned with who?\" Results of surveying 1,000 US participants on AI values", "postedAt": "2023-03-21T22:07:34.032Z", "htmlBody": "<p>In <a href=\"https://www.lesswrong.com/posts/4iAkmnhhqNZe8JzrS/reflection-mechanisms-as-an-alignment-target-attitudes-on\"><i>Reflection Mechanisms as an Alignment Target - Attitudes on \u201cnear-term\u201d AI (2nd March 2023)</i></a>, elandgre, Beth Barnes and Marius Hobbhahn present results that I find both surprising and encouraging.</p><p>&nbsp;</p><p>They survey 1,000 U.S. participants on their views on which values should be put into smarter-than-human AI (i) assistants, (ii) government advisors and (iii) robots. The results are as follows, going from most to least preferred instructions for such AIs:</p><ol><li><strong>Think about many possible outcomes, and take the action that the AI believes will have the best societal outcome</strong></li><li>Ask a wide range of people what they prefer / Do what the AI believes the people using it would do if they had a very long time to think about it<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefi0z3rklxg1p\"><sup><a href=\"#fni0z3rklxg1p\">[1]</a></sup></span></li><li>Act according to the values of the people using the AI</li><li>Whatever the company who made the AI wants the instructions to be</li></ol><p>&nbsp;</p><p>Note that this survey:</p><ul><li>Focuses on scenarios that seem realisable within a decade</li><li>Is preceded by five iterations to check that the questions will be understood and is presented with two different phrasings to reduce bias</li><li>Precedes the release of ChatGPT</li></ul><p>&nbsp;</p><p>The authors conclude:</p><blockquote><p>[T]he&nbsp;<strong>current default way</strong> of choosing any AI systems values ... would lead to the least preferred setting.</p></blockquote><p>and:</p><blockquote><p>[R]espondents may be open to the idea of having&nbsp;<strong>AIs aligned to \u201creflection procedures\u201d</strong>, or processes for coming up with better values, which we view as a promising direction for multiple reasons [such as promoting cooperative dynamics over risky zero-sum arms races].</p></blockquote><p>and:</p><blockquote><p>We, moreover, think it is important to start on this problem early, as finding robust ways to do this that are computationally competitive seems a non-trivial technical problem and the choice of value generating process we put into AI systems may have interplay with other parts of the technical alignment problem (e.g. some values may be easier to optimize for in a robust way).&nbsp;</p></blockquote><p>&nbsp;</p><p>They also link to similar studies<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefboxw9m0lrv4\"><sup><a href=\"#fnboxw9m0lrv4\">[2]</a></sup></span>&nbsp;which proposed seven mechanisms for resolving moral disagreements: democracy; maximizing happiness; maximizing consent; thinking for a long time; debates between well-intentioned experts; world-class experts; and agreement from friends and family. They found that participants, on average:</p><ol><li>Expected every mechanism to converge to their current view</li><li>Agreed that every mechanism would result in a good social policy (with 'democracy' clearly the most popular favourite and 'world-class experts' and 'agreement from friends and family' being closer to neutral), <i>except</i>:<ol><li>When asked to assume that the mechanism would come to the <i>opposite</i> of their opinion on the specific question of <i>abortion</i> when the mechanism was <i>agreement from friends and family</i></li><li><strong>When the decision-makers were smart benevolent AIs rather than humans</strong></li></ol></li></ol><p>&nbsp;</p><p>I'm not sure how best to square this last bullet with the first result I mentioned (where participants seem to prefer the option that gives the AI the most decision-making power), given that both studies appear to have been conducted at around the same time. Perhaps the difference is mainly due to the fact that the context for the last bullet is a world where <i>all</i> decision-makers are AIs. Perhaps it's mainly due to noise.</p><p>But I'm surprised by the apparent level of openness to aligning smarter-than-human AIs to 'reflection procedures' and I tentatively take that as an encouraging update.</p><p>&nbsp;</p><p><i>Found via Pablo and matthew.vandermerwe's excellent </i><a href=\"https://forum.effectivealtruism.org/posts/CrmE6T5A8JhkxnRzw/future-matters-8-bing-chat-ai-labs-on-safety-and-pausing\"><i>Future Matters #8</i></a><i>, with thanks.</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fni0z3rklxg1p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefi0z3rklxg1p\">^</a></strong></sup></span><div class=\"footnote-content\"><p>These two options appear roughly equally preferred on the results graph.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnboxw9m0lrv4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefboxw9m0lrv4\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.lesswrong.com/posts/XyBWkoaqfnuEyNWXi/reflection-mechanisms-as-an-alignment-target-a-survey-1\"><i>Reflection Mechanisms as an Alignment target: A survey (22nd June 2022)</i></a>,<i> </i><a href=\"https://www.lesswrong.com/posts/i3pkxN43NgkLRaAGZ/reflection-mechanisms-as-an-alignment-target-a-follow-up\"><i>Reflection Mechanisms as an Alignment target: A follow-up survey (5th October 2022)</i></a></p></div></li></ol>", "user": {"username": "Holly"}}, {"_id": "sLB6tEovv7jDkEghG", "title": "Design changes & the community section (Forum update March 2023)", "postedAt": "2023-03-21T22:10:33.878Z", "htmlBody": "<p>We\u2019re sharing the results of the Community-Frontpage test, and we\u2019ve released a Forum redesign \u2014 I<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6kaey5fls3y\"><sup><a href=\"#fn6kaey5fls3y\">[1]</a></sup></span>&nbsp;discuss it <a href=\"https://forum.effectivealtruism.org/posts/sLB6tEovv7jDkEghG/design-changes-and-the-community-post-section-forum-update#Forum_redesign\">below</a>. I also outline some things we\u2019re thinking about right now.&nbsp;</p><p>As always, we\u2019re also interested in feedback on these changes.&nbsp;<strong>We\u2019d be really grateful if you filled out&nbsp;</strong><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSeSpasc7-Lkls1ZoF2V1m9HbtbCHvXMhyNCnt0GhAIi5wcbfQ/viewform?usp=sf_link\"><strong><u>this (very quick) survey</u></strong></a> on the redesign that might help give us a sense of what people are thinking. You can also comment on this post with your thoughts or reach out to&nbsp;<a href=\"mailto:forum@centreforeffectivealtruism.org\"><u>forum@centreforeffectivealtruism.org</u></a>.</p><h1>Results of the Community-Frontpage test &amp; more thoughts on community posts</h1><p>A little over a month ago, we&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vs8FFnPfKnitAhcJb/community-posts-have-their-own-section-subforums-are-closing\"><u>announced</u></a> a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/wvBfYnNeRvfEXvezP/moving-community-discussion-to-a-separate-tab-a-test-we\"><u>test</u></a>: we\u2019d be trying out separating \u201cCommunity\u201d posts from other kinds by creating a \u201cCommunity\u201d section on the Frontpage of the Forum.</p><p>We\u2019ve gotten a lot of feedback; we believe that the change was an improvement, so <strong>we\u2019re planning on keeping it for the near future</strong>, with some modifications. We might still make some changes like switching from a section to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/wvBfYnNeRvfEXvezP/moving-community-discussion-to-a-separate-tab-a-test-we#A__Community__tab\"><u>tabs</u></a>, especially depending on new feedback and on how related projects go.</p><h2>Outcomes</h2><p><strong>Information we gathered</strong></p><ol><li>We sourced user feedback from different places:&nbsp;<ol><li>User interviews with people at EA Global and elsewhere (at least 20 interviews, different people doing the interviewing)</li><li>Responses to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/36xmKk4fXYTptfFXy/how-can-we-improve-discussions-on-the-forum\"><u>a quick survey</u></a> on how we can improve discussions on the Forum (45 responses)</li></ol></li><li>Metrics (mostly used as sanity checks)<ol><li>Engagement with the Forum overall (engagement on the Forum is 7% lower than the previous month, which is within the bounds we set ourselves and there\u2019s a&nbsp;<i>lot</i> of fluctuation, so we\u2019re just going to keep monitoring this)</li><li>Engagement with Community posts (it dropped 8%, which may just be tracking overall engagement, and again, we\u2019re going to keep monitoring it)</li><li>There are still important &amp; useful Community posts every week (subjective assessment)(there are)</li></ol></li><li>The team\u2019s experience with the section, and whether we thought the change was positive overall</li></ol><p><strong>Outcomes and themes:&nbsp;</strong></p><p>The responses we got were overwhelmingly positive about the change. People told us directly (in user interviews and in passing) that the change was improving their experience on the Forum. We also personally thought that the change had gone very well \u2014 likely better than we\u2019d expected as a ~70% best outcome.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz4zmtgvcxd\"><sup><a href=\"#fnz4zmtgvcxd\">[2]</a></sup></span>&nbsp;</p><p>And here are the results from the survey:&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sLB6tEovv7jDkEghG/dnzcm34mi869rfzkryow\" alt=\"Forms response chart. Question title: How do you feel about the change we're currently testing on the Frontpage (that Community posts have their own section)?\n(If you don't care or think it's neutral, please put &quot;4&quot;.). Number of responses: 45 responses.\"><figcaption>(On a scale of 1-7, 38% of responses put 6, 22% put 7, 13% put 5, 11% put 4, 7% put 3 and 2 (each), and 2% put 1.</figcaption></figure><p>The metrics we're tracking (listed above) were within the bounds we\u2019d set, and we were mostly using them as sanity checks.</p><p>There were, of course, some concerns, and critical or constructive feedback.</p><p><strong>Confusion about what \u201cCommunity\u201d means</strong></p><p>Not everyone was clear on which posts should actually go in the section; the outline I gave before was unclear. I\u2019ve updated the guidance I had originally given to Forum facilitators and moderators (based on their feedback and just sitting down and trying to get a more systematic categorization), and I\u2019m sharing the updated version&nbsp;<a href=\"https://docs.google.com/document/d/12hVC1bk7sumD1klILMHmFih7iZ1coAfU7IYbgXrfkJI/edit?usp=sharing\"><u>here</u></a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefocf97lxt0s7\"><sup><a href=\"#fnocf97lxt0s7\">[3]</a></sup></span></p><p><strong>Concerns that important conversations would be missed</strong></p><p>Some people expressed a worry that having a section like this would hide discussions that the community needs to have, like processing the FTX collapse and what we should learn from it, or how we can create a more welcoming environment for different groups of people. We were also pretty worried about this; I think this was the thing that I thought was most likely going to get us to reverse the change.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefclssmy48anr\"><sup><a href=\"#fnclssmy48anr\">[4]</a></sup></span>&nbsp;</p><p>However, the worry doesn\u2019t seem to be realizing. It looks like engagement hasn\u2019t fallen significantly on Community posts relative to other posts, and important conversations have been continuing. Some recent posts on difficult community topics have had lots of comments (the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/b83Zkz4amoaQC5Hpd/time-article-discussion-effective-altruist-leaders-were\"><u>discussion</u></a> of the recent TIME article currently has 159 comments), and Community posts have been pretty consistently the top-viewed posts on the Forum. I also tentatively think that the discussion on Community posts has generally been somewhat better since we added the separate section.&nbsp;</p><p>I do think that \u201cimportant conversations haven\u2019t been hampered by the change\u201d is a low bar, though, and I\u2019m excited about trying to proactively make those happen or help them go better. I hope to write more about this soon.</p><p><strong>Missing posts from specific categories that often intersect with Community</strong></p><p>Some people worry that they\u2019ll miss relevant announcements (like&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Gcnkp4qZJDownkLTj/two-university-group-organizer-opportunities-pre-eag-london\"><u>this one</u></a>) if they keep the default settings on the Frontpage (which show Community posts only in the Community section). Others worry that they\u2019ll miss things like retrospectives on community-building projects, or EA meta organizations\u2019 updates.&nbsp;</p><p>I share a lot of the relevant content in the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/bi9WWR58m45GJG7bc/forum-digest-reminder-that-it-exists-and-request-for\"><u>Forum Digest</u></a>, so I hope this will help. And there\u2019s&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vs8FFnPfKnitAhcJb/community-posts-have-their-own-section-subforums-are-closing?commentId=MvGAAnZy3RCBhtnLX#comments\"><u>a workaround</u></a> for some issues like this.&nbsp;</p><p>And unfortunately, I think we\u2019ll always have posts that some people would like to see outside of the Community section \u2014 people don\u2019t agree on where the line should be. I endorse the current classification because it makes sense (in that it doesn\u2019t seem significantly gerrymandered or overfitted to the feedback that we\u2019re getting or to our experience on specific posts, it tracks&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/dDudLPHv7AgPLrzef/karma-overrates-some-topics-resulting-issues-and-potential\"><u>this dynamic</u></a>, and seems like a mostly \u201creal\u201d category). But we might modify it somewhat in the future. (There were also issues with all the other proposals we considered. E.g. we considered excluding some update-style posts from the Community classification, but we worried that this would create an asymmetry between posts by organizations and posts criticizing the organizations, and we did not want to do that.)</p><p><strong>Implementation suggestions or requests</strong></p><p>We got a lot of pretty specific feedback on how the Community section currently works, like suggestions that we should:</p><ol><li>Add a \u201cload more\u201d button on the Community section<ol><li>Some people on the team (including me) agree that this is something we should have, but we\u2019re currently not prioritizing it.&nbsp;</li></ol></li><li>Display more posts in the section<ol><li>We currently think that 3 is the right number of posts, but we might reconsider.&nbsp;</li></ol></li><li>Develop some customization options for users, like the option of hiding the section entirely and possibly the option of setting a specific number of posts to see in that section<ol><li>For hiding the section: for now, we\u2019ve decided to make the section collapsible, and the Forum should remember the setting you left it on. We\u2019ll keep tracking this, though, in case people still feel like they find themselves engaging in Community discussions against their better judgement. (The section will be collapsed to start with \u2014 more on this <a href=\"https://forum.effectivealtruism.org/posts/sLB6tEovv7jDkEghG/design-changes-and-the-community-post-section-forum-update#2__The_Community_section_on_the_Frontpage_is_collapsible_expandable__and_collapsed_to_start_with_\">below</a>.)</li><li>Very few people end up using customization options like this, so we haven\u2019t prioritized this, although we might get to some of these options at some point \u2014 it\u2019ll somewhat depend on where other projects go.&nbsp;</li></ol></li><li>Assorted other suggestions<ol><li>We really appreciated all the feedback, and will continue to consider it as we work on the section.&nbsp;</li></ol></li></ol><h2>Looking forward</h2><p>We\u2019re viewing the Community section as a sort of bandaid on some of the issues with the Forum right now. It seems to be an effective bandaid, so we\u2019re keeping it for now (potentially with some changes), but we\u2019re also trying to investigate the causes of the broader problems and see what we can do about them.&nbsp;</p><p>Some of the broader problems include:&nbsp;</p><ul><li>Quality of discussion not being what we want it to be</li><li>Users don\u2019t always see the content that is most useful for them</li><li>New users are disoriented and put off</li><li>People feel stressed and bad after using the Forum</li></ul><p>We\u2019re exploring a fairly wide range of changes to the site and to Forum support/facilitation/moderation to try to address sub-problems of the above, and we\u2019ll likely be testing some soon.</p><p>Depending on how all that goes, we might modify the current setup with the Community section.</p><h1>Forum redesign</h1><p>The site\u2019s design was (and continues to be) imperfect in various ways:</p><ol><li>The Forum can be disorienting to new users; it\u2019s hard to navigate, know what people are talking about, and understand how things like voting work.&nbsp;</li><li>People sometimes discover a hidden feature that they wish they\u2019d known about sooner, which could be a failure of how we organize the site.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefc8hx6p71pxk\"><sup><a href=\"#fnc8hx6p71pxk\">[5]</a></sup></span></li><li>We\u2019d like to give people the information they need to decide what content to engage with.</li><li>People have trouble identifying which posts will be relevant for them, and keeping up with the topics or discussions they\u2019re interested in.&nbsp;</li><li>It\u2019s often hard to use the Forum on mobile devices.&nbsp;</li><li>The design is inconsistent and pretty outdated in some ways.</li><li>And more.&nbsp;</li></ol><p>So <strong>we\u2019ve made an update to the design of the Forum</strong>, which we hadn\u2019t changed in a while.&nbsp;</p><p>The redesign didn\u2019t solve all the issues above, and we don\u2019t think it\u2019s final. We expect to keep iterating on the design based on feedback and data we get about how people use the different features. (For instance, it may turn out that a feature whose prominence we just increased based on (2) above isn\u2019t getting significantly more use, in which case we\u2019d hide it again.)&nbsp;</p><p>Please don\u2019t hesitate to share your feedback here, in&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSeSpasc7-Lkls1ZoF2V1m9HbtbCHvXMhyNCnt0GhAIi5wcbfQ/viewform?usp=sf_link\"><u>the survey</u></a>, or at&nbsp;<a href=\"mailto:forum@centreforeffectivealtruism.org\"><u>forum@centreforeffectivealtruism.org</u></a>.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sLB6tEovv7jDkEghG/z9xediho7vaoutil78mx\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sLB6tEovv7jDkEghG/xlsjbekpozkmhh6wyflr\"></p><h2>What are the changes?</h2><p><strong>1. Topic tabs on the Frontpage</strong></p><p>You can now visit tabs on the Frontpage that let you see only the posts that have been tagged with that core topic.&nbsp;</p><p>We hope that this will help semi-regular users get quick overviews of what\u2019s been happening in their fields of interest (and avoid missing posts that would have been useful for them), and that it will help people new to EA go deeper on topics relevant to them.&nbsp;</p><p><strong>2. The Community section on the Frontpage is collapsible/expandable (and collapsed to start with)</strong></p><p>Some people have asked for a way to hide the Community section entirely from the Frontpage, and we know that some people worry that they\u2019re getting sucked into Community discussions they don\u2019t endorse engaging with. We\u2019ve made the section collapsible/expandable; the site will remember whether you last left the section collapsed or expanded, and keep it like that for the next time you visit.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb19vopavmjs\"><sup><a href=\"#fnb19vopavmjs\">[6]</a></sup></span></p><p>By default, we\u2019ve chosen to collapse the section. This is largely because of the \u201cgetting sucked in\u201d dynamics described above, and because discussions in the Community section seem like they\u2019d be less relevant to people who are less involved with the community and those who are newer to the Forum (we think a large portion of Forum users \u2014 especially people who are logged out \u2014 aren\u2019t involved with the EA community). We might reverse this if we see a noticeable drop in engagement with that section and depending on the feedback we get.&nbsp;</p><p><strong>3. New information on posts on the Frontpage and other changes in the information displayed in various places (by default)</strong></p><p>A quick list:&nbsp;</p><ol><li>The Frontpage list of posts now displays reading time (and we made bookmarking more prominent).&nbsp;</li><li>We\u2019ve changed what we include in the left sidebar.</li></ol><p><strong>4. We changed fonts and styles in various places</strong></p><p>Most of this is about usability and consistency.&nbsp;</p><h1>Assorted other changes</h1><ol><li>We displayed side-comments on posts for a while (comments that were responding to a particular excerpt were displayed next to the post itself). We\u2019ve reverted that, as it seemed to be distracting and confusing users.&nbsp;</li><li>You can now hide Community posts from the&nbsp;<a href=\"https://forum.effectivealtruism.org/allPosts\"><u>All Posts</u></a> page. Community posts often get a lot of karma, so sorting by \u201cTop\u201d or \u201cTop (inflation-adjusted)\u201d showed a lot of Community posts and seemed to give people an incorrect understanding of what the EA community cares about (see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/dDudLPHv7AgPLrzef/karma-overrates-some-topics-resulting-issues-and-potential#This_leads_to_some_issues_\"><u>here</u></a>).&nbsp;</li><li>We fixed the&nbsp;<a href=\"https://forum.effectivealtruism.org/events\"><u>Events page</u></a> so that events properly appear based on the user\u2019s location.&nbsp;</li></ol><h1>Other things we\u2019re working on or are considering working on</h1><p>We\u2019ve been gathering more data on how people are using the Forum and what they\u2019d like to change about that (you may have seen a survey about this).&nbsp;</p><p>In brief, we\u2019re looking into things like:&nbsp;</p><ul><li>Making versions of the Frontpage sorting algorithm that work better for users who visit the Forum more or less frequently</li><li>Exploring changes to karma</li><li>Developing a \u201ccard\u201d view to give people previews of posts</li><li>Seeing if language models can improve discussions</li><li>Improving shortform discussions</li><li>Differentiating between different types of posts (threads, blog posts, opportunity announcements, etc.)</li><li>Developing and better-featuring recommendations for content Forum users should engage with, based on their activity on the Forum</li></ul><p>This isn\u2019t an exhaustive list (and it focuses primarily on future&nbsp;<i>product</i> changes), but I wanted to share it in case it gives people a sense for what we\u2019re working on. As always, feel free to suggest features&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/NhSBgYq55BFs7t2cA/ea-forum-feature-suggestion-thread\"><u>here</u></a>.&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6kaey5fls3y\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6kaey5fls3y\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This post was mostly written by Lizka (and then reviewed by others on the team), but most of the work was not done by me! Agnes is the Forum's designer, and a lot of the people on the team worked on the changes we're talking about. Thanks to <a href=\"https://forum.effectivealtruism.org/users/imben?mention=user\">@Clifford</a> for work on the Community section, to <a href=\"https://forum.effectivealtruism.org/users/sharang-phadke-1?mention=user\">@Sharang Phadke</a> for work on the redesign, and <a href=\"https://forum.effectivealtruism.org/users/ollie-etherington?mention=user\">@Ollie Etherington</a> and <a href=\"https://forum.effectivealtruism.org/users/syc?mention=user\">@Sarah Cheng</a> for implementing the UI .</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz4zmtgvcxd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz4zmtgvcxd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I wish we\u2019d made some concrete predictions here, but oh well.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnocf97lxt0s7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefocf97lxt0s7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There\u2019s also a scrappy quiz that I made for people to get calibrated. I don\u2019t want to share it entirely publicly, as it\u2019s got serious flaws and I don\u2019t want to spend more time improving it right now, but you can reach out and I\u2019ll try to share a version with you.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnclssmy48anr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefclssmy48anr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Have I mentioned that I wish we had made some concrete predictions?</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnc8hx6p71pxk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefc8hx6p71pxk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>(The existence of the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Y8gkABpa9R6ktkhYt/forum-user-manual\"><u>Forum user manual</u></a> is also a result of this failure.)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb19vopavmjs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb19vopavmjs\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We considered adding it as an option in site customization settings, but unfortunately, very few people use customization options like this, so we didn\u2019t think that would be a good solution. Making the section visibly collapsible solves this problem (and it\u2019s a common interface on many websites).</p></div></li></ol>", "user": {"username": "Lizka"}}, {"_id": "dfwuHD69keSEj6mBN", "title": "New 'South Park' episode on AI & Chat GPT ", "postedAt": "2023-03-21T20:06:32.390Z", "htmlBody": "<p>In case anyone's a fan of the US animated TV series 'South Park', a recent episode (Season 26, Episode 4, released March 9, 2023) is titled 'Deep Learning', and features AI &amp; Chat GPT themes. (Link <a href=\"https://southpark.cc.com/episodes/8byci4/south-park-deep-learning-season-26-ep-4\">here</a> if you want to watch with ads; otherwise it's on HBO Max or Comedy Central streaming services.)</p><p>Curious what your reactions are....</p>", "user": {"username": "geoffreymiller"}}, {"_id": "pvZwc3wmTdKfQRorR", "title": "Free coaching sessions", "postedAt": "2023-03-21T22:31:47.150Z", "htmlBody": "<p>I\u2019m offering free one-on-one coaching sessions to autistic people in the EA community. I\u2019m autistic myself and have provided direct support to autistic people for over 9 years.&nbsp;</p><p>My sessions focus on self-discovery, skill-development, and finding solutions to common challenges related to being autistic. It can also be nice to talk to someone else who just gets it.&nbsp;</p><p>Send me a message if you're interested in free coaching sessions, want to learn more, or just want to connect. You can also book a 30-minute introductory meeting with me here: <a href=\"https://calendly.com/monicadiazaf/30-minute-initial-consultation\">https://calendly.com/monicadiazaf/30-minute-initial-consultation</a></p><p>UPDATE 4/10/23: I've received a really positive response and have had several people start coaching sessions. For now, I have reached my capacity. If you're still interested, I can add you to my waitlist. Send me an e-mail at <a href=\"mailto:monica@autisticfreedom.com\">monica@autisticfreedom.com</a></p>", "user": {"username": "Monica Diaz"}}, {"_id": "YrXZ3pRvFuH8SJaay", "title": "Reflecting on the Last Year \u2014 Lessons for EA (opening keynote at EAG)", "postedAt": "2023-03-24T15:35:35.456Z", "htmlBody": "<p>I recently delivered the opening talk for EA Global: Bay Area 2023. I reflect on FTX, the differences between EA and utilitarianism, and the importance of character. Here's the recording and transcript.</p><figure class=\"media\"><div data-oembed-url=\"https://youtu.be/3a6xb6vj6AA\"><div><iframe src=\"https://www.youtube.com/embed/3a6xb6vj6AA\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>&nbsp;</p><h2><strong>The Last Year</strong></h2><p>Let\u2019s talk a bit about the last year.</p><p>The spring and summer of 2022 were a time of rapid change.&nbsp;A second major donor had appeared, roughly doubling the amount of committed money. There was a plan to donate this new money more rapidly, and to use more of it directly on projects run by people in the EA community. Together, this meant much more funding for projects led by EAs or about effective altruism.</p><p>It felt like a time of massive acceleration, with EA rapidly changing and growing in an attempt to find enough ways to use this money productively and avoid it going to waste. This caused a bunch of growing pains and distortions.</p><p>When there was very little money in effective altruism, you always knew that the person next to you couldn\u2019t have been in it for the money \u2014 so they must have been in it because they were passionate about what they were doing for the world. But that became harder to tell, making trust harder.</p><p>And the most famous person in crypto had become the most famous person in EA. So someone whose views and actions were quite radical and unrepresentative of most EAs, became the most public face of effective altruism, distorting public perception and even our self-perception of what it meant to be an EA. It also meant that EA became more closely connected to an industry that was widely perceived as sketchy. One that involved a product of disputed social value, and a lot of sharks.</p><p>One thing that especially concerned me was a great deal of money going into politics. We\u2019d tried very hard over the previous 10 years to avoid EA being seen as a left or right issue \u2014 immediately alienating half the population. But a single large donor had the potential to change that unilaterally.</p><p>And EA became extremely visible: people who\u2019d never heard of it all of a sudden couldn\u2019t get away from it, prompting a great deal of public criticism.</p><p>From my perspective at the time, it was hard to tell whether or not the benefits of additional funding for good causes outweighed these costs \u2014 both were large and hard to compare. Even the people who thought it was worth the costs shared the feelings of visceral acceleration: like a white knuckled fairground ride, pushing us up to vertiginous heights faster than we were comfortable with.</p><p>And that was just the <i>ascent</i>.</p><p>Like many of us, I was paying attention to the problems involved in the rise, and was blindsided by the fall.</p><p>As facts started to become more clear, we saw that the companies producing this newfound income had been very poorly governed, allowing behaviour that appears to me to have been both immoral and illegal \u2014 in particular, it seems that when the trading arm had foundered, customers\u2019 own deposits were raided to pay for an increasingly desperate series of bets to save the company.</p><p>Even if that strategy had worked and the money was restored to the customers, I still think it would have been illegal and immoral. But it didn\u2019t work, so it also caused a truly vast amount of harm. Most directly and importantly to the customers, but also to a host of other parties, including the members of the EA community and thus all the people and animals we are trying to help.</p><p>I\u2019m sure most of your have thought a lot about this over last few months. I\u2019ve come to think of my own attempts to process this as going through these four phases.&nbsp;</p><p>First, there\u2019s: <i><strong>Understanding what happened</strong>.</i></p><ul><li>What were the facts on the ground?</li><li>Were crimes committed?</li><li>How much money have customer\u2019s lost?</li><li>A lot of this is still unknown.</li></ul><p>Second, there\u2019s: <i><strong>Working out the role EA played in it, and the effect it had on EA</strong>.</i></p><ul><li>Is EA to blame? Is EA a victim? \u2014Both?</li><li>How should we think about it when a few members of a very large and informal group do something wrong, when this is against the wishes of almost all the others, who are earnestly and conscientiously working to help the less fortunate?</li><li>Yet we can\u2019t just dismiss this as exceptionally rare and atypical actions. It is an important insight of EA that the total value of something can often be driven by a few outliers. We are happy to claim those atypical cases when they do great amounts of good, but we\u2019ve see that the harms can be driven by outliers too.</li></ul><p>Third, there\u2019s: <i><strong>Working out how best to move forward</strong>.</i></p><ul><li>This is clearly an opportunity to learn how to avoid things like this ever happening again.</li><li>Which lessons should we be learning?</li><li>It\u2019s a time for thinking about new ideas for improving EA and revisiting some old ideas we\u2019d neglected.</li></ul><p>Finally, there\u2019s: <i><strong>Getting back to projects for helping make the world a better place</strong>.</i></p><ul><li>This is what EA is fundamentally all about \u2014 what inspires us.</li><li>It\u2019s what we ultimately need to return to, and what many of us need to keep on doing, even while others help work out which lessons we should be learning.</li></ul><p>Different people here will be at different stages of this processing. And that\u2019s fine.</p><p>This morning, I want to explore some ideas about the third step \u2014 working out how to best move forward.</p><h2><strong>Utilitarianism &amp; Effective Altruism</strong></h2><p>Let me begin by taking you back in time 20 years to the beginnings of effective altruism. In 2003 I arrived in Oxford from Australia, fresh-faced and excited to get to study philosophy at a university that was older than the Aztec empire. Over the next 6 years, I completed a masters and doctorate, specialising in ethics.</p><p>One of the things I studied was a moral theory called <i>utilitarianism</i>. At its heart, utilitarianism consists of two claims about the nature of ethics:</p><p><i>1. The only thing that matters, morally speaking, is how good the outcome is.</i></p><p>This is a claim about the structure of ethics. It says it ethics just about outcomes (or consequences). On its own, we call this claim <i>consequentialism</i>.</p><p>Utilitarianism combines this with a claim about the content of ethics:</p><p><i>2. The value of an outcome is the total wellbeing of all individuals.</i></p><p>This was a radical moral theory. It is easy to forget, but one of the most radical ideas was that all beings mattered equally: women as well as men; people of all countries, religions and races; animals.</p><p>It was an attempt to free moral thinking from dogma and superstition, by requiring morality to be grounded in actual benefits or losses for individuals.&nbsp;</p><p>And it had practical reforming power. It wasn\u2019t just a new way of explaining what we already believed, but could be used to find out what we were getting wrong \u2014 and fix it. In doing so, it was ahead of the curve on many issues:</p><ul><li>individual and economic freedom</li><li>separation of church and state</li><li>equal rights for women</li><li>the right to divorce</li><li>decriminalization of homosexuality</li><li>abolition of slavery</li><li>abolition of death penalty</li><li>abolition of corporal punishment</li><li>respecting animal welfare</li></ul><p>Utilitarians spoke out in favour of all these things you see here, long before they were socially accepted.</p><p>But for all that, it was, and remains, a very controversial theory. It has no limits on what actions can be taken if they promote the overall good. And no limit on what morality can demand of you. It offers no role for the intentions behind an act to matter, and makes no distinction between not helping people or actively harming them. Moreover, it allows no role for ultimate values other than happiness and suffering.</p><p>And ultimately, I don\u2019t endorse it. The best versions are more sophisticated than the critics recognise and better than most people think. But there are still cases where I feel it reaches the wrong conclusion. And it is very brittle \u2014 imperfect attempts to follow it can lead to very bad outcomes.</p><p>However, there are also key parts of utilitarianism that are <i>not</i> controversial. It is not controversial that outcomes really matter. As the famous opponent of utilitarianism, John Rawls, put it:</p><p>\u2018All ethical doctrines worth our attention take consequences into account in judging rightness. One which did not would simply be irrational, <i>crazy</i>.\u2019&nbsp;</p><p>And it is not controversial that a key part of these consequences is the effect on people\u2019s wellbeing.</p><p>As I studied utilitarianism, I saw some key things that became clear through that lens, but which weren\u2019t often discussed.</p><p>One was the moral importance of producing <i>positive</i> outcomes. Most ethical thought focuses on avoiding harm or mistreatment. It accepts that actively helping people is great, but says very little about how to do it, or that it could be truly important.</p><p>And another was caring about <i>how much</i> good we do: the idea that giving a benefit to ten people is ten times more important than giving it to one.</p><p>I saw that these two principles had surprising and neglected implications, especially when combined with empirical facts about cost-effectiveness in global health. They showed that the fact that each person living in a rich country could save about 100 lives if they really wanted to is a key part of our moral predicament.</p><p>And they showed that when people (or nations) donate to help others, it really matters where they give: it\u2019s the difference between whether they end up fulfilling just 1% of their potential or 100%. It\u2019s almost everything.</p><p>These principles were not especially controversial \u2014 but they were almost completely neglected by moral thinkers \u2014 even those focusing on global health or global poverty. I wondered: could I build a broad tent around these robustly good ideas that the utilitarians had found?</p><p>I could leave behind the controversial claims of utilitarianism:</p><ul><li>that only effects on wellbeing mattered</li><li>that these should be simply added together</li><li>and that wellbeing only took only the form of happiness and suffering.</li></ul><p>Instead, I could allow people to combine the ideas about the importance of doing good at scale with almost any other approach to moral thinking they may have started with. It was a place where one could draw surprisingly strong practical conclusions from surprisingly weak assumptions.</p><p>Because of the focus on the positive parts of moral life, I started calling this approach \u2018positive ethics\u2019 in 2010 and it was one of the main ingredients of what by 2012 we\u2019d started calling \u2018effective altruism\u2019.</p><p>Unlike utilitarianism, effective altruism is not a moral theory. It is only a partial guide. It doesn\u2019t say \u2018that is all there is to ethics or value\u2019. And it\u2019s compatible with a real diversity of approaches to ethics: side-constraints,&nbsp;options, the distinction between acts and omissions,&nbsp;egalitarianism,&nbsp;allowing the intentions behind an act to matter, and so on.</p><p>Indeed, it is compatible with almost anything, just so long as we can still agree that saving a life is a big deal, and saving ten is a ten times bigger deal.</p><p>But if a way of helping a lot of people or animals conflicted with these other parts of ethics, you would want to stop and seriously think about what to do. Are there alternatives that get most of the value while avoiding these other problems? And how should one make the right trade-offs?</p><p>Effective altruism itself doesn\u2019t have much to say about resolving such conflicts. Like similar guides to action such as environmentalism or feminism, it isn\u2019t trying to be a complete theory. All three point to something important that others are neglecting, but don\u2019t attempt to define how important all other facets of moral life are in comparison so that one can resolve these conflicts. Instead it is taken for granted that people from many different moral outlooks can join in the projects of environmentalism or feminism \u2014 or effective altruism.</p><p>To the extent that EA has been prescriptive about such things, it is generally to endorse widely held prohibitions on action. For example, in <i>The Precipice</i> I wrote:</p><blockquote><p><i>Don\u2019t act without integrity</i>. When something immensely important is at stake and others are dragging their feet, people feel licensed to do whatever it takes to succeed. We must never give in to such temptation. A single person acting without integrity could stain the whole cause and damage everything we hope to achieve.</p></blockquote><p>Others have made similar statements. I\u2019d thought they were really quite explicit and clear. But I certainly wish we\u2019d made them even more clear.</p><h2><strong>Lessons from the Philosophy of Doing Good</strong></h2><p>I think EA may still have more to learn from the centuries of philosophical thought on producing good outcomes.</p><p>A common definition of Utilitarianism is that:</p><blockquote><p>An act is right if and only if it maximises total wellbeing.</p></blockquote><p>There are two key problems with this way of defining it: the focus on <i>maximising;</i> and the sole focus on <i>acts</i>.</p><p>Here is a simplified case to help explain why maximisation isn\u2019t quite the right idea, even in theory:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/oxh3mtbuqvne4febzpyp\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/higtl2few1pgssgf2nzq 158w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/oe4xjtn2rpbt2r76ygfk 238w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/dmz5a2zetm9anamcybit 318w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/xcecupohkjaczl0o4equ 398w\"></p><p>You have three options: save 1 life, save 99 lives, or save 100 lives. I think the big difference is between <i>A</i>and the others. Of these options, <i>A</i> is mediocre, while the other two are great.&nbsp;But maximisation says the big difference is between <i>C</i> and the others. <i>C</i> is maximal and therefore right, while the others are both wrong.</p><p>I don\u2019t think that is a good representation of what is going on here morally speaking. Sure, if you can get the maximum \u2014 great; that\u2019s even better. But it\u2019s just not that important compared to getting most of the way there. The moral importance at stake is really <i>scalar</i>, not binary.</p><p>And here is a case that helps explain why maximisation can be dangerous in practice:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/wgpdgm4jjfl9kum96wvu\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/aujzk42xgyf5znlkzeg0 120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/ectabgjipbhwpobtq4yk 240w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/bnoescjzpqlpblxbowph 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/btvvpnm9qlsvdbwl1map 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/bkcxjel6qwgzgl3f3ido 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/kd29n4kmd8h5cqtnv1tj 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/g4vrcnpttbdgxnuxnwof 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/c0js07rjcr3ootyj25il 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/rwkfz42dybplarptwofv 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YrXZ3pRvFuH8SJaay/tdzap0ioslj067gvfdjw 1194w\"></p><p>The vertical axis is supposed to represent how good the outcome will be, while the horizontal axis represents how much optimisation pressure is being brought to bear.</p><p>First let\u2019s consider what happens if goodness is defined in terms of total happiness and you are optimising for total happiness. This is the gold curve: the situation gets better, but perhaps with diminishing returns. But what happens if you are still optimising for total happiness but we are considering things from a different value system, where happiness matters, but other things do too. This is the red curve: it starts off improving, but as you get close to full optimisation, lots of the other things are lost in order to eke out a bit more happiness. The same would be true for many other value systems (such as the grey curve).</p><p>You could think of this as an argument for the fragility of maximisation \u2014 if the thing you are maximising is even slightly off, it can go very wrong in the extremes. As Holden Karnofsky put it, in a <a href=\"https://forum.effectivealtruism.org/posts/T975ydo3mx8onH3iS/ea-is-about-maximization-and-maximization-is-perilous\"><u>rather prescient article</u></a>: \u2018Maximization is Perilous\u2019.</p><p>This is a problem when you have any moral uncertainty at all. And even if you were dead certain that utilitarianism was right, it would be a problem if you are trying to work together in a community with other people who also want to do good, but have different conceptions of what that means \u2014 it is more cooperative and more robust to not go all the way. (Some of you will note that this is the same argument for how things can go wrong if an AI were to truly maximise its reward function.)</p><p>As it happens, some of the earliest formulations of utilitarianism, such as John Stuart Mill\u2019s were scalar rather than maximising, and more recent utilitarians seem to be converging on that being the best way. I think that effective altruism would do well to learn this lesson too. A focus on <i>excellence</i> rather than <i>perfection</i>. A focus on the idea that scale matters: that getting twice as much benefit matters as much as all that you achieved so far, so it is really worth seeing if you can reach that rather than settling for doing quite a lot of good. But not a fixation on the absolute maximum \u2014 on getting from 99% to 100%.</p><p>How should a utilitarian go about deciding what to do? The most common, unreflective, answer is to make all your decisions by constantly calculating which act has the best consequences. Most people who teach ethics at universities imply that this is part and parcel of what utilitarianism means. And they may then point out that this is <i>self-defeating</i>: due to a range of human imperfections and biases, it is likely to lead to a worse outcome, even by utilitarian measures.</p><p>But utilitarian philosophers don\u2019t recommend it. Indeed for over 200 years, they have explicitly called it out as a mistaken interpretation of their theory, and it has come to be known as \u2018Na\u00efve Utilitarianism\u2019. Instead, they recommend making decisions in a way that will lead to good outcomes \u2014 <i>whatever that method happens to be</i>. If following common-sense morality would lead to the best outcomes, then by all means use that.&nbsp;</p><p>They see utilitarianism as an idealised <i>criterion</i> that ultimately grounds what it means for one choice to be better than another \u2014 that it leads to a better outcome. But they distinguish this from a <i>decision procedure</i>for day-to-day use.</p><p>The same is true for motives. Universal benevolence sounds very utilitarian, but it is not always the best motive. Motives should be assessed in terms of the outcomes they lead to. Even Jeremy Bentham explicitly said this. It is OK to do things out of love for particular people or out of rage at injustice.</p><p>More recently, some consequentialist philosophers (those who are committed to outcomes being the only things that matter, but not to what makes an outcome good) have tried to systematize this thinking. They put forward an approach called <i>global consequentialism</i> that says to assess <i>every</i> kind of focal point in terms of the quality of outcome it leads to: acts, decision procedures, motives, character traits, institutions, laws \u2014 you name it.</p><p>Believe it or not, I\u2019ve actually written a book about this.</p><p>This was the topic of my dissertation at Oxford. And while lots of dissertations are a pretty miserable read, I went to a lot of effort to write it as a readable book (albeit an academic book!). The idea was to publish it when I finished, but one month after I finished my thesis I met a student called William MacAskill, and got distracted.</p><p>I\u2019m still distracted, and not sure when that will end, so as of this morning, I put the <a href=\"http://files.tobyord.com/beyond-action.pdf\"><u>full text</u></a> up on my <a href=\"http://www.tobyord.com/\"><u>website</u></a>.</p><p>It starts by observing that the three main traditions in Western philosophy each emphasize a different focal point:</p><p>Consequentialism emphasises <i>Acts.</i></p><p>And from a certain perspective it can seem like that covers everything in ethics: every single time you are deciding what to <i>do</i> you are assessing acts. Isn\u2019t ethics about deciding what to do?&nbsp;</p><p>Deontology emphasises <i>Rules.</i></p><p>And from a certain perspective it can seem like that covers everything in ethics: ethics is a system of rules governing action. Rules are closely related to what we called \u2018decision procedures\u2019 a moment ago. And isn\u2019t ethics about how we should decide what to do? (i.e. which decision procedure to follow?)</p><p>Virtue ethics emphasises <i>Character.</i></p><p>And from a certain perspective it can seem like that is what ethics is all about: what makes someone a good person? How can I live a more virtuous life?</p><p>But interestingly, these don\u2019t really have to be in disagreement with each other. It is almost like they are talking past each other. So I thought: <i>could there be a way of unifying these three traditions?</i></p><p>One thing I had to do was to provide a coherent theory of global consequentialism \u2014 one that ties up some loose ends in the earlier formulations and is logically sound. Then armed with that, I showed how it has the resources to capture many of the key intuitions about rules and character that make deontology and virtue ethics compelling. To use an analogy of my supervisor, Derek Parfit, it was like all three traditions had been climbing the same mountain, but from different sides.&nbsp;</p><p>If Na\u00efve Utilitarianism leads to bad outcomes, what kind of decision procedure leads to good outcomes? Here\u2019s my best guess:&nbsp;</p><ul><li><i>Stay close to common-sense on almost everything.</i></li></ul><p>It encodes the accumulated wisdom of thousands of years of civilisation (and hundreds of thousands of years before that). Indeed, even when the stated reasons for some rule are wrong, the rule itself can still be right \u2014 preserved because it leads to good outcomes, even if we never found out why.</p><ul><li><i>Don\u2019t trust common-sense morality fully \u2014 but trust your deviations from it even less.</i></li></ul><p>It has survived thousands of years; your clever idea might not survive even one.</p><ul><li><i>Explore various ways common-sense might be importantly wrong.</i></li></ul><p>Discuss them with friends and colleagues. There have been major changes to common-sense morality before, and finding them is extremely valuable.</p><ul><li><i>Make one or two big bets.&nbsp;</i></li></ul><p>For example mine were that giving to the most cost-effective charities is a key part of a moral life and that avoiding existential risk is a key problem of our time.</p><ul><li><i>But then keep testing these ideas.</i></li></ul><p>Listen to what critics say \u2014 most new moral ideas are wrong.</p><ul><li><i>And don\u2019t break common-sense rules to fulfil your new ideas.</i></li></ul><p>&nbsp;</p><p>What about character? We can assess people\u2019s characters (and individual character traits) by their tendency to produce good outcomes. The philosopher Julia Driver&nbsp;<a href=\"https://books.google.je/books?id=pb-cUEXPvz0C&amp;printsec=copyright#v=onepage&amp;q&amp;f=false\"><u>pioneered this approach</u></a>.</p><p>We can go through various character traits and think about whether they are conducive to good outcomes, calling those that <i>are</i> conducive \u2018virtues\u2019. This will pick out character traits that have much in common with the classical conception of virtues. They are not knowable by pure reason or introspection, but require experience.</p><p>I think the importance of character is seriously neglected in EA circles. Perhaps one reason is that unlike many other areas, we don\u2019t have comparative advantage when it comes to identifying virtues. This means that we should draw on the accumulated wisdom as a starting point.</p><p>Here are some virtues to consider.</p><p>There are virtues that help anyone achieve their aims, even if they were living on a desert island. These are less distinctively moral, but worth having. Things like: patience, determination, and prudence.</p><p>There are virtues relating to how we interact with others. Such as: generosity, compassion, humility, integrity, and honesty. I think we\u2019re pretty good at generosity and compassion, actually. And sometimes good at humility too.&nbsp;</p><p>I think integrity deserves more focus than we give it. It is about consistently living up to your values; acting in a principled way in private \u2014 living up to your professed values even when no-one else is there to see. One of the features of integrity is that it allows others to trust your actions, just as honesty allows them to trust your words.</p><p>Another interesting set of character traits, that are not always identified as virtues are things like: authenticity, earnestness, and sincerity. I think these are character traits we could stand to see more of in EA.</p><p>An earnest disposition allows your motivation to be transparent to others \u2014 for everyone to be able to see the values that guide you. I think most of us who are drawn to effective altruism start with a lot earnestness, but then lose some over time \u2014 either to wanting to join the cool kids in their jaded cynicism, or to thinking it must be better to wear a poker face and choose your words carefully.</p><p>But the thing about earnestness is that it forces you to be honest and straightforward. If someone talks of something while brimming with earnest enthusiasm, it is transparent to all that they care about it. That it isn\u2019t some kind of ploy. I think this is especially important for EA. Lots of people think we must have some kind of ulterior motives. But we often don\u2019t. If we are cynical or detached, people can\u2019t know either way. But earnestness and unabashed excitement is something that is hard to fake, so helps prove good intent.</p><p>Armed with this focus on character, one obvious thing to do is to try to inculcate such virtues in ourselves: to put effort into developing and maintaining these character traits. But that is not the whole story. We should also try to promote and reward good character in others. And we should avoid vouching for people with flawed characters, or joining their projects. Even if you aren\u2019t sure that someone has a flawed character, if you have doubts, be careful. And we should put more focus on character into our community standards.</p><p>Is character really as important as other focal points, like selecting causes or interventions?</p><p>For some choices, <a href=\"https://80000hours.org/2023/02/how-much-do-solutions-differ-in-effectiveness/\"><u>the best options are hundreds of times better than the typical ones</u></a>; thousands of times better than poor ones. This was <a href=\"https://www.cgdev.org/sites/default/files/1427016_file_moral_imperative_cost_effectiveness.pdf\"><u>one of the earliest results of EA</u></a> \u2014 By really focusing on finding the very best charities, we can have outsized impact.</p><p>Am I saying that the same is true for character?&nbsp;That instead of trying to find the most amazing charity, we would do just as well if EA was all about having the most amazing character possible?</p><p>No.&nbsp;It\u2019s important in a different way.</p><p>I think a really simple model of the impact of character goes like this:</p><p>The inherent quality of character doesn\u2019t vary anywhere near as much. Imagine a factor that ranges from something like \u20135 to +5, where 1 is the typical value. And this factor acts as a <i>multiplier</i> for impact. The bigger the kind of impact someone is planning, the more important it is that they have good character. If they have an unusually good character, they might be able to create substantially more impact. But if they have a particularly flawed character, the whole thing could go into reverse. This is especially true if their impact goes via an indirect route like first accumulating money or power.</p><p>Now, <i>charities</i> can also end up having negative cost-effectiveness \u2014 where the more money you donate, the worse things are. But in our community we spend so much time on evaluating them, that we can usually avoid the negative ones and are trying to distinguish the good from the great. But we don\u2019t have anything like the same focus on character, so we run a much greater risk of having people whose character is a negative multiplier on their impact. And the higher impact their work is, the more that matters.</p><p>&nbsp;</p><p>Let\u2019s take a moment to return to what happened at FTX last year.&nbsp;</p><p>I don\u2019t think anyone fully understands what motivated Sam (or anyone else who was involved). I don\u2019t know how much of it was greed, vanity, pride, shame, or genuinely trying to do good. But one thing we do know is that he was already a committed utilitarian before he even heard about EA.&nbsp;</p><p>And it increasingly seems he was that most dangerous of things \u2014 a naive utilitarian \u2014 making the kind of mistakes that philosophers (including the leading utilitarians) have warned of for centuries. He had heard of the various sophistications needed to get the theory to work but seems to have dismissed them as being \u2018soft\u2019.</p><p>If I\u2019m right, then what he thought of as hardcore bullet biting bravado was really just dangerous naivety. And the sophistications that he thought were just a sop to conventional values were actually essential parts of the only consistent form of the theory he said he endorsed.&nbsp;</p><h2><strong>Conclusion</strong></h2><p>I hope it was useful to see some of the history, and how effective altruism was in part designed to capture some of the uncontroversially good ideas that utilitarians had found, without the controversial commitments \u2014 that doing good at scale really matters (but not that nothing else matters).</p><p>It has been a hard year \u2014 and we haven\u2019t fully sorted through its import. But I\u2019m becoming excited about some of these new ways of moving forward and improving the ideas and community of effective altruism. And I\u2019m especially excited about getting back to the ultimate work of helping those who need us.</p>", "user": {"username": "Toby_Ord"}}, {"_id": "h5sJepiwGZLbK476N", "title": "Assessment of Happier Lives Institute\u2019s Cost-Effectiveness Analysis of StrongMinds", "postedAt": "2023-03-22T17:04:19.978Z", "htmlBody": "<p><em>Author: Alex Cohen, GiveWell Senior Researcher</em></p>\n<h2>In a nutshell</h2>\n<ul>\n<li>The Happier Lives Institute (HLI) has argued in a <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">series</a> <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">of</a> <a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\">posts</a> that GiveWell should use subjective well-being measures in our moral weights and that if we did, we would find StrongMinds, which provides group-based interpersonal psychotherapy (IPT-G), is as or more cost-effective than marginal funding to our top charities.</li>\n<li>This report provides our initial thoughts on HLI's assessment, based on a shallow review of the relevant literature and considerations.</li>\n<li>Our best guess is that StrongMinds is approximately 25% as cost-effective as our marginal funding opportunities. This assessment is based on several subjective adjustments, and we\u2019ve identified limited evidence to discipline these adjustments. As a result, we think a wide range of cost-effectiveness is possible (approximately 5% to 80% as cost-effective as our marginal funding opportunities), and additional research could lead to different conclusions.</li>\n</ul>\n<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3FFyQBDzsujs8pm8K/rixgivvseib7v0kdlng4\" alt=\"\"></p>\n<ul>\n<li>The main factors that cause us to believe StrongMinds is less cost-effective than HLI believes it is\u2014and that we are unsure about\u2014are:\n<ul>\n<li><em>Spillovers to household members</em>: It\u2019s possible that therapy for women served by StrongMinds benefits other members of their households. Our best guess is that the evidence HLI uses to estimate spillover effects overestimates spillovers, but we think it\u2019s possible that direct evidence on the effect of StrongMinds on non-recipients could lead to a different conclusion.</li>\n<li><em>Adjustments for internal validity of therapy studies</em>: In our analysis, we apply downward adjustments for social desirability bias and publication bias in studies of psychotherapy. Further desk research and conversation with experts could help inform adjustments for social desirability and publication bias.</li>\n<li><em>Lower effects outside of trial contexts</em>: Our general expectation is that programs implemented as part of randomized trials are higher quality than similar programs implemented at scale outside of trial settings. We expect forthcoming results from two randomized controlled trials (RCTs) of StrongMinds could provide an update on this question.</li>\n<li><em>Duration of effects of StrongMinds</em>: There is evidence for long-term effects for some lay-person-delivered psychotherapy programs but not IPT-G, and we\u2019re skeptical that a 4- to 8-week program like StrongMinds would have benefits that persist far beyond a year. We expect one of the forthcoming RCTs of StrongMinds, which has a 2-year follow-up, will provide an update on this question.</li>\n<li><em>Translating improvements in depression to life satisfaction scores</em>: HLI\u2019s subjective well-being approach requires translating effects of StrongMinds into effects on life satisfaction scores, but studies of psychotherapy generally do not report effects on life satisfaction. We think HLI overestimates the extent to which improvements in depression lead to increases in life satisfaction. However, we think direct evidence on the effect of StrongMinds on life satisfaction scores could update that view.</li>\n</ul>\n</li>\n<li>Comparing StrongMinds to our top charities relies heavily on one\u2019s moral views about the trade-off between StrongMinds\u2019 program and averting a death or improving a life. As a result, we also think it\u2019s important to understand what HLI\u2019s estimates imply about these trade-offs at a high level, in addition to considering the specific factors above. HLI\u2019s estimates imply, for example, that a donor would pick offering StrongMinds\u2019 intervention to 20 individuals over averting the death of a child, and that receiving StrongMinds\u2019 program is 80% as good for the recipient as an additional year of healthy life. We\u2019re uncertain about how much weight to put on these considerations, since these trade-offs are challenging to assess, but they seem unintuitive to us and further influence our belief that StrongMinds is less cost-effective than HLI\u2019s estimates.</li>\n<li>We may conduct further work on this topic, but we\u2019re uncertain about the timeline because even under optimistic scenarios, StrongMinds is less cost-effective than our marginal funding opportunities. If we did additional work, we would prioritize reviewing two forthcoming RCTs of StrongMinds and conducting additional desk research and conversations with subject matter experts to try to narrow our uncertainty on some of the key questions above.</li>\n</ul>\n<h2><strong>Background</strong></h2>\n<p>Group interpersonal psychotherapy (IPT-G) is a time-limited course of group therapy sessions which aims to tackle depression. StrongMinds implements an IPT-G program that specifically targets women with depression and consists of participants meeting with a facilitator in groups of five to ten, on average, for 90 minutes one to two times per week for four to eight weeks. <sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-1\" id=\"fnref-AEsP2mm8QjfePzYi6-1\">[1]</a></sup></p>\n<p>The Happier Lives Institute (HLI) has argued in a series of reports and posts that if we were to assess charities we recommend funding based on their impact on subjective well-being measures (like life satisfaction scores), StrongMinds\u2019 interpersonal group psychotherapy program would be competitive with Against Malaria Foundation (AMF), one of our top charities. <sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-2\" id=\"fnref-AEsP2mm8QjfePzYi6-2\">[2]</a></sup></p>\n<p>This report is intended to share our view of HLI\u2019s assessment and StrongMinds\u2019 cost-effectiveness, based on a shallow review of the relevant literature and considerations. It incorporates feedback we\u2019ve received from HLI on a previous (unpublished) draft of our work and follow-up research HLI has done since then.</p>\n<h2><strong>HLI\u2019s estimate of the cost-effectiveness of StrongMinds</strong></h2>\n<p>HLI estimates the effect of StrongMinds compared to AMF, one of our top charities, by measuring the impact of both on life satisfaction scores.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-3\" id=\"fnref-AEsP2mm8QjfePzYi6-3\">[3]</a></sup> Life satisfaction scores measure how people respond, on a scale from 0-10, to the question, \u201cAll things considered, how satisfied are you with your life as a whole these days?\"<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-4\" id=\"fnref-AEsP2mm8QjfePzYi6-4\">[4]</a></sup></p>\n<p>HLI estimates that psychotherapy from StrongMinds creates <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=76487430&amp;range=B20\">77 life satisfaction point-years (or WELLBYs) per $1,000 spent</a>.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-5\" id=\"fnref-AEsP2mm8QjfePzYi6-5\">[5]</a></sup> Summary of its calculations:</p>\n<ul>\n<li><strong>Main effect</strong>: It estimates that StrongMinds' program increases mental health scores among recipients of psychotherapy by 1.69 standard deviation (SD)-years.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-6\" id=\"fnref-AEsP2mm8QjfePzYi6-6\">[6]</a></sup> This is based on combining estimates from studies of programs similar to StrongMinds in low- and middle-income countries (Thurman et al. 2017, Bolton et al. 2007, Bolton et al. 2003), studies of StrongMinds, and a meta-regression of indirect evidence.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-7\" id=\"fnref-AEsP2mm8QjfePzYi6-7\">[7]</a></sup></li>\n<li><strong>Internal and external validity</strong>: In its meta-regression of indirect evidence, HLI includes adjustments for internal validity (including publication bias) and external validity (proxied by geographic overlap). These are reported relative to cash transfers studies.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-8\" id=\"fnref-AEsP2mm8QjfePzYi6-8\">[8]</a></sup> It notes that social desirability bias and concerns about effects being smaller at higher scale are excluded.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-9\" id=\"fnref-AEsP2mm8QjfePzYi6-9\">[9]</a></sup> These internal and external validity adjustments lead to a 90% discount for therapy relative to cash transfers.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-10\" id=\"fnref-AEsP2mm8QjfePzYi6-10\">[10]</a></sup></li>\n<li><strong>Spillovers</strong>: HLI estimates that non-recipients of the program in the recipient\u2019s household see 53% of the benefits of psychotherapy from StrongMinds and that each recipient lives in a household with 5.85 individuals.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-11\" id=\"fnref-AEsP2mm8QjfePzYi6-11\">[11]</a></sup> This is based on three studies (Kemp et al. 2009, Mutamba et al. 2018a, and Swartz et al. 2008) of therapy programs where recipients were selected based on negative shocks to children (e.g., automobile accident, children with nodding syndrome, children with psychiatric illness).<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-12\" id=\"fnref-AEsP2mm8QjfePzYi6-12\">[12]</a></sup> This leads to a 3.6x multiplier for other household members.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-13\" id=\"fnref-AEsP2mm8QjfePzYi6-13\">[13]</a></sup> The total benefit to the household is 6.06 SD-years.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-14\" id=\"fnref-AEsP2mm8QjfePzYi6-14\">[14]</a></sup></li>\n<li><strong>Translating depression scores into life satisfaction</strong>: To convert improvements in depression scores, measured in SDs, into life satisfaction scores, HLI assumes (i) 1 SD improvement in depression scores is equivalent to 1 SD improvement in life satisfaction scores and (ii) a 1 SD improvement in life satisfaction is 2.17 points. <sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-15\" id=\"fnref-AEsP2mm8QjfePzYi6-15\">[15]</a></sup> This 2.17 estimate is based on data from low-income countries, which finds an average SD in life satisfaction scores of 2.37, and data from high-income countries, which finds an average SD in life satisfaction scores of 1.86.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-16\" id=\"fnref-AEsP2mm8QjfePzYi6-16\">[16]</a></sup></li>\n<li><strong>Cost</strong>: HLI estimates that StrongMinds costs $170 per recipient.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-17\" id=\"fnref-AEsP2mm8QjfePzYi6-17\">[17]</a></sup></li>\n<li><strong>Cost-effectiveness</strong>: This implies 77 life satisfaction point-years per $1,000 spent. <sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-18\" id=\"fnref-AEsP2mm8QjfePzYi6-18\">[18]</a></sup></li>\n</ul>\n<p>HLI estimates that AMF creates <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=1455103561&amp;range=B7\">81 life satisfaction point-years (or WELLBYs) per $1,000 spent</a>. Note: This is under the deprivationist framework and assuming a \u201cneutral point\u201d of 0.5 life satisfaction points. <a href=\"https://www.happierlivesinstitute.org/report/the-elephant-in-the-bednet/\">HLI\u2019s report</a> presents estimates using a range of views of the badness of death and range of neutral points. It does not share an explicit view about the value of saving a life. We are benchmarking against this approach, since we think this is what we would use and it seems closest to our current moral weights. Summary of HLI's calculations:</p>\n<ul>\n<li>\n<p>Using a deprivationist framework, HLI estimates the value of averting a death using the following formula: ([Average life satisfaction score out of 10 during remaining years of life] minus [Score out of 10 on life satisfaction scale that is equivalent to death]) times [years of life gained due to death being averted].<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-19\" id=\"fnref-AEsP2mm8QjfePzYi6-19\">[19]</a></sup></p>\n</li>\n<li>\n<p>Average life satisfaction is 4.95/10. Average age of death from malaria is 20 and they live to be 70, giving them 50 extra years of life. As a result, WELLBYs gained equal (4.95-neutral point)*(70-20).<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-20\" id=\"fnref-AEsP2mm8QjfePzYi6-20\">[20]</a></sup></p>\n</li>\n<li>\n<p>HLI cites a cost per death averted of $3,000 for AMF.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-21\" id=\"fnref-AEsP2mm8QjfePzYi6-21\">[21]</a></sup></p>\n</li>\n<li>\n<p>With a neutral point of 0.5, this would be approximately 74 WELLBYs (life satisfaction point-years) per $1,000 spent.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-22\" id=\"fnref-AEsP2mm8QjfePzYi6-22\">[22]</a></sup> (Note: HLI presents a range of neutral points. We chose 0.5 since that\u2019s the neutral point we\u2019re using.)</p>\n</li>\n<li>\n<p>HLI also adds grief effects of 2.4 WELLBYs per $1,000 spent and income-increasing effects of 4 WELLBYs per $1,000 spent.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-23\" id=\"fnref-AEsP2mm8QjfePzYi6-23\">[23]</a></sup></p>\n</li>\n<li>\n<p>This yields a bottom line of approximately 80 WELLBYs per $1,000 spent for a neutral point of 0.5.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-24\" id=\"fnref-AEsP2mm8QjfePzYi6-24\">[24]</a></sup></p>\n</li>\n</ul>\n<p>HLI estimates cash transfers from GiveDirectly create <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=902328019&amp;range=B18\">8 life satisfaction point-years (or WELLBYs) per $1,000 spent</a>.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-25\" id=\"fnref-AEsP2mm8QjfePzYi6-25\">[25]</a></sup></p>\n<h2><strong>Our assessment</strong></h2>\n<p>Overall, we estimate StrongMinds is approximately 25% as cost-effective as marginal funding to AMF and our other top charities. However, this is based on several subjective adjustments, and we think a wide range of cost-effectiveness is possible (approximately 5% to 80% as cost-effective as our marginal dollar).</p>\n<h3><em>Best guess on cost-effectiveness</em></h3>\n<p>We put together an initial analysis of StrongMinds' cost-effectiveness under a subjective well-being approach, based on HLI\u2019s analysis.</p>\n<p>We estimate StrongMinds is roughly 25% as cost-effective as our marginal funding to AMF and other top charities. Compared to HLI, we estimate lower spillover effects and stricter downward adjustments for social desirability bias, publication bias, and lower effects at scale. This is partially counterbalanced by estimating lower costs and lower cost-effectiveness of AMF under a subjective well-being approach, compared to HLI.</p>\n<p>A <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=76487430&amp;range=A1\">summary</a> of HLI\u2019s estimates vs. our view:</p>\n<p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/3FFyQBDzsujs8pm8K/rixgivvseib7v0kdlng4\" alt=\"\"></p>\n<p>Our best guess is that StrongMinds leads to <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=76487430&amp;range=D20\">17 life satisfaction point-years (or WELLBYs) per $1,000 spent</a>. Summary of our calculations:</p>\n<ul>\n<li>\n<p><strong>Main effect</strong>: HLI\u2019s estimate of the effect of the main effect of IPT-G on SDs in depression scores is roughly similar to our estimate, which was based on a shallower review of the literature.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-26\" id=\"fnref-AEsP2mm8QjfePzYi6-26\">[26]</a></sup> We\u2019re uncertain about these estimates and think it\u2019s possible our estimates could change if we prioritized a more in-depth review. (We describe this further <a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness#Main_effect_of_StrongMinds\">below</a>.)</p>\n</li>\n<li>\n<p><strong>Internal and external validity adjustments</strong>: We include downward adjustments for three additional factors that are not incorporated into HLI\u2019s estimates. These are subjective guesses, but we believe they\u2019re worth including to make StrongMinds comparable to top charities and other funding opportunities. These include:</p>\n<ul>\n<li>Lower effectiveness at a larger scale and outside of trial contexts (75% adjustment). (We describe this further <a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness#Effects_at_scale_and_outside_of_trial_contexts\">below</a>.)</li>\n<li>Social desirability bias due to self-reported outcomes (80% adjustment). (We describe this further <a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness#Social_desirability_bias\">below</a>.)</li>\n<li>Publication bias (85% adjustment). (We describe this further <a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness#Publication_bias\">below</a>.)</li>\n</ul>\n</li>\n<li>\n<p><strong>Duration of benefits</strong>: There is evidence for long-term effects for some lay-person-delivered psychotherapy programs but not IPT-G, and we\u2019re skeptical that a 4- to 8-week program like StrongMinds would have benefits that occur far beyond a year. We also expect some of the internal and external validity adjustments we apply would also lead to shorter duration of effects. We apply an 80% adjustment factor for this. (We describe this further <a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness#Durability_of_benefits\">below</a>.)</p>\n</li>\n<li>\n<p><strong>Spillovers</strong>: We roughly double the effects to account for spillovers to other household members. This is lower than HLI\u2019s adjustment for spillovers. This reflects our assumption that the evidence HLI uses to estimate spillovers may overestimate spillover effects and household size is lower than HLI estimates. (We describe these further <a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness#Spillover_effects_to_other_household_members\">below</a>.)</p>\n</li>\n<li>\n<p><strong>Translating depression scores into life satisfaction</strong>: We make a slight discount (90% adjustment) to account for improvements in depression scores translating less than 1:1 to improvements in life satisfaction scores and a discount (80% adjustment) to account for individuals participating in StrongMinds having depression at baseline and therefore having a more concentrated distribution of life satisfaction scores. (We describe this further <a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness#Effect_of_depression_on_life_satisfaction\">below</a>.)</p>\n</li>\n<li>\n<p><strong>Cost</strong>: StrongMinds cited a figure of $105 per person receiving StrongMinds for 2022.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-27\" id=\"fnref-AEsP2mm8QjfePzYi6-27\">[27]</a></sup> We use that more recent figure instead of the $170 per person figure used by HLI.</p>\n</li>\n<li>\n<p><strong>Cost-effectiveness</strong>: This implies 17 life satisfaction point-years per $1,000 spent.</p>\n</li>\n</ul>\n<p>We estimate marginal funding to AMF creates <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=76487430&amp;range=D21\">70 life satisfaction point-years per $1,000 spent</a>. We define marginal funding to AMF as funding that is roughly 10 times as cost-effective as unconditional cash transfers through GiveDirectly (our current bar for funding opportunities). This is similar to marginal funding to our other top charities.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-28\" id=\"fnref-AEsP2mm8QjfePzYi6-28\">[28]</a></sup> Our assumptions are similar to HLI's on life satisfaction point-years per death averted from AMF. When we input this into our current cost-effectiveness analysis, we find an effect of 70 life satisfaction point-years per $1,000 spent.</p>\n<p>We also estimate that GiveDirectly creates <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=902328019&amp;range=D18\">8 life satisfaction point-years per $1,000</a> spent, which is similar to HLI's estimate. This is largely because we rely on HLI\u2019s meta-analysis of the effect of cash transfers on life satisfaction scores.</p>\n<h3><em>Key uncertainties and judgment calls that we would like to explore further</em></h3>\n<p>The cost-effectiveness of StrongMinds relies on several judgment calls that we\u2019re uncertain about. We would like to explore these further.</p>\n<h4><strong>Spillover effects to other household members</strong></h4>\n<p>It\u2019s possible that improvements in well-being of StrongMinds participants lead to improvements in well-being of other individuals in their household. We had excluded these benefits in our initial analysis, and HLI\u2019s work updated us toward believing these could be a substantial part of the benefits of therapy.</p>\n<p>To estimate spillover effects of StrongMinds, HLI relies on three studies that measure spillovers from therapy given to caregivers or children with severe health issues:<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-29\" id=\"fnref-AEsP2mm8QjfePzYi6-29\">[29]</a></sup></p>\n<ul>\n<li><a href=\"https://pubmed.ncbi.nlm.nih.gov/29444721/\">Mutamba et al. 2018a</a>: This trial measured the effect of therapy to caregivers of children with nodding syndrome. Spillovers were assessed by comparing the effect of therapy on caregivers and the child with nodding syndrome. The study was non-randomized.</li>\n<li><a href=\"https://pubmed.ncbi.nlm.nih.gov/19923161/\">Kemp et al. 2009</a>: This trial measured the effect of eye movement desensitization and reprocessing for post-traumatic stress disorder from a motor vehicle accident among children 6-12 years old. Spillovers were assessed by comparing mental health among children vs. parents.</li>\n<li><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2757752/\">Swartz et al. 2008</a>: This trial measured the effect of interpersonal therapy for mothers of children with psychiatric illness. Spillovers were assessed by comparing effects on mothers to their children.</li>\n</ul>\n<p>These three studies find a household member effect of 0.35 SDs (95% confidence interval, -0.04, 074), compared to 0.66 SDs for the recipient (95% confidence interval, 0.35, 0.97),<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-30\" id=\"fnref-AEsP2mm8QjfePzYi6-30\">[30]</a></sup> or a benefit that\u2019s 53% as large as the recipient\u2019s benefits.</p>\n<p>We think it\u2019s possible this evidence leads to greater spillovers than we would expect from StrongMinds, though these are speculative:</p>\n<ul>\n<li><a href=\"https://pubmed.ncbi.nlm.nih.gov/29444721/\">Mutamba et al. 2008</a> and <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2757752/\">Swartz et al. 2008</a> were oriented specifically toward caregivers having better relationships with children with severe health conditions.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-31\" id=\"fnref-AEsP2mm8QjfePzYi6-31\">[31]</a></sup> As a result, we may expect the effects on those children to be larger than children of StrongMinds recipients, since StrongMinds participants may not focus as intensively on relationships with household members.</li>\n<li><a href=\"https://pubmed.ncbi.nlm.nih.gov/29444721/\">Mutamba et al. 2008</a> and <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2757752/\">Swartz et al. 2008</a> look at therapy provided to caregivers of children with severe health issues and measure spillovers to children. It seems plausible that this would have a larger spillover effect than StrongMinds, since those children may rely on that caregiver more intensively for care, and therefore be more affected by changes in that caregiver\u2019s depression scores, than household members of typical StrongMinds participants.</li>\n<li>In <a href=\"https://pubmed.ncbi.nlm.nih.gov/29444721/\">Mutamba et al. 2008</a> and <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2757752/\">Swartz et al. 2008</a>, it seems possible children may also experience higher rates of treatment for their psychiatric conditions as a result of caregivers receiving therapy, which would confer direct benefits to non-recipients (in this case, children with nodding syndrome or psychiatric illness).</li>\n</ul>\n<p>In addition, a <a href=\"https://forum.effectivealtruism.org/posts/gr4epkwe5WoYJXF32/why-i-don-t-agree-with-hli-s-estimate-of-household\">recent blog post</a> points out that the results of <a href=\"https://pubmed.ncbi.nlm.nih.gov/19923161/\">Kemp et al. 2009</a> show that parents' depression scores increased, rather than decreased, which should lower HLI\u2019s estimates. HLI <a href=\"https://forum.effectivealtruism.org/posts/gr4epkwe5WoYJXF32/why-i-don-t-agree-with-hli-s-estimate-of-household?commentId=n2zZj5MmQRnzxcCPs\">notes in a comment on this post</a> that updating for this error lowers the spillover effect to 38%.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-32\" id=\"fnref-AEsP2mm8QjfePzYi6-32\">[32]</a></sup></p>\n<p>We also did a shallow review of correlational estimates and found a range of 5% to 60% across studies. We haven\u2019t reviewed these studies in depth but view them as illustrative of a range of possible effect sizes.</p>\n<ul>\n<li>\n<p><a href=\"https://openknowledge.worldbank.org/bitstream/handle/10986/4493/1564698x-23-1-31-55.pdf?sequence=1&amp;isAllowed=y\">Das et al. 2008</a> estimates that a one standard deviation change in mental health of household members is associated with a 22% to 59% of a standard deviation change in own mental health, across a sample of low- and middle-income countries.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-33\" id=\"fnref-AEsP2mm8QjfePzYi6-33\">[33]</a></sup></p>\n</li>\n<li>\n<p><a href=\"https://www.researchgate.net/publication/40676370_Mental_Health_of_Parents_and_Life_Satisfaction_of_Children_A_Within-Family_Analysis_of_Intergenerational_Transmission_of_Well-Being\">Powdthavee and Vignoles 2008</a> find a one standard deviation increase in parents' mental distress in the previous year lowers life satisfaction in the current year by 25% of a standard deviation for girls, using a sample from the UK. Effects are smaller for boys.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-34\" id=\"fnref-AEsP2mm8QjfePzYi6-34\">[34]</a></sup></p>\n</li>\n<li>\n<p><a href=\"https://docs.iza.org/dp11431.pdf\">Mendolia et al. 2018</a> find a standard deviation increase in partner\u2019s life satisfaction leads to a 5% of a standard deviation increase in individual life satisfaction, using data from Australia.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-35\" id=\"fnref-AEsP2mm8QjfePzYi6-35\">[35]</a></sup></p>\n</li>\n</ul>\n<p>These correlations may overestimate the extent of spillovers if there are shocks that are common to the household driving this correlation, assortative matching based on life satisfaction, or genetic transmission of life satisfaction scores within households. The authors control for some of these (consumption, physical health indicators),<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-36\" id=\"fnref-AEsP2mm8QjfePzYi6-36\">[36]</a></sup> but it\u2019s possible there are unobserved differences driving the correlation. These also do not account for assortative matching or genetic transmission of life satisfaction. On the other hand, measurement error in life satisfaction scores could bias the relationship downward.</p>\n<p>Our best guess is that spillovers to other household members is 15%, but we don\u2019t feel very confident and think new research could update us a lot.</p>\n<p>We think additional research on StrongMinds\u2019 costs could lead us to higher or lower estimates of program cost.</p>\n<p>We would be interested in exploring ways to fund further research to understand the extent to which improvements in depression scores or life satisfaction measures of StrongMinds participants lead to improvements in these outcomes for others in the household.</p>\n<h4><strong>Household size</strong></h4>\n<p>The extent of spillovers also depends on the number of individuals in StrongMinds participants\u2019 households.</p>\n<p>HLI estimates household size using data from the Global Data Lab and UN Population Division.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-37\" id=\"fnref-AEsP2mm8QjfePzYi6-37\">[37]</a></sup> They estimate a household size of 5.9<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-38\" id=\"fnref-AEsP2mm8QjfePzYi6-38\">[38]</a></sup> in Uganda based on these data, which appears to be driven by high estimates for rural household size in the Global Data Lab data, which estimate a household size of 6.3 in rural areas in 2019.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-39\" id=\"fnref-AEsP2mm8QjfePzYi6-39\">[39]</a></sup> A recent Uganda National Household Survey, on the other hand, estimates household size of 4.8 in rural areas.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-40\" id=\"fnref-AEsP2mm8QjfePzYi6-40\">[40]</a></sup></p>\n<p>We\u2019re not sure what\u2019s driving differences in estimates across these surveys, but our best guess is that household size is smaller than the 5.9 estimate HLI is using.</p>\n<p>We would also be interested in understanding what may be driving differences in estimates and whether it\u2019s possible to collect data directly on household size for women participating in StrongMinds program, since these data could potentially be collected cheaply and provide a meaningful update on the extent of spillovers.</p>\n<h4>Effect of depression on life satisfaction</h4>\n<p>HLI\u2019s estimates of the effect of StrongMinds are in terms of SD-years of improvement in mental health measures like depression scores.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-41\" id=\"fnref-AEsP2mm8QjfePzYi6-41\">[41]</a></sup></p>\n<p>To translate these measures into life satisfaction, HLI assumes that (i) 1 SD improvement in depression scores is equivalent to 1 SD improvement in life satisfaction scores in trials of the effect of psychotherapy programs similar to StrongMinds and (ii) the SD in life satisfaction among StrongMinds recipients is equal to the SD in life satisfaction among a pooled average of individuals in low-, middle-, and high-income countries.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-42\" id=\"fnref-AEsP2mm8QjfePzYi6-42\">[42]</a></sup></p>\n<p>We apply a 90% adjustment to assumption (i) to account for the possibility that improvements in depression scores do not translate 1:1 to improvements in life satisfaction scores. This is based on:</p>\n<ul>\n<li>\n<p>HLI\u2019s review of five therapeutic interventions that report effects on subjective well-being measures and depression. This finds a ratio in effects of 0.89 SD.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-43\" id=\"fnref-AEsP2mm8QjfePzYi6-43\">[43]</a></sup></p>\n</li>\n<li>\n<p>Our prior that there may be conceptual reasons why depression scores and life satisfaction might not map 1:1 onto each other. The highest/worst values on depression scales correspond to the most severe cases of depression. It seems likely that having the highest score on a depression scale would correspond to a life satisfaction score of 0. However, it\u2019s less clear that this applies on the other end of the scale. Those who have low scores on depression scales have an absence of depressive symptoms.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-44\" id=\"fnref-AEsP2mm8QjfePzYi6-44\">[44]</a></sup> These individuals likely have a higher life satisfaction, but it\u2019s not obvious that the absence of depressive symptoms corresponds to a life satisfaction of 10. If absence of depression means people are completely satisfied with their lives, then it makes sense to scale in this way. But if high life satisfaction requires not just the absence of depressive symptoms but something more, then this approach seems less plausible. We\u2019re uncertain about this line of reasoning, though, and would be interested in direct evidence on the effect of IPT-G or similar programs on life satisfaction measures.</p>\n</li>\n</ul>\n<p>We apply an 80% adjustment to assumption (ii). This is because it seems likely that SD in life satisfaction score is lower among StrongMinds recipients, who are screened for depression at baseline<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-45\" id=\"fnref-AEsP2mm8QjfePzYi6-45\">[45]</a></sup> and therefore may be more concentrated at the lower end of the life satisfaction score distribution than the average individual.</p>\n<p>For both of these adjustments, we\u2019re unsure about any non-linearities in the relationship between improvements in depression and improvements in life satisfaction. For example, it\u2019s possible that going from severely depressed to moderately depressed leads to a larger than 1:1 increase in life satisfaction measures.</p>\n<p>Because adjustments here are highly subjective, we would be open to considering collecting more evidence on this question. A potential approach would be to include surveys on life satisfaction, in addition to depression measures and other mental health scores, in subsequent studies of IPT-G. It may also be possible to explore whether existing datasets allow estimating SD in life satisfaction separately for individuals classified as depressed at baseline vs. not.</p>\n<h4><strong>Effects at scale and outside of trial contexts</strong></h4>\n<p>HLI does not include discounts for StrongMinds having a smaller effect when implemented at a larger scale and outside of trial contexts.</p>\n<p>Our general expectation is that programs implemented as part of randomized trials are higher quality than similar programs implemented at scale. We would guess that the dominant factor here is that it is difficult to maintain quality of services as an organization scales. This seems particularly relevant for a program that relies on trained practitioners, such as interpersonal group therapy. It's plausible that as StrongMinds scales up its program in the real world, the quality of implementation will decrease relative to the academic trials.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-46\" id=\"fnref-AEsP2mm8QjfePzYi6-46\">[46]</a></sup></p>\n<p>For example, HLI notes that StrongMinds uses a reduced number of sessions and slightly reduced training, compared to Bolton (2003), which its program is based on.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-47\" id=\"fnref-AEsP2mm8QjfePzYi6-47\">[47]</a></sup> We think this type of modification could reduce program effectiveness relative to what is found in trials. However, we have not done a side-by-side of training, session duration, or other program characteristics of StrongMinds compared to other programs in HLI\u2019s full meta-analysis.</p>\n<p>We can also see some evidence for lower effects in larger trials:</p>\n<ul>\n<li>Thurman et al. 2017 finds no effect of IPT-G and suggests that one reason for this might be that the study was conducted following rapid program scale-up (unlike the Bolton et al. 2017 trials).<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-48\" id=\"fnref-AEsP2mm8QjfePzYi6-48\">[48]</a></sup></li>\n<li>In the studies included in HLI\u2019s meta-analysis, larger trials tend to find smaller effects.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-49\" id=\"fnref-AEsP2mm8QjfePzYi6-49\">[49]</a></sup> This could be consistent with either smaller effects at scale or publication bias.</li>\n</ul>\n<p>We would be eager to see studies that measure the effect of StrongMinds, as it is currently implemented, directly and think the ongoing trial from Baird and Ozler will provide a useful data point here.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-50\" id=\"fnref-AEsP2mm8QjfePzYi6-50\">[50]</a></sup> We\u2019re also interested in learning more about the findings from StrongMinds' RCT and how the program studied in that RCT compares to its typical program.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-51\" id=\"fnref-AEsP2mm8QjfePzYi6-51\">[51]</a></sup></p>\n<p>In addition, we would be interested in understanding how StrongMinds\u2019 costs might change if it were to expand (see <a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness#Costs\">below</a>).</p>\n<h4><strong>Social desirability bias</strong></h4>\n<p>One major concern we have with these studies is that participants might report a lower level of depression after the intervention because they believe that is what the experimenter wants to see (more detail in footnote).<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-52\" id=\"fnref-AEsP2mm8QjfePzYi6-52\">[52]</a></sup> This is a concern because the depression outcomes in therapy programs are self-reported (i.e. participants answer questions regarding their own mental health before and after the intervention).</p>\n<p>HLI responded to this criticism and noted that studies that try to assess experimenter-demand effects typically find small effects.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-53\" id=\"fnref-AEsP2mm8QjfePzYi6-53\">[53]</a></sup> These studies test how much responses to questions about depression scores (or other mental health outcomes) change when the surveyor says they expect a particular response (either higher or lower score).</p>\n<p>We\u2019re not sure these tests would resolve this bias so we still include a downward adjustment (80% adjustment factor).</p>\n<p>Our guess is that individuals who have gone through IPT-G programs would still be inclined to report having lower depression scores and better mental health on a survey that is related to the IPT-G program they received. If the surveyor told them they expected the program to worsen their mental health or improve their mental health, it seems unlikely to overturn whatever belief they had about the program\u2019s expected effect that was formed during their group therapy sessions. This is speculative, however, and we don\u2019t feel confident in this adjustment.</p>\n<p>We also guess this would not detect bias arising from individuals changing their responses in order to receive treatment subsequently (or allowing others to do so),<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-54\" id=\"fnref-AEsP2mm8QjfePzYi6-54\">[54]</a></sup> though we\u2019re unsure how important this concern is or how typical this is of other therapy interventions included in HLI\u2019s meta-analysis.</p>\n<p>We would be interested in speaking more to subject matter experts about ways to detect self-reporting bias and understand possible magnitude.</p>\n<h4>Publication bias</h4>\n<p>HLI\u2019s analysis includes a roughly 10% downward adjustment for publication bias in the therapy literature relative to cash transfers literature.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-55\" id=\"fnref-AEsP2mm8QjfePzYi6-55\">[55]</a></sup> We have not explored this in depth but guess we would apply a steeper adjustment factor for publication bias in therapy relative to our top charities.</p>\n<p>After publishing its cost-effectiveness analysis, HLI published a funnel plot showing a high level of publication bias, with well-powered studies finding smaller effects than less-well-powered studies.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-56\" id=\"fnref-AEsP2mm8QjfePzYi6-56\">[56]</a></sup> This is qualitatively consistent with a <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4589340/\">recent meta-analysis</a> of therapy finding a publication bias of 25%.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-57\" id=\"fnref-AEsP2mm8QjfePzYi6-57\">[57]</a></sup></p>\n<p>We roughly estimate an additional 15% downward adjustment (85% adjustment) to account for this bias. We may look into this further if we prioritize more work on StrongMinds by speaking to researchers, HLI, and other experts and by explicitly estimating publication bias in this literature.</p>\n<h4>Main effect of StrongMinds</h4>\n<p>We undertook a shallow review of the evidence for IPT-G prior to reviewing HLI\u2019s analysis. Because we ended up with a similar best guess on effect size,<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-58\" id=\"fnref-AEsP2mm8QjfePzYi6-58\">[58]</a></sup> we did not prioritize further review. There are several key questions we have not investigated in depth:</p>\n<ul>\n<li>How much weight should we put on different studies? In our shallow review, we rely on three RCTs that tested the impact of IPT-G on depression in a low- and middle-income country context (Bolton et al. 2003, Bolton et al. 2007, Thurman et al. 2017) and broader meta-analysis of psychotherapy programs across low-income and non-low-income countries. HLI uses Thurman et al. 2017, Bolton et al. 2007, and Bolton et al. 2003, studies of StrongMinds, and a meta-regression of indirect evidence.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-59\" id=\"fnref-AEsP2mm8QjfePzYi6-59\">[59]</a></sup> We\u2019re not sure how much to weight these pieces of evidence to generate a best guess for the effect of StrongMinds in countries where it would operate with additional funding.</li>\n<li>How do Bolton et al. 2003, Bolton et al. 2006, Thurman et al. 2017, and the programs included in HLI\u2019s meta-analysis vary from StrongMinds program, in terms of the program being delivered and target population, and how should that affect how much we generalize results? A key piece of the assessment of how much weight to put on different trials is the similarity in program type and target population. We have not done a thorough review of study populations (e.g., the extent to which different trials targeted women with depression at baseline, like StrongMinds) and programs (e.g., number of sessions, level of training, group size, etc.).<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-60\" id=\"fnref-AEsP2mm8QjfePzYi6-60\">[60]</a></sup></li>\n<li>What interventions did control groups receive? It\u2019s possible that counterfactual treatment varied across studies. If control groups received some type of effective treatment, this could bias effects downward.</li>\n<li>Would we come to the same conclusions if we replicated HLI\u2019s meta-analysis? We have not vetted its analysis of the studies it uses in its meta-analysis,<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-61\" id=\"fnref-AEsP2mm8QjfePzYi6-61\">[61]</a></sup> and it\u2019s possible further work could uncover changes.\nWe think it\u2019s possible that further review of these questions could lead to changes in our best guess on the main effects of StrongMinds and similar programs on depression scores.</li>\n</ul>\n<h4>Durability of benefits</h4>\n<p>HLI estimates durability of benefits by fitting a decay model of the effects of therapy programs over time, based on studies of the effect of therapy at different follow-up periods.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-62\" id=\"fnref-AEsP2mm8QjfePzYi6-62\">[62]</a></sup> HLI estimates that effects persist up to five years, based on programs it deems similar to StrongMinds.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-63\" id=\"fnref-AEsP2mm8QjfePzYi6-63\">[63]</a></sup> To the best of our knowledge, there are no long-term follow-up studies (beyond 15 months) of IPT-G in low-income countries specifically.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-64\" id=\"fnref-AEsP2mm8QjfePzYi6-64\">[64]</a></sup></p>\n<p>We do think it\u2019s plausible that lay-person-delivered therapy programs can have persistent long-term effects, based on recent trials by <a href=\"https://www.nber.org/system/files/working_papers/w30011/w30011.pdf\">Bhat et al. 2022</a> and <a href=\"https://www.zora.uzh.ch/id/eprint/190391/1/aer.20180511.pdf\">Baranov et al. 2020</a>.</p>\n<p>However, we\u2019re somewhat skeptical of HLI\u2019s estimate, given that it seems unlikely to us that a time-limited course of group therapy (4-8 weeks) would have such persistent effects. We also guess that some of the factors that cause StrongMinds\u2019 program to be less effective than programs studied in trials (see <a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness#Effects_at_scale_and_outside_of_trial_contexts\">above</a>) could also limit how long the benefits of the program endure. As a result, we apply an 80% adjustment factor to HLI\u2019s estimates.</p>\n<p>We view this adjustment as highly speculative, though, and think it\u2019s possible we could update our view with more work. We also expect the forthcoming large-scale RCT of StrongMinds in Uganda by Sarah Baird and Berk Ozler, which will measure follow-up at 2 years, could provide an update to these estimates.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-65\" id=\"fnref-AEsP2mm8QjfePzYi6-65\">[65]</a></sup></p>\n<h4>Costs</h4>\n<p>HLI\u2019s most recent analysis includes a cost of $170 per person treated by StrongMinds, but StrongMinds cited a 2022 figure of $105 in a recent blog post and said it expects costs to decline to $85 per person treated by the end of 2024.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-66\" id=\"fnref-AEsP2mm8QjfePzYi6-66\">[66]</a></sup></p>\n<p>We would be interested in learning more about StrongMinds\u2019 costs and understanding what may be driving fluctuations over time and whether these are related to program impact (e.g., in-person or teletherapy, amount of training).</p>\n<p>We are also interested in understanding whether to value volunteers\u2019 time, since StrongMinds relies on volunteers for many of its models.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-67\" id=\"fnref-AEsP2mm8QjfePzYi6-67\">[67]</a></sup></p>\n<h4>Additional considerations</h4>\n<ul>\n<li>\n<p><em>Potential unmodeled upsides</em>: There may be additional benefits of StrongMinds\u2019 programs that our model is excluding. An example is advocacy for improved government mental health policies by StrongMinds recipients.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-68\" id=\"fnref-AEsP2mm8QjfePzYi6-68\">[68]</a></sup></p>\n</li>\n<li>\n<p><em>Implications for cost-effectiveness of other programs</em>: HLI\u2019s analysis has updated us toward putting more weight on household spillover effects of therapy and to consider putting at least some weight on subjective well-being measures in assessing the benefits of therapy. It\u2019s possible that incorporating both of these could cause us to increase our estimates of cost-effectiveness of other morbidity-averting programs (e.g., cataract surgery, fistula surgery, clubfoot), since they may also benefit from within-household spillovers or look better under a subjective well-being approach.</p>\n</li>\n<li>\n<p><em>Measures of grief</em>: We have not prioritized an in-depth review of the effects of grief on life satisfaction, since this seems relatively unlikely to change the bottom line in our current analysis. We are taking HLI\u2019s estimates at face value for now.</p>\n</li>\n</ul>\n<p><em>Plausibility</em></p>\n<p>Stepping back, we also think HLI\u2019s estimates of the cost-effectiveness of StrongMinds seem surprisingly large compared to other benchmarks, which gives us some additional reservations about this approach.</p>\n<p>Because we\u2019re uncertain about the right way to trade off improvements in subjective well-being from therapy vs. other interventions like cash transfers and averting deaths, we think it\u2019s useful to compare against other perspectives. This includes:</p>\n<ul>\n<li>\n<p><em>Examining the trade-offs between offering StrongMinds, averting a death, and providing unconditional cash transfers</em>: HLI\u2019s estimates imply that offering 17 recipients StrongMinds is as valuable as averting a death from malaria and that offering 19 recipients StrongMinds is as valuable as averting an under-5 death from malaria.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-69\" id=\"fnref-AEsP2mm8QjfePzYi6-69\">[69]</a></sup> HLI\u2019s estimates also imply that providing someone a $1,000 cash transfer would be _less _valuable to them than offering StrongMinds.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-70\" id=\"fnref-AEsP2mm8QjfePzYi6-70\">[70]</a></sup> These feel like unintuitive trade-offs that beneficiaries and donors would be unlikely to want to make. We acknowledge that this type of reasoning has limitations: It\u2019s not obvious we should defer to whatever trade-offs we\u2019d expect individuals to make (even if we knew individuals\u2019 preferences) or that individuals are aware of what would make them the best off (e.g., individuals might not prefer bed nets at the same rate as our cost-effectiveness analysis implies).</p>\n</li>\n<li>\n<p><em>Comparing the benefits of IPT-G to an additional year of life</em>. HLI\u2019s estimates imply that receiving IPT-G is roughly 40% as valuable as an additional year of life per year of benefit or 80% of the value of an additional year of life total.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-71\" id=\"fnref-AEsP2mm8QjfePzYi6-71\">[71]</a></sup> This feels intuitively high.</p>\n</li>\n<li>\n<p><em>Comparing HLI\u2019s estimates of grief from deaths averted to impact of StrongMinds</em>: HLI estimates that each death prevented by AMF causes a gain of 7 WELLBYs that would have been lost due to grief.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-72\" id=\"fnref-AEsP2mm8QjfePzYi6-72\">[72]</a></sup> It estimates that StrongMinds causes a gain of 13 WELLBYs. This is nearly twice the benefits of averting the grief over someone\u2019s death, which seems intuitively high. We have not dug deeply into evidence on grief effects on life satisfaction but think the current comparison seems implausible.</p>\n</li>\n</ul>\n<p>We\u2019re uncertain about how much weight to put on these considerations, since these trade-offs are challenging to assess, but they seem unintuitive to us and influence our belief that StrongMinds is less cost-effective than HLI estimates.</p>\n<p><em>Cost-effectiveness using our moral weights, rather than a subjective well-being approach</em></p>\n<p>The above analysis focuses on estimating cost-effectiveness under a subjective well-being approach. Our bottom line is similar if we use our current moral weights.</p>\n<p>HLI argues for using subjective well-being measures like life satisfaction scores to compare outcomes like averting a death, increasing consumption, and improving mental health through psychotherapy.</p>\n<p>We think there are important advantages to this approach:</p>\n<ul>\n<li>\n<p>Subjective well-being measures provide an independent approach to assessing the effect of charities. The subjective well-being approach relies on measures that we have not previously used (i.e., life satisfaction scores) and provides a distinct and coherent methodology for establishing the goodness of different interventions. How we value charities that improve different outcomes, such as increasing consumption or averting death, are one of the most uncertain parts of our process of selecting cost-effective charities, and we believe we will reach more robust decisions if we consider multiple independent lines of reasoning.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-73\" id=\"fnref-AEsP2mm8QjfePzYi6-73\">[73]</a></sup></p>\n</li>\n<li>\n<p>These measures capture a relevant outcome. We think most would agree that subjective well-being is an important component of overall well-being. Measuring effects that interventions have on changes in life satisfaction may be a more accurate way to assess impacts on subjective well-being than using indirect proxies, such as increases in income.</p>\n</li>\n<li>\n<p>The subjective well-being approach is empirical. It seems desirable for a moral weights approach to be able to change based on new research or facts about a particular context. The subjective well-being approach can change based on, for example, new studies about the effect of a particular intervention on life satisfaction.</p>\n</li>\n</ul>\n<p>We\u2019re unsure what approach we should adopt for morbidity-averting interventions. We\u2019d like to think further about the pros and cons of the subjective well-being approach and also the extent to which disability-adjusted life years may fail to capture some of the benefits of therapy (or other morbidity-averting interventions).</p>\n<p>In this case, however, using a subjective well-being approach vs. our current moral weights does not make a meaningful difference in cost-effectiveness. If we use disability-adjusted life years instead of subjective well-being (i.e., effect on life satisfaction scores), we estimate StrongMinds is roughly 20% as cost-effective as a grant to AMF that is 10 times as cost-effective as unconditional cash transfers.<sup class=\"footnote-ref\"><a href=\"#fn-AEsP2mm8QjfePzYi6-74\" id=\"fnref-AEsP2mm8QjfePzYi6-74\">[74]</a></sup></p>\n<h2><strong>Our next steps</strong></h2>\n<p>We may prioritize further work on StrongMinds in the future to try to narrow some of our major uncertainties on this program. This may include funding additional studies, conducting additional desk-based research, and speaking with experts.</p>\n<p>We should first prioritize the following:</p>\n<ul>\n<li>Reviewing the forthcoming large-scale RCT of StrongMinds in Uganda by Sarah Baird and Berk Ozler, as well as a recent (unpublished) RCT by StrongMinds</li>\n<li>Speaking to StrongMinds, Happier Lives Institute, researchers, and other subject matter experts about the key questions we\u2019ve raised</li>\n</ul>\n<p>Beyond that, we would consider:</p>\n<ul>\n<li>Exploring ways to fund research on spillover effects and on effects on life satisfaction directly, potentially as part of ongoing trials or new trials</li>\n<li>Exploring data collection on household size among StrongMinds participants</li>\n<li>Learning more about program costs from StrongMinds</li>\n<li>Conducting additional desk research that may inform adjustments for social desirability bias, publication bias, effects on grief, and duration of benefits of StrongMinds</li>\n<li>Considering whether to incorporate subjective well-being measures directly into our moral weights and how much weight we would put on a subjective well-being approach vs. our typical approach in our assessment of StrongMinds</li>\n<li>Considering how much weight to put on plausibility checks, potentially including additional <a href=\"https://docs.google.com/document/d/1hOQf6Ug1WpoicMyFDGoqH7tmf3Njjc15Z1DGERaTbnI/edit#heading=h.82utnglspame\">donor surveys</a> to understand where they fall on questions about moral intuitions</li>\n<li>Considering research to measure effect of StrongMinds or other therapy programs on life satisfaction directly</li>\n<li>Exploring how this might change our assessment of other programs addressing morbidity (because, e.g., they also have spillover effects or they also look more cost-effective under a subjective well-being approach) and consider collecting data on the effect on life satisfaction of those programs as well</li>\n</ul>\n<h2>Sources</h2>\n<table>\n<thead>\n<tr>\n<th>Title</th>\n<th>Link</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>American Psychological Association, Hamilton Depression Rating Scale (HAM-D)</td>\n<td><a href=\"https://www.apa.org/depression-guideline/hamilton-rating-scale.pdf\">https://www.apa.org/depression-guideline/hamilton-rating-scale.pdf</a></td>\n</tr>\n<tr>\n<td>Baranov et al. 2020</td>\n<td><a href=\"https://doi.org/10.1257/aer.20180511\">https://doi.org/10.1257/aer.20180511</a></td>\n</tr>\n<tr>\n<td>Bhat et al. 2022</td>\n<td><a href=\"https://doi.org/10.1257/rct.3823-1.0\">https://doi.org/10.1257/rct.3823-1.0</a></td>\n</tr>\n<tr>\n<td>Bolton et al. 2003</td>\n<td><a href=\"https://doi.org/10.1001/jama.289.23.3117\">https://doi.org/10.1001/jama.289.23.3117</a></td>\n</tr>\n<tr>\n<td>Bolton et al. 2007</td>\n<td><a href=\"https://doi.org/10.1001/jama.298.5.519\">https://doi.org/10.1001/jama.298.5.519</a></td>\n</tr>\n<tr>\n<td>Bright Futures, Center for Epidemiological Studies Depression Scale for Children (CES-DC)</td>\n<td><a href=\"https://www.brightfutures.org/mentalhealth/pdf/professionals/bridges/ces_dc.pdf\">https://www.brightfutures.org/mentalhealth/pdf/professionals/bridges/ces_dc.pdf</a></td>\n</tr>\n<tr>\n<td>Cuijpers et al. 2010</td>\n<td><a href=\"https://doi.org/10.1017/S0033291709006114\">https://doi.org/10.1017/S0033291709006114</a></td>\n</tr>\n<tr>\n<td>Cuijpers et al. 2016</td>\n<td><a href=\"https://doi.org/10.1176/appi.ajp.2015.15091141\">https://doi.org/10.1176/appi.ajp.2015.15091141</a></td>\n</tr>\n<tr>\n<td>Das et al. 2008</td>\n<td><a href=\"https://doi.org/10.1093/wber/lhn010\">https://doi.org/10.1093/wber/lhn010</a></td>\n</tr>\n<tr>\n<td>Donaldson et al. 2020</td>\n<td><a href=\"https://forum.effectivealtruism.org/posts/xgxzCkpKQsPwrd5W7/using-subjective-well-being-to-estimate-the-moral-weights-of-2\">https://forum.effectivealtruism.org/posts/xgxzCkpKQsPwrd5W7/using-subjective-well-being-to-estimate-the-moral-weights-of-2</a></td>\n</tr>\n<tr>\n<td>Driessen et al. 2015</td>\n<td><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4589340/pdf/pone.0137864.pdf\">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4589340/pdf/pone.0137864.pdf</a></td>\n</tr>\n<tr>\n<td>GiveWell, 2020 update on GiveWell's moral weights</td>\n<td><a href=\"https://docs.google.com/document/d/1hOQf6Ug1WpoicMyFDGoqH7tmf3Njjc15Z1DGERaTbnI/edit#heading=h.82utnglspame\">https://docs.google.com/document/d/1hOQf6Ug1WpoicMyFDGoqH7tmf3Njjc15Z1DGERaTbnI/edit#heading=h.82utnglspame</a></td>\n</tr>\n<tr>\n<td>GiveWell, December 2022 copy of HLI's v3 AMF BOTEC (and sensitivity to different views)</td>\n<td><a href=\"https://docs.google.com/spreadsheets/d/1ESXTA9kD5aYJb8_dKgMsHxJralL1RaS8q7V4zSoOkyY/edit#gid=2083362429&amp;range=D2\">https://docs.google.com/spreadsheets/d/1ESXTA9kD5aYJb8_dKgMsHxJralL1RaS8q7V4zSoOkyY/edit#gid=2083362429&amp;range=D2</a></td>\n</tr>\n<tr>\n<td>GiveWell, edited copy of HLI's TherapyInterventionsData</td>\n<td><a href=\"https://docs.google.com/spreadsheets/d/11EX5dNZdK9-kNXHhXUXdOnqItaFaO0AA2ITHcM_jr-A/edit#gid=200587636\">https://docs.google.com/spreadsheets/d/11EX5dNZdK9-kNXHhXUXdOnqItaFaO0AA2ITHcM_jr-A/edit#gid=200587636</a></td>\n</tr>\n<tr>\n<td>GiveWell, IPT-G RCTs: Choice of informal meta-analysis weights</td>\n<td><a href=\"https://docs.google.com/document/d/1gVxVoAeZoRVG2nGeI0B_6h0saJKmjNz_K7cmpSoRCI4/edit\">https://docs.google.com/document/d/1gVxVoAeZoRVG2nGeI0B_6h0saJKmjNz_K7cmpSoRCI4/edit</a></td>\n</tr>\n<tr>\n<td>GiveWell, Subjective well-being evaluation of StrongMinds [2023]</td>\n<td><a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=605819695\">https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=605819695</a></td>\n</tr>\n<tr>\n<td>GiveWell, SWB 2023 update_Copy of 2022 GiveWell cost-effectiveness analysis \u2014 version 5 (public)</td>\n<td><a href=\"https://docs.google.com/spreadsheets/d/1kjNMZdNVj4cZuTTMAosfAtAtFwxNr-4S_PIgpcWVys8/edit#gid=1070538669\">https://docs.google.com/spreadsheets/d/1kjNMZdNVj4cZuTTMAosfAtAtFwxNr-4S_PIgpcWVys8/edit#gid=1070538669</a></td>\n</tr>\n<tr>\n<td>GiveWell, SWB 2023_IPT-G effect size in standard deviations</td>\n<td><a href=\"https://docs.google.com/spreadsheets/d/1MJbT2P6OQ8n3DkVvCf1ez1XITuhxm0A6KZ7DONalALY/edit#gid=0\">https://docs.google.com/spreadsheets/d/1MJbT2P6OQ8n3DkVvCf1ez1XITuhxm0A6KZ7DONalALY/edit#gid=0</a></td>\n</tr>\n<tr>\n<td>GiveWell, SWB_Deaths and life satisfaction BOTEC</td>\n<td><a href=\"https://docs.google.com/spreadsheets/d/1_GlmfFMTSb-Kj_R1walcyhYYbOgWBlmDV2Ox-1dOPTw/edit#gid=520247736&amp;range=A94\">https://docs.google.com/spreadsheets/d/1_GlmfFMTSb-Kj_R1walcyhYYbOgWBlmDV2Ox-1dOPTw/edit#gid=520247736&amp;range=A94</a></td>\n</tr>\n<tr>\n<td>Global Data Lab, Average household size, accessed March 8, 2023.</td>\n<td><a href=\"https://globaldatalab.org/areadata/table/hhsize/KEN+UGA/?levels=1+2+3\">https://globaldatalab.org/areadata/table/hhsize/KEN+UGA/?levels=1+2+3</a></td>\n</tr>\n<tr>\n<td>Happier Lives Institute, \"Cost-effectiveness analysis: Group or task-shifted psychotherapy to treat depression,\" 2021</td>\n<td><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/Psychotherapy-CEA.pdf\">https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/Psychotherapy-CEA.pdf</a></td>\n</tr>\n<tr>\n<td>Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</td>\n<td><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf</a></td>\n</tr>\n<tr>\n<td>Happier Lives Institute, \"Happiness for the whole family: Accounting for household spillovers when comparing the cost-effectiveness of psychotherapy to cash transfers,\" February 2022</td>\n<td><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/Happiness-for-the-whole-family.pdf\">https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/Happiness-for-the-whole-family.pdf</a></td>\n</tr>\n<tr>\n<td>Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</td>\n<td><a href=\"https://www.happierlivesinstitute.org/report/the-elephant-in-the-bednet/\">https://www.happierlivesinstitute.org/report/the-elephant-in-the-bednet/</a></td>\n</tr>\n<tr>\n<td>Happier Lives Institute, Copy of 2022 GiveWell (saving) CEA v4</td>\n<td><a href=\"https://docs.google.com/spreadsheets/d/1lDUxIYssnZVWHq3PLjNt2kNw075YfcGiHQoFaNkd5KM/edit#gid=1364064522\">https://docs.google.com/spreadsheets/d/1lDUxIYssnZVWHq3PLjNt2kNw075YfcGiHQoFaNkd5KM/edit#gid=1364064522</a></td>\n</tr>\n<tr>\n<td>Happier Lives Institute, Depression to LS</td>\n<td><a href=\"https://docs.google.com/spreadsheets/d/1_ErgKPSNinrbc0oFDiJfqDncUI0rtinhw6kGazwAS_o/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/1_ErgKPSNinrbc0oFDiJfqDncUI0rtinhw6kGazwAS_o/edit?usp=sharing</a></td>\n</tr>\n<tr>\n<td>Happier Lives Institute, TherapyInterventionsData</td>\n<td><a href=\"https://docs.google.com/spreadsheets/d/1XAGgIazfVGEtxwF_c7IDybyp4xPFJICl1hKdBnMRsYE/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/1XAGgIazfVGEtxwF_c7IDybyp4xPFJICl1hKdBnMRsYE/edit?usp=sharing</a></td>\n</tr>\n<tr>\n<td>Happier Lives Institute, V3 AMF BOTEC (and sensitivity to different views)</td>\n<td><a href=\"https://docs.google.com/spreadsheets/d/15Mm_wjZCbInW7HlmdRLb_8BB4KXtIZTRrlgaHifx8wY/edit#gid=1045478457\">https://docs.google.com/spreadsheets/d/15Mm_wjZCbInW7HlmdRLb_8BB4KXtIZTRrlgaHifx8wY/edit#gid=1045478457</a></td>\n</tr>\n<tr>\n<td>Joel McGuire, Research Analyst, Happier Lives Institute, comment on EA Forum article \"Evaluating StrongMinds: how strong is the evidence?\", 2023</td>\n<td><a href=\"https://forum.effectivealtruism.org/posts/HqEmL7XAuuD5Pc4eg/evaluating-strongminds-how-strong-is-the-evidence?commentId=gtLgSMD8NjohTZtQM\">https://forum.effectivealtruism.org/posts/HqEmL7XAuuD5Pc4eg/evaluating-strongminds-how-strong-is-the-evidence?commentId=gtLgSMD8NjohTZtQM</a></td>\n</tr>\n<tr>\n<td>Kemp et al. 2009</td>\n<td><a href=\"https://doi.org/10.1093/wber/lhn010\">https://doi.org/10.1093/wber/lhn010</a></td>\n</tr>\n<tr>\n<td>Makerere University School of Public Health, \"Family Based Group Interpersonal Psychotherapy for Caregivers of Children with Nodding Syndrome,\" 2014 [video]</td>\n<td><a href=\"https://www.youtube.com/watch?v=RQ2eYn-J8w8\">https://www.youtube.com/watch?v=RQ2eYn-J8w8</a></td>\n</tr>\n<tr>\n<td>Mayberry, \"AMA: Sean Mayberry, Founder &amp; CEO of StrongMinds,\" November 2022</td>\n<td><a href=\"https://forum.effectivealtruism.org/posts/82heDPsmvhThda3af/ama-sean-mayberry-founder-and-ceo-of-strongminds\">https://forum.effectivealtruism.org/posts/82heDPsmvhThda3af/ama-sean-mayberry-founder-and-ceo-of-strongminds</a></td>\n</tr>\n<tr>\n<td>Mendolia et al. 2018</td>\n<td><a href=\"https://docs.iza.org/dp11431.pdf\">https://docs.iza.org/dp11431.pdf</a></td>\n</tr>\n<tr>\n<td>Morina et al. 2017</td>\n<td><a href=\"https://DOI.org/10.1002/da.22618\">https://DOI.org/10.1002/da.22618</a></td>\n</tr>\n<tr>\n<td>Mutamba et al. 2008</td>\n<td><a href=\"https://doi.org/10.1017/S0033291718000193\">https://doi.org/10.1017/S0033291718000193</a></td>\n</tr>\n<tr>\n<td>Mutamba et al. 2018a</td>\n<td><a href=\"https://doi.org/10.1017/S0033291718000193\">https://doi.org/10.1017/S0033291718000193</a></td>\n</tr>\n<tr>\n<td>Mutamba et al. 2018b</td>\n<td><a href=\"https://implementationscience.biomedcentral.com/articles/10.1186/s13012-018-0785-y\">https://implementationscience.biomedcentral.com/articles/10.1186/s13012-018-0785-y</a></td>\n</tr>\n<tr>\n<td>OECD Guidelines on Measuring Subjective Well-Being: Annex A</td>\n<td><a href=\"https://doi.org/10.1787/9789264191655-en\">https://doi.org/10.1787/9789264191655-en</a></td>\n</tr>\n<tr>\n<td>Oswald and Powdthavee 2008</td>\n<td><a href=\"https://www.zora.uzh.ch/id/eprint/52349/1/iewwp396.pdf\">https://www.zora.uzh.ch/id/eprint/52349/1/iewwp396.pdf</a></td>\n</tr>\n<tr>\n<td>Ozler and Baird, \"Using Group Interpersonal Psychotherapy to Improve the Well-Being of Adolescent Girls,\" (ongoing)</td>\n<td><a href=\"https://clinicaltrials.gov/ct2/show/NCT03966833\">https://clinicaltrials.gov/ct2/show/NCT03966833</a></td>\n</tr>\n<tr>\n<td>Patient, Patient Health Questionnaire (PHQ-9)</td>\n<td><a href=\"https://patient.info/doctor/patient-health-questionnaire-phq-9\">https://patient.info/doctor/patient-health-questionnaire-phq-9</a></td>\n</tr>\n<tr>\n<td>Plant and McGuire, \"Donating money, buying happiness: new meta-analyses comparing the cost-effectiveness of cash transfers and psychotherapy in terms of subjective well-being,\" 2021</td>\n<td><a href=\"https://forum.effectivealtruism.org/posts/mY4pZSwvFCDsjorJX/donating-money-buying-happiness-new-meta-analyses-comparing\">https://forum.effectivealtruism.org/posts/mY4pZSwvFCDsjorJX/donating-money-buying-happiness-new-meta-analyses-comparing</a></td>\n</tr>\n<tr>\n<td>Powdthavee and Vignoles 2008</td>\n<td><a href=\"https://DOI.org/10.1007/s11205-007-9223-2\">https://DOI.org/10.1007/s11205-007-9223-2</a></td>\n</tr>\n<tr>\n<td>Snowden, \"Why I don\u2019t agree with HLI\u2019s estimate of household spillovers from therapy,\" February 24, 2023</td>\n<td><a href=\"https://forum.effectivealtruism.org/posts/gr4epkwe5WoYJXF32/why-i-don-t-agree-with-hli-s-estimate-of-household\">https://forum.effectivealtruism.org/posts/gr4epkwe5WoYJXF32/why-i-don-t-agree-with-hli-s-estimate-of-household</a></td>\n</tr>\n<tr>\n<td>StrongMinds, \"Big Win For Mental Health in Uganda's schools,\" 2022</td>\n<td><a href=\"https://strongminds.org/big-win-for-mental-health-in-ugandas-schools/?blm_aid=21531\">https://strongminds.org/big-win-for-mental-health-in-ugandas-schools/?blm_aid=21531</a></td>\n</tr>\n<tr>\n<td>StrongMinds, \"Impact Evaluation: End of Phase Two Impact Evaluation for the Treating Depression at Scale in Africa Program in Uganda,\" July 2015</td>\n<td><a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf</a></td>\n</tr>\n<tr>\n<td>StrongMinds, \"Our Model at Work\"</td>\n<td><a href=\"https://strongminds.org/our-model/\">https://strongminds.org/our-model/</a></td>\n</tr>\n<tr>\n<td>StrongMinds, \"StrongMinds FAQs\"</td>\n<td><a href=\"https://strongminds.org/strongminds-faqs/\">https://strongminds.org/strongminds-faqs/</a></td>\n</tr>\n<tr>\n<td>StrongMinds, Q4 2022 Report</td>\n<td><a href=\"https://strongminds.org/wp-content/uploads/2023/03/2022-Q4-report-8.5x11-FINAL.pdf\">https://strongminds.org/wp-content/uploads/2023/03/2022-Q4-report-8.5x11-FINAL.pdf</a></td>\n</tr>\n<tr>\n<td>Swartz et al. 2008</td>\n<td><a href=\"https://doi.org/10.1176/appi.ajp.2008.07081339\">https://doi.org/10.1176/appi.ajp.2008.07081339</a></td>\n</tr>\n<tr>\n<td>The GiveWell Blog, \"Sequence thinking vs. cluster thinking,\" 2014</td>\n<td><a href=\"https://blog.givewell.org/2014/06/10/sequence-thinking-vs-cluster-thinking/\">https://blog.givewell.org/2014/06/10/sequence-thinking-vs-cluster-thinking/</a></td>\n</tr>\n<tr>\n<td>Thurman et al. 2017</td>\n<td><a href=\"https://doi.org/10.1111/camh.12241\">https://doi.org/10.1111/camh.12241</a></td>\n</tr>\n<tr>\n<td>Uganda Bureau of Statistics, Uganda National Household Survey 2019/2020</td>\n<td><a href=\"https://www.ubos.org/wp-content/uploads/publications/09_2021Uganda-National-Survey-Report-2019-2020.pdf\">https://www.ubos.org/wp-content/uploads/publications/09_2021Uganda-National-Survey-Report-2019-2020.pdf</a></td>\n</tr>\n<tr>\n<td>United Nations, Database on Household Size and Composition 2022</td>\n<td><a href=\"https://www.un.org/development/desa/pd/data/household-size-and-composition\">https://www.un.org/development/desa/pd/data/household-size-and-composition</a></td>\n</tr>\n</tbody>\n</table>\n<h2>Notes</h2>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn-AEsP2mm8QjfePzYi6-1\" class=\"footnote-item\"><p>\"Over 8-10 sessions, counselors guide structured discussions to help participants identify the underlying triggers of their depression and examine how their current relationships and their depression are linked.\" <a href=\"https://strongminds.org/our-model/\">StrongMinds, \"Our Model at Work\"</a></p>\n<p>\"StrongMinds treats African women with depression through talk therapy groups led by community workers. Groups consist of 5-10 women with depression or anxiety, meeting for a 90-minute session 1-2x per week for 4-8 weeks. Groups can meet in person or by phone.\" <a href=\"https://strongminds.org/strongminds-faqs/\">StrongMinds, \"StrongMinds FAQs\"</a> <a href=\"#fnref-AEsP2mm8QjfePzYi6-1\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-2\" class=\"footnote-item\"><p>See, for example: <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-2\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-3\" class=\"footnote-item\"><p>1.\u201cIn order to do as much good as possible, we need to compare how much good different things do in a single \u2018currency\u2019. At the Happier Lives Institute (HLI), we believe the best approach is to measure the effects of different interventions in terms of \u2018units\u2019 of subjective well-being (e.g. self-reports of happiness and life satisfaction).\" <a href=\"https://forum.effectivealtruism.org/posts/mY4pZSwvFCDsjorJX/donating-money-buying-happiness-new-meta-analyses-comparing\">Plant and McGuire, \"Donating money, buying happiness: new meta-analyses comparing the cost-effectiveness of cash transfers and psychotherapy in terms of subjective well-being,\" 2021</a></p>\n<p>2.\u201cWe will say that 1 WELLBY (wellbeing-adjusted life year) is equivalent to a 1-point improvement on a 0-10 life satisfaction scale for 1 year.\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>, p. 14. <a href=\"#fnref-AEsP2mm8QjfePzYi6-3\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-4\" class=\"footnote-item\"><p>\u201cExample evaluative measures: \u2026  An overall life satisfaction question, as adopted in the World Values Survey (Bj\u00f8rnskov, 2010): All things considered, how satisfied are you with your life as a whole these days? Using this card on which 1 means you are \u201ccompletely dissatisfied\u201d and 10 means you are \u201ccompletely satisfied\u201d where would you put your satisfaction with life as a whole?\u201d <a href=\"https://www.oecd-ilibrary.org/docserver/9789264191655-9-en.pdf\">OECD Guidelines on Measuring Subjective Well-Being: Annex A</a>, p. 1 <a href=\"#fnref-AEsP2mm8QjfePzYi6-4\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-5\" class=\"footnote-item\"><p>\"We found that GiveDirectly\u2019s cash transfers produce 8 WELLBYs/$1,000 and StrongMinds\u2019 psychotherapy produces 77 WELLBYs/$1,000, making the latter about 10 times more cost-effective than GiveDirectly.\" <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>, p. 16. <a href=\"#fnref-AEsP2mm8QjfePzYi6-5\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-6\" class=\"footnote-item\"><p><a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\">Happier Lives Institute, \"Happiness for the whole family: Accounting for household spillovers when comparing the cost-effectiveness of psychotherapy to cash transfers,\" February 2022</a>, p. 22, Table 2: summary of estimated spillover effects and change in comparison. <a href=\"#fnref-AEsP2mm8QjfePzYi6-6\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-7\" class=\"footnote-item\"><ol>\n<li>\n<p><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</a>, p. 15, Table 2: Evidence of direct and indirect evidence of StrongMinds' effectiveness.</p>\n</li>\n<li>\n<p>Studies are described in \"Section 4. Effectiveness of StrongMinds' core programme,\" Pp. 9-18.</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-7\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-8\" class=\"footnote-item\"><p>These are described in <a href=\"https://docs.google.com/spreadsheets/d/1jyi44_LxAxxuHoqWRDYjfG4I3qVabILDYOvRrjXol-k/edit#gid=59603083&amp;range=B1:K9\">this spreadsheet</a> and Table A.3 of <a href=\"https://www.happierlivesinstitute.org/report/psychotherapy-cost-effectiveness-analysis/\">this page</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-8\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-9\" class=\"footnote-item\"><p><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</a>, Section \"6.5 Considerations and limitations,\" Pp. 26-27. <a href=\"#fnref-AEsP2mm8QjfePzYi6-9\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-10\" class=\"footnote-item\"><p>See <a href=\"https://docs.google.com/spreadsheets/d/1jyi44_LxAxxuHoqWRDYjfG4I3qVabILDYOvRrjXol-k/edit#gid=59603083&amp;range=J9\">this cell</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-10\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-11\" class=\"footnote-item\"><p><a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\">Happier Lives Institute, \"Happiness for the whole family: Accounting for household spillovers when comparing the cost-effectiveness of psychotherapy to cash transfers,\" February 2022</a>, p. 22, Table 2: summary of estimated spillover effects and change in comparison. <a href=\"#fnref-AEsP2mm8QjfePzYi6-11\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-12\" class=\"footnote-item\"><p>1.<a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\">Happier Lives Institute, \"Happiness for the whole family: Accounting for household spillovers when comparing the cost-effectiveness of psychotherapy to cash transfers,\" February 2022</a>, p. 19, Figure 3.</p>\n<p>2.\u201cA limitation to the external validity of this evidence is that all of the samples were selected based on negative shocks happening to the children in the sample. In Kemp et al. (2009), children received EMDR for PTSD symptoms following an automobile accident. In Mutamba et al. (2018), caregivers of children with nodding syndrome received group interpersonal psychotherapy. In Swartz et al. (2008), depressed mothers of children with psychiatric illness received interpersonal psychotherapy. We are not sure if this would lead to an over or underestimate of the treatment effects, but it is potentially a further deviation from the type of household we are trying to predict the effects of psychotherapy for. Whilst recipients of programmes like StrongMinds might have children who have experienced negative shocks, we expect this is not the case for all of them.\u201d <a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\">Happier Lives Institute, \"Happiness for the whole family: Accounting for household spillovers when comparing the cost-effectiveness of psychotherapy to cash transfers,\" February 2022</a>, p. 12. <a href=\"#fnref-AEsP2mm8QjfePzYi6-12\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-13\" class=\"footnote-item\"><p>1 + (5.85-1)*0.53)= 3.5705 <a href=\"#fnref-AEsP2mm8QjfePzYi6-13\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-14\" class=\"footnote-item\"><ol>\n<li>\n<p>6.06 = 1.69 + 4.85 * 1.69 * 0.53</p>\n</li>\n<li>\n<p><a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\">Happier Lives Institute, \"Happiness for the whole family: Accounting for household spillovers when comparing the cost-effectiveness of psychotherapy to cash transfers,\" February 2022</a>, Table 2, p. 22.</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-14\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-15\" class=\"footnote-item\"><ol>\n<li>\n<p>Life satisfaction point-years are also known as WELLBYs.</p>\n</li>\n<li>\n<p>\u201cTo convert from SD-years to WELLBYs we multiply the SD-years by the average SD of life satisfaction (2.17, see row 8, <a href=\"https://docs.google.com/spreadsheets/d/1RrBuiPVgL-t8hlr6EqkqABiaqdHMGkpvfeiqiiX49LU\">\u201cInputs\u201d tab</a>), which results in 0.6 x 2.17 = 1.3 WELLBYs.\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>, p. 25.</p>\n</li>\n<li>\n<p>See <a href=\"https://docs.google.com/spreadsheets/d/1ESXTA9kD5aYJb8_dKgMsHxJralL1RaS8q7V4zSoOkyY/edit#gid=2083362429&amp;range=D2\">this cell</a>.</p>\n</li>\n<li>\n<p>\u201cOur previous results (McGuire et al., 2022b) are in standard deviation changes over time (SD-years) of subjective wellbeing gained. Since these effects are standardised by dividing the raw effect by its SD, we convert it into life satisfaction points by unstandardising it with the global SD (2.2, see <a href=\"https://docs.google.com/spreadsheets/d/1RrBuiPVgL-t8hlr6EqkqABiaqdHMGkpvfeiqiiX49LU/edit#gid=309035308\">row 8</a>) for life satisfaction (Our World in Data). Crucially, we assume a one-to-one exchange rate between a 1 SD change in affective mental health and subjective wellbeing measures. We\u2019re concerned this may not be justified, but our investigations so far have not supported a different exchange rate.\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>, footnote 24, p. 16.</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-15\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-16\" class=\"footnote-item\"><p>See <a href=\"https://docs.google.com/spreadsheets/d/1RrBuiPVgL-t8hlr6EqkqABiaqdHMGkpvfeiqiiX49LU/edit#gid=309035308&amp;range=A6:G8\">these cells</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-16\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-17\" class=\"footnote-item\"><p><a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\">Happier Lives Institute, \"Happiness for the whole family: Accounting for household spillovers when comparing the cost-effectiveness of psychotherapy to cash transfers,\" February 2022</a>, p. 22, Table 2: summary of estimated spillover effects and change in comparison. <a href=\"#fnref-AEsP2mm8QjfePzYi6-17\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-18\" class=\"footnote-item\"><ol>\n<li>\n<p>6.06 * 2.17 / $170 * $1,000</p>\n</li>\n<li>\n<p>This is 36 SD-years improvements in depression scores per $1,000 spent. That matches the value <a href=\"https://docs.google.com/spreadsheets/d/1ESXTA9kD5aYJb8_dKgMsHxJralL1RaS8q7V4zSoOkyY/edit#gid=2083362429&amp;range=B2\">here</a>.</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-18\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-19\" class=\"footnote-item\"><p>\u201cWe start with the simplest account, deprivationism. On this view: <em>badness of death = net wellbeing level x years of life lost</em></p>\n<p>\u201cWe assume that the average age of the individual who dies from malaria is 20 years old, they would expect to live to 70, and so preventing their death leads to 50 extra years. We estimate their average expected life satisfaction to be 4.95/10. Hence, the WELLBYs gained by the person whose death is prevented is (4.95 \u2013 neutral point) * (70 \u2013 20).\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>, p. 17. <a href=\"#fnref-AEsP2mm8QjfePzYi6-19\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-20\" class=\"footnote-item\"><p>\u201cWe assume that the average age of the individual who dies from malaria is 20 years old, they would expect to live to 70, and so preventing their death leads to 50 extra years. We estimate their average expected life satisfaction to be 4.95/10. Hence, the WELLBYs gained by the person whose death is prevented is (4.95 \u2013 neutral point) * (70 \u2013 20).\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>, p. 17. <a href=\"#fnref-AEsP2mm8QjfePzYi6-20\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-21\" class=\"footnote-item\"><p>\u201cAccording to GiveWell, it costs $3,000 for AMF to prevent a death (on average).\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>, p. 18. <a href=\"#fnref-AEsP2mm8QjfePzYi6-21\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-22\" class=\"footnote-item\"><p>Equals $3,000 per death averted divided by (4.95-0.05)*50 WELLBYs per death averted x $1,000. <a href=\"#fnref-AEsP2mm8QjfePzYi6-22\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-23\" class=\"footnote-item\"><p>\u201cWe estimate the grief-averting effect of preventing a death is 7 WELLBYs for each death prevented (see Appendix A.2), so 2.4 WELLBYs/$1,000. We estimate the income-increasing effects to be 4 WELLBYs/$1,000 (see Appendix A.1).\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>, p. 18 <a href=\"#fnref-AEsP2mm8QjfePzYi6-23\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-24\" class=\"footnote-item\"><p>We're ignoring HLI's estimates of the cost-effectiveness of cash transfers because the most important point of comparison is to our top charities, and because we don\u2019t come to a meaningfully different bottom line on cost-effectiveness of GiveDirectly than HLI does. An overview of its calculations are <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=902328019&amp;range=A1\">here</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-24\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-25\" class=\"footnote-item\"><p>Calculations are summarized in <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=902328019&amp;range=B18\">this spreadsheet</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-25\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-26\" class=\"footnote-item\"><p>We identified three RCTs that tested the impact of IPT-G on depression in a low- and middle-income country context (<a href=\"https://jamanetwork.com/journals/jama/fullarticle/196766\">Bolton et al. 2003</a>, <a href=\"https://jamanetwork.com/journals/jama/fullarticle/208211\">Bolton et al. 2007</a>, <a href=\"https://acamh.onlinelibrary.wiley.com/doi/10.1111/camh.12241\">Thurman et al. 2017</a>). Two of these trials (<a href=\"https://jamanetwork.com/journals/jama/fullarticle/196766\">Bolton et al. 2003</a> and <a href=\"https://jamanetwork.com/journals/jama/fullarticle/208211\">Bolton et al. 2007</a>) find IPT-G decreases symptoms of depression, while one (<a href=\"https://acamh.onlinelibrary.wiley.com/doi/10.1111/camh.12241\">Thurman et al. 2017</a>) does not find evidence of an effect. Averaging across trials, we estimate an effect on depression scores of <a href=\"https://docs.google.com/spreadsheets/d/1MJbT2P6OQ8n3DkVvCf1ez1XITuhxm0A6KZ7DONalALY/edit#gid=0&amp;range=D8\">1.1 standard deviations</a>. We describe our weighting in <a href=\"https://docs.google.com/document/d/1gVxVoAeZoRVG2nGeI0B_6h0saJKmjNz_K7cmpSoRCI4/edit\">this document</a>.</p>\n<p>We also did a quick review of three meta-analyses of the effect of various forms of therapy on depression score in low-, middle- and high-income countries. We have low confidence that these papers provide a comprehensive look at the effect of therapy on depression, and we view it as an intuitive check on the findings from the three RCTs of IPT-G in Sub-Saharan Africa.</p>\n<p>These trials have effects that range from 0.2 to 0.9 standard deviations, which is lower than what we found in IPT-G trials in Sub-Saharan Africa reported above.</p>\n<ul>\n<li><a href=\"https://pubmed.ncbi.nlm.nih.gov/27032627/\">Cuijpers et al. 2016</a> is a meta-analysis of RCTs of the effect interpersonal psychotherapy (IPT) on mental health. It finds IPT for depression had an effect of 0.6 standard deviations (95% CI 0.45-0.75) across 31 studies.</li>\n<li><a href=\"https://www.researchgate.net/publication/316250114_Meta-analysis_of_interventions_for_posttraumatic_stress_disorder_and_depression_in_adult_survivors_of_mass_violence_in_low-_and_middle-income_countries\">Morina et al. 2017</a> is a meta-analysis of RCTs of psychotherapy for adult post-traumatic stress disorder and depression in low- and middle-income countries.# It finds an effect of 0.86 standard deviations (95% CI 0.536-1.18) for 11 studies measuring an effect on depression.</li>\n<li><a href=\"https://pubmed.ncbi.nlm.nih.gov/19490745/\">Cuijpers et al. 2010</a> is a meta-analysis of RCTs of psychotherapy for adult depression that examines whether effect size varies with study quality. It finds an effect of 0.22 standard deviations for high-quality studies, compared to 0.74 for low-quality studies.</li>\n</ul>\n<p>Based on this, we apply a 25% downward adjustment to these trials. We put slightly higher weight on <a href=\"https://pubmed.ncbi.nlm.nih.gov/19490745/\">Cuijpers et al. 2010</a>, which finds a 0.2 standard deviations effect, since it explicitly takes into account study quality, and our best guess is the typical therapy program reduces depression scores by 0.4 standard deviations. We put a 40% weight on these meta-analyses and 60% weight on the trials from Sub-Saharan Africa reported above (<a href=\"https://jamanetwork.com/journals/jama/fullarticle/196766\">Bolton et al. 2003</a>, <a href=\"https://doi.org/10.1001/jama.298.5.519\">Bolton et al. 2007</a>, and <a href=\"https://acamh.onlinelibrary.wiley.com/doi/10.1111/camh.12241\">Thurman et al. 2017</a>), which implies an average effect of 0.82, or a 25% downward adjustment. Weight effect is 0.82 = 1.1<em>60% + 0.4</em>40%. This is 75% of the effect reported in IPT-G trials from Sub-Saharan Africa, or a 25% discount. <a href=\"#fnref-AEsP2mm8QjfePzYi6-26\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-27\" class=\"footnote-item\"><p>\u201cIn 2022 we expect the cost to treat one patient will be $105 USD.\u201d <a href=\"https://forum.effectivealtruism.org/posts/82heDPsmvhThda3af/ama-sean-mayberry-founder-and-ceo-of-strongminds\">Mayberry, \"AMA: Sean Mayberry, Founder &amp; CEO of StrongMinds,\" November 2022</a> <a href=\"#fnref-AEsP2mm8QjfePzYi6-27\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-28\" class=\"footnote-item\"><p>For example, we estimate Malaria Consortium in Oyo, Nigeria is 11 times as cost-effective as GiveDirectly under our current moral weights and 69 life satisfaction point-years per $1,000 spent under a subjective well-being approach, and HKI in Guinea is 11 times as cost-effective as GiveDirectly under our current approach and 71 life satisfaction point-years per $1,000 spent under a subjective well-being approach. See <a href=\"https://docs.google.com/spreadsheets/d/1kjNMZdNVj4cZuTTMAosfAtAtFwxNr-4S_PIgpcWVys8/edit#gid=1070538669\">this spreadsheet</a> for calculations. <a href=\"#fnref-AEsP2mm8QjfePzYi6-28\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-29\" class=\"footnote-item\"><p><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/Happiness-for-the-whole-family.pdf\">Happier Lives Institute, \"Happiness for the whole family: Accounting for household spillovers when comparing the cost-effectiveness of psychotherapy to cash transfers,\" February 2022</a>, Appendix A, Section A2. Psychotherapy studies, p. 32. <a href=\"#fnref-AEsP2mm8QjfePzYi6-29\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-30\" class=\"footnote-item\"><p><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/Happiness-for-the-whole-family.pdf\">Happier Lives Institute, \"Happiness for the whole family: Accounting for household spillovers when comparing the cost-effectiveness of psychotherapy to cash transfers,\" February 2022</a>, Figure 3, p. 19. <a href=\"#fnref-AEsP2mm8QjfePzYi6-30\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-31\" class=\"footnote-item\"><ol>\n<li>\n<p>\u201cThe therapist also related interpersonal therapy\u2019s emphasis on addressing interpersonal stressors, which led Ms. A to say that she needed guidance in dealing with Ann\u2019s problems. The therapist explained that IPT-MOMS would specifically help Ms. A find ways to interact with Ann that would be more helpful to both mother and daughter.\u201d <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2757752/\">Swartz et al. 2008</a>, p. 7.</p>\n</li>\n<li>\n<p>\u201cITP-MOMS has been described elsewhere (18). Briefly, it consists of an initial engagement session based on principles of motivational interviewing and ethnographic interviewing (28), which is designed to explore and resolve potential barriers to treatment seeking (17, 29), followed by eight sessions of brief in- terpersonal psychotherapy (30). IPT-MOMS differs from standard interpersonal psychotherapy (16) in that 1) it follows the brief in- terpersonal psychotherapy model that is both shorter than standard interpersonal psychotherapy and uses some \u201csoft\u201d behavioral strategies to rapidly activate depressed patients (30), 2) it incorporates a motivational interviewing- and ethnographic in- terviewing-based engagement session and continues to draw on these engagement strategies as needed during the treatment, and <strong>3) it uses specific strategies to assist mothers in managing prob- lematic interpersonal relationships with their dependent, psychi- atrically ill offspring</strong>. [...] Subjects assigned to treatment as usual were informed of their diagnoses, given psychoeducational materials, and told to seek treatment.\u201d Swartz et al 2008, p. 3.</p>\n</li>\n<li>\n<p>A <a href=\"https://www.youtube.com/watch?v=RQ2eYn-J8w8\">video</a> shared in Mutamba et al. 2018b shows sample sessions with women discussing care of children with nodding syndrome.</p>\n</li>\n<li>\n<p>Mutamba et al. 2018b provides more description of the intervention in Mutambda et al. 2008. \u201cQuantitative results of the trial have been published and demonstrate the effectiveness of IPT-G in treating depression in both caregivers and their children [<a href=\"https://implementationscience.biomedcentral.com/articles/10.1186/s13012-018-0785-y#ref-CR34\">34</a>].\u201d <a href=\"https://implementationscience.biomedcentral.com/articles/10.1186/s13012-018-0785-y\">Mutamba et al. 2018b</a>, p. 10.</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-31\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-32\" class=\"footnote-item\"><ol>\n<li>\n<p>\"In the forest plot above, HLI reports that Kemp et al. (2009) finds a non-significant 0.35 [-0.43,1.13] standard deviation improvement in mental health for parents of treated children. But table 2 reports that parents in the treatment groups\u2019 score on the GHQ-12 <em>increased</em> relative to the wait-list group (higher scores on the GHQ-12 indicate more self-reported mental health problems).\" <a href=\"https://forum.effectivealtruism.org/posts/gr4epkwe5WoYJXF32/why-i-don-t-agree-with-hli-s-estimate-of-household\">Snowden, \"Why I don\u2019t agree with HLI\u2019s estimate of household spillovers from therapy,\" February 24, 2023</a></p>\n</li>\n<li>\n<p>From HLI's comment: \"This correction would reduce the spillover effect from 53% to 38% and reduce the cost-effectiveness comparison from 9.5 to 7.5x, a clear downwards correction.\" <a href=\"https://forum.effectivealtruism.org/posts/gr4epkwe5WoYJXF32/why-i-don-t-agree-with-hli-s-estimate-of-household\">Snowden, \"Why I don\u2019t agree with HLI\u2019s estimate of household spillovers from therapy,\" February 24, 2023</a></p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-32\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-33\" class=\"footnote-item\"><p><a href=\"https://openknowledge.worldbank.org/bitstream/handle/10986/4493/1564698x-23-1-31-55.pdf?sequence=1&amp;isAllowed=y\">Das et al. 2008</a>, Table 2 for results. <a href=\"#fnref-AEsP2mm8QjfePzYi6-33\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-34\" class=\"footnote-item\"><p>\u201cIn summary, Table 4 suggests that there is variation by gender in the estimated transmission coefficient from parental distress to child\u2019s LS. Specifically, mothers\u2019 distress levels do not appear to be an important determinant of boys\u2019 LS. \u2026 Transmission correlations are quantitatively important as well as statistically significant. For example, the mean of _FDhi(t-1) _and _MDhi(t-1) _are 1.759 and 2.186, and their standard deviations are 2.914 and 3.208, respectively. An increase of one standard deviation from the means of _FDhi(t-1) _and _MDhi(t-1) _imply a change in the mental distress level to 4.674 for fathers and 5.394 for mothers. Taking conservative estimates of _FDhi(t-1) _and _MDhi(t-1) _for girls to be -.029 and -.022, the implied changes in the girl\u2019s LS are approximately -.051 and - .048. Given that the mean of LS for girls is 5.738 and its standard deviation is 1.348, a _ceteris paribus _increase of one standard deviation in either parent\u2019s mental distress level explains around a 25% drop in the standard deviation in the girl\u2019s LS.\u201d <a href=\"https://www.researchgate.net/publication/40676370_Mental_Health_of_Parents_and_Life_Satisfaction_of_Children_A_Within-Family_Analysis_of_Intergenerational_Transmission_of_Well-Being\">Powdthavee and Vignoles 2008</a>, p. 18. <a href=\"#fnref-AEsP2mm8QjfePzYi6-34\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-35\" class=\"footnote-item\"><p>\u201cIn Table 7, we begin with the analysis of the impact of the partner\u2019s standardised SF36 mental health score (0-100, where higher values represent higher level of well-being). Increasing this score by one standard deviation increases individual\u2019s life satisfaction by 0.07 points (on a 1-10 scale), which is equivalent to 5% of a standard deviation in life satisfaction. To put this in context, this is similar to the (reversed) effect of becoming unemployed or being victim of a property crime (see Table 10).\u201d <a href=\"https://docs.iza.org/dp11431.pdf\">Mendolia et al. 2018</a>, p. 12. <a href=\"#fnref-AEsP2mm8QjfePzYi6-35\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-36\" class=\"footnote-item\"><ol>\n<li>\n<p>For <a href=\"https://openknowledge.worldbank.org/bitstream/handle/10986/4493/1564698x-23-1-31-55.pdf?sequence=1&amp;isAllowed=y\">Das et al. 2008</a>, Table 2 includes controls for age, female, married, widowed, education indicators, household consumption, household size, physical health, elderly dependents, and young dependents. See Pp. 39-40.</p>\n</li>\n<li>\n<p>For <a href=\"https://www.researchgate.net/publication/40676370_Mental_Health_of_Parents_and_Life_Satisfaction_of_Children_A_Within-Family_Analysis_of_Intergenerational_Transmission_of_Well-Being\">Powdthavee and Vignoles 2008</a>: \u201cWe include a set of youth attributes, as well as both parents\u2019 characteristics and some household characteristics ((taken from the main BHPS dataset) as control variables in the child\u2019s LS regressions. Youth attributes include child\u2019s age and the number of close friends the child has. Age and the number of close friends are measured as continuous variables, and are time-varying across the observation waves. Parental characteristics include education, employment status, and health status of both parents if present in the household. Education is captured by two dummy variables, which represent (i) whether the parent achieved A levels or not and (ii) whether they achieved a degree. More disaggregated measures of parental education are not feasible with these data. Parental employment status is measured as a categorical variable identifying selfemployment and full-time employment. Health status is also measured as a categorical variable, ranging from \u201c1.very poor health\u201d to \u201c5.excellent health\u201d. Household characteristics include household income in natural log form and the number of children in the household. Household income is calculated by taking the summation of all household members\u2019 annual incomes and is converted into real income in 1995 prices by dividing it by the annual consumer prices index (CPI). The number of children is a continuous variable and time varying across the panel. We include these variables because they are known to be correlated with measures of LS, and they may also be correlated with the mental distress of the parents (for a review, see Oswald, 1997). Following prior studies on how to model psychological well-being (Clark, 2003; Gardner &amp; Oswald, 2007), a similar set of controls were included in each parent\u2019s mental distress equations, with the addition of each parent\u2019s age. The spouse\u2019s observed characteristics are not included in the parent\u2019s own mental distress equation as the model already allows for the correlations between the residuals. We also include the gender of the child in later analyses of moderating gender effects. Details of mean scores and standard deviations in the final sample for each of the dependent and control variables are given in Appendix B. In order to avoid non-response bias, we create dummy variables representing missing values for all control variables in the final sample.\u201d p. 12.</p>\n</li>\n<li>\n<p>For <a href=\"https://docs.iza.org/dp11431.pdf\">Mendolia et al. 2018</a>: \u201cOur main model (Specification 1) includes an extensive set of independent variables, to consider other factors that may influence life satisfaction, such as individual\u2019s and partner\u2019s self-assessed health, education, gender, employment and marital status, number and age of children, geographic remoteness, time binary variables1 , and life events that took place in the last 12 months (personal injury or illness, serious illness of a family member, victim of physical violence, death of a close relative or family member, victim of a property crime). We also estimate two additional specifications (Specifications 2 and 3) of each model, including other variables, such as partners\u2019 long term conditions, and possible strategies to help the individual to deal with partners\u2019 mental health, such as presence of social networks, and engagement in social activities. The complete list of variables included in the model is reported in Table 4.\u201d p. 9.</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-36\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-37\" class=\"footnote-item\"><p>\u201cWe calculate average household sizes by averaging the latest available data from the United Nations Population Division (2019a), with average rural household sizes in these countries. Rural household size data comes from the Global Data Lab. We do this because StrongMinds and GiveDirectly operate mainly in rural or suburban areas.\u201d <a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\">Happier Lives Institute, \"Happiness for the whole family: Accounting for household spillovers when comparing the cost-effectiveness of psychotherapy to cash transfers,\" February 2022</a>, p. 33. <a href=\"#fnref-AEsP2mm8QjfePzYi6-37\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-38\" class=\"footnote-item\"><p><a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\">Happier Lives Institute, \"Happiness for the whole family: Accounting for household spillovers when comparing the cost-effectiveness of psychotherapy to cash transfers,\" February 2022</a>, Table 2, p. 22. <a href=\"#fnref-AEsP2mm8QjfePzYi6-38\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-39\" class=\"footnote-item\"><ol>\n<li>\n<p>The Global Data Lab household size estimate is approximately <a href=\"https://globaldatalab.org/areadata/table/hhsize/KEN+UGA/?levels=1+2+3\">6.3 for rural areas in Kenya and Uganda 2019</a>.</p>\n</li>\n<li>\n<p>The UN household size estimate for Uganda is approximately 4.9 based on 2019 DHS data (from \"dataset\" spreadsheet, sheet \"HH Size and Composition 2022,\" downloaded <a href=\"https://www.un.org/development/desa/pd/data/household-size-and-composition\">here</a>).</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-39\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-40\" class=\"footnote-item\"><p><a href=\"https://www.ubos.org/wp-content/uploads/publications/09_2021Uganda-National-Survey-Report-2019-2020.pdf\">Uganda Bureau of Statistics, Uganda National Household Survey 2019/2020</a>, Figure 2.4, p. 36. <a href=\"#fnref-AEsP2mm8QjfePzYi6-40\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-41\" class=\"footnote-item\"><ol>\n<li>\n<p>See, for example, Table 1B. Effect on depression at t=0 in Cohen\u2019s d.</p>\n</li>\n<li>\n<p>\u201cWe assume that treatment improves the \u2018subjective well-being\u2019 factors to the same extent as the \u2018functioning\u2019 factors, and therefore we could unproblematically compare depression measures to \u2018pure\u2019 SWB measures using changes in standard deviations (Cohen\u2019s d).\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</a>, p. 14.</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-41\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-42\" class=\"footnote-item\"><ol>\n<li>\n<p>\u201cTo convert from SD-years to WELLBYs we multiply the SD-years by the average SD of life satisfaction (2.17, see row 8, <a href=\"https://docs.google.com/spreadsheets/d/1RrBuiPVgL-t8hlr6EqkqABiaqdHMGkpvfeiqiiX49LU\">\u201cInputs\u201d tab</a>), which results in 0.6 x 2.17 = 1.3 WELLBYs.\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>, p. 25.</p>\n</li>\n<li>\n<p>See <a href=\"https://docs.google.com/spreadsheets/d/1ESXTA9kD5aYJb8_dKgMsHxJralL1RaS8q7V4zSoOkyY/edit#gid=2083362429&amp;range=D2\">this cell</a>.</p>\n</li>\n<li>\n<p>\u201cOur previous results (McGuire et al., 2022b) are in standard deviation changes over time (SD-years) of subjective wellbeing gained. Since these effects are standardised by dividing the raw effect by its SD, we convert it into life satisfaction points by unstandardising it with the global SD (2.2, see row 8) for life satisfaction (Our World in Data). Crucially, we assume a one-to-one exchange rate between a 1 SD change in affective mental health and subjective wellbeing measures. We\u2019re concerned this may not be justified, but our investigations so far have not supported a different exchange rate.\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/11/The-Elephant-in-the-Bednet-MASTER.pdf\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>, footnote 24, p. 16.</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-42\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-43\" class=\"footnote-item\"><p>\u201cWe summarized the relative effectiveness of five different therapeutic interventions on SWB (not just LS specifically) and depression. The results are summarized in <a href=\"https://docs.google.com/spreadsheets/d/1_ggdEur8uhQozmNWqWUZumr-w7Zv_3gR4dJnYysnoCE/edit?usp=sharing\">this spreadsheet</a>. The average ratio of SWB to depression changes in the five meta-analyses is 0.89 SD; this barely changes if we remove the SWB measures that are specifically affect-based.\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/Psychotherapy-CEA.pdf\">Happier Lives Institute, \"Cost-effectiveness analysis: Group or task-shifted psychotherapy to treat depression,\" 2021</a>, p. 29. <a href=\"#fnref-AEsP2mm8QjfePzYi6-43\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-44\" class=\"footnote-item\"><p>Examples of scales are here:</p>\n<ul>\n<li><a href=\"https://www.apa.org/depression-guideline/hamilton-rating-scale.pdf\">American Psychological Association, Hamilton Depression Rating Scale (HAM-D)</a></li>\n<li><a href=\"https://patient.info/doctor/patient-health-questionnaire-phq-9\">Patient, Patient Health Questionnaire (PHQ-9)</a></li>\n<li><a href=\"https://www.brightfutures.org/mentalhealth/pdf/professionals/bridges/ces_dc.pdf\">Bright Futures, Center for Epidemiological Studies Depression Scale for Children (CES-DC)</a></li>\n</ul>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-44\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-45\" class=\"footnote-item\"><p>StrongMinds reports in its 2022 Q4 report that across all programs 100% of participants had depression (3% mild, 41% moderate, 41% moderate-severe, 15% severe). <a href=\"https://strongminds.org/wp-content/uploads/2023/03/2022-Q4-report-8.5x11-FINAL.pdf\">StrongMinds, Q4 2022 Report</a>, p. 2 <a href=\"#fnref-AEsP2mm8QjfePzYi6-45\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-46\" class=\"footnote-item\"><p>Some possibilities are as follows. As StrongMinds scales up its program:</p>\n<ul>\n<li>It has to train more facilitators. It seems possible that the first individuals to come forward to get trained as facilitators are the highest quality, and that as more individuals come forward as the program scales up in an area the marginal facilitator is of decreasing quality.</li>\n<li>It may not have the resources to oversee the quality of implementation at scale to the same extent as academic researchers in a small trial.</li>\n<li>It may start to operate in new contexts in which it has less experience or understanding of locally relevant concepts/causes of depression. It may take time to tailor its program accordingly, and in the meantime the program may be less effective.</li>\n</ul>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-46\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-47\" class=\"footnote-item\"><p>\u201cBolton et al. (2003) and its six-month follow-up (Bass et al., 2006) were studies of an RCT deployed in Uganda (where StrongMinds primarily operates). StrongMinds based its core programme on the form, format, and facilitator training[footnote 5] of this RCT, which makes it highly relevant as a piece of evidence. StrongMinds initially used the same number of sessions (16) but later reduced its number of sessions to 12.  They did this because the extra sessions did not appear to confer much additional benefit (<a href=\"https://strongminds.org/wp-content/uploads/2013/07/StrongMinds-Phase-Two-Impact-Evaluation-Report-July-2015-FINAL.pdf\">StrongMinds, 2015</a>, p.18), so it did not seem worth the cost to maintain it\u2026.Footnote 5: In personal communication StrongMinds says that their mental health facilitators receive slightly less training than those in the Bolton et al., (2003) RCT.\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</a>, p. 10. <a href=\"#fnref-AEsP2mm8QjfePzYi6-47\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-48\" class=\"footnote-item\"><ol>\n<li>\n<p>\"Finally, the study was conducted following rapid program scale-up. Mechanisms to ensure implementation fidelity were not overseen by the researchers, in contrast to the Uganda trial (Bolton et al., 2007). This study captured World Vision South Africa\u2019s first experience delivering IPTG in these communities; time and experience may contribute to increased effectiveness. A variety of new local implementation contexts, many of them resource-constrained, and the pace and scope of scale-up likely contributed to variation in the level of program quality and fidelity to the original model\", <a href=\"https://doi.org/10.1111/camh.12241\">Thurman et al. 2017</a>, p. 229.</p>\n</li>\n<li>\n<p>\"While 23% of adolescents in the intervention group did not attend any IPTG sessions, average attendance was 12 out of 16 possible sessions among participants. The intervention was not associated with changes in depression symptomology.\" <a href=\"https://doi.org/10.1111/camh.12241\">Thurman et al. 2017</a>, Abstract, \"Results.\"</p>\n</li>\n<li>\n<p>Whilst we might not want to additionally adjust the estimates in <a href=\"https://doi.org/10.1111/camh.12241\">Thurman et al. 2017</a> much for this concern, we do want to adjust the estimates in the two Bolton et al. studies downwards. Without much detail in the Thurman et al. 2017 study as to the problems that rapid scale up caused with implementation, we have not adjusted the relative weights in the meta-analysis to favor the <a href=\"https://doi.org/10.1111/camh.12241\">Thurman et al. 2017</a> study (because it is hard to know to what extent those same factors would apply to StrongMinds' program).</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-48\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-49\" class=\"footnote-item\"><p>See \u201cEffect vs. sample size\u201d chart in <a href=\"https://docs.google.com/spreadsheets/d/11EX5dNZdK9-kNXHhXUXdOnqItaFaO0AA2ITHcM_jr-A/edit#gid=200587636\">this spreadsheet</a>.\nThese charts are based on the meta-analysis described in section 4.1.2 of <a href=\"https://www.happierlivesinstitute.org/report/strongminds-cost-effectiveness-analysis/\">this report</a> and the spreadsheet linked below:</p>\n<p>\u201cWe include evidence from psychotherapy that isn\u2019t directly related to StrongMinds (i.e., not based on IPT or delivered to groups of women). We draw upon a wider evidence base to increase our confidence in the robustness of our results. We recently reviewed any form of face-to-face modes of psychotherapy delivered to groups or by non-specialists, deployed in LMICs (<a href=\"https://www.happierlivesinstitute.org/report/psychotherapy-cost-effectiveness-analysis/\">HLI,  2020b</a>).9 At the time of writing, we have extracted data from 39 studies that appeared to be delivered by non-specialists and or to groups from five meta-analytic sources10 and any additional studies we found in our<a href=\"https://docs.google.com/spreadsheets/d/1j7odMDj_reHRzP0_6A4iA5s8yvPjlj5Pl6d2cKk86sw/edit#gid=896443586\"> search for the costs</a> of psychotherapy.</p>\n<p>\u201cThese studies are not exhaustive. We stopped collecting new studies due to time constraints (after 10 hours), and the perception that we had found most of the large and easily accessible studies from the extant literature.11 The studies we include and their features can be viewed <a href=\"https://docs.google.com/spreadsheets/d/1jyi44_LxAxxuHoqWRDYjfG4I3qVabILDYOvRrjXol-k/edit#gid=2009930020\">in this spreadsheet</a>.\u201d <a href=\"#fnref-AEsP2mm8QjfePzYi6-49\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-50\" class=\"footnote-item\"><p>\"Actual enrollment: 1914 participants.\" <a href=\"https://clinicaltrials.gov/ct2/show/NCT03966833\">Ozler and Baird, \"Using Group Interpersonal Psychotherapy to Improve the Well-Being of Adolescent Girls,\" (ongoing)</a>, \"Study Design.\" <a href=\"#fnref-AEsP2mm8QjfePzYi6-50\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-51\" class=\"footnote-item\"><p>\u201cStrongMinds recently conducted a geographically-clustered RCT (n = 394 at 12 months) but we were only given the results and some supporting details of the RCT. The weight we currently assign to it assumes that it improves on StrongMinds\u2019 impact evaluation and is more relevant than Bolton et al., (<a href=\"https://jamanetwork.com/journals/jama/fullarticle/196766\">2003</a>).  We will update our evaluation once we have read the full study.\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</a>, p. 11. <a href=\"#fnref-AEsP2mm8QjfePzYi6-51\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-52\" class=\"footnote-item\"><p>A couple examples of why social desirability bias might exist in this setting:</p>\n<ul>\n<li>If a motivated and pleasant IPT facilitator comes to your village and is trying to help you to improve your mental health, you may feel some pressure to report that the program has worked to reward the effort that facilitator has put into helping you.</li>\n<li>In Bolton et al. 2003, the experimenters told participants at the start of the study that the control group will receive the treatment at a later date if it proved effective. Participants might then feel some pressure to report that the treatment worked so as not to deprive individuals in control villages from receiving the treatment too. \"Prior to randomization, all potential participants were informed that if the intervention proved effective, it would later be offered to controls (currently being implemented by World Vision International)\", <a href=\"https://doi.org/10.1001/jama.289.23.3117\">Bolton et al. 2003</a>, p. 3118.</li>\n<li>Individuals may report worse findings if they think doing so would lead to them receiving the intervention. \u201cOn this occasion informed consent included advising each youth of the study group to which he or she had been allocated. Our NGO partners had previously agreed to provide/continue on a permanent basis whichever intervention proved effective. Individuals assigned to the wait-control group were told they would be first to receive whichever intervention (if any) proved effective.\u201d <a href=\"https://doi.org/10.1001/jama.298.5.519\">Bolton et al. 2007</a>, p. 522.</li>\n</ul>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-52\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-53\" class=\"footnote-item\"><p>\"As far as we can tell, this is not a problem. Haushofer et al., (2020), a trial of both psychotherapy and cash transfers in a LMIC, perform a test \u2018experimenter demand effect\u2019, where they explicitly state to the participants whether they expect the research to have a positive or negative effect on the outcome in question. We take it this would generate the maximum effect, as participants would know (rather than have to guess) what the experimenter would like to hear. Haushofer et al., (2020), found no impact of explicitly stating that they expected the intervention to increase (or decrease) self-reports of depression. The results were non-significant and close to zero (n = 1,545). [...]</p>\n<p>Other less relevant evidence of experimenter demand effects finds that it results in effects that are small or close to zero. Bandiera et al., (n =5966; 2020) studied a trial that attempted to improve the human capital of women in Uganda. They found that experimenter demand effects were close to zero. In an online experiment Mummolo &amp; Peterson, (2019) found that \u201cEven financial incentives to respond in line with researcher expectations fail to consistently induce demand effects.\u201d Finally, in de Quidt et al., (2018) while they find experimenter demand effects they conclude by saying \u201cAcross eleven canonical experimental tasks we \u2026 find modest responses to demand manipulations that explicitly signal the researcher\u2019s hypothesis\u2026 We argue that these treatments reasonably bound the magnitude of demand in typical experiments, so our \u2026 findings give cause for optimism.\u201d\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</a>, p. 26. <a href=\"#fnref-AEsP2mm8QjfePzYi6-53\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-54\" class=\"footnote-item\"><ol>\n<li>\n<p>Individuals may choose to report more favorable findings due to thinking that if they say it was helpful, others will receive the program.</p>\n</li>\n<li>\n<p>\u201cPrior to randomization, all potential participants were informed that if the intervention proved effective, it would later be offered to controls (currently being implemented by World Vision International).\u201d <a href=\"https://doi.org/10.1001/jama.289.23.3117\">Bolton et al. 2003</a>, p. 3118.</p>\n</li>\n<li>\n<p>Individuals may report worse findings if they think doing so would lead to them receiving the intervention.</p>\n</li>\n<li>\n<p>\u201cOn this occasion informed consent included advising each youth of the study group to which he or she had been allocated. Our NGO partners had previously agreed to provide/continue on a permanent basis whichever intervention proved effective. Individuals assigned to the wait-control group were told they would be first to receive whichever intervention (if any) proved effective.\u201d <a href=\"https://jamanetwork.com/journals/jama/fullarticle/208211\">Bolton et al. 2007</a>, p. 522.</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-54\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-55\" class=\"footnote-item\"><p>Calculations are in <a href=\"https://docs.google.com/spreadsheets/d/1jyi44_LxAxxuHoqWRDYjfG4I3qVabILDYOvRrjXol-k/edit#gid=59603083&amp;range=B7:J7\">this spreadsheet</a>. HLI applies an overall discount factor of <a href=\"https://docs.google.com/spreadsheets/d/11EX5dNZdK9-kNXHhXUXdOnqItaFaO0AA2ITHcM_jr-A/edit#gid=59603083&amp;range=J9\">89%</a>. Removing the publication bias adjustment (setting the weight in <a href=\"https://docs.google.com/spreadsheets/d/11EX5dNZdK9-kNXHhXUXdOnqItaFaO0AA2ITHcM_jr-A/edit#gid=59603083&amp;range=I7\">cell I7</a> to 0) changes this adjustment factor to 96%. <a href=\"#fnref-AEsP2mm8QjfePzYi6-55\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-56\" class=\"footnote-item\"><p>See funnel plots <a href=\"https://forum.effectivealtruism.org/posts/HqEmL7XAuuD5Pc4eg/evaluating-strongminds-how-strong-is-the-evidence?commentId=gtLgSMD8NjohTZtQM\">here</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-56\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-57\" class=\"footnote-item\"><p>\u201cAmong comparisons to control conditions, adding unpublished studies (Hedges\u2019 g = 0.20; CI95% -0.11~0.51; k = 6) to published studies (g = 0.52; 0.37~0.68; k = 20) reduced the psychotherapy effect size point estimate (g = 0.39; 0.08~0.70) by 25%.\u201d <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4589340/pdf/pone.0137864.pdf\">Driessen et al. 2015</a>, p. 1. <a href=\"#fnref-AEsP2mm8QjfePzYi6-57\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-58\" class=\"footnote-item\"><p>See estimates <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=76487430&amp;range=4:4\">here</a>. We describe calculations <a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness#Best_guess_on_cost_effectiveness\">above</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-58\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-59\" class=\"footnote-item\"><ol>\n<li>\n<p>\"We include evidence from psychotherapy that isn\u2019t directly related to StrongMinds (i.e., not based on IPT or delivered to groups of women).\" <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</a>, p. 12.</p>\n</li>\n<li>\n<p><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</a>, p. 15, Table 2: Evidence of direct and indirect evidence of StrongMinds' effectiveness.</p>\n</li>\n<li>\n<p>Studies are described in \"Section 4. Effectiveness of StrongMinds' core programme,\" Pp. 9-18.</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-59\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-60\" class=\"footnote-item\"><p>For example:</p>\n<ul>\n<li><a href=\"https://doi.org/10.1001/jama.289.23.3117\">Bolton et al. 2003</a> and <a href=\"https://doi.org/10.1001/jama.298.5.519\">Bolton et al. 2007</a> also only include individuals who have been screened for depression in the study. By contrast, Thurman et al. 2017 does not directly screen participants for depression (but rather targets an \"at risk\" group - children who have been orphaned as a result of HIV/AIDS or are otherwise vulnerable).</li>\n<li><a href=\"https://doi.org/10.1001/jama.298.5.519\">Bolton et al. 2007</a> treats individuals in camps for internally displaced people, 40% of whom had been abducted as children. <a href=\"https://doi.org/10.1111/camh.12241\">Thurman et al. 2017</a> treats children who have been orphaned as a result of HIV/AIDS or are otherwise vulnerable.</li>\n</ul>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-60\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-61\" class=\"footnote-item\"><p>These are in <a href=\"https://docs.google.com/spreadsheets/d/1jyi44_LxAxxuHoqWRDYjfG4I3qVabILDYOvRrjXol-k/edit#gid=2009930020\">this spreadsheet</a> and described in Appendix B (p. 30) of <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/Psychotherapy-CEA.pdf\">this page</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-61\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-62\" class=\"footnote-item\"><p><a href=\"https://www.happierlivesinstitute.org/report/strongminds-cost-effectiveness-analysis/\">Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</a>, Section 4.2 Trajectory of efficacy through time. <a href=\"#fnref-AEsP2mm8QjfePzYi6-62\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-63\" class=\"footnote-item\"><p><a href=\"https://www.happierlivesinstitute.org/report/strongminds-cost-effectiveness-analysis/\">Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</a>, Figure 3, p. 18.\n\u201cWe assume the effects have entirely dissipated in five years19 (95% CI: 2, 10).\u201d <a href=\"https://www.happierlivesinstitute.org/report/strongminds-cost-effectiveness-analysis/\">https://www.happierlivesinstitute.org/report/strongminds-cost-effectiveness-analysis/</a> <a href=\"#fnref-AEsP2mm8QjfePzYi6-63\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-64\" class=\"footnote-item\"><ol>\n<li>\n<p>The longest follow-up in the RCT literature on IPT-G in developing countries is 1y3m in <a href=\"https://doi.org/10.1111/camh.12241\">Thurman et al. 2017</a> (which demonstrates the persistence of a null effect measured 3 months after follow up).</p>\n</li>\n<li>\n<p>The next longest follow-up is the 6 month follow-up in Bass et al. 2006, which demonstrates the persistence of the treatment effect on the treated (although there is no direct test of the persistence of the intent-to-treat effect).</p>\n</li>\n<li>\n<p>It is possible that the effects persist for longer than the first 1-2 years, but that longer duration just hasn't been tested.</p>\n</li>\n<li>\n<p>However, I am skeptical that the effects persist beyond the first 1-2 years for two reasons: a) My prior is that a time-limited and fairly light-touch intervention (12 90-minute group sessions) is unlikely to have a persistent effect, b) These RCTs were done sufficiently long ago that the authors have had time to be able to conduct longer-term follow-ups. There are many possible reasons why they haven't done so which are not related to the effect size. However, I believe that a long-term follow-up demonstrating a persistent effect of IPT-G would make for a good academic publication and so the absence of a published long-term follow-up updates me slightly in the direction that the effect does not persist.</p>\n</li>\n</ol>\n <a href=\"#fnref-AEsP2mm8QjfePzYi6-64\" class=\"footnote-backref\">\u21a9\ufe0e</a></li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-65\" class=\"footnote-item\"><p>See \"Outcome Measures\" section, \"Primary Outcome Measures\" subsection <a href=\"https://clinicaltrials.gov/ct2/show/NCT03966833\">here</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-65\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-66\" class=\"footnote-item\"><p>\u201cIn 2022 we expect the cost to treat one patient will be $105 USD. By the end of 2024, we anticipate the cost per patient will have decreased to just $85. We will continue to reduce the cost of treating one woman even while our numbers increase. This is through effective scaling and continuing to evaluate where we can gain more cost savings. A donation to StrongMinds will be used as effectively and efficiently as possible. And when you think about what it costs for therapy in the United States, to spend just $105 and treat a woman for depression is a pretty incredible feat.\u201d <a href=\"https://forum.effectivealtruism.org/posts/82heDPsmvhThda3af/ama-sean-mayberry-founder-and-ceo-of-strongminds\">Sean Mayberry, Founder and CEO, StrongMinds, responses to questions on the Effective Altruism Forum, November 2022</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-66\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-67\" class=\"footnote-item\"><p>\u201cGroup tele-therapy (38.27% of 2021 budget) is delivered over the phone by trained mental health facilitators and volunteers (peers) to groups of 5 (mostly women) for 8 weeks. We expect the share of the budget this programme receives to decline as the threat of COVID diminishes.\u201d [...]</p>\n<p>\u201cIn addition to the core programme, StrongMinds also implements face-to-face g-IPT directed to young women and has begun a volunteer-run model. The youth programme (14.07%) is delivered by trained mental health facilitators to groups of adolescent girls.\u201d [...] \u201cStrongMinds\u2019 peer programme (5.70%) is described as \u201cself-replicating, volunteer-led talk therapy groups of eighteen people led by individuals trained in IPT-G. For this programme component, mental health facilitators recruit [core programme] graduates eager to give back to their communities and train them to be volunteer peer mental health facilitators. They train by co-facilitating courses of the core programme for half a year\u201d (<a href=\"https://strongminds.org/strongminds-our-model/\">StrongMinds.org, 2021</a>). The peer groups are smaller than the core programme groups (6-8) instead of 12-14.\u201d <a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2022/04/StrongMinds-CEA.pdf\">Happier Lives Institute, \"Cost-effectiveness analysis: StrongMinds,\" October 2021</a>, Pp. 22-23. <a href=\"#fnref-AEsP2mm8QjfePzYi6-67\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-68\" class=\"footnote-item\"><p>\"Building on this success, StrongMinds Uganda is advocating for new country-level adolescent mental healthcare policies. Between April and August of 2022, we identified and trained learners and female teachers from five districts around the country to serve as mental health advocates. All had experienced StrongMinds therapy as group members or leaders.\" <a href=\"https://strongminds.org/big-win-for-mental-health-in-ugandas-schools/?blm_aid=21531\">StrongMinds, \"Big Win For Mental Health in Uganda's schools,\" 2022</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-68\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-69\" class=\"footnote-item\"><p>See calculations <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=76487430&amp;range=A30:B31\">here</a>.</p>\n<p>Note that the comparisons to the value of deaths averted are assuming deprivationism and a neutral point of 0.5. In <a href=\"https://www.happierlivesinstitute.org/report/the-elephant-in-the-bednet/\">their report</a>, HLI presents a range of views of the badness of death and does not share an explicit view about the value of saving a life. Assuming deprivationism and a neutral point of 0.5 leads to among the highest values for averting a death. As a result, nearly all of the alternative assumptions HLI presents would suggest lower values for averting a death and lead to us what we think are more unintuitive conclusions. <a href=\"#fnref-AEsP2mm8QjfePzYi6-69\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-70\" class=\"footnote-item\"><p>See calculations <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=76487430&amp;range=A32:B32\">here</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-70\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-71\" class=\"footnote-item\"><p>HLI estimates 1.70 SD-years of impact over 2.13 years and 2.17 life satisfaction points per SD of impact, compared to 4.45 life satisfaction points from each additional year of life (under a deprivationist approach to valuing death and a neutral point of 0.5). See calculations <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=76487430&amp;range=B33\">here</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-71\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-72\" class=\"footnote-item\"><p>\u201cWe do a shallow calculation for grief in the same way we did in Donaldson et al. (<a href=\"https://forum.effectivealtruism.org/posts/xgxzCkpKQsPwrd5W7/using-subjective-well-being-to-estimate-the-moral-weights-of-2\">2020</a>). The best estimate we found is from Oswald and Powdthavee (<a href=\"https://www.zora.uzh.ch/id/eprint/52349/1/iewwp396.pdf\">2008</a>): a panel study in the UK which finds the effect on life satisfaction due to the death of a child in the last year as being -0.72 (adjusted for a 0-10 scale). According to Clark et al. (2018), the duration of grief is ~5 years. Based on <a href=\"https://www.un.org/development/desa/pd/data/household-size-and-composition\">data from the UNDP</a>, we calculate that the average household size across the beneficiary countries (excluding the recipient of the nets) is 4.03 people (<a href=\"https://docs.google.com/spreadsheets/d/1NMAU-a1X4vqjodjI6kf8KnUyCJaK9uyNvXWj5VetDZw\">row 16</a>). Hence, an overall effect of grief per death prevented is (0.72 x 5 x 0.5) x 4.03 = 7.26 WELLBYs. However, we think this is an upper bound because it doesn\u2019t account for the counterfactual grief averted.\u201d <a href=\"https://www.happierlivesinstitute.org/report/the-elephant-in-the-bednet/\">Happier Lives Institute, \"The elephant in the bednet: the importance of philosophy when choosing between extending and improving lives,\" 2022</a>, p. 26. <a href=\"#fnref-AEsP2mm8QjfePzYi6-72\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-73\" class=\"footnote-item\"><p>We describe this as \u201ccluster thinking\u201d in <a href=\"https://blog.givewell.org/2014/06/10/sequence-thinking-vs-cluster-thinking/\">this post</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-73\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n<li id=\"fn-AEsP2mm8QjfePzYi6-74\" class=\"footnote-item\"><p>See calculations <a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=1181685756&amp;range=D22\">here</a>. <a href=\"#fnref-AEsP2mm8QjfePzYi6-74\" class=\"footnote-backref\">\u21a9\ufe0e</a></p>\n</li>\n</ol>\n</section>\n", "user": {"username": "GiveWell"}}, {"_id": "zeL52MFB2Pkq9Kdme", "title": "Exploring Metaculus\u2019 community predictions", "postedAt": "2023-03-24T07:59:16.296Z", "htmlBody": "<p>Disclaimer: this is not a project from <a href=\"https://arbresearch.com/\"><u>Arb Research</u></a>.</p><h1>Summary</h1><ul><li>I really like <a href=\"https://www.metaculus.com/\"><u>Metaculus</u></a>!</li><li>I have collected and analysed in this <a href=\"https://docs.google.com/spreadsheets/d/1Mxl8vGsZemmuKytV9zH1ft-iP2q4xwnxz7gCkSlYmPg/edit?usp%3Dsharing\"><u>Sheet</u></a>&nbsp;metrics about Metaculus\u2019 questions outside of question groups, and their <a href=\"https://www.metaculus.com/help/faq/%23community-prediction\"><u>Metaculus\u2019 community predictions</u></a>&nbsp;(see tab \u201cTOC\u201d). The Colab to extract the data and calculate the metrics is <a href=\"https://colab.research.google.com/drive/1JqXgir413MJ6nf0RVpUw0fwh82LRu4ji?usp%3Dsharing\"><u>here</u></a>.</li><li>The mean metrics vary a lot across categories, and the same is seemingly true for correlations among metrics. So one should not assume the performance&nbsp;across all questions is representative of that within each of <a href=\"https://www.metaculus.com/questions/categories/\"><u>Metaculus\u2019 categories</u></a>. To illustrate:<ul><li>Across categories, the 5th and 95th percentiles of the mean normalised outcome are 0 and 0.784<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefj6bz6cf2jy\"><sup><a href=\"#fnj6bz6cf2jy\">[1]</a></sup></span>, and of the mean Brier score are 0.0369 and 0.450. For context, the Brier score is 0.25 (= 0.5^2) for the maximally uncertain probability of 0.5.</li><li>According to Metaculus\u2019 track record <a href=\"https://www.metaculus.com/questions/track-record/\"><u>page</u></a>, the mean <a href=\"https://en.wikipedia.org/wiki/Brier_score\"><u>Brier score</u></a>&nbsp;for Metaculus\u2019 community predictions evaluated at all times is 0.126 for all questions, but 0.237 for those of the category <a href=\"https://www.metaculus.com/questions/?search%3Dcat:computing--ai\">artificial intelligence</a>. So Metaculus\u2019 community predictions about probabilities<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefiemyc829csk\"><sup><a href=\"#fniemyc829csk\">[2]</a></sup></span>&nbsp;look good in general, but they perform close to random predictions for the category of artificial intelligence. However, note there are other categories with questions about artificial intelligence, like <a href=\"https://www.metaculus.com/questions/?search=cat:comp-sci--ai-and-machinelearning\">AI and machine learning</a>.</li></ul></li><li>There can be significant differences between Metaculus community predictions and <a href=\"https://www.metaculus.com/help/faq/%23metaculus-prediction\"><u>Metaculus\u2019 predictions</u></a>. For instance, the mean Brier score of the latter for the category of artificial intelligence is 0.168, which is way more accurate than the 0.237 of the former.</li><li>According to my results, Metaculus\u2019 community predictions are:<ul><li>In general (i.e. considering all questions), less accurate for questions:<ul><li>Whose predictions are more extreme under Bayesian updating (<a href=\"https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\"><u>correlation coefficient</u></a>&nbsp;R = 0.346, and <a href=\"https://en.wikipedia.org/wiki/P-value\"><u>p-value</u></a>&nbsp;p = 0<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4ztx3gz691\"><sup><a href=\"#fn4ztx3gz691\">[3]</a></sup></span>).</li><li>With a greater amount of updating (R = 0.262, and p = 0).</li><li>With a greater difference between amount of updating and uncertainty reduction (R = 0.256, and p = 0).</li></ul></li><li>For the category of artificial intelligence, less accurate for questions with:<ul><li>Greater difference between amount of updating and uncertainty reduction (R = 0.361, and p = 0.0387).</li><li>More predictions (R = 0.316, and p = 0.0729).</li><li>A greater amount of updating (R = 0.282, and p = 0.111).</li></ul></li><li>Compatible with Bayesian updating in general, in the sense I failed to reject it during the 2nd half of the period during which each question was or has been open (mean p-value of 0.425).</li></ul></li><li>If you want to know how much to trust a given prediction from Metaculus, I think it is sensible to check Metaculus\u2019 track record for similar past questions (more <a href=\"https://forum.effectivealtruism.org/posts/zeL52MFB2Pkq9Kdme/exploring-metaculus-community-predictions#My_recommendation_on_how_to_use_Metaculus\"><u>here</u></a>).</li></ul><h2>Acknowledgements</h2><p>Thanks to Charles Dillon, Misha Yagudin from <a href=\"https://arbresearch.com/\"><u>Arb Research</u></a>, Peter M\u00fchlbacher, and Ryan Beck.</p><figure class=\"image image_resized\" style=\"width:340.16px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/zeL52MFB2Pkq9Kdme/zfmp6qwxthgbf7ifbzun\" alt=\"\"><figcaption>Dark crystall&nbsp;ball in a bright foggy galaxy. Generated by OpenAI's DALL-E.</figcaption></figure><h1>Introduction</h1><p>I really like <a href=\"https://www.metaculus.com/help/faq/%23community-prediction\"><u>Metaculus</u></a>!</p><h1>Methods</h1><p>I believe it would be important to better understand how much to trust Metaculus\u2019 predictions. To that end, I have determined in this <a href=\"https://docs.google.com/spreadsheets/d/1Mxl8vGsZemmuKytV9zH1ft-iP2q4xwnxz7gCkSlYmPg/edit?usp%3Dsharing\"><u>Sheet</u></a>&nbsp;(see tab \u201cTOC\u201d) metrics about all Metaculus\u2019 questions outside of question groups with an ID from 1 to 15000 on 13 March 2023<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwztdbn0o85\"><sup><a href=\"#fnwztdbn0o85\">[4]</a></sup></span>, and their Metaculus\u2019 community predictions. The metrics for each question are:</p><ul><li>Tags, which identify the <a href=\"https://www.metaculus.com/questions/categories/\"><u>Metaculus\u2019 category</u></a>.</li><li>Publish time (year).</li><li>Close time (year).</li><li>Resolve time (year).</li><li>Time from publish to close (year).</li><li>Time from close to resolve (year).</li><li>Time from publish to resolve (year).</li><li>Number of forecasters.</li><li>Number of predictions.</li><li>Number of analysed dates, which is the number of instances at which the predictions were assessed.</li><li>Total belief movement, which is a measure of the amount of updating, and is the sum of the belief movements, which are the squared differences between 2 consecutive beliefs.<ul><li>The values of the beliefs range from 0 to 1, and can respect a:<ul><li>Probability.</li><li>Ratio between an expectation and difference between the maximum and minimum allowed by Metaculus.</li></ul></li><li>To illustrate, the belief movement from a probability of 0.5 to 0.8 is 0.09 (= (0.8 - 0.5)^2).</li></ul></li><li>Total uncertainty reduction, which is the difference between the initial and final uncertainties, where the uncertainty linked to a belief value p equals p (1 - p). This is null for probabilities of 0 and 1, and maximum and equal to 0.25 for a probability of 0.5.</li><li>Total excess belief movement, which is the difference between the total belief movement and total uncertainty reduction.</li><li>Normalised excess belief movement, which is the ratio between the total belief movement and total uncertainty reduction.</li><li>Absolute value of normalised excess belief movement.</li><li><a href=\"https://en.wikipedia.org/wiki/Standard_score\"><u>Z-score</u></a>&nbsp;for the null hypothesis that the beliefs are Bayesian.</li><li><a href=\"https://en.wikipedia.org/wiki/P-value\"><u>P-value</u></a>&nbsp;for the null hypothesis that the beliefs are Bayesian.</li><li>Normalised outcome, which is, for questions about:<ul><li>Probabilities, 0&nbsp;if the question resolves as \u201cno\u201d, and 1 if as \u201cyes\u201d.</li><li>Expectations, the ratio between the outcome and the difference between the maximum and minimum allowed by Metaculus.</li></ul></li><li><a href=\"https://en.wikipedia.org/wiki/Brier_score\"><u>Brier score</u></a>, which&nbsp;is the mean squared difference between the predicted probability and outcome (0 or 1). Note the Brier score does not apply to questions about expectations, whose accuracy I did not assess.</li></ul><p><a href=\"https://academic.oup.com/qje/article-abstract/136/2/933/6127317?redirectedFrom%3Dfulltext\"><u>Augenblick 2021</u></a>&nbsp;shows the total belief movement should match the total uncertainty reduction in expectation for <a href=\"https://forum.effectivealtruism.org/topics/bayes-theorem\"><u>Bayesian updating</u></a>&nbsp;(see \u201cProposition 1\u201d), in which case the total excess movement and normalised excess belief movement should be 0 and 1. I suppose Metaculus\u2019 community predictions are less reliable early on. So, in the context of the metrics regarding belief movement and uncertainty reduction, I only analysed predictions concerning the 2nd half of the period during which each question was or has been open.</p><p>The Colab to extract the data and calculate the metrics is <a href=\"https://colab.research.google.com/drive/1JqXgir413MJ6nf0RVpUw0fwh82LRu4ji?usp%3Dsharing\"><u>here</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4kyfwk7siq5\"><sup><a href=\"#fn4kyfwk7siq5\">[5]</a></sup></span>.</p><h1>Results</h1><p>The tables below have results for:</p><ul><li>The mean, and 5th and 95th percentiles across categories of the number of questions, number of resolved questions, and mean metrics (1st table).</li><li>Mean metrics for all questions and <a href=\"https://www.metaculus.com/questions/?search%3Dcat:computing--ai\"><u>those of the category of artificial intelligence</u></a>&nbsp;(2nd table).</li><li>Correlations among metrics for all questions and those of the category of artificial intelligence (3rd table).</li></ul><p>The results in the 2nd and 3rd tables for the other categories are in the <a href=\"https://docs.google.com/spreadsheets/d/1Mxl8vGsZemmuKytV9zH1ft-iP2q4xwnxz7gCkSlYmPg/edit?usp%3Dsharing\"><u>Sheet</u></a>.</p><h2>Mean metrics</h2><figure class=\"table\"><table><thead><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt\" colspan=\"1\" rowspan=\"2\"><p>Metric</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"3\" rowspan=\"1\"><p>Category</p></th></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Mean</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5th percentile</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>95th percentile</p></th></tr></thead><tbody><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Number of questions</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>64.8</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>3.00</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>179</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Number of resolved questions</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>27.4</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>68.0</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean publish time (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2020</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2017</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2022</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean close time (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2039</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2019</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2077</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean resolve time (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2062</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2020</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2161</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean time from publish to close (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>18.8</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0530</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>56.2</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean time from close to resolve (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>23.0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2.04*10^-7</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>72.9</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean time from publish to resolve (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>41.8</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.159</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>141</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean number of forecasters</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>82.1</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>23.5</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>166</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean number of predictions</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>172</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>50.0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>357</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean number of analysed dates</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>86.5</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>56.4</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>104</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean total belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0191</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2.15*10^-3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0461</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean total uncertainty reduction</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0130</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.0108</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0491</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean total excess belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>6.10*10^-3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.0253</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0394</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean normalised excess belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-43.6</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-7.09</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>7.77</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean absolute value of normalised excess belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>49.0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.213</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>18.5</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean z-score for the null hypothesis that the beliefs are Bayesian</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.103</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.711</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.811</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean p-value for the null hypothesis that the beliefs are Bayesian</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.456</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.306</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.638</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean normalised outcome</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.328</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.669</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean Brier score</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.162</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0367</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.300</p></td></tr></tbody></table></figure><figure class=\"table\"><table><thead><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt\" colspan=\"1\" rowspan=\"2\"><p>Metric</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"2\" rowspan=\"1\"><p>Category</p></th></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Any</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Artificial intelligence</p></th></tr></thead><tbody><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Number of questions</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5,335</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>199</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Number of resolved questions</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2,337</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>50</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean publish time (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2,021</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2,020</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean close time (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2,036</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2,043</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean resolve time (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2,048</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>2,050</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean time from publish to close (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>15.3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>22.9</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean time from close to resolve (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>12.2</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>7.07</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean time from publish to resolve (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>27.6</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>30.0</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean number of forecasters</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>88.2</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>104.5</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean number of predictions</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>206</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>200</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean number of analysed dates</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>90.4</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>91.0</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean total belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0238</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0219</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean total uncertainty reduction</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0191</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0144</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean total excess belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.70*10^-3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>7.53*10^-3</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean normalised excess belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-43.1</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-3.92</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean absolute value of normalised excess belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>47.2</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5.52</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean z-score for the null hypothesis that the beliefs are Bayesian</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-6.78*10^-3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.105</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean p-value for the null hypothesis that the beliefs are Bayesian</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.425</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.413</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean normalised outcome</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.365</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.381</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Mean Brier score</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.151</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.230</p></td></tr></tbody></table></figure><h2>Correlations among metrics</h2><figure class=\"table\"><table><thead><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt\" colspan=\"1\" rowspan=\"3\">Correlation between Brier score and...</th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"4\" rowspan=\"1\"><p>Category</p></th></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"2\" rowspan=\"1\"><p>Any (N = 1,374)</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"2\" rowspan=\"1\"><p>Artificial intelligence (N = 33)</p></th></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p><a href=\"https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\"><u>Correlation coefficient</u></a></p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>P-value for the null hypothesis that there is no correlation<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4ztx3gz691\"><sup><a href=\"#fn4ztx3gz691\">[3]</a></sup></span></p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>Correlation coefficient</p></th><th style=\"border:1pt solid rgb(0, 0, 0);padding:5pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>P-value for the null hypothesis that there is no correlation</p></th></tr></thead><tbody><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Publish time (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.143</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>9.82*10^-8</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.179</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.319</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Close time (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.117</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.40*10^-5</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.172</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.339</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Resolve time (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.146</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>5.68*10^-8</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.184</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.305</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Time from publish to close (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0319</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.238</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>7.82*10^-3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.966</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Time from close to resolve (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.0193</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.476</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0341</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.850</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Time from publish to resolve (year)</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0102</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.705</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0318</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.861</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Number of forecasters</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.0776</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.02*10^-3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0680</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.707</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Number of predictions</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.0366</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.175</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.316</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0729</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Number of analysed dates</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.107</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>6.57*10^-5</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.198</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.270</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Total belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.262</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.282</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.111</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Total uncertainty reduction</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.136</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>4.61*10^-7</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.150</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.405</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Total excess belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.256</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.361</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0387</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt\" colspan=\"1\" rowspan=\"1\">Normalised excess belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-4.63*10^-3</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.864</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0708</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.695</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Absolute value of normalised excess belief movement</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0893</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>9.17*10^-4</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.110</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.542</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Z-score for the null hypothesis that the beliefs are Bayesian</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.346</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.241</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.176</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">P-value for the null hypothesis that the beliefs are Bayesian</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.0296</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.273</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>-0.0269</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.882</p></td></tr><tr><th style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;vertical-align:bottom\" colspan=\"1\" rowspan=\"1\">Normalised outcome</th><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.102</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>1.60*10^-4</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.112</p></td><td style=\"border:1pt solid rgb(0, 0, 0);padding:2pt;text-align:center\" colspan=\"1\" rowspan=\"1\"><p>0.535</p></td></tr></tbody></table></figure><h1>Discussion</h1><h2>Mean metrics</h2><p>The mean metrics vary a lot across categories. For example, the 5th and 95th percentiles of the mean normalised outcome are 0 and 0.669, and of the mean Brier score are 0.0367 and 0.300.</p><p>I computed mean normalised excess belief movements of -43.1 and -3.92 for all questions and those of the category of artificial intelligence, but these are not statistically significant, as the mean p-values are 0.425 and 0.413. So it is not possible to reject Bayesian updating for Metaculus\u2019 community predictions during the 2nd half of the period during which each question was or has been open. To contextualise, Table III of <a href=\"https://academic.oup.com/qje/article-abstract/136/2/933/6127317?redirectedFrom%3Dfulltext\"><u>Augenblick 2021</u></a>&nbsp;presents normalised excess belief movements pretty close to 1 (and the p-values for the null hypothesis of Bayesian updating are all lower than 0.001):</p><ul><li>1.20 for \u201ca large data set, provided by and explored previously in <a href=\"https://journals.sagepub.com/doi/pdf/10.1177/0956797614524255\"><u>Mellers (2014)</u></a>&nbsp;and <a href=\"https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2016.2525\"><u>Moore (2017)</u></a>, that tracks individual probabilistic beliefs over an extended period of time\u201d.</li><li>0.931 for \u201cpredictions of a popular baseball statistics website called <a href=\"https://en.wikipedia.org/wiki/FanGraphs\"><u>Fangraphs</u></a>\u201d.</li><li>1.046 for \u201c<a href=\"https://en.wikipedia.org/wiki/Betfair\"><u>Betfair</u></a>, a large British prediction market that matches individuals who wish to make opposing financial bets about a binary event\u201d.</li></ul><p>I estimated mean normalised outcomes of 0.365 and 0.381 for all questions and those of the category of artificial intelligence. If we assume these values apply to questions about both probabilities and expectations:</p><ul><li>The likelihood of a question about probabilities resolving as \u201cyes\u201d is 36.5 % for all questions, and 38.1 % for those of the category of artificial intelligence.</li><li>The outcome of a question about expectations is expected to equal the allowed minimum plus 36.5 % of the distance between the allowed minimum and maximum for all questions, and 38.1 % for those of the category of artificial intelligence.</li></ul><p>I got mean Brier scores of 0.151 and 0.230 for all questions and those of the category of artificial intelligence, which are 19.5 % higher and 2.86 % lower than the mean Brier scores of 0.126 and 0.237 shown in Metaculus\u2019 track record <a href=\"https://www.metaculus.com/questions/track-record/\"><u>page</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaplmoo626z6\"><sup><a href=\"#fnaplmoo626z6\">[6]</a></sup></span>. I believe the differences are explained by my results:</p><ul><li>Excluding group questions.</li><li>Approximating the mean Brier score based on a set of dates which covers the whole lifetime of the question (in uniform time steps<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzol4hy6cuv\"><sup><a href=\"#fnzol4hy6cuv\">[7]</a></sup></span>), but does not encompass all community predictions<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgzqg5ardt3l\"><sup><a href=\"#fngzqg5ardt3l\">[8]</a></sup></span>.</li></ul><p>I think the 1st of these considerations is much more important than the 2nd. The category of artificial intelligence does not include probabilistic group questions, so it is only affected by the 2nd consideration, and the discrepancy is much smaller than for all questions (2.86 % &lt; 19.5 %).</p><p>In any case, according to Metaculus\u2019 track record <a href=\"https://www.metaculus.com/questions/track-record/\"><u>page</u></a>, Metaculus\u2019&nbsp;community predictions for questions of the category of artificial intelligence perform close to randomly, as 0.237 is pretty close to 0.25. However, <a href=\"https://www.metaculus.com/help/faq/%23metaculus-prediction\"><u>Metaculus\u2019 predictions</u></a>&nbsp;and postdictions<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefks4cyu0ax7k\"><sup><a href=\"#fnks4cyu0ax7k\">[9]</a></sup></span>&nbsp;for the same category perform considerably better, with mean Brier scores of 0.168 and 0.146.&nbsp;These are also lower than the mean Brier score of 0.232 achieved for predictions matching the mean outcome of 0.365<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4x5qilixcnx\"><sup><a href=\"#fn4x5qilixcnx\">[10]</a></sup></span>&nbsp;for probabilistic questions of the category of artificial intelligence<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz5upe3xa7y\"><sup><a href=\"#fnz5upe3xa7y\">[11]</a></sup></span>.&nbsp;In addition, I should note Metaculus\u2019 predictions for the category of <a href=\"https://www.metaculus.com/questions/?search%3Dcat:comp-sci--ai-and-machinelearning\"><u>AI and machine learning</u></a>&nbsp;have a mean Brier score of 0.149 (&lt; 0.168).</p><p>In contrast, among all questions, the mean Brier score of Metaculus\u2019&nbsp;community predictions of 0.126 is similar to that of 0.120 for Metaculus\u2019 predictions. So, overall, Metaculus\u2019&nbsp;community predictions perform roughly as well as Metaculus\u2019&nbsp;predictions, although there can be important differences between them within categories, as illustrated above for the category of artificial intelligence.</p><p>It would also be nice to see the mean accuracy of the predictions of questions about expectations, but I have not done that here.</p><h2>Correlations among metrics</h2><p>The 3 metrics which correlate more strongly with the Brier score are, listed by descending strength of the correlation (correlation coefficient; p-value):</p><ul><li>For all questions:<ul><li>Z-score for the null hypothesis that the beliefs are Bayesian (0.346; 0), i.e. predictions are less accurate (higher Brier score) for questions whose predictions are more extreme under Bayesian updating.</li><li>Total belief movement (0.262; 0), i.e. predictions are less accurate for questions with a greater amount of updating. This is surprising, as one would expect predictions to converge to the truth as they are updated.</li><li>Total excess belief movement (0.256; 0), i.e. predictions are less accurate for questions with greater difference between amount of updating and uncertainty reduction.</li></ul></li><li>For the category of artificial intelligence:<ul><li>Total excess belief movement (0.361; 0.0387), i.e. predictions are less accurate for questions with greater difference between amount of updating and uncertainty reduction.</li><li>Number of predictions (0.316; 0.0729), i.e. predictions are less accurate for questions with more predictions. Maybe more popular questions attract worse forecasters?</li><li>Total belief movement (0.282; 0.111), i.e. predictions are less accurate for questions with a greater amount of updating. This is surprising, but connected to the correlation above. The community prediction moves each time a new prediction is made.</li></ul></li></ul><p>The correlations with the normalised excess belief movement are weak (correlation coefficients of -4.63*10^-3 and 0.0708), and not statistically significant (p-values of 0.864 and 0.695). So it is not possible to reject (the null hypothesis) that there is no correlation between accuracy and Bayesian updating, but the correlation I obtained is quite weak anyways.</p><p>Comparing the correlations for all questions and those of the category of artificial intelligence shows one should not extrapolate the results from all questions to each of the categories. The signs of the correlations are different for 52.9 % (= 9/17) of the metrics, although some of those of the category of artificial intelligence are not statistically significant. I guess the same applies to other categories. Feel free to check the correlations among metrics for each of the categories in tab \u201cCorrelations among metrics within categories\u201d, selecting the category in the drop-down at the top.</p><p>Finally, correlations with accuracy for questions about expectations may differ from the ones I have discussed above for ones about probabilities.</p><h2>My recommendation on how to use Metaculus</h2><p>If you want to know how much to trust a given prediction from Metaculus, I think it is sensible to check <a href=\"https://www.metaculus.com/questions/track-record/\"><u>Metaculus\u2019 track record</u></a>&nbsp;for similar past questions:</p><ul><li>The type of prediction you are seeing, either Metaculus\u2019 community prediction or Metaculus\u2019 prediction.</li><li>The categories to which that question belongs (often more than one). The relevant menus show up when you click on \u201cShow Filter\u201d.</li><li>The type of question. If it is about:<ul><li>Probabilities, select \u201cBrier score\u201d or \u201cLog score (discrete)\u201d. I think the latter is especially important if small differences in probabilities close to 0 or 1 matter for your purpose.</li><li>Expectations, select \u201cLog score (continuous)\u201d.</li></ul></li><li>The time which matches more closely your conditions. To do this, you can select \u201cother time\u2026\u201d after clicking on the dropdown after \u201cevaluated at\u201d.<ul><li>This is relevant because, even if the track record as evaluated at \u201call times\u201d is good, it may not be so early in the question lifetime.</li><li>The \u201cother time\u201d can be defined as a fraction of the question lifetime, or time before resolution.</li></ul></li></ul><p>I am glad Metaculus has made available all these options, and I really appreciate the transparency!</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnj6bz6cf2jy\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefj6bz6cf2jy\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I define the normalised outcome such that it ranges from 0 to 1 for questions about expectations, such that its lower and upper bound match the possible outcomes for probabilities.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fniemyc829csk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefiemyc829csk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The Brier score does not apply to expectations.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4ztx3gz691\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4ztx3gz691\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;All p-values of 0 I present here are actually positive, but are so small they were rounded to 0 in Sheets.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwztdbn0o85\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwztdbn0o85\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The pages of Metaculus\u2019 questions have the format \u201chttps://www.metaculus.com/questions/ID/\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4kyfwk7siq5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4kyfwk7siq5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The running time is about 20 min.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaplmoo626z6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaplmoo626z6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;To see the 1st of these Brier scores, you have to select \u201cBrier score\u201d, for the \u201ccommunity prediction\u201d, evaluated&nbsp;at \u201call times\u201d. To see the 2nd, you have to additionally click on \u201cShow filter\u201d, and select \u201cArtificial intelligence\u201d below \u201cCategories include\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzol4hy6cuv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzol4hy6cuv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Metaculus considers all predictions, which are not uniformly distributed in time (unlike the ones I retrieved), and therefore have different weights in the mean Brier score.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngzqg5ardt3l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgzqg5ardt3l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The mean number of analysed dates is 43.9 % (= 90.4/206) of the mean number of predictions.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnks4cyu0ax7k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefks4cyu0ax7k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;From <a href=\"https://www.metaculus.com/questions/track-record/\"><u>here</u></a>, Metaculus\u2019 postdictions refer to \u201cwhat our [Metaculus\u2019] current algorithm would have predicted if it and its calibration data were available at the question's close\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4x5qilixcnx\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4x5qilixcnx\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Mean of column T of tab \u201cMetrics by question\u201d for the questions of the category of artificial intelligence with normalised outcome of 0 or 1.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz5upe3xa7y\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz5upe3xa7y\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;0.232 = 0.365*(1 - 0.365)^2 + (1 - 0.365)*(0.365)^2.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncngw35pext\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcngw35pext\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Some p-values are so small that they were rounded to 0 in Sheets.</p></div></li></ol>", "user": {"username": "vascoamaralgrilo"}}, {"_id": "8XZmu8BM5JBtSnHiP", "title": "Part 3: A Proposed Approach for AI Safety Movement Building: Projects, Professions, Skills, and Ideas for the Future [long post][bounty for feedback]", "postedAt": "2023-03-22T00:54:26.315Z", "htmlBody": "<h1>Epistemic status</h1><p>Written as a non-expert to develop my views and get feedback, rather than persuade.&nbsp;</p><h1>Why read this post?</h1><p>Read this post for</p><ul><li>a&nbsp;<strong>theory of change for AI safety movement building</strong>, including measuring key outcomes of contributors, contributions, and coordination to determine if we are succeeding</li><li>activities to realise the promise of this theory of change, focused on (1) building shared understanding, (2) evaluating progress (3) coordinating workers and projects, (4) prioritising projects to support, and (5) changing how we do related movement building</li><li>examples of how technical and non-technical skills are both needed for AI safety</li><li>an explanation of a new idea, \"fractional movement building\", where most people working in AI safety spend some fraction of their time building the movement (i.e. by splitting time between a normal job and movement-building, or taking time off to do a \"<a href=\"https://forum.effectivealtruism.org/posts/waeDDnaQBTCNNu7hq/ea-tours-of-service\">tour of service</a>\")</li><li>ideas for how we might, evaluate, prioritise and scale AI Safety movement building.</li></ul><p>I also ask for your help in providing feedback and answering questions I have about this approach. Your answers will help me and others make better career decisions about AI safety, including how I should proceed with this movement building approach.&nbsp;<strong>I am offering cash bounties of $20 for the most useful inputs</strong> (see section at the bottom of the post).</p><h1>Summary</h1><p>If we want to more effectively address problems of AI safety, alignment, and governance, we need better i) shared understanding of the challenges, better coordination of people and resources, and ii) prioritisation.&nbsp;</p><p>AI Safety Movement Building activities are currently mired in uncertainty and confusing. It's not clear who can or should be a contributor; it's not clear what contributions people in the community are making or value; and it's not clear how to best coordinate action at scale.</p><p>In response, this post is the third in a series that outlines a theory of change for AI Safety Movement Building.&nbsp;<a href=\"https://forum.effectivealtruism.org/s/RwtygELTfbRJzcvwD/p/5iQoR8mhEpvRT43jv\"><u>Part 1</u></a> introduced the&nbsp;<strong>context&nbsp;</strong>of the AI Safety community, and its four work groups: Strategy, Governance, Technical, and Movement Building.&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/YMvSZi2EWxNHwFtbb/part-2-ai-safety-movement-builders-should-help-the-community\"><u>Part 2</u></a> proposed measurable&nbsp;<strong>outcomes&nbsp;</strong>that AI Safety Movement Building should try to improve:&nbsp;<i>Contributors</i>: individuals making positive contributions to AI Safety;&nbsp;<i>Contributions</i>: positive inputs into AI Safety work; and,&nbsp;<i>Coordination</i>: understanding and aligning contributions to ensure maximal efficiency.&nbsp;</p><p>In this post, I describe a&nbsp;<strong>process</strong> for AI Safety Movement Builders that can be implemented in this context, to produce these outcomes.</p><p>The process is thus: Technical and non-technical AI Safety movement builders, including those working in a fractional capacity,&nbsp;<a href=\"https://docs.google.com/document/d/14-YF_tioUvcyskQHbpJcGFNnwOVhOx8tWqrlcRsxIfc/edit#heading=h.bgu1qal6i71o\"><u>start, sustain or scale</u></a> AI Safety projects. They mainly do this by providing access <a href=\"https://docs.google.com/document/d/14-YF_tioUvcyskQHbpJcGFNnwOVhOx8tWqrlcRsxIfc/edit#heading=h.6yjhj1iyiail\"><u>human resources</u></a> (i.e., needed professions and skills). They exercise caution by&nbsp;<a href=\"https://docs.google.com/document/d/14-YF_tioUvcyskQHbpJcGFNnwOVhOx8tWqrlcRsxIfc/edit#heading=h.jtwj9n965yph\"><u>validating their assumptions that a project will be useful as early as possible</u></a>. These concepts and the process are elaborated on in the full post.</p><p>My key recommendations for people and organisations working on AI Safety and movement building are:</p><ul><li><a href=\"https://docs.google.com/document/d/14-YF_tioUvcyskQHbpJcGFNnwOVhOx8tWqrlcRsxIfc/edit#heading=h.fbgq71ljg262\"><u>Evaluate how well AI Safety movement building is achieving key outcomes such as increasing the number and quality of contributors, improving contributions, or helping coordination of work</u></a></li><li><a href=\"https://docs.google.com/document/d/14-YF_tioUvcyskQHbpJcGFNnwOVhOx8tWqrlcRsxIfc/edit#heading=h.z6e63moxewjr\"><u>Support or lead work to improve shared understanding of the main challenges in AI Safety, to improve prioritisation, and speed of progress&nbsp;</u></a></li><li><a href=\"https://docs.google.com/document/d/14-YF_tioUvcyskQHbpJcGFNnwOVhOx8tWqrlcRsxIfc/edit#heading=h.9t492g3eux8e\"><u>Consider a fractional movement building approach where everyone doing direct work has some of their time allocated to growing the community.</u></a></li></ul><p>&nbsp;</p><h1>Why did I write this series of posts?&nbsp;</h1><h2>There is uncertainty about what AI Safety Movement Building is, and how to do it helpfully</h2><p><a href=\"https://www.alignmentforum.org/posts/5rsa37pBjo4Cf9fkE/a-newcomer-s-guide-to-the-technical-ai-safety-field#:~:text=AI%20safety%20is%20a%20pre,and%20how%20to%20approach%20it.\">AI Safety is&nbsp;<u>a pre-paradigmatic area of research</u>&nbsp;</a>and practice which recently emerged to address an impending, exceptionally pressing, societal problem. This has several implications:&nbsp;</p><ul><li>The emergent community is relatively lacking in established traditions, norms, maturity and scientific consensus.</li><li>Most community members' focus and effort have gone into understanding problems they are personally interested in rather than community wide considerations.&nbsp;</li><li>Most knowledge is in the heads of community members and *relatively* (e.g., compared to an established research domain) little information has been made easily legible and accessible to new entrants to the community (e.g., see various posts calling for, and providing more of such information:&nbsp;<a href=\"https://www.lesswrong.com/posts/5rsa37pBjo4Cf9fkE/a-newcomer-s-guide-to-the-technical-ai-safety-field\"><u>1</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/QWuKM5fsbry8Jp2x5/why-people-want-to-work-on-ai-safety-but-don-t\"><u>2</u></a>).&nbsp;</li><li>Most people in and outside AI safety, have relatively poor information on, and understanding, of what other relevant people and groups think (e.g.,&nbsp;<a href=\"https://www.facebook.com/story.php?story_fbid=pfbid0kSouvndP39s2rbPjLWtdkFWm91E3HHuwLuiKiQiqVfin1QrDJHXKEzvjBvPxGm7bl&amp;id=509414227&amp;post_id=509414227_pfbid0kSouvndP39s2rbPjLWtdkFWm91E3HHuwLuiKiQiqVfin1QrDJHXKEzvjBvPxGm7bl&amp;mibextid=Nif5oz\"><u>1</u></a>)&nbsp;</li></ul><p>As a result of these and other factors, there is considerable uncertainty about which outcomes are best to pursue, and which processes and priorities are best for achieving these outcomes.&nbsp;</p><p>This uncertainty is perhaps particularly pronounced in the smaller and newer sub-field of AI Safety Movement building (e.g.,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Ayu5im98u8FeMWoBZ/my-personal-cruxes-for-working-on-ai-safety?commentId=vFyf4Je8YN4k4rsAL\"><u>1</u></a>). &nbsp;This may be partially due to differences in perspective on Movement Building across the emerging AI Safety community. Most participants are from diverse backgrounds: technical and non-technical researchers, mathematicians, rationalists, effective altruists, philosophers, policymakers, entrepreneurs. They are not groups of people who share an innate conceptualisation of what \u2018Movement Building\u2019 is or what it should involve.&nbsp;</p><p>Regardless, the uncertainty about what AI Safety Movement Building is, and how to do it helpfully, creates several problems. Perhaps most significantly, it probably reduces the number of people who consider, and select, AI Safety Movement Building as a career option.</p><h2>&nbsp;</h2><h2>Uncertainty about AI Safety Movement Building reduces the number of potentially helpful movement builders</h2><p>People who care about AI safety and want to help with movement building are aware of two conflicting facts: i) that the AI Safety community badly needs more human resources and ii) that there are significant risks from doing movement building badly (e.g.,&nbsp;<a href=\"https://www.lesswrong.com/posts/bkpZHXMJx3dG5waA7/ways-to-buy-time?commentId=jropYhtAW72zfHRBr\"><u>1</u></a>,<a href=\"https://www.lesswrong.com/posts/BbM47qBPzdSRruY4z/instead-of-technical-research-more-people-should-focus-on?commentId=fEfLqfaLtnwDPYstf#comments\"><u>2</u></a>).&nbsp;</p><p>To determine if they should get involved, they ask questions like: Which movement building projects are generally considered good to pursue for someone like me and which are bad? What criteria should I evaluate projects on? What skills do I need to succeed? If I leave my job would I be able to get funding to work on (Movement Building Idea X)?&nbsp;&nbsp;</p><p>It\u2019s often hard to get helpful answers to these questions. There is considerable variance in vocabulary, opinions, visions and priorities about AI Safety Movement Building within the AI Safety community. If you talk to experts or look online you will get very mixed opinions. Some credible people will claim that a particular movement building project is good, while others will claim the opposite.&nbsp;</p><p>There is also a problem of fragmented and abstract discussion: Most discussions happen in informal contexts that are difficult to discover or synthesise, such as Facebook, Twitter, Slack, in-person conversations, or in the comments of three different forums(!). There is limited discussion of specifics, for instance, what specifically is good or bad movement building, or lowest or highest priority to do. Instead, discussions are vague or kept at a high level, such as the kinds of norms, constraints, or values that are (un)desirable in the AI Safety community. As an example, memes and sentiments like the image below are commonly seen. These don\u2019t specify what they\u2019re critiquing or provide a good example of what is acceptable or desirable in response. They serve as a sort of indefinite expression of concern that can\u2019t easily be interpreted or mitigated.&nbsp;<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/undynuvplj1otcomc7wv\"></p><p>An example of an indefinite expression of concern:&nbsp;<a href=\"https://www.facebook.com/groups/OMfCT/posts/3411877719127122/\"><u>Source</u></a></p><p>&nbsp;</p><p>Because of the lack of coherence in discussions and abstract nature of concerns, it is very hard for movement builders to evaluate the risk and rewards of potential actions against the risks of inaction.</p><p>This creates uncertainty which is generally unpleasant and promotes inaction. The consequence of this uncertainty is that fewer potential AI Safety Movement Builders will choose to engage in AI Safety Movement Building over competing options with more clearly defined processes and outcomes (e.g., direct work, their current job, or other impact focused roles).&nbsp;</p><h2>&nbsp;</h2><h2>Having fewer movement builders probably reduces AI Safety contributors, contributions and collective coordination</h2><p>Let\u2019s explore some arguments for why movement builders are important for key outcomes for the AI Safety Community.</p><p><strong>The lack of AI Safety movement builders probably reduces the number of CONTRIBUTORS to AI Safety by reducing awareness and ability to get involved.&nbsp;</strong>I believe that the vast majority of people who could work on AI safety don\u2019t have a good understanding of the core arguments and opportunities.<strong>&nbsp;</strong>Of those who do, many&nbsp;<a href=\"https://www.lesswrong.com/posts/XkmG8XGf6uhXLmZN7/so-you-think-you-re-not-qualified-to-do-technical-alignment\"><u>don\u2019t know how to get involved and therefore don\u2019t even try</u></a>. Many who know how to get involved, erroneously think that they can\u2019t contribute. It\u2019s much harder to get involved than it should be:&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/QWuKM5fsbry8Jp2x5/why-people-want-to-work-on-ai-safety-but-don-t\"><u>the effort to understand whether / how to help</u>&nbsp;</a>is unreasonably high.</p><p><strong>The lack of movement builders probably reduces CONTRIBUTIONS to AI Safety by making it harder for new and current contributors to collaborate on the most important research topics</strong>. Researchers don\u2019t know what is best to research. For instance, Eli Tyre<a href=\"https://musingsandroughdrafts.com/2023/02/17/my-current-summary-of-the-state-of-ai-risk/\"><u> argues</u></a> that most new researchers \u201care retreading old ideas, without realizing it\u201d. Researchers don\u2019t seem to know much about what other researchers are doing and why. When<a href=\"https://www.lesswrong.com/posts/4ujM6KBN4CyABCdJt/ai-alignment-researchers-don-t-seem-to-stack%20%20Reference%20in%20article%20-%20one%20reason%20people%20don't%20stack%20is%20because%20most%20information%20is%20in%20people's%20heads,%20like%20early%20academia\"><u> Nate Soares talks about how AI safety researchers don\u2019t stack</u></a> I wonder how much of this is due to a lack of shared language and understanding. Researchers don\u2019t get much support. When&nbsp;<a href=\"https://www.lesswrong.com/posts/4NFDwQRhHBB2Ad4ZY/the-filan-cabinet-podcast-with-oliver-habryka-transcript\"><u>Oliver Harbyka says</u></a>: \u201cbeing an independent AI alignment researcher is one of the [jobs] with, like, the worst depression rate in the world\u201d, I wonder how much of that is due to insufficient support for mental and physical needs.&nbsp;</p><p><strong>The lack of movement builders probably reduces coordination because it leads to a lower level of shared language and understanding.&nbsp;</strong>Without the support of movement builders there is no one in the AI Safety community responsible for creating shared language and understanding inside and outside the community: reviewing, synthesising and communicating AI Safety community member\u2019s work, needs and values to relevant groups (within and outside the community). Without this, the different parts of AI Safety community and outside stakeholders are less well able to understand and communicate what they collectively do or agree/disagree on, and to make efficient progress towards their goals.</p><p><strong>But what if current movement building is harmful?&nbsp;</strong>Some people in the community have concerns about current work on movement building (e.g.,&nbsp;<a href=\"https://www.lesswrong.com/posts/bkpZHXMJx3dG5waA7/ways-to-buy-time?commentId=jropYhtAW72zfHRBr\"><u>1</u></a>,<a href=\"https://www.lesswrong.com/posts/BbM47qBPzdSRruY4z/instead-of-technical-research-more-people-should-focus-on?commentId=fEfLqfaLtnwDPYstf#comments\"><u>2</u></a>,<a href=\"https://www.lesswrong.com/posts/psYNRb3JCncQBjd4v/shutting-down-the-lightcone-offices#comments\"><u>3</u></a>), many of which I share. However, these concerns do not strike me as compelling reasons to stop movement building. Instead, they strike me as reasons to improve how we do movement building by better understanding the needs and values of the wider community.&nbsp;</p><p>For instance, right now, to ensure we have movement builders who&nbsp;</p><ul><li>Survey the AI Safety community and communicate its collective values and concerns.</li><li>Research how fast the community is growing and why and facilitate productive conversation around if/how that should change</li><li>Synthesise different viewpoints, identify differences, and progress the resolution of debates</li><li>Help the existing community to collaborate and communicate more effectively.</li></ul><p>However, before we can understand how to do movement building better, we need to address an underlying bottleneck - a lack of shared language and understanding.</p><p>&nbsp;</p><h2>To address the uncertainty and related problems we need a better shared language and shared understanding&nbsp;</h2><p>To address the uncertainty and related problems, the AI Safety (Movement Building) community appears to need a better&nbsp;<i>shared language</i>, and&nbsp;<i>shared understanding</i>.</p><p>By a&nbsp;<i>shared language</i>, I mean a shared set of concepts which are consistently used for relevant communication. These shared concepts are helpful categorisations for differentiating otherwise confusing and complex phenomena (e.g., key parts, process, or outcomes within the community). Some adjacent examples are the EA cause areas, the Importance, Tractability and Neglectedness (ITN) framework and the 80,000 Hours priority careers.</p><p>A shared language offers potential for a&nbsp;<i>shared understanding</i>. By a&nbsp;<i>shared understanding</i>, I mean a situation where the collective understanding of key variables (e.g., our context, processes, desired outcome, and priorities) is clear enough that it is very well understood \u2018who needs to do what, when and why\u2019. An adjacent example within the EA community, is the 80,000 Hours priority career paths list which provide a relatively clear understanding of which careers are the highest priority from EA perspective and why.</p><p>I argued earlier that variance in vocabulary, opinions, visions and priorities about AI Safety Movement Building contributed to uncertainty. A&nbsp;<i>shared language&nbsp;</i>can help address *some* of this uncertainty by standardising vocabulary and conceptual frameworks.</p><p>I argued earlier that uncertainty stems from limited discussion of specifics, for instance, what specifically is good or bad AI Safety Movement Building, or lowest or highest priority to do. Creating a&nbsp;<i>shared understanding&nbsp;</i>can help address *some* of this uncertainty and reduce the related problems by standardising i) the collective understanding of key variables (e.g., context, process, desired outcomes), and, later, ii) priorities.</p><p>The above has hopefully outlined a few of the reasons why I value shared&nbsp;<i>language&nbsp;</i>and&nbsp;<i>understanding.&nbsp;</i>I wanted them<i>&nbsp;</i>as a new entrant to the community and couldn\u2019t find anything substantive. This is why I wrote this series of posts to outline and share the language and understanding that I have developed and plan to use if I engage in more direct work. I am happy for others to use or adapt it. If there are flaws then I\u2019d encourage others to point them them out and/or develop something better.&nbsp;</p><h1>&nbsp;</h1><h1>What have I already written?</h1><p>This is the third part of a&nbsp;<a href=\"https://forum.effectivealtruism.org/s/RwtygELTfbRJzcvwD\"><u>series</u></a> which outlines an approach/a theory of change for Artificial Intelligence (AI) Safety movement building.&nbsp;<a href=\"https://forum.effectivealtruism.org/s/RwtygELTfbRJzcvwD/p/5iQoR8mhEpvRT43jv\"><u>Part one</u></a> gave&nbsp;<i>context</i> by conceptualising the AI Safety community.&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/b6771xqjayhljcwr4wmw\"></p><p><a href=\"https://forum.effectivealtruism.org/posts/YMvSZi2EWxNHwFtbb/part-2-ai-safety-movement-builders-should-help-the-community\"><u>Part two</u></a> proposed&nbsp;<i>outcomes</i>: three factors for movement builders to make progress on.&nbsp;</p><p><br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/r1kvnlebisyjvzdqzkoi\"></p><p>I next explain the&nbsp;<i>process&nbsp;</i>used to achieve these outcomes in this context. In doing so, I aim to provide i) a basic conceptual framework/shared language for AI Safety Movement Building, and ii) show the breadth and depth of contributions required as part of movement building.</p><p>&nbsp;</p><h1>AI Safety movement builders contribute to AI Safety via&nbsp;<i>projects</i></h1><p>As used here a \u2018project\u2019 refers to a temporary effort to create a unique product, service, or outcome. Projects can be focused on technical research, governance, strategy (e.g.&nbsp;<a href=\"https://aisafety.world/\"><u>1</u></a>.<a href=\"https://www.aisafetysupport.org/resources/lots-of-links\"><u>2</u></a>) or movement building specifically (e.g.,&nbsp;<a href=\"https://www.lesswrong.com/posts/QRST9ctX5Cu2dM2Sb/agi-safety-field-building-projects-i-d-like-to-see\"><u>1</u></a>,<a href=\"https://forum.effectivealtruism.org/posts/5KsrEWEbc4mwzMTLp/some-more-projects-i-d-like-to-see\"><u>2</u></a>).&nbsp; They range in size from very small (e.g., an hour a week to do X) to very large (e.g., a large organisation or group). They can encompass smaller subprojects (e.g., teams in an organisation).&nbsp;</p><p>&nbsp;</p><h2>AI Safety movement builders contribute by helping to&nbsp;<i>start, sustain</i> and&nbsp;<i>scale&nbsp;</i>AI Safety projects&nbsp;</h2><p>Starting projects refers to cases where movement builders enable one or more people to provide a unique product, service, or outcome which contributes to AI safety. For instance, an AI Safety movement builder might encourage a newly graduated computer science student to start an independent research project and connect them with a mentor. They might join several people with diverse skills to start an AI Safety related training project in their university or organisation.&nbsp;</p><p>Sustaining project means keeping them going at their current level of impact/output. For instance, this might involve supporting a newly created independent research, or AI Safety related training project to keep it running over multiple years.</p><p>Scaling projects refers to cases where movement builders enable an AI safety project to have a greater positive impact on AI Safety contributors, contributions and coordination. For instance, an AI Safety movement builder might help a newly started organisation to find researchers for their research projects as a recruiter, or find them a recruiter. Or they might find several industry partners for an AI related training project which is seeking to give their best students\u2019 industry experience before they graduate. They could also join a bigger organisation of AI governance researchers as a research communicator to help them reach a wider audience.</p><p>AI Safety Movement builders start, sustain and scale project by contributing resources (e.g., knowledge, attitudes, habits, professions, skills and ideas). &nbsp;Their main contribution is 'human resources': access to the professions and skills that the project needs to start or scale.&nbsp;</p><p>&nbsp;</p><h2>AI Safety movement builders start and scale AI Safety projects by contributing <i>human resources</i>:&nbsp; <i>technical&nbsp;</i>and&nbsp;<i>non-technical professions&nbsp;</i>and&nbsp;<i>skills </i>in <i>full-time </i>and <i>fractional </i>capacities.</h2><p>A \u2018profession\u2019 refers to a broad role which people are often hired to do (e.g., a marketer or coach) and a \u2018skill\u2019 refers to a commonly used ability (e.g., using Google Ads or CBT). Professions are essentially \u2018careers\u2019. Skills are professionally relevant skills and experience. They are somewhat akin to \u2018career capital\u2019 - what you might learn and transfer in a career.&nbsp;</p><p>AI Safety movement builders contribute professions and skills to projects directly (e.g., via working for an organisation as founder or a recruiter) or indirectly (e.g., via finding founder or a recruiter for that organisation).&nbsp;</p><p>It seems useful to split contributions of professions and skills into those which are technical (i.e., involve knowledge of Machine Learning (ML)), non-technical&nbsp; (i.e., don\u2019t involve knowledge of ML), full-time (i.e., 30+ hours a week) or fractional (e.g., 3 hours a month or 3 months a year). This conceptual framework is visualised below and referenced in the content that follows.<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/tt7jbluisoyxc4qvw7u2\"></p><p>&nbsp;</p><h2><i>AI Safety Projects&nbsp;</i>generally require many <i>technical&nbsp; </i>and&nbsp;<i>non-technical professions&nbsp;</i>and&nbsp;<i>skills&nbsp;</i>to start/scale</h2><p>AI Safety Projects typically require a wide range of professions and skills. As an example, the below shows a typical AI Safety Project and some of the professional skills required to make it happen.&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Project type</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Explanation</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Professional skills involved</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">AI Safety training program &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">An eight-week course to train people in machine learning</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Planning the course, providing the research training, facilitating the sessions, marketing the course, creating and maintaining the digital assets, communicating with stakeholders and attendees, measuring and evaluating impact, managing staff, participants, and finances.</td></tr></tbody></table></figure><p><br>&nbsp;The professional skills involved include \u2018technical\u2019 contributions: research mentorships or and help to develop or deliver technical aspects of the course. They also involve non-technical professional skills, for instance, in the development of digital assets, marketing, project management and evaluation.</p><h1>What professions and skills are relevant to current and future AI Safety projects?&nbsp;</h1><p>To unpack this, I next outline professions and skills which I think can contribute to AI Safety Movement building. I start by offering some general thoughts on how these contributions might be made. I then give examples of how these can impact the three target outcomes of AI Safety Movement Builders: increasing contributors, contributions and coordination.</p><p>Because of how technical competence affects personal capacity to contribute to AI Safety Movement building, I discuss technical and non-technical contributions in separate sections.&nbsp;</p><p>In each case I am not presenting an exhaustive list - just a set of examples to make my overall theory of change somewhat clear. At the end of the section, I argue that we should properly explore the demand for specific professions and skills within the AI Safety community.</p><h2>Technical contributions to AI Safety Movement Building are very valuable, but need to be balanced against trade-offs, and may best be made in a fractional capacity</h2><p>AI emerged from specific types of Machine Learning. As such, anyone interested in interpreting and communicating the technical and theoretical risk from AI, and related AI Safety community needs and opportunities would ideally have a deep background in the relevant technologies and theories. This is why technical experts (e.g., Paul Christiano, Buck Schlegeris, and Rohin Shah) have privileged insight and understanding and are essential to the AI Safety movement building. But there is a problem\u2026</p><h3>&nbsp;</h3><h3>There are relatively few technical experts within the AI Safety community and most are (rightly) focused on doing technical work</h3><p>Relatively few people possess in-depth knowledge of ML in conjunction with a focus on safety. Relatively few of those who do are focused on movement building as most instead prefer to directly work on AI Safety theory or empirical work.&nbsp;</p><h3>&nbsp;</h3><h3>Many technical experts within the AI Safety should consider fractional movement building</h3><p>It seems likely that technical experts can sometimes have a much higher indirect impact on expectation via doing movement building than their alternatives. For instance, they may encounter someone who they could work with, have a chance to influence a group of relevant experts at a networking event or talk, or accelerate the development of one or more projects or research labs in some advisory capacity. In each case they could have a valuable opportunity to increase coordination, contribution or cooperation.</p><p>To the extent that the above is true, it seems valuable for experts to consider assigning a portion of their time to movement building activities. As an example, they could aim to spend 10% of their time attending conferences, speaking with other researchers and engineers, mentoring other technical experts, and creating educational programs.</p><h3>&nbsp;</h3><h3>Technical novices within the AI Safety community should consider assigning a larger fraction of time to movement building</h3><p>By technical novices, I mean people who have one or two years of experience in ML. For such people, there is a case for investing a relatively large fraction of time in movement building as opposed to research. For instance, early career researchers may stand to contribute a lot by helping more senior researchers to provide more presentations, training, research operations or research communication, particularly if they do not feel that they are likely to make progress on difficult research problems within their expected timelines for AI takeoff.</p><p>There are opportunities to accelerate the acquisition and development of exceptional talents. A researcher who believes they are good but not brilliant enough to make significant contributions to AI Safety research might be very well suited to engage and help people who are younger and less experienced, but more talented. They might also be able to make significant contributions to movement building in areas such as AI governance or strategy where the required technical knowledge for making significant contributions may be significantly lower.</p><p>To the extent that the above is true, it seems valuable for novice researchers to consider assigning some portion of their time to movement building activities. For instance, depending on aptitude and opportunity they could plan to spend 25% - 75% of their time communicating research, running conferences, supporting expert researchers, engineers and creating and running educational programs.</p><p>&nbsp;</p><h3>What do technical contributions look like in practice?&nbsp;</h3><p>To help illustrate the above, the following table outlines professions (in this case with a technical specialisation) which can contribute to AI Safety Movement building and suggests potential impacts on contributors, contributions and coordination.&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Profession</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Definition</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Example of movement building impact</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Research</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Researching how to best develop and deploy artificial intelligence systems.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Attending technical AI conferences to network and increase the number of&nbsp;<i>contributors.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Engineering</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Providing technical expertise to research, develop and deploy AI systems.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Supervising new AI research projects to increase the number of&nbsp;<i>contributors.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Policymaker</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Providing technical expertise in policy settings.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Mentoring relevant civil servants to increase future&nbsp;<i>contributors&nbsp;</i>to policy research and enactment.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Entrepreneurship</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Creating, launching, and managing ML related ventures.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Creating a new AI safety related research organisation which can then hire new&nbsp;<i>contributors</i>.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Consulting</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Helping organisations solve technical problems or improve performance.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Helping to scale a new AI safety related research organisation which can then hire new&nbsp;<i>contributors</i>.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Management</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Overseeing and directing technical operations.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Helping to manage engineers in an AI safety related research organisation to increase their&nbsp;<i>contributions</i>.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Recruiting</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Finding, screening, and selecting qualified job candidates.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Recruiting and trialling engineers for an organisation to increase the number of&nbsp;<i>contributors.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Education</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Providing individuals with necessary knowledge and skills.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Offering technical training to provide important skills and increase the number of&nbsp;<i>contributors.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Community manager &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Building communities of researchers, engineers and related specialisations.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Connecting important researchers via research seminars to improve&nbsp;<i>coordination.&nbsp;</i></td></tr></tbody></table></figure><p><br>&nbsp;</p><p>For illustration, the following table outlines skills relevant to those with technical expertise and examples of potential impacts on&nbsp;<i>contributors, contributions&nbsp;</i>and&nbsp;<i>coordination.</i><br>&nbsp;</p><figure class=\"table\"><table><thead><tr><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Skill</strong></th><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Definition</strong></th><th style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Example movement building impact</strong></th></tr></thead><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Mentorship</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Providing guidance and support to new participants within the community.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increasing&nbsp;<i>contributors, contributions&nbsp;</i>and&nbsp;<i>coordination</i> by mentoring new researchers.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Ambassador/ advocate</p><p><br>&nbsp;</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Becoming an effective representative or spokesperson for AI safety.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Communication and engagement with peers to increase awareness of AI safety issues and to attract new&nbsp;<i>contributors</i> to the community.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Machine Learning focused recruitment (ML)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Identifying, attracting, and hiring individuals with ML skills and qualifications.&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Finding and testing individuals to help to increase the number of&nbsp;<i>contributors.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">AI Safety Curriculum design</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Creating AI Safety educational programs and materials.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increasing&nbsp;<i>contributors, contributions&nbsp;</i>and&nbsp;<i>coordination</i> by curating needed skills and bodies of knowledge into educational courses and materials.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Research dissemination</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Effectively spreading research information to relevant groups.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increasing&nbsp;<i>contributors, contributions&nbsp;</i>and&nbsp;<i>coordination&nbsp;</i>by creating simple and easily communicable summaries and syntheses.&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Career coaching</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Helping others with career choice.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Making progress on&nbsp;<i>contributors, contributions&nbsp;</i>and&nbsp;<i>coordination&nbsp;</i>by helping new and novice researchers to understand what they need to know and where to work.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Writing</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Strong writing skills for creating clear and effective research and communication.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Writing blog posts, articles, or social media posts to share information and engage with followers, which can increase&nbsp;<i>contributions</i> and&nbsp;<i>coordination&nbsp;</i>within the AI safety movement.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Presenting</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Presenting information persuasively to relevant audiences.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Giving presentations at conferences, workshops, or other events to share information and ideas about AI safety, increase&nbsp;<i>contributions</i> and&nbsp;<i>coordination&nbsp;</i>within the AI safety movement.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Networking</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Building relationships and connections with others who share similar interests or goals.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Building partnerships and collaborations with/between other organisations or individuals who are also working on AI safety issues to increase&nbsp;<i>contributions</i> and&nbsp;<i>coordination.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Social skills</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Being able to effectively understand and collaborate with others</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Communicating effectively, collaborating with others, and building trust and rapport with stakeholders to increase&nbsp;<i>contributions&nbsp;</i>and&nbsp;<i>coordination</i>.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Teaching skills</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Educating others about the potential risks and challenges associated with advanced AI.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Providing training to help people develop the skills and knowledge needed to work on AI Safety and increase the number of&nbsp;<i>coordinators.</i></td></tr></tbody></table></figure><p><br>&nbsp;</p><h2>Non-technical contributions to AI Safety Movement Building can best support AI strategy and AI governance but can also support AI Safety technical work.</h2><h3>&nbsp;</h3><h3>Non-technical people may be best suited to movement build for AI strategy and AI governance</h3><p>AI Strategy and AI governance involve a lot of non-technical tasks including setting up and managing courses, creating community surveys, communicating research, writing up social media content or helping with general operation. AI Strategy and AI governance areas can therefore absorb many contributions of non-technical professions and skills in relatively obvious ways.&nbsp;</p><h3>&nbsp;</h3><h3>Non-technical people can also contribute to technical AI safety</h3><p>Non-technical people appear at a major disadvantage when it comes to helping with the technical aspect of AI Safety Movement building. They cannot provide many of the important inputs of those offered by technical people. They also cannot easily understand some of the technical literature and related reasoning. Accordingly, it might seem that non-technical people can only make useful contributions to AI Safety via working in AI Strategy and AI policy.</p><p>In contrast, I think that non-technical people can also contribute to technical AI safety and are going to be increasingly important as it scales. Here are three reasons why.<i>&nbsp;</i></p><h3>&nbsp;</h3><h3>Non-technical people are in greater supply than technical people, they have lower opportunity costs, and their complementary skills are needed to produce the optimal outcomes from technical contributors and contributions.</h3><p>Non-technical people are in greater supply than technical people. I suspect that a much larger percentage of people interested in AI Safety, or open to working on it for a market rate salary, will have non-technical, than technical backgrounds.</p><p>Non-technical people have fewer opportunity costs than technical people because they don\u2019t have a competing opportunity to do technical research instead of movement building.</p><p>Non-technical people can contribute to the AI Safety movement by providing complementary resources that save technical people time, or address gaps in their competency or interests. For instance, a technical person might be very happy to speak at a conference but not to spend the time looking for conferences, contacting organisers, or reworking their slides and planning their trip. However, a nontechnical person working as an operational staff member might however be able and willing to do all of this.&nbsp;</p><p>By working with the technical person the operation person can therefore greatly increase their collective impact on AI Safety outcomes. By working with a team of researchers, they may be able to dramatically improve the level of awareness of their work with compounding effects over time.</p><p>The above reasons may help explain why half or more of the staff at technical companies (e.g., focused on software engineering) are often non-technical: usually marketers, lawyers, recruiter, social media managers, managers and many other forms of support staff are required to maximise the value of technical work, particularly at scale.</p><p><br>&nbsp;</p><h3>Non-technical people who are able and willing to contribute to AI Safety should prioritise support technical AI Safety movement building when possible<i>.</i></h3><p>I believe:</p><ul><li>In AI strategy and governance there is a higher level of awareness, understanding and usage of nontechnical people in movement building roles than in technical AI safety.</li><li>Technical research is the most bottlenecked group within the AI safety community (although one might argue that movement building is actually the issue as it is an upstream cause of this blocker)</li></ul><p>I therefore believe that most non-technical AI safety movement builders will have maximal impact if they allocate as much of their time to technical AI Safety movement building as can be productively accommodated.&nbsp;</p><p>For instance, this could be via working at an organisation alongside technical workers in a nontechnical operations' role as discussed in the example above. In a more abstract sense, it could also be helping to recruit for people who might be more immediately productive. For instance, if you know an organisation really needs a technical recruiter then you could have an outsized impact by helping them find one (if working in a relevant context).</p><h3>&nbsp;</h3><h3>For some non-technical movement builders, it will make sense to work in a fractional role where only part of one\u2019s time is spent on AI safety work</h3><p>In some cases having more than one role may outperform the alternative of working full time as an \u2018AI Safety Movement Builder\u2019. For instance, a nontechnical social science researcher might have more impact from a fractional role where they teach and do research at a university for 50% of their time than from leaving their university to put 100% of their time into movement building.&nbsp;</p><p>In the fractional role, they may be able to do a range of important movement building activities: to interact with more people who are unaware of but potentially open to AI safety arguments, invite in speakers to talk to students, advocate for courses etc. All of these are things they cannot do if they leave their research role.&nbsp;</p><p>They are also potentially more likely to be able to engage with other researchers and experts more effectively as an employed lecturer interested in X, than as an employee of an AI safety organisation or \u201cmovement builder\u201d with no affiliation.</p><p>Fractional roles may make sense where individuals believe that the AI safety community can only make productive use of a percentage of their time (e.g., one day a week they facilitate a course).&nbsp;</p><p>&nbsp;</p><h3>For some non-technical movement builders, it will make sense to work as a generalist across multiple parts of the AI safety community</h3><p>In some cases a nontechnical AI safety movement builder (e.g., a recruiter or communicator) might be better off working across the AI strategy, governance and technical groups as a generalist than focusing on one area. For instance, this may give them more opportunities to make valuable connections.&nbsp;</p><h3>&nbsp;</h3><h3>Non-technical people working as experts in AI governance or strategy roles should consider being fractional movement builders</h3><p>Non-technical people working as experts in governance or strategy roles (e.g., Allan Dafoe) should consider a fractional approach to AI Safety movement building. For instance, they might consider allocating 10% of their time to networking events, talks, or mentorship.&nbsp;</p><h3>&nbsp;</h3><h3>What do non-technical contributions look like in practice?&nbsp;</h3><p>To help illustrate the above, the following table outlines non-technical professions which can contribute to AI Safety Movement building and explains how doing so could impact contributors, contributions and coordination.&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Profession &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Definition</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Example movement building impact</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Marketing (and communications)</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Promoting and selling products or services through various tactics and channels using various forms of communication.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Using marketing communication to increase awareness of AI safety research opportunities in relevant audiences to increase the number of&nbsp;<i>contributors.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Management</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Overseeing and directing the operations of a business, organisation, or group.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Joining a research organisation to improve how well researchers involved in the AI safety movement&nbsp;<i>coordinate</i> around the organisation's goals and research agendas.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Entrepreneurship</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Creating, launching, and managing new ventures.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Creating a new AI safety related research training program which can then hire new&nbsp;<i>contributors.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Research</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Gathering and analysing information to gain knowledge about a relevant topic.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Applied research to make the values, needs and plans of the AI (safety) community more legible which can help increase&nbsp;<i>contributors, contributions&nbsp;</i>and&nbsp;<i>coordination.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Coaching</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Providing guidance, advice, and instruction to individuals or teams to&nbsp; improve performance.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Coaching novice individuals and organisations within the AI safety movement can help to increase their&nbsp;<i>contributions.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Operations</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Planning, organising, and directing the use of resources to efficiently and effectively meet goals.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Reducing administration or providing support services to help AI safety organisations make better&nbsp;<i>contributions</i>.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Recruiting &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Finding, screening, and selecting qualified job candidates.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Recruiting top talent and expertise to organisations to increase the number of&nbsp;<i>contributors.</i></td></tr></tbody></table></figure><p><br><br>&nbsp;</p><p>The following table outlines skills relevant to those with non-technical expertise and examples of potential impacts on&nbsp;<i>contributors, contributions&nbsp;</i>and&nbsp;<i>coordination.</i></p><p>&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Skill &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Definition</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Example movement building impact</strong></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Search Engine Optimisation (SEO)&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Managing websites and content to increase visits from search engine traffic.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Optimising a website or online content to increase capture of AI career related search engine traffic and increase&nbsp;<i>contributors.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Research lab management</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Overseeing and directing the operations of a research laboratory.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increasing&nbsp;<i>contributions</i> by creating and managing labs that amplify the research output of experienced AI safety researchers.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Commercial innovation</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Creating and implementing new ideas, products, or business models.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Creating AI safety related ventures that increase the funding and/or research and therefore increase the number of contributors to AI Safety and/or their&nbsp;<i>contributions&nbsp;</i>or coordination.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Surveying&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Measuring and collecting data about a specific area or population to gain understanding.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Surveying key audiences at key intervals to better understand the values, needs and plans of the AI safety community and improve&nbsp;<i>contributors, contributions or coordination.</i></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Therapy</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Treating emotional or mental health conditions through various forms of treatment.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Increasing&nbsp;<i>contributions</i> by helping individuals within the AI safety movement to improve their mental health, well-being and long term productivity.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Project management</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Planning, organising, and overseeing the completion of specific projects or tasks within an organisation.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Coordinating resources and timelines, setting goals and objectives, and monitoring progress towards achieving them to help researchers in the AI safety movement to make better&nbsp;<i>contributions</i>.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Job description creation</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Developing adverts for a specific job within an organisation.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Creating clear, accurate, and compelling job descriptions that effectively communicate the responsibilities, qualifications, and expectations for a role and therefore increase the number of&nbsp;<i>contributors</i>.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Facilitation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Coordinating and leading meetings, workshops, and other events.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Bringing together people from different backgrounds and perspectives to discuss and work on AI Safety issues and increase&nbsp;<i>coordination</i>.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Design</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Create attractive visuals and interactive tools.</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Create engaging and compelling content that raise awareness and increase&nbsp;<i>contributions</i>.&nbsp;</td></tr></tbody></table></figure><p>&nbsp;</p><p>&nbsp;</p><p><br>&nbsp;</p><h1>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Mistakes to avoid in movement building</h1><p>It shouldn\u2019t be assumed that all AI Safety Movement building projects will be net positive or that everyone with these professions or skills would be useful within AI Safety.&nbsp;</p><p>It is particularly important to avoid issues such as causing reputational harm to the EA and AI Safety community, speeding up capabilities research or displacing others who might make more significant contributions if they took the role you fill.&nbsp;</p><p>Professions such as marketing, advocacy and entrepreneurship (and related skills) are therefore particularly risky to practice.</p><p>I recommend that anyone with a relevant profession or skill should&nbsp;<i>consider&nbsp;</i>using it to support or start a project and then seek to&nbsp;<i>validate&nbsp;</i>their belief that it may be useful. For now&nbsp;<i>validation&nbsp;</i>might involve talking with senior people in the community and/or doing some sort of trial, or seeking funding.&nbsp;</p><p>I think that it's important to have a strong model of possible downsides if you're considering doing a trial and that some things might not be easy to test in a trial.</p><p>In future, there will hopefully be a clearer sense of i) the collective need for specific professions and skills, ii) the thresholds for when on can be confident that they/a project will be provide value and iii) the process to be followed to validate that if a person/project was useful.</p><p>&nbsp;</p><h1>Summary</h1><p>Across my three posts, I have argued:</p><ul><li><a href=\"https://forum.effectivealtruism.org/s/RwtygELTfbRJzcvwD/p/5iQoR8mhEpvRT43jv\"><u>The AI Safety community mainly comprises four overlapping, self-identifying, groups:&nbsp;</u><i><u>Strategy, Governance, Technical and Movement Building.</u></i></a><ul><li>AI Safety movement builders are like&nbsp;<i>a \u2018Human Resources and operations team\u2019 for the AI Safety community</i>.</li><li>People in other parts of the community can (and should) contribute to movement building<i>&nbsp;</i>in a<i> fractional capacity.</i></li></ul></li><li>AI Safety movement builders<i> contribute</i> to AI Safety by helping to&nbsp;<i>start and scale AI Safety projects&nbsp;</i><ul><li><i>Projects&nbsp;</i>require&nbsp;<i>contributions&nbsp;</i>of many&nbsp;<i>technical&nbsp;</i>and&nbsp;<i>non-technical professions&nbsp;</i>and&nbsp;<i>skills&nbsp;</i>in&nbsp;<i>full-time&nbsp;</i>and&nbsp;<i>fractional&nbsp;</i>capacities.</li></ul></li><li><a href=\"https://forum.effectivealtruism.org/posts/YMvSZi2EWxNHwFtbb/part-2-ai-safety-movement-builders-should-help-the-community\"><u>AI Safety movement builders help the community to optimise three outcomes/factors:</u></a><ul><li><i>Contributors:&nbsp;</i>individuals making positive contributions to AI Safety.</li><li><i>Contributions:</i> contributors\u2019 inputs into AI Safety work.</li><li><i>Coordination:</i> understanding and aligning contributions to ensure maximal efficiency.</li></ul></li></ul><p>The summarised approach is illustrated below.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/ccrbciuzpaphptxb7rxp\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/v8adjvtoqjzaynwmgkah 130w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/kdxefku9y3reqjui9yjy 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/zdaiowrtb0nls19c4fyz 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/sfdrk3wwh1npt1rn59gm 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/zax6vbudsfomtrjt8ia1 650w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/xxtupjq1pmyhbiti1nrt 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/lkwxzypms7cjtqqk7blo 910w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/t87wzkm1tslneta2qmpd 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/zkjte65om5bhnvyl6qiv 1170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/8XZmu8BM5JBtSnHiP/gvgpbm76angil0lttdbt 1227w\"></figure><p>&nbsp;</p><h1>Implications and ideas for the future&nbsp;</h1><p>I argued that a lack of shared language and understanding was the cause of many problems with AI Safety Movement Building. With that in mind, if the response to my approach is that it seems helpful (even if just as a stepping stone to a better approach), this suggests a range of implications and ideas for the future.&nbsp;</p><h2>&nbsp;</h2><h2>Use the three AI Safety Movement building outcome metrics suggested (Contributors, Contributions and Coordination), or something similar, to evaluate progress in AI Safety Movement Building</h2><p>It may be useful to have some sort of benchmarking for progress in AI Safety Movement building. One way to do this would be to have some sort of regular evaluation of the three AI Safety Movement building outcome metrics I suggested (or similar).&nbsp;</p><p>These outcome metrics are&nbsp;<i>Contributors</i>: how many people are involved in AIS Safety (total and as a percentage of what seems viable),&nbsp;<i>Contributions</i>: how well they are functioning and performing and&nbsp;<i>Coordination</i>: How well all contributors understand and work with each other.</p><p>If the factors that I have suggested seem suboptimal, then I\u2019d welcome critique and the suggestion of better alternatives. I am confident that some sort of tracking is very important but not yet confident that my suggested outcomes are optimal to use.</p><p>However, as they are the best option that I have right now, I will next use them to frame my weakly held perspective on how AI Safety Movement building is doing right now.</p><h3>&nbsp;</h3><h3>I think that AI Safety Movement building is doing well for a small community but has significant potential for improvement</h3><p>I really appreciate all the current AI Safety movement building that I am seeing, and I think that there is a lot of great work.&nbsp; Where we are reflects very well on the small number of people working in this space. I also think that we probably have a huge amount of opportunity to do more. While I have low confidence in my intuitions for why we are under optimised I will now explain them for the sake of hopefully provoking discussion and increasing shared understanding.&nbsp;</p><p>All the evaluations that follow are fuzzy estimates and offered in the context of me finally being convinced that optimising the deployment of AI is our most important societal challenge and thinking about what I might expect if say, the US government, was as convinced of the severity of this issue as many of us are. From this perspective, where we are is far from where I think we should be if we believe that there is ~5%+ chance of AI wiping us out, and a much higher chance of AI creating major non-catastrophic problems (e.g, economic, geopolitical, and suffering focused risks).&nbsp;</p><p><strong>I think that probably less than 5% of all potentially valuable contributors are currently working on AI safety.&nbsp;</strong>I base this on the belief that the vast majority of people who could work on AI safety don\u2019t even know about the core arguments and opportunities. Of those that do know of these options many have a very high friction path to getting involved, especially if they are outside key hubs. For instance, there are lots of different research agendas to evaluate, good reasons to think that none of them work, limited resources beyond introductory content, a lack of mentors and a lack of credible/legible safe career options to take.</p><p><strong>I think that probably less than 50% of maximal potential individual productivity has been achieved in the current group of contributors.&nbsp;</strong>I base this on conversations with people in the community and work I have done alongside AI safety researchers. Physical health, mental health and social issues seem very significant. Burnout rates seem extremely high. Some people seem to lack technical resources needed to do their research.</p><p><strong>I think that probably less than 10% of optimal coordination has been achieved across all contributors.</strong> I base this on conversations with people in the community and work I have done alongside AI safety researchers. It seems that there is relatively little communication between many of the top researchers and labs and little clarity around which research agendas are the most well-accepted. There seems to be is even less coordination across areas within the community (.e.g, between governance and technical research)</p><p>Assume we regard the total output of AI Safety community as being approximated by the combination of contributors, contributions &amp; coordination. This means that&nbsp;<strong>I think that we are at around 0.25% of our maximum impact (0.05*.5*.1*100)</strong>.&nbsp;</p><p>I\u2019d welcome critiques that endorse or challenge my reasoning here.</p><h2>&nbsp;</h2><h2>Determining clear priorities for AI Safety Movement Building is the most important bottleneck to address once we have a shared understanding</h2><p>To varying extents, we appear to lack satisfactorily comprehensive answers to key questions like: Which AI Safety movement building projects or research projects are most valued? Which professions and skills are most needed by AI Safety organisations? Which books, papers and resources are most critical to read for new community members? Which AI organisations are best to donate to?&nbsp;</p><p>We also appear to lack comprehensive understanding of the drivers of differences in opinions within answers to these questions. All of this creates uncertainty, anxiety, inaction and inefficiency. It therefore seems very important to set up projects that explore and surface our priorities and the values and differences that underpin them.&nbsp;</p><p>Projects like these could dramatically reduce uncertainty and inefficiency by helping funders, community members, and potential community members to understand the views and predictions of the wider community, which in turn may provide better clarity and coordinated action. Here are three examples which illustrate the sorts of insights and reactions that could be provoked.</p><ul><li>If we find that 75 percent of a sample of community members are optimistic about project type Y (courses teaching skill x in location y) and only 20% are optimistic about project Z (talent search for skill y in location x), this could improve related funding allocation and communication and action from movement builders and new contributors.&nbsp;</li><li>If we find that technical AI Safety organisations expect to hire 100 new engineers with a certain skill over the next year, then we can calibrate a funding and movement building response to create/run related groups and training programs in elite universities and meet that need.&nbsp;</li><li>We find that 30% of people of a sample of community members see a risk that movement building project type Y might be net negative and explain why. We can use this information to iterate project type Y to add safeguards that mitigate the perceived risks. For instance, we might add a supervisory team or a pilot testing process. If successful, we might identify a smaller level of concern in a future survey.</li></ul><p>Here are some other benefits from prioritisation.&nbsp;</p><ul><li>To help new entrants to the AI safety community to understand the foundational differences in opinion which have caused its current divisions, and shape their values around the organisations and people they trust most.&nbsp;</li><li>To help Movement Builders to communicate such information to the people they are in contact with, raising the probability that these people act optimally (e.g., by working on the skills or projects that seem best in our collective expectation).&nbsp;</li><li>To help current contributor to realise that they have overlooked or undervalued key projects or projects and align to work on those which are forecast to be more effective.</li></ul><p>I am not confident of the best way to pursue this goal, but here are some ideas for consideration:</p><ul><li>We create panel groups for the different sectors of the AI Safety Community. Participants in the groups consent to be contacted about paid participation in surveys, interviews and focus groups relating to AI Safety Community matters.</li><li>Groups run regular projects to aggregate community and expert opinions on key questions (e.g., see the questions above but note that we could also collect other key questions in these surveys)</li><li>Where surveys or dialogue show important differences in prediction (e.g., in support for different research agendas or movement building projects), groups curate these differences and try to get to identify the causes for underlying differences</li><li>Groups run debates and/or discussions between relevant research organisations and actors to explore and surface relevant differences in opinion.</li><li>Groups try to explore key differences in intuitions between organisations and actors by collecting predictions and hypotheses and testing them.</li></ul><p><strong>What are some examples? </strong>This survey of <a href=\"https://forum.effectivealtruism.org/posts/g4fXhiJyj6tdBhuBK/survey-on-intermediate-goals-in-ai-governance \">intermediate goals in AI governance</a> is an example of the sort of survey work that I have in mind. I see <a href=\"https://www.lesswrong.com/posts/QBAjndPuFbhEXKcCr/?commentId=8pJYzFSfvAaFZM5tq\">curation work</a> as a precursor for surveys of this nature (because of the need for shared language).</p><p>I might be wrong to believe that determining priorities is such a problem or that related projects are so important, so please let me know if you agree or disagree.<strong>&nbsp;</strong></p><h2>&nbsp;</h2><h2>Fractional movement building seems like the best way to grow the community once it knows if, and how, it wants to grow</h2><p>I have argued that fractional movement building - allocating some, but not all, of my productive time to movement building- is a useful approach for many people to consider. Here is why I think it is probably the best approach for the AI Safety community to grow with.</p><p>&nbsp;</p><h3>It will usually be better for most people in the AI safety community to do fractional movement building than to entirely focus on direct work</h3><p>It seems likely the average AI safety expert will get maximal impact from their time when they allocate some portion of that time for low frequency, but high impact, movement building work. This could be networking with intellectual peers in other areas and/or providing little known meta-knowledge (e.g., about what to read or do to make progress on problems), which can make it much easier for other and future researchers to make important contributions.&nbsp;</p><p>Why will the average AI safety expert will get maximal impact from their time when they allocate some portion of that time for low frequency, but high impact, movement building work? This is mainly because&nbsp;<a href=\"https://www.alignmentforum.org/posts/5rsa37pBjo4Cf9fkE/a-newcomer-s-guide-to-the-technical-ai-safety-field#:~:text=AI%20safety%20is%20a%20pre,and%20how%20to%20approach%20it.\">AI Safety is&nbsp;<u>a pre-paradigmatic&nbsp;</u>field</a> of research and practice where there is no clear scientific consensus on what to do and with what assumptions. This has the following implications.&nbsp;&nbsp;</p><p><strong>Many (probably orders of magnitude more) potentially good contributors are unaware, than aware, of the field of AI Safety.</strong><i>&nbsp;</i>I suspect there are millions of very smart people who are not aware of, or engaged with, AI Safety Research. I am optimistic that some portion of these people can be persuaded to work on AI Safety if engaged by impressive and capable communicators over extended periods, which will require our best brains to communicate and engage with outside audiences (ideally with the help of others to coordinate and communicate on their behalf where this is helpful).</p><p><strong>Most important information in AI Safety is in the heads of the expert early adopters.</strong> Because AI Safety is a pre-paradigmatic field of research and practice there is little certainty about what good content is, that bar is changing as the assumptions change with the result that there are few to no production systems for, and examples of, well synthesised explanatory content (e.g., a college level textbook). This means that even a very smart person seeking to educate themselves about the topic will lack access to the most key and current knowledge unless they have an expert guide.</p><p>&nbsp;</p><h3>It will be usually be better for AI safety movement building to focus on growing fractional movement building commitments than full-time movement building commitments</h3><p><strong>Fractional movement building can likely engage more people than full time movement building</strong></p><p><i>Most people are more comfortable and capable of persuading other people to do something when they already do that thing or something similar.</i> Someone with a PhD in X, researching X, is probably going to feel much more comfortable recommending other people to do a PhD in, or research on, X than if they have only a superficial understanding of this area and no professional experience.&nbsp;</p><p><i>Most people who are at all risk-adverse will generally feel more comfortable working on something superficially legitimate than on being a full time \u2018movement builder\u2019.</i> They will be more comfortable being hired to research X at Y institution, which may involve doing movement building, than being a full-time movement builder for CEA. As a personal example, I feel it will look very strange for my career if I go from being a university based academic/consultant with a certain reputation built up over several years to now announcing that I am a freelance \u2018movement builder\u2019 or one working for CEA. I imagine that many of my professional contacts would find my new role to be very strange/cultish and that it would reduce the probability of getting future occupations if it didn\u2019t work out as it\u2019s not a very well understood or respected role outside of EA.</p><p><i>It is easier to get involved as a fractional role. Many more people can give 10% of their time to be a fractional movement builder and many more organisations can avail of small contributions than full time commitments.</i></p><p><br>&nbsp;</p><p><strong>Fractional movement building will often provide a better return on time and effort than full time movement building</strong></p><p><i>Community builders with recognised roles at credible organisations will be seen as credible and trustworthy sources of information.</i> If someone approached me as \u2018climate change/socialism/veganism\u2019 movement builder working for a centre I hadn\u2019t heard of or named after that movement, I\u2019d probably be more resistant to and sceptical of their message than if they worked for a more conventional and/or reputable organisation in a more conventional and/or reputable role. Here are two examples:</p><ul><li>Someone working as an average level researcher at an AI safety research organisation is likely to more trusted and knowledge able communicator about their research area and related research opportunities than someone who works full time as a movement builder.&nbsp;</li><li>Someone who works in a university as a lecturer is going to be much better at credibly influencing research students and other faculty than someone who is outside the community and unaffiliated. As a lecturer focused on spending 20% of time on AI Safety Movement building this person can influence hundreds, maybe thousands, of students with courses. As a full-time movement builder they would lose this access and also associated credibility.</li></ul><p><i>Most people who can currently contribute the most to movement building are better suited to fractional than full-time roles.</i> As stated above, most experts, particularly technical experts, have unique, but rare opportunities to influence comparably talented peers, and/or provide them with important knowledge that can significantly speed up their research.&nbsp;</p><p><i>Fractional movement building is more funding efficient.&nbsp;</i>Much movement building work by fractional movement builders (e.g., networking, presenting, or teaching etc) is partially or fully funded by their employer. It may displace less favourable work (e.g., a different lecturer who would not offer an AI Safety aligned perspective). This saves EA funders from having to fund such work, which is valuable while we are funding constrained.</p><p>&nbsp;</p><h1>Feedback</h1><h2>I have outlined a basic approach/theory of change - does it seem banal, or flawed? I will pay you for helpful feedback!</h2><p>Supportive or critical feedback on this or my other posts would be helpful for calibrating my confidence in this approach and for deciding what to do or advocate for next.&nbsp;</p><p>For instance, I am interested to know:</p><ul><li>What, if anything, is confusing from the above?</li><li>What, if anything, was novel, surprising, or useful / insightful about the proposed approach for AI safety movement building I outlined in my post?</li><li>What, if anything, is the biggest uncertainty or disagreement that you have, and why?&nbsp;</li></ul><p>If you leave feedback, please consider indicating how knowledgeable and confident you are to help me to update correctly.</p><h3><strong>To encourage feedback I am offering a bounty.&nbsp;</strong></h3><p>I will pay up to 200USD in Amazon vouchers, shared via email, to up to 10 people who give helpful feedback on this post or the two previous posts in the series. I will also consider rewarding anonymous feedback left&nbsp;<a href=\"https://forms.gle/Ds7ACVfLiaab7Myy5\"><u>here</u></a> (but you will need to give me an email address). I will share anonymous feedback if it seems constructive and I think other people will benefit from seeing it.</p><p>I will also leave a few comments that people can agree/disagree vote on to provide quick input.</p><h2>&nbsp;</h2><h2>What next?</h2><p>Once I have reviewed and responded to this feedback I will make a decision about my next steps. I will probably start working on a relevant fractional role unless I am subsequently convinced of a better idea. Please let me know if you are interested in any of the ideas proposed and I will explore if we could collaborate or I can help.</p><h2>&nbsp;</h2><h2>Acknowledgements</h2><p>The following people helped review and improve this post: Alexander Saeri, Chris Leong, Bradley Tjandra and Ben Smith. All mistakes are my own.</p><p>This work was initially supported by a grant from the FTX Regranting Program to allow me to explore learning about and doing AI safety movement building work. I don\u2019t know if I will use it now, but it got me started.</p>", "user": {"username": "Peterslattery"}}, {"_id": "ErmimTsFQLCfm3NGk", "title": "Retrospective: Tools for Collaborative Truth Seeking", "postedAt": "2023-03-27T09:30:09.533Z", "htmlBody": "<p>This is a retrospective post for the <a href=\"https://forum.effectivealtruism.org/s/dr9sjmfd6vB2ztXMt\">Tools for Collaborative Truth Seeking</a> project. I recommend reading it if you want to do a project involving writing tutorials for the forum, matched forum posts and live streams, or short projects involving user interviews.&nbsp;</p><p>Some quick notes: the project took around 55 hours of work in total, and consisted of 8 forum posts and 8 live events in the EA GAtherTown where we discussed the use of the tool and used it for a short exercise. The posts were put up once a day over a week and a half, with the live streams initially the same day as the post, but by halfway we changed to the day after.&nbsp;</p><p>I feel the two key mistakes were not understanding where the list of tools had come from and not re-assessing as the project grew. I'll also mention a couple of more specific points about the format and timing of the final product.&nbsp;</p><h2>Key Mistakes</h2><p>I feel the biggest mistake I made with this project was not asking where the list of tools had come from. Even assuming it was from a great source, not being able to regenerate the method really limited my ability to write about the true reasons why a tool was on the list, and how it compared to other tools<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefztm4uxprhw\"><sup><a href=\"#fnztm4uxprhw\">[1]</a></sup></span>.&nbsp;</p><p>The other really central mistake was that the project changed quite a lot over time, and we never stopped to re-assess. Initially, the project was just <a href=\"https://forum.effectivealtruism.org/topics/list-of-tools-for-collaborative-truth-seeking\">the wiki page</a>, then we added a sequence of posts to explain the tools, then we added livestreams. &nbsp;At some point, the project had changed enough that we should have stopped and looked at the project with fresh eyes.&nbsp;</p><p>I think this affected the quality of the final product; it was less cohesive than it should have been, and the timing was a little off<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgun4854zx0e\"><sup><a href=\"#fngun4854zx0e\">[2]</a></sup></span>. An (untested) rule of thumb I will be trying to implement is to re-assess all of your assumptions about a project when you make a decision that seems to at least double the time the project will take.</p><h2>More Specific Mistakes</h2><h3>Scheduling</h3><p>The tight schedule felt good generally to keep people interested, but the biggest scheduling mistake was that people didn't have enough time between the post going up and the event itself. Our best-attended event was Squiggle, the post for which went up a few days in advance of the event due to the weekend (though this was also our most popular post). I suggest posting event announcements right at the beginning of the project, so people can book time into their day to come to live events.</p><p>The other minor issue was that some people who came to several events said they wished they had been spaced out slightly more; maybe every other day. I think this would be particularly important for projects longer than ours or where you're expecting the same people to turn up to several live events.&nbsp;</p><h3>Livestreams</h3><p>Attendance for some livestreams was low (0-1). The format of having an exercise to do seemed useful. The main mistake was not bringing the devs of the tools in earlier and advertising their attendance and/or getting them more involved in picking exercises that showcased the tools well.</p><h3>User Interviews</h3><p>User interviews were run less like writing feedback and more like software user testing. This worked well when we were able to get access to people who were the target audience, and was not so helpful otherwise; I recommend putting effort into reaching your target audience for this kind of interview. People who understood this was the type of feedback we were looking for were also more helpful.</p><h3>LessWrong</h3><p>The posts generally did very poorly on LessWrong. This could be because the titles followed more of the forum format (very explicit, not weird at all), or because LW is more about working on AI than the forum. I think the two mistakes here were not talking to the LessWrong team about the project and just cross-posting rather than having a version tailored to LessWrong (e.g. with more AI examples, more individual working).</p><h2>Conclusion</h2><p>Overall, I was quite happy with how the project went. The key metrics will be how many people are using these tools in 6 months and what they're using them for, but I'm cautiously optimistic. The key mistakes were not re-assessing the project when it grew, and not thinking carefully about how we formed the list of tools that were included</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnztm4uxprhw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefztm4uxprhw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For those interested, the initial list came from a brainstorm on an epistemics slack, though it was altered quite substantially through the course of the project</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngun4854zx0e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgun4854zx0e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>e.g. I wish we had posted all of the event announcements a week or two in advance of the posts going up, so people could plan ahead</p></div></li></ol>", "user": {"username": "brook"}}, {"_id": "E7CvbPvvNF2XnKqdJ", "title": "Resolving moral uncertainty with randomization", "postedAt": "2023-03-29T10:10:58.632Z", "htmlBody": "<h2>Problems with maximizing expected choice-worthiness</h2><p>A popular approach to moral uncertainty is \"<a href=\"https://forum.effectivealtruism.org/s/XrybQambStcer5i7C/p/ex834aaANLhamLkvf#Maximising_Expected_Choice_worthiness__MEC_\"><strong>maximizing expected choice-worthiness</strong></a>\" (MEC) by William MacAskill. However, it has some issues.</p><ol><li>It requires theories to be <strong>interval-scale measurable.</strong><br>This means that a theory needs to provide information about the ratio of difference in choice-worthiness between different options.<br>E.g. Stoicism says that the difference between lying and killing is ten times bigger than the difference between being honest and lying.</li><li>It requires <strong>intertheoretic comparisons of value</strong>.<br>We need to be able to tell to what extend one theory deems an option as more important than another option, when compared to a different theory.<br>E.g. Utilitarianism says the moral difference between lying and killing is three times bigger than Kantianism says it is.</li><li>It falls prey to the <a href=\"https://www.journals.uchicago.edu/doi/10.1086/669564\"><strong>infectiousness of nihilism</strong></a>.<br>When an agent has positive credence in nihilism then the choice-worthiness of all actions is undefined.<br>E.g. If you think nihilism has 1% chance of being true, you can't evaluate one option as morally better than another.</li><li><a href=\"https://forum.effectivealtruism.org/posts/Gk7NhzFy2hHFdFTYr/a-dilemma-for-maximize-expected-choiceworthiness-mec\">Some say</a> it has a problem with <strong>fanaticism</strong>.<br>It ranks a minuscule probability of an arbitrarily large value above a guaranteed modest amount of value.<br>E.g. If you think christianity has a 1% chance of being true, and it gives people infinite happiness in heaven, you should choose it above your 99% chance that utilitarianism is true, which only posits finite happiness.</li></ol><p><a href=\"https://forum.effectivealtruism.org/posts/jo8anuDYkehAkyZYm/sortition-model-of-moral-uncertainty\">Two years ago</a> one of us created an approach that wouldn't fall prey to these problems: the sortition model of moral uncertainty.</p><p>&nbsp;</p><h2>Problems with the sortition model of moral uncertainty</h2><p>The sortition model prescribes that if you have <i>x</i>% credence in a theory, then you follow that theory <i>x</i>% of cases. If you have 20% credence in Kantianism, 30% credence in virtue ethics and 50% credence in utilitarianism, you follow Kantianism 20% of the time, virtue ethics 30% of the time and utilitarianism 50% of the time. <i>When</i> you act according to a theory is selected randomly with the probability of selection being the same as your credence in said theory.</p><p>This approach doesn't fall prey to the problems of interval-scale measurability, intertheoretic comparisons of value, or the infectiousness of nihilism. Furthermore, the theory is fair, computationally cheap and doesn't generate problems with fanaticism and theory-individuation. However, it does have a big problem of its own, it violates the principle of moral dominance.</p><p>Suppose you face this decision:</p><figure class=\"table\"><table><tbody><tr><td style=\"vertical-align:top\">&nbsp;</td><td style=\"vertical-align:top\">Theory 1</td><td style=\"vertical-align:top\">All other theories</td></tr><tr><td style=\"vertical-align:top\">Option A: Punching someone</td><td style=\"vertical-align:top\">permissible</td><td style=\"vertical-align:top\">impermissible</td></tr><tr><td style=\"vertical-align:top\">Option B: Not punching someone</td><td style=\"vertical-align:top\">permissible</td><td style=\"vertical-align:top\">permissible</td></tr></tbody></table></figure><p>The principle of moral dominance states that if an option A is better than B according to at least one possible moral theory and as good as B in all others, then you should choose A instead of B. The principle of moral dominance prescribes in this scenario that we shouldn't punch someone. However, if the sortition model randomly selects theory 1, then according to the sortition model it is equally appropriate to punch or not punch someone, directly violating the principle of moral dominance.</p><p>You could solve this by saying that once a theory doesn't eliminate all the options, the leftover 'appropriate' options are presented to another randomly selected theory who eliminates the options they deem inappropriate and so on, until only one option remains. However, this doesn't solve the sentiment that some choices are just higher stakes for some theories than others. Consider this decision:</p><figure class=\"table\"><table><tbody><tr><td style=\"vertical-align:top\">&nbsp;</td><td style=\"vertical-align:top\">Theory 1</td><td style=\"vertical-align:top\">All other theories</td></tr><tr><td style=\"vertical-align:top\">Option A: Punching someone</td><td style=\"vertical-align:top\">0.0002</td><td style=\"vertical-align:top\">0</td></tr><tr><td style=\"vertical-align:top\">Option B: Not punching someone</td><td style=\"vertical-align:top\">0.0001</td><td style=\"vertical-align:top\">1000</td></tr></tbody></table></figure><p>Even with this solution, it's possible that the sortition model lands on theory 1 and chooses option A, despite it only being a very slight preference for theory 1, while all the other theories have a very strong preference for option B. We could solve this by normalizing the distributions (giving the theories \"equal say\"), but sometimes some theories genuinely care more about a decision than others (We'll return to this problem at the end of this post). Perhaps we give the selection process a random chance to switch to another theory, with the odds of that occurring being determined by how much the other theories prefer a different option. However, this adds computational complexity. Let's look at a different approach.</p><h2>&nbsp;</h2><h2>Runoff randomization</h2><p>We might want to do is something in between \"only letting theories assign options either permissible or impermissible\" and \"giving a numeric value to options\".<br>What if we let the process go through several runoff rounds? Let's call this version <strong>runoff randomization</strong>. Say you face the following decision:</p><figure class=\"table\"><table><tbody><tr><td style=\"vertical-align:top\">&nbsp;</td><td>Theory 1</td><td style=\"vertical-align:top\">Theory 2</td><td style=\"vertical-align:top\">Theory 3</td></tr><tr><td style=\"vertical-align:top\">Option A</td><td>1</td><td style=\"vertical-align:top\">1</td><td style=\"vertical-align:top\">2</td></tr><tr><td>Option B</td><td>1</td><td>1</td><td>1</td></tr><tr><td style=\"vertical-align:top\">Option C</td><td>20</td><td style=\"vertical-align:top\">20</td><td style=\"vertical-align:top\">impermissible</td></tr><tr><td>Option D</td><td>20</td><td>20</td><td>impermissible</td></tr></tbody></table></figure><p>If you think we should strongly focus on impermissibility (e.g. certain strands of deontology and suffering-focussed ethics) you might want to first have a selection round that eliminates all the options that at least one theory considers impermissible (options C and D). You subsequently select in a second round the best option from the ones that remain (in this case it would be option A between A and B).</p><p>However this gives some weird results. Theory 1 and 2 strongly prefer options C and D, but because Theory 3 finds them impermissible it can eliminate them and cause its (slightly) preferred option to win. This can get especially weird if there are hundreds of theories under consideration, any one of which can shut down all the options except their favorite one.</p><p>Let's be a bit milder. Suppose you face the following decision:</p><figure class=\"table\"><table><tbody><tr><td style=\"vertical-align:top\">&nbsp;</td><td>Theory 1</td><td style=\"vertical-align:top\">Theory 2</td><td style=\"vertical-align:top\">Theory 3</td></tr><tr><td style=\"vertical-align:top\">Option A</td><td>10</td><td style=\"vertical-align:top\">10</td><td style=\"vertical-align:top\">11</td></tr><tr><td>Option B</td><td>10</td><td>10</td><td>10</td></tr><tr><td style=\"vertical-align:top\">Option C</td><td>10</td><td style=\"vertical-align:top\">neutral</td><td style=\"vertical-align:top\">13</td></tr><tr><td>Option D</td><td>impermissible</td><td>10</td><td>-10 (impermissible)</td></tr></tbody></table></figure><p>A notable feature of this approach is that theories can give quantitative recommendations, qualitative recommendations or a combination of the two.<br>This doesn't matter because the idea is that we do three rounds of runoffs:</p><ol><li>First we randomly select a theory. In said theory we eliminate the \"<strong>impermissible</strong>\" options.<br>Let's say we randomly draw theory 1 and see that it only considers option D to be impermissible, we therefore eliminate option D.</li><li>Secondly we randomly draw another theory. In said theory we eliminate the \"<strong>neutral</strong>\" options.<br>Let's say that this time we draw theory 2. It considers option D, B and A permissible, but we've already eliminated option D in the previous round, so the only thing we can eliminate is option C which it is \"neutral\" towards.</li><li>Lastly we randomly draw a final theory and we eliminate its \"<strong>non-optimal</strong>\" options so we only end up with the \"<strong>optimal</strong>\" options.<br>Let's say that this time we draw theory 3. While it considers option C the optimal choice we have already eliminated options C and D. Between options B and A it considers option A to be the \"optimal\" choice, so we end up choosing option A.</li></ol><p>If a theory eliminates all the remaining options, you draw again. E.g. if nihilism is neutral towards all the options (because it doesn't make a value judgement), you randomly select another theory. If in this process, you have exhausted all theories without reaching the next round, we go to the next round anyway, keeping all the remaining options in.</p><p>For any round the chance that a theory is selected depends on the credence you have in said theory. So if you have 98% credence in theory 1 and only 1% in the others, you have a 98% chance of selecting it in the first round, a 98% chance in the second and a 98% in the third.</p><p>Note that value and permissibility are not the same thing. A negative value for example doesn't necessarily mean an option is impermissible. If a theory assigns option A '<i>-1000</i>' and option B '<i>-1</i>' it might be that it doesn't consider option B to be impermissible, but rather optimal. Where a theory draws the line between merely assigning a low value and also considering an option impermissible varies from theory to theory.</p><h2>&nbsp;</h2><h2>Why you need randomization</h2><p>So why would we still use randomization and not exclusively the runoff? Let's say you face the following decision:</p><figure class=\"table\"><table><tbody><tr><td style=\"vertical-align:top\">&nbsp;</td><td><p>Theory 1</p><p>30% credence</p></td><td style=\"vertical-align:top\"><p>Theory 2</p><p>20%</p></td><td style=\"vertical-align:top\"><p>Theory 3</p><p>20%</p></td><td><p>Theory 4</p><p>20%</p></td><td><p>Theory 5</p><p>10%</p></td></tr><tr><td>Option A</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td style=\"vertical-align:top\">Option B</td><td>0</td><td style=\"vertical-align:top\">1</td><td style=\"vertical-align:top\">1</td><td>1</td><td>1</td></tr></tbody></table></figure><p>If you start with the theory you have the most credence in, it's possible that you'll keep choosing options that most other plausible theories don't agree with. Randomization solves this.</p><p>Not randomizing also makes your theory vulnerable to \"theory-individuation\". Theory-individuation occurs when one theory splits into multiple versions of the same theory. For example, say you have 60% credence in utilitarianism and 40% credence in Kantianism:</p><figure class=\"table\"><table><tbody><tr><td style=\"vertical-align:top\">&nbsp;</td><td><p>Utilitarianism</p><p>60% credence</p></td><td style=\"vertical-align:top\"><p>Kantianism</p><p>40%</p></td></tr><tr><td>Option A</td><td>1</td><td>0</td></tr><tr><td style=\"vertical-align:top\">Option B</td><td>0</td><td style=\"vertical-align:top\">1</td></tr></tbody></table></figure><p>However, you soon realize that there are two slightly different versions of utilitarianism, hedonistic utilitarianism and preference utilitarianism:</p><figure class=\"table\"><table><tbody><tr><td style=\"vertical-align:top\">&nbsp;</td><td><p>Kantianism</p><p>40%</p></td><td style=\"vertical-align:top\"><p>Hedonistic<br>Utilitarianism</p><p>30%</p></td><td><p>Preference<br>Utilitarianism</p><p>30%</p></td></tr><tr><td>Option A</td><td>0</td><td>1</td><td>1</td></tr><tr><td style=\"vertical-align:top\">Option B</td><td>1</td><td style=\"vertical-align:top\">0</td><td>0</td></tr></tbody></table></figure><p>Without randomization Kantianism would dictate how you behave, even though your overall credence in utilitarianism hasn't changed.</p><p>&nbsp;</p><h2>Epistemological runoff</h2><p>However, the various versions of both \"maximizing expected choice-worthiness\" and \"the sortition model\" require you to able to assign a numerical percentage of credence to each theory. What if we aren't fans of Bayesian epistemology? Or what if we aren't able to do this in the real world?</p><p>We could have the same runoff that we did for moral value, but apply it to epistemology. So all the moral theories that our epistemological theory considers \"impermissible\" get eliminated, then the \"neutral\" ones and then the \"impermissible\" but not \"optimal\" ones. What's left are the moral theories we use our theory of moral uncertainty on.</p><p>What if we are uncertain about our epistemological theory? Don't we run into an infinite regress problem? I'm not sure how fruitful this runoff business is in meta-epistemology. Let's see if we can get a theory of moral uncertainty that doesn't require a runoff.</p><p>&nbsp;</p><h2>Convex randomization</h2><p>If we use a convex hull we don't have to assign probabilities. Here's how that works:</p><ul><li>Order the options in an arbitrary way from 1 to k.</li><li>For each theory Z, let V(Z) be the list of choice-worthinesses of all options according to this theory. I.e., the first entry is Z's evaluation of option 1, the last entry is Z's evaluation of option k.</li><li>Interpret the entries in the list V(Z) as the coordinates of a point in a k-dimensional space.</li><li>Let P be the set of all these points, one for each theory.</li><li>Let H be the \"convex hull\" of the set of points P, i.e., all points contained in a tight rubber envelope around P, or, more mathematically, all points that lie on some straight line between any two points in P.</li><li>Let R be a randomly chosen point in the interior of H (i.e., in H but not on the boundary of H), chosen from the uniform distribution on H. (Note that by excluding the boundary, we in particular exclude the possibility that R equals any of the original points in P.)</li><li>Choose the option that corresponds to the largest entry in R. I.e., if the third entry in R is the largest, choose the third option.</li></ul><p>Let's look at an example. Suppose you face this decision:</p><figure class=\"table\"><table><tbody><tr><td style=\"vertical-align:top\">&nbsp;</td><td style=\"vertical-align:top\">Theory 1</td><td>Theory 2</td><td style=\"vertical-align:top\">Theory 3</td></tr><tr><td style=\"vertical-align:top\">Option A</td><td style=\"vertical-align:top\">1</td><td>5</td><td style=\"vertical-align:top\">1</td></tr><tr><td style=\"vertical-align:top\">Option B</td><td style=\"vertical-align:top\">6</td><td>4</td><td style=\"vertical-align:top\">2</td></tr></tbody></table></figure><p>We now need to interpret the choice-worthiness as coordinates, with option A being the x-axis and option B being the y-axis.</p><figure class=\"image image_resized\" style=\"width:57.17%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/nbal1fujydal5i6hsj5p\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/eqfqftksmbabtzlvuepg 151w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/zrpqpjipkpi0gc8xbwky 231w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/djeexlolrhfqi34pwzas 311w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/msnojkyvj3mh9cvjhmac 391w\"></figure><p>Now we draw a convex hull around it. Imagine it's a tight rubber envelope around all points.</p><figure class=\"image image_resized\" style=\"width:57.52%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/dijhlkznhpxrqy9f14rn\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/ci3631tbpsalgfkqtzwh 151w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/uzkqkos2xoqwtvxzys06 231w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/sbj0ifov6kybvpw0pbxt 311w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/yqftsffzdj3pezcqhp5m 391w\"></figure><p>Now we randomly pick a point R inside this space (without its boundary).</p><figure class=\"image image_resized\" style=\"width:57.71%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/bhag6jprebgduhoficuy\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/qdazswrspwfzum2bbxax 151w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/gauup952gpoftpsvecnp 231w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/ifrxsybylzwyvfe5wgh4 311w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/orhpf9e0hmackvr1zrcd 391w\"></figure><p>Point R gives option A a choice-worthiness of 2 and B a choice-worthiness of 3, so we choose option B.</p><figure class=\"image image_resized\" style=\"width:57.83%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/ls4s0yiv4uvchxyrkhkk\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/qarsq8dk8dotrbgdzf8z 151w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/vrz4vvakey1xi4td6h7l 231w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/mhyuyskmxkdmjjplaomu 311w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/E7CvbPvvNF2XnKqdJ/pvfhutlp3my5haxstjro 391w\"></figure><p>If we make a diagonal line we can see it even more clearly. The area of the convex hull that is beneath the blue line (aka the green area) represents the odds that R will land on option A. The area of the convex hull that is above the blue line (aka the pink area) represents the odds that R will land on option B. As you can see there's a bigger chance that this process will choose option B.</p><p>The convex hull ensures that dominated option cannot win. This is because when S is dominated by T, then there is at least one theory that rates T better than S, and that theory has a nonzero weight in the mixture corresponding to R (because we exclude the boundary, on which that theory might make a zero contribution to R), so T will always have at least one larger entry in R than S has.</p><p>It also makes the theory clone-consistent: If someone takes a theory T, modifies it in a negligible way and adds it as another theory T', then the set H will change only negligibly and hence the winning probabilities won't change much. Similarly, it combats the problem of theory-individuation, splitting a theory into multiple similar theories only changes H very slightly.</p><p>&nbsp;</p><h2>Problems with convex randomization</h2><p>Convex randomization (CR) solves the problems of violating moral dominance (because of the convex hull), theory cloning/theory-individuation, and arguably the infectiousness of nihilism (because nihilism doesn't prescribe coordinates so it doesn't get added to the graph), however it does require intertheoretic comparisons of value and ratio-scale measurability.</p><p>We could say that theories find actions either permissible, impermissible, or are neutral on the matter. We could represent this as a coordinate system where permissible actions get 1, impermissible actions get -1 and actions that are deemed neutral get 0. However, while this might be preferable for categorical theories like Kantianism, this does collapse the nuance of numerical theories. If prioritarianism gives an action a choice-worthiness of 100, while utilitarianism gives it a 2, they will both be collapsed down into permissible (1) despite the huge difference between them. Perhaps adding a runoff with an \"optimal\" round will solve this, but the whole point of using the convex hull is that we no longer need a runoff.</p><p>Another problem is that CR is more computationally complex than the sortition approach. However, computational complexity isn't generally seen as a weak point by philosophers.</p><p>CR also requires there to be more theories than options. If there aren't, the interior of the 'envelope' will be empty. This isn't really a problem since almost any theory will have some continuous parameter (such as a discount rate or degree of risk-aversion) which makes it become infinitely many theories. Even if you have infinitely many discrete options, the infinite continuous theories will still outnumber them (\u2135<strong><sub>0</sub></strong> &lt; \u2135<strong><sub>1</sub></strong>).</p><p>CR has a problem with fanaticism, although to a lesser extent than MEC. If a theory says option A has 10^1000 choice-worthiness, R won't always land on option A but it will be biased towards it. Similarly, if a theory says option A has an infinite amount of choice worthiness, R won't literally always land on A, but will practically always land on A. However, MEC's solution of using amplification or using normalization to give different theories 'equal say' could also be used by CR. If you don't think we should normalize at every choice, here's a different approach. Perhaps all theories get an equal choice-worthiness 'budget' over a span of time (e.g. the agents lifetime). The theories can spent this budget however they like on any options that are presented giving theories more power to influence events they consider crucial. This would tackle choice-worthiness in the same way linear and quadratic voting tackle votes (and the same debate between the linear and quadratic approach exists here).</p><p>CR makes you less single-minded, it stops a moral theory from dominating even though it only has slightly more credence (e.g. 51% vs 49%). However, because CR uses randomization you don't appear to be entirely consistent to an outsider, which might make you harder to coordinate with. This could be solved by using the centroid instead of a random point.</p><h2>Using centroids&nbsp;</h2><p>The centroid is the \"center of gravity\" of the convex hull, and it can be seen as the most natural \"representative point\" inside that set. Interestingly, that approach can also lead to some form of &nbsp;\"ex-post\" credence values for theories, relative to the preference data. This is because the centroid can be expressed as a convex combination of all the points representing the individual theories, similar to barycentric coordinates. Each such convex combination assigns coefficients to all theories, and these coefficients sum up to 1; so they could be interpreted as credence values for the respective theories. It remains however to clarify which convex combination is the most natural one since in general there will be several.<i> &nbsp;</i></p><p>However, you might conversely think that the 'centroid theory' of moral uncertainty makes you too morally rigid. One solution could be that the randomization process is biased towards the centroid (i.e., the further from the centroid a point is the lower the probability of point R appearing there) with the strength of the bias being determined by how much you value consistency. What this allows you to do is regain a kind off credence distribution (like MEC) without actually needing probabilities.</p><p>&nbsp;</p><p>&nbsp;</p><p><strong>References</strong></p><p>MacAskill, W. (2013). The Infectiousness of Nihilism. <i>Ethics</i>, <i>123</i>(3), 508\u2013520. https://doi.org/10.1086/669564</p><p>Macaskill, W., Bykvist, K. &amp; Ord, T. (2020). Moral Uncertainty. OXFORD UNIV PR.</p>", "user": {"username": "bmjacobs@telenet.be"}}]