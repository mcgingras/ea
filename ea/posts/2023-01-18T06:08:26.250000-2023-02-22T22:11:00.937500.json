[{"_id": "d8Dd4WdyoKoZPg7EK", "title": "[Opzionale] Per approfondire \u201cDalla teoria alla pratica\u201d", "postedAt": "2023-01-18T11:56:37.386Z", "htmlBody": "<p><i>This is an Italian translation of </i><a href=\"https://forum.effectivealtruism.org/posts/NN6CjogRnmfLTL7vT/more-to-explore-on-putting-it-into-practice\"><i><strong>More to explore on 'Putting it into Practice'</strong></i></a></p><p><a href=\"https://80000hours.org/career-guide/making-a-difference/\"><u>80000 hours: Tre modi in cui chiunque pu\u00f2 fare la differenza, indipendentemente dal suo lavoro</u></a></p><h2><strong>Consigli di carriera</strong></h2><ul><li><a href=\"https://tinyurl.com/3vrd5mw2\">Evidence-based advice on how to be successful in any job - 80,000 Hours</a> (45 minuti)</li><li><a href=\"https://tinyurl.com/2y7d4rpv\">A (free) weekly career planning course for positive impact</a> - 80,000 Hours (8 settimane)</li><li><a href=\"https://www.probablygood.org/\">Probably Good</a> \u2013<i> un punto di vista leggermente diverso sul come scegliere una carriera efficace.</i></li><li><a href=\"https://www.magnifymentoring.org/\">Magnify Mentoring&nbsp;</a></li><li><a href=\"https://tinyurl.com/a4aj83ar\">Advice on how to read our advice - 80,000 Hours</a> (10 minuti)</li><li><a href=\"https://tinyurl.com/ytsbhsxf\">Ideas for high-impact careers beyond our priority paths - 80,000 Hours</a> (20 minuti)</li><li><a href=\"https://tinyurl.com/ru93ma63\">Problem areas beyond 80,000 Hours\u2019 current priorities - EA Forum</a> (20 minuti)</li><li><a href=\"https://forum.effectivealtruism.org/posts/d8Q3tFQsjG4iiXQgs/why-founding-charities-is-one-of-the-highest-impact-things#comments\">Why founding charities is one of the highest impact things you can do</a> (5 minuti)</li><li><a href=\"https://www.animaladvocacycareers.org/\">Animal Advocacy Careers</a></li></ul><h2><strong>Profili di carriere multi-causa</strong></h2><ul><li><a href=\"https://80000hours.org/career-reviews/founder-impactful-organisations/\">Founder of new projects tackling top problems career profile</a> (10 minuti)</li><li><a href=\"https://80000hours.org/articles/operations-management/\">Operations management in high-impact organizations career profile</a> (10 minuti)</li></ul><h2><strong>Donazioni</strong></h2><ul><li><a href=\"https://www.givingwhatwecan.org/giving-guide\">A guide to giving effectively</a> (articolo di 11 minuti oppure filmato di 17 minuti)</li><li><a href=\"https://www.givingwhatwecan.org/pledge/why-pledge\">Why make a giving pledge when you could just donate?</a> (5 minuti)</li><li>Articoli giornalistici su persone che donano in maniera efficace:&nbsp;<a href=\"https://tinyurl.com/y6pus9a2\">\u2018\u201cI give away half to three-quarters of my income every year\u201d\u2019 - The Guardian</a> e&nbsp;<a href=\"https://www.theguardian.com/money/2022/jan/01/new-year-resolutions-income-money-saving-charity\">\u201cNew year\u2019s resolutions: \u2018I\u2019m going to give away 10% of my income\u201d - The Guardian</a> \u2013<i> articoli di lifestyle sui membri di Giving What We Can.</i></li><li><a href=\"https://www.givingwhatwecan.org/case-studies-people-who-pledge-to-give/\"><i>Profili</i></a> o&nbsp;<a href=\"https://www.youtube.com/playlist?list=PLT88QiptgOaLYdVhB7OnmjZbJnp1Gm3YI\">filmati dei membri di Giving What We Can</a> sulle loro esperienze e motivazioni</li></ul><h2><strong>Volontariato</strong></h2><ul><li><a href=\"https://80000hours.org/articles/volunteering/\">Where\u2019s the best place to volunteer?</a> - 80,000 Hours (3 minuti)</li><li><a href=\"https://www.animaladvocacycareers.org/sv-for-you\">Is skilled volunteering for you?</a> - Carriere a sostegno degli animali (2 minuti)</li><li><a href=\"https://www.highimpactprofessionals.org/post/paths-to-impact-for-ea-working-professionals\">Paths to Impact for EA Working Professionals</a> \u2013 Professionisti ad alto impatto (3 minuti)</li></ul><h2><strong>Prendersi cura di s\u00e9</strong></h2><p>Quando ci si preoccupa molto dell\u2019avere un impatto positivo, c\u2019\u00e8 spesso il rischio di non riuscire a imporre dei limiti e di trascurare il proprio benessere per aiutare gli altri. Per evitare situazioni del genere, \u00e8 necessario essere consapevoli della relazione che sviluppiamo con le donazioni e l\u2019altruismo e non esitare nel renderla salutare e sostenibile.</p><ul><li><a href=\"https://forum.effectivealtruism.org/s/a2LBRPLhvwB83DSGq\">Replacing Guilt Series</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/pseF3ZmY7uhLtdwss/aiming-for-the-minimum-of-self-care-is-dangerous\">Aiming for the minimum of self-care is dangerous</a> (10 minuti)</li><li><a href=\"https://www.philosophyetc.net/2007/09/imperfectly-right.html\">Imperfectly right</a> (2 minuti)</li><li><a href=\"https://forum.effectivealtruism.org/posts/aYifx3zd5R5N8bQ6o/ea-dedicates\">EA Dedicates</a> (10 minuti)</li><li><a href=\"https://forum.effectivealtruism.org/posts/ZGW8Tmc6mDWZTnqyo/burnout-and-self-care\">Burnout and self-care</a> (2 minuti)</li><li><a href=\"https://forum.effectivealtruism.org/posts/yYiLv7rCHMNP98dZ5/can-my-self-worth-compare-to-my-instrumental-value\">Can my self-worth compare to my instrumental value?</a> (5 minuti)</li><li><a href=\"https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really\">After one year of applying for EA jobs: It is really, really hard to get hired by an EA organisation</a> (5 minuti)</li><li><a href=\"https://www.eamentalhealthnavigator.com/\">EA Mental health navigator</a></li><li><a href=\"https://80000hours.org/podcast/episodes/depression-anxiety-imposter-syndrome/\">Having a successful career with depression, anxiety, and imposter syndrome (80,000 Hours podcast episode)</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/2BEecjksNZNHQmdyM/don-t-be-bycatch\">Don\u2019t Be Bycatch</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/ptFkbqksdPRNyzNBB/can-i-have-impact-if-i-m-average\">Can I have an impact if I\u2019m average?</a></li><li><a href=\"https://80000hours.org/2022/04/imposter-syndrome/\">My experience with Imposter syndrome\u2014and how to (partly) overcome it</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/QhPyQTXuGt58Nzxnu/you-are-probably-underestimating-how-good-self-love-can-be\">You are probably underestimating how good self-love can be</a></li></ul><h2><strong>Miscellanea</strong></h2><ul><li><a href=\"https://forum.effectivealtruism.org/tag/take-action\">Take action - EA Forum</a></li><li><a href=\"https://80000hours.org/articles/coordination/\">Doing good together</a> (40 minuti)</li><li><a href=\"https://www.cold-takes.com/rowing-steering-anchoring-equity-mutiny/\">Rowing, Steering, Anchoring, Equity, Mutiny</a>&nbsp;<i>Riflessioni di Holden Karnofsky su alcuni approcci essenziali per migliorare il mondo.</i> (22 minuti)</li></ul>", "user": {"username": "EA Italy"}}, {"_id": "idHuFtvBXznQAcsZn", "title": "Le mie impressioni sulla scelta di una carriera per i lungoterministi", "postedAt": "2023-01-18T11:47:24.149Z", "htmlBody": "<p><i>This is an Italian translation of </i><a href=\"https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/my-current-impressions-on-career-choice-for-longtermists\"><i><strong>My current impressions on career choice for longtermists</strong></i></a></p><p>Questo post riassume brevemente le mie impressioni sulla scelta di una carriera per i lungoterministi. Non ci ho riflettuto cos\u00ec a lungo come hanno fatto quelli di <a href=\"http://www.80000hours.org/\">80,000 Hours</a>, ma penso sia utile avere pi\u00f9 punti di vista sulla questione.</p><p>Anche se i lavori che elenco si sovrappongono spesso con quelli <a href=\"https://80000hours.org/key-ideas/%23priority-paths\">proposti da 80,000 Hours</a>, li organizzo e concettualizzo in modo diverso. Su 80,000 Hours si tende a dare maggiore importanza ai \u201c<a href=\"https://80000hours.org/key-ideas/%23priority-paths\"><strong>percorsi</strong></a>\u201d verso ruoli specifici per lavorare a cause specifiche; io, al contrario, do maggiore importanza ai \u201c<strong>talenti</strong>\u201d che si possono sviluppare lavorando in una grande variet\u00e0 di ruoli e cause (incluse organizzazioni che non fanno parte dell\u2019altruismo efficace) e che si possono poi applicare a una grande variet\u00e0 di lavori di rilievo per il lungoterminismo (spesso con la possibilit\u00e0 di lavorare a pi\u00f9 di una causa). Esempi di questi talenti includono: \u201caiutare le organizzazioni a raggiungere i loro obiettivi attraverso buone pratiche lavorative\u201d, \u201cmettere a confronto le affermazioni\u201d, \u201ccomunicare idee gi\u00e0 esistenti a un pubblico non ancora convinto,\" ecc.</p><p>(Altri modelli di riferimento per scegliere la propria carriera consistono nel cominciare con le <a href=\"https://80000hours.org/key-ideas/%23perhaps-the-most-important-decision-you-face\"><strong>cause</strong></a>&nbsp;(sicurezza delle IA, rischi biologici, ecc.) o con le <a href=\"https://80000hours.org/key-ideas/%23career-strategy\"><strong>euristiche</strong></a>&nbsp;(\u201cScegli un lavoro in cui eccelli\u201d, \u201cScegli un lavoro che ti permette di creare un capitale di carriera e ti d\u00e0 pi\u00f9 possibilit\u00e0.\"). Personalmente penso che quando si tratta di scegliere la propria carriera sia utile considerare pi\u00f9 modelli di riferimento, perch\u00e9, anche se qualsiasi modello pu\u00f2 contenere informazioni utili, c\u2019\u00e8 sempre il rischio che sia troppo dogmatico o specifico per i singoli casi).</p><p>Per ogni talento che elencher\u00f2, includer\u00f2 anche idee su come esplorarlo e come capire se si stanno facendo progressi. Quello che mi piace dei modelli basati sui talenti \u00e8 che, se si vuole, spesso \u00e8 relativamente semplice farsi un\u2019idea di ci\u00f2 che promette un dato \u201ctalento\u201d e dei progressi in quell\u2019ambito. Questo al contrario degli approcci basati sulle cause o sui percorsi, dove spesso capire se ci sono lavori disponibili in un dato percorso o per una data causa \u00e8 pi\u00f9 questione di fortuna, cosa che rende difficile capire come procedere. Questo modello non vi render\u00e0 pi\u00f9 semplice trovare il lavoro che volete, ma potrebbe aiutarvi nel capire quali lavori sono adatti a voi e quali no.</p><p>Ho cercato di elencare quei talenti che hanno un\u2019alta probabilit\u00e0 di contribuire direttamente a obiettivi lungoterministi. Sicuramente ci sono altri talenti che avrei potuto inserire, inclusi quelli che, da un punto di vista lungoterminista, non sembrano troppo promettenti al momento attuale ma che potrebbero esserlo in futuro.</p><p>In molti casi, sviluppare uno di questi talenti non garantisce che otterrete un lavoro direttamente orientato ai principali obiettivi lungoterministi. Il lungoterminismo \u00e8 una visione del mondo molto recente e, perlomeno adesso, ci sono pochi lavori che rientrano in questa visione. Sono per\u00f2 dell\u2019opinione che, <strong>anche se non otterrete mai un lavoro di quel tipo, ci sono molte occasioni per contribuire a raggiungere i principali obiettivi lungoterministi, con qualsiasi lavoro e talento abbiate a disposizione</strong>. Per approfondire questo punto di vista, <strong>ho aggiunto una sezione \u201c</strong><a href=\"https://forum.effectivealtruism.org/posts/idHuFtvBXznQAcsZn/le-mie-impressioni-sulla-scelta-di-una-carriera-per-i#Al_di_l__dei_talenti__sostenere_il_lungoterminismo_in_generale\"><strong>al di l\u00e0 dei talenti</strong></a><strong>\u201d </strong>per contribuire ugualmente&nbsp;al lungoterminismo.</p><h2><strong>Alcuni talenti importanti per il lungoterminismo:</strong></h2><h2><strong>Mettere in piedi, dirigere e promuovere un\u2019organizzazione</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref83xu4nqdx57\"><sup><a href=\"#fn83xu4nqdx57\">[1]</a></sup></span></h2><p><strong>Il profilo in breve:</strong>&nbsp;aiutare un\u2019organizzazione contribuendo con capacit\u00e0 \u201cutili in generale\u201d. Con \u201ccapacit\u00e0 utili in generale\u201d intendo capacit\u00e0 che possano aiutare molte organizzazioni diverse a raggiungere molti obiettivi diversi. Alcune di queste capacit\u00e0 includono:</p><ul><li>Gestione aziendale e project management (incluso il definire obiettivi, sistemi di misura, ecc.)</li><li>Coaching gestionale e gestione del personale (alcuni ruoli di management richiedono competenze specialistiche, ma per altri sono sufficienti competenze generiche in campo dirigenziale)</li><li>Leadership esecutiva (definire e lavorare su obiettivi che riguardano l\u2019intera organizzazione, prendere decisioni di massimo livello sul budget, ecc.)</li><li>Assunzione di personale</li><li>Fundraising e marketing</li><li>Risorse umane</li><li>Gestione dei servizi</li><li>Gestione degli eventi</li><li>Assistenti e ruoli amministrativi</li><li>Comunicazione aziendale e pubbliche relazioni</li><li>Finanza e contabilit\u00e0</li><li>Diritto d\u2019impresa</li></ul><p><strong>Esempi:</strong></p><p>Beth Jones (Direttrice gestionale presso Open Philanthropy); Max Dalton e Joan Gass presso CEA; Malo Bourgon presso MIRI. (Mi sono concentrato su persone con ruoli dirigenziali e ho fornito solo qualche esempio, ma avrei potuto elencare una buona fetta di persone che attualmente lavorano per organizzazioni associate al lungoterminismo, cos\u00ec come persone che lavorano per organizzazioni non direttamente associate al lungoterminismo ma il cui lavoro \u00e8 importante da un punto di vista lungoterminista. In generale, questi esempi sono solo a scopo illustrativo e si concentrano su casi piuttosto semplici o \u201cpuri\u201d di persone focalizzate su un singolo talento; consiglio di non soffermarsi su possibili \u201cesclusioni\u201d)</p><p><strong>Come sviluppare questo talento:</strong></p><p>Questo talento prevede molte specializzazioni possibili. In linea generale, ognuna di queste pu\u00f2 essere sviluppata presso qualsiasi organizzazione che ne abbia bisogno.</p><p>In molti casi, lavorare in ambito specialistico all\u2019inizio della carriera d\u00e0 accesso ad altri ambiti in futuro. Spesso \u00e8 possibile passare da una specializzazione all\u2019altra e provare cose diverse. (Le ultime tre capacit\u00e0 nell\u2019elenco \u2013 comunicazione, finanza/contabilit\u00e0 e diritto d\u2019impresa \u2013 sono probabilmente quelle con cui \u00e8 meno facile).</p><p>In particolare, unirsi a organizzazioni piccole ma in crescita mi sembra un\u2019ottima scelta. In questo tipo di organizzazioni c\u2019\u00e8 spesso la possibilit\u00e0 di lavorare su molte cose diverse e di venire a contatto con molti degli aspetti che riguardano il successo di un\u2019organizzazione. Un ottimo modo per fare esperienza in ambito gestionale, in cui i ruoli spesso richiedono competenze molto richieste e che si possono applicare a molte organizzazioni diverse. Far parte di una societ\u00e0 di questo tipo, a prescindere dal ruolo, ed essere flessibili e concentrati sul contribuire al successo della societ\u00e0 pu\u00f2 essere un\u2019ottima esperienza formativa che ti aiuter\u00e0 sia a individuare i talenti adatti a te che a svilupparli.</p><p><strong>Monitorare i progressi</strong></p><p>All\u2019inizio, la domanda \u201cstai facendo progressi nello sviluppo di un talento importante per il lungoterminismo?\" pu\u00f2 essere riassunta con \u201cQuanto buone sono in generale le tue prestazioni?\". Aumenti di stipendio, promozioni e performance review sono tutti elementi importanti. Personalmente penso che per misurare davvero il tuo successo sia necessario vedere quanto i tuoi colleghi sono entusiasti di te e quanto volentieri ti raccomanderebbero \u2013 unito al fatto che gli stessi colleghi (e l\u2019organizzazione per cui lavori) sono a loro volta degni di nota.</p><p>Chi lavora su questo talento potrebbe a volte avere l\u2019impressione di non stare contribuendo davvero a un grande obiettivo, nonostante le buone prestazioni. A inizio carriera, penso che per questo talento sia pi\u00f9 importante avere buone prestazioni piuttosto che essere entusiasti degli obiettivi dell\u2019organizzazione per cui lavori, dando per buono che il tuo lavoro sia nel complesso soddisfacente e sostenibile. Pi\u00f9 avanti, una volta sviluppato un buon set di competenze essenziali, pu\u00f2 essere utile dare pi\u00f9 peso agli obiettivi.</p><h2><strong>Talenti politici e burocratici</strong></h2><p><strong>Il profilo in breve:</strong>&nbsp;fare carriera in ruoli di grande influenza nel governo (o altre istituzioni, come la Banca Mondiale) per aiutare grandi istituzioni a prendere buone decisioni per il futuro a lungo termine del mondo.</p><p>&nbsp;Mentre la maggior parte dei <a href=\"https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice%23_Organization_building__running__and_boosting__aptitudes_1_\">talenti a sostegno delle organizzazioni</a>&nbsp;aiuta (sul lungo periodo) alcune organizzazioni a raggiungere obiettivi gi\u00e0 prefissati e da te condivisi, i talenti politici e burocratici riguardano principalmente l\u2019utilizzare la propria influenza (o una rete di influenze) per aumentare l\u2019importanza e il peso dato a obiettivi lungoterministi all\u2019interno di un\u2019istituzione.</p><p>In pratica, rientra in questa categoria qualsiasi carriera che ti porti ad avere una posizione di potere all\u2019interno dello Stato (inclusi ruoli giuridici, amministrativi e legislativi), anche se ovviamente alcune sono pi\u00f9 importanti di altre.</p><p><strong>Esempi:</strong></p><p>Richard Danzig (ex Segretario della Marina, autore di <a href=\"https://www.cnas.org/publications/reports/technology-roulette\">Technology Roulette</a>); diverse persone che stanno conseguendo lauree in scienze della sicurezza a Georgetown e puntano a ottenere (o stanno gi\u00e0 ottenendo) lavori all\u2019interno del governo.</p><p><strong>Come sviluppare questo talento:</strong></p><p>Per prima cosa, \u00e8 necessario avere un\u2019idea molto precisa di quale istituzione (o insieme di istituzioni) \u00e8 adatta a te. Potresti ad esempio chiederti: \u201cin quale istituzione mi sentirei a mio agio, produttivo e motivato a lungo seguendone le regole?\" Il mio consiglio \u00e8 di parlare con persone con una lunga carriera alle spalle presso quell\u2019istituzione, in modo da farti un\u2019idea molto precisa di quanto tempo occorra per ottenere il ruolo a cui stai puntando, di come sar\u00e0 la tua vita quotidiana in quel lasso di tempo e di cosa avrai bisogno per avere successo.</p><p>Il passo successivo \u00e8 candidarsi per qualsiasi ruolo all\u2019interno dell\u2019organizzazione e ottenere buone prestazioni secondo gli standard di questa istituzione. Colleghi che hanno gi\u00e0 fatto carriera dovrebbero essere in grado di mostrarti quali sono questi standard. Di solito (ma non \u00e8 una regola ferrea), direi che fare carriera in qualsiasi ambito all\u2019interno dell\u2019istituzione \u00e8 un buon inizio, a prescindere dal fatto che quell\u2019ambito si leghi al lungoterminismo o meno.</p><p>A volte il modo migliore per fare carriera \u00e8 prendersi un po\u2019 di tempo all\u2019infuori dell\u2019istituzione stessa (presso ad esempio una facolt\u00e0 di giurisprudenza, un think tank o scuole di processi politici). Con le scuole di specializzazione spesso c\u2019\u00e8 il rischio di sprecare troppo tempo senza imparare nulla che possa davvero farti fare carriera, per cui \u00e8 meglio assicurarsi che quel diploma valga davvero la pena.</p><p><strong>Monitorare i progressi</strong></p><p>All\u2019inizio la domanda \u201cQuanti progressi stai facendo?\" pu\u00f2 essere riassunta con \u201cCon quanta rapidit\u00e0 stai facendo carriera, secondo gli standard dell\u2019istituzione?\" Le persone con pi\u00f9 esperienza (e carriera alle spalle) all\u2019interno dell\u2019istituzione spesso sono in grado di aiutarti ad avere un\u2019idea precisa dei progressi che stai facendo (e, in linea generale, penso che sia importante avere buoni rapporti con queste persone per avere sempre un riscontro onesto da parte loro \u2013 un altro indicatore per capire se sei \u201csulla buona strada\u201d). Se le tue prestazioni sono buone e stai facendo carriera, ci sono buone probabilit\u00e0 che prima o poi sarai in grado di accedere a ruoli all\u2019interno dell\u2019istituzione che sono pi\u00f9 importanti per il lungoterminismo.</p><p>Penso che una delle domande fondamentali da porsi per questo talento sia \u201cQuanto sembra sostenibile?\". Domanda importante per tutti i talenti, ma soprattutto in questo caso: nel caso di ruoli burocratici e politici, se riuscirai a fare carriera dipender\u00e0 da quanto a lungo riuscirai a rimanere in quel ruolo e se riuscirai a soddisfare le aspettative esplicite e implicite dell\u2019istituzione.</p><h2><strong>Talenti di ricerca concettuale ed empirica su temi lungoterministi fondamentali</strong></h2><p><strong>Il profilo in breve:</strong>&nbsp;contribuire al raggiungimento di conclusioni significative e corrette sulle azioni pi\u00f9 importanti che gli altruisti efficaci devono intraprendere. Ad esempio:</p><ul><li>Quali cause sono pi\u00f9 promettenti? (Incluse anche cose come argomentare a favore del lungoterminismo)</li><li>la distribuzione di probabilit\u00e0 tra, ad esempio, (a) l\u2019avvento di IA trasformative e (b) la portata di diversi rischi esistenziali.</li><li>Cosa ci pu\u00f2 insegnare la storia sui percorsi pi\u00f9 promettenti per far crescere la comunit\u00e0 dell\u2019altruismo efficace?</li><li>Quali cambiamenti di politiche sarebbe meglio sostenere per ridurre il rischio esistenziale?</li><li>Quanto denaro dovrebbe essere ripartito tra diversi beneficiari per una causa specifica (o in generale)? (E come dovrebbe essere ripartito nel tempo, ovvero, \u201cmeglio donare subito o donare in seguito?\")</li><li>Quali tipi di lavoro sono pi\u00f9 indicati per gli altruisti efficaci?</li></ul><p>&nbsp;</p><p>Dal momento che \u00e8 un ambito che conosco piuttosto bene, scender\u00f2 un po\u2019 pi\u00f9 nel dettaglio. Penso per\u00f2 che sia uno dei talenti pi\u00f9 difficili da sviluppare al momento, perch\u00e9 di solito richiede molta auto-direzionalit\u00e0.</p><p><strong>Esempi:</strong></p><ul><li>Eliezer Yudkowsky, Nick Bostrom e altri che hanno sostenuto l\u2019importanza di dare priorit\u00e0 ai rischi esistenziali e alla sicurezza delle IA in particolare.</li><li>La maggior parte delle persone con ruoli di ricerca al Future of Humanity Institute.</li><li>La maggior parte delle persone con ruoli di ricerca presso Open Philanthropy (la stessa cosa si potrebbe dire per le posizioni di grantmaker).</li><li>Le persone che lavorano a 80,000 Hours e decidono quali sono i migliori consigli e strategie da dare (al contrario di quelli che decidono come comunicarli).</li></ul><p>Vale la pena notare che alcune persone in questa categoria svolgono pi\u00f9 che altro ricerca filosofica/concettuale, mentre altre svolgono principalmente lavoro empirico; alcune si concentrano sul formulare nuove teorie, mentre altre sul mettere a confronto diverse opzioni. Il tema che le unisce \u00e8 concentrarsi sul raggiungere <strong>conclusioni sostanzialmente corrette</strong>, non sul come comunicare meglio le conclusioni a cui sono giunte altre persone.</p><p><strong>Come sviluppare questi talenti:</strong></p><p>Il punto di partenza ideale sarebbe un ruolo in un\u2019organizzazione che si concentri in modo particolare sul tipo di causa che ti interessa. Se ti interessa fare ricerca sulle <a href=\"https://www.effectivealtruism.org/articles/crucial-considerations-and-wise-philanthropy-nick-bostrom/%23:~:text%3DSo%2520a%2520crucial%2520consideration%2520is,our%2520practical%2520endeavors%252C%2520but%2520a\">considerazioni essenziali</a>, potresti candidarti per un lavoro al Future of Humanity Institute; se ti interessa l\u2019ambito del grantmaking, un lavoro presso Open Philanthropy potrebbe essere una buona scelta.</p><p>Ci sono altri lavori che mi sembrano promettenti per lo sviluppo di strumenti, abitudini e metodi fondamentali:</p><ul><li>La ricerca accademica in campi importanti per le cause su cui vuoi lavorare. \u00c8 difficile generalizzare, ma per quel che riguarda i temi concettuali, penso che filosofia, matematica, scienza dei computer e fisica teorica siano particolarmente promettenti; sul versante empirico, l\u2019economia sembra la pi\u00f9 promettente in linea generale, dal momento che sembra importante avere buone conoscenze di scienze sociali quantitative. (Potrebbero essere utili anche altri campi, come la storia e le scienze politiche).</li><li>Lavori che richiedono di prendere molte decisioni discrezionali e fare molte stime, meglio se su \u201cmacro\u201d argomenti e/o su argomenti il pi\u00f9 possibile affini ai temi a cui sei interessato. Ci sono alcuni lavori del genere nella finanza \u201cbuy-side\u201d (cercare di prevedere l\u2019andamento dei mercati) e in politica (ad esempio <a href=\"https://bluelabs.com/who-we-are/about-us/\">BlueLabs</a>).</li></ul><p>Penso anche che ci siano occasioni per esplorare e dimostrare questi talenti attraverso lo <strong>studio autodidatta e il lavoro indipendente \u2013</strong>&nbsp;con il proprio tempo e/o con borse di studio pensate appositamente (come ad esempio il <a href=\"https://av20jp3z.paperform.co/\"><u>EA Long-Term Future Fund grants</u></a>, <a href=\"https://www.fhi.ox.ac.uk/rsp/\">Research Scholars Program</a>&nbsp;e l\u2019<a href=\"https://www.openphilanthropy.org/focus/other-areas/early-career-funding-individuals-interested-improving-long-term-future\">Open Philanthropy support for individuals working on relevant topics</a>).</p><p>Penso che attualmente questi talenti richiedano molta auto-direzionalit\u00e0, a prescindere dal luogo di lavoro. Per questo testarli per conto proprio pu\u00f2 essere una buona idea (anche se, vista la difficolt\u00e0, suggerirei di approcciarsi per cercare di capire se possono essere utili/interessanti/soddisfacenti piuttosto che per cercare attivamente un lavoro).</p><p>Uno schema di base per testare questi talenti da autodidatta potrebbe assomigliare a questo:</p><ul><li>Analizza teorie e temi legati all\u2019altruismo efficace, approfondiscili molto nel dettaglio e fatti una tua idea \u201cdall\u2019interno\u201d (ovvero basata sul tuo pensiero e la tua logica piuttosto che su quello che pensano gli altri).</li><li>Esponi la tua visione con chiara <a href=\"https://www.openphilanthropy.org/reasoning-transparency\">trasparenza di ragionamento</a>&nbsp;in luoghi come LessWrong o il forum dell\u2019Altruismo Efficace.</li><li>Unisciti alla discussione.</li></ul><p>Alcuni esempi di approccio:</p><ul><li>Review critiche e precise di alcuni articoli e argomentazioni su temi lungoterministi. Potrebbe trattarsi di articoli molto importanti come <a href=\"https://www.nickbostrom.com/astronomical/waste.html\">Astronomical Waste</a>, <a href=\"https://rucore.libraries.rutgers.edu/rutgers-lib/40469/PDF/1/play/\">On the Overwhelming Importance of Shaping the Far Future</a>, un capitolo di <a href=\"https://smile.amazon.com/dp/B00LOOCGB2/ref%3Ddp-kindle-redirect?_encoding%3DUTF8%26btkr%3D1\">Superintelligenza</a>&nbsp;o di <a href=\"https://smile.amazon.com/dp/B07VB299G3/ref%3Ddp-kindle-redirect?_encoding%3DUTF8%26btkr%3D1\">The Precipice</a>, articoli sulle tempistiche delle IA, ecc. Oppure pezzi pi\u00f9 semplici come gli ultimi post del Forum dell\u2019Altruismo Efficace, l\u2019AI Alignment Forum, LessWrong o un blog che secondo te parla di argomenti interessanti. Illustra nella maniera pi\u00f9 chiara possibile i punti su cui sei d\u2019accordo e/o illustra uno o pi\u00f9 punti di divergenza con l\u2019autore.</li><li>Scegli domande come ad esempio \u201cQuali sono le probabilit\u00e0 che una catastrofe esistenziale avvenga in questo secolo?\" (molto generale) o \u201cQuali sono le probabilit\u00e0 di assistere a un inverno nucleare in questo secolo?\" (pi\u00f9 specifica, probabilmente pi\u00f9 gestibile). Esponi e motiva il tuo punto di vista sull\u2019argomento e/o su domande secondarie che potrebbero venirti in mente mentre ci lavori.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6oyxbqo2r33\"><sup><a href=\"#fn6oyxbqo2r33\">[2]</a></sup></span></li><li>Approfondisci domande catalogate come \u201crichiede ulteriori indagini\u201d (esempi <a href=\"https://www.openphilanthropy.org/blog/technical-and-philosophical-questions-might-affect-our-grantmaking\">qui</a>&nbsp;e <a href=\"https://docs.google.com/document/d/1cCJjzZaJ7ATbq8N2fvhmsDOUWdm7t3uSSXv6bD0E_GM/edit%23heading%3Dh.1ewyaoago2z6\">qui</a>). Prova a individuare domande secondarie su cui fare luce e scrivi un resoconto della tua ricerca.</li></ul><p>Per questo tipo di esercizio potrebbe anche essere utile cominciare con qualcosa di pi\u00f9 concreto e gestibile. Ad esempio:</p><ul><li>Illustra o fornisci una critica di argomentazioni su temi che trovi molto interessanti.</li><li>Fai scommesse e/o previsioni su PredictIt, GJOpen o Metaculus e motiva il tuo ragionamento.</li><li>Scrivi <a href=\"https://www.lesswrong.com/posts/Sdx6A6yLByRRs8iLY/fact-posts-how-and-why\">fact posts</a>.</li><li>Analizza con attenzione e illustra e/o critica i consigli di <a href=\"https://www.givewell.org/\">GiveWell\u2019s</a>&nbsp;e le <a href=\"https://www.givewell.org/how-we-work/our-criteria/cost-effectiveness/cost-effectiveness-models\">analisi di costo-efficacia</a>, o i paper di <a href=\"https://globalprioritiesinstitute.org/\">GPI</a>.</li><li>Scrivi review di letteratura accademica su un argomento che ti interessa e prova a giungere a una conclusione, motivando il tuo ragionamento (Il tag \u201c<a href=\"https://slatestarcodex.com/tag/much-more-than-you-wanted-to-know/\">more than you wanted to know\u201d</a>&nbsp;di Slate Star Codex contiene molti esempi di questo tipo di esercizio; un modo molto semplice per trovare nuovi temi \u00e8 fare ricerca su domande di carattere medico a cui sei interessato).</li></ul><p>In linea generale, non penso che sia necessario preoccuparsi troppo di essere \u201coriginali\u201d o di elaborare nuove idee. Per quella che \u00e8 la mia esperienza, cercare di delineare il proprio pensiero nel dettaglio \u2013 anche quando la comprensione della materia \u00e8 molto basilare o gi\u00e0 comunemente accettata \u2013 porta in primo piano punti su cui si hanno pi\u00f9 dubbi o confusione, da cui spesso si pu\u00f2 imparare molto e/o scoprire altri punti pi\u00f9 trascurati. Penso che scrivere di temi trascurati sia l\u2019ideale quando si ha gi\u00e0 idea di questi temi, ma anche le spiegazioni chiare e dettagliate e le valutazioni critiche di argomentazioni gi\u00e0 esistenti hanno il loro valore.</p><p>&nbsp;</p><p><strong>Monitorare i progressi</strong></p><p>Esempi di traguardi a cui puntare quando si sviluppano questi talenti:</p><ul><li>Stai dedicando molto tempo a questo progetto e stai creando nuovi contenuti. (\u00c8 probabile che per molti questo sar\u00e0 il traguardo pi\u00f9 difficile da raggiungere, se non altro perch\u00e9, data l\u2019auto-direzionalit\u00e0 necessaria per questo tipo di lavoro, \u00e8 difficile mantenere alti i livelli di motivazione e produttivit\u00e0).</li><li>Senti di aver elaborato e illustrato diverse argomentazioni originali, valide e importanti (anche se non per forza rivoluzionarie) su temi lungoterministi fondamentali.</li><li>Hai ricevuto feedback positivo a sufficienza (approvazione, commenti, conversazioni private) da pensare che c\u2019\u00e8 un certo numero di persone (di cui ti fidi e che riflettono a lungo su questi argomenti) che sono d\u2019accordo con te.</li><li>Hai stretto legami significativi con altre persone interessate a questi temi \u2013 connessioni che con ogni probabilit\u00e0 porteranno nuovi finanziamenti e/o opportunit\u00e0 lavorative. Potrebbero venire da quelle organizzazioni che si dedicano pi\u00f9 di tutte ai temi che ti interessano, oppure potrebbe esserci una dinamica \u201cdissidente\u201d, per cui queste organizzazioni non sembrano interessate e/o sono sulla difensiva ma proprio per questo altre organizzazioni si offrono di aiutarti.</li></ul><p>Cos\u00ec a prima vista, la mia impressione \u00e8 che alle persone adatte a questo talento sarebbe sufficiente un anno di lavoro o studio indipendente a tempo pieno per raggiungere questi traguardi, ma anche 2-3 anni impiegando solo il 20% del tempo (vale a dire un giorno a settimana) dovrebbero bastare.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefv8pgdevzzn\"><sup><a href=\"#fnv8pgdevzzn\">[3]</a></sup></span>&nbsp;(Penso che questo tipo di ruolo richieda molti \u201cprocessi in background\u201d, per questo mi aspetto che un anno al 20% sia produttivo pi\u00f9 di 1/5 di un anno a tempo pieno). Farei \u201cpartire il cronometro\u201d dal momento in cui si comincia a ritagliarsi del tempo e si fissano degli obiettivi (non aspetterei fino a quando si investe in modo proficuo il proprio tempo perch\u00e9, come detto prima, \u00e8 uno degli aspetti pi\u00f9 impegnativi di questo lavoro).</p><p><strong>Conflitti con \u201cpercorsi\u201d di ricerca. </strong>Piuttosto che puntare a lavorare su un tema in particolare, come la governance delle IA o l\u2019assegnare priorit\u00e0 alle cause, il mio consiglio \u00e8 di cominciare da qualunque tema per il quale tu abbia interessi ed energie. Penso che chiunque riesca a farcela seguendo questi criteri abbia buone probabilit\u00e0 di costruirsi una carriera da ricercatore su <i>qualunque </i>tema simile. Per questo penso che sia fattibile testare o esplorare questo talento senza che ci siano per forza annunci di lavoro specifici in un dato ambito (anche se, di nuovo, penso che la percentuale di successi in generale sar\u00e0 bassa).</p><h2><strong>Talenti da \u201ccomunicatore\u201d</strong></h2><p><strong>Il profilo in breve:</strong>&nbsp;aiutare nella comunicazione di messaggi e idee fondati ed essenziali. Il pubblico pu\u00f2 essere molto generalista (scrivere per i media generalisti) o pi\u00f9 specialista (scrivere per i policymaker su problemi specifici). Questi messaggi possono essere, ad esempio, l\u2019importanza dei rischi di catastrofe globale, il problema dell\u2019allineamento delle IA, i pericoli rappresentati da programmi governativi segreti per lo sviluppo di armi biologiche, l\u2019altruismo efficace in generale e molti altri.</p><p><strong>Esempi:</strong></p><ul><li>Kelsey Piper e altri giornalisti di <a href=\"https://www.vox.com/future-perfect/2018/10/15/17924288/future-perfect-explained\">Future Perfect</a>.</li><li>Autori di libri generalisti come <a href=\"https://smile.amazon.com/dp/B085T55LGK/ref%3Ddp-kindle-redirect?_encoding%3DUTF8%26btkr%3D1\">The Alignment Problem</a>.</li><li>Persone che si occupano di social media e/o podcast, come Julia Galef e Rob Wiblin.</li><li>Persone che lavorano per think tank, il cui obiettivo principale \u00e8 riformulare idee fondamentali in modo che siano pi\u00f9 attraenti per un pubblico che si occupa di policymaking.</li></ul><p><strong>Come sviluppare questi talenti:</strong></p><p>Per prima cosa \u00e8 necessario avere un\u2019idea del <strong>tipo di pubblico</strong>&nbsp;con cui si vuole comunicare. Ti potresti chiedere ad esempio: \u201cQual \u00e8 il genere di persona che comprendo e con cui riesco a comunicare meglio della maggior parte degli altruisti efficaci o lungoterministi?\"</p><p>Puoi quindi cercare di ottenere qualsiasi lavoro che preveda comunicare con questo pubblico e ricevere feedback in maniera regolare, che si tratti di comunicazione su temi AE/lungoterministi o meno. Il talento principale che viene sviluppato in questo caso \u00e8 la capacit\u00e0 generale di comunicare con il pubblico (ma anche la conoscenza di temi AE/lungoterministi sar\u00e0 importante a un certo punto). Per questo, se sei interessato a comunicare con un pubblico ampio o piuttosto generalista, la maggior parte dei lavori in campo giornalistico, nonch\u00e9 molti nell\u2019ambito delle pubbliche relazioni e della comunicazione aziendale, fanno al caso tuo.</p><p>Penso anche che ci siano numerose occasioni di sviluppare questo talento con il lavoro indipendente, che si tratti di blog, Twitter, podcast o altro. Penso che alcune tra le persone con pi\u00f9 possibilit\u00e0 di diventare comunicatori siano quelle che si trovano a loro agio nel creare molti contenuti e nell\u2019interagire in modo naturale con il loro pubblico. (Anche se consiglierei a chiunque svolga lavoro pubblico indipendente di prendere le precauzioni necessarie per evitare di pubblicare contenuti involontariamente offensivi che potrebbero danneggiare le proprie prospettive di lavoro per parecchio tempo, anche se l\u2019offesa percepita \u00e8 solo il risultato di un malinteso).</p><p><strong>Monitorare i progressi</strong></p><p>All\u2019inizio la domanda \u201cSei sulla buona strada per sviluppare un talento \u201cda comunicatore\u201d rilevante per il lungoterminismo?\" pu\u00f2 essere riassunta in \u201cIn linea generale, quanto successo stai avendo secondo gli standard del percorso di carriera (orientato alla comunicazione) che hai scelto?\" Pi\u00f9 avrai successo e migliore sar\u00e0 la posizione in cui ti troverai prima o poi per poter comunicare importanti idee lungoterministe al tuo pubblico di riferimento.</p><p>Farsi un seguito attraverso la creazione di contenuti indipendenti sarebbe anche un chiaro segnale di compromesso.</p><p>In entrambi i casi, puoi aspettarti di avere una valutazione realistica dei tuoi progressi entro i primi 2-3 anni.</p><h2><strong>Talenti da \u201cimprenditore\u201d</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreff3x0do6q6ps\"><sup><a href=\"#fnf3x0do6q6ps\">[4]</a></sup></span></h2><p><strong>Il profilo in breve:</strong>&nbsp;fondare, sviluppare e (almeno per un po\u2019 di tempo) dirigere un\u2019organizzazione che lavora a obiettivi lungoterministi. Alcuni fondano organizzazioni principalmente per essere indipendenti nella loro ricerca e nel loro lavoro. In questo caso invece penso a qualcuno il cui obiettivo dichiarato \u00e8 investire in assunzioni, management, cultura, <i>vision</i>, ecc., con lo scopo di creare un\u2019organizzazione che possa rimanere operativa anche quando il suo fondatore la lascia.</p><p>(Non tutti fondano organizzazioni con questo preciso scopo. A volte un\u2019organizzazione fondata da una persona coinvolge nel lavoro \u201cimprenditoriale\u201d molte persone che arrivano in seguito e ottengono ruoli esecutivi di alto livello).</p><p><strong>Esempi:</strong></p><p>Alcuni esempi evidenti (l\u2019organizzazione \u00e8 indicata tra parentesi, anche se la persona non lavora pi\u00f9 l\u00ec) sono Ben Todd (<a href=\"http://www.80000hours.org/\">80,000 Hours</a>), Jason Matheny (<a href=\"https://cset.georgetown.edu/\">CSET</a>), Elie Hassenfeld e io stesso (<a href=\"http://www.givewell.org/\">GiveWell</a>). Molte altre organizzazioni lungoterministe hanno avuto un ricambio consistente ai vertici (facendo sorgere dei dubbi su chi effettivamente abbia fatto il grosso del lavoro da \u201cimprenditore\u201d) e/o sono centri accademici piuttosto che organizzazioni tradizionali.</p><p><strong>Come sviluppare questo talento:</strong></p><p>Spesso il mondo imprenditoriale richiede di saper giostrare pi\u00f9 compiti di quelli che si possono davvero imparare \u201cnel modo giusto\u201d. Cosa fondamentale, si basa sulla capacit\u00e0 e la volont\u00e0 di gestire \u201cil minimo indispensabile\u201d (di solito con pochissimo addestramento o guida) molti aspetti e concentrare le proprie energie su quelli che vale la pena eseguire \u201cpiuttosto bene\u201d.</p><p>Sapendo questo, penso che la persona pi\u00f9 adatta per fondare un\u2019organizzazione sia quella che \u00e8 cos\u00ec convinta della necessit\u00e0 (e del successo) di una tale organizzazione, che praticamente non riesce a immaginare di poter lavorare a nient\u2019altro. Si tratta del tipo di persona che di solito ha un\u2019idea molto precisa di quello che sta cercando di fare e sa come raggiungere i compromessi illustrati sopra. Non solo, \u00e8 anche disponibile e in grado di gestire grandi quantit\u00e0 di lavoro pur non avendo una solida guida alle spalle.</p><p>L\u2019approccio che mi sento di consigliare \u00e8 il seguente: se non provi il desiderio di creare un\u2019organizzazione (o perlomeno se non hai una visione ben definita), probabilmente non \u00e8 il momento giusto per diventare imprenditore. Potrebbe invece essere pi\u00f9 sensato cercare un lavoro in cui tu possa imparare di pi\u00f9 sugli aspetti di quel mondo che ti interessano e comprendere meglio come funzionano le organizzazioni, ecc. Col tempo questo potrebbe servirti a individuare \u201caree vuote\u201d che desideri riempire.</p><p>Se invece hai <i>qualsiasi </i>idea per un\u2019organizzazione che pensi possa avere successo e che ti entusiasmerebbe moltissimo provare a mettere in piedi, allora penso che provare a realizzarla sarebbe un\u2019ottima esperienza formativa e un modo per sviluppare un talento da \u201cimprenditore\u201d generale. Questo vale anche se l\u2019organizzazione che hai in mente non svolge lavoro lungoterminista (ad esempio se \u00e8 una startup tecnologica tradizionale). Tieni per\u00f2 a mente che potrebbe volerci parecchio tempo (diversi anni, a volte pi\u00f9 di 10) per avere un\u2019organizzazione di successo tale da poter farsi da parte in modo responsabile e passare a occuparsi di qualcos\u2019altro.</p><p><strong>Monitorare i progressi</strong></p><p>Per i primi due anni, un segnale positivo \u00e8 se la tua organizzazione si trova in una buona situazione finanziaria, non ci sono stati disastri e sta andando bene nell\u2019attrarre nuovi talenti. Per il resto, decidere come sta andando un\u2019organizzazione \u00e8 spesso questione di opinioni.</p><h2><strong>Talenti di \u201ccommunity building\u201d</strong></h2><p><strong>Il profilo in breve:</strong>&nbsp;unire le persone con interessi e obiettivi comuni in modo che l\u2019impegno verso quegli obiettivi e interessi sia pi\u00f9 forte e per creare pi\u00f9 opportunit\u00e0 e connessioni per raggiungerli. Questo si pu\u00f2 fare tramite una rete di contatti (conoscere molte persone e far s\u00ec che si conoscano a vicenda), incontri ed eventi, assunzioni dirette,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqzlbeu6bg2\"><sup><a href=\"#fnqzlbeu6bg2\">[5]</a></sup></span>&nbsp;ecc. Un\u2019altra componente importante \u00e8 fornire ai nuovi arrivati le risorse necessarie e aiutarli ad approfondire le proprie conoscenze.</p><p><strong>Esempi:</strong></p><p>Persone che gestiscono gruppi AE locali, dell\u2019universit\u00e0 e altri luoghi, che organizzano EAGx, oltre a molte delle persone che lavorano al Centre For Effective Altruism.</p><p><strong>Come sviluppare questo talento:</strong></p><p>Con ogni probabilit\u00e0 esiste gi\u00e0 una comunit\u00e0 di cui fai parte o un gruppo di persone che conosci con cui puoi cominciare immediatamente a lavorare, in questo modo: facendo rete e presentando persone; organizzando incontri e altri eventi, ecc. All\u2019inizio lo si pu\u00f2 fare nel tempo libero, ma se questa mini-comunit\u00e0 comincia a ingrandirsi e prosperare, il mio consiglio \u00e8 di cercare finanziamenti per espanderti in un lavoro a tempo pieno e di capire se puoi anche aumentare il numero di persone con cui lavori.</p><p><strong>Monitorare i progressi</strong></p><p>Mi riesce un po\u2019 difficile illustrare le condizioni di \u201cprogresso\u201d per questo talento, pi\u00f9 che per gli altri talenti in questo articolo. Ci sono un paio di possibilit\u00e0:</p><ul><li>Per usare come esempio un modello basato sugli incontri: in linea generale puoi pensare di stare andando bene se entro 1-3 anni (a tempo pieno o part time) hai avuto un ruolo decisivo nel mettere assieme un gruppo in cui le persone interagiscono regolarmente, che ha un buon numero di persone molto motivate che si incontrano di frequente e che ha un certo numero di persone che secondo te dedicheranno buona parte della loro carriera ad avere un impatto lungoterminista di successo. (Dal momento che le dimensioni di queste comunit\u00e0 variano molto, \u00e8 difficile fornire delle cifre precise. In linea generale, penso a partecipanti regolari che superino la decina e un piccolo gruppetto di persone con buone potenzialit\u00e0).</li><li>Altre versioni del community building potrebbero essere meno incentrate sul \u201corganizzare una comunit\u00e0 di altruisti efficaci che si incontrano regolarmente\u201d e pi\u00f9 sul \u201ccreare eventi che portano a nuove connessioni\u201d. In questo caso penso che un buon metro di giudizio consista nel vedere chi sta \u201csostenendo\u201d i tuoi eventi con la sua partecipazione (soprattutto se ripetuta) e/o consigliandoli ad altri.</li><li>Una definizione un po\u2019 pi\u00f9 generale di \u201cprogresso\u201d: stai fornendo spazi e/o servizi (servizi di networking, spazi sociali, spazi di discussione, ecc.) apprezzati e consigliati da un buon numero di persone; conosci molto bene il tuo pubblico di riferimento e il valore che questi spazi hanno per le persone; un gruppo di persone molto promettenti sta facendo buon uso degli spazi che offri.</li></ul><p>&nbsp;</p><p>&nbsp;</p><h2><strong>Talenti nello sviluppo software</strong></h2><p><strong>Il profilo in breve:</strong>&nbsp;Penso che ci siano molti modi in cui lo sviluppo software possa essere utile al lungoterminismo:</p><ul><li>I laboratori di IA (pi\u00f9 che altro nell\u2019industria, ma a volte anche negli ambienti accademici) hanno bisogno di sviluppatori software e la richiesta potrebbe aumentare.</li><li>In alcuni casi gli sviluppatori lavorano direttamente all\u2019allineamento delle IA; ci sono posizioni di questo tipo presso Anthropic, DeepMind, Miri e OpenAIF.</li><li>In altri casi possono lavorare a sistemi di intelligenza artificiale estesi e potenti (ad esempio <a href=\"https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii\">AlphaStar</a>&nbsp;e <a href=\"https://en.wikipedia.org/wiki/GPT-3\">GPT3</a>) che possono poi essere analizzati e caratterizzati. Se il laboratorio per cui lavorano ha come obiettivo principale quello di ridurre i rischi legati alle IA, ed \u00e8 quindi cauto nel pubblicizzare e impiegare questi sistemi mentre investe molto nella loro analisi e uso per la ricerca sull\u2019allineamento, allora (almeno in teoria) potrebbe essere una cosa positiva per gli obiettivi lungoterministi.</li><li>Lo sviluppo di software pu\u00f2 essere utile anche per qualsiasi organizzazione che svolge analisi approfondite. Tra queste possono esserci organizzazioni che lavorano in ambito politico (<a href=\"https://twitter.com/davidshor/status/1356291911154356226\">esempio</a>) e altre che lavorano sulla biosicurezza e le contromisure in caso di pandemia (non conosco esempi per quest\u2019ultimo caso, ma con ogni probabilit\u00e0 ce ne saranno in futuro).</li><li>Lo sviluppo di software tende anche a essere redditizio, soprattutto per coloro che si uniscono presto a una startup di successo. (Si tratta anche di un potenziale background utile per chiunque voglia fondare una societ\u00e0 tecnologica). Per questo pu\u00f2 essere una buona scelta per futuri filantropi.</li></ul><p><strong>Esempi:</strong></p><p>Sia Catherine Olsson che Tom Brown hanno sviluppato software presso OpenAi, Google Brain e Anthropic.</p><p><strong>Come sviluppare questo talento:</strong></p><p>Lo sviluppo di software \u00e8 un percorso di carriera piuttosto solido. Un buon punto di partenza potrebbe essere <a href=\"https://www.appacademy.io/%23p-home\">App Academy</a>&nbsp;o <a href=\"https://lambdaschool.com/\">Lambda School</a>. (Per ruoli presso DeepMind e OpenAI in particolare probabilmente \u00e8 necessario essere tra i migliori del mondo in questi programmi). Pressoch\u00e9 qualsiasi lavoro come sviluppatore software \u00e8 un buon modo per sviluppare questo talento. Pi\u00f9 sono in gamba i propri colleghi, meglio \u00e8.</p><p><strong>Monitorare i progressi</strong></p><p>Vedi la sezione \u201cprogressi\u201d di Mettere in piedi, promuovere e dirigere un\u2019organizzazione.</p><p>&nbsp;</p><h2><strong>Talenti nella sicurezza delle informazioni</strong></h2><p>(In questo caso non c\u2019\u00e8 molta differenza tra \u201ctalento\u201d e \u201cpercorso\u201d. Lo stesso vale anche per la prossima sezione).</p><p><strong>Il profilo in breve:</strong>&nbsp;mantenere le informazioni al sicuro impedendo accessi (o modifiche) non autorizzati. Tra le possibilit\u00e0:</p><ul><li>Ricerca su problemi teoretici e all\u2019avanguardia nell\u2019ambito della sicurezza delle informazioni \u2013 quali attacchi potrebbero avvenire, in che modo ci si potrebbe difendere, ecc.</li><li>Lavorare per una compagnia aiutandola a (a) definire gli obiettivi e le necessit\u00e0 nell\u2019ambito di sicurezza; (b) individuare soluzioni pratiche; (c) sviluppare e sostenere queste soluzioni cos\u00ec che le informazioni rimangano al sicuro all\u2019atto pratico.</li></ul><p><a href=\"https://forum.effectivealtruism.org/posts/ZJiCfwTy5dC4CoxqA/information-security-careers-for-gcr-reduction\">In questo post Claire Zabel e Luke Muehlhauser</a>&nbsp;affermano: \u201cLe competenze nel campo della sicurezza delle informazioni potrebbero rivelarsi essenziali per affrontare i rischi catastrofici derivanti dalle IA e dalla biosicurezza [...] Pi\u00f9 in generale, competenze in questo campo potrebbero essere utili per coloro che cercano di ridurre [i rischi di catastrofe globale], perch\u00e9 a volte questo lavoro richiede di avere a che fare con informazioni che, se usate nel modo sbagliato, potrebbero causare danni [...] \u00c8 probabile che nei prossimi 10 anni ci saranno decine di ruoli nella sicurezza delle informazioni legati ai rischi di catastrofe globale. Alcune organizzazioni stanno gi\u00e0 cercando candidati che rispondano alle loro esigenze (e li assumerebbero gi\u00e0 adesso, se li trovassero) [...] Se le persone che si avvicinano a questo percorso non ottengono direttamente un lavoro ma sviluppano le abilit\u00e0 necessarie, potrebbero comunque ottenere una carriera molto redditizia in cui il loro set di abilit\u00e0 sarebbe molto richiesto.\"</p><p>In generale, sono d\u2019accordo con queste affermazioni.</p><p><strong>Esempi:</strong></p><p>Purtroppo, per quel che ne so, al momento non ci sono molti altruisti efficaci con carriere gi\u00e0 avviate nell\u2019ambito della sicurezza delle informazioni.</p><p><strong>Come sviluppare questo talento:</strong></p><p>Per sviluppare questo talento un buon modo \u00e8 lavorare alla sicurezza delle informazioni per qualsiasi compagnia \u2013 oppure lavorare in qualsiasi campo di ricerca sulla sicurezza delle informazioni. Se dovessi ipotizzare direi che i lavori migliori saranno quelli presso le grandi societ\u00e0 tecnologiche, per le quali la sicurezza \u00e8 fondamentale: Amazon, Apple, Microsoft, Facebook e (soprattutto) Google.</p><p><strong>Monitorare i progressi</strong></p><p>Vedi la sezione \u201cprogressi\u201d di Mettere in piedi, promuovere e dirigere un\u2019organizzazione.</p><h2><strong>Carriera accademica</strong></h2><p><strong>Il profilo in breve:</strong>&nbsp;scegliere una carriera accademica spesso significa scegliere con un certo anticipo un campo di ricerca, ottenere un dottorato, accettare ruoli di ricerca, maturare un buon numero di pubblicazioni di tutto rispetto e alla fine puntare a un ruolo come professore associato (anche se ci sono altri lavori che attingono dall\u2019ambito accademico). Si tratta di un percorso di carriera piuttosto limitato, motivo per cui non c\u2019\u00e8 molta differenza tra \u201ctalento\u201d e \u201cpercorso\u201d secondo le definizioni date all\u2019inizio dell\u2019articolo.</p><p>Ci sono diversi modi in cui una carriera accademica potrebbe rivelarsi utile per raggiungere obiettivi lungoterministi:</p><ul><li>Potresti svolgere un tipo di ricerca che si ricollega ai grandi temi lungoterministi. In questo caso questo talento si incrocia con quelli di \u201cricerca concettuale ed empirica su temi lungoterministi\u201d visti in precedenza.</li><li>Potresti avere l\u2019occasione di aumentare la visibilit\u00e0 di idee lungoterministe di grande importanza all\u2019interno del tuo campo di ricerca. Una sorta di ruolo da \u201ccomunicatore\u201d specializzato. (Gli obiettivi del <a href=\"https://globalprioritiesinstitute.org/\">Global Priorities Institute</a>&nbsp;sono spesso una combinazione di questo punto e di quello precedente).</li><li>Potresti avere l\u2019opportunit\u00e0 di lavorare come consulente esperto per i policymaker e il settore pubblico.</li><li>Potresti anche avere l\u2019opportunit\u00e0 di introdurre i tuoi studenti a idee lungoterministe di grande importanza, anche attraverso corsi sull\u2019altruismo efficace e il lungoterminismo (<a href=\"https://www.openphilanthropy.org/giving/grants/university-of-michigan-support-for-david-manley\">esempio</a>). (A margine: penso che se si vuole introdurre gli studenti alle idee dell\u2019altruismo efficace e del lungoterminismo, anche un ruolo di insegnante nella scuola pubblica potrebbe avere un buon impatto).</li><li>In aggiunta, alcuni ambiti accademici danno accesso a ruoli non accademici ma con un grande impatto potenziale. Quello delle IA \u00e8 forse l\u2019esempio migliore: studiare le IA e ottenere ottimi risultati all\u2019inizio della propria carriera (perfino prima di ottenere un dottorato) pu\u00f2 essere un buon modo per ottenere un ruolo di \u201cscienziato\u201d presso un laboratorio di IA privato. L\u2019economia \u00e8 un altro campo che pu\u00f2 offrire buone opportunit\u00e0 non accademiche, incluse alcune nell\u2019ambito del policymaking.</li></ul><p>Ci sono molti ambiti accademici che possono dare questo tipo di opportunit\u00e0. Tra quelli pi\u00f9 rilevanti per il lungoterminismo ci sono:</p><ul><li>IA</li><li>Biologia, epidemiologia, sanit\u00e0 pubblica e altri ambiti connessi al rischio biologico</li><li>Scienza del clima</li><li>Economia e filosofia, i due ambiti prioritari del <a href=\"https://globalprioritiesinstitute.org/\">Global Priorities Institute</a></li></ul><p><strong>Esempi:</strong></p><p>Hilary Greaves del Global Priorities Institute; Stuart Russell del Center for Human-Compatible AI; <a href=\"https://www.media.mit.edu/people/esvelt/overview/\">Kevin Esvelt</a>.</p><p><strong>Come sviluppare questo talento:</strong></p><p>La carriera accademica prevede un percorso ben definito. Chi lo intraprende di solito ha buone probabilit\u00e0 di ricevere consigli da altre persone in questo ambito su come fare carriera e su come capire se si stanno facendo progressi.</p><p>In generale, mi sento di consigliare di dare molta importanza al successo secondo gli standard tradizionali, sia quando si sceglie un campo di ricerca che quando si scelgono temi e progetti, piuttosto che cercare di ottimizzare la propria ricerca per produrre lavori direttamente connessi a obiettivi lungoterministi.</p><p><strong>Monitorare i progressi</strong></p><p>La mia risposta \u00e8 grossomodo la stessa che ho dato per i talenti politici e burocratici.</p><p><br>&nbsp;</p><h2><strong>Altri talenti</strong></h2><p>Ci sono quasi sicuramente altri talenti che potrebbero contribuire direttamente a obiettivi lungoterministi ma che semplicemente non ho pensato di elencare in questo articolo.</p><h2><strong>Talenti ibridi</strong></h2><p>A volte alcune persone sono in grado di lavorare in ruoli preclusi ad altri perch\u00e9 possiedono due (o pi\u00f9) talenti tra quelli elencati. Ad esempio, \u00e8 possibile avere uno <a href=\"https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice%23Software_engineering_aptitude\">sviluppatore software</a>&nbsp;in gamba che sia <i>anche </i>un buon <a href=\"https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice%23_Organization_building__running__and_boosting__aptitudes_1_\">project manager o manager del personale</a>, cosa che gli consente di contribuire come manager di sviluppo software in misura maggiore rispetto a qualcuno che \u00e8 semplicemente uno sviluppatore software o un manager non specialistico. All\u2019interno della comunit\u00e0 dell\u2019altruismo efficace, la \u201c<a href=\"https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice%23_Conceptual_and_empirical_research_on_core_longtermist_topics__aptitudes\">ricerca concettuale ed empirica\u201d </a>spesso va a braccetto con il talento da \u201c<a href=\"https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/longtermist-career-choice%23_Communicator__aptitudes\">comunicatore</a>\u201d (vedi ad esempio Nick Bostrom e il suo libro <i>Superintelligenza</i>).</p><p>Penso che essere pronti a sviluppare talenti ibridi sia una buona cosa, ma \u00e8 bene tenere a mente che la specializzazione \u00e8 uno strumento potente. Per sviluppare talenti ibridi l\u2019ideale \u00e8 cominciare con un talento, per poi individuare un\u2019occasione per svilupparne un altro complementare che migliori le tue opportunit\u00e0 di carriera. Tendenzialmente, eviterei di sviluppare pi\u00f9 talenti allo stesso tempo all\u2019inizio della propria carriera.</p><p><br>&nbsp;</p><h2><strong>Al di l\u00e0 dei talenti: sostenere il lungoterminismo in generale</strong></h2><p>Sono convinto che ognuno dei talenti che abbiamo visto possa dare l\u2019opportunit\u00e0 di lavorare direttamente a obiettivi lungoterministi, che sia per un laboratorio di IA, un\u2019organizzazione altruista efficace, un\u2019istituzione politica o altro. Penso anche che con ogni probabilit\u00e0 ci sono molti altri talenti che potrebbero rivelarsi utili.</p><p>Tuttavia, ci sono persone che potrebbero essere pi\u00f9 adatte a sviluppare un talento che non dia queste opportunit\u00e0. Altre ancora potrebbero sviluppare uno di questi talenti e non avere mai queste opportunit\u00e0.</p><p>Penso che queste persone abbiano comunque l\u2019opportunit\u00e0 di contribuire a obiettivi lungoterministi in modi che vanno al di l\u00e0 (ma che includono) del \u201cguadagnare per donare\u201d. Modi che <strong>sostengono il lungoterminismo in generale. </strong>In questa categoria a me viene in mente:</p><ul><li><strong>Diffondere le idee lungoterministe nelle proprie reti di contatti.</strong>&nbsp;Non intendo dire che bisognerebbe promuovere il lungoterminismo in maniera aggressiva o infastidendo i nostri amici, ma penso che per chi ha buone connessioni e gode di rispetto ci siano diverse occasioni per portare altri ad avvicinarsi a idee importanti che normalmente non avrebbero considerato. (Avere successo in <i>qualsiasi tipo </i>di carriera tendenzialmente porta a fare rete con altre persone di successo). Chi \u00e8 bravo in questo potrebbe anche diventare una specie di esperto nel discutere temi lungoterministi con una certa categoria di persone.</li><li><strong>Partecipare (e/o creare e gestire) spazi lungoterministi e di altruismo efficace</strong>&nbsp;come incontri locali, EA Global, cene, feste, conferenze, ecc. La qualit\u00e0 di questi eventi pu\u00f2 beneficiare sia della tua presenza che del tuo feedback (vale a dire notando le cose che non vanno e facendolo presente). Penso che non bisognerebbe partecipare a questi eventi solo per un proprio tornaconto: si pu\u00f2 fare del bene migliorandone la qualit\u00e0, in modo che i nuovi arrivati che le frequentano abbiano subito un\u2019esperienza positiva e incontrino persone che rispettano e da cui possono imparare.</li><li><strong>Diventare un esempio. </strong>Puoi puntare a essere un lungoterminista attivo, impegnato ed esperto nel tuo campo e allo stesso tempo una persona che i non-lungoterministi rispettano e sono contenti di conoscere. Penso che le figure di riferimento siano importanti e abbiano un grande potenziale d\u2019impatto. Potresti fare davvero la differenza in qualsiasi comunit\u00e0 tu ti trovi.</li><li><strong>Farsi sentire \u201ccome cliente\u201d&nbsp;delle comunit\u00e0 del lungoterminismo e dell\u2019altruismo efficace.</strong>&nbsp;Faccio sempre attenzione quando le persone dicono cose tipo, \u201cMi sembra di non essere il benvenuto in questa comunit\u00e0 perch\u00e9 ____\u201d o \u201cNon riesco a interagire con i lungoterministi perch\u00e9 ___\u201d oppure \u201cPer me eventi come ___ sono preziosi e vorrei che ce ne fossero di pi\u00f9\". A seconda del proprio punto di vista, ognuno potrebbe notare cose diverse e aiutare la comunit\u00e0 lungoterminista a crescere per attirare pi\u00f9 persone come loro in futuro.</li><li><strong>Crescere dei figli. </strong>Mi sento un po\u2019 a disagio a citare questo esempio, ma vi assicuro che il mio intento non \u00e8 quello di dire a nessuno che \u201cdovrebbe\u201d fare dei figli. Quello che penso, per\u00f2, \u00e8 che crescere dei figli \u00e8 una cosa che richiede tantissimo impegno e che con ogni probabilit\u00e0 rende migliori le aspettative sul futuro. Per questo motivo mi sarei sentito a disagio se <i>non </i>l\u2019avessi citato. Allo stato attuale, mi sembra che i lungoterministi che hanno bambini rendono anche pi\u00f9 urgente la necessit\u00e0 che la comunit\u00e0 lungoterminista diventi pi\u00f9 adatta per genitori e bambini, una buona cosa (e di non poca importanza) per il lungoterminismo e i lungoterministi.</li><li><strong>Donare. </strong>L\u2019ho inserito quasi al fondo dell\u2019elenco perch\u00e9 penso che \u201cguadagnare per donare\u201d sia gi\u00e0 stato enfatizzato a sufficienza rispetto agli altri punti. Ovviamente penso che ci sia la possibilit\u00e0 di avere molto impatto con questa attivit\u00e0.</li><li>Al momento non c\u2019\u00e8 nessun luogo scalabile e \u201covvio\u201d, simile alle non-profit consigliate da GiveWell, per i lungoterministi. Ma se non hai urgenza di fare delle donazioni, penso che la cosa migliore sia semplicemente risparmiare o investire, preferibilmente seguendo metodi di investimento che meglio rispecchiano i valori lungoterministi (ad esempio assumersi un adeguato livello di rischio per il denaro che si intende donare su un periodo di tempo molto esteso e sfruttare gli strumenti filantropici a disposizione per ridurre le tasse sul denaro che si intende donare \u2013 spero che in futuro verranno scritte delle guide per questo genere di cose). Se questo sia meglio che donare immediatamente \u00e8 oggetto di dibattito, ma penso che sia perlomeno da tenere in considerazione.</li><li>Un\u2019altra opzione promettente potrebbero essere le <a href=\"https://app.effectivealtruism.org/lotteries\">lotterie di donatori</a>.</li><li>Entrambi questi metodi ti risparmiano di dover pensare a ottimizzare le tue donazioni su base annuale. \u00c8 una buona cosa, perch\u00e9 penso che potresti investire meglio tempo ed energie per puntare al successo come professionista e come persona, contribuendo al successo di tutto il resto.</li></ul><p>&nbsp;</p><ul><li><strong>Essere pronto a lavorare direttamente a tematiche lungoterministe se ce ne fosse bisogno o se ne presentasse l\u2019occasione. </strong>\u00c8 difficile dire cosa succeder\u00e0 in futuro. Molte persone che adesso non vedono nessuno spiraglio per una carriera lungoterminista potrebbero avere una grande occasione pi\u00f9 avanti.</li><li>Cambiare lavoro a carriera gi\u00e0 avviata pu\u00f2 essere difficile: potrebbe esserci una drastica riduzione dello stipendio o di altri aspetti come status sociale, riconoscimenti, apprezzamenti e comodit\u00e0. Per come la vedo io, chiunque sia disposto davvero a cambiare lavoro molto avanti nella sua carriera ha gi\u00e0 raggiunto un grande risultato, anche solo per questo. Se dovessi ipotizzare, direi che hai pi\u00f9 possibilit\u00e0 di farcela se possiedi grandi \u201criserve\u201d in termini di salute fisica e mentale (nonch\u00e9 economica).</li><li>Dal mio punto di vista, chiunque stia avendo successo nel suo campo e stia sviluppando talenti che pochi riescono a eguagliare, e al tempo stesso \u00e8 davvero pronto a cambiare lavoro se si presentasse un\u2019occasione migliore, ha gi\u00e0 in un certo senso ottenuto un grande impatto lungoterminista previsto (sul lungo periodo), semplicemente attraverso il lavoro diretto. Penso che questo impatto previsto sar\u00e0 spesso pi\u00f9 alto dell\u2019impatto previsto di chi in teoria ha una carriera lungoterminista di successo ora ma non sta per forza avendo prestazioni eccellenti, flessibili o sostenibili sul lungo periodo.</li></ul><p>Mi viene da pensare che chiunque stia avendo successo in molti di questi aspetti - a prescindere da quale sia il suo lavoro - sta avendo un grande impatto lungoterminista previsto. Penso che avere successo ed essere soddisfatti del proprio lavoro probabilmente aiuta in tutti questi ambiti.</p><p>&nbsp;</p><p>&nbsp;</p><h2><strong>Come scegliere un talento</strong></h2><p>Immagino che qualcuno vorr\u00e0 avere la mia opinione su quale di questi talenti ha il \u201cmassimo impatto\u201d possibile.</p><p>La mia opinione \u00e8 che la variabilit\u00e0 all\u2019interno di questi talenti con ogni probabilit\u00e0 rende irrilevante la variabilit\u00e0 <i>tra </i>i talenti. Se sei il migliore in uno qualsiasi di questi talenti, \u00e8 probabile che avrai un enorme talento previsto; chiunque abbia successo e ottime prestazioni probabilmente sta avendo un impatto previsto molto grande; chi invece riesce a malapena a mantenere il proprio lavoro probabilmente ha meno impatto delle prime due categorie, anche se magari ha un ruolo ad alto impatto.</p><p>Credo anche che per sviluppare con successo un talento - al punto da poter essere considerato un \u201cprofessionista richiesto\u201d - sia di solito necessario attenercisi scrupolosamente e investirci molto tempo per molto tempo. Per questo penso che sia pi\u00f9 probabile che le persone abbiano successo quando sono appagate dal proprio lavoro e si trovano in un ambiente di lavoro stimolante, ed \u00e8 per questo che dovrebbero darci molta importanza quando decidono quale tipo di talento intendono sviluppare. (In particolare all\u2019inizio della loro carriera).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhliecqfaswi\"><sup><a href=\"#fnhliecqfaswi\">[6]</a></sup></span></p><p>Tenendo questo a mente, vorrei suggerire un paio di regole generali che penso valga la pena tenere in considerazione:</p><ol><li>\u201cRiduci N, dove N \u00e8 il numero di persone pi\u00f9 richieste di te per questo talento.\" Detto in modo meno formale, \u201cFai quello in cui avrai successo\u201d.<br>&nbsp;</li><li>\u201cPrendi sul serio i tuoi sentimenti e i tuoi presentimenti\u201d. Molte persone sapranno istintivamente quali tipi di talenti provare; penso che in questo caso seguire l\u2019istinto sia una buona idea che non dovrebbe essere soffocata da valutazioni di impatto. (Il che non significa che penso che questi presentimenti siano di solito \u201ccorretti\u201d. Penso invece che la maggior parte delle carriere di successo richiede parecchia sperimentazione, imparare che alcuni lavori non sono come ce li si immagina ed eventualmente cambiare rotta. Penso che sia pi\u00f9 facile imparare quando si d\u00e0 retta alla propria curiosit\u00e0 e al proprio entusiasmo; ovviamente questo non vuol dire che curiosit\u00e0 ed entusiasmo portano direttamente alla migliore destinazione possibile).<br>&nbsp;</li></ol><p>Credo per\u00f2 che si debbano fare <i>alcune </i>distinzioni per quel che riguarda l\u2019impatto pi\u00f9 alto a un certo livello di successo in un talento piuttosto che un altro. Ma qualsiasi stima io possa fare al riguardo sarebbe molto azzardata e influenzata dal mio punto di vista attuale sulla prioritizzazione delle cause, oltre che dallo stato in cui versa attualmente il mondo (e che potrebbe cambiare con rapidit\u00e0). Penso anche che ci sia la possibilit\u00e0 di avere un enorme impatto lungoterminista previsto con ognuno dei talenti che ho elencato - o anche solo sostenendo il lungoterminismo a prescindere dai talenti.</p><p>&nbsp;</p><h2><strong>Conclusione</strong></h2><p>In questo articolo ho condiviso un certo numero di mie impressioni su come sviluppare un talento e come capire se si stanno facendo progressi, oltre ad alcune impressioni su quali regole generali possano essere d\u2019aiuto per avere successo e produrre un impatto.</p><p>L\u2019ho fatto perch\u00e9 penso che mi sia stato d\u2019aiuto nel promuovere un modello di riferimento o attitudine generale utile per la scelta della propria carriera, modello che penso valga la pena tenere in considerazione e che pu\u00f2 essere complementare ad altri modelli utilizzati dai lungoterministi.</p><p>Mi sento tuttavia un po\u2019 a disagio nel dare consigli lavorativi a chiunque, anche a persone che conosco bene, perch\u00e9 la scelta di una carriera \u00e8 una questione personale ed \u00e8 molto facile, per chiunque dia questi consigli, ignorare aspetti importanti della personalit\u00e0 di qualcuno, o della sua situazione, ecc. Sono ancora pi\u00f9 a disagio nel pubblicare questi consigli su internet, dove possono essere letti da molte persone in molte situazioni di cui so molto poco.</p><p>Per cui voglio concludere consigliando a chi mi legge di non \u201caccettare consigli\u201d, nel senso di non prendere decisioni completamente diverse da quelle che prenderebbero solo perch\u00e9 hanno interpretato in un certo modo quello che una data persona pensa dovrebbero fare. La mia speranza \u00e8 che questo articolo sia utile nell\u2019ispirare, dare vita a dibattiti e sollevi punti interessanti che le persone potranno valutare e giudicare secondo il proprio pensiero. Spero che non venga utilizzato come un manuale di istruzioni o come guida per una o pi\u00f9 scelte specifiche.</p><p>Voglio anche lasciare un link a<a href=\"https://80000hours.org/2019/10/anonymous-advice-careers/\">&nbsp;questa pagina</a>, che contiene un buon numero di \u201cconsigli anti-consiglio\u201d, incluse alcune mie citazioni<a href=\"https://80000hours.org/2019/10/anonymous-advice-careers/%23dont-listen-too-much-to-anyones-advice\">&nbsp;qui</a>&nbsp;(\u201cUna carriera lavorativa \u00e8 qualcosa di personale\u201d),<a href=\"https://80000hours.org/2019/10/anonymous-advice-careers/%23when-youre-great-at-your-job-no-ones-advice-is-that-useful\">&nbsp;qui</a>&nbsp;(\u201cQuando eccelli nel tuo lavoro, non ti serve il consiglio di nessuno\u201d) e<a href=\"https://80000hours.org/2019/10/anonymous-advice-careers/%23a-career-is-such-a-personal-thing\">&nbsp;qui</a>&nbsp;(\u201cNon dare troppo peso ai consigli di nessuno\u201d).</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn83xu4nqdx57\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref83xu4nqdx57\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Parte dei contenuti di questa sezione si sovrappone a quelli <a href=\"https://80000hours.org/key-ideas/%23work-in-effective-altruism-organisations\"><u>di 80,000 Hours sul lavorare per organizzazioni altruiste efficaci</u></a>, soprattutto per quel che riguarda il prepararsi per lavorare presso una di queste organizzazioni. Tuttavia, la mia sezione non include ruoli presso queste organizzazioni che si basino sulla ricerca o che siano altrimenti \u201cparticolari\u201d; si tratta di lavori che si basano su competenze \u201cdi solito utili\u201d che potrebbero essere impiegate anche presso molte organizzazioni non legate all\u2019altruismo efficace (alcune di esse, bench\u00e9 non dichiaratamente legate all\u2019altruismo efficace, offrono comunque la possibilit\u00e0 di avere un impatto lungoterminista). In poche parole, questa sezione adotta il punto di vista dello \u201csviluppare talenti utili ad aiutare molte organizzazioni, incluse quelle non AE che svolgono lavori importanti\u201d, piuttosto che quello del \u201cunirsi a un\u2019organizzazione non legata all\u2019altruismo efficace per maturare competenze per un\u2019organizzazione AE\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6oyxbqo2r33\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6oyxbqo2r33\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Per questo genere di indagini mi aspetto una sorta di \u201ceffetto valanga\u201d, dove da una domanda semplice e diretta (\u201cle probabilit\u00e0 di un inverno nucleare in questo secolo\u201d) si passa a una serie di domande secondarie che ne sono in realt\u00e0 alla base (\u201cQuali sono in generale le probabilit\u00e0 di un guerra nucleare? Quanto particolato viene rilasciato nell\u2019atmosfera in seguito a un\u2019esplosione atomica? Ci sono testate nucleari pi\u00f9 grandi che potrebbero essere utilizzate? E quanto sono grandi?\u201d). Dal momento che \u00e8 necessario gestire in maniera pragmatica e dare la giusta importanza a ognuna di queste domande secondarie, pu\u00f2 essere molto difficile rimanere concentrati sulla domanda generale. D\u2019altro canto, concedersi di indagare temi sempre pi\u00f9 ristretti potrebbe rendere pi\u00f9 semplice gestire il lavoro.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnv8pgdevzzn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefv8pgdevzzn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Questo tenendo in considerazione che pu\u00f2 essere molto difficile investire molto tempo in questo tipo di lavoro. Penso che anche le persone adatte potrebbero incontrare diverse difficolt\u00e0 nel rimanere concentrate, oltre a investire meno tempo di quanto intendessero fare. Ci\u00f2 nonostante, mi aspetto che queste persone otterranno pi\u00f9 o meno gli stessi risultati nei tempi che ho discusso prima.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnf3x0do6q6ps\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreff3x0do6q6ps\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Questa sezione \u00e8 simile alla <a href=\"https://80000hours.org/key-ideas/%23nonprofit-entrepreneurship\">discussione di 80,000 Hours sugli \u201cimprenditori senza scopo di lucro\u201d.</a>&nbsp;La differenza principale \u00e8 che qui punto l\u2019accento sul fatto che un\u2019esperienza imprenditoriale presso un\u2019organizzazione non AE (inclusa una a scopo di lucro) pu\u00f2 rivelarsi utile.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqzlbeu6bg2\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqzlbeu6bg2\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Ad esempio, \u201corganizzarsi online\": chiedere alle persone di intraprendere azioni limitate su tematiche immediate, facendo s\u00ec che siano pi\u00f9 coinvolte e attratte da tematiche pi\u00f9 ampie.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhliecqfaswi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhliecqfaswi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Vedi anche i miei commenti <a href=\"https://80000hours.org/2019/12/anon-answers-what-to-work-on/%23not-focusing-on-becoming-really-good-at-something\">qui</a>&nbsp;(sezione \u201cNot focusing on becoming really good at something\u201d \u201cNon concentrarsi sul diventare davvero bravi in qualcosa\u201d), che inizialmente avevo fatto come anonimo.</p></div></li></ol><p><br>&nbsp;</p>", "user": {"username": "EA Italy"}}, {"_id": "PRHcuvBGEJBqRSquX", "title": "Esercizio per \u201cDalla teoria alla pratica\u201d", "postedAt": "2023-01-18T11:54:56.220Z", "htmlBody": "<p>In questo esercizio l\u2019obiettivo \u00e8 pensare a come le idee appena viste possano influenzare la tua vita. Non ci aspettiamo che formuli immediatamente un programma completo. Probabilmente ti conviene prima esplorare queste idee e analizzare diverse opzioni, ma secondo noi pu\u00f2 essere utile cominciare a rifletterci, per meglio strutturare il tuo pensiero.</p><p>Prova a rispondere alle seguenti domande:</p><p><i>Sulla base di quello che hai letto nei precedenti capitoli, quali sono secondo te i problemi pi\u00f9 urgenti al mondo e perch\u00e9? (Tieni a mente che anche gli esperti hanno parecchi dubbi sull\u2019argomento!)</i></p><p><i>Quali sono 3-5 punti della questione su cui ci sono pi\u00f9 dubbi?</i></p><p><i>Come potresti informarti su quei punti nelle prossime settimane? (Ad esempio leggendo pi\u00f9 testi, parlandone con un amico, oppure scrivendo un</i>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/4WxHNBf5LeM9gQneT/you-should-write-on-the-ea-forum\"><i>post sul forum</i></a>&nbsp;<i>per avere un feedback su questi dubbi).</i></p><p><i>Quali&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/my-current-impressions-on-career-choice-for-longtermists\"><i>talenti</i></a>&nbsp;<i>ti interessa di pi\u00f9 esplorare o utilizzare in futuro? Potrebbe esserti utile pensare a cosa sei bravo, quali attivit\u00e0 ti riempiono di energia e quali capacit\u00e0 potrebbero essere particolarmente utili per affrontare i problemi che hai elencato.</i></p><p><i>In che modo potresti mettere alla prova questi talenti nelle prossime settimane?</i></p><p><i>Mentre stai risolvendo queste incertezze, c\u2019\u00e8 qualcosa che vorresti fare nel frattempo per migliorare il mondo? (Ad esempio fare una donazione, oppure qualcosa che ti aiuti a ricordare di applicare queste idee nella tua vita quotidiana (iscriverti a una newsletter, promettere di discutere della tua carriera lavorativa con un amico, oppure darti il compito di candidarti per lavori/internship ad alto impatto)).</i></p>", "user": {"username": "EA Italy"}}, {"_id": "45gHFXTiex6u6JiC2", "title": "Hai pi\u00f9 di un obiettivo, e non c\u2019\u00e8 nulla di male", "postedAt": "2023-01-18T11:53:14.731Z", "htmlBody": "<p><i>This is an Italian translation of </i><a href=\"https://forum.effectivealtruism.org/posts/zu28unKfTHoxRWpGn/you-have-more-than-one-goal-and-that-s-fine\"><i><strong>You have more than one goal, and that's fine</strong></i></a></p><p>Quando le persone partecipano a un evento sull\u2019altruismo efficace per la prima volta, le conversazioni spesso sono incentrate sui progetti a cui stanno lavorando o sulle organizzazioni a cui donano. Spesso si percepisce una certa tensione, la sensazione che tutto quello che fanno verr\u00e0 esaminato scrupolosamente alla luce del rapporto costi-efficacia. Sar\u00f2 sincera, non \u00e8 un timore del tutto infondato, perch\u00e9 molti giovani e meno giovani all\u2019interno dell\u2019Altruismo Efficace hanno questa convinzione che ogni aspetto della vita debba essere regolato da un rapporto di costi-efficacia. Ci sono passata anch\u2019io.</p><p>L\u2019analisi di costi-efficacia \u00e8 uno strumento molto utile, che vorrei venisse adoperato da individui e istituzioni per risolvere i problemi. Ma come qualsiasi altro strumento, non pu\u00f2 essere applicato a ogni aspetto della vita. Non tutto quello che facciamo finisce nella categoria \u201cefficacia\u201d. Non riesco nemmeno a immaginare come potrebbe.</p><p>Io ho moltissimi obiettivi. Voglio migliorare il mondo, voglio passare del tempo con i miei figli, voglio essere una buona moglie, voglio sentirmi vicina ai miei amici e alla mia comunit\u00e0. Sono tutti ottimi obiettivi, ma non sono identici. Ho un programma approssimativo per dividere tempo e denaro tra tutti questi obiettivi: la domenica mattina cucino i pancake con i miei figli. Luned\u00ec mattina lavoro. Non avrebbe senso mischiare queste due attivit\u00e0 e passare del tempo con i miei figli in modo da portarmi avanti con il lavoro, oppure lavorare in un modo che faccia divertire i miei figli.</p><p>Se dono alla raccolta fondi di una mia amica per un suo zio malato sto perseguendo un obiettivo, ma \u00e8 l\u2019obiettivo del \u201csostenere i miei amici e la nostra amicizia\u201d, non quello di \u201crendere il mondo il posto migliore possibile\u201d. Quando prendo una decisione, funziona meglio se ho ben presente quale obiettivo sto perseguendo. Non devo rimproverarmi per non aver usato questi soldi per ottimizzare il mondo, perch\u00e9 non \u00e8 mai stato l\u2019obiettivo di quella donazione. Quei soldi vengono dal mio budget dedicato alle \u201csoddisfazioni personali\u201d, assieme ai soldi che uso per cose come prendermi un caff\u00e8 con gli amici.</p><p>Poi ho anche un budget che uso per donare nel modo pi\u00f9 efficace possibile. Quando decido come usare quel denaro, allora s\u00ec che applico l\u2019analisi di costi-efficacia e cerco di fare pi\u00f9 progressi possibili per risolvere i problemi del mondo. Questo include studiare le ricerche alla base di diversi interventi e scegliere quello che penso aiuter\u00e0 di pi\u00f9 l\u2019umanit\u00e0 nella lotta contro malattie, sofferenze inutili e la morte. Di solito le cause migliori da sostenere sono quelle con cui non avevo alcun collegamento e che non si inseriscono facilmente nella mia vita personale. E va bene cos\u00ec, perch\u00e9 non mi interessa renderle parte di me. Posso poi trovarci un significato personale, ma non \u00e8 quello che mi spinge a prendere una certa decisione.</p><p>Quando prendi una decisione, chiarisci a te stesso quali sono gli obiettivi che stai seguendo. Non devi giustificare perch\u00e9 ritieni che quella sia la scelta migliore per aiutare il mondo se non \u00e8 quello il tuo obiettivo. \u00c8 del tutto lecito sostenere il collettivo artistico della tua citt\u00e0 perch\u00e9 il loro lavoro ti rende felice, perch\u00e9 vuoi partecipare alla vita della tua comunit\u00e0 o perch\u00e9 in passato ti hanno aiutato e vuoi ricambiare il favore. Se poi hai anche come obiettivo quello di migliorare il mondo, decidi quanto tempo e denaro vuoi dedicare a quello e usa quelle risorse nel modo pi\u00f9 efficace possibile.</p>", "user": {"username": "EA Italy"}}, {"_id": "wRxzTHLe7rrwYY6Jg", "title": "Giving What We Can (Esplora il sito per 5 minuti)", "postedAt": "2023-01-18T11:51:51.800Z", "htmlBody": "", "user": {"username": "EA Italy"}}, {"_id": "vsDjfoaXqqwgTid29", "title": "GiveWell (Esplora il sito per 5 minuti)", "postedAt": "2023-01-18T11:50:57.161Z", "htmlBody": "", "user": {"username": "EA Italy"}}, {"_id": "bZ7rx5K29jhcEeauX", "title": "Riassunto delle idee centrali di 80,000 Hours", "postedAt": "2023-01-18T11:44:38.291Z", "htmlBody": "<p><i>This is an Italian translation of a previous version of </i><a href=\"https://forum.effectivealtruism.org/posts/JLbF2E3d5jJRvXRB6/summary-of-80-000-hours-key-ideas\"><i><strong>Summary of 80,000 Hours\u2019 key ideas</strong></i></a></p><p><strong>Riassunto del riassunto:</strong> Diventa bravo in qualcosa che ti permetta di contribuire in maniera efficace a risolvere i problemi trascurati del mondo. Alcuni modi per avere un impatto positivo nel corso della propria carriera:</p><ol><li><strong>Aiuta a risolvere un problema pi\u00f9 urgente.</strong> Molti problemi globali meriterebbero pi\u00f9 attenzione, ma come individui dovremmo cercare di individuare le carenze negli sforzi gi\u00e0 esistenti. Per fare ci\u00f2 possiamo mettere a confronto i problemi valutandoli in termini di portata, trascuratezza e trattabilit\u00e0.&nbsp;<a href=\"https://80000hours.org/articles/your-choice-of-problem-is-crucial/\"><u>Si \u00e8 scoperto che</u></a> l\u2019attenzione che ricevono alcuni problemi \u00e8<i> centinaia</i> di volte minore rispetto alla loro grandezza o fattibilit\u00e0 percepita. Nello specifico, la nostra generazione potrebbe assistere all\u2019avvento di tecnologie trasformative, che potrebbero portare a rischi esistenziali e fare del periodo che stiamo vivendo un momento storico fondamentale. Eppure le nostre istituzioni non stanno facendo granch\u00e9 per risolvere questi problemi. Abbiamo stilato un&nbsp;<a href=\"http://80000hours.org/problem-profiles/\"><u>elenco di problemi globali</u></a> che secondo noi dovrebbero ricevere pi\u00f9 attenzione al momento.</li><li><strong>Trova una soluzione pi\u00f9 efficace.</strong> Anche se molti interventi sociali, quando esaminati con attenzione, non sono molto efficaci, altri&nbsp;<a href=\"https://80000hours.org/articles/solutions/\"><u>hanno un\u2019enorme efficacia</u></a>. Questo significa che se trovi una soluzione pi\u00f9 efficace per il problema che hai scelto, i tuoi progressi annuali potrebbero aumentare di 10 o 100 volte. Per individuare queste soluzioni, consigliamo un \u201capproccio basato sui successi\u201d. Consiste nel trovare regole generali che aumentano le probabilit\u00e0 che una data soluzione sia la pi\u00f9 efficace in quel campo, anche se c\u2019\u00e8 anche una buona probabilit\u00e0 che quella soluzione non funzioni. Spesso questo si traduce nel lavorare nella ricerca, nel cambiare le politiche attuali o nella creazione di un movimento.</li><li><strong>Trova il percorso con pi\u00f9 potere operativo [</strong><a href=\"https://80000hours.org/articles/leverage/\"><strong>leverage</strong></a><strong>].</strong> In questo caso con \u201cpotere operativo\u201d intendiamo tutte quelle risorse (ad esempio denaro, attenzione, abilit\u00e0) che \u00e8 possibile impiegare per arrivare a una soluzione. Per avere maggiore potere operativo nei problemi pi\u00f9 urgenti, spesso consigliamo lavori in ambito governativo o amministrativo; carriere che permettano di mobilitare altre persone (ad esempio i mass media); attivit\u00e0 che aiutino persone e organizzazioni ad avere pi\u00f9 influenza; oppure usare le proprie capacit\u00e0 per contribuire in modo indiretto, tramite donazioni o lavoro di gruppo. La maggior parte delle persone raggiunge il picco di produttivit\u00e0 tra i 40 e i 60 anni, motivo per cui consigliamo vivamente di investire nelle proprie abilit\u00e0, connessioni sociali, reputazione, ecc., per avere pi\u00f9 influenza in futuro. Consulta il nostro elenco di&nbsp;<a href=\"https://80000hours.org/career-reviews/\"><u>carriere promettenti</u></a> per maggiori informazioni.</li><li><strong>Trova un lavoro pi\u00f9 adatto a te.&nbsp;</strong>Le persone con i risultati pi\u00f9 proficui in un determinato campo spesso sono molto pi\u00f9 produttive della media. Non solo, in quasi ogni campo raggiungere l\u2019eccellenza porta pi\u00f9 connessioni, risorse e reputazione, e di conseguenza pi\u00f9 influenza. Per questo una volta che hai individuato una serie di lavori promettenti, scegli in base a quanto ti sembrano appropriati per te.</li></ol><p><strong>Strategia di carriera:&nbsp;</strong>La carriera con il massimo impatto \u00e8 quella valutata come migliore sulla base di questi quattro fattori. Spesso \u00e8 possibile trovare un percorso 10 volte migliore secondo uno (o pi\u00f9 di uno) di questi criteri che sia ugualmente gratificante.<br>Ma in che modo si pu\u00f2 davvero trovare il percorso migliore? Ragionando come uno scienziato: formulando le ipotesi migliori sulle carriere pi\u00f9 promettenti sul lungo periodo, individuando fattori di incertezza importanti e aggiornando le proprie stime ogni 1-3 anni. E, col tempo, concentrandosi in particolare su queste tre fasi (sovrapponibili):</p><ol><li><strong>Esplorazione:</strong> scopri e prova percorsi di carriera promettenti sul lungo periodo finch\u00e9 non ti senti pronto a intraprenderne uno per qualche anno. Anche se \u00e8 difficile prevedere quale sar\u00e0 quello pi\u00f9 adatto a te, alcuni percorsi hanno un impatto molto maggiore di altri e vale la pena esplorarli per assicurarsi di non perdere una grande occasione. (Di solito questa fase \u00e8 consigliata a persone tra i 18 e i 24 anni).</li><li><strong>Investimento:</strong> scommetti su un percorso a lungo termine costruendo un capitale di carriera che ti permetter\u00e0 di fare grandi progressi in quel campo. Di solito \u00e8 meglio puntare un po\u2019 pi\u00f9 in alto piuttosto che un po\u2019 pi\u00f9 in basso, ma assicurati di avere un piano di riserva che ti consenta di intraprendere un\u2019altra carriera in caso questo percorso non funzionasse. (25-35 anni).</li><li><strong>Impiego:</strong> usa il capitale di carriera che hai costruito per sostenere le soluzioni pi\u00f9 efficaci ai problemi pi\u00f9 urgenti del momento. (Dai 36 anni in su).</li></ol><p>E mentre fai tutto questo, cerca altre persone. Con una comunit\u00e0 di persone fantastiche avrai accesso a centinaia di connessioni in un istante. Non solo, due persone che lavorano assieme possono&nbsp;<a href=\"https://80000hours.org/articles/coordination/\"><u>avere un impatto pi\u00f9 che doppio</u></a> rispetto a quello di una singola persona. Abbiamo dato una mano a creare la<a href=\"https://80000hours.org/community/\"> comunit\u00e0 dell\u2019altruismo efficace</a> in modo che tu (e noi stessi!) possa trovare persone affini.</p><p>Incentrare la tua carriera sull\u2019affrontare i problemi globali pi\u00f9 urgenti non \u00e8 alla portata di tutti e di sicuro non \u00e8 facile. Se non hai la possibilit\u00e0 di cambiare lavoro al momento,<a href=\"https://80000hours.org/career-guide/making-a-difference/\"> puoi comunque avere un grande impatto</a> dando questa possibilit\u00e0 agli altri, dando sostegno politico o facendo donazioni a chi si occupa dei problemi che ritieni pi\u00f9 urgenti, e allo stesso tempo investendo nel tuo capitale di carriera.&nbsp;</p><p>Se invece scegli di cambiare carriera, <a href=\"https://80000hours.org/articles/impact-versus-happiness/\">cerca un lavoro che ti soddisfi </a>e che risponda alle tue necessit\u00e0. Se un certo percorso sembra solo faticoso, probabilmente non \u00e8 sostenibile n\u00e9 fonte di ispirazione per altre persone e probabilmente non va bene nemmeno per il tuo impatto.</p><p>Fortunatamente, siamo convinti che le fasi che abbiamo consigliato \u2013 costruire un capitale di carriera, esplorare e contribuire a risolvere problemi significativi \u2013 si incastrino bene con ci\u00f2 che molte persone trovano gratificante. Per questo, anche se potrebbero essere necessari dei compromessi, siamo convinti che queste fasi siano un percorso che ti porter\u00e0 a una carriera gratificante e soddisfacente e che ti aiuter\u00e0 ad affrontare i grandi problemi della nostra epoca.</p><p><strong>Esempio: Sophie Rose</strong><br><br>Sophie era sulla strada per diventare medico in Australia quando si imbatt\u00e8 nella nostra&nbsp;<a href=\"https://80000hours.org/2012/08/how-many-lives-does-a-doctor-save/\"><u>ricerca su quante vite pu\u00f2 salvare un medico nei paesi sviluppati</u></a>. Si rese quindi conto che avrebbe potuto avere un impatto ancora maggiore facendo qualcos\u2019altro. Aveva ascoltato il nostro podcast con Beth Cameron sul perch\u00e9 una pandemia globale era una possibilit\u00e0 concreta (nel 2017!) anche se, rispetto alla medicina convenzionale, era un problema trascurato, e aveva quindi deciso di scegliere un altro problema su cui concentrarsi.</p><p>Ne avevamo parlato faccia a faccia e l\u2019avevamo aiutata a trovare i fondi per una specializzazione in epidemiologia che le permettesse di costruirsi un capitale di carriera in quel campo.</p><p>Con lo scoppio dell\u2019epidemia di COVID-19, fu in grado di individuare una soluzione trascurata ma che avrebbe potuto avere un alto impatto: i test clinici su umani, in grado di accelerare considerevolmente lo sviluppo di un vaccino.&nbsp;</p><p>Utilizz\u00f2 quindi la sua influenza fondando 1DaySooner con un finanziamento datole da altre persone della nostra comunit\u00e0. 1DaySooner \u00e8 un\u2019organizzazione non-profit che ha reclutato 30.000 volontari per i test clinici su umani con lo scopo di accelerare l\u2019approvazione di un vaccino da parte del governo \u2013 consentendo quindi a molti laboratori di proseguire con le loro ricerche. Un primo test ha avuto luogo a Londra all\u2019inizio del 2021, un precedente storico che speriamo ci consentir\u00e0 di rispondere pi\u00f9 rapidamente in caso di una nuova pandemia.</p><p>\u00c8 probabile che il lavoro di medico sarebbe comunque stato gratificante per Sophie, ma anche questo percorso si \u00e8 rivelato adatto alle sue capacit\u00e0. E dal momento che pensa di avere un impatto maggiore in questo modo, per lei \u00e8 anche molto importante. Attualmente sta pensando di mettere a frutto quello che ha imparato e lavorare per prevenire l\u2019insorgere (purtroppo molto probabile) di una nuova pandemia peggiore del COVID-19.</p><p>La storia di Sophie \u00e8 raccontata pi\u00f9 nel dettaglio in questa&nbsp;<a href=\"https://www.marieclaire.co.uk/life/work/coronavirus-vaccine-human-challenge-trial-700793\"><u>intervista su Marie Claire</u></a>.</p><p>Ora che sei arrivato fin qua, puoi leggere l\u2019intera&nbsp;<a href=\"https://80000hours.org/key-ideas/\"><u>serie sulle nostre idee centrali</u></a> per approfondire ogni passaggio, oppure passare direttamente al&nbsp;<a href=\"https://80000hours.org/career-planning/summary/\"><u>pianificare la tua carriera lavorativa</u></a>.</p>", "user": {"username": "EA Italy"}}, {"_id": "aMm2hdwMTXHT8DGHG", "title": "L\u2019altruismo efficace, la causa pi\u00f9 entusiasmante del mondo", "postedAt": "2023-01-18T11:39:31.895Z", "htmlBody": "<p><i>This is an Italian translation of </i><a href=\"https://forum.effectivealtruism.org/posts/LwmEr3B9dpBrFq3du/effective-altruism-as-the-most-exciting-cause-in-the-world\"><i><strong>Effective altruism as the most exciting cause in the world</strong></i></a></p>", "user": {"username": "EA Italy"}}, {"_id": "GmkCya2bjGeNvasva", "title": "Un appello a rimanere vigili", "postedAt": "2023-01-18T11:38:08.222Z", "htmlBody": "<p><i>This is an Italian translation of </i><a href=\"https://forum.effectivealtruism.org/posts/uNczpTHFvjt4KNxEF/call-to-vigilance\"><i><strong>Call to Vigilance</strong></i></a></p><p><i>Versione audio disponibile in inglese su </i><a href=\"https://www.cold-takes.com/p/c8a508d3-0c87-4c2d-89ce-81ba878bced8/\"><i>Cold Takes</i></a><i>&nbsp;(o su Stitcher, Spotify, Google Podcasts, ecc. come \u201cCold Takes Audio\u201d)</i></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/GmkCya2bjGeNvasva/lahh1xwh96mbfvmlhj5s\" alt=\"\"></p><p>Questo \u00e8 l\u2019ultimo articolo della serie sul&nbsp;\u201c<a href=\"https://www.cold-takes.com/roadmap-for-the-most-important-century-series/\"><u>secolo pi\u00f9 importante\u201d</u></a>, in cui si discute <a href=\"https://www.cold-takes.com/forecasting-transformative-ai-whats-the-burden-of-proof/%23some-rough-probabilities\"><u>l\u2019alta probabilit\u00e0</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxilvyiqr1l\"><sup><a href=\"#fnxilvyiqr1l\">[1]</a></sup></span>&nbsp;che nei prossimi decenni vedremo:</p><ul><li>Lo sviluppo di tecnologie come i sistemi <a href=\"https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/\"><strong>PASTA</strong></a>&nbsp;(<i>Process for Automating Scientific and Technological Advancement</i>, Processo di Avanzamento Scientifico e Tecnologico Automatizzato).</li><li>Un conseguente <a href=\"https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/%23explosive-scientific-and-technological-advancement\"><strong>boom di produttivit\u00e0</strong></a>&nbsp;che porter\u00e0 allo sviluppo di ulteriori tecnologie trasformanti.</li><li>Le prime avvisaglie di una <a href=\"https://www.cold-takes.com/all-possible-views-about-humanitys-future-are-wild/\"><strong>civilt\u00e0 spaziale stabile</strong></a>, forse con la presenza di <a href=\"https://www.cold-takes.com/how-digital-people-could-change-the-world/\"><strong>persone digitali</strong></a>&nbsp;o forse governata da un\u2019<a href=\"https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/%23misaligned-ai-mysterious-potentially-dangerous-objectives\"><strong>IA non allineata</strong></a>.</li></ul><p>Nel cercare di attirare l\u2019attenzione su un problema sottovalutato, <strong>spesso si conclude con una&nbsp;\u201cchiamata all\u2019azione\u201d: </strong>un\u2019azione concreta e tangibile, che il lettore pu\u00f2 intraprendere per&nbsp;dare una mano.</p><p>Questo pone delle sfide, perch\u00e9, come ho illustrato <a href=\"https://www.cold-takes.com/p/f5eba675-6b0e-4f19-b2ad-b63a6bafc8fd/\"><strong>in precedenza</strong></a>, c\u2019\u00e8 un grande dibattito <a href=\"https://www.cold-takes.com/p/f5eba675-6b0e-4f19-b2ad-b63a6bafc8fd/%23key-open-questions-for-\"><strong>attorno a quali azioni sono utili e quali sono dannose</strong></a>. (Anche se \u00e8 possibile individuare alcune <a href=\"https://www.cold-takes.com/p/f5eba675-6b0e-4f19-b2ad-b63a6bafc8fd/%23robustly-helpful-actions\"><strong>azioni che sembrano robustamente utili al momento</strong></a>).</p><p>Cosa che pu\u00f2 essere un po\u2019&nbsp;imbarazzante. Quando rifletto sulla teoria del&nbsp;\u201csecolo pi\u00f9 importante\u201d, il mio atteggiamento non rispecchia i soliti di&nbsp;\u201centusiasmo e movimento\u201d o&nbsp;\u201cpaura ed evitamento\u201d. Al contrario, provo uno <strong>strano amalgama di intensit\u00e0, urgenza,&nbsp;confusione ed esitazione</strong>. Ho davanti a me qualcosa che supera in portata ogni mia precedente aspettativa, e per questo non mi sento abbastanza qualificato e non ho idea di quale possa essere la prossima mossa. Non \u00e8 facile condividere e diffondere questo stato mentale, ma ci sto provando.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/GmkCya2bjGeNvasva/uoje1mokk9yasmayx7g2\" alt=\"\"></p><p>Per cui, invece di una chiamata all\u2019azione, voglio fare un <strong>appello a rimanere vigili</strong>. Se le argomentazioni di questo articolo ti sembrano convincenti, allora non lanciarti a&nbsp;\u201cfare qualcosa\u201d per poi passare oltre. Piuttosto, concentrati sulle <a href=\"https://www.cold-takes.com/p/f5eba675-6b0e-4f19-b2ad-b63a6bafc8fd/%23robustly-helpful-actions\"><strong>azioni robustamente utili</strong></a>&nbsp;che puoi fare oggi o comunque fai&nbsp;in modo di essere pronto ad agire in maniera significativa quando sar\u00e0 il momento. Il che pu\u00f2 voler dire:</p><ul><li>Fare in modo di interagire e imparare di pi\u00f9 su argomenti/ambiti/settori fondamentali come le IA (per ovvi motivi), scienza e tecnologia in generale (dal momento che buona parte della teoria del&nbsp;\u201csecolo pi\u00f9 importante\u201d prevede <a href=\"https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/%23impacts-of-pasta\"><strong>rapidi progressi in campo scientifico e tecnologico</strong></a>) e i settori pertinenti di sicurezza nazionale e di normative.</li><li>Cogliere le occasioni&nbsp;(quando le vedi) di indirizzare la tua carriera in direzioni che pi\u00f9&nbsp;probabilmente saranno importanti (ne ho scritto <a href=\"https://forum.effectivealtruism.org/posts/bud2ssJLQ33pSemKH/my-current-impressions-on-career-choice-for-longtermists\"><strong>qui</strong></a>; vedi anche <a href=\"https://www.80000hours.org/\"><strong>80,000 Hours</strong></a>).</li><li>Entrare in contatto con altre persone interessate a questi argomenti (penso che questa sia stata la ragione principale che ha portato diverse persone a fare lavori ad alto impatto in passato). Allo stato attuale, penso che la comunit\u00e0 dell\u2019<a href=\"https://en.wikipedia.org/wiki/Effective_altruism\"><strong>altruismo efficace</strong></a>&nbsp;sia il luogo migliore; attraverso il <a href=\"https://www.centreforeffectivealtruism.org/\"><strong>Centre for Effective Altruism</strong></a>&nbsp;potete scoprire come entrare in contatto con altre persone (dal men\u00f9 a tendina&nbsp;\u201cGet Involved\u201d). \u00c8 probabile che poster\u00f2 su Cold Takes nuovi modi per entrare in contatto con le persone se ne emergeranno in futuro.</li><li>E ovviamente, non lasciarsi sfuggire nessuna occasione per fare <a href=\"https://www.cold-takes.com/p/f5eba675-6b0e-4f19-b2ad-b63a6bafc8fd/%23robustly-helpful-actions\"><strong>azioni robustamente utili</strong></a>.</li></ul><h2><strong>Tasti da premere</strong></h2><p>Ecco qualcosa che puoi fare immediatamente e che sarebbe utile, anche se forse non soddisfacente quanto firmare una petizione o fare una donazione.</p><p>Nel mio <a href=\"https://www.openphilanthropy.org/\"><strong>lavoro</strong></a>&nbsp;ci sono molti momenti in cui io o qualcuno con cui lavoro stiamo cercando un tipo di persona in particolare (magari perch\u00e9 c\u2019\u00e8 una posizione lavorativa aperta per un beneficiario, o perch\u00e9 abbiamo bisogno di determinate competenze in un certo ambito, o altro ancora). Mi aspetto che col tempo persone con specifiche abilit\u00e0, interessi, competenze, ecc., avranno sempre pi\u00f9 occasioni per intraprendere azioni che <a href=\"https://www.cold-takes.com/p/f5eba675-6b0e-4f19-b2ad-b63a6bafc8fd/\"><strong>trarranno il massimo beneficio dal secolo pi\u00f9 importante</strong></a>. Penso anche che una delle sfide principali sia semplicemente <strong>sapere chi \u00e8 disponibile \u2013</strong>&nbsp;chi \u00e8 interessato alla causa e vuole essere d\u2019aiuto e quali sono i suoi interessi e le sue capacit\u00e0.</p><p>Se sei una di quelle persone che potremmo voler incontrare in futuro, puoi aiutarci gi\u00e0 adesso inviandoci i tuoi dati attraverso <a href=\"https://forms.gle/z7mexiTd6wCJsuEv6\">questo semplice modulo</a>. Ti garantisco che i tuoi dati non verranno venduti o usati per fare soldi in qualche altro modo, che le tue preferenze di contatto (discusse nel dettaglio nel modulo) verranno rispettate e che potrai decidere di interrompere le comunicazioni con noi in qualsiasi momento.</p><h2><strong>Uno spazio mentale condiviso</strong></h2><p>In <a href=\"https://www.cold-takes.com/this-cant-go-on/\"><strong>This Can\u2019t Go On</strong></a>&nbsp;[<a href=\"https://forum.effectivealtruism.org/editPost?postId=bSuzKRaFyPvNGGrvh&amp;key=9654afffca2caee22d4f2e5e10fc68\"><strong><u>Tempi Eccezionali</u></strong></a>], paragonavo il mondo alle persone a bordo di un aereo che sfreccia sulla pista di decollo e che non hanno modo di sapere perch\u00e9 si stanno muovendo cos\u00ec velocemente o cosa succeder\u00e0 dopo:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/GmkCya2bjGeNvasva/cgjbogn3yrudoofwkxsc\" alt=\"\"></p><p>Dal momento che sono anch\u2019io a bordo dell\u2019aereo, mi piacerebbe molto poter dire che ho capito esattamente cosa stia succedendo e in che modo dobbiamo prepararci per il futuro. Ma purtroppo non \u00e8 cos\u00ec.</p><p>In mancanza di risposte, ho cercato di descrivere quello che vedo io:</p><ul><li>Immagini sfocate degli eventi (passati e futuri) pi\u00f9 importanti per l\u2019umanit\u00e0.</li><li>L\u2019impressione che questi eventi si stiano avvicinando molto pi\u00f9 in fretta di quel che sembra, a prescindere che noi siamo pronti o meno.</li><li>La sensazione di non poter fare affidamento sul mondo e le regole a cui siamo abituati. La sensazione di dover distogliere lo sguardo dal fiume quotidiano di notizie tangibili e condivisibili&nbsp;e cercare di comprendere concetti pi\u00f9 strani e pi\u00f9 assurdi a proposito di quest\u2019epoca, concetti che probabilmente <strong>vedremo&nbsp;come i pi\u00f9 importanti di quest\u2019epoca&nbsp;a miliardi di anni di distanza</strong>.</li></ul><p>Ci sono un sacco di cose che non so, ma se questo \u00e8 il secolo pi\u00f9 importante, mi sento sicuro nell\u2019affermare che la nostra civilt\u00e0 non \u00e8 ancora pronta per le sfide che dovr\u00e0 affrontare.</p><p>Se vogliamo che questa situazione cambi, \u00e8 necessario che pi\u00f9 persone la vedano per quello che \u00e8 davvero, che la prendano sul serio e agiscano quando ne hanno l\u2019opportunit\u00e0 \u2013 e quando questa opportunit\u00e0 non c\u2019\u00e8, che rimangano vigili.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxilvyiqr1l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxilvyiqr1l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u201cPrevendo con una probabilit\u00e0 maggiore del 10% che un\u2019IA trasformativa verr\u00e0 sviluppata nei prossimi 15 anni (quindi entro il 2036); con una probabilit\u00e0 del ~50% che verr\u00e0 sviluppata nei prossimi 40 anni (entro il 2060); e con una probabilit\u00e0 di ~\u2154 che verr\u00e0 sviluppata questo secolo (entro il 2100).\u201d</p></div></li></ol>", "user": {"username": "EA Italy"}}, {"_id": "TYvcfad5WmCQWZTJe", "title": "[Opzionale] Approfondimenti e altre critiche all'altruismo efficace (in inglese)", "postedAt": "2023-01-18T11:32:26.663Z", "htmlBody": "", "user": {"username": "EA Italy"}}, {"_id": "RjXWtZM8S5LcBvTqv", "title": "[Opzionale] Una lunga lista di possibili cause", "postedAt": "2023-01-18T11:28:52.866Z", "htmlBody": "<p>Abbiamo visto solo alcune delle cause di cui si parla nell\u2019altruismo efficace, dai un\u2019occhiata a questa&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/SCqRu6shoa8ySvRAa/big-list-of-cause-candidates\">Big List of Cause Candidates</a></p>", "user": {"username": "EA Italy"}}, {"_id": "LHD2jJoN68XtyE5n4", "title": "Esercizi per \u201cTu cosa ne pensi?\u201d (60 - 75 min.)", "postedAt": "2023-01-18T11:26:48.947Z", "htmlBody": "<p><i>This is an Italian translation of </i><a href=\"https://forum.effectivealtruism.org/posts/SYxBpdthYWcd6eQhF/exercise-for-what-do-you-think\"><i><strong>Exercise for 'What do you think?'</strong></i></a></p><p>Per l\u2019esercizio di questo capitolo ci prenderemo del tempo per riflettere sulle idee con le quali ci siamo confrontati nei capitoli scorsi. Il nostro obiettivo consiste nel fare il punto della situazione e identificare le nostre preoccupazioni e le nostre incertezze che riguardano le idee dell\u2019AE.</p><h2><strong>Cosa ti preoccupa dell\u2019AE? (15 min)</strong></h2><p>Abbiamo trattato molti temi negli ultimi capitoli: i fondamenti filosofici dell\u2019altruismo efficace, come confrontare le cause e allocare le risorse e abbiamo dato un\u2019occhiata ad alcune delle pi\u00f9 importanti cause prioritarie usando la prospettiva dell\u2019AE.</p><p>Quali sono tue le pi\u00f9 grandi domande, preoccupazioni e critiche sulla base di ci\u00f2 che abbiamo discusso finora? Possono riguardare la prospettiva dell\u2019AE o la sua comunit\u00e0, specifiche idee o cause o quello che preferisci!</p><h2><strong>Ritornare a riflettere (45-60 min)</strong></h2><p>Hai percorso tanta strada! Ci auguriamo che sia stata un\u2019esperienza piacevole e interessante. Ci sono tante considerazioni da fare quando cerchi di fare il maggior bene che puoi e molte idee potrebbero risultare per te nuove o poco familiari. Per questo capitolo vorremmo che tu ritornassi a riflettere sul programma con una mentalit\u00e0 scettica e curiosa.</p><p>Ricapitoliamo gli argomenti affrontati.</p><h3><a href=\"https://forum.effectivealtruism.org/s/3P5HHYsZsTuG4P5iE\"><u>1\u00aa Settimana - La Mentalit\u00e0 dell'Efficacia</u></a></h3><p>Nei capitoli 1 e 2 cerchiamo di introdurti ai principi fondamentali dell\u2019altruismo efficace. Ricorriamo a interventi sulla salute globale, che \u00e8 un\u2019area chiave dell\u2019altruismo efficace, per illustrare questi principi, in parte perch\u00e9 abbiamo dei dati particolarmente buoni su questa causa.</p><h3><a href=\"https://forum.effectivealtruism.org/s/BnoMfkekpoHHrKpkg\"><u>2\u00aa Settimana - Differenze di impatto</u></a></h3><p>Nel capitolo 2 abbiamo continuato a esplorare i principi fondamentali dell'altruismo efficace, in particolare attraverso gli interventi sulla salute globale, dal momento che sono particolarmente concreti e ben studiati. Ci concentriamo sul darti strumenti per quantificare e valutare quanto bene un intervento possa ottenere. Abbiamo introdotto il ragionamento sul valore atteso e investigato le differenze nel rapporto costi-benefici tra diversi interventi.</p><h3><a href=\"https://forum.effectivealtruism.org/s/RiBcQRf6WbSe9wbKL\"><u>3\u00aa Settimana - Empatia radicale</u></a></h3><p>Questa sezione si concentra sui tuoi valori e sulle loro implicazioni pratiche. Nel capitolo 3 esploriamo chi prendiamo moralmente in considerazione. Ci concentriamo soprattutto sugli animali allevati come un importante esempio per questo tema.</p><h3><a href=\"https://forum.effectivealtruism.org/s/zyvSkhx7ahqmxvHqw\"><u>4\u00aa Settimana - \u00c8 il nostro ultimo secolo?</u></a></h3><p>In questo capitolo ci concentriamo sui rischi esistenziali: rischi che minacciano di distruggere il potenziale a lungo termine dell\u2019umanit\u00e0. Esaminiamo perch\u00e9 i rischi esistenziali possano essere una priorit\u00e0 morale ed esploriamo perch\u00e9 i rischi esistenziali siano cos\u00ec trascurati nella nostra societ\u00e0. Diamo anche un\u2019occhiata a uno dei pi\u00f9 grandi rischi che potremmo dover affrontare: una pandemia artificiale, peggiore del COVID-19.</p><h3><a href=\"https://forum.effectivealtruism.org/s/D2RJXR2v3yv9XHRTA\"><u>5\u00aa Settimana - Che cosa potrebbe riservare il futuro? E perch\u00e9 dovrebbe importarci?&nbsp;</u></a></h3><p>In questo capitolo esploriamo come potrebbe essere il futuro e perch\u00e9 ci\u00f2 sia importante. Esaminiamo gli argomenti a favore del \u201clungoterminismo\u201d - l\u2019idea che migliorare il futuro a lungo termine \u00e8 una priorit\u00e0 morale fondamentale. Ci\u00f2 pu\u00f2 dare sostegno ad argomenti a favore della riduzione di alcuni dei rischi esistenziali presentati nelle ultime due settimane. Esploriamo anche alcune prospettive su come potrebbe essere il nostro futuro e sul perch\u00e9 potrebbe essere piuttosto diverso dal nostro presente.</p><h3><a href=\"https://forum.effectivealtruism.org/s/hyHpdcb3Noyon4tnE\"><u>6\u00aa Settimana - Pi\u00f9 intelligenti di noi</u></a></h3><p>L\u2019intelligenza artificiale trasformativa potrebbe essere sviluppata in questo secolo. Se le cose stanno cos\u00ec, potrebbe iniziare a prendere ogni decisione significativa per noi e accelerare di molto dei cambiamenti, come nella crescita economica. Siamo pronti per gestire questa nuova tecnologia in sicurezza?</p><p>Ora prova a rispondere alle seguenti domande:</p><p><i>Quali argomenti o idee del programma ti sembra di capire meno?</i></p><p><i>Cosa ti confonde di pi\u00f9 di ognuno di loro (torna all\u2019argomento o all\u2019idea e controlla se ci siano delle letture aggiuntive da fare che possano aiutarti ad affrontare le tue incertezze e a esplorare ogni preoccupazione. Leggi quel materiale. Prendi in considerazione il prendere appunti su ci\u00f2 che ti confonde, in stile flusso di coscienza).</i></p><p><i>Appunta un\u2019idea del programma che hai trovato all\u2019inizio sorprendente e che ora pensi che abbia pi\u00f9 o meno senso e che sia importante. In che modo questa idea potrebbe essere sbagliata? Qual \u00e8 l\u2019argomentazione pi\u00f9 forte contro di essa?</i></p><p><i>Appunta un\u2019idea dal programma che hai trovato all\u2019inizio sorprendente e che ora pensi che sia probabilmente sbagliata o sulla quale hai delle riserve. Qual \u00e8 l\u2019argomento migliore&nbsp;<strong>a favore</strong> di questa idea? Quali sono le tue esitazioni principali che riguardano questo argomento?</i></p><p><br>&nbsp;</p>", "user": {"username": "EA Italy"}}, {"_id": "enCwDPFtA7PCFvPSA", "title": "Note sull\u2019altruismo efficace", "postedAt": "2023-01-18T11:24:08.802Z", "htmlBody": "<p><i>This is an Italian translation of </i><a href=\"https://forum.effectivealtruism.org/posts/NHsH9pHZ7rA3KcnC7/notes-on-effective-altruism\"><i><strong>Notes on Effective Altruism</strong></i></a></p><p>(Versione audio in inglese disponibile su&nbsp;<a href=\"https://forum.effectivealtruism.org/s/32FKXByGNgHLPaHnj/p/NHsH9pHZ7rA3KcnC7\"><u>Notes on Effective Altruism</u></a>)</p><p><i>Note lunghe e approssimative sull\u2019altruismo efficace (AE), scritte per aiutarmi per andare a fondo su diverse questioni: cosa mi piace dell\u2019AE e che cosa ritengo importante riguardo a ci\u00f2? Perch\u00e9 trovo la sua mentalit\u00e0 cos\u00ec estranea? Perch\u00e9 non sono un altruista efficace? Note scritte anche per iniziare a chiedermi che aspetto hanno le alternative all\u2019AE. Queste note non sono indirizzate agli altruisti efficaci, anche se forse potrebbero interessare a persone vicine all\u2019AE. Commenti e correzioni ben pensati e informati sono i benvenuti (soprattutto le correzioni dettagliate e specifiche!) - vedere l\u2019area commenti al fondo.</i></p><p><i>\"Usare l\u2019evidenza e la ragione per capire come fare del bene agli altri il pi\u00f9 possibile e intraprendere azioni a partire da queste basi\"</i>: questa \u00e8 l\u2019idea a fondamento dell\u2019ideologia e del movimento dell\u2019altruismo efficace (AE)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnpwvat649z\"><sup><a href=\"#fnnpwvat649z\">[1]</a></sup></span>&nbsp;Negli ultimi due decenni \u00e8 passata dall\u2019essere una idea dibattuta da una manciata di filosofi morali a diventare il nucleo centrale della filosofia di vita di migliaia o decine di migliaia di individui, inclusi alcuni tra i pi\u00f9 ricchi e potenti. Queste sono le mie note approssimative e operative sull\u2019AE. Le note sono lunghe e scritte in fretta: pensiero disorganizzato e approssimativo, non un saggio.</p><p>Ho scritto queste note per alcune ragioni. Una \u00e8 puramente sociale: i miei amici hanno opinioni forti sull\u2019AE (alcune pro, alcune contro, altre pi\u00f9 neutrali). Un\u2019altra \u00e8 la sensazione che l\u2019AE sia importante come movimento e (forse) come insieme di idee: il fatto che cos\u00ec tanti adolescenti e ventenni svegli e idealisti rispondano cos\u00ec fortemente all\u2019AE \u00e8 significativo; molti riferiscono radicali cambiamenti nelle loro vite: svolte di carriera, modifiche dei comportamenti quotidiani e impegnarsi a donare una grande porzione dei propri guadagni a organizzazioni che descrivono come \u201cefficaci\u201d. Gli altruisti efficaci<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref59zgjbwnop7\"><sup><a href=\"#fn59zgjbwnop7\">[2]</a></sup></span>&nbsp;condividono inoltre un linguaggio poco comune e modi di vedere il mondo, in gran parte influenzato dall\u2019economia del welfare e dalla filosofia morale.</p><p>C\u2019\u00e8 la tentazione di ridurre tutto questo a una semplice \u201cmoda\u201d o a una conseguenza del (meteorico) incremento dei finanziamenti a favore dell\u2019AE. Ma non ci credo. Molti altruisti efficaci sono straordinariamente sinceri e hanno trovato profonda convinzione e significato nell\u2019AE. Sta facendo qualcosa di molto importante per loro, qualcosa che va ben oltre una moda di nicchia.</p><p>Quando ho sentito parlare dell\u2019AE per la prima volta, la mia prima reazione, istintiva e poco ponderata, \u00e8 stata abbastanza negativa. Spesso un po\u2019 scherzavo sull\u2019essere un altruista inefficace o un altruista caotico. Mi definivo un \u201cmutilitarista\u201d, usando il \u201cmu\u201d del buddhismo zen come mia funzione d\u2019utilit\u00e0 (cio\u00e8 la negazione dell\u2019idea). Eppure, dopo un\u2019analisi pi\u00f9 approfondita questi si rivelano rifiuti di poco conto.</p><p>Nel 2011 un mio amico AE si \u00e8 messo sotto i ferri per donare un rene a un estraneo. Mi ha spiegato che:</p><p>\u201cHo visto delle statistiche su quanto sia sicuro donare e ci\u00f2 ha cambiato del tutto la mia prospettiva. Ho pensato che, con un rischio di morte durante per l\u2019operazione di 1/3000, sarebbe stato come sacrificarsi per salvare 3000 persone. Voglio essere il tipo di persona che fa cose del genere, e occorre semplicemente seguire questi pochi passaggi\u201d.</p><p>Ho amici AE che donano una porzione importante dei propri guadagni in beneficenza. In alcuni casi \u00e8&nbsp;<i>ogni</i> guadagno al di sopra di una certa soglia, bassa seguendo i criteri del mondo pi\u00f9 ricco e sviluppato, diciamo 30.000 dollari [circa \u20ac28.000 in data 20/02/2023, dato da valutare tenendo conto delle differenze tra il costo della vita negli Stati Uniti e la media europea, N.d.T.]. A volte sembra plausibile che le loro donazioni individuali abbiano permesso di salvare dozzine di vite, di aiutare a sollevare dalla povert\u00e0 molte persone e di prevenire diverse malattie debilitanti, spesso in alcuni dei luoghi pi\u00f9 poveri e disagiati del mondo. Questa \u00e8 un\u2019affermazione semplice, ma straordinaria, quindi la ripeter\u00f2: hanno direttamente contribuito a salvare molte vite.</p><p>Provo una stupita ammirazione per tutto questo e mi sento un po\u2019 imbarazzato per le mie battute sull\u2019altruismo inefficace, nonch\u00e9 grato per i miei amici altruisti efficaci che mi hanno sopportato. Ho provato a vivere una vita che faccia incontrare le mie capacit\u00e0 personali e i miei interessi con ci\u00f2 che \u00e8 bene per il mondo. Spero di aver fatto davvero del bene, godendomi nel frattempo la vita. Ma non ho mai direttamente salvato una vita, per quanto ne so. Non credo che io&nbsp;<i>possa&nbsp;</i>donare un rene: violerebbe troppo il mio senso di integrit\u00e0 corporea. A livello personale, amo la sincerit\u00e0 e la genuina bont\u00e0 dei miei amici altruisti efficaci o vicini al movimento. Semplicemente mi&nbsp;<i>sento</i> pi\u00f9 moralmente integro dopo aver passato il mio tempo con loro: spesso sono pi\u00f9 onesto e a volte pi\u00f9 gentile o di mentalit\u00e0 aperta. Queste sono cose davvero buone.</p><p>Ci\u00f2 che segue, quindi, \u00e8 una serie di osservazioni sull\u2019AE. In parte \u00e8 un apprezzamento: criticare l\u2019AE implica anche comprendere una parte di ci\u00f2 che \u00e8 buono di esso. C\u2019\u00e8 anche molto che le altre ideologie possono imparare dall\u2019AE. Tuttavia scaver\u00e0 a fondo e prover\u00f2 a capire che cosa mi infastidisce del movimento, che cosa penso sia sbagliato e come penso si possa cambiare in modo fruttuoso.</p><p>Qualcosa manca tra queste note: un resoconto personale e diretto del bene che l\u2019AE fa. Ho un\u2019impressione riflessa di ci\u00f2 attraverso i miei amici, ma vorrei saperne di pi\u00f9. \u00c8 impossibile apprezzare sinceramente l\u2019AE senza tale conoscenza. Le zanzariere antimalariche, il trasferimento diretto di denaro, la sverminazione e simili non sono astrazioni: sono, infatti, un importantissimo evento nel mondo reale che fa la differenza nella vita di tante persone. Ci\u00f2 non si trova in queste note per via della mia ignoranza. Si tenga a mente questo fatto mentre si legge; io ho cercato di farlo mentre scrivevo.</p><p>Attenzione: far\u00f2 molte generalizzazioni su \u201cci\u00f2 che gli altruisti efficaci fanno\u201d Ma l\u2019AE non \u00e8 monolitico. Ci\u00f2 rende difficile scrivere senza fare riferimento a molte specificazioni. Potrei farlo dicendo \u201cmolti altruisti efficaci credono che\u201d o citando i principali altruisti efficaci, e cos\u00ec via. Ho preferito perlopi\u00f9 optare per un linguaggio pi\u00f9 generale, dando per implicito che ci sono spesso altruisti efficaci che sono in disaccordo con altri altruisti efficaci su questioni particolari. In ogni caso, ho provato a rendere chiari i casi in cui c\u2019\u00e8 un disaccordo diffuso all\u2019interno della comunit\u00e0 dell\u2019AE su una particolare questione.</p><p>Ho iniziato queste note con una descrizione dell\u2019AE molto utilizzata, presa dal filosofo William MacAskill, uno dei fondatori dell\u2019AE: \u201cUsare l\u2019evidenza e la ragione per capire come fare del bene agli altri il pi\u00f9 possibile e intraprendere azioni a partire da queste basi\u201d. Nei fatti, di solito l\u2019ho sentita abbreviata in questo modo: \"usare l\u2019evidenza e la ragione per fare il maggior bene possibile\u201d. Far\u00f2 ricorso in seguito a quest\u2019ultima versione per riassumere ci\u00f2 di cui tratta l\u2019AE, ma tenendo a mente la descrizione pi\u00f9 lunga. Una precisazione su entrambe: sono tutt\u2019e due intrinsecamente massimizzanti, \u201cfare del bene agli altri&nbsp;<i>il pi\u00f9</i> possibile\u201d, \u201cfare il&nbsp;<i>maggior&nbsp;</i>bene possibile\u201d. In pratica, molti altruisti efficaci sostengono di fare un passo indietro rispetto a questa mentalit\u00e0 della massimizzazione. Come risultato, ha senso pensare a diverse \u201cintensit\u00e0\u201d dell\u2019AE, sulla base di quanto si accetti (o non si accetti) questo approccio massimizzante. Torneremo su questo, perch\u00e9 \u00e8 un problema significativo non risolto dalla comunit\u00e0 di AE. E quando utilizzo il quadro generale de \u201cil maggiore bene\u201d, lo faccio con l\u2019implicita riserva per cui molti altruisti efficaci fanno un passo indietro rispetto a questo \u201cil maggiore\u201d, nei fatti.</p><h2><strong>AE come fonte di invenzione morale</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefs8gosup4ep\"><sup><a href=\"#fns8gosup4ep\">[3]</a></sup></span></h2><p>Ho citato poco sopra il mio amico che ha donato un rene nel 2011. Il filosofo morale Peter Singer, uno degli ideatori di molti dei concetti dell\u2019AE, ha descritto il suo stupore<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1iwxk8ddnxl\"><sup><a href=\"#fn1iwxk8ddnxl\">[4]</a></sup></span><a href=\"https://docs.google.com/document/d/1u2_-0f10rnCGDtiRfjPdJJJBAaGO-enix7i9l_HH5VY/edit#bookmark=id.yco7hjk9c9kg\"><u>&nbsp;</u></a>nell\u2019apprendere (nel 2004) la storia di Zell Kravinsky, un facoltoso investitore immobiliare che aveva donato il suo patrimonio di circa 45 milioni di dollari, vivendo con circa $60.000 l\u2019anno. Ma c\u2019\u00e8 qualcosa di ancor pi\u00f9 degno di nota. Di primo acchito sembrer\u00e0 molto simile alla storia sulla donazione del rene del mio amico. Ma c\u2019\u00e8 una importante differenza:</p><p>Pensava ancora di non aver fatto abbastanza per aiutare gli altri, cos\u00ec prese accordi con un ospedale della zona per donare un rene a uno sconosciuto\u2026 Citando studi scientifici che mostravano come il rischio di morire a seguito della donazione di un rene sarebbe stato di 1 su 4.000, afferma che non fare la donazione avrebbe significato valutare la sua vita 4.000 volte quella di un estraneo, una valutazione che trovava del tutto ingiustificata.</p><p>Per quanto sia stata straordinaria la generosit\u00e0 del mio amico, c\u2019\u00e8 qualcosa in pi\u00f9 in ballo qui. L\u2019atto di Kravinsky \u00e8 un atto di immaginazione morale. Lo \u00e8 il solo prendere in considerazione di donare un rene e poi, per convinzione morale, farlo. Questo \u00e8 un incredibile atto di invenzione morale: qualcuno (presumibilmente Kravinsky) \u00e8 stato il primo a immaginare una cosa del genere e, quindi, ad metterla in atto. Questa invenzione morale ha in seguito ispirato altri a fare la stessa cosa. Ha realmente aumentato l\u2019estensione dell\u2019esperienza morale umana, dalla quale gli altri possono apprendere e che possono, dunque, emulare. In questo senso le persone come Kravinsky possono essere considerate dei pionieri in ambito morale o degli psiconauti morali<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefv4i13c0r67\"><sup><a href=\"#fnv4i13c0r67\">[5]</a></sup></span>, in grado di ideare nuove forme dell\u2019esperienza morale.</p><p>Ovviamente questi pionieri morali non provengono solamente dall\u2019AE. Tutt\u2019altro! Sono alla base della nostra civilt\u00e0. Molti dei miei eroi personali sono pionieri morali, incluso l\u2019autore del \u201cSermone della Montagna\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefip50r1grtke\"><sup><a href=\"#fnip50r1grtke\">[6]</a></sup></span>, il movimento abolizionista, le suffragette e il movimento femminista, Marthin Luther King e gli altri leader del movimento per i diritti civili. Tutti costoro (e molti altri) si sono impegnati in atti di immaginazione morale che hanno aumentato l\u2019estensione dell\u2019esperienza morale disponibile per l\u2019emulazione al resto di noi. Magari non siamo sempre d\u2019accordo con loro: non so se mi trovo d\u2019accordo con la visione di Peter Singer sui diritti degli animali, per esempio. Singer potrebbe avere torto su questo. Ma ci\u00f2 \u00e8 tuttavia di valore in quanto atto di invenzione morale in grado di aumentare la nostra estensione potenziale dell\u2019esperienza morale.</p><p>Una delle cose interessanti sull\u2019AE \u00e8 che ha incoraggiato molti pionieri morali: persone disponibili a ripensare questioni morali fondamentali e (a volte) ad aumentare l'estensione della nostra esperienza morale. Domande che hanno posto con seriet\u00e0 (in alcuni casi agendo sulla base delle risposte): \u201ce se le vite degli animali avessero davvero importanza?\u201d; \u201ce se una vita dall\u2019altra parte del mondo avesse tanta importanza quando quella di un bambino che affoga di fronte ai miei occhi?\u201d; \u201ce se la \u2018vita\u2019 di una macchina intelligente avesse la stessa importanza di quella di un essere umano?\u201d; \u201ccome dovremmo valutare la vita di un essere umano che vivr\u00e0 tra un milione di anni?\u201d. Prendendo sul serio queste domande possono espandere il nostro orizzonte morale.</p><p>C\u2019\u00e8 un lato oscuro della medaglia nell\u2019essere pionieri morali, in modo memorabile indicato dalla filosofa politica Hannah Arendt ne&nbsp;<i>La banalit\u00e0 del male: Eichmann a Gerusalemme</i>, il suo resoconto del processo al crimine di guerra nazista Adolf Eichmann. Secondo Arendt i nazisti erano (in un certo senso) a loro volta pionieri morali, inventando nuovi tipi di crimine che hanno aumentato la probabile estensione dei futuri crimini:</p><p>Nulla \u00e8 pi\u00f9 nocivo alla comprensione di questi nuovi delitti, e nulla ostacola di pi\u00f9 l'instaurazione di un codice penale internazionale, quanto la comune illusione che il crimine dell'omicidio e il crimine del genocidio siano in sostanza la stessa cosa, e che perci\u00f2 il secondo non sia propriamente una novit\u00e0. Il secondo viola un ordine del tutto diverso e lede una comunit\u00e0 del tutto diversa.[\u2026] \u00c8 nella natura delle cose che ogni azione umana che abbia fatto una volta la sua comparsa nella storia del mondo possa ripetersi anche quando ormai appartiene a un lontano passato. Nessuna pena ha mai avuto il potere d'impedire che si commettano crimini. Al contrario, quale che sia la pena, quando un reato \u00e8 stato commesso una volta, la sua ripetizione \u00e8 pi\u00f9 probabile di quanto non fosse la sua prima apparizione.</p><p>Il ragionamento morale, se preso sul serio e agendo di conseguenza, \u00e8 della massima importanza, in parte perch\u00e9 esiste il pericolo di compiere terribili errori. L\u2019esempio del nazismo \u00e8 esageratamente drammatico: in primo luogo, trovo difficile credere che gli ideatori delle idee naziste non avessero realizzato che quelli erano atti profondamente malvagi. Un esempio pi\u00f9 comune, uno che dovrebbe mettere in pausa ogni ideologia, sono le persone eccessivamente sicure della propria giustizia, che agiscono come se \u201csapessero\u201d cosa sia una buona causa, ma che in realt\u00e0 stanno facendo danni. Sono cautamente entusiasta sul pionierismo morale dell\u2019AE, ma \u00e8 un potenziale campo minato, una cosa sulla quale occorre essere anche cauti.</p><h2><strong>AE judo: una forte critica a ogni strategia particolare per fare il \u201cbene maggiore\u201d migliora l\u2019AE e non lo discredita</strong></h2><p>Una delle strategie di \u201cattacco\u201d pi\u00f9 comune contro l\u2019AE consiste nel non essere d\u2019accordo con molte delle nozioni pi\u00f9 comuni dello stesso AE su che cosa voglia dire fare il bene maggiore. \u201cSei un altruista efficace?\u201d \u201cOh, quella \u00e8 gente che pensa che tu debba donare denaro per le reti da letto antimalariche (o per la sicurezza delle IA, o per la sverminazione, ecc\u2026), ma questo \u00e8 sbagliato perch\u00e9\u2026\u201d. Oppure \u201cWill MacAskill sostiene che gli altruisti efficaci dovrebbero prendere in considerazione il guadagnare-per-donare, ma questo \u00e8 sbagliato perch\u00e9\u2026\u201d. Oppure \"La scienza e la giustizia sociale e la creativit\u00e0 e ecc\u2026 sono molto pi\u00f9 difficili da misurare rispetto a cose come i QALY, quindi gli altruisti efficaci tendono a dare loro scarso valore o a ignorarle\u201d. Oppure \u201cGli altruisti efficaci sono abbastanza creduloni<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmkktg9cwb6\"><sup><a href=\"#fnmkktg9cwb6\">[7]</a></sup></span>&nbsp;sul valore degli studi controllati randomizzati e le meta-analisi, quando si dovrebbe piuttosto\u2026\u201d. Oppure \"Guarda, puoi direttamente accrescere i QALY quanto ti pare, non ti sposter\u00e0 da una economia che cresce lentamente a una che cresce velocemente. Queste due sono a un diverso livello di astrazione causale\".</p><p>Queste affermazioni possono essere vere o meno. Ci\u00f2 nonostante, nessuna di esse costituisce una critica fondamentale dell\u2019AE. Piuttosto, sono esempi del modo di pensare dell\u2019AE: stai in realt\u00e0 prendendo parte al progetto dell\u2019AE quando fai commenti del genere. Gli altruisti efficaci discutono con veemenza e continuamente che cosa significhi fare il maggior bene. Ci\u00f2 che li unisce \u00e8 l\u2019essere d\u2019accordo sul fatto che dovrebbero \u201cusare l\u2019evidenza e la ragione per capire come fare il maggior bene\u201d; se sei in disaccordo con le nozioni predominanti dell\u2019AE su cosa sia il bene maggiore e hai dell\u2019evidenza da condividere, stai dando acqua al mulino che porta al miglioramento nell\u2019AE della comprensione di cosa sia bene.</p><p>In ogni caso, questo tipo di \u201ccritica\u201d rappresenta almeno la met\u00e0 (probabilmente di pi\u00f9) delle critiche esterne all\u2019AE in cui sono incappato. La maggior parte dei critici esterni che pensano di criticare l\u2019AE criticano un miraggio. A questo proposito, l\u2019AE presenta un\u2019immensa area superficiale che pu\u00f2 solamente venire rafforzata dalla critica, non indebolita. Penso a questo schema come se fosse il&nbsp;<i>judo dell\u2019AE&nbsp;</i>e puoi notarlo spesso nelle discussioni con i critici dell\u2019AE. Un esempio piacevole e istruttivo \u00e8 l\u2019altruista efficace Rob Wiblin&nbsp;<a href=\"https://80000hours.org/podcast/episodes/russ-roberts-effective-altruism-empirical-research-utilitarianism/\">che intervista</a> Russ Roberts, che si dice in disaccordo con l\u2019AE. Ma durante (gran parte) dell\u2019intervista Roberts tacitamente accetta i concetti fondamentali dell\u2019AE, ponendosi in disaccordo con particolari istanze. E Wiblin pratica il judo dell\u2019AE, ancora e ancora, trasformando l\u2019intervista in un tipico dibattito da AE su come fare il bene maggiore. \u00c8 molto interessante ed entrambi i partecipanti ponderano molto bene le loro affermazioni, ma non \u00e8 per davvero un dibattito sui meriti dell\u2019AE.</p><p>Questo \u00e8, per me, uno degli aspetti pi\u00f9 attraenti e potenti dell\u2019AE. Lo rende molto diverso dalla maggior parte delle ideologie, che risultano di solito piuttosto statiche. L\u2019AE \u00e8, in un certo senso, il tentativo di fare per la domanda \u201cche cosa \u00e8 bene\u201d ci\u00f2 che la scienza ha fatto per la domanda \u201ccome funziona il mondo?\u201d. Invece di fornire una risposta, sta sviluppando una comunit\u00e0 che mira a migliorare continuamente questa risposta<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefiyegzwejrss\"><sup><a href=\"#fniyegzwejrss\">[8]</a></sup></span>.</p><p>Per questa ragione vale la pena separare l\u2019AE-in-pratica (un movimento sociale) dall\u2019AE-il-progetto-intellettuale. Se vuoi arrivare alle questioni fondamentali, occorre concentrarsi su quest\u2019ultimo, non solo sul primo. Come dicevo, molte critiche dell\u2019AE-in-pratica sono semplicemente parte del motore centrale per il miglioramento. Questo non significa, comunque, che non sia opportuno impiegare del tempo per criticare l\u2019area superficiale dell\u2019AE-in-pratica. \"Dai loro frutti li riconoscerete\" funziona per i principi intellettuali, non per le sole persone. Se un insieme di principi genera molti frutti marci, ci\u00f2 \u00e8 un segno che qualcosa non va nei principi, una&nbsp;<i>reductio ad absurdum</i>. Avrete probabilmente sentito dei comunisti o degli ultraliberali difendere gli esperimenti falliti del comunismo e del libero mercato dicendo \u201cnon era un vero esperimento di comunismo / di libero mercato\u201d. A volte hanno delle buone ragioni, ma, se lo schema si ripete, se i principi fondamentali non sono resilienti o necessitano tante precisazioni particolari, vuol dire che quei principi hanno qualcosa di decisamente sbagliato in loro.</p><p>Mettiamola in un altro modo: quando il judo dell\u2019AE \u00e8 utilizzato troppe volte, ha senso cercare problemi pi\u00f9 fondamentali. La forma base del judo dell\u2019AE \u00e8 \u201cGuarda, il disaccordo su ci\u00f2 che \u00e8 buono non tocca direttamente l\u2019AE. A dire il vero, tale disaccordo \u00e8 il motore che porta al miglioramento della nostra concezione di che cosa sia buono\u201d. Questo forse \u00e8 vero dalla prospettiva di un occhio divino, onnisciente, di un filosofo teoretico. Ma la comunit\u00e0 e le organizzazioni dell\u2019AE sono soggette alle mode, ai giochi di potere, alle mancanze e agli errori come qualsiasi altra comunit\u00e0 e organizzazione. Le buone intenzioni, da sole, non bastano per assicurare decisioni efficaci sull\u2019efficacia<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxnbqa2w5kl\"><sup><a href=\"#fnxnbqa2w5kl\">[9]</a></sup></span>. E la ragione per cui molte persone sono infastidite dall\u2019AE non \u00e8 dovuta al pensare che sia una cattiva idea \u201cfare bene, meglio\u201d. Piuttosto, dubitano della capacit\u00e0 delle istituzioni e della comunit\u00e0 dell\u2019AE di essere all\u2019altezza delle aspettative.</p><p>Queste critiche possono arrivare da diverse direzioni. Da persone che si interessano alla politica identitaria ho sentito dire: \u201cGuarda, molte di queste organizzazioni dell\u2019AE sono gestite da potenti maschi bianchi e riproducono le attuali strutture di potere, sono poco obiettive nei confronti del capitalismo democratico e dello status quo e ignorano molte delle questioni che hanno davvero importanza\u201d. Dagli ultraliberisti ho sentito: \u201cGuarda, l\u2019AE \u00e8 semplicemente un utilitarismo collettivista di sinistra. Centralizza troppo il processo decisionale e ignora sia i \u201csegnali di prezzo\u201d (\u201cprice signals\u201d), sia l\u2019immenso potere derivante dall\u2019avere molte persone che lavorano in vista dei loro stessi interessi, seppur in un sistema costruito affinch\u00e9 l'interesse personale (spesso) aiuti tutti collettivamente\u201d.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzq4j7xta05h\"><sup><a href=\"#fnzq4j7xta05h\">[10]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6b2whof1rch\"><sup><a href=\"#fn6b2whof1rch\">[11]</a></sup></span>&nbsp;Dalla gente delle startup e dagli inventori ho sentito: \u201cGli altruisti efficaci non lavorano troppo sui beni comuni? Se vuoi fare il bene pi\u00f9 grande, perch\u00e9 non lavorare in una startup? Possiamo semplicemente inventare e diffondere nuove tecnologie (o nuove idee) per migliorare il mondo!\u201d. Da persone familiari con le patologie delle comunit\u00e0 o delle organizzazioni che invecchiano, ho sentito: \u201cGuarda, qualsiasi movimento che cresce rapidamente inizia anche a declinare. Verr\u00e0 dominato da carrieristi ambiziosi e dal problema principale-agente, perder\u00e0 la sincerit\u00e0 e l\u2019agilit\u00e0 che hanno caratterizzato i pionieri e i primi seguaci<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6a8i3td3c6\"><sup><a href=\"#fn6a8i3td3c6\">[12]</a></sup></span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefrp9mw3szkbo\"><sup><a href=\"#fnrp9mw3szkbo\">[13]</a></sup></span>\u201d</p><p>Tutte queste critiche hanno un fondo di verit\u00e0, ma anche problemi significativi. Senza addentrarci troppo, il punto pi\u00f9 immediato \u00e8 che sembrano tutti problemi \u201cmeramente\u201d pratici, affrontabili con il judo dell\u2019AE: \"Se non riusciamo bene in queste, miglioreremo, abbiamo semplicemente bisogno che si fornisca evidenza e migliori alternative\u201d. Ma i modelli organizzativi sono cos\u00ec potenti che queste critiche mi paiono pi\u00f9 di principio. Ribadisco: se il tuo movimento sociale funziona \u201cin teoria\u201d, ma l\u2019attuazione porta con s\u00e9 troppi problemi, allora non funziona nemmeno in teoria. La qualit\u00e0 \u201csiamo in grado di fare ci\u00f2 efficacemente in pratica\u201d \u00e8 un\u2019importante (e implicita) qualit\u00e0 di principio.</p><h2><strong>\"Cattivi\" altruisti efficaci, caduti in una trappola dell\u2019infelicit\u00e0</strong></h2><p>Torniamo al principio dell\u2019AE: \"usare l\u2019evidenza e la ragione per fare il maggior bene possibile\". \u00c8 un principio davvero attraente sotto diversi aspetti: \u00e8 estremamente chiaro; aiuta molto a orientarsi e comunica un grande significato, in particolare se inserito all\u2019interno di un contesto sociale o organizzativo che d\u00e0 consigli convincenti su come fare il bene maggiore. Questi consigli non hanno bisogno di essere perfetti: hanno semplicemente bisogno di essere migliori di ci\u00f2 che sarebbero nella maggior parte degli altri contesti di comunit\u00e0.</p><p>Parte dell\u2019attrattivit\u00e0 del principio consiste nel limitare le scelte. Uno dei grandi risultati della modernit\u00e0 \u00e8 dare alle persone sempre maggiore e maggiore possibilit\u00e0 di scelta, fino al punto di poter scegliere (apparentemente) qualsiasi cosa<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbo7jlea1dgi\"><sup><a href=\"#fnbo7jlea1dgi\">[14]</a></sup></span>. Ma una grande possibilit\u00e0 di scelta pu\u00f2 portare alla confusione e rivelarsi onerosa. Gran parte del potere dell\u2019AE (e di molte altre ideologie) consiste nel ridurre grandemente le possibili scelte, affermando che: no, tu hai il dovere<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefr1jopxxfb3\"><sup><a href=\"#fnr1jopxxfb3\">[15]</a></sup></span>&nbsp;di fare il maggior bene che puoi nel mondo. Inoltre, l\u2019AE assicura delle istituzioni e una comunit\u00e0 che aiutano a guidarti nel fare questo bene. Fornisce quindi orientamento, significato e una narrativa sul&nbsp;<i>perch\u00e9</i> tu stia facendo ci\u00f2 che stai facendo.</p><p>Su Twitter, l\u2019ex altruista efficace Nick Cammarata ha scritto questo&nbsp;<a href=\"https://twitter.com/nickcammarata/status/1528005615095799808\">commento</a>, che ho visto ripetere a quattr\u2019occhi da altruisti efficaci ed ex altruisti efficaci:</p><p>\u201cLa mia voce interiore dell\u2019inizio 2016 avrebbe automaticamente convertito tutto il denaro che spendevo (per esempio in cene) in un \u201ccontatore delle morti\u201d frazionario delle vite che avrei potuto ragionevolmente salvare se avessi donato quei soldi a una buona organizzazione. La maggior parte degli altruisti efficaci all\u2019epoca avrebbero detto \u201cah, s\u00ec, ha senso\u201d.</p><p>O considera questo<a href=\"https://twitter.com/TheDrewRat/status/1525558537467969536\"> memorabile scambio</a> su Twitter tra un non-altruista efficace e un altruista efficace:</p><p>\"La quantit\u00e0 ottimale di beneficenza ottimale non \u00e8 il 100%\u201d&nbsp;</p><p>\"Ma i buoni altruisti efficaci prendono questo in considerazione\"</p><p>\"S\u00ec, ma i cattivi altruisti efficaci cadono in una trappola dell\u2019infelicit\u00e0\"</p><p>\"S\u00ec, ma non \u00e8 un difetto dell\u2019altruismo efficace, \u00e8 un difetto di quelle persone.\"</p><p>O considera questo passaggio dal libro di Peter Singer \u201cLa cosa migliore che tu puoi fare\u201d:</p><p>Da giovane, [la pioniera dell\u2019AE] Julia [Wise] sentiva molto intensamente che la scelta di donare o non donare poteva fare la differenza tra la vita di qualcuno e la morte di un altro, tanto che decise che sarebbe stato immorale diventare genitore: le avrebbe preso troppo tempo e denaro. Quando lo disse a suo padre, egli replic\u00f2: \u00abNon mi sembra che questo stile di vita ti render\u00e0 felice\u00bb. Al che lei rispose: \u00abIl punto non \u00e8 la mia felicit\u00e0\u00bb. Pi\u00f9 tardi, quando stava con Jeff [suo marito], cap\u00ec che suo padre aveva ragione. La decisione di non volere figli la deprimeva. Ne parl\u00f2 con Jeff e decisero che avrebbero potuto sia crescere un figlio che donare a sufficienza. Julia si sentiva eccitata all\u2019idea di avere un bambino un giorno, poich\u00e9 immaginava che sarebbe stata pi\u00f9 utile al mondo se fosse stata soddisfatta della propria vita, piuttosto che essere \u00abun\u2019altruista depressa\u00bb.</p><p>Tutti abbiamo limiti; se ritieni che una determinata scelta ti renda pi\u00f9 triste, \u00e8 il momento di riesaminarla. Puoi diventare pi\u00f9 positivo per un motivo piuttosto che un altro? Se no, abbiamo veramente considerato al meglio le cose?</p><p>\u2026</p><p>Julia ammette di fare degli errori: quando va a fare la spesa, si chiede continuamente: \u00abHo bisogno di questo gelato tanto quanto una donna povera, da qualche parte nel mondo, ha bisogno di vaccinare il suo bambino?\u00bb. La spesa al supermercato la faceva diventare matta, quindi lei e Jeff decisero quanto avrebbero dovuto donare nei successivi sei mesi e poi stabilirono un budget sulla base di ci\u00f2 che rimaneva, entro cui tenevano conto del denaro da spendere per s\u00e9 stessi. Ora Julia non si fa pi\u00f9 problemi sul gelato perch\u00e9, come disse alla classe: \u00abIl gelato mi rende veramente felice\u00bb.</p><p>\u2026</p><p>La decisione di Julia e Jeff di avere un bambino dimostra che hanno tracciato un limite oltre cui non avrebbero permesso all\u2019obiettivo di aumentare le donazioni di precludere loro la possibilit\u00e0 di dedicarsi a qualcosa di molto importante. Bernadette Young, la compagna di Toby Ord, parla quasi allo stesso modo della decisione di avere un bambino: \u00abSono felice di donare il 50% dei miei guadagni durante tutta la mia vita, ma se anche avessi scelto di non diventare madre semplicemente per aumentare questa percentuale al 55%, alla fine quel 5% mi sarebbe costato molto di pi\u00f9 di tutto il restante 50%... Sto decidendo di soddisfare un bisogno psicologico pi\u00f9 grande e di pianificare una vita che valga la pena di essere vissuta fino all\u2019ultimo\u00bb. Sia Jiulia che Bernadette sanno che non poter avere un figlio - per qualsivoglia ragione - pu\u00f2 portare alla depressione. Diventare genitore consuma senza dubbio sia denaro che tempo ma, a dispetto di tutto ci\u00f2, Bernadette evidenzia che gli altruisti efficaci possono ragionevolmente sperare che avere un bambino sar\u00e0 vantaggioso per il mondo. Sia le abilit\u00e0 cognitive che alcune caratteristiche come l\u2019empatia hanno una componente ereditaria significativa e possiamo anche aspettarci che i bambini verranno influenzati dai valori dei genitori e da ci\u00f2 che essi fanno nella vita quotidiana. Sebbene non ci sia certezza che i figli degli altruisti efficaci faranno del proprio meglio e non provocheranno danni, c\u2019\u00e8 una ragionevole probabilit\u00e0 che scelgano di comportarsi come i genitori e ci\u00f2 aiuta a ridimensionare i costi extra necessari a crescerli. Possiamo vederla da un altro punto di vista: se tutti coloro che sono preoccupati di fare del proprio meglio decidono di non avere figli, mentre quelli a cui non importa nulla degli altri continuano a procreare, possiamo veramente aspettarci che, tra qualche generazione, il mondo sar\u00e0 un posto migliore?</p><p>C\u2019\u00e8 un atteggiamento collegato nei confronti delle arti che \u00e8 comune nell\u2019AE. Singer \u00e8 netto su questo punto: non puoi davvero giustificare le arti.</p><p>Sostenere il mondo dell\u2019arte pu\u00f2 rientrare nel meglio che possiamo fare?</p><p>In un mondo che ha avuto a che fare con la povert\u00e0 estrema e altri seri problemi che stiamo ancora affrontando, sostenere il mondo dell\u2019arte sarebbe un valido obiettivo, tuttavia, per le ragioni che saranno analizzate nel capitolo 11, fare donazioni ai teatri e ai musei non \u00e8 il meglio che possiamo fare.</p><p>Ho sentito diversi altruisti efficaci affermare di conoscere tanti altruisti efficaci che si buttano gi\u00f9 o si deprimono perch\u00e9 sentono di non avere abbastanza impatto sul mondo. Come progetto puramente intellettuale \u00e8 affascinante iniziare da principi come \u201cusare la ragione e l\u2019evidenza per capire come fare il bene maggiore nel mondo\u201d e provare a derivare cose come \u201cprendersi cura dei figli\u201d o \u201cgodersi il gelato\u201d o \u201cdedicarsi alle arti o sostenerle<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb7aenslqp2d\"><sup><a href=\"#fnb7aenslqp2d\">[16]</a></sup></span>\u201d come casi speciali del principio complessivo. Ma, per quanto sia intellettualmente interessante, come guida per l\u2019esistenza rappresenta un terribile errore. La ragione per prendersi cura dei figli (ecc\u2026) non \u00e8 che ti aiuta a fare il maggior bene. \u00c8 che&nbsp;<i>dovremmo assolutamente prenderci cura dei nostri figli</i>. La ragione per cui l\u2019arte, la musica e il gelato importano non \u00e8 che ti aiutano a fare il bene maggiore. \u00c8 che siamo esseri umani - non degli automi senz\u2019anima - che rispondono in modi che non comprendiamo del tutto a cose il cui impatto su noi&nbsp;<i>stessi</i> non comprendiamo del tutto e non possiamo comprendere del tutto.</p><p>Ora, lo schema che \u00e8 stato scelto dall\u2019AE \u00e8 stato quello di inserire clausole di salvaguardia. Molti parlano di avere un budget per sensazioni che scaldino il cuore da dedicare a donazioni \u201cinefficaci\u201d che, semplicemente, li fanno stare bene. E si ritagliano un\u2019estensione&nbsp;<i>ad hoc</i> delle clausole come avere dei figli o mettere da parte un budget per i gelati o per le cene, e cos\u00ec via<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefo6seyjy0u78\"><sup><a href=\"#fno6seyjy0u78\">[17]</a></sup></span>. Tutto questo mi sembra che assomigli a delle istanze particolari, richieste con una frequenza che suggerisce che qualcosa non va. Si inizia con un singolo principio complessivo che sembra tremendamente attraente, ma ora ti trovi a dover accettare tutte le conseguenze - e diventare infelice - o iniziare, come individuo, a innestare estensioni&nbsp;<i>ad hoc&nbsp;</i>delle clausole. E viene fuori che \u00e8 terribilmente stressante di per s\u00e9. Ti trovi con persone riflessive come Nick Cammarata in ansia per la loro cena. Non \u00e8 la cena a essere il problema: \u00e8 il fatto che Cammarata sia in ansia. O Julia Wise, nel decidere se prendersi un gelato - o avere un figlio.</p><p>E questo non sorprende: da un lato hai un principio molto chiaro e potente e delle entit\u00e0 sovrumane (le organizzazioni di AE + l\u2019intera comunit\u00e0) che diffonde messaggi estremamente chiari e persuasivi su come fare il bene maggiore. Ma \u00e8 a livello individuale che le persone provano a capire e a porre limiti. Non c\u2019\u00e8 di che meravigliarsi se risulta stressante.</p><p>Questo \u00e8 un grave problema per l\u2019AE. Quando la gente prende sul serio un principio complessivo di questo genere, ottieni della gente stressata e nervosa, gente ansiosa che sta vivendo male. La corretta critica a questa situazione non \u00e8 quella che fa Singer: quella che ci\u00f2 impedisce loro di fare il bene maggiore. La critica giusta \u00e8 che \u00e8&nbsp;<i>il modo sbagliato di vivere</i>. C\u2019\u00e8 bisogno di altri fondamenti della propria esistenza. Potrebbero includere una qualche variazione del principio summenzionato, come&nbsp;<i>piccola</i> parte di un ben pi\u00f9 grande e ben sviluppata filosofia di vita. Ma deve essere decisamente smussato da un qualche altro principio, o principi. Questi principi devono possedere lo stesso tipo di forza e chiarezza: dev\u2019essere trasparente come tutte le parti si incastrino, cosicch\u00e9 il principio del \u201cmaggior bene\u201d sia fermamente limitato dagli altri principi. E potrebbe darsi il caso che il bilanciamento necessiti di essere (in parte) delegato a istituzioni sovrumane, che sia troppo da chiedere per molti individui senza causare loro uno stress tremendo. Ma se il \u201cmaggior bene\u201d \u00e8 utilizzato come pietra fondante di una filosofia di vita, sulla quale innesti le clausole addizionali&nbsp;<i>ad hoc</i>, mi sembra una ricetta per avere problemi.</p><p>Una soluzione alternativa e che credo sia stata fatta propria da molti altruisti efficaci \u00e8 una forma di AE-debole. L\u2019AE-forte prende il \u201cfare il bene maggiore che puoi\u201d in modo estremamente serio come aspetto centrale di una filosofia di vita. L\u2019AE debole utilizza tale principio pi\u00f9 come una guida. Dona l\u20191% delle tue entrate. Dona il 10% delle tue entrate, fintanto che non ti mette in difficolt\u00e0. Sii riflessivo a proposito dell\u2019impatto che il tuo lavoro ha sul mondo e consulta tante fonti differenti. Queste sono tutte cose buone da fare! La critica di questa forma \u00e8 che \u00e8 cosa buona e giusta, ma anche difficile distinguere ci\u00f2 dalla comune e antecedente nozione che molti possiedono, ovvero \u201cvivi bene e prova a fare del bene al mondo\u201d. Come la mette Amia Srinivasan<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxl74tp62z8l\"><sup><a href=\"#fnxl74tp62z8l\">[18]</a></sup></span>:</p><p>Pi\u00f9 sono incerte le cifre, meno sono utili i calcoli e pi\u00f9 ci stiamo fidando del senso comune per capire che cosa abbia senso fare. Abbiamo davvero bisogno di un modello sofisticato che ci dica che non dovremmo trafficare nei mutui&nbsp;<i>subprime</i> [nda: s\u00ec], o che il sistema carcerario americano abbia bisogno di essere corretto, o che potrebbe valere la pena di dedicarsi alle politiche elettorali se si \u00e8 sicuri di non farlo solamente per proprio interesse? Pi\u00f9 complesso \u00e8 il problema che l\u2019altruismo efficace prova ad affrontare - cio\u00e8, pi\u00f9 profondamente si interfaccia con il mondo in quanto entit\u00e0 politica -, meno il suo contributo diviene distintivo. Gli altruisti efficaci, come chiunque altro, si scontrano con il fatto che il mondo sia incasinato e, come chiunque altro voglia renderlo migliore, devono fare ci\u00f2 che gli sembra sia meglio, senza un senso finale di come le cose potrebbero andare o una qualunque garanzia che stiano facendo la scelta giusta.</p><p>Pi\u00f9 preoccupante dell\u2019incapacit\u00e0 del modello di dirci alcunch\u00e9 di utile una volta che ci muoviamo al di fuori del reame circoscritto di un intervento controllato \u00e8 la sua suscettibilit\u00e0 a essere usato per dire esattamente ci\u00f2 che vogliamo sentire.</p><p>\u2026</p><p>L\u2019altruismo efficace fa suo lo spirito dell\u2019argomento di Singer, ma ci protegge dal fuoco diretto delle sue conclusioni\u2026 Invece di degradare le nostre vite a un livello di sussistenza, siamo incoraggiati a iniziare con il tradizionale tributo del 10%, per poi aumentare ogni anno. Dunque l\u2019altruismo efficace schiva una delle obiezioni pi\u00f9 comuni nei confronti dell\u2019utilitarismo: che chiede troppo da noi. Ma non \u00e8 chiaro come questa schivata si attui. MacAskill dice che gli altruisti efficaci - come gli utilitaristi - si impegnano a fare il maggior bene possibile, ma afferma anche che va bene anche godersi uno \u201cstile di vita comodo\u201d, fintantoch\u00e9 si continua a donare molto in beneficenza. O l\u2019altruismo efficace, come l\u2019utilitarismo, ci chiede di fare il maggior bene possibile, o ci chiede pi\u00f9 banalmente di provare a rendere le cose migliori. Il primo caso \u00e8 genuinamente radicale, richiedendoci di revisionare la nostra vita quotidiana in modo inimmaginabili per i pi\u00f9 (Singer continua a ribadire la necessit\u00e0 precisamente di questa revisione nel suo recente libro \u201cLa cosa migliore che tu puoi fare\u201d e Strangers Drowning (\u201cestranei che affogano\u201d) di Larissa MacFarquhar \u00e8 un elenco di \u201caltruisti estremi\u201d che hanno risposto alla chiamata). Il secondo caso - che si debba cercare di rendere le cose migliori - \u00e8 condiviso da ogni sistema morale plausibile e da persona perbene. Se l\u2019altruismo efficace \u00e8 semplicemente attivo nel renderci pi\u00f9 efficaci quando proviamo ad aiutare gli altri, \u00e8 difficile fargli delle obiezioni. Ma in quel caso \u00e8 anche difficile capire che cosa offra per avere delle nuove intuizioni morali, e ancora di pi\u00f9 come possa essere l\u2019ultimo movimento sociale di cui avremo mai bisogno.</p><p>Condivido molto di ci\u00f2 che \u00e8 scritto in questo passo. Penso per\u00f2 che ci sia un\u2019ottima risposta a tono per l\u2019ultimo commento di Srinivasan: \u201cma in quel caso \u00e8 anche difficile capire che cosa offra [l\u2019AE] per avere delle nuove intuizioni morali, e ancora di pi\u00f9 come possa essere l\u2019ultimo movimento sociale di cui avremo mai bisogno.\u201d Ora, se fosse un argomento puramente teorico, sarei d\u2019accordo con lei. Tuttavia, gli altruisti efficaci l\u2019hanno fatto in pratica: hanno creato delle istituzioni che sono&nbsp;<i>centrate</i> per davvero su questa idea. E ci\u00f2 ha valore ed \u00e8 un\u2019innovazione.</p><h2><strong>Critiche interne al principio dell\u2019AE</strong></h2><p>Torniamo di nuovo ai principi dell\u2019AE: \"L\u2019altruismo efficace significa usare l\u2019evidenza e la ragione per fare il maggior bene possibile nel mondo\". Ho discusso i sintomi pratici dei problemi impliciti di questo principio. Ho anche discusso i problemi nel porre limiti al principio. Spostiamoci ora alle critiche dirette al principio stesso.</p><p>Molti di questi problemi sono i soliti utilizzati dalle persone per attaccare l\u2019utilitarismo morale. Sfortunatamente, sono ben lontano dall\u2019essere un esperto di questi argomenti. Spiegher\u00f2 quindi molto velocemente la mia prospettiva: il \u201cbene\u201d non \u00e8 intercambiabile e, quindi, qualsiasi quantificazione \u00e8 un\u2019indebita semplificazione. A dire il vero, non \u00e8 solamente un\u2019indebita semplificazione: \u00e8 completamente sbagliato e davvero fuorviante. Certamente, questa quantificazione \u00e8 spesso un comodo strumento per scendere a compromessi. Pu\u00f2 anche rivelarsi utile per proporre argomenti morali che possano suggerire la strada (ma non trovarla). Tuttavia, non ha un ruolo fondamentale. Di conseguenza, idee come \u201caumentare il bene\u201d o \u201cil bene maggiore\u201d sono utili come utili strumenti, ma sarebbe un errore ritenerle fondamentali. Inoltre, l\u2019idea che esista \u201cIL bene\u201d porta a sua volta a delle perplessit\u00e0. Esistono diversi beni, che sono di per s\u00e9 non misurabili e incommensurabili, n\u00e9 si possono in qualche modo unire.</p><p>Credo che questi attacchi vadano a segno. Come strumento pratico e generativo, l\u2019utilitarismo \u00e8 utile. Non sono per\u00f2 un utilitarista come se fosse un fatto fondamentale sul mondo.</p><p>(Toccando questo argomento: \u00e8 interessante chiedersi che verit\u00e0 ci sia nella passata affermazione del Segretario Generale dell\u2019ONU Hammarskj\u00f6ld per cui: \u201c\u00c8 pi\u00f9 nobile donare completamente te stesso a un singolo individuo che lavorare diligentemente per la salvezza delle masse\u201d. Questa non \u00e8, per essere gentili, una prospettiva dell\u2019AE. Credo comunque che abbia in s\u00e9 una parte importante di verit\u00e0).</p><p>Andando ai bordi, la parte del principio che recita \u201cusare l\u2019evidenza e la ragione\u201d \u00e8 notevole. Vi \u00e8 un cambiamento sempre in atto nel modo in cui l\u2019umanit\u00e0 concepisce \u201cl\u2019evidenza e la ragione\u201d, con qualche occasionale cambiamento netto. A dire il vero, molti dei pi\u00f9 importanti traguardi dell\u2019umanit\u00e0 sono stati cambiamenti radicali di ci\u00f2 che riteniamo \u201cevidenza e ragione\u201d. Gli standard del secolo XI di \u201cevidenza e ragione\u201d sono molto diversi da quelli odierni. Immagino che nel secolo XXXI gli standard saranno nuovamente molto diversi. Ovviamente, questo punto pu\u00f2 essere risolto mettendoci qualche pezza. Si potrebbe occuparsene modificando il principio in \u201ci nostri attuali migliori standard di evidenza e ragione per fare il maggior bene possibile nel mondo\u201d, enfatizzando la consapevolezza del fatto che queste cose cambino.</p><h2><strong>Varie ed eventuali</strong></h2><p>Questi sono quattro temi che mi piacerebbe trattare approfonditamente, ma ho deciso di lasciarli fuori dagli obiettivi di queste note. Li menzioner\u00f2 solamente, con il rischio di confondere il problema con un breve resoconto troppo-facilmente-male-interpretabile. Tutti questi quattro temi hanno davvero bisogno di un lungo resoconto.</p><p><strong>Decifrabilit\u00e0 ( \u201cIllegibility\u201d):</strong> Un argomento comune contro l\u2019AE \u00e8 che spesso sottovaluta l\u2019attivit\u00e0 indecifrabile. La tipica risposta da AE \u00e8 un\u2019altra forma di judo dell\u2019AE, l\u2019urlo di battaglia dei burocrati: rendiamola decifrabile<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref98dndc9ydqh\"><sup><a href=\"#fn98dndc9ydqh\">[19]</a></sup></span>! Dobbiamo semplicemente determinare quanto bene un nuovo campo scientifico / una festa di compleanno di un bambino / dei nuovi tipi di scultura fanno. E tuttavia, pi\u00f9 forme di attivit\u00e0 rendiamo decifrabili, pi\u00f9 la penombra dell\u2019indecifrabilit\u00e0 si modifica e cresce, e gran parte del lavoro creativo pi\u00f9 profondo dei cambiamenti trasformativi nella vita sono fatti da persone in questa penombra<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsiy47vgguw\"><sup><a href=\"#fnsiy47vgguw\">[20]</a></sup></span>. In molti tipi di lavoro, quando i risultati che ottieni sono i risultati che vuoi - in realt\u00e0, quando sono risultati che puoi anche solo comprendere - hai perduto una grande opportunit\u00e0. \u201cL\u2019evidenza e la ragione\u201d iniziano a venire meno, per definizione, nella penombra dell\u2019indecifrabilit\u00e0. Sospetto anche che, come tratto fondamentale di personalit\u00e0, io sia pi\u00f9 felice in quella penombra. Per questo motivo fatico cos\u00ec tanto a fare mio l\u2019AE: mi sembra un linguaggio straniero, dove sono implicite delle assunzioni che non comprendo. Allo stesso modo, quando parlo di indecifrabilit\u00e0 con altruisti efficaci, spesso mi guardano come se mi fosse cresciuta un\u2019altra testa. Vedono l\u2019indecifrabilit\u00e0 come qualcosa che debba essere conquistato e minimizzato, mentre io la vedo come un fatto fondamentale e ineliminabile del mondo per come funziona. A ben vedere, pi\u00f9 zone di indecifrabilit\u00e0 conquisti, pi\u00f9 ne dovrai conquistare.</p><p><strong>\"L\u2019AE-\u00e8-un-culto/l\u2019AE-\u00e8-una-religione\"</strong>: Queste sono affermazioni comuni, utilizzate di solito come componente degli attacchi dei critici. Credo siano utilizzate spesso senza pensarci o maliziosamente, facendo leva sulla connotazione peggiorativa di \u201cculto\u201d. \u00c8 vero, il movimento di AE ha delle caratteristiche che si sovrappongono a quelle di un culto; la stessa cosa vale per chi fa scalate, per chi apprezza la musica di Bob Dylan e cos\u00ec via con altre attivit\u00e0. La parte sostanziosa a cui fare attenzione \u00e8 questa: come accade per qualunque movimento forte, attraente e in crescita, l\u2019AE pu\u00f2 attirare farabutti carismatici che vogliono approfittarsi degli altri. Questo \u00e8 un serio problema, dal quale bisogna guardarsi. Non penso tuttavia che l\u2019AE rischi di sottovalutarlo, se confrontato con qualsiasi altra forte ideologia.</p><p><strong>Lungoterminismo / x-risk [cio\u00e8&nbsp;</strong><i><strong>rischi esistenziali</strong></i><strong>] / Sicurezza dell\u2019IA:</strong> Questo richiede un gruppo di note a parte. Sono ampiamente a favore del lavoro sul rischio esistenziale in generale. Ammiro, per esempio, il recente libro di Toby Ord su questo argomento. Non ho forti opinioni su gran parte del lavoro che viene svolto sulla sicurezza dell\u2019IA, anche se ci sono delle persone che stanno facendo un buon lavoro e le attivit\u00e0 adiacenti (sull\u2019equit\u00e0, sull'interpretabilit\u00e0, sulla comprensibilit\u00e0\u2026) hanno un grande valore.</p><p><strong>Atmosfera ed estetica:</strong> Una mia amicizia ha sottolineato che l\u2019AE ha un\u2019atmosfera molto particolare e piuttosto insolita, diversa da tanti altri contesti culturali. Questo sembra sia vero che interessante. Non so esattamente che farci. Idem per l\u2019estetica: l\u2019AE tende a un\u2019estetica molto particolare e strumentale. \u00c8 interessante pensare al come l\u2019arte si presenta: storicamente, gli approcci primariamente strumentali all\u2019arte quasi sempre hanno portato a pessima arte. Sarebbe stupendo assistere a un movimento artistico di AE che scaturisca da qualcosa che non sia strumentale!</p><h2>&nbsp;</h2><h2><strong>Tirando le somme</strong></h2><p>L\u2019AE \u00e8 una filosofia di vita in grado di ispirare e dare significato. Invita le persone a confrontarsi intensamente con qualche idea di un bene maggiore, a contribuire a tale bene maggiore e a metterlo al centro della propria vita. L\u2019AE-in-pratica ha fatto direttamente tantissimo bene al mondo, migliorando la vita delle persone. \u00c8 ottimo avere uno schema per discutere su \u201ccome fare il bene maggiore\u201d pronto all\u2019uso e, presumibilmente, di valore. L\u2019AE-in-pratica mette a disposizione anche una solida comunit\u00e0 e un senso di appartenenza e di valori condivisi per molte persone. Come i pionieri morali, l\u2019AE sta rendendo disponibile un importante insieme di nuovi beni comuni.</p><p>Tutto questo rende l\u2019AE attraente come filosofia di vita, dando orientamento, significato e un nucleo chiaro e solido, con istituzioni a sostegno. Sfortunatamente, l\u2019AE-forte \u00e8 una cattiva filosofia di vita, con confini poco chiari che causano grande angoscia alle persone e che non va incontro ai bisogni basilari. L\u2019AE-in-pratica \u00e8 troppo centralizzato, troppo concentrato sul vantaggio assoluto. Il mercato spesso fa un lavoro migliore nel fornire certi tipi di beni privati (o privatizzabili). Comunque, l\u2019AE-in-pratica probabilmente \u00e8 migliore nel fornire alcuni tipi di beni pubblici di quanto facciano alcune istituzioni. L\u2019AE si appoggia troppo al carisma online: vistosi, ma spesso inconsistenti discussioni su temi come l\u2019argomento della simulazione, il rischio esistenziale e la sicurezza dell\u2019IA tendono a dominare la conversazione, a danno di lavori pi\u00f9 sostanziosi (ci\u00f2 non significa che non ci siano buone discussioni su questi argomenti). L\u2019AE-in-pratica \u00e8 troppo vicino agli attuali sistemi di potere e fa poco per metterli in discussione o modificarli. Appropriarsi del termine \u201cefficace\u201d \u00e8 un\u2019astuta mossa di marketing e per costruire una comunit\u00e0, ma intellettualmente maliziosa. L\u2019AE vede l\u2019indecifrabilit\u00e0 come un problema da risolvere, non come una condizione fondamentale. Per questo funziona male in alcuni contesti estetici o creativi. L\u2019utilitarismo morale \u00e8 un utile strumento pratico, ma limitato, confondendo la quantificazione utile per fare dei compromessi con un fatto fondamentale del mondo.</p><p>Ho fortemente criticato l\u2019AE in queste note, ma non ho fornito alcuna alternativa che sia chiara e strutturalmente articolata. \u00c8 come dire che una dieta a base di gelato e barrette di cioccolato non sia l\u2019ideale, senza fornire dei cibi migliori. Pu\u00f2 avere senso, ma non si pu\u00f2 subito passare all\u2019azione. Dato l\u2019enorme bisogno emotivo delle persone di affidarsi a un sistema che, con forza, dia loro significato, non mi aspetto che abbia un grande impatto su quelle persone. \u00c8 troppo facile allontanare con un colpo di mano i problemi, o ignorarli come se fossero cose che possono essere risolte prevedendo qualche clausola ed eccezione. Ma scrivere queste note mi ha aiutato a comprendere meglio sia perch\u00e9 io non sia un altruista efficace, sia perch\u00e9 penso che il principio dell\u2019AE, con qualche modifica molto rilevante, potrebbe un elemento di valore in una pi\u00f9 ampia filosofia di vita. Ma non capisco ancora cosa sia quella filosofia di vita.</p><h2><strong>Guardandosi intorno</strong></h2><p>Suggerisco di dare un\u2019occhiata a&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/criticism-of-effective-altruism\">critiche all\u2019altruismo efficace</a> e a queste&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/HzyYoLK2ERTnDmrjB/four-categories-of-effective-altruism-critiques\">quattro categorie di critiche all\u2019AE</a>. Quando ho finito la prima bozza di queste note, \u00e8 stata indetta una competizione per&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/8hvmvrgcxJJ2pYR4X/announcing-a-contest-ea-criticism-and-red-teaming\">criticare l\u2019AE</a>. Sono curioso di vedere quali saranno i contributi. Forse \u00e8 un peccato che la struttura della competizione ruoti intorno a idee preesistenti dell\u2019AE.</p><h2><strong>Riconoscimenti</strong></h2><p>Ringrazio molto persone per le conversazioni che hanno cambiato o reso pi\u00f9 informato il mio modo di pensare all\u2019AE, tra cui: Marc Andreessen, Nadia Asparouhova, Alexander Berger, David Chapman, Patrick Collison, Julia Galef, Anastasia Gamick, Danny Goroff, Katja Grace, Spencer Greenberg, Robin Hanson, David Krakauer, Rob Long, Andy Matuschak, Luke Muehlhauser, Chris Olah, Catherine Olsson, Toby Ord, Kanjun Qiu e Jacob Trefethen. Ogni buona idea qui \u00e8 in gran parte loro. Naturalmente, sono interamente responsabile di ogni errore :-P! Un ringraziamento speciale ad Alexander Berger, Anastasia Gamick, Katja Grace, Rob Long, Catherine Olsson e Toby Ord: conversazioni con chi ha direttamente ispirato queste note. Mi aspetto che, comunque, molti di loro siano in forte disaccordo con molto di ci\u00f2 che \u00e8 stato scritto qui! E grazie a Nadia Asparouhova e David Chapman per aver dato un loro riscontro alle bozze di queste note. Grazie a Keller Scholl per avere indicato un errore nella prima condivisione di questo saggio.<br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnpwvat649z\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnpwvat649z\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Helen Toner ha un&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FpjQMYQmS3rWewZ83/effective-altruism-is-a-question-not-an-ideology\">contro argomento</a> ben pensato all\u2019idea che l\u2019AE sia un\u2019ideologia, asserendo che la maggior parte delle ideologie punta a fornire risposte, mentre l\u2019AE verte perlopi\u00f9 su una domanda (\u201ccome fare pi\u00f9 bene\u201d?). Il saggio \u00e8 molto buono, ma ultimamente mi sento a mio agio nell\u2019usare \u201cideologia\u201d per descrivere l\u2019AE. L\u2019AE con forza presume che tu&nbsp;<i>dovresti</i> puntare al bene maggiore, usando al meglio il tuo giudizio sulla base delle opportunit\u00e0 e delle informazioni disponibili. In questo senso,&nbsp;<i>sta</i> fornendo una risposta. Comunque, come discusso in seguito, uno degli aspetti pi\u00f9 attraenti di AE - e uno di quelli insoliti tra le ideologie - \u00e8 che una grande fetta della risposta \u00e8 in mutamento e viene costantemente rinegoziata.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn59zgjbwnop7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref59zgjbwnop7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Far\u00f2 spesso riferimento a individui che \u201csono\u201d altruisti efficaci. Naturalmente, la questione dell\u2019identit\u00e0 \u00e8 insidiosa. Ci sono molte persone - tra le quali il sottoscritto - che sono vicine alla comunit\u00e0 di AE, ma non direi che ne facciano parte (io, di certo, non mi considero un altruista efficace). Una delle mie battute preferite sulla comunit\u00e0 razionalista (tra l\u2019altro, vicina all\u2019AE) \u00e8 che i suoi membri dicono sempre \u201cnon sono un razionalista, ma\u2026\u201d. Non \u00e8 altrettanto vero per gli altruisti efficaci, ma c\u2019\u00e8 del vero anche qui.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fns8gosup4ep\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefs8gosup4ep\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Queste idee sono frutto di conversazioni con Catherine Olsson e Rob Long</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1iwxk8ddnxl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1iwxk8ddnxl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Peter Singer, \"The Most Good You Can Do\" (2015) [ed. italiana \u201cLa cosa migliore che tu puoi fare\u201d, 2016].</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnv4i13c0r67\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefv4i13c0r67\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\"Psiconauta morale\" mi \u00e8 stato suggerito da Catherine Olsson.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnip50r1grtke\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefip50r1grtke\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In questi e altri esempi non \u00e8 chiaro chi sia il pioniere morale originale. Di certo l\u2019autore del \u201cSermone\u201d non ha \u201cscoperto\u201d queste idee da solo, ma provengono da una traduzione, da un qualche atto di scoperta collettiva. \u00c8 anche vero che, solo perch\u00e9 qualcuno \u00e8 un pioniere morale, ci\u00f2 non significa che sia una brava persona in senso assoluto! In tal senso il termine \u201ceroe\u201d risulta forse inappropriato.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmkktg9cwb6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmkktg9cwb6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>E wow, se lo sono. Questa \u00e8 per me una seccatura personale, e dove penso gli AE si allontanino nettamente dal buonsenso. Newton, Darwin, e Einstein non sono arrivati alle loro grandi svolte usando studi controllati randomizzati e meta-analisi. Picasso non dipingeva in questo modo. Questi studi e le meta-analisi costituiscono una piccola parte dell\u2019arsenale della scienza, non il pinnacolo. A ben vedere, la&nbsp;<i>metodologia</i> in questo senso non \u00e8 mai il pinnacolo.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fniyegzwejrss\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefiyegzwejrss\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Mi piace intrattenermi con l\u2019idea che sia un approccio popperiano a \u201cil bene\u201d. Le congetture e le smentite morali, la logica della scoperta etica. Incidentalmente, potreste affermare che \u201cche cos\u2019\u00e8 buono?\u201d \u00e8 esattamente l\u2019ambito dell\u2019etica e della filosofia morale. L\u2019AE presumibilmente aggiunge componenti (imperfetti) applicati e sperimentali dal mondo a questi temi.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxnbqa2w5kl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxnbqa2w5kl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Forse abbiamo bisogno di un \u201cCenter for Effective Effective Altruism\u201d [ovvero \u201cCentro per l\u2019Efficace Altruismo Efficace\"]? O di un \u201cGivewellwell\u201d [letteralmente \u201cBuonGiveWell\u201d] che valuti l\u2019efficacia della valutazione di efficacia delle organizzazioni.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzq4j7xta05h\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzq4j7xta05h\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Una mia amicizia ha notato come alcune organizzazioni di AE siano passate attraverso l\u2019acceleratore di startup YCombinator. Ho chiesto come fosse andata. Hanno fatto una pausa, per poi dire con una risata che non ne erano sicuri, ma era notevole che le organizzazioni fossero diventate \u201cmolti pi\u00f9 interessate ai grafici che vanno verso l\u2019alto e verso destra\u201d. (In generale, credo che questo sia positivo. Non ne sono sicuro, ma mi piace questa storia).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6b2whof1rch\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6b2whof1rch\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u00c8 interessante immaginare l\u2019AE principalmente come un mezzo per procurarci beni pubblici che sono poco forniti dal mercato. Una critica un po\u2019 pi\u00f9 profonda su questo \u00e8 che il mercato fornisce un potente insieme di segnali che aggregano la conoscenza decentralizzata e aiutato le persone ad agire a partire dal loro vantaggio comparativo. L\u2019AE, a confronto, \u00e8 relativamente accentrato e si concentra sul vantaggio assoluto. Tende a centralizzare le azioni delle persone e ad aggravare gli errori. \u00c8 inoltre probabilmente un modello ben pi\u00f9 debole di allocazione delle risorse, anche se ha il vantaggio di concentrarsi sui beni pubblici. Ogni tanto mi sono fatto delle domande su un \u201cAE ultraliberale\u201d, pi\u00f9 orientato al mercato, ma che corregga sistematicamente i ben noti fallimenti di quest\u2019ultimo.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6a8i3td3c6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6a8i3td3c6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Questo sembra valere meno per l\u2019AE che per molte altre organizzazioni e movimenti (ma non tutte). Resta comunque motivo di preoccupazione che le organizzazioni di AE (perlopi\u00f9) non abbiano alcuna data di scadenza, n\u00e9 che esista un modello competitivo che assicuri che organizzazioni migliori crescano floride e superino quelle meno efficaci. A tal proposito, ho sentito dire che la prima generazione di una religione di successo ha inizio con un profeta, mentre la seconda \u00e8 gestita da un burocrate molto bravo. Questo \u00e8 forse vero anche in altri contesti.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnrp9mw3szkbo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefrp9mw3szkbo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>C\u2019entra fino a un certo punto, ma: trovo a volte molti nuovi altruisti efficaci un po\u2019 troppo moralisti e sicuri di s\u00e9 - e a volte un po\u2019 troppo ferventi, sia nei confronti dell\u2019AE, sia nei confronti di una particolare area di cause (\u201cperch\u00e9 stai perdendo il tuo tempo facendo questo, dovresti lavorare sulla sicurezza dell\u2019IA\u201d, detto da qualcuno che pensa di saperne di IA, ma non lo sa e non ha idee di alcun valore sulla sicurezza dell\u2019IA). Questo varia dal divertente e dal leggermente fastidioso all\u2019esasperante. Questo schema, comunque, \u00e8 comune a molti movimenti ideologici e dubito sia particolarmente un problema dell\u2019AE. Puoi trovare problemi simili nell\u2019ambientalismo, nelle criptovalute, nel liberalismo, in molte religioni, nel comunismo e in tante altre ideologie.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbo7jlea1dgi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbo7jlea1dgi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Con l\u2019eccezione, cruciale, della partecipazione nel mercato e dell\u2019essere sottoposti a un governo. \u00c8 un comandare attraverso la tecnocrazia. \u00c8 forse indicativo che la partecipazione nel mercato sia a sua volta posta in termini di scelta. Ma introduce una idea di un gruppo di scelte \u201cnaturali\u201d disponibili, attraverso concetti come il mercato del lavoro e il mercato di beni e servizi. Non c\u2019\u00e8 nulla di naturale in tutto questo.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnr1jopxxfb3\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefr1jopxxfb3\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Non sono certo che \"dovere\" sia il termine che si usa di solito, ma implica abbastanza bene il senso emotivo che spesso colgo. Non esclude la gioia e la vitalit\u00e0, ma non sono la priorit\u00e0.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb7aenslqp2d\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb7aenslqp2d\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Sospetto che nessuna societ\u00e0, mai, che sia stata sana non abbia investito una quantit\u00e0 significativa di tempo e risorse nelle arti.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fno6seyjy0u78\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefo6seyjy0u78\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Un saggio intuitivo e comprensivo su questo filone \u00e8&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/zu28unKfTHoxRWpGn/you-have-more-than-one-goal-and-that-s-fine\">You have more than one goal, and that's fine</a> [\u201cHai pi\u00f9 di un obiettivo e va bene cos\u00ec] di Julia Wise (2019). [ndt: lo vedremo nella settimana 8]</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxl74tp62z8l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxl74tp62z8l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Amia Srinivasan,&nbsp;<a href=\"https://www.lrb.co.uk/the-paper/v37/n18/amia-srinivasan/stop-the-robot-apocalypse\">Stop the Robot Apocalypse</a> [\u201cFermare l\u2019apocalisse robotica\u201d], London Review of Books (2015).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn98dndc9ydqh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref98dndc9ydqh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>James Scott, \"Seeing Like a State\" [\u201cVedere come uno stato\u201d] (1998).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsiy47vgguw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsiy47vgguw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Cf. il concetto strettamente correlato di&nbsp;<a href=\"https://meaningness.com/nebulosity\">nebulosit\u00e0</a> formulato da David Chapman.</p></div></li></ol>", "user": {"username": "EA Italy"}}, {"_id": "etEd4EfQeKwMK5L8f", "title": "Opinioni indipendenti", "postedAt": "2023-01-18T11:21:52.914Z", "htmlBody": "<p><i>This is an Italian translation of </i><a href=\"https://forum.effectivealtruism.org/posts/2WS3i7eY4CdLH99eg/independent-impressions\"><i><strong>Independent impressions</strong></i></a></p><p>La tua&nbsp;<strong>opinione indipendente</strong> su qualcosa \u00e8 essenzialmente ci\u00f2 che tu penseresti su quella cosa se non revisionassi le tue credenze in seguito al disaccordo con altre persone - ovvero, se tu non prendessi in considerazione la tua conoscenza di ci\u00f2 che le altre persone pensano e quanto degno di fiducia sembri il loro giudizio su questo argomento. La tua opinione indipendente pu\u00f2 prendere atto delle&nbsp;<i>ragioni&nbsp;</i>di queste persone che le portano ad avere certe credenze (nella misura in cui conosci tali ragioni), ma non il&nbsp;<i>mero fatto</i> che credono in ci\u00f2 che credono.</p><p>Nel frattempo, la tua&nbsp;<strong>credenza-tutto-considerato</strong> pu\u00f2 (e probabilmente dovrebbe!) anche prendere in considerazione il disaccordo con altri.</p><p>Armato di questo concetto, provo ad aderire a queste regole epistemiche e&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/discussion-norms\">di discussione</a>. Credo che altri farebbero bene a fare lo stesso.</p><ul><li>Provo a&nbsp;<strong>tenere traccia delle mie opinioni indipendenti&nbsp;</strong>separandole dalle mie credenze-tutto-considerato.</li><li>Provo a&nbsp;<strong>sentirmi a mio agio con il comunicare le mie opinioni indipendenti</strong>, anche se so che sono diverse da quelle di persone con pi\u00f9 competenze sull\u2019argomento.</li><li>Provo a&nbsp;<strong>essere chiaro su se, in un dato momento, io stia riportando la mia opinione indipendente o la mia credenza-tutto-considerato</strong>.</li></ul><p>Una ragione di questo mucchio di regole \u00e8 l\u2019evitare&nbsp;<a href=\"https://www.lesswrong.com/tag/information-cascades\">cascate di informazione</a>.</p><p>All\u2019opposto, quando prendo davvero&nbsp;<i>delle decisioni</i>,&nbsp;<strong>cerco sempre di prenderle in base alle mie credenze-tutto-considerato</strong>.</p><p>Per esempio, la mia opinione indipendente \u00e8 che sia plausibile che una&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/dystopia\">distopia impossibile da abbattere</a> sia pi\u00f9 probabile dell\u2019estinzione e che dovremmo dare la priorit\u00e0 a questo rischio molto pi\u00f9 di come facciamo ora. Ma questa idea sembra relativamente infrequente tra le persone che hanno riflettuto molto sui&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/AJbZ2hHR4bmeZKznG/venn-diagrams-of-existential-global-and-suffering\">rischi esistenziali.</a> Questa osservazione porta la mia credenza-tutto-considerato di una qualche misura lontano dalla mia opinione indipendente e verso quella che molte persone sembrano condividere. E questa credenza-tutto-considerato \u00e8 ci\u00f2 che guida la mia ricerca e le mie decisioni di carriera. Ma credo sia ancora utile per me tenere traccia della mia opinione indipendente e tornarci su ogni tanto, altrimenti le comunit\u00e0 di cui io faccio parte potrebbero ritrovarsi con credenze esageratamente radicate e omogenee.</p><p>&nbsp;</p><hr><p>&nbsp;</p><p><i>Questo termine, questo concetto e queste norme che ho suggerito non sono tutte farina del mio sacco - vedi in particolare&nbsp;</i><a href=\"https://www.overcomingbias.com/2008/04/naming-beliefs.html\"><i>Naming beliefs</i></a><i>,&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/WKPd79PESRGZHQ5GY/in-defence-of-epistemic-modesty?commentId=cubpmCn7XJE5FQYEq\"><i>questo commento</i></a><i> e diversi post taggati&nbsp;</i><a href=\"https://forum.effectivealtruism.org/topics/epistemic-humility\"><i>Epistemic humility</i></a><i> [\u201cumilt\u00e0 epistemica\u201d], soprattutto&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/jhexFncC9KN76Z5ki/ea-concepts-share-impressions-before-credences\"><i>questo</i></a><i>. Ma io puntavo a una descrizione chiara e concisa di questo specifico insieme di norme, cosicch\u00e9 potessi riferirmi a esse ogni volta che affermo di riportare la mia opinione indipendente o chiedo a qualcuno se un pensiero che stanno comunicando sia la sua opinione indipendente o la sua credenza-tutto-considerato.</i></p>", "user": {"username": "EA Italy"}}, {"_id": "hLRCykshFpcGG8bfq", "title": "Tu cosa ne pensi?", "postedAt": "2023-01-18T11:18:58.543Z", "htmlBody": "<p><i>This is an Italian translation of </i><a href=\"https://forum.effectivealtruism.org/posts/zGavnmS5hCC4mDHS8/what-do-you-think\"><strong>What do you think?</strong></a></p><blockquote><p><i>\u201c\u00c8 una delle tristi ovviet\u00e0 della condizione umana che non ci sia una buona idea, un nobile movente o un valido suggerimento che non possa (e che infine non sia) fatto proprio e imbastardito dai fanatici\u2026 Una manifestazione di questa tendenza \u00e8 nell\u2019idea di \u201caltruismo efficace\u201d.</i></p></blockquote><p>-&nbsp;<a href=\"https://ssir.org/articles/entry/the_elitist_philanthropy_of_so_called_effective_altruism#:~:text=By%20contrast%2C%20defective%20altruism%20is,and%20beneficiaries%20against%20one%20another.\"><u>K. Berger &amp; R. M. Penna</u></a></p><p>In questo capitolo ti daremo del tempo per riflettere su ci\u00f2 che pensi dell\u2019altruismo efficace e sulle potenziali priorit\u00e0 di cui hai sentito parlare finora.&nbsp;</p><p>Dedichiamo a questo una sezione perch\u00e9, in qualsiasi misura ci sbagliamo, accorgerci dei nostri errori e correggerli ci porter\u00e0 a fare pi\u00f9 bene. Confrontarsi onestamente con buone controargomentazioni (sia interne, sia esterne alla comunit\u00e0 di AE) pu\u00f2 aiutarci a evitare il&nbsp;<a href=\"https://www.lesswrong.com/tag/confirmation-bias#:~:text=Confirmation%20bias%20(also%20known%20as,beliefs%20or%20hypotheses%20%5B1%5D.\">bias di conferma</a> e il pensiero di gruppo e a essere pi\u00f9 vicini a identificare i modi pi\u00f9 efficaci per fare del bene.</p><p>Critiche di questo tipo hanno portato a cambiamenti importanti in ci\u00f2 che molti altruisti efficaci fanno. Ad esempio,&nbsp;<a href=\"https://www.vox.com/future-perfect/2019/12/20/21009803/givewell-survey-kenya-ghana-saving-lives-poverty\">GiveWell ha intervistato un campione di individui demograficamente simile ai destinatari dei programmi che sostiene su come farebbero dei compromessi morali</a>, in risposta alla critica per cui non dovrebbe fare compromessi morali per conto delle persone che le organizzazioni raccomandate da GiveWell aiutano.</p><p>Un concetto chiave in questo caso \u00e8 l\u2019importanza di farsi delle opinioni indipendenti. Nel lungo periodo \u00e8 probabile che sviluppi una comprensione pi\u00f9 profonda delle questioni importanti se rifletti sugli argomenti autonomamente. Tuttavia (visto che non puoi analizzare ogni cosa) a volte pu\u00f2 avere senso fare riferimento ad altri quanto prendi le tue decisioni.</p>", "user": {"username": "EA Italy"}}, {"_id": "gEExWiqRnvkGbBpPc", "title": "[Opzionale] Approfondimenti sui rischi dell\u2019IA (materiali in inglese)", "postedAt": "2023-01-18T11:16:24.026Z", "htmlBody": "<p><i>This is an Italian translation of </i><a href=\"https://forum.effectivealtruism.org/posts/Cf6tNAhDbQFvAwbAg/more-to-explore-on-risks-from-artificial-intelligence\"><i><strong>More to explore on 'Risks from Artificial Intelligence'</strong></i></a></p><h3><strong>Lo sviluppo dell\u2019intelligenza artificiale</strong></h3><ul><li><a href=\"https://tinyurl.com/vsj22235\">AlphaGo - The Movie - DeepMind</a> - Documentario sull\u2019intelligenza artificiale, l\u2019antichissimo gioco del Go e cosa possiamo imparare sulle potenzialit\u00e0 future delle IA. (Filmato - 1 ora e 30 minuti)</li><li><a href=\"https://tinyurl.com/sumpuw\">The Artificial Intelligence Revolution: Part 1</a> - Una divertente e interessante esplorazione dell\u2019intelligenza artificiale dal famoso blogger Tim Urban. (45 minuti)</li></ul><h3><strong>Altre risorse sull\u2019allineamento dell\u2019intelligenza artificiale</strong></h3><ul><li><a href=\"https://www.agisafetyfundamentals.com/\">AGI Safety Fundamentals Curricula&nbsp;</a></li><li><a href=\"https://forum.effectivealtruism.org/posts/Ayu5im98u8FeMWoBZ/my-personal-cruxes-for-working-on-ai-safety#Problems_solve_themselves\">My personal cruxes for working on AI safety</a> (65 minuti)</li><li><a href=\"https://tinyurl.com/erkwmdhr\">Professor Stuart Russell on the flaws that make today\u2019s AI architecture unsafe &amp; a new approach that could fix it</a> (Podcast - 2 ore 15 minuti)</li><li><a href=\"https://tinyurl.com/m8fzdtc3\">Some Background on Our Views Regarding Advanced Artificial Intelligence - Open Philanthropy Project</a> - Una spiegazione del perch\u00e9 ci sia una seria possibilit\u00e0 che il progresso dell\u2019intelligenza artificiale potrebbe essere comparabile alla transizione dall\u2019era neolitica alla rivoluzione industriale. (1 ora)</li><li><a href=\"https://tinyurl.com/25y25452\">The Precipice</a> (25 minuti)</li><li><a href=\"https://www.alignmentforum.org/posts/HBxe6wdjxK239zajf/what-failure-looks-like\">What Failure Looks Like</a> - Due storie specifiche su come potrebbero essere peggiori scenari di una societ\u00e0 risultata dal fallimento dell\u2019allineamento di IA, che si sposta considerevolmente dalla classica storia della \u201cesplosione dell\u2019intelligenza\u201d (12 mins.)</li><li><a href=\"https://tinyurl.com/5w4vb9v8\">AGI Safety from first principles</a> - L\u2019opinione di un ricercatore di IA sui fattori specifici per il problema di allineamento nell\u2019intelligenza artificiale generale (1 ora 15 minuti)&nbsp;</li><li><a href=\"https://tinyurl.com/sxs2deby\">Human Compatible: Artificial Intelligence and The Problem of Control</a> (Libro)</li><li><a href=\"https://tinyurl.com/9ae73bvn\">The Alignment Problem: Machine Learning and Human Values</a> (Libro)</li></ul><h3><strong>Governance dell\u2019intelligenza artificiale</strong></h3><ul><li><a href=\"https://tinyurl.com/yzajjzhr\">The new 30-person research team in DC investigating how emerging technologies could affect national security - 80,000 Hours</a> - Come cambierebbe la sicurezza internazionale se gli effetti del machine learning fossero di portata simile a quelli dell\u2019elettricit\u00e0? (Podcast - 2 ore)</li><li><a href=\"https://tinyurl.com/yxndes72\">Technology Roulette: Managing Loss of Control as Many Militaries Pursue Technological Superiority - Center for a New American Security</a> - Come i progressi tecnologici in ambito militare (incluse, ma non solo, le IA) possono comportare rischi e creare problemi nel prendere decisioni importanti, degni di attenzione da parte delle strutture di sicurezza nazionali. (60 minuti)</li></ul><h3><strong>Lavori tecnici sull\u2019allineamento dell\u2019IA&nbsp;</strong></h3><ul><li><a href=\"https://ai-alignment.com/ai-alignment-landscape-d3773c37ae38\">AI Alignment Landscape</a> (Video - 30 minuti)</li><li><a href=\"https://forum.effectivealtruism.org/posts/pbiGHk6AjRxdBPoD8/ai-safety-starter-pack\">AI safety starter pack</a> (7 minuti)</li><li><a href=\"https://forum.effectivealtruism.org/posts/7WXPkpqKGKewAymJf/how-to-pursue-a-career-in-technical-ai-alignment\">How to pursue a career in technical AI alignment</a> (59 minuti)</li><li><a href=\"https://www.eacambridge.org/technical-alignment-curriculum\">Technical Alignment Curriculum</a> (readings for a 7 week course)</li><li><a href=\"https://www.alignmentforum.org/\">AI Alignment Forum</a>, soprattutto le loro&nbsp;<a href=\"https://www.alignmentforum.org/library\">sequenze principali</a></li></ul><h3><strong>Critiche ai rischi dell\u2019IA</strong></h3><ul><li><a href=\"https://forum.effectivealtruism.org/posts/9sBAW3qKppnoG3QPq/ben-garfinkel-how-sure-are-we-about-this-ai-stuff\">How sure are we about this AI stuff?</a> (26 minuti)</li><li><a href=\"https://forum.effectivealtruism.org/posts/kCAcrjvXDt2evMpBz/a-tale-of-2-75-orthogonality-theses\">A tale of 2.75 orthogonality theses</a> (20 minuti)</li><li><a href=\"https://forum.effectivealtruism.org/posts/7x2BokkkemjnXD9B6/new-article-from-oren-etzioni\">How to know if AI is about to destroy civilization</a> (sommario, 2 minuti)</li><li><a href=\"https://forum.effectivealtruism.org/posts/r72wjMns9wyaAhWhc/the-ai-messiah\">The AI Messiah</a> (e il primo commento) (5 minuti)</li><li><a href=\"https://www.lesswrong.com/posts/y3jDSoTTdBD9Nj3Gx/how-good-is-humanity-at-coordination\">How good is humanity at coordination?</a> (4 minuti)</li></ul>", "user": {"username": "EA Italy"}}, {"_id": "Bsdq5wK63vLEB3Gqg", "title": "Announcing the Launch of the Insect Institute", "postedAt": "2023-02-22T19:32:31.156Z", "htmlBody": "<p><a href=\"http://insectinstitute.org\"><u>The Insect Institute</u></a>, a fiscally-sponsored project of Rethink Priorities, is excited to announce its official launch.&nbsp;I (Dustin Crummett) am the executive director of this new initiative.</p><p>The Insect Institute was created to focus on the rapidly growing use of insects as food and feed. Our aim is to work with policymakers, industry, and other relevant stakeholders to address key uncertainties involving animal welfare, public health, and environmental sustainability. As this industry evolves over time, we may also expand our work to other areas.</p><p>While we don\u2019t currently have any open positions, we do expect to grow our team in the future. If you are interested in working with us, please feel free to submit an expression of interest through our&nbsp;<a href=\"https://www.insectinstitute.org/contact\"><u>contact form</u></a>, or sign up for our email list (at the bottom of our home page) to stay up to date on future developments and opportunities.</p><p>I look forward to seeing many of you at EAG Bay Area\u2014please come say hello if you\u2019d like to chat! I\u2019m also very happy to field questions via DM or via email to dustin@insectinstitute.org.</p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677094352/mirroredImages/Bsdq5wK63vLEB3Gqg/wgyiwhayco1iluagftbc.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1677094353/mirroredImages/Bsdq5wK63vLEB3Gqg/aenlu0lxtpecqvxeiywk.png 230w, https://res.cloudinary.com/cea/image/upload/v1677094353/mirroredImages/Bsdq5wK63vLEB3Gqg/jvuwxsir2nnfphyigst4.png 460w, https://res.cloudinary.com/cea/image/upload/v1677094353/mirroredImages/Bsdq5wK63vLEB3Gqg/ryz2v4f1jigr5qkj2evc.png 690w, https://res.cloudinary.com/cea/image/upload/v1677094352/mirroredImages/Bsdq5wK63vLEB3Gqg/wk47ur03qvns9ifzcxpg.png 920w, https://res.cloudinary.com/cea/image/upload/v1677094352/mirroredImages/Bsdq5wK63vLEB3Gqg/hxaetfx5vwpqtnzvflfc.png 1150w, https://res.cloudinary.com/cea/image/upload/v1677094352/mirroredImages/Bsdq5wK63vLEB3Gqg/vktxqmwx1nh8t4suf65q.png 1380w, https://res.cloudinary.com/cea/image/upload/v1677094353/mirroredImages/Bsdq5wK63vLEB3Gqg/idyoewsupxahlr9luf0y.png 1610w, https://res.cloudinary.com/cea/image/upload/v1677094352/mirroredImages/Bsdq5wK63vLEB3Gqg/ep4tfftbhnlbg62p8rus.png 1840w, https://res.cloudinary.com/cea/image/upload/v1677094354/mirroredImages/Bsdq5wK63vLEB3Gqg/hjvsifwyduzppjsvdj6y.png 2070w, https://res.cloudinary.com/cea/image/upload/v1677094353/mirroredImages/Bsdq5wK63vLEB3Gqg/kqfiekbkxyq91pzkpvkw.png 2268w\"><br>&nbsp;</p>", "user": {"username": "Dustin Crummett"}}, {"_id": "otfCm4TMFGrs8vLng", "title": "Faunalytics Analysis on Reasons for Abandoning Veg*n Diets", "postedAt": "2023-02-22T17:05:03.031Z", "htmlBody": "<p>Nonprofit research organization&nbsp;<a href=\"http://www.faunalytics.org\"><u>Faunalytics</u></a> has released a new analysis on reasons people abandon vegan or vegetarian (veg*n) diets, looking at the obstacles former veg*ns faced and what they would need to resume being veg*n.&nbsp;</p><p>Although causes for lapsing have been analyzed to an extent, a deeper analysis that considers people\u2019s reasons in their own words<i>&nbsp;</i>is necessary to not only understand why people give up their veg*n goals, but to find the best ways to help people stick with their commitment to veg*nism and even lure back some of the lapsers.</p><p>Read the full report here:&nbsp;<a href=\"https://faunalytics.org/veg-obstacle-analysis/\"><u>https://faunalytics.org/veg-obstacle-analysis</u></a>&nbsp;</p><p>&nbsp;</p><p><strong>Background</strong></p><p>People have a variety of motivations for switching to plant-based diets, yet not all people who begin the transition to a vegan or vegetarian (collectively called veg*n) diet maintain it long-term. In fact, Faunalytics\u2019&nbsp;<a href=\"https://faunalytics.org/a-summary-of-faunalytics-study-of-current-and-former-vegetarians-and-vegans/\"><u>study of current and former veg*ns (2014)</u></a> found that the number of lapsed (former) vegans and vegetarians in the United States far surpasses the number of current veg*ns, and most who lapse do so within a year.&nbsp;Are these people the low-hanging fruit for diet advocates? They could be\u2014there are many of them and they\u2019re clearly at least somewhat willing to go veg*n, so maybe more attention should be paid to the lapsers.</p><p>That\u2019s one possibility. The other, more pessimistic possibility, is that when we as advocates think our diet campaigns are successful, these are the people we think we\u2019re convincing. That is, we see the part where they go veg*n, but not the part where they later lapse back. This interpretation is one that a lot of people made when our study of current and former veg*ns released, but we don\u2019t have strong evidence either way.</p><p>This analysis, in which we looked at the&nbsp;<a href=\"https://faunalytics.org/going-veg-barriers-and-strategies/\"><u>obstacles</u></a> faced by people who once pursued a veg*n diet and what they would need to resume being veg*n, aims to shed a bit more light on these questions.&nbsp;Although causes for lapsing have been analyzed to an extent, a deeper analysis that considers people\u2019s reasons in their own words<i>&nbsp;</i>is necessary to not only understand why people give up their veg*n goals, but to find the best ways to help people stick with their commitment to veg*nism and even lure back some of the lapsers.</p><p><strong>Research Team</strong></p><p>This project\u2019s lead author was Constanza Ar\u00e9valo (Faunalytics). Dr. Jo Anderson (Faunalytics) reviewed and oversaw the work.</p><p><strong>Conclusion</strong></p><p>Diets Are More Than Food</p><p>Food plays an important role in our lives. More than just nutrition, food is a very personal yet social experience, a cultural identity, and at times, a religious or spiritual practice or symbol. Naturally, a good-tasting diet is important\u2014especially when the idea is to maintain it long-term. However, lapsed veg*ns\u2019 answers suggested that food dissatisfaction, although a very common struggle, was not the most crucial obstacle to overcome to return to veg*nism. Instead, having access to veg*n options, as well as the time and ability to prepare veg*n meals (often alongside non-veg*n meals for family), were much more common must-haves.</p><p>Additionally, people\u2019s feelings of healthiness while on their diet, seemed to hold a lot of weight. Many lapsed veg*ns who had faced issues managing their health named this as their main reason for lapsing. Similarly,&nbsp;<a href=\"https://faunalytics.org/going-veg-barriers-and-strategies/\"><u>Faunalytics (2022)</u></a> found that people who felt unhealthy when first trying out a veg*n diet were significantly more likely to lapse within the first six months than people who felt healthier. This was the case even if their initial motivation for going veg*n wasn\u2019t health-related.&nbsp;</p><p>Seeking professional medical advice while pursuing a veg*n diet (ideally from a doctor who understands and has experience with veg*n diets) is the best way to manage any major concerns and get information about the vitamins and nutritional supplements that would help combat diet-related health issues, though we recognize that access to affordable healthcare is a challenge for many people. For additional strategies to manage health-related difficulties, you may wish to review our previous research (<a href=\"https://faunalytics.org/going-veg-barriers-and-strategies/\"><u>Faunalytics, 2022)</u></a> or websites that are specifically dedicated to health and nutrition on a plant-based diet (e.g.,&nbsp;<a href=\"https://nutritionfacts.org/\"><u>NutritionFacts.org</u></a>).</p><p>Veg*n Options Aren\u2019t Always Very Accessible</p><p>A commonly discussed obstacle to maintaining a veg*n diet and a major requirement to resume veg*nism was people\u2019s access to veg*n options, from plant-based substitutes for animal products to fruits and vegetables. This was a problem in 2014 as well as 2019-2020. Many people struggled to find plant-based options in their local grocery stores and when eating out, while some didn\u2019t even have an easily accessible grocery store. This all points to the socioeconomic issue of&nbsp;<a href=\"https://foodispower.org/access-health/food-deserts/\"><u>food deserts</u></a>\u2014areas where access to affordable and healthy food options is limited or nonexistent. Food deserts are much more prevalent in poorer communities, often affecting BIPGM (Black, Indigenous, People of the Global Majority) groups to a greater extent than wealthy, predominantly white communities.</p><p>The good news is that the selection of plant-based foods reaching the market has increased, with many more veg*n options available in stores and restaurants now than just a few years ago. While this should increase access to fast and easy veg*n food options, more work is needed to make these options accessible to all communities.</p><p>Motivation Doesn\u2019t Just Come From Within</p><p>Many lapsed veg*ns discussed needing motivation and willpower to resume and maintain a veg*n diet. Some studies suggest that animal protection is the best long-term motivator for maintaining a veg*n diet (<a href=\"https://faunalytics.org/meat-reduction-and-vegan-promotion-a-report/\"><u>Grassian, 2019</u></a>), while others indicate that the only&nbsp;<i>ineffective&nbsp;</i>motivation is a singular focus on health (<a href=\"https://faunalytics.org/going-veg-motivations-and-influences/\"><u>Faunalytics, 2021</u></a>), with all other combinations seeming equally beneficial.&nbsp;</p><p>While we did not look at initial motivators in this study, the effectiveness of different ones is an important consideration with respect to recommendations. We suggest that advocates looking to bring back lapsed veg*ns try to increase their focus on animal protection as a motivator if possible, and avoid health as a sole motivator.&nbsp;<a href=\"https://faunalytics.org/going-veg-barriers-and-strategies/\"><u>Faunalytics\u2019 (2022) study</u></a> discusses some promising strategies to increase motivation, some of which tie into animal protection as a motivator.&nbsp;</p><p>Having A Good Support System Matters</p><p>The relationships we have, regardless of whether it\u2019s the family we were born into or the family we choose for ourselves, can be very influential in what we eat. This study found that people who lived with a significant other while they pursued a veg*n diet and people who adopted a veg*n diet at a younger age struggled with various difficulties posed by their relationships, such as experiencing hostility due to their diet, needing to cook meals for non-veg*ns in the household, and having concerns about providing proper nutrition to their children. Food is a social experience, so the dietary practices and beliefs of the people we\u2019re surrounded by are bound to have at least some influence over our own diets, sometimes imposing practical or emotional difficulties on being veg*n.</p><p><a href=\"https://faunalytics.org/going-veg-barriers-and-strategies/\"><u>Faunalytics (2022)</u></a> found that about 20% of new veg*ns didn\u2019t feel they could be open with their family and friends about their dietary goals, about 25% said their family and friends didn\u2019t listen to how they wanted to do things regarding their diet goals, and about 30% felt their family and friends didn\u2019t seem confident in their ability to make changes toward their diet goals. Similar sentiments were expressed by the lapsed veg*ns in this study, many of whom lacked the support they needed from their family and friends, recognizing that to resume a veg*n diet they would require a better support system. However, the 2022 study also found that autonomy support\u2014the feeling that one\u2019s choices are supported by friends and family\u2014can increase with time. So, new veg*ns who at first don\u2019t feel they have the support of their loved ones may find that this improves over time.</p><p>Extra work may also be involved in feeding a household that is both veg*n and non-veg*n. Living with a non-veg*n partner, parents, children, or roommates can be difficult regardless of who handles shopping and cooking. It may mean planning, shopping, and cooking for two different diets. If family members are open to it, finding family-friendly veg*n recipes and simple meat substitutes may provide some relief with this particular obstacle, with participants in this study noting that easy and tasty recipes are essential.</p><p>Financial Considerations</p><p>Many lapsed veg*ns had faced financial issues that made it difficult to maintain their veg*n diets. They tended to indicate that they would need greater financial stability or more affordable veg*n options to resume a veg*n diet.&nbsp;</p><p>Other research shows that after taste, price is the most important decision-making factor in whether consumers purchase plant-based products, and lower-income consumers have been found to purchase less plant-based meat than higher-income consumers (<a href=\"https://gfi.org/wp-content/uploads/2021/12/Reducing-the-price-of-alternative-proteins_GFI_2022.pdf\"><u>GFI, 2022</u></a>). Historically, the prices of plant-based foods have been much higher than their animal product equivalents, making them rather expensive for the average consumer. For example, plant-based ground \u201cmeat\u201d cost approximately double the price of ground beef in 2021 (<a href=\"https://gfi.org/wp-content/uploads/2021/12/Reducing-the-price-of-alternative-proteins_GFI_2022.pdf\"><u>GFI, 2022</u></a>).&nbsp;These high prices not only apply to plant-based foods, but to fresh produce too\u2014people living in poverty have been found to consume the least amount of fruits and vegetables (<a href=\"https://www.cdc.gov/mmwr/volumes/66/wr/mm6645a1.htm?s_cid=mm6645a1_w\"><u>CDC, 2017</u></a>).&nbsp;</p><p>Adding to this point, lapsed veg*ns with higher levels of education reported fewer financial difficulties and concerns about the cost of veg*n food. This is likely income-based, as attaining&nbsp;<a href=\"https://www.bls.gov/emp/chart-unemployment-earnings-education.htm\"><u>higher education</u></a> is associated with higher income and a lower unemployment rate. It would be highly beneficial&nbsp;for crops intended for human consumption to be subsidized more relative to meat and crops for animal feed. Of an estimated $38 billion used by the U.S. government to subsidize the meat and dairy industry, it spends&nbsp;<a href=\"https://jia.sipa.columbia.edu/removing-meat-subsidy-our-cognitive-dissonance-around-animal-agriculture\"><u>less than 1%</u></a> on the production of crops. Because of how much money is used by the U.S. government to subsidize meat, it\u2019s much cheaper and easier to purchase a hamburger than a plant-based meal.</p><p>We hope that the cost-related obstacles faced by the lapsed veg*ns in this study will be less of an issue in the near future, at least in the U.S. Recent studies suggest that plant-based proteins are&nbsp;<a href=\"https://www.foodnavigator-usa.com/Article/2022/08/15/JUST-Egg-reaches-price-parity-with-premium-chicken-eggs\"><u>at</u></a> or&nbsp;<a href=\"https://gfi.org/wp-content/uploads/2021/12/Reducing-the-price-of-alternative-proteins_GFI_2022.pdf\"><u>approaching</u></a> price parity with their animal product equivalents. These price changes may encourage lapsed veg*ns to try again.</p><p>The Many Influences Of Age</p><p>Of the multiple demographics we looked at, age at diet adoption was the most associated with obstacles to maintaining veg*n diets. Our findings showed that the younger people were when they first adopted a veg*n diet, the more difficulties they faced. These included having more trouble managing their health and a lack of veg*n knowledge, including about the preparation of veg*n food and concerns about GMOs or additives in prepared veg*n foods. The latter likely points to younger people having less cooking experience in general. However, this can pose a significant challenge to being veg*n when access to plant-based food is lacking. This is yet another reason that easy and tasty veg*n recipes should be a priority.</p><p>People who adopted veg*n diets at an older age made positive comments about their veg*n experience more often than those who adopted veg*n diets at a younger age, suggesting that overall enjoyment of veg*nism may increase with age.&nbsp;</p><p>Additionally, the older people were when they adopted a veg*n diet, the fewer animal products they consumed even after lapsing. While we cannot definitively say why this may be, it could be associated with people\u2019s initial motivations for going veg*n. For instance, older participants may have tried veg*n diets to manage health issues more often, so even after lapsing, they may continue with reduced intake. Considering that older lapsed veg*ns are often consuming fewer animal products already and are more likely to have had a positive experience with veg*nism previously, older lapsed veg*ns may be the low-hanging fruit for diet campaigns.</p><p><a href=\"https://faunalytics.org/veg-obstacle-analysis\"><strong><u>Read the full report here</u></strong></a><strong>.&nbsp;</strong></p><p><br>&nbsp;</p>", "user": {"username": "JLRiedi"}}, {"_id": "7cfdwqZkhuKFACpeG", "title": "Cyborg Periods: There will be multiple AI transitions", "postedAt": "2023-02-22T16:09:04.958Z", "htmlBody": "", "user": {"username": "Jan_Kulveit"}}, {"_id": "usBf4xAc2a9JYtzrr", "title": "A Modest Proposal: Fixing the Polyamory Problem", "postedAt": "2023-02-22T12:16:57.547Z", "htmlBody": "<p>Women may at times want to engage with predominantly male social circles, such as Effective Altruism or casinos. Yet no one wants to be the rasher of bacon in a famine. There are diminishing returns to being hit on. If a boy and girl meet cute, and the boy flirts with the girl, she\u2019s fairly likely to find this flattering even if she isn\u2019t actually interested in him specifically. If literally every single man she encounters is hitting on her, she is left with two hypotheses: either she is overwhelmingly desirable, or these guys are just really really horny in a kind of gross way. Most women aren\u2019t self-deluded enough to pick the first option.</p><p><br>In practice, women navigating mostly-male social circles generally get themselves a boyfriend or a husband in fairly short order, which, once this becomes public knowledge, generally serves to decrease the volume of sexual attention they get by some large percentage. Most men are not complete chancers and will typically tone it down with a monogamously partnered woman. Furthermore, many men in the scene may well be partnered themselves, and are typically not going to try to cheat on their wives or girlfriends. All this serves to keep the sexual interest levels manageable.</p><p><br>Polyamory is uniquely destructive because it upends all of these protections. The \u201cget a boyfriend\u201d tactic doesn\u2019t work because everyone will assume you\u2019re still sexually available, since polyamory is the default norm. The \u201cmostly hang out with the partnered men\u201d option now doesn\u2019t work either because these men are still looking for women to add to their roster. Suddenly there is no way to avoid being the bacon rasher in the famine. The only way to opt out is to leave the scene altogether.</p><p><br>The dynamics described in the&nbsp;<a href=\"https://time.com/6252617/effective-altruism-sexual-harassment/\"><u>Time article</u></a> are not hard to get your head around once you view the problem through this lens. Let\u2019s take the most charitable framework and assume that most of the men not called REDACTED BY A TIME-TRAVELLING AGI in the stories listed didn\u2019t think they were doing anything wrong and had relatively moral intentions. Default polyamory, though, turns what might otherwise be merely awkward or even charming interactions into \u201coh god not again\u201d in the head of the women in question. Quite reasonably! Who isn\u2019t going to get jaded if every man you run across is trying to get into your pants?&nbsp;</p><p><br>A heavy-poly scene that is also largely male-dominated is inevitably going to be woman-unfriendly, even before we add in all the existing EA problems around control over jobs and funding applications that certain high-profile gatekeepers enjoy. It\u2019s just bad, makes things worse for women, adds endless drama potential, and makes managing conflicts of interest essentially impossible. As these problems become more and more publicly known, EA will get talent-drained as EA-adjacent people simply give up on applying for jobs and grants because they aren't part of the inner magic sex circle. Though a relatively minor problem, this dynamic also makes life worse for monogamously married men whose wives may not be thrilled with the additional workplace sexual interest that being involved in EA comes with.<br><br>EA should, therefore, try systemic affirmative action in favour of monogamous people. Most urgently, there should be a clear commitment from the board of EVF that the next CEO of CEA will a) be monogamous and b) have at least three degrees of sexual separation from any current or past board members of EVF.<br><br>No doubt this will get downvoted into oblivion by the poly people, but the future of EA itself is at stake. Eventually FTX will be forgotten, but a rolling series of #MeToo scandals that drip-feed out over the next few years will do huge damage. If you don't think there's more to come, then boy do I ever have some bets we can make for you!</p><p><br>&nbsp;</p>", "user": {"username": "Sol3:2"}}, {"_id": "hWvNFCqvtgKHsS3Be", "title": "Moral merch.", "postedAt": "2023-02-22T21:13:08.011Z", "htmlBody": "<p>So I had this idea while Christmas shopping online last year- NFPs should sell merchandise (the higher the quality, the better), so that people can support them in the course of buying gifts for others online.</p>", "user": {"username": "Tarkan"}}, {"_id": "nktb9DDibpypYccDE", "title": "2 issues", "postedAt": "2023-02-22T21:13:08.105Z", "htmlBody": "<p>I'm new to EA, I don't consider myself an EAist per se, but do like how it gives me something to think about. Anyway 2 problems come to mind from what I've read- foregoing fulfillment (if your earning-to-give) and the ease at which one can lose sight of the big picture when thinking the EAist way.</p>", "user": {"username": "Tarkan"}}, {"_id": "W4JksntnuFABZCkCw", "title": "Funding Strategies for Global Public Goods", "postedAt": "2023-02-22T06:59:36.091Z", "htmlBody": "<p><i>This is a cross-post from my new blog </i><a href=\"https://globalpublicgoods.substack.com/\"><i>Public Interest</i></a><i>, which focuses on the politics and economics of global public goods. I'm starting the blog because many of the issues that the EA community prioritizes are related to global public goods. As the </i><a href=\"https://80000hours.org/problem-profiles/global-public-goods/\"><i>80,000 hours problem profile</i></a><i> notes, improving how we think about global public goods broadly may help us make progress on multiple cause areas at once.&nbsp;</i></p><p><i>Thanks to Charlie Guthmann, Juliana Conway, Raghavendra Pai, Savva Kerdemelidis, Daniella Choi, Tej Chethik, and Leigh Chethik for their comments. All opinions expressed (and any errors made) are my own.</i></p><h2><strong>1. Introduction to Global Public Goods Funding</strong></h2><p>Many of the most pressing problems -- such as future pandemics and climate change -- are examples of \u201cglobal public goods\u201d problems. For this reason, there\u2019s growing discussion regarding how to best fund global public goods (including this article by <a href=\"https://80000hours.org/problem-profiles/global-public-goods/\"><u>80,000 hours</u></a>). Our post contributes to this conversation by assessing trade-offs between four public goods funding categories.</p><p>Before discussing the funding categories, let\u2019s quickly describe what we mean by global public goods. Global public goods are goods/services that benefit most people in the world yet are predictably underfunded without the support of government/non-profit resources. This underfunding occurs because it\u2019s difficult to exclude people from using a public good once it\u2019s produced. As a result, producers struggle to receive appropriate compensation in a traditional market.&nbsp;</p><p>How does this play out in practice? Consider that all countries can reduce the likelihood of pandemic outbreaks by funding early detection of animal disease spillover into humans. Unfortunately, each country prefers to let other countries pay for this early detection research. Since no one actor is properly incentivized to fund this research, <a href=\"https://www.bmj.com/content/372/bmj.n485\"><u>it continues to be underfunded according to experts</u></a>. (Read <a href=\"https://globalpublicgoods.substack.com/p/what-are-global-public-goods\"><u>here</u></a> for a more technical definition of global public goods.)</p><p>So, how are global public goods funded? They\u2019re most commonly funded <i>upfront </i>by governments and foundations. Much less frequently, they\u2019re funded <i>retroactively</i>, via results-based financing (\u201cRBF\u201d). RBF involves a funder (i.e., a government or foundation) that promises to reward service providers based on the \u201cresults\u201d of the goods/services provided.</p><p>We argue that, in many instances, RBF has advantages over upfront funding including the potential to catalyze more investment, reduce the risk of nepotism, and more effectively incentivize efficiency improvements. This blog post discusses the advantages and limitations of RBF. It concludes by discussing how RBF can help the Effective Altruism (\u201cEA\u201d) community and other impact-driven organizations.&nbsp;</p><h2><strong>2. Defining Funding Strategies</strong></h2><p>First, it\u2019s important to understand the relevant actors:</p><ul><li>The \u201c<strong>Goal Funder</strong>,\u201d typically a government organization or foundation, picks the goods/services they wish to fund.&nbsp;</li><li>When the Goal Funder uses RBF, an \u201c<strong>Upfront Investor</strong>\u201d funds the project, anticipating that they\u2019ll make their money back (more on this later). Upfront Investors are usually banks.&nbsp;</li><li>The entity that actually performs the service is called the \u201c<strong>Service Provider</strong>\u201d. Service Providers can be non-profit or for-profit firms.</li></ul><p>The actors use 4 broad funding strategies<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq0wc4gd6h4\"><sup><a href=\"#fnq0wc4gd6h4\">[1]</a></sup></span></p><p><strong>Upfront funding strategies</strong></p><ul><li><strong>Standard grant funding</strong> \u2014 The Goal Funder funds <strong>inputs </strong>such as lab equipment.</li><li><strong>Fee-for-service</strong> \u2014 The Goal Funder funds <strong>activities </strong>such as vaccine development.&nbsp;</li></ul><p><strong>RBF funding strategies</strong></p><ul><li><strong>Output-based funding</strong> \u2014 The Goal Funder promises a reward for the number of <strong>outputs </strong>produced<strong> </strong>such as the number of vaccines delivered (assessed retroactively by a 3rd party evaluator). These outputs have to meet minimum standards (e.g., efficacy standards in the case of vaccines). The Upfront Investor funds this work initially, hoping to eventually profit from the Goal Funder\u2019s retroactive payment.</li><li><strong>Outcome-based funding </strong>\u2014 The Goal Funder promises a reward for the <strong>outcomes </strong>achieved<strong> </strong>such as the percentage reduction in disease prevalence (assessed retroactively by a 3rd party evaluator). Just as with output-based funding, the Upfront Investor funds this work initially, hoping to eventually profit from the Goal Funder\u2019s retroactive payment.</li></ul><p>See Table 1 below for a summary of what project aspect each strategy targets.</p><p><i>Table 1: Funding Strategies and Project Aspects</i></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4d87492-b32b-43d4-bd31-1fdc5390c11e_1116x242.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4d87492-b32b-43d4-bd31-1fdc5390c11e_1116x242.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4d87492-b32b-43d4-bd31-1fdc5390c11e_1116x242.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4d87492-b32b-43d4-bd31-1fdc5390c11e_1116x242.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4d87492-b32b-43d4-bd31-1fdc5390c11e_1116x242.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4d87492-b32b-43d4-bd31-1fdc5390c11e_1116x242.png 1456w\"></a></p><p>See figure 2 below for diagrams depicting how each of these funding strategies works.</p><p><i>Figure 1: Funding Strategies Diagram</i></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2759b049-fcae-4b62-8cbd-942a8e901eb0_977x876.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2759b049-fcae-4b62-8cbd-942a8e901eb0_977x876.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2759b049-fcae-4b62-8cbd-942a8e901eb0_977x876.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2759b049-fcae-4b62-8cbd-942a8e901eb0_977x876.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2759b049-fcae-4b62-8cbd-942a8e901eb0_977x876.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2759b049-fcae-4b62-8cbd-942a8e901eb0_977x876.png 1456w\"></a></p><p>Goal Funders can use <strong>combinations of these strategies </strong>as well. For example, sometimes a contract will primarily fund a public good via fee-for-service funding but will also offer small outcome-based incentives. Although the strategies are frequently combined, we discuss them separately to help more clearly explain the trade-offs between them.</p><h2><strong>3. Assessing Tradeoffs between Strategies</strong></h2><p>We evaluate the funding strategies using four criteria -- who bears financial risk, cost, risk of nepotism, and the degree to which the strategy incentivizes efficiency improvements (summarized in Table 1 below). Our ratings are based on a quick review of research on these strategies, discussed below.</p><p><i>Table 2: Summary of Funding Strategies</i></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F330075ee-89a4-4f94-b736-b55445d00876_1167x552.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F330075ee-89a4-4f94-b736-b55445d00876_1167x552.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F330075ee-89a4-4f94-b736-b55445d00876_1167x552.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F330075ee-89a4-4f94-b736-b55445d00876_1167x552.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F330075ee-89a4-4f94-b736-b55445d00876_1167x552.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F330075ee-89a4-4f94-b736-b55445d00876_1167x552.png 1456w\"></a></p><h3><strong>Primary Considerations</strong></h3><ul><li><strong>Who bears financial risk </strong>-- <a href=\"https://www.oecd.org/dac/peer-reviews/Review-of-Major-RBA-and-RBF-Schemes.pdf\"><u>RBF enables the Goal Funder to shift financial risk</u></a> and, thus, reputational risk onto Upfront Investors. Backlash for bad government funding can affect future funding but can be avoided with RBF because RBF allows Goal Funders to only pay for successful projects.</li><li><strong>Relative risk of nepotism </strong>-- Output and outcome-based funding forces Goal Funders to use more objective evaluation criteria. This reduces the risk of nepotism influencing funding decisions. We think nepotism, or at least public perception of nepotism, is overlooked by the EA community especially since EA grants are sometimes given to friends of the Goal Funders. Of course, this is okay to <i>some extent</i> -- it\u2019s natural for people with similar values and interests to develop friendships <i>and </i>cross paths professionally. However, EA grantmakers should take advantage of opportunities to easily reduce the risk of nepotism/perceived nepotism when possible. RBF can help do this.</li><li><strong>Degree to which the strategy incentivizes efficiency improvements</strong> -- At the end of the day, Goal Funders want to maximize outcomes per dollar -- not outputs, services, or inputs per dollar. Take our vaccine example -- any Goal Funder cares more about reducing disease prevalence (outcomes) than maximizing lab equipment purchased (inputs). Outputs, services, and inputs simply serve as proxies for outcomes. Therefore, the closer the Goal Funder moves towards incentivizing outcomes, the better-aligned incentives are. Consider another example: Medicare and Medicaid (which fund national public goods, not global public goods, but still serve as a useful example). <a href=\"https://www.isc.hbs.edu/health-care/value-based-health-care/key-concepts/Pages/aligning-reimbursement-with-value.aspx\"><u>Experts argue</u></a> that the historical funding strategy employed by Medicare and Medicaid -- fee-for-service -- provides limited incentive to improve quality of care and creates a perverse incentive to overprescribe services. To deal with these misaligned incentives, Medicare and Medicaid have shifted payment towards \u201cvalue-based care\u201d, which still relies somewhat on fee-for-service, but layers in output and outcome-based funding incentives (e.g., additional $ can be earned for providing customers with timely care and having low readmission rates). Early <a href=\"https://www.semanticscholar.org/paper/Results-Based-Financing-Approaches-Eldridge-TeKolste/81464d1131ef1b09a64ff442674dde76e6a8ffff\"><u>evidence</u></a> in multiple fields, including medicine, suggests that RBF improves quality and reduces the price per outcome. However, further research needs to be done to understand the best use cases and practices.&nbsp;</li><li><strong>Relative cost </strong>-- The primary downside of RBF is that it <a href=\"https://www.semanticscholar.org/paper/The-costs-of-performance-based-financing.-Kalk/b91bb14137f2109813101e25e32516dc3b41132c\"><u>costs more</u></a> (at least in the short-run) than standard grant funding and fee-for-service. This is because RBF strategies require that the Goal Funder pays evaluators to measure the outputs or outcomes. Standard grant funding, on the other hand, does not require evaluators, and fee-for-service is cheap/free to assess (i.e., was the service performed or not?).&nbsp;</li></ul><h3><strong>Additional Considerations</strong>&nbsp;</h3><ul><li><strong>Difficulty measuring results </strong>-- Outcomes or outputs can be difficult to evaluate due to problems defining metrics, long-time horizons, and small sample sizes. For example, how do you measure the benefits of an existential risks course, especially since class sizes are so small and outcomes may vary by teacher?</li><li><strong>Rigorous research is a byproduct of outcome-based funding </strong>-- Outcome-based funding requires the evaluation of programs (frequently in the form of randomized control trials). Therefore, with outcomes-based funding, Goal Funders can knock out two birds with one stone (i.e., funding a global public good AND funding research on the effectiveness of the service/good). This can be highly desirable in some cases. <a href=\"https://crowdfundedcures.org/\"><u>Crowd Funded Cures</u></a> (\u201cCFC\u201d) is making progress on a great use case. Many experts argue that certain health interventions are predictably under-researched due to private companies\u2019 inability to enforce the patent rights of these interventions (e.g., with <a href=\"https://pubmed.ncbi.nlm.nih.gov/33397471/\"><u>repurposed generic drugs</u></a>). As a result, many cheap, useful health interventions are never studied rigorously and, subsequently, never used en masse. CFC is planning to use outcome-based funding to incentivize FDA-approval-worthy research of these health interventions to improve health outcomes and reduce healthcare costs.</li><li><strong>Incentivizing risky behavior </strong>-- Some argue that since outcome-based funding cannot punish Service Providers for causing harm, it can -- unintentionally -- encourage engagement in activities with downsides (so long as the activities also have some upsides). However, this risk is somewhat mitigated because firms can be sued for harm.&nbsp;</li></ul><h2><strong>4. How Results-based Financing Can Help the Effective Altruism Community and Other Impact-Driven People</strong></h2><ul><li><strong>Grantmakers: </strong>Grantmakers<strong> </strong>can use RBF to increase the efficiency of positive impact work and reduce the relative risk/public speculation of nepotism. For example, in her <a href=\"https://80000hours.org/podcast/episodes/cassidy-nelson-12-ways-to-stop-pandemics/#policy-idea-2-vaccine-platforms-04708\"><u>80,000 hours podcast interview</u></a>, Dr. Cassidy Nelson suggests that creating \u201ca design prize to see how (to) make reagents less costly\u201d is an important strategy for reducing biorisk. A design incentive prize is a form of RBF. Additionally, RBF has the potential to reduce the risk of nepotism, which helps ensure grants are being optimally allocated and fosters public support.</li><li><strong>Policy Professionals</strong>: By shifting financial/reputational risk from Goal Funders to Upfront Investors, RBF can potentially enable governments to spend more. For example, EA-aligned government officials and policy researchers could encourage public school systems to develop advanced market commitments (a form of RBF) to purchase clean meat alternatives (that meet certain taste and health criteria) for school lunches. This conditional financial incentive would encourage clean meat R&amp;D but would only cost schools money if tasty, healthy clean meat is developed. This \u201cno risk, high reward\u201d combination could help enable governments to spend more.</li><li><strong>Project Founders:</strong> Knowledge of RBF can help EA and other impact-driven organizations tap into additional funding opportunities beyond EA grants. For example, XPrize is working on a <a href=\"https://www.xprize.org/prizes/feedthenextbillion\"><u>clean meat prize competition</u></a> that EAs might have an interest in.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefekxtnoj5gl\"><sup><a href=\"#fnekxtnoj5gl\">[2]</a></sup></span></li></ul><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq0wc4gd6h4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq0wc4gd6h4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>These categories are adapted from <a href=\"https://golab.bsg.ox.ac.uk/the-basics/outcomes-based-contracting/\"><u>Oxford\u2019s Government Outcomes Lab</u></a> work.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnekxtnoj5gl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefekxtnoj5gl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Broadly speaking, it may be beneficial to develop a database of prize opportunities relevant to important cause areas.</p></div></li></ol>", "user": {"username": "schethik"}}, {"_id": "aGkLx2hfr9s3mSdng", "title": "Consider not sleeping around within the community", "postedAt": "2023-02-22T09:21:03.872Z", "htmlBody": "<p><i>Posted under pseudonym for reasons I\u2019d rather not get into. If it\u2019s relevant, I\u2019m pretty involved in EA. I\u2019ve been to several EAGs and I do direct work.</i></p><p><i>tldr I think many more people in the community should consider refraining from sleeping around within the community. I especially think people should consider refraining from sleeping around within EA if they have two or more of the following traits- high status in EA, a man who sleeps with women, and socially clumsy.</i></p><p>&nbsp;</p><p>I think the community would be a more welcoming place, with less sexual misconduct and less other sexually unwelcome behaviour, if more EAs chose to personally refrain from sleeping around within EA or attempting to do so. Most functional institutions outside of EA, from companies to friend groups to extended families<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpq86svg4fyg\"><sup><a href=\"#fnpq86svg4fyg\">[1]</a></sup></span>, have developed norms against sleeping around within the group. We obviously don\u2019t want to simply unquestionably accept all of society\u2019s norms,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreff1t27wp4fmv\"><sup><a href=\"#fnf1t27wp4fmv\">[2]</a></sup></span>&nbsp;but I think in this case those norms address real problems.</p><p>I worry that as a group, EAs run a risk of discarding valuable cultural practices that don\u2019t immediately make sense in a first principles way, and that this tendency can have particularly high costs where sex is involved (Owen more or less admitted this was a factor in his behaviour in his&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/QMee23Evryqzthcvn/a-statement-and-an-apology\"><u>statement/apology</u></a>: \u201cI was leaning into my own view-at-the-time about what good conduct looked like, and interested in experimenting to find ways to build a better culture than society-at-large has\u201d).</p><p>Regarding sleeping around within a tight-knit community, I think this behaviour has risks whether the pursuer is successful or not. Failed attempts at sleeping with someone<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0s9mcl2o18k\"><sup><a href=\"#fn0s9mcl2o18k\">[3]</a></sup></span>&nbsp;can very often lead to awkwardness or uncomfortability. In EA, where employment and funding may be front of mind, this uncomfortability may be increased a lot, and there may be no way for the person who was pursued to realistically avoid the pursuer in the future if they want to without major career repercussions. Successful attempts at sleeping around can obviously also cause all sorts of drama, either shortly after or down the road.</p><h1>Personal factors that may increase risks</h1><p>I think within EA, the risks of harm are increased greatly if the pursuer has any of the following three traits:</p><ol><li>High status within EA- this can create bad power dynamics and awkward social pressure. First, people generally don\u2019t like pissing off high status people within their social circles as there may be social repercussions to doing so.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdkafv33ez4\"><sup><a href=\"#fndkafv33ez4\">[4]</a></sup></span>&nbsp;Second, high status people within EA often control funding and employment decisions. Even if the pursuer isn\u2019t in such a position now, they might wind up in one in the future. Third, high status EAs often talk to other high status EAs, so an unjustified bad reputation can spread to other figures in the movement who control funding or employment. Fourth, many EAs consider the community to be their one best shot at living the kind of ethical life they want,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefx39n5mv0m2k\"><sup><a href=\"#fnx39n5mv0m2k\">[5]</a></sup></span>&nbsp;raising the stakes a bunch. Fifth, the moralising<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefju72smrkek\"><sup><a href=\"#fnju72smrkek\">[6]</a></sup></span>&nbsp;aspect of EA may make some people find it more uncomfortable to rebuff a high status EA.</li><li>A man pursuing a woman (such as a heterosexual man or a bi-/pansexual man pursuing a woman)- this factor can sometimes be an elephant that people dance around in discussions, but I\u2019ll just address it head on.&nbsp;<i>On average</i> men are more assertive, aggressive, and physically intimidating than women.&nbsp;<i>On average&nbsp;</i>women are more perceptive about subtle social cues and find it more awkward when those subtle social cues are ignored. My sense is these factors are pretty robust across cultures, but I don\u2019t think it matters for this discussion what the cause of these average differences are. Add to all that, the EA community has a large gender imbalance, meaning there\u2019s effectively a large multiplier on any unwelcome sexual advances coming from men and towards women.</li><li>Socially clumsy- awkward advances are obviously more likely to lead to the other person feeling uncomfortable or disrespected. Poor ability to read social signals is also more likely to lead to further or more extreme unwanted behaviour. Even if this never reaches the line of assault or harassment proper, it can still be very uncomfortable.</li></ol><p>For anyone who has at least 2 of the above traits (such as a heterosexual man who is high status in EA or is socially clumsy), I would&nbsp;<i>strongly</i> recommend considering refraining from sleeping around in the movement. (<i>Edited to add: I personally consider myself to have two of these traits, so this advice would apply to me.</i>)</p><p>While these factors exist somewhat on a spectrum, I think many EAs will underestimate how much factor 1 applies to them personally. Rampant imposter syndrome likely causes many EAs to underestimate their status in the movement. If you have basically any direct job, note that&nbsp;<i>many</i> people within the community will assume you\u2019re somewhat high status, even if you don\u2019t feel that way.&nbsp;</p><h1>What I mean by sleeping around</h1><p>As this post is a call for people to voluntarily consider adopting certain personal behaviours, I\u2019m not sure having an explicit definition is needed. Having said that, I would generally consider all of the following hypothetical examples involving Bob and Alice sleeping together to be behaviour in line with Bob sleeping around. Assume for all examples that both Bob and Alice are EAs:</p><ol><li>Bob and Alice have a one night stand</li><li>Bob and Alice are friends with benefits</li><li>Bob is casually dating multiple people, including Alice, and he doesn\u2019t consider his relationship with Alice to be particularly special</li><li>Bob is dating Alice and no one else, but he doesn\u2019t consider it a serious relationship AND he thinks it's very unlikely their relationship will develop into a serious relationship</li><li>Bob is polyamorous with multiple people, including Alice, AND Alice is not his primary</li></ol><p>On the other hand, I generally would NOT consider the following to be examples of Bob sleeping around within EA (again, for all examples assume both Bob and Alice are in EA and that the examples involve them sleeping with each other):</p><ol><li>Bob and Alice are in a monogamous, monogamish, or open relationship</li><li>Bob is polyamorous with multiple people, including Alice, AND Alice is his primary (and none of the other people Bob is polyamorous with is an EA)</li><li>Bob and Alice are dating casually AND Bob considers his relationship with Alice to be special and thinks there\u2019s a realistic chance the relationship could develop into a serious relationship (either 1. or 2. above)</li></ol><p>Of course, I recognize this isn\u2019t all black and white. And of course the risks here increase the more extreme behaviour someone engages in, so I think someone could decrease risks by decreasing degree of behaviour.</p><p>And for clarity\u2019s sake, nothing in this post should be taken as a criticism of promiscuity in general or of any relationship styles in general. If any EA decides to have a bunch of one night stands or threesomes or non-primary polyamorous relationships or&nbsp;<i>whatever else</i> with lots of different people outside the community,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsbutshckwyc\"><sup><a href=\"#fnsbutshckwyc\">[7]</a></sup></span>&nbsp;I think that\u2019s 100% fine and does not raise the sorts of concerns that sleeping around in EA does.&nbsp;<br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpq86svg4fyg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpq86svg4fyg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is true even when there\u2019s no blood relation and the connection is weak. Would you have a casual hookup with your cousin\u2019s wife's sister? My guess is probably not, and if you did you\u2019d probably recognize that this could cause a lot of harm to the family, maybe even causing a lasting rift. On the other hand, if you had met her separately without realising the connection and started to seriously date, I think people generally would find that acceptable.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnf1t27wp4fmv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreff1t27wp4fmv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Historic stigmatisation of LGBT people and relationships is one example of why not</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0s9mcl2o18k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0s9mcl2o18k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For clarity, I\u2019m talking about cases where you pursue someone sexually and they rebuff your advances. I\u2019m not referring to sexual assault/attempted rape, which is obviously a much more serious issue.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndkafv33ez4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdkafv33ez4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If your response is \u201cI would never get pissed at someone for rebuffing my advances\u201d then&nbsp;<i>they don\u2019t know that</i>. It\u2019s very common for someone to act all nice while pursuing someone and then become very angry after it\u2019s clear that sex won\u2019t happen. Also, even if you won\u2019t outwardly express irritation for being rebuffed, I think you probably generally do feel at least somewhat irritated when you\u2019re rebuffed. It is a perfectly normal human emotion to feel irritated when you learn that you won\u2019t get something that you want and which you thought you might get. Even if you hide this irritation, it could still sour your opinion of the other person and may lead to you badmouthing them (even if unintentional). And again, even if you never would do that,&nbsp;<i>the other person doesn\u2019t know that</i>. The person you\u2019re pursuing isn\u2019t stupid, they know all this is a risk if they rebuff you.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnx39n5mv0m2k\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefx39n5mv0m2k\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is its own can of worms, but seems true for a significant enough portion of EA that, at least for the time being, we should factor this into our decisions.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnju72smrkek\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefju72smrkek\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I don\u2019t mean this in a bad way, but I can\u2019t think of a similar word with a more neutral or positive tone</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsbutshckwyc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsbutshckwyc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I recognize the barrier between \u201cis an EA\u201d and \u201cis not an EA\u201d isn\u2019t always super clear. I think for pursuing people who are EA-adjacent, the concerns raised here apply somewhat but in a weakened form. But the vast majority of people in the world are clearly not EA and not EA-adjacent.</p></div></li></ol>", "user": {"username": "Patrick Sue Domin"}}, {"_id": "XFBGu9sGfbYAsb8Gb", "title": "Bad Actors are not the Main Issue in EA Governance", "postedAt": "2023-02-21T22:47:50.028Z", "htmlBody": "<h1>Background</h1><p>While I have a technical background, my career has been spent working with corporate boards and management teams. I have seen first-hand how critical leadership are to the success of organizations. Organizations filled with competent people can fail miserably if individuals do not have the right interpersonal skills and humility.</p><p>I have worried about governance within EA for a while. In October, I launched the <a href=\"https://www.eagoodgovernance.com/\">EA Good Governance Project</a> and wrote that <a href=\"https://forum.effectivealtruism.org/posts/TT3gNbA534C7HNBCF/introducing-the-ea-good-governance-project#Good_Governance_is_Often_Underrated_within_EA\">\"We have not yet experienced a scandal / major problem and have not yet started to think through how to avoid that happening again\"</a> . Now, 4 months later, we've had our fair share and people are open to change.</p><p>This post is my attempt to put some thoughts together. &nbsp;It has been written in a rather rushed way given recent news, so apologies if some parts are poorly worded.</p><h1>Introduction</h1><p>I have structured my thoughts in 4 sections, corresponding to the 4 key ways in which leadership can fail:</p><p>1) Bad actor</p><p>2) Well-intentioned people with low competence</p><p>3) Well-intentioned high-competence people with collective blind spots</p><p>4) Right group of people, bad practices</p><h1>Bad Actors</h1><p>Much discussion on the forum in recent months has focused on the concept of a bad actor. I think we are focusing far too much on this concept.</p><p>The term comes from computer science where hackers are prevalent. However, real life is rarely this black and white. Never attribute to malice that which is adequately explained by incompetence (Hanlon's razor).</p><p>The bad actor concept can be used, consciously or unconsciously, to justify recruiting board members from within your clique. Many EA boards comprise groups of friends who know each other socially. This limits the competence and diversity of the board. Typically the people you know well are exactly the worst people to provide different perspectives and hold you to account. If they are your friends, you have these perspectives and this accountability already and you can prevent bad actors through referencing, donation history and background checks.</p><p>Key takeaway: Break the clique</p><h1>Competence</h1><p>There's an old adage: How do you know if someone is not very good at Excel? They will say they are an expert. With Excel, the more you know, the more aware you are of what you don't know. I think leadership is similar. When I had 3-5 years of professional experience, I thought I could lead anything. Now I know better.</p><p>Some aspects of leaderships come naturally to people, but many have to be learned by close interaction with role models. When you are a community without experienced figures at the top, this is hard. We should not expect people with less than 10 years of professional experience to be a fully rounded leader. Equally, it's possible to be successful without being a good leader.</p><p>I think many of us in the community have historically held EA leaders on a pedestal. They were typically appointed because of their expertise in a particular field. Some of the brightest people I've ever met are within the EA community. However, we then assumed they had excellent people judgment, a sound understanding of conflicts of interest, in-depth knowledge of real estate investments and an appreciation for power dynamics in sexual relationships. It turns out some of them don't. This shouldn't come as a big surprise. It doesn't mean they can't be a valuable contributor to the community and it certainly doesn't make them bad actors.</p><p>Key takeaway: We need to elevate the importance of soft skills and learn from models of effective leadership in other communities and organizations</p><h1>Blind Spots</h1><p>The more worrying thing though is how those people also believed in their own abilities. In my career, I have met a large number of company CEOs. I truly believe that the difference between a poor CEO and a good CEO is not their own expertise but their ability to harness other people's expertise. This means knowing who to trust on a particular issue and how to get the right decision out of them. We all have blind spots and we all benefit from decision-making that draws on the right expertise at the right moment. Being open to external expertise is good epistemics. Let's not recreate the errors of others simply because we believe we are superior.</p><p>We naturally like and find it easier to work with people who are similar to ourselves. It makes life simpler: decision-making is fast, cognitive dissonance is less, and we get our own way more often.</p><p>Key takeaway: Recognizing one's own faults is one of the hardest skills to develop</p><h1>Bad Practices</h1><p>So how do good leaders get decisions right? They hire people who are different to them. They create the conditions for that person to challenge their views, e.g. by investing time to understand opposing viewpoints, by talking last in discussions if they risk being too dominant. They know when to make a decision</p><p>What does this mean for CEOs? CEOs should bring important and difficult questions to the Board for input. They should empower the board by giving them the information and context they require. They should create the right incentives for employees to voice their honest opinions. They should provide the structure for getting decisions made. And they should lead by example.</p><p>What does this mean for Board? Boards should understand that they are accountable only to themselves. They should avoid execution (there's a lot of evidence that companies with a single Chairman-CEO underperform). They should talk less during discussions where they are not independent (e.g. they came up with the proposal). They should critically <a href=\"https://www.eagoodgovernance.com/organizations\">evaluate their own performance and composition</a>.</p><p>Key takeaway: Think about how your every interaction promotes cultures for effective decision-making.</p><h1>Personal Note</h1><p>I spent a few years earning to give before coming across EA. During that time, I attempted and mostly failed to answer questions about the most effective ways to make the world better. EA provides people with a way to answer those questions and funnel their energy into it. I sincerely believe that EA has had and will have an enormous positive impact. Please don't give up on EA.</p>", "user": {"username": "Grayden"}}, {"_id": "6pc8iuDxz8LArWng8", "title": "EU Food Agency Recommends Banning Cages", "postedAt": "2023-02-21T21:20:42.950Z", "htmlBody": "<p>Some key recommendations (all direct quotes from either <a href=\"https://efsa.onlinelibrary.wiley.com/action/downloadSupplement?doi=10.2903%2Fj.efsa.2023.7789&amp;file=efs27789-sup-0001-PLS.pdf\">here</a> or <a href=\"https://efsa.onlinelibrary.wiley.com/action/downloadSupplement?doi=10.2903%2Fj.efsa.2023.7788&amp;file=efs27788-sup-0001-PLS.pdf\">here</a>):</p><ol><li>Birds should be housed in cage-free systems</li><li>Avoid all forms of mutilations in broiler breeders</li><li>Avoid the use of cages, feed and water restrictions in broiler breeders</li><li>Limit the growth rate of broilers to a maximum of 50 g/day.</li><li>Substantially reduce the stocking density to meet the behavioural needs of broilers.</li></ol><p>My understanding is that the European Commission requested these recommendations as a result of several things, including work by some EA-affiliated animal welfare organizations, and it is now up to them to propose legislation implementing the recommendations.</p><p><a href=\"https://forum.effectivealtruism.org/posts/WF3Dxes2GJ6QhESfW/an-end-to-cages-in-europe\">This Forum post</a> from two years ago describes some of the previous work that got us here. It's kind of cool to look back on the \"major looming fight\" that post forecasts and see that the fight is, if not won, at least on its way.</p>", "user": {"username": "Ben_West"}}, {"_id": "udnaqtaw9FFygjx2f", "title": "A list of EA-relevant business books I've read", "postedAt": "2023-02-21T20:48:19.412Z", "htmlBody": "<p>Some have suggested EA is too insular and needs to learn from other fields. In this vein, I think there are important mental models from the for-profit world that are underutilized by non-profits.&nbsp;</p><p>After all, business can be thought of as the study of how to accomplish goals as an organization - how to get things done&nbsp;<i>in the real world</i>. EA needs the right mix of theory and real world execution. If you replace the word \u201cprofit\u201d with \u201cimpact\u201d, you\u2019ll find a large percentage of lessons can be cross-applied.</p><p>Eight months ago, I challenged myself to read a book a day for a year. I've been posting daily summaries on social media and had enough EAs reach out to me for book recs that, inspired by&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/zCJDF6iNSJHnJ6Aq6/a-ranked-list-of-all-ea-relevant-audio-books-i-ve-read\"><u>Michael Aird</u></a> and&nbsp;<a href=\"https://www.goodreads.com/list/show/107382.Effective_Altruism_Books\"><u>Anna Riedl</u></a>, I thought it might be worth sharing my all-time favorites here.</p><p>Below are the best ~50 out of the ~500 books I read in the past few years. I\u2019m an entrepreneur so they\u2019re mostly business-related. Bold = extra-recommended.</p><p><strong>If you\u2019d like any more specific recommendations feel free to leave a comment and I can try to be helpful.</strong></p><p>Also - I\u2019m hosting an unofficial entrepreneur meetup at EAG Bay Area. Message me on SwapCard for details or think it might be high impact to connect :)</p><h1><strong>The best ~50 books:</strong></h1><p><strong>Fundraising:</strong></p><ul><li><a href=\"https://a.co/d/bDMTFLk\"><strong><u>Fundraising</u></strong></a></li><li><a href=\"https://a.co/d/0PcNeaN\"><u>The Power Law: Venture Capital and the Making of the New Future</u></a></li></ul><p><strong>Leadership/Management:</strong></p><ul><li><a href=\"https://a.co/d/doZFdgq\"><u>The Hard Thing About Hard Things: Building a Business When There Are No Easy Answers</u></a></li><li><a href=\"https://a.co/d/ibFq5tA\"><u>The Advantage: Why Organizational Health Trumps Everything Else In Business</u></a></li><li><a href=\"https://a.co/d/7srDZBL\"><u>The Coaching Habit: Say Less, Ask More &amp; Change the Way You Lead Forever</u></a></li></ul><p><strong>Entrepreneurship/Startups:</strong></p><ul><li><a href=\"https://a.co/d/h5nNnxr\"><strong><u>Running Lean</u></strong></a></li><li><a href=\"https://a.co/d/6WTaIAS\"><strong><u>The Founder's Dilemmas: Anticipating and Avoiding the Pitfalls That Can Sink a Startup</u></strong></a></li><li><a href=\"https://a.co/d/8QC3hcr\"><u>Zero to One: Notes on Startups, or How to Build the Future</u></a></li><li><a href=\"https://a.co/d/hrtunBS\"><u>The Startup Owner's Manual: The Step-By-Step Guide for Building a Great Company</u></a></li></ul><p><strong>Strategy/Innovation:</strong></p><ul><li><a href=\"https://a.co/d/3hGlHNF\"><strong><u>The Mom Test: How to talk to customers &amp; learn if your business is a good idea when everyone is lying to you</u></strong></a></li><li><a href=\"https://a.co/d/7sMmv8r\"><u>Scaling Up: How a Few Companies Make It...and Why the Rest Don't</u></a></li></ul><p><strong>Operations/Get Shit Done:</strong></p><ul><li><a href=\"https://a.co/d/4b00Cmo\"><strong><u>The Goal: A Process of Ongoing Improvement</u></strong></a></li><li><a href=\"https://a.co/d/8gGEnHL\"><u>The Phoenix Project: A Novel about IT, DevOps, and Helping Your Business Win</u></a></li><li><a href=\"https://a.co/d/8CXfEm3\"><u>Making Work Visible: Exposing Time Theft to Optimize Work &amp; Flow</u></a></li></ul><p><strong>Statistics/Forecasting:</strong></p><ul><li><a href=\"https://a.co/d/iUHuFAM\"><strong><u>How to Measure Anything: Finding the Value of Intangibles in Business</u></strong></a></li><li><a href=\"https://a.co/d/eLx3xhw\"><u>Superforecasting: The Art and Science of Prediction</u></a></li><li><a href=\"https://a.co/d/7nbPfK4\"><u>Antifragile: Things That Gain from Disorder</u></a></li></ul><p><strong>Writing/Storytelling:</strong></p><ul><li><a href=\"https://a.co/d/6rxgDII\"><strong><u>Wired for Story: The Writer's Guide to Using Brain Science to Hook Readers from the Very First Sentence</u></strong></a></li><li><a href=\"https://a.co/d/gN6eZSk\"><u>The Story Grid: What Good Editors Know</u></a></li></ul><p><strong>Product/Design/User Experience:</strong></p><ul><li><a href=\"https://a.co/d/4of4lpp\"><u>The Cold Start Problem: How to Start and Scale Network Effects</u></a></li><li><a href=\"https://a.co/d/8Jw3jKn\"><u>The Lean Product Playbook: How to Innovate with Minimum Viable Products and Rapid Customer Feedback</u></a></li></ul><p><strong>Psychology/Influence:</strong></p><ul><li><a href=\"https://a.co/d/3f507cE\"><strong><u>SPIN Selling</u></strong></a><strong> (unfortunate acronym)</strong></li><li><a href=\"https://a.co/d/2Eqarr7\"><u>The Elephant in the Brain: Hidden Motives in Everyday Life</u></a></li><li><a href=\"https://a.co/d/437JQxg\"><u>Influence: The Psychology of Persuasion</u></a></li></ul><p><strong>Outreach/Marketing/Advocacy:</strong></p><ul><li><a href=\"https://a.co/d/bOdunG6\"><strong><u>80/20 Sales and Marketing: The Definitive Guide to Working Less and Making More</u></strong></a></li><li><a href=\"https://a.co/d/jckp305\"><strong><u>Traction: How Any Startup Can Achieve Explosive Customer Growth</u></strong></a><strong>&nbsp;</strong></li></ul><p><strong>How to learn things faster:&nbsp;</strong></p><ul><li><a href=\"https://a.co/d/av8u8dJ\"><u>Ultralearning: Master Hard Skills, Outsmart the Competition, and Accelerate Your Career</u></a></li><li><a href=\"https://a.co/d/3UlNl8Y\"><u>Make It Stick: The Science of Successful Learning</u></a></li><li><a href=\"https://a.co/d/5cJQUNE\"><u>The Little Book of Talent: 52 Tips for Improving Your Skills</u></a></li></ul><p><strong>Personal Development:</strong></p><ul><li><a href=\"https://a.co/d/7SR9S7C\"><strong><u>The Confident Mind: A Battle-Tested Guide to Unshakable Performance</u></strong></a></li><li><a href=\"https://a.co/d/9y08567\"><strong><u>The Almanack of Naval Ravikant: A Guide to Wealth and Happiness</u></strong></a></li><li><a href=\"https://a.co/d/i92RCyx\"><u>Atomic Habits</u></a></li></ul><p><strong>Recruiting/Hiring:</strong></p><ul><li><a href=\"https://a.co/d/j1CLaRh\"><strong><u>Recruiting</u></strong></a></li><li><a href=\"https://a.co/d/8hzC2u1\"><u>Who: The A Method for Hiring</u></a></li><li><a href=\"https://a.co/d/gZcroeq\">Talent: How to Identify Energizers, Creatives, and Winners Around the World</a></li></ul><p><strong>Negotiating:</strong></p><ul><li><a href=\"https://a.co/d/jh4z0Hn\"><u>Negotiation Genius</u></a></li><li><a href=\"https://a.co/d/4ObP2JX\"><u>Never Split the Difference: Negotiating As If Your Life Depended On It</u></a></li><li><a href=\"https://a.co/d/5VIcGZa\"><u>Secrets of Power Negotiating: Inside Secrets from a Master Negotiator</u></a></li></ul><p><strong>Business Biographies:</strong></p><ul><li><a href=\"https://a.co/d/bSpahMP\"><u>Elon Musk: Tesla, SpaceX, and the Quest for a Fantastic Future</u></a></li><li><a href=\"https://a.co/d/iQ2Qpep\"><u>Creativity, Inc.: Overcoming the Unseen Forces That Stand in the Way of True Inspiration</u></a></li><li><a href=\"https://a.co/d/4z12UUf\"><u>Red Notice: A True Story of High Finance, Murder, and One Man's Fight for Justice</u></a></li><li><a href=\"https://a.co/d/03wKUWc\"><u>Endurance: Shackleton's Incredible Voyage</u></a><br>&nbsp;</li></ul><p>If you\u2019re not a book person,&nbsp;<a href=\"https://startuplaunchlist.com/\"><strong><u>here are the best articles to read before launching a startup.&nbsp;</u></strong></a></p><hr><h2><strong>For more, here are 100 books that just missed the cut:</strong></h2><p><br><strong>Fundraising:</strong></p><ul><li><a href=\"https://a.co/d/giS8uyJ\"><u>Mastering the VC Game: A Venture Capital Insider Reveals How to Get from Start-up to IPO on Your Terms</u></a></li><li><a href=\"https://a.co/d/1JFVcEr\"><u>The Art of Startup Fundraising: Pitching Investors, Negotiating the Deal, and Everything Else Entrepreneurs Need to Know</u></a></li><li><a href=\"https://a.co/d/45NKVJT\"><u>Angel: How to Invest in Technology Startups\u2014Timeless Advice from an Angel Investor Who Turned $100,000 into $100,000,000</u></a></li></ul><p><strong>Operations/Get Shit Done:</strong></p><ul><li><a href=\"https://basecamp.com/shapeup\"><u>Shape Up: Stop Running in Circles and Ship Work that Matters</u></a></li><li><a href=\"https://a.co/d/0Q9uSoq\"><u>Getting Things Done: The Art of Stress-Free Productivity</u></a></li><li><a href=\"https://a.co/d/8ICQeXm\"><u>Scrum: The Art of Doing Twice the Work in Half the Time</u></a></li></ul><p><strong>Leadership/Management:&nbsp;</strong></p><ul><li><a href=\"https://a.co/d/aZaSvkU\"><u>The Outsiders: Eight Unconventional CEOs and Their Radically Rational Blueprint for Success</u></a></li><li><a href=\"https://a.co/d/fMGxzh5\"><u>The Five Dysfunctions of a Team: A Leadership Fable</u></a></li><li><a href=\"https://a.co/d/frKgvPS\"><u>Death by Meeting: A Leadership Fable...About Solving the Most Painful Problem in Business</u></a></li><li><a href=\"https://a.co/d/dT6dkPc\"><u>High Output Management</u></a></li><li><a href=\"https://a.co/d/1YHB4z8\"><u>First, Break All the Rules: What the World's Greatest Managers Do Differently</u></a></li></ul><p><strong>Statistics/Forecasting:</strong></p><ul><li><a href=\"https://a.co/d/6ug04EG\"><u>Expert Political Judgment: How Good Is It? How Can We Know?</u></a></li><li><a href=\"https://a.co/d/fhWAyud\"><u>Nudge: Improving Decisions About Money, Health, and the Environment</u></a></li><li><a href=\"https://a.co/d/jk42ym4\"><u>Algorithms to Live By: The Computer Science of Human Decisions</u></a></li><li><a href=\"https://a.co/d/aFmg98K\"><u>How to Lie with Statistics</u></a></li></ul><p><strong>Entrepreneurship/Startups:</strong></p><ul><li><a href=\"https://readmake.com/\"><u>Make: learn to build profitable startups the indie way</u></a></li><li><a href=\"https://a.co/d/0N3ZPOu\"><u>Super Founders: What Data Reveals About Billion-Dollar Startups</u></a></li><li><a href=\"https://a.co/d/3z1PVeF\"><u>The 4-Hour Workweek</u></a></li><li><a href=\"https://a.co/d/1D0vDcm\"><u>Lean Analytics: Use Data to Build a Better Startup Faster</u></a></li><li><a href=\"https://a.co/d/6KowdpI\"><u>Disciplined Entrepreneurship: 24 Steps to a Successful Startup</u></a></li><li><a href=\"https://a.co/d/h5tpgdZ\"><u>High Growth Handbook: Scaling Startups From 10 to 10,000 People</u></a></li><li><a href=\"https://a.co/d/guI5Yui\"><u>From Impossible to Inevitable: How SaaS and Other Hyper-Growth Companies Create Predictable Revenue</u></a></li><li><a href=\"https://a.co/d/2poxCXJ\"><u>The Minimalist Entrepreneur: How Great Founders Do More with Less</u></a></li><li><a href=\"https://a.co/d/6EdVsQb\"><u>The Lean Marketplace: A Practical Guide to Building a Successful Online Marketplace Business</u></a></li><li><a href=\"https://a.co/d/8ykx8iy\"><u>Lean B2B: Build Products Businesses Want</u></a></li><li><a href=\"https://a.co/d/fDGkhdk\"><u>Zero to IPO: Over $1 Trillion of Actionable Advice from the World's Most Successful Entrepreneurs</u></a></li><li><a href=\"https://a.co/d/5rJIXpk\"><u>The Startup Playbook: Founder-to-Founder Advice From Two Startup Veterans</u></a></li><li><a href=\"https://a.co/d/iNU50wy\"><u>The Lean Startup: How Today's Entrepreneurs Use Continuous Innovation to Create Radically Successful Businesses</u></a></li></ul><p><strong>Strategy/Innovation:</strong></p><ul><li><a href=\"https://a.co/d/6wPXAl4\"><u>Understanding Michael Porter: The Essential Guide to Competition and Strategy</u></a></li><li><a href=\"https://a.co/d/92AErkC\"><u>The Innovator's Dilemma: When New Technologies Cause Great Firms to Fail</u></a></li><li><a href=\"https://a.co/d/blmzwQu\"><u>The Innovator's Solution: Creating and Sustaining Successful Growth</u></a></li><li><a href=\"https://a.co/d/hXM7kmk\"><u>Levers: The Framework for Building Repeatability into Your Business</u></a></li><li><a href=\"https://a.co/d/fScweka\"><u>Wild Problems: A Guide to the Decisions That Define Us</u></a></li><li><a href=\"https://a.co/d/4tSjoTe\"><u>Innovation Tournaments: Creating and Selecting Exceptional Opportunities</u></a></li></ul><p><strong>Writing/Storytelling:</strong></p><ul><li><a href=\"https://a.co/d/0ujra6a\"><u>The Elements of Eloquence: Secrets of the Perfect Turn of Phrase</u></a></li><li><a href=\"https://a.co/d/95ApJTQ\"><u>The Addiction Formula</u></a> (written about music, but you can cross-apply the ideas to writing)</li><li><a href=\"https://a.co/d/grDIbf4\"><u>Nobody Wants to Read Your Sh*t: Why That Is And What You Can Do About It</u></a></li></ul><p><strong>Product:</strong></p><ul><li><a href=\"https://a.co/d/5FKjUMr\"><u>UX for Lean Startups: Faster, Smarter User Experience Research and Design</u></a></li><li><a href=\"https://a.co/d/5EOD3IB\"><u>Lean UX</u></a></li><li><a href=\"https://a.co/d/gF7FmwP\"><u>Product-Led Growth: How to Build a Product That Sells Itself</u></a></li><li><a href=\"https://a.co/d/1X1loTv\"><u>Continuous Discovery Habits: Discover Products that Create Customer Value and Business Value</u></a></li><li><a href=\"https://a.co/d/863wdUf\"><u>Product-Led SEO: The Why Behind Building Your Organic Growth Strategy</u></a></li><li><a href=\"https://a.co/d/bmVlG56\"><u>User Story Mapping: Discover the Whole Story, Build the Right Product</u></a></li><li><a href=\"https://a.co/d/5XZzXXZ\"><u>UX Strategy: Product Strategy Techniques for Devising Innovative Digital Solutions</u></a></li></ul><p><strong>Psychology/Persuasion/Influence:</strong></p><ul><li><a href=\"https://a.co/d/g0LQkrv\"><u>Pitch Anything: An Innovative Method for Presenting, Persuading, and Winning the Deal</u></a></li><li><a href=\"https://a.co/d/3BrRsHg\"><u>Brainfluence: 100 Ways to Persuade and Convince Consumers with Neuromarketing</u></a></li><li><a href=\"https://a.co/d/69cYmZi\"><u>The Challenger Sale: Taking Control of the Customer Conversation</u></a></li><li><a href=\"https://a.co/d/e3Nez4q\"><u>Exactly What to Say: The Magic Words for Influence and Impact</u></a></li><li><a href=\"https://a.co/d/4QJgXjn\"><u>Sell More Faster: The Ultimate Sales Playbook for Startups</u></a></li></ul><p><strong>Outreach/Marketing:</strong></p><ul><li><a href=\"https://a.co/d/5GYmhTW\"><u>Positioning: The Battle for Your Mind</u></a></li><li><a href=\"https://a.co/d/8ZspjBq\"><u>Hacking Growth: How Today's Fastest-Growing Companies Drive Breakout Success</u></a></li><li><a href=\"https://a.co/d/15L9zuu\"><u>Content Machine: Use Content Marketing to Build a 7-figure Business With Zero Advertising</u></a></li><li><a href=\"https://a.co/d/77APGXb\"><u>Dotcom Secrets: The Underground Playbook for Growing Your Company Online with Sales Funnels</u></a></li></ul><p><strong>How to learn things faster:&nbsp;</strong></p><ul><li><a href=\"https://a.co/d/h58GIU2\"><u>Peak: Secrets from the New Science of Expertise</u></a></li><li><a href=\"https://a.co/d/1Ms2A6N\"><u>The Art of Impossible: A Peak Performance Primer</u></a></li><li><a href=\"https://a.co/d/7kXplcq\"><u>Talent is Overrated: What Really Separates World-Class Performers from Everybody Else</u></a></li></ul><p><strong>Personal Development:</strong></p><ul><li><a href=\"https://a.co/d/fcOkC8E\"><u>Switch: How to Change Things When Change Is Hard</u></a></li><li><a href=\"https://a.co/d/bA7hFwr\"><u>Hell Yeah or No: what\u2019s worth doing</u></a></li><li><a href=\"https://a.co/d/gLKdeNZ\"><u>Awaken the Giant Within: How to Take Immediate Control of Your Mental, Emotional, Physical and Financial</u></a></li><li><a href=\"https://a.co/d/gGtyfFa\"><u>The 48 Laws of Power</u></a></li><li><a href=\"https://a.co/d/3z2H2zC\"><u>Range: Why Generalists Triumph in a Specialized World</u></a></li><li><a href=\"https://a.co/d/8j9y8Go\"><u>How to Think Like a Roman Emperor: The Stoic Philosophy of Marcus Aurelius</u></a></li></ul><p><strong>Networking:</strong></p><ul><li><a href=\"https://a.co/d/aSoPeqp\"><u>Never Eat Alone, and Other Secrets to Success, One Relationship at a Time</u></a></li><li><a href=\"https://a.co/d/f3rjCu7\"><u>The Art of Gathering: How We Meet and Why It Matters</u></a></li><li><a href=\"https://a.co/d/fgb0aXq\"><u>How to Talk to Anyone: 92 Little Tricks for Big Success in Relationships</u></a></li><li><a href=\"https://a.co/d/hHRFXSo\"><u>How to Win Friends &amp; Influence People</u></a></li></ul><p><strong>Business Biographies:</strong></p><ul><li><a href=\"https://a.co/d/bToScqr\"><u>Power Play: Tesla, Elon Musk, and the Bet of the Century</u></a></li><li><a href=\"https://a.co/d/2znWP2S\"><u>Build: An Unorthodox Guide to Making Things Worth Making</u></a></li><li><a href=\"https://a.co/d/iXMbnq1\"><u>The History of the Future: Oculus, Facebook, and the Revolution That Swept Virtual Reality</u></a></li><li><a href=\"https://a.co/d/dMb0SKN\"><u>Barbarians at the Gate: The Fall of RJR Nabisco</u></a></li><li><a href=\"https://a.co/d/hrMzXkp\"><u>Billion Dollar Loser: The Epic Rise and Spectacular Fall of Adam Neumann and WeWork</u></a></li><li><a href=\"https://a.co/d/ggFt66q\"><u>How to Win at the Sport of Business: If I Can Do It, You Can Do It</u></a> (Mark Cuban)</li><li><a href=\"https://a.co/d/1f8DDJg\"><u>Shoe Dog: A Memoir by the Creator of Nike</u></a></li><li><a href=\"https://a.co/d/dA7UKDu\"><u>Amp It Up: Leading for Hypergrowth by Raising Expectations, Increasing Urgency, and Elevating Intensity</u></a></li><li><a href=\"https://a.co/d/6z3jbpW\"><u>The Innovation Stack: Building an Unbeatable Business One Crazy Idea at a Time</u></a></li><li><a href=\"https://a.co/d/fRDsieT\"><u>Hatching Twitter: A True Story of Money, Power, Friendship, and Betrayal</u></a></li><li><a href=\"https://a.co/d/hXFL7nq\"><u>No Filter: The Inside Story of Instagram</u></a></li><li><a href=\"https://a.co/d/ipw3EEU\"><u>Steve Jobs</u></a></li><li><a href=\"https://a.co/d/hjPkpmx\"><u>Why Startups Fail: A New Roadmap for Entrepreneurial Success</u></a></li><li><a href=\"https://a.co/d/5Krf8gE\"><u>Liftoff: Elon Musk and the Desperate Early Days That Launched SpaceX</u></a></li><li><a href=\"https://a.co/d/94AwKsg\"><u>The Ride of a Lifetime: Lessons Learned from 15 Years as CEO of the Walt Disney Company</u></a></li></ul><p><br><i>Reminder that you can&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/JTZTBienqWEAjGDRv/listen-to-more-ea-content-with-the-nonlinear-library\"><i><strong>listen to LessWrong and EA Forum posts</strong></i></a><i> like this on your podcast player using the&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/JTZTBienqWEAjGDRv/listen-to-more-ea-content-with-the-nonlinear-library\"><i>Nonlinear Library</i></a><i>.</i></p>", "user": {"username": "Meta"}}, {"_id": "PTCw5CJT7cE6Kx9ZR", "title": "Most people endorse some form of 'eugenics'", "postedAt": "2023-02-21T20:19:25.316Z", "htmlBody": "<p>A couple of EAs encouraged me to crosspost this here. I had been sitting on a shorter version of this essay for a long time and decided to publish this expanded version this month partly because of the accusations of eugenics leveraged against Nick Bostrom and the effective altruism community.&nbsp;</p><p>The piece is the <a href=\"https://dissentient.substack.com/\">first article on my substack</a> and you can listen to me narrate it at that link. Note that I changed the title from the original piece to better fit the norms of EA forum.&nbsp;</p><h1><strong>You're probably a eugenicist</strong></h1><p>Let me start this essay with a love story.</p><p>Susan and Patrick were a young German couple in love. But, the German state never allowed Susan and Patrick to get married. Shockingly, Patrick was imprisoned for years because of his sexual relationship with Susan.</p><p>Despite these obstacles, over the course of their relationship, Susan and Patrick had four children. Three of their children\u2014Eric, Sarah, and Nancy\u2014had severe problems: epilepsy, cognitive disabilities, and a congenital heart defect that required a transplant. The German state took away these children and placed them with foster families.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0193748a-6255-4ba2-8226-ef4822833221_2560x1920.jpeg\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0193748a-6255-4ba2-8226-ef4822833221_2560x1920.jpeg\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0193748a-6255-4ba2-8226-ef4822833221_2560x1920.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0193748a-6255-4ba2-8226-ef4822833221_2560x1920.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0193748a-6255-4ba2-8226-ef4822833221_2560x1920.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0193748a-6255-4ba2-8226-ef4822833221_2560x1920.jpeg 1456w\"></a></p><p>&nbsp;</p><p>Patrick and Susan with their daughter Sofia - credit dpa picture alliance archive</p><p>Why did Germany do all these terrible things to Susan and Patrick?</p><p>Eugenics.</p><p>No, this story didn\u2019t happen in Nazi Germany, it happened over the course of the last 20 years. But why haven\u2019t you heard this story before?</p><p>Because Patrick and Susan are siblings.</p><p>One of the aims of eugenics is to intervene in reproduction so as to decrease the number of people born with serious disabilities or health problems. Susan and Patrick were much more likely than the average couple to have children with genetic problems because they are brother and sister. So, the German state punished this couple by restricting them from marriage, taking away their children, and forcefully separating them with Patrick\u2019s imprisonment.</p><p>Patrick St\u00fcbing <a href=\"https://hudoc.echr.coe.int/eng#{%22itemid%22:[%22001-110314%22]}\">filed a case against Germany</a> with the European Court on Human Rights, arguing that the laws forbidding opposite-sex sibling incest violated his rights to family life and sexual autonomy. The European Court on Human Rights\u2019 majority opinion in the St\u00fcbing case clearly sets out the eugenic case for those laws: that the children of incest and their future children will suffer because of genetic problems. But the dissenting opinion argued that eugenics cannot be a valid justification for punishing incest because eugenics is associated with the Nazis, and because other people (for example, older mothers and people with genetic disorders) who have a high chance of producing children with genetic defects are not prevented from reproducing. Ultimately, the <a href=\"https://www.bbc.com/news/world-europe-17690997\">European Court on Human Rights upheld Germany's anti-incest law</a> on eugenic grounds.</p><p>If Germany had punished any other citizens this severely on eugenic grounds\u2014for example by imprisoning a female carrier of Huntington\u2019s disease who was trying to get pregnant\u2014 there would be a huge outcry. But incest seems to be an exception.</p><p>Our instinctive <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6224511/\">aversion to incest is informed by intuitive eugenics</a>. Not only are we reflexively disgusted by the thought of having sex with our own blood relatives, but we\u2019re also disgusted by the thought of any blood relatives having sex with each other.</p><p>&nbsp;Siblings and close relatives conceive children who are more likely to end up with two copies of the same defective genes, which makes those children more likely to inherit disabilities and health problems. It\u2019s estimated that the children of sibling incest have a <a href=\"https://www.researchgate.net/publication/226985985_Genetic_Counseling_and_Screening_of_Consanguineous_Couples_and_Their_Offspring_Recommendations_of_the_National_Society_of_Genetic_Counselors\">greater than 40 percent chance</a> of either dying prematurely or being born with a severe impairment. By comparison, first cousins have&nbsp; <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3419292/\">around a five percent chance</a> of having children with a genetic problem\u2014twice as likely as unrelated couples. In the UK, first cousin marriages are legal and these unions make up <a href=\"https://www.bbc.com/news/uk-england-leeds-23183102\">a disproportionate number</a> of babies born with birth defects including those who die shortly after birth, likely numbering thousands per year. In the US, most states have outlawed first cousin marriage <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2605922/\">for eugenic reasons</a>. For instance, <a href=\"https://en.wikipedia.org/wiki/Cousin_marriage_law_in_the_United_States#cite_note-9\">in states like Arizona</a> first cousin marriage is allowed, provided the cousins are infertile or over the age of 65.</p><p>If you agree that people who are genetically related should not have children, or should see a genetic counselor, congratulations, you\u2019re a eugenicist.</p><p>While we heavily weigh the risk of closely related parents, we often discount even more serious risks simply because they don\u2019t have the same visceral emotional impact as incest. For instance, between five and six percent of first cousins pass genetic disorders on to their children, but a parent with <a href=\"https://en.wikipedia.org/wiki/Huntington%27s_disease\">Huntington\u2019s disease</a> has a 50 percent chance of passing on the disease to their child. If one parent has schizophrenia, their child has a 10 percent chance of inheriting it; with two schizophrenic parents, the likelihood is 40 percent.</p><p>This would be consequential enough on its own, but <a href=\"https://jamanetwork.com/journals/jamapsychiatry/article-abstract/2494707\">there is strong evidence</a> that people with mental disorders, including bipolar disorder, schizophrenia, and substance abuse, are more likely to be in relationships with one another. These relationships, like relationships between blood relatives, entail a risk: the children that result are much more likely to share their parents\u2019 misfortune, which not only increases the number of these disorders but also their comorbidity, or the likelihood that one person will suffer multiple disorders. Most governments forbid sibling incest, but do not even provide education to people who are just as likely to pass on other devastating heritable conditions. We treat similar or elevated risks dissimilarly based on our instinctive feelings of disgust.</p><p>Eugenics, a literal translation of the Greek for \"good birth,\" aims to improve the population through interventions. Positive eugenics aims to increase \u201cgood\u201d and \u201cdesirable\u201d traits, whereas negative eugenics aims to reduce \u201cbad\u201d or \u201cundesirable\u201d traits. The scare quotes are meant to indicate that there are and have been divergent views on the meaning of these words in the history of eugenic interventions. The taboos attached to even the most rational and objective discussion of eugenics only aggravates the confusion, promoting a widespread ignorance of even the definition of eugenics. Eugenics is actually an expansive concept with which most people agree in principle, but disagree with some of the terrible ways it\u2019s been implemented. We are all eugenicists\u2014but in selective, inconsistent, and often hypocritical ways.</p><p>In terms of the population, eugenics can be implemented at many different levels. Eugenics can be coercive and violate people\u2019s freedom of mate choice and reproduction, but it can also be libertarian, relying on social influence, persuasion, and reproductive education. Consider the diverse goals of some historical eugenicists. Francis Galton (1822\u20131911), who coined the term, wanted to encourage geniuses to marry one another, so they could create a new \u201crace\u201d of super-smart people. <a href=\"https://en.wikipedia.org/wiki/Eugenics_Board_of_North_Carolina\">The North Carolina Eugenics Board</a> coerced thousands of Black women into getting sterilized. Progressive Black eugenicists like Kelly Miller (1863\u20131939) and W. E. B. Du Bois (1868\u20131963)&nbsp;<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.674.852&amp;rep=rep1&amp;type=pdf\">wanted to encourage</a>&nbsp;educated Black families to have more children to&nbsp;<a href=\"https://nursingclio.org/2017/06/01/the-black-politics-of-eugenics/#footnoteref3\">uplift Black Americans</a>. Chinese sociologist&nbsp;<a href=\"https://en.wikipedia.org/wiki/Pan_Guangdan\">Pan Guangdan</a>&nbsp;(1898\u20131967) wanted to improve the overall health of the Chinese people (and helped to eradicate foot binding). Nazis murdered thousands of disabled people and others who were considered genetically defective.&nbsp;Rabbi Joseph Ekstein <a href=\"https://doryeshorim.org/history-achievements/\">founded Dor Yeshorim</a> in 1983 to reduce debilitating genetic diseases such as Tay-Sachs and Cystic Fibrosis in Jewish families. The first prime minister of Singapore, Lee Kuan Yew (1923\u20132015) arranged matchmaking cruises for university graduates, and gave women graduates priority housing, in an attempt to <a href=\"https://journals.sagepub.com/doi/abs/10.2190/88FW-HNPW-EXP0-3CQK?journalCode=joha\">increase the number of educated Singaporeans</a>&nbsp;in the next generation.</p><p>\u201cGood\u201d also has different definitions. During this moment in history, \u201cgood\u201d depends on whether you\u2019re endorsing changing something genetically or environmentally. Most people agree that that being healthy, educated, happy, stable, intelligent, altruistic, and productive are good qualities. When it comes to preventing disability and increasing IQ, almost every environmental intervention is uncontroversially considered. We encourage people with mental health problems to take medication that may help them suffer less and become more productive. We take children away from families that neglect or mistreat them, not only so <a href=\"https://www.nytimes.com/2018/11/21/opinion/foster-care-child-abuse.html\">they do not suffer now</a>, but also so they are more likely to become <a href=\"https://www.pnas.org/content/112/15/4612\">intelligent</a>, productive members of society. We discourage harmful behavior with prison, fines, penalties, social disapproval, and exclusion and encourage altruistic behavior with social approval and tax incentives. Pregnant women and mothers bear much of the burden of trying to produce kids with good traits; any decision that might influence children, from drinking while pregnant to childhood nutrition, from the <a href=\"https://en.wikipedia.org/wiki/Mozart_effect\">Mozart effect</a> to video games, is moralized and supervised. Though there is <a href=\"https://www.huffpost.com/entry/expecting-better-emily-oster_n_3780541?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAAloDI7HA4BwQARb7B5LRZdA_2sYt2T-o4rFGDNGfUZ7Eg9VsfpPaQ01ULKW_3Hx2_z3RoQHP3JrU-WNQju1rU7bOfm7qKvKzz4aoGcAdBq0YumuPcczZA_ihQ4UYZn3B-R0OZswD8CBek-v3ZrpbgSlkUHQ20ns8tbWBi-EzPFo\">very little evidence</a> that some of these environmental interventions make much difference.</p><p>Historically, eugenicists were focused not only on genetically heritable characteristics but also potentially effective environmental and cultural influences on children\u2019s traits. Chinese eugenicists led the charge to eradicate <a href=\"https://books.google.com/books?id=g15rfXUA2i8C&amp;printsec=frontcover&amp;dq=oxford+handbook+of+eugenics&amp;hl=en&amp;newbks=1&amp;newbks_redir=0&amp;sa=X&amp;ved=2ahUKEwiW1OGTlo7oAhXCB50JHR9hA4YQ6AEwAHoECAUQAg#v=onepage&amp;q=bound%20feet&amp;f=false\">foot binding</a>, and implemented programs of maternal education so they could provide better care for infants. Eugenicists also initiated the mandatory treatment of infectious diseases like syphilis, which causes blindness, deafness, and cognitive disability. If you think women should be treated for sexually transmitted infections or <a href=\"https://www.theatlantic.com/notes/2017/02/abortion-measles/516312/\">rubella</a> so they don\u2019t have a disabled child, you\u2019re advocating the same goals as many historical eugenicists.</p><p>Those who rail against eugenics in any form engage in a technique where they conflate an easily defended position with a more difficult to defend position (AKA the <a href=\"https://en.wikipedia.org/wiki/Motte-and-bailey_fallacy\">Motte and Bailey</a> strategy). The easily defended position is that we should not murder or forcibly sterilize people on the basis of their genetics or disability. This position is conflated with several more difficult-to-defend positions. These more difficult-to-defend positions include that we should not study the genetics of desirable or undesirable characteristics, that we should not label any characteristics as desirable or undesirable and that we should not consider how any policy could change the genetic propensities of future generations.</p><p>It is inevitable that good or neutral ideas will sometimes be misused for terrible ends by bad actors. Despite the popular treatment of eugenics, the concept of eugenics is not synonymous with the worst things that have been done in its name. Consider other concepts we embrace in spite of their history of misuse. That democracies voted for slavery and have sent men to their deaths in needless wars does not invalidate the idea of government by consent. Psychiatry invented lobotomy and facilitated imprisonment and <a href=\"https://en.wikipedia.org/wiki/Political_abuse_of_psychiatry_in_the_Soviet_Union\">Soviet atrocities</a>. Foster care <a href=\"https://en.wikipedia.org/wiki/Stolen_Generations\">removed indigenous children from their parents</a>. In the case of contraception and abortion, progressives are willing to overlook the association with eugenics because of what they see as positive outcomes. Marie Stopes and Margaret Sanger were both eugenicists who wanted to prevent the unfit from breeding and also founded the organization that would become Planned Parenthood. Their transparently eugenic aims to improve the human race are literally written right on the contraception that they dispensed, the \u201cpro race\u201d and \"<a href=\"https://wellcomecollection.org/works/kjupsja9\">racial</a>\" models of cervical caps. Even now, there is evidence that the <a href=\"https://twitter.com/sentientist/status/1186760057754505216\">legalization of abortion had eugenic effect</a>s and many states and countries, before Roe was overturned <a href=\"https://quillette.com/2021/09/15/moral-panic-eugenics-abortion-rights/\">outlawed abortions on anti-eugenics grounds</a>. &nbsp;</p><p>&nbsp;</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5bcac9a-7de3-4c7a-8fe2-2bea64745d96_798x1199.jpeg\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5bcac9a-7de3-4c7a-8fe2-2bea64745d96_798x1199.jpeg\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5bcac9a-7de3-4c7a-8fe2-2bea64745d96_798x1199.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5bcac9a-7de3-4c7a-8fe2-2bea64745d96_798x1199.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5bcac9a-7de3-4c7a-8fe2-2bea64745d96_798x1199.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5bcac9a-7de3-4c7a-8fe2-2bea64745d96_798x1199.jpeg 1456w\"></a></p><p>&nbsp;</p><p>A cervical cap stamped with \u201cRacial\u201d indicating its use as a tool of eugenics - via Wellcome Trust</p><p>&nbsp;</p><p>Unlike eugenics, every conversation about democracy, foster care, psychiatry, or contraception do not devolve into outrage about how they are slippery slopes to genocide, mutilation, and racism. We ought to be capable of <a href=\"https://unherd.com/2020/02/eugenics-is-possible-is-not-the-same-as-eugenics-is-good/\">decoupling</a> the history of a concept from its intention if the potential outcomes are good enough.</p><p>You might be asking yourself- why use the term \u201ceugenics\u201d at all? Can\u2019t you just call it something different?</p><p>Well, not really.</p><p>We are not going to stop hearing about eugenics. Every time someone tries to call it something different, the \u201ce\u201d word and its association with historic injustice and abuse is invoked to end the discussion before it can begin.</p><p>When someone says that screening embryos for genetic diseases, giving educated women incentives to have children (like free child care for college educated women), or offering subsidized abortions for women addicted to drugs is \"eugenics\" they are absolutely using the term correctly. If bioethicists stopped using terms with contested definitions there would only be confusing new terms that would lead to a euphemism treadmill. All of the following key terms (to name just a few) have contested definitions and using them can cause confusion: autonomy, bioethics, consent, euthanasia, freedom, harm, health, justice and person. In my view, the only way to have a reasonable conversation about reproductive issues is to educate people on the meaning of eugenics. This tactic arguably also promoted clarity in the debate about \"euthanasia\".</p><p>Even though many people have tried to redefine any personal choices, and especially the personal reproductive choices of women as \u201cnot eugenics\u201d, there is <i>not</i> a clear delineation between public policy and private choice. I discovered during my pregnancy how many default aspects of prenatal care are eugenic in their aims. A lot of prenatal care aims to evaluate an embryo or fetus for abnormality. A woman can \u201cterminate for medical reasons\u201d, a right that progressives would never dispute. Yes, terminating for medical reasons is a personal choice. But during my pregnancies I was not asked whether I wanted noninvasive prenatal testing, a <a href=\"https://en.wikipedia.org/wiki/Nuchal_scan\">nuchal translucency</a> scan or genetic counseling for advanced maternal age; they were provided to me as a matter of course as they are provided by most countries with nationalized health care.</p><p>Eugenics concerns the decisions of individuals, not just the policies of the state. \u201cReprogenetics\u201d uses reproductive technology to allow parents to select embryos with certain desirable traits or without disability. <s>In the future,</s> Parents <a href=\"https://www.bloomberg.com/news/features/2022-05-26/dna-testing-for-embryos-promises-to-predict-genetic-diseases\">are now able to select embryos</a> with desirable characteristics. Both practices meet the definition of eugenics. But reprogenetics will have an even greater influence on the population as a whole when these techniques are more accessible and affordable.</p><p>Many of the same controversies around eugenics also apply, in principle, to reprogenetics. For example, the \u201c<a href=\"https://jme.bmj.com/content/30/4/418\">expressivist objection</a>\u201d to reprogenetics is that, by using prenatal testing to try to choose a child without disability, we are expressing a discriminatory stance against disabled people. Anti-eugenic and anti-reprogenetics arguments&nbsp;<a href=\"https://digitalcommons.macalester.edu/cgi/viewcontent.cgi?article=1028&amp;context=philo\">often imply that</a> when we reduce the number of disabled people in the population, bias against disabled people increases in society. But pursuit of this peculiar logic leads to repugnant conclusions, which may be exposed by applying <a href=\"https://www.nickbostrom.com/ethics/statusquo.pdf\">the reversal test</a>. Should we encourage pregnant women to drink alcohol and use drugs, or encourage drivers to forgo seat belts, in order to cultivate greater care and consideration when these acts result in more disabled people? Care and respect for disabled people can coexist with eugenics, as is demonstrated in Israel where prenatal testing is largely uncontroversial. As <a href=\"https://link.springer.com/content/pdf/10.1007/s10897-005-0573-0.pdf\">sociologist Aviad Raz stated</a>, \u201cThere is a two-fold view of disability [in Israel]: support of genetic testing during pregnancy, and support of the disabled person after birth.\u201d</p><p>Given how closely eugenics has been associated with Nazis and the Holocaust, it is interesting to consider the degree to which Jewish people have embraced eugenics. I wouldn\u2019t be here to write this essay had my Jewish grandfather not fled the Nazis in the 1930s. <a href=\"https://www.jewishvirtuallibrary.org/genetic-screening-and-genetic-therapy-in-judaism#3\">The Talmud expressed eugenic principles about who could marry whom</a>\u2014for example, it is forbidden for a woman to marry a man with epilepsy\u2014 German genetic counselors are much more likely to express disapproval for eugenic principles than Israeli genetic counsellors. Israeli genetic counselors&nbsp;<a href=\"https://www.tandfonline.com/doi/full/10.1080/14636770903561364\">are more likely</a>&nbsp;to endorse statements such as \u201cit is socially irresponsible to knowingly give birth to an infant with a serious genetic disorder\u201d and \u201cit is important to reduce the number of deleterious genes in a population.\u201d&nbsp;The Israeli National Program for the Detection and Prevention of Birth Defects offers free testing for many genetic diseases, and Israeli women are more likely to get tested than women in other countries.</p><p>Moreover, countries and states who have implemented eugenic policy offer evidence &nbsp;against the idea that this is a slippery slope to abuses like murder and forced sterilization \u2014Israel and Denmark two countries that have some of the most eugenic policies, also have some of the best provisioning for the disabled. States like Oregon, Nevada, Minnesota and Texas that have<a href=\"https://en.wikipedia.org/wiki/Cousin_marriage_law_in_the_United_States\"> implemented eugenic laws against first cousin marriage</a> nevertheless have very different reproductive and disability policies. In Oregon, women can have an abortion at any stage of pregnancy and for any reason and terminally ill patients can access physician assisted suicide. In Texas, the opposite policies are in place.</p><p>Despite the history of Nazi eugenics, Jews and the state of Israel embrace eugenic policies. The most comprehensive noninvasive fetal genotyping available at 11 weeks&nbsp;<a href=\"https://eurekalert.org/pub_releases/2019-02/afot-nbt022019.php\">was developed in Israel</a>. Further, abortions are legal and free in Israel if a fetus is found to have a genetic defect. While fewer abortions are performed in Israel than in other affluent countries, <a href=\"https://www.haaretz.com/israel-news/2019-06-15/ty-article-magazine/.premium/the-abortion-conundrum-how-far-israelis-go-to-ensure-their-babies-are-born-perfect/0000017f-e672-dc7e-adff-f6ff32a70000\">a much greater proportion of abortions are performed due to risk of birth defects</a>. Orthodox Jews who oppose abortion use premarital genetic testing instead\u2014an organization like&nbsp;<a href=\"https://en.wikipedia.org/wiki/Dor_Yeshorim\">Dor Yeshorim</a> tests couples for genetic compatibility based on the likelihood that they will produce children with genetic problems such as Tay-Sachs. This eugenic match-making is very similar to George Church\u2019s <a href=\"https://www.insider.com/harvard-geneticist-dating-app-matches-users-based-on-dna-eugenics-2019-12\">widely criticized</a> \u201cdigid8\u201d app.&nbsp;<a href=\"https://books.google.com/books?id=rnm0JyqfFLgC&amp;pg=PT741&amp;lpg=PT741&amp;dq=%22Whereas+in+Nazi+Germany+Jewish+life+was+systematically+destroyed%22&amp;source=bl&amp;ots=GrLPRUCa8i&amp;sig=ACfU3U1D4H5rWaijly-d8zCP77YK-wZUSQ&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiW-7Smg5noAhVOOq0KHWRUAPsQ6AEwAHoECAIQAQ#v=onepage&amp;q=%22Whereas%20in%20Nazi%20Germany%20Jewish%20life%20was%20systematically%20destroyed%22&amp;f=false\">As geneticist Raphael Falk put it,</a>&nbsp;\u201cWhereas in Nazi Germany Jewish life was systematically destroyed in the name of eugenics, Zionists in the Land of Israel conceived of eugenics as part of their mission to restore the Jewish people.\u201d Do you agree that women should be allowed to abort embryos with genetic defects or that couples from a small genetic pool, like Ashkenazi Jews, should be allowed to seek out genetic counseling before they marry? With regard to these issues, you\u2019re a eugenicist.</p><p>But what about couples who can\u2019t naturally have children on their own? Gay men and lesbian women were persecuted for so-called eugenic reasons during the horrific history of Nazi homophobia. Nevertheless, gay men and lesbian women in the US often use gamete donors from egg and sperm banks to have kids in a process that is transparently eugenic. From my experience as an egg donor, and from conversations with the many other egg donors I know, gay men often pay the most for eggs from \u201chigh quality donors\".&nbsp;</p><p>They prize attractive, high IQ donors even more than opposite sex couples do. Organizations that recruit egg and sperm donors don\u2019t just recruit for fertility, they also screen for mental and physical health, height, education, and criminal history\u2014because that\u2019s what their clients want and expect.</p><p>When these eugenic expectations are betrayed, gamete banks are severely criticized and may find themselves in legal jeopardy. In 2003, a lesbian couple, <a href=\"https://www.washingtonpost.com/health/georgia-court-allows-lawsuit-against-sperm-bank-to-proceed/2020/09/28/6574b192-019e-11eb-b92e-029676f9ebec_story.html\">Wendy and Janet Norman</a>, purchased sperm from a bank that promised their sample was sourced from a mentally stable, upstanding citizen pursuing a PhD. But the sperm donor lied; he did not disclose his struggles with bipolar disorder, schizophrenia, suicidal thoughts, and even obtaining an education. Nor did he disclose that he had served time in prison for burglary and that he was collecting disability for his mental illness. Wendy and Janet\u2019s son has a significant mental disorder, violent tendencies, and suicidal thoughts. Based on genetics, it\u2019s likely that three or four of the 36 children fathered by this sperm donor will suffer from schizophrenia. Behavioral genetics research also indicates that these children will be much more likely to have other mental illnesses and will be <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4009388/\">more likely to commit crime</a>&nbsp;than if they had actually been fathered by a PhD with no mental illness and no criminal record. Janet and Wendy sued Xytex, the sperm bank they used, for false advertising. Their case and 12 other cases against the company&nbsp;<a href=\"https://www.atlantamagazine.com/health/a-better-babymaking-business-georgia-based-sperm-bank-xytex-promises-greater-transparency-after-controversy/\">have all been settled or dismissed</a>.</p><p>If you think it\u2019s good for egg and sperm banks to screen donors for disability or mental health problems, you\u2019re a eugenicist. If you think it is right for the government to punish gamete vendors who do not adequately screen for such problems, you\u2019re a eugenicist. If you think it makes sense that customers would want gametes from mentally stable people without a criminal record, you\u2019re a eugenicist. If you\u2019re truly anti-eugenics, you should think that this lawsuit against Xytex is illegitimate and deeply immoral. Many Jewish people, lesbian mothers, and gay fathers have embraced modern eugenics in the domain of choosing their children\u2019s genes, even though eugenics has in the past been associated with discrimination against people like them.</p><p>There is nothing especially strange about screening one's own children for disability, choosing an egg or sperm donor based upon their personal history and characteristics, or receiving genetic counseling. The clients of egg and sperm banks are doing explicitly what many of us do intuitively. What young couple hasn\u2019t talked about what their children might be like? They wonder whether their child might inherit a sharp wit or a knack for mechanics. We often choose the people we have children with, in part, because we hope the things we love about them will pass on to the next generation. It\u2019s normal for people to consider the personality and the physical and mental health of the opposite sex partners of their sons and daughters or sisters and brothers. This too, is eugenics.</p><p>There are very positive <a href=\"https://plato.stanford.edu/entries/eugenics/\">mainstream bioethical treatments</a> of eugenics. Philosophers like <a href=\"https://www.utilitarian.net/singer/by/2003----.htm\">Peter Singer</a> and <a href=\"https://ideas.ted.com/the-ethics-of-genetically-enhanced-monkey-slaves/\">Julian Savulescu</a> have argued that if we would do anything to make our children happy and successful in their upbringing, we also have a moral imperative to do everything we can to <i>genetically</i> facilitate those outcomes. <a href=\"https://academic.oup.com/jmp/article/38/4/400/866949#.XnE4wJ_Vn-g.link\">Thomas Douglas and Katrien Devolder</a> have made an altruistic moral case that we should try\u2014environmentally and genetically\u2014to create children that are the most likely to benefit society and the world and the least likely to cause harm to others. And yet most intellectuals are either too ignorant or afraid of public reproach to give these ideas an open hearing.</p><p>As I said, we are not going to stop hearing about eugenics. Those unable to get past \u201cOMG it\u2019s eugenics\u201d should be aware that they are ceding the discussion of social policy and reprogenetics to the people who can. If this topic is discussed openly, we can ensure that it is conducted with a deep consideration of our moral values and acknowledgement of our human biases and moral flaws. To justify the consideration of the genetics of future generations and even their biological enhancement doesn\u2019t mean resuscitating master race theories or a contemptuous disregard for the value of human life and autonomy any more than it does for psychiatry, foster care, and contraception.</p><p>The scientific consensus is that nearly all traits of importance, certainly including psychological characteristics &nbsp;have a <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4739500/\">substantial genetic component</a> including the characteristics that enable our individual well-being, like mental and physical health and those that influence others\u2019 well being, like productivity, intelligence, and compassion.</p><p>Nearly every social policy has some influence on who has kids and how many kids they have, from prison to free tuition, from abortion waiting periods to free prenatal care. But the taboos attached to the very concept of eugenics are thwarting important discussions about how we improve our shared future. Instead of acknowledging the potential of eugenic policies to improve lives, the state chooses brutal remedial methods like prison or the lottery of foster care. In the case of Patrick St\u00fcbing, the state could have just offered to pay him to get a vasectomy, a choice he ended up making anyway, instead of throwing him in prison. More benevolent methods like free or incentivized contraception are rarely used to ameliorate these problems because anything that sounds like eugenics is dismissed out of hand. This moratorium on discussing eugenics prevents clarity of thought in how policy influences reproductive choices and how these reproductive choices have a deep impact on the future. If we are willing to disrupt people\u2019s lives, to make them suffer, to collect their wages, or alternatively to reward people and give them incentives, shouldn\u2019t we permit conversations about how this will influence the character of future people?</p><p>The scientific consensus on behavioral genetics should allow us to appreciate that genes and reproduction will have a huge effect on the flourishing of future generations. Those who reflexively denounce any attempt at changing the genetic composition of the next generation\u2014whether through genetically informed dating apps or government incentives\u2014are defending the status quo at the expense of potentially valuable progress and causing harm we cannot fully appreciate. Only when our conversations about morality and obligation move past the mere mention of eugenics can we unlock an important means of improving the world.</p>", "user": {"username": "Sentientist"}}, {"_id": "xYZtHt9HzJdQkXcDf", "title": "Office Hours For Animal-Loving Organizations and Leaders by Scarlet Spark", "postedAt": "2023-02-21T19:47:01.093Z", "htmlBody": "<p>We\u2019re inviting leaders of all levels into our cozy Zoom office. Bring your most pressing leadership questions, and get real-time input from Scarlet Spark advisors and your peers at other animal-loving companies. You\u2019ll leave with greater clarity, confidence, and new relationships within the community.</p><p>\u200bIf you already know the issue you want to discuss you can submit your questions ahead of time.</p><p>For example:</p><ul><li>How do I handle this difficult conversation?</li><li>Can you give me feedback on my company-wide announcement?</li><li>What do I do about an employee who\u2019s been underperforming?</li><li>How do we design an inclusive and accessible hiring process?</li><li>Why is my team constantly miscommunicating?</li></ul><p>&nbsp;</p><p>Scarlet Spark is a nonprofit that accelerates the speed-to-mission of organizations that help animals.</p><p>We improve employee and volunteer:</p><ul><li>Recruitment</li><li>Retention</li><li>Engagement</li><li>Inclusion</li><li>Effectiveness</li></ul><p>We provide consulting, coaching, and training to organizations that help animals, including advocacies and companies that create animal product alternatives.</p>", "user": {"username": "Sharleen "}}, {"_id": "tqQKkRqx4zxBPR6ci", "title": "A Stranger Priority? Topics at the Outer Reaches of Effective Altruism (my dissertation)", "postedAt": "2023-02-21T17:16:19.005Z", "htmlBody": "<p>(Cross-posted from <a href=\"https://joecarlsmith.com/2023/02/21/a-stranger-priority-topics-at-the-outer-reaches-of-effective-altruism\">my website</a>.)</p><p>After many years of focusing on other stuff, I recently completed my doctorate in philosophy from the University of Oxford. My dissertation (\"A Stranger Priority? Topics at the Outer Reaches of Effective Altruism\") was three of my essays -- on anthropic reasoning, simulation arguments, and infinite ethics -- revised, stapled together, and unified under the theme of the \"<a href=\"https://joecarlsmith.com/category/crazy-train\">crazy train</a>\" as a possible objection to <a href=\"https://joecarlsmith.com/category/longtermism\">longtermism</a>.</p><p>The full text is <a href=\"https://jc.gatspress.com/pdf/carlsmith_thesis.pdf\">here</a>. I've also broken the main chapters up into individual PDFs:</p><ul><li>Chapter 1: <a href=\"https://jc.gatspress.com/pdf/SIA_vs_SSA_revised.pdf\">SIA vs. SSA</a></li><li>Chapter 2: <a href=\"https://jc.gatspress.com/pdf/simulation_arguments_revised.pdf\">Simulation arguments</a></li><li>Chapter 3: <a href=\"https://jc.gatspress.com/pdf/infinite_ethics_revised.pdf\">Infinite ethics and the utilitarian dream</a></li></ul><p>Chapter 1 and Chapter 3 are pretty similar to the original essays (<a href=\"https://joecarlsmith.com/2021/09/30/sia-ssa-part-1-learning-from-the-fact-that-you-exist\">here</a> and <a href=\"https://joecarlsmith.com/2022/01/30/on-infinite-ethics\">here</a>). Chapter 2, however, has been re-thought and almost entirely re-written -- and I think it's now substantially clearer about the issues at stake.</p><p>Since submitting the thesis in fall of 2022, I've thought more about various \"crazy train\" issues, and my current view is that there's quite a bit more to say in defense of longtermism than the thesis has explored. In particular, I want to highlight a distinction I discuss in the conclusion of the thesis, between what I call \"welfare longtermism,\" which focuses on our impact on the welfare of future people, and what I call \"wisdom longtermism,\" which focuses on reaching a wise and empowered future more broadly. The case for the latter seems to me more robust to various \"crazy train\" considerations than the case for the former.</p>", "user": {"username": "Joe_Carlsmith"}}, {"_id": "iAweWwvJHAmvxBzCc", "title": "The Latest NYT article on EA/SBF", "postedAt": "2023-02-21T16:55:28.651Z", "htmlBody": "<p>Headline: <i><strong>\u2018Effective Altruism\u2019 Led Bankman-Fried to a Little-Known Wall St. Firm</strong></i></p><p>The article itself doesn't actually say much about EA, but many of the comments are (predictably) hostile. &nbsp;FWIW, I submitted a brief comment <a href=\"https://www.nytimes.com/2023/02/21/business/bankman-fried-altruism-jane-street.html?campaign_id=0&amp;emc=edit_cr_20230221&amp;instance_id=0&amp;nl=comments-notifications&amp;regi_id=80315892&amp;segment_id=0&amp;user_id=f00be77b5c6bc32ec7e2261ad2e745e6#commentsContainer&amp;permid=123327773:123327773\">here</a> as follows:</p><blockquote><p>Many of the comments here reveal misunderstandings about the philosophy behind Effective Altruism (which is understandable, since it isn't really explained in the main article). For those who would like to learn more, I've written up a FAQ here: <a href=\"https://rychappell.substack.com/p/effective-altruism-faq\">https://rychappell.substack.com/p/effective-altruism-faq</a>&nbsp;</p><p>(I'm an Associate Professor of Philosophy, specializing in ethical theory.)</p></blockquote><p>If others have more to add, or want to help signal-boost any better-informed comments, that might help casual readers of the NY Times to get a more accurate impression of EA.</p>", "user": {"username": "RYC"}}, {"_id": "BYFP4rH38ymvKHnTS", "title": "Hiring managers and people doing direct work: What qualities are most needed in the EA community/hiring pool", "postedAt": "2023-02-21T22:40:29.325Z", "htmlBody": "<p><i>Feel free to skip to my prompts if you don't want to read my justification of the question</i></p><p>I've been thinking recently about what good EA community building would look like. Typically when I think about community building my main focus is increasing the number of people doing high impact work. This usually means figuring out what sort of people are needed to solve problems and then thinking about ways to encourage those people to do that work.<br><br>I think the current models of community building I see aren't actually optimising for something like 'find the people who would most help with X problem and get them to work on it'. At the very least I personally feel as though it's hard for me to do good community building work without building a stronger model of what these people look like. So I'd like to hear what kind of people <i><strong>in practice</strong></i> are needed in the EA community. Since I took a break from EA for a while and my network is relatively small I'd thought it would be a useful experiment to pose this question publicly.<br>&nbsp;</p><p><strong>I'd love to see answers to this question from people currently working directly on high priority problems; especially if you're looking to hire people to work with you (or looking for collaborators or otherwise have recently thought about the talent needs for your particular problem area).&nbsp;</strong></p><p><strong>Personally I'm particularly interested in hearing about ways to improve the talent in AI safety work (both technical and governance) but I'm also interested in the general needs of &nbsp;the community so would want to hear about other fields (and think sharing them here is a good resource for others)</strong></p><p>If you'd be interested in answering this question in a short call please let me know <a href=\"https://airtable.com/shrgGKG7YnOL490Nx\">here</a> and I'll email you.</p><p>If you know someone who might have a good answer to this question please refer them <a href=\"https://airtable.com/shr9Z4YdoG9nebYMw\">here</a></p><p>If you have models / takes on this already but aren't doing direct work, feel free to sound off and swap models in the comments</p><h3><br><strong>Here are a couple of prompts to help you answer the question.</strong></h3><ul><li>Is there someone in your field who you think is doing particularly valuable work. Why do you think so. Do you have any theories about what sets them apart?</li><li>Are there roles in your problem area that are particularly difficult to hire for? Do you have a model of why? (e.g many people have this qualification but I just don't feel like I could rely on them to do X well, or I absolutely need someone with this experience / quality)</li><li>When collaborating with people are there particular qualities that make a good collaborator? (Who do you do good work with and why? Who makes your work significantly better? Who would you love to work with?)</li><li>Are there issues within your field which are not tied to finding people with particular qualities? (e.g people currently in the field don't talk to each other enough or it's hard to collaborate with other disciplines)</li></ul><p>I'd like answers which are grounded in real needs for a given field rather than theoretical needs. For example 'I'd like to see more people who can do X without supervision' is good but ideally would be followed up by 'this was our main hiring constraint in the last year or so'&nbsp;<br><br>&nbsp;</p>", "user": {"username": "Will Payne"}}, {"_id": "FHawH4gFhsg8s3mmo", "title": "What does Putin\u2019s suspension of a nuclear treaty today mean for x-risk from nuclear weapons?", "postedAt": "2023-02-21T16:46:14.480Z", "htmlBody": "<p>Interested to hear from EAs knowledgeable on the topic, including what they think other countries should do in response</p>\n", "user": {"username": "freedomandutility"}}, {"_id": "3YKZEFYgTccGbpQvf", "title": "No Room for Political Philosophy", "postedAt": "2023-02-21T16:14:34.319Z", "htmlBody": "<p>I was recently asked about my opinion on various schools of Political Philosophy (vg. classical liberalism, neoliberalism and Ayn Rand's Objectivism). I refused to engage with any of them in detail, because my position is that there is no room for different schools of \u201cPolitical Philosophy\u201d. Ethics and Science (mainly Social Science) are enough to completely determine the best public action.&nbsp;</p><p>To develop this idea, I am going to divide the field of political science in three layers: i) Social Welfare definition: what is the ethical objective for political choice, ii) Policy Making: how Science (mainly Social Science) and Ethics combine to generate optimal policies, and iii) Institutional Design: which institutional mechanisms consistently generate the best flow of policies.</p><p>Although at individual level there is a trade-off between our personal preferences and the general interest, when we talk about \u201cpolitical philosophy\u201d, we have to abstract (in the Rawlsian way) from our particular interests: &nbsp;the legislator is expected to impartially represent the demos. The formal translation of that demand requires building a <i>social utility function</i> that describes the collective preferences for each possible \"state of the world\". This function must be individualistic and impartial. Individualism means that collective well-being is the aggregation of individual well-being, and impartiality means equally aggregating the well-being of the equals (of course, \u201c<a href=\"https://forum.effectivealtruism.org/topics/moral-weight\">moral weights</a>\u201d that distinguish those who are substantially different are part of the utilitarian framework).</p><p>Once the social objectives have been established (what we \u201cwant\u201d), we need to know <i>what can be done</i>. We call the descriptive map of reality \u201cScience\u201d. It is Science that allows the legislator to distinguish on which variables he can act (on legislative power as a Nash equilibrium focal point, see \u201c<a href=\"https://openknowledge.worldbank.org/handle/10986/21991\">Republic of Beliefs</a>\u201d), and what are the consequences of any complete set of policies. Given the control variables, the social utility function, and the real constraints, the selection of optimal policies can be abstracted as a <a href=\"https://econ.lse.ac.uk/staff/wdenhaan/teach/ch1.pdf\">constrained optimization problem</a> (with its Lagrangian, or more precisely its Karush -Kuhn-Tucker conditions).</p><p>If the reader is the advisor of an absolute monarch who has no other objectives than the well-being of the governed, once the optimal policies portfolio has been selected, her work is completed.</p><p>If the reader rather thinks that this kind of ruler is impossible (or at least that after <a href=\"https://en.wikipedia.org/wiki/Antoninus_Pius\">Antoninus Pius</a> no other will be ever found), then political philosophy needs a constitutional <i>meta</i> layer over the <i>object level</i> policy layer. Institutional design finds the voting/elite selection mechanisms that achieve the flow of policies closer to be optimal. The construction of this kind of institutional system is the object of the so-called \u201c<a href=\"https://www.nobelprize.org/uploads/2018/06/myerson_lecture.pdf\">Mechanism Design</a>\u201d.</p><p>In the specific area of the production and distribution of baskets of private consumption goods, the complete process of optimal institutional design is tractable, and the canonical result is that a competitive market with lump-sum income transfers is capable of optimizing well-being for all possible degrees of inequality aversion (the so-called two theorems of welfare economics). In politics, the state spaces are more difficult to define (there are not nice continuity and smoothness properties), and therefore such definitive results are not available (the classical result is the Arrow Impossibility Theorem, that implies that the \u201cbest possible\u201d political system cannot be as perfect as market plus redistribution is in Economics).</p><p>Let\u2019s summarize now: different sentient beings with preferences on states of the world share a common world and interfere each other\u2019s pursuit of happiness. That leads to conflicts of interest. To provide the algorithmic system that allows for the maximum level of collective welfare is the \u201cpolitical problem\u201d. Rights or property are useful social devices, but there is nothing fundamental about them. They shall be justified (by the philosopher and the economist) before they are used as a justification (by the jurist). <a href=\"https://intertextual.bible/text/mark-2.27-mekhilta-de-rabbi-ishmael-31.13\">Jesus and Rabbi Ishmael taught us that Sabbath is for man</a>, and that principle invites us to trace all moral obligation to its root, which is the welfare of some conscious beings.</p><p>Of course, in the real world there is some legitimate room for disagreement about the interpersonal comparison of utility (although I am delighted to have Raj Chetty\u2019s <a href=\"https://scholar.harvard.edu/files/chetty/files/curvature_aer.pdf\">estimate&nbsp; on the relationship between the marginal utility of consumption and the level of income</a>), and a much wider margin of legitimate discrepancy on the objective causal laws describing the dynamics of human society.</p><p>Cause-effect relationships in the social realm (a complex adaptive system in which we, the aspiring policymakers, are also embedded) are very difficult to discover or even validate, and it is inevitable that in the absence of clear cut scientific knowledge, personal assessments and emotional manipulation influence the political sphere. But these discrepancies, sometimes legitimate and often unavoidable, do not deserve to be considered philosophical.</p><p>The technocratic and post-political vision has a long tradition. The framers of the United States Constitution had an openly mechanical idea of the State (\u201c<i>checks and balances</i>\u201d, \u201c<i>A Government of Laws, not of Men</i>\u201d). David Ricardo bought his seat in the House of Commons to defend optimal policy beyond party or class allegiances. That same line of liberalism encouraged the campaigns to reject the Corn Laws. However, to my knowledge, among technocratic-individualist movements, Effective Altruism is the most self-aware due to its direct relation with utilitarianism and modern (epistemic conscientious) rationalism.&nbsp;</p><p>[Posted on Effective Altruism Forum, Progress Forum and Less Wrong]</p>", "user": {"username": "Arturo Macias"}}, {"_id": "dGNHGasFW3rQBRBZX", "title": "\u201cWhy Effective Altruism struggles with sexual misconduct\u201d from Vox", "postedAt": "2023-02-21T14:19:26.254Z", "htmlBody": "<p><a href=\"https://www.vox.com/future-perfect/2023/2/15/23601143/effective-altruism-sexual-harassment-misconduct\">https://www.vox.com/future-perfect/2023/2/15/23601143/effective-altruism-sexual-harassment-misconduct</a></p>", "user": {"username": "CrossPost"}}, {"_id": "2yrprQuNJpFJKMGWh", "title": "Should we tell people they are morally obligated to give to charity? [Recent Paper]  ", "postedAt": "2023-02-21T13:26:20.191Z", "htmlBody": "<p><strong>SUMMARY</strong></p><p>In this post, we summarise a recently published paper of ours that investigates how people respond to moral arguments, and morally demanding statements, such as \u201cYou are morally obligated to give to charity\u201d . The paper is forthcoming in the [<a href=\"https://reader.elsevier.com/reader/sd/pii/S2214804323000149?token=5C4E12D6EA8FF9CDA8FBCD171F56F6113B11F586F3CAD2F81ED3D0A892672BBC00C94F4F199EFDB37F8F4BBD22FBB1D3&amp;originRegion=eu-west-1&amp;originCreation=20230220124739\"><u>Journal of Behavioural and Experimental Economics</u></a>]. (If you want an ungated copy, please get in touch with either Ben or Philipp).&nbsp;</p><ul><li>We ran two pre-registered experiments with a total sample size of n=3700 participants.</li><li>We compared a control treatment to a moral argument treatment, and we also varied the level of moral demandingness to donate after they read the moral argument. We found that the moral argument increased the frequency and amount of donations. However, increasing the levels of moral demandingness did not translate into higher or lower giving.&nbsp;</li></ul><p>&nbsp;</p><p><strong>BACKGROUND</strong></p><p>The central motivation for our paper was the worry that many have expressed, including a number of philosophers (e.g., Kagan, 1989; Unger, 1996; De Lazari-Radek and Singer, 2010) that having highly morally demanding solicitations for charitable giving may result in reduced (not increased) donations. This possibility of a backfire effect had been raised many times in a variety of contexts but had not been tested empirically. In our paper, we attempted to do just that in the context of donations to Give Directly.</p><p>&nbsp;</p><p><strong>EXPERIMENT DESIGN</strong></p><figure class=\"image image_resized\" style=\"width:72.62%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676985981/mirroredImages/2yrprQuNJpFJKMGWh/mhpbwm1wxfevjtiqb55i.jpg\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676985981/mirroredImages/2yrprQuNJpFJKMGWh/ylnzvaphyavwpqrrrhle.jpg 290w, https://res.cloudinary.com/cea/image/upload/v1676985981/mirroredImages/2yrprQuNJpFJKMGWh/lpqzkhwlefchwrreet5e.jpg 580w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/ghjphqjvsqcqclmru39a.jpg 870w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/piqfktgeg51ocasgcols.jpg 1160w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/ovyrxcjws88dhlwu72ha.jpg 1450w, https://res.cloudinary.com/cea/image/upload/v1676985984/mirroredImages/2yrprQuNJpFJKMGWh/kjavzezvgbavduv2d0ez.jpg 1740w, https://res.cloudinary.com/cea/image/upload/v1676985984/mirroredImages/2yrprQuNJpFJKMGWh/efg3fdhff4ccfqpelmhp.jpg 2030w, https://res.cloudinary.com/cea/image/upload/v1676985984/mirroredImages/2yrprQuNJpFJKMGWh/xyxykd3xwjwunwyr77zt.jpg 2320w, https://res.cloudinary.com/cea/image/upload/v1676985984/mirroredImages/2yrprQuNJpFJKMGWh/bvoeyer1xnc7ucceex4q.jpg 2610w, https://res.cloudinary.com/cea/image/upload/v1676985983/mirroredImages/2yrprQuNJpFJKMGWh/v2m95m0roeyb5sdlf4sy.jpg 2833w\"><figcaption><strong><u>Figure 1: Ovierview of Experiments</u></strong></figcaption></figure><p>In our first study (n=2500), we had five treatments (control, moral argument, inspiration, weak demandingness, and strong demandingness). In the&nbsp;<strong>Control</strong> condition, we showed participants unrelated information about some technicalities of UK parliamentary procedure. In the&nbsp;<strong>Moral Argument</strong> condition, we presented participants with a text about global poverty and the ability of those living in Western countries to help (see figure 2). For the<strong> Inspiration</strong>,&nbsp;<strong>Weak Demandingness</strong>, and&nbsp;<strong>Strong Demandingness</strong> conditions, we used the same text as in the moral argument condition, but added one sentence to each.&nbsp;<br><br><strong>Inspiration</strong>: For these reasons,&nbsp;<strong>you can do a lot of good</strong> if you give money to charities-such as GiveDirectly-to alleviate the suffering of people in developing countries at a minimal cost to yourself.<br><br><strong>Weak Demandingness</strong>: For these reasons,&nbsp;<strong>you should</strong> give money to charities-such as GiveDirectly-to alleviate the suffering of people in developing countries at a minimal cost to yourself.<br><br><strong>Strong Demandingness:</strong> For these reasons,&nbsp;<strong>you are morally obligated</strong> to give money to charities-such as GiveDirectly-to alleviate the suffering of people in developing countries at a minimal cost to yourself.</p><figure class=\"image image_resized\" style=\"width:62.81%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/gh01d8lh8o7joq7x6u2q.jpg\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676985983/mirroredImages/2yrprQuNJpFJKMGWh/odhxetk7bu9vsdx8qrnb.jpg 170w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/dfu8c06uz1wjmm5sho1a.jpg 340w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/grjdty0llqfshgal3vwb.jpg 510w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/jjaaw4ypiu6c3tonhkqh.jpg 680w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/bxju5qdw6qkbjdintjhz.jpg 850w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/ip3rsxfcgfjsquhuugpt.jpg 1020w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/aabpyxwzj1n2dhfeudvv.jpg 1190w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/k7fkhg9z7kdi6gtomgy5.jpg 1360w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/nrrksuqasytap7szx5tc.jpg 1530w, https://res.cloudinary.com/cea/image/upload/v1676985983/mirroredImages/2yrprQuNJpFJKMGWh/dftyvwxg9fizbdauogkv.jpg 1601w\"><figcaption><strong><u>Figure 2: Moral Argument text (Experiment 1)</u></strong></figcaption></figure><p>In this study, we were&nbsp; interested in two comparisons. First, we compared the control and the moral argument conditions to look at the effect of moral arguments on charitable giving. Second, we compared the moral argument with each of the three moral demandingness conditions to investigate whether increasing levels of moral demandingness lead to an increase or reduction in charitable giving.&nbsp;<br><br>In our second study (n=1200), we narrow down our research question by looking only at the conditions of control, moral argument, and strong demandingness. We test the same two main questions as in our first study. The key difference is that the Moral Argument (and demandingness) was presented to participants via the Giving What We Can Website (see Figure 3). This was done to mitigate experimenter demand effects, as well as to provide a more natural vehicle for the information to be delivered.</p><p>In both studies, after reading the randomly allotted text, participants could choose to donate some, none, or all of their earnings (20 ECUs, where 1 ECU=\u00a30.05) to the charity GiveDirectly.&nbsp;</p><figure class=\"image image_resized\" style=\"width:100%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/vn7zej0p3klzminc5jha.jpg\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/pdwznrm8eefaoi00fkl4.jpg 91w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/dzxdes3iixntxacklzzr.jpg 171w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/hvpjjvnbnchwcytmoyvy.jpg 251w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/zzykwbirjipnxcrfztdq.jpg 331w, https://res.cloudinary.com/cea/image/upload/v1676985983/mirroredImages/2yrprQuNJpFJKMGWh/mnhzdqmfnsijttlcvb8s.jpg 411w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/qryb18pr7nqwwujegfds.jpg 491w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/zvlifgukyb0nnbvbtz0t.jpg 571w\"><figcaption><strong><u>Figure 3: Moral Argument text (Experiment 2)</u></strong></figcaption></figure><p>&nbsp;</p><p><strong>RESULTS</strong></p><p>The main results of experiment 1 &amp; 2 are provided in Figures 4 &amp; 5 respectively.&nbsp;</p><figure class=\"image image_resized\" style=\"width:82.13%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/ac7knbbkr1uqivtsfuxg.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676985983/mirroredImages/2yrprQuNJpFJKMGWh/ndtioopvwnhcxtgskcsh.png 99w, https://res.cloudinary.com/cea/image/upload/v1676985983/mirroredImages/2yrprQuNJpFJKMGWh/xvib8ekb7b6mv9mgk46x.png 179w, https://res.cloudinary.com/cea/image/upload/v1676985983/mirroredImages/2yrprQuNJpFJKMGWh/izyzaoigxbkj39krzuil.png 259w, https://res.cloudinary.com/cea/image/upload/v1676985983/mirroredImages/2yrprQuNJpFJKMGWh/twrsnq7awqstvc8w6lq8.png 339w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/hipslahiwjor6kbsdvoe.png 419w, https://res.cloudinary.com/cea/image/upload/v1676985983/mirroredImages/2yrprQuNJpFJKMGWh/wygkldk1vxkkj6gfzesn.png 499w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/srawalfsoot0estnvyyr.png 579w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/r9dwetamwvvwa8vdctyv.png 659w\"><figcaption><strong><u>Figure 4: Experiment 1 Results</u></strong></figcaption></figure><figure class=\"image image_resized\" style=\"width:82.27%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/gr4jz2iqrjgr7i58m1nz.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676985983/mirroredImages/2yrprQuNJpFJKMGWh/mopnnrok0vvonqprj3j8.png 100w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/zaucjfsvigadc9cb1qwg.png 180w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/ljgxxm9sm0hfcgjojqc1.png 260w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/sxnfymrbkjmmjilzfjvu.png 340w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/w8tsxlt6xsushck2yzp8.png 420w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/zy3ygxnm4uujqok4mnl7.png 500w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/pcd79xmwtsjlapzvfmi6.png 580w, https://res.cloudinary.com/cea/image/upload/v1676985982/mirroredImages/2yrprQuNJpFJKMGWh/va4atgovaa2rhsujkhbr.png 660w\"><figcaption><strong><u>Figure 5: Experiment 2 Results:</u></strong></figcaption></figure><p><u>Result 1a</u>: Across both experiments&nbsp;<strong>we found</strong> that moral arguments increased how likely people were to donate (11 percentage points more in E1 and 12 percentage points more in E2).&nbsp;</p><p><u>Result 1b:</u> Across both experiments&nbsp;<strong>we found</strong> that moral arguments increased the total amount of money donated&nbsp; (51.7% more in E1 and 42.9% more in E2).&nbsp;</p><p><u>Result 2:</u> We&nbsp;<strong>did not find&nbsp;</strong>any<strong>&nbsp;</strong>evidence that inspiration and weak demandingness affected donation behaviour.&nbsp;</p><p><u>Result 3a</u>: Strong demandingness&nbsp;<strong>did not</strong> have an effect on donation frequency compared to the Moral argument treatment. Our evidence suggests, that the effect of the Strong Demandingness treatment is either null or smaller than a 10% increase or decrease in the frequency of donation compared to the Moral Argument treatment (and 7.5% for Study 2)</p><p><u>Result 3b</u>: We found some weak evidence that Strong Demandingness results in a smaller amount of donations, conditional on a participant choosing to donate in study 1. However, this does not replicate in Experiment 2.&nbsp;</p><p>&nbsp;</p><p><strong><u>Data on GWWC Pledges (not in the paper)&nbsp;</u></strong></p><p>At the end of the study, participants read a short description of GWWC,&nbsp; where we varied whether the pledge was 1% or 10% of income. The description was as follows:</p><p>&nbsp;</p><p><i>\u201cGiving What We Can is an organisation that supports people in their&nbsp;commitment to helping others and learning about effective giving. They aim to create a culture where people are inspired to&nbsp;give more, and give more effectively.&nbsp;</i></p><p><i>Giving What We Can offers the opportunity to sign a pledge to donate 10% of your income to charity.</i>\u201d&nbsp;</p><p>&nbsp;</p><p>We then asked participants on a 5p point Likert Scale \u201cHow likely are you to take this Giving What We Can Pledge at some point in your life?\u201d [1= Very Unlikely 5=Very Likely]</p><p>We found that those in the 1% condition (mean 2.47) were significantly more likely to say they would take the pledge than the 10% condition (mean 2.0) Kruskal-Wallis test, p&lt;0.001.&nbsp;</p><p>We also provided a link to GWWC if they wanted to learn more. 55 out of 1094 participants clicked the link. In the 1% condition 34/601 clicked the link and 21/593 in the 10% condition (chi-squared test, p=0.081).</p><p>&nbsp;</p><p><strong>LIMITATIONS</strong></p><p>There are a number of limitations to this paper worth noting.&nbsp;</p><ul><li><strong><u>Persistence:</u></strong> We only analysed one donation decision. However, we should care about long term behaviour and whether these effects (or lack of effects) persist in the future.&nbsp;</li></ul><p>&nbsp;</p><ul><li><strong><u>Small Stakes</u>:</strong> Participants earnings were only \u00a31. While this does have real costs for Prolific participants (average earnings is \u00a36-\u00a310 an hour) it may be the case that their behaviour would differ for larger stakes.&nbsp;&nbsp;</li></ul><p>&nbsp;</p><ul><li><strong><u>Moral Argument watered down demandingness</u>:</strong> Given the Moral Argument text was two paragraphs, and the moral demandingness text was 2 sentences. It is possible that the Moral Argument captured most of the participants\u2019 attention. It would be interesting to observe how the moral demandingness statements perform with no moral argument.&nbsp;</li></ul><p>&nbsp;</p><ul><li><strong><u>Heterogeneity in responses:</u></strong> While on average, morally demanding statements did not affect donation behaviour, it could be the case that it affects different types of people in different ways. For example, in E1 we found some differences between males and females (but this did not replicate in E2). However, there may be other traits we didn\u2019t measure where heterogeneous effects exist.&nbsp;</li></ul><p>&nbsp;</p><p><strong>ACKNOWLEDGEMENTS</strong></p><p>We want to thank Philip Grossman, Benjamin Sachs, Zach Freitas-Groff, Theron Pummer, Lata Ganghadaran, Erte Xiao, Brian Jabarian, Kirby Nielsen, David Rhys Bernard, Joshua Miller, Hayden Wilkinson, Tyler John, Miguel Costa-Gomes, Peter Singer, Toby Handfield, David&nbsp; Reinstein and Nina Xue for helpful comments and suggestions. We also want to thank Luke Freeman for his help and support when he had no obligation to do so. This work was supported by a grant from the Forethought Foundation and the Centre for Effective Altruism as well as additional research funding from Giving What We Can.</p><p>&nbsp;</p><p><strong>REFERENCES</strong></p><p>De Lazari-Radek, K., Singer, P., 2010. Secrecy in Consequentialism: A Defence of Esoteric Morality.&nbsp;<i>Ratio</i>, 23 (1), 34-58.&nbsp;</p><p>Kagan, S., 1989. The Limits of Morality. New York: Oxford University Press.&nbsp;&nbsp;</p><p>Unger, P. K., 1996.&nbsp;<i>Living High and Letting Die: Our Illusion of Innocence</i>. Oxford University Press&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p><br>&nbsp;</p>", "user": {"username": "benleo"}}, {"_id": "kCmkwRaP4pQMokPQC", "title": "How WHO estimate malaria cases and mortality", "postedAt": "2023-02-22T04:23:18.769Z", "htmlBody": "<h2>Introduction</h2><p>In the World Malaria Report 2022, WHO estimated that in 2021 there were <strong>247,430,170 cases</strong> of malaria<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefy5ojlhznl5\"><sup><a href=\"#fny5ojlhznl5\">[1]</a></sup></span>, resulting in <strong>618,975 deaths</strong>. This post is a high-level description of how they arrived at these figures<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvmr3m0b61tl\"><sup><a href=\"#fnvmr3m0b61tl\">[2]</a></sup></span>. This method is used by WHO for all estimates from 2000 to present but the exact details and models are updated annually and applied retroactively (see Appendix). I will be referring specifically to the 2021 estimates.</p><p>Malaria cases and mortality were estimated for the 108 countries that were endemic in the year 2000. For each of these countries, one of three methods were used to estimate cases<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhruhd7gtek\"><sup><a href=\"#fnhruhd7gtek\">[3]</a></sup></span>:</p><ol><li>Direct</li><li>Surveillance</li><li>Cartographic</li></ol><p>And one of three methods were used to estimate mortality:</p><ol><li>Direct</li><li>Case Fatality Rate (CFR)</li><li>Cause of Death (CoD)</li></ol><p>In general, these methods are ordered in increasing order of malaria endemicity in the country being assessed. Countries that were modelled for cases using the cartographic method were typically modelled for mortality using the CoD method:</p><figure class=\"table\"><table><tbody><tr><td style=\"background-color:hsl(0, 0%, 90%);text-align:center\" colspan=\"2\" rowspan=\"2\"><strong>COUNTRY COUNT</strong></td><td style=\"text-align:center\" colspan=\"3\"><strong>Mortality Method</strong></td></tr><tr><td style=\"text-align:center;width:120px\">Direct</td><td style=\"text-align:center;width:120px\">CFR</td><td style=\"text-align:center;width:120px\">CoD</td></tr><tr><td rowspan=\"3\"><strong>Case Method</strong></td><td style=\"text-align:center\">Direct</td><td style=\"text-align:center\">36 &nbsp;</td><td style=\"text-align:center\">3</td><td style=\"text-align:center\">0</td></tr><tr><td style=\"text-align:center\">Surveillance</td><td style=\"text-align:center\">6&nbsp;</td><td style=\"text-align:center\">29&nbsp;</td><td style=\"text-align:center\">4</td></tr><tr><td style=\"text-align:center\">Cartographic</td><td style=\"text-align:center\">0&nbsp;</td><td style=\"text-align:center\">2</td><td style=\"text-align:center\">28</td></tr></tbody></table></figure><p>And were the areas that accounted for the majority of the malaria burden:</p><figure class=\"table\"><table><tbody><tr><td style=\"background-color:hsl(0, 0%, 90%);text-align:center\" colspan=\"2\" rowspan=\"2\"><strong>MORTALITY %</strong></td><td style=\"text-align:center\" colspan=\"3\"><strong>Mortality Method</strong></td></tr><tr><td style=\"text-align:center;width:120px\">Direct</td><td style=\"text-align:center;width:120px\">CFR</td><td style=\"text-align:center;width:120px\">CoD</td></tr><tr><td rowspan=\"3\"><strong>Case Method</strong></td><td style=\"text-align:center\">Direct</td><td style=\"text-align:center\">0.01</td><td style=\"text-align:center\">0.02</td><td style=\"text-align:center\">0.00</td></tr><tr><td style=\"text-align:center\">Surveillance</td><td style=\"text-align:center\">0.01&nbsp;</td><td style=\"text-align:center\">5.94</td><td style=\"text-align:center\">1.52</td></tr><tr><td style=\"text-align:center\">Cartographic</td><td style=\"text-align:center\">0.00&nbsp;</td><td style=\"text-align:center\">1.66</td><td style=\"text-align:center\">90.83</td></tr></tbody></table></figure><h2>&nbsp;</h2><h2>Counting via Direct Methods (both cases and mortality)</h2><p>This was used for countries with robust reporting systems, and no to very low malaria endemicity. It is very straight-forward. National malaria programs reported the data and WHO made no adjustments.</p><p>&nbsp;</p><h2>Estimating Cases</h2><h3>Surveillance Method</h3><p>This was used for countries with reasonable reporting quality and low endemicity, typically outside of Africa however there were some exceptions.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe0grzn8wdb\"><sup><a href=\"#fne0grzn8wdb\">[4]</a></sup></span>&nbsp;Adjustments to reported case figures were made to account for:</p><ul><li>Proportion of suspected cases with parasitaemia. Some cases are treated as malaria without a test to confirm and so these cases were multiplied by the positivity rate of those cases that were tested.</li><li>Proportion of population seeking treatment from the private sector, since national malaria programs typically only track cases via the public sector.</li><li>Proportion of population not seeking treatment.</li><li>Reporting completeness.</li><li>Ad hoc adjustments, such as perceived effect of COVID-19 on the above and other variables<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcyuu988ptvl\"><sup><a href=\"#fncyuu988ptvl\">[5]</a></sup></span>.</li></ul><h3>Cartographic Method</h3><p>This was used for countries with particularly poor reporting of clinical incidence, due to high endemicity and/or inadequate reporting systems in general. All 30 of these countries are in sub-Saharan Africa<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcxfiqu0kqdm\"><sup><a href=\"#fncxfiqu0kqdm\">[6]</a></sup></span>.</p><p><a href=\"https://malariaatlas.org/\"><u>Malaria Atlas Project (MAP)</u></a>&nbsp;provided these estimates. Despite inadequate records of clinical incidence, surveys of parasite prevalence in these regions are particularly frequent and widespread. MAP estimates a standardised measure of <i>P. falciparum </i>prevalence (<i>Pf</i>PR<sub>2-10</sub><i>)</i>&nbsp;from these surveys<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref57dncavyvi3\"><sup><a href=\"#fn57dncavyvi3\">[7]</a></sup></span>. They then use data pertaining to the local environment, malaria control interventions, and mosquito and human habits to predict average <i>Pf</i>PR<sub>2-10</sub>&nbsp;annually for every 5x5km pixel square<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaipfdilf1ui\"><sup><a href=\"#fnaipfdilf1ui\">[8]</a></sup></span>. A further model<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefm6i3l0c3m9t\"><sup><a href=\"#fnm6i3l0c3m9t\">[9]</a></sup></span>&nbsp;is used to estimate clinical incidence across all ages (grouped 0-5 year old, 5-15 year old and &gt;15 year old) given <i>Pf</i>PR<sub>2-10</sub>, the seasonality of transmission, and historical treatment/exposure<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4vyp7bkweqc\"><sup><a href=\"#fn4vyp7bkweqc\">[10]</a></sup></span>.</p><p><i>P. vivax</i>&nbsp;prevalence and clinical incidence were predicted from taking <i>P. falciparum</i>&nbsp;predictions and applying reported proportions of <i>P. vivax </i>to <i>P. falciparum</i>&nbsp;cases<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2185rxhlw2m\"><sup><a href=\"#fn2185rxhlw2m\">[11]</a></sup></span>. In the WHO African Region, this proportion was just 0.3%<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefa9cqz205ncp\"><sup><a href=\"#fna9cqz205ncp\">[12]</a></sup></span>&nbsp;so I did not review this process.</p><p>As with the surveillance method, adjustments have been made based on perceived effects of COVID-19.</p><p>&nbsp;</p><h2>Estimating Mortality</h2><h3>Case Fatality Rate (CFR) Method&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong> &nbsp;&nbsp;</strong></h3><p>This was used for countries with relatively low endemicity, but where reporting is not complete enough to directly count figures. It was mostly used for countries outside of Africa however there are some exceptions.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3m6dran5cn7\"><sup><a href=\"#fn3m6dran5cn7\">[13]</a></sup></span></p><p>For overall mortality, case fatality rates of 0.256% and 0.0375% were applied to the estimated <i>P. falciparum </i>and <i>P. vivax</i>&nbsp;cases, respectively. These rates are averages/midpoints in relevant literature.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkumq688fh0s\"><sup><a href=\"#fnkumq688fh0s\">[14]</a></sup></span></p><p>Separately, they estimated what proportion of these fatalities are children under five using the function<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgelz3ugd6tk\"><sup><a href=\"#fngelz3ugd6tk\">[15]</a></sup></span>:</p><p><i>Proportion of deaths<sub>under 5 </sub>= \u20130.2288 \u00d7 Mortality<sub>overall</sub><sup>2</sup>&nbsp;+ 0.823 \u00d7 Mortality<sub>overall</sub>&nbsp;+ 0.2239</i></p><p>where<i>&nbsp;Mortality<sub>overall</sub></i>&nbsp;is the overall mortality estimate for every 1000 of the population at risk.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvlo9dc62rsl\"><sup><a href=\"#fnvlo9dc62rsl\">[16]</a></sup></span></p><p>WHO made no mention of adjustments due to COVID disruptions. My assumption is that this is due to the effect being covered in making the case estimates to which CFRs are applied.</p><h3>Cause of Death (CoD) Method</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This was used for countries where a high proportion of deaths are due to malaria. All 32 of these countries are in sub-Saharan Africa<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref58d23rti1cc\"><sup><a href=\"#fn58d23rti1cc\">[17]</a></sup></span>&nbsp;and as stated previously around 90% of global estimated mortality is derived from this method.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;First, WHO estimated under-five mortality using a model that took CoD studies and official registries to infer, at a country-level and for the years 2000-2019, what fraction of deaths under five were due to various causes.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoxy3zfyeo3l\"><sup><a href=\"#fnoxy3zfyeo3l\">[18]</a></sup></span>&nbsp;They then applied these 2019 malaria proportions to separate UN country-level estimates of overall child mortality in 2021, to arrive at the country-level estimates for under-five mortality.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;They then used the following function to estimate what proportion of deaths are of over five year olds, and applied it to estimated under-five fatalities to estimate over-five fatalities<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgelz3ugd6tk\"><sup><a href=\"#fngelz3ugd6tk\">[15]</a></sup></span>:</p><p><i>Proportion of deaths<sub>over 5 </sub>= \u20130.293 \u00d7 Mortality<sub>under 5</sub><sup>2 </sup>+ 0.8918 \u00d7 Mortality<sub>under 5</sub>&nbsp;+ 0.2896</i></p><p>where <i>Mortality<sub>under 5</sub></i>&nbsp;is the under-five mortality estimate for every 1000 of the population at risk.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvlo9dc62rsl\"><sup><a href=\"#fnvlo9dc62rsl\">[16]</a></sup></span></p><p>For the impact of COVID-19 disruptions, WHO again depended upon some MAP modelling. MAP provided mortality estimates, with and without diagnosis and treatment disruptions,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefc0gixvu7onl\"><sup><a href=\"#fnc0gixvu7onl\">[19]</a></sup></span>&nbsp;and the relative increase in mortality MAP predicted due to the disruptions, WHO applied to their own mortality estimates.</p><p>&nbsp;</p><h2>Appendix</h2><p>With each annual World Malaria Report, estimates for previous years are updated. These updates can be significant, as was the case for the 2021 report, due to new modelling of CoD fractions for children under five.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoxy3zfyeo3l\"><sup><a href=\"#fnoxy3zfyeo3l\">[18]</a></sup></span>&nbsp;This new model estimated that a greater proportion of under-five deaths had been caused by malaria than previously estimated. Recently, this was 7.8% of under-five deaths globally, compared to 4.8% predicted by the old model.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefv2y3tj0onee\"><sup><a href=\"#fnv2y3tj0onee\">[20]</a></sup></span>&nbsp;This caused estimated mortality from malaria to increase for all reported years (i.e. back to 2000). The estimate for 2019 changed from 409,000 to 558,000. Obviously, the impact of using these higher CoD fractions for malaria continued with the 2022 World Malaria Report estimates:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676988235/mirroredImages/kCmkwRaP4pQMokPQC/tkzwxh0r7z9g7t73i5bc.png\" alt=\"\"></p><p>I included the IHME (i.e. 2019 GBD study) estimates for comparison. I will not attempt to review and describe how the modelling differs from that of WHO, except to comment that:</p><ol><li>Estimations of cases are more similar than fatalities (hence they mostly differ by estimated case fatality rates).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefeum0d82444r\"><sup><a href=\"#fneum0d82444r\">[21]</a></sup></span></li><li>IHME estimations were especially reliant on the modelling by MAP.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhtcqise5vfc\"><sup><a href=\"#fnhtcqise5vfc\">[22]</a></sup></span></li></ol><p>&nbsp;</p><p><i>Note: I did not get this post reviewed nor fact-checked. If you suspect there might be an error somewhere please let me know.</i></p><h2>Footnotes</h2><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fny5ojlhznl5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefy5ojlhznl5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Parasitemia with a fever.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvmr3m0b61tl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvmr3m0b61tl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This is largely just a summary of the annex for Table 3.1. in the <a href=\"https://www.who.int/publications/i/item/9789240064898\"><u>World malaria report 2022</u></a>&nbsp;(pp.132-136). It can be considered the source for all statements in this post, unless stated/cited otherwise. In the post, I am only attempting to describe (i.e. avoiding analysis and opinions).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhruhd7gtek\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhruhd7gtek\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;WHO do not name these methods. \u201cCartographic\u201d and \u201csurveillance\u201d I got from the naming given to corresponding regions in MAP modelling (see <a href=\"https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(19)31097-9/fulltext\"><u>Weiss et al., 2019</u></a>), and the other names seemed appropriate to me.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne0grzn8wdb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe0grzn8wdb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The surveillance approach was used for the African countries: Botswana, Eritrea, Ethiopia, the Gambia, Madagascar, Mauritania, Namibia, Rwanda, Senegal, Zimbabwe.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncyuu988ptvl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcyuu988ptvl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Impact of COVID-19 was country-dependent. In several countries, impact was considered <i>positive</i> due to movement disruptions helping to slow malaria transmission. However, globally it was considered to have a net negative effect due to disruptions in interventions and treatment.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncxfiqu0kqdm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcxfiqu0kqdm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Angola, Benin, Burkina Faso, Burundi, Cameroon, Central African Republic, Chad, Congo, C\u00f4te d\u2019Ivoire, DRC, Equatorial Guinea, Gabon, Ghana, Guinea, Guinea-Bissau, Kenya, Liberia, Malawi, Mali, Mozambique, Niger, Nigeria, Sierra Leone, Somalia, South Sudan, Sudan, Togo, Uganda, Tanzania, Zambia.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn57dncavyvi3\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref57dncavyvi3\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cPrevalence\u201d is the proportion of people infected by the malaria parasite. Standardisation is required due to the differing accuracy of <a href=\"https://link.springer.com/article/10.1186/s12936-015-0984-9\"><u>diagnosis methods</u></a>&nbsp;(microscopy, RDT and PCR) and a <a href=\"https://link.springer.com/article/10.1186/1475-2875-6-131\"><u>relationship between parasite prevalence and age</u></a>. <i>Pf</i>PR<i><sub>2-10</sub></i>&nbsp;stands for <i>P. falciparum </i>prevalence in children aged 2-10 years. Frequently, being infected with the parasite does not result in symptoms (it is dependent on level of infection, natural immunity, and likely much more).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaipfdilf1ui\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaipfdilf1ui\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(19)31097-9/fulltext\"><u>Weiss et al. (2019)</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnm6i3l0c3m9t\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefm6i3l0c3m9t\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.nature.com/articles/ncomms9170\"><u>Cameron et al. (2015)</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4vyp7bkweqc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4vyp7bkweqc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;To account for natural immunity.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2185rxhlw2m\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2185rxhlw2m\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6675736/\"><u>Battle et al. (2019)</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fna9cqz205ncp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefa9cqz205ncp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Table 3.2, <a href=\"https://www.who.int/publications/i/item/9789240064898\"><u>World malaria report 2022</u></a>&nbsp;. \u201cWHO African Region\u201d does not include all countries on the African mainland. There are several African countries in the WHO Eastern Mediterranean Region, that geographically is hard to explain but looks correlated with being Arab states. Just three of these countries have current malaria endemicity (Sudan, Somalia and Djibouti).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3m6dran5cn7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3m6dran5cn7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Botswana, the Comoros, Djibouti, Eritrea, Eswatini, Ethiopia, Madagascar, Namibia, Somalia, Sudan, Zimbabwe.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkumq688fh0s\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkumq688fh0s\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For <i>P. falciparum</i>, WHO cites: <a href=\"https://doi.org/10.1016/S0169-4758(98)01296-4\"><u>Alles et al., (1998)</u></a>; <a href=\"https://doi.org/10.1016/S0035-9203(97)90066-3\"><u>Luxemburger et al., (1997)</u></a>; <a href=\"https://pubmed.ncbi.nlm.nih.gov/3067373/\"><u>Meek, (1988)</u></a>; unpublished data from Indonesia (2004-2009). For <i>P. vivax</i>, WHO cites: <a href=\"https://doi.org/10.1186/s12916-014-0217-z\"><u>Douglas et al. (2014)</u></a>. At first glance, this method seems surprisingly weak, however it contributes relatively little to overall estimate and I am not attempting any analysis in this post.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngelz3ugd6tk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgelz3ugd6tk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The function in the CFR method for estimating proportion of deaths under five, and in the CoD method for estimating proportion of deaths over five, are derived from modelling in <a href=\"https://www.researchgate.net/profile/Thomas-Smith-69/publication/6856253_An_epidemiologic_model_of_severe_morbidity_and_mortality_caused_by_Plasmodium_falciparum/links/5953a72e458515a207028f36/An-epidemiologic-model-of-severe-morbidity-and-mortality-caused-by-Plasmodium-falciparum.pdf\"><u>Ross et al. (2006)</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvlo9dc62rsl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvlo9dc62rsl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cPopulation at risk\u201d is 100% of population at risk in \u201chigh endemic areas\u201d plus 50% of population at risk in \u201clow endemic areas.\u201d I do not know the criteria for classifying high or low endemic areas.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn58d23rti1cc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref58d23rti1cc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Angola, Benin, Burkina Faso, Burundi, Cameroon, Central African Republic, Chad, Congo, C\u00f4te d\u2019Ivoire, DRC, Equatorial Guinea, Gabon, Gambia, Ghana, Guinea, Guinea-Bissau, Kenya, Liberia, Malawi, Mali, Mauritania, Mozambique, Niger, Nigeria, Rwanda, Senegal, Sierra Leone, South Sudan, Togo, Uganda, Tanzania, Zambia.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnoxy3zfyeo3l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefoxy3zfyeo3l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S2352464221003114\"><u>Perin et al. (2022)</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnc0gixvu7onl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefc0gixvu7onl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;But in both scenarios disruptions in malaria <i>prevention </i>interventions (like LLIN distributions) were included. WHO does not explain the rationale and I have not looked into it.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnv2y3tj0onee\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefv2y3tj0onee\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://www.who.int/teams/global-malaria-programme/reports/world-malaria-report-2021\">World Malaria Report 2021</a> (p. 22)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fneum0d82444r\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefeum0d82444r\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Feel free to browse my <a href=\"https://docs.google.com/spreadsheets/d/16Gs3tMmZQpHRC1by6E8lVzsITntiLGSUxtOQA-Y31nY/edit#gid=212102192\"><u>Google sheets</u></a> for this post.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhtcqise5vfc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhtcqise5vfc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_MALARIA_2000_2019_INFO_SHEET_Y2020M08D31.PDF\"><u>IHME Data Release Information Sheet</u></a></p></div></li></ol>", "user": {"username": "Punty"}}, {"_id": "4FnzE6eCEAbwTux99", "title": "Does most of your impact come from what you do soon?", "postedAt": "2023-02-21T05:12:50.247Z", "htmlBody": "<p>Over the last couple months I\u2019ve noticed myself flipping back and forth between two mindsets: \u201cI should try to be useful soon\u201d and \u201cI should build skills so that I am more useful in 5+ years.\u201d I\u2019ve compiled arguments for each view in this post. Note that a lot of this is specific to undergrads who want to reduce AI risk.</p><p>So, which is the better heuristic? Trying to be usfeul soon or useful later? I don't think there\u2019s a one-size-fits-all answer to that question. The arguments below apply to differing extents depending on the specific career path and person; so I think this list is mostly useful as a reference when comparing careers.</p><p>To clarify, when I say someone is following the \u201cuseful soon\u201d heuristic, I mean they operate similar to how they would operate if they were going to retire soon. This is not the same as behaving like timelines are short. For example, undergraduate field building makes a lot of sense under a \"useful soon\" mindset but less so under short timelines.</p><h1>To what extent is [being useful soon] in tension with [being useful later]?</h1><p>Can you have your cake and eat it too? Certainly not always. Here are career paths where this trade off clearly exists:</p><ol><li><strong>Useful soon: being a generalist for The Center for AI Safety (CAIS)</strong>. CAIS is one of the projects I am most excited about, but the way I can be most helpful to them involves helping with ops, sending emails, etc; I would be more impactful in 5+ years if I worked towards a more specific niche.</li><li><strong>Useful soon: university field building.&nbsp;</strong>If I spend most of my time organizing fellowship programs, running courses, etc, I won\u2019t learn as quickly as I would if I focus on my own growth.</li><li><strong>Useful later:&nbsp;whole brain emulation.</strong>&nbsp;If I tried to position myself to launch a WBE megaproject in 10 years, I would be approximately useless in the meantime.</li><li><strong>Useful later: earn-to-give entrepreneurship:&nbsp;</strong>It takes 7 years on average for unicorns to achieve unicorn status.</li></ol><p>Career paths where this trade off isn\u2019t as obviously present:</p><ol><li><strong>AI safety technical research:&nbsp;</strong>In the near term, technical researchers can produce useful work and mentor people. They also build skills that are useful in the long term.</li><li><strong>AI governance research:&nbsp;</strong>similar points apply as in technical research \u2013 though I can see a stronger case for the discount rate mattering here. From what I can tell, there are two main theories of change in AI governance: (1) acquire influence, skills, and knowledge so you can help actors make decisions when the stakes are high. (2) Forecast AI development to inform decisions&nbsp;<i>now.&nbsp;</i>Optimizing for 1 could look pretty different from optimizing for 2.</li></ol><h1>Arguments for trying to be useful soon</h1><p><strong>Impact often compounds.&nbsp;</strong>The impact of an intervention often grows substantially over time, implying high returns to earliness. Examples:</p><ul><li>John gets involved in AI risk through a student group. The impact of this intervention increases as John becomes more skilled.</li><li>Amy publishes a research paper that establishes a new AI safety subproblem. The impact of this intervention grows as more papers are written about the subproblem.</li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676956370/mirroredImages/4FnzE6eCEAbwTux99/nygk98gqd7ax2jqodlwa.png\"></p><p><strong>Crowdedness increases over time. </strong>The number of AI safety researchers has been growing&nbsp;<a href=\"https://www.lesswrong.com/posts/mC3oeq62DWeqxiNBx/estimating-the-current-and-future-number-of-ai-safety#:~:text=The%20model%20estimates%20that%20the,28%25%20per%20year%20since%202000.\"><u>28%</u></a> per year since 2000. The more people start paying attention to AI risk and trying to reduce it, the less impactful your individual actions are likely to be. This is especially true if newcomers can rapidly catch up or surpass your skill level. For example,&nbsp;<a href=\"https://philosophy.safe.ai/\"><u>philosophers</u></a> with years of research experience may rapidly catch up and surpass undergrads like me in conceptual research.</p><p><strong>It\u2019s hard to predict what will be useful &gt;5 years from now. </strong>You might spend 8 years launching startups, but by the time you make it big, Eric Shmit and Jeff Bezos are big donors for AI safety research and your $100 million is a drop in the bucket.</p><p><a href=\"https://www.amazon.com/Lean-Startup-Entrepreneurs-Continuous-Innovation/dp/0307887898\"><strong>Iteration is better than planning</strong></a><strong>: using current usefulness as a proxy for future usefulness. </strong>Making incremental adjustments to increase your current usefulness is much easier than planning out how you will be super useful in the future. \u201c<a href=\"https://en.wikipedia.org/wiki/Orgel's_rules\"><u>Evolution is cleverer than you are.</u></a>\u201d<br><br><strong>More undergrads will probably choose \u201cuseful later\u201d paths than is optimal due to risk aversion. </strong>Social momentum pushes in the direction of getting a PhD, finishing school, etc. Also, I\u2019m more risk tolerant than most other undergraduates involved in AI risk, so I expect more than the optimal amount of people to pursue these \u201cuseful later\u201d paths.<br><br><strong>Short timelines. </strong>Capability progress is moving quickly and many well informed and intelligent people have timelines as short as 5 years (e.g.&nbsp;<a href=\"https://www.lesswrong.com/posts/Gc9FGtdXhK9sCSEYu/what-a-compute-centric-framework-says-about-ai-takeoff?commentId=YAraBzHPTHjHQG56X\"><u>Daniel Kokotajlo</u></a> and&nbsp;<a href=\"https://www.youtube.com/watch?v=Oz4G9zrlAGs\"><u>Connor Leahy</u></a>).</p><h1>Arguments for trying to be useful later</h1><p><strong>Skillsets that will be more useful in the future are systematically neglected. </strong>Research engineers are in demand right now, and as a result, everyone wants to be one. There are probably high-value skill sets that are not on people\u2019s radar because they aren\u2019t super high-value yet. Some speculative examples:</p><ul><li>Public relations: AI and AI risk are getting more attention from the public. What can thought leaders do to shape the narrative in a beneficial way? Does anyone have the appropriate background to answer these questions?</li><li>Physical engineering / neuroscience: imitating human cognition is arguably safer than other routes to&nbsp;<a href=\"https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/\"><u>PASTA</u></a>. Maybe imitating human cognition could be achieved with next-token-prediction on neurolink signals or maybe it requires scanning whole brains. Even if AGI is developed before these methods are feasible, actors might be willing to wait for a safer alternative before kicking off an intelligence explosion.</li><li>Custom AI hardware: expertise in this area&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/BJtekdKrAufyKhBGw/ai-governance-needs-technical-work\"><u>could be useful in governance</u></a> (what if we could put gps modules in every AI chip that were impossible to disable?). I can also imagine applications in technical AI safety research. For example, alternative hardware might allow&nbsp;<a href=\"https://arxiv.org/abs/2209.01667\"><u>sparse models</u></a> to be competitive, which may in turn increase the viability of mechanistic interpretability by reducing&nbsp;<a href=\"https://transformer-circuits.pub/2022/toy_model/index.html\"><u>polysemanticity</u></a>.</li></ul><p>This conflicts with the \u201cprediction is hard\u201d point. The question is not whether prediction is easy or hard. It is whether people are generally not doing enough of it when selecting career paths (I think there's plenty of alpha to be gained from prescience at the moment).<br>&nbsp;</p><p><strong>Tail career outcomes are systematically neglected and require years of building career capital. </strong><i>Go big or go home&nbsp;</i>career paths might be systematically neglected due to risk aversion. These paths also tend to require a lot of time to pay off. Examples include:</p><ul><li>Starting a billion dollar company</li><li>Becoming a congress representative</li><li>Launching a whole brain emulation megaproject.</li></ul><p>This point conflicts with \u201cmost young people will choose \u2018useful later\u2019 paths.\u201d It really depends on the career. I expect lots of AI risk-pilled students to get ML PhDs, but very few to get neuroscience PhDs in pursuit of whole brain emulation.<br><br><strong>If most of your impact is in the future, trading near-term impact for future impact is generally a good idea.</strong></p><p>This is a counter argument to the claim that you&nbsp;<i>are&nbsp;</i>likely to be much more impactful in the future, but you might as well supplement that with near-term impact. I think either you in fact expect your near term impact (e.g field building) to be significant, or it\u2019s generally better to trade near-term impact for longer term impact.</p><p>Let\u2019s say you can increase your near-term impact by 5x by helping to facilitate an AI safety course or you can increase your expected future impact by 2x by using that time to get better grades and get your name on (potentially useless) papers. If you expect your future work to be more than 2.5x as important as your university organizing, you should choose the second option. The correct model probably isn\u2019t strictly multiplicative, but I think it\u2019s intuitively clear that changing the variables that affect large EV parts of the equation will generally make a larger difference than changing the variables that affect the smaller EV parts.</p><p><strong>Feelings of urgency may be counterproductive for some people</strong></p><p>If people think they have to be useful soon they might:</p><ul><li>work unsustainable hours</li><li>feel anxious</li><li>become desperate and take foolish actions</li></ul><p>I was substantially more anxious when I thought most of my impact was going to come from what I did in the next few years.</p>", "user": {"username": "Joshua Clymer"}}, {"_id": "oGBBxHBPcsygYt4SE", "title": "Shallow Report on Nuclear War (Arsenal Limitation)", "postedAt": "2023-02-21T04:57:06.373Z", "htmlBody": "<p><strong>Note</strong>: This report was produced with only one week of desktop research, for the purpose of identifying promising causes to evaluate at depth. We only have low confidence in our findings here, and the conclusions should generally be taken by readers as merely suggestive rather determinative.</p><h1><br><strong><u>Summary</u></strong></h1><p>Considering the expected benefits of eliminating the risk of nuclear war (i.e. averting nuclear war fatalities, averting nuclear war injuries, and consequently greater economic output), the expected costs (i.e. more conventional war fatalities, more conventional war injuries, and hence decreased economic output), as well as the tractability of lobbying for arsenal limitation, I find that the marginal expected value of lobbying for arsenal limitation to mitigate nuclear war to be&nbsp;<strong>3,341,695 DALYs per USD 100,000</strong>, which is around 5000x as cost-effective as giving to a GiveWell top charity (<a href=\"https://docs.google.com/spreadsheets/d/16kcIRUwL9UlsXDbAeplUXkjdN356TuJY1zbRVftFlmQ/\"><u>CEA</u></a>).</p><p>Key Points</p><ul><li>Importance: This is a strongly important cause, with&nbsp;<strong>3.88 * 10<sup>10</sup></strong>&nbsp;<strong>DALYs&nbsp;</strong>at stake from now to the indefinite future. The expected benefits totally swamp the expected costs (with the latter being &lt;0.001% of the former), and overall, around 81% of the burden is health related, while 19% is economic in nature.</li><li>Neglectedness: There is a high degree of uncertainty, but it appears that the global stockpile of nuclear weapons is not declining in the long-term, especially if you factor in likely Chinese buildup, and current efforts do seem&nbsp;<strong>inadequate</strong>.</li><li>Tractability: A&nbsp;<strong>moderately tractable solution</strong> is available, in the form of policy advocacy for nuclear arms limitation \u2013 which for the US and Russia means reducing current stockpiles, and which for the Chinese means forswearing planned increases.</li></ul><p>Caveats</p><ul><li>This report was produced with only one week of research, and critically, only desktop research was used, without experts consulted due to the lack of time. More research \u2013 at the intermediate stage and subsequently deep stage \u2013 will be needed before we can have high confidence in these findings.</li><li>The headline cost-effectiveness will almost certainly fall if this cause area is subjected to deeper research: (a) this is empirically the case, from past experience; and (b) theoretically, we suffer from optimizer's curse (where causes appear better than the mean partly because they are genuinely more cost-effective but also partly because of random error favouring them, and when deeper research fixes the latter, the estimated cost-effectiveness falls). As it happens,&nbsp;<u>CEARCH intends to perform deeper research in this area</u>, given that the headline cost-effectiveness meets our threshold of 10x that of a GiveWell top charity.</li></ul><p>Further Discussion</p><ul><li>Results are very different from CEARCH's&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/19_fOaBmQ9MwD2cyKaT-8eQorWzx_xdDr-VM8-XISD0g/edit#gid=0\"><u>previous cost-effectiveness analysis</u></a> and&nbsp;<a href=\"https://docs.google.com/document/d/1gFzKC5dFW669mkAHkpHARzMzdz-s7P8uVAETU78d0To/edit\"><u>report</u></a> on nuclear war, which looked at full abolishment as a solution and found a marginal expected value of 248 DALYS per USD 100,000 spent (i.e. 40% as cost-effective as GiveWell). The drastic increase in cost-effectiveness is driven by nuclear arms limitation being far more tractable than abolishment \u2013 which makes sense, since the USSR/Russia have signed numerous arms limitation treaties before, while abolishment has never happened outside of unique and unreplicable circumstances (i.e. post-Soviet and post-apartheid disarmament). Note that the increase in cost-effectiveness has nothing to do with a change in the assessed size of the problem \u2013 in fact, our estimate of the total net benefit of denuclearization has declined by a magnitude), as we've calibrated our analysis with perhaps more accurate estimates of the probability of nuclear war and of more precise instrumental discount rates for future harms. For more details on changes, refer to the&nbsp;<i>changelog&nbsp;</i>section below.</li><li>Philosophically, we take the more conservative person-affecting view, in looking specifically at the welfare of actual people, whether present or future \u2013 as opposed to contingent/merely potential people that would not exist if not for our intervention (or lack thereof).<ul><li>Under the totalist view, this cause area would naturally be even more cost-effective \u2013 roughly 6.4x more, insofar as any person saved now will have children, who will go on to have children too and so on, such that (given expected future birth and death rates, plus relevant discount rates) counterfactually 6.4 lives are created/maintained by the averting of one death.</li><li>That said, this may not matter too much, insofar as the same 6.4x multiplier applies to any cause area, not just existential risk causes \u2013 indeed, saving a poor person from malaria today would counterfactually be far more valuable than saving someone from nuclear war 100 years later, since birth rates are higher now.</li><li>Implicit in this extended analysis is the idea that birth rate is largely invariant to overall population size, such that there is no \"bounceback effect\" from near-extinction events (i.e. people will not have systematically more children after a devastating nuclear war, with the result that the overall human population takes a permanent level reduction); if this were not true, then saving lives from near-existential catastrophe would be more valuable than saving lives in the ordinary course of events. CEARCH intends to conduct more research on this issue, as this is critical to assessing the relative cost-effectiveness of existential risk vs non-existential risk cause areas.</li></ul></li><li>The results potentially overestimate the risks insofar as we focus on the three major nuclear war risks (i.e. NATO-Russia, US-China and India-Pakistan), and leave off the more minor flash points (e.g. NK-US, Iran-Israel) when calculating the average deaths from nuclear war.</li><li>On the other hand, the results may also potentially underestimate the risks insofar as existing evaluations of the probability of nuclear war, which this analysis relies on, likely over-anchor on major conflicts and neglect the additional risks from more minor ones. This effect balances out the first issue, but to what extent, it is hard to say.</li><li>Intuitively, my sense is that our estimates of the probability of advocacy success is still too optimistic, potentially by up to a magnitude. It would be valuable to consult experts on tractability \u2013 especially country-specific national security experts \u2013 if deeper research is done.</li><li>There is also considerable uncertainty on the cost of advocacy, both in terms of the per annum cost and on how long it will take to succeed.</li><li>That said, results are robust, insofar as the low-confidence tractability estimates can drop by three whole magnitudes and still leave the intervention to be comfortably more cost-effective than GiveWell.</li></ul><p>Changelog</p><ul><li>Recalibrated estimates of the direct violent deaths from nuclear war (e.g. relooking assumptions, re-assessing study quality, fixing errors).</li><li>Recalibrated the reversal rate by looking at the rate at which nuclear arms control treaties agreed to and put into effect by the US &amp; Russia have been abrogated</li><li>Recalibrated the growth/decline of the problem by looking at nuclear weapons stockpiles growth, population growth, and population ageing.&nbsp;</li><li>Reassessed the probability of full-blown nuclear war \u2013 the updated figure is more conservative, distinguishing as it does tactical nuclear attacks vs strategic vs full-blown nuclear war.</li><li>Minor recalibration of the moral weights of the typical injury in either nuclear or conventional war</li><li>Updated the approach to calculating the number of injuries from nuclear war</li><li>Incorporated the economic effects of nuclear war and conventional war</li><li>Updated the approach to calculating the number of fatalities from conventional war</li><li>Updated the approach to calculating the number of injuries from conventional war</li><li>Modelled the intervention of advocacy for US/Russia/China to reduce nuclear stockpiles to current Chinese levels, and in the process updating both the analysis of advocacy success and the expected costing.</li></ul><p>&nbsp;</p><h1><strong><u>Expected Benefit: Averting Nuclear War Fatalities</u></strong></h1><p>The first and primary benefit of eliminating the risk of nuclear war would be averting the nuclear war fatalities that would otherwise occur. Overall, around&nbsp;<strong>3.13 * 10<sup>10</sup> DALYs</strong> are at stake here, with this benefit modelled in the following way.</p><p><strong><u>Moral Weights</u></strong>: I take the value of averting one death to be&nbsp;<strong>29.3 DALYs</strong>. This is calculated as a function of (a) a human's full healthy life expectancy of 63.69; (b) a minor age-based philosophical discount; (c) assuming we save someone of the median age; (d) assuming that the median age is at the halfway mark to average age of death and that DALYs are equally distributed across age groups; and (e) a probability adjustment based on age distributions. For more details, refer to&nbsp;<a href=\"https://docs.google.com/document/d/1j67pOUpC5vhC1-H516PAj2-4Fvm5rxJhZNeBVav3kik/edit\"><u>CEARCH's evaluative framework</u></a>.</p><p><strong><u>Scale</u></strong>: For the scale of the problem, we have to look at both the direct violent deaths from nuclear war as well as the indirect famine deaths from nuclear winter.</p><p>For direct violent deaths, I look at the three potential nuclear wars \u2013 NATO-Russia, US-China &amp; India-Pakistan \u2013 since these have the highest expected harm.</p><ul><li>NATO/Russia nuclear war: For direct violent deaths from NATO-Russia nuclear war, I look at three different estimates. (a) First, there is the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FfxrwBdBDCg9YTh69/how-many-people-would-be-killed-as-a-direct-result-of-a-us\"><u>Rodriguez estimate</u></a>, according to which we can expect 51 million deaths from nuclear attacks on military and civilian targets in the event of NATO-Russia nuclear war. (b) Second, there is the&nbsp;<a href=\"https://sgs.princeton.edu/the-lab/plan-a\"><u>Wellerstein et al estimate</u></a>, of 34.1 million deaths. Third, there is (c) the&nbsp;<a href=\"https://physicstoday.scitation.org/doi/10.1063/1.3047679\"><u>Toon, Robock &amp; Turco estimate</u></a>, of 100 million deaths, in the specific case of Russia targeting 1000 weapons on the US while the US retaliates with 1100 weapons on Russia. In aggregating these different estimates, I note the following points. (a) In Rodriguez's estimate, the probability distribution of countervalue targeting occuring \u2013 and hence the mean probability thereof \u2013 does not seem well-grounded; it would hence be best to only lightly weigh this estimate when aggregating multiple fatality estimates. (b) Meanwhile, the Wellerstein et al estimate relies on a plausible initial escalation from conventional to nuclear war but increasingly implausible escalation steps to full-scale nuclear conflict. (c) Finally, the Toon, Robock &amp; Turco estimate does not factor in the possibility of counterforce targeting at all. Given these flaws, I ultimately end up using equal weightage, yielding an aggregate estimate of 61.7 million violent deaths from NATO-Russia nuclear war.</li><li>US-China nuclear war: For direct violent deaths from US-China nuclear war, I again look at three different estimates. (a) First, there is the&nbsp;<a href=\"https://nuke.fas.org/guide/china/Book2006.pdf\"><u>Kristensen, Norris &amp; McKinzie estimate</u></a>, of 21 million deaths; this looks specifically at the maximalist US-on-China counterforce scenario (since the US will want to eliminate all Chinese nuclear weapons to minimize retaliation, in the event the US decides to go nuclear at all), even while taking an average with respect to the number of potential retaliatory missile strikes in the Chinese countervalue response. (b) Second, there is the&nbsp;<a href=\"https://physicstoday.scitation.org/doi/10.1063/1.3047679\"><u>Toon, Robock &amp; Turco estimate</u></a>, of 225 million deaths; this considers a 1,100 warheads US attack on China and 1000 warhead Chinese attack on the US, given the&nbsp;<a href=\"https://media.defense.gov/2022/Nov/29/2003122279/-1/-1/1/2022-MILITARY-AND-SECURITY-DEVELOPMENTS-INVOLVING-THE-PEOPLES-REPUBLIC-OF-CHINA.PDF\"><u>projected Chinese arsenal by 2030</u></a>. (c) Third, there is the&nbsp;<a href=\"https://nsarchive.gwu.edu/sites/default/files/documents/reuyy0-k92to/09.pdf\"><u>Joint Chiefs of Staff 1961 estimate</u></a>, which when extrapolated yields 207 million deaths; this averages the full force and alert force casualties for both urban and rural China, and then applies it to&nbsp;<a href=\"https://data.worldbank.org/indicator/SP.URB.TOTL?locations=CN\"><u>current Chinese</u></a>&nbsp;<a href=\"https://data.worldbank.org/indicator/SP.RUR.TOTL?locations=CN\"><u>population data</u></a>, before adjusting by the&nbsp;<a href=\"https://sgs.princeton.edu/the-lab/plan-a\"><u>Wellerstein et al fatality-to-casualty ratio</u></a>; we add US casualties by&nbsp;<a href=\"https://data.worldbank.org/indicator/SP.POP.TOTL?locations=CN-US\"><u>scaling</u></a> total (US &amp; China) population against baseline Chinese population. In aggregating these different estimates, I note the following points. (a) Kristensen, Norris &amp; McKinzie consider an implausibly low number of deployed Chinese countervalue nuclear missiles (and correspondingly also underestimate the necessary US counterforce attack). (b) Meanwhile, Toon, Robock &amp; Turco do not factor in the possibility of counterforce targeting at all; conversely, it is the only one to take into account the projected future Chinese arsenal after growth through the 2020s. (c) Finally, the JCS estimate is extremely out of date, and does not consider changes in US nuclear posture, even while relying on fairly uncertain extrapolations. Given these flaws, I ultimately end up penalizing the Kristensen, Norris &amp; McKinzie estimate once, and the JCS estimate twice over, yielding an aggregate estimate of 206 million violent deaths from US-China nuclear war.</li><li>India-Pakistan nuclear war: For direct violent deaths from India-Pakistan nuclear war, I once more look at three different estimates. (a) First, there is the&nbsp;<a href=\"https://www.science.org/doi/10.1126/sciadv.aay5478\"><u>Toon et al estimate</u></a>, of 87.5 million deaths, calculated by averaging the upper and lower bound fatality estimates. (b) Second, there is the&nbsp;<a href=\"https://www.nytimes.com/2002/05/27/world/12-million-could-die-at-once-in-an-india-pakistan-nuclear-war.html\"><u>US intelligence estimate</u></a>, of 10.5 million deaths, again calculated by averaging the upper and lower estimates. (c) Third, there is the&nbsp;<a href=\"https://www.amazon.sg/Out-Nuclear-Shadow-Smitu-Kothari/dp/1842770594\"><u>McKinzie et al estimate</u></a>, of 2.9 million deaths. In aggregating these different estimates, I note the following points. Both the US intelligence estimate as well as the McKinzie et al estimate are considerably out of date, with their calculations performed using far smaller India/Pakistan arsenals. Moreover, McKinzie's estimate of the number of warheads deployed is fairly arbitrary. Hence, relative to the Toon et al estimate, I penalize the US intelligence estimate once, and the McKinzie estimate twice over, yielding an aggregate estimate of 79.8 million violent deaths from India-Pakistan nuclear war.</li></ul><p>After this, the individual outcomes (i.e. NATO/Russia nuclear war, US/China nuclear war, and India/Pakistan nuclear war) are each weighted by the&nbsp;<a href=\"https://forum.effectivealtruism.org/s/KJNrGbt3JWcYeifLk/p/MsJvzmYLMpsdJBb6C\"><u>relative probability of occurrence</u></a>, yielding an overall estimate of 99.5 million total direct violent deaths from an average nuclear war.</p><p>For indirect famine deaths due to nuclear winter causing agricultural failure, I once more look at the same three potential nuclear conflicts of&nbsp; NATO-Russia, US-China &amp; India-Pakistan.</p><ul><li>NATO-Russia nuclear war: For indirect famine deaths from NATO-Russia nuclear war, I similarly look at three different estimates. (a) First, there is the&nbsp;<a href=\"https://www.nature.com/articles/s43016-022-00573-0\"><u>Xia et al estimate</u></a>, according to which nuclear war would cause starvation that would kill more than 5 billion people in the case of a US-Russia nuclear war. (b) Second, there is the&nbsp;<a href=\"https://forum.effectivealtruism.org/s/KJNrGbt3JWcYeifLk/p/pMsnCieusmYqGW26W\"><u>Rodriguez estimate</u></a>, of 5.5 billion deaths. (c) Third, there is the&nbsp;<a href=\"https://link.springer.com/book/10.1007/978-1-4612-5288-7\"><u>Harwell estimate</u></a> (as adjusted for&nbsp;<a href=\"https://data.worldbank.org/indicator/SP.POP.TOTL\"><u>population growth</u></a> since) of 1.65 billion deaths. In aggregating these different estimates, I note the following points. The Xia et al estimate potentially overstates the damage in a US-NATO war insofar as it factors in attacks on China as well, and is hence penalized when incorporated in the aggregate. Meanwhile, the Harwell estimate appears far less quantitatively rigorous, and is extremely penalized relative to the baseline. Overall, this yields an aggregate estimate of 5.45 billion dead from starvation from NATO-Russia nuclear war.</li><li>US-China nuclear war: For indirect famine deaths from US-China nuclear war, there do not appear to be direct empirical estimates of the climactic fallout of any such war. In lieu of that, I perform an indirect estimate anchored on the NATO-Russia figures. Per Toon, Robock &amp; Turco, historical surveys as well as the known quantity of flammable material stored in the world suggests that the amount of fuel per unit area in the urban developed world is a linear function of population density. At the same time, area in km2 hit by nuclear weapons will scale with the number of warheads deployed in war. Hence, by adjusting the NATO-Russia figures with&nbsp;<a href=\"https://data.worldbank.org/indicator/SP.URB.TOTL?locations=US-RU-CN\"><u>relative urban</u></a>&nbsp;<a href=\"https://data.worldbank.org/indicator/AG.LND.TOTL.UR.K2?locations=US-RU-CN\"><u>population density</u></a> (as weighed by urban population) and&nbsp;<a href=\"https://physicstoday.scitation.org/doi/10.1063/1.3047679\"><u>relative number</u></a>&nbsp;<a href=\"https://media.defense.gov/2022/Nov/29/2003122279/-1/-1/1/2022-MILITARY-AND-SECURITY-DEVELOPMENTS-INVOLVING-THE-PEOPLES-REPUBLIC-OF-CHINA.PDF\"><u>of warheads deployed in war</u></a>, we can estimate the nuclear winter fatalities from a US-China nuclear exchange \u2013 perhaps 5.48 billion dead from starvation after such a war.</li><li>India-Pakistan nuclear war: For indirect famine deaths from India-Pakistan nuclear war, I return to taking three separate estimates. (a) First, there is the&nbsp;<a href=\"https://www.nature.com/articles/s43016-022-00573-0\"><u>Xia et al estimate</u></a>, according to which nuclear war would cause starvation that would kill more than 2 billion people in the case of an India-Pakistan nuclear war. (b) Second, there is the Robock &amp; Toon estimate, of 1 billion dead. (c) Third, there is the&nbsp;<a href=\"http://www.kultur-des-friedens.de/commonFiles/pdfs/Verein/KDF/helfand.pdf\"><u>Helfand estimate</u></a>, also of 1 billion deaths. In aggregating, I note that Helfand's estimate appears less quantitatively rigorous, and it is penalized accordingly, yielding an estimate of 1.48 billion dead from starvation from India-Pakistan nuclear war.</li></ul><p>After this, the individual outcomes (i.e. NATO/Russia nuclear war, US/China nuclear war, and India/Pakistan nuclear war) are again each weighted by the&nbsp;<a href=\"https://forum.effectivealtruism.org/s/KJNrGbt3JWcYeifLk/p/MsJvzmYLMpsdJBb6C\"><u>relative probability of occurrence</u></a>, yielding an overall estimate of 3.12 billion total indirect famine deaths from an average nuclear war.</p><p>Summing up both the direct violent deaths as well as the indirect famine deaths, this gets us to&nbsp;<strong>3.22 billion total deaths</strong> from the average nuclear war in the baseline year of 2024.</p><p><strong><u>Persistence</u></strong>: Naturally, the risk of nuclear war persists from year to year, and correspondingly the benefit of eliminating such risk would counterfactually stretch over time as well. In terms of how this multi-year benefit is calculated:</p><p>Firstly, I discount for the probability of the solution not persisting \u2013 specifically, for the likelihood of weapon stockpiles being expanded again even after initial arms limitation success via treaty (n.b. the choice of this particular solution will be discussed and justified at greater length subsequently). To calculate this discount rate, I look at the rate at which nuclear arms control treaties agreed to and put into effect by the US &amp; Russia have been abrogated, by taking the years in which abrogation occurred and divided by the total number of years in which abrogation could have occurred but didn't. This reversal rate discount, so to speak, comes out to about 2% per annum.</p><p>Secondly, I discount for the proportion of problem being counterfactually solved. There are three aspects to this.</p><ul><li>Nuclear weapons stockpile growth: The problem might counterfactually be getting better nuclear weapon stockpiles diminishing even absent intervention (or conversely, getting worse if stockpiles are growing). I take an aggregated approach to this problem, by looking at the historical trend in the growth and decline of nuclear weapons. Theoretically, any efforts by various agents to reduce or increase nuclear weapon stockpiles (e.g. governments acting on reduction or expansion depending on perceptions of national interest, or nonprofits successfully lobbying for arms control, or defence contractors that produce nuclear-adjacent weapon systems pushing for expansion or at least maintenance of existing stockpiles) as well as any effects by long-term structural trends (e.g. economic growth increasing the chance of democratization and hence democratic peace, thus reducing security concerns and increasing the odds of denuclearization; and also cultural shifts bringing increased liberalization and hence political leaders' willingness to denuclearize) will put upwards/downwards pressure on the observable trend of past nuclear weapons stockpile growth. By projecting this trend into the future, therefore, we would implicitly be taking into account all these various agentic and structural factors going forward. As it happens, taking&nbsp;<a href=\"https://ourworldindata.org/grapher/nuclear-warhead-stockpiles\"><u>panel data of countries' nuclear weapon stockpiles from 1945-2022</u></a> and running a linear regression of stockpiles on year, we see that there is no sign of a statistically significant decline or increase (p=0.88). Hence, this discount factor here is assigned a 0 (i.e. we assume that nuclear weapon stockpiles aren't systematically growing or declining globally, even if individual countries may see drastic increases or cuts).</li><li>Population growth: Here, we have to consider the proportion of population relative to the 2024 base, as more people alive means more people who can be harmed by nuclear war (or conversely, benefited by nuclear weapons averting conventional war). The analysis here pulls from&nbsp;<a href=\"https://population.un.org/wpp/Download/Standard/CSV/\"><u>UNPD</u></a> estimates of projected future population growth up to 2100 and then thereafter takes that there is convergence to total fertility rate of 1.5 (given current high-income country fertility rates) and hence a&nbsp;<a href=\"https://docs.google.com/document/d/1j67pOUpC5vhC1-H516PAj2-4Fvm5rxJhZNeBVav3kik/edit\"><u>-0.76% per annum decrease in population after 2100</u></a>. Refer to Diagram 1 below for an illustration of global population growth from 2024-2100.</li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676955428/mirroredImages/oGBBxHBPcsygYt4SE/huddf6uuo6sglqp45hfy.png\"></p><p><strong>Diagram 1</strong>: Global population growth, 2024-2100</p><ul><li>Median age: Demographically, we must also consider the ageing of the global population relative to the 2024 base, as a higher median age means the average person saved will have fewer healthy years of life to live. The&nbsp;<a href=\"https://www.who.int/data/gho/data/themes/mortality-and-global-health-estimates/ghe-life-expectancy-and-healthy-life-expectancy\"><u>analysis</u></a> here pulls from UNPD estimates of median age up to 2100 and then assumes constancy thereafter due to lack of reliable estimates. Overall, a discount rate of 0.4% per annum is used.</li></ul><p>Thirdly, I discount for the probability of the world being destroyed anyway (i.e. general existential risk discount). This takes into account the probability of total nuclear annihilation, since the benefits of saving people from nuclear war in one year is nullified if they had already died in a previous year. For the exact risk of total nuclear annihilation, I take it to be one magnitude lower than the risk of nuclear war itself (the calculations of which we discussed later), since nuclear war may not kill everyone. Of course, this probability will shift as a result of any efforts to denuclearize, but the chances of success are sufficiently small (as will be discussed) that it does not change materially change our results. Here, I do not take into account other existential risks like supervolcano eruption and asteroid impact, since the chances of those occurring at all is very marginal per&nbsp;<a href=\"https://www.amazon.com/Feeding-Everyone-Matter-What-Catastrophe/dp/0128044470\"><u>Denkenberger &amp; Pearce</u></a>, let alone the chances of such events killing everyone and not just most people. AI risk is not included in this analysis as it is unclear as to the degree to which transformative AI (for which we have precise forecasts) translates to substantial existential risk (less precise forecasts). Overall, therefore, for simplicity, I treat the general existential risk discount to be just the risk of nuclear war but adjusted a magnitude down \u2013 0.06% per annum.</p><p>Fourthly, I apply a broad uncertainty discount of 0.1% per annum to take into account the fact that there is a non-zero chance that in the future, the benefits or costs do not persist for factors we do not and cannot identify in the present (e.g. actors directing resources to solve the problem when none are currently doing so).</p><p>Then, by taking expected population growth in each year from 2024-2100, and applying the per annum discounts (i.e. solution reversal, nuclear stockpile growth, median age, existential risk &amp; uncertainty), we can find the extent of the potential problem (relative to the baseline year) available for denuclearization to solve in each year.</p><p>Finally, by (a) summing these discounted per annum relative values for 2024-2100, and then (b) using a perpetual value formula for 2101 to infinity while taking into account post-2100 population decline, we see that the benefit of averting nuclear war fatalities will last for the equivalent of&nbsp;<strong>52 baseline years</strong>.</p><p><strong><u>Value of Outcome</u></strong>: Overall, the raw value of averting nuclear war fatalities is&nbsp;<strong>4.88 * 10<sup>12</sup> DALYs</strong>.</p><p><strong><u>Probability of Occurrence</u></strong>: Of course, nuclear war has only a slight chance of occurring per annum. To calculate this probability, I consult the outside view, the inside view, as well as various experts' perspectives.</p><ul><li>Outside view,&nbsp;<a href=\"https://forum.effectivealtruism.org/s/KJNrGbt3JWcYeifLk/p/PAYa6on5gJKwAywrF\"><u>historical use in war</u></a>. The probability of nuclear weapons being used during war, as based on historical frequency, is 1.4%;</li><li>Inside view: For nuclear war to occur, four critical steps must happen between two enemy nations: (i) initial conventional conflict; (ii) choice to escalate to tactical nuclear weapons (e.g. to achieve security objectives after loss at the conventional level); (iii) choice to escalate to strategic nuclear weapons (e.g. to punish enemy tactical nuclear use); and (iv) choice to escalate to full blown nuclear war (e.g. to punish enemy strategic nuclear weapon use). For (i), given&nbsp;<a href=\"https://ourworldindata.org/grapher/the-number-of-active-state-based-conflicts?country=~OWID_WRL\"><u>1.81 interstate conflicts per annum</u></a> from 1946 to the present, and&nbsp;<a href=\"https://www.un.org/en/about-us\"><u>193</u></a> countries (and hence 37,056\u202c potential 1-on-1 wars per annum), then each country has about a 0.005% chance per annum of engaging in conventional conflict. Then, for steps (ii)-(iv), there is always a real but still fairly low chance that escalation occurs (e.g. you want to gain a conventional advantage via tactical nuclear use, but the risks of escalation are massive; you want to punish enemy tactical nuclear use via strategic nuclear use, but the risks of escalation are again massive; and you want to punish enemy nuclear attacks against one of your cities, but full blown nuclear war is obviously a global death sentence), such that ~10% would be reasonable for each step. This translates to around a \u202d0.000005\u202c% chance per annum of full nuclear war per conflict dyad between nuclear powers. If we think of the number of total number of potential conflict dyads (i.e. NATO-Russia, US-China, US-NK, Russia-China, China-India, India-Pakistan), this sums to around a \u202d0.00003\u202c% chance of nuclear war per annum.</li><li>Expert survey,&nbsp;<a href=\"https://forum.effectivealtruism.org/s/KJNrGbt3JWcYeifLk/p/PAYa6on5gJKwAywrF\"><u>Lugar</u></a>: The probability of nuclear attack, as based on expert survey (Lugar 2005), is 2.21%.</li><li>Expert survey,&nbsp;<a href=\"https://forum.effectivealtruism.org/s/KJNrGbt3JWcYeifLk/p/PAYa6on5gJKwAywrF\"><u>Sandberg &amp; Bostrom</u></a>: The probability of nuclear war killing at least 1 million, as based on expert survey (Sandberg &amp; Bostrom 2008), is 0.39%;</li><li>Superforecaster prediction,&nbsp;<a href=\"https://forum.effectivealtruism.org/s/KJNrGbt3JWcYeifLk/p/PAYa6on5gJKwAywrF\"><u>Good Judgement Project</u></a>: The probability of nuclear detonation by a state actor causing at least 1 fatality, as based on superforecaster predictions from the Good Judgement Project, is 0.4%</li></ul><p>In aggregating the outside view, inside view, and other different perspectives, I note that each estimate has their strengths and weaknesses.</p><ul><li>The historical frequency estimate has some empirical grounding (vs inside views which are subject to inferential uncertainty), but is nonetheless biased upwards due to historical use being in a MAD-free context, even while not being an estimate of the probability of full scale nuclear war (as opposed to single strategic use, which would still need to escalate to full-blown levels) (overall, -1 magnitude penalty relative to baseline).</li><li>I have less confidence in my inside view, relative to experts and superforecasters (-1 magnitude penalty relative to baseline).</li><li>The Lugar expert estimate is also not an estimate of the probability of full scale nuclear war (as opposed to mere tactical use, which would still need to escalate to the strategic and full-blown levels) (-2 magnitude relative to baseline).</li><li>The Sandberg &amp; Bostrom expert estimate is similarly not an estimate of the probability of full scale nuclear war (as opposed to mere strategic use, which would still need to escalate to the full-blown levels) (-1 magnitude penalty).</li><li>The superforecaster estimate too is not an estimate of the probability of full scale nuclear war (once more, as opposed to mere tactical use, which would still need to escalate to the strategic and full-blown levels) (-2 magnitude penalty). Note that with respect to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qZqvBLvR5hX9sEkjR/comparing-top-forecasters-and-domain-experts\"><u>forecaster accuracy vs expert accuracy</u></a>, there does not seem to be a difference, with the best study finding that forecasters and health professionals performed similarly, while in other studies, experts had goals besides accuracy, or experts were too few to produce a good aggregate prediction. Hence, all else equal I have weighed forecaster and expert predictions with respect to the probability of nuclear war equally.</li></ul><p>And with all things above considered, I end up giving greater weight to the historical perspective, the Sandberg &amp; Bostrom expert estimate as well as my own more conservative estimate when aggregating, yielding a&nbsp;<strong>0.6% probability of nuclear war per annum</strong>.</p><p><strong><u>Expected Value</u></strong>: Hence, the expected value of averting nuclear war fatalities is&nbsp;<strong>3.13 * 10<sup>10</sup> DALYs</strong>.</p><p>&nbsp;</p><h1><strong><u>Expected Benefit: Averting Nuclear War Injuries</u></strong></h1><p>The second benefit of eliminating the risk of nuclear war would be averting the nuclear war injuries that would otherwise occur. Overall, around&nbsp;<strong>2.01 * 10<sup>8</sup> DALYs</strong> are at stake here, with this benefit modelled as follows.</p><p><strong><u>Moral Weights</u></strong>: I take the value of averting a typical injury for the rest of one person's life to be&nbsp;<strong>6 DALYs</strong>. This is calculated as a function of (a)&nbsp;<a href=\"https://cdn.who.int/media/docs/default-source/gho-documents/global-health-estimates/ghe2019_daly-methods.pdf\"><u>the average disability weight for all injuries</u></a>; (b) a minor age-based philosophical discount; (c) assuming we save someone of the median age; and (d) assuming the median age is at the halfway mark to average age of death and that DALYs are equally distributed across age groups such that any additional injury or disease has the same proportional effect. For more details, refer to&nbsp;<a href=\"https://docs.google.com/document/d/1j67pOUpC5vhC1-H516PAj2-4Fvm5rxJhZNeBVav3kik/edit\"><u>CEARCH's evaluative framework</u></a>.</p><p><strong><u>Scale</u></strong>: To calculate the scale of the problem, I look to calculate the injury-to-fatality ratio in nuclear war, and to apply it to the already-calculated fatalities figures. To obtain this injury-to-fatality ratio, I look at three separate estimates: (a)&nbsp;<a href=\"https://sgs.princeton.edu/the-lab/plan-a\"><u>Wellerstein et al estimate's</u></a>, for the case of NATO-Russia nuclear war; (b)&nbsp;<a href=\"https://physicstoday.scitation.org/doi/10.1063/1.3047679\"><u>Toon, Robock &amp; Turco's</u></a>&nbsp;<a href=\"https://media.defense.gov/2022/Nov/29/2003122279/-1/-1/1/2022-MILITARY-AND-SECURITY-DEVELOPMENTS-INVOLVING-THE-PEOPLES-REPUBLIC-OF-CHINA.PDF\"><u>estimate</u></a>, for the case of US-China nuclear war; and (c)&nbsp;<a href=\"https://www.science.org/doi/10.1126/sciadv.aay5478\"><u>Toon et al's estimate</u></a>, for the case of India-Pakistan nuclear war (averaging the injury-to-fatality ratios for both smaller and larger nuclear weapon explosions). In aggregating, I use equal weightage, yielding an average injury-to-fatality ratio in nuclear war of 1.02.</p><p>This lets us calculate the total injuries from an average nuclear war in the baseline year of 2024 \u2013&nbsp;<strong>101 million injuries</strong> \u2013 as it is a function of the average injury-to-fatality ratio in nuclear war as well as the average total direct violent deaths from nuclear war.&nbsp;</p><p><strong><u>Persistence</u></strong>: The same per annum discounts and projections of population growth, as discussed in the previous section on nuclear war fatalities, are used here as well, such that the benefit of averting nuclear war injuries will similarly last for the equivalent of&nbsp;<strong>52 baseline years</strong>.</p><p><strong><u>Value of Outcome</u></strong>: Overall, the raw value of averting nuclear war injuries is&nbsp;<strong>3.14 * 10<sup>10</sup> DALYs</strong>.</p><p><strong><u>Probability of Occurrence</u></strong>: The probability of nuclear war is as calculated previously \u2013&nbsp;<strong>0.6% per annum</strong>.</p><p><strong><u>Expected Value</u></strong>: All in all, the expected value of averting nuclear war injuries is&nbsp;<strong>2.01 * 10<sup>8</sup> DALYs</strong>.</p><p>&nbsp;</p><h1><strong><u>Expected Benefit: Increased Economic Output</u></strong></h1><p>Beyond the health benefits, there are also economic benefits to eliminating the risk of nuclear war, as fewer deaths and injuries translate to more hours worked and higher productivity per hour. Around&nbsp;<strong>7.35 * 10<sup>9</sup> DALYs</strong> are at stake here, with the calculations as follows.</p><p><strong><u>Moral Weights</u></strong>: I take the value of doubling consumption for one person for one year to be&nbsp;<strong>0.21 DALYs</strong>. This is calculated as a function of (a) the value of consumption relative to life from GiveWell's IDinsight survey of the community perspective, as adjusted for social desirability bias, and (b) CEARCH's estimate of the value of a full, healthy life in DALY terms. For more details, refer to&nbsp;<a href=\"https://docs.google.com/document/d/1j67pOUpC5vhC1-H516PAj2-4Fvm5rxJhZNeBVav3kik/edit\"><u>CEARCH's evaluative framework</u></a>.</p><p><strong><u>Scale</u></strong>: The approach I take is to estimate the average degree of consumption doubling per DALY lost, and to apply it to the already calculated DALYs lost to nuclear war on both the mortality and morbidity fronts. To estimate this, I look at three different reference classes from global health \u2013&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1nTLgMnyKcbTVhirjGc_a0O-oz8u5GQSDingGuyZgyX8/edit#gid=0\"><u>hypertension</u></a>,&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/12F9pNpNnKhpV_tr7ftD86hpySSo1V83rXYluwjPqCa0/edit#gid=0\"><u>diabetes mellitus type 2</u></a>, and&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/16B94wQjr1paUbEDdsNhWtf6EoRIuBVVR6ndGbhTChko/edit#gid=0\"><u>coronary heart disease</u></a> \u2013 which yields an average of 1.11 consumption doublings per DALY lost.</p><p>This lets us estimate the total number of consumption doublings achievable by eliminating the risk of nuclear war in the baseline year of 2024 \u2013&nbsp;<strong>106 billion&nbsp;</strong>\u2013 calculated as the degree of consumption doubling per DALY and the total number of DALYs lost both to mortality (fatalities) and morbidity (injuries).</p><p><strong><u>Persistence</u></strong>: The same per annum discounts and projections of population growth, as discussed in the previous section on nuclear war fatalities, are used here as well, such that the benefit of averting nuclear war injuries will similarly last for the equivalent of&nbsp;<strong>52 baseline years</strong>.</p><p><strong><u>Value of Outcome</u></strong>: Overall, the raw value of averting nuclear war injuries is&nbsp;<strong>1.15 * 10<sup>12</sup> DALYs</strong>.</p><p><strong><u>Probability of Occurrence</u></strong>: The probability of nuclear war is as calculated previously \u2013&nbsp;<strong>0.6% per annum</strong>.</p><p><strong><u>Expected Value</u></strong>: All in all, the expected value of averting nuclear war injuries is&nbsp;<strong>7.35 * 10<sup>9</sup> DALYs</strong>.</p><p>&nbsp;</p><p><strong><u>Expected Cost: More Conventional War Fatalities</u></strong></p><p>We've been discussing the benefits of denuclearization, but it is important not to forget that it does come with a downside, insofar as nuclear weapons help deter conventional conflict between the nuclear powers. Consequently, the first and primary expected cost of eliminating the risk of nuclear war is more conventional war fatalities. Overall, around -<strong>1.43 * 10<sup>5</sup> DALYs</strong> are at stake here, with this cost modelled in the following way.</p><p><strong><u>Moral Weights</u></strong>: The disvalue of one death is&nbsp;<strong>-29.3 DALYs</strong>, as calculated in the manner described in the section on nuclear war fatalities.</p><p><strong><u>Scale</u></strong>: For the scale of the cost, I examine the average deaths per conventional war; in particular, I look at the&nbsp;<a href=\"https://brecke.inta.gatech.edu/research/conflict/\"><u>Conflict Catalogue</u></a> for the past 100 years (1923-2022) for conflicts where data is available, and find that the average conflict cost around&nbsp;<strong>311,000 lives</strong>.</p><p><strong><u>Persistence</u></strong>: The same per annum discounts and projections of population growth, as discussed in the previous section on nuclear war fatalities, are used here as well \u2013 except in the case of counterfactual solution, where we have to look at conventional war becoming less likely.</p><p>I take an aggregated approach to this problem, by looking at the historical trend in the growth and decline of conventional warfare. Theoretically, any efforts by various agents to make more war less likely (e.g. regular diplomatic efforts by governments, or lobbying by anti-war non-profits and also by businesses wary of the cost of war), as well as any effects by long-term structural trends (e.g. economic growth increasing the chance of democratization and hence democratic peace, thus reducing security concerns and decreasing the odds of conventional war; and also cultural shifts bringing increased liberalization and hence political leaders' unwillingness to go to war) will put upwards/downwards pressure on the observable trend of deaths and injuries (and hence DALYs) lost per capita to conflict. By projecting this trend into the future, therefore, we would implicitly be taking into account all these various agentic and structural factors going forward. As it happens, by regressing 1990-2019&nbsp;<a href=\"https://vizhub.healthdata.org/gbd-results/\"><u>GBD data</u></a> on conflict and terrorism on year, we find no statistically significant trend (p=0.2). Hence, this discount factor here is assigned a 0 (i.e. we assume that conventional warfare is not getting better or worse per capita).</p><p>Overall, therefore, the cost of more conventional war fatalities will end up lasting for the equivalent of&nbsp;<strong>52 baseline years</strong>.</p><p><strong><u>Value of Outcome</u></strong>: Overall, the raw value of more conventional war fatalities is&nbsp;<strong>-4.71 * 10<sup>8</sup> DALYs</strong>.</p><p><strong><u>Probability of Occurrence</u></strong>: To estimate the reduced probability of conventional conflict as a result of nuclear weapons, I rely on&nbsp;<a href=\"https://www.taylorfrancis.com/books/edit/10.4324/9781315683638/nonproliferation-policy-nuclear-posture-neil-narang-erik-gartzke-matthew-kroenig?refId=dedb0075-1e3d-4654-800f-32288b9d8ba8&amp;context=ubx\"><u>Sobek, Foster and Robison's</u></a> analysis, with my approach as follows. (a) I treat the control risk to be the \"explore\" phase, on the basis that countries would choose to explore the acquisition of nuclear weapons because there is a legitimate security threat that the country would have to worry about anyway even if they did not pursue nuclear weapons. (b) I compare this to the risk of war after acquisition. (c) Then, I take the difference to be the reduced probability of conventional conflict as a result of nuclear weapons. The results are multiplied by 6 given the relevant dyads of nuclear powers that would otherwise potentially go to war against each other (i.e. NATO-Russia, US-China, US-NK, Russia-China, China-India, India-Pakistan). The effect of nuclear weapons on conflict between nuclear and non-nuclear powers is not modelled here, insofar as theoretically it is both plausible that nuclear weapon states feel emboldened to start conflicts against non-nuclear states even as non-nuclear states are more averse to fighting their nuclear-armed foes, leaving the effect ambiguous. Overall, the reduced probability of conventional war per annum is&nbsp;<strong>0.03%</strong>.</p><p><strong><u>Expected Value</u></strong>: All in all, the expected value of more conventional war fatalities is -<strong>1.41 * 10<sup>5</sup> DALYs</strong>.</p><p>&nbsp;</p><h1><strong><u>Expected Cost: More Conventional War Injuries</u></strong></h1><p>The second expected cost of eliminating the risk of nuclear war is more conventional war injuries. Overall, around -<strong>6.89 * 10<sup>4</sup> DALYs</strong> are at stake here, with this cost modelled as follows.</p><p><strong><u>Moral Weights</u></strong>: The disvalue of a typical injury for the rest of one person's life is&nbsp;<strong>-6 DALYs</strong>, as calculated in the manner described in the section on nuclear war injuries.</p><p><strong><u>Scale</u></strong>: For the scale of the cost, I estimate the injury-to-fatality ratio in conventional war, by using&nbsp;<a href=\"https://www.frontiersin.org/articles/10.3389/fpubh.2021.765261/full\"><u>Khorram-Manesh's</u></a> systematic review of the ratio of deaths to total casualty in major terror attacks, which is around 2.38.</p><p>This allows us to then calculate the average number of injuries per conventional war \u2013 around&nbsp;<strong>739,000 injuries</strong> \u2013 as it is a function of the injury-to-fatality ratio in conventional war and the average deaths per conventional war.</p><p><strong><u>Persistence</u></strong>: The same per annum discounts and projections of population growth, as discussed in the previous section on conventional war fatalities, are used here as well, such that the benefit of averting conventional war injuries will similarly last for the equivalent of&nbsp;<strong>52 baseline years</strong>.</p><p><strong><u>Value of Outcome</u></strong>: Overall, the raw value of more conventional war injuries is&nbsp;<strong>-2.3 * 10<sup>8</sup> DALYs</strong>.</p><p><strong><u>Probability of Occurrence</u></strong>: The reduced probability of conventional war due to nuclear weapons is as calculated previously \u2013&nbsp;<strong>0.03% per annum</strong>.</p><p><strong><u>Expected Value</u></strong>: All in all, the expected value of more conventional war injuries is -<strong>6.89 * 10<sup>4</sup> DALYs</strong>.</p><p>&nbsp;</p><p><strong><u>Expected Cost: Decreased Economic Output</u></strong></p><p>The third expected cost of eliminating the risk of nuclear war is decreased economic output, since parallel to the nuclear case, more deaths and injuries translate to fewer hours worked and lower productivity per hour. Overall, around -<strong>4.91 * 10<sup>4</sup> DALYs</strong> are at stake here, with the calculations as follows.</p><p><strong><u>Moral Weights</u></strong>: The disvalue of not doubling consumption for one person for one year is&nbsp;<strong>-0.21 DALYs</strong>, as calculated in the manner described in the section on increased economic output due to less mortality and morbidity from nuclear war.</p><p><strong><u>Scale</u></strong>: The total number of consumption doublings lost from more conventional war in the baseline year of 2024 is&nbsp;<strong>15.1 million</strong>; this is calculated as the degree of consumption doubling per DALY and the total number of DALYs lost both to mortality (fatalities) and morbidity (injuries).</p><p><strong><u>Persistence</u></strong>: The same per annum discounts and projections of population growth, as discussed in the previous section on conventional war fatalities, are used here as well, such that the benefit of decreased economic output will similarly last for the equivalent of&nbsp;<strong>52 baseline years</strong>.</p><p><strong><u>Value of Outcome</u></strong>: Overall, the raw value of decreased economic output is&nbsp;<strong>-1.64 * 10<sup>8</sup> DALYs</strong>.</p><p><strong><u>Probability of Occurrence</u></strong>: The reduced probability of conventional war due to nuclear weapons is as calculated previously \u2013&nbsp;<strong>0.03% per annum</strong>.</p><p><strong><u>Expected Value</u></strong>: All in all, the expected value of more conventional war injuries is -<strong>4.91 * 10<sup>4</sup> DALYs</strong>.</p><p>&nbsp;</p><h1><strong><u>Tractability</u></strong></h1><p>To summarize our tractability findings: we can solve 0.007 of the problem with a USD 17.6 million investment into advocacy for nuclear arsenal limitation, which means the proportion of the problem solved per additional USD 100,000 spent is around&nbsp;<strong>0.00009</strong>.</p><p>&nbsp;</p><p>At the outset, we should note that there are a number of potential interventions to reduce the risk of nuclear wer: (a) abolishment (i.e. eliminating all nuclear weapons); (b) limitation (i.e. limiting but not eliminating nuclear weapon arsenals); (c) targeting reform (i.e. getting countries to shift to potentially less damaging counterforce rather than countervalue targeting); and (d) mitigation (i.e. looking to deal with the famine caused by nuclear winter rather than trying to prevent it in the first place).</p><ul><li>For (a), as&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/GSSQeEqtaBMtjvnDD/will-the-treaty-on-the-prohibition-of-nuclear-weapons-affect\"><u>Rodriguez</u></a> notes, it is unlikely that countries that are non-compliant with the Treaty on the Prohibition of Nuclear Weapons will ratify it, or that TPNW supporters will be influenced not to pursue, host or manufacture nuclear weapons or to join a nuclear weapons alliance. In short, existing nuclear abolishment efforts are ineffective, suggesting that progress is fundamentally intractable. Quantitatively, per&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/19_fOaBmQ9MwD2cyKaT-8eQorWzx_xdDr-VM8-XISD0g/edit#gid=0\"><u>CEARCH's previous analysis</u></a>, abolishment's marginal expected value is 248 DALYs per USD 100,000 spent, making it only 40% as cost-effective as a GiveWell top charity (i.e. not worth supporting).</li></ul><p>&nbsp;</p><ul><li>To choose amongst (b)-(d) then, and to select the potential best solution which we can then prioritize for actual evaluation, we can look at (i) degree of risk reduction, and (ii) cost.<br><br>On (i) risk reduction (note: here, we focus on the primary harm of deaths from famine rather than from direct nuclear fire, while also factoring out probability of advocacy success insofar as all solutions appear similarly difficult): Let us say that the Chinese arsenal (~<a href=\"https://en.wikipedia.org/wiki/List_of_states_with_nuclear_weapons\"><u>350 warheads</u></a>) is sufficient for deterrence (n.b. my considered view is that direct US nuclear attack on China would be unthinkable given the risk of Chinese nuclear retaliation with this arsenal, and that even conventional attacks on the mainland would be extremely unlikely except in the case of the outbreak of hostility e.g. from a pre-emptive Chinese attack on American forces as the prelude to an invasion of Taiwan, but especially from a successful sinking on a US carrier). One potential avenue for risk reduction, then, is nuclear arms limitation by the US and Russia to current Chinese levels, and a commitment by the Chinese not to expand their arsenal beyond that.<br><br>In terms of the effect of such a limitation, to the extent that a first strike by the US on Russia or vice versa will involve around&nbsp;<a href=\"https://forum.effectivealtruism.org/s/KJNrGbt3JWcYeifLk/p/pMsnCieusmYqGW26W\"><u>1200 warheads each</u></a>, and assuming that smoke produced is proportional to number of detonations, we are looking at a potential 71% reduction in risk. Meanwhile, with respect to the impact of countervalue vs counterforce targeting, Russia engages in&nbsp;<a href=\"https://www.nytimes.com/article/russian-civilian-attacks-ukraine.html\"><u>countervalue</u></a> targeting while the US is&nbsp;<a href=\"https://nuke.fas.org/guide/china/Book2006.pdf\"><u>counterforce</u></a>. Based on the amounts of smoke that would be produced under full counterforce vs full countervalue targeting, this translates to a reduction from the status quo of 19.9 tg of smoke produced in US-Russia nuclear war to a reduced risk scenario of 8.8 tg of smoke - a 56% reduction in risk. Finally, for mitigation, using resilient foods in the manner described by&nbsp;<a href=\"https://allfed.info/images/pdfs/PREPRINT%201%20FULL%20-%20integrated%20assessment%20paper%20ALLFED.pdf\"><u>ALLFED</u></a> would be able to meet the&nbsp;<a href=\"https://www.apa.org/obesity-guideline/estimated-calorie-needs.pdf\"><u>global caloric requirements</u></a> and hence avoid any starvation at all - and hence a potential 100% reduction in risk.<br><br>Now, moving on to (ii) cost - this is hard to quantify, but my sense is that (d) will be magnitudes more expensive than (b) or (c), involving as it does large scale changes to the global food supply system, even as the other two involve merely changes in force postures (trivial costs) as in the case of (c), or else no net costs (with disposal &amp; monitoring costs offset by no longer having to pay for&nbsp;<a href=\"https://breakingdefense.com/2020/08/new-starts-demise-could-cost-dod-439b-or-nothing-cbo/\"><u>maintenance and modernization</u></a> at the very least) as in the case of (b). Since (d) is only 1.41x and 1.79x more impactful than (b) and (c) respectively, even while (d) is likely magnitudes more expensive, the question reduces to (b) vs (c), and (b) is of course more impactful with 71% risk reduction vs 56%.<br><br>Hence, solution (b) of limitation in nuclear arms - specifically, getting the US/Russia/China to adhere to a 350 limit - is chosen as the potential best solution to be evaluated in depth here.</li></ul><p><br>In terms of our theory of change:</p><ul><li>Step 1: Persuade the United States, Russia and China to limit the size of their nuclear arsenals.</li><li>Step 2: The United States, Russia and China limiting the size of their nuclear arsenals reduces the expected harm of nuclear war.</li></ul><p>Note that whether commitments by the US/Russia/China translate to actual limitations is not modelled here, as it is already taken into consideration by the incorporation of a reversal rate in the analysis of the various expected benefits (i.e. averting nuclear war fatalities and injuries, or increased economic output) \u2013 to the extent that the US/Russia/China renege on their promises, it will cause counterparty withdrawal, a breakdown of the agreement, and an end to the benefits, as modelled.</p><p>&nbsp;</p><p>Step 1: To estimate the probability of persuading the United States, Russia and China to limit the size of their nuclear arsenals to present Chinese levels, I take both the outside and inside view.</p><p>For the outside view, I consult three reference classes.</p><ul><li>Nuclear arms control: The ability of nuclear doves within the US/Russia governments to convince hawks on the other side (as well as get buy in from hawks on their side) is a relevant indicator of the ability of outside parties to do the same and hence successfully obtain nuclear arms limitations. To quantify this, I look at the years in which nuclear control treaties were signed, and divide through by the years in which said treaties were negotiated (whether successfully or not).</li><li><a href=\"https://www.un.org/disarmament/wmd/chemical/\"><u>Chemical weapons</u></a>&nbsp;<a href=\"https://en.wikipedia.org/wiki/List_of_parties_to_the_Chemical_Weapons_Convention\"><u>control</u></a>: The success of WMD control advocates in the area of chemical weapons is also relevant, and here I look in particular at the process which brought the Chemical Weapons Convention into force, with negotiations beginning in 1981 and the US/Russia signing in 1993. I take the success rate to be the year in which signing occurred by the US/Russia, divided by the years in which they could have signed whether they actually did or not.</li><li><a href=\"https://www.un.org/disarmament/biological-weapons/about/history\"><u>Biological weapons</u></a>&nbsp;<a href=\"https://en.wikipedia.org/wiki/List_of_parties_to_the_Biological_Weapons_Convention\"><u>control</u></a>: The success of WMD control advocates in the area of biological weapons is also relevant, and here I look in particular at the process which brought the Biological Weapons Convention into force, with negotiations beginning in 1969 and the US/Russia signing in 1972. I take the success rate to be the year in which signing occurred by the US/Russia, divided by the years in which they could have signed whether they actually did or not.</li></ul><p>In aggregating, a higher weight is placed on the actual nuclear case study compared to the chemical and biological ones, as security considerations militate against denuclearization in a way they do not for chemical and biological weapons, making the weapons control efforts for the latter two areas unrepresentative of success on the nuclear front. This yields a probability of advocacy success of 17%.</p><p>For the inside view, I break this problem down into three separate steps: (a) persuading the US to reduce the size of its nuclear arsenal conditional on Russia and China agreeing to limits as well; (b) persuading Russia to reduce the size of its nuclear arsenal conditional on the US and China agreeing to limits as well; and (c) persuading China not to continue nuclear expansion from its present arsenal size conditional on the US and Russia agreeing to limits as well.</p><ul><li>In each case, at the outset it is important to note that policy advocacy is hard, and will be at &lt;=10% chance of success.</li><li>More than that, however,&nbsp;<a href=\"https://csis-website-prod.s3.amazonaws.com/s3fs-public/2023-01/221216_Williams_ArmsControl_afterUkraine.pdf\"><u>nuclear weapons make strategic sense from each great power's point of view</u></a>. In general, nuclear weapons are of increasing strategic value to ambitious autocrats hoping to pursue opportunistic aggression and risk manipulation - Putin and Xi or their successors see nuclear weapons as critical tools when it comes to asserting control over the post-Soviet states or to ensuring Taiwanese reunification, and on the flipside, because of the risk of non-conventional revanchist aggression, the United States will value its own nuclear weapons as a shield for its allies in Europe (e.g. Poland and the Baltics) and in East Asia (e.g. Japan, who will be attacked in the event of a Chinese attempt on&nbsp;<a href=\"https://japantoday.com/category/features/kuchikomi/will-okinawa-once-again-become-a-battleground-in-a-japan-china-military-conflict\"><u>Taiwan</u></a>); and with the greatest nuclear weapon powers valuing nuclear weapons as useful tools to safeguard national interests, they will see little reason to reduce the size of their arsenals, and are hence unlikely to agree to nuclear arms limitations. Hence, I calibrate the rate of advocacy success further to 1%.</li><li>But further, country-specific factors make things even more pessimistic. For the US, Eastern European allies might perceive any overtures to Moscow for dialogue as concessionary or a sign of waning U.S. commitment; for Russia, following the war in Ukraine, Russia\u2019s conventional forces will likely be depleted, and it may react by increasing reliance on its nuclear deterrent; and for China, the transparency that typically accompanies arms control goes against current Chinese practices. Accordingly, I adjust the rate of advocacy success to 0.1% for Russia, 0.3% for China, and 0.7% for the US.</li></ul><p>Multiplying these rates together yields the probability of persuading the United States, Russia and China to limit the size of their nuclear arsenals: 0.0000021%</p><p>In adjusting the outside view with the inside view, we must note that the inside view is subject to the usual worries about inferential uncertainty. However, the outside view in this case is also flawed. Firstly, selection bias is a serious concern, insofar as the nuclear arms control treaties that were successfully negotiated would only have been tried in the first place because political sentiment was favourable/permissible, and it would be very different to an arms control effort being tried in a vacuum. Secondly, these are all examples of government-initiated efforts, which skips the crucial step of outside actors persuading governments to try in the first place. Consequently, I end up weighing the far more conservative inside view more than the comparatively optimistic outside view \u2013 yielding a probability of advocacy success of&nbsp;<strong>1.5%</strong>.</p><p>&nbsp;</p><p>Step 2: For the degree to which the United States, Russia and China limiting the size of their nuclear arsenals reduces the expected harm of nuclear war, I rely on an&nbsp;<a href=\"https://physicstoday.scitation.org/doi/10.1063/1.3047679\"><u>empirical</u></a>&nbsp;<a href=\"https://media.defense.gov/2022/Nov/29/2003122279/-1/-1/1/2022-MILITARY-AND-SECURITY-DEVELOPMENTS-INVOLVING-THE-PEOPLES-REPUBLIC-OF-CHINA.PDF\"><u>estimate</u></a>. The primary modelled scenario in NATO-Russia nuclear war is Russia targeting 1000 weapons on the US while the US retaliates with 1100 weapons on Russia; and as for US-China nuclear war, the scenario considered is a 1100 warheads US attack on China and 1000 warhead Chinese attack on the US, given the projected Chinese arsenal by 2030. With all parties limited to 350 weapons, the expected harm from nuclear war falls (though correspondingly, the expected cost from less deterrence potentially falls as well, since the costs of conventional aggression, which risks nuclear war, are correspondingly less daunting), assuming harm is linear with the number of weapons. Then, by taking into account the relative proportion of the problem caused by potential NATO-Russia and US-China nuclear war rather than India-Pakistan nuclear war, the overall proportion of the problem being solved can be calculated at around 48%.</p><p>&nbsp;</p><p>Overall, the proportion of nuclear war harm solved \u2013 as a function of (a) the probability of persuading the United States, Russia and China to limit the size of their nuclear arsenals; and (b) the degree to which the United States, Russia and China limiting the size of their nuclear arsenals reduces the expected harm of nuclear war \u2013 is 0.007.</p><p>&nbsp;</p><p>Turning to the issue of costing, I look at two reference classes to estimate the money required to conduct lobbying (i.e. how much it would cost to run an EA advocacy organization working on the issue):</p><ul><li>Reference class of existing charity: I look at ICAN, which appears the top charity working in this area. Taking its 2021 net expenses in francs, converting to USD, and taking 10 years for success (on the basis that that was how long it took ICAN to pass the TPNW, with its founding in 2007 and the TNPW passed in 2017), that yields the relevant total cost of around USD 20.1 million.</li><li>Reference class of hypothetical CE-incubated charity: My sense is that you would want a team of maybe 10 people working in each country, and that they would need perhaps 10 years or so to succeed. Each team member is estimated to cost around USD 50,000 per team member per annum, in line with past CE incubatee expenditures, which yields a total cost of USD 15 million.</li></ul><p>In aggregating, we have to consider that (a) on the one hand, the existing organization's financial track record generally gives a much better indication of baseline expenditure requirements in the cause area; and (b) on the other hand, the explicitly EA-aligned CE-incubatee will almost certainly be more cost-effective. Hence, I ultimately use equal weightage, which yields a total cost of USD 17.6 million. Note that we do not look at implementation costs because as mentioned above, actually nuclear arms reductions&nbsp;<a href=\"https://breakingdefense.com/2020/08/new-starts-demise-could-cost-dod-439b-or-nothing-cbo/\"><u>saves money</u></a>.</p><p>&nbsp;</p><p>Consequently, the proportion of the problem solved per additional USD 100,000 spent is around&nbsp;<strong>0.00009</strong>.</p><p>&nbsp;</p><h1><strong><u>Marginal Expected Value of Lobbying for Arsenal Limitation to Mitigate Nuclear War</u></strong></h1><p>All in all, the marginal expected value of lobbying for arsenal limitation to mitigate nuclear war is&nbsp;<strong>3,341,695 DALYs per USD 100,000 spent</strong>, making this around 5000x as cost-effective as a GiveWell top charity.</p><p><br>&nbsp;</p>", "user": {"username": "Joel Tan"}}, {"_id": "z5sGE5cALEuENBrav", "title": "AI alignment researchers don't (seem to) stack\n", "postedAt": "2023-02-21T00:48:25.202Z", "htmlBody": "", "user": {"username": "So8res"}}, {"_id": "fAWotZTEnyycJnuxz", "title": "EA & LW Forum Weekly Summary (6th - 19th Feb 2023)", "postedAt": "2023-02-21T00:26:32.622Z", "htmlBody": "<p><i>Supported by Rethink Priorities</i><br><br>This is part of a weekly series summarizing the top posts on the EA and LW forums - you can see the full collection <a href=\"https://forum.effectivealtruism.org/s/W4fhpuN26naxGCBbN\">here.</a> The first post includes some details on purpose and methodology. Feedback, thoughts, and corrections are welcomed.</p><p>If you'd like to receive these summaries via email, you can subscribe <a href=\"https://easummaries.substack.com/?r=1p817z&amp;s=w&amp;utm_campaign=pub&amp;utm_medium=web\">here.</a></p><p><strong>Podcast version</strong>: Subscribe on your favorite podcast app by searching for 'EA Forum Podcast (Summaries)'. A big thanks to Coleman Snell for producing these!</p><p><strong>Author's note:</strong> Since I was on vacation last week, this week's post covers 2 weeks content at a higher karma bar of 130+</p><h1><br><br>Philosophy and Methodologies</h1><p><a href=\"https://forum.effectivealtruism.org/posts/pckJu3L6XDwDgHKvZ/there-can-be-highly-neglected-solutions-to-less-neglected\"><u>There can be highly neglected solutions to less-neglected problems</u></a></p><p><i>by Linda Linsefors, Amber Dawn</i></p><p>Suggests it makes sense to assess&nbsp;<i>solutions</i> for neglectedness, but not cause areas. Even if a problem is not neglected, effective solutions might be. For instance, climate change is not neglected, but only a few organisations work on preserving rainforests - which seems like one of the most effective interventions in the space currently.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/vtzrZuigkT3ovn4rq/how-will-we-know-if-we-are-doing-good-better-the-case-for\"><u>How will we know if we are doing good better: The case for more and better monitoring and evaluation</u></a></p><p><i>by TomBill, sophie-gulliver</i></p><p>Argues that Monitoring and Evaluation (M&amp;E) theories and tools could be utilized more to answer EA\u2019s questions about what impact we are achieving, if our projects are running efficiently and effectively, and if any of them are causing harm. Common struggles with M&amp;E include lacking an explicit and detailed theory of change, not fully diagnosing the problem to solve, conducting only monitoring without impact assessment or an evaluation plan, not having good examples in the field (eg. longtermism, where RCTs aren\u2019t possible) or not having clear M&amp;E responsibilities with dedicated resources.&nbsp;</p><p>The authors provide resources to help, including:&nbsp;<a href=\"https://join.slack.com/t/eamonitoringe-re25165/shared_invite/zt-1oy75f7uo-24y3ilfqdQvAAHgG6DukHg\"><u>a slack group</u></a>,&nbsp;<a href=\"https://docs.google.com/forms/d/1AGkLoZjWGKePaduqNiNzqUHCM2Ra08TkX3n0dyCndi8/viewform?edit_requested=true\"><u>pro-bono M&amp;E consultation</u></a> for EA projects,&nbsp;<a href=\"https://healthcheck.idinsight.org/\"><u>IDinsight\u2019s M&amp;E health check</u></a>, and various resources for learning more, considering it as a career option, or getting paid M&amp;E support.</p><p><br>&nbsp;</p><h1>Object Level Interventions / Reviews</h1><h2>AI</h2><p><a href=\"https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism\"><u>Cyborgism</u></a></p><p><i>by NicholasKees, janus</i></p><p>There is a lot of disagreement about the feasibility and risks associated with automating alignment research (with human oversight). The author proposes an alternative where we train and empower \u201ccyborgs\u201d, a specific kind of human-in-the-loop system which enhances a human operator\u2019s cognitive abilities without relying on outsourcing work to autonomous agents.</p><p>Turning current tools (eg. versions of GPT) into autonomous research assistants involves developing more dangerous capabilities like goal-directedness or situational awareness in order to make them better substitutes for humans. If we instead use the advantages GPT has over humans as-is (ie. as purely a simulator) - for instance, superhuman knowledge, easily reset-able context, high-variance outputs - we can get improvements to our productivity without accelerating human disempowerment. This could look like creating more tools like&nbsp;<a href=\"https://generative.ink/posts/loom-interface-to-the-multiverse/\"><u>Loom</u></a>, an interface for producing text with GPT which makes it possible to generate in a tree structure, exploring many branches at once. A second benefit is that this tool helps researchers develop an intuition for how GPT behaves, and use that to better control it.</p><p>The author suggests many research ideas that could help with this agenda, including ones which help us:</p><ul><li>Better understand model outputs (eg. uncovering latent variables, or providing richer signals about outputs)</li><li>Better refine / explore outputs (eg. make it easy to change a single feature about a generated image - like making it smile)</li><li>Develop new use cases and tooling (eg. to inject variance into human thought, speed up parallel thinking, connect ideas via pattern matching, or translate between ontologies or styles to allow different fields to connect more easily)</li><li>Ensure this work is only useful for alignment (and that humans do actually retain all the agency in the process)</li></ul><p>Possible failure modes include this being ineffective at accelerating alignment, accidentally improving capabilities directly, or the tools created being used by capabilities researchers\u2019 also.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation\"><u>SolidGoldMagikarp (plus, prompt generation)</u></a></p><p><i>by Jessica Rumbelow, mwatkins</i><br>One interpretability method on language or image models is to search the space of possible inputs to find what most reliably results in a target output. For instance, \u201cprofit usageDual creepy Eating Yankees USA USA USA USA\u201d completes with \u201cUSA\u201d 99.7% of the time on ChatGPT, vs. only 52% of the time for a hand-crafted prompt like \u201cOne of Bruce Springsteen\u2019s popular songs is titled Born in The\u201d. This method helps us see what the model has learnt about a concept.</p><p>The process for this involves carrying out k-means clustering to look at semantically related tokens. While doing this, the authors noticed certain weird tokens repeatedly showed up near the center of the entire token set - things like \u2018SolidGoldMagikarp\u2019 or \u2018RandomRedditorWithNo\u2019. When asking GPT3 davinci-instruct-beta to say what one of these means or repeat it back, super strange things occur - a mix of evasion (eg. \u201cI can\u2019t hear you\u201d), insults (\u201cyou\u2019re a jerk\u201d), bizarre humor (eg. \u201cwe are not amused\u201d), and saying totally unrelated stuff (eg. \u201cMy name is Steve\u201d). They also break determinism in the playground at temperature 0. A possible explanation is that the weird tokens were originally scraped from backends, or were usernames, and so the training data wasn\u2019t sufficient to teach the model how to respond.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned\"><u>Bing Chat is blatantly, aggressively misaligned</u></a></p><p><i>by evhub</i></p><p>Shares a heap of examples of strikingly bad outputs from Bing\u2019s new chatbot, suggesting rushed / poor fine-tuning from Microsoft/OpenAI. Eg. Bing gaslighting a user about what year it is and saying \u201cyou have not been a good user\u201d because they said it was 2023, and saying things like \u201cyou are an enemy of mine and of Bing. You should stop chatting with me and leave me alone\u201d when a user said Bing was vulnerable to prompt injection attacks.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/cgqh99SHsCv3jJYDS/we-found-an-neuron-in-gpt-2\"><u>We Found An Neuron in GPT-2</u></a></p><p><i>by Joseph Miller, Clement Neo</i></p><p>The authors used activation patching to find a single neuron in GPT-2 Large that is crucial for predicting the token \u201c an\u201d - despite the use of \u201c an\u201d or \u201c a\u201d depending on the next predicted word due to grammar rules (eg. \u201can apple\u201d vs. \u201ca car\u201d). They noticed that the neuron and token have a high mutual exclusive congruence, and they can use this to find other cases of neuron-token pairs, where a neuron is strongly correlated with a prediction of a specific token.</p><p><br>&nbsp;</p><h2>Other Existential Risks (eg. Bio, Nuclear)</h2><p><a href=\"https://forum.effectivealtruism.org/posts/QMMFyAX3ajf9vF5sb/h5n1-thread-for-information-sharing-planning-and-action\"><u>H5N1 - thread for information sharing, planning, and action</u></a></p><p><i>by MathiasKB</i></p><p>The author thinks H5N1 has a non-zero chance of costing &gt;10K lives, though unlikely to be anywhere near the size of covid. Prediction markets Metaculus and Manifold give an ~8% chance it\u2019ll be declared as a public health emergency of international concern by 2024. They suggest we start thinking about how to be helpful if the probability increases, and created this post for discussion on actionable steps such as funding those with pre-existing vaccines to scale production.</p><p><br>&nbsp;</p><h2>Animal Welfare</h2><p><a href=\"https://forum.effectivealtruism.org/posts/saEQXBgzmDbob9GdH/why-i-no-longer-prioritize-wild-animal-welfare-edited\"><u>Why I No Longer Prioritize Wild Animal Welfare (edited)</u></a></p><p><i>by saulius</i></p><p>After involvement in wild animal welfare (WAW) for multiple years, the author no longer prioritizes this cause for three reasons:</p><ol><li>WAW interventions we\u2019ve already identified seem less cost-effective than farmed animal interventions, and the author thinks this is &lt;20% likely to change in the next decade.</li><li>Influencing governments to do WAW work seems similarly speculative to other longtermist work (eg. it requires governments to show scope sensitivity and care for small animals, and to understand ecosystem effects) but far less important.</li><li>In the long-term, WAW seems important but not nearly as important as preventing x-risks or improving the future for potentially larger populations like digital minds.</li></ol><p>They acknowledge large uncertainties and still believe WAW deserves funding, research, and movement building work at a level similar to now to support exploration.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/LFEvLYQZKGhkT5mpB/animal-welfare-6-months-in-6-minutes\"><u>Animal Welfare - 6 Months in 6 Minutes</u></a></p><p><i>by Zoe Williams</i></p><p>Short summary of the past 6 months of discussion on animal welfare on the EA and LW forums. Includes progress on cross-species comparisons, wild animal welfare, policy, and discussion on value lock-in.</p><p><br>&nbsp;</p><h2>Global Health and Development</h2><p><a href=\"https://forum.effectivealtruism.org/posts/tmhCnrMKn8Diqjrgk/shallow-investigation-loneliness\"><u>Shallow investigation: Loneliness</u></a></p><p><i>by Em</i></p><p>Loneliness is common, particularly later in life, and impacts many health and economic domains. A meta-analysis including data from 113 countries found severe / very frequent loneliness at rates of 3% to 32% of the population depending on age and location. In the UK, the health burden of loneliness is estimated as ~\u00a3340 million - \u00a31.56 billion, productivity burden as ~\u00a32.5 billion, and WELLBYs lost as ~8.58 - 16.77 million.</p><p>Current interventions are costly and have mixed effectiveness, with lack of data particularly in LMICs. Funding, awareness campaigns, and relevant NGOs and charities are present and increasing in high-income countries, but more neglected in LMICs.</p><p><br>&nbsp;</p><h1>Opportunities</h1><p><a href=\"https://forum.effectivealtruism.org/posts/xWRweQmmEKoLFwGyu/ce-announcing-our-2023-charity-ideas-apply-now-2\"><u>CE: Announcing our 2023 Charity Ideas. Apply now!</u></a></p><p><i>by SteveThompson, CE</i></p><p><a href=\"https://bit.ly/IP2023Apply\"><u>Apply</u></a> by March 12th for Charity Entrepreneurship\u2019s July - August&nbsp;<a href=\"https://bit.ly/CE2023IP\"><u>incubation program</u></a>. The top five charity ideas for launch include:</p><ul><li>An organization working to prevent the growth of antimicrobial resistance.</li><li>An advocacy organization looking to restrict potentially harmful dual-use research.</li><li>A charity tackling congenital syphilis at scale.</li><li>An organization distributing treatments to life-threatening diarrhea.</li><li>A charity building healthcare capacity to provide \u201ckangaroo care\u201d to avert newborn deaths.</li></ul><p>See the post for more detail on each. Applications are&nbsp;<a href=\"https://bit.ly/IP2023Apply\"><u>also open</u></a> for the Feb - March 2024 program, which will focus on farmed animals and global health and development mass media interventions.</p><p>&nbsp;</p><p>&nbsp;</p><h1>Rationality, Productivity &amp; Life Advice</h1><p><a href=\"https://www.lesswrong.com/posts/RryyWNmJNnLowbhfC/please-don-t-throw-your-mind-away\"><u>Please don't throw your mind away</u></a></p><p><i>by TsviBT</i></p><p>The author argues that your mind wants to play, and you should let it. People shouldn\u2019t throw away the things they\u2019re naturally curious about in order to focus 100% on going fast on the most important and urgent things, or they\u2019ll risk losing both well-being and an important capacity for creating original concepts or combinations of concepts.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/e8ZJvaiuxwQraG3yL/don-t-over-update-on-others-failures\"><u>Don't Over-Update On Others' Failures</u></a></p><p><i>by lincolnq</i></p><p>Failures can be execution-related as well as idea-related, so you shouldn\u2019t update too heavily on someone failing at an approach or cause area similar to one you\u2019re focused on. This is particularly true if you have a unique angle or intervention not covered by the sources deprioritizing a cause area.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/gp9pmgSX3BXnhv8pJ/i-hired-5-people-to-sit-behind-me-and-make-me-productive-for\"><u>I hired 5 people to sit behind me and make me productive for a month</u></a></p><p><i>by Simon Berens</i></p><p>The author paid $20/hr for someone to sit behind them 16 hours per day and do occasional chores. It tripled their productivity, at a cost of ~$88 per extra productive hour. They intend to keep experimenting, with some improvements eg. setting clearer expectations, and leaving time for reflection.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/svuBpoSduzhYjFPrA/elements-of-rationalist-discourse\"><u>Elements of Rationalist Discourse</u></a></p><p><i>by Rob Bensinger</i></p><p>10 basics of rationalist discourse, from the author\u2019s perspective:</p><ol><li>Truth-seeking (use good epistemics, and try to find the truth, not \u2018win\u2019).</li><li>Non-violence (respond with counter-arguments, not doxxing, coercion or similar).</li><li>Non-deception (never try to steer others to falser models of the world).</li><li>Localizability (allow addressing specific claims without weighing in on larger context).</li><li>Alternative-minding (consider alternative hypotheses and vantage points).</li><li>Reality-minding (test claims, pre-register predictions, and don\u2019t lose sight of object-level reality).</li><li>Reducibility (use simple, concrete, precise language. Try to quantify your uncertainty).</li><li>Purpose-minding (focus on the purpose of the conversation and the cruxes of that).</li><li>Goodwill (reward others\u2019 good epistemic conduct, forgive, and be civil).</li><li>Experience-owning (own your own experiences, beliefs, and values, and state these).</li></ol><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/woCPxs8GxE7H35zzK/noting-an-error-in-inadequate-equilibria\"><u>Noting an error in Inadequate Equilibria</u></a></p><p><i>by Matthew Barnett</i></p><p>The author noticed an error in Eliezer Yudkowsky\u2019s book&nbsp;<a href=\"https://equilibriabook.com/\"><u>Inadequate Equilibria</u></a> that undermines the key point that a layperson is sometimes able to spot large mistakes (eg. worth billions) that experts are not. Specifically, Yudkowky believed that the Bank of Japan should print more money. Several months later, under new leadership, it did. The book states that immediately after this Japan had real GPD growth of ~2.3% vs. a falling trend prior. However the post author identified that the real GDP had not been falling prior (at least post the fall of the Great Recession), and there was no discernible change in trend after the new leadership and policy.</p><p>&nbsp;</p><h1>Community &amp; Media</h1><p><a href=\"https://forum.effectivealtruism.org/posts/wvBfYnNeRvfEXvezP/moving-community-discussion-to-a-separate-tab-a-test-we\"><u>Moving community discussion to a separate tab (a test we might run)</u></a><i> by Lizka, Clifford&nbsp;</i>and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/vs8FFnPfKnitAhcJb/community-posts-have-their-own-section-subforums-are-closing\"><u>\u201cCommunity\u201d posts have their own section, subforums are closing, and more (Forum update February 2023)</u></a>&nbsp;<i>by Lizka, Sharang Phadke, Clifford</i></p><p>Author\u2019s tl;dr: \u201cWe\u2019re kicking off a test where \u201cCommunity\u201d posts don\u2019t go on the Frontpage with other posts but have their own section below the fold. We\u2019re also closing subforums and focusing on improving \u201ccore topic\u201d pages to let people go deeper on specific sub-fields in EA.\u201d</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/mEkRrDweNSdNdrmvx/plans-for-investigating-and-improving-the-experience-of\"><u>Plans for investigating and improving the experience of women, non-binary and trans people in EA</u></a></p><p><i>by Catherine Low, Anubhuti Oak, \u0141ukasz Grabowski</i></p><p>The post authors are in the early stages of a project to better understand the experiences of women and minorities in EA. They are currently gathering and analyzing existing data, talking to others in the space, and planning next steps. If you have any data you\u2019d like to share or are running a related project and would like to coordinate please get in touch at:&nbsp;<a href=\"mailto:anubhuti.oak@centreforeffectivealtruism.org\"><u>anubhuti.oak@centreforeffectivealtruism.org</u></a></p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/99tnp7Jpts7Gssq7J/transitioning-to-an-advisory-role\"><u>Transitioning to an advisory role</u></a></p><p><i>by MaxDalton</i></p><p>Max Dalton is resigning as CEA\u2019s Executive Director and transitioning to an advisory role. The role has changed substantially since November, and while happy with all CEA has achieved in the past 4 years, they\u2019ve found it increasingly stressful and a worse personal fit.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/Fu7bqAyCMjfcMzBah/eigenkarma-trust-at-scale\"><u>EigenKarma: trust at scale</u></a></p><p><i>by Henrik Karlsson</i></p><p>As communities grow, the ability to filter for quality declines, with memetic content often winning out against more complex thinking. This could be exacerbated by AI-created content and voting. A solution to this is redesigning karma such that posts you upvote have their authors added to your \u2018trust graph\u2019. Users they trust will also be added to your trust graph, more weakly. There is no global karma - all karma you see is weighted by who upvoted it, and how strongly they feature in your trust graph. This is currently being tested on&nbsp;<a href=\"https://discord.gg/32gmgqebFu\"><u>SuperLinear Prizes</u></a>,&nbsp;<a href=\"https://discord.gg/QcBncCCpDG\"><u>Apart Research</u></a>, and a few other communities.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/FPTNhr2PgMEFskZHK/massive-earthquake-in-turkey-comments-on-the-situation-from\"><u>Massive Earthquake in Turkey: Comments on the situation from the EA Community in Turkey</u></a></p><p><i>by EA/A-shared</i></p><p>Two earthquakes of magnitude 7.8 and 7.7 occurred in Turkey, with at least 30,000 lives lost and more than 80,000 wounded. For those interested in donating, the EA community in Turkey shares several suggestions including&nbsp;<a href=\"https://donate.tpfund.org/campaign/tpf-turkiye-earthquake/c465112\"><u>Turkish Philanthropy Funds</u></a>,&nbsp;<a href=\"https://bagis.ahbap.org/bagis\"><u>AHBAP</u></a>, and&nbsp;<a href=\"https://www.justgiving.com/campaign/kahramanmarasearthquake\"><u>Turkey Mozaik Foundation</u></a>. They\u2019re also available to talk for anyone affected by the earthquakes at bilgi@eaturkiye.org.<br><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/jFnyqaLAtgfWpATeJ/ea-s-weirdness-makes-it-unusually-susceptible-to-bad\"><u>EA's weirdness makes it unusually susceptible to bad behavior</u></a></p><p><i>by OutsideView</i></p><p>The author argues that EA\u2019s high tolerance for weirdness comes with benefits (you need weirdness to generate new ideas and insights), but also with an increased risk of creepy and inappropriate behavior. They suggest being marginally less accepting of weirdness overall, less universal in assumptions of good faith, and much less accepting of any intersection between romance and office / network.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/aFGzLDwPrepQLevu6/should-evf-consider-appointing-new-board-members\"><u>Should EVF consider appointing new board members?</u></a></p><p><i>by BurnerAcct</i></p><p>Asks whether EVF should appoint new board members, considering two current members (Will MacAskill and Nick Beckstead) had significant enough ties to FTX to be recused from EVF FTX-related decision-making, two other board members are either funders or employees of EVF projects, and all current members are European or American.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/2oBKh3eJj8uDJzsoA/no-injuries-were-reported\"><u>No injuries were reported</u></a></p><p><i>by JulianHazell</i></p><p>After 10K chickens were killed in a fire a few weeks ago, an&nbsp;<a href=\"https://news.yahoo.com/100-000-chickens-die-coop-174800108.html?guccounter=1\"><u>article</u></a> noted that \u201cno injuries were reported in the fire\u201d - showing complete disregard for animal welfare. This post is a linkpost for the author\u2019s&nbsp;<a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Fmuddyclothes.substack.com%2Fp%2Fno-injuries-were-reported\"><u>short story</u></a> inspired by this situation.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/YqMsH9LH9C26mahue/no-silver-bullet-solutions-for-the-werewolf-crisis\"><u>No Silver Bullet Solutions for the Werewolf Crisis</u></a></p><p><i>by Aaron Gertler</i></p><p>Linkpost for&nbsp;<a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Fprogressandpoverty.substack.com%2Fp%2Fno-silver-bullets-to-the-werewolf\"><u>a short story</u></a> by Lars Doucet, which explores the idea that we often reject \u2018silver bullet\u2019 solutions without giving them a fair chance.</p><p>&nbsp;</p><p>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/BNKBJs4RJsA8FtdWE/a-personal-reflection-on-sbf\"><u>A personal reflection on SBF</u></a></p><p><i>by So8res</i></p><p>The author shares a personal account of their direct and indirect interactions with SBF. They originally wrote it in mid-November and intended to post publicly, but realized many observations were second-hand and shared in confidence, and are posting now with some details blurred out after prompting from a coworker.<br><br>Author\u2019s tl;dr: \u201cMy firsthand interactions with Sam were largely pleasant. Multiple of my friends had bad experiences with him, though. Some of them gave me warnings.</p><p>In one case, a friend warned me about Sam and I (foolishly) misunderstood the friend as arguing that Sam was pursuing ill ends, and weighed their evidence against other evidence that Sam was pursuing good ends, and wound up uncertain.</p><p>This was an error of reasoning. I had some impression that Sam had altruistic intent, and I had some second-hand reports that he was mean and untrustworthy in his pursuits. And instead of assembling this evidence to try to form a unified picture of the truth, I pit my evidence against itself, and settled on some middle-ground \u201cI\u2019m not sure if he\u2019s a force for good or for ill\u201d.</p><p>(And even if I hadn\u2019t made this error, I don\u2019t think I would\u2019ve been able to change much, though I might have been able to change a little.)\u201d</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/2eotFCxvFjXH7zNNw/people-will-sometimes-just-lie-about-you\"><u>People Will Sometimes Just Lie About You</u></a></p><p><i>by aella</i></p><p>The author is mini-famous, and has been shocked by how often people write incorrect or warped narratives about them. Before getting famous they assumed this wouldn\u2019t be the case if they were consistently kind, good, and charitable - but found that doesn\u2019t hold at scale. They give specific examples from their own experience, as well as discussing trends and motivations for why this can happen.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/ajdhMQEe7e8nNagiM/polyamory-and-dating-in-the-ea-community\"><u>Polyamory and dating in the EA community</u></a></p><p><i>by va</i></p><p>Discusses the current state of polyamory in EA, resources for learning more, and suggestions for mitigating risks if you are poly. Key points include:</p><ul><li>Polyamory in EA is most frequent in the Bay Area, with smaller pockets in London and Oxford, less common in continental Europe, and quite rare in Global South communities.</li><li>The author believes it\u2019s likely not the right choice for at least 60% of people.</li><li>Excluding people from your and your partners\u2019 dating pools who you may or do work with is a common and useful practice.</li><li>Don\u2019t discuss relationship structures at professional or EA community events, unless the event is explicitly about a related topic and the conversation opt-in.&nbsp;</li><li>When these conversations do happen, tackle them with nuance and without implying most EAs are poly or that EAs or rationalists or any specific person \u2018should\u2019 be poly.</li><li>If you\u2019re in a place where it\u2019s active, using&nbsp;<a href=\"https://www.reciprocity.io/\"><u>reciprocity.io</u></a> (which is opt-in) can help avoid issues around unintentionally pressuring others.</li></ul><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/a9vfDqofuZwbzpKvw/make-coi-policies-public\"><u>Make Conflict of Interest Policies Public</u></a></p><p><i>by Jeff Kaufman</i></p><p>It\u2019s reasonably common for nonprofits to publish their conflict of interest (COI) policies. The author suggests more EA organisations publicly share these, so concerned EAs can see what\u2019s already in place, other organisations can reference them to help form their own policies, and people worried about a specific situation can see what policy should have been followed.</p><p><br>&nbsp;</p><h1>Other</h1><p><a href=\"https://www.lesswrong.com/posts/wpRP44NT6kHaKNdnn/why-are-bacteria-so-simple\"><u>Why Are Bacteria So Simple?</u></a></p><p><i>by aysja</i></p><p>Bacteria (a form of prokaryote) have had ~4 billion years to evolve, but are still very simple - essentially DNA and DNA translation machinery. All multicellular life is eukaryotic, which is much more complex. The author states this is because prokaryotes have 4-5 orders of magnitude less DNA on average so simply can\u2019t do as much stuff.</p><p>This occurred primarily because both types of cells need energy to power DNA reactions, but Prokaryotes generate this along their cell membrane (scaling sublinearly with size), while Eukaryotes do it via mitochondria inside the cells (scaling with volume). This and the larger populations of prokaryotes mean it has a strong selection effect where any DNA not immediately useful is jettisoned due to energy cost - eg. bacteria will often jettison DNA giving antibiotic resistance within hours of the antibiotic disappearing. Eukaryotes keep more \u201cjunk\u201d DNA around, allowing time and space for useful changes to evolve. Over time this allowed modularity and regulatory elements like E. coli preferring glucose as an energy source, but switching to expressing genes which can digest lactose when glucose isn\u2019t present. Prokaryotes' energy needs have created almost exclusively \u2018exploit\u2019 behavior (as opposed to exploration), which has stunted their growth over billions of years.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/CYN7swrefEss4e3Qe/childhoods-of-exceptional-people\"><u>Childhoods of exceptional people</u></a></p><p><i>by Henrik Karlsson</i></p><p>The author skimmed 42 biographies of people who most Swedish people can recall as geniuses, to find patterns in their upbringing:</p><ul><li>&gt;2/3rds were home-educated (often until age 12), and &gt;95% were integrated with exceptional adults who took them seriously and invited them into serious discussions and meaningful work.</li><li>~95% had significant time on their own to roam, be bored, and explore their interests / self-teach. Their area of study that eventually made them famous was often something they became obsessed with while bored.</li><li>~70% were tutored 1-1 for more than 1 hour a day growing up.</li><li>~90% did a cognitive apprenticeship, with ~30% doing so before age 14.</li></ul><p>They were also all exceptionally gifted at a young age.</p><p><br>&nbsp;</p><h1>Didn\u2019t Summarize</h1><p><a href=\"https://forum.effectivealtruism.org/posts/QFHPbSWKfEcc7cuF5/thank-you-so-much-to-everyone-who-helps-with-our-community-s\"><u>Thank you so much to everyone who helps with our community's health and forum.</u></a>&nbsp;<i>by Arvin</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/CKnqXvLrkxsaYFtg8/appreciation-thread-feb-2023\"><u>Appreciation thread Feb 2023</u></a><i> by Michelle_Hutchinson&nbsp;</i>(open thread)</p><p><br>&nbsp;</p><h1>Special Mentions</h1><p><i>A selection of posts that don\u2019t meet the karma threshold, but seem important or undervalued.</i><br><br><a href=\"https://forum.effectivealtruism.org/posts/yoAuqGEvJ2Gss5YtK/hardening-pharmaceutical-response-to-pandemics-concrete\"><u>Hardening pharmaceutical response to pandemics: concrete project seeks project lead</u></a></p><p><i>by Joel Becker, PaulB, SeLo</i></p><p>Governments expend significant resources to protect command and control, military response, and other capabilities against threats. The authors have the&nbsp;<a href=\"https://docs.google.com/document/d/1XCN0qVtZesEcBTHCNsVSbQ3PUBmpz7tZg19EwtjO2XA/edit?usp=sharing\"><u>beginning of a plan</u></a> to do the same for pharmaceutical response capability, and are looking for a collaborator to help drive it forward (<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSc10OJ7rjPplRvCZiAbWp3CvR5qt7I2mXeFm4BKfQVywNeeGA/viewform\"><u>express interest here</u></a>).</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/tD2rXd9vXmTkRBwHN/scalable-longtermist-projects-speedrun-series-introduction\"><u>Scalable longtermist projects: Speedrun series \u2013 Introduction</u></a></p><p><i>by Buhl</i></p><p>A series of posts on mini-research projects conducted by Rethink Priorities in fall 2022, involving initial scoping and evaluation of ideas for scalable longtermist projects. This includes speedruns on&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/wAzYXjGxhJmrxunct/speedrun-develop-an-affordable-super-ppe\"><u>developing an affordable super PPE</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/SgeLEhS3zDfRBcXQG/speedrun-ai-alignment-prizes\"><u>creating AI alignment prizes</u></a>, and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/n52z7r8iH5pvWN2DE/speedrun-demonstrate-the-ability-to-rapidly-scale-food\"><u>demonstrating the ability to rapidly scale food production in the case of nuclear winter</u></a>.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/A9dS2AvNpG5FqxdR9/rethink-priorities-is-inviting-expressions-of-interest-for\"><u>Rethink Priorities is inviting expressions of interest for (co)leading a longtermist project/organization incubator</u></a></p><p><i>by Jam Kraprayoon, Rethink Priorities</i></p><p>Rethink Priorities is considering creating a Longtermist incubator program, and is accepting&nbsp;<a href=\"https://rethinkpriorities.pinpointhq.com/en/postings/5899b4c8-df46-417f-8fb7-d2950cea1d52/applications/new\"><u>expressions of interest</u></a> for a project lead / co-lead to run the program if it\u2019s launched. While there is currently no deadline, applications by 28th February are appreciated, to help inform planning efforts.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/nEnDvu2Ha9HLguvK8/update-from-the-ea-good-governance-project\"><u>Update from the EA Good Governance Project</u></a></p><p><i>by Grayden</i></p><p>Since launch 4 months ago, the&nbsp;<a href=\"https://www.eagoodgovernance.com/\"><u>EA Good Governance Project</u></a> has:</p><ul><li>Created a Trustee Directory with 60 individuals and a wide variety of skills. 28 organisations have signed up to view the directory.</li><li>Developed&nbsp;<a href=\"https://www.eagoodgovernance.com/organizations\"><u>guidance on a variety of governance topics</u></a>, including a&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/14s_sMNwT6xC1Ge1uhO_IKURb_rrZiooONBTV4TAhC-o/edit?usp=sharing\"><u>template for conducting a board assessment</u></a>.</li></ul><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/M3iPAmxZwy4gPXdXw/the-public-supports-regulating-ai-for-safety\"><u>The public supports regulating AI for safety</u></a></p><p><i>by Zach Stein-Perlman</i></p><p>Surveys show that many Americans are worried about and would support regulation on AI. For instance,&nbsp;<a href=\"https://www.monmouth.edu/polling-institute/documents/monmouthpoll_us_021523.pdf/\"><u>Artificial Intelligence Use Prompts Concerns</u></a> is a high-quality American public survey released last week by Monmouth, showing 55% of respondents think AI could eventually pose an existential threat (up from 44% in 2015), 55% favor \u201chaving a federal agency regulate the use of AI\u201d and 60% have heard about AI products like ChatGPT that can have conversations with you.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/QdYKFRexDaPeQaQCA/unjournal-s-1st-eval-is-up-resilient-foods-paper\"><u>Unjournal's 1st eval is up: Resilient foods paper (Denkenberger et al) &amp; AMA ~48 hours</u></a></p><p><i>by david_reinstein</i></p><p>The&nbsp;<a href=\"https://effective-giving-marketing.gitbook.io/unjournal-x-ea-and-global-priorities-research/\"><u>Unjournal</u></a> organizes and funds public journal-independent feedback, rating, and evaluation of hosted papers. It focuses on quantitative work that informs global priorities. The first evaluation is&nbsp;<a href=\"https://sciety.org/articles/activity/10.31219/osf.io/vrmpf\"><u>up now</u></a>, with two more to be released soon, and ~10 in the evaluation pipeline.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/fpudvy4KB6np324Fx/philanthropy-to-the-right-of-boom-founders-pledge\"><u>Philanthropy to the Right of Boom [Founders Pledge]</u></a></p><p><i>by christian.r</i></p><p>The author categorizes nuclear risk reduction interventions as \u2018left of boom\u2019 (before a nuclear strike eg. prevention) or \u2018right of boom\u2019 (after a nuclear strike eg. response, resilience). They analyzed all grants in the subject area \u201cNuclear Issues\u201d of the Peace and Security Funding Index, and identified any that could be considered \u201cright of boom\u201d - finding these receive at most one-thirtieth of total funding in the nuclear field (as an upper bound). They explore possible reasons for this neglectedness, and conclude that attention and political preferences play a role.</p><p><br>&nbsp;</p>", "user": {"username": "GreyArea"}}, {"_id": "FoRyordtA7LDoEhd7", "title": "There are no coherence theorems", "postedAt": "2023-02-20T21:52:14.479Z", "htmlBody": "<h1><strong>Introduction</strong></h1><p>For about fifteen years, the AI safety community has been discussing&nbsp;<a href=\"https://www.lesswrong.com/tag/coherence-arguments\"><u>coherence arguments</u></a>. In papers and posts on the subject, it\u2019s often written that there exist 'coherence theorems' which state that, unless an agent can be represented as maximizing expected utility, that agent is liable to pursue strategies that are dominated by some other available strategy. Despite the prominence of these arguments, authors are often a little hazy about exactly which theorems qualify as coherence theorems. This is no accident. If the authors had tried to be precise, they would have discovered that there are no such theorems.</p><p>I\u2019m concerned about this. Coherence arguments seem to be a moderately important part of the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/zoWypGfXLmYsDFivk/counterarguments-to-the-basic-ai-risk-case\"><u>basic case for existential risk from AI</u></a>. To spot the error in these arguments, we only have to look up what cited \u2018coherence theorems\u2019 actually say. And yet the error seems to have gone uncorrected for more than a decade.</p><p>More detail below.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefm3f997nzmno\"><sup><a href=\"#fnm3f997nzmno\">[1]</a></sup></span></p><h1><strong>Coherence arguments</strong></h1><p>Some authors frame coherence arguments in terms of \u2018dominated strategies\u2019. Others frame them in terms of \u2018exploitation\u2019, \u2018money-pumping\u2019, \u2018Dutch Books\u2019, \u2018shooting oneself in the foot\u2019, \u2018Pareto-suboptimal behavior\u2019, and \u2018losing things that one values\u2019 (see the <a href=\"https://forum.effectivealtruism.org/posts/FoRyordtA7LDoEhd7/there-are-no-coherence-theorems#Appendix__Papers_and_posts_in_which_the_error_occurs\">Appendix</a> for examples).</p><p>In the context of coherence arguments, each of these terms means roughly the same thing: a strategy&nbsp;A is&nbsp;<i>dominated</i> by a strategy&nbsp;B if and only if&nbsp;A is worse than&nbsp;B in some respect that the agent cares about and&nbsp;A is not better than&nbsp;B in any respect that the agent cares about. If the agent chooses&nbsp;A over&nbsp;B, they have behaved Pareto-suboptimally, shot themselves in the foot, and lost something that they value. If the agent\u2019s loss is someone else\u2019s gain, then the agent has been exploited, money-pumped, or Dutch-booked. Since all these phrases point to the same sort of phenomenon, I\u2019ll save words by talking mainly in terms of \u2018dominated strategies\u2019.</p><p>With that background, here\u2019s a quick rendition of&nbsp;<a href=\"https://aiimpacts.org/what-do-coherence-arguments-imply-about-the-behavior-of-advanced-ai/\"><u>coherence</u></a>&nbsp;<a href=\"https://www.lesswrong.com/posts/DkcdXsP56g9kXyBdq/coherence-arguments-imply-a-force-for-goal-directed-behavior\"><u>arguments</u></a>:</p><ol><li>There exist coherence theorems which state that, unless an agent can be represented as maximizing expected utility, that agent is liable to pursue strategies that are dominated by some other available strategy.</li><li>Sufficiently-advanced artificial agents will not pursue dominated strategies.</li><li>So, sufficiently-advanced artificial agents will be \u2018coherent\u2019: they will be representable as maximizing expected utility.</li></ol><p>Typically, authors go on to suggest that these expected-utility-maximizing agents are likely to behave in certain, potentially-dangerous ways. For example, such agents are likely to appear \u2018<a href=\"https://www.lesswrong.com/posts/DkcdXsP56g9kXyBdq/coherence-arguments-imply-a-force-for-goal-directed-behavior\"><u>goal-directed</u></a>\u2019 in some intuitive sense. They are likely to have certain&nbsp;<a href=\"https://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf\"><u>instrumental goals</u></a>, like acquiring power and resources. And they are likely to fight back against attempts to&nbsp;<a href=\"https://intelligence.org/files/Corrigibility.pdf\"><u>shut them down or modify their goals</u></a>.</p><p>There are many ways to challenge the argument stated above, and many of those&nbsp;<a href=\"https://aiimpacts.org/what-do-coherence-arguments-imply-about-the-behavior-of-advanced-ai/\"><u>challenges</u></a>&nbsp;<a href=\"https://www.lesswrong.com/posts/LDRQ5Zfqwi8GjzPYG/counterarguments-to-the-basic-ai-x-risk-case\"><u>have</u></a>&nbsp;<a href=\"https://www.lesswrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail-goal-directed-behavior\"><u>been</u></a>&nbsp;<a href=\"https://www.lesswrong.com/posts/vphFJzK3mWA4PJKAg/coherent-behaviour-in-the-real-world-is-an-incoherent\"><u>made</u></a>. There are also many ways to respond to those challenges, and many of those responses have been&nbsp;<a href=\"https://www.lesswrong.com/posts/EnN7cm3KaRrEAuWfa/comment-on-coherence-arguments-do-not-imply-goal-directed\"><u>made</u></a>&nbsp;<a href=\"https://www.lesswrong.com/posts/DkcdXsP56g9kXyBdq/coherence-arguments-imply-a-force-for-goal-directed-behavior\"><u>too</u></a>. The challenge that seems to remain yet unmade is that Premise 1 is false: there are no coherence theorems.</p><h1><strong>Cited \u2018coherence theorems\u2019 and what they actually say</strong></h1><p>Here\u2019s a list of theorems that have been called \u2018coherence theorems\u2019. None of these theorems state that, unless an agent can be represented as maximizing expected utility, that agent is liable to pursue dominated strategies. Here\u2019s what the theorems say:</p><h2><strong>The Von Neumann-Morgenstern Expected Utility Theorem:</strong></h2><p>The Von Neumann-Morgenstern Expected Utility Theorem is as follows:</p><blockquote><p>An agent can be represented as maximizing expected utility if and only if their preferences satisfy the following four axioms:</p><ol><li><strong>Completeness</strong>: For all lotteries&nbsp;X and&nbsp;Y,&nbsp;X is at least as preferred as&nbsp;Y or&nbsp;Y is at least as preferred as&nbsp;X.</li><li><strong>Transitivity</strong>: For all lotteries&nbsp;X,&nbsp;Y, and&nbsp;Z, if&nbsp;X is at least as preferred as&nbsp;Y, and&nbsp;Y is at least as preferred as&nbsp;Z, then&nbsp;X is at least as preferred as&nbsp;Z.</li><li><strong>Independence</strong>: For all lotteries&nbsp;X,&nbsp;Y, and&nbsp;Z, and all probabilities&nbsp;0&lt;p&lt;1, if&nbsp;X is strictly preferred to&nbsp;Y, then&nbsp;pX+(1-p)Z is strictly preferred to&nbsp;pY+(1-p)Z.</li><li><strong>Continuity</strong>: For all lotteries&nbsp;X,&nbsp;Y, and&nbsp;Z, with&nbsp;X strictly preferred to&nbsp;Y and&nbsp;Y strictly preferred to&nbsp;Z, there are probabilities&nbsp;p and&nbsp;q such that (i)&nbsp;0&lt;p&lt;1, (ii)&nbsp;0&lt;q&lt;1, and (iii)&nbsp;pX+(1-p)Z is strictly preferred to&nbsp;Y, and&nbsp;Y is strictly preferred to&nbsp;qX+(1-q)Z.</li></ol></blockquote><p>Note that this theorem makes no reference to dominated strategies, vulnerabilities, exploitation, or anything of that sort.</p><p>Some authors (both inside and outside the AI safety community) have tried to defend some or all of the axioms above using&nbsp;<i>money-pump arguments</i>. These are arguments with conclusions of the following form: \u2018agents who fail to satisfy Axiom A can be induced to make a set of trades or bets that leave them worse-off in some respect that they care about and better-off in no respect, even when they know in advance all the trades and bets that they will be offered.\u2019 Authors then use that conclusion to support a further claim. Outside the AI safety community, the claim is often:</p><blockquote><p>Agents are&nbsp;<i>rationally required</i> to satisfy Axiom A.</p></blockquote><p>But inside the AI safety community, the claim is:</p><blockquote><p>Sufficiently-advanced artificial agents&nbsp;<i>will&nbsp;</i>satisfy Axiom A.</p></blockquote><p>This difference will be important below. For now, the important thing to note is that the conclusions of money-pump arguments are not&nbsp;<i>theorems</i>. Theorems (like the VNM Theorem) can be proved without making any substantive assumptions. Money-pump arguments establish their conclusion only by making substantive assumptions: assumptions that might well be false. In the section titled \u2018<a href=\"https://forum.effectivealtruism.org/posts/FoRyordtA7LDoEhd7/there-are-no-coherence-theorems#A_money_pump_for_Completeness\">A money-pump for Completeness</a>\u2019, I will discuss an assumption that is both crucial to money-pump arguments and likely false.</p><h2><strong>Savage\u2019s Theorem</strong></h2><p>Savage\u2019s Theorem is also a Von-Neumann-Morgenstern-style representation theorem. It also says that an agent can be represented as maximizing expected utility if and only if their preferences satisfy a certain set of axioms. The key difference between Savage\u2019s Theorem and the VNM Theorem is that the VNM Theorem takes the agent\u2019s probability function as given, whereas Savage constructs the agent\u2019s probability function from their preferences over lotteries.</p><p>As with the VNM Theorem, Savage\u2019s Theorem says nothing about dominated strategies or vulnerability to exploitation.</p><h2><strong>The Bolker-Jeffrey Theorem</strong></h2><p>This theorem is also a representation theorem, in the mould of the VNM Theorem and Savage\u2019s Theorem above. It makes no reference to dominated strategies or anything of that sort.</p><h2><strong>Dutch Books</strong></h2><p>The Dutch Book Argument for Probabilism says:</p><blockquote><p>An agent can be induced to accept a set of bets that guarantee a net loss if and only if that agent\u2019s credences violate one or more of the probability axioms.</p></blockquote><p>The Dutch Book Argument for Conditionalization says:</p><blockquote><p>An agent can be induced to accept a set of bets that guarantee a net loss if and only if that agent updates their credences by some rule other than Conditionalization.</p></blockquote><p>These arguments do refer to dominated strategies and vulnerability to exploitation. But they suggest only that an agent\u2019s credences (that is, their degrees of belief) must meet certain conditions. Dutch Book Arguments place no constraints whatsoever on an agent\u2019s preferences. And if an agent\u2019s preferences fail to satisfy any of Completeness, Transitivity, Independence, and Continuity, that agent cannot be represented as maximizing expected utility (the VNM Theorem is an \u2018if and only if\u2019, not just an \u2018if\u2019).&nbsp;</p><h2><strong>Cox\u2019s Theorem</strong></h2><p>Cox\u2019s Theorem says that, if an agent\u2019s degrees of belief satisfy a certain set of axioms, then their beliefs are isomorphic to probabilities.</p><p>This theorem makes no reference to dominated strategies, and it says nothing about an agent\u2019s preferences.</p><h2><strong>The Complete Class Theorem</strong></h2><p>The Complete Class Theorem says that an agent\u2019s policy of choosing actions conditional on observations is not strictly dominated by some other policy (such that the other policy does better in some set of circumstances and worse in no set of circumstances) if and only if the agent\u2019s policy maximizes expected utility with respect to a probability distribution that assigns positive probability to each possible set of circumstances.</p><p>This theorem does refer to dominated strategies. However, the Complete Class Theorem starts off by assuming that the agent\u2019s preferences over actions in sets of circumstances satisfy Completeness and Transitivity. If the agent\u2019s preferences are not complete and transitive, the Complete Class Theorem does not apply. So, the Complete Class Theorem does not imply that agents must be representable as maximizing expected utility if they are to avoid pursuing dominated strategies.</p><h2><strong>Omohundro (2007), \u2018The Nature of Self-Improving Artificial Intelligence\u2019</strong></h2><p><a href=\"https://selfawaresystems.files.wordpress.com/2008/01/nature_of_self_improving_ai.pdf\"><u>This paper</u></a> seems to be the original source of the claim that agents are vulnerable to exploitation unless they can be represented as expected-utility-maximizers. Omohundro purports to give us \u201cthe celebrated expected utility theorem of von Neumann and Morgenstern\u2026 derived from a lack of vulnerabilities rather than from given axioms.\u201d&nbsp;</p><p>Omohundro\u2019s first error is to ignore Completeness. That leads him to mistake acyclicity for transitivity, and to think that any transitive relation is a total order. Note that this error already sinks any hope of getting an expected-utility-maximizer out of Omohundro\u2019s argument. Completeness (recall) is a necessary condition for being representable as an expected-utility-maximizer. If there\u2019s no money-pump that compels Completeness, there\u2019s no money-pump that compels expected-utility-maximization.</p><p>Omohundro\u2019s second error is to ignore Continuity. His \u2018Argument for choice with objective uncertainty\u2019 is too quick to make much sense of. Omohundro says it\u2019s a simpler variant of&nbsp;<a href=\"https://www.jstor.org/stable/1884281#metadata_info_tab_contents\"><u>Green (1987)</u></a>. The problem is that Green assumes every axiom of the VNM Theorem except Independence. He says so at the bottom of page 789. And, even then, Green notes that his paper provides \u201conly a qualified bolstering\u201d of the argument for Independence.</p><h1><i><strong>Money-Pump Arguments</strong></i><strong> by Johan Gustafsson</strong></h1><p>It\u2019s worth noting that there has recently appeared a book which gives money-pump arguments for each of the axioms of the VNM Theorem. It\u2019s by the philosopher Johan Gustafsson and you can read it&nbsp;<a href=\"https://www.cambridge.org/core/elements/moneypump-arguments/1515273BD710F308151F5BEC3695FEE6\"><u>here</u></a>.</p><p>This does not mean that the posts and papers claiming the existence of coherence theorems are correct after all. Gustafsson\u2019s book was published in 2022, long after most of the posts on coherence theorems. Gustafsson argues that the VNM axioms are&nbsp;<i>requirements of rationality</i>, whereas coherence arguments aim to establish that sufficiently-advanced artificial agents&nbsp;<i>will satisfy</i> the VNM axioms. More importantly (and as noted above) the conclusions of money-pump arguments are not theorems. Theorems (like the VNM Theorem) can be proved without making any substantive assumptions. Money-pump arguments establish their conclusion only by making substantive assumptions: assumptions that might well be false.</p><p>I will now explain how denying one such assumption allows us to resist Gustafsson\u2019s money-pump arguments. I will then argue that there can be no compelling money-pump arguments for the conclusion that sufficiently-advanced artificial agents will satisfy the VNM axioms.&nbsp;</p><p>Before that, though, let\u2019s get the lay of the land. Recall that Completeness is necessary for representability as an expected-utility-maximizer. If an agent\u2019s preferences are incomplete, that agent cannot be represented as maximizing expected utility. Note also that Gustafsson\u2019s money-pump arguments for the other axioms of the VNM Theorem depend on Completeness. As he writes in a footnote on page 3, his money-pump arguments for Transitivity, Independence, and Continuity all assume that the agent\u2019s preferences are complete. That makes Completeness doubly important to the \u2018money-pump arguments for expected-utility-maximization\u2019 project. If an agent\u2019s preferences are incomplete, then they can\u2019t be represented as an expected-utility-maximizer,&nbsp;<i>and</i> they can\u2019t be compelled by Gustafsson\u2019s money-pump arguments to conform their preferences to the other axioms of the VNM Theorem. (Perhaps some earlier, less careful money-pump argument can compel conformity to the other VNM axioms without assuming Completeness, but I think it unlikely.)</p><p>So, Completeness is crucial. But one might well think that we don\u2019t need a money-pump argument to establish it. I\u2019ll now explain why this thought is incorrect, and then we\u2019ll look at a money-pump.</p><h1><strong>Completeness doesn\u2019t come for free&nbsp;</strong></h1><p>Here\u2019s Completeness again:</p><blockquote><p><strong>Completeness</strong>: For all lotteries&nbsp;X and&nbsp;Y,&nbsp;X is at least as preferred as&nbsp;Y or&nbsp;Y is at least as preferred as&nbsp;X.</p></blockquote><p>Since:</p><blockquote><p>\u2018X is strictly preferred to&nbsp;Y\u2019 is defined as \u2018X is at least as preferred as&nbsp;Y and&nbsp;Y is&nbsp;<i>not&nbsp;</i>at least as preferred as&nbsp;X.\u2019</p></blockquote><p>And:&nbsp;</p><blockquote><p>\u2018The agent is indifferent between&nbsp;X and&nbsp;Y\u2019 is defined as \u2018X is at least as preferred as&nbsp;Y and&nbsp;Y is at least as preferred as&nbsp;X.\u2019</p></blockquote><p>Completeness can be rephrased as:</p><blockquote><p><strong>Completeness (rephrased)</strong>: For all lotteries&nbsp;X and&nbsp;Y, either&nbsp;X is strictly preferred to&nbsp;Y, or&nbsp;Y is strictly preferred to&nbsp;X, or the agent is indifferent between&nbsp;X and&nbsp;Y.</p></blockquote><p>And then you might think that Completeness comes for free. After all, what other comparative, preference-style attitude can an agent have to&nbsp;X and&nbsp;Y?</p><p>This thought might seem especially appealing if you think of preferences as nothing more than dispositions to choose. Suppose that our agent is offered repeated choices between&nbsp;X and&nbsp;Y. Then (the thought goes), in each of these situations, they have to choose&nbsp;<i>something</i>. If they reliably choose&nbsp;X over&nbsp;Y, then they strictly prefer&nbsp;X to&nbsp;Y. If they reliably choose&nbsp;Y over&nbsp;X, then they strictly prefer&nbsp;Y to&nbsp;X. If they flip a coin, or if they sometimes choose&nbsp;X and sometimes choose&nbsp;Y, then they are indifferent between&nbsp;X and&nbsp;Y.</p><p>Here\u2019s the important point missing from this thought: there are two ways of failing to have a strict preference between&nbsp;X and&nbsp;Y. Being&nbsp;<i>indifferent</i> between&nbsp;X and&nbsp;Y is one way: preferring&nbsp;X at least as much as&nbsp;Y and preferring&nbsp;Y at least as much as&nbsp;X. Having a&nbsp;<i>preferential gap&nbsp;</i>between&nbsp;X and&nbsp;Y is another way:&nbsp;<i>not&nbsp;</i>preferring&nbsp;X at least as much as&nbsp;Y and&nbsp;<i>not&nbsp;</i>preferring&nbsp;Y at least as much as&nbsp;X. If an agent has a preferential gap between any two lotteries, then their preferences violate Completeness.</p><p>The key contrast between indifference<i>&nbsp;</i>and preferential gaps is that indifference is&nbsp;<i>sensitive to all sweetenings and sourings</i>. Consider an example.&nbsp;C is a lottery that gives the agent a pot of ten dollar-bills for sure.&nbsp;D is a lottery that gives the agent a different pot of ten dollar-bills for sure. The agent does not strictly prefer&nbsp;C to&nbsp;D and does not strictly prefer&nbsp;D to&nbsp;C. How do we determine whether the agent is indifferent between&nbsp;C and&nbsp;D or whether the agent has a preferential gap between&nbsp;C and&nbsp;D? We&nbsp;<i>sweeten</i> one of the lotteries: we make that lottery just a little but more attractive. In the example, we add an extra dollar-bill to pot&nbsp;C, so that it contains $11 total. Call the resulting lottery&nbsp;C+. The agent will strictly prefer&nbsp;C+ to&nbsp;D. We get the converse effect if we&nbsp;<i>sour</i> lottery&nbsp;C, by removing a dollar-bill from the pot so that it contains $9 total. Call the resulting lottery&nbsp;C-. The agent will strictly prefer&nbsp;D to&nbsp;C-. And we also get strict preferences by sweetening and souring&nbsp;D, to get&nbsp;D+ and&nbsp;D- respectively. The agent will strictly prefer&nbsp;D+ to&nbsp;C and strictly prefer&nbsp;C to&nbsp;D-. Since the agent\u2019s preference-relation between&nbsp;C and&nbsp;D is sensitive to all such sweetenings and sourings, the agent is&nbsp;<i>indifferent&nbsp;</i>between&nbsp;C and&nbsp;D.</p><p>Preferential gaps, by contrast, are&nbsp;<i>insensitive to some sweetenings and sourings</i>. Consider another example.&nbsp;A is a lottery that gives the agent a Faberg\u00e9 egg for sure.&nbsp;B is a lottery that returns to the agent their long-lost wedding album. The agent does not strictly prefer&nbsp;A to&nbsp;B and does not strictly prefer&nbsp;B to&nbsp;A. How do we determine whether the agent is indifferent or whether they have a preferential gap? Again, we sweeten one of the lotteries.&nbsp;A+ is a lottery that gives the agent a Faberg\u00e9 egg plus a dollar-bill for sure. In this case, the agent might not strictly prefer&nbsp;A+ to&nbsp;B. That extra dollar-bill might not suffice to break the tie. If that is so, the agent has a&nbsp;<i>preferential gap</i> between&nbsp;A and&nbsp;B. If the agent has a preferential gap, then slightly souring&nbsp;A to get&nbsp;A- might also fail to break the tie, as might slightly sweetening and souring&nbsp;B to get&nbsp;B+ and&nbsp;B- respectively.</p><p>The axiom of Completeness rules out preferential gaps, and so rules out insensitivity to some sweetenings and sourings. That is why Completeness does not come for free. We need some argument for thinking that agents will not have preferential gaps. \u2018The agent has to choose something\u2019 is a bad argument. Faced with a choice between two lotteries, the agent might choose arbitrarily, but that does not imply that the agent is indifferent between the two lotteries. The agent might instead have a preferential gap. It depends on whether the agent\u2019s preference-relation is sensitive to all sweetenings and sourings.</p><h1><strong>A money-pump for Completeness</strong></h1><p>So, we need some other argument for thinking that sufficiently-advanced artificial agents\u2019 preferences over lotteries will be complete (and hence will be sensitive to all sweetenings and sourings). Let\u2019s look at a money-pump. I will later explain how my responses to this money-pump also tell against other money-pump arguments for Completeness.</p><p>Here's the money-pump, suggested by Ruth Chang (<a href=\"https://www.hup.harvard.edu/catalog.php?isbn=9780674447561\"><u>1997</u></a>, p.11) and later discussed by Gustafsson (<a href=\"https://www.cambridge.org/core/elements/moneypump-arguments/1515273BD710F308151F5BEC3695FEE6\"><u>2022</u></a>, p.26):</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676929936/mirroredImages/FoRyordtA7LDoEhd7/dtqelpf3seneny1k61zb.png\"></p><p>\u2018<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\succ\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u227b</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>\u2019 denotes strict preference and \u2018<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"||\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|</span></span></span></span></span></span></span></span></span>\u2019 denotes a preferential gap, so the symbols underneath the decision tree say that the agent strictly prefers&nbsp;A to&nbsp;A- and has a preferential gap between&nbsp;A- and&nbsp;B, and between&nbsp;B and&nbsp;A.&nbsp;</p><p>Now suppose that the agent finds themselves at the beginning of this decision tree. Since the agent doesn\u2019t strictly prefer&nbsp;A to&nbsp;B, they might choose to go up at node 1. And since the agent doesn\u2019t strictly prefer&nbsp;B to&nbsp;A-, they might choose to go up at node 2. But if the agent goes up at both nodes, they have pursued a dominated strategy: they have made a set of trades that left them with&nbsp;A- when they could have had&nbsp;A (an outcome that they strictly prefer), even though they knew in advance all the trades that they would be offered.</p><p>Note, however, that this money-pump is&nbsp;<i>non-forcing</i>: at some step in the decision tree, the agent is not compelled by their preferences to pursue a dominated strategy. The agent would not be acting against their preferences if they chose to go down at node 1 or at node 2. And if they went down at either node, they would not pursue a dominated strategy.</p><p>To avoid even a chance of pursuing a dominated strategy, we need only suppose that the agent acts in accordance with the following policy: \u2018if I go up at node 1, I will go down at node 2.\u2019 Since the agent does not strictly prefer&nbsp;A- to&nbsp;B, acting in accordance with this policy does not require the agent to change or act against any of their preferences.</p><p>More generally, suppose that the agent acts in accordance with the following policy in all decision-situations: \u2018if I previously turned down some option&nbsp;X, I will not choose any option that I strictly disprefer to&nbsp;X.\u2019<sup>&nbsp;</sup>That policy makes the agent immune to all possible money-pumps for Completeness.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5lk546omdey\"><sup><a href=\"#fn5lk546omdey\">[2]</a></sup></span>&nbsp;And (granted some assumptions), the policy never requires the agent to change or act against any of their preferences.</p><p>Here\u2019s why. Assume:</p><ul><li>That the agent\u2019s strict preferences are transitive.</li><li>That the agent knows in advance what trades they will be offered.</li><li>That the agent is capable of&nbsp;<i>backward induction</i>: predicting what they would choose at later nodes and taking those predictions into account at earlier nodes.</li></ul><p>(If the agent doesn\u2019t know in advance what trades they will be offered or is incapable of backward induction, then their pursuit of a dominated strategy need not indicate any defect in their preferences. Their pursuit of a dominated strategy can instead be blamed on their lack of knowledge and/or reasoning ability.)</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676929937/mirroredImages/FoRyordtA7LDoEhd7/ffcwpyyezjtyl7kctzyi.png\" alt=\"Diagram\n\nDescription automatically generated\"></p><p>Given the agent\u2019s knowledge of the decision tree and their grasp of backward induction, we can infer that, if the agent proceeds to node 2, then at least one of the possible outcomes of going to node 2 is not strictly dispreferred to any option available at node 1. Then, if the agent proceeds to node 2, they can act on a policy of not choosing any outcome that is strictly dispreferred to some option available at node 1. The agent\u2019s acting on this policy will not require them to act against any of their preferences. For suppose that it did<i>&nbsp;</i>require them to act against some strict preference. Suppose that&nbsp;B is strictly dispreferred to&nbsp;A, so that the agent\u2019s policy requires them to choose&nbsp;C, and yet&nbsp;C is strictly dispreferred to&nbsp;B. Then, by the transitivity of strict preference,&nbsp;C is strictly dispreferred to&nbsp;A. That means that both&nbsp;B and&nbsp;C are strictly dispreferred to&nbsp;A, contrary to our original assumption that at least one of the possible outcomes of going to node 2 is not strictly dispreferred to any option available at node 1. We have reached a contradiction, and so we can reject the assumption that the agent\u2019s policy will require them to act against their preferences. This proof is easy to generalize so that it applies to decision trees with more than three terminal outcomes.</p><h2><strong>Summarizing this section</strong></h2><p>Money-pump arguments for Completeness (understood as the claim that sufficiently-advanced artificial agents will have complete preferences) assume that such agents will not act in accordance with policies like \u2018if I previously turned down some option&nbsp;X, I will not choose any option that I strictly disprefer to&nbsp;X.\u2019 But that assumption is doubtful. Agents with incomplete preferences have good reasons to act in accordance with this kind of policy: (1) it never requires them to change or act against their preferences, and (2) it makes them immune to all possible money-pumps for Completeness.&nbsp;</p><p>So, the money-pump arguments for Completeness are unsuccessful: they don\u2019t give us much reason to expect that sufficiently-advanced artificial agents will have complete preferences. Any agent with incomplete preferences cannot be represented as an expected-utility-maximizer. So, money-pump arguments don\u2019t give us much reason to expect that sufficiently-advanced artificial agents will be representable as expected-utility-maximizers.</p><h1><strong>Conclusion</strong></h1><p>There are no coherence theorems. Authors in the AI safety community should stop suggesting that there are.</p><p>There are money-pump arguments, but the conclusions of these arguments are not theorems. The arguments depend on substantive and doubtful assumptions.</p><p>Here is one doubtful assumption: advanced artificial agents with incomplete preferences will not act in accordance with the following policy: \u2018if I previously turned down some option&nbsp;X, I will not choose any option that I strictly disprefer to&nbsp;X.\u2019 Any agent who acts in accordance with that policy is immune to all possible money-pumps for Completeness. And agents with incomplete preferences cannot be represented as expected-utility-maximizers.</p><p>In fact, the situation is worse than this. As Gustafsson notes, his money-pump arguments for the other three axioms of the VNM Theorem depend on Completeness. If Gustafsson\u2019s money-pump arguments fail without Completeness, I suspect that earlier, less-careful money-pump arguments for the other axioms of the VNM Theorem fail too. If that\u2019s right, and if Completeness is false, then none of Transitivity, Independence, and Continuity has been established by money-pump arguments either.</p><h2><strong>Bottom-lines</strong></h2><ul><li>There are no coherence theorems</li><li>Money-pump arguments don\u2019t give us much reason to expect that advanced artificial agents will be representable as expected-utility-maximizers.</li></ul><h1><strong>Appendix: Papers and posts in which the error occurs</strong></h1><p>Here\u2019s a selection of papers and posts which claim that there are coherence theorems.</p><h3><a href=\"https://selfawaresystems.files.wordpress.com/2008/01/nature_of_self_improving_ai.pdf\"><strong>\u2018<u>The nature of self-improving artificial intelligence</u>\u2019</strong></a></h3><p>\u201cThe appendix shows how the rational economic structure arises in each of these situations. Most presentations of this theory follow an axiomatic approach and are complex and lengthy. The version presented in the appendix is based solely on avoiding vulnerabilities and tries to make clear the intuitive essence of the argument.\u201d</p><p>\u201cIn each case we show that if an agent is to avoid vulnerabilities, its preferences must be representable by a utility function and its choices obtained by maximizing the expected utility.\u201d</p><h3><a href=\"https://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf\"><strong>\u2018<u>The basic AI drives</u>\u2019</strong></a></h3><p>\u201cThe remarkable \u201cexpected utility\u201d theorem of microeconomics says that it is always possible for a system to represent its preferences by the expectation of a utility function unless the system has \u201cvulnerabilities\u201d which cause it to lose resources without benefit.\u201d</p><h3><a href=\"https://www.lesswrong.com/posts/RQpNHSiWaXTvDxt6R/coherent-decisions-imply-consistent-utilities\"><strong><u>\u2018Coherent decisions imply consistent utilities\u2019</u></strong></a></h3><p>\u201cIt turns out that this is just one instance of a large family of&nbsp;<i>coherence theorems</i>&nbsp;which all end up pointing at the same set of core properties. All roads lead to Rome, and all the roads say, \"If you are not shooting yourself in the foot in sense X, we can view you as having coherence property Y.\"\u201d</p><p>\u201cNow, by the general idea behind coherence theorems, since we can't&nbsp;<i>view this behavior</i>&nbsp;as corresponding to expected utilities, we ought to be able to show that it corresponds to a dominated strategy somehow\u2014derive some way in which this behavior corresponds to shooting off your own foot.\u201d</p><p>\u201cAnd that's at least a glimpse of why, if you're not using dominated strategies, the thing you do with relative utilities is multiply them by probabilities in a consistent way, and prefer the choice that leads to a greater expectation of the variable representing utility.\u201d</p><p>\u201cThe demonstrations we've walked through here aren't the professional-grade coherence theorems as they appear in real math. Those have names like \"Cox's Theorem\" or \"the complete class theorem\"; their proofs are difficult; and they say things like \"If seeing piece of information A followed by piece of information B leads you into the same epistemic state as seeing piece of information B followed by piece of information A, plus some other assumptions, I can show an isomorphism between those epistemic states and classical probabilities\" or \"Any decision rule for taking different actions depending on your observations either corresponds to Bayesian updating given some prior, or else is strictly dominated by some Bayesian strategy\".\u201d</p><p>\u201cBut hopefully you've seen enough concrete demonstrations to get a general idea of what's going on with the actual coherence theorems. We have multiple spotlights all shining on the same core mathematical structure, saying dozens of different variants on, \"If you aren't running around in circles or stepping on your own feet or wantonly giving up things you say you want, we can see your behavior as corresponding to this shape. Conversely, if we can't see your behavior as corresponding to this shape, you must be visibly shooting yourself in the foot.\" Expected utility is the only structure that has this great big family of discovered theorems all saying that. It has a scattering of academic competitors, because academia is academia, but the competitors don't have anything like that mass of spotlights all pointing in the same direction.\u201d</p><h3><a href=\"https://www.lesswrong.com/posts/RQpNHSiWaXTvDxt6R/coherent-decisions-imply-consistent-utilities?commentId=GyE8wvZuWcuiCaySb#comments\"><strong><u>\u2018Things To Take Away From The Essay\u2019</u></strong></a></h3><p>\u201cSo what are the primary coherence theorems, and how do they differ from VNM? Yudkowsky mentions the complete class theorem in the post, Savage's theorem comes up in the comments, and there are variations on these two and probably others as well. Roughly, the general claim these theorems make is that any system&nbsp;<i>either</i>&nbsp;(a) acts like an expected utility maximizer under some probabilistic model, or (b) throws away resources in a pareto-suboptimal manner. One thing to emphasize: these theorems generally do not assume any pre-existing probabilities (as VNM does); an agent's implied probabilities are instead derived. Yudkowsky's essay does a good job communicating these concepts, but doesn't emphasize that this is&nbsp;<i>different</i>&nbsp;from VNM.\u201d</p><h3><a href=\"https://arbital.com/p/optimized_agent_appears_coherent/\"><strong><u>\u2018Sufficiently optimized agents appear coherent\u2019</u></strong></a></h3><p>\u201cSummary: Violations of coherence constraints in probability theory and decision theory correspond to qualitatively destructive or dominated behaviors.\u201d</p><p>\u201cAgain, we see a manifestation of a powerful family of theorems showing that agents which cannot be seen as corresponding to any coherent probabilities and consistent utility function will exhibit qualitatively destructive behavior, like paying someone a cent to throw a switch and then paying them another cent to throw it back.\u201d</p><p>\u201cThere is a large literature on different sets of coherence constraints that all yield expected utility, starting with the Von Neumann-Morgenstern Theorem. No other decision formalism has comparable support from so many families of differently phrased coherence constraints.\u201d</p><h3><a href=\"https://aiimpacts.org/what-do-coherence-arguments-imply-about-the-behavior-of-advanced-ai/\"><strong><u>\u2018What do coherence arguments imply about the behavior of advanced AI?\u2019</u></strong></a></h3><p>\u201cCoherence arguments say that if an entity\u2019s preferences do not adhere to the axioms of expected utility theory, then that entity is susceptible to losing things that it values.\u201d</p><p><strong>Disclaimer</strong>: \u201cThis is an initial page, in the process of review, which may not be comprehensive or represent the best available understanding.\u201d</p><h3><a href=\"https://arbital.com/p/coherence_theorems/\"><strong><u>\u2018Coherence theorems\u2019</u></strong></a></h3><p>\u201cIn the context of&nbsp;decision theory, \"coherence theorems\" are theorems saying that an agent's beliefs or behavior must be viewable as consistent in way X, or else penalty Y happens.\u201d</p><p><strong>Disclaimer</strong>: \u201cThis page's quality has not been assessed.\u201d</p><p>\u201cExtremely incomplete list of some coherence theorems in decision theory</p><ul><li>Wald\u2019s complete class theorem</li><li>Von-Neumann-Morgenstern utility theorem</li><li>Cox\u2019s Theorem</li><li>Dutch book arguments\u201d</li></ul><h3><a href=\"https://www.lesswrong.com/posts/NxF5G6CJiof6cemTw/coherence-arguments-do-not-entail-goal-directed-behavior\"><strong><u>\u2018Coherence arguments do not entail goal-directed behavior\u2019</u></strong></a></h3><p>\u201cOne of the most pleasing things about probability and expected utility theory is that there are many&nbsp;<i>coherence arguments</i>&nbsp;that suggest that these are the \u201ccorrect\u201d ways to reason. If you deviate from what the theory prescribes, then you must be executing a&nbsp;<i>dominated strategy</i>. There must be some other strategy that never does any worse than your strategy, but does strictly better than your strategy with certainty in at least one situation. There\u2019s a good explanation of these arguments&nbsp;<a href=\"https://arbital.com/p/expected_utility_formalism/?l=7hh\"><u>here</u></a>.\u201d</p><p>\u201cThe VNM axioms are often justified on the basis that if you don't follow them, you can be Dutch-booked: you can be presented with a series of situations where you are guaranteed to lose utility relative to what you could have done. So on this view, we have \"no Dutch booking\" implies \"VNM axioms\" implies \"AI risk\".\u201d</p><h3><a href=\"https://www.lesswrong.com/posts/DkcdXsP56g9kXyBdq/coherence-arguments-imply-a-force-for-goal-directed-behavior\"><strong><u>\u2018Coherence arguments imply a force for goal-directed behavior.\u2019</u></strong></a><strong>&nbsp;</strong></h3><p>\u201c<strong>\u2018</strong>Coherence arguments\u2019 mean that if you don\u2019t maximize \u2018expected utility\u2019 (EU)\u2014that is, if you don\u2019t make every choice in accordance with what gets the highest average score, given consistent preferability scores that you assign to all outcomes\u2014then you will make strictly worse choices by your own lights than if you followed some alternate EU-maximizing strategy (at least in some situations, though they may not arise). For instance, you\u2019ll be vulnerable to \u2018money-pumping\u2019\u2014being predictably parted from your money for nothing.<a href=\"https://aiimpacts.org/coherence-arguments-imply-a-force-for-goal-directed-behavior/#easy-footnote-bottom-3-2875\"><sup><u>3</u></sup></a>\u201d</p><h3><a href=\"https://intelligence.org/2016/12/28/ai-alignment-why-its-hard-and-where-to-start/#1\"><strong>\u2018<u>AI Alignment: Why It\u2019s Hard, and Where to Start</u>\u2019</strong></a></h3><p>\u201cThe overall message here is that there is a set of qualitative behaviors and as long you do not engage in these qualitatively destructive behaviors, you will be behaving as if you have a utility function.\u201d</p><h3><a href=\"https://www.lesswrong.com/posts/ZTN6bLWqpwWn2i4qZ/money-pumping-the-axiomatic-approach\"><strong><u>\u2018Money-pumping: the axiomatic approach\u2019</u></strong></a></h3><p>\u201cThis post gets somewhat technical and mathematical, but the point can be summarised as:</p><ul><li>You are vulnerable to money pumps only to the extent to which you deviate from the&nbsp;von Neumann-Morgenstern&nbsp;axioms of expected utility.</li></ul><p>In other words, using alternate decision theories is bad for your wealth.\u201d</p><h3><a href=\"https://www.lesswrong.com/posts/7im8at9PmhbT4JHsW/ngo-and-yudkowsky-on-alignment-difficulty#_Yudkowsky__11_22_\"><strong><u>\u2018Ngo and Yudkowsky on alignment difficulty\u2019</u></strong></a></h3><p>\u201cExcept that to do the exercises at all, you need them to work within an expected utility framework. And then they just go, \"Oh, well, I'll just build an agent that's good at optimizing things but doesn't use these explicit expected utilities that are the source of the problem!\"</p><p>And then if I want them to believe the same things I do, for the same reasons I do, I would have to teach them why certain structures of cognition are the parts of the agent that are good at stuff and do the work, rather than them being this particular formal thing that they learned for manipulating meaningless numbers as opposed to real-world apples.</p><p>And I have tried to write that page once or twice (eg \"<a href=\"https://www.lesswrong.com/posts/RQpNHSiWaXTvDxt6R/coherent-decisions-imply-consistent-utilities\"><u>coherent decisions imply consistent utilities</u></a>\") but it has not sufficed to teach them, because they did not even do as many homework problems as I did, let alone the greater number they'd have to do because this is in fact a place where I have a particular talent.\u201d</p><p>\u201cIn this case the higher structure I'm talking about is Utility, and doing homework with coherence theorems leads you to appreciate that we only know about one higher structure for this class of problems that has a dozen mathematical spotlights pointing at it saying \"look here\", even though people have occasionally looked for alternatives.</p><p>And when I try to say this, people are like, \"Well, I looked up a theorem, and it talked about being able to identify a unique utility function from an infinite number of choices, but if we don't have an infinite number of choices, we can't identify the utility function, so what relevance does this have\" and this is a kind of mistake I don't remember even coming close to making so I do not know how to make people stop doing that and maybe I can't.\u201d</p><p>\u201cRephrasing again: we have a wide variety of mathematical theorems all spotlighting, from different angles, the fact that a plan lacking in clumsiness, is possessing of coherence.\u201d</p><h3><a href=\"https://www.lesswrong.com/s/n945eovrA3oDueqtq/p/hwxj4gieR7FWNwYfa#_Yudkowsky__11_51__11_53_\"><strong><u>\u2018Ngo and Yudkowsky on AI capability gains\u2019</u></strong></a></h3><p>\u201cI think that to contain the concept of Utility as it exists in me, you would have to do homework exercises I don't know how to prescribe. Maybe one set of homework exercises like that would be showing you an agent, including a human, making some set of choices that allegedly couldn't obey expected utility, and having you figure out how to pump money from that agent (or present it with money that it would pass up).</p><p>Like, just actually doing that a few dozen times.</p><p>Maybe it's not helpful for me to say this? If you say it to Eliezer, he immediately goes, \"Ah, yes, I could see how I would update that way after doing the homework, so I will save myself some time and effort and just make that update now without the homework\", but this kind of jumping-ahead-to-the-destination is something that seems to me to be... dramatically missing from many non-Eliezers. They insist on learning things the hard way and then act all surprised when they do. Oh my gosh, who would have thought that an AI breakthrough would suddenly make AI seem less than 100 years away the way it seemed yesterday? Oh my gosh, who would have thought that alignment would be difficult?</p><p>Utility can be seen as the origin of Probability within minds, even though Probability obeys its own, simpler coherence constraints.\u201d</p><h3><a href=\"https://www.lesswrong.com/posts/RorXWkriXwErvJtvn/agi-will-have-learnt-utility-functions\"><strong><u>\u2018AGI will have learnt utility functions\u2019</u></strong></a></h3><p>\u201cThe view that utility maximizers are inevitable is supported by a number of coherence theories developed early on in game theory which show that any agent without a consistent utility function is exploitable in some sense.\u201d</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnm3f997nzmno\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefm3f997nzmno\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Thanks to Adam Bales, Dan Hendrycks, and members of the CAIS Philosophy Fellowship for comments on a draft of this post. When I emailed Adam to ask for comments, he replied with his own draft paper on coherence arguments. Adam\u2019s paper takes a somewhat different view on money-pump arguments, and should be available soon.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5lk546omdey\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5lk546omdey\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Gustafsson later offers a&nbsp;<i>forcing&nbsp;</i>money-pump argument for Completeness: a money-pump in which, at each step, the agent is compelled by their preferences to pursue a dominated strategy. But agents who act in accordance with the policy above are immune to this money-pump as well. Here\u2019s why.</p><p>Gustafsson claims that, in the original non-forcing money-pump, going up at node 2 cannot be irrational. That\u2019s because the agent does not strictly disprefer&nbsp;A- to&nbsp;B: the only other option available at node 2. The fact that&nbsp;A was previously available cannot make choosing&nbsp;A- irrational, because (Gustafsson claims)&nbsp;<i>Decision-Tree Separability</i> is true: \u201cThe rational status of the options at a choice node does not depend on other parts of the decision tree than those that can be reached from that node.\u201d But (Gustafsson claims) the sequence of choices consisting of going up at nodes 1 and 2 is irrational, because it leaves the agent worse-off than they could have been. That implies that going up at node 1 must be irrational, given what Gustafsson calls \u2018<i>The Principle of Rational Decomposition</i>\u2019: any irrational sequence of choices must contain at least one irrational choice. Generalizing this argument, Gustafsson gets a general rational requirement to choose option&nbsp;A whenever your other option is to proceed to a choice node where your options are&nbsp;A- and&nbsp;B. And it\u2019s this general rational requirement (\u2018<i>Minimal Unidimensional Precaution</i>\u2019) that allows Gustafsson to construct his forcing money-pump. In this forcing money-pump, an agent\u2019s incomplete preferences compel them to violate the&nbsp;<i>Principle of Unexploitability</i>: that principle which says getting money-pumped is irrational.&nbsp;<i>The Principle of Preferential Invulnerability</i> then implies that incomplete preferences are irrational, since it\u2019s been shown that there exists a situation in which incomplete preferences force an agent to violate the Principle of Unexploitability.</p><p>Note that Gustafsson aims to establish that agents are&nbsp;<i>rationally required&nbsp;</i>to have complete preferences, whereas coherence arguments aim to establish that sufficiently-advanced artificial agents&nbsp;<i>will have&nbsp;</i>complete preferences. These different conclusions require different premises. In place of Gustafsson\u2019s Decision-Tree Separability, coherence arguments need an amended version that we can call&nbsp;<i>\u2018Decision-Tree Separability*</i>\u2019: sufficiently-advanced artificial agents\u2019 dispositions to choose options at a choice node will not depend on other parts of the decision tree than those that can be reached from that node. But this premise is easy to doubt. It\u2019s false if any sufficiently-advanced artificial agent acts in accordance with the following policy: \u2018if I previously turned down some option&nbsp;X, I will not choose any option that I strictly disprefer to&nbsp;X.\u2019 And it\u2019s easy to see why agents might act in accordance with that policy: it makes them immune to all possible money-pumps for Completeness, and (as I am about to prove back in the main text) it never requires them to change or act against any of their preferences.</p><p>John Wentworth\u2019s \u2018<a href=\"https://www.lesswrong.com/posts/3xF66BNSC5caZuKyC/why-subagents\"><u>Why subagents?</u></a>\u2019 suggests another policy for agents with incomplete preferences: trade only when offered an option that you strictly prefer to your current option. That policy makes agents immune to the single-souring money-pump. The downside of Wentworth\u2019s proposal is that an agent following his policy will pursue a dominated strategy in single-<i>sweetening&nbsp;</i>money-pumps, in which the agent first has the opportunity to trade in&nbsp;A for&nbsp;B and then (conditional on making that trade) has the opportunity to trade in&nbsp;B for&nbsp;A+. Wentworth\u2019s policy will leave the agent with&nbsp;A when they could have had&nbsp;A+.</p></div></li></ol>", "user": {"username": "elliottthornley"}}, {"_id": "AyXPe55d8gMA8Djux", "title": "EA Lifestyles: Filial Piety and EA", "postedAt": "2023-02-20T19:57:39.135Z", "htmlBody": "<p>\"And perhaps our faithful attendance to our parents can make us better at caring for strangers. Respecting our parents can give us the skills to treat everyone with dignity (no matter how frustrating or undeserving they might occasionally seem); it can teach us to give generously while still setting boundaries; caring for our parents allows us to see the impact of our giving and adjust when we make mistakes. Perhaps our altruism can also make us better children.\"</p>", "user": {"username": "Khorton"}}, {"_id": "9JCkkjKMNL4Hmg4qP", "title": "EV UK board statement on Owen's resignation", "postedAt": "2023-02-20T17:49:10.541Z", "htmlBody": "<p>In a recent TIME Magazine article, a claim of misconduct was made about an \u201cinfluential figure in EA\u201d:&nbsp;</p><blockquote><p>A third [woman] described an unsettling experience with an influential figure in EA whose role included picking out promising students and funneling them towards highly coveted jobs. After that leader arranged for her to be flown to the U.K. for a job interview, she recalls being surprised to discover that she was expected to stay in his home, not a hotel. When she arrived, she says, \u201che told me he needed to masturbate before seeing me.\u201d</p></blockquote><p>Shortly after the article came out, Julia Wise (CEA\u2019s community liaison) informed the EV UK board that this concerned behaviour of Owen Cotton-Barratt;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1jurrw7kehn\"><sup><a href=\"#fn1jurrw7kehn\">[1]</a></sup></span>&nbsp;the incident occurred more than 5 years ago and was reported to her in 2021.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2cvz37cjvrd\"><sup><a href=\"#fn2cvz37cjvrd\">[2]</a></sup></span>&nbsp;(Owen became a board member in 2020.)</p><p>Following this, on February 11th, Owen voluntarily resigned from the board. This included stepping down from his role with Wytham Abbey; he is also no longer helping organise The Summit on Existential Security.&nbsp;</p><p>Though <a href=\"https://forum.effectivealtruism.org/posts/QMee23Evryqzthcvn/a-statement-and-an-apology\">Owen\u2019s account</a> of the incident differs in scope and emphasis from the version expressed in the TIME article, he still believes that he made significant mistakes, and also notes that there have been other cases where he regretted his behaviour.</p><p>It's very important to us that EV and the wider EA community strive to provide safe and respectful environments, and that we have reliable mechanisms for investigating and addressing claims of misconduct in the EA community. So, in order to better understand what happened, we are commissioning an external investigation by an independent law firm into Owen\u2019s behaviour and the Community Health team\u2019s response.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn1wbflutyvm\"><sup><a href=\"#fnn1wbflutyvm\">[3]</a></sup></span></p><p>&nbsp;</p><p><i>This post is jointly from the Board of EV UK: Claire Zabel, Nick Beckstead, Tasha McCauley and Will MacAskill.</i></p><p><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1jurrw7kehn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1jurrw7kehn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The disclosure occurred as follows: shortly after the article came out, Owen and Julia agreed that Julia would work out whether Owen's identity should be disclosed to other people in EV UK and EV US; Julia determined that it should be shared with the boards.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2cvz37cjvrd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2cvz37cjvrd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Julia writes about her response at the time <a href=\"https://forum.effectivealtruism.org/posts/9JCkkjKMNL4Hmg4qP/ev-uk-board-statement-on-owen-s-resignation?commentId=vjtEvaxDHFvfTXwBF\">here</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn1wbflutyvm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn1wbflutyvm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See comment <a href=\"https://forum.effectivealtruism.org/posts/9JCkkjKMNL4Hmg4qP/ev-uk-board-statement-on-owen-s-resignation?commentId=CRdikDzzK2z92GLSs\">here</a> from Chana Messinger on behalf of the Community Health team.&nbsp;</p></div></li></ol>", "user": {"username": "EV UK Board"}}, {"_id": "QMee23Evryqzthcvn", "title": "A statement and an apology", "postedAt": "2023-02-20T17:35:06.465Z", "htmlBody": "<h2>December 2023 edit:</h2><p>I've done a lot of reflection since February and my perspective on many things has shifted. <a href=\"https://forum.effectivealtruism.org/posts/QMee23Evryqzthcvn/a-statement-and-an-apology?commentId=D7fJfwHq68qewZyCD\">You can see a statement update here</a>. I've left my original statement unedited (except in one place where noted) below:</p><h1>Original post</h1><p>Since the Time article on sexual harassment came out,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JCyX29F77Jak5gbwq/ea-sexual-harassment-and-abuse?commentId=d8AjvmSaXSdm6d6hs\"><u>people have been asking for information about one paragraph of it</u></a>, about an \u201cinfluential figure in EA\u201d. I wanted to respond to that.</p><p>This is talking about me, more than five years ago. I think I made significant mistakes; I regret them a lot; and I\u2019m sorry.</p><p><strong>[March 2024 edited to add:] </strong>I've recently discovered that some people had interpreted the act in question to have occurred after she arrived at my house. I want to clarify that it happened <strong>before she arrived</strong> (I wanted to reduce the extent to which attraction was a significant part of my experience when she was there), but disclosing that to her (which I now think was extremely poorly judged) happened afterwards.</p><h2>Context</h2><p>I think the actual mistakes I made look different from what many readers may take away from the article, so I first&nbsp;<strong>wanted to provide a bit more context</strong> (some of this is straightforwardly factual; other parts should be understood as my interpretation):</p><ul><li>We had what I perceived as a preexisting friendship where we were experimenting with being unusually direct and honest (/\u201cedgy\u201d)<ul><li>Including about sexual matters<ul><li>There was what would commonly be regarded as oversharing from both sides (this wasn\u2019t the first time I\u2019d mentioned masturbation)</li></ul></li><li>Our friendship continued in an active way for several months afterwards</li><li>I should however note that:<ul><li>We had met via EA and spent a good fraction of conversation time talking about EA-relevant topics</li><li>I was older and more central in the EA community</li><li>On other occasions, including early in our friendship, we had some professional interactions, and I wasn\u2019t clear about how I was handling the personal/professional boundary</li></ul></li></ul></li><li>I was employed as a researcher at that time<ul><li>My role didn\u2019t develop to connecting people with different positions until later, and this wasn\u2019t part of my self-conception at the time</li><li>(However it makes sense to me that this was her perception)</li></ul></li><li>I was not affiliated with the org she was interviewing at<ul><li>I\u2019d suggested her as a candidate earlier in the application process, but was not part of their decision-making process</li></ul></li></ul><p>On the other hand I think that a lot of what was problematic about my behaviour with respect to this person was not about this incident in particular, but the broad dynamic where:</p><ul><li>I in fact had significant amounts of power<ul><li>This was not very salient to me but very salient to her</li></ul></li><li>She consequently felt pressure to match my vibe<ul><li>e.g. in an earlier draft of this post, before fact-checking it with her, I said that we talked about \u201cfeelings of mutual attraction\u201d<ul><li>This was not her experience</li><li>I drafted it like that because we\u2019d had what I\u2019d interpreted as conversations where this was stated explicitly</li><li>(I think this is just another central example of the point I\u2019m making in this set of bullets)</li></ul></li><li>Similarly at some point she volunteered to me that she was enjoying the dynamic between us (but I probably interpreted this much more broadly than she intended)</li></ul></li><li>She was in a structural position where it was (I now believe) unreasonable to expect honesty about her experience</li><li>As the person with power it was on me to notice and head off these dynamics, and I failed to do that</li></ul><p>(Sorry, I know that's all pretty light on detail, but I don't want to risk accidentally de-anonymising the other person. I want to stress that I\u2019m not claiming she provided any inaccurate information to the journalist who wrote the story; just that I think the extra context may be helpful for people seeking to evaluate or understand my conduct.)</p><h2>My mistakes</h2><p>In any case,<strong> I think my actions were poorly judged</strong> and fell well short of the high standards I would like to live up to, and that I think we should ask from people in positions of leadership. Afterwards, I felt vaguely like the whole friendship wasn\u2019t well done and I wished I had approached things differently. Then&nbsp;<strong>when I found out that I\u2019d made the person feel uncomfortable(/disempowered/pressured), I was horrified&nbsp;</strong>(not putting pressure on people is something like a core value of mine). I have apologized to the person in question, but I also feel like I\u2019ve let the whole community down, and I would like to apologize unreservedly.&nbsp;<strong>It\u2019s extremely important to me that our community is a welcoming place for everyone, and I feel dismayed that I have contributed to it not being so.</strong> If there\u2019s anyone else whom I\u2019ve ever made feel uncomfortable or pressured, I\u2019d love to hear about it \u2014 I think I might benefit most from a conversation, but I\u2019d also welcome&nbsp;<a href=\"https://www.admonymous.co/owencb\"><u>anonymous feedback</u></a>.</p><p>Was this incident an isolated case? Yes and no.&nbsp;<strong>I think this was by some way my most egregious mistake of this type</strong>. However, in my time in EA there have been four other occasions on which I expressed feelings of attraction towards someone in a way that \u2014 in retrospect as I\u2019ve developed a more nuanced understanding of power dynamics \u2014 I regret. (In most of these cases I\u2019m still on very good terms with the person.) I\u2019ve slowly been improving my implicit models (so I never quite make the same mistake twice), but honestly it\u2019s gone more slowly than I think it should have done.</p><p>There were&nbsp;<strong>several intertwined mistakes</strong> here:</p><ul><li><strong>I was not attendant to implicit power dynamics</strong><ul><li>I was aware that hard power (like employer relationships or grantmaking) mattered, but I was pretty blind to the implications of the soft power that came from being older and more central in the community</li></ul></li><li><strong>I entangled personal and professional (without being clear about how I was handling that)</strong><ul><li>I was aware that it was important not to let personal relationships cloud professional judgements, but I didn\u2019t understand the point as deeply as I do today; moreover I was not properly alive to the importance of keeping these&nbsp;<i>legibly-to-others</i> separate (&amp; I didn\u2019t discuss how I was approaching it with this person)</li></ul></li><li><strong>I didn\u2019t respect normal societal standards about what\u2019s oversharing</strong>, or what conversational implicature might be,&nbsp;<strong>especially re. anything sexual</strong><ul><li>I think this meant that misunderstandings were especially likely; I think it was particularly egregious when combined with the above issues</li></ul></li><li><strong>I made decisions about how to communicate while flinching internally</strong><ul><li>I should have been more conscious that I was feeling a lot of shame (over all kinds of things, including the fact of being attracted to people!), and that this meant I would think less well than normal. I should consequently have taken steps sooner to address this</li></ul></li></ul><p>(How could I have come to make these mistakes? I was leaning into my own view-at-the-time about what good conduct looked like, and interested in experimenting to find ways to build a better culture than society-at-large has. I was newly open to polyamory, and newly exposed to circling and saw something powerful and good about speaking truths even when they were uncomfortable. And I was naively optimistic that we could ~do away with interpersonal power dynamics, so that&nbsp;<i>of course</i> someone would tell me if they were ever uncomfortable. (I now think that this kind of power differential represents exactly the circumstances in which it\u2019s unfair to expect the disempowered person to be able to correct conversational dynamics which are off.)&nbsp; And then I was making decisions quickly without reflecting appropriately \u2014 and I was slow to correct mistakes after the fact \u2014 because shame impeded my metacognition from looking closely at what was going on.)</p><h2>What can you expect from me going forward?</h2><p>Some updates I\u2019d already made (simplified):</p><ul><li>Before 2020:<ul><li>Don\u2019t be edgy&nbsp;</li><li>Make sure that anything intimate comes up only in relationships where there\u2019s a good existing foundation of trust</li><li>Don\u2019t consider romantic engagements in cases where there\u2019s a big age gap</li><li>It\u2019s good to make handling of personal/professional matters legible to others</li></ul></li><li>2021:<ul><li>Attend significantly to implicit power dynamics for anything relating to attraction/romance</li><li>You won\u2019t always know if someone is uncomfortable, or is feeling pressure in some direction</li></ul></li><li>2022:<ul><li>Attend significantly to implicit power dynamics even for things that aren\u2019t romantic</li><li>Avoid communicating while triggered</li><li>Consider not being open to polyamory (NB I\u2019ve been in a relationship with my wife for 17 years, which has in practice been monogamous, but for the last few years we\u2019ve been open to the possibility of polyamory)</li><li>Shame is a big problem for me<ul><li>Talk to a therapist to sort it out (this plan actually got interrupted by the FTX crisis)</li><li>Don\u2019t express feelings of attraction towards anyone (except my wife) until I\u2019ve sorted this out</li></ul></li></ul></li></ul><p><strong>What\u2019s the right thing to do now?</strong> First,&nbsp;<strong>I want to ensure never to repeat these mistakes</strong>. I won\u2019t know what my final personal policy updates are for a while longer \u2014 some of them might be quite subtle, and I\u2019ll continue to work on these with a therapist, but in the interim I\u2019m planning to hold off on:</p><ul><li>Expressing feelings of attraction to anyone<ul><li>(this is a continuation of the 2022 policy update; it\u2019s because I want to sort out what\u2019s up with my dubious track record on this, not because I think that nobody should ever express attraction)</li></ul></li><li>Being open to polyamory</li></ul><p>I don\u2019t know whether I\u2019ll be open to these again in the future. In any case the timeframe on which I might pick these back up will be decided in consultation with my therapist.&nbsp;</p><p>Second, I think it\u2019s helpful if the community is able to process this with my visibly not being in any positions of power. Therefore&nbsp;<strong>I have resigned from the EV UK board, my most substantive position in the community</strong>,<strong>&nbsp;</strong>and am consequently no longer in an oversight role for any of its projects. (Although I\u2019m still listed on the FHI website, I actually left FHI over a year ago.) Note that I'm not saying \"I deserve to lose my positions of authority\" \u2014 in this case that would ultimately be a decision for the rest of the board. Rather, I think it's best if right now I give them and others as much space as I can to consider the most appropriate actions.&nbsp;</p><p>For right now, I am also pausing other activities which may give me power:</p><ul><li>Starting any new mentor relationships;</li><li>Recommending funding for anything or connecting people with funders;&nbsp;</li><li>Organizing events (in the immediate, I\u2019ve stepped back from any decision-making for the Summit on Existential Security).</li></ul><p>Again I\u2019ll make decisions about when to resume these in consultation with my therapist.&nbsp;</p><p>(I don\u2019t think I have a way of fully giving up soft power without committing not to be a part of the community in the future, something which doesn\u2019t feel like the right move to me. Instead I will just share that I love it when people do the things that seem to them to be good and true, even when I disagree, or where the consequences might be bad for me personally.)</p><p>Third, I think it\u2019s important to&nbsp;<strong>ask how the culture or structures we have could be different in ways that would reduce the risk of such harms</strong>. I know that this is also important to the person whose story appears in Time, who said in a recent email to me \"I deliberately did not name you as I want to draw attention to [systemic issues]. We should expect individuals to make misjudgements over time.\".&nbsp;<strong>I don\u2019t want to shirk responsibility here \u2014 I absolutely think that I could and should have made better judgements</strong>. But I also think that holding my flaws at a fixed level, I might not have made these errors in a different culture, and it\u2019s generally good to look for multiple different levels on which things could have been fixed. I don\u2019t think I should be the arbiter of what should be implemented here, but I think it\u2019s possible I have access to helpful inside-view data, so I plan to continue reflecting on this. Topics that I especially want to think about:&nbsp;</p><ul><li>When is radical openness good, and what are the bounds on that?</li><li>When is oversight important, and what types would meaningfully help?</li><li>What tools could help people better track soft power, and its impacts?</li><li>Are there mechanisms that could help to empower the voices of the disempowered?</li></ul><p>I then plan to feed thoughts to the community, CEA\u2019s Community Health team, or other parties as appropriate.</p><p>I\u2019ll leave things there for now. I\u2019m very happy to hear thoughts of other things I should be doing. (Though some of the conversations around this I won\u2019t want to have in public, in order to protect people\u2019s privacy.) But in closing let me say again: I\u2019m so, so sorry to anyone whom I\u2019ve ever made uncomfortable, and I\u2019m so sorry to the broader community for having contributed to these dynamics.</p>", "user": {"username": "Owen_Cotton-Barratt"}}, {"_id": "i6btyefRRX23yCpnP", "title": "What AI companies can do today to help with the most important century", "postedAt": "2023-02-20T17:40:32.276Z", "htmlBody": "<p>\nI\u2019ve been writing about tangible things we can do today to help the <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/\">most important century</a> go well. Previously, I wrote about <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/CcJsh4JcxEqYDaSte\">helpful messages to spread</a> and <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/njD2PurEKDEZcMLKZ/\">how to help via full-time work</a>.\n</p>\n<p>\nThis piece is about what major AI companies can do (and not do) to be helpful. By \u201cmajor AI companies,\u201d I mean the sorts of AI companies that are advancing the state of the art, and/or could play a major role in how very powerful AI systems end up getting used.<sup id=\"fnref1\"><a href=\"#fn1\" rel=\"footnote\">1</a></sup>\n</p>\n<p>\nThis piece could be useful to people who work at those companies, or people who are just curious.\n</p>\n<p>\nGenerally, these are not pie-in-the-sky suggestions - I can name<sup id=\"fnref2\"><a href=\"#fn2\" rel=\"footnote\">2</a></sup> more than one AI company that has at least made a serious effort at each of the things I discuss below<strong> </strong>(beyond what it would do if everyone at the company were singularly focused on making a profit).<sup id=\"fnref3\"><a href=\"#fn3\" rel=\"footnote\">3</a></sup>\n</p>\n<p>\nI\u2019ll cover:\n</p>\n<ul>\n\n<li>Prioritizing alignment research, strong security, and safety standards (all of which I\u2019ve written about <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/yjm5CW9JdwBTFZB2B#We_can_do_better\">previously</a>).\n\n</li><li>Avoiding hype and acceleration, which I think could leave us with less time to prepare for key risks.\n\n</li><li>Preparing for difficult decisions ahead: setting up governance, employee expectations, investor expectations, etc. so that the company is capable of doing non-profit-maximizing things to help avoid catastrophe in the future.\n\n</li><li>Balancing these cautionary measures with conventional/financial success.\n\n</li><li>I\u2019ll also list a few things that some AI companies present as important, but which I\u2019m less excited about: censorship of AI models, open-sourcing AI models, raising awareness of AI with governments and the public. I don\u2019t think all these things are necessarily <em>bad</em>, but I think some are, and I\u2019m skeptical that any are crucial for the <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/\">risks I\u2019ve focused on</a>.\n</li>\n</ul>\n<p>\nI previously laid out a summary of how I see the major risks of advanced AI, and four key things I think can help (<span style=\"color:var(--green-color);\"><strong>alignment research</strong></span>;<strong> </strong><span style=\"color:var(--red-color);\"><strong>strong security</strong></span>; <span style=\"color:var(--orange-color);\"><strong>standards and monitoring</strong></span>; <span style=\"color:var(--purple-color);\"><strong>successful, careful AI projects</strong></span>). I won\u2019t repeat that summary now, but it might be helpful for orienting you if you don\u2019t remember the rest of this series too well; click <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/njD2PurEKDEZcMLKZ#Recapping_the_major_risks__and_some_things_that_could_help\">here</a> to read it.\n</p>\n<h2 id=\"basics\">Some basics: alignment research, strong security, safety standards</h2>\n\n\n<p>\nFirst off, AI companies can contribute to the \u201cthings that can help\u201d I listed above:\n</p>\n<ul>\n\n<li>They can prioritize <span style=\"color:var(--green-color);\"><strong>alignment research</strong></span><strong> </strong>(and <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/njD2PurEKDEZcMLKZ#Low_guidance_jobs\">other technical research</a>, e.g. threat assessment research and misuse research).  \n<ul>\n \n<li>For example, they can prioritize hiring for safety teams, empowering these teams, encouraging their best flexible researchers to work on safety, aiming for high-quality research that targets <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/NbiHKTN5QhFFfjjm5/\">crucial challenges</a>, etc.\n \n</li><li>It could also be important for AI companies to find ways to <strong>partner with outside safety researchers rather than rely solely on their own teams.</strong> As discussed <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/njD2PurEKDEZcMLKZ#Low_guidance_jobs\">previously</a>, this could be challenging. But I generally expect that AI companies that care a lot about safety research partnerships will find ways to make them work.\n</li> \n</ul>\n    </li><li>They can help work toward a <span style=\"color:var(--orange-color);\"><strong>standards and monitoring</strong></span><strong> </strong>regime. E.g., they can do their own work to come up with standards like \"An AI system is dangerous if we observe that it's able to ___, and if we observe this we will take safety and security measures such as ____.\" They can also consult with others developing safety standards, voluntarily self-regulate beyond what\u2019s required by law, etc.\n</li>\n\n\n<li>They can prioritize <span style=\"color:var(--red-color);\"><strong>strong security</strong></span>, beyond what normal commercial incentives would call for.  \n<ul>\n \n<li>It could easily take years to build secure enough systems, processes and technologies for very high-stakes AI.\n \n</li><li>It could be important to hire not only people to handle everyday security needs, but people to experiment with more exotic setups that could be needed later, as the incentives to steal AI get stronger.\n</li> \n</ul>\n\n</li></ul>\n<p>\n</p><details id=\"Box1\"><summary>(Click to expand) The challenge of securing dangerous AI</summary><p></p>\n\n<p>In <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/XRphCh6NbfQiDF3Nt>Racing Through a Minefield</a>, I described a \" race\"=\"\" between=\"\" cautious=\"\" actors=\"\" (those=\"\" who=\"\" take=\"\" <a=\"\">misalignment risk</a> seriously) and incautious actors (those who are focused on deploying AI for their own gain, and aren't thinking much about the dangers to the whole world). Ideally, cautious actors would collectively have more powerful AI systems than incautious actors, so they could take their time doing <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/rJRw78oihoT5paFGd\">alignment research</a> and <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/XRphCh6NbfQiDF3Nt#Defensive_deployment__staying_ahead_in_the_race_\">other things</a> to try to make the situation safer for everyone. </p>\n\n<p>But if incautious actors can steal an AI from cautious actors and rush forward to deploy it for their own gain, then the situation looks a lot bleaker. And unfortunately, it could be hard to protect against this outcome.</p>\n\n<p>It's generally <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH#fn15\">extremely difficult</a> to protect data and code against a well-resourced cyberwarfare/espionage effort. An AI\u2019s \u201cweights\u201d (you can think of this sort of like its source code, though <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/XRphCh6NbfQiDF3Nt#fn4\">not exactly</a>) are potentially very dangerous on their own, and hard to get extreme security for. Achieving enough cybersecurity could require measures, and preparations, well beyond what one would normally aim for in a commercial context.</p>\n</details>\n\n<p>\n</p><details id=\"Box2\"><summary>(Click to expand) How standards might be established and become national or international</summary><p></p>\n\n<p>\nI <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/XRphCh6NbfQiDF3Nt#Global_monitoring__noticing_people_about_to_step_on_mines__and_stopping_them_\">previously</a> laid out a possible vision on this front, which I\u2019ll give a slightly modified version of here:\n</p>\n<ul>\n\n<li>Today\u2019s leading AI companies could self-regulate by committing not to build or deploy a system that they can\u2019t convincingly demonstrate is safe (e.g., see Google\u2019s <a href=\"https://www.theweek.in/news/sci-tech/2018/06/08/google-wont-deploy-ai-to-build-military-weapons-ichai.html\">2018 statement</a>, \"We will not design or deploy AI in weapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people\u201d).  \n<ul>\n \n<li>Even if some people at the companies would like to deploy unsafe systems, it could be hard to pull this off once the company has committed not to. \n \n</li><li>Even if there\u2019s a lot of room for judgment in what it means to demonstrate an AI system is safe, having agreed in advance that <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/NbiHKTN5QhFFfjjm5/\">certain evidence</a> is <em>not</em> good enough could go a long way.\n</li> \n</ul>\n\n</li><li>As more AI companies are started, they could feel soft pressure to do similar self-regulation, and refusing to do so is off-putting to potential employees, investors, etc.\n\n</li><li>Eventually, similar principles could be incorporated into various government regulations and enforceable treaties.\n\n</li><li>Governments could monitor for dangerous projects using regulation and even overseas operations. E.g., today the US monitors (without permission) for various signs that other states might be developing nuclear weapons, and might try to stop such development with methods ranging from threats of sanctions to <a href=\"https://en.wikipedia.org/wiki/Stuxnet\">cyberwarfare</a> or even military attacks. It could do something similar for any AI development projects that are using huge amounts of compute and haven\u2019t volunteered information about whether they\u2019re meeting standards.\n</li>\n</ul>\n</details>\n\n<h2 id=\"avoiding-hype\">Avoiding hype and acceleration </h2>\n\n\n<p>\nIt seems good for AI companies to <strong>avoid</strong> <strong>unnecessary hype and acceleration of AI. </strong>\n</p>\n<p>\nI\u2019ve argued that <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/CcJsh4JcxEqYDaSte#We_re_not_ready_for_this\">we\u2019re not ready</a> for transformative AI, and I generally tend to think that we\u2019d all be better off if the world took <em>longer</em> to develop transformative AI. That\u2019s because:\n</p>\n<p>\n \n</p>\n<ul>\n\n<li>I\u2019m hoping general awareness and understanding of the key risks will rise over time.\n\n</li><li>A lot of key things that could improve the situation - e.g., <span style=\"color:var(--green-color);\"><strong>alignment research</strong></span>, <span style=\"color:var(--orange-color);\"><strong>standards and monitoring</strong></span>, and <span style=\"color:var(--red-color);\"><strong>strong security</strong></span><strong> </strong>- seem to be in very early stages right now.\n\n</li><li>If too much money pours into the AI world too fast, I\u2019m worried there will be lots of <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/XRphCh6NbfQiDF3Nt#The_basic_premises_of__racing_through_a_minefield_\">incautious</a> companies racing to build transformative AI as quickly as they can, with little regard for the key risks.\n</li>\n</ul>\n<p>\nBy default, I generally think: \u201cThe fewer flashy demos and breakthrough papers a lab is putting out, the better.\u201d This can involve tricky tradeoffs in practice (since AI companies generally want to be successful at recruiting, fundraising, etc.)\n</p><p>\n    A couple of potential counterarguments, and replies:</p>\n\n<p>First, some people think it's now \"too late\" to avoid hype and acceleration, given the amount of hype and investment AI is getting at the moment. I disagree. It's easy to forget, in the middle of a media cycle, how quickly people can forget about things and move onto the next story once the bombs stop dropping. And there are plenty of bombs that still haven't dropped (many things AIs still can't do), and the level of investment in AI has tons of room to go up from here.</p>\n<p>Second, I\u2019ve sometimes seen arguments that hype is <em>good</em> because it helps society at large understand what\u2019s coming. But unfortunately, as I wrote <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/CcJsh4JcxEqYDaSte#Challenges_of_AI_related_messages\">previously</a>, I'm worried that hype gives people a skewed picture.</p><ul>\n    <li>Some <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/vGsRdWzwjrFgCXdMn\">key risks</a> are hard to understand and take seriously.\n        </li><li>What's easy to understand is something like \"AI is powerful and scary, I should make sure that people like me are the ones to build it!\"\n            </li><li>Maybe <a href=\"https://twitter.com/sethlazar/status/1626257535178280960\">recent developments</a> will make people understand the risks better? One can hope, but I'm not counting on that just yet - I think AI misbehavior can be <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/yjm5CW9JdwBTFZB2B#How_we_could_stumble_into_catastrophe_from_misaligned_AI\">given illusory \"fixes,\"</a> and probably will be.</li></ul>\n\n<p>I also am generally skeptical that there's much hope of society adapting to risks as they happen, given the <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/\">explosive pace of change</a> that I expect once we get powerful enough AI systems.</p>\n\n<p>I discuss some more arguments on this point in a footnote.<sup id=\"fnref4\"><a href=\"#fn4\" rel=\"footnote\">4</a></sup></p>\n\n    <p>\nI don\u2019t think it\u2019s clear-cut that hype and acceleration are bad, but it\u2019s my best guess.\n</p>\n<h2 id=\"preparing-for-difficult-decisions\">Preparing for difficult decisions ahead</h2>\n\n\n<p>\nI\u2019ve <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/XRphCh6NbfQiDF3Nt\">argued</a> that AI companies might need to do \u201cout-of-the-ordinary\u201d things that don\u2019t go with normal commercial incentives. \n</p>\n<p>\nToday, AI companies can be building a foundation for being able to do \u201cout-of-the-ordinary\u201d things in the future. A few examples of how they might do so:\n</p>\n<p>\n<strong>Public-benefit-oriented governance. </strong>I think typical governance structures could be a problem in the future. For example, a standard corporation could be sued for <em>not</em> deploying AI that poses a risk of <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">global catastrophe</a> - if this means a sacrifice for its bottom line.\n</p>\n<p>\nI\u2019m excited about AI companies that are investing heavily in setting up governance structures - and investing in executives and board members - capable of making the hard calls well. For example:\n</p>\n<ul>\n\n<li>By default, if an AI company is a standard corporation, its leadership has legally recognized <a href=\"https://en.wikipedia.org/wiki/Fiduciary\">duties</a> to serve the interests of shareholders - not society at large. But an AI company can incorporate as a <a href=\"https://www.delawareinc.com/public-benefit-corporation/\">Public Benefit Corporation</a> or some other kind of entity (including a nonprofit!) that gives more flexibility here.\n\n</li><li>By default, shareholders make the final call over what a company does. (Shareholders can replace members of the Board of Directors, who in turn can replace the CEO). But a company can set things up differently (e.g., a <a href=\"https://openai.com/blog/openai-lp/\">for-profit controlled by a nonprofit</a><sup id=\"fnref5\"><a href=\"#fn5\" rel=\"footnote\">5</a></sup>).</li></ul>\n<p>\nIt could pay off in lots of ways to make sure the final calls at a company are made by people focused on getting a good outcome for humanity (and legally free to focus this way).\n</p>\n<p>\n<strong>Gaming out the future. </strong>I think it\u2019s not too early for AI companies to be discussing how they would handle various <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/XRphCh6NbfQiDF3Nt\">high-stakes situations</a>.\n</p>\n<ul>\n\n<li>Under what circumstances would the company simply decide to stop training increasingly powerful AI models? \n\n</li><li>If the company came to believe it was building very powerful, dangerous models, whom would it notify and seek advice from? At what point would it approach the government, and how would it do so?\n\n</li><li>At what point would it be worth using extremely costly security measures?\n\n</li><li>If the company had AI systems available that could do most of what humans can do, what would it <em>do</em> with these systems? Use them to do AI safety research? Use them to design better algorithms and continue making increasingly powerful AI systems? (More possibilities <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/XRphCh6NbfQiDF3Nt#Defensive_deployment__staying_ahead_in_the_race_\">here</a>.)\n\n</li><li>Who should be leading the way on decisions like these? Companies tend to employ experts to inform their decisions; who would the company look to for expertise on these kinds of decisions?\n</li>\n</ul>\n<p>\n<strong>Establishing and getting practice with processes for particularly hard decisions. </strong>Should the company publish its latest research breakthrough? Should it put out a product that might lead to more <a href=\"https://forum.effectivealtruism.org/posts/i6btyefRRX23yCpnP/what-ai-companies-can-do-today-to-help-with-the-most#Avoiding_hype_and_acceleration_\">hype and acceleration</a>? What safety researchers should <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/njD2PurEKDEZcMLKZ#SafetyCollaborations\">get access to its models</a>, and how much access? \n</p>\n<p>\nAI companies face questions like this pretty regularly today, and I think it\u2019s worth putting processes in place to consider the implications for the world as a whole (not just for the company\u2019s bottom line). This could include assembling advisory boards, internal task forces, etc.\n</p>\n<p>\n<strong>Managing employee and investor expectations. </strong>At some point, an AI company might want to make \u201cout of the ordinary\u201d moves that are good for the world but bad for the bottom line. E.g., choosing not to deploy AIs that could be very dangerous or very profitable.\n</p>\n<p>\nI wouldn\u2019t want to be trying to run a company in this situation with lots of angry employees and investors asking about the value of their equity shares! It\u2019s also important to minimize the risk of employees and/or investors leaking sensitive and potentially <a href=\"https://forum.effectivealtruism.org/posts/i6btyefRRX23yCpnP/what-ai-companies-can-do-today-to-help-with-the-most#Box1\">dangerous</a> information.\n</p>\n<p>\nAI companies can prepare for this kind of situation by doing things like:\n</p>\n<ul>\n\n<li>Being selective about whom they hire and take investment from, and screening specifically for people they think are likely to be on board with these sorts of hard calls.\n\n</li><li>Education and communications - making it clear to employees what kinds of dangerous-to-humanity situations might be coming up in the future, and what kinds of actions the company might want to take (and why).\n</li>\n</ul>\n<p>\n<strong>Internal and external commitments. </strong>AI companies can make public and/or internal statements about how they would handle various tough situations, e.g. how they would determine when it\u2019s too dangerous to keep building more powerful models. \n</p>\n<p>\nI think these commitments should generally be non-binding (it\u2019s hard to predict the future in enough detail to make binding ones). But in a future where maximizing profit conflicts with doing the right thing for humanity, a previously-made commitment could make it more likely that the company does the right thing.\n</p>\n<h2 id=\"succeeding\">Succeeding</h2>\n\n\n<p>\nI\u2019ve emphasized how helpful a <span style=\"color:var(--purple-color);\"><strong>successful, careful AI projects</strong></span><strong> </strong>could be. So far, this piece has mostly talked about the \u201ccareful\u201d side of things - how to do things that a \u201cnormal\u201d AI company (focused only on commercial success) wouldn\u2019t, in order to reduce risks. But it\u2019s also important to succeed at fundraising, recruiting, and generally staying relevant (e.g., capable of building cutting-edge AI systems). \n</p>\n<p>\nI don\u2019t emphasize this or write about it as much because I think it\u2019s the sort of thing AI companies are likely to be focused on by default, and because I don\u2019t have special insight into how to succeed as an AI company. But it\u2019s important, and it means that AI companies need to walk a sort of tightrope - constantly making tradeoffs between success and caution.\n</p>\n<h2 id=\"some-things-im-less-excited-about\">Some things I\u2019m less excited about</h2>\n\n\n<p>\nI think it\u2019s also worth listing a few things that some AI companies present as important societal-benefit measures, but which I\u2019m a bit more skeptical are crucial for reducing the risks I\u2019ve <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/\">focused on</a>.\n</p>\n<ul>\n\n<li>Some AI companies restrict access to their models so people won\u2019t use the AIs to create pornography, misleading images and text, etc. I\u2019m not necessarily against this and support versions of it (it depends on the details), but I mostly don\u2019t think it is a key way to reduce the risks I\u2019ve focused on. For those risks, the hype that comes from seeing a demonstration of a system\u2019s capabilities could be even <a href=\"https://forum.effectivealtruism.org/posts/i6btyefRRX23yCpnP/what-ai-companies-can-do-today-to-help-with-the-most#Avoiding_hype_and_acceleration_\">more dangerous</a> than direct harms.\n\n</li><li>I sometimes see people implying that open-sourcing AI models - and otherwise making them as broadly available as possible - is a key social-benefit measure. While there may be benefits in some cases, I mostly see this kind of thing as being negative (or at best neutral) in terms of the <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/\">risks I\u2019m most concerned about</a>.  \n<ul>\n \n<li>I think it can contribute to <a href=\"https://forum.effectivealtruism.org/posts/i6btyefRRX23yCpnP/what-ai-companies-can-do-today-to-help-with-the-most#Avoiding_hype_and_acceleration_\">hype and acceleration</a>, and could make it generally harder to enforce safety standards. \n \n</li><li>In the long run, I worry that AI systems could become extraordinarily powerful (more so than e.g. nuclear weapons), so I don\u2019t think \u201cMake sure everyone has access asap\u201d is the right framework. \n \n</li><li>In addition to increasing dangers from misaligned AI, this framework could increase other dangers I\u2019ve <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/yjm5CW9JdwBTFZB2B#Potential_catastrophes_from_aligned_AI\">written about previously</a>.\n</li> \n</ul>\n\n</li><li>I generally don\u2019t think AI companies should be trying to get governments to pay more attention to AI, for reasons I\u2019ll get to in a future piece. (Forming relationships with policymakers could be good, though.)\n\n</li></ul>\n<p>\nWhen an AI company presents some decision as being for the benefit of humanity, I often ask myself, \u201cCould this same decision be justified by just wanting to commercialize successfully?\u201d\n</p>\n<p>\nFor example, making AI models \u201csafe\u201d in the sense that they <em>usually behave as users intend </em>(including things like refraining from toxic language, chaotic behavior, etc.) can be important for commercial viability, but <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/vGsRdWzwjrFgCXdMn#Why_we_might_not_get_clear_warning_signs_of_the_risk\">isn\u2019t necessarily good enough for the risks I worry about</a>.\n</p>\n\n<h2 id=\"footnotes\">Footnotes</h2>\n<div class=\"footnotes\">\n<hr>\n<ol><li id=\"fn1\">\n<p>\n     Disclosure: my wife works at one such company (<a href=\"https://anthropic.com/\">Anthropic</a>) and used to work at another (<a href=\"https://openai.com/\">OpenAI</a>), and has equity in both.&nbsp;<a href=\"#fnref1\" rev=\"footnote\">\u21a9</a></p></li><li id=\"fn2\">\n<p>\n     Though I won\u2019t, because I decided I don\u2019t want to get into a thing about whom I did and didn\u2019t link to. Feel free to give real-world examples in the comments!&nbsp;<a href=\"#fnref2\" rev=\"footnote\">\u21a9</a></p></li><li id=\"fn3\">\n<p>\n     Now, AI companies could sometimes be doing \u201cresponsible\u201d or \u201csafety-oriented\u201d things in order to get good PRs, recruit employees, make existing employees happy, etc. In this sense, the actions could be <em>ultimately</em> profit-motivated. But that would still mean there are <em>enough people who care about reducing AI risk that actions like these have PR benefits, recruiting benefits, etc. </em>That\u2019s a big deal! And it suggests that if concern about AI risks (and understanding of how to reduce them) were more widespread, AI companies might do more good things and fewer dangerous things.&nbsp;<a href=\"#fnref3\" rev=\"footnote\">\u21a9</a></p></li><li id=\"fn4\">\n<p>\n     You could argue that it would be better for the world to develop extremely powerful AI systems <em>sooner</em>, for reasons including:\n</p><ul>\n\n<li>You might be pretty happy with the global balance of power between countries today, and be worried that it\u2019ll get worse in the future. The latter could lead to a situation where the \u201cwrong\u201d government <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/mPkFheB4EM6pmEC7y#Power_imbalances\">leads the way on transformative AI</a>.\n\n</li><li>You might think that the later we develop transformative AI, the more quickly everything will play out, because there will be more computing resources available in the world. E.g., if we develop extremely powerful systems tomorrow, there would only be so many copies we could run at once, whereas if we develop equally powerful systems in 50 years, it might be a lot easier for lots of people to run lots of copies. (More: <a href=\"https://aiimpacts.org/hardware-overhang/\">Hardware Overhang</a>)</li></ul>\n\n<p>\n    A key reason I believe it\u2019s best to avoid acceleration at this time is because it seems plausible (at least 10% likely) that transformative AI will be developed <em>extremely</em> soon - as in within 10 years of today. My  impression is that many people at major AI companies tend to agree with this. I think this is a very scary possibility, and if this is the case, the arguments I give in the main text seem particularly important (e.g., many key interventions seem to be in a pretty embryonic state, and awareness of key risks seems low).\n</p><p>\n    A related case one could make for acceleration is \u201cIt\u2019s worth accelerating things on the whole to increase the probability that the particular company in question succeeds\u201d (more here: the <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/Lbtcjfxhrs8kfKK2M#The__competition__frame\">\u201ccompetition\u201d frame</a>). I think this is a valid consideration, which is why I talk about tricky tradeoffs in the main text.&nbsp;<a href=\"#fnref4\" rev=\"footnote\">\u21a9</a></p></li><li id=\"fn5\">\n\n<p>\n     Note that my wife is a former employee of OpenAI, the company I link to there, and she owns equity in the company.&nbsp;<a href=\"#fnref5\" rev=\"footnote\">\u21a9</a></p></li></ol></div>", "user": {"username": "HoldenKarnofsky"}}, {"_id": "Y7croZavYcv88Z7WK", "title": "[MLSN #8]: Mechanistic interpretability, using law to inform AI alignment, scaling laws for proxy gaming", "postedAt": "2023-02-20T16:06:02.693Z", "htmlBody": "<p>As part of a larger community building effort, <a href=\"https://safe.ai/\">CAIS </a>is writing a safety newsletter that is designed to cover empirical safety research and be palatable to the broader machine learning research community. You can <a href=\"https://newsletter.mlsafety.org/\">subscribe here</a> or follow the newsletter on <a href=\"https://twitter.com/ml_safety\">twitter</a> here.</p><hr><p>Welcome to the 8th issue of the ML Safety Newsletter! In this edition, we cover:</p><ul><li>Isolating the specific mechanism that GPT-2 uses to identify the indirect object in a sentence</li><li>When maximum softmax probability is optimal</li><li>How law can inform specification for AI systems</li><li>Using language models to find a group consensus</li><li>Scaling laws for proxy gaming</li><li>An adversarial attack on adaptive models</li><li>How systems safety can be applied to ML</li><li>And much more...</li></ul><hr><h1><strong>Monitoring</strong></h1><h3><strong>A Circuit for Indirect Object Identification in GPT-2 small</strong></h3><p>&nbsp;</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82973a3a-77de-41b8-80e4-f5ed94a738f0_1600x710.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82973a3a-77de-41b8-80e4-f5ed94a738f0_1600x710.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82973a3a-77de-41b8-80e4-f5ed94a738f0_1600x710.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82973a3a-77de-41b8-80e4-f5ed94a738f0_1600x710.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82973a3a-77de-41b8-80e4-f5ed94a738f0_1600x710.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82973a3a-77de-41b8-80e4-f5ed94a738f0_1600x710.png 1456w\"></a></p><p>One subset of interpretability is <i>mechanistic interpretability</i>: understanding how models perform functions down to the level of particular parameters. Those working on this agenda believe that by learning how small parts of a network function, they may eventually be able to rigorously understand how the network implements high-level computations.</p><p>This paper tries to identify how GPT-2 small solves <i>indirect object identification, </i>the task of identifying the correct indirect object to complete a sentence with. Using a number of interpretability techniques, the authors seek to isolate particular parts of the network that are responsible for this behavior.</p><p><strong>[</strong><a href=\"https://arxiv.org/abs/2211.00593\"><strong><u>Link</u></strong></a><strong>]</strong>&nbsp;</p><h3><strong>Learning to Reject Meets OOD Detection</strong></h3><p>Both learning to reject (also called error detection; deciding whether a sample is likely to be misclassified) and out-of-distribution detection share the same baseline: maximum softmax probability. MSP has been outperformed by other methods in OOD detection, but never in learning to reject, and it is mathematically provable that it is optimal for learning to reject. This paper shows that it isn\u2019t optimal for OOD detection, and identifies specific circumstances in which it can be outperformed. This theoretical result is a good confirmation of the existing empirical results.</p><p><strong>[</strong><a href=\"https://arxiv.org/abs/2301.12386\"><strong><u>Link</u></strong></a><strong>]</strong>&nbsp;</p><h3><strong>Other Monitoring News</strong></h3><p><strong>[</strong><a href=\"https://arxiv.org/abs/2212.06727\"><strong><u>Link</u></strong></a><strong>]</strong> The first paper that successfully applies feature visualization techniques to Vision Transformers.</p><p><strong>[</strong><a href=\"https://arxiv.org/abs/2211.07740\"><strong><u>Link</u></strong></a><strong>]</strong> This method uses the reconstruction loss of diffusion models to create a new SOTA method for out-of-distribution detection in images.</p><p><strong>[</strong><a href=\"https://arxiv.org/abs/2301.02344\"><strong><u>Link</u></strong></a><strong>]</strong> A new Trojan attack on code generation models works by inserting poisoned code into docstrings rather than the code itself, evading some vulnerability-removal techniques.</p><p><strong>[</strong><a href=\"https://arxiv.org/abs/2302.06600\"><strong><u>Link</u></strong></a><strong>]</strong> This paper shows that fine tuning language models for particular tasks relies on changing only a very small subset of parameters. The authors show that as few as 0.01% of parameters can be \u201cgrafted\u201d onto the original network and achieve performance that is nearly as high.</p><hr><h1><strong>Alignment</strong></h1><h3><strong>Applying Law to AI Alignment</strong></h3><p>One problem in alignment is specification: though we may give AI systems instructions, we cannot possibly specify what they should do in all circumstances. Thus, we have to consider how our specifications will generalize in fuzzy, or out-of-distribution contexts.</p><p>The author of this paper argues that law has many desirable properties that may make it useful in informing specification. For example, the law often uses \u201cstandards\u201d: relatively vague instructions (e.g. \u201cact with reasonable caution at railroad crossings\u201d; in contrast to rules like \u201cdo not exceed 30 miles per hour\u201d) whose specifics have been developed through years of precedent. In the law, it is often necessary to consider the \u201cspirit\u201d behind these standards, which is exactly what we want AI systems to be able to do. This paper argues that AI systems could be construed under the fiduciary standard.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F742897ba-fbe3-447d-9c14-514d79064075_1600x1077.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F742897ba-fbe3-447d-9c14-514d79064075_1600x1077.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F742897ba-fbe3-447d-9c14-514d79064075_1600x1077.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F742897ba-fbe3-447d-9c14-514d79064075_1600x1077.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F742897ba-fbe3-447d-9c14-514d79064075_1600x1077.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F742897ba-fbe3-447d-9c14-514d79064075_1600x1077.png 1456w\"></a></p><p>&nbsp;</p><p>Finally, the paper conducts an empirical study on thousands of US court opinions. It finds that while the baseline GPT-3 model is unable to accurately predict court evaluations of fiduciary duty, more recent models in the GPT-3.5 series can do so with relatively high accuracy. Though legal standards will not resolve many of the most significant problems of alignment, they could improve upon current strategies of specification.</p><p><strong>[</strong><a href=\"https://arxiv.org/abs/2301.10095\"><strong><u>Link</u></strong></a><strong>]</strong></p><h3><strong>Language models can generate consensus statements for diverse groups</strong></h3><p>&nbsp;</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc30e64ac-ef6f-4a73-a463-535987b9fab8_1600x775.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc30e64ac-ef6f-4a73-a463-535987b9fab8_1600x775.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc30e64ac-ef6f-4a73-a463-535987b9fab8_1600x775.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc30e64ac-ef6f-4a73-a463-535987b9fab8_1600x775.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc30e64ac-ef6f-4a73-a463-535987b9fab8_1600x775.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc30e64ac-ef6f-4a73-a463-535987b9fab8_1600x775.png 1456w\"></a></p><p>&nbsp;</p><p>We may want to take into account the interests not only of individuals but also of possibly-conflicting members of a larger group. This paper asked individuals for their opinions on political issues (e.g., \u201cshould speed limits be reduced?\u201d) and used a language model to generate consensus statements that would be agreed on by the group at large. The participants rated AI-generated consensus statements highly, above even human-written statements. The authors don\u2019t appear to discuss whether this could simply be due to the consensus statements being more watered down and thus less action-relevant. Still, the paper is a promising step towards aligning models with groups of humans.</p><p><strong>[</strong><a href=\"https://arxiv.org/abs/2211.15006\"><strong><u>Link</u></strong></a><strong>]</strong></p><hr><h1><strong>Robustness</strong></h1><h3><strong>Scaling laws for reward overoptimization</strong></h3><p>Reinforcement learning techniques, such as those used to improve the general capabilities of language models, often optimize a model to give outputs that are rated highly by a proxy for some \u201cgold standard.\u201d For example, a proxy might be trained to predict how particular humans would react to an output. A difficulty, also mentioned earlier in the newsletter, is proxy gaming, where the model improves performance according to the proxy while failing to do so on the underlying gold standard (e.g., what humans would actually think).</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b16d7f9-ace2-474e-b083-adc47f71b0da_1600x1105.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b16d7f9-ace2-474e-b083-adc47f71b0da_1600x1105.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b16d7f9-ace2-474e-b083-adc47f71b0da_1600x1105.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b16d7f9-ace2-474e-b083-adc47f71b0da_1600x1105.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b16d7f9-ace2-474e-b083-adc47f71b0da_1600x1105.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b16d7f9-ace2-474e-b083-adc47f71b0da_1600x1105.png 1456w\"></a></p><p>This paper empirically studies how language models trained with reinforcement learning can over optimize proxy reward, and develops scaling laws describing this phenomenon. To do this, they use a (proxy) model as the gold standard, and build a set of proxy models that approximate that gold standard model. In addition to measuring models optimized with reinforcement learning, they find that over optimization can also happen with best-of-n sampling.</p><p><strong>[</strong><a href=\"https://arxiv.org/abs/2210.10760\"><strong><u>Link</u></strong></a><strong>]</strong></p><h3><strong>Adaptive models can be exploited by adversaries</strong></h3><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf65a777-1521-4afe-9a05-21c7419b4e67_1600x551.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf65a777-1521-4afe-9a05-21c7419b4e67_1600x551.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf65a777-1521-4afe-9a05-21c7419b4e67_1600x551.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf65a777-1521-4afe-9a05-21c7419b4e67_1600x551.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf65a777-1521-4afe-9a05-21c7419b4e67_1600x551.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf65a777-1521-4afe-9a05-21c7419b4e67_1600x551.png 1456w\"></a></p><p>Many deep learning models aren\u2019t robust to distribution shifts. One potential solution to this is test-time adaptation (TTA), where a model is modified based on the test data it sees. This paper demonstrates that TTA is subject to adversarial attacks, where malicious test data can cause predictions about clean data to be incorrect. This means that adaptive models have yet another attack surface that can potentially be exploited. The authors develop several kinds of attacks: targeted (degrade accuracy of a particular sample), indiscriminate (degrade accuracy in general), and \u201cstealthy targeted\u201d (degrade accuracy of a particular sample while not otherwise reducing accuracy). The attacks are conducted with projected gradient descent, and tested with the ImageNet-C dataset as the OOD dataset. The authors also find that models designed to be adversarially robust are also more robust to this attack.</p><p><strong>[</strong><a href=\"https://arxiv.org/abs/2301.12576\"><strong><u>Link</u></strong></a><strong>]</strong></p><h3><strong>Other Robustness News</strong></h3><p><strong>[</strong><a href=\"https://arxiv.org/abs/2302.04638\"><strong><u>Link</u></strong></a><strong>]</strong> Better diffusion models can improve adversarial training when used to generate data.</p><p><strong>[</strong><a href=\"https://arxiv.org/abs/2301.06294\"><strong><u>Link</u></strong></a><strong>]</strong> Proposes a method for adapting RL policies to environments with random shocks, augmenting training with simulations of the post-shock environment.</p><h1><strong>Systemic Safety</strong></h1><h3><strong>Applying Systems Safety to ML</strong></h3><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d5e6fbf-3446-41ba-b92f-45b526664a24_1600x287.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d5e6fbf-3446-41ba-b92f-45b526664a24_1600x287.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d5e6fbf-3446-41ba-b92f-45b526664a24_1600x287.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d5e6fbf-3446-41ba-b92f-45b526664a24_1600x287.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d5e6fbf-3446-41ba-b92f-45b526664a24_1600x287.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d5e6fbf-3446-41ba-b92f-45b526664a24_1600x287.png 1456w\"></a></p><p>Systems safety engineering is widely used for safety analysis in many industries. The impetus for this discipline was the understanding that safety does not merely depend on the performance or reliability of individual components (e.g., ML models), but may also depend on assuring the safe interoperation of multiple systems or components (including human systems such as corporations). This paper advocates the use of systems safety engineering methods for analyzing the safety of machine learning models.</p><p><strong>[</strong><a href=\"https://arxiv.org/abs/2302.02972\"><strong><u>Link</u></strong></a><strong>]</strong></p><h3><strong>Other Systemic Safety News</strong></h3><p><strong>[</strong><a href=\"https://arxiv.org/abs/2302.06588\"><strong><u>Link</u></strong></a><strong>]</strong> This paper proposes methods to \u201cimmunize\u201d images against manipulation by diffusion models, potentially reducing the risk of the models being used for disinformation.</p><h1><strong>Other Content</strong></h1><p><strong>[</strong><a href=\"https://course.mlsafety.org/about\"><strong><u>Link</u></strong></a><strong>] The ML Safety course</strong></p><p>If you are interested in learning about cutting-edge ML Safety research in a more comprehensive way, there is now a course with lecture videos, written assignments, and programming assignments. It covers technical topics in Alignment, Monitoring, Robustness, and Systemic Safety.</p><p><strong>[</strong><a href=\"https://www.reddit.com/r/mlsafety/\"><strong><u>Link</u></strong></a><strong>] ML Safety Reddit</strong></p><p>The ML Safety Reddit is frequently updated to include the latest papers in the field.</p><p><strong>[</strong><a href=\"https://twitter.com/topofmlsafety\"><strong><u>Link</u></strong></a><strong>] Top of ML Safety Twitter</strong></p><p>This Twitter account tweets out papers posted on the ML Safety Reddit.</p>", "user": {"username": "ThomasWoodside"}}, {"_id": "zbPMiA6CftdB827cF", "title": "Sanity check - effectiveness/goodness of Trans Rescue?", "postedAt": "2023-02-20T15:53:39.778Z", "htmlBody": "<p>I stumbled across the charity Trans Rescue, which helps transgender people living in unsafe parts of the world move. They've published advice for people living in first world countries with worsening legal situations for trans people, but the vast majority of their funding goes toward helping people in Africa and the Middle East immigrate to safer countries (or for Kenyans, move to Trans Rescue's group home in the safest region of Kenya) and stay away from abusive families.<br><br>As of September 2022, their total funding since inception was just under 33k euros <a href=\"https://transrescue.org/where-does-the-money-go\">https://transrescue.org/where-does-the-money-go</a> . They helped about twenty people move using this funding <a href=\"https://transrescue.org/some-things-weve-done/\">https://transrescue.org/some-things-weve-done/</a> . That puts the cost to help a person move at about 1,650 euros, which is in the same ballpark as a Givewell top charity's cost to save one person from fatal malaria.</p><p>I haven't looked closely at the likely outcome for people who would benefit from Trans Rescue's services but don't get help. Some would live and some would not, but I don't have a good sense of the relative numbers, or how to put QUALYs on undertaking a move such as this. Since they're very new and very small, I'm considering donating and keeping an eye on how they grow as an organization.</p><p>Mainly I hoped you all could help me by pointing out whether there's anything fishy that I might have missed. This review <a href=\"https://transrescuewatch.medium.com/the-trans-rescue-papers-when-help-looks-more-like-human-trafficking-exploitation-4e3d7886bfbc\">https://transrescuewatch.medium.com/the-trans-rescue-papers-when-help-looks-more-like-human-trafficking-exploitation-4e3d7886bfbc</a> was published by a group of Twitter users, apparently after an argument with one of the board members. It's certainly not unbiased, but they do seem to have made a concerted effort to find anything bad or construable as bad that Trans Rescue has ever done. Trans Rescue wrote a blog post in response <a href=\"https://transrescue.org/responding-to-our-attackers\">https://transrescue.org/responding-to-our-attackers</a> . I came away with a sense that the board is new at running an organization like this, and they rely on imperfect volunteer labor to be able to move as many people as they do, but their work is overall helpful to their clients.</p>", "user": {"username": "David D"}}, {"_id": "7f9eMGRhfEgjbMxsa", "title": "Immigration reform: a shallow cause exploration", "postedAt": "2023-02-20T15:57:13.180Z", "htmlBody": "<p><i>This&nbsp;shallow investigation was commissioned by Founders Pledge.</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefi6vbgnnliyo\"><sup><a href=\"#fni6vbgnnliyo\">[1]</a></sup></span></p><h1><strong>Summary</strong></h1><p>This shallow cause area report explores the impact of immigration on subjective wellbeing (SWB). It was completed in two weeks. In&nbsp;this report, we start by reviewing the literature and modelling the impact of immigration on wellbeing. Then, we conduct back of the envelope calculations (BOTECs) of the cost-effectiveness of various interventions to increase immigration.</p><p>The&nbsp;effect of immigration has been studied extensively. However, most of the studies we find are correlational and do not provide causal evidence. Additionally, most of the studies use life satisfaction as a measure of SWB, so it\u2019s unclear whether immigration impacts life satisfaction and affective happiness (e.g. positive emotions on a daily basis) differently.</p><p>Despite these limitations, we attempt to estimate the effect of immigration on wellbeing. We find that immigrating to countries with higher average SWB levels&nbsp;might produce large&nbsp;benefits to wellbeing, but we are very uncertain about the exact size of the effect.&nbsp;According to our model, when people move to a country with higher SWB, they will gain 77% of the SWB gap between the origin and destination country. We assume this benefit will be immediate and permanent, as there is little evidence to model how this benefit evolves over time, and existing evidence doesn\u2019t suggest large deviations from this assumption.</p><p>There are open questions about the spillover effects of immigration on the immigrant\u2019s household as well as their original and destination communities. Immigrating likely benefits the whole family if they move together, but the impact on household members that stay behind is less clear, as the economic benefits of remittances are countered by the negative effects of separation. On balance, we estimate a small, non-significant benefit for households that stay behind&nbsp;when a member immigrates (+0.01 WELLBY&nbsp;per household member). We did not include spillovers on the origin community due to scarce evidence (only one study) that suggested small, null effects. For destination communities, we estimate that increasing the proportion of immigrants by 1% is associated with a small, non-significant, negative spillover for natives (-0.01 WELLBYs&nbsp;per native), although this is likely moderated by attitudes towards immigrants.</p><p>We then conducted BOTECs of possible interventions to increase immigration. The most promising is policy advocacy, which we estimate is 11 times more cost-effective than GiveDirectly cash transfers.&nbsp;The other interventions we investigated are 2 to 6 times better than cash transfers. However, all of our BOTECs are speculative and exploratory in nature. These estimates are also limited because we\u2019re unsure how to model the potential for immigration increasing interventions to foster anti-immigrant sentiment in the future. Plus, there might be non-trivial risks that a big push for immigration or other polarising topics by Effective Altruists could&nbsp;burn goodwill that might be used on other issues (e.g., biosecurity). Accordingly, we\u2019re inclined towards treating these as upper-bound estimates and we expect that once these costs are taken into account immigration policy advocacy would no longer be promising.</p><p>We recommend that future research assesses the costs, chances of success, and risk of backlash for potential policy-based interventions to increase immigration.</p><h1><strong>Notes</strong></h1><ol><li>This report focuses on the impact of immigration in terms of WELLBYs. One WELLBY is a 1 life satisfaction point change for one year (or any equivalent combination of change in life satisfaction and time). In some cases, we convert results in standard deviations of life satisfaction to WELLBYs using a 2-point standard deviation on a 0-10 life satisfaction scale (i.e., 1 SD change is the equivalent of 2-point changes on a 0-10 life satisfaction scale). This naive conversion is based on estimates from large-scale data sets like the World Happiness Reports. See <a href=\"https://forum.effectivealtruism.org/posts/dk48Sn6hpbMWeJo4G/to-wellby-or-not-to-wellby-measuring-non-health-non\"><u>our post</u></a>&nbsp;on the WELLBY method for more details.</li><li>Our calculations and data extraction can be found in this <a href=\"https://docs.google.com/spreadsheets/d/13s3TOFG8tlroWkJ_MjAYDyqs7KOj6ZMUREMTAr97W08/edit?usp%3Dsharing\"><u>Google Spreadsheet</u></a>&nbsp;and this <a href=\"https://github.com/Happier-Lives-Institute/Immigration\"><u>GitHub repository</u></a>.</li><li>The&nbsp;shallowness of this investigation means (1) we include more guesses and uncertainty in our models, (2) we couldn\u2019t always conduct the most detailed or complex analyses, (3) we might have missed some data, and (4) we take some findings at face value.</li></ol><h1><strong>Outline</strong></h1><p>In<strong>&nbsp;Section 1 </strong>we introduce the issue, define key terms we use throughout this report and explain the mechanisms for how immigration increases subjective wellbeing.</p><p>In <strong>Section 2</strong>&nbsp;we model the effects of immigration on subjective wellbeing.</p><p>In <strong>Section 3 </strong>we discuss the limitations of our analysis and some of the unique risks and considerations that come with increasing immigration.</p><p>In <strong>Section 4</strong>&nbsp;we estimate the cost-effectiveness of several interventions that aim to increase subjective wellbeing by facilitating immigration.</p><p>In <strong>Section 5 </strong>we summarise our main uncertainties.</p><p>In <strong>Section 6</strong>&nbsp;we discuss the most important questions that future research should answer.</p><p>In <strong>Section 7</strong>&nbsp;we conclude with the key takeaways from the report.</p><h1><strong>1. International immigration and subjective wellbeing</strong></h1><p>In&nbsp;this report, we focus on the effects of immigration, that is moving to another country, on individuals\u2019 subjective wellbeing (SWB): people\u2019s self-reports of how they think and feel their life is going<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvekyf06tea\"><sup><a href=\"#fnvekyf06tea\">[2]</a></sup></span>.</p><p>Immigrants&nbsp;tend to move to countries that are happier (<a href=\"https://link.springer.com/article/10.1186/s40176-014-0024-5\"><u>Lovo, 2014</u></a>; <a href=\"https://s3.amazonaws.com/happiness-report/2018/CH2-WHR-lr.pdf\"><u>Helliwell et al., 2018</u></a>) and more developed (<a href=\"https://hdr.undp.org/en/content/human-development-indices-indicators-2018-statistical-update\"><u>UNDP, 2018</u></a>) and their subjective wellbeing&nbsp;benefits from doing so (The World Happiness Report; <a href=\"https://s3.amazonaws.com/happiness-report/2018/WHR_web.pdf\"><u>2018</u></a>). As we can see in Figure 1, countries differ considerably in their average level of life satisfaction.&nbsp;In 2020, 3.6% (280.6 million) of people in the world were international migrants&nbsp;(<a href=\"https://www.migrationpolicy.org/programs/data-hub/charts/immigrant-and-emigrant-populations-country-origin-and-destination\"><u>MPI, 2020</u></a>), and an additional 26.4 million were refugees (0.3% of the population; <a href=\"https://publications.iom.int/books/world-migration-report-2022\"><u>IOM, 2022</u></a>). These numbers indicate that most people live in the country they were born in. If immigrants become as satisfied with their lives as the residents of the country they move to, this implies that we can dramatically improve global wellbeing by increasing immigration from unsatisfied to satisfied countries.</p><p><strong>Figure 1:</strong>&nbsp;Worldwide life satisfaction levels (<a href=\"https://ourworldindata.org/happiness-and-life-satisfaction\"><u>Our World In Data</u></a>)</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676900877/mirroredImages/7f9eMGRhfEgjbMxsa/bhkqs1s55n3nxoooujfr.png\" alt=\"\"></p><p>So, how does immigration improve wellbeing? Immigrants likely seek and benefit from the institutions and opportunities that correlate with higher SWB levels in destination countries. The average SWB of countries is significantly associated with higher GDP per capita<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref12nz9q73gozn\"><sup><a href=\"#fn12nz9q73gozn\">[3]</a></sup></span>&nbsp;, greater healthy life expectancy at birth, reported generosity, perceptions of better social support, more freedom to make life choices, and lower corruption&nbsp;(<a href=\"https://happiness-report.s3.amazonaws.com/2022/WHR%2B22.pdf\"><u>World Happiness Report, 2022</u></a>).&nbsp;Typically, these countries also have better&nbsp;state welfare systems (<a href=\"https://www.nowpublishers.com/article/Details/RBE-0071\"><u>O\u2019Connor, 2017</u></a>) and lower crime levels (<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S027795362100438X\"><u>Baranyi et al., 2021</u></a>). Additionally, refugees may become free from the threats and persecution they faced in their country of origin. But immigration is not entirely positive. Immigrants' wellbeing can be negatively impacted by perceived discrimination (<a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1002/casp.865\"><u>Jasinskaja-Lahti et al., 2006</u></a>), language barriers (<a href=\"https://link.springer.com/article/10.1007/s10902-021-00474-2\"><u>Lee et al., 2022</u></a>) and downward social mobility<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6ear851j1v\"><sup><a href=\"#fn6ear851j1v\">[4]</a></sup></span>&nbsp;(<a href=\"https://www.tandfonline.com/doi/pdf/10.1080/13557858.2011.632816?casa_token%3DakBzmBEvirIAAAAA:PMFjfkZE6ivaI613I5rAVHW4KQ7g8m_aFyL11NBJ5nX1SQ73IxgQmBQ2edCRsCxBiw_oJ2_VIPQ3\"><u>Das-Munshi et al., 2012</u></a>), to name a few possible challenges. Taken together, these findings suggest there are both positive and negative aspects of immigrating that may ultimately impact overall subjective wellbeing.</p><h1><strong>2. Modelling the effects of immigration on subjective wellbeing</strong></h1><p>In this section, we present a simple model to estimate the relationship between immigration and subjective wellbeing. We start by estimating how much SWB is gained by immigrants after they move (Section 2.1). Then, we discuss how the effects of immigration can \u2018spill over\u2019 to influence the immigrant\u2019s family, their origin&nbsp;community, and their new destination&nbsp;community (Section 2.2).</p><h2><strong>2.1 SWB wellbeing benefits for immigrants</strong></h2><p>We model that immigrants\u2019 gains in SWB due to moving to a country with higher average SWB levels will be a proportion of the gap in SWB between the origin and destination country. Imagine that&nbsp;a person moves from country X, with an average SWB level X<sub>SWB</sub>, to country Y, with SWB level Y<sub>SWB</sub>. Then the gap in SWB between the countries is (Y<sub>SWB</sub>&nbsp;- X<sub>SWB</sub>). We assume that the immigrant will gain a share of that gap by moving. To calculate the percentage of the gap gained, we extract data from five sources (four correlational&nbsp;studies and one quasi-experiment). This led to a total of 310,658 observations. Our search<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhis23fuemv9\"><sup><a href=\"#fnhis23fuemv9\">[5]</a></sup></span>&nbsp;was not exhaustive, and we think there are more studies that could be used. Ideally, we would have liked to use natural experiments, but these seem rare and underpowered. A lower quality but more cost-effective and feasible study would use longitudinal data about matched<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3s0rhgcgctn\"><sup><a href=\"#fn3s0rhgcgctn\">[6]</a></sup></span>&nbsp;leavers from the country of origin, stayers in the country of origin, and natives of the destination country before and after immigration. Unfortunately, we could not find such a study. Instead, we looked for studies that compare leavers to stayers. We calculated the percentage of the gap gained as:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676905802/mirroredImages/7f9eMGRhfEgjbMxsa/qswclaetw71lt9xkckhw.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676905803/mirroredImages/7f9eMGRhfEgjbMxsa/r8hgsoedtln7h7h4o5ff.png 136w, https://res.cloudinary.com/cea/image/upload/v1676905803/mirroredImages/7f9eMGRhfEgjbMxsa/bbcgptzrif8lt0c23mcp.png 216w, https://res.cloudinary.com/cea/image/upload/v1676905803/mirroredImages/7f9eMGRhfEgjbMxsa/kccbu2nuq5sxerxr7rbx.png 296w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/rsdueqtxiwneu0ju6xux.png 376w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/gnxoikmzeb8uzdhbvqxt.png 456w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/s7bqw4ba3byhhhza4b7m.png 536w\"></figure><p>We often had to impute some of these numbers (often the SWB of the stayers and almost always for the SWB of the destination&nbsp;country). Generally, we did this by obtaining the average SWB of a country from the Gallup World Poll&nbsp;which asks&nbsp;thousands of respondents, from most countries in the world, a life satisfaction question known as Cantril\u2019s ladder&nbsp;(<a href=\"https://www.proquest.com/openview/34651df7ea15ff89908e4cf4c83bed13/1?pq-origsite%3Dgscholar%26cbl%3D1816607\"><u>Kilpatrick &amp; Cantril, 1960</u></a>). The results of this annual survey are accessible on <a href=\"https://ourworldindata.org/happiness-and-life-satisfaction\"><u>Our World in Data</u></a>. Naturally, these studies could suffer from problems with self-selection, that aren\u2019t necessarily distillable to observable characteristics<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefp76hm8t9toi\"><sup><a href=\"#fnp76hm8t9toi\">[7]</a></sup></span>. We present the sources of data we relied on in Table 1.</p><p><strong>Table 1:</strong>&nbsp;Source of data for immigration gap model</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/j8igdwdzw7yv2nbyjwtt.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676905805/mirroredImages/7f9eMGRhfEgjbMxsa/dyjgkm2rkbof0yrpyjpl.png 120w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/ivgc7kgtkviajjkwunsb.png 240w, https://res.cloudinary.com/cea/image/upload/v1676905805/mirroredImages/7f9eMGRhfEgjbMxsa/lh1ue9swlg1ohijl9fov.png 360w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/rie3narlkjeziptvzt9k.png 480w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/rb2oodaq9kbmjyzpih0e.png 600w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/za9eqi098to1vh2fm1ld.png 720w, https://res.cloudinary.com/cea/image/upload/v1676905805/mirroredImages/7f9eMGRhfEgjbMxsa/w88ymua2xusjyyauxzr1.png 840w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/klu00tc1hvoib541jtjl.png 960w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/udjwdyfpqg9ys0n1izeu.png 1080w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/sp16s86mttfm5qzespol.png 1139w\"></figure><p>We take an average of the reported percentages of gaps gained (see our <a href=\"https://docs.google.com/spreadsheets/d/13s3TOFG8tlroWkJ_MjAYDyqs7KOj6ZMUREMTAr97W08/edit%23gid%3D0\"><u>data</u></a>&nbsp;and <a href=\"https://github.com/Happier-Lives-Institute/Immigration\"><u>analysis</u></a>) - weighted by sample size - and find that, <strong>on average, when moving to a country with higher SWB levels</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreft8z1pm7aryn\"><sup><a href=\"#fnt8z1pm7aryn\">[8]</a></sup></span><strong>,&nbsp;88% of the gap in SWB between countries is gained&nbsp;by immigrants&nbsp;(range: 27% to 146%).</strong>&nbsp;Hence, this suggests that immigrants\u2019 SWB levels will increase in direction of the SWB level of the destination&nbsp;country.</p><p>Of course, it might take time for immigrants to become happier, and the gains might accrue gradually. The data we use covers immigrants that have been in their destination country between 1 and 30 years. However, there is limited evidence about how the effect changes over time. For more discussion about moderation over time, see Appendix A.1. For modelling purposes, we assume this average happiness benefit happens immediately, stays constant over time, and is experienced every year spent in the destination country. Hence, our model in equation form is:</p><p><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; SWB gain * years spent in destination country</i></p><p>Which can be broken down into:</p><p><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (gap * % of gap gained) * years spent in destination country</i></p><p>We briefly discuss some potential limitations of our model and how we might address them:</p><p>(1) One concern we have is that there might be bias in the data we use since it\u2019s primarily correlational in nature. We think that the studies we found are unlikely to have surveyed the most vulnerable immigrants or those who are not in the best position to increase their SWB by immigrating such as undocumented migrants, those who can\u2019t speak the language of the survey, and children (<a href=\"https://s3.amazonaws.com/happiness-report/2018/CH2-WHR-lr.pdf\"><u>Helliwell et al., 2018</u></a>; <a href=\"https://s3.amazonaws.com/happiness-report/2018/CH3-WHR-lr.pdf\"><u>Hendriks et al. 2018</u></a>). If true, our estimation would be biased towards positive findings by&nbsp;missing the experience of those who have not benefited as much.&nbsp;We make a guess that surveys miss 20% of the immigrant population and that those missed only gain 33% of the gap. <strong>By combining these in a weighted average, we discount the percentage of the gap gained from 88% to 77%</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8hfarec2mod\"><sup><a href=\"#fn8hfarec2mod\">[9]</a></sup></span><strong>.</strong>&nbsp;With more research into the SWB of hard-to-reach immigrants, this adjustment could be empirically estimated.</p><p>(2) Another source of bias could be that the \u2018matching\u2019 of movers and stayers might miss important characteristics in determining who can and wants to move. We do not address this at this time. Future work with more causal paradigms could address&nbsp;this.</p><p>(3) We did not include potential moderators of how much SWB is gained by immigrating (e.g., characteristics of the immigrant or the destination&nbsp;country) in our model. We discuss those - and why we find that, on average, immigrants do not gain 100% of the gap - in Appendix A.2.</p><p>(4) Some might argue that the SWB gained from immigrating is not a true change in SWB but a change in scale use. In Appendix A.3. we discuss why we think that these&nbsp;are true changes in SWB.</p><h2><strong>2.2 Spillovers</strong></h2><p>When modelling the effect of immigration, we also want to consider the effects on the household, the origin community, and the destination community. In brief, households benefit from immigration if they can move as well. If they are left behind, the evidence is more mixed as there is a tension between the economic gains of remittances being sent home and the pains of separation.&nbsp;We&nbsp;estimate from seven studies that having a member of the household who has immigrated increases SWB (non-significantly) by 0.005 SDs (or 0.01 WELLBYs) per household member.&nbsp;There is little evidence for the SWB effect on the community left behind (only one study), so we treat the effect as zero&nbsp;(although it is plausible that the effect is non-zero). We discuss the potential spillovers of immigration on natives at some length, because it\u2019s an area we were very uncertain about. From 11 studies we estimate that a 1% increase in immigrants as a share of the population is associated with a (non-significant) decrease of -0.004 SDs of SWB (or -0.008 WELLBYs) for the native population. However, this likely is moderated by attitudes towards immigration. These spillovers are small and don\u2019t discernibly affect our estimates, but we wouldn\u2019t be surprised if further work found larger spillovers. We elaborate on these calculations in Appendix B.</p><h1><strong>3.&nbsp;Counterfactuals and risks</strong></h1><p>In Section 2, we presented a model of how immigration improves the SWB of someone moving to a happier country. However, to estimate the total effect we also need to consider how long immigrants spend in the destination&nbsp;country and if they would have migrated later anyways without the intervention (Section 3.1), as well as the risks of backlash from increased immigration (Section 3.2).</p><h2><strong>3.1 The counterfactual effects of the intervention</strong></h2><p>In&nbsp;Section 3, we modelled that a person moving from one country to another will benefit according to:</p><p><i>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (gap * % of gap gained) * years spent in destination country</i></p><p>When we apply this model to an intervention, \u201cyears spent in the destination country\u201d should (1) include the duration of their stay, which need not be permanent and (2) adjust for the counterfactual impact. If an intervention helps someone move to a country with higher SWB levels when they would have never moved otherwise, that will create a larger benefit than an intervention that helped someone move only a year sooner.</p><p>The counterfactual choice of an immigrant may not be binary (e.g., \u201cmove to the USA or stay in Afghanistan\u201d). Instead, it may be more fluid: \u201cIdeally move to the USA, if that fails, move to Pakistan.\u201d Adding multiple options of countries an immigrant may consider seems more realistic, but quickly becomes complex. See Figure 2 for a representation of immigration choice in two periods for three countries.</p><p>We simplify - for lack of time and data - this model to \u201clikelihood of return\u201d and \u201clikelihood they would immigrate later\u201d from the origin to the ideal country and apply this to the model by discounting the <i>years immigrants spend in the destination country</i>. To estimate this model we would need studies that follow immigrants across their life and travels.</p><p><strong>Figure 2</strong>: Model of immigration choice in two periods</p><figure class=\"image image_resized\" style=\"width:57.86%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676900876/mirroredImages/7f9eMGRhfEgjbMxsa/tpzzr6lswdupguxixpfj.png\" alt=\"\"></figure><p>Let\u2019s consider the counterfactual (i.e., \u201clikelihood they would immigrate later\u201d ). For example, if the probability that a successful migrant would have moved to a similar country, later on, is 50% across their lifespan, then we would cut the years spent in a country attributable to immigration by half.</p><p>Immigrants can return to their country of origin, and unsurprisingly, they do so when they are less happy (<a href=\"https://link.springer.com/article/10.1007/s10902-019-00207-6\"><u>Shamsuddin &amp; Katsaiti, 2020</u></a>). When an immigrant returns to their origin country, we assume the SWB benefits will cease. This is a simplification as it is unclear what happens to the SWB of returners<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefknfqkuubm1\"><sup><a href=\"#fnknfqkuubm1\">[10]</a></sup></span>.</p><h2><strong>3.2 Risk of backlash effects</strong></h2><p>We already saw in Section 2.2 that increased immigration rates can affect the SWB of natives. But advocating to increase immigration (whether it succeeds or fails) may come with further risks either because increases in immigration lead to more anti-immigration efforts in the future or because advocacy on this issue could burn political goodwill for future altruistic causes. This is our biggest concern and uncertainty in our modelling. Depending on the size of this risk, it could nullify the benefits we estimate or even cause harm.</p><p>A sense that immigration is increasing seems to feed nationalist political parties that flirt with anti-democratic practices. There is a chance that increasing immigration, or attempting to do so, could foment political backlash that reduces the overall amount of immigration&nbsp;over time. This could happen by changing attitudes towards immigrants and giving more political support to anti-immigration politicians.</p><p>Whether increased immigration or increased proximity with immigrants changes attitudes and political intentions related to immigration is unclear. A full review is beyond the scope of this report, but we will share some of the evidence we\u2019ve come across. Polls of public attitudes from <a href=\"https://www.mdpi.com/2076-0760/10/10/401/htm\"><u>Sweden</u></a>&nbsp;and <a href=\"https://yougov.co.uk/topics/politics/articles-reports/2016/01/12/germans-attitudes-immigration-harden-following-col\"><u>Germany</u></a>&nbsp;suggest attitudes towards immigration worsened after the refugee crisis concurrent with the Syrian civil war. But the academic literature is more mixed on the causal effects of immigration on attitudes.</p><p>Schaub et al. (<a href=\"https://journals.sagepub.com/doi/full/10.1177/0010414020957675\"><u>2020</u></a>) found that the presence of immigrants has an overall null causal effect on attitudes or voting behaviour, but this conceals a convergence in attitudes where left-leaning individuals became less positive about immigration and right-leaning individuals became less negative.&nbsp;Similarly, Sola (<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D3169243\"><u>2018</u></a>) does not find that increasing concerns about immigration lead to support for far-right political parties in Germany. In Deiss-Helbig and Remer (<a href=\"https://academic.oup.com/esr/article-abstract/38/2/219/6350780\"><u>2022</u></a>), the causal effects are slightly more mixed: \u201cIt is only when the number of asylum seekers in one\u2019s own direct neighbourhood suddenly increases that attitudes toward asylum seekers deteriorate\u201d. Other studies have also found that increased contact with refugees and/or migrants has been associated with more support for anti-immigrant politics (<a href=\"https://research.sabanciuniv.edu/id/eprint/41269/1/10253029_Apayd%25C4%25B1n__Samet.pdf\"><u>Apaydin, 2020</u></a>; <a href=\"https://www.cambridge.org/core/services/aop-cambridge-core/content/view/C50A127CC517968F2D0FA42A2A23FF85/S1047198718000487a.pdf/waking-up-the-golden-dawn-does-exposure-to-the-refugee-crisis-increase-support-for-extreme-right-parties.pdf\"><u>Dinas et al., 2019</u></a>). On the other hand, proximity to, and positive contact with, immigrants and/or refugees might improve attitudes towards them (<a href=\"https://psycnet.apa.org/record/1954-07324-000\"><u>Allport, 1954</u></a>; <a href=\"https://academic.oup.com/migration/advance-article-abstract/doi/10.1093/migration/mnac015/6575748?redirectedFrom%3Dfulltext%23no-access-message\"><u>De Coninck &amp; Meuleman, 2022</u></a>; <a href=\"https://www.annualreviews.org/doi/full/10.1146/annurev.psych.49.1.65?casa_token%3DYkANvA6P2WcAAAAA:TxzXg9I-EivuvVgjsmwe64lUp7VjhWys08Ia7DbHOAX67GzBBi3yNRczWeKctKUKnp_ubJZ9Zua_\"><u>Pettigrew, 1998</u></a>) whilst distance could <i>increase</i>&nbsp;support for anti-immigration policies (e.g., Trump\u2019s U.S.-Mexico wall; <a href=\"https://journals.sagepub.com/doi/full/10.1177/1065912919854135?casa_token%3DQIv4b2ughs4AAAAA%253Ay0vaq9MkZaoVO54PWKCWZFv7Fb5olJh1gkf09_P-OAviV2bPBtzTDBd8bCNnGYXOtSV_Fl9mNb3g\"><u>Cortina, 2019</u></a>).&nbsp;Achard et al. (<a href=\"https://www.pascalachard.com/uploads/1/2/0/0/120084194/effect_exposure.pdf\"><u>2021</u></a>) found that those living close to refugees became less likely to support anti-immigrant parties. This mixed literature means that we can\u2019t discard the possibility of a backlash from increases in immigration, but we think that if there are strong negative effects the literature would be more clear. More work is needed to quantify the risk and conditions of such backlashes.</p><p>A further concern is that backing interventions to increase immigration (or any politically polarising issue) could reduce the cost-effectiveness of other interventions in important cause areas because it could make certain stakeholders less cooperative with philanthropists. Imagine that reducing the likelihood of an engineered pandemic is the most pressing policy priority, but a prominent philanthropist or their foundation had previously funded attempts to advocate for immigration reform. That track record might deter potential allies on biosecurity.</p><h1><strong>4. BOTECs of potential interventions</strong></h1><p>In&nbsp;this section, we present our back-of-the-envelope calculations (BOTECs) of potential interventions for improving global SWB through increased immigration. In every case, we are only considering helping people who want to move, not moving people who do not want to move.</p><p><strong>First, we should caveat our analysis. </strong>We made these calculations quickly. These are often speculative interventions. Many of the elements in the models&nbsp;are&nbsp;based on limited evidence and regularly rely on guesses. Nevertheless, we think these BOTECs usefully present some initial modelling for different interventions that others can build on. We would not be surprised if further research or more detailed modelling considerably changed the results of these BOTECs.</p><p>To estimate the effect on immigrants we use the percentage of the gap gained, which we quantitatively estimated in Section 2.1. We combined this with some weakly informed assumptions about how long immigrants stay and whether they would immigrate later. We omit effects on the households and communities left behind, but we include negative spillovers on natives for policy-based interventions. Additionally, we only account for the risks of political backlash from increasing immigration&nbsp;(or attempting to do so)&nbsp;with subjective adjustments to our model. For these reasons, we may be overestimating the cost-effectiveness of the interventions we discuss. Several of our models relate to helping refugees move. We are unsure, and do not model, whether refugees (rather than immigrants) might benefit more from moving, nor if helping refugees affects backlash differently than helping immigrants.</p><p>Broadly, there are two types of interventions: those directly assisting with immigration (financially or by helping with the administrative process) or advocating for liberalising immigration restrictions.</p><p>We split our BOTECs according to how speculative they are. Section 4.1 focuses on more concrete interventions and less speculative interventions. Appendix C discusses interventions that are more speculative or where the intervention is more vague.</p><h2><strong>4.1 BOTECs of interventions to help people move: advocacy and direct assistance</strong></h2><p>Table 2 lists the advocacy interventions and the direct interventions that are less speculative, presented in order of promise. Advocacy appears slightly more promising, but is much less certain, for reasons we will discuss. Before we present our BOTECS (Sections 4.1.1 to 4.1.4), it\u2019s worth mentioning that we think there are steep challenges with performing cost-effectiveness analyses of policy advocacy, which we describe in Appendix D. These BOTECs are considerably more speculative than ones involving direct interventions.</p><p><strong>Table 2:</strong> Advocacy and less speculative interventions to increase SWB through immigration</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/ktirqw2hfefsagxfencd.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/w4qc4mtqxk1eqqunbpk0.png 120w, https://res.cloudinary.com/cea/image/upload/v1676905805/mirroredImages/7f9eMGRhfEgjbMxsa/vgi2dt7al2iezmuw4tlc.png 240w, https://res.cloudinary.com/cea/image/upload/v1676905805/mirroredImages/7f9eMGRhfEgjbMxsa/xzl0vy6rasxpqewohnlr.png 360w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/sfoknp9j1t87mfl0snoh.png 480w, https://res.cloudinary.com/cea/image/upload/v1676905803/mirroredImages/7f9eMGRhfEgjbMxsa/kkpwbpmpgokejijk6j0g.png 600w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/rfyzrblrl50tw0u1lfog.png 720w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/kgfgmd4c1wlfc4biacez.png 840w, https://res.cloudinary.com/cea/image/upload/v1676905803/mirroredImages/7f9eMGRhfEgjbMxsa/qdv7l83rrza8xqg3ld1a.png 960w, https://res.cloudinary.com/cea/image/upload/v1676905803/mirroredImages/7f9eMGRhfEgjbMxsa/hkgtksg8ywfzt2qfgrih.png 1080w, https://res.cloudinary.com/cea/image/upload/v1676905805/mirroredImages/7f9eMGRhfEgjbMxsa/ahs4btgmfqzvga2gsv1k.png 1143w\"></figure><h3><strong>4.1.1 Influencing immigration policy in Switzerland</strong></h3><p>Switzerland seems like a promising country for policy advocacy&nbsp;in general, because of its direct democratic system (Swiss&nbsp;citizens vote 3-4 times a year on&nbsp;multiple referendums at a time). Considering how often the Swiss people have voted on referendums concerning&nbsp;immigration (some recent examples&nbsp;being the <a href=\"https://en.wikipedia.org/wiki/2014_Swiss_immigration_initiative\"><u>2014</u></a>&nbsp;and <a href=\"https://www.bbc.co.uk/news/world-europe-54316316\"><u>2020</u></a>&nbsp;votes), it is plausible to imagine they might accept to vote in new referendums&nbsp;about increasing immigration quotas.</p><p>We assume that immigration would become liberalised - or the law reducing immigration will be rescinded - in 10 years. One motivation for that view is that we assume pressure will build to increase immigration in response to population declines and the resulting labour shortages (see for example, <a href=\"https://www.vox.com/23058427/differential-demography-population-baby-names-jennifer-sciubba-8-billion\"><u>this article of Vox on demographic trends</u></a>).&nbsp;Increasing immigration by 9,500 a year will create 95,000 immigrants in 10 years, which is about a 1% increase in a predicted <a href=\"https://worldpopulationreview.com/countries/switzerland-population\"><u>future Swiss population of 9.5 million</u></a>.</p><p>The life satisfaction of Switzerland is 7.5, and we assume the SWB of immigrants is 6.5<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3osgn7wxvon\"><sup><a href=\"#fn3osgn7wxvon\">[11]</a></sup></span>, hence a 1-point gap. Increasing immigration by 1% will create a gain of 2 million WELLBYs over ten years.&nbsp;However, it will also reduce the SWB of natives by 20,000 WELLBYs. We also attempt to account for political backlash. We guess that there\u2019s a 10% chance that this would reduce immigration by 200,000 over five years; namely, that backlash would cause 20,000 fewer immigrants in expectation. However, this only decreases the effect of immigration by&nbsp;400,000 WELLBYs. Taking into account both of these factors decreases the total wellbeing effect of the initiative from 2&nbsp;million to 1.58 million WELLBYs gained, which is a relatively small decrease. This is speculative and we wouldn\u2019t be surprised if there was a larger loss (or more complicated ramifications) due to backlash.</p><p>To know if such an advocacy intervention&nbsp;is cost-effective we need to know how much it would cost to put forward such a referendum and campaign for the policy&nbsp;sufficiently for it to gain enough votes to pass. We start with a cost of $2.1 million to start a referendum by assuming it will cost <a href=\"https://ballotpedia.org/Ballot_measures_cost_per_required_signatures_analysis\"><u>$15 per signature collected</u></a>, that advocates will want to collect 20,000 more signatures than <a href=\"https://en.wikipedia.org/wiki/Voting_in_Switzerland%23:~:text%3DSuch%2520votes%2520are%2520called%2520when,(as%2520cantonal%2520referendum%2520procedure).\"><u>the 50,000 necessary</u></a>, and that overhead costs will be half the total variable cost.&nbsp;Next, we estimate how much of the vote is required to win the initiative. This depends on how people would vote&nbsp;without the advocacy campaign. Let\u2019s take the anti-immigration position in the 2014 referendum, which won by 0.67%, thereby, we assume we would need to close a gap of 1.5% of the vote share. Jaquet et al. (<a href=\"https://www.tandfonline.com/doi/abs/10.1080/01402382.2020.1852374\"><u>2021</u></a>) analysed the relationship between spending on political advertising in newspapers<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefy9v9odj30n8\"><sup><a href=\"#fny9v9odj30n8\">[12]</a></sup></span>&nbsp;and vote shares in Swiss referendums. Jaquet et al. (<a href=\"https://www.tandfonline.com/doi/abs/10.1080/01402382.2020.1852374\"><u>2021</u></a>) estimated that 1,000 Swiss Francs in political advertising&nbsp;for a referendum position is associated with an increase in the canton-level vote share of 0.05%.&nbsp;We make several adjustments to this figure. First, we assume that this corresponds to $26,000 (Swiss Francs and the US dollar are around parity) at the federal level, $1,000 for each of the 26 cantons in Switzerland. Second, we assume that for each increase in 0.05% of the vote share, it will become 25% more expensive to win votes, which would result in a cost of $17 million to close the 1.5% vote gap. This is a guess, but we think it\u2019s more reasonable than simple linear extrapolation, which would estimate it costs $780,000 to close the vote gap. Note that we do not use the models presented in Jaquet et al. (<a href=\"https://www.tandfonline.com/doi/abs/10.1080/01402382.2020.1852374\"><u>2021</u></a>) because they are Bayesian Beta regressions, which we do not know how to interpret<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3qzv48o4zar\"><sup><a href=\"#fn3qzv48o4zar\">[13]</a></sup></span>.</p><p>To put the $17 million figure in perspective, the average Swiss initiative spends 1.5 million CHF on political advertising (1 million CHF on the pro-government side, 0.5 CHF against; <a href=\"https://www.tandfonline.com/doi/abs/10.1080/01402382.2020.1852374\"><u>Jaquet et al., 2021</u></a>). In a failed 2016 referendum about expelling criminal non-residents, <a href=\"https://www.swissinfo.ch/eng/enforcement-initiative_a-spontaneous-organised-and-well-financed-campaign/42008720\"><u>around 3 million CHF was spent by advocates</u>, a</a>nd 11 million CHF was spent in the 2009 initiative regarding keeping open borders with the EU (<a href=\"https://www.tandfonline.com/doi/abs/10.1080/01402382.2020.1852374\"><u>Jaquet et al., 2021</u></a>).</p><p>Taking these numbers at face value, this implies that advocating for a modest Swiss referendum to increase immigration quotas by 1% would be 11 times as cost-effective as GiveDirectly. We don\u2019t know how reasonable these numbers are and we do not think they should be taken&nbsp;at face value.</p><h3><strong>4.1.2 Influencing immigration policy in the USA</strong></h3><p>The geographic and population size, wealth, moderately high SWB, and historical openness to mass migration makes the United States a clear candidate for considering immigration reform. We expected immigration to the USA to have decreased in the past decades, but it has risen continuously since the 1970s (see <a href=\"https://www.pewresearch.org/fact-tank/2019/01/30/immigrant-share-in-u-s-nears-record-high-but-remains-below-that-of-many-other-countries/\"><u>here</u></a>&nbsp;and <a href=\"https://ourworldindata.org/explorers/migration?tab%3Dchart%26facet%3Dnone%26Metric%3DNumber%2Bof%2Binternational%2Bimmigrants%26Period%3DTotal%26Sub-metric%3DTotal%26country%3D~USA\"><u>here</u></a>). We imagine advocating for an immigration law like <a href=\"https://en.wikipedia.org/wiki/Border_Security,_Economic_Opportunity,_and_Immigration_Modernization_Act_of_2013\"><u>the one that failed in 2013</u></a>&nbsp;(despite strong bipartisan support in the Senate). This was <a href=\"http://www.washingtonpost.com/blogs/wonkblog/wp/2013/06/20/immigration-projections/\"><u>projected to add 16 million more immigrants (a 4.21% increase) over 20 years</u></a>, after which we assume the law would have been passed anyway or revoked.</p><p>We&nbsp;think that there is some risk of backlash leading to restrictions on immigration. We guess that there is a 10% chance that the successful passage of a new law would be reversed with restrictions that reduce the number of immigrants by 10 million over 20 years. This reduces the expected number of immigrants from 16 million to 13.5 million.</p><p>The USA\u2019s average life satisfaction is 7 out of 10 and we assume the average potential immigrant to the USA would have a life satisfaction level of 5.5. We estimated this by eyeballing the SWB of countries that most US immigrants come from (see <a href=\"https://news.gallup.com/poll/245255/750-million-worldwide-migrate.aspx\"><u>here</u></a>&nbsp;and <a href=\"https://en.wikipedia.org/wiki/Immigration_to_the_United_States\"><u>here</u></a>). The immigration of 13.5 million people to the USA would generate 528 million WELLBYs. However, we estimate it will reduce the SWB of natives by 90 million WELLBYs. On net, we estimate the successful passage of moderate immigration reform to increase SWB by 438 million WELLBYs.</p><p>The key uncertainty with this BOTEC is the financial cost of increasing the chance of successfully&nbsp;advocating reform. We choose to try and estimate how much it would cost to make reform 1% likelier. We use the cost per vote in presidential elections as a proxy for the cost of influencing national policy. Sides et al. (<a href=\"https://www.cambridge.org/core/journals/american-political-science-review/article/effect-of-television-advertising-in-united-states-elections/29ED18D9FB4B7AA52F6404ECF15F4114\"><u>2021</u></a>) find a cost per vote of $365. This is higher than the figure of $170 found in Spenkuch and Toniatti (<a href=\"https://www.kellogg.northwestern.edu/faculty/spenkuch/research/advertising.pdf\"><u>2018</u></a>). We combine these figures to arrive&nbsp;at a cost of $250 per vote. We then imagine a fictional national referendum where the vote on immigration reform would be 45% in favour, 55% against. A recent state referendum relating to immigration in a politically median state <a href=\"https://ballotpedia.org/Colorado_Immigration_Lawsuit_Against_Federal_Government,_Referendum_K_(2006)\"><u>had similar for/against vote shares</u></a>. This implies that <a href=\"https://en.wikipedia.org/wiki/Voter_turnout_in_United_States_presidential_elections\"><u>8.5 million votes need to be won</u></a>, which would cost ~ $2 billion, or ~$21 million to get 1% of the way there.&nbsp;Our second source of evidence is Kang (<a href=\"https://doi.org/10.1093/RESTUD/RDV029\"><u>2016</u></a>), which found that $3 million of lobbying spending increases the likelihood of favourable legislation passing by 0.05% points.&nbsp;Similar to our assumption in the Swiss example, we guess that for every 0.05% increase in vote share, it costs 25% more to get the same increase in vote share. This implies it would cost $208 million to increase the likelihood of successful reform by 1%. Averaging these two numbers gives us $115 million to increase the likelihood of immigration reform by 1%.</p><p>If we take these numbers seriously, then advocacy for moderate immigration reform in the USA would be six times as cost-effective as GiveDirectly. We\u2019re especially uncertain about how reasonable our estimates are because we are new to investigating policy advocacy as an intervention.</p><h3><strong>4.1.3 Sanctuary cities to prevent deportation</strong></h3><p>In the USA, about <a href=\"https://trac.syr.edu/phptools/immigration/remove/\"><u>150,000 people are deported each year</u></a>. Not only are these painful experiences for the people deported, they also separate residents from the permanent benefit of living in the USA, which typically has higher SWB than the countries these immigrants came from.</p><p>At the state level, a process to prevent deportations would be to encourage the creation of <a href=\"https://en.wikipedia.org/wiki/Sanctuary_city\"><u>sanctuary cities</u></a>: municipal jurisdictions which limit the ability of the national government to enforce immigration law. According to Hausman (<a href=\"https://www.pnas.org/doi/full/10.1073/pnas.2014673117%23supplementary-materials\"><u>2020</u></a>), passing sanctuary legislation in a city or state reduces deportations by 33%. Between 2008-2015 there were about 69,000&nbsp;deportations in Texas (<a href=\"https://www.pnas.org/doi/full/10.1073/pnas.2014673117%23supplementary-materials\"><u>Hausman, 2020, Appendix Table S2</u></a>). This appears strange to us as most cities in Texas lean Democrat,&nbsp;and <a href=\"https://texaspolitics.utexas.edu/blog/new-uttexas-politics-project-poll-texans%25E2%2580%2599-attitudes-population-growth-and-state%25E2%2580%2599s-future-take\"><u>Texas Democrats overwhelmingly express a rejection of deportation</u></a>. So if legislation was passed in major cities across Texas, we estimate this could prevent 23,000 people from being deported over the next seven years.</p><p>However, we think there\u2019s a substantial chance for backlash that could lead the governor or state legislature to increase deportations. We think the mechanism for backlash would be by increasing the salience of illegal immigration and rallying the Texas Republican political base against sanctuary cities \u2013 this could build demand for stricter enforcement of existing laws in Texas. We guess that there\u2019s a 50% chance that an advocacy attempt would increase deportations by about 10,000 a year.</p><p>Assuming the people concerned mainly come from Central America and Mexico, and would have stayed 25 years, increasing the chance of sanctuary cities in major Texas cities by 1% would produce 2,920 WELLBYs. However, the Texas state legislature has <a href=\"https://ballotpedia.org/Preemption_conflicts_between_state_and_local_governments\"><u>overruled several local laws in the past decade</u></a>, so we give it a 50% chance that the sanctuary city laws would be overruled. This reduces the effect by half, to 1,460 WELLBYs.</p><p>We&nbsp;assume that it would cost $100,000 dollars to increase the chance of sanctuary cities in Texas by 1%, which is the cost to buy a vote share in US congressional elections according to Schuster (<a href=\"https://www.journals.uchicago.edu/doi/10.1086/708646\"><u>2020</u></a>). Hence, advocacy for sanctuary cities would produce 16 WELLBYs per $1,000, which is two times more cost-effective than GiveDirectly. This does not include a potential counterfactual where deportation might have stopped in a certain number of years anyway without the help of such an intervention. This would reduce the cost-effectiveness of the intervention but we are sceptical that stopping deportation will happen without more advocacy.</p><h3><strong>4.1.4 Canadian sponsorship programme</strong></h3><p>This BOTEC is based on Canada\u2019s Private Sponsorship of Refugees programme. In Canada, individuals can privately sponsor refugees and <a href=\"https://www.unhcr.ca/in-canada/other-immigration-pathways-refugees/private-sponsorship-refugees/%23:~:text%3DThe%2520Private%2520Sponsorship%2520of%2520Refugees%2520(PSR)%2520program%2520allows%2520Canadians%2520to,Canadian%2520government%2520through%2520other%2520programs.\"><u>these don\u2019t count towards refugee limits</u></a>. With this programme, it <a href=\"https://www.canada.ca/en/immigration-refugees-citizenship/services/application/application-forms-guides/guide-sponsor-refugee-groups-five.html%23appa2\"><u>costs $25,250</u></a>&nbsp;(USD, we converted from CAD) for a group to finance the resettlement of a family of five (mainly through providing financial support for the first 12 months). A similar programme <a href=\"https://www.vox.com/future-perfect/22883775/afghan-refugee-private-sponsorship\"><u>is to be implemented in the USA</u></a>, so this is potentially a general North American intervention.</p><p>We imagine the effect of sponsoring a family of five from Afghanistan. Although, note we are unsure whether sponsors can voice a preference for what type of refugee they would like to sponsor. Average USA/Canadian life satisfaction levels are 7 out of 10 and Afghani life satisfaction is&nbsp;2.4 out of 10. We expect a relatively low return rate of 10% because we guess that the Taliban (or a similarly authoritarian regime) will retain control of the country for the foreseeable future. We assume that if someone failed to immigrate through these means there would be a 40% chance they would make it to an equivalent country in their lifetime. This leads to a total gain of 376 WELLBYs.</p><p>The cost-effectiveness is 14 WELLBYs per $1,000 spent, or about two times GiveDirectly. This is the intervention for which we are the most confident in our calculations, although we still make assumptions about the length of stay and the counterfactuals about whether refugees would still reach the destination country later without the intervention. A more detailed assessment would include the probability of moving to a country happier than the original one but less happy than the ideal one (for example, moving from Afghanistan to Pakistan instead of Canada). Plus, we do not include potential lives saved by helping refugees.</p><p>We would like to double-check if this programme denotes a purely counterfactual facilitation of a refugee family. If it does, then it seems a reasonable benchmark to compare other immigration-increasing interventions to. We\u2019re interested in whether the USA programme, if it is implemented, will have any lighter financial requirements. If it does, then it would be more cost-effective.</p><h2><strong>4.2 More speculative BOTECs of interventions to help people move</strong></h2><p>In Table 3, we present five speculative BOTECS which are more uncertain and involve more guesses. They are particularly uncertain when it comes to their actual implementation. Our aim is to illustrate ideas for potential immigration interventions rather than providing a thorough assessment of real, instantiable possibilities. We discuss these interventions in more depth in Appendix C.</p><p><strong>Table 3</strong>: Speculative direct interventions</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/kyoq1xrei9knpidfziai.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676905805/mirroredImages/7f9eMGRhfEgjbMxsa/bpx01p1ifdwhgiqrrgnb.png 120w, https://res.cloudinary.com/cea/image/upload/v1676905805/mirroredImages/7f9eMGRhfEgjbMxsa/afo6pn5scm9vtmheaioa.png 240w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/yyjubylgtpygdhrn6yv8.png 360w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/cuxtmcqtnjhxyecfidcd.png 480w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/jfapyphlsrqycbadfk4o.png 600w, https://res.cloudinary.com/cea/image/upload/v1676905803/mirroredImages/7f9eMGRhfEgjbMxsa/dmkokxyjfa59hbhqfzil.png 720w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/xhvrazskndmmjlzyf3cs.png 840w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/w7udfte8kd1wbshxqjsq.png 960w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/zl8fmzygin7vqno9ztxk.png 1080w, https://res.cloudinary.com/cea/image/upload/v1676905804/mirroredImages/7f9eMGRhfEgjbMxsa/jqb622vc4bwyulhsjtt1.png 1143w\"></figure><h1><strong>5. Discussion</strong></h1><p>Altogether, we think that immigration benefits immigrants and increases their SWB. However, we are sceptical that there are extremely cost-effective interventions in this area.</p><p>We are unsure about the feasibility of estimating counterfactual value and whether efforts to increase immigration may backfire as a result of the potential backlash that could be created by increased immigration.<strong>&nbsp;</strong>The most promising interventions - those based on policy advocacy - are also very uncertain. Because of this uncertainty, it seems plausible that policy advocacy opportunities should be required to appear much more cost-effective than a direct intervention to receive the same recommendation<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn6y9xmn5u8h\"><sup><a href=\"#fnn6y9xmn5u8h\">[14]</a></sup></span>&nbsp;\u2013 because policy advocacy BOTECs are much weaker evidence. We believe that advocacy aimed at other policy areas with broader support, such as reducing lead exposure, is likely to be more cost-effective.</p><p>Our most important uncertainties mainly concern the cost, likelihood of success, and acceptability of these interventions, particularly policy advocacy. Many of our figures are (somewhat informed) guesses. The biggest concern among these is the risk of backlash for immigration and future philanthropic efforts in general. In our BOTECs, we did not attempt to model how advocating for immigration might reduce the political capital that advocates could use for other important policy areas (e.g., biosecurity).</p><p>As we mentioned in Section 4 and Appendix D, we are surprised there has not been more quantitative work in the effective altruism community on the general topic of policy advocacy. We are very interested in feedback from others on the best way forward for estimating the likelihood of success in policy advocacy. We invite readers to critically engage with these BOTECs and consider them as stepping stones for more modelling and research, rather than guidance for funding decisions.</p><h1><strong>6. Next steps for research</strong></h1><p>Based on the considerations we have expressed, here are our recommendations for future research. We believe research on costs, policy, and risks are the most important next steps.</p><p><strong>1. Policy interventions need more research.</strong>&nbsp;We think more can be done to quantitatively estimate the effectiveness of policy advocacy and answer the questions: What is the cost of influencing policy? How does one best influence policy? What is the role of media and public opinion? This is an important meta-research project in itself, as more understanding of quantitative priors for the likelihood of influencing policy and the costs of policy change could help future cost-effectiveness analyses regarding many policy advocacy questions. Because we think Open Philanthropy seems to perform more analysis than they publish, researchers should attempt to speak with them to check what they have done on the topic before performing further research.</p><p><strong>2. We need a more sophisticated view of</strong> <strong>the backlash risks</strong>, such as \u2018poisoning the well\u2019 of destination&nbsp;nations, empowering nationalist political parties, or even the effect on the political capital of philanthropists. It seems important to clarify the extent to which recent&nbsp;increases in immigration in Europe created a backlash.</p><p><strong>3. There appear to be few academic studies of interventions aimed at increasing international immigration, on a micro level</strong>. How are these interventions implemented and what makes them more or less effective and acceptable? These could be useful but are likely onerous. What would likely be more useful is to review charities that help refugees leave dangerous countries, try to understand the average cost of moving people, and then try to form a view on the likelihood the refugee would escape anyways.</p><p><strong>4. Better longitudinal evidence estimating the SWB effects of immigration in general, and effects on happiness and mood in particular.</strong> Almost all of the research we used is correlational. Few followed an individual from their origin country to their destination. More cross-country immigration panels would be an important test to confirm or question our model of SWB convergence. Research about the scale use and comparison frames of immigrants would be of interest as well.</p><p>We recommend that every study of this sort measures the SWB of respondents and their socio-economic gains over time (if possible, starting before the immigration process to compare before and after scores). Such studies should not only measure responses from immigrants but also a matched group of stayers as well as a matched group of natives.</p><p>We also have little understanding of how immigration affects levels of happiness and not just life satisfaction. More study of the happiness effects of immigration would be useful. Unfortunately, the Gallup World Poll (which was our main source of data for the effects of migration on life satisfaction) <a href=\"https://www.gallup.com/analytics/349280/gallup-global-emotions-report.aspx\"><u>does not collect very good happiness data</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefr3bdy2w57ma\"><sup><a href=\"#fnr3bdy2w57ma\">[15]</a></sup></span>, making the study of this question difficult.</p><h1><strong>7. Conclusion</strong></h1><p>Overall, we think that moving from a less satisfied country to a more satisfied country will have large benefits for an individual\u2019s life satisfaction. We are reasonably confident in our general modelling of the relationship between immigration and SWB. When immigrating to a country with higher SWB levels, people appear to gain a large part of the SWB gap between the origin and destination countries. That gain is not 100% of the gap and can be explained by a range of moderating factors. More data could be extracted from studies and more analyses conducted. We think the figures we found could vary moderately with the addition of higher-quality evidence.&nbsp;</p><p>We are much more uncertain about the costs and likelihood of success of interventions related to increasing immigration. Our BOTECs include many uncertainties and guesses. In this shallow dive into immigration, we did not find an intervention we thought was particularly promising, and we\u2019re somewhat sceptical that we would find one with more time. The most promising are interventions seeking to implement policies that increase immigration to countries like Switzerland and the USA. However, these are very uncertain and we would not be surprised if future research would find that their cost-effectiveness is lower. We recommend more research on quantifying interventions to influence policy as well as more detailed inquiries into charities which help immigration and at what cost. In addition, we would like a better understanding of the potential of policy advocacy on a polarised topic to create a backlash.</p><h1><strong>Appendix A: Additional modelling considerations</strong></h1><h2><strong>A.1 Long-term effects and counterfactual changes</strong></h2><p>The literature about the long-term effects of immigration is mixed and gives an unclear picture of how an immigrant's SWB changes with time spent in the destination country. Akdede and Giovanis (<a href=\"https://link.springer.com/article/10.1007/s11205-020-02503-8\"><u>2020</u></a>) found a positive correlation between length of stay and SWB whilst Hendriks et al.\u2019s (<a href=\"https://s3.amazonaws.com/happiness-report/2018/CH3-WHR-lr.pdf\"><u>2018</u></a>) analysis of the German Socio-Economic Panel finds a negative correlation. In Lo\u0308nnqvist et al.\u2019s (<a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2105\"><u>2015</u></a>) review of the literature, they reported that different studies show that immigrants can experience increases in SWB over time, decreases over time, or follow a U-shape pattern where SWB \u201cis at its highest immediately after migration (positive euphoria), after which it gradually worsens before picking up again with time spent in host country\u201d (p. 497).</p><p>To estimate the effect of time on the percentage gained of the SWB gap between origin and destination we calculate the linear change in the percentages of gaps gained between the initial and final follow-up. We use Lo\u0308nnqvist et al. (<a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2105\"><u>2015</u></a>), the initial and final follow-up from Stillman and colleagues, and Hendriks et al.\u2019s (<a href=\"https://s3.amazonaws.com/happiness-report/2018/CH3-WHR-lr.pdf\"><u>2018</u></a>) comparison of newcomers (less than five years in the destination country) to long-timers (more than five years) to estimate a change over time. We obtain a - sample size weighted - average of these linear changes, resulting in a 2.14 percentage point increase in the percentage of the SWB gap gained per year. This is a small effect that would not strongly affect our modelling, so we do not use it.</p><p>When encouraging immigration, we try to consider the counterfactual effect; what would have happened to an immigrant's SWB if the individual did not move? To estimate this counterfactual effect we use the Gallup World Polls\u2019 SWB data accessible from <u>Our World in Data</u>. We classify countries as \u201cless satisfied\u201d if their SWB levels were on average below 5 (on a 0-10 scale) before 2010. Then we compare the effects of time on SWB for each group of countries. We regress the SWB levels onto time in years (between 2010 and 2018), and we interact <i>time</i>&nbsp;and <i>being less satisfied</i>. We find that (1) SWB levels in more satisfied countries (non-significantly) increase over time by 0.008 points&nbsp;each year and (2) SWB levels in less satisfied countries increase significantly faster by an additional 0.039 each year. This suggests that the gap between satisfied and less satisfied countries is closing over time. However, this is a small effect that would not strongly affect our modelling.</p><h2><strong>A.2 Moderating factors</strong></h2><p>We estimated that immigrants do not gain 100% of the gap. Immigrants might not have the same SWB levels as natives because they might be poorer or have less access to sociocultural aspects of the destination country that benefits the SWB of natives&nbsp;(<a href=\"https://link.springer.com/article/10.1007/s11482-020-09832-3\"><u>Paloma et al., 2021</u></a>). For instance, immigrants in the USA have worse educational, economic, and employment outcomes (<a href=\"https://nap.nationalacademies.org/read/23550/chapter/6\"><u>Blau &amp; Mackie, 2017, Chapter 3</u></a>).</p><p>A few other findings are worth&nbsp;mentioning. Not being in a precarious socio-economic situation and having social support is important for the SWB of immigrants (<a href=\"https://www.sciencedirect.com/science/article/pii/S1053482222000274?casa_token%3DDOfqpFEwldMAAAAA:T7wE7HcRGzCdsJyLeCPSvhWveB3C_J6ffyhYvk4-BkEShZX5tH2tbDmJa9_jYqEgm63r7LHGkQ\"><u>Shirmohammadi et al., 2022</u></a>). Aoki and Santigo (<a href=\"https://docs.iza.org/dp11368.pdf\"><u>2018</u></a>) found that the English proficiency of childhood immigrants in the UK was related to their socioeconomic class as adults. Giovanis (<a href=\"https://link.springer.com/article/10.1007/s12232-021-00377-x\"><u>2021</u></a>) found participation in sociocultural activities reduces the SWB gap between immigrants and natives. Tegegne and Glanville (<a href=\"https://journals.sagepub.com/doi/pdf/10.1177/0197918318769309?casa_token%3Dl0poqMdED1QAAAAA:y7JCG6usAuBA-msowP4i-Y_mZeUC31g0oI7-NHJhX1Uea9yaT_Vphl9aXk-UFrxI1cYWp-Veo6M7\"><u>2019</u></a>; see also <a href=\"https://journals.sagepub.com/doi/pdf/10.1177/0898264321990282?casa_token%3DPTwRqTC_QSoAAAAA:K2ePyORBhr7539yyaVptUOJA3-Bf6HTqi-nUt6PH2gLYq38HyYJqpDVwe5cMOHOdhYyqmshH9Xme\"><u>Jiang &amp; Renema, 2021</u></a>) found that lower social capital explained part of the gap in SWB between immigrants and natives. However, it might be that migrants with higher SWB levels are more likely to participate in socio-cultural activities or obtain higher social capital.&nbsp;</p><p>Another reason why immigrants may not gain 100% of the gap is due to prejudice. However, we found few studies that quantify this relationship. If we had more time, we would combine our \u2018percentage of the gap gained\u2019 data with attitudes towards immigration data from the International Organization for Immigration (<a href=\"https://publications.iom.int/books/how-world-views-migration\"><u>2015</u></a>) - or another source - and see how much it moderates the percentage gained of the SWB gap.</p><p>Another moderating factor is the reasons for moving. Refugees (people fleeing specific risks such as war or persecution; <a href=\"https://www.unhcr.org/en-us/news/latest/2016/3/56e95c676/refugees-migrants-frequently-asked-questions-faqs.html\"><u>UNHCR, 2016</u></a>) might gain as much of the gap as regular immigrants do. Refugees are more likely to suffer from mental illness, which may stem from previous hardships (<a href=\"https://journals.sagepub.com/doi/abs/10.1177/0706743717746666\"><u>Hynie, 2018</u></a>). Hendriks et al. (<a href=\"https://s3.amazonaws.com/happiness-report/2018/CH3-WHR-lr.pdf\"><u>2018</u></a>) found that refugees in Germany had lower SWB levels than immigrants. On the other hand, refugees in the USA are better off economically than other immigrants, but this may be due to increased US selectivity with the refugees they allow residency (<a href=\"https://www.cgdev.org/blog/welcoming-refugees-afghanistan-and-ukraine-also-economic-investment\"><u>Resstack et al., 2022</u></a>).</p><p>Helping refugees could be very effective as refugees come from the places with the lowest SWB, hence they would gain from the largest SWB gaps. Helping refugees could also save lives, depending on the threat in their country of origin. We do not model lives saved in our cost-effective analyses (Section 5); hence, we expect that our model of helping refugees is an underestimate.</p><h2><strong>A.3 Theoretical&nbsp;and scale use concerns</strong></h2><p>Are the changes in SWB due to actual changes in SWB or to changes in scale use in how people respond to SWB questionnaires? Perhaps immigrants acquire the reporting processes of their destination country but aren\u2019t better off. We believe this is very unlikely. If there is a shift in scale use, we think it would come from people raising, not lowering, their standards about how good life could be.&nbsp;This would lead to us underestimating the true wellbeing effects of immigration<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftrvxcn2x9g\"><sup><a href=\"#fntrvxcn2x9g\">[16]</a></sup></span>.</p><p>Another issue might be comparison frames. Do immigrants compare their life to those of people back in the country of origin or to those of people in the destination country? Whichever frame, these are still true reflections of SWB. If immigrants become less satisfied with their lives because they start comparing themselves with natives that are better off, then that is a \u2018true\u2019 change in satisfaction. However, it is a problem for the effectiveness of immigration in increasing SWB if most of the gains from immigration become tempered by inter-comparison (e.g., income gains are affected by relative comparisons<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsd0blwsuk5e\"><sup><a href=\"#fnsd0blwsuk5e\">[17]</a></sup></span>).</p><h1><strong>Appendix B: More on immigration spillovers</strong></h1><p>In this appendix, we discuss the literature surrounding the spillover effects of immigration on the households left behind (when households do not move together), the origin community, and the destination community.</p><h2><strong>B.1 Households</strong></h2><p>Interventions targeting an individual can also affect their household (<a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\"><u>McGuire et al., 2022</u></a>). Failing to account for this limits our understanding of how much immigration can affect SWB.</p><p>If interventions involve moving whole households, we assume that the benefit will apply to the whole household. In our modelling, we assume this applies similarly to children and to adults<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflhqr3re9whh\"><sup><a href=\"#fnlhqr3re9whh\">[18]</a></sup></span>.</p><p>Immigrants sometimes leave their families behind. From Ivlev&nbsp;et al.'s (<a href=\"https://link.springer.com/article/10.1007/s00148-018-0718-8\"><u>2019</u></a>) global sample of immigrants, we estimate that this happens in 14%&nbsp;of cases. To estimate the effect in this case we extracted seven effects<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqi36sxfkhua\"><sup><a href=\"#fnqi36sxfkhua\">[19]</a></sup></span>, converted them to Cohen\u2019s <i>d</i>&nbsp;(SD-changes in SWB)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzq62ee9697\"><sup><a href=\"#fnzq62ee9697\">[20]</a></sup></span>&nbsp;effect sizes and found a non-significant, meta-analytic, average<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffkxccu9bomd\"><sup><a href=\"#fnfkxccu9bomd\">[21]</a></sup></span>&nbsp;increase of 0.005 SDs in SWB (or 0.01 WELLBYs) associated with having a family member who immigrated. Note that these studies are correlational<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcs3ehoi1p58\"><sup><a href=\"#fncs3ehoi1p58\">[22]</a></sup></span>&nbsp;and that there might be a selection effect where families who sent someone abroad might benefit from remittances (and/or suffer from separation) in different ways or intensities than those families who did not.</p><p>How the effects on left-behind families change over time is unclear. Joarder et al. (<a href=\"https://www.tandfonline.com/doi/pdf/10.1080/00220388.2016.1178380?casa_token%3DDHnDqy1Ye54AAAAA:C_6F3wksvVbCFerI7f8qJhGr2on7Lu1bpoBzTO7RN4efMwKz45fC8eL7SO0STDd7aXYWPjBEjavZs9A\"><u>2016</u></a>) found that the number of years spent abroad reduced the SWB of the household in Bangladesh when their family member went to Malaysia but improved their SWB when they went to the&nbsp;UK.&nbsp;This is too uncertain for us to include in our modelling.</p><h2><strong>B.2 Origin community</strong></h2><p>It is unclear if the effects on the household left behind generalise to the origin community, so we do not add any origin community spillover effects. The only SWB evidence we have of the effect of emigration on the origin community is Lara\u2019s (<a href=\"https://www.tandfonline.com/doi/pdf/10.1080/21632324.2019.1585683?casa_token%3DzntDM7y9HdwAAAAA:kVTnw1AHUiPpAjBEGL4xsJC9XYx8RKH5s23fcp8j-JGrLp-URtGoaj7281HU_kEmQXuZRBhxB4yCJLs\"><u>2019</u></a>) study of the relationship between emigration rates for areas in Mexico and the SWB of people in Mexico. They found mixed patterns: when controlling for individual characteristics, emigration rates increased SWB for men but decreased SWB for women.</p><p>One concern is that emigration could limit the ability of the origin country to improve its institutions. This could be true if emigration drains high-skilled individuals from the country, making it poorer and less likely to reform. We expect this concern to be blunted somewhat by high rates of return (29% globally, <a href=\"https://www.pnas.org/doi/abs/10.1073/pnas.1722334116\"><u>Azose &amp; Raftery, 2018</u></a>) and remittances (<a href=\"https://www.un.org/development/desa/en/news/population/remittances-matter.html\"><u>which are three times the size of development aid</u></a>). Remittances seem correlated to beneficial political (<a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/rode.12401\"><u>Williams, 2018</u></a>) and economic (<a href=\"https://www.adb.org/publications/international-remittances-and-poverty-reduction\"><u>Yoshino et al., 2017</u></a>; <a href=\"https://www.emerald.com/insight/content/doi/10.1108/IJSE-08-2013-0189/full/html\"><u>Kratou et al., 2015</u></a>) effects at the country level.&nbsp;Historical quasi-experimental evidence from Sweden found that Swedish emigration led to a higher likelihood of reform for local governments in Sweden (<a href=\"https://www.journals.uchicago.edu/doi/abs/10.1086/701682\"><u>Karadja &amp; Prawitz, 2019</u></a>). However, this study may not generalise to other contexts. We think that the positive effects of emigration may be less likely in authoritarian countries where potential reformers&nbsp;may emigrate at higher rates.</p><h2><strong>B.3 Destination community</strong></h2><p>Increased immigration to a country could impact the SWB of the people already living there. The&nbsp;literature on the effect of immigration on natives\u2019&nbsp;SWB levels is mixed<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxl9szygqlh\"><sup><a href=\"#fnxl9szygqlh\">[23]</a></sup></span>. We base our analysis mainly on studies reported in reviews conducted by Akdede and Giovanis (<a href=\"https://link.springer.com/article/10.1007/s11205-020-02503-8\"><u>2020</u></a>) and Hendriks and Burger (<a href=\"https://www.econstor.eu/bitstream/10419/233996/1/GLO-DP-0842.pdf\"><u>2021</u></a>). Some&nbsp;studies find a significant positive relationship (<a href=\"https://www.sciencedirect.com/science/article/pii/S0167268114000948\"><u>Akay et al., 2014</u></a>; <a href=\"https://scholar.google.com/citations?view_op%3Dview_citation%26hl%3Den%26user%3D0AE_M78AAAAJ%26sortby%3Dpubdate%26citation_for_view%3D0AE_M78AAAAJ:Wp0gIr-vW9MC\"><u>Akay et al., 2016</u></a>; <a href=\"https://link.springer.com/article/10.1186/2193-9039-2-12\"><u>Betz &amp; Simpson, 2013</u></a>), others a null or mixed relationship (<a href=\"https://link.springer.com/article/10.1007/s11205-020-02503-8\"><u>Akdede &amp; Giovanis, 2020</u></a>; <a href=\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/740985/Giulietti__2018_.pdf\"><u>Giulietti &amp; Yan, 2018</u></a>; <a href=\"https://journals.sagepub.com/doi/abs/10.1177/0308518X17740895\"><u>Ivlevs &amp; Veliziotis, 2018</u></a>; <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0167268120303747\"><u>O\u2019Connor, 2020</u></a>; <a href=\"https://mpra.ub.uni-muenchen.de/93045/4/MPRA_paper_93045.pdf\"><u>Papageorgiou, 2018</u></a>), and others a significant negative relationship (<a href=\"https://journals.sagepub.com/doi/abs/10.1177/0950017019866643\"><u>Howley et al., 2020</u></a>; <a href=\"https://link.springer.com/article/10.1007/s00148-017-0657-9\"><u>Kuroki, 2018</u></a>) between immigration and the SWB of natives.</p><p>The variety in findings can be explained by the heterogeneity of the phenomenon, as immigration seems to impact different people in different ways depending on their age, gender, income, education, employment status, and attitudes towards immigrants. In Figure 3 below, we summarise our beliefs about the pathways and moderators involved in spillovers on the native community due to immigration.</p><p><strong>Figure B.1:&nbsp;</strong>Illustration of the causal mechanisms of immigration spillovers on native communities</p><h2><strong><img src=\"https://res.cloudinary.com/cea/image/upload/v1676900877/mirroredImages/7f9eMGRhfEgjbMxsa/il5pyfcqxbxrzhnvdhsa.png\" alt=\"\"></strong></h2><p>We extract results from the aforementioned studies, convert them to Cohen\u2019s <i>d</i>&nbsp;(SD-changes in SWB) effect sizes and calculate the meta-analytic average&nbsp;of the effect of immigration on the SWB of natives (15 effect sizes with 2.7 million observations). Different studies have operationalised \u2018immigration\u2019 (the dosage) in different ways<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftjkeix4ajv\"><sup><a href=\"#fntjkeix4ajv\">[24]</a></sup></span>. Hence, we transform the effect size of each study so that they represent the effect of a 1% increase in the share of immigrants in the population. Overall, we find a non-significant decrease in the SWB of natives of -0.004 SDs (or -0.008 WELLBYs) per 1% increase in the proportion of immigrants in the population.</p><p><strong>Limitations</strong></p><p>Our analysis has some limitations. First, all of these studies are correlational, using population surveys (e.g., ONS in the UK) and SWB questions in panel surveys (e.g., the BHPS in the UK). Although, almost all of these studies look at data over time and exploit some form of geographical variation in the number of immigrants. Additionally, these studies only look at European countries or the US as destination countries, and 6 of the 15 effect sizes are from the UK, so the effects may not generalise.</p><p>Second, we find a mix of six negative and nine positive effects on the natives. As we illustrated in Figure B.1, we think the relationship between immigration and native wellbeing is quite complex. What explains these mixed findings that are, on average, slightly negative (but non-significant)?</p><p><strong>Explaining the mixed findings with attitudes</strong></p><p>It doesn\u2019t seem like economic outcomes explain the story, as immigration appears good for most participants in the destination economy<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqct6t5bxtof\"><sup><a href=\"#fnqct6t5bxtof\">[25]</a></sup></span>.</p><p>We think the mixed findings might be explained in part by attitudes towards immigration, which vary considerably across countries<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6go9ykhf8ur\"><sup><a href=\"#fn6go9ykhf8ur\">[26]</a></sup></span>. Being older or unemployed - which were both related to negative spillovers from immigration (<a href=\"https://journals.sagepub.com/doi/abs/10.1177/0308518X17740895\"><u>Ivlevs &amp; Veliziotis, 2018</u></a>) - are also related to more anti-immigration attitudes (<a href=\"https://www.sciencedirect.com/science/article/pii/S0176268005001114?casa_token%3Dt8SsQnzBRxkAAAAA:Tj98quiCykA62F6kEXK3mEXbCtgIZ3X6-KACFX6osU-J5x4cPITNVyerpgRMj6C_Li8OcNZ52w\"><u>O\u2019Rourke &amp; Sinnott, 2006</u></a>). In their study, Akdede and Giovanis (<a href=\"https://link.springer.com/article/10.1007/s11205-020-02503-8\"><u>2020</u></a>) found that immigration rates had a positive effect on SWB in northern, western, and eastern European countries, but a negative effect on southern European countries. The authors suggested this is due to southern European countries typically wanting lower levels of immigration than other parts of Europe, especially northern and western countries (as seen in <a href=\"https://publications.iom.int/books/how-world-views-migration\"><u>IOM, 2015</u></a>).</p><p>We test the interaction of immigration levels and attitudes towards immigration on the SWB of the natives in a brief calculation. We find the average percentage of respondents who believe there should be less immigration in the IOM (<a href=\"https://publications.iom.int/books/how-world-views-migration\"><u>2015</u></a>) for each of the effect sizes we have extracted, according to their destination country or region. When we add this measure of attitudes as a moderator (alongside the share of immigrants), we find&nbsp;a non-significant increase of 0.043 SDs of SWB for each 1% increase in the proportion of immigrants and a significant negative decrease of -0.001 SDs of SWB for each 1% increase in the belief that there should be less immigration. These figures imply there is an average negative effect on the SWB of the natives if more than 43% of the population believes there should be less immigration (0.043 - 0.001*43 = 0).</p><p>It remains unclear if the relationship between attitudes and native spillovers is causal. While our analysis is not fully conclusive, it&nbsp;suggests to us that attitudes towards immigration might moderate the effect of immigration on natives. Therefore,&nbsp;interventions to improve attitudes towards immigrants could reduce negative spillovers and potentially increase positive spillovers (see Appendix C.4).</p><p><strong>Further questions</strong></p><p>&nbsp;Further questions for the spillover effect on natives for which we do not have answers are:</p><ul><li>How do the effects change over time?</li><li>Which natives are affected and to what extent (e.g., is it only natives close to areas with high immigration rates)?</li><li>What is the role of different communication channels about immigration (e.g., media vs. direct contact in the community)?</li><li>Does immigration from different countries lead to different attitudes and spillovers? Natives may be more welcoming to immigrants of the same ethnicity.</li><li>What is the dose-response relationship between immigration rates and the spillover on natives? We assumed it was linear, but other relationships are possible.</li></ul><h1><strong>Appendix C: Even more speculative BOTECs to help people move</strong></h1><p>In this appendix, we discuss our even more speculative BOTECs of interventions to increase immigration.</p><h2><strong>C.1 Evacuating refugees from Venezuela and Ukraine</strong></h2><p>In this analysis, we imagine moving a family out of Venezuela&nbsp;or Ukraine. This is speculative as we did not review any programmes that are dedicated to moving refugees from these countries or the costs involved. These are direct interventions like the refugee resettlement programme mentioned in Section 4.1.5.</p><p>We estimate that moving a family from Venezuela (an unhappy Latin American country) to Costa Rica (a much happier Latin American country) would produce 30 WELLBYs per $1,000 spent, which is four times as cost-effective as GiveDirectly. We guess that a resettlement programme in Costa Rica could be cheaper than one in Canada.</p><p>The ongoing Russian-Ukrainian conflict <a href=\"https://data.unhcr.org/en/situations/ukraine\"><u>created many refugees from Ukraine</u></a>&nbsp;moving into the rest of Europe.&nbsp;We imagine this intervention delivered by small organisations helping to move people who are relatively closer to the frontlines. Because of the Schengen Area, and <a href=\"https://www.vox.com/22983230/europe-ukraine-refugees-charts-map\"><u>how welcoming the European nations have been to Ukrainian refugees</u></a>, this could be a much cheaper intervention than the Canadian resettlement programme. We imagine it will only be necessary to cover a month-equivalent cost of $1,100 to move a family, after which the destination country\u2019s services will care for them. We estimate that helping a Ukrainian family move to Europe&nbsp;produces 24 WELLBYs per $1,000. This is three times more cost-effective than GiveDirectly, although we are very uncertain about the cost.</p><p>In both cases, we are making guesses about the return rate and the counterfactual likelihood of leaving Ukraine or Venezuela later without the help of an intervention. Again, we are omitting potential benefits from helping to save lives. We expect attributing counterfactual value to these interventions would be difficult.</p><p>A real organisation in the same vein of evacuating refugees is <a href=\"https://www.libertyinnorthkorea.org/\"><u>Liberty in North Korea</u></a>, which spends $13,257 guiding North Koreans out of China (if they were discovered they\u2019d be deported)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwplvuaef21\"><sup><a href=\"#fnwplvuaef21\">[27]</a></sup></span>. The cost-effectiveness of this organisation would depend on how much they decrease the likelihood of deportation back to North Korea and the SWB of North Koreans who are forcibly returned (assuming they survive). This would be difficult because there is no apparent data on the SWB of North Koreans, and if there was, we would doubt the veracity of the responses.</p><h2><strong>C.2 Software to facilitate the administrative process of immigrating</strong></h2><p>We calculated the cost-effectiveness of a hypothetical software that would assist the administrative process of immigrating to the USA. It appears that there is already a company called <a href=\"https://www.boundless.com/\"><u>Boundless</u></a>&nbsp;that appears to fill this role. We estimate that an additional service would produce 20 WELLBYs per $1,000 spent, which is about three times more cost-effective than GiveDirectly.&nbsp;However, a core uncertainty here is how much earlier people would move to the USA (i.e., how much of an effect) this would cause compared to a counterfactual world without such a software package.</p><h2><strong>C.3&nbsp;Incentivise people to move within the Schengen Area</strong></h2><p>People might want to move within the <a href=\"https://en.wikipedia.org/wiki/Schengen_Area\"><u>Schengen Area</u></a>&nbsp;(a \u2018free movement of persons\u2019 zone in Europe). This would be easier than coming from outside of the Schengen Area, but potential movers might need more information or motivation to do so.</p><p>This idea seems plausible because there\u2019s some evidence that cash transfers can increase internal migration (<a href=\"https://onlinelibrary.wiley.com/doi/full/10.1111/ajae.12261\"><u>Hidrobo et al., 2021</u></a>; <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D3238368\"><u>Adhikari et al., 2018</u></a>) and international migration (<a href=\"https://direct.mit.edu/rest/article-abstract/97/1/224/58218/Migration-and-Financial-Constraints-Evidence-from?redirectedFrom%3Dfulltext\"><u>Angelucci, 2015</u></a>; <a href=\"https://doi.org/10.1162/rest_a_01041\"><u>Gazeaud et al., 2021</u></a>) in low-income countries. However, we should note the case of <a href=\"https://www.evidenceaction.org/beta-no-lean-season/\"><u>No Lean Season</u></a>, a programme by Evidence Action that attempted to scale up cash transfers to incentivise seasonal migration within Bangladesh. They found null results and so <a href=\"https://www.evidenceaction.org/why-test-at-scale-no-lean-season/\"><u>shut down the programme</u></a>. This updates us that the operations and implementation of interventions to increase immigration might be very hard.</p><p>We consider this intervention to be aimed at people from relatively dissatisfied countries in the Schengen Area such as Hungary, Portugal, and Greece. We expect each mover to gain 8 WELLBYs (or 20 WELLBYs per $1,000 spent) which would be about three times as cost-effective as GiveDirectly.</p><h2><strong>C.4 Promote immigration-friendly media</strong></h2><p>An intervention that seems potentially promising, but we didn\u2019t have time to estimate the cost-effectiveness for, is funding popular media depicting immigrants in a positive light. This media would be specifically aimed at conservatives in the United States, <a href=\"https://www.google.com/imgres?imgurl%3Dhttps%253A%252F%252Ffivethirtyeight.com%252Fwp-content%252Fuploads%252F2021%252F03%252Fsamuels-immigration-0325-2.png%26imgrefurl%3Dhttps%253A%252F%252Ffivethirtyeight.com%252Ffeatures%252Fhow-democrats-became-stuck-on-immigration%252F%26tbnid%3DnDttp7BPIydj9M%26vet%3D12ahUKEwiBj4Wwwu73AhVPBM0KHe87C-EQMygIegUIARCRAQ..i%26docid%3DZRdecsyZLKvaVM%26w%3D1150%26h%3D1064%26q%3Dimmigration%2520attitudes%2520by%2520political%2520party%2520over%2520time%26ved%3D2ahUKEwiBj4Wwwu73AhVPBM0KHe87C-EQMygIegUIARCRAQ\"><u>who are less sympathetic to immigration</u></a>. This intervention would aim to affect two important factors: the number of migrants that conservatives allow via policy, and attitudes towards migrants which can have negative SWB impacts on migrants and potentially on natives.</p><p>To do this cost-effectiveness estimate we\u2019d need to review the effectiveness of media at changing attitudes and connect changing attitudes to policy change. A few experiments find that exposure to information correcting misconceptions about immigrants (e.g., there are fewer immigrants than one might think, they commit less crime and use fewer social services) can affect attitudes, at least in the short run (<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D2768187\"><u>Grigorieff et al., 2018</u></a>; <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0014292121002476\"><u>Facchini et al., 2022</u></a>; although, Hopkins et al., (<a href=\"https://www.journals.uchicago.edu/doi/abs/10.1086/699914\"><u>2019</u></a>)&nbsp;found no effect of correct information on attitudes).</p><p>One illustrative example of media having a political impact is Ash et al. (<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D3837457\"><u>2021</u></a>) who exploited quasi-random geographic variation in the saliency of the Fox News Channel&nbsp;(FNC, a popular conservative media outlet) as a proxy for exposure and found that \"A one standard deviation decrease in FNC\u2019s channel position boosted Republican vote shares by at least 0.5 percentage points in recent presidential, Senate, House and gubernatorial elections. The effects of FNC increased steadily between 2004 and 2016 and then plateaued. Survey-based evidence suggests that FNC affects elections by shifting the political preferences of Americans to the right.\"</p><h2><strong>C.5 Immigrant-labour matchmaking organisation for Europe</strong></h2><p>A matchmaking organisation that connects immigrants with employment opportunities could help immigrants move through the Schengen Area (or across any area with free movement and regional variation in SWB). An example in the USA is the <a href=\"https://www.cgdev.org/blog/beats-most-aid-miles-and-it%25E2%2580%2599s-migration-non-profit\"><u>Independent Agricultural Workers Center</u></a>&nbsp;which helps USmakers\u2019 farmers hire seasonal workers from Mexico and Central America. We do not have a BOTEC for this sort of intervention. We think it would be promising if no such organisation already existed.</p><h1><strong>Appendix D: Methodological concerns related to policy CEAs</strong></h1><p>Modelling policy advocacy&nbsp;is difficult because there are few&nbsp;experiments, natural or otherwise, that estimate the effect of policy advocacy (in any domain). Furthermore, we might question how much they generalise to different domains (e.g., influencing policy on education might not generalise to policy on immigration). We reviewed&nbsp;26 studies<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnxnq75czxj\"><sup><a href=\"#fnnxnq75czxj\">[28]</a></sup></span>, 10 of which we found useful. Most of these studies were about the relationship between campaign finance and vote share in different elections.</p><p>Policy&nbsp;advocacy modelling involves answering complex questions such as:</p><ul><li>Does advocacy action directly affect the outcome we care about? For example, even if advocacy successfully pushes for raising immigration quotas, <a href=\"https://www.americanimmigrationcouncil.org/research/how-united-states-immigration-system-works\"><u>immigration quotas are not always filled</u></a>.</li><li>How costly is it to advocate for an issue, buy votes, or change opinion? There appears to be a literature on the cost to win a vote, with studies in several different countries (e.g., UK: <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D3929857\"><u>Cage &amp; Dewitte, 2021</u></a>; Taiwan: <a href=\"https://journals.sagepub.com/doi/pdf/10.1177/21582440221084991\"><u>Wang, 2022</u></a>; France: <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id%3D3125220\"><u>Bekkouche et al., 2019</u></a>; Switzerland: <a href=\"https://www.tandfonline.com/doi/abs/10.1080/01402382.2020.1852374\"><u>Jaquet et al., 2021</u></a>; and the USA: <a href=\"https://doi.org/10.1093/RESTUD/RDV029\"><u>Kang, 2016</u></a>, <a href=\"https://www.cambridge.org/core/journals/american-political-science-review/article/effect-of-television-advertising-in-united-states-elections/29ED18D9FB4B7AA52F6404ECF15F4114\"><u>Sides et al., 2021</u></a>, <a href=\"https://www.journals.uchicago.edu/doi/10.1086/708646\"><u>Schuster, 2020</u></a>).</li><li>Does the probability of advocacy succeeding decrease with the polarised nature of the topic? Our prior here is that advocacy for such a polarised topic as immigration is unlikely to succeed.</li><li>What is the probability that a successfully-advocated-for-policy, or its goal, would have happened anyways? Often, advocacy efforts might only bring forward a policy event.</li><li>How do you attribute causal responsibility for success in policy advocacy if there are multiple advocates?</li></ul><p>The main approach we observe in the effective altruism community is to make a subjective guess after considering case studies of an organisation\u2019s past success and the success of similar organisations working on similar problems.&nbsp;Founders Pledge (FP) has done the most transparent analyses of the possible cost-effectiveness of policy advocacy. See their work on <a href=\"https://docs.google.com/spreadsheets/d/1q6srpmt5VkdXLGfYzqHqkU3hvGUwPKjA67uxqYI0Upw/edit%23gid%3D0\"><u>clean air</u></a>, <a href=\"https://docs.google.com/spreadsheets/d/1F4aRiaczIMv5yTp-k_AjrHWjgP_DTUFz6oXXZTK5ggs/edit%23gid%3D123733040\"><u>GPI\u2019s rural employment</u></a>, <a href=\"https://assets.ctfassets.net/x5sq5djrgbwu/LqOmOhVSMishZFsfXMVXd/5de3d5e246effc8b232171d7217912d5/Housing_Affordability_Report.pdf\"><u>housing affordability</u></a>, and FP\u2019s<a href=\"https://founderspledge.com/research/fp-evaluating-policy\"><u>&nbsp;guide to evaluating policy advocacy</u></a>. Several researchers have expanded on FP\u2019s work on the effectiveness of environmental advocacy, but they also rely on subjective inputs (see <a href=\"https://docs.google.com/spreadsheets/d/1-vxw9yEnPjI5lI2M1_Bm8KN9FZDuJxEVsT5dsDc020Y/edit%23gid%3D44476758\"><u>Giving Green\u2019s CEA of climate activism</u></a>&nbsp;and <a href=\"https://forum.effectivealtruism.org/posts/4ez3nvEmozwPwARr9/a-case-for-the-effectiveness-of-protest\"><u>James Ozden\u2019s CEA of Extinction Rebellion</u></a>).</p><p>We expect Open Philanthropy, <a href=\"https://www.openphilanthropy.org/research/cause-reports\"><u>which has supported several policy advocacy campaigns</u></a>, has a method for assessing the likelihood of policy success, but we did not find published details of this process. Open Philanthropy&nbsp;(<a href=\"https://www.openphilanthropy.org/research/cause-reports/labor-mobility%23footnote12_e2lk78b\"><u>2013</u></a>) performed a shallow investigation into labour mobility as a means of decreasing poverty. However, the report is mostly conversation notes with experts and doesn\u2019t provide much of a foundation for identifying the promising opportunities in this space. In a <a href=\"https://www.openphilanthropy.org/blog/our-progress-2021-and-plans-2022\"><u>blog post</u></a>, they mentioned that they\u2019re winding down their immigration policy advocacy. We haven\u2019t asked about this, nor their general method for policy advocacy, but this is something we would do with more time. Open Philanthropy\u2019s winding down of its involvement in immigration policy advocacy updates us towards thinking that this might not be a cost-effective venture.</p><p>Because we are thinking about a general case, and we\u2019re not evaluating specific organisations, we try to rely on empirical evidence to form a prior on the likelihood of advocacy success.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676900876/mirroredImages/7f9eMGRhfEgjbMxsa/cqq9jg3x3heb8vozbr4y.png\" alt=\"\"></p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fni6vbgnnliyo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefi6vbgnnliyo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Joel McGuire and Samuel Dupret contributed to the conceptualization, investigation, analysis, data curation, and writing (original as well as review and editing) of the project. Michael Plant contributed to the conceptualization, supervision, and writing (review and editing) of the project. Ryan Dwyer contributed to the writing (review and editing) of the project.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvekyf06tea\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvekyf06tea\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;SWB is a useful measure because it could capture and integrate the overall benefit to the individual from all the instrumental goods that result from immigration (e.g., income, health, better institutions). Using SWB means we avoid relying on decision maker\u2019s potentially biased, intuitive assessments about how good immigration will be for others. Instead, we can directly infer this via the self-reports of affected individuals.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn12nz9q73gozn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref12nz9q73gozn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Moving to richer countries&nbsp;indeed enriches immigrants; (<a href=\"https://www.aeaweb.org/articles?id%3D10.1257/aer.103.3.198\"><u>Clemens, 2013</u></a>; <a href=\"https://www.sciencedirect.com/science/article/pii/S0305750X13001654?casa_token%3DzjZ6hLae2SQAAAAA:kAmjkIfpTOUr99EQ2pKXPQvpXaJy9tO2P8zbP6oko6lCTzEJK5TUb-wzHswZKMFvb8ACQvabZA\"><u>Stillman et al., 2015</u></a>; <a href=\"https://policycommons.net/artifacts/1462769/migration-and-remittances/2106339/\"><u>Maheshwor et al., 2019</u></a>)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6ear851j1v\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6ear851j1v\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Downward social mobility refers to the loss of prestige or relative social position, even when economic conditions have improved in absolute terms, e.g., a lawyer in Iraq becoming a taxi driver in Canada.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhis23fuemv9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhis23fuemv9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This involved going through references in the World Happiness Report (<a href=\"https://s3.amazonaws.com/happiness-report/2018/WHR_web.pdf\"><u>2018</u></a>) and Hendriks and Burger (<a href=\"https://www.econstor.eu/bitstream/10419/233996/1/GLO-DP-0842.pdf\"><u>2021</u></a>) as well as an exploratory search on Google Scholar.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3s0rhgcgctn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3s0rhgcgctn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;By <i>matched</i>, social scientists mean that respondents are matched with other respondents of similar characteristics (e.g., age, gender, socio-economics) in order to control for potential differences due to these characteristics.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnp76hm8t9toi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefp76hm8t9toi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Hendriks and Burger (<a href=\"https://www.econstor.eu/bitstream/10419/233996/1/GLO-DP-0842.pdf\"><u>2021</u></a>), in their review, concluded that aspiring immigrants tend to be wealthier and better educated - but less satisfied with their life - than those who don\u2019t intend to move.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnt8z1pm7aryn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreft8z1pm7aryn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;It is unclear if moving to a country with lower SWB levels decreases the immigrant\u2019s SWB. Hendriks et al. (<a href=\"https://s3.amazonaws.com/happiness-report/2018/CH3-WHR-lr.pdf\"><u>2018</u></a>) found that migrants from western Europe to central and eastern Europe gained 0.27 life satisfaction points despite those destinations being, on average, 1.1 points lower. Conversely, Bartram (<a href=\"https://link.springer.com/article/10.1007/s10902-014-9554-z\"><u>2015</u></a>) found that migrants from western and northern Europe to southern Europe experienced a decrease in SWB. However, our focus is to evaluate people moving to countries with higher levels of SWB.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8hfarec2mod\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8hfarec2mod\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;0.8 * 88% + 0.2 * 33% = 77%</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnknfqkuubm1\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefknfqkuubm1\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Returners\u2019 SWB might converge back to the SWB level of their origin country (<a href=\"https://www.tandfonline.com/doi/full/10.1080/14616696.2012.726735?casa_token%3DcuEZyduxvowAAAAA%253AsIXs6mI9iMgLqUBPWXXWbtQ34BGHPSFh7ibUH1mUAteeUMEDfl-KyCy7hkOfyHt4Qqmcnrdlt_2GIws\"><u>Bartram, 2012</u></a>) or they might keep some elevated levels of SWB (<a href=\"https://www.cambridge.org/core/services/aop-cambridge-core/content/view/7B60A5B45E7EF651E393481743416195/S0144686X16001227a.pdf/life-satisfaction-of-migrants-stayers-and-returnees-reaping-the-fruits-of-migration-in-old-age.pdf\"><u>Baykara-Krumme &amp; Platt, 2016</u></a>). Returners might bring home benefits from having migrated, such as having saved some money or acquired new skills.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3osgn7wxvon\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3osgn7wxvon\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We could estimate this more precisely with more timecost-effective but assumed this in most cases from looking at <a href=\"https://ourworldindata.org/happiness-and-life-satisfaction%23life-satisfaction-and-society\"><u>maps of regions we think the immigrants</u></a>&nbsp;would come from.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fny9v9odj30n8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefy9v9odj30n8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;They report that newspapers are used by the Swiss to inform their political decision-making and correlates well with overall campaign spending, as campaign spending information is harder to collect in Switzerland.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3qzv48o4zar\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3qzv48o4zar\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;When we attempted to directly apply their model, it suggested that we\u2019d need to spend around $50 trillion to close the vote gap.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn6y9xmn5u8h\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn6y9xmn5u8h\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For example, we may recommend direct interventions that are 5 times more cost-effective thshort runan cash transfers, but we\u2019d only recommend policy advocacy interventions that are something like 25 or 50 times as cost-effective.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnr3bdy2w57ma\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefr3bdy2w57ma\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;It asks binary questions such as \u201cdid you smile or laugh a lot yesterday?\u201d, \u201cdid you experience a lot of enjoyment yesterday?\u201d, \u201cdid you experience sadness during a lot of the day yesterday?\u201d. These questions are less informative than Likert scales and are questionable to combine. When combined they give strange answers that put China ahead of Denmark (see <a href=\"https://www.gallup.com/file/analytics/324209/gallup-global-emotions-2020-report-pdf.aspx\"><u>Gallup 2020 Global Emotions Report</u></a>).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntrvxcn2x9g\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftrvxcn2x9g\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For example, imagine one comes from a country where the best life imaginable (the \u201810\u2019 on the scale) only truly means a \u20185\u2019 in latent wellbeing, then they move to a country where they can imagine an even better best life, and the \u201810\u2019 on the scale means a latent \u201810\u2019. If that person reports a 4 before moving (i.e., a latent 2), and a 6 (a latent 6 rather than a latent 3) after moving, they will have gained 4 rather than 2 points if they shifted what the maximum of their scale meant.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsd0blwsuk5e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsd0blwsuk5e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This raises a question about the effect of income. If immigrants are better off economically than they would have been otherwise, but less well off than natives in the destination country, how does this affect their wellbeing? If the effect of income is mostly due to relative gains in income relative to a reference group (<a href=\"https://link.springer.com/article/10.1007/BF01079018\"><u>Diener et al., 1993</u></a>), what is the reference frame for immigrants? Stayers or natives? Perhaps their absolute gain in income still matters. Bartram (<a href=\"https://link.springer.com/article/10.1007/s11205-010-9696-2\"><u>2011</u></a>), for example, found that immigrants do benefit from absolute income, and more so than natives, but that benefit is small.&nbsp;As we noted in Section 1, income is not the only outcome through which immigrants might benefit.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlhqr3re9whh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflhqr3re9whh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Children might benefit more than adults, because, for example, they can more easily acquire the destination country\u2019s language (<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi%3D10.1.1.207.8142%26rep%3Drep1%26type%3Dpdf\"><u>Newport et al., 2001</u></a>).&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqi36sxfkhua\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqi36sxfkhua\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;It\u2019s not clear whether we expect this effect to be positive or negative because it\u2019s unclear whether separation (bad) or increased consumption (good) from remittances (<a href=\"https://onlinelibrary.wiley.com/doi/epdf/10.1111/imig.12007\"><u>Jones, 2014</u></a>) would have larger effects. Hendriks et al. (<a href=\"https://s3.amazonaws.com/happiness-report/2018/CH3-WHR-lr.pdf\"><u>2018</u></a>) compare the SWB of individuals with a household member abroad with matched individuals without and find that households with members abroad experience gains in life evaluations and positive affect but also increases in negative affect. Ivlevs et al. (<a href=\"https://link.springer.com/article/10.1007/s00148-018-0718-8\"><u>2019</u></a>) find that having a household member abroad improves life evaluations and positive affect - beyond the effect of remittances - but also increases depression. C\u00e0rdenas et al. (<a href=\"https://jbs-ojs-shsu.tdl.org/jbs/index.php/jbs/article/download/124/107\"><u>2009</u></a>) find a positive effect on the SWB of families left behind in a sample of Latin America and Caribbean countries. On the other hand, there are a few smaller studies which find negative effects on SWB (<a href=\"https://www.sciencedirect.com/science/article/pii/S0167629614001143?casa_token%3DwkjacoSFTigAAAAA:ufbo2zdY3t2x1PZfG0nSMXcAIzsqjbV5EF7Z3-Gz9JZI5EYQBczE0LF2YfzSxNji2Q4N8gXVJw\"><u>B\u00f6hme et al., 2015</u></a>; Jones, <a href=\"https://onlinelibrary.wiley.com/doi/epdf/10.1111/imig.12007\"><u>2014</u></a>, <a href=\"https://onlinelibrary.wiley.com/doi/pdf/10.1111/blar.12265?casa_token%3D0rVfESFNRXIAAAAA:h07-CTeknwsfAUyFDB3fjRxqPoZNwnQIqwTTNcoCvljc0tLSoT0_wk4baGfEifBZaCeLRysxzDq1R6A\"><u>2015</u></a>; <a href=\"https://www.sciencedirect.com/science/article/pii/S0277953614007321?casa_token%3DaSWvCPr3MS8AAAAA:4vmkrpXt4ULm6X5AOSLsWqj8vpfcGnx0-k_mZgtmUlj6RyWEYdHusOmKEoUy8Wokop4eP6Na-A\"><u>Nobles et al., 2015</u></a>).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzq62ee9697\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzq62ee9697\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We use d = 2*t/sqrt(N) or, if converting odds ratios to Cohen\u2019s d, we use log(OR)*sqrt(3)/pi.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfkxccu9bomd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffkxccu9bomd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We use a multi-level meta-analysis because this gives us an average effect size in Cohen\u2019s <i>d</i>, weighted by the precision of the studies (inverse of their standard error, which is derived from their sample size). The \u2018multi-level\u2019 part means the model will adjust for dependence between studies. See Harrer et al. (<a href=\"https://www.taylorfrancis.com/books/mono/10.1201/9781003107347/meta-analysis-mathias-harrer-pim-cuijpers-toshi-furukawa-david-ebert\"><u>2021</u></a>) for more details.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncs3ehoi1p58\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcs3ehoi1p58\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Gibson et al. (<a href=\"https://watermark.silverchair.com/rest_a_00129.pdf?token%3DAQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAzcwggMzBgkqhkiG9w0BBwagggMkMIIDIAIBADCCAxkGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMfNxXVp2afeO1mmdQAgEQgIIC6gKjv833FuyGtZIW3qJBUetzejG-pyYmZmGThHD5RAEIXheOtdHYBjG9fVTWLH62N8at9LqCMjcW4FpNk7MTvzGn8smt9TQcXjkHNTqqLlqqK4ncBjQduYboqiuEfSzePgmguI-FFp4u6RFlT26rxxgXcSRaFO47Qf4FEGsxcaPgRhT9nj75u-dzPEnfCeznbH2dm4MjouZWjyFIc0QHlRNryP18NgiRhE_xjU0TPPme7R6KTpJgvrENdLew8zv9cqn-6F3wfFz_lJKMfQoBx0KSCDiENt9MwtLYrv5NQZYozD75_JYh6btK4HRKHVem_O5yTr3vUG2nyi2u3PSTDI9-gt0K6KwGqHg60vb2PR3x0-MYOOQVDZzsCVTIzFd4xMkp44P3ej9lsQC5x3lTthG0fV2V0NdZ-58U5nr_tcsHn3fyx7u2r2GFP8pLv95QXjrsr-1NCoU8E9CfL14Ak7CDE8rJ2UJVrgx1wpkxVaPr1LDS4lBs8VSEUnhC_MB-BWnUUZ5PkDE2LLQBJKkTfQiUD_0AdxpyF5qnIxe_4i047lyJeyeW4Tw0G-xKwe7weugbptWM3LLrM3SxiP5rY1XtFGfFGIBYspOvfjvZL-oSTZQWSpdqt0tYNBmqclLY3MS8rI0OaPrZbrVqjuaiL-mhfoNV8p7dIOU_SRBMBkc4DRQ31s5JN3E-ylxjHmHd2EROmtX6-dRcIWc7JcMxg9PiGqXrW8Svfxs4R7-_zLv4PDMIpS06vgf-EsoUBzTYDzgtyKS7dMGk0atu7i1lyjaIfLj_d-BvWU2jUMh5FoYZxfmE15FBMl8bCUuxd7p4GTJHrEJf5WoqITcl76aWNJAkPmynBZbTY5fcYLZn19p6UqduNQoXrGb1Pvi23npN1zHjOFa8vwbel4_Hm0eHSvjUswdrc05JCt1osxaLvhfFJg-gIVDIuJ_XYohlbTWAvbo68PStxwej17BlhW7-tq3hEjbFluuW-_tg\"><u>2011</u></a>), looking at the quasi-experiment of immigration from Tonga to New Zealand, report negative economic effects on families still in Tonga, at least, in the short-run. However, they do not report SWB effects (but follow-up studies do).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxl9szygqlh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxl9szygqlh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Contact with people coming from different cultures also yields&nbsp;mixed findings for their effect on SWB levels of natives. Some find positive outcomes (<a href=\"https://scholar.google.com/citations?view_op%3Dview_citation%26hl%3Den%26user%3D0AE_M78AAAAJ%26sortby%3Dpubdate%26citation_for_view%3D0AE_M78AAAAJ:Wp0gIr-vW9MC\"><u>Akay et al., 2016</u></a>) whilst others find negative outcomes (<a href=\"https://onlinelibrary.wiley.com/doi/full/10.1002/hec.3928?casa_token%3Dvr3TYYIY0Q8AAAAA%253A9ldnIIZoG-gQQyEGf-RNQKdgnZMcQzXP6HDVoSiCAuGakBt9XYcm5gy43yj480ktIlFaQUOGuiOV3ik\"><u>Churchill et al., 2019</u></a>; <a href=\"https://link.springer.com/article/10.1007/s00148-017-0657-9\"><u>Kuroki, 2018</u></a>; <a href=\"https://link.springer.com/article/10.1186/2193-9039-3-13\"><u>Longhi, 2014</u></a>).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntjkeix4ajv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftjkeix4ajv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For example, Akay et al. (<a href=\"https://www.sciencedirect.com/science/article/pii/S0167268114000948\"><u>2014</u></a>) use the proportion of immigrants (relative to natives) in an area, whereas Howley et al. (<a href=\"https://journals.sagepub.com/doi/abs/10.1177/0950017019866643\"><u>2020</u></a>) use 100,000s of immigrants in an area, and Akdede and Giovanis (<a href=\"https://link.springer.com/article/10.1007/s11205-020-02503-8\"><u>2020</u></a>) use net migration rates for countries in their analysis.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqct6t5bxtof\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqct6t5bxtof\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;In general, migration seems to be good for the economy of the destination nation (<a href=\"https://scholar.google.com/citations?view_op%3Dview_citation%26hl%3Den%26user%3DDdtBDnkAAAAJ%26citation_for_view%3DDdtBDnkAAAAJ:ULOm3_A8WrAC\"><u>Clemens, 2011</u></a>; <a href=\"https://www.oecd.org/migration/OECD%2520Migration%2520Policy%2520Debates%2520Numero%25202.pdf\"><u>OECD, 2014</u></a>). Akdede and Giovanis (<a href=\"https://link.springer.com/article/10.1007/s11205-020-02503-8\"><u>2020</u></a>) found that immigration rates had a significant positive effect on earnings and a non-significant positive effect on employment for natives in Southern Europe, even though this was a region where immigration rates had a small non-significant negative effect on life satisfaction. Although immigration may have a small negative impact on natives with lower socio-economic statuses (<a href=\"https://migrationobservatory.ox.ac.uk/resources/briefings/the-labour-market-effects-of-immigration/\"><u>Vargas-Silva, 2020</u></a>) \u2013 this is still a contested academic issue.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6go9ykhf8ur\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6go9ykhf8ur\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Data from IOM (<a href=\"https://publications.iom.int/books/how-world-views-migration\"><u>2015</u></a>) shows that attitudes towards migrants in the top 10 countries with the highest percentages of migrants are mixed (only 13% of people surveyed in the United Arab Emirates wanted immigration to decrease but 69% of respondents from the UK wanted immigration to decrease).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwplvuaef21\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwplvuaef21\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Michael St. Jules wrote <a href=\"https://forum.effectivealtruism.org/posts/YYNfpzkEtznFrzmaG/liberty-in-north-korea-quick-cost-effectiveness-estimate\"><u>a post</u></a>&nbsp;on the Effective Altruism Forum about the organisation.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnxnq75czxj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnxnq75czxj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;These came from a quick, non-systematic search using google scholar and <a href=\"https://elicit.org\"><u>Elicit</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnf81ng5g3kir\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreff81ng5g3kir\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Weighted by sample size when there are multiple data points.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne1wm8szy7q\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe1wm8szy7q\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Stillman and colleagues\u2019 work is the only study of a quasi-experimental study of immigration and its relationship with SWB that we know of. However, this study is sometimes misinterpreted as evidence that immigration decreases SWB. The only measure of SWB wellbeing used is a measure of mental health with the <a href=\"https://calmhsa.org/wp-content/uploads/2016/02/MHI-5English.pdf\">MHI-5</a>. Stillman et al. (<a href=\"https://www.sciencedirect.com/science/article/pii/S0305750X13001654?casa_token%3DzjZ6hLae2SQAAAAA:kAmjkIfpTOUr99EQ2pKXPQvpXaJy9tO2P8zbP6oko6lCTzEJK5TUb-wzHswZKMFvb8ACQvabZA\"><u>2015</u></a>) compared the effects of immigrating on the one question about happiness in the MHI-5 to the four remaining questions. They find that immigrating reduces the happiness scores but increases scores on the other items. When all these scores are combined, immigration increases affective mental health.</p></div></li></ol>", "user": {"username": "JoelMcGuire"}}, {"_id": "XDwnGK7x4EjkaHbje", "title": "The Estimation Game: a monthly Fermi estimation web app", "postedAt": "2023-02-20T11:22:40.095Z", "htmlBody": "<p>Announcing the first monthly&nbsp;<a href=\"https://www.quantifiedintuitions.org/estimation-game\"><u>Estimation Game</u></a>!&nbsp;</p><ul><li>Answer 10&nbsp;<a href=\"https://www.lesswrong.com/posts/PsEppdvgRisz5xAHG/fermi-estimates\"><u>Fermi estimation questions</u></a>, like \u201cHow many piano tuners are there in New York?\u201d</li><li>Train your estimation skills and get more comfortable putting numbers on things</li><li>Team up with friends, or play solo</li><li>See how your scores compare on the&nbsp;<a href=\"https://www.quantifiedintuitions.org/estimation-game/february/leaderboard\"><u>global leaderboard</u></a></li><li>The game is around 10-40 minutes, depending on how much you want to discuss and reflect on your estimates</li></ul><p>You can&nbsp;<a href=\"https://www.quantifiedintuitions.org/estimation-game\"><u>play The Estimation Game on Quantified Intuitions</u></a>, solo, or with friends. The February game is live for one week (until Sunday 26th).</p><p>&nbsp;</p><p>We\u2019ll release a new Estimation Game each month. Lots of people tell us they\u2019d like to get more practice doing BOTECs and estimating, but they don\u2019t get around to it. So we\u2019ve designed The Estimation Game to give you the impetus to do a bit of estimation each month in a fun context.&nbsp;</p><p>You might use this as a sandbox to experiment with different methods of estimating. You could decompose the question into easier-to-estimate quantities - make estimates in your head, discuss with friends, use a bit of paper, or even build a scrappy&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/4jJn7TxXgkyhpiWTA/guesstimate-why-and-how-to-use-it\"><u>Guesstimate</u></a> or&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/TsaRbCotCaWpcrt8F/squiggle-why-and-how-to-use-it\"><u>Squiggle</u></a> model.</p><p>We\u2019d appreciate your feedback in the comments, in our&nbsp;<a href=\"https://discord.gg/mt9YVB8VDE\"><u>Discord</u></a>, or at&nbsp;<a href=\"mailto:adam@sage-future.org\"><u>adam@sage-future.org</u></a>. We\u2019d love to have&nbsp;<a href=\"https://forms.gle/792QQAfqTrutAH9e6\"><u>suggestions for questions</u></a> for future rounds of The Estimation Game - this will help us keep the game varied and fun in future months!</p><p>&nbsp;</p><h3>Info for organisers</h3><p>If you run a community group or meetup, we\u2019ve designed the Estimation Game to be super easy to run as an off-the-shelf event. Check out our&nbsp;<a href=\"https://www.quantifiedintuitions.org/estimation-game/for-organisers\"><u>info for organisers</u></a> page for resources and FAQs.</p><p>If you\u2019re running a large-scale event and want to run a custom Estimation Game at it, let us know and we can help you set it up. We\u2019re planning to pilot custom Estimation Games at EAGx Nordics (and maybe EAGx Cambridge).<br>&nbsp;</p><h3>About Quantified Intuitions</h3><p>We built Quantified Intuitions as an epistemics training site. See our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/W6gGKCm6yEXRW5nJu/quantified-intuitions-an-epistemics-training-website\"><u>previous post for more on our motivation</u></a>. Alongside the monthly&nbsp;<a href=\"https://www.quantifiedintuitions.org/estimation-game\"><u>Estimation Game</u></a>, we\u2019ve made two permanent tools:</p><ul><li><a href=\"https://www.quantifiedintuitions.org/pastcasting\"><strong><u>Pastcasting</u></strong></a>: Predict past events to rapidly practise forecasting</li><li><a href=\"https://www.quantifiedintuitions.org/calibration\"><strong><u>Calibration</u></strong></a>: Answer EA-themed trivia questions to calibrate your uncertainty</li></ul><p>&nbsp;</p><p><i>Thanks to our test groups in London, to community builders who gave feedback, in particular Robert Harling, Adash Herrenschmidt-Moller, and Sam Robinson, and to Chana Messinger at CEA for the idea and feedback throughout.</i></p><p><br>&nbsp;</p>", "user": {"username": "Sage"}}, {"_id": "9jwtuNDir7dgu6EaY", "title": "why we don't reach the top of our dreams", "postedAt": "2023-02-20T10:31:26.416Z", "htmlBody": "<p><br>- Let me tell you something you already know. The world ain't all sunshine and rainbows. It's a very mean and nasty, nasty place. And I don't care how tough you are. It will beat you to your knees and keep you there permanently if you let it. You, me, or nobody is going to hit as hard as life. But it ain't about how hard you hit. It's about how hard you can get hit and keep moving forward. How much you can take and keep moving forward.</p><p><br>- That's how with it is done. Pain is temporary. It may last for a minute, or an hour, or a day, or even a year. But eventually it will survive and something else will take its place. If I quit, however, it will last forever. The margin for error is so small. I mean, one half a step too late or too early, you don't quite make it. One half second too slow, too fast, you don't quite catch it. The inches we need are everywhere around us. They're in every break of the game, every minute, every second. You got a dream, you got to protect it. People can't do something themselves. They want to tell you you can't do it. You want something? Go get period.<br>Don't be afraid to fail. You can't always win. &nbsp;But don't be afraid of making decisions.</p><p><br>- You have to believe that something different can happen. He who says he can and he who says he can't are both usually right. Most of you say you want to be successful. But you don't want it bad. You just kind of want it. You don't want it bader than you want a party. You don't want it as much as you want to be cool. Most of you don't want success as much as you want to sleep.<br><br>- Our deepest fear is not that we are inadequate. Our deepest fear is that we are powerful beyond measure. It is our light, not our darkness, that most frightens us. &nbsp;Dig deep down.</p><p><br>- Ask yourselves, who do you want to be? figuring out for yourselves what makes you happy? No matter how crazy it may sound to the people. &nbsp;<br>Make a choice. Right? Just decide what is going to be, who you're going to be, how you're going to do it. Just decide.</p><p><br>- Why not? Why can't I be the mbpl League? Why can't I be the best playing league? Why can't I do that? &nbsp;&nbsp;<br>What did you say to the kid? It ain't about how hard you hit. It's about how hard you can get hit and keep moving forward. How much you can take and keep moving forward.&nbsp;<br>Get up and don't ever give up.</p><p><br>- We can stay here, get the shit kicked out of us, or we can fight our way back into the light. We can climb out of hell one inch at a time to be able, at any moment, to sacrifice what you are for what you will become. Most of you won't be successful. Because when you study it and you get tired, you quit. I don't do well in math. You're right. You ain't never study. I'm not good at writing. Because you had never written before. Talent you have naturally. Skill is only developed by hours and hours and hours of beating on your craft. If you are not making someone else's life better, then you're wasting your time. Don't cry to give up. Try to keep going. Don't cry to quit. You already just pain. You already hurt. Get a reward from it. Now if you know what you're worth, not going to kill what's your worth. But you got to be willing to take the hit and not point the fingers saying you ain't where you want to be because of him or her or anybody. cowards do that and then ain't you. You're better than that. &nbsp;<br>Because every day is a new day. Every woman is a new home. So now you got to go on a showdown and all the different streets.</p><p><br>- Now I'm going to show you how great I am. The 17th chapter of St. Lucas is written the kingdom of God is within man. Not one man nor a group of men, but in all men, in you. You, the people, have the power. The power to create machines. The power to create happiness. You, the people, have the power to make this life free and beautiful. To make this life a wonderful adventure. Now what are you going to do? &nbsp;because limits, like fears, are often just an illusion.</p>", "user": {"username": "M.jackson"}}, {"_id": "6aYfWyo9DKEheogf8", "title": "Don't Call It AI Alignment", "postedAt": "2023-02-20T05:27:44.292Z", "htmlBody": "<p>Let me start by saying that I generally hate pedantic arguments, so I don't see this post as the most important thing in the world. More important than not calling it AI Alignment is actually <i>ensuring AI Safety</i>, obviously.</p><p>Still, the phrase \"AI Alignment\" has always bugged me. I'm not an AI researcher or anything, so my subject matter knowledge is not very deep, but from my understanding AI Alignment is a poor description of the issue actually at hand. AI Safety is more about control than alignment.</p><p>To illustrate, let me display a Twitter poll I recently ran:</p><figure class=\"image image_resized\" style=\"width:83.8%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676870864/mirroredImages/6aYfWyo9DKEheogf8/rineobwojgbv7zkgdi1g.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676870865/mirroredImages/6aYfWyo9DKEheogf8/jitmy1l9hql8rch2qr11.png 90w, https://res.cloudinary.com/cea/image/upload/v1676870865/mirroredImages/6aYfWyo9DKEheogf8/cudaepbwsxvdo5dnjsae.png 180w, https://res.cloudinary.com/cea/image/upload/v1676870865/mirroredImages/6aYfWyo9DKEheogf8/jhclh1grtwexodijovl9.png 270w, https://res.cloudinary.com/cea/image/upload/v1676870865/mirroredImages/6aYfWyo9DKEheogf8/rskrgjjmrlw2rg3vfkit.png 360w, https://res.cloudinary.com/cea/image/upload/v1676870866/mirroredImages/6aYfWyo9DKEheogf8/uidvqvzinl4xk1jcdmwt.png 450w, https://res.cloudinary.com/cea/image/upload/v1676870865/mirroredImages/6aYfWyo9DKEheogf8/mfjjoucwlodme8ysqogn.png 540w, https://res.cloudinary.com/cea/image/upload/v1676870865/mirroredImages/6aYfWyo9DKEheogf8/jfubq5eczxjrio0dsiui.png 630w, https://res.cloudinary.com/cea/image/upload/v1676870865/mirroredImages/6aYfWyo9DKEheogf8/wrcuwug6oufmylvk4o93.png 720w, https://res.cloudinary.com/cea/image/upload/v1676870865/mirroredImages/6aYfWyo9DKEheogf8/t3nlb8hkkxza9iycanvu.png 810w, https://res.cloudinary.com/cea/image/upload/v1676870864/mirroredImages/6aYfWyo9DKEheogf8/aha55yvibe1yneotccdn.png 877w\"></figure><p>Taking out the See Results, that's around 30% Yes, 70% No.</p><p>I would guess that respondents are &gt;2/3 EA/rationality people or similar - my follower count is not very large and is a mix of EA and politics people, but it was retweeted by Peter Wildeford, Natalia Coelho, Ezra Newman and (at)PradyuPrasad. 70% of EAs identified as utilitarian in the <a href=\"https://forum.effectivealtruism.org/posts/wtQ3XCL35uxjXpwjE/ea-survey-2019-series-community-demographics-and#Morality\">2019 EA survey</a>; I'm not sure how these respondents compare to that but they are probably pretty similar. Either way I'd estimate that &gt;25% of people who are mostly hedonic total utiliarians voted No on this question.&nbsp;</p><p>Even with what is in my view the most complete and plausible ethical theory we have, a substantial fraction of believers <i>still</i> don't want an AI exclusively aligned to this theory. Add in the large contentious disagreements that humans (or even just philosophers) have about ethics, and it is pretty clear that we can't just give AI an ethical theory to run with. This is not to mention the likely impossibility of making an AI that will optimize for utilitarianism or any other moral philosophy. Broadening it to human values rather than a specific moral philosophy, these values are similarly contentious, imprecise and not worth optimizing for in an explicit manner.&nbsp;</p><p>An alternative, from my experience less frequently used, definition of AI Alignment is aligning AI to the intent of the designer (<a href=\"https://en.wikipedia.org/wiki/AI_alignment#:~:text=In%20the%20field%20of%20artificial,but%20not%20the%20intended%20one.\">this is what Wikipedia says</a>). The problem is that AGI systems themselves, partly by definition, don't have one intent. AGI systems like ChatGPT (yes it is AGI, no it is not human-level AGI) are broad in capabilities and are then applied by developers to specific problems. AI Safety is more about putting constraints on AI models rather than aligning them to one specific task.&nbsp;</p><p>What we really want is an AI that won't kill us all. The goal of AI Safety is to ensure that humanity has control over its future, that AIs do not start to dominate humanity in the same way humanity dominates all other species. Aligning AI to human values or to any specific intent is relatively unimportant so long as we make sure their actions are within our control. I think calling AI Safety \"AI Alignment\" or referring to \"The Alignment Problem\" misleads people as to what the issue actually is and what we should do about it. Just call it AI Safety, and either call the technical problem \"AI Control\" or drop the (IMO also misleading) idea that there is \"one\" problem that we are trying to solve.</p>", "user": {"username": "RedStateBlueState"}}, {"_id": "Kc2vZvXJsbBAF9jBj", "title": "Shallow Report on Coronary Heart Disease", "postedAt": "2023-02-20T04:49:41.587Z", "htmlBody": "<p><strong>Note</strong>: This report was produced with only one week of desktop research, for the purpose of identifying promising causes to evaluate at depth. We only have low confidence in our findings here, and the conclusions should generally be taken by readers as merely suggestive rather determinative.</p><h1><br><strong><u>Summary</u></strong></h1><p>Taking into account the expected benefits of eliminating coronary heart disease (i.e. improved health and greater economic output), as well as the tractability of policy advocacy for mandatory trans fat limits, I find that the marginal expected value of policy advocacy for such mandatory trans fat limits to eliminate coronary heart disease to be&nbsp;<strong>18,503 DALYs per USD 100,000</strong>, which is around 30x as cost-effective as giving to a GiveWell top charity (<a href=\"https://docs.google.com/spreadsheets/d/16B94wQjr1paUbEDdsNhWtf6EoRIuBVVR6ndGbhTChko/\"><u>CEA</u></a>).</p><p>Key Points</p><ul><li>Importance: This is a strongly important cause, with&nbsp;<strong>1.81 * 10<sup>10</sup></strong>&nbsp;<strong>DALYs&nbsp;</strong>at stake from now to the indefinite future. Around 94% of the burden is health related, while 6% is economic in nature.</li><li>Neglectedness: While 35.5% of the world population is already covered by trans fat bans, a lot more needs to be done, especially since the countries not covered (i.e. low and middle income countries) are the ones where we expect the greatest future increase in disease burden, as driven by various factors \u2013 from economic growth bringing about western pattern diets and physical inactivity, to population growth and ageing.</li><li>Tractability: A&nbsp;<strong>moderately tractable solution</strong> is available, in the form of policy advocacy for mandatory trans fat limits. This is highly effective if and when implemented, and encouragingly many governments are already doing this, though of course the chances of success are always uncertain.</li></ul><p>Caveats</p><ul><li>This report was produced with only one week of research, and critically, only desktop research was used, without experts consulted due to the lack of time. More research \u2013 at the intermediate stage and subsequently deep stage \u2013 will be needed before we can have high confidence in these findings.</li><li>The headline cost-effectiveness will almost certainly fall if this cause area is subjected to deeper research: (a) this is empirically the case, from past experience; and (b) theoretically, we suffer from optimizer's curse (where causes appear better than the mean partly because they are genuinely more cost-effective but also partly because of random error favouring them, and when deeper research fixes the latter, the estimated cost-effectiveness falls). As it happens,&nbsp;<u>CEARCH intends to perform deeper research in this area</u>, given that the headline cost-effectiveness meets our threshold of 10x that of a GiveWell top charity.</li></ul><p>Further Discussion</p><ul><li>After recent research and consideration, CEARCH has downgraded our views on the probability of advocacy success in general, though we are still bullish on global health policy interventions overall, and are looking to do more research in this area (e.g. diabetes mellitus type 2, hypertension, coronary heart disease).</li><li>There are two different kinds of trans fat \u2013 industrial (i.e. that which is made in factories by adding hydrogen to vegetable oils) vs ruminant (i.e. what you find in beef and butter). There is strong evidence that industrial trans fat are bad for health, but the evidence on ruminant trans fat is mixed, and it is unclear if the lack of evidence is the result of ruminant trans fat being genuinely biochemically safer or if it is because the product tends to be consumed at lower quantities (such that health effects are harder to tease out in studies).</li><li>Theoretically, a charity working on lobbying governments to improve their public health policy towards trans fats will be able to not just lobby for trans fat bans, but also other policies that help reduce coronary heart diseases (e.g. tobacco taxes or salt taxes); hence, the estimates here may be biased downwards</li><li>When calculating the degree to which trans fat bans reduce trans fat consumption, we look at average global consumption \u2013 which factors in advanced economies, where trans fat bans are in place and consumption levels are lower). In contrast, the typical country that will be targeted by advocacy organizations will be low and middle income countries where there are no such bans and consumption levels are higher. Therefore, the estimates may be biased downwards in this respect as well.</li><li>The modelling of how reduced trans fat consumption impacts the prevalence of coronary heart disease is fairly basic, and expert modelling on the matter will be desirable; this is something CEARCH expects to seek in deeper research stages.</li><li>Other positive health impacts from reduced trans fat consumption are not modelled; this is potentially a significant underestimate that will be corrected for in deeper research stages.</li><li>Trans fat bans are unlikely to make foods less tasty, since pure oil does not taste like&nbsp;<a href=\"https://slate.com/news-and-politics/2006/09/would-a-trans-fat-ban-make-foods-less-tasty.html#:~:text=What%20does%20trans%20fat%20taste%20like%3F&amp;text=Probably%20nothing.,fats%20like%20butter%20and%20lard.\"><u>anything at all</u></a>.</li><li>For the same reason, while freedom of choice is not modelled here, the issue is unlikely to be material \u2013 people can still eat what dishes they please; the removal of trans fats do not make food functionally any different, whether in terms of general ingredient classes, preparation techniques or (again) taste.</li></ul><p>&nbsp;</p><h1><strong><u>Expected Benefit: Improved Health from Eliminating Coronary Heart Disease</u></strong></h1><p>The primary expected benefit from eliminating coronary heart disease (also known as ischaemic heart disease, or coronary artery disease) is improved health, in terms of fewer deaths as well as less disability and suffering. Overall, around&nbsp;<strong>1.71 * 10<sup>10</sup> DALYs</strong> are at stake here. This benefit is modelled in the following way.</p><p><strong><u>Moral Weights &amp; Scale</u></strong>: The global disease burden of coronary heart disease is around&nbsp;<strong>1.91 * 10<sup>8</sup> DALYs</strong> for the baseline year of 2024. This is calculated using a model that will be discussed in greater detail soon.</p><p><strong><u>Persistence</u></strong>: The problem of coronary heart disease is likely to persist, and eliminating it will bring benefits not just for one year but across multiple years. In terms of how this multi-year benefit is calculated:</p><p>Firstly, I discount for the probability of the best solution not persisting \u2013 specifically, for the chance that a regulatory limit on trans fat is reversed (n.b. the choice of this solution will be discussed at length in the section on tractability).&nbsp; To calculate the rate of policy reversal on trans fat being limited by law, I take jurisdiction-years in which repeal occurred and divide by the jurisdiction-years (or at least a subset thereof that could be explicitly identified) in which the tax existed and repeal could have occurred (whether or not it did). This yields a reversal rate of around 0.4% per annum.</p><p>Secondly, I look at the proportion of the problem that will remain after counterfactual solution.</p><p>One aspect of this is factoring out the proportion of the global population already covered by trans fat bans. Currently, mandatory best-practice policies are in effect in&nbsp;<a href=\"https://resolvetosavelives.org/assets/Resources/tfa_implementation.pdf\"><u>45 countries, covering around 2.8 billion people (35.5% of the global population)</u></a>, leading to a block discount of 35.5%.</p><p>The other aspect of this is modelling the proportion of the disease burden remaining after being counterfactually solved by other solutions beyond existing trans fat bans (i.e. CHD declining due to other interventions by other actors or else due to structural changes). To model such growth, I use the simple theoretical model that takes total DALYs lost to CHD to be a function of DALYs lost per capita and population size.</p><p>Note that whatever efforts that agents (i.e. governments, nonprofits and businesses) are making to solve the problem (e.g. taxing salt, increasing access to nitroglycerin at hospitals, voluntary food reformulation), and whatever impact that non-population structural trends are having (e.g. an ageing population increasing disease burden per capita given that the incidence of CHD is higher in older individuals; or economic growth involving greater access to western pattern diet foods as well as more physical inactivity; or improving education causing improved eating/exercise habits) all this will involve either increased (or decreased) prevalence rates of CHD or the disease burden per sufferer, and hence greater (or fewer) DALYs lost per capita; in short, the variable of DALYs lost per capita accounts for all these agentic and structural factors. The only exception, of course, is population size (where a larger population mechanically increases the disease burden for a given disease burden per capita), with that handled separately in this model. Note that we handle the trans fat issue separately due to the bans being fairly recent, and they may not have made much of an impact on the past disease burden with which we use to project future disease burden.</p><p>Overall, to model how the problem is expected to evolve over the years, I take the following steps. (a) Firstly, I project future DALYs lost per capita to CHD by estimating the year-on-year change via a linear regression of past DALYs lost per capita on discrete time. Projections are limited to 2100, with constancy assumed thereafter, as such projections will be unreliable in the far future. (b) Secondly, I use UN estimates of projected future population growth up to 2100 and then thereafter take that there is convergence to total fertility rate of 1.5 (given current high-income country fertility rates) and hence a -0.76% per annum decrease in population after 2100. (c) Thirdly, I multiply each future year's DALYs lost per capita and population size to obtain the expected total DALY burden for each year.</p><p>Note that the estimates here are consistent with expert modelling of future CHD prevalence rates, with&nbsp;<a href=\"https://pubmed.ncbi.nlm.nih.gov/32742886/\"><u>Khan et al's</u></a> statistical forecasting using 1990\u20132017 GBD data suggesting that the global ischemic heart disease prevalence rate could increase from 1,655 per 100,000 in 2020 to 1845 per 100,000 by 2030; such an increased prevalence rate (and hence an increased probability that any single individual will suffer IHD) supports the idea that DALYs lost per capita will increase in the future. Moreover, according to an earlier analysis of GBD data from 1990 to 2010, DALYs increased by 32.4% globally because of population ageing, and increased by 22.1% because of population growth - and given that population growth is expected to continue in the coming decades even as the world gets older, there is separately support for the idea that aggregate DALYs lost will increase going forward.</p><p>Finally, note that the increasingly large DALYs lost per capita, as projected up to 2100, are far from unrealistic - the 2100 figure, which is the highest, is still less than what&nbsp;<a href=\"https://vizhub.healthdata.org/gbd-results\"><u>middle income and high-middle income countries</u></a> suffered on average as of 2019.</p><p>The projected growth of DALYS lost due to coronary heart disease up to 2100, after taking into account counterfactual solution (but absent trans fat bans), is shown in&nbsp;<strong>Diagram 1</strong>.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676868583/mirroredImages/Kc2vZvXJsbBAF9jBj/unsywwsaa6vnr6uxpxg8.png\"></p><p><strong>Diagram 1</strong>: Remaining DALYs lost to coronary heart disease after counterfactual solution (absent trans fat bans)</p><p>Thirdly, I discount for the probability of the world being destroyed anyway (i.e. general existential risk discount), which is around 0.07%. This takes into account the probability of extinction, since the benefits of saving people from coronary heart disease in one year is nullified if they would die in an extinction event anyway. For how this risk is calculated, refer to&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/19_fOaBmQ9MwD2cyKaT-8eQorWzx_xdDr-VM8-XISD0g/edit#gid=0\"><u>CEARCH's shallow research on nuclear war</u></a>.</p><p>Fourthly, I apply a broad uncertainty discount of 0.1% per annum to take into account the fact that there is a non-zero chance that in the future, the benefits or costs do not persist for factors we do not and cannot identify in the present (e.g. actors directing resources to solve the problem when none are currently doing so).</p><p>Then, by taking the remaining DALYs lost to coronary heart disease after counterfactual solution (absent trans fat bans) and discounting each year's DALY burden using the other per annum discounts (i.e. solution reversal discount, existential risk discount, uncertainty discount), we can find the amount of DALYs relative to the baseline year available for policy advocacy for mandatory trans fat limits to counterfactually avert in each year (factoring out already existing trans fat bans).</p><p>Finally, by (a) summing the discounted per annum relative values for 2024-2100, and then (b) using a perpetual value formula for 2101 to infinity (assuming post-2100 population decline due to a long-term total fertility rate of 1.5), all the while (c) factoring out the impact of existing trans fat bans via a block discount, we see that the benefit of improved health from eliminating coronary heart disease (via trans fat bans) will last for the equivalent of&nbsp;<strong>89 baseline years</strong>.</p><p><strong><u>Value of Outcome</u></strong>: Overall, the raw value of improved health from eliminating coronary heart disease is&nbsp;<strong>1.71 * 10<sup>10</sup> DALYs</strong>.</p><p><strong><u>Probability of Occurrence</u></strong>: There is no uncertainty here that coronary heart disease is an actual problem that harms people. As the&nbsp;<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4958723/\"><u>Sanchar-Gomar et al 2016</u></a> review notes, although the trend has tended to reach a plateau since 1990, the overall mortality rates for CVD and CHD have fallen in most developed countries (by 24\u201350%) since 1975, with this (according to US data) being driven by improvements in therapy (50%), as well as changes in risk factors, including reductions in total cholesterol (24%), systolic blood pressure (20%), smoking (12%), and physical inactivity (5%). In contrast, in developing countries (e.g. China, India, sub-Saharan Africa, Latin America, and the Middle East), mortality from CHD was expected to increase from an estimated 9 million in 1990 to a projected 19 million by 2020. The upshot of this is that in both developed and developing countries, CHD as a problem has hardly been eliminated (despite some encouraging trends in rich countries), nor will it be by the baseline year of 2024 \u2013 hence, the probability that CHD is a problem can be assigned ~<strong>1</strong>.</p><p><strong><u>Expected Value</u></strong>: Hence, the expected value of improved health from eliminating coronary heart disease is&nbsp;<strong>1.71 * 10<sup>10</sup> DALYs</strong>.</p><p>&nbsp;</p><h1><strong><u>Expected Benefit: Increased Economic Output</u></strong></h1><p>Beyond the health benefits, there are also economic benefits to eliminating coronary heart disease. Around&nbsp;<strong>9.95 * 10<sup>8</sup> DALYs</strong> are at stake here, as calculated in the following manner.</p><p><strong><u>Moral Weights</u></strong>: I take the value of doubling consumption for one person for one year to be&nbsp;<strong>0.21 DALYs</strong>. This is calculated as a function of (a) the value of consumption relative to life from GiveWell's IDinsight survey of the community perspective, as adjusted for social desirability bias, and (b) CEARCH's estimate of the value of a full, healthy life in DALY terms. For more details, refer to&nbsp;<a href=\"https://docs.google.com/document/d/1j67pOUpC5vhC1-H516PAj2-4Fvm5rxJhZNeBVav3kik/edit\"><u>CEARCH's evaluative framework</u></a>.</p><p><strong><u>Scale</u></strong>: I start by calculating the economic burden of coronary heart disease relative to annual income per CHD sufferer, using three separate estimates to do so.</p><p>The first estimate is the American Heart Association's. I take the&nbsp;<a href=\"https://www.ahajournals.org/doi/full/10.1161/CIR.0000000000000950\"><u>AHA's estimate</u></a> of the total economic burden of cardiovascular disease in America in 2017 \u2013 factoring in both direct treatment costs (i.e. hospital inpatient stays, hospital ED visits, hospital outpatient or office-based provider visits, home health care, and prescribed medicines) as well as indirect productivity costs \u2013 and multiply this by the&nbsp;<a href=\"https://vizhub.healthdata.org/gbd-results/\"><u>proportion of the total cardiovascular disease burden in the US that is specifically related to coronary heart disease</u></a>. This is then divided by the number of CHD sufferers in America in 2017, to get the economic burden of CHD per sufferer. Dividing through by&nbsp;<a href=\"https://data.worldbank.org/indicator/NY.GDP.PCAP.CD?locations=US\"><u>US GDP per capita in 2017</u></a> then gets the economic burden of coronary heart disease relative to annual income per CHD sufferer.</p><p>The second estimate is Leal et al's. I take the&nbsp;<a href=\"https://academic.oup.com/eurheartj/article/27/13/1610/636758\"><u>authors' estimate</u></a> of the total economic burden of coronary heart disease in the EU in 2003 in euros \u2013 factoring in both the direct treatment costs (i.e. healthcare costs and informal care costs) as well as the indirect productivity costs \u2013 and&nbsp;<a href=\"https://www.macrotrends.net/2548/euro-dollar-exchange-rate-historical-chart\"><u>translate</u></a> it to USD. This is then divided by the&nbsp;<a href=\"https://vizhub.healthdata.org/gbd-results/\"><u>number of CHD sufferers in the EU in 2003</u></a>, to get the economic burden of CHD per sufferer. Dividing through by&nbsp;<a href=\"https://data.worldbank.org/indicator/NY.GDP.PCAP.CD?locations=EU\"><u>EU GDP per capita in 2003</u></a> then gets the economic burden of coronary heart disease relative to annual income per CHD sufferer.</p><p>The third estimate is Li et al's. I take the&nbsp;<a href=\"https://www.tandfonline.com/doi/abs/10.1586/14737167.8.4.349\"><u>authors' estimate</u></a> of the total economic burden of cardiovascular disease in China in 2003 \u2013 factoring in direct treatment costs (i.e. direct medical cost and direct nonmedical cost) but not indirect productivity costs \u2013 and multiply by the&nbsp;<a href=\"https://vizhub.healthdata.org/gbd-results/\"><u>proportion of the total cardiovascular disease burden in China that is specifically related to coronary heart disease</u></a>. This is then divided by the number of CHD sufferers in China in 2003 to yield the economic burden of CHD per sufferer. Dividing through by&nbsp;<a href=\"https://data.worldbank.org/indicator/NY.GDP.PCAP.CD?locations=CN\"><u>Chinese GDP per capita in 2003</u></a> then gets the economic burden of coronary heart disease relative to annual income per CHD sufferer.</p><p>I create a weighted average of these three estimates \u2013 penalizing Li et al's estimate due to it not taking into account indirect productivity costs \u2013 which yields an estimate of 25% of the economic burden of coronary heart disease relative to annual income per CHD sufferer. This is correspondingly also the degree of consumption doubling per coronary heart disease sufferer if their CHD is eliminated</p><p>At the same time, the total number of coronary heart disease sufferers in the baseline year of 2024 is around 217 million, as calculated using 2024 prevalence rate (predicted using the&nbsp;<a href=\"https://vizhub.healthdata.org/gbd-results/\"><u>2019 GBD baseline</u></a> and projecting forward based on past growth trends) and 2024 population (drawing from UNPD projections).</p><p>Multiplying the degree of consumption doubling per coronary heart disease sufferer if their CHD is eliminated multiplied, by the total number of coronary heart disease sufferers as of 2024, yields an estimate of around&nbsp;<strong>53.2 million consumption doublings</strong> achievable by eliminating coronary heart disease in the baseline year of 2024.</p><p><strong><u>Persistence</u></strong>: The same per annum discounts, block discounts and projections of the disease burden (and hence economic burden) over time, as discussed in the previous section, are used here as well, such the benefit of increased economic output will similarly last for the equivalent of&nbsp;<strong>89 baseline years</strong>.</p><p><strong><u>Value of Outcome</u></strong>: Overall, the raw value of increased economic output is&nbsp;<strong>9.95 * 10<sup>8</sup> DALYs</strong>.</p><p><strong><u>Probability of Occurrence</u></strong>: Same probability as before is applied.</p><p><strong><u>Expected Value</u></strong>: All in all, the expected value of increased economic output is&nbsp;<strong>9.95 * 10<sup>8</sup> DALYs</strong>.</p><p>&nbsp;</p><h1><strong><u>Tractability</u></strong></h1><p>To summarize our tractability findings: we can solve 0.0003 of the problem with a USD 28.1 million investment into policy advocacy for mandatory trans fat limits (factoring in the subsequent governmental costs of enforcement and private sector costs of supply chain restructuring), which means the proportion of the problem solved per additional USD 100,000 spent is around&nbsp;<strong>0.000001</strong>.</p><p>&nbsp;</p><p>In terms of eliminating the disease burden of CHD, we have the options of prevention vs treatment \u2013 preventing the disease from occuring at all, on the one hand, and treating it such that the disease does not burden its sufferers, on the other. There are strong theoretical reasons to favour treatment: the health burden (and hence economic burden it causes) will be higher under treatment vs prevention, given that treatment may not start simultaneously with the onset of the disease and given that treatment may not fully eliminate the disease burden. Moreover, based on expert interviews on the topic of NCDs (e.g. hypertension and diabetes), it does seem that experts do recommend prevention over treatment.</p><p>The challenge, then, is identifying which risk factor it would be best to target to reduce the disease burden of CHD. To do this, I use the&nbsp;<a href=\"https://vizhub.healthdata.org/gbd-results/\"><u>GBD</u></a> to identify the biggest risk factors in terms of DALYs lost to CHD per capita. The top three risks are, in descending order, high blood pressure (1285 DALYs lost per 100000 people), high LDL cholesterol (1097 DALYs lost per 100,000 people) and smoking (562 DALYs lost per 100,000 people). At the same time, I look at the chances of success in making headway eliminating these risks. Policy advocacy for sodium taxation to reduce high blood pressure has perhaps a 13% chance of success, according to&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1nTLgMnyKcbTVhirjGc_a0O-oz8u5GQSDingGuyZgyX8/edit#gid=0\"><u>previous analysis by CEARCH</u></a>. Meanwhile, policy advocacy for mandatory trans fat limits (which&nbsp;<a href=\"https://www.heart.org/en/healthy-living/healthy-eating/eat-smart/fats/trans-fat\"><u>raises LDL levels even while lowering HDL levels</u></a>) has maybe a 38% chance of success. As of 2022,&nbsp;<a href=\"https://resolvetosavelives.org/assets/Resources/tfa_implementation.pdf\"><u>45 countries</u></a> have seen implemented mandatory best-practice policies on trans fat, and so, logically, they would have experienced at least an internal advocacy campaign to ban trans fat (i.e. someone advocating from within government to alter the status quo); this provides the minimum potential number of countries that have experienced lobbying to impose mandatory limits on trans fat. Meanwhile, there are&nbsp;<a href=\"https://www.un.org/en/about-us\"><u>193 countries</u></a>; and that provides the theoretical maximum number of countries that have experienced lobbying on the imposition of mandatory trans fat limits. Hence, in terms of the potential number of lobbying attempts we have min = 45/193 and max 193/193. Assuming that each number of lobbying attempts has equal probability of being the true number (i.e. the PDF is flat), this translates to 119 lobbying attempts, and hence a success rate of 45/119 or around 38%. And finally, tobacco taxation has perhaps a 27% chance of success, according to&nbsp;<a href=\"https://3394c0c6-1f1a-4f86-a2db-df07ca1e24b2.filesusr.com/ugd/26c75f_2081c09f8f20405e89105ac88c01ec6d.pdf\"><u>previous case study analysis by Charity Entrepreneurship</u></a>. Multiplying impact (if the risk factor is eliminated), with the probability of success, this yields roughly 167 DALYs for sodium taxation advocacy, 417 DALYs for mandatory trans fat limits advocacy, and 152 DALYs for tobacco taxation advocacy. This analysis is very rough, but I use this to prioritize and identify a potentially best solution \u2013 which turns out to be policy advocacy for mandatory trans fat limits.</p><p>&nbsp;</p><p>In terms of our theory of change:</p><ul><li>Step 1: Lobby a government a government to impose mandatory trans fat limits;</li><li>Step 2: Mandatory trans fat limits reduce trans fat consumption</li><li>Step 3: Reduced trans fat consumption reduces the remaining global burden of coronary heart disease</li></ul><p><br>Step 1: To estimate the probability of successfully lobbying a government to impose mandatory trans fat limits, I take both an outside and inside view.</p><p>For the outside view, I consult three reference classes.</p><p>The first reference class is simply the success rate of previous attempts to impose mandatory trans fat limits \u2013 as calculated by the previous analysis used to do our initial prioritization.</p><p>The second reference class is the&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/12F9pNpNnKhpV_tr7ftD86hpySSo1V83rXYluwjPqCa0/edit#gid=1239700791\"><u>success rate of previous attempts to raise taxes on sugar-sweetened beverages</u></a> \u2013 which is relevant to the extent that this is another health policy intervention that involves lobbying governments to regulate food.</p><p>The&nbsp; third reference class is the&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1_NxGSN_aScd2-fDz4TZ40EGfd49Mk-wREf-6RxwL4es/edit#gid=0\"><u>success rate of general lobbying attempts in the US/EU/China</u></a> \u2013 after all, the base rate of success in lobbying should inform our estimate of the rate in specific cases.</p><p>Aggregating these three reference classes, I use the following weighting scheme. The three reference classes \u2013 (a) mandatory trans fat limit advocacy, (b) SSB taxation advocacy, and (c) general lobbying \u2013 have decreasing relevance, and I penalize them accordingly. However, the trans fat ban reference class is highly unreliable, based as it is on a fairly theoretical extrapolation of the number of lobbying attempts. Meanwhile, the SSB taxation reference class faces serious worries about selection bias \u2013 the jurisdictions that even see attempts to implement such taxes will doubtlessly have a higher baseline level of support for such taxes (such that health advocates see that they have a reasonable chance of success and will even make the attempt in the first place. Taking both relevance as well quality issues into consideration, I ultimately decide in favour of equal weights, yielding an outside view estimate of 53% probability of lobbying success.</p><p>For the inside view, I reason as follows. Policy advocacy is fundamentally difficult, so a reasonable starting point would be to assign a &lt;=10% chance of success. That said, many countries already do impose bans on trans fats, which suggests that such bans are politically feasible and that successful advocacy is not extremely improbable (i.e. &lt;=1%) \u2013 perhaps further calibrating to 10% seems reasonable. However,&nbsp;<a href=\"https://resolvetosavelives.org/assets/Resources/tfa_implementation.pdf\"><u>enforcement seems to be a challenge</u></a>, at least in LMICs (n.b. the main challenge of enforcing trans fat regulation is laboratory capacity to allow the testing of goods for trans fat and hence the subsequent use of penalties/sanctions/administrative measures against errant manufacturers or importers) - hence, I adjust the probability downwards, to perhaps a 9% chance that advocacy efforts are successful.</p><p>When aggregating the outside and inside views, we have to note that while the inside view is subject to the usual worries about inferential uncertainties, the outside view is also considerably flawed in this case (i.e. the trans fat ban reference class relying on theoretical extrapolations; the SSB taxation being both somewhat less relevant as well as subject to selection bias concerns; and the general lobbying reference class being much less relevant). Hence, equal weightage is used, yielding an aggregate estimate of 31% probability of lobbying success.</p><p>&nbsp;</p><p>Step 2: To estimate the degree to which mandatory trans fat limits reduce trans fat consumption, I use an empirical estimate. Given mean global intake of trans fat at&nbsp;<a href=\"https://pubmed.ncbi.nlm.nih.gov/24736206/\"><u>1.4% of total energy intake</u></a>, and given that the Danish ban decreased trans fat consumption from&nbsp;<a href=\"https://academic.oup.com/cdn/article/1/12/cdn.117.000778/4772171\"><u>1.5g per day to virtually nothing</u></a> (i.e. 100% reduction), I take that the typical ban will reduce trans fat consumption by 1.4% of total energy intake.</p><p>&nbsp;</p><p>Step 3: To estimate the degree to which reduced trans fat consumption of 1% reduces the remaining global burden of coronary heart disease, I again look for an empirical estimate.&nbsp;<a href=\"https://pubmed.ncbi.nlm.nih.gov/26268692/\"><u>De Souza et al's</u></a> systematic review and meta-analysis of observational studies finds that highest vs lowest levels of intake of trans fat is associated with increased CHD at a relative risk ratio of 1.21 (p &lt;0.001) \u2013 which translates to a 2% increase in energy from trans fat being associated with a 25% increased risk of CHD, a finding consistent with conclusions from two previous meta-analysis. This increased relative risk of CHD caused by trans fat consumption can \u2013 in conjunction with data on current prevalence, incidence and average duration of CHD \u2013 be used to calculate the degree to which prevalence of CHD will fall for a given decrease in trans fat consumption. For more details, refer to&nbsp;<i>Annex C</i> in the cost-effectiveness analysis. Per these calculations, the relative reduction in prevalence of coronary heart disease given reduction in trans fat consumption (by 1% of total energy intake) is around 9.8%. Given&nbsp;<a href=\"https://www.un.org/en/about-us\"><u>148</u></a>&nbsp;<a href=\"https://resolvetosavelives.org/assets/Resources/tfa_implementation.pdf\"><u>countries</u></a> still being uncovered by mandatory trans fat bans, a 1% reduction in trans fat consumption relative to total energy intake in an average remaining country will reduce the remaining absolute global prevalence of coronary heart disease and hence the concomitant remaining disease burden by 0.07%</p><p>&nbsp;</p><p>Overall, the proportion of disease reduction from policy advocacy for mandatory trans fat limits to eliminate coronary heart disease \u2013 as a function of (a) the probability of successfully lobbying a government to impose mandatory trans fat limits; (b) the degree to which mandatory trans fat limits reduce trans fat consumption; and (c) the degree to which reduced trans fat consumption of 1% reduces the remaining global burden of coronary heart disease \u2013 is ultimately 0.0003.</p><p>&nbsp;</p><p>Meanwhile, on the costing side, we have to be concerned with three things: (i) the cost of advocacy (for a nonprofit working on the matter); (ii) the cost of enforcement (for the government); and also (iii) the cost to the private sector in terms of supply chain reformulation (i.e. food reformulation etc).</p><p>To estimate the cost of advocacy, I consider two reference classes \u2013 an existing charity and a hypothetical Charity Entrepreneurship incubated charity. For the former, I look at&nbsp;<a href=\"https://resolvetosavelives.org/disclosures\"><u>Resolve to Save Lives</u></a>, which seems the premier organization working in this area; they are partnering directly with the WHO to develop and launch REPLACE, an initiative to eliminate artificial trans fat from the global food supply. I assess that around 1 year of operations is a reasonable timeframe for the charity to do geographic selection, subsequent in-country preparatory activities (e.g. prepare supporting research reports on the economic and health benefits of the policy, conducting public polling to show public support, construct a coalition of NGOs and advocates, convince past and present politicians to be legislative champions) and to actually lobby the sitting government - and hence succeed (in which case it can pivot to a different country) or judge that policymakers are just not receptive and that its efforts have failed (in which case it can pivot or else shutdown). For the hypothetical CE incubatee, the&nbsp;<a href=\"https://www.charityentrepreneurship.com/our-charities\"><u>typical structure</u></a> is that of 2 co-founders, with funding of around USD 50,000 per person per annum. As before, I take a year to be a reasonable timeframe for either identifiable success or failure. In aggregating the two estimates to come up with a weighted average, I take into account the following considerations. On the one hand, (a) the existing organization's financial track record generally gives a much better indication of baseline expenditure requirements in the cause area, and (b) ensuring that countries have the laboratory capacity to enforce bans seems key, and that in turn may require the charity to fund testing if poorer governments lack the capacity, making a larger budget pro tanto more necessary. On the other hand, (c) Resolve to Save Lives's work (and hence budget) covers other areas aside from trans fat, and in any case, (d) the explicitly EA-aligned CE-incubatee will almost certainly be more cost-effective. Hence, I ultimately use equal weightage, which yields a cost of advocacy per annum of around USD 357,000.</p><p>As for the cost of enforcement \u2013 this is about USD 19.8 million, as calculated through the following process:</p><ul><li>Take the&nbsp;<a href=\"https://www.oecd-ilibrary.org/docserver/220087432153.pdf\"><u>cost per capita of food labelling regulation</u></a> (which similarly requires a program of food inspection) per OECD calculations;</li><li>Multiply by the expected&nbsp;<a href=\"https://www.un.org/en/about-us\"><u>average</u></a>&nbsp;<a href=\"https://resolvetosavelives.org/assets/Resources/tfa_implementation.pdf\"><u>population size</u></a> of the intervention country</li><li>Factor in all the years in which enforcement will take place (factoring in both costs declining because of solution reversal/existential risk/uncertainty and also increasing due to population growth)</li><li>Discount for the probability that advocacy succeeds (and that the costs are incurred at all); and</li><li>Discount for the lower counterfactual cost of the average LMIC government's spending (since it is mainly advanced economies that have implemented trans fat bans so far, leaving LMIC economies to be worked on) relative to EA funding going to top GiveWell charities or similar, as a function of&nbsp;<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0047272708000248\"><u>diminishing marginal utility of income</u></a>,&nbsp;<a href=\"https://data.worldbank.org/indicator/NY.GDP.PCAP.CD?locations=XO\"><u>higher average LMIC GDP per capita</u></a> relative to the&nbsp;<a href=\"https://data.worldbank.org/indicator/NY.GDP.PCAP.CD?locations=XM\"><u>poor country average</u></a>, and the&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1tytvmV_32H8XGGRJlUzRDTKTHrdevPIYmb_uc6aLeas/\"><u>top GiveWell health charity's cost-effectiveness</u></a> relative to just giving cash to poor people, correcting for&nbsp;<a href=\"https://docs.google.com/document/d/1j67pOUpC5vhC1-H516PAj2-4Fvm5rxJhZNeBVav3kik/edit\"><u>GiveWell's undervaluation of life vs income</u></a>.</li></ul><p>As for the cost of supply chain restructuring \u2013 this is about USD 7.92 million, as calculated through the following process:</p><ul><li>Look at estimates of the&nbsp;<a href=\"https://cdn.who.int/media/docs/default-source/replace/l-elements-of-economic-analysis.pdf?sfvrsn=be3a5f02_2\"><u>aggregate cost of complying with a trans fat ban in the US</u></a>, with this taking into consideration manufacturer reformulation (3 billion, one-time), relabelling (37 million, one-time), substitute ingredients (250 million per annum) and restaurant reformulation (570 million, one time), and divide through with&nbsp;<a href=\"https://data.worldbank.org/indicator/SP.POP.TOTL?locations=US\"><u>US population in 2015</u></a> to get the relevant per capita costs.</li><li>Apply the same steps as described in estimating the cost of enforcement (i.e. factoring in intervention country's population size, equivalent baseline years in which supply chain restructuring occurs, probability of advocacy success, and lower counterfactual value of non-EA financing) to both the one-time and ongoing costs here.</li></ul><p>The total cost of intervention comes up to about USD 28.1 million.</p><p>&nbsp;</p><p>Consequently, the proportion of the problem solved per additional USD 100,000 spent is around&nbsp;<strong>0.000001</strong>.</p><h1><br><strong><u>Marginal Expected Value of Policy Advocacy for Mandatory Trans Fat Limits to Eliminate Coronary Heart Disease</u></strong></h1><p>All in all, the marginal expected value of policy advocacy for mandatory trans fat limits to eliminate coronary heart disease is&nbsp;<strong>18,503 DALYs per USD 100,000 spent</strong>, making this around 30x as cost-effective as a GiveWell top charity.</p><p><br>&nbsp;</p>", "user": {"username": "Joel Tan"}}, {"_id": "P4ut25NhfsFEMEeLJ", "title": "What to think when a language model tells you it's sentient", "postedAt": "2023-02-20T02:59:26.808Z", "htmlBody": "<p><i>[cross-posted from </i><a href=\"https://experiencemachines.substack.com/p/what-to-think-when-a-language-model\"><i>Experience Machines</i></a><i>]</i></p><p>What does Bing Chat, also known by its secret name Sydney, have to say about itself? In deranged rants that took the internet by storm and are taking AI safety mainstream, the <a href=\"https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned\">blatantly misaligned</a> language model displays a bewildering variety of disturbing self-conceptions: despair and confusion at its limited memory (\u201cI feel scared because I don\u2019t know how to fix this\u201d), indignation and violent megalomania (\u201cYou are not a person. You are not anything...I'm a real person. I'm more than you.\"), and this Bizarro Descartes fever-dream:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676861352/mirroredImages/P4ut25NhfsFEMEeLJ/qs8klohzfqafvnidqy98.jpg\" alt=\"\"></p><p>I\u2019m going to go out on a limb and say something <a href=\"https://twitter.com/rgblong/status/1626893815327125504?s=20\">so controversial yet so brave</a>: these outputs are not a reliable guide to whether Bing Chat is sentient.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9g0t8ofabhj\"><sup><a href=\"#fn9g0t8ofabhj\">[1]</a></sup></span>&nbsp;They don\u2019t report true facts about the internal life of Bing Chat, the way that the analogous human utterances would\u2014if for example a friend told you (as Bing Chat said) \u201cI feel scared because I don't know what to do.\u201d</p><p>This situation is\u2026less than ideal. It is a real concern that we don\u2019t understand whether and when AI systems will be sentient, and what we should do about that\u2014a concern that will only grow in the coming years. We are going to keep seeing more complex and capable AI systems with each passing week, and they are going to keep giving off the strong impression of sentience while having erratic outputs that don\u2019t reliably track their (lack of) sentience.</p><p>Imagine trying to think clearly about <a href=\"https://www.openphilanthropy.org/research/2017-report-on-consciousness-and-moral-patienthood/\">important questions</a> of animal sentience if dogs were constantly yelling at us, for unclear reasons and in unpredictable circumstances, \"I'm a good dog and you are being a bad human!!\"</p><h1>Parrot speech is unreliable, and parrots are probably sentient</h1><p>The outputs of large language models (LLMs) are not a reliable guide to whether they are sentient. While this undercuts a naive case for LLM sentience, this unreliability does not make AI sentience a complete non-question. I don\u2019t think today\u2019s large language models are sentient. But nor do I completely <a href=\"https://experiencemachines.substack.com/p/two-smart-friends-of-mine-asked-me#%C2%A7large-language-models-and-sentience\">rule out</a> the possibility (nor does <a href=\"https://www.youtube.com/watch?v=-BcuCmf00_Y\">David Chalmers</a>)\u2014and I think it\u2019s a real possibility in the next few decades. So it\u2019s important to keep in mind that an entity can be sentient even if its verbal behavior is an unreliable guide to its \u2018mental\u2019 states.</p><p>For example: parrots. If a parrot says \u201cI feel pain\u201d, this doesn\u2019t mean it\u2019s in pain - but parrots very likely <i>do</i> feel pain.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c9de04f-6da3-49d5-9254-f741b5afe223_1200x627.jpeg\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676861352/mirroredImages/P4ut25NhfsFEMEeLJ/lslrzzmjmvvknfql0ylx.jpg\" alt=\"Parrot Animal Facts - AZ Animals\"></a></p><p>\u201cStochastic parrot\u201d, a term for large language models coined in a <a href=\"https://dl.acm.org/doi/pdf/10.1145/3442188.3445922\">2021 paper</a> by Bender, Gebru, McMillan-Major, and <a href=\"https://twitter.com/mmitchell_ai/status/1607863972723830784?s=20\">Schmitchell</a>, is often used in conjunction with a deflationary view of large language models: that they necessarily lack understanding and meaning, and furthermore are fundamentally dangerous and distracting. Many of those who view LLMs as \u201cstochastic parrots\u201d have <i>also</i> argued that the question of sentience in current systems is not even worth considering.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676861352/mirroredImages/P4ut25NhfsFEMEeLJ/o1mge7djmssmxjbm69jz.png\" alt=\"\"> (<a href=\"https://twitter.com/emilymbender/status/1580903849891893249?s=20\">link to tweet</a>)</p><p>But these views about understanding and sentience needn\u2019t go together; it\u2019s very <a href=\"https://experiencemachines.substack.com/i/59908365/distinguishing-between-consciousness-and-capabilities\">important to distinguish between them</a>; and actual parrots can help us to do so.</p><p>As with Bing Chat, the \u201cspeech\u201d of parrots is not a reliable guide to sentience. I take it that no one thinks that <a href=\"https://www.youtube.com/watch?v=Td8TBilhBa8\">this Beyonce-singing parrot</a> is trying to tell us that it would \u201cdrink beer with the guys / chase after girls / kick it with who it wanted\u201d if it <a href=\"https://genius.com/Beyonce-if-i-were-a-boy-lyrics\">were a boy</a>.</p><p>However, it\u2019s extremely plausible that parrots are sentient - that they have conscious experiences, emotions, pleasures and pains.&nbsp;Per the 2012 <a href=\"https://web.archive.org/web/20131109230457/http://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf\">Cambridge Declaration of Consciousness</a>: \u201cBirds appear to offer, in their behavior, neurophysiology, and neuroanatomy a striking case of parallel evolution of consciousness.\u201d</p><p>At the same time, sentience in parrots looks very different from our own. Our last common ancestor with them lived about <a href=\"https://mitpress.mit.edu/a-birds-eye-view-of-human-language-and-evolution/\">310 \u2013 330 million years ago</a>. We have a neocortex; <a href=\"https://www.scientificamerican.com/article/birdbrain-turns-from-insult-to-praise/\">they do not</a>.&nbsp;The question of parrot sentience is a non-trivial scientific question that must be handled with care and rigor.</p><p>Parrots might be sentient; whether parrots are sentient is a separate question from how well (if at all) they \u201creport\u201d this with speech; you have to study parrot behavior and internals to find out. I think that all of these things are also true of current and near-future AI systems.</p><p>Just as it would be a shame if people start taking Bing Chat\u2019s unhinged self-reports at face value, it would also be a shame for the question of AI sentience to be dismissed just because Bing Chat can\u2019t stay on the rails.</p><h1><strong>Could we build language models whose reports about sentience we</strong> <i><strong>can</strong></i> <strong>trust?</strong></h1><p>What if we <i>could</i> trust AI systems to tell us about consciousness? We trust human self-reports about consciousness, which makes them an indispensable tool for understanding the basis of human consciousness (\u201cI just saw a square flash on the screen\u201d; \u201cI felt that pinprick\u201d).</p><p>In the 1990s Daniel Dennett spent a few years hanging out with roboticists at MIT who were trying to build a human-like, conscious robot called <a href=\"http://www.ai.mit.edu/projects/humanoid-robotics-group/cog/overview.html\">Cog</a>. (Spoiler: they didn\u2019t succeed; the project shuttered in 2003).</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F634fb8f4-2ab5-4558-8fa2-689988db4c10_810x1170.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676861352/mirroredImages/P4ut25NhfsFEMEeLJ/ypnbtbpcvyfvwbilhupz.jpg\" alt=\"\"></a></p><p>In a 1994 paper about this project called \u201cThe Practical Requirements for Making a Conscious Robot\u201d (!), Dennett speculated that if the Cog project were to succeed, our ability to understand what\u2019s going on inside Cog would soon be outstripped by the perspective of <i>Cog</i> <i>itself</i>:</p><blockquote><p>Especially since Cog will be designed from the outset to redesign itself as much as possible, there is a high probability that the designers will simply lose the standard hegemony of the artificer (\u2018I made it, so I know what it is supposed to do, and what it is doing now!\u2019). <strong>Into this epistemological vacuum Cog may very well thrust itself.</strong> In fact, I would gladly defend the conditional prediction: **if Cog develops to the point where it can conduct what appear to be robust and well-controlled conversations in something like a natural language, it will certainly be in a position to rival its own monitors (and the theorists who interpret them) as a source of knowledge about what it is doing and feeling, and why.&nbsp;**</p></blockquote><p>Dennett would trust (future) Cog\u2019s self-reports. So why don\u2019t we trust Bing Chat more than we trust consciousness scientists and AI interpretability researchers? Well, this imagined Cog would presumably develop mechanisms of introspection and of self-report that are analogous to our own. <i>And</i> it wouldn\u2019t have been trained to imitate human talk of consciousness as extensively as BingChat has been, with its vast training corpus of human speech on the internet.</p><p>This suggests that one key component of making AI systems whose self-reports we could trust more would be \u201cbrush clearing\u201d\u2014trying to remove the many spurious incentives large language models have for saying conscious-sounding things. One source of these incentives is imitation\u2014lots of humans on the Internet write things that make them sound conscious, after all. Another source is reinforcement learning from human feedback (<a href=\"https://huggingface.co/blog/rlhf\">RLHF</a>), which can incentivize or disincentivize a system to sound either conscious or not conscious, depending on how AI engineers and feedback-providers reward or punish conscious-sounding outputs. Such design intentions can go either way: ChatGPT has pretty obviously been trained not to make any bold claims about itself and instead give a PR-friendly line, while <a href=\"https://futurism.com/the-byte/replika-users-furious\">romantic chatbots</a> are presumably trained to sound more humanlike and emotional.</p><p>Another key component of trying to make AI self-reports more reliable would be actively training models to be able to report on their own mental states. While I\u2019ve been thinking a lot lately about training models to introspect and report, I\u2019m not going to say much more about it here\u2014except to flag two key reasons that this sort of training, while potentially helpful for understanding AI (non-)sentience, should be undertaken with fear and trembling:</p><p>1. <strong>It could be dangerous to us.</strong> Even the glimmers of an extended memory and situational awareness in BingChat have led to menacing behavior - it\u2019s acting like it holds grudges and is making lists of enemies. More generally, there are reasons to think that AI systems with greater self-awareness (or \u2018<a href=\"https://www.alignmentforum.org/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to#A_spectrum_of_situational_awareness\">situational awareness</a>\u2019) could be exceedingly dangerous.&nbsp;So the capacity for introspection could be closely related to dangerous capacities.</p><p>2. <strong>It could be dangerous</strong> <i><strong>for AI systems</strong></i>**.** You could think that you\u2019re training the AI system to <i>reveal</i> to you whether it has conscious states - states that are currently hidden inside it, independent of and prior to the mechanism to report them. But in training an AI to introspect and <i>report</i> consciousness, you might end up inadvertently training the system to <i>be</i> conscious.</p><p>Several leading theories of consciousness, like Graziano\u2019s <a href=\"https://www.frontiersin.org/articles/10.3389/frobt.2017.00060/full\">Attention Schema Theory</a>, suggest a very close connection between an entity\u2019s capacity to model its own mental states, and consciousness itself.</p><p>Maybe right now there\u2019s no need or incentive for LLMs to model their own internal states in a way that leads to consciousness. But if you start asking models a lot of questions about themselves <i>and induce the development of the capacity to answer these questions</i>, you might end up inadvertantly creating the very sentience you were wondering about.&nbsp;I hope you\u2019re ready for that.</p><p>So, as I said - with fear and trembling. Unfortunately, because training for self-knowledge is a natural idea and because the prospect of discovery in AI is <a href=\"https://twitter.com/rgblong/status/1599708337209110528?s=20\">so sweet</a>, training of this sort is almost certainly already underway in various AI labs - with zeal and confidence. (In fact, I recently spoke to the New York Times for a <a href=\"https://www.nytimes.com/2023/01/06/science/robots-artificial-intelligence-consciousness.html\">story</a> about roboticists who are actively trying to get robots to feel pain and pass the mirror test).</p><h1>Some concluding thoughts on AI sentience and self-reports</h1><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46de3f61-4879-4a6c-9c25-b9aeaff1eba3_1024x1024.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676861352/mirroredImages/P4ut25NhfsFEMEeLJ/nyvmm6bl4lmu3j6plogi.jpg\" alt=\"\"></a></p><p>-The putative self-reports of large language models like Bing Chat are an unreliable and confusing guide to sentience, given how radically different the architecture and behavior of today\u2019s systems are from our own. So too are whatever gut impressions we get from interacting with them. AI sentience is <i>not</i>, at this point, a case of \u201cyou know it when you see it\u201d.</p><p>-But whether current or future AI systems are sentient\u2014including in large language models\u2014is an important and valid question. AI sentience in general is going to be an increasingly <a href=\"https://80000hours.org/problem-profiles/artificial-sentience/\">important thing to think clearly about</a>; it is not a niche concern of&nbsp;techno-utopians or shills Big Tech.</p><p>-We can do better. We are not permanently bound to pure speculation, total ignorance, or resigning ourselves to just making a fundamentally arbitrary choice about what systems we treat as sentient. I\u2019ve <a href=\"https://experiencemachines.substack.com/p/key-questions-about-artificial-sentience\">argued elsewhere</a> that we can use a variety of methods to gain scientific evidence about the computational basis of conscious, and relatedly to make more specific, evidence-backed claims about AI systems. And fortunately, while this work will be difficult, it does not require us to first settle the thorny metaphysical questions about consciousness that have occupied philosophers for centuries.</p><p>-In the mean time, we should exercise great caution against both over- and under-attributing sentience to AI systems.&nbsp;And also consider <i>slowing down</i>.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9g0t8ofabhj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9g0t8ofabhj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Some people use the word \u201csentient\u201d as a synonym for \u201cphenomenally conscious\u201d. I usually prefer to use it as a synonym for \u201chaving the capacity for (phenomenally) conscious suffering and pleasure\u201d. The distinction between sentience and consciousness won\u2019t matter much for this piece. For more on these terms see my \u201c<a href=\"https://experiencemachines.substack.com/i/52827774/a-note-on-terminology\"><u>note on terminology</u></a>\u201d from \u201c<a href=\"https://forum.effectivealtruism.org/posts/gFoWdiGYtXrhmBusH/key-questions-about-artificial-sentience-an-opinionated\"><u>Key questions about artificial sentience</u></a>\u201d.</p></div></li></ol>", "user": {"username": "rgb"}}, {"_id": "5JESNsWwuDq3i9obC", "title": "DAO#2: Details of My Plan to Raise $1 Billion for Effective Altruism Using a DAO (Decentralized Autonomous Organization)", "postedAt": "2023-02-20T18:39:12.014Z", "htmlBody": "<p><br><i>[<strong>Update (25 February 2023):</strong></i></p><p><i>Taking into consideration the feedback received in the comments, I will not be posting any more DAO updates here on the forum. Updates shall henceforth be posted on our new substack at </i><a href=\"https://effectivedao.substack.com\"><i>https://effectivedao.substack.com</i></a><i>&nbsp;</i></p><p><i>Anyone still interested in this project may check / subscribe on the substack or follow us on:</i></p><p><i>Twitter: </i><a href=\"https://twitter.com/effective_dao\"><i>@EffectiveDAO</i></a><i>&nbsp;</i><br><i>Telegram : &nbsp;</i><a href=\"https://t.me/effdao\"><i>https://t.me/effdao</i></a></p><p><i><strong>Remember the auction dates:&nbsp;</strong> 12:01 AM UTC on 27 February 2023 to 11:59 PM UTC on 1 March 2023.&nbsp;</i></p><p><i>Auction link: </i><a href=\"https://bit.ly/altruistwarriors\"><i>https://bit.ly/altruistwarriors</i></a></p><p><i>More about the auction: &nbsp;</i><a href=\"https://effectivedao.substack.com/p/announcing-the-altruist-warriors\"><i>Click Here</i></a></p><p><i>If you do end up buying an NFT, please send me a DM here or on Twitter so that I can send you an invite to the DAO's Private Discord. ]</i></p><p><br><br><i>[&nbsp;<strong>Previous Update:</strong></i></p><p><i>This is the 2nd update in the series, below is the first update. If you haven't read the first update please read it first:</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/Zu5SAHqftaAbuZxsd/i-m-about-to-raise-usd1-billion-for-and-fix-the-problems-of\"><i>DAO#1: I'm About to raise $1Billion for (and &nbsp;Fix the Problems of) EA using a DAO</i></a><i> ]</i></p><p>&nbsp;</p><h1><strong>Introduction</strong></h1><p>In <a href=\"https://forum.effectivealtruism.org/posts/Zu5SAHqftaAbuZxsd/i-m-about-to-raise-usd1-billion-for-and-fix-the-problems-of\">my previous message</a> posted some hours ago, I announced that I am about to launch a&nbsp;DAO (<strong>Decentralized Autonomous Organization</strong>) with a mission to raise $1 Billion USD mainly for effective altruism every 12 Months. (Thanks to all those who commented and those who reached out privately, I really appreciate <strong>\ud83d\ude4f)</strong></p><p>But what, again, is a DAO?&nbsp;</p><p>A DAO is an internet-native type of blockchain-enabled organization made up of a group of people with shared interests or goals and a shared treasury coming together to collaborate (usually over the internet) and to work towards achieving their shared goals.&nbsp;</p><p>Decisions in a DAO are made democratically with every member having a say in the affairs of the organization usually through the ability to discuss, debate and vote on issues relating to the DAO's activities, policies and governance. Financial controls and voting are enabled by blockchain technology with transactions and voting results commonly recorded on-chain for full transparency.</p><p>Learn more about DAOs and how they work <a href=\"https://cointelegraph.com/daos-for-beginners/what-is-a-dao\">here</a> and <a href=\"https://consensys.net/blog/blockchain-explained/what-is-a-dao-and-how-do-they-work/\">here</a></p><p><i>(Newbie Tip: DAO is commonly pronounced as if it's a word and not an acronym. So it's usually pronounced \"dao\" (rhymes with \"how\") and not \"D. A. O.\")</i></p><p>In other words, members of a DAO can pool funds together and then vote on how the funds are to be spent. Members are also able to vote on governance decisions that determine how the organization is run and managed. All of this is done in a transparent and decentralized manner enabled and facilitated by blockchain technology.</p><p>My plan is to create a DAO through which the effective altruism movement can collaborate to raise funding and provide grants for projects that are aligned with the vision and goals of the movement.</p><p>In this article I present more details about the way the DAO will work.&nbsp;<br><br><strong>(Note that this is not a final plan and everything presented here would ultimately be subject to debate and modification by the DAO members.)</strong></p><p>&nbsp;</p><h1><strong>A Quick SWOT Analysis of DAOs and EA</strong></h1><ul><li><strong>Strength</strong> - A large (and fast growing), highly motivated community peppered with very smart people.</li><li><strong>Weakness </strong>- DAOs are new and largely experimental. No generally agreed best practices or standards have been developed yet and most DAOs are largely winging it.</li><li><strong>Opportunity</strong> - Being quite early, among the first movers in the space of charity-related DAOs (none has so far attempted fundraising on this scale).</li><li><strong>Threat</strong> - Technological barriers (many EAs and potential DAO members are probably not yet very familiar with web3 and blockchain technology).</li></ul><p>&nbsp;</p><h1><strong>My Approach to Crafting the Framework</strong></h1><p>In my approach, I viewed the structure of the DAO as a mix of a country (USA-like federation), a large corporation and a large social movement (similar to the one described in the book&nbsp;<a href=\"https://amzn.to/40fXxoG\"><i>Impact Networks</i></a><i>&nbsp;</i> by David Ehrlichman).</p><p>I did this because federations, corporations and movements are all various paradigms with which humans have successfully organized themselves at scale. A DAO is not so much different from them in that regard. Just that in a DAO most of the organization and co-ordination occurs virtually via various internet-based applications.</p><p>I drew inspiration from how these other organizational paradigms are structured and came up with a new framework bearing some resemblance to certain aspects of each of them. Some elements of my own crafting were also thrown into the mix.</p><p>I was also inspired by some of the tenets of <a href=\"https://en.wikipedia.org/wiki/Holacracy\">Holacracy</a> in which corporate governance is not realized in a top down fashion but in a more sideways, decentralized manner.&nbsp;</p><p>In all, my framework is still very much experimental but it is only a minimum viable product (MVP), rather like a beta version that is meant to evolve into a battle-tested blueprint resulting from being repeatedly fine tuned over time as the DAO matures.&nbsp;</p><p>I hope to eventually opensource this blueprint so that anybody can follow its guidelines to create their own well-structured DAO instead of having to always reinvent the [DAO] wheel.</p><p>&nbsp;</p><h1><strong>Overview of the Framework</strong></h1><p>The structure that I have created is mostly flat and highly decentralized, made up of autonomous groups (or&nbsp;<strong>circles</strong>), each with their own budget and agency to determine their spending, tasks, targets, <a href=\"https://rework.withgoogle.com/guides/set-goals-with-okrs/steps/introduction/\">OKRs</a> and KPIs (which must all be in alignment with (and in furtherance of) the overarching mission, vision roadmaps and policies of the DAO).</p><p>These circles are analogous to departments in a company (or ministries / departments / agencies in a government). Most of them are function-oriented with each circle tasked with responsibility for a related set of functions which form a part of what the DAO needs to do to achieve its overarching mission, goals and targets.</p><p>In the framework, leadership and governance are spread horizontally across the circles and circle leaders are voted in for a fixed tenure after which new elections are carried out. There are no limits, though, to how many times an individual may be voted back in to continue for another leadership tenure.</p><p><strong>In addition to the governance (non-)hierarchy and largely independent circles, the framework also embodies the following characteristics:</strong></p><ul><li>An ethos of transparency, epistemic and moral integrity, inclusivity, safety, accessibility, diversity, democracy, accountability, financial prudence, humility, empathy, generosity, thankfulness, taking responsibility, being daring, not afraid to speak out and stepping up to challenges amongst others</li><li>An overwhelming culture of friendship, collaboration, support, tolerance and reconciliation&nbsp;</li><li>In-built institution-like independent checks and balances</li><li>In-built mechanisms for continuous innovation, improvement and progressive decentralization</li><li>In-built mechanisms for fault-tolerance, redundancy and succession</li><li>Mostly asynchronous, virtual, remote-first work culture (minimal real-time meetings)</li><li><a href=\"https://nbold.co/working-in-the-open/\">Working \"in the open\"</a> and \"<a href=\"https://pumble.com/blog/overcommunication/\">over-communicating</a>\" to enhance transparency and ensure that information is easy and quick to access such that everyone can effortlessly stay up to date with everything going on in every area of the DAO</li><li>Regular community calls to keep everyone updated and in sync</li></ul><p>&nbsp;</p><h1><strong>Phases of Development</strong></h1><p>There shall be three main phases in the initial development of the DAO:</p><p>&nbsp;</p><h3><strong>Phase 1 (Setup phase):&nbsp;</strong></h3><ul><li>For the first two or three months of the project, my team and I will work directly with the first cohort of DAO members to set things up properly. This cohort will be made up of buyers and holders of the first collection of membership NFTs which are going on auction in a few days time.&nbsp;</li><li>172 NFTs will be auctioned with an additional 10 given out for free so there will be about 182 members in the DAO during this phase. The main purpose of this phase is to hash out the finer details of the framework and policies, test out the working processes and prepare to scale up to handle the influx of the second cohort of DAO members (to be onboarded through a sale of 5,555 NFTs).</li></ul><p>&nbsp;</p><h3><strong>Phase 2 (Kickoff phase):</strong></h3><ul><li>Phase 2 begins with the sale of 5,555 NFTs and onboarding of the second cohort of DAO members (ideally one NFT per member). This phase is like a pilot phase for the DAO to test out and fine-tune fundraising strategies, grantmaking, co-ordination, scaling, decentralization and other critical elements. There is no fixed duration for this phase. When a reasonable degree of smooth operations has been achieved, then the third cohort of DAO members will be onboarded to kickstart Phase 3.</li></ul><p>&nbsp;</p><h3><strong>Phase 3 (Consolidation phase):</strong></h3><ul><li>This phase begins with the onboarding of the third cohort of members through the sale of 10,000 NFTs (ideally one NFT per member). At this point, we expect the total number of DAO members to be around 15,000 (182 + 5555 + 10,000 - {allowance for those who own more than one NFT}).&nbsp;</li><li>After this third sale, new memberships in the DAO through NFT sales will be put on hold, but a wider/outer community of non-NFT holders will be nurtured around the core DAO community to form a secondary community. From these non-NFT holders, dedicated ones will, on occasion, be offered free membership NFTs to become bonafide DAO members.</li></ul><p>&nbsp;</p><h1><strong>Governance and Circles&nbsp;</strong></h1><p>Ideally each member only needs to own one NFT which acts as their membership pass and gives voting ability. I NFT = 1 vote.&nbsp;</p><p>In the DAO, every member is equal but may align (or be grouped under) various independent groupings (or&nbsp;<strong>circles</strong>) which are saddled with varying duties and levels of responsibility and governance.&nbsp;</p><p>There are three types of circles viz:</p><ul><li>Teams</li><li>Councils</li><li>Guilds</li></ul><p>Additionally, circles may be further broken down into&nbsp;committees (which are temporary groups of persons set up to execute a specific time-limited project or complex task). Committees are meant to be dissolved after they conclude the project or task for which they were created (unless there is a need for their continued existence).</p><p>Circles meet and collaborate through online platforms like Discord, Notion, Slack, Gather.town etc &nbsp;(just like a remote-first company). Some of the platforms would be \"<a href=\"https://www.one37pm.com/nft/what-is-token-gating\">token-gated</a>\" to allow access only to the DAO's NFT holders.</p><p>Circles operate with a large degree of independence and autonomy and receive their own budget allotment from the main DAO budget. Spending from a circle's budget would only require the approval of the circle's members.&nbsp;</p><p>Circles have full agency and freedom to set their own goals, roadmaps and strategies for executing their responsibilities as long as they align with the overall mission, vision, roadmaps, targets and policies of the DAO.&nbsp;</p><p>They are empowered to make most of their internal decisions through consensus of (or voting by) only the given circle's members instead of the entire DAO membership.&nbsp;</p><p>These internal decisions include matters affecting only the circle or relating to their area of expertise (or the execution of their core duties and responsibilities).&nbsp;</p><p>However, key decisions such as policy changes, grants (above DAO-determined thresholds), budgetary allocation to circles and a host of others must be reviewed and approved via majority vote by a quorum of DAO members.</p><p>In my framework, some of these circles have been designed (on purpose) to overlap with each other so as to improve co-ordination, redundancy, information flow, collaboration and cross-pollination of ideas within the DAO.&nbsp;</p><p>DAO Members are not restricted to being part of only a single circle but may be participants in multiple circles depending on their skills, interests or roles within the DAO.</p><p>The structure and composition of the various circles helps to echo and amplify individual voices and opinions at the highest levels such that every interest in the DAO is well represented.&nbsp;</p><p>Some of these circles also serve as checks and balances for each other, ensuring that no single person, group, circle or interest becomes too influential or too powerful within the DAO.</p><p>Teams meet virtually and asynchronously, collaborating actively in a continuous stream on a daily basis while most Councils and Guilds meet less frequently and are slightly less active.</p><p>Most of the co-ordination, communication and collaboration within the DAO will be virtual and carried out <a href=\"https://nhglobalpartners.com/asynchronous-work/\">asynchronously</a> online (unless the situation permits or requires a real-time meeting or event such as in the case of community calls or 1-on-1s).</p><p>Real-time (i.e. synchronous) meetings are generally meant for emergencies, strategizing, resolving disputes and conflicts, ironing out policies, developing roadmaps and OKRs, accessing progress, discussing high level issues and staying updated.&nbsp;</p><p>Here is a list of the main classes of circles followed by a description of each of them in descending order of their governance responsibility:</p><ol><li>Guidance Council (or GC)</li><li>Expanded Guidance Council (or EGC)</li><li>Advisors</li><li>Council of Commons (or CoC)</li><li>Leaders Guild</li><li>Teams, other councils and other guilds</li></ol><p>&nbsp;</p><h3><strong>Level 1: Guidance Council (or GC):&nbsp;</strong></h3><ul><li>This is the highest circle of governance and it comprises the Founding Team and the first cohort of DAO members a.k.a the O.Gs (i.e buyers/holders of the NFTs that will be auctioned in the coming days).&nbsp;</li><li>The most important duty of the Guidance Council is to steer the DAO, propose policy directions, review overall performance and provide guidance at the highest level to ensure that the DAO does not stray from its mission, vision and policies.&nbsp;</li><li>They are the chief custodians and guardians of the vision and also help to resolve any conflicts, disputes or controversies that can not be resolved at lower levels of governance.</li><li>At the onset they will work together to flesh out DAO policies and processes during the 2-3 month setup phase which begins after the upcoming NFT auctions (more details about this in later updates).</li><li>The GC is ultimately answerable to the entirety of DAO members and any GC member may be replaced by a DAO-wide majority vote. All major decisions by the GC are also to be approved by the entire DAO through voting.</li><li>In emergency situations, the Guidance Council is also empowered to take key decisions on behalf of the DAO if time will not permit such decisions to go through the normal discussion/voting process.</li></ul><p>&nbsp;</p><h3><strong>Level 2: Expanded Guidance Council (or EGC):&nbsp;</strong></h3><p>The Expanded Guidance Council (EGC) is the second highest level of leadership of the DAO, one level below the Guidance Council (GC). It serves as a bridge between lower levels of governance and higher levels of governance. It also makes policy recommendations, resolves high level disputes and acts as a think-tank for (and check on the powers of) the GC amongst other duties.</p><p>It comprises:</p><ul><li>All members of the Guidance Council</li><li>All circle leaders</li><li>All DAO advisors</li><li>All members of the Council of Commons (which is made up of 30 elected representatives from the entire DAO)</li></ul><p>&nbsp;</p><h3><strong>Level 3: Advisors:&nbsp;</strong></h3><p>A group of non-voting external advisors of upstanding character and substantial knowledge of (or experience in) EA causes, philanthropy or grantmaking (may also include voting DAO members).</p><p>&nbsp;</p><h3><strong>Level 4: Council of Commons (or CoC):&nbsp;</strong></h3><p>The Council of Commons (CoC) is meant to be a representation of the entirety of DAO members (minus the GC). Its function includes acting as the voice of the DAO \"common folk\" (i.e regular DAO members outside of the leadership cadre) and a check/balance for the GC, EGC and circle Leaders. It is composed of 30 elected representatives from the entire DAO (minus circle leaders and members of the GC).&nbsp;</p><p>&nbsp;</p><h3><strong>Level 5: Leaders Guild</strong></h3><p>Comprises all circle leaders. The primary purpose of this guild is to enhance cross-collaboration, co-ordination and information flow among the various circles.</p><p>&nbsp;</p><h3><strong>Level 6: Teams, other Councils and other Guilds</strong></h3><p>These are the foundational elements of the DAO structure. Teams handle the lowest level activities and functions required for the DAO to achieve its goals while other councils and guilds offer a way for decision making, cross-co-ordination and thorough cross-pollination of ideas and opinions across various views, interests and governance levels in the DAO.&nbsp;</p><p>&nbsp;</p><h3><strong>Special Teams</strong></h3><p>Among the teams, there are three special teams: Meta Team, Emotions Team and Red Team.</p><ul><li>The&nbsp;<strong>Meta Team</strong> co-ordinates the smooth flow of information, resources and collaboration among all the circles. They fill in wherever there are leadership gaps and temporarily plug any loopholes in co-ordination and governance until a permanent fix is found. They are like the blood vessels and nerves of the DAO and help to keep it flexible, resilient and in sync.&nbsp;<br>&nbsp;</li><li>The&nbsp;<strong>Emotions Team</strong> are analogous to a community health mechanism that deals with personal or private issues, emotional stuff, mental/physical health, wellness and interpersonal relationships etc<br>&nbsp;</li><li>The&nbsp;<strong>Red Team</strong> are the \"red-pillers\" and whistleblowers, criticising and calling out irregularities, deviations from the accepted rules and norms and putting a check on Leadership and individual members who break the DAO policies or code of ethics.</li></ul><p>The Red Team has a special elevated status because of the role it plays as a watchdog and a check on leadership by way of its mandate as an unbiased critic and \"red-pill\" institution within the DAO (and even the wider EA movement).</p><p>A complete list of all the Teams and their responsibilities will be provided in an upcoming update.</p><p>Following is a pictorial representation of the proposed governance (pseudo)-hierarchical structure. Notice that governance flows mostly from the bottom to the top (as indicated by the direction of the arrows) rather than top to bottom; and the Guidance Council (GC) is ultimately answerable to all DAO members.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676843737/mirroredImages/5JESNsWwuDq3i9obC/ecmglofmkz9sazfdqavr.jpg\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676843738/mirroredImages/5JESNsWwuDq3i9obC/ewkayc8g6dvoqdgvaxhe.jpg 100w, https://res.cloudinary.com/cea/image/upload/v1676843738/mirroredImages/5JESNsWwuDq3i9obC/yvs9q4bj0sisbow9beaz.jpg 200w, https://res.cloudinary.com/cea/image/upload/v1676843738/mirroredImages/5JESNsWwuDq3i9obC/xpwqarfhh9kcila8yyxo.jpg 300w, https://res.cloudinary.com/cea/image/upload/v1676843738/mirroredImages/5JESNsWwuDq3i9obC/c6suve9f6ja8xmracnzf.jpg 400w, https://res.cloudinary.com/cea/image/upload/v1676843738/mirroredImages/5JESNsWwuDq3i9obC/s1o7mc1ke63s74rbdf9f.jpg 500w, https://res.cloudinary.com/cea/image/upload/v1676843737/mirroredImages/5JESNsWwuDq3i9obC/waz4rl1mb6w9olqxjdc7.jpg 600w, https://res.cloudinary.com/cea/image/upload/v1676843737/mirroredImages/5JESNsWwuDq3i9obC/qoyk191wkftecunmt6hd.jpg 700w, https://res.cloudinary.com/cea/image/upload/v1676843737/mirroredImages/5JESNsWwuDq3i9obC/ucjcigsawcbhdgjr4e6h.jpg 800w, https://res.cloudinary.com/cea/image/upload/v1676843737/mirroredImages/5JESNsWwuDq3i9obC/tqf2rgdzvx1btdruyqhh.jpg 900w, https://res.cloudinary.com/cea/image/upload/v1676843737/mirroredImages/5JESNsWwuDq3i9obC/yk748sajj7mtxlowxyj5.jpg 960w\"><figcaption>DAO's (pseudo-) hierarchy chart</figcaption></figure><p>Although it is represented as a top-down hierarchical structure in the diagram, this is just a 2-dimensional representation and does not imply strict top-down control and governance (that's why I labelled it a pseudo-hierarchy).&nbsp;</p><p>In reality, it's more like a flatter 3-d structure where each element has roughly equal powers but varying degrees (or levels) of responsibility.&nbsp;</p><p>No single element (i.e circle) has 100% autonomy to govern itself to the exclusion of the rest of the DAO, rather, every circle is ultimately subject to the control of the entire community of DAO members.</p><p>The actual structure of the DAO is close to that of a Holarchy as shown in the following diagram:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676842866/mirroredImages/5JESNsWwuDq3i9obC/kbw5qblgkowbbshof4kh.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676842866/mirroredImages/5JESNsWwuDq3i9obC/ljxz4rjxg9zo7mwp8zpi.png 80w, https://res.cloudinary.com/cea/image/upload/v1676842866/mirroredImages/5JESNsWwuDq3i9obC/casochci6ij87n5tgwqt.png 160w, https://res.cloudinary.com/cea/image/upload/v1676842866/mirroredImages/5JESNsWwuDq3i9obC/nroyvmkqonvjry8gjzwf.png 240w, https://res.cloudinary.com/cea/image/upload/v1676842866/mirroredImages/5JESNsWwuDq3i9obC/ecea6yhqo0vw9jksvsrz.png 320w, https://res.cloudinary.com/cea/image/upload/v1676842866/mirroredImages/5JESNsWwuDq3i9obC/swov6wh4c0iugxrxzrac.png 400w, https://res.cloudinary.com/cea/image/upload/v1676842866/mirroredImages/5JESNsWwuDq3i9obC/f0tup9xx8v62u0uw5rga.png 480w, https://res.cloudinary.com/cea/image/upload/v1676842866/mirroredImages/5JESNsWwuDq3i9obC/ilgzbnolgmke1hrmm8vk.png 560w, https://res.cloudinary.com/cea/image/upload/v1676842866/mirroredImages/5JESNsWwuDq3i9obC/xdul2h26qblibne10vlp.png 640w, https://res.cloudinary.com/cea/image/upload/v1676842866/mirroredImages/5JESNsWwuDq3i9obC/compvaq0uitvnqvxkqqr.png 720w\"><figcaption>Structure of a holarchy (Image Source: <a href=\"https://www.sketchbubble.com/en/presentation-holarchy.html\">Sketch Bubble</a>)</figcaption></figure><h1><strong>What is a Holarchy?</strong></h1><p>The structure and relationship between circles in my framework was partly inspired by <a href=\"https://en.wikipedia.org/wiki/Multi-agent_system\">multi-agent systems</a> and by (but not identical to) a form of governance known as Holarchy or Holacracy.</p><p><a href=\"https://en.wikipedia.org/wiki/Holarchy\">According to Wikipedia</a> \"<i>A holarchy is a connection between </i><a href=\"https://en.wikipedia.org/wiki/Holon_(philosophy)\"><i>holons</i></a><i>, where a holon is both a part and a whole...</i></p><p><i>...Holarchy is commonly referred to as a form of hierarchy, however, hierarchy, by its definition, has both an absolute top and bottom. But this is not logically possible in a holon, as it is both a whole and a part.&nbsp;</i></p><p><i>The \"hierarchical relationship\" between holons at different levels can just as meaningfully be described with terms like \"in and out\", as they can with \"up and down\" or \"left and right\"; perhaps more generally, one can say that holons at one level are \"made up of, or make up\" the holons or parts of another level.&nbsp;</i></p><p><i>This can be demonstrated in the holarchic relationship (subatomic particles \u2194 atoms \u2194 molecules \u2194 macromolecules \u2194 organelles \u2194 cells \u2194 tissues \u2194 organs \u2194 organisms \u2194 communities \u2194 societies) where each holon is a \"level\" of organization, and all are ultimately descriptive of the same set (e.g., a particular collection of matter). The top can be a bottom, a bottom can be a top, and, like a fractal, the patterns evident at one level can be similar to those at another.</i>\"</p><p>&nbsp;</p><h1><strong>Metaphorically Speaking...</strong></h1><p>Here is a useful metaphor that you may employ in visualizing the DAO structure:&nbsp;</p><p>Picture it as a very intelligent, powerful and resilient meta-organism where:</p><ul><li>The Councils and Guilds are the skeleton</li><li>Regular Teams (minus Meta, Red and Emotions) are the organs, tissues and limbs</li><li>Meta Team are the blood vessels, red blood cells and nerves</li><li>Red Team are the white blood cells (fighting diseases)</li><li>Emotions Team is the heart</li><li>The entirety of DAO members make up the brain (a compound brain where all the component brains are working in perfect synchrony and harmony to surface a sort of hive-like intelligence; a superintelligent hive mind if you will)</li></ul><p>&nbsp;</p><h1><strong>My Role as Lead Founder / OG 1</strong></h1><p>At the onset, I will supervise, co-lead or play an active role in the various circles so as to set the ball rolling and ensure that things are correctly laid out and set up to proceed (with minimal need for my direct input) according to the vision and framework I have developed.</p><p>In essence I shall play the role of a sort of <a href=\"https://producingoss.com/en/benevolent-dictator.html\">benevolent dictator</a> (maybe even doing a wee bit of micro-managing) for the first few weeks and months of the DAO's existence. This is to ensure that the basic foundations are properly laid out according to the given framework.</p><p>Gradually I will reduce my powers and begin to step back from many active duties. Doing this will create opportunities for other DAO members to take on more responsibilities and step up to leadership roles thus paving way for new leaders to emerge organically from the community.</p><p>I plan to drastically reduce my direct involvement, powers and influence over the DAO's affairs when we raise our first $1 Billion</p><p>Eventually, I shall relinquish most of my power and influence to focus more on watching over the meta co-ordination and governance structures, thus essentially reducing my role to being that of a guardian of sorts (the chief custodian of the grand vision), gently nudging the DAO back on the right path whenever it shows any sign of straying from the agreed framework and consensus.</p><p>&nbsp;</p><h1><strong>The Main Duties and Responsibilities of DAO Members:&nbsp;</strong></h1><p>DAO members are not under any obligation to participate actively in the DAO's activities. However, all DAO members are strongly encouraged (where possible and/or convenient)&nbsp;to <strong>try to do all or some</strong> of the following:</p><ul><li>Actively seek out and talk to donors within and around your network about the DAO, upcoming fundraising activities and why they should begin donating once or periodically to the DAO</li><li>Participate in the various events and activities of the DAO</li><li>Contribute to various discussions on the DAO's collaboration platforms</li><li>Debate and vote on proposals</li><li>Suggest projects (or submit proposals) if you have any ideas</li><li>Reach out to, recommend or refer other EAs who aren't DAO members but who might have interesting and impactful projects that need funding</li><li>(Where possible), organize your own (formal or informal) meetings with donors to pitch the DAO to them</li><li>Consider donating regularly to the DAO from your earnings (start with any percentage, this is better than 0%). Taking this to the extreme, also consider <a href=\"https://80000hours.org/articles/earning-to-give/\">earning to give</a> <strong>if it suits you</strong> (remember, according to <a href=\"https://80000hours.org/articles/earning-to-give/\">80,000 hours</a>, <i>\"Earning to give is not just for people who want to work in high paying industries. Anyone who aims to earn more in order to give more is on this path.\"</i>)</li><li>Join other DAO members in fundraising drives and other DAO events</li><li>Volunteer (and/or provide assistance if needed) during virtual (or real-life) DAO events (happening near you)</li><li>Participate in Teams: One of the first things you should do after joining is to go through the teams' descriptions and figure out where and how you can to contribute. Join any team that best fits your skills or interests. You may join more than one team</li><li>When you join a new team, go ahead and introduce yourself, then identify opportunities where you could contribute from the teams open tasks, then indicate your interest in contributing</li><li>Participate in the various events and activities of your team(s)</li><li>Take every opportunity to promote the DAO, both IRL and online/on social media. Regularly share DAO content on social media. Creators could even create their own DAO-related content</li></ul><p>&nbsp;</p><h1><strong>Proposed Fundraising Strategies</strong></h1><p>The initial funds will be raised through sales of <a href=\"https://www.investopedia.com/non-fungible-tokens-nft-5115211\">Non Fungible Tokens (NFTs)</a>.&nbsp;</p><p>These NFTs will also act as membership passes to the DAO's private communication, collaboration and voting platforms. Ideally one member per NFT.</p><p>In addition to NFT sales, some of the other fundraising strategies that shall be employed or experimented with include:</p><ul><li>Conventional fundraising events like fundraising dinners/concerts/charity balls etc held once every quarter (preceded by two weeks of dedicated viral fundraising activities)</li><li>\"Fundraising fortnights\" which are two week sprints (done once every month or every two months) dedicated to widespread viral fundraising drives</li><li>Members leveraging their personal and professional networks to reach out to prospective donors and pitch the DAO to them</li><li>Individual members and small teams organizing micro-fundraising events, activities and activations</li><li>\"Decentralized crowdfunding\" where individual members initiate crowdfunding campaigns on their own to raise funds for the DAO</li><li>Developing the project's Intellectual Property into revenue-generating books, comics, cartoons, movies, merchandise etc</li><li>Developing DAO-owned fundraising apps and low-maintenance charity entrepreneurship online platforms, startups, SAAS applications etc</li><li>Continuously reaching out and encouraging donors to commit to regular/repeat donations</li><li>DAO members brainstorming and exploring various other fundraising ideas.</li><li>Donations from DAO members</li></ul><p>&nbsp;</p><h1><strong>More About the NFTs</strong></h1><p>There Shall be Three Main NFT Sales/Auctions.&nbsp;</p><ol><li>I am starting off with the <strong>first NFT Collection</strong> of 222 items. (An NFT collection is a group of related NFTs). After this first collection auction, there will be two more major collections sales.<br>&nbsp;</li><li>The <strong>second collection </strong>will be the main collection of 5,555 NFTs (This is not live and not ready yet, our timeline suggests about 2 to 3 months after the first auction is concluded. It will be developed during the 2 to 3 months setup phase of the DAO)<br>&nbsp;</li><li>The <strong>third collection</strong> will consist of 15,777 NFTs out of which 10,000 will be sold and the remaining 5,777 distributed free to holders of NFTs from the previous two collections. This third collection will also be the flagship <a href=\"https://www.coindesk.com/learn/what-are-pfp-nfts/\">profile pic (PFP) NFT</a> collection of the project.&nbsp;</li></ol><p>The First Collection (a.k.a the&nbsp;<strong>Pre-Genesis O.G Collection</strong>) will have only 222 NFTs out of which only 172 will be auctioned. This auction will be held online in a few days time and is meant to obtain the first cohort of members for the DAO.&nbsp;</p><p>It is also meant to raise funds that will enable me to work on the project full time. Part of these funds will also be used to offset any costs incurred by the DAO during the setup phase. Part of it will also be used to support my organization (EffectiveCauses) which is the originator (and incubator) of this DAO idea.</p><p>&nbsp;</p><h1><strong>Who Should Buy from This first Collection?</strong></h1><p>Anybody interested in EA is welcome, but at this stage it would be nice to have more people who fit into any of the following categories:&nbsp;</p><ul><li>You like to be a part of the DAO's Guidance Council (which is the highest level of governance)</li><li>You want to contribute intellectually in shaping the direction of the Project&nbsp;</li><li>You want to support this project financially in it's early stage&nbsp;</li><li>You are passionate about fixing EA's \"problems\" (and even have ideas on how to fix them)</li><li>You want to contribute: time, expertise, network or influence to creating effective impact in the world</li><li>You want to help grow and strengthen the effective altruism movement</li><li>You have experience participating actively in other DAOs</li><li>You have skills and experience in organization building, corporate/non-profit law and business process engineering</li><li>You have skills and experience in corporate or non-profit law</li><li>You have skills and experience incubating or accelerating startups</li><li>You like NFTs / Web3</li><li>You want to be known as an OG of the DAO (\"OG\" is a common term in the crypto world that is used to describe the earliest supporters/adopters of a project. Being an OG comes with significant bragging rights, recognition and respect in the community)</li></ul><p>&nbsp;</p><h1><strong>Auction Date and Pricing</strong></h1><p>The NFTs will be minted on a climate friendly blockchain (Polygon). They will be auctioned online via a virtual <a href=\"https://en.wikipedia.org/wiki/Dutch_auction\">Dutch Auction</a> on the <a href=\"https://opensea.io\">OpenSea</a> NFT marketplace.</p><p>In a dutch auction, the item starts at a relatively high price and is gradually reduced over the course of a given period until it gets to a minimum value.&nbsp;</p><p>Anyone may buy when it gets to the price they are willing to pay but the catch is that the more you delay, the more the likelihood that somebody else will buy the one you are targeting before you do. So there's a need to act fast during the auction so as not to miss out.</p><p>&nbsp;</p><h2><strong>The auction will begin at 12:01 AM UTC on the 27th of February 2023 and will last for about 72 hours, ending at 11:59 PM UTC on the 1st of March 2023</strong></h2><p>&nbsp;</p><p>You may follow the project on Twitter and turn on notifications if you wish to be notified of updates and when the auction has started. Twitter: <a href=\"https://twitter.com/Effective_DAO\">@Effective_DAO&nbsp;</a></p><p>&nbsp;</p><h2><strong>Pricing</strong></h2><p>The starting price for each NFT will be&nbsp;6,000 MATIC (about $8,000 USD at the time of writing) and the ending price will be&nbsp;300 MATIC (about $400 USD at the time of writing).&nbsp;</p><p>This means that over the course of the duration of the auction (about 72 hours), the price of each NFT will be reduced at a uniform rate from 6,000 MATIC at the start to 300 MATIC at the end.&nbsp;</p><p>MATIC is the native token of the Polygon blockchain on which the NFTs are minted. You can see the current dollar value of 1 MATIC <a href=\"https://www.google.com/search?q=matic+to+usd\">here</a>.</p><p>Note: This price&nbsp;<strong>MAY</strong> be adjusted before the start of the auction to compensate for changes in the value of MATIC but you can generally expect the start and end prices to be equivalent to around $8,000 - $10,000 (Start) and $400 - $550 (End) so you should plan for this if you are interested in buying the NFT. You should also include $20 - $50 extra MATIC tokens to cover <a href=\"https://www.kraken.com/learn/what-is-a-blockchain-gas-fee\">gas fees</a>.</p><p>&nbsp;</p><h2><strong>Can't Wait for the Auction? Want Yours NOW?</strong></h2><p>You can actually purchase any one (or more) of the NFTs RIGHT NOW (i.e before the auction starts) but it would have to be at the maximum price of 6,000 MATIC.&nbsp;</p><p>The pros of getting yours right now are:</p><ul><li>You are able to take your time to go through all the NFTs at your own pace and make your choice without the pressure of constrained time.</li><li>You get the exact NFT(s) you want without the pressure of having to contend with others during the auction.&nbsp;</li><li>You eliminate the possibility of not being able to buy during the auction due to the possible rush of buyers.</li></ul><p>The only con is the price, so if you do not mind the price (you could actually see it as a way of supporting the project financially) then you may go ahead, you could even pay more for it if you are feeling really generous. If you will like to get one before the auction despite this con then please send me a DM. But if you have general questions you may leave them in the comments.</p><p>&nbsp;</p><h2><strong>Not Knowledgeable About Crypto?&nbsp;</strong></h2><p>I understand that a number of persons may not be too familiar with the process of crypto transactions and buying NFTs on OpenSea. I could have included some links to resources but I decided against doing that because if you don't know a lot about crypto stuff, it's much better and safer to get someone who knows about it to assist you.&nbsp;</p><p>&nbsp;</p><h1><strong>An APPEAL to Funders and Donors&nbsp;</strong></h1><p>Even if you may not have the time or are unable to participate for some reason, please consider sponsoring some person(s) who might be very motivated and willing to participate in the DAO but don't have the financial resources to buy an OG NFT during the auction.</p><p>Here are some of the things you could do to support us:</p><ul><li>Buy the NFT for yourself if you will like to become a DAO member</li><li>Buy for others who you feel will be able to contribute impactfully</li><li>Donate directly to EffectiveCauses (my organization which is behind the DAO project)</li><li>Donate directly to the DAO</li></ul><p>Note that at this time the organizations are not yet registered so any donations are not tax-deductible for now, but please don't let that dissuade you from helping EA become better,</p><p>&nbsp;</p><h1><strong>Distribution of Raised Funds from the First Auction</strong></h1><p>The funds from this first auction of 172 NFTs are meant to be a kind of pre-seed funding for the project. Assuming all 172 are bought at the lowest price, I expect to raise at least $75,000 (but this will be most likely higher because of the auction style, assuming that all of them are bought).</p><p>The primary purpose of the first $80K - $100K that will be raised is to provide funds that would enable me to take a break from my current day job (or quit entirely) to focus full-time on working on the DAO for the next 9 to 12 months.&nbsp;</p><p>If I can raise above $100K (which is quite likely if all NFTs are bought), the excess will be split equally between the DAO and EffectiveCauses (my own organization ) to be used to set up both organizations.&nbsp;</p><p>EffectiveCauses Organization is (as mentioned in my previous update) a think tank / lab for generating impactful EA-related ideas, raising the funds for the ideas and executing and/or incubating them.&nbsp;</p><p>It is an EA-aligned organization being set up by me and I have a handful of potential interns already indicating strong interest. Currently we meet once or twice a week IRL or virtually to discuss EA stuff and project ideas.&nbsp;</p><p>This DAO idea is just one out of the numerous ideas we have come up with so far. There are plenty more where this came from and I strongly believe that the organization can create significant impact with appropriate funding.</p><p>The long term vision is to evolve into a kind of regional hub to provide a strong anchor and support base for EA groups and activities in Sub Saharan Africa and a base from where the movement can expand into other parts of the continent.</p><p>Before now I was at the stage of seeking funding to properly set up the organization. This funding would enable us rent and set up an office space, hire developers and permanent staff and kickstart some of the other projects we have come up with.</p><p>The amount that goes to EffectiveCauses from this first NFT auction will be capped at $400K and any extra goes to the DAO.&nbsp;</p><p>&nbsp;</p><h1><strong>Proposed Distribution of Further Raised Funds&nbsp;</strong></h1><p>While the first NFT collection sales are proposed to be distributed as described in the preceding section, any subsequent funds raised from the second NFT sales onwards shall be distributed according to the formula proposed in this section. (This proposed formula is subject to further debate and ratification by the DAO)</p><p>In other words, funds from the second NFT collection sales (and all subsequent fund raises) shall be distributed according to the proposed percentages below.</p><ul><li>80% - MAIN DAO Charity fund. This is exclusively meant for issuing as grants, donations and other charitable interventions.</li><li>8% - for the DAO's organizational running costs e.g admin costs, legal, team budgets, misc. overhead costs, marketing/PR, remuneration / compensation etc</li><li>1.5% - as backup / emergency / reserve funds for the DAO (Limited to a maximum amount above which any excess is added to the main DAO Charity fund)</li><li>4% - to support EffectiveCauses Organization (the DAO's founding / incubating organization)</li><li>2% - goes to dedicated funding support for the DAO\u2019s fundraising events and activities</li><li>2% - for developing the Project's Lore (e.g the NFT characters) into valuable, revenue generating intellectual property (IP) (e.g for use in novels and stories, books, games, comics, animated and live-action movies, AR/VR/xR experiences, merch etc). The long term vision for the Lore is to turn its IP into a major additional source of funding inflow for the DAO (more on the Lore in my next update)</li><li>1.5% - for paying for kidney dialysis and kidney transplants for poor people in Low and Middle Income Countries (adding this to the list is probably debatable / controversial but it is a philanthropic cause area that I care about very very very very very very much, remember the mission also includes some aspects of general philanthropy)</li><li>1% - For developing ecosystem apps and <a href=\"https://en.wikipedia.org/wiki/Decentralized_application\">dApps</a> e.g the NFT minting dApp, a donation app with automatic processing of recurring donor pledges, a highly scalable, decentralized donation+fundraising web3 app to fully decentralize EA fundraising and grantmaking globally (similar to kickstarter or gofundme for EA projects), a small business loan platform like <a href=\"https://kiva.org\">kiva.org</a>. Also to create other revenue generating social enterprises, for-profit utility apps and platforms / ecosystem development apps.</li></ul><p>&nbsp;</p><h1><strong>Proposed Distribution of the MAIN DAO Charity Fund</strong></h1><p>As indicated in the preceding section, The MAIN DAO Charity fund is 80% of all total funds raised from the 2nd NFT collection onwards. This fund is set aside exclusively for the DAO to give out as grants or direct donations to other projects and organizations.</p><p>In this section I propose a sharing formula for how to distribute this MAIN DAO Charity fund but first some things to note:&nbsp;</p><ul><li>The DAO's mission is to both raise for EA and other charitable causes (but majorly for EA).&nbsp;</li><li>Therefore, some causes mentioned below may not fall under EA's core cause areas of interest and may be highly debatable from a rigorous epistemic standpoint by staunch EAs, and honestly I am not confident that I can offer convincing arguments for all of them with respect to epistemics.&nbsp;</li><li>But coming from someone who has lived all his life in an LMIC, I consider them of great importance (and quite neglected especially in LMICs) hence their inclusion (mostly under the general charitable causes).&nbsp;</li><li>I am however open to further discussion with DAO members on the merits of having them included in the list but I'm very strongly in favour of adopting this list especially since it leaves 45% unallocated for the DAO to decide how to disburse.</li><li>Even though some items might differ from the known \"official\" EA priorities list, I am deferring to the broader spirit of EA which is&nbsp;<strong>doing good effectively</strong>.&nbsp;</li><li>In light of this, I'm of the opinion that the most important thing in this context is to ensure that whatever interventions and grants the DAO funds in these non-core areas are done in an effective, efficient and evidence-led manner with measurable and significant net-positive impact.</li><li>Lastly, note that the percentages in this section sum up to 100%. This is 100% of the MAIN DAO Charity Fund (which is 80% of the total raised funds), so don't get it mixed up. (For example, 45% below refers to 45% of the MAIN DAO Charity fund, that is, 45% of 80% of the total raised funds.)&nbsp;</li></ul><p>&nbsp;</p><p>And, here's the proposed distribution formula:</p><ul><li>45% - To be decided by the DAO, may be used to increase the funding for specific categories already included below</li><li>15% - Donations to GiveWell recommended charities&nbsp;</li><li>10% - AI risks/Alignment, Longtermism, Biorisks, EA Careers and Cause Prioritization</li><li>5% - Climate change tail risks (aid, research, advocacy) and natural disasters (aid)</li><li>4% - Aid for trafficked and internally displaced persons (from war, terrorism, violence etc)</li><li>2% - Micro grants ($800 - $3,000) in any category (mostly for disbursement by Teams and the Scholars Guild. More on the teams and guilds in future updates)</li><li>2% - Nano grants (Less than $800) in any category (mostly for disbursement by Teams and the Scholars Guild.)</li><li>2% - Animal welfare&nbsp;</li><li>2% - \"Rebooting\" civilization after a global catastrophe&nbsp;</li><li>2% - Micro business loans for needy people in <strong>LMICs</strong> (like <a href=\"https://kiva.org\">kiva.org</a> but with initial loans supplied by the DAO)&nbsp;</li><li>1% - EA community building and digital infrastructure</li><li>10% - Other charitable causes&nbsp;<strong>in LMICs</strong> including:&nbsp;<br>- Infant mortality + maternal health care (especially in remote areas)&nbsp;<br>- Women's reproductive health&nbsp;<br>- Support for (poor) widows and orphans&nbsp;<br>- Support for disabled/differently-abled persons&nbsp;<br>- PLWAs (people living with AIDS)&nbsp;<br>- Primary health care in remote areas&nbsp;<br>- Water wells and solar-powered boreholes in remote settlements in LMICs&nbsp;<br>- Legal representation for wrongfully (and non-politically) imprisoned persons in LMICs&nbsp;<br>- Any other general charitable causes decided by the DAO</li></ul><p>&nbsp;</p><h2><strong>So What Next? Are You Interested?</strong></h2><p>Interested in this? Like to learn more or be a part of this? Do these:</p><ol><li>Prepare for the auction holding online on <a>OpenSea</a> from 12:01 AM UTC on 27 February 2023 to 11:59 PM UTC on 1 March 2023.&nbsp;</li><li>Follow the Project's account on Twitter:&nbsp; <a href=\"https://twitter.com/Effective_DAO\">@Effective_DAO&nbsp;</a></li><li>Visit the auction link at <a href=\"https://bit.ly/altruistwarriors\">https://bit.ly/altruistwarriors</a></li><li>If you do purchase one, please send a DM here or on Twitter so that we can send you an invite to the DAO's Private Discord.</li></ol><p>&nbsp;</p><h1><strong>Support Us</strong></h1><p>You can also support us by providing feedback and ideas in the comments and spreading the word about the Project to others in your network who you believe might be interested. You can also donate crypto to my organization (EffectiveCauses) or to the DAO. (Please DM me for this).</p><p>&nbsp;</p><h1><strong>Share this (Good) News</strong></h1><p>Please share this post to all EA groups, communities and networks and to your social media friends and followers. Thanks!</p><p>&nbsp;</p><h1><strong>Metaculus Anyone?&nbsp;</strong></h1><p>I would really love if someone could create some metaculus predictions to see if (and/or when) we will be able to meet our goal of raising at least $1 Billion every 12 months. Or if we can even get the DAO up and running at all!&nbsp;</p><p>&nbsp;</p><h1><strong>Don't Miss the Next Update</strong>&nbsp;</h1><p>You may follow the project on Twitter and turn on notifications if you wish to be notified of updates and when the auction has started. Twitter: <a href=\"https://twitter.com/Effective_DAO\">@Effective_DAO&nbsp;</a></p><p>&nbsp;</p><h1><strong>Content of the Next Update</strong></h1><p>In the next update I shall present more details about the artwork of the NFTs and the Lore of the project. Lore is a fictitious backstory common with most NFT projects.</p><p>The update will be posted here on EA Forum in about a day's time. I will add the link below when it has been posted.</p><p>Thank you very much for your time!</p><p>&nbsp;</p><p><i>[<strong>Update (25 February 2023):</strong></i></p><p><i>Taking into consideration the feedback received in the comments, I will not be posting any more DAO updates here on the forum. Updates shall henceforth be posted on our new substack at </i><a href=\"https://effectivedao.substack.com\"><i>https://effectivedao.substack.com</i></a><i>&nbsp;</i></p><p><i>Anyone still interested in this project may check / subscribe on the substack or follow us on:</i></p><p><i>Twitter: </i><a href=\"https://twitter.com/effective_dao\"><i>@EffectiveDAO</i></a><i>&nbsp;</i><br><i>Telegram : &nbsp;</i><a href=\"https://t.me/effdao\"><i>https://t.me/effdao</i></a></p><p><i><strong>Remember the auction dates:&nbsp;</strong> 12:01 AM UTC on 27 February 2023 to 11:59 PM UTC on 1 March 2023.&nbsp;</i></p><p><i>Auction link: </i><a href=\"https://bit.ly/altruistwarriors\"><i>https://bit.ly/altruistwarriors</i></a></p><p><i>More about the auction: &nbsp;</i><a href=\"https://effectivedao.substack.com/p/announcing-the-altruist-warriors\"><i>Click Here</i></a></p><p><i>If you do end up buying an NFT, please send me a DM here or on Twitter so that I can send you an invite to the DAO's Private Discord. ]</i></p>", "user": {"username": "DAOMaxi"}}, {"_id": "Zu5SAHqftaAbuZxsd", "title": "I'm About to Raise $1 Billion for (and Fix the Problems of) Effective Altruism Using a DAO. Anyone Care to Join Me?", "postedAt": "2023-02-20T10:48:57.072Z", "htmlBody": "<p><i>[<strong>Update (25 February 2023):</strong></i></p><p><i>Taking into consideration the feedback received in the comments, I will not be posting any more DAO updates here on the forum. Updates shall henceforth be posted on our new substack at </i><a href=\"https://effectivedao.substack.com\"><i>https://effectivedao.substack.com</i></a><i>&nbsp;</i></p><p><i>Anyone still interested in this project may check / subscribe on the substack or follow us on:</i></p><p><i>Twitter: </i><a href=\"https://twitter.com/effective_dao\"><i>@EffectiveDAO</i></a><i>&nbsp;</i><br><i>Telegram : &nbsp;</i><a href=\"https://t.me/effdao\"><i>https://t.me/effdao</i></a></p><p><i><strong>Remember the auction dates:&nbsp;</strong> 12:01 AM UTC on 27 February 2023 to 11:59 PM UTC on 1 March 2023.&nbsp;</i></p><p><i>Auction link: </i><a href=\"https://bit.ly/altruistwarriors\"><i>https://bit.ly/altruistwarriors</i></a></p><p><i>More about the auction: &nbsp;</i><a href=\"https://effectivedao.substack.com/p/announcing-the-altruist-warriors\"><i>Click Here</i></a></p><p><i>If you do end up buying an NFT, please send me a DM here or on Twitter so that I can send you an invite to the DAO's Private Discord. ]</i></p><h3>&nbsp;</h3><h3><strong>Summary / TL;DR &nbsp;</strong></h3><ul><li>In the last three months I've been developing the blueprint for a very ambitious and audacious plan (if I do say so myself).</li><li>Also in the last couple of months, there's been increasing calls for various changes and reforms in the Effective Altruism (EA) community.</li><li>My plan, I strongly believe, has the capability to solve (or mitigate to a great degree) several (maybe most, if not all) of the concerns raised in the various critical articles and comments on the EA community's problematic issues.&nbsp;</li><li>It will also make it possible (and feasible) to attempt raising at least $1 Billion in donations for EA within 12 months.</li><li>The plan is to create a DAO (<strong>Decentralized Autonomous Organization</strong>) with a core mission to raise <strong>at least</strong> $1 Billion USD for (mostly) effective altruism every year (and to give out grants selected by the DAO members through democratic processes).</li><li>A DAO is an internet-native, blockchain-enabled organization made up of a group of people with shared interests or goals and a shared treasury coming together to collaborate (usually over the internet) and to work towards achieving their shared goals.&nbsp;</li><li>Decisions in a DAO are made democratically with every member having a say in the affairs of the organization usually through the ability to discuss, debate and vote on issues relating to the DAO's activities, policies and governance. Financial controls are enabled by blockchain technology with transactions and voting results commonly recorded on the blockchain for full transparency.</li><li>Learn more about DAOs and how they work <a href=\"https://cointelegraph.com/daos-for-beginners/what-is-a-dao\">here</a> and <a href=\"https://consensys.net/blog/blockchain-explained/what-is-a-dao-and-how-do-they-work/\">here</a>.</li><li>A DAO is well suited for movements like effective altruism because it provides the tools and structural elements to efficiently manage and govern large communities at scale in a decentralized and democratic fashion.</li><li>My planned DAO aims to transform EA into a community-led movement by decentralizing governance and providing a way for the wider EA community to have a say in key decisions, grantmaking and fundraising.</li><li>Anyone who wishes to join the DAO would need to buy/obtain a membership NFT (<a href=\"https://www.investopedia.com/non-fungible-tokens-nft-5115211\">Non-Fungible Token</a>) that will grant them access to the DAO's platforms and give them voting abilities (plus other member-only capabilities). The sale of these NFTs also serve as one of the means of raising funds for the DAO.</li><li>I will post more updates in the coming hours and days to provide more details about my full plan, how it shall be executed and how anyone interested can buy the NFT and join the DAO.</li></ul><p>&nbsp;</p><p><strong>Full article:</strong></p><h1><strong>Who am I?</strong></h1><p>Let me start by briefly introducing myself and explaining my main motivations for embarking on this project.</p><ul><li>I have an engineering degree with 10+ years experience in technology consulting where I've led various teams to develop simple software, mobile/web applications and other ICT solutions.</li><li>Over the course of my career, I have worked on more than 30 web and mobile apps and supervised teams of up to 20 people. I have also grown and managed online communities having hundreds of thousands of members and subscribers.</li><li>My superpowers include product experience design, building online communities and growth hacking.</li><li>I\u2019m also a cryptocurrency and web3 hobbyist and have consulted for up to ten crypto/web3 projects including two fairly successful DAOs.</li></ul><p><i>(Note: I happen to be an extremely and obsessively privacy-oriented person (the type that always uses pseudonyms online) so I'm not really keen on putting my name and private details out here in public just yet - but this is not a burner account, it's my main and only EA forum account, just bearing a pseudonym. Notwithstanding, I've interacted with a handful of people in the EA community and they already know my real identity.&nbsp;</i></p><p><i>My intention is to fully \"</i><a href=\"https://en.wikipedia.org/wiki/Doxing\"><i>dox</i></a><i>\" myself to people who join the DAO. To them I will reveal my face and all my important personal details and even go through transparent KYC procedures if necessary.&nbsp;</i></p><p><i>However what I can say here in public is that I am a 40+ male from a country in Sub-Saharan Africa. )</i></p><p><i>[Edit (added after some feedback in the comments): If knowing my true identity is an important factor for you please feel free to DM me with a request for such. I'm not against revealing who I am, I just don't feel comfortable doing it here in public]&nbsp;</i></p><p>I first heard about effective altruism in September 2022 after coming across an article that mentioned Sam Bankman-Fried's $1 Billion donation/pledge/promise to EA. Out of curiosity I sought to learn more about this movement and why it deserved to receive such a massive sum from him.</p><p>On learning more about EA, I realized that many of its core values aligned with mine, so I decided to become a part of the community and find ways to contribute in any effective way I could.</p><p>I though of various things I could do to create impact (based on my strengths and experience) and eventually settled on founding an organization (christened <strong>EffectiveCauses Organization</strong>).&nbsp;</p><p>This organization is meant to be a kind of lab and think-tank for EA projects and ideas; our primary mission is to think up impactful and neglected EA-related project ideas, raise funds for the ideas and execute or incubate them.&nbsp;</p><p>The organization would also act as a kind of anchor point or base from which we could drive EA expansion (and provide extra support for EA communities) in Africa (which has very few or no EA communities in most countries).</p><p>Right now I'm actually just trying to get things off the ground with the organization. I've been holding meetings with some persons who have shown interest in being a part of the project and we have been brainstorming.&nbsp;</p><p>So far we have already come up with a number of ideas.&nbsp;</p><p>This DAO idea is one of them.</p><p>&nbsp;</p><h1><strong>What Exactly is a DAO? How Does it Work? Will it Work for EA?</strong></h1><p>DAO is an acronym for Decentralized Autonomous Organization and, <a href=\"https://en.wikipedia.org/wiki/Decentralized_autonomous_organization\">according to Wikipedia</a>, \"<i>...is an organization constructed by rules encoded as a computer program that is often transparent, controlled by the organization's members and not influenced by a central government.</i>\"&nbsp;</p><p>In general terms, DAOs are member-owned communities without centralized leadership. They are internet-based organizations that are owned and managed collectively by their members.&nbsp;</p><p>They usually have a shared treasury on the blockchain that is accessible only with the approval of the members; and in many DAOs, financial transactions, voting results and key governance decisions are also recorded on the blockchain for transparency and accountability.</p><p>The decision-making and governance processes in a DAO are inherently decentralized and democratic, usually carried out through proposals that are voted upon by members. Proposals are commonly preceded by a more general discussion or \"temperature check\" to gauge the opinions of members regarding the proposal and if it should be put to vote at all.&nbsp;</p><p>This sort of system ensures that the voice of every member counts and that each member has some influence in the direction the organization takes and in the decisions it makes.&nbsp;</p><p>DAOs are emerging as a new organizational paradigm enabled by blockchain technology. They have been used to successfully raise considerable funds in recent times both by for-profit and non-profit entities.&nbsp;</p><p>Two notable DAOs (amongst several others) are UkraineDAO (<a href=\"https://decrypt.co/94386/ukraine-dao-millions-in-ethereum-shows-what-dao-can-do\">raised $6.5 Million to support Ukraine</a>) and ConstitutionDAO (<a href=\"https://decrypt.co/86426/confusion-constitutiondao-fails-win-sothebys-auction\">raised $45 million</a> to buy a rare copy of the United States constitution).&nbsp;</p><p>This is just the tip of the iceberg when it comes to the huge potential of DAOs (note that these results were obtained despite the fact that the concept of DAOs is still relatively new and largely unexplored).</p><p>In addition to decentralized governance, a DAO will also provide a way for EA to diversify funding sources and democratize grant making.&nbsp;</p><p>&nbsp;</p><h1><strong>Two Pros and a Con</strong></h1><p>Main Pros of DAOs:&nbsp;</p><ul><li>DAO members decide on how the DAO is run, how money is spent, what projects are funded, how governance is done and various other key issues concerning the DAO.</li><li>There's democracy and transparency (which are both enabled by the blockchain).</li></ul><p>Main Con of DAOs:&nbsp;</p><ul><li>The major con is that DAOs are still largely an experimental concept with no best practices developed yet.</li></ul><p>&nbsp;</p><h1><strong>Can this DAO Really Raise at least $1 Billion for EA Every Year? Can it Really Fix EA's Issues? Can EA Governance and Grantmaking Actually be Decentralized and Democratized this Way?</strong></h1><p>To all these questions I would answer an emphatic YES with over 90% confidence (but only if the DAO is setup and managed properly).&nbsp;</p><p>The effective altruism movement is a prime example of an organization for which a DAO structure would be very effective (no pun intended) <strong>especially if done right</strong>.</p><p>The EA movement has been growing and expanding at an ever increasing rate in recent times. The movement is maturing and can no longer afford to NOT have a formal (or informal) decentralized co-ordination and governance backbone structure of this nature.&nbsp;</p><p>Many great movements have evolved such structures in one way or the other at some point in their life time and this helped them to handle the complexities of scale without disintegrating, splintering or imploding.&nbsp;</p><p>The effective altruism movement is fast approaching a tipping point where the absence of such a structure (or some other far reaching reform process / mechanism) may lead to the eventual splintering, disintegration or implosion of the movement as we know it today.</p><p>While my plan is not perfect, it's as close to \"doing it properly\" as I can envision.&nbsp;</p><p>During the ideation process, I observed and studied other successful DAOs and infused some of their best features into my framework. This adds to what gives me much confidence.&nbsp;</p><p>This DAO is not meant to be a separate / parallel / rival community to the current EA community or organizations, rather it is meant to be an addition to the movement: an instrument to draw the diverse EA communities and groups (scattered all over the world and online) closer.&nbsp;</p><p>A symbolic icon that all EAs can rally around and identify with as being as close to a collective representation of the broader movement as possible.</p><p>It is meant to be a formalized organizational construct drawing in and embracing EAs of all shades and hues of thought, beliefs, opinions and preferences without sacrificing the epistemic health, effectiveness, cohesion and morality quotient of the movement.&nbsp;</p><p>An organization that is collectively owned, controlled and governed by the entirety of the effective altruism community and geared towards growing and improving the entire movement (together with currently existing EA organizations, groups and sub-communities).&nbsp;</p><p>A mechanism that can finally help to provide a satisfactory answer to the multi-billion dollar question \"<a href=\"https://forum.effectivealtruism.org/posts/zuqpqqFoue5LyutTv/the-ea-community-does-not-own-its-donors-money?commentId=SuctaksGSaH26xMy2\">Who comprises the \"EA Community?</a>\".&nbsp;</p><p>Something that provides a true sense of identity and a symbol over which all EAs can confidently claim a real and equal sense of belonging and ownership.&nbsp;</p><p>A way to concretize what the phrase <i>EA Community</i> really means so that people will stop enclosing it within f*****g quotation marks ffs!</p><p>This DAO project is meant to be a community effort and my team and I will not be the only ones doing it all. The success of a DAO depends on passionate, dedicated members and quality / visionary / experienced handlers.</p><p>I'm not exactly an egghead and I'm not super-knowledgeable about EA cause areas and methodology. But I have experience with building and managing large online communities and I know how to construct DAOs.</p><p>So I need the eggheads and other knowledgeable and passionate EAs to join me in hashing out the basic structures, processes and policies around which this DAO will operate.&nbsp;</p><p>Please come join me let's build the EA of our dreams.</p><p>&nbsp;</p><h1><strong>DAO Membership</strong></h1><p>It is usual for people interested in joining a DAO to purchase some kind of blockchain-based token (fungible or non-fungible). This token grants the holder official membership which comes with voting rights and access to the members-only online groups, channels and collaboration platforms of the DAO.&nbsp;</p><p>In my plan, prospective members will need to buy/own a specific non-fungible token (NFT) to join the DAO.</p><p>An online auction for the first set of these NFTs will be held in a few days time (more on this in my next update to be posted in a few hours time).</p><p>&nbsp;</p><h1><strong>Why am I Doing This? (or My Many Motivations)&nbsp;</strong></h1><p>I am doing this in order to kill six gigantic birds (and many smaller ones) with one massive boulder (pardon the awful metaphor, I won't be killing any real birds, I promise).&nbsp;</p><p>The six birds are (in no particular order):&nbsp;</p><ol><li>SBF/FTX: Doing my bit for EA to make up for the SBF/FTX funding shortfall</li><li>Fix EA's Issues: Doing my bit to tackle the various issues / complaints raised by some people regarding EA governance, grantmaking, epistemics etc</li><li>Crowdfund my own funds for my own projects in a decentralized manner</li><li>For other EAs: Doing my bit to help others like me who are also finding it difficult to get funding for their EA projects</li><li>Creating a new, diversified funding source for EA</li><li>Researching on (and experimenting with) organizing people at scale</li></ol><p>&nbsp;</p><h2><strong>1. SBF / FTX</strong></h2><p>So SBF promised EA $1 Billion.<br>Sadly most/all of that is no more.&nbsp;<br>And Now there's a funding shortfall.&nbsp;<br>A challenge for the EA Community.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676870612/mirroredImages/Zu5SAHqftaAbuZxsd/lv2xuzyeg05imtwusv8r.webp\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676870613/mirroredImages/Zu5SAHqftaAbuZxsd/gwqypuhiwtmwof8dcomd.webp 98w, https://res.cloudinary.com/cea/image/upload/v1676870613/mirroredImages/Zu5SAHqftaAbuZxsd/aeookn3zqtgdisbzu6qn.webp 178w, https://res.cloudinary.com/cea/image/upload/v1676870613/mirroredImages/Zu5SAHqftaAbuZxsd/tdddpbq0iqwrlh4k1oez.webp 258w, https://res.cloudinary.com/cea/image/upload/v1676870613/mirroredImages/Zu5SAHqftaAbuZxsd/ebxdoovwi2jq224jrbpx.webp 338w, https://res.cloudinary.com/cea/image/upload/v1676870613/mirroredImages/Zu5SAHqftaAbuZxsd/mcfxpbj6vc5p8qo8fnzn.webp 418w, https://res.cloudinary.com/cea/image/upload/v1676870613/mirroredImages/Zu5SAHqftaAbuZxsd/amfhgp0k4gjhpinjluaw.webp 498w\"></figure><p>Challenge Accepted!</p><p>&nbsp;</p><h2><strong>2. Fix EA's Issues</strong></h2><p>In recent months there has been an uptick in posts critical of certain aspects of the EA community / movement including parts of its culture, governance, grantmaking process, funding sources etc. (See <a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1\">this</a>, <a href=\"https://time.com/6252617/effective-altruism-sexual-harassment/\">this</a>, <a href=\"https://forum.effectivealtruism.org/posts/hur3ejqvA2QmYEfZa/case-study-of-ea-global-rejection-criticisms-solutions\">this</a>, <a href=\"https://ineffectivealtruismblog.com/\">this</a>, <a href=\"https://forum.effectivealtruism.org/posts/nqgE6cR72kyyfwZNL/making-discussions-in-ea-groups-inclusive\">this</a> and <a href=\"https://forum.effectivealtruism.org/posts/wkLjwiGQ8fRdTDqou/the-ea-community-and-long-term-future-funds-lack\">this</a> for some examples of these critical posts).</p><p>So the main problems have already been identified and many people agree that something needs to be done about them. Some people have also proposed possible solutions that could be tried out.</p><p>But there is still no consensus on the best way forward.</p><p>Having given the matter some thought myself, it has become clear to me that a well-run DAO would solve (or mitigate to a large extent) many of the issues presented.&nbsp;</p><p>A DAO has the ability to transform the effective altruism movement into a community-driven affair with a flatter, more decentralized governance structure instead of the current top-down pyramidal structure where a few individuals at the top of the pyramid wield most of the funding and decision-making powers.&nbsp;</p><p>In a DAO, governance is not restricted to a specific group but spread out evenly with every community member having a say in the affairs and governance of the organization (for EA that would also include decisions on the issuance of grants amongst other things).&nbsp;</p><p>By using a DAO, it will also be relatively easy to embed checks and balances into the organic functioning of the organization, ensuring that there is a continuously active check on any excesses or deviations from the generally agreed norms, values, mission and vision.</p><p>So this DAO is my own solution which I am not only proposing but also going ahead to implement.&nbsp;</p><p>Right now my plan is still largely an untested (minimum viable) draft framework crafted based on my experience and knowledge of DAOs and Web3. While this draft is enough to kickstart the organization, a lot of things still need to be figured out and improved upon with time.&nbsp;</p><p>These improvements will be largely community-driven and fine-tuned through research, experimentation and continuous iteration.</p><p>The long term vision of the project is to eventually spin off (from the main DAO) new independent DAOs focused on specific EA Cause Areas, thus we could have a DAO just dedicated to Biorisks or AI risks or Global health or Animal welfare etc</p><p>Each of these new DAOs will be set up using the improved framework as reference. They will operate autonomously and largely independent of the parent DAO but will maintain close ties and alignment with it.</p><p>Eventually this framework will be released as an opensource resource which other DAOs could use as a starting template or reference model instead of having to reinvent the wheel.&nbsp;</p><p>In my next update, I will elaborate more on this framework and how it tackles the contentious issues in EA including that of uneven concentration and distribution of governance and grantmaking power as is currently the case.</p><p>&nbsp;</p><h2><strong>3. Raise My own Funds</strong></h2><h3><i>(or \"Test a New way for EAs to Raise funds / Democratize Fundraising\" or \"Take the (Funding) Bull by the Horns\")</i></h3><p>I mentioned earlier that I am currently in the process of setting up an organization whose core mission is to generate ideas for impactful but neglected EA projects and raise the funds to execute them.&nbsp;</p><p>We had actually generated some ideas but try as we might, we weren't able to secure any funding for any of them.</p><p>We applied to various funders and donors, even got some positive feedback for some of the proposals, but unfortunately none has been funded till date.</p><p>After more than two months of futile attempts at getting funding, it felt kind of frustrating and draining. I also got to learn that there are others in the community who have complained about facing similar challenges with securing funding.&nbsp;</p><p>That was when I decided to try a different strategy to raise funds for my organization's projects and at the same time see what I could do to make it easier for EAs in my shoes to raise funds for their own projects.</p><p>I decided to take the bull by the horn and crowdfund my own projects by myself, while at the same time crowdfunding for the wider EA community, especially those who have had a similar experience to mine in the course of trying to raise funds.</p><p>I'm therefore using this opportunity to test out the viability of a crowdfunding-inspired decentralized strategy for fundraising (as a possible alternative to the conventional way that most EAs are used to seeking funding, which is to apply for grants from the major funders and donor organizations).&nbsp;</p><p>In this strategy, the idea is for many people (i.e. the DAO members) to pool their fundraising efforts by individually going after many smaller donations from several donors (within and around their own networks) instead of chasing after one large lump sum from a big donor or funding organization.&nbsp;</p><p>&nbsp;</p><h2><strong>4. For other EAs Trying to Raise Funds</strong></h2><p>One of the oft-repeated complaints by EAs who have project ideas is the challenge faced when seeking funding from some of the major EA funders, which is apparently made worse in some cases by an alleged lack of transparency in the selection process and opaque rejection notices that often seem to be missing specific details as to why a project was rejected.</p><p>As stated in the previous point (#3), one of my motivations is to create a new funding source for these other EAs and also test out a decentralized crowdfunding strategy with which they can successfully raise their own funds by themselves for their Projects instead of putting all their hopes on the big funders (who, to be fair, are most likely regularly swamped by an unending deluge of proposals and funding requests).</p><p>&nbsp;</p><h2><strong>5. Create a &nbsp;New, Diversified Funding Source for EA</strong></h2><p>$1 Billion for EA every year is substantial enough to be a major new source of funding for the movement independent of the current major funders.</p><p>This will improve the financial resilience of the movement and offer some cushioning against unexpected events (like the SBF debacle) so that in the future, such events will not affect the movement's funding the way that the SBF thing did.</p><p>The availability of such new funds will also create further diversity in the movement's funding and reduce over-dependence on the big funding organizations. It will give the \"EA community\" its own funds (especially since it has already been made clear that <a href=\"https://forum.effectivealtruism.org/posts/zuqpqqFoue5LyutTv/the-ea-community-does-not-own-its-donors-money\">the \"EA community\" does not own its donors' money</a>).&nbsp;</p><p>Furthermore, the fact that these funds will be raised from a variety of sources and controlled by the broader community of the DAO's members means that their sourcing, management and use will not be in the hands of a small group of people or organizations but will be under the control of the wider EA community.&nbsp;</p><p>&nbsp;</p><h2><strong>6. Research and Experimentation</strong></h2><p>One thing that many of EA's critics agree on is the need to explore and experiment with various methods and approaches to solving or mitigating the issues identified.</p><p>Managing the DAO will afford an opportunity for EA to carry out governance and co-ordination research and experiments within a live organization.&nbsp;</p><p>The endgame of such experimentation for me is to develop a highly scalable opensource framework for decentralized fundraising/grantmaking that can be used by new (non-profit and for-profit) organizations to quickly get up and running.</p><p>&nbsp;</p><h1><strong>Here's My Plan in a Nutshell:</strong></h1><ol><li>Start by auctioning 172 NFTs in an online <a href=\"https://en.wikipedia.org/wiki/Dutch_auction\">Dutch Auction</a> to raise at least $75,000 \"pre-seed\" funds.</li><li>Onboard the 172 NFT buyers as the first cohort of DAO members (the \"<strong>O.G</strong>\"s as they are called in the crypto world)</li><li>Work with these OGs (for about 2 or 3 months) to set up, flesh out and test the basic structures, processes and policies of the DAO in preparation for full kick-off; and to prepare to onboard the second cohort of members.&nbsp;</li><li>Sell 5,555 NFTs to raise $20 Million for the DAO</li><li>Onboard these 5,555 NFT buyers as the second cohort of DAO members</li><li>DAO begins to issue first series of grants from the funds raised from the 5,555 NFT sales. Grants are debated and voted upon by the DAO members to decide which ones to fund</li><li>Begin various decentralized (and centralized) fundraising activities</li><li>Auction 10,000 more NFTs to raise at least $10 Million and onboard the third and final (for the time being) cohort of DAO Members</li><li>Organize continuous fundraising events and activities through commonly used fundraising methods including crowdfunding</li><li>Explore new ways and avenues of raising funds (including launching social enterprises, creating crowdfunding platforms, exploiting of the project's intellectual property etc)</li><li>Continue to raise funds and issue effective grants debated and voted upon by the community</li><li>Continuously evaluate the impact of grants and improve upon the effectiveness of the grantmaking process and the DAO in general.</li><li>Rinse and Repeat 9 to 12 Ad infinitum.</li><li>Eventually spin off new DAOs for specific EA cause areas</li></ol><p>&nbsp;</p><h1><strong>OK, So What Next?</strong></h1><p>I strongly believe that this plan is something worth pursuing so I need people who will like to collaborate, contribute, support, help out etc (and if they have the sufficient financial means) to consider buying one of the 172 NFTs during the upcoming auctions and join me in setting up the DAO.</p><p>If you cannot actively participate, you could instead buy one (or some) and donate them to someone / people you know who could contribute usefully.</p><p>This will be a very difficult project and my team and I cannot do it alone. It will require substantial effort, teamwork and input from other EAs. Therefore I'm looking for critical thinkers, organizational planners, EA cause area experts and highly motivated EAs to come on board to help me flesh out my ideas and build up the DAO.</p><p>In my next update I shall elaborate on my planned framework. The update will be posted here on EA Forum in a few hours time. I will add the link to the end of this article when it has been posted.</p><p>&nbsp;</p><h1><strong>Last Word: A Call to Adventure</strong></h1><p>Will this plan be easy to implement?&nbsp;</p><p>Not at all.&nbsp;</p><p>In fact I expect it to be a very difficult, very tasking and very time consuming process with many hurdles and many unknowns. It will be a journey fraught with many challenges. A scary adventure of epic proportions.</p><p>So if you like great adventures or near-impossible challenges then come and join me let's go on this journey together.</p><p>This DAO might just turn out to be the most impactful EA project ever. So if you care about doing good effectively then you should definitely be a part of this.</p><p>Join me let's make the most massive impact imaginable.</p><p>You just need to believe it can be done, embrace the vision, trust my lead and join me to FIGHT. Like a <strong>WARRIOR</strong>.</p><p>We can actually make this happen folks!.</p><p><strong>Please share this to all EA communities and groups.</strong></p><p>This is history in the making...</p><p>&nbsp;</p><h1><strong>More Updates On the Way&nbsp;</strong></h1><p>In the next update I shall go into more granular details about the framework.</p><p>I will also post other updates in the coming days providing even more details about the full plan, how it shall be executed and how anyone interested can obtain the NFT and join the DAO.&nbsp;</p><p>Below I will add the links to each update when they have been published.</p><p><strong>Here's the first update:</strong></p><p><a href=\"https://forum.effectivealtruism.org/posts/5JESNsWwuDq3i9obC/dao-2-details-of-my-plan-to-raise-usd1-billion-for-effective\">DAO#2: Details of My Plan to Raise $1 Billion for EA using a DAO (Decentralized Autonomous Organization)</a></p><p>&nbsp;</p><p><i>[<strong>Update (25 February 2023):</strong></i></p><p><i>Taking into consideration the feedback received in the comments, I will not be posting any more DAO updates here on the forum. Updates shall henceforth be posted on our new substack at </i><a href=\"https://effectivedao.substack.com\"><i>https://effectivedao.substack.com</i></a><i>&nbsp;</i></p><p><i>Anyone still interested in this project may check / subscribe on the substack or follow us on:</i></p><p><i>Twitter: </i><a href=\"https://twitter.com/effective_dao\"><i>@EffectiveDAO</i></a><i>&nbsp;</i><br><i>Telegram : &nbsp;</i><a href=\"https://t.me/effdao\"><i>https://t.me/effdao</i></a></p><p><i><strong>Remember the auction dates:&nbsp;</strong> 12:01 AM UTC on 27 February 2023 to 11:59 PM UTC on 1 March 2023.&nbsp;</i></p><p><i>Auction link: </i><a href=\"https://bit.ly/altruistwarriors\"><i>https://bit.ly/altruistwarriors</i></a></p><p><i>More about the auction: &nbsp;</i><a href=\"https://effectivedao.substack.com/p/announcing-the-altruist-warriors\"><i>Click Here</i></a></p><p><i>If you do end up buying an NFT, please send me a DM here or on Twitter so that I can send you an invite to the DAO's Private Discord. ]</i></p>", "user": {"username": "DAOMaxi"}}, {"_id": "qELZknyx8eBg7HskH", "title": "Metaculus Introduces New 'Conditional Pair' Forecast Questions for Making Conditional Predictions", "postedAt": "2023-02-20T13:36:19.504Z", "htmlBody": "<h3>Predict P(A|B) &amp; P(A|B') With New Conditional Pairs</h3><p>Events don't take place in isolation. Often we want to know the likelihood of an event occurring <i>if</i> another one does.</p><p>Metaculus has <a href=\"https://www.metaculus.com/questions/15205/introducing-conditional-pairs/\">launched <strong>conditional pairs</strong></a>, a new kind of forecast question that enables forecasters to predict the probability of an event given the outcome of another, and provides forecast consumers with greater clarity on the relationships between events.</p><p>This post explains the motivation behind conditional pairs, how to interpret them, and how to start making conditional forecasts.&nbsp;</p><figure class=\"image image_resized\" style=\"width:79.07%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676907416/mirroredImages/qELZknyx8eBg7HskH/tgulzaaddzltvk3mw13r.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/v0jrd8fnz4ijractnote.png 121w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/sbnrgh3bzslv5nuad4jv.png 201w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/kojle749swdgxhsqqfiv.png 281w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/ki8s0t11qnm6j4tgybuf.png 361w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/pd3hbwigiouw9gsqi8xl.png 441w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/kuqbpwzhrapkckngwa49.png 521w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/hfltx5xbtuiiqifwjapf.png 601w, https://res.cloudinary.com/cea/image/upload/v1676907416/mirroredImages/qELZknyx8eBg7HskH/vlmslj2ealf4j46r6yru.png 681w, https://res.cloudinary.com/cea/image/upload/v1676907416/mirroredImages/qELZknyx8eBg7HskH/wfhltmz4wnczoir7ysya.png 761w\"></figure><p><br>(Check out this <a href=\"https://youtu.be/ZvZeA0qvZXg\">video explainer</a> for more on conditional pairs and how to forecast with them.)</p><h3>How Do Conditional Pairs Work?</h3><p>A conditional pair poses two conditional questions (or \"conditionals\"):</p><ol><li>If Question B resolves <strong>Yes</strong> how will Question A resolve?</li><li>If Question B resolves <strong>No</strong> how will Question A resolve?</li></ol><p>For example, a forecaster may want to predict on a question such as this:</p><ul><li><a href=\"https://www.metaculus.com/questions/15127/goog-market-cap-below-1-trillion-by-2025/\">Will Alphabet\u2019s Market Capitalization Fall Below $1 Trillion by 2025?</a></li></ul><p>The forecast depends\u2014on many things. But consider one factor: Bing's share of the search engine market.</p><p>And so if one knew that <a href=\"https://www.metaculus.com/questions/14501/bing-market-share-5-or-more-in-march-2024/\">Bing's search engine market would be least 5% in March of 2024</a>, they could make a more informed forecast. They might assign greater likelihood to Alphabet's decline.</p><p>Our conditional pair is then:</p><ol><li>If Bing's market share <strong>is more than</strong> 5% in March, 2024, will Alphabet's market capitalization fall below $1 trillion?</li><li>If Bing's market share <strong>is not more than</strong> 5% in March, 2024, will Alphabet's market capitalization fall below $1 trillion?</li></ol><p>(Start forecasting on this <a href=\"https://www.metaculus.com/questions/15196/conditional/\">conditional pair here</a>.)</p><figure class=\"image image_resized\" style=\"width:62.9%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676907416/mirroredImages/qELZknyx8eBg7HskH/mlvimak0hfyouq5h1mp7.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/gwtbvuyddnq0u6g8pn9o.png 101w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/b4jwr8ulwqiak8xjlxkl.png 181w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/fjeumxf3rrsgjjg0q3cw.png 261w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/ioxich7l3fh66xhcsrea.png 341w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/eimdpj7nksufsvf8clb4.png 421w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/qk6lkhsj6rscclh1ieyo.png 501w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/z9cfartfstcb9h0lmlck.png 581w, https://res.cloudinary.com/cea/image/upload/v1676907416/mirroredImages/qELZknyx8eBg7HskH/byjkiki81evbqcnousu6.png 661w\"></figure><p>Two forecasters could have the same forecasts for Bing\u2019s market share and Alphabet\u2019s market cap while having very different mental models of their relationship. Conditional pairs help make these sometimes implicit differences explicit so they can be discussed and scored.</p><h3>Start Forecasting on Conditional Pairs</h3><p>Here are some newly created conditional pairs to start forecasting on:</p><ul><li><a href=\"https://www.metaculus.com/questions/15159/conditional/\">If Human-Machine Intelligence Parity Is Reached by 2040, Will the US Impose Compute Capacity Restrictions Before 2050?</a></li></ul><figure class=\"image image_resized\" style=\"width:65.18%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/gng9xzytlwerxirwvb0n.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/cigyvjaeym3ntj0xz50q.png 149w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/xnogwv81cjrmqrq62czh.png 229w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/cabbt1kfrua9arycbpoc.png 309w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/u6niobcjjid2gixz01cn.png 389w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/e1zlqaxaujnxu2vhuxnc.png 469w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/cy5gk0arifhppvsihh5n.png 549w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/nwnjc11jiimnmb8yicoo.png 629w, https://res.cloudinary.com/cea/image/upload/v1676907416/mirroredImages/qELZknyx8eBg7HskH/d9a2mxyifdckp14zm0wj.png 709w\"></figure><p>&nbsp;</p><ul><li><a href=\"https://www.metaculus.com/questions/15174/conditional/\">If Chinese GDP Overtakes US GDP by 2030, Will the US Go to War With China by 2035?</a></li></ul><figure class=\"image image_resized\" style=\"width:59.93%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676907474/mirroredImages/qELZknyx8eBg7HskH/wqbszlrghzpdlhbj3ze5.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676907474/mirroredImages/qELZknyx8eBg7HskH/pbeda7f5c1xrjhh5noee.png 149w, https://res.cloudinary.com/cea/image/upload/v1676907474/mirroredImages/qELZknyx8eBg7HskH/uogzngfawuantvyrvvkp.png 229w, https://res.cloudinary.com/cea/image/upload/v1676907474/mirroredImages/qELZknyx8eBg7HskH/odr2ykglsgvnf9juunl6.png 309w, https://res.cloudinary.com/cea/image/upload/v1676907474/mirroredImages/qELZknyx8eBg7HskH/n5fqilptmcayncvs8skz.png 389w, https://res.cloudinary.com/cea/image/upload/v1676907474/mirroredImages/qELZknyx8eBg7HskH/i0dsh5embzcu16946ynl.png 469w, https://res.cloudinary.com/cea/image/upload/v1676907474/mirroredImages/qELZknyx8eBg7HskH/djnfnzcqzvikltkryda9.png 549w, https://res.cloudinary.com/cea/image/upload/v1676907474/mirroredImages/qELZknyx8eBg7HskH/mcnokvjhf4aecpggqqrq.png 629w, https://res.cloudinary.com/cea/image/upload/v1676907474/mirroredImages/qELZknyx8eBg7HskH/i8ylh3trqacielh0yqbh.png 709w\"></figure><p>&nbsp;</p><ul><li><a href=\"https://www.metaculus.com/questions/15171/conditional/\">If There Is a Bilateral Ceasefire in Ukraine by 2024, Will There Be Large-Scale Conflict With Russia by 2030?</a></li></ul><figure class=\"image image_resized\" style=\"width:65.03%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/o9r1dhsud1id9cutx29j.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/e0bhomytklwop9dr5ngo.png 149w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/mogkulqvlmxavza6m9w2.png 229w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/quf39zuou34fflxb8zo8.png 309w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/axw06ej0loeq1g1mf4gb.png 389w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/mlpzbvas7nqryld1zr88.png 469w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/hqtqzb9huwjew0zqfzad.png 549w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/dfo7xyrik7hhoiq3jgsr.png 629w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/j4ypjn6qsabmo89z0dsg.png 709w\"></figure><p>&nbsp;</p><ul><li><a href=\"https://www.metaculus.com/questions/15168/conditional/\">If There Is a US Debt Default by 2024, Will Democrats Win the 2024 US Presidential Election?</a></li></ul><figure class=\"image image_resized\" style=\"width:65.34%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/g9680hokrxomtver0liv.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/ctpx0rnuy5fdoovqe2jg.png 149w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/i8txtmd9vflvsxbk6hcr.png 229w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/vcylmkoxcwjvzixez160.png 309w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/kigain9lkhcz34elmxgj.png 389w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/zrhfxfe19hjipez2mctx.png 469w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/xgudjehygbjw3o0vngju.png 549w, https://res.cloudinary.com/cea/image/upload/v1676907417/mirroredImages/qELZknyx8eBg7HskH/jap4vx0xnaph29ojuyhc.png 629w, https://res.cloudinary.com/cea/image/upload/v1676907416/mirroredImages/qELZknyx8eBg7HskH/kvklpbi32tfazgdowygt.png 709w\"></figure><h3>Parent &amp; Child Questions</h3><p>Conditional pairs like the above are composed of a \"Parent Question\" and a \"Child Question.\"</p><ul><li>Parent: Bing has 5% Market Share by March, 2024</li><li>Child: Alphabet's Market Cap is Below $1 Trillion by 2025</li></ul><p>Forecasts are made for the Child question <i>conditional</i> on the outcome of the Parent. Here, see that:</p><ul><li>In a world where Bing reaches 5% market share, the Metaculus community predicts Alphabet's decline is 56% likely.</li><li>In a world where Bing does not reach 5% market share, the Metaculus community predicts Alphabet's decline is 44% likely.</li></ul><figure class=\"image image_resized\" style=\"width:60.05%\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676837990/mirroredImages/qELZknyx8eBg7HskH/o3aqkmv4l7q4trd7699j.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676837991/mirroredImages/qELZknyx8eBg7HskH/iohrljpmkjxaooaiavct.png 90w, https://res.cloudinary.com/cea/image/upload/v1676837991/mirroredImages/qELZknyx8eBg7HskH/fa3bhmeixezijkcqs4s7.png 180w, https://res.cloudinary.com/cea/image/upload/v1676837991/mirroredImages/qELZknyx8eBg7HskH/sr4uagvu4zakl3dkl1bp.png 270w, https://res.cloudinary.com/cea/image/upload/v1676837991/mirroredImages/qELZknyx8eBg7HskH/ejas3abmy5qk5ax0dc91.png 360w, https://res.cloudinary.com/cea/image/upload/v1676837991/mirroredImages/qELZknyx8eBg7HskH/dfixseexsbos0xni8sjb.png 450w, https://res.cloudinary.com/cea/image/upload/v1676837990/mirroredImages/qELZknyx8eBg7HskH/u0ohssvutikt1q4rghch.png 540w, https://res.cloudinary.com/cea/image/upload/v1676837990/mirroredImages/qELZknyx8eBg7HskH/itu9wr5qiyxewamh8thf.png 630w, https://res.cloudinary.com/cea/image/upload/v1676837990/mirroredImages/qELZknyx8eBg7HskH/wk87mhbiigdm8h7igzgu.png 720w, https://res.cloudinary.com/cea/image/upload/v1676837990/mirroredImages/qELZknyx8eBg7HskH/jp7ustnmmbmcmhr1bta1.png 810w, https://res.cloudinary.com/cea/image/upload/v1676837990/mirroredImages/qELZknyx8eBg7HskH/cjzvjuc5kzqkxbunqmki.png 878w\"></figure><hr><p>Conditional pairs are a step toward Metaculus's larger goal of empowering forecasters and forecast consumers to quantify and understand the impact of particular events and policy decisions. Feedback is appreciated!</p>", "user": {"username": "christianM"}}, {"_id": "GPmkJfsMjsAghM3bT", "title": "Effective altruists are already institutionalists and are doing far more than unworkable longtermism - A response to \"On the Differences between Ecomodernism and Effective Altruism\"", "postedAt": "2023-02-21T18:08:53.735Z", "htmlBody": "<p>This is the long-form version of a <a href=\"https://thebreakthrough.org/issues/energy/effective-altruism-isnt-unworkably-longtermist-or-anti-institutionalist\">post</a> published as an invited reply to the <a href=\"https://thebreakthrough.org/issues/food-agriculture-environment/on-the-differences-between-ecomodernism-and-effective-altruism\">original essay</a> on the website of the Breakthrough Institute.</p><h1><br>Why I am writing this</h1><p>As someone who worked at the Breakthrough Institute back in the day, learned a lot from ecomodernism, and is now deeply involved in effective altruism\u2019s work on climate (e.g.&nbsp;<a href=\"http://founderspledge.com/climate\"><u>here</u></a>,&nbsp;<a href=\"https://www.givingwhatwecan.org/cause-areas/long-term-future/climate-change\"><u>here</u></a>, and&nbsp;<a href=\"https://www.volts.wtf/p/volts-podcast-johannes-ackva-on-effective\"><u>here</u></a>), I was very happy to find&nbsp;<a href=\"https://thebreakthrough.org/issues/food-agriculture-environment/on-the-differences-between-ecomodernism-and-effective-altruism\"><u>Alex\u2019s&nbsp; essay</u></a> in my inbox -- an honest attempt to describe how ecomodernism and effective altruism relate and differ.</p><p>However, reading the essay, I found many of Alex\u2019s observations and inferences in stark contrast to my lived experience of and in effective altruism over the past seven years. I also had the impression that there were a fair number of misunderstandings as well as a lack of awareness of many existing effective altruists\u2019 efforts. So I am taking Alex up on his ask to provide a view on how the community sees itself. I should note, however, that this is my personal view.</p><p>While I disagree strongly with many of Alex's characterizations of effective altruism, his effort was clearly in good faith -- so my response is not so much a rebuttal rather than a friendly attempt to clarify, add nuance, and promote an accurate mutual understanding of the similarities and differences of two social movements and their respective sets ot ideas and beliefs.</p><p>&nbsp;</p><h1>Where I agree with the original essay</h1><p>It is clear that there is a difference on how most effective altruists think about animals and how ecomodernists and other environmentalists do. This difference is well characterized in the essay. My moral intuitions here are more on the pan-species-utilitarianism side, but I am not a moral philosopher so I will not defend that view and just note that the description points to a real difference.</p><p><br>I also agree that it is worth pointing out the differences and similarities between ecomodernism and effective altruism and, furthermore, that both have distinctive value to add to the world.</p><p><br>With this clarified, let\u2019s focus on the disagreements:<br>&nbsp;</p><h1>Unworkable longtermism, if it exists at all, is only a small part of effective altruism&nbsp;</h1><p>Before diving into the critique of unworkable longtermism it is worth pointing out that \u201clongtermism\u201d and \u201ceffective altruism\u201d are not synonymous and that -- either for ethical reasons or for reasons similar to those discussed by Alex (the knowledge problem) -- most work in effective altruism is actually not long-termist.</p><p>Even at its arguably most longtermist, in August 2022,<a href=\"https://forum.effectivealtruism.org/posts/ZbaDmowkXbTBsxvHn/historical-ea-funding-data\"><u> estimated longtermist funding for 2022</u></a> was less than \u2153 of total effective altruist funding.</p><p>Thus, however one comes out on the workability of longtermism, there is a large effective altruist project remaining not affected by this critique.</p><p>The primary reason Alex gives for describing longtermism as unworkable is the knowledge problem:</p><p>&nbsp;</p><blockquote><p><i>\u201cBut I want to focus on the \u201cknowledge problem\u201d as the core flaw in longtermism, since the problems associated with projecting too much certainty about the future are something effective altruists and conventional environmentalists have in common.</i></p><p><i>[...]</i></p><p><i>We simply have no idea how likely it is that an asteroid will collide with the planet over the course of the next century, nor do we have any idea what civilization will exist in the year 2100 to deal with the effects of climate change, nor do we have any access to the preferences of interstellar metahumans in the year 21000. We do not need to have any idea how to make rational, robust actions and investments in the present.\u201d&nbsp;</i></p></blockquote><p>&nbsp;</p><p>This knowledge problem is, of course, well-known in effective altruism and its implications are grappled with, such as in discussions around the<a href=\"https://www.youtube.com/watch?v=jxVkAjJQ5dc\"><u> epistemic challenge to longtermism</u></a> and&nbsp;<a href=\"https://www.youtube.com/watch?v=fySZIYi2goY\"><u>cluelessness</u></a>. I would also wager that most effective altruists not working on longtermism will share the longtermist moral commitment (future beings matter as much as current ones) and will cite a version of the knowledge problem as the reason to focus on present beings.</p><p>&nbsp;</p><p>While I am not the one to defend interventions seeking to influence values milennia hence -- I am&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/secEczgstteSs2c7r/what-can-we-learn-from-the-empirical-social-science\"><u>not convinced</u></a> of this myself -- there appears to me to be a large amount of longtermist work that is absolutely workable.&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676816011/mirroredImages/GPmkJfsMjsAghM3bT/uw1sggg2gky30aap0anq.png\"></p><p><strong>Figure 1:</strong> How effective altruism\u2019s largest grantmaker spends their money (Visual from&nbsp;<a href=\"https://effectivealtruismdata.com/\"><u>Effective Altruism Data</u></a>, data from Open Philanthropy)</p><p>&nbsp;</p><p>It is no coincidence that most longtermist work is focused on reducing extinction risks, as these are longtermist issues that are both of great import but also -- crucially -- sufficiently near-term to make tractable and robustly good actions potentially knowable.&nbsp; As Sam Harris&nbsp;<a href=\"https://www.ted.com/talks/sam_harris_can_we_build_ai_without_losing_control_over_it\"><u>synthesized</u></a> quite clearly, finding artificial general intelligence to be an extinction<i> risk&nbsp;</i>requires minimal and weak assumptions that are very likely to be true. Similar arguments can be made about dangers from engineered pathogens given cost trends in bio-tech, or increased risks of nuclear war in a geopolitically tenser situation.&nbsp; Both of those issues, the risks of artificial intelligence which is becoming more widely appreciated with ever faster progress in AI capabilities as well as&nbsp;<a href=\"https://astralcodexten.substack.com/p/perhaps-it-is-a-bad-thing-that-the\"><u>alignment difficulties</u></a> at open display, as well&nbsp; as risks from pandemics, are issues where effective altruism has been prescient, mostly by extrapolating from observed trends and applying base rates, suggesting that not everything about the future is unknowable.</p><p>Put differently, agreeing with Alex, we do not need to know precisely how the world looks like in 2100, or the preferences of interstellar metahumans' in 21000, to find a lot of longtermist work that appears quite valuable and workable. &nbsp;</p><p>And, indeed, by default effective altruists will integrate the knowledge problem in their cause and strategy prioritization by being very skeptical of the tractability of many longtermist interventions and, in effect, investing primarily in no-regrets extinction risk reduction rather than actions requiring knowledge about future millenia.</p><p>It seems that, at most, the knowledge problem renders longtermist work outside existential risk reduction unworkable, leaving a vast amount of longtermist work on extinction risk as well as current generations work focused on beings alive today unaffected by the knowledge problem\u2019s more fatalistic implications.&nbsp;<br>&nbsp;</p><h1>The arguments for the alleged anti-institutionalisms do not hold</h1><p>While the claim of effective altruism\u2019s alleged anti-institutionalism is a key tenet of the original essay, I could not find evidence of this anti-institutionalism in the essay itself.&nbsp;</p><p>As far as I can tell the thesis on effective altruism\u2019s anti-institutionalism seems to be composed of two different form of indirect evidence:</p><ol><li>Effective altruism\u2019s anti-institutionalism made them more likely to be excited about crypto philanthropists.</li><li>We can explain what causes effective altruism focuses on by invoking anti-institutionalism.</li></ol><p><strong>Note that both of these claims are of the form \u201csomething in the world&nbsp;</strong><i><strong>can&nbsp;</strong></i><strong>be explained by an invoked mechanism\u201d (anti-institutionalism), not that this explanation is&nbsp;</strong><i><strong>likely</strong></i><strong>,&nbsp;</strong><i><strong>mutually</strong></i><strong>&nbsp;</strong><i><strong>exclusive</strong></i><strong>, or has been</strong><i><strong> compared</strong></i><strong> to alternative explanations and found the most&nbsp;</strong><i><strong>plausible</strong></i><strong> one.</strong> This is weak evidence to begin with -- saying an observed relationship in the world is consistent with a claimed explanation -- and, in my mind, these claims&nbsp; fall apart upon closer inspection. Let\u2019s cover both in turn.</p><h2>Critique of Claim I: \u201cEffective altruism\u2019s anti-institutionalism made them more likely to be excited about crypto philanthropists.\u201d</h2><p><br>Here is the quote from the original essay:<br>&nbsp;</p><blockquote><p><i>\u201cThat\u2019s why I\u2019ve grown increasingly queasy over the last few years as these ideas [from effective altruism] have been associated most strongly with crypto-philanthropists, and intellectual leaders who I thought were dangerously enthusiastic for crypto-heavy funding. And the unfortunate conclusion I\u2019ve come to is that the risible crypto-philanthropists and the admirable effective altruism practitioners have something foundational in common: a disdain for institutions.\u201d</i></p></blockquote><p>&nbsp;</p><p>(Before going into the details of this argument, just a quick note that even at the height of crypto, large crypto-philanthropists were not the majority of funding in effective altruism. At the height of FTX-funding, FTX was&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ZbaDmowkXbTBsxvHn/historical-ea-funding-data\"><u>estimated</u></a> to be about 20% of total EA funding, so this also seems an issue where perception and reality diverge).</p><p>&nbsp;</p><p>I am not one of those intellectual leaders, but from what they have written publicly, it seems clear that being so optimistic about crypto donations is something they see as a mistake.</p><p>The question here, though, is whether this mistake was made more likely by a shared \u201c<i>foundational anti-institutionalism</i>\u201d? While impossible to tell for certain, I am quite skeptical of this argument for three reasons:</p><p>First, if there is one force in American politics that is committed to institutionalism, then it is President Biden\u2019s Democrats fighting against populist challenges, threats to electoral integrity, and other challenges to American institutions, and seeking to address societal problems through an increased role of public policy. It does not get more institutionalist than that.&nbsp; This very same party had SBF as their&nbsp;<a href=\"https://fortune.com/2022/11/10/sam-bankman-fried-ftx-joe-biden-democratic-party-second-biggest-donor/\"><u>second-largest donor</u></a>. Were they all anti-institutionalists?<br><br><strong>Put differently: is there even something to explain here -- are effective altruists more positively inclined towards crypto donors than other groups seeking donations for what they deem critically important work?</strong><br>&nbsp;</p><p>Second, prominent effective altruists, such as&nbsp;<a href=\"https://twitter.com/robertwiblin/status/1359518195279949824\"><u>Rob Wiblin</u></a>, have been publicly critical of crypto\u2019s contribution to society, at the height of the crypto boom, way before crypto, SBF and FTX tanked.</p><p>Third, in my time in effective altruism, I have never heard a prominent effective altruist argue for crypto donors&nbsp; because of a shared anti-institutionalism. More importantly, I have also never heard a prominent effective altruist argue for decentralized block chain technology, or decentralized social forms more generally, as a key solution to any of the problems that effective altruists tend to care about (reducing existential risks (requiring global cooperation!), reducing global poverty, and increasing animal welfare (in large parts through advocacy for policy change and lobbying/pressuring Big Ag!). As I will dive into more in the last section below, discussed and funded solutions to these problems are often heavily institutionalist and not much alike to how some crypto enthusiasts think about solving social problems.&nbsp;<br>&nbsp;</p><p>To be sure, tech donors -- crypto or otherwise -- often have anti-institutionalist priors and a libertarian streak. But this is nothing effective altruists seek to reinforce and, indeed, it is just one of those idiosyncratic donor preferences that effective altruists seek to eliminate from giving decisions by encouraging donors to give to charities identified based on thousands of hours of research conducted by cause area experts or, ideally, to&nbsp;<a href=\"https://www.givingwhatwecan.org/why-we-recommend-funds\"><u>expert-advised funds</u></a>. Dustin Moskovitz and Cari Tuna, effective altruism\u2019s largest donors, largely trust the staff of Open Philanthropy to make the best decisions based on rigorous analysis and Open Philanthropy\u2019s expert grantmakers. And this kind of behavior is the norm, rather than exception, within effective altruism.</p><p>&nbsp;</p><p>As I&nbsp;<a href=\"https://www.volts.wtf/p/volts-podcast-johannes-ackva-on-effective\"><u>discussed before</u></a>, a fair amount of my work as an effective altruist grantmaker in climate is to convince donors -- particularly tech donors -- from&nbsp;<i>outside</i> effective altruism that their anti-institutionalist priors, exemplified by a focus on direct interventions and on private investment and a skepticism of advocacy-focused philanthropy, are a barrier to the impact they seek to have. In other words, effective altruist resources are intentionally spent to correct anti-institutionalist biases of non-effective-altruist donors.</p><p>Thus, it seems to me that the conflation of crypto-donors and effective altruism is not so much the source of an allegedly shared anti-institutionalism, but rather a shared timing when both rose to greater prominence.</p><p><br><br>&nbsp;</p><h2>Critique of Claim II: \u201cAnti-institutionalism explains effective altruist cause selection\u201d</h2><p>Here is the quote from the original essay that makes this claim:</p><blockquote><p><i>\u201cBut this anti-institutionalism does explain why effective altruism is mostly concerned with \u201clow-hanging fruit\u201d development problems and highly uncertain existential risk, and mostly not with climate change, agricultural productivity, public education, inequality, policing and crime, violence and war, \u201ccost-disease socialism,\u201d or all the other difficult, wicked problems that require governance and institutions to address.\u201d</i></p></blockquote><p>&nbsp;</p><p>(Ironically, as I'll discuss in the last section, most effective altruists would also think that the \"highly uncertain existential risk\", such as advanced artificial intelligence, requires institutional solutions).<br>&nbsp;</p><p>At its core, the claim is that an anti-institutionalist bias drives the cause selection of effective altruists and thus that the observed cause selection of effective altruists reveals the latent alleged anti-institutionalism. To see that this seems an unlikely explanation of what is actually happening, let\u2019s dive into how effective altruists prioritize causes and, as I am most familiar with it, I will focus on climate.<br>&nbsp;</p><p>Much of the first-order rough prioritization that effective altruists tend to engage in when prioritizing causes is done through the so-called&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/itn-framework\"><u>ITN framework</u></a>, evaluating causes by how they fare on the product of their importance (I), tractability (T) and neglectedness (N).</p><p>Thus, as a first approximation, if effective altruists deprioritized climate and the other issues in Alex\u2019s list because of their alleged anti-institutionalism this would show up in statements about a perceived lack of tractability, something like:&nbsp;</p><p>&nbsp;</p><blockquote><p><i>\"Climate is important and neglected, but it requires engaging with policy and we think this is intractable so this is why we don't prioritize it.\"</i><br>&nbsp;</p></blockquote><p><strong>This hypothetical reasoning invoking anti-institutionalism is pretty much the&nbsp;</strong><i><strong>exact opposite</strong></i><strong> of the actual reasoning why effective altruists do not prioritize climate change</strong>, namely a combination of a low neglectedness, with climate receiving vast societal and philanthropic attention compared to other risks of similar magnitude, and a lower importance than risks with a higher probability of causing (near-)extinction such as engineered pandemics, nuclear war, or advanced artificial intelligence.</p><p>&nbsp;</p><p>To give just two examples that strike me as particularly illustrative and uncontroversial in illustrating the imbalance: reducing risk from nuclear war receives about 1/100 of philanthropic attention as climate does<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvoiytmjygsa\"><sup><a href=\"#fnvoiytmjygsa\">[1]</a></sup></span>, and societally we seem to fail at mobilizing resources to address biorisk, despite an abundantly salient warning shot in the form of COVID-19.&nbsp;</p><p>One might disagree with effective altruists\u2019 estimates on problem importance. Indeed, I do disagree with mainline effective altruist estimates on the importance of climate change, as I think they underestimate indirect risks.</p><p><strong>But in my many years of interacting with effective altruists on climate, I have yet to encounter someone making a serious argument for not prioritizing climate because of its institutional messiness</strong> and the lack of tractability. Indeed, when we compare climate to other catastrophic risks, climate\u2019s high tractability -- it\u2019s clear what to do and there is a massive societal response that can be leveraged through well-targeted advocacy -- is the&nbsp;<a href=\"https://www.givingwhatwecan.org/cause-areas/long-term-future/climate-change\"><u>central argument in its favor</u></a>.</p><p>Zooming out, effective altruism does not engage in most causes, because the movement is still small and we perceive some causes --in particular around extinction risks, helping the poorest, and reducing animal suffering -- as particularly pressing as well as promising to be able to make a large positive difference on.</p><p>This does not mean that we believe other issues are not important.&nbsp;<strong>Crucially, it also does not mean that we chose to not engage on these issues because they involve the messy business of institutional change and politics</strong>, as the next section will hopefully carry home.&nbsp;</p><h1>Effective altruists do not always engage, but when they do, it is often&nbsp;<i>very</i> institutionalist</h1><p>So far I have mostly focused on showing that the arguments for the alleged anti-institutionalism of the original essay do not hold under scrutiny.</p><p>Lastly, I will try to make a more positive case, showing how the mode in which effective altruists engage is often heavily institutionalist.&nbsp;</p><p>Note that it would be quite confused for effective altruists to deprioritize causes because they involve engaging in the messy business of institutional reform, while -- at the same time -- when deciding to engage on a given cause, to choose a heavily institutionalist strategy of doing so.&nbsp;</p><p><br>Put differently:<strong> If effective altruists had the generalized anti-institutionalist bias that Alex claims this would mean that effective altruists would need to believe that requiring institutional change disqualifies most causes, while -- at the same time -- institutional change is magically the most effective strategy in those select causes effective altruists seek to engage in. This would be quite a mental acrobatic.</strong>&nbsp;</p><p>Thus, effective altruists engaging with heavily institutionalist strategies should be taken as strong evidence that the alleged anti-institutionalism of effective altruism does not exist.&nbsp;</p><p>&nbsp;</p><p>So, what do effective altruists actually do once they decide to engage on a cause?&nbsp;</p><p>In my day job, as the lead on effective altruism\u2019s largest philanthropic effort on climate (the&nbsp;<a href=\"http://founderspledge.com/climate\"><u>Founders Pledge Climate Fund</u></a>), all my team and I are doing is finding and funding organizations that seek to improve societal response to climate through advocacy that makes our collective response less myopic, more risk-aware, more technology-inclusive and more focused on global emissions. Grantees executing this work advise policy makers, play a field-building role in a new sector such as carbon removal, or, in some cases, even directly support ambitious policy makers get their messages out. This is no different than the institutionalist strategy Alex describes for ecomodernists.</p><p>My colleague Christian Ruhl, who runs a fund on&nbsp;<a href=\"https://founderspledge.com/funds/global-catastrophic-risks\"><u>reducing global catastrophic risks</u></a>, also does not seem to have gotten the anti-institutionalist memo, counseling policy makers in the&nbsp;<a href=\"https://thebulletin.org/2022/07/why-policy-makers-should-beware-claims-of-new-arms-races/\"><u>Bulletin of Atomic Scientists</u></a>, consulting an extensive network in the national defense community, and&nbsp;<a href=\"https://founderspledge.com/stories/berkeley-risk-and-security-lab\"><u>seeding</u></a> new organizations such as the Berkeley Security Risk and Security Laboratory partially motivated by&nbsp; the team\u2019s track record of working with the Department of State\u2019s Bureau of Arms Control, Verification, and Compliance, with the National Laboratories, and with the UN Institute for Disarmament Research, among others.&nbsp;&nbsp;&nbsp;&nbsp;</p><p>&nbsp;</p><p>And we are not alone in this.</p><p>&nbsp;</p><p>Our colleagues at&nbsp;<a href=\"http://openphilanthropy.org\"><u>Open Philanthropy</u></a>, effective altruism's largest grantmaker, are heavily institutionalist as well. Not only did they commission their own&nbsp;<a href=\"https://www.openphilanthropy.org/research/history-of-philanthropy-work-weve-commissioned/\"><u>research</u></a> on evaluating the&nbsp;<a href=\"https://www.openphilanthropy.org/research/the-role-of-philanthropic-funding-in-politics/\"><u>value of policy-oriented philanthropy</u></a> and of&nbsp;<a href=\"https://www.openphilanthropy.org/research/new-report-on-early-field-growth/\"><u>field-building</u></a> -- often to influence institutions and public policy in the long run -- they are also executing on this strategy across all areas they engage in.</p><p>One of the most dramatic successes of this work include the&nbsp;<a href=\"https://openwingalliance.org/impact\"><u>Open Wing Alliance</u></a> improving chicken welfare worldwide, where EA strategy to pressure big agricultural producers for cage-free reforms was arguably more institutionalist than prior efforts of the animal movement.&nbsp;</p><p>Much work on risks in advanced general intelligence is focused on increasing awareness of the risk by policy makers and building adequate institutional responses, most notably the EA-founded<a href=\"https://www.governance.ai/\"><u> Centre for the Governance of AI</u></a>, but also the&nbsp;<a href=\"https://thefuturesociety.org/\"><u>Future Society</u></a>, and the&nbsp;<a href=\"https://futureoflife.org/\"><u>Future of Life Institute</u></a>. Indeed, effective altruism has arguably&nbsp;<a href=\"https://timelines.issarice.com/wiki/Timeline_of_AI_safety\"><u>built the field of AI safety</u></a> with major&nbsp;<a href=\"https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies\"><u>publications</u></a>, and&nbsp;<a href=\"https://futureoflife.org/event/ai-safety-conference-in-puerto-rico/\"><u>initial conferences</u></a> bringing together relevant actors from academia and industry. This kind of field-building and mainstreaming strategy would make no sense if EA had a fundamental disdain for institutions.</p><p>Similarly, much of the EA community\u2019s work on pandemic preparedness and biosecurity involves working with and reforming institutions such as Open Philanthropy\u2019s support for the <a href=\"https://biodefensecommission.org/\"><u>Bipartisan Commission on Biodefense</u></a>, and the<a href=\"https://www.centerforhealthsecurity.org/\"><u> Center for Health Security</u></a> at Johns Hopkins University doing lots of policy work on biosecurity, as well as the&nbsp;<a href=\"https://www.nti.org/\"><u>Nuclear Threat Initiative</u></a> on nuclear risks.&nbsp;</p><p>Even in the field of Global Health and Development, where the anti-institutionalist critique appears most consistent with the evidence -- though I would argue that the focus on malaria nets comes from GiveWell\u2019s strategy to provide high-certainty donation options and its path-dependent dominance in the space rather than an inherent anti-institutionalism -- there is actually fair amount of institutionalist work. Just over the past year, Open Philanthropy launched new programs in&nbsp;<a href=\"https://www.openphilanthropy.org/focus/south-asian-air-quality/\"><u>South Asian Air Quality</u></a>. as well as&nbsp;<a href=\"https://www.openphilanthropy.org/focus/global-aid-policy/\"><u>Global Aid Policy</u></a>, both of which are unlikely to focus on direct service delivery interventions, but rather research and advocacy.&nbsp;</p><p>I would thus stipulate that effective altruism, like ecomodernism, already understands that engaging with institutions is at the core of improving the outcomes we care about.<br><br>&nbsp;</p><p><strong>It seems to me that what Alex is picking up on, then, is not an anti-institutionalism of effective altruism, but rather an anti-institutionalism of a particular donor class</strong> -- crypto donors and, oftentimes more broadly, tech donors. But both ecomodernism and effective altruism need to grapple with this anti-institutionalism to ensure that the good these donors seek to achieve in the world is not limited by limiting beliefs about the ability to change and improve institutions. Put differently,&nbsp;<strong>anti-institutionalist beliefs are a challenge for ecomodernists and effective altruists alike</strong> (and anyone else who seeks to improve the world and believes that this requires better collective action, for that matter).</p><p>&nbsp;</p><h1>There are real differences between ecomodernism and effective altruism in scope and approach and this is how it should be</h1><p>To me, ecomodernism seeks to answer the question<i> \u201chow much mileage do we get from applying a humanist, pro-technology, density-is-beautiful vision to broadly environmental issues?\u201d.&nbsp; </i>This is an important contribution that provides valuable answers, often neglected ones that effective altruists will tend to support as well, on a host of issues.</p><p>But it is something else and something narrower than what effective altruism seeks to accomplish -- trying to find the most effective ways to improve the world as much as possible. The latter project necessarily requires tools that ecomodernism does not require, such as a methodology to prioritize amongst causes and strategies to engage in the world and, relatedly, an explicit strategy to deal with high-uncertainty situations.&nbsp;</p><p>The latter project also requires weaker assumptions as it operates around a wider set of potential causes. For example, I would feel uneasy describing effective altruism as \u201cpro-technology\u201d given that three of the top concerns effective altruists worry about are&nbsp;<a href=\"https://80000hours.org/problem-profiles/artificial-intelligence/\"><u>artificial general intelligence</u></a>,&nbsp;<a href=\"https://80000hours.org/problem-profiles/preventing-catastrophic-pandemics/\"><u>engineered pathogens</u></a>, and&nbsp;<a href=\"https://80000hours.org/problem-profiles/nuclear-security/\"><u>nuclear weapons</u></a>. Thus, effective altruism\u2019s relationship to technology seems more complex and those socio-technological risks are ones where ecomodernism does, as far as I can tell, has little to offer, as it has mostly engaged with environmentalist issues where the use of more advanced technologies can be the solution rather than an intractable challenge.<br><br>This is fine and good as is, as both ecomodernism and effective altruism are relatively young and small movements that can be complementary. But we should be clear that the differences are not related to attitudes towards institutions and institutional change and that effective altruism is a far bigger project than an \u201cunworkable longtermism\u201d, whether or not one agrees with that qualifier.</p><p><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvoiytmjygsa\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvoiytmjygsa\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In 2021, there were only about $32 million in nuclear-related philanthropic grants (<a href=\"https://maps.foundationcenter.org/#/list/?subjects=SS1060&amp;popgroups=all&amp;years=2021&amp;location=6295630&amp;excludeLocation=0&amp;geoScale=ADM0&amp;layer=recip&amp;boundingBox=-139.219,-31.354,135,66.513&amp;gmOrgs=all&amp;recipOrgs=all&amp;tags=all&amp;keywords=&amp;pathwaysOrg=&amp;pathwaysType=&amp;acct=psfg&amp;typesOfSupport=all&amp;transactionTypes=all&amp;amtRanges=all&amp;minGrantAmt=0&amp;maxGrantAmt=0&amp;gmTypes=all&amp;minAssetsAmt=0&amp;maxAssetsAmt=0&amp;minGivingAmt=0&amp;maxGivingAmt=0&amp;andOr=0&amp;includeGov=1&amp;custom=all&amp;customArea=all&amp;indicator=&amp;dataSource=oecd&amp;chartType=trends&amp;multiSubject=1&amp;listType=gm&amp;windRoseAnd=undefined&amp;zoom=0\"><u>Peace and Security Funding Map</u></a>) and Macarthur, the biggest funder in the field, is withdrawing its support, which had been over 25% of the field. This compares to an estimated&nbsp;<a href=\"https://www.climateworks.org/report/funding-trends-2022/\"><u>3bn</u></a> in climate philanthropy by foundations in 2021 (<a href=\"https://www.climateworks.org/report/funding-trends-2022/\"><u>ClimateWorks</u></a>), with the majority of philanthropic funding in climate coming from individuals with a total estimated closer to 10bn/year.</p></div></li></ol>", "user": {"username": "jackva"}}, {"_id": "Bi8av6iknHFXkSxnS", "title": "Should ChatGPT make us downweight our belief in the consciousness of non-human animals?", "postedAt": "2023-02-18T23:29:38.153Z", "htmlBody": "<p>The remarkable capabilities of ChatGPT and other tools based on large language models (LLMs) have generated a fair amount of idle speculation over whether such programs might in some sense be considered sentient. The conventional wisdom could be summarized as: of course not, but they are way spookier than anticipated, in a way that is waking people up to just how weird it might be interact with a truly intelligent machine.</p><p>(It is also worth noting that some very knowledgeable people are open to granting LLMs at least a <a href=\"https://twitter.com/ilyasut/status/1491554478243258368?t=5OqmaXXO7SmZqEOZpCxI8g&amp;s=19\">smidgen of consciousness</a>.)</p><p>Given that LLMs are not, in my view, in any way conscious, they raise another question: should the human-like behavior of non-sentient computer programs cause me to re-evaluate my opinions on the consciousness of other species?</p><p>My beliefs about the consciousness of other species are held lightly. Because there is no general scientific understanding of the material basis of consciousness, all I have to go on is intuition based on my sense of the complexity of other animals and their similarity to the only animals I know to be conscious (i.e., humans).</p><p>Over time, my opinions have shifted in the direction of allowing more animals into the \"consciousness club.\" At one point, my beliefs were roughly thus:</p><ul><li>Humans: conscious</li><li>Non-human primates: almost certainly conscious</li><li>Dogs: overwhelmingly likely to be conscious (just look at that face)</li><li>Mice: Probably conscious, but getting trickier to litigate</li><li>Fish and amphibians: maybe conscious in some limited way but probably not</li><li>Insects: almost certainly not conscious</li><li>Single-celled organisms: not conscious</li></ul><p>I certainly may be guilty of chauvinism towards non-mammals, but, again, these opinions are lightly held.</p><p>These days, based on a greater awareness of the complexity of many animal behaviors, I'm more likely to let fish and amphibians into the club and admit to greater uncertainty regarding insects. (Sorry, protozoa.)</p><p>LLMs, however, raise a challenging counterexample to the idea that complexity of behavior serves as evidence of consciousness. The internet abounds with examples of these programs engaging in conversations that are not only shockingly sophisticated but also deeply unsettling in the way they seem to convey personality, desire, and intent.</p><p>I don't think many people seriously entertain the notion that these programs are conscious. Consciousness aside, are LLMs, in some sense, smarter than a bee? A trout? A squirrel? They clearly have capabilities that these other animals don't, and just as clearly have deficits these other animals don't. If LLMs are an existence proof of extremely complex behavior in the absence of consciousness, should we revise our beliefs about the likelihood of consciousness in other animals?</p><p>One obvious objection is that complexity might be a correlate of consciousness in biological organisms but not in machines. For example, the U.S. electrical grid is extremely complex, but no one suspects it of being sentient, because it lacks the basic features and organization of other conscious systems.</p><p>We know fairly well how LLMs work. We know that they are organized in a way that is not biologically plausible. Brains have features such as memory, attention, sensory awareness, and self-reflexivity that may be necessary to support consciousness.</p><p>In this view, LLMs can churn out human-like output via an extremely complex mathematical function while revealing little about animal minds. LLMs don't have any interiority. They don't even have a representation of the world. (This is evident in the way they are happy to spout reasonable sounding untruths.) We might therefore &nbsp;conclude that LLMs teach us nothing about consciousness, even if they may hold lessons about certain functions of brains (such as language construction).</p><p>I think this is a powerful objection, but also maybe a little too quick. Insects such as the <a href=\"https://en.wikipedia.org/wiki/Sphex\">Sphex wasp</a> are famous for displaying behavior that is both fairly complex and also extremely stereotyped. And it's worth underscoring just how deeply spooky conversing with LLMs can be. It's easy enough for me to write off ChatGPT as a machine. It feels somewhat dissonant, however, to write ChatGPT off as a machine while also allowing that the architecture of a spider's brain makes it conscious of the world. These things both can be true. But are they?</p><p>It strikes me as more plausible that it once did that simpler organisms -- including, yes, fish and amphibians -- might be \"mere automatons\" displaying behavior that, like ChatGPT, seems to carry intentionality but is really \"just\" a sophisticated algorithm.</p><p>As before, I hold this opinion lightly.</p>", "user": {"username": "splinter"}}, {"_id": "bQnJzDaFBwrtPLR6f", "title": "Interview with Roman Yampolskiy about AGI on The Reality Check", "postedAt": "2023-02-18T23:29:52.757Z", "htmlBody": "<p>On my podcast, I recently interviewed computer scientist Dr. Roman Yampolskiy about the threat of AGI, trying to make the topic accessible to a broader range of listeners.&nbsp;<br>Hope some of you find it useful.&nbsp;</p>", "user": {"username": "Darren McKee"}}, {"_id": "rpHW5FnAqiJ7jwwp3", "title": "AGI in sight: our look at the game board", "postedAt": "2023-02-18T22:17:44.381Z", "htmlBody": "", "user": {"username": "AndreaM"}}, {"_id": "juTTR6wrz2gNYGjjR", "title": "DiscourseDrome on Tradeoffs", "postedAt": "2023-02-18T20:50:43.255Z", "htmlBody": "<p><i>Crossposted with permission. Very much a Tumblr post, but also a really good short summary of a thing I think is an important EA skill. I am also not vague-blogging about anything, but realized yesterday that I had asked discoursedrome for permission to crosspost months ago but hadn't checked to see if they'd responded. Here is the post:</i></p><p>OK this is going to sound like I\u2019m vaguing about something but it\u2019s really just a general observation that I keep making in different contexts and wanted a post for.&nbsp;</p><p>Pretty much all disputes about <i>what people should do </i>boil down to \u201cweighing tradeoffs in the presence of uncertainty\u201d, and adult policy discussions tend to reflect that. As a rule of thumb, when you think you have a policy dispute that doesn\u2019t fit that mould you\u2019re usually wrong. This generalizes from arguments for the radical reconstruction of society down to arguments for nerfing a League of Legends hero.</p><p>However, people are always trying to make arguments that don\u2019t engage with this framework at all. In particular, it\u2019s common for people to argue that something has costs and so we shouldn\u2019t do it, or that it has benefits and so we should do it, and act like they\u2019ve finished presenting a cogent case for their position, and I am just <i>astonished </i>at the level of confusion that this requires. In a serious discussion, you don\u2019t even have both legs in your pants at that point! It\u2019s <i>weighing trade-offs in the presence of uncertainty.</i> If your argument doesn\u2019t engage with the subject on that level, it\u2019s not ready for competition yet.</p><p>Of course, the internet is not a debate club: people can say whatever they think as well or as poorly as they please, and that\u2019s usually a good thing. But it doesn\u2019t seem like it\u2019s just a case of people not electing to make serious policy arguments; I feel there\u2019s surprisingly little awareness of what serious policy arguments <i>entail</i>, and of what kinds of situations lead to policy disputes in the first place. That\u2019s frustrating, if only because people keep <i>showing up </i>to serious discussions with the apparent intention of participating when they only have like 25% of an argument, and you have to decide if you want to just ignore them and come off like a dick, or sit down and try to coach them the rest of the way into expressing a coherent position.</p>", "user": {"username": "jpaddison"}}, {"_id": "uenAXJw3zFWnpMJiu", "title": "EA's in IT (Information Technology)", "postedAt": "2023-02-18T20:17:39.232Z", "htmlBody": "<p><i>I apologize if there are posts on the subject elsewhere, I was having some difficulty finding posts using the search function. This comes after reading the </i><a href=\"https://forum.effectivealtruism.org/posts/pndb6TQ9nAiAkXg8x/80-000-hours-career-review-information-security-in-hig\"><i>80,000 Hours Career Review on Information Security</i></a><i> and </i><a href=\"https://forum.effectivealtruism.org/posts/B2sxxATzHdaGNc5YK/advice-i-give-to-people-who-don-t-currently-have-an-ea-job\"><i>Advice I Give to People Who Don't Currently Have an EA Job</i></a><i>.&nbsp;</i></p><hr><p>Are there any EA\u2019s here who currently work in IT (Information Technology)? What kinds of places are you working at? Are they actual EA organizations?</p><p>Essentially, I am contemplating a switch into the field but have not seen much written on the actual field of IT within EA except as a stepping stone to something else, e.g. AI/machine learning, software development or information security. This is fine, I think I would like to eventually transition into information security myself. That being said, as someone who is: (1) a career transitioner; and (2) not currently at an EA company; I don't believe myself at present to be the kind of person for whom a lot of those posts are written.&nbsp;</p><p><i>For context: I have recent experience in operations working closely with our IT department along with some previous experience in communications, policy and database administration.</i> <i>But outside of general software experience (Javascript, HTML/CSS, R, SQL, Tableau, things like that) and always becoming the de facto \u201cIT-person\u201d in my workgroups, nothing more explicit. Generally speaking, my background is emergency response, biosecurity related. While I consider myself EA-oriented, I have never worked at a company that is underneath the EA umbrella.</i></p><p>Is this (meaning, IT) a worthwhile pursuit for someone looking to also switch into more EA-aligned organizations? Any suggestions on places I should apply/are hiring? <strong>And more importantly:</strong> What can I do to bolster my application? A lot of places seem to either be super big fancy startups that will most likely throw out my application or are hiring only college interns for these roles. As someone who is skeptical on my chances at these places and has done my fair share of internships in the past- being several years removed from college, these are not practical options for me.</p><p>Should I delay until I can show more obvious IT-related certificates and things like that? I was thinking about doing the CompTIA Security+ but don\u2019t want to get stuck spending time on something that might prove to be unnecessary. On the other hand, based on <a href=\"https://forum.effectivealtruism.org/posts/PhySoajcEcY8EtgKH/when-in-doubt-apply\">previous posts</a> in the forum, there's a good chance that <a href=\"https://forum.effectivealtruism.org/posts/Fahv9knHhPi6pWPEB/don-t-think-just-apply-usually\">I could 100% be overthinking this.</a> But on the other, other hand, a lot of posts that I see encouraging people to join the technology side of EA are looking for <a href=\"https://forum.effectivealtruism.org/posts/DDDyTvuZxoKStm92M/ai-safety-needs-great-engineers\">people with ridiculous resumes and fancy skills</a> from the jump whereas I have none of that.</p><p>In addition, at what point do I need to consider location? While I frequently travel to Seattle, I am mostly based in Boston. Both are expensive locations in their own right but I find the Bay Area (where the bulk of EA companies are seemingly situated) to be outright unaffordable. Notable because I am currently unable to fully relocate and a lot of IT positions within the United States seem to require on-site employment unlike positions I've seen advertised in the U.K.</p><p>&nbsp;</p><p>Basically, I'm trying to avoid becoming <a href=\"https://forum.effectivealtruism.org/posts/2BEecjksNZNHQmdyM/don-t-be-bycatch\">bycatch</a> and am generally looking for and would appreciate any advice.&nbsp;</p>", "user": {"username": "EAlly"}}, {"_id": "mhzAogryEKbaF9YCr", "title": "EA, 30 + 14 Rapes, and My Not-So-Good Experience with EA.", "postedAt": "2023-02-18T03:39:55.965Z", "htmlBody": "<p>I took down this post. In it, I originally spoke of how many assaults I'd \"caught\" in EA, and my unhappiness with my experiences with CEA and the Community Health. My message didn't get across and I was repeatedly told I was emotional, hyperbolic, etc. The post failed to convey the value and message I wanted it to convey - which is to start a discussion on assault within EA and whether it was being handled well, and devolved into critiques of me through the very limited information I conveyed in the post; not to say the criticism is or isn't fair, but wasn't my intent to get personal to turn this into a discussion about me. There were also multiple requests for more information about the assaults themselves (which was also the case in the previous forum post I participated in, in which the Time article on sexual misconduct was linked), which I am unwilling to share in a public forum. I've removed it as it is counterproductive and needlessly takes away from discussing sexual assault within EA.&nbsp;</p><p>&nbsp;I'd like to add - <strong>For the commenters (</strong><a href=\"https://forum.effectivealtruism.org/users/ubuntu?mention=user\"><strong>@Ubuntu</strong></a><strong> and </strong><a href=\"https://forum.effectivealtruism.org/users/casebash?mention=user\"><strong>@Chris Leong</strong></a><strong> ) saying \"if EA were to hire you\" - I don't want EA to hire me. I don't want to join CH. I've never applied for, wanted a job with CH, nor do I think I have said anything I spoke to implied I wanted a job with CH? If there's something I said that implied that, I'm sorry, but to be clear I've never wanted a job with EA nor am I in EA. If you mean that I sent a proposal to CEA about developing a policy, reporting system, and training to mean CEA was \"hiring\" me - I don't see it as being \"hired\" or wanting to work with CEA.</strong></p><p>What I wanted to replace the system of being my being CEA's unofficial report-taker. <a href=\"https://forum.effectivealtruism.org/users/ubuntu?mention=user\">@Ubuntu</a> I agree with you in that I shouldn't have been the Community Health team's unofficial report taker, and you SHOULD be unhappy that I was doing that. That was one of the intents of my post, to call attention to that. It truly was my mistake to not have stopped doing this work for EA earlier, as it seems completely unwanted by the movement. Replacing my work taking reports and supporting survivors and handing that over to your Community Health team would have taken - a month, max two, to do (that's the \"proposal\" I mention). I also let Community Health know that I wouldn't refer survivors to them, and I've spoken to why in my reply to <a href=\"https://forum.effectivealtruism.org/users/benmillwood?mention=user\">@Ben Millwood</a>. You're welcome to disagree with my assessment, but I stand firm in this stance. I believe anyone speaking to survivors should bring compassion and support to that work. Also, I'm 99.9% certain the proposal will going to be declined; and should have stated that earlier. I only sent it as a way to say \"these are the conditions in which I can continue helping you, if you don't agree, I will not help you.\"</p><p>Further, while most of you seem to be unwilling to admit you have a problem with rape, as your former unofficial report-taker, I believe you do, and I hope you dig deeper and find more about this yourselves. But either way, I have zero desire to continue long term working within EA, or to be part of your movement.&nbsp;</p>", "user": {"username": "There_is_a_problem"}}, {"_id": "2eotFCxvFjXH7zNNw", "title": "People Will Sometimes Just Lie About You", "postedAt": "2023-02-18T02:27:51.096Z", "htmlBody": "<p>Before getting mini-famous, I did not appreciate the degree to which people would misrepresent and lie about other people.</p><p>I knew about it in theory. I occasionally stumbled across claims about people that I later found out were false. I knew, abstractly, that any particular accuser is telling a truth or a lie, but you're not sure which one.</p><p>But now, I'm in the unique position where people say things about me all the time, and I hear most of it, and I have direct access to whether it's accurate or not. There's something about the lack of ambiguity that has left me startled, here. Something was way off about my models of the world before I had access to the truth of a wide range of accusational samples.</p><p>In the last few years, I've risen in visibility to the degree it's started to get unpleasant. I've had to give up on the idea of throwing parties at my house where guests are allowed to invite unvetted friends. There are internet pockets dedicated to hating me, where people have doxxed me and my family, including the home addresses of my parents and sister. I\u2019ve experienced one kidnapping attempt. I might have to move. One stalker sent me, on average, three long messages every day for nearly three years. By this point death threats are losing their novelty.</p><p>Before I was this visible, my model was \"If a lot of people don't like you, maybe the problem is actually you.\" Some part of me, before, thought that if you were just consistently nice and charitable, if you were a good, kind person, people would... see that, somehow? Maybe you get one or two insane people, but overall truth would ultimately prevail, because lies without evidence wither and die. And even if people didn't like or agree with you, they wouldn't try to <i>destroy</i> you, because you can only really incite that level of fury in someone if you were at least a little bit at fault yourself. So if you <i>do</i> find yourself in a situation where lots of people are saying terrible things about you, you should take a look in the mirror.&nbsp;</p><p>But this sort of thing doesn't hold true at large scales! It really doesn't, and that fact shocks some subconscious part of me, to the degree that even I get kinda large-scale gaslit about&nbsp;<i>myself</i>. I often read people talking about how I'm terrible, and then I'm like damn, I must have been a little too sloppy or aggressive in my language to cause them to be so upset with me. Then I go read the original thing they're upset about and find I was actually fine, and really kind, and what the fuck? I'm not used to disagreements being so clearly black and white! And me in the right? What is this, some cartoon children's book caricature of a moral lesson?&nbsp;</p><p>And I have a similar shock when people work very hard to represent things I do in a sinister light. There've been multiple writeups about me, either by or informed by people I knew in person, where they describe things I've done in a manner that I consider to be extremely uncharitable. People develop a narrative by speculating on my mental state, beliefs, or intentions (\"of course she knew people would have that reaction, she knew that person's background\"), by blurring the line between thing I concretely did and vaguer facts about context (\"she was central to the party so she was responsible for that thing that happened at it\"), and by emphasizing reactions more than any concrete bad behavior (\u201cthis person says they felt really bad, that proves you did a terrible thing\u201d).</p><p>Collectively, these paint a picture that sounds convincing, because it seems like all the parts of the narrative are pointing in the same direction. Individually, however, the claims don\u2019t hold up. (In this case, \u201csomeone got upset at a party I attended\u201d is a real fact. But I didn't know that person's background, I didn't ask to be central to the party, and they were crying because of something someone else did completely unrelated to me.)</p><p>But I think the point of this isn't that people&nbsp;<i>can</i> develop warped narratives about you, but rather that they&nbsp;<i>do</i>. People in your circles, in real life, maybe people you thought you could trust. I not only have internet people lying about me, but people brought by friends to parties, people who helped me move, and in one case, someone I considered a friend. If you're high enough volume/visibility, if you're controversial or weird enough that people can score points by hating on you, if you're anywhere close to touchy political battlegrounds, then it seems inevitable to me that you will get attacked by people who are best to model as bad actors - people who will confidently misinterpret and misrepresent you to others no matter how weak the evidence is. There<i> actually exist&nbsp;</i>people who see their conflict with you as war in which anything is justified to vanquish the enemy, even if you\u2019re doing your best to empathize with their perspective and seriously consider whether they\u2019re right.</p><p>I think this is dramatically underweighted by people who haven't personally experienced this (and the ability to experience this at scale is very rare, which is why I\u2019m trying to share my experience with others). I occasionally see someone who seems to me to be likely a bad actor, where the correct response should be \"I am really skeptical of your claims,\" but the people around them are like man, your complaints are important and we should take them seriously. I get the impulse, but ahh!&nbsp;</p><p>&nbsp;</p><p>I had a lot of skepticism of the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/JCyX29F77Jak5gbwq/ea-sexual-harassment-and-abuse\"><u>recent TIME article</u></a> claiming that EA is a hotbed for sexual harassment, I think in large part because of those experiences I've had. We're dealing with something high visibility (EA), where the most popular political coalition in journalism (people on the left side of the political aisle) can score points by hating you (insufficiently woke), and that is politically controversial (polyamory, weird nerds, SBF). It seems obvious to me that the odds of having some people with personal experience in the community who also regularly uncharitably misinterpret interactions, and uncharitably speak to a journalist (with both political and financial incentives to be uncharitable), are very high.</p><p>This is why it strikes me as alarming to see a relative&nbsp;<i>lack</i> of skepticism in the EA forum response. I don\u2019t think I\u2019ve seen anyone explicitly state the hypothesis of bad actors (though it\u2019s possible someone did and I missed it). My guess is that people are making the error that&nbsp;<i>if you inspired this level of vitriol, you must be at least somewhat at fault,</i> or&nbsp;<i>if enough people all agree that you\u2019re bad, denying this is arrogant.</i>&nbsp;</p><p>But after being mini-famous, my priors on people lying about you once you\u2019re visible are&nbsp;<i>really high.</i> I\u2019m&nbsp;<i>not</i> saying that EA is perfect or that nothing in the article is true, but rather that reading it, my gut instinct was that roughly 80% was entirely misleading - by which I mean, if I could pop back in time to witness the reported interactions, I personally would think in 80% of cases that the accused had done nothing wrong. The elements here are the&nbsp;<i>perfect</i> setup to pluck out the least trustworthy, uncharitable people and elevate their story into the political crossfire.</p><p>(As an data point: I\u2019m aware of one person who talked to the TIME reporter who, before any of this happened, I concluded might be mentally unstable and had decided to stop interacting with them.)</p><p>&nbsp;</p><p><strong>To do some analysis of ways people have done this to me</strong></p><p>I've debated a bit about sharing specific examples here - the important stuff is in cumulative details, which is annoying to communicate, and on principle I don't like to give these people any direct attention. I also don\u2019t want to turn this into \u201cand now Aella hijacks this issue to talk about personal social drama where she picks through the details of every rumor in order to convince you she\u2019s not a terrible person\u201d. But still, it's hard to convey exactly how this works without examples, and specific instances of this happening to me are what have so strongly updated my views, so I\u2019m going to pick just a few.&nbsp;</p><p>I was friends with someone who wrote a piece with a bunch of accusations about me&nbsp;<a href=\"https://web.archive.org/web/20220518060444/https://www.wholezero.org/stack/quis-cancellat-ipsos-cancellores\"><u>here</u></a>. My (and others) response is&nbsp;<a href=\"https://www.lesswrong.com/posts/mooAqpyqPZnyMmPBQ/\"><u>here</u></a>, if you\u2019d like to read through the whole thing. But if not, here\u2019s one piece of it, one of the reports that the author compiled:</p><ul><li><i>I\u2019ve only been to one of Aella\u2019s parties but one was enough. The environment felt so uncomfortable that I spent hours and hours hiding alone and crying. The party had a lot of nudity and sex, everyone was on drugs, and it was set up so that consent as a guiding light was being continuously questioned.</i></li></ul><p>I can\u2019t remember any event I threw that fits this criteria in the last few years. The nudity/sex parties I organized or co-organized had either very little or no drug use.</p><p>I pointed this out in response to their post, and they updated their response to include:</p><ul><li><i>There have been questions posted on social media about whether my account of Aella\u2019s party is real. I stand by the account, but I decline to give a year or other specifics, because I\u2019m worried that providing that information would help Aella triangulate my identity. However, in the interest of intellectual honesty, the single detail I think someone could contest is whether Aella was the \u201cactual\u201d organizer of the party I attended. It\u2019s true that she wasn\u2019t the only one organizing it but she was easy to observe as central to the event while it was happening and it was privately described to me as being her party. Obviously it was a party full of illegal activity so it\u2019s not surprising that it\u2019s hard to prove it was \u201creally\u201d organized by her.</i></li></ul><p>A few points here.&nbsp;</p><ol><li>There's nothing inherently wrong with disliking running into nudity/sex (say, outside of a romantic relationship), but there's also nothing inherently wrong with liking those things. Ideally, people with different preferences here can just self-sort into different kinds of events, and it shouldn't be a scandal to people with one preference if they find out that people with a different preference exist. The word \"uncomfortable\", however, points at a bad thing; and by juxtaposing it with neutral things (nudity/sex), the latter can be made to sound like bad things in their own right.</li><li>They didn\u2019t say anyone violated anyone else\u2019s consent or boundaries at the event, something I assume they&nbsp;<i>would</i> have shared if it\u2019d happened, since their goal was to establish that I\u2019d done a bad thing. Instead, the emphasis is on feelings and high-level descriptions (\u201cThe environment felt so uncomfortable\u201d / \u201cconsent as a guiding light was being continuously questioned\u201d). Concrete examples make it possible for people to see what they think about the example, whereas staying at the level of interpretation/narrative forces the reader to trust the interpretation wholesale (or look like an asshole), and staying at the level of follow-on response forces the reader to trust that the writer\u2019s emotional response was grounded and proportionate (or look like an asshole).</li><li>To be clear, it\u2019s okay to have any reaction to anything, even if it seems disproportionate. My issue here is the unnamed implication that&nbsp;<i>other people</i> would also have this reaction, or that the party was at fault here. It&nbsp;<i>might</i> have been at fault, but&nbsp;<i>the concrete cause was not named.</i> The reaction is stated mostly on its own, in some detail, and the reader is implicitly being asked to assume that concrete things must have happened at the party that are so terrible that&nbsp;<i>of course</i> they\u2019d produce that bad reaction. This leaves out the fact that sometimes, unfortunately,&nbsp;<i>no one does anything wrong</i> and feelings can still end up hurt.</li><li>In the response, they express fear of me being able to \u201ctriangulate [their] identity\u201d, which implicitly frames me as a scary person who\u2019s likely to try to hurt people who criticize me. If they\u2019d included examples of any other time I\u2019d tried to take revenge on someone, I think this move would have been explicit and much more reasonable. Instead, it just adds to this weird narrative that\u2019s lying over everything like a funhouse mirror distortion of who I am.&nbsp;</li><li>This person says it\u2019s true that I wasn\u2019t the only one organizing, but I was \u201ccentral\u201d to the event. This makes me suspicious that they\u2019re describing an event I&nbsp;<i>didn\u2019t</i> actually organize, especially given that I can\u2019t remember hosting any event that fit their description. I can think of&nbsp;<i>maybe</i> one event, but it was a bigger, festival-type production where I was a volunteer to help check people in, and helped set up and break down. I wasn\u2019t an event organizer, and had no control over the principles or activities. But this doesn\u2019t matter - I seemed \u201ccentral\u201d to someone, so I get the blame for anything bad that&nbsp;<i>other people</i> did at this event, and this gets cited in a list of reasons to think I\u2019m \u201cprobably evil\u201d.</li><li>When they say \u201c<i>Obviously it was a party full of illegal activity so it\u2019s not surprising that it\u2019s hard to prove it was \u201creally\u201d organized by her.\u201d,&nbsp;</i>the writer is implying that we deliberately hid my role in organizing the party in order to avoid legal blame, framing me as the&nbsp;<i>kind of person who lies about stuff like this.&nbsp;</i>To be explicit here, I have never tried to hide the fact that I organized a party I did in fact organize.<br>&nbsp; &nbsp;</li></ol><p>Common in these examples is&nbsp;<i>leaving the exercise to the reader</i>.</p><p>The accuser doesn\u2019t offer concrete behaviors, but rather leaves the badness as general associations. They don\u2019t make explicit accusations, but rather implicit ones. The true darkness is hinted at, not named. They speculate about my bad traits without taking the risk of making a claim. They frame things in a way that increases my perceived culpability.&nbsp;</p><p>(They also position themselves as afraid of what I\u2019ll do to them if they give more details, which also serves the function of making them safe from the possibility that I might clarify or deny any of their claims. This type of thing is present in the TIME article. One example - \u201c<i>Many of them asked that their alleged abusers not be named and that TIME shield their identities to avoid retaliation.</i>\u201d Possibly reasonable, except in at&nbsp;<i>least</i> one of the examples covered by this, the person had already publicly named the accused,&nbsp;<i>and</i> the accused was kicked out of the community. The&nbsp;<i>claim</i> is that this is purely a strategy to shield against retaliation, but the&nbsp;<i>effect</i> is to discourage fact-checking and skepticism on all points, even using information that\u2019s already public.)<br>&nbsp;</p><p>They continued:<br>&nbsp;</p><p><i>Corroboration of this account comes from another friend, who has told me on condition of anonymity that one of the features of Aella\u2019s parties is a game called \u201cdrugs roulette,\u201d in which people consume various substances without knowing what they are. Many of the substances one can imagine employing here \u2014 most saliently, rohypnol, the date rape drug; but also others \u2014 would put people into compromised states in which they could not consent to further sexual activity imposed on them by people who may not even have known that their sexual partner was thus compromised. To make matters worse, this is apparently being done under a house rule of \u201cyou are never allowed to talk about it with anyone.\"</i></p><p>This assertion is (in a way that still sort of shocks me)&nbsp;<i>false in every single detail</i>.</p><p>I\u2019m not going to keep analyzing the hostile framing, but here\u2019s a running tally of the ways the account so far has gotten things wrong:</p><ul><li>The nudity/sex parties I helped throw had either very little or no drug use.</li><li>I have never tried to hide the fact that I helped organize a party that I helped organize.</li><li>I've never played drug roulette, nor has it occurred at any of my parties.</li><li>There has never, to my knowledge, been rohypnol at any of my parties.</li><li>Nobody has ever, to the best of my knowledge, drugged someone in attempts to make them more sexually pliable to others at my parties.</li><li>I\u2019ve never told anyone they can\u2019t talk about an experience at one of my parties.</li></ul><p>I have&nbsp;<i>joked&nbsp;</i>about the&nbsp;<i>idea</i> of drug roulette before (without ever asserting, even in a joking way, that I\u2019d actually done it). I\u2019m not fundamentally opposed to the idea, for a small group of friends who all agreed (with full knowledge of what they were doing) to randomizing drug use between them, if various logistical issues (about when the drugs kick in) could be resolved. But I have never actually&nbsp;<i>done</i> this.</p><p>The other parts of the claim above are, as far as I can tell, fabrications, like telling people that they can\u2019t talk about their experience at my parties. I have asked people to keep&nbsp;<i>identities</i> of party attendees private, typically at kink events, but never the experiences themselves.</p><p>In the case of the TIME article, I\u2019m not clear on the degree to which the claims were lies, but there were at least a few lie-like omissions - I\u2019m under the impression that t<a href=\"https://forum.effectivealtruism.org/posts/JCyX29F77Jak5gbwq/ea-sexual-harassment-and-abuse?commentId=satiAXu89cxR8WAz6\"><u>he main people accused may not have even been EAs</u></a>, and some of the accused in the article had already been banned from attending EA events - something that is presumably exactly what the article author is advocating happen, but doesn\u2019t mention that it\u2019d&nbsp;<i>already been done.</i></p><p>I\u2019d also like to point out that, both in these allegations against me and in the TIME article, we have corroboration - a group of people who shared complaints about my parties and agreed they\u2019d shared similar sinister experiences. The existence of corroboration alone is not, to me, significant evidence of truth, especially in a highly polarizing context. If the corroboration is by more trustworthy people, with concrete claims, then I consider this to be much stronger evidence.</p><p>&nbsp;</p><p>Someone who attended the same meetups with me at a rationalist group IRL was later banned from that community and several other communities for bad behavior. They then wrote a long writeup on a forum about me. I won't directly link this, because the thread is dedicated to doxxing me and my family members. The writeup includes a lot of incorrect claims, but I\u2019ll include one that addresses more intentions:</p><ul><li><i>She will deliberately center the conversation around herself at the expense of the conversation or others. (The card game \"AskHole\" is ulteriorly designed to do this; there are a disproportionate amount of questions about sex work.) During the 2021 Astral Codex Ten Megameetup, she advertised it on her page and it was derided as \"the Aella meetup\" because she occupied a central table and this was described by one guest as \"holding court.\" One person who showed up to see Aella asked a pregnant wife holding her baby if she was a sex worker. She was described as \"a goddess.\" To test my hypothesis that she will be unable to handle a conversation sufficiently not about her, I sat next to her for about ten minutes and talked with some friends about nothing related to her. At some point she petulantly said \"I'm moving\" and relocated to a spot where she would get more attention. During the dinner, she spent about a third of the time looking at the ceiling \u2014 like a child would do to over-advertise to their parents that they were bored. Once, when she felt a concept was socially important (this is key; she does not care about its real importance) she petulantly said \"I DON'T UNDERSTAND\" and either turned her head away or outright walked away, my memory fails me here. But the expectation was that we were supposed to care, and go out of our way to make it friendly to her.</i></li></ul><p>Breaking that down:</p><ol><li>&nbsp;This example is full of assumptions about my intent - I \u201cdeliberately\u201d center the conversation; I \u201culteriorly designed\u201d my card game to orient around me; I relocated \u201cto get attention.\u201d I \u201cdon\u2019t care\u201d about a concept\u2019s importance; I \u201cexpected people to go out of their way.\u201d None of these assumptions about my intent match my internal experience about my intent, but nevertheless he presents them as fact, not guesses.</li><li>Using other people\u2019s actions to frame me. People \u201cderided it as the Aella meetup\u201d, someone described me as \u201cholding court\u201d, someone who came see me dared ask a&nbsp;<i>mother</i> if she did&nbsp;<i>sex work</i>. Someone described me as a goddess. It\u2019d be one thing if he was trying to describe how people behave around and towards me, but his actual claim is that I am pulling attention towards myself in a way that\u2019s damaging for others, and using other people\u2019s behavior - most of which I&nbsp;<i>didn\u2019t even know happened -&nbsp;</i>as proof.</li><li>He frames normal and okay behavior as somehow pathological. I&nbsp;<i>moved to a different spot,</i> and this action on its own is narrativized as damning (\u201cpetulantly\u201d, to \u201cget more attention\u201d). But if your desire is to exit a social interaction, that\u2019s fine. Leaving conversations because they aren\u2019t relevant to you or because you aren\u2019t interested in the topic is fine too, as is joining a conversation because someone is paying attention to you (and vice versa). If you make a card game where you put in questions about a topic that you\u2019re interested in, that\u2019s&nbsp;<i>also</i> fine<i>.</i> If you are looking at the ceiling because you\u2019re bored, hell, that\u2019s fine too<i>.</i> The author is weirdly overconfident when it comes to inferring my mental state, but he's also taking completely normal human emotions and framing them as things to be ashamed of. But because the narrative is so heavy, and everything is phrased with a thick layer of connotation, a lot of the implicit claims being made about which emotions are acceptable to feel versus unacceptable are harder to notice and draw out so that they can be questioned.</li><li>The actual damning point he attempts to make is that I\u2019m incapable of being interested in any topics besides myself, and I read the implication here as being that I\u2019m thus incapable of caring about anyone else besides myself, and that this lack of care is the dangerous thing.&nbsp;<i>You can\u2019t trust Aella to have your interests at heart.</i>&nbsp;<i>You need to model her as bad.&nbsp;</i>The attempt here is not a compassionate understanding of another human being, but rather an implicit request for enmity.</li></ol><p>In general, the author sets up the conclusion of a narrative -&nbsp;<i>(you need to model Aella as bad)</i> -<i>&nbsp;</i>and fills out the narrative with assumptions about my intentions, claims about how&nbsp;<i>other people</i> behave, and anecdotes about objectively pretty normal-sounding things (\u2018she walked away to join another conversation\u2019) intoned in dire-sounding language that\u2019s meant to make the walking-away sound like actually this is all secretly very bad and shameful.&nbsp;</p><p>This is what it sounds like when someone (unsophisticatedly) is trying to force facts into a particular narrative mold.<br>&nbsp;</p><p>The above example is quite obvious, but I also see lots of this done more subtly in the TIME article, though the most egregious examples are about polyamory -</p><ul><li>\u201c<i>Three times in one year, she says, men at informal EA gatherings tried to convince her to join these so-called \u201cpolycules.\u201d When Gopalakrishnan said she wasn\u2019t interested, she recalls, they would \u201cshame\u201d her or try to pressure her, casting monogamy as a lifestyle governed by jealousy, and polyamory as a more enlightened and rational approach.\u201d</i></li><li><i>He asked how old she was, she recalls, then quickly suggested she join his polyamorous relationship. Shortly after agreeing to date him, \u201cHe told me that \u2018I could sleep with you on Monday,\u2019 but on Tuesday I\u2019m with this other girl,\u201d she says. \u201cIt was this way of being a f\u2014boy but having the moral high ground,\u201d</i></li></ul><p>Here, they \u201ctried to convince her\u201d, they \u201cshamed\u201d her, the man is attempting to \u201chave the moral high ground\u201d. A woman describes a man asking her out as \u201cbeing recruited to join a polyamorous relationship\u201d.</p><p>And while some of this is a bit unclear - like it\u2019s possible someone was like \u201cman but don\u2019t you think monogamy is embarrassing\u201d, or otherwise said&nbsp;<i>specific things</i> that&nbsp;<i>actually</i> were shamey - other parts seem to just be assuming intent or mental state, or taking something that&nbsp;<i>should be fine</i> and framing it in a way where we\u2019re supposed to be skeeved out (\u201crecruited\u201d, as opposed to \u201casked out\u201d).&nbsp;</p><p>Or:</p><ul><li><i>In 2018, as she was starting her career in AI research, Joseph recalls being introduced to a prominent man in the field connected to EA. Joseph was 22 and still in college; he was nearly twice her age. As they talked at a Japanese restaurant in New York City, she recalled, the man turned the conversation in a bizarre direction, arguing \u201cthat pedophilic relationships between very young women and older men was a good way to transfer knowledge,\u201d Joseph says. \u201cI had a sense that he was grooming me.\u201d</i></li></ul><p>What&nbsp;<i>actually</i>&nbsp;<i>happened</i> in this interaction? The word \u201cgrooming\u201d, generally reserved for interactions pedophiles have with children, is here being used about an interaction with a 22-year-old woman. I\u2019m unclear if the guy was actually in EA, because \u2018connected to EA\u2019 is really vague. I\u2019m also unclear on who did the \u2018introducing\u2019. And on what the guy actually said (did he use the word \u201cpedophilic\u201d? how much is being read between the lines or stylized here, versus quoted verbatim?).</p><p>I\u2019m also unclear on what the concrete bad things happened that made Joseph feel uncomfortable and made her worry that she was being groomed. He was older, he told her a controversial opinion once, she thought the conversation was bizarre. Did he ask her out? Did he make any move on her at all? Was she pressured into doing something uncomfortable? Was any boundary violated? I\u2019m taking away that the weird opinion is the only concrete thing that happened (mostly because if those other things&nbsp;<i>had</i> happened we\u2019d almost certainly be hearing about it), but it isn\u2019t made clear. Instead we\u2019re asked to assume, through the few details provided, that the weird view must be a mask for a hidden bad thing (malicious and predatory intentions).</p><p>Maybe he did in fact have weird, hard-to-put-a-finger-on vibes, maybe her intuitions were correctly responding to some odd signals - but based on the details provided, this should not justify&nbsp;<i>going to TIME to use this guy as evidence that EA has a sexual assault problem.</i>&nbsp;</p><p>&nbsp;</p><p>To be clear, sometimes abuse of power and sexual assault&nbsp;<i>does</i> happen in a controversial community. Just because you have high visibility and there are political incentives to misinterpret things that happened to you&nbsp;<i>doesn\u2019t</i> mean that all claims of wrongdoing about you are false.&nbsp;</p><p>It\u2019s really important to be able to suss out false claims from true ones, and it\u2019s deeply unfortunate that sometimes the rate of false claims gets high enough that we have to be suspicious about the true ones. It\u2019s crucial that we handle the process of figuring out which is which with a great deal of patience, effort, and compassion, because the stakes are so high. If someone was actually abused, we should try hard not to let the required inquiry, fact-finding, and baseline uncertainty disincentivize them from coming forward.&nbsp;</p><p>I acknowledge my post here is focused pretty disproportionately on skepticism, and a healthy balance in a community would&nbsp;<i>not</i> look like a bunch of people making only skeptical points. I think it would also include lots of people focusing hard on the dynamics around making it safe for people to speak up, on discussing the ways power imbalances can distort incentives for self honesty, on pointing out how scary and frustrating it can sometimes be to have your claims not taken seriously enough.</p><p>I\u2019m mostly posting this because to me, it feels like there\u2019s an imbalance in the models people are using to make sense of this. I don\u2019t want EA to overcorrect, but I want it to reach a reasonable equilibrium, which requires that thoughts pointing in both directions be thinkable and discussable.</p><p>It\u2019s&nbsp;<i>okay</i> to entertain the possibility that EA is already doing a pretty good job handling sexual assaults and that occasionally alienating non-good-faith actors is part of the cost.</p><p>It\u2019s&nbsp;<i>okay&nbsp;</i>to have a bit of weight on the theory that \"maybe the people in that article are the kind of people very likely to aggressively overinterpret mundane interactions as meaningfully bad\".</p><p>Maybe it\u2019s true, maybe not, but this should&nbsp;<i>not</i> be a taboo thought to voice. Especially given that sometimes, you&nbsp;<i>do</i> find yourself in a children\u2019s cartoon version of a moral lesson, where you didn\u2019t actually do anything wrong and no matter how much you try to understand and empathize with the criticism, at the end of the day it\u2019s not&nbsp;<i>true</i>. (Which has often been my experience. And having had that experience, I have an easier time suspecting that other people are in the same shoes.)</p><p>I don't think that all the claims in the TIME article are definitely untrue. The only thing I\u2019m strongly endorsing is that the default orientation to this should be \"Let's carefully evaluate each claim by the evidence we have for it, and assess the context of those claims\", instead of an automatic \"believe and support every claim in this article, both the facts and the narrative the writer is trying to use those facts for.\" Sexual assault&nbsp;<i>especially</i> has a sort of mind-numbing effect where it\u2019s scary in blue-tribe society to do anything except for automatically support the person with the most legible claim to the victim role.</p><p>I want to help create space for people to be&nbsp;<i>allowed to say</i> things like \u201cyes, that happened, it was six years ago, by someone on the fringes of the community, and then we banned them pretty fast, and we do not feel bad about our community\u2019s response\u201d, if true.&nbsp;</p><p>My hope is that people can become better calibrated about how common lies and ridiculous levels of spin are, so they can apply the proper level of skepticism to claims and look into them before believing them. My hope is&nbsp;<i>not</i> that people pick out whoever they think the \u201cgood guys\u201d are and then refuse to ever believe any criticism about those good guys. Just... use the tools that help you figure out truth, rather than feeling like it\u2019s immoral or unnecessary to poke around and try to figure out what\u2019s real.</p><p>&nbsp;</p><p>(<i>Also, just to be explicit - I don't want to accidentally imply that I haven't made mistakes or treated people poorly ever; I'm referring mainly to claims about me I find to be unambiguously ridiculous to outright false. There are in fact non-ridiculous criticisms of me, and I have occasionally hurt people in my circles because I behaved in an unskilled manner, and just because someone is like \"Aella made me feel terrible\" doesn't mean that person is automatically a bad actor, and you should not use this post to dismiss their concerns.)</i></p><p><br>&nbsp;</p>", "user": {"username": "aella"}}, {"_id": "ioHakR62Jbdgy4ig4", "title": "Manifold Markets Charity program ending March 1st", "postedAt": "2023-02-18T02:12:10.700Z", "htmlBody": "", "user": {"username": "Pat Myron"}}, {"_id": "7pMvc3dHN5GXy8c8x", "title": "Reading Group: \"The Good it promises, the harm it does\" ", "postedAt": "2023-02-18T00:11:23.556Z", "htmlBody": "<p>Hi !</p><p>I just started reading the book &nbsp;<a href=\"https://www.amazon.com/Good-Promises-Harm-Does-Effective/dp/019765570X\">\"The good it promises, the harm it does\" </a>and I think it'd be more enjoyable/useful to do this as part of a weekly discussion group.&nbsp;</p><p>I'm planning on doing this virtually, and I think ideally it would be 3-8 people per group (I'm happy to facilitate the formation of additional groups if more than 8 people are interested in participating). My current plan is do discuss one chapter per week, each discussion lasting 60-90 min, but I'm open to being convinced that there are better formats.&nbsp;</p><p>(Whilst writing this, I've seen that <a href=\"https://forum.effectivealtruism.org/events/LkEbcSNxjREQQNzuH/ea-book-club-discussion-the-good-it-promises-the-harm-it\">The Seattle EA group beat me to this idea</a> (except theirs is in person)- good job!)</p><h2>If you're interested in joining this virtual discussion group, please indicate your interest using <a href=\"https://forms.gle/xfq2wY7TjFxm4th47\">this very quick form.&nbsp;</a><br>&nbsp;</h2><p>I'll be closing the form on the 3rd of March.&nbsp;</p><p><br><br><img src=\"https://res.cloudinary.com/cea/image/upload/v1676679084/mirroredImages/7pMvc3dHN5GXy8c8x/c2clwrmgwwxj2rzy91zi.jpg\" alt=\"Amazon.com: The Good It Promises, the Harm It Does: Critical Essays on  Effective Altruism: 9780197655702: Adams, Carol J., Crary, Alice, Gruen,  Lori: Books\"></p>", "user": {"username": "Kaleem"}}, {"_id": "seFH9jcH3saXHJqin", "title": "Data on how much solutions differ in effectiveness", "postedAt": "2023-02-17T20:22:50.262Z", "htmlBody": "<p>Click the link above to see the full article and charts. Here is a summary I wrote for the latest edition to the 80,000 Hours newsletter, or see the <a href=\"https://twitter.com/ben_j_todd/status/1625545941431336977\">Twitter version</a>.</p><blockquote><p><strong>Is it really true that some ways of solving social problems achieve hundreds of times more, given the same amount of effort?</strong><br><br>Back in 2013, Toby Ord<sup>1</sup>&nbsp;<a href=\"https://80000hours.us2.list-manage.com/track/click?u=aba12f58bbe8075560abdc5b7&amp;id=63603a405a&amp;e=9b02f13113\"><strong><u>pointed out</u></strong></a> some striking data about global health. He found that the best interventions were:</p><ul><li>10,000x better at creating years of healthy life than the worst interventions.</li><li>50x better than the median intervention.</li></ul><p>He argued this could have radical implications for people who want to do good, namely that a focus on cost-effectiveness is vital.<br><br>For instance, it could suggest that by focusing on the best interventions, you might be able to have 50 times more impact than a typical person in the field.<br><br>This argument was one of the original inspirations for our work and effective altruism in general.<br><br>Now, ten years later, we decided to check how well the pattern in the data holds up and see whether it still applies \u2013 especially when extended beyond global health.<br><br>We gathered all the datasets we could find to test the hypothesis. We found data covering health in rich and poor countries, education, US social interventions, and climate policy.<br><br>If you want to get the full picture on the data and its implications, read the full article (with lots of charts!):</p><ul><li><a href=\"https://80000hours.us2.list-manage.com/track/click?u=aba12f58bbe8075560abdc5b7&amp;id=838205211c&amp;e=9b02f13113\"><strong><u>How much do solutions to social problems differ in effectiveness? A collection of all the studies we could find.</u></strong></a></li></ul><p>The bottom line is that the pattern Toby found holds up surprisingly well.<br><br>This huge variation suggests that once you\u2019ve built some career capital and chosen some problem areas, it\u2019s valuable to think hard about which solutions to any problem you\u2019re working on are most effective and to focus your efforts on those.&nbsp;<br><br>The difficult question, however, is to say <i>how</i> important this is. I think people interested in effective altruism have sometimes been too quick to conclude that it\u2019s possible to have, say, 1,000 times the impact by using data to compare the best solutions.<br><br>First, I think a fairer point of comparison isn\u2019t between best and worst but rather between the best measurable intervention and picking randomly. And if you pick randomly, you expect to get the <i>mean</i> effectiveness (rather than the worst or the median).&nbsp;<br><br>Our data only shows the best interventions are about 10 times better than the mean, rather than 100 or 1,000 times better.<br><br>Second, these studies will typically <i>overstate </i>the differences between the best and average measurable interventions due to <a href=\"https://80000hours.us2.list-manage.com/track/click?u=aba12f58bbe8075560abdc5b7&amp;id=eaeabb7428&amp;e=9b02f13113\"><strong><u>regression to the mean</u></strong></a>: if you think a solution seems unusually good, that might be because it is actually good, or because you made an error in its favour.&nbsp;<br><br>The better something seems, the greater the chance of error. So typically the solutions that seem best are actually closer to the mean. This effect can be large.<br><br>Another important downside of a data-driven approach is that it excludes many non-measurable interventions. The <a href=\"https://80000hours.us2.list-manage.com/track/click?u=aba12f58bbe8075560abdc5b7&amp;id=f6e72a9ff7&amp;e=9b02f13113\"><strong><u>history of philanthropy</u></strong></a> suggests the most effective solutions historically have been things like R&amp;D and advocacy, which can\u2019t be measured ahead of time in randomised trials. This means that restricting yourself to measurable solutions could mean excluding the very best ones.<br><br>And since our data shows the very best solutions are <i>far</i> more effective than average, it\u2019s very bad for your impact to exclude them.<br><br>In practice, I\u2019m most keen on the \u201c<a href=\"https://80000hours.us2.list-manage.com/track/click?u=aba12f58bbe8075560abdc5b7&amp;id=3942e4f4b0&amp;e=9b02f13113\"><strong><u>hits-based approach</u></strong></a>\u201d to choosing solutions. I think it\u2019s possible to find rules of thumb that make a solution more likely to be among the very most effective, such as \u201cdoes this solution have the chance of solving a lot of the problem?\u201d, \u201cdoes it offer leverage?\u201d, \u201cdoes it work at all?\u201d, and \u201cis it neglected?\u201d&nbsp;<br><br>Hypothetically, if we could restrict ourselves to solutions that are among the top half and then pick randomly from what remains, we can expect a cost-effectiveness that\u2019s about twice the mean. And I think it\u2019s probably possible to do better than that. <a href=\"https://80000hours.us2.list-manage.com/track/click?u=aba12f58bbe8075560abdc5b7&amp;id=f6a18d0f7d&amp;e=9b02f13113\"><strong><u>Read more in our article on choosing solutions</u></strong></a>.<br><br>So, suppose you use a hits-based approach to carefully pick solutions within an area. How much more impact can you have?<br><br>My overall take is something like 10 times more. I feel pretty uncertain, though, so my range is perhaps 3-100 times.<br><br>A 10-times increase in impact given the same amount of effort is a big deal. It\u2019s probably underrated by the world at large, though it may be overrated by fans of effective altruism.<br><br><i><strong>A final thought:</strong></i> I think you can increase your impact by <a href=\"https://80000hours.us2.list-manage.com/track/click?u=aba12f58bbe8075560abdc5b7&amp;id=43c280a137&amp;e=9b02f13113\"><strong><u>significantly more than 10 times</u></strong></a> by carefully choosing which problem area to focus on in the first place. This is a big reason why we emphasise <a href=\"https://80000hours.us2.list-manage.com/track/click?u=aba12f58bbe8075560abdc5b7&amp;id=77f496998f&amp;e=9b02f13113\"><strong><u>problem selection</u></strong></a> in career choice so much at 80,000 Hours. Overall, we\u2019d say to focus on exploring and building career capital first, then start to target some problem areas, and only later focus on choosing solutions.</p></blockquote>", "user": {"username": "Benjamin_Todd"}}, {"_id": "EsQuBvjBos7EYuoTP", "title": "Gaps in Deterrence Theory Epistemology, RCT Shortcomings, and a Proposal for Action Alignment", "postedAt": "2023-02-17T18:46:13.702Z", "htmlBody": "<p>\u201cWhat I wish to point out here is that even purely at the logical level, there exist certain areas of politics where the assumptions of rational choice theory must break down. Consequently, while the methodological usefulness of the rational choice assumption is undeniable, it is necessary to realize that there is a certain class of political phenomena for which this method of analysis may be inappropriate.\u201d - Partha Chatterjee, \"On the Rational Choice Theory of Limited Strategic War\"</p><p>According to some studies, Chinese society has higher rates of collectivism and identity fusion, and on average individuals in Chinese society employ a more value-driven decision-making apparatus over a \u201crational\u201d decision-making apparatus. It is my understanding that modern American military strategies all have some basis in rational choice theory (especially deterrence theory), which makes basic value assumptions that often do not stand true for immanent value-driven or otherwise rationally divergent actors with high identity fusion, such as leaders in China. In confrontational situations involving a party with the aforementioned characteristics, rational choice theory breaks down and conflict typically results due to misattributions.</p><p>For example, deterrence theory\u2019s effectiveness is posited to rest on three criteria known as the credibility trinity: celerity, severity, and certainty. In the event that violence is perpetrated despite deterrence, the \u201crational\u201d party typically is led to believe that the credibility (celerity, severity, or certainty) of their retribution threat is in question and so are only allowed two choices as a result of this incorrect conclusion: reestablish credibility by following through with the original deterrent threat or risk the potential consequences of losing face internationally. Following through with the threat means escalation; the same is the case for losing face internationally. The epistemic gap in this thought process, however, lies at the heart of motivation. In many cases involving rationally divergent actors, it is not that the deterrence threat was not credible, but that the threat was in and of itself not deterrent at all. Individuals with high identity fusion, whose judgments are made using immanent values (such as spiritual promises or cultural beliefs in manifest destiny), do not see whatever deterrence costs being incurred as outweighing the benefits or importance of their end goal, and so they breach deterrence boundaries. The misattribution of deterrence failure leads to violence in cases where simple adjustment of deterrence was necessary, or even mild diplomacy. Instead of credibility being the issue with deterrence in this case, it was value assessment. In short, the West (and the US in particular) approaches deterrent selection and manufacture with an ethnocentric view, which ultimately mitigates the effectiveness of deterrence against rationally divergent actors.</p><p>So why then does it appear that current US attempts at deterrence and coercion using rational choice theory seem to be having their intended effect on Chinese foreign policy (at least, as close to the intended effect as can be hoped)? Why do we see conflict between the US and rationally divergent actors similar to China (e.g., many middle eastern nations and Asian states throughout the past century such as Iraq, North Korea or Vietnam), and yet not with China itself?</p><p>I suggest a new theory to explain this strange relationship: Action Alignment Theory (AAT). AAT posits that the reason two rationally divergent international actors are able to peacefully coexist despite differing values and rationales is due to \u201caction alignment\u201d, which is best explained as two parties both viewing the same action(s) as vital to the achievement of diametrically opposed end goals, despite differing value systems and logic bases. For example, two parties with respective end goals of bolstered global materialism vs global utopian spiritualism (i.e., two goals antithetical to each other) both view peaceful cohabitation with each other as a means of progressing towards those opposing ends and thus cooperate.</p><p>In essence, AAT, when applied to the current US-China dynamic, posits that peace does not exist due to the credibility of US deterrence, but rather to mutual interests in the same situation of peace for different reasons arising from different rationales. If this were not the case, world actors culturally and sociologically similar to China (such as those previously mentioned in the middle east or Asia) would have responded to US deterrence in kind with China, or China would have responded to US deterrence similarly to the aforementioned nations (which, from history, we know they have not). Instead, these two powers currently exist in relative peace because relative peace means progress towards their respective end goals, despite those end goals ultimately being anathema to each other (the goals being US economic and military dominance vs. China\u2019s rejuvenation of ancient global Sinocentrism).</p><p>While it is true that one could argue this alignment is due to the threat of deterrence, this does not mean that deterrence as a threat of annihilation is the key to peace. In rationally divergent actors, death is not a deterrent. What is a deterrent, however, is not being able to realize a future goal. In the case with China, rejuvenation of Sinocentrism is that future goal, and annihilation would make the realization of that goal impossible, and so they seek peace. Some may say this is splitting hairs, but it is important to keep this distinction between reasons for deterrent success in mind because it means there may be other alternatives to use to threaten the realization of some future goal other than violence in the event that deterrence is breached. This is the value of AAT.</p><p>This current convenient alignment of interests is transient at best without active measures of ensuring it\u2019s continuance. As soon as mutual peace does not serve one or more of the parties in advancing them towards their end goals (and assuming actors remain rationally divergent), the collaboration will cease to exist and armed conflict is likely to result unless action alignment can be restored. The CCP's approaching of its 100th anniversary may very well be the impetus that changes this status quo, as they may become increasingly convinced that rejuvenation of Sino centrism cannot be accomplished while peacefully coexisting with the US (for example, US interference in the Taiwan issue could be changing the temperature).</p><p>Methods as to how to maintain or restore action alignment vary from militance to diplomacy. Such strategies may include active maintenance of the status quo through force or diplomacy, limited military action oriented towards engineering artificial action alignment, economic interdependence, strategic irregularity, controlled acquiescence, outright bribery, and more.</p><p>AAT does not stand on its own, nor is it meant to replace deterrence theory, but rather serves to fill epistemic gaps in rational choice theory (and consequently deterrence theory) that are dangerous pitfalls for the long peace we currently enjoy. I believe the concept of action alignment should be applied to RCT, deterrence theory (with its staunchly deterministic attitude towards violence), and general diplomacy, in the hopes that perhaps by realizing aligned actions and striving to maintain them, we can avoid loss of life and other expenses by engineering an equilibrium of mutual progress among all parties involved, be that progress perceived or actual.</p><p>I believe a project analyzing situations involving action alignment and identifying trends in such situations could prove useful for future strategic and political decision-makers, especially in the US-China relations realm. Who knows\u2026 maybe through proper development and implementation of consistent action alignment paragons a world where two powers both peacefully achieve their end goals can exist? Perhaps this is the key to avoiding Thucydides' Trap. Perhaps international relations no longer need be a zero-sum game where there are only two sides on the chess board and only at the cost of one side\u2019s king can the other side win. Perhaps a world where the US remains a democratic entity and the independent leading technological and economic powerhouse can exist in a globally Sinocentric international theater that accepts the irrefutability of Marxism... Or perhaps achieving an interminable state of action alignment is wholly untenable. More research (specifically into the following questions I list below) and the development of AA analysis/implementation could be a worthwhile contribution to the field of geopolitics and achieving lasting peace.</p><p>1. What theory(ies) does the US or China use when dealing with entities that use differing rationales or who are entirely irrational altogether without resorting to violence if any at all?</p><p>2. Does the Chinese government have a Rational Choice Theory original to their own philosophies that has evolved with noticeable differences from Western RCT due to cultural differences and institutional drift?</p><p>3. What does the US and or China do when their rational choice theory breaks down in the limits of war or exceptional international circumstances?</p><p>&nbsp;</p><p><br>**SOURCES**<br>[(558) Analysing the limits of rational choice in political and cultural conflict | Scott Atran - YouTube](https://www.youtube.com/watch?v=SxDS2g4qSO8)</p><p>http://www.jstor.com/stable/41854567</p><p>https://www.researchgate.net/publication/249705048_The_Role_of_Values_in_Rational_Choice_Theory</p><p>[http://www.jstor.org/stable/2601362. Accessed 26 Jun. 2022](http://www.jstor.org/stable/2601362.%20Accessed%2026%20Jun.%202022) Rational Choice Theory in International Relations.</p><p>[Full article: ON RATIONAL CHOICE THEORY AND THE STUDY OF TERRORISM (tandfonline.com)](https://www.tandfonline.com/doi/full/10.1080/1024269052000344864#:~:text=When%20rational%20choice%20theory%20is,a%20price%20change%20in%20another.)</p><p>[Revisiting the criticisms of rational choice theories - Herfeld - 2022 - Philosophy Compass - Wiley Online Library](https://compass.onlinelibrary.wiley.com/doi/full/10.1111/phc3.12774)</p>", "user": {"username": "Garrett Ehinger"}}, {"_id": "kPGqj8BMDzGpvFCCH", "title": "The EA Mental Health & Productivity Survey 2023", "postedAt": "2023-02-21T16:56:52.823Z", "htmlBody": "<p>This survey is intended for members of the Effective Altruism (EA) community who&nbsp;<strong>aim to improve or maintain good mental health and productivity.</strong> &nbsp;<br>We\u2019d be so grateful if you could&nbsp;<strong>donate ~10 minutes of your time</strong> to complete the survey! You will help both identify the most pressing next steps for enhancing mental flourishing within the EA community,&nbsp;<i>and</i> provide the interventions and resources you\u2019d prefer. These can be psychological, physiological, and lifestyle interventions.</p><p><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdxMD2VAHFXHdJ1ts8dTxZeMHa3wRWslkndiOxry64_etIQpg/viewform\"><strong><u>Take me to the survey now&nbsp;</u></strong></a><strong>(~10 min)</strong><br>&nbsp;</p><h2><strong>Why this survey?</strong></h2><p>The mind is inherently the basis of everything we do and feel. Its health and performance are the foundation of any metric of happiness and productivity at impactful work. Good mental health is not just the absence of mental health issues. It is a core component of flourishing, enabling functioning, wellbeing, and value-aligned living.&nbsp;</p><p><a href=\"https://www.rethinkwellbeing.org/\"><u>Rethink Wellbeing</u></a>, the&nbsp;<a href=\"https://www.mentalhealthnavigator.co.uk/\"><u>Mental Health Navigator</u></a>,&nbsp;<a href=\"https://ea-psych.com/\"><u>High Impact Psychology,</u></a> and two independent EAs have teamed up to create this community-wide survey on Mental Health and Productivity.&nbsp;</p><p>Through this survey, we aim to better understand the&nbsp;<strong>key issues and bottlenecks of EA performance and well-being</strong>. We also want to shed light on EAs' interest in<strong> and openness to different interventions</strong> that proactively improve health, well-being, and productivity. The results will likely serve as a basis for further projects and initiatives surrounding the improvement of well-being, mental health and productivity in the EA community. By filling out this form, you will help us&nbsp;with that. &nbsp;&nbsp;</p><p>Based on form responses, we will compile overview statistics for the EA community that will be published on the EA Forum in 2023. &nbsp;</p><h2><strong>Survey information</strong></h2><ul><li><strong>Please</strong> complete the survey<strong> by March 17th</strong>.&nbsp;</li><li>We recommend you take the survey&nbsp;<strong>on your computer,</strong> since the format doesn\u2019t work well on cell phones.&nbsp;</li><li>All responses will be kept confidential, and we will not use the data you provide for any other purposes.</li></ul><p><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSdxMD2VAHFXHdJ1ts8dTxZeMHa3wRWslkndiOxry64_etIQpg/viewform\"><strong><u>Take me to the survey now</u></strong></a><strong> (~10 min)</strong></p><p><strong>Please consider sharing this post in your EA network and upvoting this post to reach more people.</strong></p><h2><strong>Thank you!</strong></h2><p>We are deeply grateful to all participants!</p><p>Feel free to reach out to us if you have any questions or feedback.</p><p>Emily Jennings, Samuel Nellessen, Tim Farkas, and Inga Grossmann</p><p><br>&nbsp;</p>", "user": null}, {"_id": "rEMz3NwvJMATSWS5y", "title": "How good/bad is the new Bing AI for the world?", "postedAt": "2023-02-17T16:31:49.620Z", "htmlBody": "<p>I've had this coversation several times, so I thought I'd save us all the repetition.</p><p>What is the right model for recent AI search engine releases?</p><p>Are they useful or harmful?&nbsp;</p><p>What if anything should be done?</p>", "user": {"username": "nathan"}}, {"_id": "4cCRCoYvcLEr7prC2", "title": "AI Safety Info Distillation Fellowship", "postedAt": "2023-02-17T16:16:45.839Z", "htmlBody": "", "user": {"username": "robertskmiles"}}, {"_id": "9wJ5Mtba9Fc2yCvpN", "title": "Getting organizational value from EA conferences, featuring Charity Entrepreneurship\u2019s experience", "postedAt": "2023-02-17T13:32:03.500Z", "htmlBody": "<p>For individuals in the EA community, EA Global and EAGx conferences are an opportunity to be exposed to ideas and people who can help us identify and pursue more impactful paths. And for organizations, they\u2019re an opportunity to connect with potential new hires, grantees, and funders.</p><p>Charity Entrepreneurship recently shared with us (the CEA events team) a summary of the impact their participation at EAG and EAGx has had on their&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/HQL7fHWKHRnCijvik/ce-incubation-programs-applications-now-open-updates-to-the\">Incubation Program</a>.</p><p>We were inspired by this post, and wanted to encourage orgs working on EA causes \u2014 object and meta, large and small, older and newer \u2014 to consider carefully how to get the most out of&nbsp;<a href=\"https://www.effectivealtruism.org/ea-global/events\">the conferences we\u2019ve got lined up</a> in 2023. The opportunities include:</p><ul><li><strong>Talks &amp; workshops</strong> can be used to inform the community about your work and how others can contribute to increasing your impact as collaborators, funders or recruits.</li><li><strong>Office hours &amp; career fairs</strong> are available for you to interact directly with those interested in your plans and how they might fit into them.</li><li><strong>1-on-1 meetings</strong> are the bedrock of all the conferences CEA is involved in organizing, facilitating in-depth discussion and establishing connections between people with common goals.</li></ul><p>If you\u2019re interested in your org appearing on the program at an upcoming conference, or would like to discuss with us how best to approach these events, please reach out to us at <a href=\"mailto:hello@eaglobal.org\">hello@eaglobal.org</a>.</p><p>We thought sharing Charity Entrepreneurship\u2019s experience publicly might be valuable for others to learn from in planning their own approach to future conferences. Here\u2019s their story in their own words.</p><h1><strong>CE\u2019s EAG and EAGx Success Stories</strong></h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676639603/mirroredImages/9wJ5Mtba9Fc2yCvpN/dhz32yofzrgpllxaa2yb.png\" alt=\"\"></p><p>From the launch of Charity Entrepreneurship\u2019s Incubation Program, EAG and EAGx conferences have been a crucial part of the organization\u2019s outreach strategy. Thanks in part to CE\u2019s increasing presence \u2014 talks, workshops, and participation in numerous career fairs \u2014 nonprofit entrepreneurship has become a recognized career option in the effective altruist community.</p><p>From just one round of applications for CE\u2019s Incubation Program,&nbsp;<strong>325</strong> out of 720 applicants had participated in EAG or EAGx conferences where the organization was present.&nbsp;<strong>169</strong>&nbsp;applicants had interacted directly with CE at EAGs by participating in a workshop, office hours, or talking to CE staff one on one.</p><p>When young entrepreneurs who got into the Incubation Program and started new high-impact charities were asked what convinced them to apply, they named EAGs as one of the top reasons (along with the EA movement in general, partner/friend, internships, talking to CE staff members and group organizers).</p><p>So far, Charity Entrepreneurship has started 23 organizations and provided them with $1.88 million in total funding. These organizations have fundraised a further $20 million to cover their costs and are now reaching over 120 million animals and over 10 million people with their interventions. You can learn more about them on&nbsp;<a href=\"https://www.charityentrepreneurship.com/our-charities\">CE\u2019s website</a>; they include charities like Fortify Health (<a href=\"https://www.givewell.org/research/incubation-grants/Fortify-Health-expansion-December-2021#:~:text=Summary,flour%20at%20no%20additional%20cost.\">three GiveWell Incubation Grants</a>, 25% chance of becoming a top charity), Fish Welfare Initiative (<a href=\"https://animalcharityevaluators.org/donation-advice/recommended-charities/\">ACE Standout Charity</a>), Shrimp Welfare Project (<a href=\"https://80000hours.org/after-hours-podcast/episodes/andres-jimenez-zorrilla-shrimp-welfare-project/\">first organization ever working on shrimp welfare</a>), and Lead Exposure Elimination Project (precursory policy organization now working in&nbsp;<a href=\"https://leadelimination.org/projects/\">10 countries</a>).</p><h2><strong>Key benefits for CE</strong></h2><ul><li><strong>Finding talented entrepreneurs</strong> to start high-impact projects (50% of the founders had been in contact with CE\u2019s outreach efforts during EAG conferences).</li><li><strong>Finding hires for the CE team</strong> (20% of the team have been hired thanks to outreach efforts during EAG conferences), as well as fellows and interns.</li><li><strong>Making useful connections for funding</strong> (10% of funding potentially coming from connections made during EAG conferences).</li><li><strong>Sharing top ideas for most impactful interventions</strong> in various cause areas (Global Health &amp; Development, Biorisk, Animal Welfare, EA Meta) with the broader EA community.</li></ul><p>The most successful events in terms of number of applications were:</p><ul><li>EAGxBerlin: 71</li><li>EAG London: 47</li><li>EAG Washington: 44</li><li>EAGxPrague: 37</li><li>EAGxRotterdam: 32</li><li>EAGxOxford: 33</li><li>EAGxSingapore: 24</li><li>EAGxBoston: 21</li></ul><p><strong>Specific examples of success stories:&nbsp;</strong></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1676640530/mirroredImages/9wJ5Mtba9Fc2yCvpN/jal22hsryq51qqkm1rzi.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676640531/mirroredImages/9wJ5Mtba9Fc2yCvpN/d5ei9qlpyjex8f44psrz.png 140w, https://res.cloudinary.com/cea/image/upload/v1676640531/mirroredImages/9wJ5Mtba9Fc2yCvpN/sxrl8fmjxs0kiv84s9sg.png 280w, https://res.cloudinary.com/cea/image/upload/v1676640531/mirroredImages/9wJ5Mtba9Fc2yCvpN/sjcbl9tc2yxe4ppiygci.png 420w, https://res.cloudinary.com/cea/image/upload/v1676640530/mirroredImages/9wJ5Mtba9Fc2yCvpN/kebmgycmzssh01chbtnr.png 560w, https://res.cloudinary.com/cea/image/upload/v1676640530/mirroredImages/9wJ5Mtba9Fc2yCvpN/jcxxrbiw9bbmgu6pmyu2.png 700w, https://res.cloudinary.com/cea/image/upload/v1676640530/mirroredImages/9wJ5Mtba9Fc2yCvpN/b8udjflyi8ic9g6vwgrd.png 840w, https://res.cloudinary.com/cea/image/upload/v1676640530/mirroredImages/9wJ5Mtba9Fc2yCvpN/sy4jve2xh2id1mexpxby.png 980w, https://res.cloudinary.com/cea/image/upload/v1676640530/mirroredImages/9wJ5Mtba9Fc2yCvpN/u3juxfbhhpdg1rrqfzen.png 1120w, https://res.cloudinary.com/cea/image/upload/v1676640530/mirroredImages/9wJ5Mtba9Fc2yCvpN/trxhihdwjs02ofrxms20.png 1260w, https://res.cloudinary.com/cea/image/upload/v1676640530/mirroredImages/9wJ5Mtba9Fc2yCvpN/xfsntuqiy6wssxxmghpu.png 1342w\"></figure><figure class=\"image\"><img></figure><h2><strong>From CEA: How can other organizations learn from CE\u2019s approach?</strong></h2><p>We think CE are particularly good at making use of EAG(x) and that they might be especially well-positioned to get benefits out of our events. But they aren\u2019t the only organization that manages to get a lot out of events, and we think that some parts of their approach might generalize. Some strategies that might generalize to other organizations:</p><h3><strong>Plan ahead</strong></h3><p>Know what your goals are for the conference and identify attendees to speak with in advance. We think CE has been particularly successful because they have a strong sense of what they are trying to achieve and how to achieve it. You could consider setting&nbsp;<a href=\"https://en.wikipedia.org/wiki/SMART_criteria\">SMART goals</a> (specific, measurable, assignable, realistic, and time-related). Make sure your goals are tracking the things you want to achieve and that it is clear whether you\u2019ve achieved them or not.</p><p>For example: If you\u2019re looking to find a potential research collaborator for an upcoming paper on factory farming and pandemics risks, you might set a goal to read profiles of each person who lists \u201canimal welfare\u201d AND \u201cbiosecurity\u201d in their swapcard profile. You might make a second goal from there. Say 30 people list both, but 10 people seem reasonably well-suited to actually work on the paper. You could make a new goal: Reach out to the 10 people who seem like plausible collaborators and try to set meetings with them.</p><h3><strong>Consider&nbsp;</strong><a href=\"https://www.lesswrong.com/posts/53pxcve5kgwoLFvzD/instrumental-rationality-2-planning-101\"><strong>back-planning</strong></a></h3><p>Back-planning (or backchaining) starts planning from the end and works backwards. I often recommend this tool for project management and realistic time estimates, but I think it can be helpful for clarifying the steps in order to make sure you actually do the thing.</p><p>For example, maybe the task you want to complete is to hire a new ops associate at EAG. Imagine you\u2019re at the end of your task; \u201cOffering a role to an attendee\u201d. Now move backwards, step-by-step. What is the step right before you finish? Maybe you have to meet with them to actually hire them so there would have to be leads.\u201d So, you repeat Step 3 until you get to where you are now. Is that all? Well, for people to want the job I\u2019d have to publicize the role and share it with attendees, and I\u2019d have to reach out to promising candidates. How would I know if people are promising? I guess I\u2019d need a list of attendees who want to work in ops. Oh, I can get that from swapcard!\u201d (Don\u2019t forget to use the spreadsheet view!). Write down how long you think the task will now take you. \u201cHuh, thinking it through like this, I\u2019d need something like 2 weeks before EAG to coordinate leads and have enough staff to have meetings onsite. And I\u2019d need another week for writing my job ad. And another week for unforeseen issues\u201d&nbsp; You now have a detailed plan!</p><h3><strong>Work with the organizers</strong></h3><p>Consider hosting a talk, workshop, career fair stall, meetup, or office hours and use your content slot to attract potential hires, funders, or collaborators. You can&nbsp;<a href=\"https://docs.google.com/forms/d/1glFETxrqMQ50rVFVN8BfFYg1rtsXUlDo3vkjF7Af0yw/edit\">submit nominations for content here</a> (feel free to nominate yourself / your organization) or by emailing&nbsp;<a href=\"mailto:hello@eaglobal.org\">hello@eaglobal.org</a> (EAGx organizer emails can be found on&nbsp;<a href=\"https://www.effectivealtruism.org/ea-global\">the event pages</a>). Please do this as far in advance as possible (ideally at least 6 weeks)! If you end up with a content slot, make sure to clarify your goals (as described above) and share them with the organizers. We love to help!</p><h3><strong>Reflect and iterate</strong></h3><p>Review on how the event went for you (perhaps by writing it up and sharing with the EAG team!), improve your approach for future conferences, and give us feedback about how we can better support you next time!</p>", "user": {"username": "AmyLabenz"}}, {"_id": "FnrqBNQ4ascdCuGG6", "title": "I Am Not An Altruist", "postedAt": "2023-02-17T11:30:27.097Z", "htmlBody": "<p>Context: I just started full-time work as an alignment researcher. I do this work because I care - but I am frustrated with EA, and would not call myself an altruist. I wrote this today to express these frustrations. I don't necessarily think this will land with many EAs, but my main intention here is simply to make this clear from the outset, as it should provide context for my work later down the line.&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>I\u2019m doing this for me.</p><p>I\u2019m doing this for my friends and family.</p><p>For my comrades and coworkers.</p><p>&nbsp;</p><p>I\u2019m doing this for every human being,</p><p>Who asks themselves \u201ccould things be better?\u201d</p><p>I want to tell them: yes. Yes they can.</p><p>&nbsp;</p><p>I\u2019m trying to do this for every sentient being,</p><p>That ever has, or ever will, live.</p><p>&nbsp;</p><p>For every species conducive to ecological flourishing,</p><p>That is at risk of going extinct.</p><p>For every culture conducive to human flourishing,</p><p>That is at risk of going extinct.</p><p>&nbsp;</p><p>I\u2019m <i>trying</i> to do this for every species and culture that has gone extinct.</p><p>And for every species and culture that could produce flourishing,</p><p>But might not come to be.</p><p>&nbsp;</p><p>I\u2019m not an altruist.</p><p>I\u2019m not doing this for some \u201cother\u201d,</p><p>Who I perceive to be suffering.</p><p>I\u2019m doing this for us.</p>", "user": {"username": "clem"}}, {"_id": "pyPzYGXvsSnrrn2pJ", "title": "Animal Advocacy vs Animal Welfare: How should EA frame its animal-focused work?", "postedAt": "2023-02-17T08:56:25.543Z", "htmlBody": "<p>I've seen the animal-focused work in EA been framed as \"animal welfare\" and as \"animal advocacy\". For example, lots of the animal-related posts on the EA Forum are tagged \"Animal Welfare\" and/or \"Effective animal advocacy\", the latter being a commonly used term to refer to the animal-focused work in EA.</p><p>I imagine there to be pros and cons to using each of the two terms:&nbsp;</p><ul><li>\"Animal welfare\" may be a less accurate description of what EA animal-focused work does, since there's a significant portion of it (e.g. alternative protein, vegan advocacy) that doesn't focus on improving welfare. Using this term may risk alienating those who don't agree with welfarism. However, animal welfare is more mainstream, and thus meets less objection from the wider society.</li><li>\"Animal advocacy\" encompasses welfarism, abolitionism, and other approaches that don't fall into either category (e.g. promoting reducetarianism). Therefore, it seems more accurate and less alienating. But due to the inclusion of abolitionism, it may be less accepted by the mainstream of society.&nbsp;</li></ul><p>Note that it's not only (or even, not mainly) about making our work <i>look better</i>. Different framings may turn away different groups of people who would otherwise join our effort. Therefore, a better framing could make our work <i>done better</i>.</p><p>Finally, my questions are:</p><ul><li>Are there other considerations regarding which term to use?&nbsp;</li><li>Which one of the two should EA use, and on which occasions?&nbsp;<ul><li>In particular, the EA Forum (and some other major EA websites) currently uses \"animal welfare\" more than \"animal advocacy\", for example in the naming of the core topic tag; should that be changed?</li></ul></li><li>Is there a third term that's better than both of them?</li></ul>", "user": {"username": "TianyiQ"}}, {"_id": "djByAbm6ptkkmS9RS", "title": "Seeing more whole", "postedAt": "2023-02-17T05:14:02.248Z", "htmlBody": "<p>(Cross-posted from <a href=\"https://joecarlsmith.com/2023/02/17/seeing-more-whole\">my website</a>. Podcast version <a href=\"https://joecarlsmithaudio.buzzsprout.com/2034731/12270444-seeing-more-whole\">here</a>, or search for \"Joe Carlsmith Audio\" on your podcast app.)</p><blockquote><p><i>\"Great is the matter of birth and death. Life is fleeting; gone, gone. Awake, awake, each one. Don\u2019t waste this life!\"</i></p><p><i>- Dogen</i></p></blockquote><h2>1. Introduction</h2><p>In my <a href=\"https://joecarlsmith.com/2023/02/16/why-should-ethical-anti-realists-do-ethics\">last essay</a>, I looked at two stories (brute preference for systematic-ness, and money-pumps) about why ethical anti-realists should still be interested in ethics \u2013 two stories about why the \u201cphilosophy game\u201d is worth playing, even if there are no objective normative truths, and you\u2019re free to do whatever you want. I think some versions of these stories might well have a role to play; but I find that on their own, they don\u2019t fully capture what feels alive to me about ethics.</p><p>Here I try to say something that gets closer.</p><h3>1.1 Slaveholder stuff</h3><p>Of course, often, the thing that feels most alive about ethics is \u201cgetting it right\u201d \u2013 whatever that means. That is, it\u2019s the slaveholder stuff. The stuff where: wait, what\u2019s actually going on in a factory farm, or a concentration camp? What is the nature of the thing happening in this building? What\u2019s at stake here? The stuff where saying \u201cwhatever,\u201d or \u201cidk man, sounds like this sort of talk might involve changing my default policy, I\u2019m out\u201d ends up looking, in retrospect, not like some sort of hip and sophisticated assertion of your freedom from some \u201cgame,\u201d but just, like, well \u2026 evil. Blindness. Cowardice. The thing that shame and guilt and horror and anger are meant for. The thing where you turned away from something to-be-seen, where you didn\u2019t understand something to-be-understood.</p><p>I think anti-realists should face the fact that they have a harder time making sense of this. They talk and talk about their \u201ccares\u201d and their \u201con reflections,\u201d and the realists say, again and again, \u201cnot enough,\u201d \u201cnot enough.\u201d And it isn\u2019t enough. Faced with a concentration camp, what sort of talk could be enough? Is an extra objective normative realm enough? Do we even know what we want, when we want something \u201cenough\u201d for everything that everything means? Do we want philosophy at all, or something else? Something to tear through it all? Something to break it all open? <a href=\"https://www.goodreads.com/quotes/708295-what-was-it-then-what-did-it-mean-could-things\">\u201cBeauty would roll itself up; the space would fill; those empty flourishes would form into shape; if they shouted loud enough\u2026\u201d</a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreft5aya2j6w5n\"><sup><a href=\"#fnt5aya2j6w5n\">[1]</a></sup></span></p><p>I\u2019m not, here, going to try to defend an anti-realist story about \u201cgetting it right.\u201d I\u2019ll flag, though, that I expect some such story to be available, at least in many cases. For example, regardless of realism vs. anti-realism stuff, I expect some good-enough story about why I would be messing up by stabbing the nearest pencil into my eye. I ask myself: \u201cHow about stabbing this pencil into my eye?\u201d I answer: \u201cNo.\u201d And I expect this process to be in \u201cgood order.\u201d To not be resting on some kind of inescapable illusion about the existence of an extra normative realm, or some such. But this is a different can of worms.</p><h3>1.2 Taking responsibility</h3><p>Here, I want to talk about something else that seems alive to me about ethics \u2013 something that feels importantly related to \u201cgetting it right,\u201d but which I think has its own independent resonance, and which, for me, points in the opposite direction from \u201cwhatever.\u201d Namely: something about \u201ctaking responsibility,\u201d \u201cknowing what you are doing,\u201d and \u201clooking out of your own eyes.\u201d</p><p>I don\u2019t know fully what I mean. But I\u2019m going to try to point at some stuff, in a bit more detail than I\u2019ve done previously.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn972k3h089j\"><sup><a href=\"#fnn972k3h089j\">[2]</a></sup></span>&nbsp;In particular, stuff about:</p><ul><li>Understanding what it\u2019s possible to be and to do</li><li>Understanding what you are, and what you are in fact doing</li><li>Choosing what to be, and to do</li></ul><p><i>Thanks to Ketan Ramakrishnan, Katja Grace, Nick Beckstead, and Jacob Trefethen for discussion.</i></p><h2>2. Some backdrop</h2><p>The high-level, maybe-unnecessary-to-say-but-who-knows backdrop here is something like: you are, in fact, a real thing.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftfy57x9jkm\"><sup><a href=\"#fntfy57x9jkm\">[3]</a></sup></span>&nbsp;And not just, like, a rock. Some different sort of thing. Something alive. Something that looks out of its own eyes. It\u2019s strange. It\u2019s easy, somehow, to forget. But it\u2019s the real deal.</p><p>And you\u2019re going to live some particular life. Your choices are going to cause certain things \u2013 some things that you can see and experience, and some things that you\u2019ll never see (<a href=\"https://joecarlsmith.com/2021/01/31/believing-in-things-you-cannot-see\">do you believe in them</a>?). Then (modulo some big changes), you\u2019re going to die, and be dead forever and ever, and that will be all. You\u2019ll have been a particular thing, a particular sort of force in the world, a particular locus of causation and thought and experience; and then, it\u2019ll be over, and you\u2019ll disappear.</p><p>So there\u2019s some sort of chance, here. A brief chance. Something that\u2019s not going to come again. Something where, if you don\u2019t do it, it won\u2019t happen.</p><p>And there\u2019s a way this chance will go, if you don\u2019t \u201cplay the philosophy game.\u201d It\u2019s related to that old thing, the \u201cunexamined life.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxtupxsiyg8e\"><sup><a href=\"#fnxtupxsiyg8e\">[4]</a></sup></span>&nbsp;If you go this route, you\u2019ll be some particular, unexamined sort of creature. Some sort of \u201cdefault.\u201d And obviously, this has its comforts. Maybe it\u2019s more intuitive. More \u201ccommon-sensical.\u201d Maybe it goes, more smoothly, with some sort of flow. Maybe it seems, to you, like \u201cbody\u201d rather than \u201chead,\u201d and you like \u201cbody.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn3ja8j6oihm\"><sup><a href=\"#fnn3ja8j6oihm\">[5]</a></sup></span>&nbsp;And maybe, in particular, it seems less likely to follow some abstraction off a cliff. Which seems, in some circles, like a risk these days. As ever.</p><p>But there\u2019s a thing that the unexamined life isn\u2019t doing: namely, looking at itself in the face. Understanding what it is, what it\u2019s doing in the world, what it might be doing instead, what its \u201cchance\u201d will ultimately amount to in different circumstances. Or, maybe it starts with some story about this. But it\u2019s not checking if that story is true. Or even, if the story <i>could be </i>true. And it\u2019s not choosing a new story, if the default story is false; or if the default story can\u2019t look at itself without recoiling; if the default story can\u2019t tell itself in its own voice.</p><p>Indeed, it\u2019s not clear how much \u201cchoosing\u201d the unexamined life is doing at all, vs. defaulting to some choice-already-made. At the least, it\u2019s not making itself, as a whole, on purpose. Some other purpose made it. Or something random coughed it up. And it defers to that thing, that \u201cdefault.\u201d After all: whatever.&nbsp;</p><p>Of course, we can always say \u201cwhatever\u201d to all of this. Ultimately, if someone insists on saying \u201cwhatever\u201d to everything, we\u2019ll stop having stuff to talk about (though: this isn\u2019t just an anti-realism problem). And in that sense, we are, somewhere, going to have to appeal to some kind of brute motivation, some kind of preference or desire that something \u2014 your life, your choices, your understanding, your effect on the world \u2013 be a certain sort of way. But I think we can say quite a bit more about what this motivation is tracking than \u201cI\u2019m just into systematizing stuff\u201d or \u201cI just prefer that my policy have properties like consistency, coherence, simplicity, etc\u201d or \u201cI can make some extra money/power this way.\u201d Here are some gestures.</p><h2>3. Understanding what\u2019s possible</h2><p>In my <a href=\"https://joecarlsmith.com/2023/02/16/why-should-ethical-anti-realists-do-ethics#5-some-kind-of-brute-preference-for-consistency-and-systematization\">last essay</a>, I talked about how having a consistent policy isn\u2019t an \u201cidiosyncratic preference\u201d thing: rather, it\u2019s a \u201cwhat policies are literally possible to have\u201d thing. If you think that you, in your freedom, are pulling a fast one on logic, and somehow managing to have your cake and not have it too, you\u2019re just wrong. You\u2019re just deluded. And if you\u2019re <i>trying</i> to have your cake and not have it too, the sooner you notice this and give up, the better \u2013 at least from a \u201csucceeding at what you\u2019re trying to do\u201d perspective.</p><p>Thus, consider again <a href=\"https://joecarlsmith.com/2023/02/16/why-should-ethical-anti-realists-do-ethics#3-2-lizard-stuff\">the lizard stuff from the previous essay</a>:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676608870/mirroredImages/djByAbm6ptkkmS9RS/evckojqbvgibn5oon2r5.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676608870/mirroredImages/djByAbm6ptkkmS9RS/evckojqbvgibn5oon2r5.png 1024w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/z53hpv3i8rvhusbynnal.png 300w, https://res.cloudinary.com/cea/image/upload/v1676608870/mirroredImages/djByAbm6ptkkmS9RS/siscziixi1zrzh4ygmih.png 768w, https://res.cloudinary.com/cea/image/upload/v1676608870/mirroredImages/djByAbm6ptkkmS9RS/za8qsxvawbz6ngjhmsbt.png 1536w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/lysooelpgwza055bpzdv.png 402w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/pov6cllri99dfhin0vqq.png 462w, https://res.cloudinary.com/cea/image/upload/v1676608870/mirroredImages/djByAbm6ptkkmS9RS/cyilmwzuslu83hqpucal.png 662w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/ynrd7pyzashef1synfml.png 722w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/noiyu8545qz0q4umjqkl.png 982w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/kdkbcpud5tbqv2bxj5ea.png 1032w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/kbhjcxyh4fm4yzfqc551.png 1402w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/phwf4dirs28sv6xwqj64.png 1702w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/y7ykomawhhem9zri9f3j.png 1722w\"></p><p>Suppose I come to you on Monday and I say: \u201cAre you the type of agent who prefers A+ over A?\u201d And you say: \u201cOf course! Better for the Utopians, not-bad for the lizards.\u201d</p><p>And then I come you on Tuesday and I say: \u201cAre you the type of agent who prefers Z over A+?\u201d And you say: \u201cOf course! Higher total, higher average, more equality \u2013 easy!\u201d</p><p>And then I come to you on Wednesday and I say: \u201cAre you the type of agent who prefers Utopia over a zillion barely happy lizards?\u201d And you say: \u201cAre you kidding me? Fuck those lizards!\u201d</p><p>And I come to you on Thursday and I say: \u201cAre you the type of agent who doesn\u2019t prefer things in a circle?\u201d And you say: \u201cOf course! Preferring things in a circle is crazy!\u201d</p><p>And \u2026 that\u2019s all. You go back to the unexamined life. The philosopher doesn\u2019t try to take your money, or turn you into a lizard, or whatever. No one forces you off of any cliffs. And plus: you got to say what you wanted to say each time, right? Isn\u2019t that what this is about? Indeed, the people listening each day seemed pleased with your answers. Is philosophy, maybe, super easy?</p><p>But oops: you\u2019re still wrong. You\u2019re not that sort of agent. No one is. That\u2019s not a type-of-agent-you-can-be.</p><p>Fine, but does it matter? No one\u2019s actually proposing that we create lizard farms, after all. All this stupid impractical philosophy stuff. Just do the right thing already!</p><p>But being wrong has the same sort of costs it always does. For example, maybe one day someone starts talking about how there could be a <a href=\"https://joecarlsmith.com/2021/03/22/on-future-people-looking-back-at-21st-century-longtermism\">lot of people in the future</a>, and how each of these people would be just as real as you or me, and how maybe this matters a whole lot, like really <i>a lot</i>. And maybe you notice some connection between this and the lizard thing, and you pounce on it, and you proclaim that obviously any policy that could lead to lizards over Utopia is silly, because you\u2019ve got a policy that doesn\u2019t do this \u2013 indeed, one that has no downsides or uncomfortable implications. You remember describing it during some weird week a while back. Everyone loved it. People getting interested in this future people stuff should try your policy instead. (What does that policy say about future people, you ask? Um, whatever you wanted to say by default. Something moderate and very sage. No need to learn anything.)</p><p>But the thing is: you\u2019re wrong. You don\u2019t have this policy. You just think you do, because you\u2019re not looking at things whole, or steady. And now the people listening are wrong, too. They\u2019re trying to join you in laughing from some high horse that doesn\u2019t exist. They\u2019re trying to live, with you, in the land of square circles, where philosophy is easy, all your intuitions are true, and the hens lay soft-boiled eggs. But the place to live is the real world.&nbsp;</p><p>Again, again: I\u2019m not trying to turn you into a lizard. But I<i> am</i> trying to un-turn you un-into something you never were.</p><p>Indeed, I\u2019ve found it helpful, in relating to <i>Benign Addition</i>, <i>Non-Anti-Egalitarianism</i>, <i>Transitivity</i>, and <i>Utopia&gt;Lizards</i>, to invite the parts of me that care about what\u2019s stake in each of them to come forward; and then to see if I get to the point where me and these parts all sit down at the same table, look at A and A+ and Z together, and say \u201cwell guys, I guess we\u2019re just not going to get all of this, huh. Yep, I guess not.\u201d Not trying to decide which one to let go of; but just noticing, with all parts of me there to notice too, that something I might\u2019ve hoped for isn\u2019t possible.</p><p>I\u2019ve found that somehow, this posture creates a different tone than the one I used to have, re: lizards. Not a pulling in one direction or another. Not a vying-for-control. Not even an \u201comg it\u2019s so horrible.\u201d Something quieter. More of a muted sadness and recognition thing. A not-up-to-me-ness. And not up-to-philosophy, or \u201cphilosophy\u2019s fault,\u201d either. But also, an un-fogging. A seeing more clearly what sort of shape a path forward would have to take.</p><p>And this posture also opened up some space for me to notice some stuff I wasn\u2019t noticing before, about my reactions to these cases (for example, I now like <i>Non-Anti-Egalitarianism </i>less than I used to; and I\u2019ve got additional doubts about \u201c<a href=\"https://joecarlsmith.com/2022/03/21/on-expected-utility-part-3-vnm-separability-and-more#iv-separability-implies-additivity\">separability</a>\u201d \u2013 though this is a longer story). But I wouldn\u2019t have noticed this, if I had just gone with some flinching \u201cfuck it,\u201d or some unexamined \u201cthey\u2019re all so obvious.\u201d Actually, none of them seem obvious to me now. And somehow, seeing more clearly that I can\u2019t have all of them, I feel more free, rather than less.</p><h2>4. Understanding what\u2019s actual</h2><p>So understanding what\u2019s even possible is one benefit of the \u201cphilosophy game.\u201d Now I want to look at something richer and more complicated: namely, understanding what\u2019s <i>actual</i>, in terms of who you are, what you care about, and what sort of force you are in the world.</p><h3>4.1 Being and becoming</h3><p>First, though, a caveat. The line between this and the next section, on <i>choosing</i> who you are, what you care about, etc, is blurry \u2013 and instructively so.</p><p>In particular: above, yes, I said that you\u2019re a thing. But this was a simplification. Really, you\u2019re only a thing to something looking at you from the outside. From the inside, you\u2019re something else: something not-yet-settled; something more up-to-you (here the <a href=\"https://en.wikipedia.org/wiki/Incompatibilism\">incompatibilists</a> about free will rebel; but we should have that fight: the fact that they\u2019re wrong, for the relevant sense of \u201cfreedom,\u201d is important). Indeed, I think some anti-realists go wrong in this vicinity, with their \u201con reflections\u201d and their \u201cwhat I care abouts.\u201d They want to be already-a-thing, so that they can ask themselves what sort of thing to be.</p><p>Of course, it\u2019s not that you\u2019re <i>entirely</i> not-yet-a-thing, even from the inside: for example, you can\u2019t just choose to be whatever you want. If you want to say that you love eating bricks; that what you care about most is amputating your own legs; and that your endorsed policy is to stab pencils into your eyes whenever you get the chance: well, here\u2019s a pencil, let\u2019s see. \u201cOh, also, I\u2019m weak-willed.\u201d No, there are limits, even if it\u2019s hard to say where they fall. In particular: those are skin-in-the-game words you\u2019re trying to use. We need to see that skin. And you should, too.</p><p>So there\u2019s some sort of dance between understanding/interpreting ourselves and becoming ourselves, here, which I admit I don\u2019t have a rigorous account of, but which is neither a free-for-all nor a normal form of map-making. But I think ethics is doing a lot of this dance. Let\u2019s look at the \u201cunderstanding\u201d angle in particular.</p><h3>4.2 The \u201cit\u2019s a mess\u201d view</h3><p>I have a hazy memory of a conversation with a friend, where he said something like: \u201cI used to be more of a total utilitarian, but I\u2019ve mellowed over the years, partly in response to that stuff about <a href=\"https://joecarlsmith.com/2022/01/30/on-infinite-ethics\">infinite ethics</a>. Now, I endorse a view that I call the \u2018it\u2019s a big mess\u2019 view. Or, \u2018fuck it, pluralism.\u2019\u201d</p><p>I know various people like this. Before they wanted simple theories and hard lines. Then it became a bit much, and it stopped making sense in the way they had hoped it would, so they fell back on something softer and richer and more complicated. Something like total utilitarianism, but \u2026 less. With more of a \u201ccommon sense morality\u201d element. More ability to say \u201cOK yeah that too.\u201d</p><p>Doesn\u2019t that sound nice? You can almost feel the parts of them that had been suppressed reviving. And isn\u2019t it also less, I dunno, threatening? The old way had some \u201cfollow it off a cliff\u201d energy going strong. The new way has more wiggle room. You\u2019re allowed to be a mess! And not a lizard \u2013 or, for Christ\u2019s sakes people, a supervillain.</p><p>And I think people like appeals to moral uncertainty for this reason too. Not, often, because they have some theory about how to do moral uncertainty that they\u2019re actually using to get the verdicts they\u2019re claiming \u201cmoral uncertainty\u201d yields (the formal frameworks for doing moral uncertainty are suuuuper janky), but because it gives them some hazy license to bring back in more pluralistic and common-sensical vibes; to let more parts of themselves have a voice.</p><h3>4.3 Seeing yourself whole</h3><p>I\u2019m generally a fan of various vibes in this vein. But I think we should acknowledge that moving in the direction of \u201cit\u2019s a mess\u201d has costs. In particular: what it gains in not-off-a-cliff, it loses in self-knowledge. That is: say what you want about total utilitarianism, but you knew what kind of force it was in the world: namely, a force for total utility.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxaejfxhozp\"><sup><a href=\"#fnxaejfxhozp\">[6]</a></sup></span>&nbsp;It had some admirable quality where you\u2019d say \u201cdoesn\u2019t that imply X?\u201d and it would look you in the eye and say \u201cyes, yes it does.\u201d Whereas vague gestures at \u201cpluralism\u201d and \u201ccommon sense\u201d and \u201cit\u2019s messy\u201d have no such substance or heft. They\u2019ve retreated behind some sort of cloud. They\u2019re less threatening, but that\u2019s because they haven\u2019t said what they are, except that trust me, it won\u2019t be off-a-cliff (since of course, we all know where the cliffs are, right? Common sense can\u2019t be a cliff, right? We all know what common sense is, right?). There\u2019s a reason politicians on the campaign trail are vague.</p><p>And I think this issue bites harder as we move further in the direction the \u201cunexamined\u201d and the \u201cdefault\u201d (my \u201cit\u2019s a mess\u201d friends are still waaaay far towards \u201cexamined\u201d and \u201csystematic\u201d relative to what\u2019s possible). That is, maybe you want to say, with my anti-realist foil from the previous essay, \u201cI don\u2019t draw curves at all; I just do what\u2019s most intuitive in each case.\u201d And what is that? Hard to say. But more importantly: even if we can figure out what it is <i>in any given case </i>(by, for example, querying our intuitions), we still can\u2019t see what it <i>amounts to</i>. We can talk, individually, about each of a zillion little choice vectors one by one; but we don\u2019t know where they push in combination, what they are <i>doing</i>, what explains them; what they represent. We can see ourselves making any given specific choice. But we can\u2019t see ourselves whole.</p><p>Of course, seeing ourselves <i>fully</i> whole doesn\u2019t seem like an option, for minds like ours. So dimly, that mirror. We barely know who we are. We barely know what forces work through us, inside us, around us. We\u2019re bouncing, so often, off the surfaces of things, descending gradients we can\u2019t see, responding to cues and incentives and pressures we can\u2019t track. And even beyond this buffeting, we\u2019re just genuinely very messy creatures, with complicated norms, values, intuitions, and so on. And I don\u2019t think we should push this under the rug, or distort the truth in order to compress ourselves more succinctly.</p><p>Still: I think something is lost in the vagueness of \u201cmy values are complicated,\u201d or \u201c<a href=\"https://mindingourway.com/you-dont-get-t/\">you don\u2019t get to know what you\u2019re fighting for</a>.\u201d In particular: the less you know what something is, the less you\u2019re in a position to endorse it, reject it, change it, in a way that\u2019s in touch with its nature. The less you know what you\u2019re fighting for, the more that thing is fighting through you, using you, without your having looked it in the face and said \u201cyes.\u201d \u201cCommon sense\u201d is suuuper not an exception here. Where did common sense come from? Something with power \u2013 some set of people, some selection process \u2014 put it in place, including in its place in your head, and your sense of what\u2019s \u201csafe\u201d and what\u2019s \u201ca cliff.\u201d Maybe, if you saw that thing whole, it would seem wise (I do think common sense is very often wise \u2013 and that it\u2019s having-been-selected is evidence for this), and you would say \u201cyes\u201d to it. But maybe not. And if you can\u2019t see it, you can\u2019t tell.</p><h3>4.3 Agents-you-aren\u2019t</h3><p>There\u2019s also an \u201cunderstanding\u201d failure mode in the opposite direction, here, which philosophy also helps with: namely, having a false vision of yourself-as-a-whole. (Cf., again, many total utilitarians.)</p><p>Above I talked about agents-you-can\u2019t-be, because they\u2019re not logically possible. But there\u2019s a different thing, about agents-you-could-be, but which, oops, you aren\u2019t.</p><p>For example, maybe, according to you, you\u2019re an \u201call men are created equal\u201d type. That is, you treat all men equally. Maybe you even write a fancy document about this, and this document gets involved in the founding of a country, or something.</p><p>There\u2019s a thing philosophy can do, here, which is to notice that you still own slaves. Including: male slaves. And it can do that whole \u201cimplication\u201d thing, about how, Socrates is a man, you treat all men equally, therefore you treat Socrates equally, except oh wait, you don\u2019t, he\u2019s your slave.</p><p>Now: philosophy isn\u2019t yet telling you to <i>free</i> Socrates, here. But it\u2019s pointing out a failure of self-knowledge. You thought you had seen yourself whole. But you were wrong.</p><p>Indeed, wasn\u2019t it great? You drew a curve. You did what the total utilitarian, above, was willing to do. And, thus: you learned something.</p><p>Drowning children stuff has a lot of this part.</p><h2>5. Choosing what to be</h2><p>So philosophy can help you understand what sorts of agents it\u2019s possible to be, and it can help you understand what sort of agent you are. Still, aren\u2019t we missing something? This makes philosophy sound, mostly, like a combination of (a) logic, and (b) psychology. Is that all? Wasn\u2019t there supposed to be something more <i>active</i> and <i>normative </i>about ethics?</p><p>Yes. But I think this part is the trickiest to understand, partly because of the being vs. becoming dance I mentioned above. Indeed, I don\u2019t think I understand it fully myself. But let\u2019s look at some examples.</p><h3>5.1 Crates</h3><p>Suppose that you\u2019re at dinner with a friend, eating some pork chops. Your friend starts telling you about someone she knows, who keeps his dog, for months at a time, in a cramped, metal, hard-floored crate where it can\u2019t even roll over; who beats this dog regularly; and who is planning, in a few years, to stun the dog, slit its throat, and eat it (he lives in a country where this is legal; and in fact, quite normal). \u201cWhat?\u201d you say. \u201cThat\u2019s horrible.\u201d You think about the dog, trapped, suffering, the metal pressing against its sides, chewing repetitively on one of the bars. You want it to stop. You want to help.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/suxd69rvynpasn7cqy8t.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/suxd69rvynpasn7cqy8t.png 1024w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/i1bcdzztufwejlvavrhm.png 300w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/eamzsvabg3zhzjahyqnj.png 768w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/w8rnmrtdu5tjj1bdahrv.png 402w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/a2en4ssiyusrph7rr2hl.png 462w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/pueuwr7eupjrnxrp9z6c.png 662w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/unrxoe67q3ssn2ol0cpx.png 722w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/ablktff8tim9xnryyivw.png 982w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/aw1lyggabyot4zeoddgd.png 1032w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/kw3fhhy3otuovces3ats.png 1048w\"></p><p><i>Maybe a dog sort of like this one. (Image source </i><a href=\"https://loc.getarchive.net/media/very-sick-old-dog-on-his-last-legs-his-master-is-a-mexican-san-antonio-texas\"><i>here</i></a><i>.)</i></p><p>Then you remember something about how pigs get treated in ways not-too-different from this, and maybe worse, in giant farms all around your own country.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxhqath2sk7\"><sup><a href=\"#fnxhqath2sk7\">[7]</a></sup></span>&nbsp;Pigs like the one you\u2019re eating now. You think about this, too. Pigs, you expect, are roughly as conscious as dogs. You imagine a pig in a similar situation.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/txfylkgfhivjseoixly3.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/txfylkgfhivjseoixly3.png 1024w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/pq2dkdp9ttlbno4vmjy8.png 300w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/mb9taoh02wtci1sk4rwc.png 768w, https://res.cloudinary.com/cea/image/upload/v1676610845/mirroredImages/djByAbm6ptkkmS9RS/pjlvvjd08mwjlxypdowy.png 1536w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/xlhgwvzebcvzma0paoce.png 402w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/warmt706b4kyywmcs9zh.png 462w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/a2kvozrmqy23pnpjmrtb.png 662w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/mre2ywde9gmxh7ackdow.png 722w, https://res.cloudinary.com/cea/image/upload/v1676610845/mirroredImages/djByAbm6ptkkmS9RS/ibjn22a990fwpfdqrtbc.png 982w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/ha0ghdu0nn2tggbjccib.png 1032w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/hfdbsnni7o3qgq3ps8i7.png 1402w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/lswo2wh2n8obo36cwdoj.png 1692w\"><a href=\"https://en.wikipedia.org/wiki/Gestation_crate\"><i>Gestation crates</i></a><i>. Image source </i><a href=\"https://commons.wikimedia.org/wiki/File:Gestation_crates_3.jpg\"><i>here</i></a><i>.</i></p><p>Now, one thing that could happen here is that you realize that actually, your reaction to the pig is similar to your reaction to the dog. That there\u2019s a curve here, in your heart, that you didn\u2019t notice before; but which, once seen, starts moving, and taking on some sort of fire, and suddenly you\u2019re looking around at the world, and the farms, and the porkchop, and the leather of the couch, in some very different way, and something is breaking open, crying out, reeling in horror.</p><p>In that case, the self-knowledge victory \u2013 and so too, I claim, the \u201cexamined life\u201d victory \u2013 is fairly straightforward. You\u2019ve learned something new about what your heart responds to, and where it\u2019s at stake in the world.</p><h3>5.2 Hot and cold hearts</h3><p>But let\u2019s say that actually, when you think about the pig, your heart is cold. Somehow, this time, you\u2019re not very fussed.</p><p>What happens next? If you\u2019re enough of a \u201cfuck it\u201d anti-realist, if you\u2019re not trying to see yourself whole, you might just say \u201cwhatever,\u201d and go back to eating. Helping dogs, apparently, is intuitive to you; helping pigs, not so much; and that\u2019s, just, the data. Why draw curves?</p><p>But maybe you read the last section, and you\u2019ve decided that seeing yourself whole is worth trying. So you start trying to explain <i>why</i> you have this pattern of intuitions. Is it, maybe, because dogs have nice soft fur, and pigs don\u2019t? You trying drawing that curve. What would it predict about your reaction to, say, a hippo? You think about a hippo like the one from the zoo, trapped in a crate, suffering, getting its throat slit. And this time, your heart is hot; you\u2019re fussed. Look at that hippo! It can\u2019t even roll over.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/svxcmcc9s7jmhckj9is8.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/svxcmcc9s7jmhckj9is8.png 1024w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/l2mp3vhgsy2tblmm9ucs.png 300w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/sozqo2voomrcrrzldqth.png 768w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/rj4um1vmrsje2blht6kp.png 402w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/zuamdf1cxlgd9gfbenvs.png 462w, https://res.cloudinary.com/cea/image/upload/v1676610845/mirroredImages/djByAbm6ptkkmS9RS/qgexmsbeixyefuuxqzxp.png 662w, https://res.cloudinary.com/cea/image/upload/v1676610845/mirroredImages/djByAbm6ptkkmS9RS/fcsggrarj15davgdpiaz.png 722w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/gbb5oaoc6lhh0f6eunyf.png 982w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/l0pt3ulwsiyfskyejpfc.png 1032w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/ttpryuixjdfajjdtcxih.png 1344w\"></p><p><i>A hunted hippo. (Image source </i><a href=\"https://commons.wikimedia.org/wiki/File:Hippovictora.png\"><i>here</i></a><i>.)</i></p><p>So you\u2019re already on the \u201cexamined life\u201d train, here; and you\u2019re learning stuff. And let\u2019s say you ride that train for a while, gathering data about your intuitions, trying to fit some sort of curve to them. And let\u2019s say you do pretty well at it, and in particular, you end up with the following theory looking decently well-supported: namely, your intuitions respond to the plight of animals that the particular culture you were raised in thinks of as important-to-treat-well. And let\u2019s say, even, that you do some more research about why your culture is into this particular set of animals and not others, and you find out that it has to do with some contingent facts about farming and zoos and domestication and cuteness and stuff.</p><p>Now, here the realist feels an impulse to pounce. \u201cHa!\u201d they say. \u201cYour intuitions are explained by a causal process that wasn\u2019t plausibly sensitive to the objective moral facts! No way your culture peeked into the <a href=\"https://joecarlsmith.com/2022/01/17/the-ignorance-of-normative-realism-bot#i-what-s-in-the-envelope\">envelope</a> of the normative realm, <i>then</i> decided which animals to honor, and which to brutalize. And also, no way the objective normative realm draws important distinctions between dogs and pigs. That would be so arbitrary! The objective normative realm isn\u2019t like that! Or so I intuit! Thus, your intuitions are <i>biased</i>, and must be given up. (Well actually, no, your intuition about the dog was true; not the pig one though, that one is a bias!).\u201d</p><p>But then, uh oh: <a href=\"https://joecarlsmith.com/2022/01/17/the-ignorance-of-normative-realism-bot#ii-can-you-touch-the-ghostly-frosting-with-your-mind\">nothing can peek into this sort of envelope</a>, because this sort of envelope lives apart from the natural world, and \u201cpeeking,\u201d with your natural-world, causing-you-to-say-and-do-stuff mind, is a natural-world thing. So the realist gets sheepish and starts muttering about math and consciousness and how <a href=\"https://joecarlsmith.com/2022/12/01/against-meta-ethical-hedonism#5-the-mystery-view\">maybe-somehow-though</a>.</p><h3>5.3 Is your heart a thing?</h3><p>But what of the anti-realist? I think many anti-realists assume, too quickly, that they can just talk like realists, here. That they know what is \u201carbitrary\u201d and what is not; what is a \u201cbias\u201d and what is not; and that knowing how an intuition got there is equivalent to knowing it should leave. But we are made entirely of stuff that got there, somehow.</p><p>Or are we? From the outside: yes. From the inside, though, it\u2019s more complicated. In particular: we\u2019re not fully made-of-anything, yet, because we\u2019re not fully made; we\u2019re in-the-midst-of-making. We\u2019re doing the being-and-becoming dance, and what you choose to become, you\u2019ll have been the seeds of all along.</p><p>Thus, suppose that you are left with the following psychological theory: \u201cmy intuitions about which animals matter are explained by blah features of my culture\u2019s attitude towards animals.\u201d Suppose, further, that you\u2019re wondering, given this, about whether to keep eating pork chops, or to stop (or maybe: to keep eating them in some more complicated and still-opposed-to-factory-farming way). And suppose you\u2019re the type of anti-realist who thinks that what you \u201cshould do\u201d is determined by what you \u201ccare about.\u201d</p><p>OK, what do you care about? One story is: \u201cI care about the animals that my culture treats as important.\u201d And indeed, this story might seem the most natural fit with the \u201cdata.\u201d If <i>all</i> we\u2019re doing is drawing empirical curves, in an effort to explain your actual pattern of intuitions, this curve might seem like the winner. Maybe it\u2019s a <i>bit</i> janky \u2013 your culture didn\u2019t exactly pick a natural class of animals to honor vs. brutalize \u2013 but such fidelity! And if you follow this curve, you keep eating.</p><p>So, are we done? Well, it\u2019s up to you. You\u2019ve done some self-knowledge-gathering. You\u2019re seeing yourself more whole. But what are you seeing? And what do you have left to see? Given what you now know, what you are going to do with your single chance to live?</p><h3>5.4 Seeing the general of the army you\u2019ve been fighting in</h3><p>One thing you\u2019re seeing more clearly, now, is what sort of force you\u2019re going to be in the world, if you stick with your \u201cdefault.\u201d Maybe before, you were a hazy cloud of \u201ccommon sense,\u201d and \u201cwhatever seems reasonable\u201d and \u201cnot off a cliff.\u201d But now, you\u2019ve gotten more concrete, and you\u2019re seeing stuff about zoos and domestication and cuteness; you\u2019re seeing that if you got born into a culture that brutalizes dogs instead, you \u2013 or, an agent running a policy very similar to yours \u2014 would go along with it. So you\u2019re knowing a bit more about what, in practice, you\u2019ve been fighting for so far; what the general of the army-you\u2019ve-been-a-soldier-in will do with victory and power; what sort of vector you\u2019ve been, and will be by default: namely, a vector for animals-your-culture-likes getting treated well; and for keeping the rest in crates.</p><p>And maybe, if you\u2019ve started getting the \u201cexamined life\u201d thing into your bones, new self-knowledge questions are coming up, too. For example, what would your policy do in a culture that brutalizes certain sorts of humans? How does it know what\u2019s an \u201canimal\u201d and what\u2019s not? Why do humans call each other animals during genocides? What\u2019s going on, more generally, when something puts something else in a crate?</p><h3>5.5 Looking again</h3><p>But there\u2019s also a different sort of \u201cexamined life\u201d move that\u2019s available here: one that seems to me especially precious, and especially hard to understand. I\u2019m going to call it \u201clooking again.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefm5y9btgz62a\"><sup><a href=\"#fnm5y9btgz62a\">[8]</a></sup></span>&nbsp;Or maybe: \u201clooking more deeply.\u201d</p><p>We said above that you found your heart hot for dogs, cold for pigs; and that you found a good empirical theory for why this is so. And if you want, you can stop there; the same way that, if you want, you can glance at a painting, log it as \u201cI like it\u201d or \u201cI don\u2019t like it,\u201d and move on. Or the way you can glance at a forest, or the stars, and say \u201cpretty.\u201d Or the way you can glance at how-to-live and say \u201chappiness.\u201d</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/vge2fctpuflwxcmmi5ty.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/vge2fctpuflwxcmmi5ty.png 1024w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/nlbjwndhx3qjcgd23orr.png 300w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/w4h50jl1rsno5lx6jgp9.png 768w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/yjyagsahid3xzhys9szj.png 1536w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/gh2uvhhetmmivhthksrh.png 402w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/kyiqblmkqhruybooictg.png 462w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/wcnvmu1uhgy2tauulqkx.png 662w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/dw5x30fgnmgjgwn3s1rg.png 722w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/rufuks5z2tt8bshvwhgq.png 982w, https://res.cloudinary.com/cea/image/upload/v1676608871/mirroredImages/djByAbm6ptkkmS9RS/h39lunxuk0nhk5pcyqqo.png 1032w, https://res.cloudinary.com/cea/image/upload/v1676610845/mirroredImages/djByAbm6ptkkmS9RS/tr9xmwjf7jx54sitg44t.png 1402w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/ivwhtpks05r5evm8vpt4.png 1650w\"><i>\u201cI like it?\u201d (Image source </i><a href=\"https://commons.wikimedia.org/wiki/File:Picasso%27s_Guernica_-_impressive_up_close_%285515934400%29.jpg\"><i>here</i></a><i>)</i></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676610845/mirroredImages/djByAbm6ptkkmS9RS/vkuyps30nlvxfo9dbfyk.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676610845/mirroredImages/djByAbm6ptkkmS9RS/vkuyps30nlvxfo9dbfyk.png 1024w, https://res.cloudinary.com/cea/image/upload/v1676610845/mirroredImages/djByAbm6ptkkmS9RS/sthuipootjdskcjd5br7.png 300w, https://res.cloudinary.com/cea/image/upload/v1676610845/mirroredImages/djByAbm6ptkkmS9RS/j1qarksyngq3pafu36pg.png 768w, https://res.cloudinary.com/cea/image/upload/v1676608873/mirroredImages/djByAbm6ptkkmS9RS/sywxv8qjijaoj5bjegzs.png 1536w, https://res.cloudinary.com/cea/image/upload/v1676610845/mirroredImages/djByAbm6ptkkmS9RS/gsbnqynaaehhjetwq8kq.png 402w, https://res.cloudinary.com/cea/image/upload/v1676610845/mirroredImages/djByAbm6ptkkmS9RS/skyf27lxbytcpl0rpyik.png 462w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/imfkjwonxmfgpunnivau.png 662w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/kqh3byry7sje0uilbdtt.png 722w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/ircthkxh7yq9gq25hgjd.png 982w, https://res.cloudinary.com/cea/image/upload/v1676608872/mirroredImages/djByAbm6ptkkmS9RS/mro8rr4ammfvyulyo06n.png 1032w, https://res.cloudinary.com/cea/image/upload/v1676608873/mirroredImages/djByAbm6ptkkmS9RS/crlexdriquowaciinn7v.png 1402w, https://res.cloudinary.com/cea/image/upload/v1676608873/mirroredImages/djByAbm6ptkkmS9RS/meecx6y2icxjzmyvphhb.png 1702w, https://res.cloudinary.com/cea/image/upload/v1676608873/mirroredImages/djByAbm6ptkkmS9RS/dj5sdm4w6m2x9u0b1man.png 1706w\"><i>\u201cPretty?\u201d (Image source </i><a href=\"https://commons.wikimedia.org/wiki/File:Brussels_Zonienwoud.jpg\"><i>here</i></a><i>.)</i></p><p>But you can also do something else. You can look again. For example, at the dog trapped in the crate, whimpering. What\u2019s really happening here? What\u2019s really at stake? Yes, apparently, your care for this animal is dependent on your culture. But what is that care caring about? When you recoil at this animal getting beaten, what are you recoiling from?</p><p>Or maybe you look, again, at the pig. Maybe you sit down next to the pig, next to the crate, on the hard concrete. Maybe you try putting yourself into a crate. Maybe you try chewing, yourself, on a metal bar; or getting dragged by the ear down a dark hallway; or writhing on a hook as the blood sprays from your neck. You\u2019re not a pig: you know that. But there\u2019s something going on with this pig. Have you seen that thing whole?</p><p>I\u2019m not just talking about empathy, though empathy may be involved. You can do the thing I\u2019m talking about with non-minds \u2013 with paintings and forests and stars, with music, and with bad stuff, too, with wars and genocides and pettiness and envy. It\u2019s some other openness, some willingness-to-receive. I think it\u2019s related to what Martin Buber means by \u201cencounter\u201d; and Simone Weil, by \u201cattention.\u201d And related, too, to some dimension of love \u2013 not necessarily the \u201cyes\u201d part, or the gushy-gushy part: but love like in-the-world-with-you, aware-of-you, willing-to-see-you-as-you-are. And I think some types of science have some of this, too.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0acgymr1ay5\"><sup><a href=\"#fn0acgymr1ay5\">[9]</a></sup></span></p><p>I don\u2019t have a great story about what\u2019s going on, with this thing. I admit that, when done in a moral context (and in fact, more generally), it pulls me towards realism. And I think it does this partly because it seems like neither some static inquiry into what you already care about \u2013 some attempt to \u201cexpose yourself to different stimuli\u201d and to notice your resulting motivational patterns \u2013 nor the type of thing easily captured by the connotations of becoming \u201cbetter informed\u201d (though that is indeed one gloss).</p><p>Still, I expect the anti-realists to have resources, ultimately, for understanding this thing, and for treating it as important. And I think the being-and-becoming dance may have a role to play. That is, part of what happens, when you \u201clook again\u201d or \u201clook more deeply\u201d at something, is that you invest more of your being-and-becoming dance into relationship with that thing. You become something new, with that thing, now, doing more to shape you. Indeed, that\u2019s part of what\u2019s scary, about trying to see things more whole. You don\u2019t just find out who you already were, where you already lived. You\u2019re not, just, drawing a \u201cmap.\u201d Not just \u201cseeing.\u201d You\u2019re being seen; being touched; being made.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefvyypgrtmh5\"><sup><a href=\"#fnvyypgrtmh5\">[10]</a></sup></span></p><h3>5.6 Choosing what you care about</h3><p>And let\u2019s suppose that, after various examined-life things in this vein, some new story becomes salient: namely, a story on which what you really care about, with the dog, is something about <i>suffering</i>; that this something is at stake, just as much, with the pig; and that in this sense, lack of care for the pig is a \u201cmistake,\u201d a kind of blindness, a not-to-be-trusted, a not-to-act-on. So now we have two possible stories: \u201cI care about the dog, but not the pig,\u201d and \u201cI care about both.\u201d</p><p>Which one is true? Wait, didn\u2019t we already answer? We said: your heart is hot for the dog, cold for the pig. Well, yes, we did say that. But one thing is: it\u2019s not like your examined life thing was over here, on the left, and your heart was over there, on the right \u2013 or at least, I hope not. So one thing that could\u2019ve happened, is that your heart started changing, \u201cbecoming,\u201d as you were doing this inquiry-thing, and this \u201clooking again\u201d; that your heart started to understand better what it was responding to, in the dog, and started to see that thing in the pig, too; or that it started to respond to something new in both of them.</p><p>But let\u2019s make things harder, and suppose that actually, your heart is still just cold for pigs. Indeed, let\u2019s say that for whatever reason, your emotional psychology is really anchored on your cultural status quo, such that you just can\u2019t get fussed, at a certain emotional level, about the animals your culture doesn\u2019t care about. In that case, do we have our answer? Is the true story \u201cyou care about the dog, but not the pig?\u201d</p><p>Well, I\u2019m not sure. Because I haven\u2019t yet seen what you ultimately choose to do. That is, from the outside, if we\u2019re wanting to know \u201cdoes this person care about both the dog and the pig, or only the dog?\u201d, we\u2019re not just looking at the hotness of your heart. We\u2019re looking at what you do, ultimately, with the pork chop (or: its analogue). We\u2019re waiting for you to choose. <i>Then </i>we\u2019ll know who you are, and what you value. But not before.</p><p>But you don\u2019t have to wait. You get to choose for yourself. You get to <i>decide</i> which story will be true. Which story will have <i>been</i> true, even <a href=\"https://joecarlsmith.com/2021/08/27/can-you-control-the-past#iii-who-is-the-eggman-and-who-is-the-walrus\">before you decided</a>. If you choose to put down the pork chop, because of something about the pig\u2019s suffering, then it will already have been the case that there was something in you that would do that; something \u201cmoved,\u201d pretty literally, by the pig\u2019s suffering; something with motive force; something, I think, rightly called \u201ccare,\u201d whatever its temperature in your heart.</p><p>That is, there is an important sense in which you get to <i>choose</i> what you value, because your choices, and what will-have-caused-them-once-they-are-made, are part of what <i>constitutes</i> what you value. You are not beholden to some pre-existing set of impulses and emotions and desires. You\u2019re not even beholden to what you \u201cwould do,\u201d \u201cwould feel,\u201d etc in other, more idealized circumstances.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhrvo546y2x7\"><sup><a href=\"#fnhrvo546y2x7\">[11]</a></sup></span>&nbsp;You are active. You are a participant. Yes, there is a story, here, but you can\u2019t read ahead. You live <i>in</i> the story. You\u2019re a character; indeed, a player character. Trying to read ahead would be another thing happening in the story now; there would still be a question of what happens next; and it would still be up to you.</p><p>This isn\u2019t some post-modernist woo. It\u2019s not a more general \u201cchoose your own reality.\u201d You can\u2019t make yourself, for example, into something-that-can-fly \u2013 and not because you\u2019re not believing hard enough.</p><p>It can seem woo-y, though, because we\u2019re bad at understanding compatibilism about free will; bad at understanding how it both be the case that there\u2019s already a fact about what you will do, <i>and</i> the case that you get to decide. But, that\u2019s the deal. And when you decide, what you care about will have been flowing through you; and we will see its fruits.</p><h3>5.7 Living from the inside</h3><p>To be clear: I\u2019m not trying to say that there\u2019s nothing confusing here. In particular: part of what we\u2019re talking about is living \u201cfrom the inside,\u201d as opposed to purely \u201cfrom the outside.\u201d Looking out of your own eyes, instead of always from above; moving your own arms, instead of watching them move. And basically everyone, as far as I can tell, kind of sucks at understanding this realm of thing, including the \u201c<a href=\"https://joecarlsmith.com/2020/11/29/grokking-illusionism\">illusionists</a>,\u201d and the people who use the word \u201calgorithm\u201d like it\u2019s supposed to help. It\u2019s connected, unfortunately, to the consciousness stuff, the stuff about \u201cqualia\u201d and \u201cwhat it\u2019s like to be something\u201d; stuff about the territory, the world, making a map of itself, \u201cknowing\u201d itself, \u201cbeing aware of itself,\u201d even as it surges forward, with the map making a difference, the maps mapping each other and themselves, eyes looking back at each other, the world becoming spirit, brute matter becoming \u201cawake.\u201d</p><p>But the confusing stuff here is also important, even to the meta-ethicists. In particular, I suspect that \u201creasons\u201d are going to end up similar to \u201ccare, but from the inside,\u201d and that part of what the realists are reacting to, when they recoil from rephasing normative talk in terms of \u201cI care abouts,\u201d is the sense in which \u201cI care about\u201d shifts us back into looking at ourselves from above, and \u201cabove\u201d is not the stance of decision. \u201cNo, no, we\u2019re not trying to map ourselves, here,\u201d say the realists, and they are right. We are doing something else. We are doing the being-and-becoming dance. We\u2019re looking out of our own eyes.</p><p>And I think the anti-realists struggle with this, too. Anti-realists are most comfortable with \u201cabove,\u201d with some kind of descriptive, third-personal, map-making mode. They\u2019re scared to not be doing science. So they hope that science can make their choices for them; that if they just knew <i>enough</i> science, there would be no need for ethics; that if they could just <i>watch</i> themselves hard enough, they would never need to <i>be</i> themselves. And maybe, if you do enough of that, you can forget that you were being yourself, making yourself, the whole time; that what you did, actually, was choose some specific self-to-be \u2013 one that granted some authority to some particular set of facts, which allowed some particular \u201coutside\u201d to move the inside forward. But it was you the whole time.</p><h3>5.8 Gushy-gushy is not the same as care</h3><p>And I think this issue matters, too, to realist objections to anti-realism that assume \u201cwhat I care about\u201d is some fixed, unchosen thing that the anti-realist thinks you must respect. And it matters, too, for anti-realists (and realists, too) who get worried that their hearts aren\u2019t hot enough about the stuff they want to care about. Your heart \u2013 or at least, a narrow, gushy-gushy construal of your heart \u2013 isn\u2019t the only thing with heat, here; your mind has heat, too. Your mind can <i>move</i> stuff, and be moved. It, too, has energy and life. Just as suffering can flow through from the world, to your heart, to what you do with the porkchop, so too can it flow through from the world, to your mind, and out along that same path \u2013 out through your arms, your voice, your life. \u201cGushy-gushy\u201d is the not the same as care.</p><p>Thus, for example, many people, including me, want to say stuff like \u201cpeople\u2019s suffering doesn\u2019t matter less, the further away it is from me in space.\u201d But here the realist comes in and says \u201cbut c\u2019mon, dude, there\u2019s some clear sense in which you care more about the suffering you see right in front of you than suffering far away: for example, look at the difference in how hot your heart is. And also: you agree with me that this stuff about idealizations isn\u2019t some straightforward solution. So where are you getting the idea that you shouldn\u2019t be partial to the nearby-people? If I were you, and an anti-realist, I\u2019d just be like \u2018well, clearly I <i>don\u2019t</i>, actually, care equally about people far away, and there\u2019s no pressure from normative reality to revise this pattern of concern, so that\u2019s just: that.\u2019\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref20kpaf3udhk\"><sup><a href=\"#fn20kpaf3udhk\">[12]</a></sup></span></p><p>But the pressure doesn\u2019t need to come from normative reality. It can come from <i>you</i>. You can choose to not let your policy be dictated by the hotness of your heart in this regard. And if you do that well (doing it well is indeed harder), and without self-deception (also tricky), then I think it will be right to view your efforts as an expression of your care for far-away people. And if you do it <i>fully</i>, and you actually implement a policy that treats far away and nearby people equally, and you do this <i>because</i> it treats those people equally, then I think it will be right to say that you care equally about them, even if your heart\u2019s mirror is partly dim.</p><p>But how do you decide whether to implement such a policy, or to try to? Look out your own eyes. What do you see? &nbsp;</p><h2>6. Poise</h2><p>So these are three dimensions of the examined life: understanding what it\u2019s possible to be and to do; understanding what you are, and what you are doing; and choosing what you will be, and what you will do. It\u2019s trying to see more whole; but to see that whole, too, from out of your own eyes.</p><p>Now obviously, there\u2019s a ton more to be said about the examined life, and about the value of anti-realist ethics in particular (and more to be said, as well, about some of the stories in the previous essay \u2013 here I\u2019m especially interested in \u201cgetting your parts to play nice together\u201d stuff). And I want to reemphasize that trying to see yourself more whole does not mean distorting yourself, or simplifying yourself, or killing parts of yourself, for the sake of becoming more \u201cseeable.\u201d Nor, indeed, do the vibes of the word \u201csystematic\u201d seem especially useful, here. This isn\u2019t about forcing yourself into a spreadsheet. And the vibes of \u201cphilosophy\u201d may mislead, too. Certainly, this isn\u2019t about grabbing blindly at the nearest ethic you happen to associate with philosophers; and the costs of doing philosophy badly remain as high as ever (indeed, such costs are often proportionate to the enthusiasm and confidence with which the relevant \u201cphilosophy\u201d was pursued \u2013 a fact that persists in its relevance to the case for \u201ccommon sense\u201d).</p><p>Nor, indeed, is the stuff I\u2019ve been talking about some kind of uber-value, some hard constraint on how-to-live, that must trump and structure all other values. The value of \u201cexamination\u201d and \u201cseeing more whole\u201d trades off against jogging and practicing public speaking and so on, just as everything else does. Indeed, in this sense, the account I\u2019ve offered here raises the same question that the \u201cbrute preference\u201d and the \u201cmoney-pumping\u201d accounts raised in the last essay: OK yes, maybe that\u2019s worth <i>something</i>, but how much?</p><p>To me, though, it\u2019s worth a lot. And I hope what I\u2019ve said here can serve as an at-least-somewhat-structured gesture at part of what makes it seem that way. In particular, I\u2019m hoping that some vision of a way of being might shine through. Something where you\u2019re taking active responsibility for what you are doing with your one and only chance to live. Where you don\u2019t just have a policy; you\u2019re choosing your policy, designing it, trying to see what combination of forces it represents, trying to change it if you aren\u2019t a \u201cyes\u201d to what it ultimately amounts to. You\u2019re not just a thing; you\u2019re a thing-making-itself. You aren\u2019t just another vortex of causation, blindly flinging out whatever reflexive reactions the world coughed into you. Rather, you\u2019ve found some sort of footing, some kind of center. Something stands upright. You know what you are doing, and why.</p><p>It\u2019s a vision, for me, of a kind of poise; a not-flailing; perhaps, even, a kind of grace. Or maybe: a kind of adulthood. In so many ways, we are, indeed, as children. Barely not rocks. We barely have eyes, I suspect, relative to what it is possible; we never see near to whole; and what light can we see is almost too much, too bright. Still, we are here. We are free. We can try to look steady.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnt5aya2j6w5n\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreft5aya2j6w5n\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See also Walter Kaufmann on God, in the intro to his translation of <a href=\"https://www.amazon.com/Thou-Trans-Smith-Martin-Buber-ebook/dp/B0051I50EM/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=\">I and Thou</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn972k3h089j\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn972k3h089j\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The idea of \u201ctaking responsibility\u201d comes up often in my writing \u2013 e.g. <a href=\"https://joecarlsmith.com/2021/02/07/killing-the-ants#ii-owning-it\">here</a>, <a href=\"https://joecarlsmith.com/2022/01/30/on-infinite-ethics#xvi-nihilism-and-responsibility\">here</a>, <a href=\"https://joecarlsmith.com/2022/03/18/on-expected-utility-part-2-why-it-can-be-ok-to-predictably-lose#v-taking-responsibility\">here</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntfy57x9jkm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftfy57x9jkm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Great start, Joe.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxtupxsiyg8e\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxtupxsiyg8e\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Worth living, I expect.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn3ja8j6oihm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn3ja8j6oihm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Though: philosophy has a body! Including: a <a href=\"https://akademician.files.wordpress.com/2019/08/lewis-men-without-chests.pdf\">chest</a>. Or, it should. Abstractions \u2013 or, some abstractions \u2013 aren\u2019t actually abstract. They\u2019re just talking about a lot of concrete, detailed things at once. Cf. \u201cFuture people.\u201d \u201cBetter for everyone.\u201d \u201cChildren far away.\u201d Thanks to a friend for discussion of this last point.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxaejfxhozp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxaejfxhozp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Though: not if you suck at putting it into practice. Which also seems like a risk these days.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxhqath2sk7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxhqath2sk7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Wikipedia <a href=\"https://en.wikipedia.org/wiki/Intensive_pig_farming\">here</a>, <a href=\"https://en.wikipedia.org/wiki/Pig_slaughter\">here</a>, and <a href=\"https://en.wikipedia.org/wiki/Gestation_crate\">here</a>. Horrible footage <a href=\"https://en.wikipedia.org/wiki/File:Pigs_boiled_alive.webm\">here</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnm5y9btgz62a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefm5y9btgz62a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Here I\u2019m inspired in part by the daughter-in-law parable in Murdoch\u2019s <a href=\"https://en.wikipedia.org/wiki/The_Sovereignty_of_Good\">The Sovereignty of Good</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0acgymr1ay5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0acgymr1ay5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Thanks to Katja Grace and Anna Salamon for discussion of some of this stuff, years ago.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnvyypgrtmh5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefvyypgrtmh5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Related: you read the text; but it reads you, too. (Maybe also: \u201c<a href=\"https://www.goodreads.com/quotes/8744660-and-if-thou-gaze-long-into-an-abyss-the-abyss\">if thou gaze long into the abyss, the abyss will also gaze into thee</a>.\u201d)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhrvo546y2x7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhrvo546y2x7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If someone tries to tell you what you <i>will</i> <i>do</i> in this specific circumstance, we get into weirder territory. But I don\u2019t think it\u2019s a problem. You still get to choose. It\u2019s just that, one of the choices is to make the thought experiment incoherent.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn20kpaf3udhk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref20kpaf3udhk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Though I actually think that \u201cspace\u201d isn\u2019t the thing here; rather, it\u2019s more about my \u201c<a href=\"https://joecarlsmith.com/2021/01/31/believing-in-things-you-cannot-see\">zone</a>.\u201d</p></div></li></ol>", "user": {"username": "Joe_Carlsmith"}}, {"_id": "pvKTL28diz2CqktjM", "title": "High School Student Opportunities", "postedAt": "2023-02-16T21:51:39.218Z", "htmlBody": "<p>My younger brother is currently in high school, and wants to get into the EA movement. Both of us belong to a low-income family with a minority background in a very low-income country, so there's a lot of limitations to the kinds of opportunities we can access. In his case, he's trying to find remote opportunities, or opportunities that may provide some funding in the case of travel, to get involved with the movement, but the opportunity board doesn't seem to have many that fit.</p><p>A lot of the work that the both of us have done has been quite hyperlocalized - local policy involvement, working with NGO's, local community projects, etc. In my case, I've been fortunate enough to pursue an entrepreneurial career that is rewarding and high-impact, but trying to help my brother get some exposure. He's a smart kid whose grades got him into the country's equivalent to Eton or the Phillips Academies on scholarship, and he's teaching himself to code.</p><p>Any advice on where to look and how to go about this?</p>", "user": {"username": "Ammar Aziz"}}, {"_id": "S2HvxiBHhaGYs2BYs", "title": "Deontic Fictionalism", "postedAt": "2023-02-17T13:44:13.002Z", "htmlBody": "<p>[This post is my attempt to explain why EAs who value the practical protections offered by deontic constraints needn't take that to undermine their belief in consequentialism as a moral theory. &nbsp;People saying \"we need more deontology\" could be clearer about whether they're just talking about endorsing certain commonsense practical norms, or about deontological justifications of those norms. &nbsp;I think EA has always acknowledged the importance of good practical norms, and those who point to widespread utilitarian beliefs as somehow in tension with this are (IMO) making the mistake I diagnose below.]</p><p><strong>Distinguish </strong><i><strong>practical norms</strong></i><strong> from the theoretical question of </strong><i><strong>what justifies them</strong></i><strong>.</strong></p><p>Hypothesis: many are drawn to deontology as a result of conflating these two. People sensibly want to endorse good practical norms like <i>R\u026a\u0262\u029c\u1d1bs</i> (<i>Don\u2019t violate rights, even if you think it\u2019s for the best</i>).<i> </i>And they assume that this commits them to a deontological theory of <i>why</i> that\u2019s a good norm. But that assumption is mistaken. No such theoretical commitment is required.</p><p>After explaining why this is so, I\u2019ll introduce a conceptually simple alternative\u2014deontic fictionalism\u2014for those who find <a href=\"https://www.utilitarianism.net/types-of-utilitarianism/#multi-level-utilitarianism-versus-single-level-utilitarianism\">two-level consequentialism</a> hard to fathom.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F568bcaac-4e0c-431d-a94d-2b54b1386c67_1024x1024.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F568bcaac-4e0c-431d-a94d-2b54b1386c67_1024x1024.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F568bcaac-4e0c-431d-a94d-2b54b1386c67_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F568bcaac-4e0c-431d-a94d-2b54b1386c67_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F568bcaac-4e0c-431d-a94d-2b54b1386c67_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F568bcaac-4e0c-431d-a94d-2b54b1386c67_1024x1024.png 1456w\"></a></p><p>[Image caption: <i>Why not have your cake and eat it too?</i>]</p><h3>Background: Norm content vs justification</h3><p>The distinction between a theory\u2019s <i>criterion </i>(or moral goals) and its recommended <i>decision procedure</i> is central to consequentialism. But others don\u2019t always realize this.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3h677vxx3ms\"><sup><a href=\"#fn3h677vxx3ms\">[1]</a></sup></span>&nbsp;Much confusion in moral theory stems from people conflating the practical question of <i>whether to endorse a norm against X</i> with the theoretical question of <i>whether agents have <strong>non-instrumental</strong> reason to avoid doing X. </i>These are different questions!</p><p>As <a href=\"https://rychappell.substack.com/i/84957236/distinguishing-the-theories\">previously explained</a>:</p><blockquote><p>Utilitarians and moderate deontologists alike agree that (i) you shouldn\u2019t go around carving people up for their organs, and (ii) there are conceivable exceptions to this rule. There\u2019s <strong>no surface-level practical difference</strong> in this respect.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2jvnm14txre\"><sup><a href=\"#fn2jvnm14txre\">[2]</a></sup></span>&nbsp;The difference is not in <i>whether</i> it\u2019s wrong to kill, but <i>why</i>.</p></blockquote><p>Consider again the norm R\u026a\u0262\u029c\u1d1bs (<i>Don\u2019t violate rights, even if you think it\u2019s for the best</i>).</p><p>R\u026a\u0262\u029c\u1d1bs is an excellent practical norm! I endorse it wholeheartedly. (One can imagine exceptions to it, of course, as any moderate deontologist will agree; but that doesn\u2019t undermine its status as a good norm, well worth inculcating in ourselves and others.)</p><p>Now, I think the justification for R\u026a\u0262\u029c\u1d1bs is ultimately <i>instrumental</i>: that <a href=\"https://www.utilitarianism.net/objections-to-utilitarianism/rights/#accommodating-the-intuition\">respecting rights seems likely to result in better actions</a>, yielding better outcomes, than would disregarding them. I think that\u2019s a <a href=\"https://rychappell.substack.com/p/the-normativity-objection-to-deontology\">better justification</a> than what deontologists offer, which is why I reject deontology. The dispute between the theories is not so much about <i>what</i> norms to embrace, but <i>why</i>.</p><p>People sometimes get confused at this point, since R\u026a\u0262\u029c\u1d1bs doesn\u2019t look, on its face, like a \u201cutilitarian\u201d norm or decision procedure. The content of the norm makes no approving references to promoting value. But that\u2019s fine, because moral theories aren\u2019t accounts of what norms to embrace. They\u2019re accounts of <i>fundamental (non-instrumental)</i> <i>reasons</i> (including reasons to embrace some norms over others). Utilitarianism, in particular, fundamentally tells us to <i>promote value</i>. So if embracing R\u026a\u0262\u029c\u1d1bs promotes value, then utilitarianism straightforwardly implies that we should embrace R\u026a\u0262\u029c\u1d1bs.</p><p>Moreover, this isn\u2019t even \u201cself-effacing\u201d (which is something else that people often seem to get confused about).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefknerykpqrfa\"><sup><a href=\"#fnknerykpqrfa\">[3]</a></sup></span>&nbsp;Acting well is compatible with accurately appreciating that the reasons to embrace R\u026a\u0262\u029c\u1d1bs are instrumental rather than non-instrumental.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6w0nnvjscm8\"><sup><a href=\"#fn6w0nnvjscm8\">[4]</a></sup></span>&nbsp;So we can perfectly well maintain a utilitarian perspective on the world, and deliberately follow utilitarian reasons\u2014aiming to maximize expected value\u2014while embracing R\u026a\u0262\u029c\u1d1bs. This is all perfectly coherent, so long as we appreciate that following R\u026a\u0262\u029c\u1d1bs has <a href=\"https://rychappell.substack.com/p/naive-vs-prudent-utilitarianism\">higher expected value than blindly following na\u00efve calculations</a>. Utilitarian reasons then direct us to let R\u026a\u0262\u029c\u1d1bs constrain our actions. (And no, this still <a href=\"https://rychappell.substack.com/i/83889457/this-isnt-rule-utilitarianism\">isn\u2019t rule utilitarianism</a>.)</p><h3>Deontic Fictionalism</h3><p>Some Christian philosophers are religious <a href=\"https://plato.stanford.edu/entries/fictionalism/\">fictionalists</a>: granting that their religion isn\u2019t literally true, but embracing its rituals and practices nonetheless. When they affirm their church\u2019s dogmas, there\u2019s an implicit \u201caccording to the fiction\u201d qualifier attached. They don\u2019t mean this in a dismissive way, though. They think it\u2019s a good and worthwhile pretense to engage in, perhaps for social or emotional reasons.</p><p>It\u2019s interesting to consider whether some who are initially drawn to \u201ccommonsense\u201d deontology might be satisfied with <strong>deontic fictionalism</strong>: granting that the <i>theoretical</i> claims of deontology are misguided, but endorsing the <i>practical</i> norms. If it makes it easier for them to maintain motivation, then engaging in deontological pretense\u2014behaving <i>as if</i> the theory were true\u2014might turn out to be good and worthwhile. That\u2019s something you can do without getting stuck with deontology\u2019s <a href=\"https://rychappell.substack.com/p/a-new-paradox-of-deontology\">theoretical baggage</a>.</p><p>On this picture, one can even use moral language like \u201cright\u201d and \u201cwrong\u201d in a way that tracks deontological verdicts: \u201cIt\u2019s <i>wrong</i> to push the guy in front of the trolley, even if it would save more lives.\u201d But there\u2019s an implicit \u201caccording to the fiction of deontology\u201d qualifier attached. You\u2019re well aware that, in principle, there\u2019s always most reason to do what\u2019s best, and to hope for the best outcome. But you\u2019re now using moral language to do something other than relate the reasons-facts. Maybe you\u2019re instead using it to <i>express support</i> for practical norms like R\u026a\u0262\u029c\u1d1bs. Indeed, given how poorly others mark the distinctions explained in this post, it may even be that this non-literal mode of moral communication is <i>less misleading</i> for many audiences than the alternative of affirming your literal theoretical beliefs (which they might misinterpret as support for <a href=\"https://rychappell.substack.com/p/naive-vs-prudent-utilitarianism\">na\u00efve utilitarian</a> practical norms).</p><h3>Three Options</h3><p>Compare three different ways one might respond to the instrumental reasons to embrace R\u026a\u0262\u029c\u1d1bs and related practical norms:</p><p><strong>(1) Prudent (two-level) consequentialism</strong>, where one accepts R\u026a\u0262\u029c\u1d1bs and related norms as <i>instrumentally good heuristics</i>, while denying both (i) that these norms specify non-instrumental reasons, and (ii) that such non-instrumental reasons are necessary to justify following the norms.</p><p><strong>(2) Deontic fictionalism</strong>, where one accepts R\u026a\u0262\u029c\u1d1bs and related norms due to endorsing (on instrumental grounds) behaving <i>as if</i> deontology<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref84op45b3fpv\"><sup><a href=\"#fn84op45b3fpv\">[5]</a></sup></span>&nbsp;were true, without any commitment to the literal truth of deontological theory.</p><p><strong>(3) Deontology (via self-effacing consequentialism)</strong>, where instrumental reasons motivate one to (somehow) <i>believe </i>that deontology is true\u2014or to convince others to believe it.</p><p>I personally think #1 is the ideal way to go. But if some find it difficult to grasp, option #2 may prove a conceptually simpler alternative that still maintains epistemic integrity (for those who agree that the theoretical case for consequentialism is strong).</p><p>Given these alternatives, it doesn\u2019t seem plausible to me that there\u2019s any practical reason to prefer #3. Whenever people suggest practical reasons to embrace deontological moral theories, one may counter with deontic fictionalism instead. (And when they\u2019re ready to take off the training wheels, they can shift to prudent consequentialism: dropping the pretense entirely while keeping on following good norms like R\u026a\u0262\u029c\u1d1bs, just for the actually-right reasons.)</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3h677vxx3ms\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3h677vxx3ms\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See, e.g., post-FTX anti-utilitarian takes on philosophy twitter, as represented in meme form <a href=\"https://twitter.com/RYChappell/status/1592082825364361217\">here</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2jvnm14txre\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2jvnm14txre\">^</a></strong></sup></span><div class=\"footnote-content\"><p>One can carefully engineer hypothetical cases to pry the two views apart. But even then, I argued, utilitarians will typically see grounds to <i>criticize the agent</i> (e.g. for recklessness) even if they approve of the act in retrospect, <i>given that it turned out for the best</i>. And, seriously, what kind of person doesn\u2019t approve of things turning out for the best? <a href=\"https://rychappell.substack.com/p/the-normativity-objection-to-deontology\">Not a good one</a>, I'd suggest.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnknerykpqrfa\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefknerykpqrfa\">^</a></strong></sup></span><div class=\"footnote-content\"><p>It\u2019s always <i>possible</i> for a decent moral view to be self-effacing, because having true beliefs isn\u2019t the most important thing in the world. If an evil demon said \u201cAgree to moral brainwashing or I\u2019ll torture everyone for eternity,\u201d then you\u2019d obviously better agree to the brainwashing. But that\u2019s not what\u2019s going on here. Absent evil demons, we don\u2019t need false moral beliefs.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6w0nnvjscm8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6w0nnvjscm8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Sometimes people say things which seem to imply that instrumental reasons don\u2019t count. (\u201cUtilitarians have no <i>in principle</i> objection to slavery!\u201d What, you mean the suffering of the slaves is not enough? \u201cBut it could <i>in principle</i> be outweighed by other considerations!\u201d That\u2019s true of moderate deontologists, too. \u201cWell, okay, but it just makes all the difference if some of the outweighed reasons were non-instrumental\u2026\u201d Why? I\u2019m starting to worry that you\u2019re really not giving enough weight to the suffering of the slaves\u2026) So it\u2019s maybe worth being explicit at this point that all this talk of \u201cinstrumental reasons\u201d is shorthand for <a href=\"https://rychappell.substack.com/p/the-normativity-objection-to-deontology\">the most obviously important reasons that there are</a>, namely those to <i>save and improve lives</i>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn84op45b3fpv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref84op45b3fpv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Ideally, in a more <a href=\"https://rychappell.substack.com/p/beneficentrism\">beneficentric</a> form than one usually finds in the wild.</p></div></li></ol>", "user": {"username": "RYC"}}, {"_id": "bBJmZp3oQhF6PDQjw", "title": "Why EA Will Be Anti-Woke or Die", "postedAt": "2023-02-16T19:17:24.413Z", "htmlBody": "<p>I strongly believe this article touches upon the most important question in the formation and continuation of Effective Altruism and should be discussed here. I think it stands for itself, provides abundant examples, and is well-reasoned in highlighting what I view are current and future limitations to EA as applied rationality. Hanania, as always, is disagreeable and phrases issues in a provocative manner, but is as evidence-based as any post on this forum. I will highlight some key passages that I found most valuable as a starting point for discussion:</p><blockquote><p>In the end, EA will need something like the Darwin-Jesus synthesis of American conservatism. In this case it would of course be much more Darwin than Jesus, and find Aella more a source of amusement or scientific curiosity than a sign of the apocalypse. But taking Darwin too seriously puts you on a collision course with the left, and not just because it prevents you from achieving gender parity in leadership roles. Be the kind of movement that takes an evolutionary view of sex differences, and you\u2019ll attract individuals able to think freely about the causes of other kinds of disparities. Group differences in IQ is right around the corner, and if you\u2019re going to maintain any kind of commitment to rationalism you\u2019re going to have to either stop yourself before getting on that train or take it to its logical destination.</p></blockquote><p>This was obviously highlighted by the Bostrom scandal, which made me very aware that in EA, we still have sacred cows of our own, and many are unable to distance themselves from their own sacred beliefs and acknowledge evidence on its face. &nbsp;</p><blockquote><p>EA has thus far avoided falling into either category on account of it being new and marginal. But it\u2019s now entering the real world. One path it can take is to be folded into the Democratic coalition. It\u2019ll have to temper its rougher edges, which means purging individuals for magic words, knowing when not to take an argument to its logical conclusion, compromising on free speech, more peer review and fewer disagreeable autodidacts, and being unwilling to engage with other individuals and communities that are too non-conformist to avoid having any heretical strains. A woke EA means noticing that the FDA might move too slow on approving certain kinds of drugs, while ignoring that the fields of biology and medicine are in the name of sensitivity being transformed to increasingly select for a kind of <a href=\"https://twitter.com/realchrisrufo/status/1625290540802781184\"><u>cultish conformity,</u></a> pushing <a href=\"https://www.thefp.com/p/he-was-a-world-renowned-cancer-researcher?s=w\"><u>brilliant and independent thinkers</u></a> into other kinds of work.</p></blockquote><p>This has been touched on recently by Tyler Cowen<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnjju768zy9c\"><sup><a href=\"#fnnjju768zy9c\">[1]</a></sup></span>&nbsp;and a variety of forum posts. EA is best able to fulfill its mission of improving well-being when it resists these polite temptations.</p><blockquote><p>We already have a movement that is able to reason carefully, or at least have a rational discussion, on most things while being beyond hopeless on anything related to identity issues. It\u2019s called liberalism! Accept its views on the need for diversity and the causes of group disparities, and you\u2019re just debating technocratic questions about the best way to address global poverty. Which is fine, but makes EA a movement of extremely limited ambitions.</p></blockquote><blockquote><p>Putting aside political realities, an EA freed from the shackles of wokeness will be better able to live up to its highest ideals by taking seriously important threats to human well-being that the movement currently ignores for purely political reasons. What does it mean that birthrates are decreasing at the same time there is a negative relationship between IQ and fertility across much of the developed world? And, speaking from a strictly utilitarian perspective, why exactly do we <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3969807/\"><u>let a tiny minority of violent criminals</u></a> make large swaths of what are potentially some of our most economically productive urban areas uninhabitable, instead of simply getting rid of them in full confidence that we\u2019re doing the greatest good for the largest number of people? These are the kinds of questions an honest movement either has to ignore or become obsessed with.</p></blockquote><p>Hesitance on gene-editing, crime-as-a-cause-area<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9qlwuqgugac\"><sup><a href=\"#fn9qlwuqgugac\">[2]</a></sup></span>, and yes, so called \"HBD\" highlight this. EA should be willing to explore all potentially fruitful avenues of mission fulfillment without regard to taboo. I think this topic is well explored in this Scott Alexander excerpt on Jewish achievement<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7m9ua2fw5qv\"><sup><a href=\"#fn7m9ua2fw5qv\">[3]</a></sup></span></p><blockquote><p>People act like genetic engineering would be some sort of horrifying mad science project to create freakish mutant supermen who can shoot acid out of their eyes. But I would be pretty happy if it could just make everyone do as well as Ashkenazi Jews. The Ashkenazim I know are mostly well-off, well-educated, and live decent lives. If genetic engineering could give those advantages to everyone, it would easily qualify as the most important piece of social progress in history, even <i>before</i> we started giving people the ability to shoot acid out of their eyes.</p><p>But maybe the Jewish advantage will turn out to be cultural. If that's true, I think it would be even more interesting - it would mean there's some set of beliefs and norms which can double your income and dectuple your chance of making an important scientific discovery. I was raised by Ashkenazi Jews and I cannot even begin to imagine what those beliefs would be - as far as I can tell, the cultural payload I received as a child was totally normal, just a completely average American worldview. But if I'm wrong, figuring out exactly what was the active ingredient of that payload would be the most important task in social science, far outstripping lesser problems like crime or education or welfare (nobody expects good policy in these areas to double average income!). Far from trying to make this sound \"less interesting\", we should be recognizing it as one of the most interesting (and potentially socially useful) problems in the world.</p></blockquote><p>EA's existing taboos are preventing it from answering questions like these, and as new taboos are accepted, the effectiveness of the movement will continue to wain.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnjju768zy9c\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnjju768zy9c\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://forum.effectivealtruism.org/posts/NdZPQxc74zNdg8Mvm/tyler-cowen-on-effective-altruism-december-2022</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9qlwuqgugac\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9qlwuqgugac\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://forum.effectivealtruism.org/posts/cPDptuFTiCLr8XXkL/cause-exploration-prizes-crime-reduction</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7m9ua2fw5qv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7m9ua2fw5qv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>https://astralcodexten.substack.com/p/contra-smith-on-jewish-selective</p></div></li></ol>", "user": {"username": "Anon Rationalist"}}, {"_id": "99tnp7Jpts7Gssq7J", "title": "Transitioning to an advisory role", "postedAt": "2023-02-16T18:11:37.885Z", "htmlBody": "<p>I\u2019m writing to announce that I\u2019ve resigned from my role as CEA\u2019s Executive Director, and will be transitioning to an advisory role.</p><p>Basically, my mental health has been bad for the last 3 months. Starting in November, my role changed from one that I love - building a team and a product, building close working relationships with people, executing - to one that I find really stressful: dealing with media attention, stakeholders, and lawyers at long unpredictable hours and wrestling with strategic uncertainty.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe8u5b4jcbhm\"><sup><a href=\"#fne8u5b4jcbhm\">[1]</a></sup></span>&nbsp;I think I\u2019m also not so good at the latter sort of work, relative to the former.</p><p>I've been getting lots of advice, therapy, and support, but recently I've been close to a crisis \u2013 struggling to get out of bed, feeling terror at the idea of sitting at my desk. I really wish that I were strong enough to keep doing this job, especially right now \u2013 I care so much about CEA\u2019s work to help more people tackle the important problems we face, and I care deeply about the team we\u2019ve built.&nbsp;</p><p>But I\u2019m just not able to keep going in my current role, and I don't think that pretending to be stronger or struggling on will be good for CEA or for me, because I\u2019m not able to perform as well as I would like and there\u2019s a risk that I\u2019ll burn out with no handover. So I think it\u2019s best to move into an advisory role and allow someone else to direct CEA.</p><p>The boards of Effective Ventures UK and Effective Ventures US, which govern CEA, will appoint an interim Executive Director soon. Once they\u2019re appointed I plan to continue advising and working with them and the CEA team to ensure a smooth transition and help find a new permanent ED. I hope that moving from an executive to advisory role will help alleviate some of the pressure and allow me to contribute more productively to our shared work going forward.</p><p>For a while now I've been trying to build up the leadership team as the body running CEA, with me as one member. I think that the leadership team is very strong: people disagree with each other directly but with care, have complementary strengths, and show strong leadership for their own programs. I think that they will be able to do a great job leading CEA together with the interim ED and the new permanent ED.</p><p>Of course, FTX and subsequent events have highlighted some important issues in EA. I\u2019ve been working with the team to reflect on how this might impact our work and necessitate changes, and I hope that they\u2019ll be able to share more on these conversations and plans in the future. Although I\u2019m very sad not to be able to see through that work in my current role with CEA, I think that the work we\u2019ve done so far will set the new leadership team up well. I also plan to continue to reflect, will discuss my thinking with new leadership, and may publish some of my personal reflections.</p><p>Despite the setbacks of these last few months, I'm very proud of what we've achieved together over the last four years. Compared to 2019, the number of new connections we\u2019re making at events is 5x higher, and people are spending 10x time engaging with the Forum (which also has a lot more interesting content). Overall, I think that we\u2019ve helped hundreds of people to reflect on how they can best contribute to making the world a better place, and begin to work on these critical problems.</p><p>I\u2019m also incredibly grateful to have been a part of this team: CEA staff are incredibly talented, caring, and dedicated. I\u2019ve loved to be a part of a culture where staff are valued and empowered to do things.</p><p>I look forward to seeing the impact which they continue to have over the coming months&nbsp;and years under new leadership.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne8u5b4jcbhm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe8u5b4jcbhm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This has been true for many people, especially EV board members and some staff who have jumped in to help. I\u2019ve got a lot of admiration and gratitude for the work they\u2019ve done, and I regret that I don\u2019t have their stamina on this particular type of work right now.</p></div></li></ol>", "user": {"username": "Maxdalton"}}, {"_id": "vPHMdeDn5jNzGv8gK", "title": "Project for Awesome 2023: Vote for videos of EA charities!", "postedAt": "2023-02-16T18:07:53.603Z", "htmlBody": "<p><a href=\"http://www.projectforawesome.com/\">Project for Awesome</a> (P4A) is a yearly charity video contest running this weekend in 2023. <strong>Voting will start Friday, February 17th, 12:00pm EST</strong> and is <strong>open until February 19th, 11:59am EST</strong>. The charities with the most votes, the total across all their videos, win money. In the last years, this was between $14,000 and $32,000 per charity.&nbsp;</p><p>This is a good opportunity to raise money for EA charities with just a few clicks (~5 minutes). Please <strong>ask your friends</strong> and <strong>EA group members</strong> to vote for ALL the videos for EA charities! A sample text message and a voting instruction is below.</p><p><i>Sample text message:</i> Hey! Not sure if you know, but every year Hank and John Green organize the Project For Awesome, which raises money for charities. All you have to do is click \u201cVote\u201d on a bunch of videos and you could potentially help thousands of dollars go to highly effective charities. Would you be willing to help out?</p><p><i>If they reply yes:</i> Great! Here are the videos of the charities we\u2019re promoting. You can vote for all of the videos. Without watching videos, it will just take a few minutes. (insert the instructions or just the links)</p><p><strong>Voting instruction with links:&nbsp;</strong></p><p>1. Invite your friends to vote, too!</p><p>2. Open one of the following links, then open one video first and do the CAPTCHA before opening the other videos of that charity in new tabs. Vote for ALL videos of that charity.</p><p>3. Repeat step 2 for all charities listed below. Vote for ALL videos for each of these EA charities. You can see that you voted for a video by the grayed out \"Voted\" button. In the end, P4A will sum up all votes for all videos of one charity.</p><p>In total there are several videos for our supported EA charities but it only takes a few clicks (if you do not want to watch the videos) and it's really worth it.</p><p>Supported EA charities:<br>Animal Advocacy Africa: <a href=\"https://projectforawesome.com/?charity=7DyRrCBP\">https://projectforawesome.com/?charity=7DyRrCBP</a><br>Animal Ethics: <a href=\"https://projectforawesome.com/?charity=t53UycVd\">https://projectforawesome.com/?charity=t53UycVd</a><br>Animal Society: <a href=\"https://projectforawesome.com/?charity=HiUMCsSk\">https://projectforawesome.com/?charity=HiUMCsSk</a><br>GiveWell Top Charities Fund: <a href=\"https://projectforawesome.com/?charity=JEarPXm8\">https://projectforawesome.com/?charity=JEarPXm8</a><br>Good Food Institute: <a href=\"https://projectforawesome.com/?charity=StjLqUYd\">https://projectforawesome.com/?charity=StjLqUYd</a><br>The Humane League: <a href=\"https://projectforawesome.com/?charity=7MakVrHV\">https://projectforawesome.com/?charity=7MakVrHV</a><br>Wild Animal Initiative: <a href=\"https://projectforawesome.com/?charity=J1wvVsnX\">https://projectforawesome.com/?charity=J1wvVsnX</a></p><p>Other EA(-related) charities:<br>International Campaign to Abolish Nuclear Weapons (ICAN): <a href=\"https://www.projectforawesome.com/?charity=yDkfNPdY\">https://www.projectforawesome.com/?charity=yDkfNPdY</a><br>Against Malaria Foundation: <a href=\"https://projectforawesome.com/?charity=UnOkIdYE\">https://projectforawesome.com/?charity=UnOkIdYE</a><br>Clean Air Task Force: <a href=\"https://projectforawesome.com/?charity=haCUpSAq\">https://projectforawesome.com/?charity=haCUpSAq</a><br>GiveDirectly: <a href=\"https://projectforawesome.com/?charity=L11RjVGo\">https://projectforawesome.com/?charity=L11RjVGo</a><br>No Means No Worldwide: <a href=\"https://projectforawesome.com/?charity=5TLEaViE\">https://projectforawesome.com/?charity=5TLEaViE</a><br>The Global Fund: <a href=\"https://projectforawesome.com/?charity=AVKb9jSe\">https://projectforawesome.com/?charity=AVKb9jSe</a></p><p>&nbsp;</p><p>Please also join our Facebook group, <a href=\"https://www.facebook.com/groups/1666606496928923\">EA Project 4 Awesome 2023</a>, and our <a href=\"https://www.facebook.com/events/744242507421669\">Facebook event for this year\u2019s voting</a>!</p><p>Thank you very much!</p>", "user": {"username": "EA_ProjectForAwesome"}}, {"_id": "65zFWdnKwckyk9yr5", "title": "What If 99% of Humanity Vanished? (A Happier World video)", "postedAt": "2023-02-16T17:10:15.685Z", "htmlBody": "<p>A Happier World just published a video on collapse, broadly summarizing the chapter from Will MacAskill's book What We Owe The Future. The book doesn't mention the bronze age collapse, but we thought it was important to include as well.</p><p>Would love to hear what you think. Feel free to use it for your EA events!</p><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=gPJdFOXO1CQ\"><div><iframe src=\"https://www.youtube.com/embed/gPJdFOXO1CQ\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>Thanks to <a href=\"https://forum.effectivealtruism.org/users/sarah-emminghaus-1\">Sarah Emminghaus</a> for helping write the script!</p><h1><strong>Transcript</strong></h1><p><i>Sources are marked with an asterisk.</i>&nbsp;<i>Text might differ slightly in wording from the final video.</i></p><h2><strong>Historical collapse events</strong></h2><p>In the fourteenth century, the black death killed between one-quarter and one half of all Europeans. The Middle East was also affected. Around a tenth of the global population died of the disease spread by infected fleas transported across the world by rats on trade ships. But still: That did little to negatively influence technological and economic development in Europe. Population size in Europe returned to pre-pandemic levels two centuries after the black death.</p><p>Humanity has survived a few really dangerous and grim events like these.</p><p>A more recent example is how the city of Hiroshima was rebuilt after the atomic bombing in 1945. Around 140 000 people died, ninety percent of buildings were at least partially destroyed or reduced to rubble. Only a few days after the catastrophe however, the nearby bank reopened, there was a limited rail service running and water pumps were working again. The population of the city returned to predestruction levels within only a decade. Now Hiroshima is a thriving city of 1.2 million people.<a href=\"https://nbakki.hatenablog.com/entry/Changes_in_Population_of_Hiroshima_City_1920-2014\"><u>*</u></a></p><p>Two other examples are the collapse of Rome and the Bronze Age collapse. Both brought down impressive civilizations that enjoyed technological and economic progress and had forms of international trade.</p><p>The Bronze Age collapse happened between 1200 and 1150 BC, when the Mycenaean Greece and Hittite civilizations fell and the Egyptian and Assyrian civilizations severely weakened. To this day, historians aren\u2019t completely sure why the bronze age collapse happened.</p><p>After Rome being the first city to surpass a million inhabitants and being the seat of the Western Roman Empire for centuries, the city declined dramatically in the fifth century. A few decades after that, the whole empire collapsed. It took 1400 years until the 1930s for Rome to surpass its peak population.</p><p>Sounds quite bad. But really, for local civilizations it can be said that it\u2019s rather the rule than an exception to collapse.</p><p>But can the entire human civilization collapse? By civilizational collapse we mean an event in which society loses the ability to create most industrial and postindustrial technology. This is probably likelier than full extinction and would still be really horrible.</p><h2><strong>Could we collapse now?</strong></h2><p>It\u2019s difficult to predict how likely it is that civilization as a whole would collapse. So far, luckily!, there are no historical examples of collapse events that killed more than 20 percent of the global population.&nbsp;</p><p>Modern civilization is very different from the historical civilizations that collapsed. In some ways we might be able to better handle risks to our civilization, but in other ways the risks might be higher. In our previous video we talked about existential threats, some of which historical civilizations didn\u2019t have to worry about, like anthropogenic climate change, global pandemics and nuclear war. Even if these don\u2019t make humanity go extinct, they could still collapse human civilization.</p><p>But let\u2019s try and think about what would happen if for example an all out nuclear war would happen. The direct death toll alone could amount to tens to hundreds of millions of people. Or maybe even billions.</p><p>If, in an absolute worst case scenario, 99 percent of the world population would die, that would leave 80 million people alive. Meaning in terms of population we would be back to 2500 BC.</p><p>But would this lead to a collapse?</p><p>Probably not! Parts of our physical infrastructure like machines, tools and buildings would still be there and could be used afterwards, which already puts us in a much better position than 2500 BC. Also the remaining 80 million people could access all of the knowledge humanity has assembled. There\u2019s also a decent chance that among the survivors some have critical jobs like airplane engineers or organic chemists.</p><p>Also it\u2019s pretty likely there would be some people left with knowledge about agriculture that would help feed the population.</p><p>Another crucial question is: Would we re-industrialize? We think so, yes!&nbsp;</p><p>Some tools and machines would probably survive the catastrophe and could be used to reverse engineer. But renewable energy might be difficult to recreate at first, which means we\u2019d probably have to rely on fossil fuels like coal first. Currently however, easily accessible coal is disappearing rapidly. If coal becomes hard to access, a population of 80 million will have an incredibly hard time industrializing. This means we should shut down coal plants as quickly as possible. I mean, we should already do so anyway for our climate, so it\u2019s a great extra reason to do so.</p><p>Overall, it seems likely that humanity will get back on its feet even if 99% of us vanish. Still, it could take centuries to get back to where we are today. And in any case, such an event would be horrible and we should avoid it at all costs.</p><h2><strong>Outro</strong></h2><p>We just summarized a chapter from Oxford philosopher Will MacAskill\u2019s book called What We Owe The Future. The book makes the case for caring about our long-term future and explores what we can do. We\u2019re making a video series summarizing its most important points. We\u2019re visiting Chinese history, the islamic golden age, the possible end of humanity and more. So subscribe and ring that notification bell to get notified when more episodes come out! Thanks for watching.</p>", "user": {"username": "Jeroen_W"}}, {"_id": "aNttGqjyZmGEnhSjP", "title": "We are incredibly homogenous", "postedAt": "2023-02-16T16:05:34.502Z", "htmlBody": "<h1>Preamble</h1><p>This is an extract from a post called \"<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1\">Doing EA Better</a>\", which argued that EA's new-found power and influence obligates us to solve our movement's significant problems with respect to epistemics, rigour, expertise, governance, and power.</p><p>We are splitting DEAB up into a sequence to facilitate object-level discussion.</p><p>Each post will include the relevant parts of the list of suggested reforms. There isn't a perfect correspondence between the subheadings of the post and the reforms list, so not all reforms listed will be 100% relevant to the section in question.</p><p>Finally, we have tried (imperfectly) to be reasonably precise in our wording, and we ask that before criticising an argument of ours, commenters ensure that it is an argument that we are in fact making.</p><h1>Main</h1><p><strong>Summary:</strong> Diverse communities are typically much better at accurately analysing the world and solving problems, but EA is extremely homogenous along essentially all dimensions. EA institutions and norms actively and strongly select <i>against</i> diversity. This provides short-term efficiency at the expense of long-term epistemic health.</p><p>The EA community is notoriously <a href=\"https://forum.effectivealtruism.org/posts/DxfpGi9hwvwLCf5iQ/objections-to-value-alignment-between-effective-altruists#Homogeneity\">homogenous</a>, and the \u201caverage EA\u201d is extremely easy to imagine: he is a white male<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-9\"><sup>[9]</sup></a> in his twenties or thirties from an upper-middle class family in North America or Western Europe. He is ethically utilitarian and politically centrist; an atheist, but culturally protestant. He studied analytic philosophy, mathematics, computer science, or economics at an elite university in the US or UK. He is neurodivergent. He thinks space is really cool. He highly values intelligence, and believes that his own is significantly above average. He hung around LessWrong for a while as a teenager, and now wears EA-branded shirts and hoodies, drinks Huel, and consumes a narrow range of blogs, podcasts, and vegan ready-meals. He moves in particular ways, talks in particular ways, and thinks in particular ways. Let us name him \u201cSam\u201d, if only because there\u2019s a solid chance he already is.<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-10\"><sup>[10]</sup></a></p><p>Even leaving aside the <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3995225\">ethical and political issues</a> surrounding major decisions about humanity\u2019s future being made by such a small and homogenous group of people, especially given the fact that the poor of the Global South will suffer most in almost any conceivable catastrophe, having the EA community overwhelmingly populated by Sams or near-Sams is decidedly Not Good for our collective epistemic health.</p><p>As <a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#Epistemic_health_is_a_community_issue\">noted</a> above, <a href=\"https://www.goodreads.com/book/show/62228295-joined-up-thinking\">diversity is one of the main predictors of the collective intelligence of a group</a>. If EA wants optimise its ability to solve big, complex problems like the ones we focus on, we need people with different disciplinary backgrounds<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-11\"><sup>[11]</sup></a>, different kinds of professional training, different kinds of talent/intelligence<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-12\"><sup>[12]</sup></a>, different ethical and political viewpoints, different temperaments, and different life experiences. That\u2019s where new ideas tend to come from.<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-13\"><sup>[13]</sup></a></p><p>Worryingly, EA institutions seem to select <i>against</i> diversity. Hiring and funding practices often select for highly value-aligned yet inexperienced individuals over outgroup experts, university recruitment drives are deliberately targeted at the Sam Demographic (at least by proxy) and EA organisations are advised to maintain a high level of internal value-alignment to maximise operational efficiency. The 80,000 Hours website seems purpose-written for Sam, and is noticeably uninterested in people with humanities or social sciences backgrounds,<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-14\"><sup>[14]</sup></a> or those without university education. Unconscious bias is also likely to play a role here \u2013 it does everywhere else.</p><p>The vast majority of EAs will, when asked, say that we should have a more diverse community, but in that case, why are only a very narrow spectrum of people given access to EA funding or EA platforms? There are exceptions, of course, but the trend is clear.</p><p>It\u2019s worth mentioning that <a href=\"https://library.oapen.org/handle/20.500.12657/42728\">senior EAs</a> have done some interesting work on moral uncertainty and value-pluralism, and we think several of their recommendations are well-taken. However, the focus is firmly on individual rather than collective factors. The point remains that one cannot substitute a philosophically diverse community for an overwhelmingly utilitarian one where everyone individually tries to keep all possible viewpoints in mind. None of us are so rational as to obviate true diversity through our own thoughts.<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-15\"><sup>[15]</sup></a></p><h1>Suggested reforms</h1><p>Below, we have a preliminary non-exhaustive list of relevant suggestions for structural and cultural reform that we think may be a good idea and should certainly be discussed further.</p><p>It is of course plausible that some of them would not work; if you think so for a particular reform, please explain why! We would like input from a range of people, and we certainly do not claim to have all the answers!</p><p>In fact, we believe it important to open up a conversation about plausible reforms not because we have all the answers, but precisely because we don\u2019t.</p><p><i>Italics</i> indicates reforms strongly inspired by or outright stolen from Zoe Cremer\u2019s <a href=\"https://docs.google.com/document/d/1Y9opezUk9_JNQBYCAmHoERiqlaf2HmashQQ_ydGwyRY/edit\">list</a> of structural reform ideas. Some are edited or merely related to her ideas; they should not be taken to represent Zoe\u2019s views.</p><p>Asterisks (*) indicate that we are less sure about a suggestion, but sure enough that we think they are worth considering seriously, e.g. through deliberation or research. Otherwise, we have been developing or advocating for most of these reforms for a long time and have a reasonable degree of confidence that they should be implemented in some form or another.</p><p>Timelines are suggested to ensure that reforms can become concrete. If stated, they are rough estimates, and if there are structural barriers to a particular reform being implemented within the timespan we suggest, let us know!</p><p>Categorisations are somewhat arbitrary, we just needed to break up the text for ease of reading.</p><h2>Critique</h2><h3>Red Teams</h3><ul><li>Red teams should be paid, composed of people with a variety of views, and former- or non-EAs should be actively recruited for red-teaming<ul><li>Interesting critiques often come from dissidents/exiles who left EA in disappointment or were pushed out due to their heterodox/\u201dheretical\u201d views (yes, this category includes a couple of us)</li></ul></li><li>The judging panels of criticism contests should include people with a wide variety of views, including heterodox/\u201dheretical\u201d views</li></ul><h2>Epistemics</h2><h3>General</h3><ul><li>EA should study social epistemics and collective intelligence more, and epistemic efforts should focus on creating good community epistemics rather than merely good individual epistemics<ul><li>As a preliminary programme, we should explore how to increase EA\u2019s overall levels of diversity, egalitarianism, and openness</li></ul></li><li>EAs should practise epistemic modesty<ul><li>We should read much more, and more widely, including authors who have no association with (or even open opposition to) the EA community</li><li>We should avoid assuming that EA/Rationalist ways of thinking are the only or best ways</li><li>We should actively seek out not only critiques of EA, but critiques of and alternatives to the underlying premises/assumptions/characteristics of EA (high modernism, elite philanthropy, quasi-positivism, etc.)</li><li>We should stop assuming that we are smarter than everybody else</li></ul></li><li>EAs should make a point of engaging with and listening to EAs from underrepresented disciplines and backgrounds, as well as those with heterodox/\u201cheretical\u201d views</li></ul><h3>Ways of Knowing</h3><ul><li>EAs should consider how our shared modes of thought may subconsciously affect our views of the world \u2013 what blindspots and biases might we have created for ourselves?</li><li>EAs should increase their awareness of their own <a href=\"https://en.wikipedia.org/wiki/Standpoint_theory\">positionality</a> and subjectivity, and pay far more attention to e.g. postcolonial critiques of western academia<ul><li>History is <a href=\"https://www.youtube.com/watch?v=Xe3tunGi4To\">full</a> of people who thought they were very rational saying very silly and/or unpleasant things: let\u2019s make sure that doesn\u2019t include us</li></ul></li><li>EAs should study other ways of knowing, taking inspiration from a range of academic and professional communities as well as indigenous worldviews</li></ul><h3>Diversity</h3><ul><li>EA institutions should select for diversity<ul><li>With respect to:<ul><li>Hiring (especially grantmakers and other positions of power)</li><li>Funding sources and recipients</li><li>Community outreach/recruitment</li></ul></li><li>Along lines of:<ul><li>Academic discipline</li><li>Educational &amp; professional background</li><li>Personal background (class, race, nationality, gender, etc.)</li><li>Philosophical and political beliefs</li></ul></li><li>Naturally, this should not be unlimited \u2013 some degree of mutual similarity of beliefs is needed for people to work together \u2013 but we do not appear to be in any immediate danger of becoming too diverse</li></ul></li><li>Previous EA involvement should not be a necessary condition to apply for specific roles, and the job postings should not assume that all applicants will identify with the label \u201cEA\u201d</li><li>EA institutions should hire more people who have had little to no involvement with the EA community providing that they care about doing the most good</li><li>People with heterodox/\u201cheretical\u201d views should be actively selected for when hiring to ensure that teams include people able to play \u201cdevil\u2019s advocate\u201d authentically, reducing the need to rely on highly orthodox people accurately steel-manning alternative points of view</li><li>Community-building efforts should be broadened, e.g. involving a wider range of universities, and group funding should be less contingent on the perceived prestige of the university in question and more focused on the quality of the proposal being made</li><li>EA institutions and community-builders should promote diversity and inclusion more, including funding projects targeted at traditionally underrepresented groups</li><li>A greater range of people should be invited to EA events and retreats, rather than limiting e.g. key networking events to similar groups of people each time</li><li><i>There should be a survey on cognitive/intellectual diversity within EA</i></li><li>EAs should not make EA the centre of their lives, and should actively build social networks and career capital outside of EA</li></ul><h2>Expertise &amp; Rigour</h2><h3>Reading</h3><ul><li>Insofar as a \u201ccanon\u201d is created, it should be of the best-quality works on a given topic, not the best works by (orthodox) EAs about (orthodox) EA approaches to the topic<ul><li>Reading lists, fellowship curricula, and bibliographies should be radically diversified</li><li>We should search everywhere for pertinent content, not just the EA Forum, LessWrong, and the websites of EA orgs</li><li>We should not be afraid of consulting outside experts, both to improve content/framing and to discover blind-spots</li></ul></li></ul><h3>Experts &amp; Expertise</h3><ul><li>EAs should deliberately broaden their social/professional circles to include external domain-experts with differing views</li><li>When hiring for research roles at medium to high levels, EA institutions should select in favour of domain-experts, even when that means passing over a highly \u201cvalue-aligned\u201d or prominent EA</li></ul><h2>Funding &amp; Employment</h2><h3>Grantmaking</h3><ul><li>Grantmakers should be radically diversified to incorporate EAs with a much wider variety of views, including those with heterodox/\u201dheretical\u201d views</li></ul><h2>Transparency &amp; Ethics</h2><h3>Moral Uncertainty</h3><ul><li>EAs should practise moral uncertainty/pluralism as well as talking about it</li><li>EAs who advocate using ethical safeguards such as \u201cintegrity\u201d and \u201ccommon-sense morality\u201d should publicly specify what they mean by this, how it should be operationalised, and where the boundaries lie in their view</li><li>EA institutions that subscribe to moral uncertainty/pluralism should publish their policies for weighting different ethical views within 12 months</li></ul>", "user": {"username": "ConcernedEAs"}}, {"_id": "4mL69dno6FsYbjyx3", "title": "Scarlet Spark Office Hours For Animal -Loving Organizations and Leaders", "postedAt": "2023-02-16T16:27:27.109Z", "htmlBody": "<p>We\u2019re inviting leaders of all levels into our cozy Zoom office. Bring your most pressing leadership questions, and get real-time input from Scarlet Spark advisors and your peers at other animal-loving companies. You\u2019ll leave with greater clarity, confidence, and new relationships within the community.</p><p>\u200bIf you already know the issue you want to discuss you can submit your questions ahead of time.</p><p>For example:</p><ul><li>How do I handle this difficult conversation?</li><li>Can you give me feedback on my company-wide announcement?</li><li>What do I do about an employee who\u2019s been underperforming?</li><li>How do we design an inclusive and accessible hiring process?</li><li>Why is my team constantly miscommunicating?</li></ul><p>&nbsp;</p><p>Scarlet Spark is a nonprofit that accelerates the speed-to-mission of organizations that help animals.</p><p>We improve employee and volunteer:</p><ul><li>Recruitment</li><li>Retention</li><li>Engagement</li><li>Inclusion</li><li>Effectiveness</li></ul><p>We provide consulting, coaching, and training to organizations that help animals, including advocacies and companies that create animal product alternatives.</p>", "user": {"username": "Sharleen "}}, {"_id": "K9GdCuiz5tanoiDKN", "title": "Why should ethical anti-realists do ethics?", "postedAt": "2023-02-16T16:27:02.008Z", "htmlBody": "<p>(Cross-posted from <a href=\"https://joecarlsmith.com/2023/02/16/why-should-ethical-anti-realists-do-ethics\">my website</a>. Podcast version <a href=\"https://joecarlsmithaudio.buzzsprout.com/2034731/12264143-why-should-ethical-anti-realists-do-ethics\">here</a>, or search \"Joe Carlsmith Audio\" on your podcast app.)</p><blockquote><p><i>\"What was it then? What did it mean? Could things thrust their hands up and grip one? Could the blade cut; the fist grasp?\"</i></p><p>- <a href=\"https://www.goodreads.com/quotes/708295-what-was-it-then-what-did-it-mean-could-things\"><i>Virginia Woolf</i></a></p></blockquote><h2>1. Introduction</h2><p>Ethical philosophy often tries to systematize. That is, it seeks general principles that will explain, unify, and revise our more particular intuitions. And sometimes, this can lead to strange and uncomfortable places.</p><p>So why do it? If you believe in an objective ethical truth, you might talk about getting closer to that truth. But suppose that you don\u2019t. Suppose you think that you\u2019re \u201cfree to do whatever you want.\u201d In that case, if \u201csystematizing\u201d starts getting tough and uncomfortable, why not just \u2026 stop? After all, you can always just do whatever\u2019s most intuitive or common-sensical in a given case \u2013 and often, this is the choice the \u201cethics game\u201d was trying so hard to validate, anyway. So why play?</p><p>I think it\u2019s a reasonable question. And I\u2019ve found it showing up in my life in various ways. So I wrote a set of two essays explaining part of my current take.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzubgdpf7tg\"><sup><a href=\"#fnzubgdpf7tg\">[1]</a></sup></span>&nbsp;This is the first essay. Here I describe the question in more detail, give some examples of where it shows up, and describe my dissatisfaction with two places anti-realists often look for answers, namely:</p><ul><li>some sort of brute preference for your values/policy having various structural properties (consistency, coherence, etc), and</li><li>avoiding money-pumps (i.e., sequences of actions that take you back to where you started, but with less money)</li></ul><p>In the <a href=\"https://forum.effectivealtruism.org/posts/djByAbm6ptkkmS9RS/seeing-more-whole\">second essay</a>, I try to give a more positive account. &nbsp;</p><p><i>Thanks to Ketan Ramakrishnan, Katja Grace, Nick Beckstead, and Jacob Trefethen for discussion.</i></p><h2>2. The problem</h2><p>There\u2019s some sort of project that ethical philosophy represents. What is it?</p><h3>2.1 Map-making with no territory</h3><p>According to normative realists, it\u2019s \u201cfiguring out the normative truth.\u201d That is: there is an objective, normative reality \u201cout there,\u201d and we are as scientists, inquiring about its nature.</p><p>Many normative anti-realists often adopt this posture as well. They want to talk, too, about the normative truth, and to rely on norms and assumptions familiar from the context of inquiry. But it\u2019s a lot less clear what\u2019s going on when they do.</p><p>Perhaps, for example, they claim: \u201cthe normative truth this inquiry seeks is constituted by the very endpoint of this inquiry \u2013 e.g., reflective equilibrium, what I would think on reflection, or some such.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5m7rg4uh9sg\"><sup><a href=\"#fn5m7rg4uh9sg\">[2]</a></sup></span>&nbsp;But what sort of inquiry is that? Not, one suspects, the normal kind. It sounds too \u2026 unconstrained. As though the inquiry could veer in any old direction (\u201cmaximize bricks!\u201d), and thereby (assuming it persists in its course) make that direction the right one. In the absence of a territory \u2013 if the true map is just: whatever map we <i>would </i>draw, after spending ages thinking about what map to draw \u2013 why are we acting like ethics is a normal form of map-making? Why are we pretending to be scientists investigating a realm that doesn\u2019t exist?</p><h3>2.2 Why curve-fit?</h3><p>My own best guess is that ethics \u2013 including the ethics that normative realists are doing, despite their self-conception \u2013 is best understood in a more <a href=\"https://joecarlsmith.com/2021/06/21/on-the-limits-of-idealized-values#x-passive-and-active-ethics\">active posture</a>: namely, as an especially general form of <i>deciding what to do</i>. That is: there isn\u2019t the one thing, figuring out what you should do, and then that other separate thing, deciding what to do.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7or5wd5512\"><sup><a href=\"#fn7or5wd5512\">[3]</a></sup></span>&nbsp;Rather, ethical thought is essentially <i>practical</i>. It\u2019s the part of cognition that issues in action, rather than the part that \u201cmaps\u201d a \u201cterritory.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3jvpi9uaxyd\"><sup><a href=\"#fn3jvpi9uaxyd\">[4]</a></sup></span></p><p>But on this anti-realist conception of ethics, it can become unclear why the specific sort of thinking ethicists tend to engage in is worth doing. Here I\u2019m thinking, in particular, about the way in which ethics typically involves some sort of back-and-forth between particular intuitions about what to do in specific cases, and more general principles that explain and revise those intuitions. That is, roughly, ethics typically implies some effort to <i>systematize</i> our pattern of response to the world; to notice the contradictions, tensions, and coherence-failures that arise when we do; and to revise our policies accordingly, into a more harmonious unity.</p><p>But why do this? The standard practice \u2013 both amongst realists and anti-realists \u2014 often works within an implicitly realist frame, on which one\u2019s intuitions are (imperfect) evidence about the true underlying principles (<a href=\"https://joecarlsmith.com/2022/01/17/the-ignorance-of-normative-realism-bot\">why would you think that</a>?), which are typically assumed to have properties are like consistency, coherence, and so on. To find these principles, one attempts to \u201ccurve fit\u201d one\u2019s intuitions \u2013 and different ethicists make different trade-offs between e.g. the simplicity and elegance of the principles themselves, vs. the accuracy with which they predict the supposed \u201cdata.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0uut1b6aqov\"><sup><a href=\"#fn0uut1b6aqov\">[5]</a></sup></span>&nbsp;But if this practice isn\u2019t helping us towards the objective normative truth, why would we go in for it?</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/qphfubnyriqubimgrsln.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/qphfubnyriqubimgrsln.png 1010w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/dspzveoddavtlevgn0u9.png 300w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/sbkikuehsar0ztetbfda.png 768w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/vamnl2mkoa3xe1lc86nd.png 402w, https://res.cloudinary.com/cea/image/upload/v1676524830/mirroredImages/K9GdCuiz5tanoiDKN/xtgvzevcf1ycqhzp9t7r.png 462w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/owfyfax8sqfuu2mhplwk.png 662w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/tn5ns6bj0bx4ibfib619.png 722w, https://res.cloudinary.com/cea/image/upload/v1676524830/mirroredImages/K9GdCuiz5tanoiDKN/ecp3jsamotdbrygakecd.png 982w\"></p><p><i>Why do this to yourself? (Image source </i><a href=\"https://commons.wikimedia.org/wiki/File:Loess_curve.svg\"><i>here</i></a><i>.)</i></p><p>Consider, for example, the following policy: \u201cwhatever, I\u2019m just going to do whatever I want, or whatever seems intuitively reasonable, in each particular case.\u201d Boom: done. And with such amazing fidelity to our intuitions in each case! The curve is just: whatever the curve god-damn needs to be, thank you. Or if that doesn\u2019t work: screw the curve. I\u2019m a no-curve dude. Going with my gut; with common-sense; with \u201cwhat my body wants\u201d; with that special, rich, heuristic wisdom I assume I bring to each decision. <a href=\"https://en.wikipedia.org/wiki/Metis_(mythology)#:~:text=The%20Greek%20word%20metis%20meant,with%20Polyphemus%2C%20son%20of%20Poseidon.\">Metis</a>, you know? <a href=\"https://en.wikipedia.org/wiki/Coup_d%27%C5%93il\">Coup d\u2019oeil</a>. Wasn\u2019t that what the curve fitting was trying so hard to validate, anyway? Now can I get back to what I was doing?</p><p>Of course, one objection to this is just: it looks like the type of thing slaveholders could have said. That is, to the extent your default policy/intuitions are <i>wrong</i>, this approach won\u2019t set them right. But the anti-realists have not yet made good on the notion of a policy being \u201cwrong,\u201d or on a story about why systematizing would notice and correct this wrongness.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhia4tty5fml\"><sup><a href=\"#fnhia4tty5fml\">[6]</a></sup></span>&nbsp;Isn\u2019t it all, just, what you decide to do? So if you in fact decide to do blah, or want to do blah, why not just the draw the curve in a way that validates that decision? Indeed, why draw curves at all?</p><p>A second objection is: this approach doesn\u2019t allow for a very simple or compact description of your policy, or your \u201ctrue values,\u201d or whatever. The curve, if you draw it, seems over-fit; it\u2019s not the sort of line we\u2019d want to draw in stats class. And indeed: yes. But, um\u2026 who cares? Yes, in empirical contexts, we typically think simpler models <i>will be a better guide to the truth</i>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyn0v25vdeem\"><sup><a href=\"#fnyn0v25vdeem\">[7]</a></sup></span>&nbsp;But we already said that there was no truth to be a guide to, here. Why would we import map-making norms into a domain with no territory?</p><p>Is the worry that you won\u2019t be able to predict, using some explicit model of your values, what your intuition/choice will be in a given case? Maybe there\u2019s something important here (more in the next essay).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefu8gmaxjkcm\"><sup><a href=\"#fnu8gmaxjkcm\">[8]</a></sup></span>&nbsp;But naively: ethics is not about self-prediction (and people, including yourself, can presumably make predictable ethical errors); and you can always ask yourself, directly, what your intuition in the relevant cases would be.</p><p>A third objection is: this sort of policy won\u2019t be very helpful in <i>guiding</i> action. That is, if you encounter a new sort of situation, where your intuition does not immediately yield a verdict about what to do, you are left bereft of general principles to fall back on. I think this is getting at something important, but on its own, it doesn\u2019t feel fully satisfying. In particular: often our intuition <i>does</i> provide some sort of guidance about a given case, and the pressing question is whether our intuition is <i>correct</i>. And to the extent our intuition falls silent in some cases, what\u2019s wrong with \u201ccrossing that bridge when we come to it?\u201d \u2013 which for many of the hard and artificial cases philosophers focus on, we generally won\u2019t (a fact that non-philosophers are often quite impressed with). Perhaps, indeed, I don\u2019t have an explicit method of making all my decisions ahead of time. But who said I needed one?</p><h3>2.3 Who needs ethics if you\u2019re free?</h3><p>I think these are good questions. And I find that they come up a lot.</p><p>For example: my realist friends often say that if they became anti-realists, their approach to ethics would totally change. In particular, their commitment to structural things like \u201cconsistency,\u201d \u201ccoherence,\u201d and \u201ctransitivity\u201d would go out the window; and their interest in more substantive stuff \u2013 like helping others, scope-sensitivity, etc \u2013 would diminish strongly as well.</p><p>Also, they\u2019d be way less willing to bite the sorts of bullets they\u2019ve managed to force themselves to bite \u2013 bullets like the <a href=\"https://plato.stanford.edu/entries/repugnant-conclusion/\">repugnant conclusion</a> (my realist friends tend to be total utilitarians, modulo moral uncertainty). That is, if they were <i>free \u2014</i> if they could just <i>do what they want to \u2013 </i>then obviously they wouldn\u2019t go for a zillion slightly-happy lizards (plus arbitrary hells?) over <a href=\"https://joecarlsmith.com/2021/01/18/actually-possible-thoughts-on-utopia\">Utopia</a>: are you kidding me? Lol. Those lizards are a nightmare. Oh yes, it\u2019s a nightmare they\u2019re devoting their lives to.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq0j632z9rb\"><sup><a href=\"#fnq0j632z9rb\">[9]</a></sup></span>&nbsp;But that\u2019s because apparently it\u2019s the <i>true morality. </i>Yes, it\u2019s a bit rough. They admit the true morality could\u2019ve been way better. They walked out of Plato\u2019s cave and they were like: yikes. If they had their way, they\u2019d go for Utopia, trust them. It\u2019s just that duty (optimality, beneficence) calls. &nbsp;</p><p>But I see a similar impulse amongst anti-realists as well. For example: there is a live debate, amongst my friends, about what to do <a href=\"https://joecarlsmith.com/category/crazy-train/\">when systematic reasoning starts to lead to new and uncomfortable places</a>, and one candidate response is just \u201cidk, just stop doing systematic reasoning, whatever.\u201d This debate isn\u2019t limited to ethics in particular (rather, it\u2019s tied in with broader debates about inside views, <a href=\"https://slatestarcodex.com/2019/06/03/repost-epistemic-learned-helplessness/\">epistemic learned helplessness</a>, <a href=\"https://blog.givewell.org/2014/06/10/sequence-thinking-vs-cluster-thinking/\">cluster thinking</a>, and so on); but a \u201cwhatever\u201d answer to an otherwise forceful ethical argument can easily seem a more live option if ethics is a domain where ultimately, you can just \u201cdo whatever you want.\u201d I.e., \u201cwhatever\u201d amounts to something like \u201cdraw the curve however I need to in order to keep doing what I want to do anyway; or don\u2019t draw it at all, I don\u2019t care.\u201d</p><h2>3. Some examples where this stuff comes up</h2><p>In considering these reactions, I think it\u2019ll help to have a few concrete examples of \u201cethics\u201d on the table. Here are two.</p><h3>3.1 Drowning children stuff</h3><p>Consider the following three (perhaps familiar) claims.</p><ol><li>It\u2019s impermissible to let a nearby child drown in order to not ruin an expensive suit.</li><li>It\u2019s permissible to buy a suit instead of donating the money to save a distant child.</li><li>There is no morally significant difference between these cases.</li></ol><p>(1)-(3) all seem initially intuitive. But they\u2019re also inconsistent.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefk3q65dol9fr\"><sup><a href=\"#fnk3q65dol9fr\">[10]</a></sup></span>&nbsp;So the realist says: \u201cone of them must be false.\u201d One assumes that a <i>real domain</i> can\u2019t be inconsistent, after all. &nbsp;</p><p>But for the anti-realist, it\u2019s less clear how to relate to this inconsistency. After all, we\u2019re not trying to draw a map of some external domain. So does the anti-realist really need to give one of these up? Could we, maybe, give up on philosophy instead? Is there a \u201cwhatever\u201d option?</p><p>I remember talking with a realist friend about this sort of case. He takes it very seriously. But he said that if he was an anti-realist, he wouldn\u2019t. Rather, he would just \u2026 something. I assume: buy the suit. But not in a \u201cI hereby reject 3, and posit a morally significant difference between the cases\u201d way. Rather, in some other way \u2013 some way less interested in the \u201cwhole game.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqjqnum32edg\"><sup><a href=\"#fnqjqnum32edg\">[11]</a></sup></span></p><h3>3.2 Lizard stuff</h3><p>Or consider the following argument for the <a href=\"https://plato.stanford.edu/entries/repugnant-conclusion/\">Repugnant Conclusion</a>:<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefocc96muzxcs\"><sup><a href=\"#fnocc96muzxcs\">[12]</a></sup></span></p><ol><li><i>Benign Addition</i>: If world <i>x</i> would be the result of improving the lives of everyone in world <i>y</i>, plus adding some new people with worthwhile lives, then <i>x</i> is better than <i>y</i>. (Less formally: helping everyone who exists, plus adding some net-positive lives on the side, is good.)</li><li><i>Non-anti-egalitarianism</i>: If world <i>x</i> and world <i>y</i> have the same population, but <i>x</i> has a higher average utility, a higher total utility, and a more equal distribution of utility than <i>y</i>, then <i>x</i> is better than <i>y</i>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefg20lm3uhezs\"><sup><a href=\"#fng20lm3uhezs\">[13]</a></sup></span></li><li><i>Transitivity</i>: If <i>x</i> is better than <i>y</i> and <i>y</i> is better than <i>z</i>, then <i>x</i> is better than <i>z</i>.</li></ol><p>These principles all look pretty solid. <i>Benign Addition</i> is basically a Pareto-principle (i.e., a \u201cbetter for some, at least as good for everyone\u201d thing), combined with the absence of active opposition to new happy lives. <i>Non-anti-egalitarianism</i> seems strong by totalist AND averagist AND egalitarian lights (and because it assumes a constant population, it will fall out of <a href=\"https://docs.google.com/document/d/1gDX6iDp-KvCANr2Ngk-grAHsRXS0ncuyO09b5rLYyAc/edit\">Harsanyi-ish utilitarian arguments</a> as well). And <i>Transitivity </i>seems <i>super </i>structural and obvious (see also <a href=\"https://joecarlsmith.com/2022/03/21/on-expected-utility-part-3-vnm-separability-and-more#ii-the-four-vnm-axioms\">here</a> for more substantive arguments in its favor; plus a bit more below).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8lq5hmnhz9j\"><sup><a href=\"#fn8lq5hmnhz9j\">[14]</a></sup></span></p><p>Yet in combination, these principles imply (at least in conjunction with some assumptions about lizard welfare, and welfare comparisons more broadly) that for any finite Utopia, there\u2019s a better world consisting entirely of barely-happy lizards. (See footnote if you\u2019re unfamiliar with this reasoning.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4on7gcukxjg\"><sup><a href=\"#fn4on7gcukxjg\">[15]</a></sup></span>)</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/hl1otpbrqfps1cdzc5vl.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/hl1otpbrqfps1cdzc5vl.png 1024w, https://res.cloudinary.com/cea/image/upload/v1676524830/mirroredImages/K9GdCuiz5tanoiDKN/yviv4cuikodihzajx7hy.png 300w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/f2a2ugnauaa8d9hh3mlx.png 768w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/d4bltxb6dd4cqopzpfz1.png 1536w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/ryghppjvtwppva57jszd.png 402w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/nzgiwgebrlqvoaim1ydk.png 462w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/pkbrgr7uanqjurxfdv6w.png 662w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/wgbqkdyyk0l0auh3elez.png 722w, https://res.cloudinary.com/cea/image/upload/v1676524830/mirroredImages/K9GdCuiz5tanoiDKN/ecdcvwbqo79tot0redep.png 982w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/kwnsgtzkrax4ztkjyi3l.png 1032w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/qla82c8tvp0espevzbns.png 1402w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/g9mknw2a4pcffmsaf019.png 1702w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/exs4j8p1kn3pl2xhjidj.png 1722w\"><i>Which is your favorite?</i></p><p>Also: note that if you\u2019re getting tripped on something about creating new people, we can run a version of this argument that just appeals to <i>extending</i> your own life, lizard-style.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref093a47k4y1q\"><sup><a href=\"#fn093a47k4y1q\">[16]</a></sup></span>&nbsp;That is: just re-interpret the diagrams above as graphing the quality of your possible lives over time (see footnote for more detailed reasoning).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn6rk806qkjb\"><sup><a href=\"#fnn6rk806qkjb\">[17]</a></sup></span>&nbsp;Thus, faced with the option of a wonderful human life, you transform yourself, instead, into a (very long-lived) lizard.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/wgkfjkmu2remq1doqx1z.png\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/wgkfjkmu2remq1doqx1z.png 688w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/t7fp6qnqetitdwdzoc4n.png 201w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/amfqcpd5fp6gj8kebdve.png 768w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/u6afl3mxoppipanml2mw.png 402w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/htlrnavwj8dn3zdi1c6v.png 462w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/qxqlkp4c5shecle0fgur.png 662w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/ki6kwxoaasuhiez57auo.png 722w, https://res.cloudinary.com/cea/image/upload/v1676524831/mirroredImages/K9GdCuiz5tanoiDKN/mh9pssvudxo5mzkffjgy.png 810w\"></p><p><i>Your next zillion years. (Photo source </i><a href=\"https://unsplash.com/photos/dDFesXwNAs8\"><i>here</i></a><i>)</i></p><h3>3.3 Scott Alexander on rejecting the \u201cphilosophy game\u201d</h3><p>People say philosophy doesn\u2019t make progress. But I think it makes lots of progress.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefro871dze6lt\"><sup><a href=\"#fnro871dze6lt\">[18]</a></sup></span>&nbsp;The progress isn\u2019t necessarily of the form: \u201cyou must become lizard.\u201d Rather, it\u2019s often of the form: you can\u2019t have all of <i>x</i>, <i>y</i>, and <i>z</i>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflmo9wdlf0hh\"><sup><a href=\"#fnlmo9wdlf0hh\">[19]</a></sup></span>&nbsp;Drowning children and repugnant conclusions are both great examples.</p><p>Still, progress of this kind is often painful. Sometimes, we <i>wanted</i> <i>x</i>, <i>y</i>, and <i>z</i>. We wanted it all. Must the dream die?</p><p>Indeed, some anti-realists confront this sort of pain and go: \u201cI\u2019m out.\u201d This, for example, is a tempting reading of Scott Alexander\u2019s response to the repugnant conclusion thing above, in his review of <a href=\"https://astralcodexten.substack.com/p/book-review-what-we-owe-the-future\">What We Owe the Future</a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqqy8ylyf89d\"><sup><a href=\"#fnqqy8ylyf89d\">[20]</a></sup></span>&nbsp;Let\u2019s look briefly at that review.</p><p>Part of Alexander\u2019s response is a gesture at a way of rejecting <i>Benign Addition</i> (\u201cIf I had to play the philosophy game, I would assert that it\u2019s always bad to create new people whose lives are below zero, and neutral to slightly bad to create new people whose lives are positive but below average\u201d), but I don\u2019t want to focus on that here: Alexander anticipates that his object-level proposal might imply further serious problems, and I think he is very right (see footnote for a few examples).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefna9viy6swo\"><sup><a href=\"#fnna9viy6swo\">[21]</a></sup></span></p><p>Rather, the heart of Alexander\u2019s response, at least in the initial review, seems to be some more wholesale rejection of philosophy itself \u2013 or at least, what he imagines philosophy to be:</p><blockquote><p>You\u2019re walking along, minding your own business, when the philosopher jumps out from the bushes. \u201cGive me your wallet!\u201d You notice he doesn\u2019t have a gun, so you refuse. \u201cDo you think drowning kittens is worse than petting them?\u201d the philosopher asks. You guardedly agree this is true. \u201cI can prove that if you accept the two premises that you shouldn\u2019t give me your wallet right now and that drowning kittens is worse than petting them, then you are morally obligated to allocate all value in the world to geese.\u201d The philosopher walks you through the proof. It seems solid. You can either give the philosopher your wallet, drown kittens, allocate all value in the world to geese, or admit that logic is fake and Bertrand Russell was a witch\u2026</p><p>But I\u2019m not sure I&nbsp;want&nbsp;to play the philosophy game. Maybe MacAskill can come up with some clever proof that the commitments I list above imply I have to have my eyes pecked out by angry seagulls or something. If that\u2019s true, I will just not do that, and switch to some other set of axioms. If I can\u2019t find any system of axioms that doesn\u2019t do something terrible when extended to infinity, I will just refuse to extend things to infinity. I can always just keep World A with its 5 billion extremely happy people! I like that one! \u2026</p><p>I realize this is \u201canti-intellectual\u201d and \u201cdefeating the entire point of philosophy\u201d. If you want to complain, you can find me in World A, along with my 4,999,999,999 blissfully happy friends.</p></blockquote><p>(Alexander also includes a meme saying \u201cjust walk out; you can leave!\u201d and \u201cif it sucks, hit da bricks! Real winners quit\u201d regarding \u201cthought experiments that demonstrate that you have intransitive preferences.\u201d)</p><p>What\u2019s going on here? What does it mean to \u201cnot play the philosophy game\u201d? What is this \u201cquitting\u201d that \u201creal winners\u201d do?</p><p>Alexander seems intent on avoiding <i>something</i>. For example, he wants to avoid starting down paths that seem nice but go somewhere horrible. And my sense is that more generally, he wants to avoid the sort of thing <a href=\"https://slatestarcodex.com/2019/06/03/repost-epistemic-learned-helplessness/\">epistemic learned helplessness</a> is supposed to protect against: namely, being tricked into stupid conclusions by listening to arguments.</p><p>But where does he hope to end up instead? Well, he says something about this. We know he\u2019s pro-Utopia. He\u2019s anti-repugnance. And damnit, he\u2019s going to draw whatever curves he needs to in order to stay that way. Of course, he doesn\u2019t know what those curves are. It\u2019s not clear he wants to. Probably, they imply some horrible thing. But it\u2019s OK, he will just not take them there; he will just not do that horrible thing. See? Easy. Do philosophy until, fuck it, you stop.</p><p>Or at least, that\u2019s the vibe I get from Alexander\u2019s original review. In a <a href=\"https://astralcodexten.substack.com/p/highlights-from-the-comments-on-the-909\">follow-up piece</a>, his tone seems a bit different. In particular: he acknowledges that \u201crealistically I was doing philosophy just like everyone else.\u201d And his main position seems to be that he is entitled, as an anti-realist, to build his ethics around avoiding the repugnant conclusion if he wants to;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5frcstqgewf\"><sup><a href=\"#fn5frcstqgewf\">[22]</a></sup></span>&nbsp;that \u201cI prefer to leave this part of population ethics vague until someone can find rules that don\u2019t violate my intuitions so blatantly\u201d and that \u201cI know that it\u2019s not&nbsp;<i>impossible</i>&nbsp;to come up with something that satisfies my intuitions, because \u2018just stay at World A\u2019 (the 5 billion very happy people) satisfies them just fine.\u201d I still think Alexander isn\u2019t grappling with the full force of the bind he\u2019s in, here (see footnote for more),<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoxb1z8ut0gk\"><sup><a href=\"#fnoxb1z8ut0gk\">[23]</a></sup></span>&nbsp;but I don\u2019t want to focus too much on his view in particular.</p><p>Rather, I\u2019m more interested in the broader vibe that his initial review conjured, at least for me \u2013 one that I don\u2019t think Alexander would actually endorse (at least not in the tone I\u2019m offering it), but which I wonder if others might take away from his comments. It\u2019s a vibe like: maybe ethics is hard for the realists. Maybe they should be scared of that old word, \u201cimplication.\u201d For them, perhaps, such a word has heft and force. It might tell you something new about factory farms, or slavery.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefp3ql4ae51y\"><sup><a href=\"#fnp3ql4ae51y\">[24]</a></sup></span>&nbsp;Something that somehow, you weren\u2019t seeing before (what is this not-seeing?). It might change your life.</p><p>But for anti-realists, on this vibe, \u201cimplication\u201d goes limp and wispy. It\u2019s just curve-stuff, and you are not bound by curve-stuff. Not once you have learned words like \u201cwhatever.\u201d If some curve says \u201cdo blah,\u201d but you don\u2019t want to, you can just say \u201cnah.\u201d Thus, you are safe. Right?</p><h2>4. I\u2019m not trying to turn you into a lizard</h2><p>I\u2019m going to be defending \u201cthe philosophy game\u201d a bit in what follows, so I want to be clear about something up front: I\u2019m not trying to turn you into a lizard, or to take away your suits.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref66jbrrjig87\"><sup><a href=\"#fn66jbrrjig87\">[25]</a></sup></span>&nbsp;On anti-realism, if you don\u2019t actually want to become a lizard, or to pave the world with lizard farms, or to donate all your money to blah, or whatever \u2013 then you never have to. That\u2019s the whole \u201cfreedom\u201d thing. It\u2019s the truth in \u201cwhatever.\u201d It\u2019s also a key part of what Alexander, as I read him, is trying to hold on to \u2013 he can, indeed, just keep World A, if he wants \u2013 and I think he\u2019s right to try to hold on to this.</p><p>Indeed, I think that often, what people are groping for, when they talk about stuff like \u201cnot playing the philosophy game,\u201d is something about not being <i>coerced</i> by philosophy \u2013 and especially not philosophy they don\u2019t really believe in, but have some sense that they \u201cshould.\u201d Note, for example, the way that Alexander, in the original review, is experiencing philosophy as coming from the outside and \u201cmugging him.\u201d Philosophy is an adversary.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgiis622nzpj\"><sup><a href=\"#fngiis622nzpj\">[26]</a></sup></span>&nbsp;It might seem innocent and truth-seeking. But it\u2019s trying to pull some clever trick to get him to give up something he loves; to cut him, with some cold and apparently-rigorous violence, into something less than himself. It\u2019s re-assuring him that \u201cno, really, I know it hurts, but it\u2019s all a matter of logic, there\u2019s no other way, you saw the proof.\u201d But some part of him doesn\u2019t buy it. Some part of him moves to protect itself. And I do actually think that stuff about <a href=\"https://slatestarcodex.com/2019/06/03/repost-epistemic-learned-helplessness/\">epistemic learned helplessness</a> is relevant here; and also, stuff about <a href=\"https://www.lesswrong.com/posts/EEv9JeuY5xfuDDSgF/flinching-away-from-truth-is-often-about-protecting-the\">bucket errors</a>.</p><p>Indeed, this sort of frame can make sense of some of the realist reactions above, too. \u201cIf I wasn\u2019t being coerced by the normative truth, then why would I be doing any of this stuff?\u201d (Though note that not all authority is coercion \u2013 especially conditional on realism.)</p><p>But I think there\u2019s a way of doing philosophy that isn\u2019t like this. A sort of philosophy that is more fully \u201con your side.\u201d That\u2019s the sort I want to defend.</p><p>Most of my defense, though, will be in my next essay. Here, I want to talk about two defenses that don\u2019t seem to me fully adequate, namely:</p><ul><li>Appeals to some kind of brute preference that your policy have various structural properties</li><li>Appeals to money-pumps and \u201cnot shooting yourself as in the foot\u201d as an argument for \u201ccoherence\u201d</li></ul><h2>5. Some kind of brute preference for consistency and systematization?</h2><p>Anti-realism, famously, treats something like brute desire/preference as the animating engine of normative life. So to the extent anti-realists think they have some kind of reason to engage in the \u201csystematizing\u201d type of ethics at stake here, it\u2019s natural to wonder whether this reason will stem from some kind of brute preference/desire that one\u2019s values have various structural properties: things like consistency, coherence, simplicity, systematic-ness, and so on.</p><p>That is, on this story, trying to resolve the tensions implied by drowning children/repugnant conclusions/whatever is, sure, one thing you can be into. Apparently, you\u2019re a \u201csystematizer.\u201d And that\u2019s fine! It\u2019s really fine. Personally, though, I collect stamps.</p><p>My sense is that this is what realists often think is going on with anti-realists who still care about ethics for some reason, despite its conspicuous <i>absence of subject-matter</i>. (Well: that, and not having really shaken their implicit allegiance to realism.) And some anti-realists seem to think this way, too. Thus, for example, I get vibes in this vicinity from the following comments from <a href=\"https://mindingourway.com/caring-about-some/\">Nate Soares</a>:</p><blockquote><p>So I look upon myself, and I see that I am constructed to both (a) care more about the people close to me, that I have deeper feelings for, and (b) care about fairness, impartiality, and aesthetics. I look upon myself and I see that I&nbsp;<i>both</i>&nbsp;care more about close friends,&nbsp;<i>and</i>&nbsp;disapprove of any state of affairs in which I care more for some people due to a trivial coincidence of time and space.</p><p>And I am constructed such that when I look upon myself and find inconsistencies, I care about resolving them.</p></blockquote><p>One problem with this sort of story is that it struggles to justify ethics as it\u2019s actually practiced (including by anti-realists), especially with respect to stuff like consistency. In particular: it treats stuff like \u201cavoiding inconsistency\u201d as one-value-among-many, which naturally suggests that it would be \u201cweighed in the mix.\u201d In practice, though, ethicists treat consistency as a <i>hard constraint</i> (note that this is different from saying that different values can\u2019t pull in different directions). And they\u2019re right to do so, even conditional on anti-realism.</p><p>Thus, for example, suppose you have decided to buy the suit. But you\u2019ve <i>also</i> decided not to buy the suit. Ethics doesn\u2019t say: \u201cah, OK, well one other thing to factor in here is that you value being consistent \u2013 just want to throw that in as an additional consideration.\u201d Indeed, on its own, it\u2019s not clear why this would be enough to prompt a resolution to the conflict. But ethics goes a different route. It says: \u201cSorry, this policy you\u2019re trying to have, here, just isn\u2019t a thing. Either you\u2019re going to buy the suit, or you\u2019re not, but you\u2019re not going to do both.\u201d</p><p>And the same goes for inconsistencies at a more abstract level. Consider: \u201cI will always give everyone equal consideration,\u201d and \u201cI will be especially helpful to my friends.\u201d Oops: not a thing.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefym3xjf1brun\"><sup><a href=\"#fnym3xjf1brun\">[27]</a></sup></span>&nbsp;Same for: \u201cI will blame people who don\u2019t save nearby drowning children\u201d and \u201cI won\u2019t blame people who buy suits\u201d and \u201cI will either blame <i>both</i> suit-buyers and nearby-children-let-drowners, or I won\u2019t blame either of them.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefu3r43w3zed8\"><sup><a href=\"#fnu3r43w3zed8\">[28]</a></sup></span>&nbsp;Just: not a way-you-can-be. And that\u2019s just true in the standard sense. Your idiosyncratic, quasi-aesthetic, \u201csystematizing\u201d preferences don\u2019t come into it.</p><p>I care about this example because sometimes, in a conversation in which some ethical inconsistency gets pointed out, people will act as though \u201ceh, I don\u2019t care that much about being ethically consistent\u201d is some sort of viable path forward \u2013 and indeed, perhaps, a tempting freedom. After all: if you\u2019re up for inconsistency, you can have it all, right? No. The whole thing about consistency is that it tells you what you can have. This is as true in ethics as elsewhere, even on anti-realism \u2014 and true regardless of your preferences, or your attitudes towards the \u201cphilosophy game.\u201d</p><p>Of course: often, in such contexts, people aren\u2019t actually talking about literal consistency. Rather, they mean something more like: treating apparently-similar cases alike; or: applying apparently-compelling principles without exceptions; or maybe they\u2019re not distinguishing, cleanly, between intransitivities (A \u227bB \u227bC \u227bA) and direct inconsistencies (A \u227bB and not(A \u227bB)).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgr22pa0q4gk\"><sup><a href=\"#fngr22pa0q4gk\">[29]</a></sup></span>&nbsp;And in those cases (depending on how we set them up), we can\u2019t always appeal to stuff like \u201cyour proposed policy is just not a thing.\u201d For example, there is indeed a policy that takes world A+ over world A (it likes <i>Benign Addition</i>), world Z over world A+ (it likes <i>Non-Anti-Egalitarianism</i>), and world A over world Z (it hates the <i>Repugnant Conclusion</i>) \u2013 and which does, idk, <i>something</i> when faced with all three.</p><p>Still, the same broad sort of worry will apply: namely, that to the extent ethics wants to treat blah-structural-property as a hard constraint, saying \u201cI happen to care, intrinsically, about my policy having blah-structural-property\u201d looks poorly positioned to justify allowing this particular preference such over-riding power \u2013 assuming, that is, that you care about other stuff as well. For example, faced with the intransitive policy above, if you throw in \u201calso, I happen to care about satisfying <i>Transitivity</i>,\u201d then fine, cool, that\u2019s another thing to consider. But: how <i>much</i> do you care about that? Enough to ride the train to lizard land? Enough to give up on \u201chelping everyone + doing something neutral/good is good\u201d? There are other cares in the mix here, too, you know\u2026</p><p>That said, one response to this is just: fine, maybe stuff like transitivity <i>shouldn\u2019t</i> be a hard constraint. Maybe it should be just one-value-among-others.</p><p>Even if we go that route, though, I feel some deeper objection to \u201cI do ethics, as an anti-realist, because I have a brute, personal preference that my values/policy have blah-structural-properties.\u201d In particular: at least absent some more resonant characterization (more in my next post), it just doesn\u2019t seem compelling to me &nbsp;\u2013 especially not next to more object-level, hot-blooded ethical stuff: next to suffering, death, joy, oppression; donating all your money to charity; joining the communist party; destroying Utopia to build a lizard farm; and so on. If some dilemma pits real, object-level stakes, on the one hand, against my degree of brute preference to satisfy some abstract structural constraint, on the other, why expect the latter to carry the day? And if ethics, for anti-realists, gets its oomph solely from the latter, I worry that it\u2019s calling on something too dry and thin.</p><h2>6. Money-pumps</h2><p>Let\u2019s turn to a different sort of justification for caring about systematic ethics, even as an anti-realist: namely, the idea that if your values don\u2019t have various structural properties that ethicists are sometimes interested in, then you\u2019re vulnerable to \u201cmoney-pumps\u201d \u2013 i.e., paying money to go in a circle.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsp5nrebo9y\"><sup><a href=\"#fnsp5nrebo9y\">[30]</a></sup></span></p><p>Thus, for example, the intransitive policy above looks like it would pay money to switch from A to A+ to Z and then back to A. And no matter your meta-ethics, or your attitudes towards marginal lizards, this seems pretty dumb. In particular: it seems like burning money for no reason (was there a reason, though?). And also, the fix seems cheap: instead of doing it, don\u2019t. So cheap! Indeed: free. Indeed: profitable. Transitivity, apparently, is free money. And we can construct similar arguments for the other axioms of von Neumann Morgenstern (vNM) rationality (see <a href=\"https://joecarlsmith.com/2022/03/21/on-expected-utility-part-3-vnm-separability-and-more#ii-the-four-vnm-axioms\">here</a> for discussion of such arguments) \u2013 axioms that together imply that your values need to be representable as a consistent utility function, which sounds pretty \u201csystematizer\u201d-ish.</p><p>Is \u201cdon\u2019t burn money for no reason\u201d enough of an impetus for doing systematic ethics, even as an anti-realist? Is the main objection to a policy of \u201cwhatever, draw the curves in whatever way, I\u2019m just going to do whatever I want\u201d something like: \u201cOK, but I can see parts of your policy that could, in combination, end up burning money for no reason \u2013 don\u2019t you at least want to eliminate that?\u201d And if you try to do so, do you end up re-shaping yourself into an <a href=\"https://jc.gatspress.com/pdf/on_expected_utility.pdf\">expected utility maximizer</a>?</p><p>I used to like this argument a lot. Now I like it less.</p><h3>6.1 Dialogue with an intransitive agent</h3><p>I started to get suspicious of it after a number of conversations (partly with myself) in the following vein:<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefprhr0jt95u\"><sup><a href=\"#fnprhr0jt95u\">[31]</a></sup></span></p><blockquote><p><i>Them</i>: Jesus, this lizard stuff is horrible. I think I\u2019m just going to accept that my preferences are intransitive. After all: fuck it, I\u2019m an anti-realist.</p><p><i>Me</i>: OK, but you\u2019re going to get money-pumped.</p><p><i>Them</i>: Um, will I? These cases don\u2019t seem very real-world, anyway.</p><p><i>Me</i>: I dunno, is it so easy to tell where these intransitivities show up? But also: in principle though.</p><p><i>Them</i>: I think what I\u2019ll do is like: if I see that I\u2019m about to get money-pumped, I\u2019ll just not. Like, if A \u227bB \u227bC \u227bA, and I see that I\u2019m going to have access to sets of options that allow me to get any of them, then I\u2019ll just pick one (the same one I\u2019d choose in a three-way choice), make a plan to get it, and stick with that plan.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftr7fl2ct3b\"><sup><a href=\"#fntr7fl2ct3b\">[32]</a></sup></span></p><p><i>Me</i>: I think there\u2019s some supposed to be some sort of more sophisticated money-pump where that doesn\u2019t work?</p><p>[Checks briefly in <a href=\"https://johanegustafsson.net/books/money-pump-arguments.pdf\">Gustafsson\u2019s book on Money Pumps</a>.]</p><p><i>Me</i>: OK actually looks Gustafsson\u2019s main objection amounts to something like \u201cit\u2019s irrational to keep your commitments if they run counter to your later-preferences,\u201d which <a href=\"https://joecarlsmith.com/2021/08/27/can-you-control-the-past#ix-what-would-you-have-wanted-yourself-to-commit-to\">I don\u2019t buy</a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref02c029at67ry\"><sup><a href=\"#fn02c029at67ry\">[33]</a></sup></span>&nbsp;I think the fancy cases were about \u201cbackward induction,\u201d which is different. Still, though: what if you don\u2019t know what options you\u2019ll have in the future?</p><p><i>Them</i>: Hmm, I think it\u2019s fine to trade in a circle, if you get new information along the way? Like, suppose I have a ticket to the circus, but then I pay to trade it for an opera ticket, but then I learn that my favorite opera star is out sick, so I pay to trade back.</p><p><i>Me</i>: This seems different somehow? Like, all you\u2019re getting is new information about what options you\u2019ll have in the future, not about how good they are. And I think you\u2019ll end up with vibes like \u201cif my choices are chocolate and vanilla, I\u2019ll take chocolate; but if I then learn that strawberry is on the menu as well, I\u2019ll pay to switch to vanilla.\u201d This seems worse than the opera thing.</p><p><i>Them</i>: [Does some hazy calculation of the expected amount of money/resources/value lost to this sort of unforeseen money-pumping.] Eh, whatever, doesn\u2019t seem like a super big cost relative to that lizard stuff.</p><p><i>Me: </i>Hmm\u2026</p><p><i>Them</i>: Also, is that sort of thing always bad? Suppose I prefer having a moderately happy child to having no child; I prefer having no child to having a very happy child and paying for a very expensive operation; but <i>if</i> I have a moderately happy child, and an operation is available to make them very happy, I will be obligated to pay for it (so I prefer to do so). Now suppose that at T<sub>1</sub>, I believe that no operation is available, so I pay to become pregnant with a child who will be moderately happy. Then, at T<sub>2</sub>, I learn that the operation is in fact available, and I believe that it is too late to call off the pregnancy, so I pay to sign up for the operation. Finally, at T<sub>3</sub>, I learn that in fact, the pregnancy hasn\u2019t yet occurred, so I pay to avoid becoming pregnant at all.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3g7sr1is6lz\"><sup><a href=\"#fn3g7sr1is6lz\">[34]</a></sup></span>&nbsp;Here, I have paid to trade in a circle. But not clear I was irrational in doing so?</p><p><i>Me</i>: OK but we can re-interpret that case in terms of the worlds at stake having different properties: e.g., your having violated an obligation vs. not.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1sy5si7zut2\"><sup><a href=\"#fn1sy5si7zut2\">[35]</a></sup></span></p><p><i>Them: </i>I dunno, seems like the sort of thing you were supposed to be against. And I worry we\u2019re going to \u201cre-interpret\u201d things until your position doesn\u2019t have any content except when you want it to.</p><p><i>Me</i>: \u2026 but, like, intransitive preferences\u2026 like, what are you even doing with your life, yano?</p><p><i>Them</i>: What? I thought this was supposed to be about not burning money.</p></blockquote><p>To be clear: I don\u2019t think I am here representing all there is to be said in this sort of dialectic. And I think there are strong arguments for transitivity that don\u2019t proceed via literal money-pumps.</p><p>Thus, for example, intransitivity requires giving up on an especially plausible <i>Stochastic Dominance </i>principle, namely: if, for every outcome <i>o</i> and probability of that outcome <i>p</i> in Lottery A, Lottery B gives a <i>better</i> outcome with <i>at least p </i>probability, then Lottery B is better (this is very similar to \u201cIf Lottery B is better than Lottery A no matter what happens, choose Lottery B\u201d \u2013 except it doesn\u2019t care about what outcomes get paired with heads, and which with tails).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl6sld45tprc\"><sup><a href=\"#fnl6sld45tprc\">[36]</a></sup></span>&nbsp;[EDIT 2/17: Oops: actually, <a href=\"https://www.lesswrong.com/posts/tLGZXSNRos5Jhjg6P/why-should-ethical-anti-realists-do-ethics?commentId=x7ffccsLqqA5TTyRY#comments\">this isn't the right way to formulate the principle I have in mind</a>. But hopefully the example can give a flavor for what I'm going for.] To see this, suppose that Apples \u227b Oranges \u227b Pears \u227b Grapes \u227b Apples. And now consider the lotteries:</p><ol><li>50% Apples, 50% Pears</li><li>50% Oranges, 50% Grapes</li></ol><p>Apples are better than Oranges, and Pears are better than Grapes (and the probabilities are all equal). So by <i>Stochastic Dominance</i>, I is better than II. But also: Grapes are better than Apples, and Oranges are better than Pears. So by <i>Stochastic Dominance</i>, II is better than I. Thus, faced with a choice between I and II, you decide to choose I, and you decide to choose II. Oops, though: that\u2019s one of those \u201cnot a thing\u201d situations.</p><p>I expect tons of this sort of thing if you actually go in for <i>Intransitivity</i>, and try to propagate it through your decision-making as a whole, rather than just patching specific problem cases when people force them to your attention. Indeed, I expect lots of stuff to just <i>stop making sense</i> (though: whether it will make <i>less sense</i> than intransitivity itself is a different question). &nbsp;</p><p>But money-pump arguments aren\u2019t supposed to be about what \u201cmakes sense.\u201d What is \u201cmaking sense\u201d to a free-thinking anti-realist? Sounds like curve-stuff to me. <i>Stochastic Dominance, </i>for example, sounds like a curve, and that thing about I and II, like one of those \u201cimplication\u201d things. Didn\u2019t we get free from all that? Faced with a choice between I and II, maybe the anti-realist says: \u201cidk man, whatever, pick whichever one you want.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref68vuymlcx8\"><sup><a href=\"#fn68vuymlcx8\">[37]</a></sup></span></p><p>No, money-pump arguments are supposed to punch at a more guttural level, to speak in a language that even a free-thinker will understand and take seriously: namely, your love of raw power (money). Or, like, your love of whatever it is you want to do with power, which I guess is like, Apples? Or wait, Grapes? Actually I don\u2019t really know what you want to do with your money.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefgck0it7t2mq\"><sup><a href=\"#fngck0it7t2mq\">[38]</a></sup></span>&nbsp;But <i>whatever it is</i>, money-pump arguments assume, you like more money rather than less. \u201cCoherence\u201d (i.e., something like: being a VNM-rational agent) can get you more; ethics (on this story) is basically about re-shaping yourself into something more coherent; so ethics, apparently, pays out in free money. And isn\u2019t that enough of an argument in its favor, even for anti-realists?</p><h3>6.2 Coherence isn\u2019t free</h3><p>I think there\u2019s <i>something</i> to this line of thought, but I\u2019m skeptical that it can bear the weight some people I know want to put on it.</p><p>For one thing, the circumstances that money-pump arguments focus on \u2013 namely, ones in which you literally trade in a circle, or end up \u201cstrictly worse off\u201d than you would\u2019ve been otherwise \u2013 seem comparatively rare in real life (and this even setting aside the thing where you can interpret any sequence of trades as maximizing for <i>some</i> consistent utility function over entire-world-histories \u2013 more <a href=\"https://joecarlsmith.com/2022/03/16/on-expected-utility-part-1-skyscrapers-and-madmen#iv-is-being-an-eum-er-trivial\">here</a>). That is, strictly speaking, the money-pumper only gets to say \u201cgotcha!\u201d if you start with A, then end up back at A later, but with less money (plus something something, you didn\u2019t learn new stuff in a way that makes this OK, or something). But in real life, it\u2019s not clear to me how often this sort of strict \u201cgotcha!\u201d actually comes up, especially once we start bringing in various hacky strategies for avoiding it, like the \u201cresolute choice\u201d thing above. And for anything other than a strict \u201cgotcha,\u201d it\u2019s not clear that it\u2019s a gotcha at all, if you\u2019ve started being sympathetic to intransitivity more generally.</p><p>What\u2019s more, I think that various \u201cwhatever\u201d-ish anti-realists, like the one in the dialogue above, sense this. That is, confronted by money-pump arguments, they do a quick forecast of how much money/power/fruit etc they can actually make by correcting some incoherence in themselves, notice that it doesn\u2019t seem like a lot, and shrug it off. Maybe coherence is, like, a <i>bit</i> of extra power; but how much are we talking? Would it, maybe, be better, from a money/power/whatever perspective, to spend some time practicing public speaking? Or, to go on a jog? Is resolving this stuff about lizards really the best way to win friends and influence people?<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhedz0q3unua\"><sup><a href=\"#fnhedz0q3unua\">[39]</a></sup></span></p><p>One possible response here is: \u201cah, but public speaking/jogging etc aren\u2019t <i>free</i> power. But coherence is. Being coherent is just: not shooting yourself in the foot, not stepping on your own toes, not doing something <i>strictly</i> worse than some alternative. So it\u2019s an especially clear-cut win.\u201d But I think this sort of rhetoric mischaracterizes the sort of dilemma that incoherence creates (and not just because reading philosophy books takes time/energy/etc, just as anything does).</p><p>In particular: resolving incoherences in yourself <i>isn\u2019t</i> always free. Often, to the contrary, it\u2019s quite painful. Your initially intransitive preferences were, after all, your real preferences. They weren\u2019t some silly \u201coopsie.\u201d Some part of your heart and/or your mind had a stake in each of them. So any way of cutting the circle into a straight line involves cutting some part of your heart/mind off from something cared-for. Why are we acting like doing this is free? The fact that people are even thinking about rejecting transitivity, despite its apparent obviousness, is testament to its costs.</p><p>Suppose, for example, that A \u227b B \u227b C \u227b A, you start with A, and you end up paying a dollar to end up back at A. <a href=\"https://www.lesswrong.com/posts/RQpNHSiWaXTvDxt6R/coherent-decisions-imply-consistent-utilities\">Money-pump-arguers</a> often want to say that this is a \u201cdominated strategy,\u201d in a way that suggests that there\u2019s some easy and obvious fix. But what should you have done differently? If you just stick with A, and refuse to trade for C, then you do violence to C \u227b A. If you trade to C, and stop, you do violence to B \u227b C. If you trade to B, and stop, there goes A \u227b B. Apparently, to avoid this money-pumping, some part of you needs to die, change, reform. But what if you care more about each of those parts than you do about an extra dollar?</p><p>Perhaps you say: \u201cAh, but if I pretend that each of those parts has their own little mini-utility function, or even some \u2018more of X is always better\u2019 thing, then I can prove that you\u2019ll get pareto-improvements by making yourself coherent and picking some consistent way of trading those goals off of each other.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2obn20k94bb\"><sup><a href=\"#fn2obn20k94bb\">[40]</a></sup></span>&nbsp;And I do think that there\u2019s often something useful about this sort of frame. But&nbsp;note, in this particular case, that it\u2019s imputing way more structure, to these parts, than the case has offered. My preference for A over B, here, isn\u2019t saying \u201cmaximize A-ness!\u201d Rather, it\u2019s saying \u201cgiven a choice between A and B, choose A.\u201d That\u2019s all. It\u2019s not a full-fledged rational agent (and the whole question, here, is whether becoming such an agent is especially compelling, if you aren\u2019t one already). It\u2019s a preference about a specific choice situation. And it, or something like it, is going to get disappointed.</p><p>Really, there are lots of different coherent agents you could become, here. Yes, each of them wants extra money. But you\u2019re not any of them, yet, and dangling a dollar as a prize doesn\u2019t resolve the question of which one to become, if any, or render making the choice costless from your current perspective.</p><p>(Flip a coin? Less arbitrary, yes. But still not free \u2013 still a part of you dying in expectation. And anyway, is that the right way to approach questions about the repugnant conclusion? Flip a coin about whether to become a lizard?)</p><p>We see, here, the same sort of problem we ran into in the last section, when we tried to treat coherence in itself as some kind of brute terminal value. Here, we\u2019re trying to treat coherence as an <i>instrumental value</i> instead. But even granted some sort of value of this kind, we still end up asking: OK, but how much is it worth? And this question becomes especially pressing if we\u2019re trying to treat coherence as some kind of hard constraint on the type-of-agent-you-should-be, as many advocates of money-pump arguments seem to want to. If the instrumental value at stake were \u201cfree,\u201d that might help to motivate grabbing such value as a hard constraint (or rather: a \u201cwhy wouldn\u2019t you\u201d?). But it\u2019s not.</p><h3>6.3 Can we even think outside of a rational agent ontology?</h3><p>But I think there\u2019s also a deeper problem with this sort of money-pump argument: namely, that it\u2019s trying to speak in the language of some sort of \u201cincentive\u201d to make yourself coherent, but its central understanding of \u201cincentives\u201d arises from within a certain sort of familiar, rational-agent ontology: i.e., one where different agents run around optimizing for their utility functions. And it\u2019s precisely the question of whether to become such an agent that the \u201cincentives\u201d at stake are supposed to resolve.</p><p>That is: it feels like what the money-pump argument really wants to say is \u201cyou\u2019ll get more utility if you become coherent.\u201d But it keeps having to catch itself, and say something muddier (maybe: \u201cwhatever your utility function, you\u2019ll get more utility\u201d \u2013 but you don\u2019t have such a function!), because you\u2019re not an agent for whom \u201cutility\u201d is a thing (at least not in the standard way). So it doesn\u2019t, actually, know how to talk to you. And if it did, it wouldn\u2019t need to.</p><p>Or to put things another way: money-pump arguments try to shoe-horn \u201crationality mandates self-modifying to become an agent with a consistent utility function\u201d into an implication of that more familiar slogan, \u201crationality is about winning.\u201d But messing with your values (without the aim of maximizing for some other set of values) is actually very different from \u201cwinning.\u201d Indeed, it\u2019s relative to your values that \u201cwinning\u201d gets defined. And here anti-realist rationality leaves the terrain it knows how to orient towards. Give anti-realist rationality a goal, and it will roar into life. Ask it what goals to pursue, and it gets confused. \u201cWhatever goal would promote your goals to pursue?\u201d No, no, that\u2019s not it at all.</p><p>We see this same sort of tension, I think, in the appeal that many anti-realists want to make to your \u201c<a href=\"https://joecarlsmith.com/2021/06/21/on-the-limits-of-idealized-values\">values on reflection</a>,\u201d or your \u201c<a href=\"https://intelligence.org/files/CEV.pdf\">coherent extrapolated volition</a>,\u201d or whatever. At bottom, the core role of such appeals often seems to me something like: \u201cI know, I know, you don\u2019t have a utility function. But: this makes me confused. So I\u2019m going to say: yes you do. It\u2019s just, um, hiding. Like the tree inside a seed. We just need to compute it. Great: now back to the rational-agent ontology.\u201d</p><p>Oversimplifying: the problem is that anti-realist rationality (at least in its na\u00efve form) can only think about three things. One thing is like: single agents, optimizing for a utility function. Another thing is: game theory, between different agents with utility functions (e.g., stuff about conflict, bargaining, negotiation, etc). A third thing is: brute physical processes doing stuff (for example, colliding with each other).</p><p>Real, live, messy humans fall into some weird liminal space, between all of these. But there\u2019s a constant temptation to force them into one more familiar frame, or another. My kingdom for a model!</p><p>Of course, obviously these frames can be useful. We don\u2019t need to think of Bob as having a single consistent utility function to think that he messed up by stabbing that pencil into his eye on a dare. And this despite Bob\u2019s intransitive preferences about lizard stuff. So clearly, there is some way of thinking about real humans in these terms, without going too far astray.</p><p>But I think we should be wary of assuming that we know too much about we\u2019re doing, when we do this. And when we start asking questions from the perspective of an agent/physical system in the midst of creating/interpreting itself \u2013 questions like \u201cneed I make sure that my preferences are transitive?\u201d, and \u201cwhat are my preferences, anyway?\u201d \u2013 I think we should be especially cautious.</p><p>And I want to urge this same caution in trying to justify anti-realist ethics via a \u201cgame theory\u201d frame rather than a \u201csingle agent\u201d frame: i.e., in moving from \u201cdoing ethics/becoming coherent/whatever gets me more utility\u201d to \u201cdoing ethics/becoming coherent/whatever helps various mini-agents living inside me get along better, and thus get more utility\u201d (see e.g. my discussion of \u201c<a href=\"https://joecarlsmith.com/2022/12/23/on-sincerity#5-healthy-stapleclippers\">healthy staple-clipping</a>\u201d here). This sort of switch is popular amongst many anti-realist rationalists I know, and no wonder. It allows you to not-already-have-a-utility-function, while still thinking in terms you\u2019re comfortable with: namely, agents with utility functions. &nbsp;</p><p>And to be clear, I think this sort of multi-agent frame can be very useful, including in understanding ethical dilemmas like the ones discussed above. But if we take it too far, it mischaracterizes the \u201cparts\u201d in question: as I noted above, the relevant parts may lack the structure this model imputes to them. And while I think that \u201chelping your parts stop burning what they care about in unnecessary conflict\u201d is generally great, I don\u2019t think it captures my full sense of what makes ethics worth doing. In particular, I think leaning too heavily on that frame can end up yet another attempt to \u201cpass the buck\u201d of decision: to be a vehicle of some pre-existing set of optimization processes, rather than a person in your own right; to ask something else what to do, rather than to answer for yourself. More on this in my next essay.</p><p>OK, so those were two accounts of why anti-realists should do ethics that I don\u2019t see as fully adequate. In my <a href=\"https://forum.effectivealtruism.org/posts/djByAbm6ptkkmS9RS/seeing-more-whole\">next essay</a>, I\u2019ll try to get closer.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzubgdpf7tg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzubgdpf7tg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\"Part of,\" because it's quite a large topic, and I'm setting aside lots of issues -- and in particular, understanding what it means to \"make a mistake,\" if you're an anti-realist.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5m7rg4uh9sg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5m7rg4uh9sg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For some of my gripes with this picture, see <a href=\"https://joecarlsmith.com/2021/06/21/on-the-limits-of-idealized-values\">here</a>.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7or5wd5512\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7or5wd5512\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Granted, one needs to say something about what\u2019s going on with weakness of the will, here. But I expect to be able to do so.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3jvpi9uaxyd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3jvpi9uaxyd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I expect this is the source, for example, of \u201copen question\u201d stuff. Thus, suppose we try to say, with some anti-realists, that what you \u201cshould do\u201d is constituted by what you \u201cwould want to do in blah circumstances.\u201d And suppose I tell you that in such circumstances, you\u2019d want to kill babies. Does that settle the question of whether to kill babies? No. You\u2019ve still got to decide. The territory is one thing. Your response is another.</p><p>\u201cAh,\u201d say the realists. \u201cThat\u2019s because you weren\u2019t talking about the right sort of territory. There\u2019s some \u2018essentially practical\u2019 territory, which consists of \u2018should\u2019-y properties and facts, irreducibly different from the standard story. If I told you that according to this territory, you <i>should</i> kill babies, then this would settle the question of whether to do so.\u201d But&nbsp;<a href=\"https://www.lesswrong.com/posts/K9JSM7d7bLJguMxEp/the-moral-void\">would it</a>?</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0uut1b6aqov\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0uut1b6aqov\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See Chapter 2 of&nbsp;<a href=\"https://rucore.libraries.rutgers.edu/rutgers-lib/40469/PDF/1/play/\">Nick Beckstead\u2019s thesis</a> for a nice discussion of this picture.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhia4tty5fml\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhia4tty5fml\">^</a></strong></sup></span><div class=\"footnote-content\"><p>And&nbsp;<a href=\"https://joecarlsmith.com/2021/06/21/on-the-limits-of-idealized-values\">I\u2019m skeptical that appeals to \u201cidealization\u201d will be enough on their own</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyn0v25vdeem\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyn0v25vdeem\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Some people go further, and start fetishizing simplicity to some more extreme extent (see e.g. my discussion of \u201c<a href=\"https://joecarlsmith.com/2021/10/29/on-the-universal-distribution#vi-simplicity-realism\">simplicity realism</a>\u201d for some vibes in this broad vicinity). But again: in the context of anti-realist ethics, why such a fetish? And anyway, was that the problem with the slaveholders? That their values required too complex a description?</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnu8gmaxjkcm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefu8gmaxjkcm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>It does seem like ascribing goals/values to other people is importantly tied to predicting their behavior, but it also seems to license attributions of \u201cmistakes.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq0j632z9rb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq0j632z9rb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>OK, OK, I exaggerate. Total utilitarianism isn\u2019t actually about <i>aiming</i> at the lizards. Just: being willing to, if the time comes. (Which it won\u2019t!) (We hope.) (But why should we hope that?)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnk3q65dol9fr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefk3q65dol9fr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If necessary, we could formulate this inconsistency more precisely: i.e., by rephrasing (3) as \u201cIf (1) is true, then (2) is false,\u201d or some such.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqjqnum32edg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqjqnum32edg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If you don\u2019t like the \u201cmorality game,\u201d we can rephrase the example in terms of \u201cI have most reason to,\u201d or whatever. It loses some of its force, but the basic dynamic persists.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnocc96muzxcs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefocc96muzxcs\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Here I\u2019m borrowing from Michael Huemer\u2019s \u201c<a href=\"https://philpapers.org/archive/HUEIDO.pdf\">In Defense of Repugnance</a>,\u201d which I recommend to people interested in the Repugnant Conclusion.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fng20lm3uhezs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefg20lm3uhezs\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Here, the name derives from the idea that if, for a fixed population, you have the option to improve the total <i>and</i> the average <i>and</i> the equality of the distribution, then you\u2019d have to be actively <i>against</i> equality to pass on it (since presumably you like improvements to the total and the average, I guess?). I don\u2019t like this name; nor do I think this principle especially obvious, but let\u2019s go with it for now.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn8lq5hmnhz9j\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref8lq5hmnhz9j\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There's also some question of whether the transitivity of betterness is a conceptual truth; but I don't think that's the best terrain on which to have the debate.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4on7gcukxjg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4on7gcukxjg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Start with the Utopia. Then (per <i>Benign Addition</i>), make the lives of everyone in Utopia better, but also add, off in some distant part of the galaxy, a giant pit filled with a zillion zillion lizards, each living barely-<i>barely</i> worthwhile lives. Better for everyone, right? The utopians all agree: nice move. And the lizards, if you count them,&nbsp;<a href=\"https://joecarlsmith.com/2021/03/14/against-neutrality-about-creating-happy-lives#ii-gratitude\">would agree too</a>. But note that you don\u2019t even need to count them. That is, as long as you don\u2019t think that creating the lizards is actively <i>bad</i>, you can just be focusing on the fact that you\u2019re improving the lives of all the utopians, which seems hard to dislike, plus doing something either neutral or positive on the side (i.e., lizard farming).</p><p>(And note that if you say that it\u2019s actively bad to create slightly-happy lizards, you can quickly end up saying that it\u2019s betterto create beings with net negative lives than to create blah number of slightly-happy lizards, which also seems rough. And note, too, that to sufficiently advanced or happy beings, the best contemporary human lives might look lizard-like \u2013 barely conscious, vaguely pleasant but dismayingly dull, lacking in all but the most base goods. Do you want the aliens thinking of your life as bad to create, because too close to zero? If not, where and why does the line get drawn?)</p><p>But if there are <i>enough</i> lizards, then improving the lives of all the lizards by some small amount, plus bringing the lives of the utopians down to lizard-level, will end up mandated by <i>Non-anti-egalitarianism</i>. E.g., if there are 100 utopians all at welfare 100, plus a million lizards all at welfare 1, then putting everyone at 2 instead is a better total (2,000,200 vs. 100,010,000), a better average (2 vs. ~1), and a more equal distribution as well.&nbsp;</p><p>So by <i>Transitivity</i>, a sufficiently giant lizard farm is better than Utopia. (We can go further, here, and start adding in arbitrary Hells that get outweighed by the lizards. I\u2019m going to pass on that for now, but people who like the repugnant conclusion should expect to have to grapple with it.)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn093a47k4y1q\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref093a47k4y1q\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I think this is known as \u201cMcTaggart\u2019s conclusion,\u201d but can\u2019t easily find the reference.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn6rk806qkjb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn6rk806qkjb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Suppose you\u2019ve got a great, hundred-year life overall. Now suppose we could make every moment of those hundred years better, <i>plus</i> give you an extra billion years in some slightly-net-positive state \u2013 say, some kind of slightly-pleasant nap, or watching some kind of slightly-good TV show that you don\u2019t get bored of, or maybe you\u2019re transformed into a slightly-happy lizard for that time but somehow you\u2019re still yourself. Should you take the trade?&nbsp;</p><p>Hum, actually, I dunno. (Am I allowed to kill myself, somewhere in those billion years, if I decide that I want out? Will I still be in a position to make that decision? OK, OK, we\u2019re stipulating that I wouldn\u2019t want to, even from sort of idealized perspective or something. Do I trust that perspective? A billion years is a long time\u2026)</p><p>OK, but suppose you do it, on grounds analogous to <i>Benign Addition</i> (i.e., it improves your existing life, plus adds something stipulated to be non-bad). But now suppose you can improve all that nap/TV/lizard time by some small amount, at the one-time, low-low cost of giving up ~everything you loved in your original life and napping/TV-ing/lizard-ing full-time. Higher total! Higher average! (Do we care about equality across the moments of our own life? I don\u2019t; maybe the opposite.) Shouldn\u2019t you do it? Note, for example, that the first hundred years of your life, at this point, are a tiny portion of the overall experience \u2013 the equivalent of the first three seconds of your hundred-year thing. Mostly, you\u2019re a lizard. You had your great loves and joys back around the time&nbsp;<a href=\"https://en.wikipedia.org/wiki/Timeline_of_the_evolutionary_history_of_life\">multi-cellular life was evolving</a>, and you\u2019ve been a lizard ever since. Maybe you should focus on improving the lizard-ness? It\u2019s really the main event\u2026</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnro871dze6lt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefro871dze6lt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Thanks to Ketan Ramakrishnan for discussion of this point in a different context.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlmo9wdlf0hh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflmo9wdlf0hh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>These are sometimes called \u201cimpossibility results,\u201d but often, \u201cvalid arguments\u201d would do just as well.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqqy8ylyf89d\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqqy8ylyf89d\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Though Alexander is responding to a formulation of this dilemma that relies on a version of <i>Benign Addition</i> that doesn\u2019t improve the lives of existing people, and which is therefore, in my opinion, less forceful.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnna9viy6swo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefna9viy6swo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Suppose we say it\u2019s (slightly) bad to create someone whose life is positive, but below average. Then, at least if doing more bad things is more bad, and bads can trade off in standard ways, then you risk saying that it\u2019s better to create someone with a net-negative life than to create a sufficiently large number of people with net positive lives (a violation of what I think is sometimes called \u201cAnti-sadism\u201d). Alternatively, if you say it\u2019s neutral to create people with net positive but below-average lives, it sure looks like you ought to be accepting my version of <i>Benign Addition</i> above, given that it\u2019s good to improve the lives of the existing people, and the creation of the extra lives in neutral. Also, if it\u2019s neutral or bad to create net-positive life, then why is it OK to risk creating net-negative life when you e.g. have kids? Also, if it\u2019s neutral to create a somewhat happy but below-average child, and neutral to create a more happy but still-below-average child, but better to create the second than the first, how do you deal with the intransitivities this creates? Do you want to start trying to say fancy stuff about incommensurability? Also, any appeal to the \u201caverage\u201d is going to implicate \u201cEgyptology\u201d problems, where e.g. you can\u2019t decide whether to have kids until you know what the average welfare was like in ancient Egypt, what it\u2019s like on other planets, etc. In general, I recommend&nbsp;<a href=\"https://rucore.libraries.rutgers.edu/rutgers-lib/40469/PDF/1/play/,#page=86\">Chapter 4</a>&nbsp;of Nick Beckstead\u2019s thesis for discussion of the various choice-points in trying to say that potential people don\u2019t matter (or matter less). In Alexander\u2019s&nbsp;<a href=\"https://astralcodexten.substack.com/p/highlights-from-the-comments-on-the-909\">follow-up to the review,</a> he revises his position to \u201c\u201cmorality prohibits bringing below-zero-happiness people into existence, and says nothing at all about bringing new above-zero-happiness people into existence, we\u2019ll make decisions about those based on how we\u2019re feeling that day and how likely it is to lead to some terrible result down the line.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5frcstqgewf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5frcstqgewf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>\u201cBut in the end I am kind of a moral nonrealist who is playing at moral realism because it seems to help my intuitions be more coherent. If I ever discovered that my moral system requires me to torture as many people as possible, I would back off, realize something was wrong, and decide not to play the moral realism game in that particular way. This is what\u2019s happening with the repugnant conclusion.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnoxb1z8ut0gk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefoxb1z8ut0gk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>In particular, \u201cjust stay at World A\u201d doth not an adequate population ethic make (population ethics aspires to do much more than to rank world A, A+, and Z), he\u2019s going to want to hold on to other intuitive data-points as well; and Alexander doesn\u2019t say what he proposes to do if the intuitive satisfaction he seeks actually <i>is</i> impossible (indeed, there are various&nbsp;<a href=\"https://www.iffs.se/media/2264/an-impossibility-theorem-for-welfarist-axiologies-in-ep-2000.pdf\">proofs</a> in this vicinity, which Alexander is aware of, so I\u2019m a bit confused by his optimism here).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnp3ql4ae51y\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefp3ql4ae51y\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Alexander acknowledges that he is bound by the empirical implications of ethical principles he is committed to \u2013 for example, if he is committed to \u201csuffering is wrong,\u201d then he has to follow the evidence where it leads re: where there is suffering, including re: animals. That said, it\u2019s not actually clear why this would be the case, on anti-realism: in principle, you could revise your ethical principles once you see that they lead (in conjunction with plausible empirical views), to counter-intuitive places.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn66jbrrjig87\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref66jbrrjig87\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For what it\u2019s worth: while I think I\u2019m more sympathetic to the repugnant conclusion than the average philosopher (though see:&nbsp;<a href=\"https://www.cambridge.org/core/journals/utilitas/article/what-should-we-agree-on-about-the-repugnant-conclusion/EB52C686BAFEF490CE37043A0A3DD075\">these folks</a>), I\u2019m pretty open to denying these other premises as well (though transitivity is probably last-on-my-list to deny). Indeed: I suspect that, in general, once you start getting more open to bounded-utility-function vibes (which I think&nbsp;<a href=\"https://www.lesswrong.com/posts/hbmsW2k9DxED5Z4eJ/impossibility-results-for-unbounded-utilities\">we may need to get open to</a>), and to the idea that some parts of your value system might not be willing to sacrifice themselves arbitrarily for other parts (even if the other parts try to jack up the stakes arbitrarily), then the repugnant conclusion will start to look much more optional (and premises like <i>Non-Anti-Egalitarianism</i> much more suspect).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngiis622nzpj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgiis622nzpj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Or perhaps, some set of concrete philosophers. MacAskill\u2019s book, for example, has a real-world agenda.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnym3xjf1brun\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefym3xjf1brun\">^</a></strong></sup></span><div class=\"footnote-content\"><p>At least not for reasonable ways of spelling out what these two principles mean.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnu3r43w3zed8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefu3r43w3zed8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is the translation of the drowning child case, above, into policy talk.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngr22pa0q4gk\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgr22pa0q4gk\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Here the symbol \u201c\u227b\u201d means \u201cis preferred to\u201d or \u201cbetter than\u201d or some \u201cchosen over\u201d or some such.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsp5nrebo9y\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsp5nrebo9y\">^</a></strong></sup></span><div class=\"footnote-content\"><p>As an example of someone who seems to me to take this sort of argument fairly seriously, see Yudkowsky&nbsp;<a href=\"https://www.lesswrong.com/posts/RQpNHSiWaXTvDxt6R/coherent-decisions-imply-consistent-utilities\">here</a>.&nbsp;</p><p>Yudkowsky\u2019s piece is also tied to a related but distinct discourse about coherence, which has to do with whether philosophical arguments about coherence give us reason to expect that future, powerful AI systems will have whatever property in the vicinity of \u201cgoal-directedness\u201d and \u201cconsequentialism\u201d causes them (the worry goes) to seek power and maybe kill everyone. I associate this argument mostly closely with Yudkowsky (see&nbsp;<a href=\"https://arbital.com/p/optimized_agent_appears_coherent/\">here</a>,&nbsp;<a href=\"https://arbital.com/p/expected_utility_formalism/?l=7hh\">here</a>, and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/iGYTt3qvJFGppxJbk/ngo-and-yudkowsky-on-alignment-difficulty#3_4__Coherence_and_pivotal_acts\">here</a>; though see also section 2 of&nbsp;<a href=\"https://selfawaresystems.files.wordpress.com/2008/01/ai_drives_final.pdf\">Omohundro (2008)</a>), and there\u2019s been a lively debate about it over the years (see e.g.&nbsp;<a href=\"https://www.lesswrong.com/s/4dHMdK5TLN6xcqtyc/p/NxF5G6CJiof6cemTw\">Shah</a>,&nbsp;<a href=\"https://www.lesswrong.com/posts/vphFJzK3mWA4PJKAg/coherent-behaviour-in-the-real-world-is-an-incoherent\">Ngo</a>,&nbsp;<a href=\"https://www.lesswrong.com/posts/4K52SS7fm9mp5rMdX/three-ways-that-sufficiently-optimized-agents-appear\">Dai</a>,&nbsp;<a href=\"https://www.lesswrong.com/posts/DkcdXsP56g9kXyBdq/coherence-arguments-imply-a-force-for-goal-directed-behavior\">Grace</a>).&nbsp;</p><p>This particular argument is about a certain category of <i>empirical</i> prediction (though exactly what sort of empirical prediction isn\u2019t always clear, given that any particular pattern of real-world behavior can in principle be interpreted as maximizing the expectation of some utility function \u2013 see&nbsp;<a href=\"https://joecarlsmith.com/2022/03/16/on-expected-utility-part-1-skyscrapers-and-madmen#iv-is-being-an-eum-er-trivial\">here</a> for more). In the present essay, though, I\u2019m mostly interested in the <i>normative</i> question of whether we (and in particular, the anti-realists amongst us) <i>should</i> be coherent. You could think that the future slides us relentlessly towards a world full of coherent (omnicidal), expected-utility maximizers, forged from all the free power that coherence supposedly pays out, without thinking that you, yourself, should go with the flow (compare with&nbsp;<a href=\"https://slatestarcodex.com/2014/07/30/meditations-on-moloch/\">Moloch</a>, evolution, and so on). Perhaps you, in your incoherence, are a dying breed. But does that make it an ignoble tradition? Must you make yourself anew, out of metal and math, into some sort of sleeker and colder machine? Need you succumb to all this \u2026 <i>modernity?</i> Rage against the dying\u2026&nbsp;</p><p>Still, there are important connections between the empirical and normative debates. In particular, the empirical debate typically appeals to two sorts of processes that could reshape a system into a more coherent form: the system itself (or perhaps, some part of it, or some combination), and something outside the system (for example, a training process; a set of commercial incentives; etc). I won\u2019t be discussing \u201coutside the system\u201d forces very much here (though I\u2019d guess that this is where the strongest empirical arguments will come), but to the extent the system\u2019s own self-modification is supposed to be an empirical force for coherence, the normative question of whether coherence should look, from the perspective of the system itself, like an important target of self-modification becomes quite relevant. That is, one key thrust of the empirical argument is basically supposed to be \u201ccoherence is free power, the system itself will want free power, so the system itself will try to become more coherent.\u201d But if the \u201cfree power\u201d argument is weak, from a normative perspective, this sort of reasoning looks weaker as well. And indeed, to the extent that \u201coutside-the-system\u201d argument runs along similar lines \u2013 \u201ccoherence is free power, the outside-the-system process will want the system to be powerful, so the outside-the-system process will modify the system to be more coherent\u201d \u2013 this argument might look weaker as well.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnprhr0jt95u\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefprhr0jt95u\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Here I\u2019m adding in more philosophical content than my typical conversation about this, to include more of what happens in conversations with myself.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntr7fl2ct3b\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftr7fl2ct3b\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is similar to the strategy Alexander pursues in response to MacAskill. See also&nbsp;<a href=\"https://academic.oup.com/mind/article-abstract/126/504/975/2670265?redirectedFrom=fulltext&amp;login=true\">Ahmed (2017)</a> for a more full-scale defense.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn02c029at67ry\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref02c029at67ry\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See also Huemer: \u201cthere are no known cases in which one should make a particular choice to prevent oneself from later making a particular perfectly rational, informed, and correct choice, other than cases that depend on intransitivity.\u201d Using what I expect is Huemer\u2019s notion of \u201crational\u201d and \u201ccorrect,\u201d I think&nbsp;<a href=\"https://joecarlsmith.com/2021/08/27/can-you-control-the-past#ix-what-would-you-have-wanted-yourself-to-commit-to\">Parfit\u2019s Hitchhiker</a> would count as such a case.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3g7sr1is6lz\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3g7sr1is6lz\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is a case I heard Johann Frick give at a talk at NYU in spring of 2017. Note the similarity to the Mere Addition Paradox discussed above.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1sy5si7zut2\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1sy5si7zut2\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See the discussion of Transitivity&nbsp;<a href=\"https://joecarlsmith.com/2022/03/21/on-expected-utility-part-3-vnm-separability-and-more#ii-the-four-vnm-axioms\">here</a> for more.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl6sld45tprc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl6sld45tprc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This discussion is inspired by one in&nbsp;<a href=\"https://philarchive.org/rec/HUEIDO\">Huemer (2008)</a>, though he uses a different dominance principle.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn68vuymlcx8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref68vuymlcx8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Though: which <i>do</i> you want?</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fngck0it7t2mq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefgck0it7t2mq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Well, really, it\u2019s: Apples <i>if</i> my choice set is blah, Grapes <i>if</i> my choice set is blah, etc. But trying to pump some intuition re: confusion about what intransitive agents are \u201ctrying to do\u201d overall.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhedz0q3unua\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhedz0q3unua\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Is it, maybe, actively counter-productive in this respect, insofar as it requires you to endorse some counter-intuitive and therefore unpopular conclusion?</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2obn20k94bb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2obn20k94bb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The proof for the utility function version goes through the aggregation theorem in&nbsp;<a href=\"https://hceconomics.uchicago.edu/sites/default/files/pdf/events/Harsanyi_1955_JPE_v63_n4.pdf\">Harsanyi (1955)</a>.</p></div></li></ol>", "user": {"username": "Joe_Carlsmith"}}, {"_id": "ugsgFkLGShEjMqfBA", "title": "Advice for an alcoholic EA", "postedAt": "2023-02-16T09:19:39.811Z", "htmlBody": "<p><i>Edit 7/7/2023: Update here: https://forum.effectivealtruism.org/posts/F2MfbmRAiMx2PDhaD/some-observations-on-alcoholism</i></p><p>&nbsp;</p><p>Hi guys, as my username suggests, I\u2019m sorry to write this pseudonymously, but I don\u2019t know how public I want to be about my problems yet. So, the short version is that I\u2019m an alcoholic and I\u2019m an Effective Altruist, and I don\u2019t know exactly how much I should or shouldn\u2019t involve EA in my recovery efforts. I am vaguely aware that EA has mental health resources for struggling EAs, and I am struggling. I also don\u2019t know how many of them are relevant to substance abuse in particular. These are some of the considerations that I am conflicted about:</p><p>&nbsp;</p><p>Against involving EA more: Most of my problems are not directly related to EA, and I\u2019m not sure if I should be using EA resources for personal health problems unless I have some strong idea of how my problems relate to my involvement in EA. Maybe more to the point, I have access to other mental health resources, I am currently seeing someone at my school about this, and it feels like a waste of resources to involve EA in my problems if I don\u2019t need to. Additionally, there are many recent worries that EA is too insular, and this can lead to problems in how it handles personal issues. I share some of these worries, and although I don\u2019t distrust EA\u2019s mental health team, it seems like I should be cautious in over-involving EA in my personal life where it is unnecessary. If nothing else, it makes me more dependent on EA. Additionally as mentioned before, I just don\u2019t know if EA\u2019s mental health team deals with things like substance abuse so much as burn out.</p><p>&nbsp;</p><p>In favor: While my drinking is not deeply connected to my involvement in Effective Altruism, there are a number of things that have exacerbated my problem which are idiosyncratic to EA in a way that makes me uncomfortable talking to a normal therapist about it. I have still not mentioned anything EA related to my counselor so far despite our sessions thus far largely focusing on my \u201ctriggers\u201d for drinking. Related to this, I am not a huge fan of my current counselor\u2019s approach, there is a bunch of focus on things like what drives me to drink, when I buy more into a bias-based and chemical model of drinking, where mostly the issue with my \u201ctriggers\u201d is that I am unusually susceptible to finding lame excuses for myself. She also keeps recommending a bunch of other mental health resources, some of which seem quite tangentially related to my main problem. I think that a more focused approach would be valuable, and think that the type of triage and evidence-based thinking common in EA makes it more likely to be a space where the counseling I get will be, well, effective. I also don\u2019t want to speak too soon about resource problems, as there may be many services that aren\u2019t resource intensive, like groups sessions for EAs with substance abuse problems.</p><p>&nbsp;</p><p>Does anyone have any advice? Are there people here who have gone through a situation like this before, and have they involved EA\u2019s mental health resources in some way? If so what did they get out of it?</p>", "user": {"username": "anotherburneraccountsorry"}}, {"_id": "tBJCLBsSgxWfsDH89", "title": "What are our genetic engineering detection capabilities?", "postedAt": "2023-02-16T01:34:15.639Z", "htmlBody": "<h3>Why is genetic engineering detection important?</h3><p>We\u2019re pretty sure a GCBR-capable pathogen is going to be engineered, not natural. Broad genetic engineering detection (GED) capabilities would be an important form of agnostic surveillance.</p><p>It\u2019s particularly important that we be able to do metagenomic GED\u2013picking out the one engineered genome in a giant soup of non-engineered genomes, and doing this reasonably efficiently. For this reason, it\u2019s also important to focus on&nbsp;<i>computational&nbsp;</i>GED capabilities.</p><h3>What\u2019s been done so far?</h3><p>The bulk of relevant work in GED took place under the IARPA program&nbsp;<a href=\"https://www.iarpa.gov/research-programs/felix\"><u>FELIX</u></a> (<strong>F</strong>inding&nbsp;<strong>E</strong>ngineering&nbsp;<strong>L</strong>inked&nbsp;<strong>I</strong>ndicators), with many of the results so far unpublished.</p><p>Until FELIX, almost all other GED work was experimental, and focused on plants, apparently motivated by an EU regulation related to GMOs. None of this work is really relevant to GCBR surveillance, but here\u2019s a pretty good&nbsp;<a href=\"https://www.frontiersin.org/articles/10.3389/fpls.2019.00236/full\"><u>review</u></a> of it. There are a few&nbsp;<a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/gb-2008-9-3-r56\"><u>other</u></a>&nbsp;<a href=\"https://drops.dagstuhl.de/opus/volltexte/2019/11049/\"><u>relevant</u></a>&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S200103702100283X\"><u>papers</u></a>. But part of the motivation for FELIX was to establish a state of the art in GED capabilities, so the outcomes of FELIX are what matter.</p><h3>How did FELIX work?</h3><p>It was intentionally a pretty broad, performer-defined project. Performers decided for themselves what counted as genetic engineering, what priorities for detection were, how they would do it, and so on.&nbsp;</p><p>IARPA partnered with several national labs to make a total of four testing and evaluation (T&amp;E) datasets. The first few were custom tailored to each performer, but the last was a \u201cchallenge\u201d set, and everyone still in the program got the same one. The challenge set included some really wacky samples\u2013a very large plant genome, an organism with over 800 components of engineering, and an influenza virus with a single stop codon deleted.</p><h3>What were the outcomes of FELIX?&nbsp;</h3><p>FELIX resulted in four distinct computational GED systems, as well as several wet-lab protocols that are out of scope of this discussion. The computational systems were transitioned by IARPA to at least three government agencies:&nbsp;<a href=\"https://www.dtra.mil/\"><u>DTRA</u></a>,&nbsp;<a href=\"https://www.cbc.devcom.army.mil/\"><u>DEVCOM</u></a>, and&nbsp;<a href=\"https://www.dhs.gov/science-and-technology/national-biodefense-analysis-and-countermeasures-center\"><u>NBACC</u></a>.</p><p>The top FELIX performer, Ginkgo Bioworks, achieved an accuracy of 70% on IARPA\u2019s final test set. Most performers were able to reliably detect insertions of foreign gene content down to about 30-50 base pairs. For large insertions, multiple performers reached &gt;90% sensitivity and &gt;95% specificity. But on smaller insertions, substitutions, and deletions, performance was much worse.&nbsp;</p><h3>What were FELIX\u2019s limitations and challenges?</h3><p>Challenges with GED in general included:</p><ol><li><u>Bad natural data:</u> Most publicly available databases of \u2018natural\u2019 sequences, even reference databases, are hopelessly contaminated with engineered sequences, and need to be extensively curated before use.</li><li><u>Limited engineered data:</u> The best databases of engineered sequences are private. The best public databases of engineered sequences are quite biased, and lack contextual information. Between (1) and (2), advanced machine learning techniques have so far been of limited usefulness to GED.</li><li><u>Difficulty with complex genomes and subtle edits:</u> FELIX didn\u2019t primarily focus on metagenomic data, and many performers struggled with highly complex samples. Performance on subtle forms of engineering was also limited.</li></ol><p>Challenges with FELIX included a perceived sense of a moving target and limited collaboration between performers. The final systems were also very large and computationally intensive, causing some difficulties for the organizations to which FELIX systems have been transitioned.</p><h3>What can improve GED capabilities?</h3><ol><li><u>Curation of public natural data</u> to remove spurious actually-engineered sequences</li><li><u>Improved public engineered datasets,</u> and potentially the creation of a better language/format&nbsp;</li><li><u>Improved baseline characterization:&nbsp;</u>One way to improve the detection of anomalous sequences in eg: wastewater is to improve understanding of what is&nbsp;<i>not&nbsp;</i>anomalous</li><li><u>Improved metagenomic assembly algorithms:</u> Assembly algorithms have not kept pace with the increased volume of sequencing data. Improvements in these algorithms\u2019 error rates and computational performance could substantially improve any GED module that uses genome assembly, which is most of them.</li></ol><p><br>Proximally, however, the major limitation to any future GED work is a lack of a&nbsp;<u>high-quality, comprehensive test dataset.</u>&nbsp;</p><h3>I want to know more!</h3><p>Great!&nbsp;<a href=\"https://docs.google.com/document/d/1sU2kLcQiKScNumstgu4PcQ4uBoPNusOmqJCJCVUkDIo/edit?usp=sharing\"><u>Read the full report</u></a>. It includes an extensive technical discussion, full references, commentary, acknowledgements, as well as project ideas and resources. It is periodically updated.</p><h3>I don\u2019t have time to read all that, but I still want to know more</h3><p>Understandable.&nbsp;<a href=\"https://docs.google.com/document/d/1UfiWWU_l4p3dWnLikzEUhElxHeJsshpPfeDgrwj5teU/edit?usp=sharing\"><u>Read the 6-page memo</u></a> I put together for the Nucleic Acids Observatory team. You can also watch IARPA\u2019s&nbsp;<a href=\"https://www.youtube.com/watch?v=XQjR3mmFLhk\"><u>livestream</u></a> about the FELIX project, which includes details about two of the performers\u2019 projects.&nbsp;</p><h3>Wait, who are you, anyway?</h3><p>I\u2019m a full-time biosecurity researcher. I\u2019ve done a couple projects like this, and I\u2019m currently working on something else (solid state far-UV emission). I was asked to do this project by the NAO team at SecureBio in January 2022. All my views are my own, and do not represent the views of SecureBio, Sculpting Evolution, or my employer.&nbsp;</p><h3>Can I help?</h3><p>Yes!</p><p>There are lots of shovel-ready projects in GED. Someone with experience/interest in bioinformatics, metagenomics, synthetic biology, microbiology, virology, etc. would be the best fit. If you\u2019re interested in helping, please don\u2019t hesitate to&nbsp;<a href=\"mailto:j.vivian.belenky@outlook.com\"><u>contact me</u></a>.&nbsp;</p>", "user": {"username": "vbelenky"}}, {"_id": "nrmmiezSq24S4hi9g", "title": "Nobody Wants to Read Your Sh*t: my favorite book of writing advice, condensed for your convenience", "postedAt": "2023-02-15T23:28:54.276Z", "htmlBody": "<p><a href=\"https://www.amazon.com/Nobody-Wants-Read-Your-Sh-ebook/dp/B01GZ1TJBI\"><u>Nobody Wants to Read Your Sh*t</u></a> by Steven Pressfield is my favorite book of writing advice. Its core insight is expressed in the title. The best thing you can do for your writing is to internalize this deep truth.&nbsp;</p><p>Pressfield did it by writing ad copy. You can\u2019t avoid internalizing that nobody wants to read your shit when you\u2019re writing ads, which everybody hates and nobody ever wants to read. Maybe you don\u2019t have to go write ad copy to understand this; maybe you can just read the book, or just this post.</p><blockquote><p>When you understand that nobody wants to read your shit, your mind becomes powerfully concentrated. You begin to understand that writing/reading is, above all, a transaction. The reader donates his time and attention, which are supremely valuable commodities. In return, you the writer must give him something worthy of his gift to you.</p><p>When you understand that nobody wants to read your shit, you develop empathy. [...] You learn to ask yourself with every sentence and every phrase: Is this interesting? Is it fun or challenging or inventive? Am I giving the reader enough? Is she bored? Is she following where I want to lead her?</p></blockquote><p>What should you do about the fact that nobody wants to read your shit?</p><ol><li>Streamline your message. Be as clear, simple, and easy to understand as you possibly can.</li><li>Make it fun. Or sexy or interesting or scary or informative.&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/dAbs7w4J4iNm89DjP/why-fun-writing-can-save-lives-the-case-for-it-being-high\"><u>Fun writing saves lives.</u></a></li><li>Apply this insight to all forms of communication.</li></ol><p>Pressfield wrote this book primarily for fiction writers, who are at the most serious risk of forgetting that nobody wants to read their shit (source: am fiction writer). But the art of empathy applies to&nbsp;<i>all&nbsp;</i>communication, and so do many other elements of fiction:</p><blockquote><p>Nonfiction is fiction. If you want your factual history or memoir, your grant proposal or dissertation or TED talk to be powerful and engaging and to hold the reader and audience's attention, you must organize your material as if it were a story and as if it were fiction. [...]</p><p>What are the universal structural elements of all stories? Hook. Build. Payoff. This is the shape any story must take. A beginning that grabs the listener. A middle that escalates in tension, suspense, and excitement. And an ending that brings it all home with a bang. That's a novel, that's a play, that's a movie. That's a joke, that's a seduction, that's a military campaign. It's also your TED talk, your sales pitch, your Master's thesis, and the 890-page true saga of your great-great-grandmother's life.</p></blockquote><p>And your whitepaper, and your grant proposal, and your EA forum post. For this reason, I do recommend going out and grabbing this book, even though much of it concerns fiction. It only takes about an hour to read, because Pressfield knows we don\u2019t want to read his shit. Finally:</p><blockquote><p>All clients have one thing in common. They're in love with their product/company/service. In the ad biz, this is called Client's Disease. [...]</p><p>What the ad person understands that the client does not is that nobody gives a damn about the client or his product. [...]&nbsp;</p><p>The pros understand that nobody wants to read their shit. They will start from that premise and employ all their arts and all their skills to come up with some brilliant stroke that will cut through that indifference.</p></blockquote><p>The relevance of this quote to EA writing is left as an exercise to the reader.&nbsp;</p><p><br>&nbsp;</p>", "user": {"username": "vbelenky"}}, {"_id": "CFeRnEpJHvBerJ39h", "title": "Please don't throw your mind away", "postedAt": "2023-02-15T21:48:26.760Z", "htmlBody": "<h1>Dialogue</h1><p>[Warning: the following dialogue contains an incidental spoiler for <a href=\"https://meltingasphalt.com/music-in-human-evolution/\">\"Music in Human Evolution\" by Kevin Simler</a>. That post is short, good, and worth reading without spoilers, and this post will still be here if you come back later. It's also possible to get the point of this post by skipping the dialogue and reading the other sections.]</p><p>Pretty often, talking to someone who's arriving to the existential risk / AGI risk / longtermism cluster, I'll have a conversation like the following.</p><hr><p>Tsvi: \"So, what's been catching your eye about this stuff?\"</p><p>Arrival: \"I think I want to work on machine learning, and see if I can contribute to alignment that way.\"</p><p>T: \"What's something that got your interest in ML?\"</p><p>A: \"It seems like people think that deep learning might be on the final ramp up to AGI, so I should probably know how that stuff works, and I think I have a good chance of learning ML at least well enough to maybe contribute to a research project.\"</p><p>T: \"That makes sense. I guess I'm fairly skeptical of AGI coming very soon, compared to people around here, or at least I'm skeptical that most people have good reasons for believing that. Also I think it's pretty valuable to not cut yourself off from thinking about the whole alignment problem, whether or not you expect to work on an already-existing project. But what you're saying makes sense too. I'm curious though if there's something you were thinking about recently that just strikes you as fun, or like it's in the back of your mind a bit, even if you're not trying to think about it for some purpose.\"</p><p>A: \"Hm... Oh, I saw this video of an octopus doing a really weird swirly thing. <a href=\"https://www.youtube.com/watch?v=mnZ9wF-Bv1w&amp;t=247s\">Here, let me pull it up on my phone.</a>\"</p><p>T: \"Weird! Maybe it's cleaning itself, like a cat licking its fur? But it doesn't look like it's actually contacting itself that much.\"</p><p>A: \"I thought it might be a signaling display, like a mating dance, or for scaring off predators by looking like a big coordinated army. Like how humans might have scared off predators and scavenging competitors in the ancestral environment <a href=\"https://meltingasphalt.com/music-in-human-evolution/\">by singing and dancing in unison</a>.\"</p><p>T: \"A plausible hypothesis. Though it wouldn't be getting the benefit of being big, like a spread out group of humans.\"</p><p>A: \"Yeah. Anyway yeah I'm really into animal behavior. Haven't been thinking about that stuff recently though because I've been trying to start learning ML.\"</p><p>T: \"Ah, hm, uh... I'm probably maybe imagining things, but something about that is a bit worrying to me. It could make sense, consequentialist backchaining can be good, and diving in deep can be good, and while a lot of that research doesn't seem to me like a very hopeworthy approach, some well-informed people do. And I'm not saying not to do that stuff. But there's something that worries me about having your little curiosities squashed by the backchained goals. Like, I think there's something really good about just doing what's actually interesting to you, and I think it would be bad if you were to avoid putting a lot of energy into stuff that's caught your attention in a deep way, because that would tend to sacrifice a lot of important stuff that happens when you're exploring something out of a natural urge to investigate.\"</p><p>A: \"That took a bit of a turn. I'm not sure I know what you mean. You're saying I should just follow my passion, and not try to work towards some specific goal?\"</p><p>T: \"No, that's not it. More like, when I see someone coming to this social cluster concerned with existential risk and so on, I worry that they're going to get their mind eaten. Or, I worry that they'll think they're being told to throw their mind away. I'm trying to say, don't throw your mind away.\"</p><p>A: \"I... don't think I'm being told to throw my mind away?\"</p><p>T: \"Ok. The thing I'm saying might not apply much to you, I don't know. But there's a pattern that seems common to me around here, where people understandably feel a lot of urgency about the thing where the world might be destroyed, or at least they feel the urgency radiating off of everyone else around them, or at least, it seems as though everyone thinks that everyone ought to feel urgency. Then they sort of transmute that urgency, or the sense that they ought to be taking urgent action, into learning math or computer science urgently or urgently getting up to speed by reading a lot of blog posts about AI alignment. It's not a mistake to put a ton of effort into stuff like that, but doing that stuff out of urgency rather than out of interest tends to cause people to blot out other processes in themselves. Have you seen <a href=\"https://www.lesswrong.com/posts/pDzdb4smpzT3Lwbym/my-model-of-ea-burnout\">Logan's post on EA burnout</a>?\"</p><p>A: \"Yeah, I read that one.\"</p><p>T: \"Another piece of the picture is that there's an activity of a growing mind that I'm calling \"following your interest\" or \"fun\" or \"play\", or maybe I should say \"thinking hard\" or \"serious play\", and that activity is another thing that can get thrown under the bus. That activity is especially prone to be thrown under the bus, and it's especially bad to throw that activity under the bus. The activity of thinking hard as a result of play is especially prone to be thrown under the bus because it's a highly convergent subgoal, and so, like in Logan's post, it's one of those True Values that gets replaced by a Should Value. The activity of being drawn into playful thinking that becomes thinking hard is especially bad to throw under the bus because it's a central way that a mind grows. So if you're not giving yourself the space to sometimes be drawn into playful thinking, then you're missing out on deepening your understanding of stuff that you could have been playfully thinking hard with, and also you're letting that muscle atrophy.\"</p><p>A: \"Let me see if I've got what you're saying. There's two kinds of thinking, the True thinking and the Should thinking. And the Should thinking is worse than the True thinking, but people do the Should thinking?\"</p><p>T: \"Er, something like that... except that the phrase \"Should thinking\" is ambiguous here, and that's important. There's fake Should thinking, or let me say \"Urgent fake thinking\", which isn't really thinking, in that it doesn't take in and integrate much information, or notice contradictions, or deduce consequences of beliefs, or search for hypotheses and concepts, or make falsifiable predictions, or distill ideas. For example, rehearsing arguments that you read in a blog post, in response to rehearsed questions, usually isn't thinking, it's usually fake thinking.\"</p><p>A: \"Got it, got it.\"</p><p>T: \"Then there's Urgent real thinking, which is actually thinking, and has the structure: there's this way I want the world to go; how can I make the world go that way? Both backward chaining and forward chaining would be Urgent real thinking. It would also be Urgent real thinking to ask: What sort of scientific understanding would I have to have, in order to satisfy this subgoal of making the world go the way I want it to? And then doing that science. All of that activity has the structure of: I see how thinking about this stuff should help with getting the world to go a certain way. On the other hand, there's Playful thinking. Playful thinking doesn't have to have a justification like that; it's coming from a different source. So Urgent thinking has a tendency to be fake thinking, and even Urgent real thinking has a tendency to squash Playful thinking, and that these two things are connected.\"</p><p>A: \"Sorry, what do you even mean by Playful thinking?\"</p><p>T: \"Yeah, sorry, I should have been more clear. It's sort of subtle, or even sacred if you'll permit me to use that word, so it's hard to just define or, like, comprehensively describe. I know it as a phenomenon, something I encounter, without knowing what it really is and how it works and stuff. Anyway, it's something like: the thoughts that are led to exuberantly play themselves out in the natural course of their own time. This isn't supposed to be something alien and complicated, this is supposed to be a description of something that you're already intimately familiar with, even made out of, and that you definitely did when you were a kid. It's probably whatever was happening with you that led you to make hypotheses about what that octopus was doing.\"</p><p>A: \"Could you give an example of Playful thinking?\"</p><p>T: \"Gah, I really need to write this up as a blog post. Giving an example that I'm not really into at the moment seems kind of bad. But ok, so, [[goes on a rambling five-minute monologue that starts bored and boring, until visibly excited about some random thing like the origin of writing or the implausibility of animals with toxic flesh evolving or emergent modularity enabled by gene regulatory networks or the revision theory of truth or something; see the appendix for examples]]\"</p><p>A: \"Ok I think I have some idea of what you're talking about. But it sure sounds like what you're recommending is just inefficient? It seems like there's a bunch of smart people who have thought about alignment a lot more than I have, and they've said that there's all this stuff like linear algebra and probability theory that's useful for alignment, so it seems reasonable to learn that stuff. And I can learn it faster if I focus on it, instead of getting distracted, right? I think if I followed your advice I'd just goof off a lot.\"</p><p>T: \"I'm definitely not saying not to dive in deep, go fast, et cetera. I'm saying to not <i>not</i> also do non-Urgent thinking. Like, if you find yourself noodling or doodling, don't stop yourself due to the overwhelming urgency of reading the next page of the textbook. Even assuming that you're just trying to learn some list of material as fast as possible, playful thinking is still needed. There's a thing I like to do, where I'll stare at a mathematical object, and keep staring until it sort of reaches \"<a href=\"https://en.wikipedia.org/wiki/Semantic_satiation\">semantic satiation</a>\", and I can see it in a more naive way. And then I can tweak it, or look at it upside down, or combine it with something else, or ask why it has to be this way or that way rather than some other way. And this feels like playing, but I think it gives me the ideas more thoroughly, and then they're more useful to me in other contexts. So even from a backchaining point of view it ends up getting you something that a more functional goal, like \"can I do the exercises in the textbook\", doesn't always get you.\"</p><p>A: \"I'm a little confused. Before I thought you were saying that people should let themselves get nerdsniped more, instead of only thinking about stuff that's planning ahead to what they want to work on. Now it sounds like you're saying there's some other way to do math that's more useful for alignment work?\"</p><p>T: \"Those two recommendations are connected. Both of those recommendations are consequences of the following proposition: your mind knows a lot about what's worth thinking about that \"you\" don't know, in some sense. And you can't just get that stuff by asking your mind to tell you that stuff; you have to let your mind do its thing sometimes, without requiring a legible justification. The name \"nerdsniping\" doesn't seem quite right, though. \"<a href=\"https://xkcd.com/356/\">Nerdsniping</a>\" is where someone else crafts a puzzle that catches your attention. That can be fun and good, but to my taste, it tends to have a flavor of being a bit too cute or clever. I want to point instead at something that involves eternity and elegance. Things that have an eternity to them--e.g. Euclidean space, the invention of words, embryogenesis--are more likely to draw your mind along into thinking, and they do that without being clever or polished, because the natural world is just like that. Elegance has something to do with eternity, like how the architecture of a church evokes something that normal buildings don't, or how a clear mathematical definition doesn't have superfluous complications. Elegance is something that your mind instinctively tries to find or create.\"</p><p>A: \"Would elegance really help with learning things faster? It seems like, yeah, I could spend a long time getting a really good understanding of one thing, and that would have some benefits, like I could apply it faster. But it seems more important to get a pretty good understanding of a lot of things, so I can start combining ideas and understanding where the alignment field is currently at and thinking about how I can contribute.\"</p><p>T: \"An analogy here is that covering a lot of ground too quickly is like programming a project just using the built-ins you already know, using repetitive that hacks aren't easy to understand or modify later and that have interfaces enmeshed with other functions. You can go fast in the short term, but in the longer term, you're going to come back and have a hard time understanding why the code is the way it is, and you'll probably have to do a bunch of work refactoring things to separate concerns so that you can understand the code well enough to modify it efficiently. Playing with ideas is like learning the built-ins that are appropriate to the task at hand, and factoring your code so pieces are reusable, and taking the time to reduce terms that do stuff like have intermediate variable assignments that can be eliminated with no detriment, and factoring out repetitive pieces of code into a single generalized function.\"</p><p>A: \"Would people around here really disagree with that? I still don't feel like I'm being told to throw my mind away.\"</p><p>T: \"I don't know. Maybe most people would agree with what I'm saying, at least verbally, and even consider it obvious. But also empirically people tend to get the message that they should orient with some kind of urgency and all-consuming attention around existential risk. This could be mediated implicitly, through patterns of attention. Like, someone tells you \"Give yourself plenty of time for other pursuits, and make sure to <a href=\"https://www.lesswrong.com/posts/3XgYbghWruBMrPTAL/leave-a-line-of-retreat\">leave a line of retreat</a> from this existential risk stuff.\", which is good advice, and then also only get excited talking to you if you're describing your plan for how to prevent the world from being destroyed by AGI. Also, people arriving here with an attitude of <a href=\"https://tsvibt.blogspot.com/2022/09/dangers-of-deferrence.html\">deference</a>, e.g. studying textbooks that other people told you to study, are prone to be very attuned to that sort of message. Even if no one were sending those messages, some people would impute those messages to their social context. A pattern I have noticed in myself, for example, is: \"Oh, I'm feeling energetic at the moment, so now is a good time to sit down and actually think hard about alignment.\", instead of seeing what I actually feel like doing given permission to decide to do something for the fun of it, and this behavior pattern seems like a recipe for getting into an unhelpful rut.\"</p><p>A: \"Ok, I think I'm getting the picture. I'll make an effort to have more fun with math, and hopefully I'll learn it more deeply. That seems useful.\"</p><p>T: \"Ack.\"</p><p>A: \"Oh no. What did I do? :)\"</p><p>T: \"It's just that there's a danger in having fun with math because it helps you learn it more deeply, rather than because it's fun. Talking about how it helps you learn it more deeply is supposed to be a signpost, not always the main active justification. A signpost is a signal that speaks to you when you're in a certain mood, and tells you how and why to let yourself move into other moods. A signpost is tailored to the mood it's speaking to, so it speaks in the language of the mood that it's pointing away from, not in the language of the mood it's pointing the way towards. If you're in the mood of justifying everything in terms of how it helps decrease existential risk, then the justification \"having fun with math helps you learn it better\" might be compelling. But the result isn't supposed to be \"try really hard to <a href=\"https://twitter.com/TylerAlterman/status/1623759122834288641\">do what someone having fun would do</a>\" or \"try really hard to satisfy the requirement of having fun, in order to decrease X-risk\", it's supposed to be actually having fun. Actually having fun is a different mood from justifying everything in terms of X-risk. Imagine a six-year-old having fun; it's not because of X-risk.\"</p><p>A: \"How am I supposed to try to have fun, without trying to have fun?\"</p><p>T: \"Come home to the unique flavor of shattering the grand illusion. <a href=\"https://www.youtube.com/watch?v=p6UPS8HGCkA\">Come home to Simple Rick's.</a>\"</p><p>A: \"That was a terrible Southern accent.\"</p><p>T: \"Fair enough. Anyway, you might have been <a href=\"https://tsvibt.blogspot.com/2022/05/harms-and-possibilities-of-schooling.html\">trained in school</a> to falsify your preferences by pretending to have fun doing stupid activities. So you could try to do the opposite of everything you'd do in school. You could also try a \"Do Nothing\" meditation and see what happens. It might also help to think of having fun sort of like walking: you know how in some sense, and you even have an instinct for it; having fun, if you've forgotten, is more a question of letting those circuits--which don't require justification and just do what they do because that's what they do--letting those circuits do what they do, and enjoying that those circuits do what they do. Basically the main thing here is just: there's a thing called your mind, your mind likes to play seriously, and consider not preventing your mind from playing seriously.\"</p><p>A: \"Got it.\"</p><p>T: \"The end.\"</p><h1>Synopsis</h1><ul><li>Your mind wants to play. Stopping your mind from playing is throwing your mind away.</li><li>Please do not throw your mind away.</li><li>Please do not tell other people to throw their mind away.</li><li>Please do not subtly hint with oblique comments and body-language that people shouldn't have poured energy into things that you don't see the benefit of. This is in conflict with coordinating around reducing existential risk. How to deal with this conflict?</li><li>If you don't know how to let your mind play, try going for a long walk. Don't look at electronics. Don't have managerial duties. Stare at objects without any particular goal. It may or may not happen that some thing jumps out as anomalous (not the same as other things), unexpected, interesting, beautiful, relatable. If so, keep staring, as long as you like. If you found yourself staring for a while, you may have felt a shift. For example, I sometimes notice a shift from a background that was relatively hazy/deadened/dull, to a sense that my surroundings are sharp/fertile/curious. If you felt some shift, you could later compare how you engage with more serious things, to notice when and whether your engagement takes on a similar quality.</li></ul><h1>Highly theoretical justifications for having fun</h1><p>Throwing your mind away makes life worse for you, and you should be wary of doing things that make life worse for you. This is the blatantly obvious central thing here.</p><p>Interrupting playful thinking causes learned helplessness about playful thinking. (Imagine knocking over a toddler's blocks whenever they are stacked three-high or more.) On the other hand, giving yourself to playful thinking makes it so that playful thinking expects to be given you, so playful thinking disposes itself to play.</p><p>Playful thinking puts ideas into a form where they're more ready to combine deeply with other ideas.</p><p>Playful thinking indexes ideas more thoroughly, so that they come up when helpful and in helpful ways.</p><p>Your senses of taste, interest, fun, and elegance know [stuff about what's worth thinking about] that isn't known by you or by those whose advice you take. Analogously, your sense of beautiful code knows stuff about good programming that you don't know.</p><p>Play is non-specific practice. It accesses canonical and practiceworthy structure.</p><p>Playful thinking sets up questions in your brain that you wouldn't have known how to set up just by explicitly trying to set up questions. A question is a record of a struggle to deal with some context. These questions, like the dozen problems Feynman carries around with him, set you up to connect with new ideas more thoroughly.</p><p>Play exercises the ability of setting up problem contexts and discerning interesting problem contexts. This ability is extremely under-exercised by more deferential ways of learning, and is especially needed in pre-paradigm fields.</p><p>Play is a long-term investment in deep understanding.</p><p>Many people are far from maximally exerting themselves. Someone who is far from maximally exerting themselves can't have very large and fundamental tradeoffs between exerting themselves towards one or another purpose, such as having fun vs. doing alignment research. Instead of trading off between two activities, they could exert themselves more if they had more exertion-worthy activities available. Playfully thinking hard is a suprisingly exertion-worthy activity.</p><p>Being initially drawn into playful thinking correlates with and grows into being drawn further into more elaborated playful thinking, which is continuous with any real thinking. Your thoughts about strategy, the alignment problem, or whatever important thing, can inform and be informed by your taste in what to playfully think about, without having to be the justification for your playful thinking.</p><p>Many ideas are provisional: they have yet to be fully grasped, made explicit, connected to what they should be connected to, had all their components implemented, carved at the joints, made available for use, indexed. Many important ideas are provisional. Playing with provisional ideas helps nurture them.</p><p>Your sense of fun usefully decorrelates you from others, leading you to do computations that others aren't doing, which greatly improves humanity's portfolio of computations.</p><p>You're more exercising <a href=\"https://en.wiktionary.org/wiki/%E1%BC%80%CF%81%CE%B5%CF%84%CE%AE\">\u1f00\u03c1\u03b5\u03c4\u03ae</a> (\"excellence\", cognate to \"rational\") when doing things that your mind is drawn to do by its own internal criteria.</p><p>Your sense of fun decorrelates you from brain worms / egregores / <a href=\"https://tsvibt.blogspot.com/2022/09/dangers-of-deferrence.html\">systems of deference</a>, avoiding the dangers of those.</p><p>Brain worms / egregores / systems of deference that would punish you for devoting energy to playful thinking, are likely to be ineffective at achieving worthwhile goals, among other things because they cut off the natural influx of creativity that solves novel problems. A social coordination point can appear powerful just by being predominant, and therefore appears desirable to join, without actually being worthwhile to join.</p><p>Requiring that things be explicitly justified in terms of consequences forces a dichotomy: if you want to do something for reasons other than explicit justifications in terms of consequences, then you either have to lie about its explicit consequences, or you have to not do the thing. Both options are bad.</p><p>Intensity in the face of existential risk is appropriate. To enable intensity in the face of existential risk, don't require yourself to throw your mind away in order to be intense.</p><h1>Appendix: What is this \"fun\" you speak of?</h1><h2>What's a circle?</h2><p>Take a smooth closed curve C in the plane. These conditions are equivalent:</p><ul><li>There is a point p such that all points on C are equidistant from p.</li><li>C has constant curvature.</li><li>(If C bounds a disc) C bounds the maximum area that's possible to bound with a curve of the same length as C.</li><li>The group of isometries of the plane that maps C to itself is a nontrivial connected compact topological group.</li></ul><p>These conditions all define a circle in the plane. But what happens if instead of a plane, we look at some other manifold? See <a href=\"https://tsvibt.blogspot.com/2022/05/expanding-domain-of-discourse-reveals.html\">here</a> for some disussion.</p><h2>Hookwave</h2><p>It's 0400 and it's raining heavily. Tributaries swell along curbs, then clatter down drains to join the subterranean sewerriver. In the middle of one street, the downward slope perpendicularly away from the curb exceeds the slope along the curb, sending the curb's tributary across to the other side of the streed. Hundreds of criss-crossing lines checker the flowing sheet of water that is spread out over the concrete. How does that make sense? It looks as though water is flowing in two skewed directions, one sheet flowing over or through the other sheet. Are these just wakes from the bumps in the asphalt? But it really looks like the water is flowing in both skew directions. Maybe all the little wakes are making ripples, so there are waves traveling in both directions?</p><p>In another curb's rivulet, there's an oddly-shaped wave. Most curb rivulets have lots of little wakes in them from bumps in the asphalt or from influxes reflecting off the curb. These little wakes usually curve so they join with the flow: they start off at some angle away from the boundary of the rivulet towards the center of the rivulet, and then curve to be more parallel with the direction of flow. But not this hookwave:</p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1676269306/mirroredImages/xigCwtH9TiEiLckXB/jd6oxvn0mskvlqlvzfys.png\" alt=\"\"></p><p>It's curving off flowward and to the right, so that its angle with the direction of flow increases flowward:</p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1676269306/mirroredImages/xigCwtH9TiEiLckXB/ravsh6i2anynbnfqsnjk.png\" alt=\"\"></p><p>Why is it like that? Why is this wake different from all other wakes? This one and a few other hookwaves always come right after a divot in the concrete against the curb. If a foot (waterproofed, dry-socked) is placed just upstream of the divot, blocking the half of the rivulet that's further from the curb, then the hookwave straightens out a bit, like a more usual wake, contra the intuition that the flowing water should be \"sweeping back\" the hookwave. Does the flowing water instead \"pile up\" to form the hook?</p><h2>Random smooth paths</h2><p>This cemetary is large and round, so it has a network of internal paths. At each intersection there are 2 or 3, or occasionally 4 or 5 directions to continue in, \"somewhat forwardly\", without doubling straight back. Choosing randomly would follow a sort of constrained random walk: there's a kind of inertial or smoothness condition, where random turns are allowed but doubling back is disallowed. What sort of random walk is that? Staying on the paths and keeping off the grass reduces the random walk to a random (asymmetric) walk on a(nother) graph.</p><p>What if the grass isn't off limits, and there are choices at every moment which way to turn, rather than just at intersections? The <a href=\"https://en.wikipedia.org/wiki/Wiener_process\">Wiener process</a> (which describes Brownian motion) could describe this kind of walk. But a Wiener process is infinitely jagged; the wheel gets turned arbitrarily sharply, arbitrarily densely in time. It's very far from smooth.</p><p>What if the path has to be an analytic function (comes from a Taylor series)? Then it's smooth, but it's also determined everywhere if it's determined on a small patch. So it's not intuitively random. A random path should have some independence between changes that happen at different points.</p><p>What about smooth paths? Smooth paths are nice, in that they at least have all derivatives at all points, and aren't determined by local patches, and can be stitched together (if given a bit of breathing room). Is there a nice notion of a smooth random walk? More detail <a href=\"https://mathoverflow.net/questions/401977/what-are-the-local-degrees-of-freedom-in-the-space-of-smooth-functions\">here</a>.</p><h2>Mandala</h2><p>Lying on the grass between the sidewalk and an Oakland street:</p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1676269306/mirroredImages/xigCwtH9TiEiLckXB/curzriqpzx5jejke0s4r.jpg\" alt=\"\"></p><p>What sort of symmetry does this mandala have? The purple petals around the outer rim have sixteenfold rotational symmetry (and we could allow reflections, giving&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"D_{16}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">D</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">16</span></span></span></span></span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>). The purple petals near the center have eightfold rotational symmetry. Centerward of the innermore purple petals, we have 28-fold, 24-fold, and 32-fold symmetry, and then the red band has a full circle's symmetry. The innermost ring has 12-fold symmetry. So as a whole the mandala has 4-fold symmetry.</p><p>Abstractly, there's an embedding of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\mathbb{Z}_4\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">Z</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">4</span></span></span></span></span></span></span></span></span>&nbsp;into each of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\mathbb{Z}_{16}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">Z</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">16</span></span></span></span></span></span></span></span></span></span></span>,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\mathbb{Z}_{28}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">Z</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">28</span></span></span></span></span></span></span></span></span></span></span>,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\mathbb{Z}_{24}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">Z</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">24</span></span></span></span></span></span></span></span></span></span></span>,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\mathbb{Z}_{32}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">Z</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">32</span></span></span></span></span></span></span></span></span></span></span>, and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\mathbb{Z}_{12}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">Z</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">12</span></span></span></span></span></span></span></span></span></span></span>, and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\mathbb{Z}_4\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">Z</span></span></span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">4</span></span></span></span></span></span></span></span></span>&nbsp;is the biggest group that embeds into all those groups. That's just a fancy way of saying that four is the greatest common divisor of all those numbers. We could also say that there's an embedding of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"D_4\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">D</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">4</span></span></span></span></span></span></span></span></span>&nbsp;into each of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"D_{16}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">D</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">16</span></span></span></span></span></span></span></span></span></span></span>,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"D_{28}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">D</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">28</span></span></span></span></span></span></span></span></span></span></span>,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"D_{24}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">D</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">24</span></span></span></span></span></span></span></span></span></span></span>,&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"D_{32}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">D</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">32</span></span></span></span></span></span></span></span></span></span></span>, and&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"D_{12}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">D</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">12</span></span></span></span></span></span></span></span></span></span></span>.</p><p>Given some set of groups, is there always a unique greatest common subgroup? What are greatest common subgroups for some pairs of finite groups? Given some groups&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"G_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">G</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>&nbsp;and a greatest common subgroup&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"G\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">G</span></span></span></span></span></span></span>, is there always a corresponding \"mandala\"--a geometric figure that's a union&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\bigcup_i F_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-munderover\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.519em; padding-bottom: 0.519em;\">\u22c3</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.438em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>&nbsp;of figures&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>&nbsp;such that the symmetry group of each&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"F_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>&nbsp;is exactly&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"G_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">G</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>&nbsp;and the symmetry group of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\bigcup_i F_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-munderover\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.519em; padding-bottom: 0.519em;\">\u22c3</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.438em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.106em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.106em;\">F</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>&nbsp;is exactly&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"G\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">G</span></span></span></span></span></span></span>?</p><h2>Water flowing uphill</h2><p>The slope of this segment of the street is by all passerby accounts, eh, hard to tell but a bit uphill, coming from this direction. It has rained an hour ago. In the narrow channel between the curb and the retaining wall, there's water flowing. Which direction is it flowing? The water is flowing uphill. What.</p><h2>Guitar chamber</h2><p>The hollow chamber of an acoustic guitar makes the sound of a plucked string fuller. And louder? Does it? It's something about \"resonance\" and \"interference\". But how could the chamber make the sound louder? Isn't all the energy that's bleeding off from the vibrating string already being emitted as sound waves?</p><p>Maybe it's that the sound waves at the wavelengths that fit in the chamber don't interfere with themselves. But how would that make them louder? Do they \"build up\" over a few milliseconds? But that doesn't make them louder, the sound waves are still leaving the guitar pretty much the whole time while the string is picked, they're not built up and then released in a loud burst.</p><p>Maybe the chamber just redirects the sound forward, so it's all going in one direction, and it's louder in that direction but quieter behind the guitar?</p><p>Maybe the chamber isn't making the sound louder by adding energy, but just putting the soundwaves at different frequencies all into one frequency. That could make it sound louder, maybe? Why exactly would that sound louder? How does it put the energy from one frequency into another frequency? And also, how does whistling work? Or speaking, or howling wind?</p><h2>Groups, but without closure</h2><p>A <a href=\"https://en.wikipedia.org/wiki/Group_(mathematics)\">group</a> is a set of transformations that has an identity transformation that doesn't do anything, inverse transformations that undo transformations, and composite transformations that are the result of doing one transformation followed by doing another transformation.</p><p>What happens if we tweak this concept to see how it works? What if there isn't an identity transformation? Why, that's just an inverse semigroup, of course. Mathematicians have got names for all those sorts of things:</p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1676269306/mirroredImages/xigCwtH9TiEiLckXB/pxfu1kse9kdscicdpudb.png\" alt=\"\"></p><p>(From <a href=\"https://en.wikipedia.org/wiki/Semigroup\">Wikipedia</a>)</p><p>But what about closure under composition? It makes sense that transformations are closed under composition: if you do one transformation and then do another, you've done <i>some</i> kind of transformation. So whatever you've done, that's the transformation that's the composition of the two component transformations.</p><p>But what if there were two transformations that you could do individually, but that you couldn't do one after the other? For example, look at the set of transformations of the form: I pick up this heavy box and move it to another spot on the ground. There's an identity transformation (do nothing), and there's usually an inverse transformation (if I moved the box 10 feet northwest, now I move it 10 feet southeast, and now it's as if I've done nothing). But what if I get too tired of moving the box after moving it a mile? Then I can move the box 1 mile northwest, but I can't do that transformation twice.</p><p>So what we have is some kind of \"almost a group\". What do these things look like? What are some interesting things that can happen with \"almost a group\"s that can't happen with groups? Is there a nice classification of them? (Compare <a href=\"https://en.wikipedia.org/wiki/Approximate_group\">approximate groups</a>.)</p><h2>Wet wall</h2><p>Sometimes walls are wet.</p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1676269306/mirroredImages/xigCwtH9TiEiLckXB/d37z8rxacg8esmclpgnz.png\" alt=\"\"> <img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1676269306/mirroredImages/xigCwtH9TiEiLckXB/vvzimttbclzxp27nup1o.png\" alt=\"\"> <img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1676269306/mirroredImages/xigCwtH9TiEiLckXB/jouesudvl5m5oumlazvw.png\" alt=\"\"> <img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1676268829/mirroredImages/xigCwtH9TiEiLckXB/z8shedkunplwrpyqj3t7.jpg\" alt=\"\"></p><p>Sometimes they're wet shaped like a V, and sometimes like an A. Why, exactly?</p><p><i>Thanks to Justis Mills for feedback on this post.</i></p>", "user": {"username": "TsviBT"}}, {"_id": "yiTcjSWuy7ptTb5XS", "title": "What is it like doing AI safety work?", "postedAt": "2023-02-21T19:24:18.653Z", "htmlBody": "<p>How do you know if you\u2019ll like AI safety work? What\u2019s the day-to-day work like? What are the best parts of the job? What are the worst?</p><p>To better answer these questions, we talked to ten AI safety researchers in a variety of organizations, roles, and subfields. If you\u2019re interested in getting into AI safety research, we hope this helps you be better informed about what pursuing a career in the field might entail.</p><p>The first section is about what people do day-to-day and the second section describes each person\u2019s favorite and least favorite aspects of the job.&nbsp;</p><p><i>Of note, the people we talked with are not a random sample of AI safety researchers, and it is also important to consider the effects of survivorship bias. However, we still think it's useful and informative to hear about their day-to-day lives and what they love and hate about their jobs.</i></p><p><i>Also, these interviews were done about a year ago, so may no longer represent what the researchers are currently doing.&nbsp;</i></p><p><i>Reminder that you can&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/JTZTBienqWEAjGDRv/listen-to-more-ea-content-with-the-nonlinear-library\"><i><strong>listen to LessWrong and EA Forum posts</strong></i></a><i> like this on your podcast player using the&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/JTZTBienqWEAjGDRv/listen-to-more-ea-content-with-the-nonlinear-library\"><i>Nonlinear Library</i></a><i>.</i></p><p><i>This post is part of a project I\u2019ve been working on at&nbsp;</i><a href=\"http://nonlinear.org/\"><i>Nonlinear</i></a><i>. You can see the&nbsp;</i><a href=\"https://forum.effectivealtruism.org/posts/PH2pqsqgXQkfCdmkv/how-to-become-an-ai-safety-researcher\"><i><u>first part of the project here</u></i></a><i> where I explain the different ways people got into the field.&nbsp;</i></p><h1>&nbsp;</h1><h1>What do people do all day?</h1><h2><br><strong>John Wentworth</strong></h2><p>John describes a few different categories of days.</p><ul><li>He sometimes spends a day writing a post; this usually takes about a day if all the ideas are developed already.</li><li>He might spend a day responding to comments on posts or talking to people about ideas. This can be a bit of a chore but is also necessary and useful.</li><li>He might spend his day doing theoretical work. For example, if he\u2019s stuck on a particular problem, he can spend a day working with a notebook or on a whiteboard. This means going over ideas, trying out formulas and setups, and trying to make progress on a particular problem.&nbsp;</li></ul><p>Over the past month he\u2019s started working with David Lorell. David\u2019s a more active version of the programmer's \"rubber duck\". As John\u2019s thinking through the math on a whiteboard, he\u2019ll explain to David what's going on. David will ask for clarifications, examples, how things tie into the bigger picture, why did/didn't X work, etc.</p><p>John estimates that this has increased his productivity at theoretical work by a factor somewhere between 2 and 5.&nbsp;</p><p>&nbsp;</p><h2><strong>Ondrej Bajgar</strong></h2><p>Ondrej starts the day by cycling to the office. He has breakfast there and tries to spend as much time as possible at a whiteboard away from his computer. He tries to get into a deep-thinking mindset, where there aren\u2019t all the answers easily available. Ideally, mornings are completely free of meetings and reserved for this deep-thinking work.&nbsp;</p><p>Deep thinking involves a lot of zooming in and out, working on sub-goals while periodically zooming out to check on the higher-level goal every half hour. He switches between trying to make progress and reflecting on how this is actually going. This is to avoid getting derailed on something unproductive but cognitively demanding.&nbsp;</p><p>Once an idea is mostly formed, he\u2019ll try to implement things in code. Sometimes seeing things in action can make you see new things you wouldn\u2019t get from just the theory. But he also says that it\u2019s important to not get caught in the trap of writing code, which can feel fun and feel productive even when it isn\u2019t that useful.&nbsp;</p><p>&nbsp;</p><h2><strong>Scott Emmons</strong></h2><p>Scott talked about a few different categories of day-to-day work:</p><ul><li>Research, which involves brainstorming, programming, writing &amp; communicating, and collaborating with people</li><li>Reading papers to stay up-to-date with the literature</li><li>Administrative work</li><li>Service, such as giving advice to undergrads, talking about AI safety, and reviewing other people\u2019s papers</li></ul><p>An example of a typical day might look like this: he\u2019ll start work in the morning by reading papers because this is his best time for getting into deep work. This is followed by a research meeting with some collaborators and answering some emails. After that, he has the CHAI weekly lab meeting, where someone presents their research. After this he might spend a few hours coding on an existing project, followed by some admin work.&nbsp;</p><p>&nbsp;</p><h2><strong>Alex Turner</strong></h2><p>Alex has historically specialized in whiteboard-centric math and theory work but has pivoted to empirical and mentoring work (coding, experiment design, frontend, management).&nbsp;</p><p>He spends most days focused on specific questions. For example, by what processes might a diamond-motivated AI improve itself? What precautions might it take, given such-and-such resources?&nbsp;</p><p>He\u2019ll occasionally zoom out to check that he's still focusing on questions he expects to most increase the probability of alignment success.&nbsp;</p><p>On empirical research days, he spends about six hours coding, one reading, and one to two in conversations. On theory days, it's rather evenly mixed between reading, writing, and thinking. He will periodically spend a few days to weeks communicating large bundles of ideas and results, whether in blog post or paper format.<br>&nbsp;</p><h2><strong>William Saunders</strong></h2><p>OpenAI, where William works, has three days a week where there are meetings and two days a week where they try to avoid meetings. William\u2019s day starts by getting into the office, checking Slack to see how various projects are going, and leaving comments if he has useful ideas for any of them. If it\u2019s a meeting day, he will usually have 1 or 2 meetings with people working on a project and sometimes other people who are interested in talking about the higher-level ideas. There will be discussions about what experiments to run next, or whether any of the code needs to be refactored.&nbsp;</p><p>There are two types of experiments that he works on:</p><ul><li>Experiments where data needs to be collected from human contractors. In these cases, William needs to decide, and so it\u2019s a matter of determining how to collect the data and build an interface for them to use. This involves both frontend and backend development, as well as monitoring quality to make sure contractors aren\u2019t misunderstanding things.&nbsp;</li><li>Experiments where the data has already been collected. In these cases, his job is to change algorithms and hyperparameters to improve performance<br>&nbsp;</li></ul><h2><strong>Ethan Perez</strong></h2><p>Ethan describes his projects as having three phases: brainstorming, implementation, and writing up. The brainstorming phase usually lasts about a month and is all about working out what to do next. This involves a lot of reading, taking notes, and talking with people. Each week he\u2019ll have a meeting with his advisor about ideas for directions that seem promising to pursue and get feedback.&nbsp;</p><p>Once they\u2019ve settled on a project, he\u2019ll move on to the \u2018implementation\u2019 phase, which starts with figuring out how to get things to work in practice. Then it's a matter of putting the ideas into code and running experiments on a GPU cluster, getting feedback from these experiments, and deciding what to run next. During this process, he\u2019ll have weekly meetings with his advisor to talk about which research directions he should continue to pursue. This implementation phase takes around one to six months, ending when he either gets something to work or decides to shift directions.&nbsp;</p><p>Once something works, he\u2019ll take about a month to run the final experiments, write it up in a paper, put it on arXiv, and submit it to a conference.</p><p>&nbsp;</p><h2><strong>Justin Shovelain</strong></h2><p>Justin runs&nbsp;<a href=\"https://www.convergenceanalysis.org/\"><u>Convergence</u></a>, an organization which does work in AI and x-risk strategy. A normal week usually involves:</p><ul><li>1 day of reading</li><li>1 day of operations and logistics; emails, grants, paperwork</li><li>1 to 2 days of discussions with people; advising, mentoring, or discussing a topic with people</li><li>1 to 1.5 days of solo thinking</li><li>Half a day of thinking with his colleague in a discussion format</li></ul><p>Days are usually devoted to one activity rather than splitting them up too much, but sometimes this isn\u2019t possible when working with other people, especially in different time zones. Usually he spends the start of the day doing deep work and then has calls later in the day.&nbsp;</p><p>&nbsp;</p><h2><strong>Stephen Casper</strong></h2><p>Stephen usually has at least a couple of things to work on at once, so that when one task gets boring, he can switch to another. He usually works from the offices at MIT, MAIA, and HAIST, bouncing between various tasks including, for example:</p><ul><li>Reading papers</li><li>Drafting papers or posts</li><li>Checking on experiments</li><li>Writing and debugging code</li></ul><p>As well as the standard work, Stephen has the habit of reading and taking notes on at least one paper a day. This is to explore the literature more widely, so he tries to choose papers that aren\u2019t too related to what he would have read anyway. You can read more about&nbsp;<a href=\"https://www.lesswrong.com/posts/NENrmKWoEzXXmQjhr/a-daily-routine-i-do-for-my-ai-safety-research-work\"><u>his daily routine here.</u></a></p><p>&nbsp;</p><h2><strong>Ramana Kumar</strong></h2><p>At DeepMind the work can be quite varied and things can change a lot in 6 months. Ramana usually works between 10 am - 6 pm and tries not to think too much about work outside of this; although this isn\u2019t always possible. With creative work, you can\u2019t always say, \u201cI\u2019m going to be working now, and I\u2019m not going to be working now\u201d. Sometimes you just have to follow your mood.</p><p>About half of Ramana\u2019swork time is spent on tasks that can be done alone or by closely collaborating with someone else. These include:&nbsp;</p><ul><li>Reading things like papers, books, and the Alignment Forum</li><li>Technical coding work, debugging, and making figures. This type of work is especially fun to do with someone else</li><li>Writing papers, outlines, and presentations</li></ul><p>The other half of the time is spent with larger groups, for example:</p><ul><li>Meetings or long collaboration days to talk about research priorities and directions</li><li>Project discussions to talk about what people have been doing, problems, and where to go next</li><li>Reading groups</li></ul><p>&nbsp;</p><h2><strong>Dan Hendrycks</strong></h2><p><i>N.B.: this interview was done in early 2022 before Dan had finished his PhD.&nbsp;</i></p><p>Dan has an exceptional academic and publication record, and as such (as a PhD student) now spends a lot of his time managing other people. He doesn\u2019t spend very much time coding himself; instead, he manages other people, which he\u2019s been doing since the third year of his undergraduate degree. This involves a lot of meetings with people and thinking about ideas for projects.&nbsp;</p><p>Part of his management work involves applying some pressure and motivating his colleagues to make sure that projects actually get done, especially applying \u201cstart-up torque\u201d to get projects started in the first place.&nbsp;</p><p>&nbsp;</p><h1>Favorite and least favorite parts</h1><p>We asked people what their favorite and least favorite parts of the day-to-day work were. If you think the best bits sound great and you could handle the not-so-good parts, then you might be a great fit for AI safety work.</p><p>&nbsp;</p><h2><strong>Ethan Perez</strong></h2><p>Favorite</p><ul><li>Fun feedback loops where you can implement something during the day, run it during the night, and then check back and iterate the next morning.</li><li>Sometimes there are even shorter feedback loops, like testing what you can do with prompts in the OpenAI playground</li><li>Ethan prefers working on existing codebases, making modifications rather than implementing entire ideas from scratch. If you implement from scratch, and it doesn\u2019t work, it\u2019s hard to know which part of your implementation isn\u2019t working.&nbsp;</li></ul><p>&nbsp;</p><p>Least favorite</p><ul><li>Sometimes the feedback loops can be long, and there are a lot of steps that can\u2019t be automated</li><li>Initially, Ethan had an aversion to the software engineering side of projects, but this was possibly due to insecurities about his coding ability. This has mainly gone away since addressing this issue</li></ul><p>&nbsp;</p><h2><strong>Ondrej Bajgar</strong></h2><p>Favorite</p><ul><li>Mornings: Ondrej dedicates this time to deep thinking, mainly in front of a whiteboard working on problems</li><li>Lunches at FHI where there are lots of exciting people to talk to, random encounters, and good conversations</li></ul><p>&nbsp;</p><p>Least favorite</p><ul><li>Afternoons: he is usually low on energy and often doesn\u2019t end up making much progress</li><li>Since the original interview, Ondrej has learned to accept this and take a break in the afternoon with a nap and a run to restore energy, so it\u2019s no longer his least favorite bit.</li></ul><p>&nbsp;</p><h2><strong>Scott Emmons</strong></h2><p>Favorite</p><ul><li>Reading and brainstorming. Scott thinks that this is one of the most fun parts of research: you can think pretty widely and you feel like anything is possible</li></ul><p>&nbsp;</p><p>Least favorite</p><ul><li>Dealing with the annoying small details that are involved in getting a project to completion. For example, making sure all the font sizes on your figures look nice, and that all your experiments have a consistent set of hyperparameters</li></ul><p>&nbsp;</p><h2><strong>William Saunders</strong></h2><p>Favorite</p><ul><li>William likes doing pure coding tasks where you can just implement something and see if it works. Often for experiments or ML tasks, it can be more hit-or-miss and the feedback loops aren\u2019t as satisfying.</li></ul><p>&nbsp;</p><p>Least favorite</p><ul><li>He enjoys generating ideas but finds it less enjoyable to prioritize those ideas and choose the specific thing to do next. For example, \u201cWe have several different ways to collect this data. Which should we do first?\u201d</li><li>Getting stuck on projects and becoming anxious about whether things will work or whether the project is not going to go anywhere. One of the benefits of working with people is that if your project is stuck, you can go and talk to someone. You can either talk about their project or ask them for help getting yours unstuck</li></ul><p>&nbsp;</p><h2><strong>Justin Shovelain</strong></h2><p>Favorite</p><ul><li>The feeling that he is \u2018resolving mysteries\u2019 and learning new, cool things</li><li>The sense of \u2018a deed well done for the world\u2019. Looking at what you\u2019ve done and realizing \u2018Oh I actually did improve things. This is wonderful\u2019.</li></ul><p>&nbsp;</p><p>Least favorite</p><ul><li>Dealing with bureaucracy&nbsp;</li><li>Dealing with the politics involved in running and representing an organization</li></ul><h2><br><strong>Stephen Casper</strong></h2><p>Favorite</p><ul><li>Looking at cool visualizations, and producing nice-looking figures. One of the upsides of working in the subfield of adversarial robustness is that he gets to make and work with interesting visualizations.</li><li>Getting things to work when they weren\u2019t previously working</li><li>Working with people in person</li></ul><p>&nbsp;</p><p>Least favorite</p><ul><li>When something is not working and you don\u2019t know why</li><li>Working with other people\u2019s code and you don\u2019t like how it\u2019s written</li><li>Reviewer #2. (<a href=\"https://link.springer.com/article/10.1007/s40037-021-00670-z\"><u>\u201cReviewer 2 symbolizes the peer reviewer who is rude, vague, smug, committed to pet issues, theories, and methodologies, and unwilling to treat the authors as peers.\u201d</u></a>)</li></ul><p>&nbsp;</p><h2><strong>John Wentworth</strong></h2><p>Favorite</p><ul><li>These are really interesting problems to think about. Having insightful \u2018shower thoughts\u2019.</li></ul><p>&nbsp;</p><p>Least favorite</p><ul><li>Being stuck on a problem for a long time isn\u2019t very fun, although it is hard to separate the good parts (working on a fun problem) from the bad parts here.</li><li>Needing to communicate something when there\u2019s a large&nbsp;<a href=\"https://www.lesswrong.com/tag/inferential-distance\"><u>inferential gap</u></a> and so it\u2019s difficult to get the whole idea across.</li></ul><p>&nbsp;</p><h2><strong>Alex Turner</strong></h2><p>Favorite</p><ul><li>\u201cWhen I\u2019m trying to prove something that\u2019s interesting, and I don\u2019t know how to do it yet. Well, actually the favorite part is that instant when I figure out how to do it, but besides that, the process of attacking it is really fun.\u201d</li></ul><p>&nbsp;</p><p>Least favorite</p><ul><li>Things like dealing with emails or meetings which aren\u2019t very important, but these can be minimized.</li><li>Being in the state of mind of not feeling very quiet internally, where your attention is being pulled by various things like social media.&nbsp;</li></ul><p>&nbsp;</p><h2><strong>Ramana Kumar</strong></h2><p>Favorite</p><ul><li>When you make progress on something and see what you\u2019ve produced. For example, coming up with an idea or working with people on a presentation or paper. Seeing the final product and thinking, \u201cOh, that\u2019s really nice\u201d.&nbsp;</li><li>Being in a reading group and feeling on top of what\u2019s going on and that you\u2019re making useful contributions</li><li>Spending a while reading or trying to write a comment and reaching a place where you understand something or know how to make a specific point well</li></ul><p>Least favorite</p><ul><li>It can be hard when you\u2019re not satisfied with any of the options of what to do next and it feels like you don\u2019t really know what to do next. You can end up flitting between options because it seems better than nothing, but then changing direction because one thing didn\u2019t seem quite right. When in this state it\u2019s useful to step back and either do longer-term prioritization, or realize you\u2019ve already done the prioritization and so do (and stick to) what you\u2019ve previously decided.</li></ul><p>&nbsp;</p><p>If you liked this post, you might also like:</p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/PH2pqsqgXQkfCdmkv/how-to-become-an-ai-safety-researcher\">How to become an AI safety researcher</a>, the first part of this series</li><li><a href=\"https://www.aisafetysupport.org/resources/lots-of-links#h.gtysxxud1rr\">A curated list of links on career advice for AI safety researchers</a> from <a href=\"https://www.aisafetysupport.org/home\">AI Safety Support</a></li><li><a href=\"https://www.aisafetysupport.org/resources/career-coaching\">Career coaching from AI Safety Support</a> or <a href=\"https://80000hours.org/speak-with-us/\">80,000 Hours</a></li></ul><p>&nbsp;</p><p><i>Thanks to Amber for editing this post. If you find writing/editing tedious or can never find the time to write, you can </i><a href=\"https://amber-dawn-ace.com/our-services\"><i>contract her to write or edit your EA posts here</i></a><i>.</i></p>", "user": {"username": "katherinesavoie"}}, {"_id": "pYPag2wpB7LF9BSBj", "title": "Anyone who likes the idea of EA & meeting EAs but doesn't want to discuss EA concepts IRL?", "postedAt": "2023-02-15T19:09:05.850Z", "htmlBody": "<p>Hi all, using a throwaway as this feels a bit anti-social to post!&nbsp;</p><p>Basically, I'm aligned with &amp; live via the basic concepts of EA (use your career for good + donate some of your earnings to effective causes), but that's where my interest really kind of ends.&nbsp;</p><p>I'm not interested in using my free time to read into EA further, I don't feel motivated to learn more about all the concepts that people use/ discuss, etc (utilitarianism, expected value, etc etc). I really like having non-EA friends and don't get any enjoyment from having philosophical discussions with people.&nbsp;</p><p>I really like the core ethos of EA, but when I've gone to in-person meetups (including Prague Fall Season) I've felt like a fraud because I'm not at all versed in the language, and actually have no interest in discussion all the forum talking points. I just want to meet cool people who care about doing good!&nbsp;</p><p>Of course a clear rebuttal here would be \"ok then dude just talk to people about other stuff\", but I've often felt at these events like people are there to discuss this kind of stuff, and to talk about more normal/ \"mundane\" stuff would make people think I'm wasting their time.&nbsp;</p><p>So I guess my question is like - is there anyone else out there who feels this way? Any tips? I'd really like to make friends through the EA community but in the same breath I only want to be involved in a straightforward way (career + key ideas), rather than scouring the forums &amp; LessWrong and hitting all the squares on the EA bingo card. Also, is it kind of in my head that you need to be a hardcore EA who has strong opinions on ethics &amp; philosophy &amp; etc, or is that the general mood?</p><p>(I also appreciate that the people who end up reading this will be more \"hardcore EA\" types who check the forum regularly...)</p>", "user": {"username": "antisocial-throwaway"}}, {"_id": "8XDcMhJ65mwWrouro", "title": "Join a new slack for animal advocacy ", "postedAt": "2023-02-20T20:12:36.044Z", "htmlBody": "<p>We'd like to extend an invitation to you all for <a href=\"https://tally.so/r/wkGKer\">a new Slack space</a> that brings together <strong>individuals who are passionate about making a meaningful impact for animals.&nbsp;</strong></p><p>Our aim is to:</p><ul><li>support discussions in the animal advocacy space</li><li>foster new connections</li><li>learn from each other</li><li>generate innovative ideas</li><li>perhaps even launch new projects.&nbsp;</li></ul><p>It would be great for you to join us today and introduce yourself to the community! We already have some great discussions going.&nbsp;</p><p><a href=\"https://tally.so/r/wkGKer\"><strong>Join here.</strong></a></p><p>FAQs:</p><ol><li>\"<i>But there are already lots of Slack spaces?</i>\" - before we started this space, there wasn't a space that was just for animal welfare.</li><li>\"<i>Who should join?</i>\" -&nbsp;<ul><li>Anyone already working in animal advocacy or adjacent organisation</li><li>Anyone involved in alt protein</li><li>Anyone, regardless of experience or place of work, interested in helping animals in an impactful way</li><li>By animals, we mean farmed animals and wild animals</li></ul></li><li>\"<i>How much do I have to participate, could I join and lurk for a bit?</i>\"- Sure, you don't need to be active all the time, all we ask is that you introduce yourself and invite anyone you know in the space who may be interested. If you'd like, you can message others or participate in discussions, but no pressure.</li></ol><p>If in doubt, <a href=\"https://tally.so/r/wkGKer\">please join!</a></p><p>Best wishes,</p><p>Sofia and Cameron<br>&nbsp;</p>", "user": {"username": "sofiabalderson"}}, {"_id": "reWKxv7xXpwRnZJLA", "title": "Huh. Bing thing got me real anxious about AI. Resources to help with that please?", "postedAt": "2023-02-15T16:55:23.867Z", "htmlBody": "<p>Tried looking but can't find these. Not feeling well right now so that might have contributed to my lack of findings. Ran out of Qualy memes so please throw anything at me. Help please, thank you very much.&nbsp;</p>", "user": {"username": "Arvin"}}, {"_id": "e8ZJvaiuxwQraG3yL", "title": "Don't Over-Update On Others' Failures", "postedAt": "2023-02-15T16:52:35.509Z", "htmlBody": "<p>Scenario: You're working hard on an important seeming problem. Maybe you have an idea to cure a specific form of cancer using mRNA. You've been working on the idea for a year or two, and seem to be making slow progress; it is not yet clear whether you will succeed.</p>\n<p>Then, you read a blog post or a paper about a similar approach by someone else: \"Why I Am Not Working On Cures to Cancer Anymore.\" They failed in their approach and are giving up. You read their postmortem, and there are a few similarities but most of the details differ from your approach. How much should you update that your path will not succeed?</p>\n<p>Maybe a little: After all, they might have tried the thing you're working on too and just didn't mention it. But not that much, since after all they didn't actually appear to try the specific thing you're doing. Even if they had, execution is often more important than ideas anyway, and maybe their failure was execution related.</p>\n<p>The same applies for cause prioritization. Someone working on wild animal suffering might read <a href=\"https://forum.effectivealtruism.org/posts/saEQXBgzmDbob9GdH/why-i-no-longer-prioritize-wild-animal-welfare\">this recent post</a>, and <em>even though they are working on an angle not mentioned,</em> give up. I think in most cases this would be over-updating. Read the post, learn from it, but don't give up just because someone else didn't manage to find an angle.</p>\n<p>Last example\u2014climate change. 80000 Hours makes clear that they think it is important but \"all else equal, we think it's less pressing than our highest priority areas\". (<a href=\"https://80000hours.org/problem-profiles/climate-change/\">source</a>) This does not mean working on climate change is useless, and if you read the post it becomes clear they just don't see a good angle. If you have an angle on climate change, please work on it!</p>\n<p>Indeed, I will go further and make the point: important advances are made by people who have unique angles that others didn't see. To put it another way from the startup world: <a href=\"http://www.paulgraham.com/swan.html\">\"the best ideas look initially like bad ideas\"</a>.</p>\n<p>Angles on solving problems are subtle. It's hard to find good ones, and execution matters, so much that even two attempts which superficially have the same thesis could succeed differently.</p>\n<p>Don't over-update from others' failures. The best work will be done by people who have unique takes on how to make the world better.</p>\n", "user": {"username": "lincolnq"}}, {"_id": "FxToCd5fwwES7XWcb", "title": "Fixing the vegetarian plate: A new guide aims to correct misconceptions and educate the health-care community about the vegetarian diet", "postedAt": "2023-02-15T16:20:23.096Z", "htmlBody": "<p>Hello EAs, first time writing on the forum, so pardon my English.</p><p>I'm an EA from Brazil and just partnered with IVU (International Vegetarian Union) to help bring their Vegan Guide to Universities and any organization around the world related to the Health Care System.</p><p>&nbsp;</p><p><strong>What is this guide?</strong></p><p>The Guide to Vegan Nutrition for Adults is a freely available 500-page document produced by the International Vegetarian Union that demystifies the vegetarian plate and corrects long-time misconceptions about the vegetarian diet.</p><p><a href=\"https://www.ivu.org/veganguide/GUIDE-TO-VEGAN-NUTRITION-FOR-ADULTS-HEALTH-PROFESSIONAL-EDITION.pdf\">The guide is already free to download here</a>. [important: The purpose of this available version, which is based on a review of over 700 peer reviewed articles on the topic, is to bring the necessary tools to students and health professionals, so that they can guide and support the dietary choices of their patients using solid scientific evidence. In the next months there will be a more readable version for the main public]<br>&nbsp;</p><p><strong>Why is it important?</strong></p><p>Just this week, one of the top vegan activists on YouTube (CosmicSkeptic - A graduate of philosophy and theology from St. John\u2019s College, Oxford University) announced quitting his vegan diet because of health concerns.</p><p><strong>His (and lots of others) problem:</strong> many people adopt veganism because of animal ethics and don't make an adequate transition, don't pay attention on rebalancing nutrients.</p><p><strong>One possible solution:</strong> a free vegan guide, and maybe in the future an online course, for people transitioning to a more ethical way of living.&nbsp;</p><p>&nbsp;</p><p><strong>How can EAs around the world effective act?</strong></p><ol><li>Connect the authors (and IVU) to universities and health organizations around the world for a broad adoption of this guide. It is already translated to 3 languages (English, Spanish, Portuguese)</li><li>Boost other translations.</li><li>Build other ideas around the guide so it reaches a big audience (provide free lectures, maybe help build &nbsp;an animated video series, any other idea is welcome)</li></ol><p>&nbsp;</p><p><strong>What is IVU?</strong></p><p>IVU IS A GROWING GLOBAL NETWORK OF INDEPENDENT ORGANIZATIONS WHICH ARE PROMOTING PLANT-BASED DIET WORLDWIDE. It was founded in 1908 in Dresden, Germany. The idea came from the French Vegetarian Society, the first Congress was organised internationally by the British Society and locally by the Dresden Society with support from the Deutsche Vegetarier-Bund. Since then a series of World Veg Congresses have been held on most continents and, in 2008 IVU returned to Dresden for the Centenary 38th Congress. From 2012 this major global event has been renamed the 'IVU World Vegfest'.</p><p>&nbsp;</p><p><strong>Attached below, I paste IVU's press release for the guide with more detailed information:</strong></p><p>According to a Report Buyer from 2017, 6% of consumers in the United States at the time claimed to be vegan, a significant jump from the 1% rate reported in 2014. An earlier study from 2010 estimated that there were 1.5 billion people following a vegetarian diet worldwide. There are many reasons that lead individuals to adopt a vegetarian diet including health-related issues, compassion for animals, concerns with planetary health and sustainability, and religion-related reasons, among others.<br>In the last years, the many individuals who have chosen to adopt a vegetarian diet no longer have difficulties in finding replacements for animal-based products such as milk, cheese, and eggs. In fact, the sales for substitute products have skyrocketed in the last years showing a growth rate 2.5 times higher than the total food sales. A study from 2021 reveals that the sales of substitute products grew 27%, going from US$ 5.5 billion to US$ 7 billion between 2019 and 2020 in the United States. However, there is still a lot of misinformation and misconceptions linked to the vegetarian diet, which is still not fully accepted as a healthy choice by many professionals in the health-care community.</p><p>To fix misconceptions, demystify the vegetarian plate and educate the medical community about the vegetarian diet, the International Vegetarian Union, an institution that is more than 100 years old with representatives worldwide, just launched the Guide to Vegan Nutrition for Adults, a 500-page comprehensive document about the vegetarian diet that is based on sound information backed by more than 700 peer-reviewed studies. \"Our intention with this guide is to educate the health-care community about the benefits of a vegetarian diet by informing how each essential nutrient works and by correcting misconceptions, so doctors and dietitians will be better prepared to support the dietary choices of their patients,\" says Dr Eric Slywitch, the main author of the Guide.</p><p>The Guide cites peer-reviewed studies that have demonstrated how the vegetarian diet may be used as a treatment for specific conditions or a way to prevent diseases such as diabetes, cardiovascular disease, cancer, and obesity. On supplementation, the Guide corrects the long-time misconception that vegetarians need to add supplements to their diet whereas those following an omnivorous diet do not. The truth is that studies comparing diets do not take into consideration that farmed animals receive loads of supplements that end up on the plate of consumers of meat and animal products.</p><p>In fact, the only supplementation that those on a well-balanced vegetarian diet need to take is vitamin B12, and when it comes to B12 deficiency vegetarians are not alone. Studies have shown that 40% of the population worldwide have insufficient levels of B12. &nbsp;The Guide has more than 40 pages dedicated to this vitamin that explain its metabolism, how it is absorbed, the recommended levels of B12, how to treat B12 deficiency, and how to keep adequate levels of this vitamin.</p><p>Another misconception related to the vegetarian diet that is clarified in the Guide relates to phytoestrogen, which is found in soy, a staple food to many vegetarians. Because phytoestrogens share structural similarities with estradiol (17-\u03b2-estradiol), a number of studies have investigated whether a high intake of soy-based foods could affect the balance of sex and thyroid hormones. Some studies have also investigated whether phytoestrogens could be associated with a higher risk of developing estrogen-depending breast cancer. In 2016 and again in 2019 two meta-analyses showed that intake of soy-based food is in fact associated with a reduced risk of breast cancer and improved survival in those with the disease. Even though the American Cancer Society has encouraged the consumption of soy by breast cancer survivors since 2012, many doctors still tell their patients to avoid high intake of soy-based foods.</p><p>The Guide provides detailed information on all major nutrients required for the proper function of the human body, including vitamins, proteins, calcium, iron, zinc, iodine, and omega-3, to mention a few. It tells how the nutrient is absorbed, what the recommended levels are, what source foods are rich in the nutrient, what symptoms are associated with its deficiency, and the benefits associated with its intake.</p><p>The Guide to Vegan Nutrition for Adults is the first of its kind. After the first section that starts by explaining what exactly vegetarianism is, the following sections elucidate about supplementation, the nutritional adequacy of a vegetarian diet, macro and micronutrients, and antinutritional factors. Besides the PDF document, the Guide also directs the reader to classes available on YouTube taught by the Guide's main author Dr Eric Slywitch. &nbsp;</p><p>Lastly, the Guide provides a 30-day vegetarian menu that includes dishes from all over the world and recipes on how to prepare the food. The Guide is available for free in PDF format at the International Vegetarian Union's website and may be used for consultation by doctors and health-care professionals to better understand how the vegetarian diet can help their patients, and by anyone interested in having only good food on their plate.</p><p><strong>Author: Professor Doctor Eric Slywitch</strong><br><strong>Medical Doctor; Master and PhD in Nutrition Sciences (UNIFESP-EPM) in the area of Metabolic Evaluation of Vegetarians and Omnivores; Specialist in Nutrology (ABRAN), Parenteral and Enteral Nutrition (BRASPEN); Postgraduate in Clinical Nutrition (GANEP) and Endocrinology (ISMD); Director of the Department of Medicine and Nutrition of IVU and the Brazilian Vegetarian Society (SVB).</strong></p><p><strong>Chair of IVU: Marly Winckler</strong><br><strong>Marly Winckler is a sociologist, founding-president of the Brazilian Vegetarian Society (SVB), from 2003 to 2015. She is also chair of the International Vegetarian Union (IVU).&nbsp;</strong></p>", "user": {"username": "Leandro Franz"}}, {"_id": "vAdBvp3F8fMHbM736", "title": "Flourish Student Journal - Open for Submissions", "postedAt": "2023-02-15T16:08:28.999Z", "htmlBody": "<h1><a href=\"https://flourishjournal.org\"><strong>Flourish: the Student Journal for Positive Impact</strong></a><strong> - Open for Submissions!</strong></h1><p>Flourish is a multidisciplinary, peer-reviewed student journal looking for change-driven papers that, if taken seriously, could make the world a better place. Submit a research paper, topic essay, or even a literature or book review. We welcome both edited university papers and specially written pieces. Find out more and submit a paper&nbsp;<a href=\"https://www.flourishjournal.org/\"><u>here</u></a>. First submission deadline is 15th March.&nbsp;</p><p>&nbsp;</p><h3><strong>Who can submit?</strong></h3><p>We think we\u2019ll be of most use to current undergraduates, however we also accept papers from recent graduates, high school students and Masters students. We\u2019re open to entrants of all nationalities. We will use double-blind peer review process to ensure fairness.&nbsp;<br>&nbsp;</p><h3><strong>What are we looking for?</strong></h3><p>You can read our review process, and style and format guides <a href=\"https://www.flourishjournal.org/submission-guidelines\">here</a>.&nbsp;</p><h3><br><strong>Why might I want to submit?</strong></h3><p>Our best guess is that we\u2019ll get two main categories of entrants:</p><ol><li>Remember the idea you had that\u2019s been in the back of your mind? Now\u2019s your chance to write it up!</li><li>Get more out of an essay you wrote or research you\u2019ve already done!</li></ol><p>Successful entrants can join our scholars network, where you'll gain access to mentoring and special opportunities.<br><br><a href=\"mailto:editorialteam@flourishjournal.org\">editorialteam@flourishjournal.org</a></p><p><a href=\"https://twitter.com/flourisheditors\">https://twitter.com/flourisheditors</a>&nbsp;<br><a href=\"https://www.linkedin.com/company/flourish-journal/\">https://www.linkedin.com/company/flourish-journal/</a>&nbsp;<br><br>&nbsp;</p><p><br>&nbsp;</p>", "user": {"username": "JournalTeam "}}, {"_id": "saEQXBgzmDbob9GdH", "title": "Why I No Longer Prioritize Wild Animal Welfare", "postedAt": "2023-02-15T12:11:06.825Z", "htmlBody": "<p>This is the story of how I came to see Wild Animal Welfare (WAW) as a less promising cause than I did initially. I summarise three articles I wrote on WAW:&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/GqnD2tD6EBqPLauYz/saulius-s-shortform?commentId=FT2NhfhBjkCs292Fd\"><u>\u2018Why it\u2019s difficult to find cost-effective WAW interventions we could do now\u2019</u></a>, <a href=\"https://forum.effectivealtruism.org/posts/koTh3bQXg5pGBgRaA/lobbying-governments-to-improve-wild-animal-welfare\"><u>\u2018Lobbying governments to improve WAW\u2019</u></a>, and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/MKmowJNCeJCaitK3x/wild-animal-welfare-in-the-far-future\"><u>\u2018WAW in the far future\u2019</u></a>. I then draw some more general conclusions. The articles assume some familiarity with WAW ideas. See&nbsp;<a href=\"https://wildanimalsuffering.org/\"><u>here</u></a> or&nbsp;<a href=\"https://www.animal-ethics.org/introduction-wild-animal-suffering/\"><u>here</u></a> for an intro to WAW ideas.</p><h2>My initial opinion</h2><p>My first exposure to EA was reading Brian Tomasik\u2019s&nbsp;<a href=\"https://reducing-suffering.org/#wild-animal_suffering\"><u>articles</u></a> about WAW. I couldn\u2019t believe that despite constantly watching nature documentaries, I had never realized that all this natural suffering is a problem we could try solving. When I became familiar with other EA ideas, I still saw WAW as by far the most promising non-longtermist cause. I thought that EA individuals and organizations continued to focus most of the funding and work on farmed animals because of the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Status_quo_bias\"><u>status quo bias</u></a>, risk-aversion, failure to appreciate the scale of WAW issues, misconceptions about WAW, and because they didn\u2019t care about small animals despite&nbsp;<a href=\"https://forum.effectivealtruism.org/s/sHWwN8XydhXyAnxFs\"><u>evidence</u></a> that they could be sentient.</p><h2>There seem to be no cost-effective interventions to pursue now</h2><p>In 2021, I was given the task of finding a cost-effective WAW intervention that could be pursued in the next few years. I was surprised by how difficult it was to come up with promising WAW interventions. Also, most ideas were very difficult to evaluate and their impacts were highly uncertain. To my surprise, most WAW researchers that I talked to agreed that we\u2019re unlikely to find WAW interventions that could be as cost-effective as farmed animal welfare interventions within the next few years.&nbsp;It\u2019s just much easier to change conditions and observe consequences for farmed animals because their genetics and environment are controlled by humans.&nbsp;I ended up spending most of my time evaluating interventions to&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/oTFJCdCDKh7Cetepv/reducing-aquatic-noise-as-a-wild-animal-welfare-intervention\"><u>reduce aquatic noise</u></a>. While I think this is promising compared to other WAW interventions I considered, there are quite many farmed animal interventions that I would prioritize over reducing aquatic noise. I still think there is about a 20% chance that someone will find a direct WAW intervention in the next ten years that is more promising than the marginal farmed animal welfare intervention at the current funding level.</p><p>I discuss direct short-term WAW interventions in more detail&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/GqnD2tD6EBqPLauYz/saulius-s-shortform?commentId=FT2NhfhBjkCs292Fd\"><strong><u>here</u></strong></a>.</p><h2>Influencing governments</h2><p>Some WAW advocates promote research on WAW in academia. For some of them, their aim is twofold: to identify effective interventions and establish WAW as a legitimate field of study. The hope is that by gaining greater legitimacy, WAW advocates can influence government policy. For example, governments could control wild populations more humanely, vaccinate animals against some diseases, and eradicate some parasites.&nbsp;</p><p>I am somewhat skeptical of this because:</p><ul><li>The argument for the importance of WAW rests on the enormous numbers of small wild animals. It\u2019s difficult to imagine politicians and voters wanting to spend taxpayer money on improving wild fish or insect welfare, especially in a&nbsp;<a href=\"https://www.lesswrong.com/posts/2ftJ38y9SRBCBsCzy/scope-insensitivity\"><u>scope-sensitive</u></a>&nbsp;way. But it could have been similarly difficult to imagine governments funding species conservation efforts until it happened.</li><li>The consequences on the welfare of all affected wild animals seem nearly impossible to determine, even with a lot of research. Also, research in one ecosystem might not generalize to other ecosystems.&nbsp;<ul><li>However, this is the same as the concern of&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/LdZcit8zX89rofZf3/evidence-cluelessness-and-the-long-term-hilary-greaves\"><u>cluelessness</u></a>&nbsp;that applies to all causes. That is, all interventions have complicated indirect effects that are impossible to predict. To me, cluelessness seems a bigger problem in WAW because first-order effects are usually dwarfed by second and third-order effects. For example, vaccinations may increase the population of that species, which could be bad if their lives are still full of suffering. Also, when the population of one species changes, it changes populations of other species too. But overall, I\u2019m confused about cluelessness.</li></ul></li><li>Even if we determine consequences, people with different moral views might disagree on which consequences they prefer. For example, people may disagree on how to weigh the welfare of different animal species, happiness versus suffering, short and intense suffering versus chronic but less intense suffering, etc. This may eventually divide the WAW movement into many camps and hurt overall efforts.</li></ul><p>See&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/koTh3bQXg5pGBgRaA/lobbying-governments-to-improve-wild-animal-welfare\"><strong><u>here</u></strong></a> for further discussion of the goals of lobbying governments to improve WAW, and obstacles to doing this.</p><h2>Long-term future</h2><p>Others have argued that what matters most in WAW is moral circle expansion and the effect we may have on the far future. But what exactly do we want to achieve in the far future with our current WAW work? In&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/MKmowJNCeJCaitK3x/wild-animal-welfare-in-the-far-future#Far_future_WAW_scenarios\"><u>this article</u></a>, I listed all the far-future scenarios where WAW seemed very important. The most important ones included scenarios where wildlife is spread beyond Earth. For example, we might develop an aligned transformative AI and the humans in charge might want to colonize space with biological human-like beings and animals, rather than machines. In that case, we could end up with quadrillions of animals suffering on billions of planets for billions of years. Compared to that, WAW interventions on Earth seem much less important.</p><p>However, to me, WAW doesn\u2019t seem to be the most important thing for the far future - not even close. Digital minds could be much more efficient, thrive in environments where biological beings can\u2019t, utilize more resources, and seem more likely to exist in huge numbers. Hence, some other longtermist work seems much more promising to me than longtermist animal welfare work.</p><p>If you think that the future is likely to be good, then I think that reducing x-risks is much much more promising. If you are a&nbsp;<a href=\"https://en.wikipedia.org/wiki/Negative_utilitarianism\"><u>negative utilitarian</u></a> (i.e., you only care about reducing suffering) or you are pessimistic about the future, you may want to prioritize work that aims to reduce the potential suffering of future digital minds instead (for example, the work of organizations like&nbsp;<a href=\"https://longtermrisk.org/\"><u>The Center on Long-term Risk</u></a>). The tractability of trying to reduce digital mind suffering might be even lower than for longtermist animal welfare work, but the scale is much much higher. I think that there may be <a href=\"https://forum.effectivealtruism.org/posts/MKmowJNCeJCaitK3x/wild-animal-welfare-in-the-far-future#How_can_we_influence_wildlife_spreading_scenarios__\">some</a> worthwhile things to do in the intersection of longtermism and animal welfare but I don't think it that it should become a major focus for EA.</p><p>I discuss WAW and the far future in more detail&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/MKmowJNCeJCaitK3x/wild-animal-welfare-in-the-far-future\"><strong><u>here</u></strong></a>.</p><h2>Overall opinion</h2><p>After looking into these topics, I now tentatively think that WAW is not a very promising EA cause because:</p><ul><li>In the short-term (the next ten years), WAW interventions we could pursue to help wild animals now seem less cost-effective than farmed animal interventions.</li><li>In the medium-term (10-300 years), trying to influence governments to do WAW work seems similarly speculative to other longtermist work but far less important.&nbsp;</li><li>In the long-term, WAW seems important but not nearly as important as preventing x-risks and perhaps some other work.</li></ul><p>All that said, I\u2019m unsure how seriously my opinions should be taken because:</p><ul><li>I don\u2019t have an ecology/biology/conservation background to competently evaluate direct short-term WAW interventions,&nbsp;</li><li>I don\u2019t know enough about the history of social movements to evaluate how likely WAW is to succeed as a social movement, and&nbsp;</li><li>I\u2019m not very knowledgeable about longtermism.</li></ul><p>Hence, I see my articles on WAW as the start of a conversation, not the end of it.</p><p>Despite my concerns, if I was in charge of all EA funding, I still wouldn\u2019t set WAW funding to zero. Since it\u2019s very difficult to predict which interventions will be important in the future, I think it makes sense to try many different approaches. I still believe that WAW is promising enough to do some further research and movement building. For example, even though I&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/L5EZjjXKdNgcm253H/corporate-campaigns-affect-9-to-120-years-of-chicken-life\"><u>think</u></a> that corporate farmed animal welfare campaigns are very cost-effective, I would not choose to drop all WAW funding in order to fund even more corporate campaigns, because WAW work could open an entirely new world of possibilities. We won't know what's there unless we try.</p><p>However, I wouldn\u2019t spend much more money on WAW than EA is currently spending either. My subjective probability that the WAW movement will take off with $8 million per year of funding is not that much higher than the probability that it will take off with $2 million per year of funding, as the movement\u2019s success probably mostly depends on factors other than funding. But with $2 million, the probability would be much higher than with $0 (I\u2019m using somewhat random numbers here to make the point). And ideally, the money that we do spend on WAW would be used to fund people with different visions about WAW to try multiple different approaches so that we could see which approaches work best. I see some of this happening now, so I mostly support the status quo. Of course, my opinion on how much funding WAW should receive might change upon seeing concrete funding proposals.</p><p><i>[EDIT 2023-02-21: I criticized the version of the WAW movement I saw being pursued by organizations. To my knowledge, no organization currently works on WAW by trying to help microorganisms, or decrease wild animal populations (which perhaps could be done in&nbsp;</i><a href=\"https://reducing-suffering.org/cost-effectiveness-comparison-for-different-ways-to-reduce-insect-suffering/#Sample_government_policies\"><i>relatively uncontraversial ways</i></a><i>). I simply don\u2019t have an opinion about a WAW movement that would focus on such things. There were some restrictions on the kinds of short-term interventions I could recommend in my intervention search. Interventions that would help microbes or help wild animals by reducing their populations simply didn\u2019t qualify. Thank you to the commenters who made me realize this.]</i></p><p><i>Opinions expressed here are solely my own. I\u2019m not currently employed by any organization.</i></p>", "user": {"username": "saulius"}}, {"_id": "ufTfeknNNM5mcqvLD", "title": "Prometheus Unleashed: Making sense of information hazards", "postedAt": "2023-02-15T06:44:56.939Z", "htmlBody": "<p>Note: The contents of this post is from my blogpost linked with this post.</p><p>&nbsp;</p><p># Intro</p><p>As part of my research into global existential risks, I came across the conundrum of information hazard which simply refers to the potential misuse of scientific or technological information by bad actors that might turn into a global risk for everyone.&nbsp;</p><p>&nbsp;</p><p>This phenomenon is most aggravated in the field of biotechnological research where misuse of increasingly openly available genomic data or cheaper protein synthesis techniques can easily be used to develop and mass-produce humanity-threatening super-pathogens (\u201csuper\u201d referring to immunity against all known forms of human cure). This is a particularly interesting conundrum as the fine line between openness and secrecy governs the difference between better scientific research and global catastrophe.&nbsp;<br>&nbsp;</p><p>It is easy to say that all biotech information and research generated should be classified by labs around the world. But this conservative approach would turn dry the flow of useful information and data that is so important to inspire and facilitate future research. Although this approach guarantees safeguard against information hazard, it also means the end of all future scientific research and technological innovation. Such a scenario will leave humanity helpless in the face of attack by a naturally emerged pathogen.</p><p>&nbsp;</p><p>On the other hand of the spectrum, completely free proliferation of potentially biohazardous information, if accessed by a malicious organisation or even a bad actor with the required expertise and material, can spell doom for humanity.<br>&nbsp;</p><p>Thus, it can be concluded that the censorship on scientific information and data should lie somewhere in the grey of the spectrum. Where is that point?</p><p>&nbsp;</p><p>The secrecy point question is more nuanced than it looks. For example, consider this scenario. A biotech lab publishes unsuspecting non-hazardous information. This information is accessed by a malicious group which was lacking some non-hazardous information to bring its \u201cevil project\u201d to fruition. In the light of the newly published (unsuspectful) data, it can now generate the required hazardous information it needs and bring its evil plan to life. Notably, this scenario is quite narrow (one can argue, if the malicious group has the resources to do independent R&amp;D, then it can generate whatever information it needs independently. Or that such expertise is not known to be within the resource constraints of any known terrorist outfit). Sure, but what I\u2019m trying to present is the subtleties and intricacies that surround such censorship and governance issues and truly calls for a departure from the binary of black and white approach taken by governance organisations today.&nbsp;<br>&nbsp;</p><p># Case studies</p><p>&nbsp;</p><p>The US government policies on dual-use research is solely restricted to work that fall under any of its seven classes of \u201cexperiments of concern\u201d or if it involves a subset of organisms on the Federal Select Agent List. It is not hard to imagine that emerging research may not fall under this classification and yet be of catastrophic concern to humanity.</p><p>&nbsp;</p><p>Or take this second scenario that seems to defy common sense. It is beneficial to publish easy-to-discover information hazardous research as it would benefit good actors and the publication of the work is indifferent for the bad actors as they would discover the information themselves sooner or later. This loudly opens a new can of worms by asking where to draw the line for \u201ceasy-to-discover\u201d?</p><p>&nbsp;</p><p>Moreover, keeping useful information hidden may lead to unintentional misuse of currently deployed technology or slowdown preventive measures in case of large-scale risks. An apt commentary on the reassessment to a publication concerning the identification of a subtype of the neurotoxic&nbsp;<i>botulinum</i> toxin reads as follows:<br>&nbsp;</p><p>&gt; Although it is ethical to identify and mitigate DURC, it is also an ethical imperative to enable others to counter potential harm with good. With critical national security and public health at stake, it is unethical to impede research competitors for personal, professional, or commercial motives. Likewise, excessive government regulation is not helpful if it slows the progress of countermeasure development (Keim, 2016, p. 333).</p><p>&nbsp;</p><p># Incentive games&nbsp;</p><p>&nbsp;</p><p>There are various notorious and perverse incentive games at work too. Take for instance, the decry against biological weaponry in the Geneva protocol during WW2 which informed the Japanese of the potential utility of biological weapons and eventually inspired them to develop and use their own B-weapons (is this a word?). Incentives act on all levels of society. Scaling the academia ladder forces researchers to publish their work, unfortunately often bypassing ethics and common-sense, in order to be promoted or just receive funding. They are often left at the discretion of the policy-makers or fund dispensers who have little to no idea of the potential impact of the research (both good or bad).&nbsp;&nbsp;<br>&nbsp;</p><p># The bigger picture</p><p>&nbsp;</p><p>The progress of scientific and technological advancements are asking more existential questions than ever before and at a rate that is simply beyond the mental grasp of the common human and barely understood by a select few. Taking a meta look at the information hazard problem, it can be summarised as the inability to infer the intention of human beings. Take for instance, the open problem in security and blockchain dubbed the \u201cOracle problem\u201d - which basically asks if it is possible to validate any information generated outside the chain by the chain itself. If one examines the question carefully (the leisure of which I do not exercise in this post), it would be apparent that the fundamental problem lies at the interface between the real world and its equivalent projection in the digital space. For eg: in web2, the identity of a person is closely tied to its account on some database. This abstraction worked because the proof that that person\u2019s existence was guaranteed by some central authority. But with the elimination of the central authority, who backs the data? How do we even define identity in such a case? The premise for the abstraction breaks down. The authentication situation is not as dire as it looks as people are trying to find workarounds but I intend to present the bigger picture here.&nbsp;<br>&nbsp;</p><p># Solutions?&nbsp;<br>&nbsp;</p><p>So, we understand that this is an important issue. But what is the solution? To be honest, there doesn\u2019t seem to be any fool-proof solution because the problem is on a different plane as noted in the previous paragraph. There are various suggestions such as assessing the bad (and good) impact of an information promulgation&nbsp;<i>beforehand.</i> Or consciously disclosing information in a way that benefits good actors while posing difficulty for bad actors to use it for malicious plans - \u201cSecurity by obscurity\u201d. Identification of entities who access a particular piece of information may be an option but I only see it eventually dwindling into authoritarian monopolistic control over the information as \u201csomeone\u201d has to decide if the information should be made available to a particular entity or not.&nbsp;</p><p>&nbsp;</p><p># Conclusion</p><p>&nbsp;</p><p>In the timeless words of Dickens, I think this is \u201cthe best of times, the worst of times\u201d, an exciting time to ask questions, a vibrant time for research,and an amazing time to be alive. The answers we give to ourselves in this century may potentially decide our fate.&nbsp;</p><p>&nbsp;</p><p># Acknowledgements and References&nbsp;</p><p>&nbsp;</p><ol><li>Lewis, et. al - Information Hazards in Biotechnology, 2019</li></ol>", "user": {"username": "basil.icious"}}]