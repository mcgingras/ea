[{"_id": "XWW9pohAagCuuXxSG", "postedAt": "2024-03-07T15:02:58.147Z", "postId": "EJx4SpWyJJa6C7LvP", "htmlBody": "<p><strong>Executive summary</strong>: Curran argues that longtermism conflicts with plausible deontic skepticism about aggregation from both ex-ante and ex-post perspectives, as long-term interventions like catastrophic risk mitigation generate weak complaints from future individuals compared to short-term interventions.</p><p><strong>Key points:</strong></p><ol><li>The Late Train thought experiment illustrates the problematic conclusion that aggregating small harms can outweigh a large harm, which can be remedied by anti-aggregative moral theories.</li><li>Ex-ante anti-aggregationism finds long-term interventions generate weaker complaints than short-term interventions as they change individuals' prospects less significantly.</li><li>Ex-post anti-aggregationism only justifies long-term interventions reasonably expected to save lives in reality, excluding catastrophic risk mitigation.</li><li>Skeptics of aggregation should be similarly skeptical of longtermism, while the paper may cast doubt on anti-aggregative theories for insufficiently valuing long-term interventions.</li><li>The conflict between intuitions in Late Train and the importance of long-term interventions suggests there may not be a moral theory that can consistently accommodate both.</li></ol><p>&nbsp;</p><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}, {"_id": "MrfrFxspHmvkEQLGH", "postedAt": "2024-03-07T15:55:59.760Z", "postId": "EJx4SpWyJJa6C7LvP", "htmlBody": "<p>Thanks for the excellent summary, Nicholas!&nbsp;</p>", "parentCommentId": null, "user": {"username": "emmajcurran"}}, {"_id": "aZL5wGbZyXCgzQFhA", "postedAt": "2024-03-07T17:59:23.362Z", "postId": "EJx4SpWyJJa6C7LvP", "htmlBody": "<blockquote><p>\"50 people wouldn\u2019t actually die if we don\u2019t choose the AI research, instead, 100 million people would face a 0.00005% chance of death.\"</p></blockquote><p>I'm a bit puzzled by talk of probabilities <i>ex post</i>. &nbsp;Either 100 million people die or zero do. Shouldn't the <i>ex post</i> verdict instead just depend on <i>which outcome actually results</i>?<br><br>(I guess the \"ex post\" view here is really about <i>antecedently predictable ex post outcomes</i>, or something along those lines, but there seems something a bit unstable about this intermediate perspective.)</p>", "parentCommentId": null, "user": {"username": "RYC"}}, {"_id": "tYzmuzJGZjo3akxuj", "postedAt": "2024-03-07T19:10:58.469Z", "postId": "EJx4SpWyJJa6C7LvP", "htmlBody": "<p>\"50 people wouldn\u2019t actually die if we don\u2019t choose the AI research, instead, 100 million people would face a 0.00005% chance of death.\" I think, perhaps, this line is infelicitous.&nbsp;</p><p>The point is that all 100 million people have an ex-post complaint, as there is a possible outcome in which all 100 million people die (if we don't intervene). However, these complaints need to be discounted by the improbability of their occurrence.&nbsp;</p><p>To see why we discount, imagine we could save someone from a horrid migraine, but doing so creates a 1/100 billion chance some random bystander would die. If we don't discount ex-post, then ex-post we are comparing a migraine to death - and we'd be counterintuitively advised not to alleviate the migraine.</p><p>Once you discount the 100 million complaints, you end up with 100 million complaints of death, each discounted by &nbsp;99.99995%.&nbsp;</p><p>I hope this clears up the confusion, and maybe helps with your concerns about instability?&nbsp;</p>", "parentCommentId": "aZL5wGbZyXCgzQFhA", "user": {"username": "emmajcurran"}}, {"_id": "46Hdp8Qf9hkHaJjYt", "postedAt": "2024-03-07T22:21:30.079Z", "postId": "EJx4SpWyJJa6C7LvP", "htmlBody": "<p>Thanks! But to clarify, what I'm wondering is: why take unrealized probabilities to create ex post complaints at all? On an alternative conception, you have an ex post complaint if something bad <i>actually</i> happens to you, and not otherwise.</p><p>(I'm guessing it's because it would mean that we cannot know what ex post complaints people have until literally <i>after the fact, </i>whereas you're wanting a form of \"ex post\" contractualism that is still capable of being action-guiding -- is that right?)</p>", "parentCommentId": "tYzmuzJGZjo3akxuj", "user": {"username": "RYC"}}, {"_id": "Kqx3DYfdErtgSJBZh", "postedAt": "2024-03-08T00:16:55.989Z", "postId": "EJx4SpWyJJa6C7LvP", "htmlBody": "<p>Your guess is precisely right. Ex-post evaluations have really developed as an alternative to ex-ante approaches to decision-making &nbsp;under risk. Waiting until the outcome realises does not help us make decisions. Thinking about how we can justify ourselves depending on the various outcomes we know could realise does help us.&nbsp;</p><p>The name can definitely be misleading, I see how it can pull people into debates about retrospective claims and objective/subjective permissibility.&nbsp;</p><p>&nbsp;</p><p><i>Sorry I edited this as I had another thought</i>.</p>", "parentCommentId": "46Hdp8Qf9hkHaJjYt", "user": {"username": "emmajcurran"}}, {"_id": "JeBr2yaKhBDid7Wz5", "postedAt": "2024-03-10T16:17:40.623Z", "postId": "EJx4SpWyJJa6C7LvP", "htmlBody": "<p>I apologize for this confusion. I've updated the section with the inaccurate statement <a href=\"https://forum.effectivealtruism.org/users/ryc?mention=user\">@Richard Y Chappell</a> quoted.</p>", "parentCommentId": "tYzmuzJGZjo3akxuj", "user": {"username": "NicholasNicholas"}}]