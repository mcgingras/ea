[{"_id": "Bw4L4LDKkCbLhuwmK", "postedAt": "2022-11-10T23:43:17.998Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I agree! As a founder, I promise to never engage in fraud, either personally or with my business, even if it seems like doing so would result in large amounts of money (or other benefits) to good things in the world. I also intend to discourage other people who ask my advice from making similar trade-offs.</p>\n<p>This should obviously go without saying, and I already was operating this way, but it is worth writing down publicly that I think fraud is of course wrong, and is not in line with how I operate the philosophy of EA.</p>\n", "parentCommentId": null, "user": {"username": "lincolnq"}}, {"_id": "LotyLidnsAjWk4rJG", "postedAt": "2022-11-11T00:07:47.579Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I really appreciate the content and tone of this; I want us to have a lot of integrity in our responses, and keep cultivating it.</p><p>(Edited to add month later: I really liked the intensity and the connection to consequentialist reasons to care about deontological and virtue ethical considerations. I have updated that there was a sweepingness to this post I might not endorse and I suspect I got swept up in appreciation that the EA community had people who were going to stand strong and condemn bad behavior, over and above the specifics of the argument made).</p>", "parentCommentId": null, "user": {"username": "ChanaMessinger"}}, {"_id": "eDSnGWjwudfGEAf9M", "postedAt": "2022-11-11T00:29:09.851Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>From <a href=\"https://www.centreforeffectivealtruism.org/ceas-guiding-principles\">CEA's guiding principles</a>:</p><blockquote><p><strong>Integrity:</strong> Because we believe that trust, cooperation, and accurate information are essential to doing good, we strive to be honest and trustworthy. More broadly, we strive to follow those rules of good conduct that allow communities (and the people within them) to thrive. We also value the reputation of effective altruism, and recognize that our actions reflect on it.</p></blockquote>", "parentCommentId": null, "user": {"username": "evelynciara"}}, {"_id": "pZiuLJDDtDon3urNs", "postedAt": "2022-11-11T00:31:28.770Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>The situation at FTX is illustrative of a central flaw in utilitarianism. When you start thinking the ends justify the means, anything becomes justifiable.</p><p>Trust is so important. Doing the right thing is so important.</p><p>I don't really know what else to say.</p>", "parentCommentId": null, "user": {"username": "NicoleJaneway"}}, {"_id": "RKYrS7wG8DB5sHyK6", "postedAt": "2022-11-11T00:35:41.272Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I think the Utilitarian arguments you presented are quite strong, such as precommiting to certain principles being very advantageous,\nbut surely they're not infinitely advantageous right? A few billion is quite a lot.</p>\n", "parentCommentId": null, "user": {"username": "Daryl D'Souza"}}, {"_id": "8QktgrXKRGE3rcaHY", "postedAt": "2022-11-11T00:36:40.175Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote>\n<p>When we, as humans, consider whether or not it makes sense to break the rules for our own benefit, we are running on corrupted hardware: we are very good at justifying to ourselves that seizing money and power for own benefit is really for the good of everyone. If I found myself in a situation where it seemed to me like seizing power for myself was net good, I would worry that in fact I was fooling myself\u2014and even if I was pretty sure I wasn't fooling myself, I would still worry that I was falling prey to the unilateralist's curse if it wasn't very clearly a good idea to others as well.</p>\n</blockquote>\n<p>Also, I would encourage people to read Elephant in the Brain, which backs up this paragraph.</p>\n<p>Also, Goodhart's law would appear as soon as you actually try to optimize for seeming good, when it's not actually a good thing.</p>\n", "parentCommentId": null, "user": {"username": "Sharmake"}}, {"_id": "Gfmqswvppw2e5sCfg", "postedAt": "2022-11-11T01:02:48.330Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>There is a possibility SBF committed fraud motivated directly by his own utilitarian beliefs - a charitable Ponzi scheme.</p>\n<p>But your argument is that utilitarianism systematically generates fraud in a way alternative moral systems do not. Finding one potential bad example is nowhere near enough to justify such a claim.</p>\n", "parentCommentId": "pZiuLJDDtDon3urNs", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "CripXx3akQLJZKf5t", "postedAt": "2022-11-11T01:15:49.870Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Assuming fraud occured: the harder question is whether those who received funding have an obligation to return it, at least under some circumstances.  Verbally condemning fraud is a rather low bar; presumably few would openly defend any fraudulent behavior that occured. But some people may be holding grants funded by fraud, and any future avoidable spending of those funds could be seen as condoning the fraud.</p>\n", "parentCommentId": null, "user": {"username": "Jason"}}, {"_id": "g5bMpeGct7aFHWpeM", "postedAt": "2022-11-11T02:06:53.924Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I think this point is really important. Statements like those mentioned in the post are important, but now that FTX doesn\u2019t look like it\u2019s going to be funding anyone going forward, they are also clearly quite cheap. The discussion we should be having is the higher stakes one, where the rubber meets the road. If it turns out that this was fraudulent, but then SBF makes a few billion dollars some other way, do we refuse that money then? That is the real costly signal of commitment, the one that actually makes us trustworthy.</p>\n", "parentCommentId": "CripXx3akQLJZKf5t", "user": {"username": "Devin Kalish"}}, {"_id": "jpf5mq4ESaAorEKZ5", "postedAt": "2022-11-11T02:14:03.183Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I\u2019m not sure the argument is specifically about fraud.</p>\n<p>I think the argument is more that \u201cwhen ends justify the means, you are far more likely to break norms / rules / laws\u201d, which is a very old objection to utilitarianism and doesn\u2019t <em>rely</em> on the FTX example.</p>\n", "parentCommentId": "Gfmqswvppw2e5sCfg", "user": {"username": "freedomandutility"}}, {"_id": "zE9tQ4jzGwSd2KNQu", "postedAt": "2022-11-11T02:45:21.799Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>\u2026is what you tell yourself before you get exposed for committing massive fraud, costing far more billions than you ended up with.</p>\n<p>If SBF did commit fraud, it looks like he did it to keep Alameda from going bankrupt. If that\u2019s the case, he ended up destroying billions of dollars of potential donations from FTX. \u201cTake a risk that might let you earn a billion dollars illegally\u201d and \u201cMake 0 dollars\u201d are not your only options here! You could have taken not-illegal risks that might have won big instead. Those tend to have higher EV.</p>\n", "parentCommentId": "RKYrS7wG8DB5sHyK6", "user": {"username": "Closed Limelike Curves"}}, {"_id": "sdQ7vfKos9qmT4u2t", "postedAt": "2022-11-11T02:48:55.422Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>No, the argument is self-contradictory in a way that your version is not. \u201cWhen the ends justify the means,\u201d only those means that are, in fact, justified by the ends become justifiable. Means that are not justified by the ends do not become justifiable.</p>\n<p>It would be fair to say \u201csome forms of utilitarianism license fraudulent behavior in exchange for a sufficient altruistic outcome.\u201d</p>\n<p>Of course, we can also say \u201csome forms of deontology advocate we allow the world to be destroyed before we break a rule.\u201d</p>\n<p>I don\u2019t think either line of argument leads to productive moral debate.</p>\n", "parentCommentId": "jpf5mq4ESaAorEKZ5", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "ifekub2ix8knCcjig", "postedAt": "2022-11-11T03:04:50.302Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Right, but utilitarianism has a lower bar for deciding that means are justifiable than other ethical views do (things just need to be overall net positive, even if means are extremely harmful).</p>\n<p>I think these weaknesses of utilitarianism and deontology are useful and given that EA contains lots of utilitarians / is closer to utilitarianism than common sense ethics / is watered down utilitarianism, I think it\u2019s good for EAs to keep the major weaknesses of utilitarianism at the front of their minds.</p>\n", "parentCommentId": "sdQ7vfKos9qmT4u2t", "user": {"username": "freedomandutility"}}, {"_id": "npDC9qhBTDJa9wYX4", "postedAt": "2022-11-11T03:48:16.485Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote><p>Right, but utilitarianism has a lower bar for deciding that means are justifiable than other ethical views do (things just need to be overall net positive, even if means are extremely harmful).</p></blockquote><p>Claiming this as a \"weakness\" of utilitarianism needs justification, and I stridently disagree with characterizing EA utilitarianism as \"watered down.\" It is well-thought-through and nuanced.</p>", "parentCommentId": "ifekub2ix8knCcjig", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "z6ELkWiDDFx5oAGbC", "postedAt": "2022-11-11T04:05:19.079Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>TLDR because I got long-winded: If you ever find yourself planning to commit some morally horrible thing in the name of a good outcome, stop. Those kinds of choices aren't made in the real world, they are a thought exercise (normally a really stupid one too.)</p><p>Long version:&nbsp;</p><p>Sorry that you got downvoted hard, keep in mind that knee-jerk reactions are probably pretty strong right now. While the disagrees are justified, the downvotes are probably not (I'm assuming this is a legit question.)</p><p>I'm constantly looking to learn more about ethics, philosophy, etc and I recently got introduced to this website: &nbsp;<a href=\"https://www.utilitarianism.net/\">What is Utilitarianism? | Utilitarianism.net</a> &nbsp;which I really liked. There are a few things that I disagree with or feel could have been more explored, but I think it's overall good. &nbsp;</p><p>To restate and make sure that I understand where you're coming from, I think that you're framing the current objections like a trolley problem, or its more advanced version the transplant case. (Addressed in <a href=\"https://www.utilitarianism.net/objections-to-utilitarianism\">8. Objections to Utilitarianism and Responses \u2013 Utilitarianism.net</a> second paragraph under \"General Ways of Responding to Objections to Utilitarianism\") &nbsp;if I was going to reword it, I would put it something like this:</p><p>\"When considered in large enough situations, the ideal of precommitment would be swamped by the potential utility gains for defecting.\"&nbsp;</p><p>This is the second response commonly used in defense of the utilitarian framework \"<i>debunk the moral intuition\" &nbsp;</i>(paragraph 5 in the same chapter and section.)&nbsp;</p><p>I believe, and I think most of us believe that this isn't the appropriate response (to this situation) because in this case, the moral intuition is <i><strong>correct.</strong></i> <i><strong>Any</strong></i> misbehavior on this scale results in a weaker economic system, harms thousands if not millions of people, and erodes trust in society itself.&nbsp;</p><p>A response you might think would be something like \"but if the stakes were even <i>higher.\"&nbsp;</i>&nbsp;</p><p>And I agree, it would be pretty ridiculous if after the Avengers saved NYC from a chitauri invasion someone tried to sue the Hulk for using his car to crush an alien or something. We would all agree with you there, the illegal action (crushing a car) is justified by the alternative (aliens killing us all.)&nbsp;</p><p>The problem with that kind of scale, however, is that if you ever find yourself in a situation where you think \"I'm the only one that can save everyone, all it takes is 'insert thing that no one else wants me to do.'\" stop what you're doing and do what the people around you tell you to do. &nbsp;</p><p>If you think you're Jesus, you're probably not Jesus. (or in this case the Hulk.)</p><p>That's why the discussions of corrupted hardware and the unilateralist's curse (links provided by OP) are so important.&nbsp;</p><p>For more discussion on this you can look in <a href=\"https://www.utilitarianism.net/types-of-utilitarianism\">Elements and Types of Utilitarianism \u2013 Utilitarianism.net</a> &nbsp;\"Multi-level Utilitarianism Versus Single-level Utilitarianism.\"&nbsp;</p><p>One must-read section says that \"In contrast, to our knowledge no one has ever defended single-level utilitarianism, including the classical utilitarians.<sup>26</sup> Deliberately calculating the expected consequences of our actions is error-prone and risks falling into decision paralysis.\"&nbsp;</p><p>I would encourage you to read that whole section (and the one that follows it if you think much of rule utilitarianism) as I think one of the most common problems with most people's understanding of utilitarianism is the single-level vs multi-level distinction.</p>", "parentCommentId": "RKYrS7wG8DB5sHyK6", "user": {"username": "Will Kirkpatrick"}}, {"_id": "frki5zSqgxZniRZz9", "postedAt": "2022-11-11T04:14:33.376Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote><p>Utilitarianism without accounting for longterm consequences straightforwardly says that you should be willing to steal from the middle class to send money to poor people (even if some of those people kill themselves) or kill 1 person to save 2.</p></blockquote><p>Possibly the most visible element in EA utilitarianism is literally called \"longtermism,\" so I am not sure this objection is relevant to utilitarianism as practiced here.</p><p>But I understand your objection: conceivably, &nbsp;you could find yourself in a situation where, in your honest judgment, the very best thing you can do for the world is to commit a terrible crime.</p><p>The problem is that when people design these thought experiments, they often set it up in such a way as to make people reject the crime <i>on utilitarian grounds.</i> For example, I'm sure you've heard the surgeon example - should a surgeon kill one healthy patient to harvest their organs and transplant them into 5 other patients to save their lives?</p><p>For most people, they feel this is repugnant. But the natural way to argue against it is with utilitarianism itself. If we did this, patients would flee from surgeons, even fight them. Sick people who didn't want to have somebody murdered to save their own lives would die rather than seek medical treatment. We probably get a lot more QALYs by leaving healthy people alive than by killing them for their organs to put in people who probably have other underlying pathologies.</p><p>These are just natural, obvious consequences of trying to implement this rule. By contrast, deontological and virtue ethics objections to this practice sound weak. \"Doctors SWORE AN OATH to do no harm!\" \"Medicine is about practicing the virtue of beneficence!\" Those sound like slogans.</p><p>Utilitarianism may, in specific and, for all practical purposes, exceedingly rare circumstances, cause somebody to do something awful to achieve a good outcome. But at all other times, utilitarianism motivates you working as hard as you can to <i>avoid</i> ever being put in such circumstances in the first place.&nbsp;</p>", "parentCommentId": "9htgXFd6fZij5pAgD", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "9rJGa7jg7WgQdGPWZ", "postedAt": "2022-11-11T05:00:53.709Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote><p>Why does utilitarianism give you a special incentive to want to run away from being in positions where you are faced with controversial decisions or dilemmas?</p></blockquote><p>Insofar as it does, one reason is moral parliament. Utilitarianism \"plays nice\" with other moralities: if we are unsure of the correct moral theory, utilitarianism advocates we hedge our risk of a fundamental moral wrong by giving some credence to other value systems.</p><p>Let's say we're faced with a choice of situations, A and B. They are of exactly equal utility from a \"simple utilitarian\" standpoint of weighing up the materialistic utilons. However, A is morally fraught from a deontological standpoint, while B is not. Utilitarianism would not say that these two situations are of equal moral weight. It would say that, since we can't be sure utilitarianism is right, we ought to strongly prefer situation B, which is compatible with deontological ethics as well.</p><p>But I'd also say that my point wasn't that utilitarianism wants us to run from controversy. It motivates us to avoid strictly worse situations to strictly better ones. A situation in which reward X can only be obtained by committing a (lesser) cost C is strictly worse than a situation in which we can obtain X without C. Utilitarianism motivates such a search.</p><blockquote><p>I find ordinary morality as practiced by many people currently better than taking any formalisms (atleast the ones I've seen) to their extreme ends. This doesn't ofcourse solve much, you still really want formalised ways of taking moral decisions because there are advantages of formalization. But it is the reason I also don't buy \"utilitarianism is the least worst theory\" yet, better seems possible.</p></blockquote><p>Honestly, sounds like you are taking a utilitarian approach to evaluating other people's ethical schemes. If it seems \"better,\" you think it <i>is</i> better. Quite logical, and quite properly utilitarian. If it would produce more utils for us to all forget utilitarianism even existed and take up virtue ethics, that is what utilitarianism would advocate we do.</p>", "parentCommentId": "nrx8nzWmLiCvyANvp", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "HfGFHXMJBDvkcvtBx", "postedAt": "2022-11-11T06:27:01.297Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote><p>It is people who are uncertain about whether utilitarianism is correct in the first place who decide to factor in moral uncertainty. Also open question how you actually factor it in, and whether this improved version also doesn't run into its own set of repugnant conclusions.</p></blockquote><p>Utilitarianism factors in uncertainty, moral and epistemic. Sure, if you can find a way to criticize factoring in uncertainty into utilitarianism, I'm all ears! But of course, then whatever was the superior solution is what utilitarianism recommends as well. Utilitarianism is best thought of as something engineered, not given.</p><blockquote><p>I would also like to separate moral uncertainty from moral parliament. Moral parliament is usually for multiple people with different values to provide their inputs to a decision process (such as superintelligent AI's values). Moral uncertainty can exist inside the mind of a single person.</p></blockquote><p>I've always heard of moral parliament as being primarily about an individual reconciling their own different moral intuitions into a single aggregate judgment. Never heard it used in the sense you're describing. Here's <a href=\"http://amirrorclear.net/files/the-parliamentary-approach-to-moral-uncertainty.pdf\">Newberry &amp; Ord</a>, which is clearly about reconciling one's own diverse moral intuitions, rather than a way of aggregating the moral judgments of a group.</p><blockquote><p>We introduce a novel approach to the problem of decision-making under moral uncertainty, based on an analogy to a parliament. The appropriate choice under moral uncertainty is the one that would be reached by a parliament comprised of delegates representing the interests of each moral theory, who number in proportion to your credence in that theory.</p></blockquote><p>It does seem helpful to have a term for aggregating moral judgments of multiple people, but \"moral parliament\" is already taken.</p><blockquote><p>Utilitarianism comes with more assumptions than a vague non-formalised sense of \"do what you think is better\", it formalises \"better decisions\" in a very specific way.</p></blockquote><p>I was going to keep arguing, but I wanted to ask - it seems like you might be concerned that utilitarianism is \"morally unfalsifiable.\" In general, my own argument here may convey the idea that \"whatever moral frameowrk is correct is utilitarian.\" In which case, it's only tautologically \"true\" and doesn't provide any actual decision-making guidance of its own. I don't think this is actually <i>true</i> about utilitarianism, but I can see how my own writing here could give that impression. Is this getting at the point you're making?</p>", "parentCommentId": "bd5smmnou2qGXCEoN", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "32McoACzFMtf9qEDe", "postedAt": "2022-11-11T07:00:29.124Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Can you please explain how utilitarianism factors in moral uncertainty?</p>\n<p>As far as I\u2019m aware it has nothing to say on the matter.</p>\n", "parentCommentId": "HfGFHXMJBDvkcvtBx", "user": {"username": "jackmalde"}}, {"_id": "F5mnP5myP7SiTfWzj", "postedAt": "2022-11-11T07:03:55.532Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote><p>We likely won't know for a long time exactly who was responsible for what, nor do I think it really matters\u2014what's done is done, and what's important now is making very clear where EA stands with regards to fraudulent activity, not throwing any individual people under the bus.</p></blockquote><p><br>I agree witch hunts are bad, I agree we should collectively be extremely unambiguous in condemning fraud, and I agree focusing on individuals can be unhealthy and not the most productive.</p><p>But I do think the community should do some reflection and have a postmortem process, part of which is developing a detailed understanding of how events unfolded, so we can develop strategies for avoiding similar situations in the future.</p>", "parentCommentId": null, "user": {"username": "jli"}}, {"_id": "zuC8JkgTK8m7jK5So", "postedAt": "2022-11-11T07:06:58.553Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Thanks for this post. Wondering if 'earning to give' advice should be updated to more clearly argue for going for (the most) ethical ways to earn instead of just the most ethical ways to give. To me it seems like a lot of the fastest ways to make money can be unethical (which should bother us as EA's more than usual) or outright fraudulent, so arguing for making as much money as possible can incentivize behaviour like this (in that sense I do think EA bears some responsibility for Sam's behaviour). I love giving what you earn, just not trying to maximize what you earn unless it is done by doing good.</p>", "parentCommentId": null, "user": {"username": "Jitse Goutbeek"}}, {"_id": "AyftSHF9mDcnhNWqW", "postedAt": "2022-11-11T07:12:54.763Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Agree with the postmortem process, there is a reasonable chance that SBF used EA type thinking to justify his behaviour and we certainly celebrated him as some kind of hero. I think it is important to not just condemn fraud but also really try to figure out if there is stuff EA did or advice it gives that incentivizes this kind of behaviour.</p>", "parentCommentId": "F5mnP5myP7SiTfWzj", "user": {"username": "Jitse Goutbeek"}}, {"_id": "eTsBW5ER4mGtvps6k", "postedAt": "2022-11-11T08:41:36.301Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Surely it\u2019s at least implied that people shouldn\u2019t earn to give through fraud/criminal behaviour?</p>\n", "parentCommentId": "zuC8JkgTK8m7jK5So", "user": {"username": "HenryStanley"}}, {"_id": "iCcxM8uRTAoF33QmL", "postedAt": "2022-11-11T08:44:12.336Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>A weakness in the sense that it severely contradicts our intuitions on morality and severely violates other moral systems, because under classical total utilitarianism this would not only justify fraud to donate to AI safety, it would justify violence against AI companies too.</p>\n<p>(I understand that not everyone agrees that violating moral intuitions makes a moral system weaker, but I don\u2019t want to debate that because I don\u2019t think there\u2019s much point in rehashing existing work on meta-ethics).</p>\n<p>I mean that EA is watered-down classical utilitarianism.</p>\n<p>I don\u2019t think that\u2019s bad because classical utilitarianism would support committing fraud to give more money to AI safety, especially with short AI timelines. And my understanding is that the consensus in EA is that we should not commit fraud.</p>\n", "parentCommentId": "npDC9qhBTDJa9wYX4", "user": {"username": "freedomandutility"}}, {"_id": "KwSwgKAD2koJAqxaZ", "postedAt": "2022-11-11T08:55:40.819Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>It's more than implied, e.g. <a href=\"https://80000hours.org/articles/harmful-career/\">https://80000hours.org/articles/harmful-career/</a><br>Edit: removed a quote to encourage people to skim the full article</p>", "parentCommentId": "eTsBW5ER4mGtvps6k", "user": {"username": "Lorenzo Buonanno"}}, {"_id": "Lrt4KidQeajcBBxwh", "postedAt": "2022-11-11T09:08:24.764Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Maybe \u2018vast majority of cases\u2019 is too ambiguous or allows too much wiggle room for SBF-alikes.</p>\n", "parentCommentId": "KwSwgKAD2koJAqxaZ", "user": {"username": "David Mears"}}, {"_id": "LdubDA3zmb4Jbn8fu", "postedAt": "2022-11-11T09:12:30.639Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I think there\u2019s additional factors that make classical total utilitarians in EA more likely to severely violate rules:</p>\n<ol>\n<li>x-risk mitigation has close to infinite expected value.</li>\n</ol>\n<p>And</p>\n<ol start=\"2\">\n<li>AI timelines mean that violating rules is likely to not have harmful long-term effects.</li>\n</ol>\n", "parentCommentId": "frki5zSqgxZniRZz9", "user": {"username": "freedomandutility"}}, {"_id": "4bxbTPRQ37G8KkR2N", "postedAt": "2022-11-11T09:29:11.420Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Good point, I removed the quote. The article is pretty nuanced and I think I wasn't making it justice by quoting just two sentences.</p>", "parentCommentId": "Lrt4KidQeajcBBxwh", "user": {"username": "Lorenzo Buonanno"}}, {"_id": "2YEkG6TstEc2pSNiX", "postedAt": "2022-11-11T09:33:04.185Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Thanks for the responses. I was not aware of the article on harmful careers and think it is very good (I recognize that many of these issues are hard, so even tough I might be a bit more skeptical about some of these high paying jobs and examples I could easily be wrong). Thanks for bringing it to my attention, it shows that some of my criticism was a bit misguided.&nbsp;</p>", "parentCommentId": "KwSwgKAD2koJAqxaZ", "user": {"username": "Jitse Goutbeek"}}, {"_id": "q95eTd3ujhEQNWt3N", "postedAt": "2022-11-11T11:06:05.003Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>\"Don't do fraud in service of EA because it's bad PR\" (my read of what you said) is not, in fact, a condemnation of fraud. Nor is it good PR.<br><br>Hardcore utilitarians may not have a better condemnation to make, but that's not a problem, because <a href=\"https://forum.effectivealtruism.org/posts/T975ydo3mx8onH3iS/ea-is-about-maximization-and-maximization-is-perilous#We_d_have_a_community_full_of_low_integrity_people__and__bad_people__as_most_people_define_it__\">only a minority of EAs are actually full utilitarians</a>, rather than having one foot in common-sense morality or other moralities, or in uncertainty.<br><br>If hardcore utilitarians can't say something to unequivocally condemn fraud, they should leave it to those who have one foot in common-sense morality to do so.</p>", "parentCommentId": null, "user": {"username": "David Mears"}}, {"_id": "ij3issXvCHggpjgTR", "postedAt": "2022-11-11T11:19:58.720Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I wish you kept the quote. The effect is that I didn't read the quote and did not read the article.</p>\n", "parentCommentId": "4bxbTPRQ37G8KkR2N", "user": {"username": "Dragon God"}}, {"_id": "BQ9t4LEK9CTYzLAcC", "postedAt": "2022-11-11T11:27:05.215Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I think this post is my favourite for laying out why a really convincing utilitarian argument for something which is common sense very bad shouldn\u2019t move you. From memory Eliezer says something like ~Thinking there\u2019s a really good utilitarian argument doesn\u2019t mean the ends justify the means, it just means your flawed brain with weird motivations feels like there\u2019s a really good utilitarian argument. Your uncertainty in that always dominates and leaves room for common sense arguments, even when you feel really extra super sure. Common sense morality rules like \u201cthe ends shouldn\u2019t justify the means\u201d arose because people in practice are very miscallibrated about when the ends actually justify the means so we should take the outside view and assume we are too.~</p>\n<p>(By miscallibrated I think I could defend a claim like \u201c90% of the time people think the ends definitely justify the means and this clashes with common sense morality they are wrong\u201d)</p>\n<p>I might be butchering the post though so you should definitely read it.</p>\n<p><a href=\"https://www.lesswrong.com/posts/K9ZaZXDnL3SEmYZqB/ends-don-t-justify-means-among-humans\">https://www.lesswrong.com/posts/K9ZaZXDnL3SEmYZqB/ends-don-t-justify-means-among-humans</a></p>\n", "parentCommentId": "RKYrS7wG8DB5sHyK6", "user": {"username": "Will Payne"}}, {"_id": "3aFcQiSTYmHPydGJG", "postedAt": "2022-11-11T12:09:48.601Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Independent audits should be installed in EA organizations especially if it is handling tremendous amount of resources or funds, so fraud can be avoided in the future...</p>", "parentCommentId": null, "user": {"username": "Miguel"}}, {"_id": "JuuGKYaCePzzAvrd3", "postedAt": "2022-11-11T12:18:21.870Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Hardcore utilitarians can endorse a norm that says \u201cdon\u2019t commit fraud\u201d because they think such a norm will have better consequences than an alternative norm that says \u201cgenerally don\u2019t commit fraud unless it seems like it could achieve more good than harm\u201d.</p>\n<p>The former norm is likely to avoid instances of fraud, which isn\u2019t only good because fraud can lead to bad PR, but also because a society with widespread fraud is unlikely to be a pleasant one.</p>\n<p>So I do think hardcore utilitarians can be justified in condemning fraud in the strongest possible terms, although I accept one could debate this point.</p>\n", "parentCommentId": "q95eTd3ujhEQNWt3N", "user": {"username": "jackmalde"}}, {"_id": "iuCLhbremhhtDzKFD", "postedAt": "2022-11-11T12:24:40.529Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Good point</p>", "parentCommentId": "JuuGKYaCePzzAvrd3", "user": {"username": "David Mears"}}, {"_id": "XsCn3RWHsbbM5vjFt", "postedAt": "2022-11-11T13:06:33.785Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I will try to read everyone's comments and the related articles that have been shared. I haven't yet, but I'm going on a trip today \u2014 I may have time on the way.</p>\n<p>To be clear: I am against utilitarianism.  It is not my personal value system.   It seems like an SBF-type-figure could justify any action if the lives of trillions of future people are in the balance.</p>\n<p>The utilitarians who aren't taking radical actions to achieve their ends just have a failure of imagination and ambition relative to SBF.</p>\n", "parentCommentId": "pZiuLJDDtDon3urNs", "user": {"username": "NicoleJaneway"}}, {"_id": "5b4PJbcCgdQ6DjCpz", "postedAt": "2022-11-11T14:54:37.942Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I strongly agree with the spirit of this post, and strong upvoted it. However I would criticise this...</p><blockquote><p>Additionally, if you're familiar with decision theory, you'll know that credibly <a href=\"https://en.wikipedia.org/wiki/Precommitment\">pre-committing</a> to follow certain principles\u2014such as never engaging in fraud\u2014is extremely advantageous, as it makes clear to other agents that you are a trustworthy actor who can be relied upon.</p></blockquote><p>... as being too abstract, both in the sense that to a lay person it could sound manipulative, like we're only saying this for PR reasons, and in the theoretical sense that it's &nbsp;a murky concept at best, and arguably nonsensical. Any con artist can assert 'precommitment' as a statement of intent &nbsp;as easily as they can assert any other kind of intent - the only thing that could <i>prove</i> intent is making a physically inescapable commitment, which the EA community has no way of doing here.</p>", "parentCommentId": null, "user": {"username": "Arepo"}}, {"_id": "WuiQYGBk2iQeAJJGA", "postedAt": "2022-11-11T15:16:01.903Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Eh, we can always have it be an acausal deal to some simulator via multiverse cooperation and use some game theory to actually make sure that they won't cheat, after all...</p>\n<p>As long as they are rational.</p>\n<p>There's a literature on this.</p>\n", "parentCommentId": "5b4PJbcCgdQ6DjCpz", "user": {"username": "Sharmake"}}, {"_id": "CwZY6pbHyDfn4kbpy", "postedAt": "2022-11-11T15:39:52.536Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote>\n<p>It seems like an SBF-type-figure could justify any action if the lives of trillions of future people are in the balance.</p>\n</blockquote>\n<p>This doesn't seem specific to utilitarianism. I think most ethical views would suggest that many radical actions would be acceptable if billions of lives hung in the balance. The ethical views that wouldn't allow such radical actions would have their own crazy implications. Utilitarianism does make it easier to justify such actions, but with numbers so large I don't think it generally makes a difference.</p>\n", "parentCommentId": "XsCn3RWHsbbM5vjFt", "user": {"username": "Derek Shiller"}}, {"_id": "7TeBdsZ4SF8ELdmCy", "postedAt": "2022-11-11T15:49:31.537Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Even if other views in fact have the same implications as utilitarianism here, it's possible that that the effects of believing in utiltarianism are particularly psychological pernicious in this sort of context. (Though my guess is the psychologically important things are just <i>take high stakes seriously</i>, lack of risk aversion, and being prepared to buck common-sense, and that those are correlated with believing utilitarianism but mostly not caused by it. But that is just a guess.) &nbsp;</p>", "parentCommentId": "CwZY6pbHyDfn4kbpy", "user": {"username": "Dr. David Mathers"}}, {"_id": "aDsoFjiQpbgNu2Wzq", "postedAt": "2022-11-11T15:51:52.950Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>'The utilitarians who aren't taking radical actions to achieve their ends just have a failure of imagination and ambition relative to SBF.' Quite clearly, though, this has blown up in SBF's face. Maybe the expected value was still good, but it's entirely possible that the (many) utilitarians who think bucking conventional morality and law to this degree nearly always does more harm than good are simply correct, in which case utilitarianism itself condemns doing so (at least absent very strong evidence that your case is one of the exceptions).&nbsp;</p><p><br>&nbsp;</p>", "parentCommentId": "XsCn3RWHsbbM5vjFt", "user": {"username": "Dr. David Mathers"}}, {"_id": "c2EbBQDqCjJhToaEi", "postedAt": "2022-11-11T17:33:37.602Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I don't think talking about fraud right now is a good move. If somebody asks you whether EAs should do fraud, of course your answer should be an unqualified 'no'. But if you bring it up, you are implying that SBF actually did fraud, which (1) may not be true and (2) is bad PR.</p>", "parentCommentId": null, "user": {"username": "River"}}, {"_id": "5FWGrxpTfXSjWboTT", "postedAt": "2022-11-11T17:36:44.220Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I\u2019ll have to think about that. I\u2019ve been working on a response, but on consideration, perhaps it\u2019s best to reserve \u201cutilitarianism\u201d for the act of evaluating world-states according to overall sentient affinity for those states.</p>\n<p>Utilitarianism might say that X is bad insofar as people experience the badnesss of X. The sum total of badness that people subjectively experience from X determines how bad it is.</p>\n<p>Deontology would reject that idea.</p>\n<p>And it might be useful to have utilitarianism refuse to accept that \u201cdeontology might have a point,\u201d and vice versa.</p>\n", "parentCommentId": "32McoACzFMtf9qEDe", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "ACopKhCbxhaMs6di8", "postedAt": "2022-11-11T18:09:09.149Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Yes, I agree that believing the world may be about to end would tend to motivate more rules-breaking behavior in order to avoid that outcome. I'll say that I've never heard anybody make the argument \"Yes, AGI is about to paperclip the world, but we should not break any rules to avoid that from happening because that would be morally wrong.\"</p><p>Usually, the argument seems to be \"Yes, AGI is about to paperclip the world, but we still have time to do something about it and breaking rules will do more harm than good in expectation,\" or else \"No, AGI is not about to paperclip the world, so it provides no justification for breaking rules.\"</p><p>I would be interested to see somebody bite the bullet and say:</p><ul><li>The world is about to be destroyed.</li><li>There is one viable strategy for averting that outcome, but it requires a lot of rule-breaking.</li><li>We should not take that strategy, due to the world-breaking, and let the world be destroyed instead.</li></ul>", "parentCommentId": "LdubDA3zmb4Jbn8fu", "user": {"username": "AllAmericanBreakfast"}}, {"_id": "QtjL5JnuLbn9TYn6r", "postedAt": "2022-11-11T18:13:20.744Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>taking that seriously: wouldn't it be the best for EA, to officially say that any fraud is bad (thus getting good PR), but at the same time internally looking away, thus not to be forced to see fraud?</p><p>Would still using the money already be that?</p>", "parentCommentId": "iuCLhbremhhtDzKFD", "user": {"username": "Hans"}}, {"_id": "pgJEDQARQyobqpP5j", "postedAt": "2022-11-11T18:21:08.275Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote>\n<p>taking that seriously: wouldn't it be the best for EA, to officially say that any fraud is bad (thus getting good PR), but at the same time internally looking away, thus not to be forced to see fraud?</p>\n</blockquote>\n<blockquote>\n<p>Would still using the money already be that?</p>\n</blockquote>\n<p>This is a perfect example of Goodhart's law. More specifically, assuming you don't value fraud or lying (in a moral anti-realist framework), not seeing fraud or lying does not equal no fraud or lying is occuring.</p>\n<p>This is a thermonuclear idea bound to fail due to Extremal Goodhart.</p>\n", "parentCommentId": "QtjL5JnuLbn9TYn6r", "user": {"username": "Sharmake"}}, {"_id": "rnpnzzBLKPbM6ZqxR", "postedAt": "2022-11-11T18:38:09.329Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Hey, crypto insider here.</p><p>sbf actions seem to be directly inspired by his effective altruism believes. He mentioned a few times on podcasts that his philosophy was: &nbsp;Make the most money possible, whatever the way, and then donate it all in the best way to improve the world. He was only in crypto because he thought this was the place where he could make the most money.</p><p>sbf was first a trader for Alameda and then started FTX&nbsp;</p><p>some actions that Alameda/FTX was known for:</p><p>*Using exchange data to trade against their own customers</p><p>&nbsp;*Paying twitter users money to post tweets with the intention of promoting ftx, hurting competitors, and manipulating markets</p><p>*Creating ponzi coins with no usage with the only intention of selling these for the highest price possible to naive users. Entire ecosystems were created for this goal.&nbsp;</p><p>The typical plan was:&nbsp;</p><p>1.Fund a team to create a new useless token. 2% of coins to public, 98% to investors who get it year later. 2. Create manipulation story for why this project is useful. 3.Release news item: Alameda invested in x coin (because alameda had a good reputation at first). 4. pump up the price as high as they can using twitter influencers. 5. list the coin on FTX so investors can hedge position. 6. Alameda has another coin they can trade around and liquidate speculators based on the data they get from ftx.7. repeat x20</p><p>*Lying and predatory behavior</p><p>It seems like they took most actions based on a \"expected value\" approach, calculating which of possible options would on average make them more money.</p><p>including decisions like lying or telling the truth , &nbsp;breaking the law yes or no ,and building reputation for only goal of being more effective at manipulation later on.</p><p>I think this expected value approach made them super succesful traders. And they stayed with strictly the same approach when running the exchange. This is where things are going wrong. &nbsp;In social interactions and situations when your actions impact other people you should also think about things like your reputation, or what would happen if everyone starts acting like you.&nbsp;</p><p>Otherwise, you could rationalize pretending to be friends with your neighbours and then murdering them to give their money away to the poor.Maybe it seems like a good action on paper for a naive utilitarian but if everyone would act like this things would break down.</p><p>&nbsp;I think another factor of this outcome with sbf is narcissistic personality. Something like Effective Altruism can feel emotionally attractive for people like this because it implies, they can do things \"better\", or \"more effective\". It feeds the need for superiority. &nbsp;And then they rationalize everything with, its good for the world, i will be 10x as effective with the money than others etc. It could be true, but it could also not be true and it might not be the real reason why they are acting in this way.</p><p>I think effective altruism works better when blended with normal human behavior and moral principles like: \"try generally to tell the truth\", \"dont steal from your users.\"&nbsp;</p>", "parentCommentId": null, "user": {"username": "Lukio"}}, {"_id": "KNyKmGWn9atahnQdP", "postedAt": "2022-11-11T18:50:32.037Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>This is very important if true, because it suggests with due diligence, EA leaders could have known that it was morally dodgy to be associated with FTX, even before the current blow-up. In comparison if the story is \"previously reasonably ethical by finance standards trader steals to cover losses in a panic\", then while you can say there is always <i>some</i> risk of something like that, it's not really the kind of thing where you can blame people for associating with someone with beforehand. I think it'd be good if some EA orgs had a proper look into which of these narratives is more correct when they do a post-mortem on this whole disasters.&nbsp;</p>", "parentCommentId": "rnpnzzBLKPbM6ZqxR", "user": {"username": "Dr. David Mathers"}}, {"_id": "dYNqCdj5Kz8tpYdFF", "postedAt": "2022-11-11T20:28:27.944Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Thanks a lot for joining the discussion and sharing these observations, that's super valuable info and imo extremely damning &nbsp;if true. Do you happen to have some sources I could check which corroborate what you've written here?</p>", "parentCommentId": "rnpnzzBLKPbM6ZqxR", "user": {"username": "MaxRa"}}, {"_id": "GEP2uHr6c3f5TKc7Q", "postedAt": "2022-11-11T20:30:27.145Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote>\n<p>Paying twitter users money to post tweets with the intention of promoting ftx, hurting competitors, and manipulating markets</p>\n<p>Creating ponzi coins with no usage with the only intention of selling these for the highest price possible to naive users. Entire ecosystems were created for this goal.</p>\n</blockquote>\n<p>Do you have any evidence for these two? Not challenging you, just curious. E.g. Twitter users who admitted to being paid by FTX, or examples of coins that FTX/Alameda created in the way you describe, that sort of thing.</p>\n", "parentCommentId": "rnpnzzBLKPbM6ZqxR", "user": {"username": "Erich_Grunewald"}}, {"_id": "vBfs9yNFcJojZTW2C", "postedAt": "2022-11-11T20:40:10.374Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>That's a pretty wild misreading of my post. The main thesis of the post is that we should unequivocally condemn fraud. I do not think that the reason that fraud is bad is because of PR reasons, nor do I say that in the post\u2014if you read what I wrote about why I think it's wrong to commit fraud at the end, what I say is that you should have a general policy against ever committing fraud, regardless of the PR consequences one way or another.</p>\n", "parentCommentId": "q95eTd3ujhEQNWt3N", "user": {"username": "evhub"}}, {"_id": "uQRJjw6xYQtpvywNR", "postedAt": "2022-11-11T21:12:06.154Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote><p>However, I think it is <a href=\"https://twitter.com/binance/status/1590449161069268992\">starting to look increasingly likely</a> that, even if FTX's handling of its customer's money was not technically legally fraudulent, it seems likely to have been fraudulent in spirit.</p></blockquote><p>Evan do we really have enough information to conclude this? The only real pieces of information I am aware of is that (1) binance declined to acquire, (2) Alameda owned a lot of FTT, (3) SBF's tweets from yesterday.</p><p>I don't think that merely lending out deposits is 'fraudulent in spirit'. That's standard operating procedure in ordinary banking. For example, in Vanguard terms of service:<br><br>&gt; The Program Banks will use Your Sweep Deposits in the Omnibus Accounts to support their investment lending and other activities. [...] Program Banks will receive substantial deposits from the Bank Sweep at a price that may be less than alternative funding sources. Sweep Deposits in the Omnibus Accounts held at a Program Bank provide a stable source of funds for such bank.</p><p>FTX has been accused of much worse than merely lending out depositor's funds, but I'm not aware of any real information about these further claims.</p>", "parentCommentId": null, "user": {"username": "alexflint"}}, {"_id": "BEojTKtEAisyDeWfk", "postedAt": "2022-11-11T21:19:23.186Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>They were an exchange, not a bank, so this still is bad.</p>\n", "parentCommentId": "uQRJjw6xYQtpvywNR", "user": {"username": "Sharmake"}}, {"_id": "qJpEeqzkQcKepiZuq", "postedAt": "2022-11-11T21:28:02.182Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>FTX's terms of service  did not allow for this. The deposits were \"lent\" to plug a hole at a corporation  owned by SBF. Vanguard is talking about sending  certain monies, not your core investment, to a heavily-regulated entity which posed  very low risk. That's  OK in my book if disclosed.</p>\n", "parentCommentId": "uQRJjw6xYQtpvywNR", "user": {"username": "Jason"}}, {"_id": "Cpvp5pi5AvEhKGQLk", "postedAt": "2022-11-11T22:14:38.149Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>it was mostly the SOLANA ecosystem coins: like Oxygen, Raydium, MAPS, All of them were created with the playbook of a very low float (initial available tokens) and very high fully diluted valuation (98% of the tokens would be released to investors later on).</p><p><a href=\"https://twitter.com/SBF_FTX/status/1335531934269591556\">SBF on Twitter: \"11) Paypal is likely the product with the largest userbase in crypto, at around 300m. Soon, the second largest will probably be MAPS.\" / Twitter</a></p><p>&nbsp;You could check the graph of these coins , all these &nbsp;dropped 95-99% in value after investor tokens unlocks started. By this time the big investors already hedged (shorted) the tokens on ftx so they could lock in the value at the higher prices.</p><p><a href=\"https://twitter.com/HsakaTrades/status/1517272687466401793\">Hsaka on Twitter: \"The greatest transfer of wealth this cycle has been from ignorant plebs to the Alameda/Solana/FTX VC crew running the low float high FDV scam. Tis a feature, not a bug, since people still continue to willingly donate their money.\" / Twitter</a></p>", "parentCommentId": "GEP2uHr6c3f5TKc7Q", "user": {"username": "Lukio"}}, {"_id": "pXjwzhNQhmwM9DBav", "postedAt": "2022-11-11T22:23:59.650Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>It's easy to say that no one should do what SBF did. If the rumours were true, there are very few ethical systems that would justify the behavior. What's harder and more action relevant is to specify ahead of time very clearly the exact lines of you find acceptable&nbsp;</p><ul><li>What is \"fraud\" and how much \"fraud\" do we allow? You can argue good advertisements always toe the line. at some point, you seriously screw over business opportunities. Now, not gambling with customer money is again an obvious case far exceeding this.<ul><li>Lots of companies toe the line of honesty but we would never expect huge backlash, there is a level that is accepted by society.&nbsp;</li></ul></li><li>What about anti-competitive practices and monopolistic behavior? Should we ask our founders to not profit max? Should we ask them to not lobby the government for tax breaks and favorable licensing, etc. ?&nbsp;<ul><li>If so, do we feel bad about taking money from bill gates? Microsoft has a history of anti-competitive behavior.&nbsp;</li></ul></li><li>What about businesses that probably harm society overall?<ul><li>Facebook has probably been net-bad for society in my view- though it is hard to imagine what would exist if it was gone - Should we feel bad about taking money from meta?&nbsp;</li></ul></li><li>If I'm in a VC meeting trying to get funding for my startup, should I not significantly exaggerate my product? Isn't this what everyone does while in a VC meeting?</li><li><s>What if we know for sure that we can lie to consumers, make a ton of money, and there won't be any backlash for it (yes this is probably not a real situation). Are we not doing that? if so we aren't utilitarians, which is fine but then why are we utilitarians in our cause prioritization? Seems arbitrary</s></li></ul><p>etc.</p>", "parentCommentId": null, "user": {"username": "Charles_Guthmann"}}, {"_id": "z9fXwgpAhGTBYKYTh", "postedAt": "2022-11-11T22:40:02.563Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I've been repeatedly astonished by the level of moral outrage amongst EAs and expressions of prior cluelessness over FTX 'fraud'. As an EA newcomer, I was assuming most everyone was aware and okay with it \"because consequentialism\". Ignoring the specific egregious act of asset misallocation that brought FTX down, I thought it's been more or less common knowledge that FTX has been engaged in, at a bare minimum, knowingly facilitating the purchase and sale of shares in Ponzi schemes, and that Alameda has been trading in the same, against counterparties made up in large part by a population of people who did not understand these assets and would have lacked the financial sophistication to be allowed into other, better regulated leveraged financial markets. I say 'knowingly' because SBF all but admitted this (with regard to 'yield farming') in an interview, and there's also an old video going around of the Alameda CEO expressing her initial discomfort with the schemes as well. I was aware of these schemes going on within maybe 1 week of first having heard of FTX &amp; SBF back in May of this year. My immediate take was \"Billionaire 'Robin Hood' figure is re-allocating wealth from crypto-bros to the global poor, animals, and the longterm future of humanity... eh, why not? But I sure hope he cashes out before the house of cards comes crashing down\".</p><p>The few times I mentioned any of this at a gathering, it was always met by something along the lines of \"Yeah, I guess... meh\". It never seemed to be a particularly surprising or contentious take.</p><p>The other thing that's weird to me is the idea of taking this firm stance that the ponzi schemes we did know about <i>weren't</i> going over the line, but that 're-investing customer funds' <i>was</i> going over the line. This feels like a fairly arbitrary line from which to go, on one side, \"eh, whatevs\" to \"this is an outrage!\" on the other side. It's convenient that the title of this post uses the term 'fraud' rather than 'theft'; that makes this criticism much easier to levy because ponzi schemes are by definition 'fraud'. In both cases, people are being taken advantage of. They're both against norms, both involve misleading customers, both involve customers losing a lot of money, and they're both illegal within well-regulated financial markets (which I know crypto is not, but still).</p><p>All of this to say... I don't think now is the time for handwringing about this... that time was many months ago for anyone who had a principled stance on the matter and was aware of the DeFi schemes FTX was openly invovled in; handwringing now comes off sort of as lamenting getting caught, with an after-the-fact rationalization for the arbitrary placement of the line that was crossed.</p><p>To be fair, I can't moralize about this either; I don't get to say \"I told you so\" because I didn't tell many people so, and certainly not anyone in a position of authority to do anything about it. Personally, I didn't have a principled stance on the matter, and I would have needed a quite strong principled stance to justify going against the social incentives for keeping that opinion to myself.</p><p>On the other question of the day, whether to give the money back: if you're in the subset who were aware of the FTX DeFi shenanigans and weren't lobbying for giving back or rejecting the money 3-6 months ago, little has materially changed about the issue on a moral level since then.</p><p><i>EA Forum moderators: If you strongly believe this post is net-negative for EA, please delete it.&nbsp;</i></p>", "parentCommentId": null, "user": {"username": "Chase Carter"}}, {"_id": "oaQyyw8ckLdnsQMLX", "postedAt": "2022-11-11T22:52:52.121Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>To answer for myself: I didn't participate in the crypto and FTX discussions, so I am very afraid that my only source of knowledge about FTX is what the general public has, plus a distrustful prior over crypto that got it right here.</p>\n", "parentCommentId": "z9fXwgpAhGTBYKYTh", "user": {"username": "Sharmake"}}, {"_id": "v6f54H2ZSWAmagfth", "postedAt": "2022-11-11T23:01:17.376Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I endorse the sentiment but I think anyone who was planning to commit fraud would say the same thing, so I don't think that promise is particularly useful.&nbsp;</p>", "parentCommentId": "Bw4L4LDKkCbLhuwmK", "user": {"username": "Lukas_Gloor"}}, {"_id": "FxxkqyFgm9G3b72GG", "postedAt": "2022-11-11T23:02:45.529Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I deep-dived into crypto in the latter half of 2020 because I was curious what was going on there. It took me a few months to see but what's said in the top-level comment were basically all true back then. I started my learning from scratch with an open mind, I would imagine had one looked into SBF activities with due diligence in mind, questionable behavior would be obvious to see.</p>\n", "parentCommentId": "KNyKmGWn9atahnQdP", "user": null}, {"_id": "NsWhtF3Bd4dDpj22g", "postedAt": "2022-11-11T23:37:26.952Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Even if they weren't infinitely advantageous, it seems like you'd have to be unrealistically sure that you can get away with shadiness and no bad consequences before risking it. If the downsides of getting caught are bad enough, then you can never be sufficiently confident in practice. And if the downside risk of some action isn't quite as devastating as \"maybe the entire EA movement has its reputation ruined,\" then it might anyway be the better move to come clean right away. For instance, if you're only 0.5 billion in the hole out of 30 billion total assets (say), and you've conducted your business with integrity up to that point, why not admit that you fucked up and ask for a bailout? The fact that you come clean should lend you credibility and goodwill, which would mitigate the damage. Doubling down, on the other hand, makes things a lot worse. Gambling to get back multiple billions really doesn't seem wise because if it was risk-free to make billions then a lot more people would be billionaires...&nbsp;<br><br>In any case, faced with the choice of whether to precommit to always act with integrity, it's not necessary for the pro-integrity arguments to be \"infinitely strong.\" The relevant question is \"is the precommitment better in EV or not?\" (given the range of circumstances you expect in your future). And the answer here seems\"yes.\" (Somewhat separately, I think people tend to underestimate how powerful and motivating it can be to have leadership with high integrity \u2013 it opens doors that would otherwise stay closed.)&nbsp;<br><br>You might say \"That's a false dilemma, that choice sounds artificially narrow. What if I can make a <i>sophisticated</i> precommitment that says I'll act with integrity under <i>almost </i>all circumstances, except if the value at stake is (e.g.) 100 billion and I'm <i>ultra-sure</i> I can get away with it?\" Okay, decent argument. But I don't think it goes through. Maybe if you were a perfect utilitarian robot with infinitely malleable psychology and perfect rationality, maybe then it would go through. Maybe you'd have some kind of psychological \"backdoor\" programmed in where you activate \"deceitful mode\" if you ever find yourself in a situation where you can get away with &gt;100 billion in profits. The problem though, in practice, is \"when do you notice whether it's a good time to activate 'deceitful mode'?\" To know when to activate it, you have to think hypothetically-deceitful-thoughts even earlier than the point of actually triggering the backdoor. Moreover, you have to take actions to preserve your abilities to be a successful deceiver later on. (E.g., people who deceive others tend to have a habit of generally not proactively sharing a lot of information about their motives and \"reasons for acting,\" while high-integrity people do the opposite. This is a real tradeoff \u2013 so which side do you pick?) These things aren't cost free! (Not even for perfect utilitarian robots, and certainly not for humans where parts of our cognition cannot be shut off at will.) In reality, the situation is like this: you either train your psychology, your \"inner <a href=\"https://www.amazon.co.uk/Elephant-Brain-Hidden-Motives-Everyday/dp/0190495995\">elephant in the brain</a>,\" to have integrity to the very best of your abilities (it's already hard enough!), or you do not. Retaining the ability to turn into a liar and deceitful manipulator \"later on\" doesn't come cost-free; it changes you. If you're planning to do it when 100 billion are at stake, that'll reflect on how you approach other issues, too. (See also my comment in <a href=\"https://www.lesswrong.com/s/nyEFg3AuJpdAozmoX/p/iCfdcxiyr2Kj8m8mT?commentId=kGWk4jK6zECQfNepe#comments\">this comment section</a> for more reasons why I don't think it's psychologically plausible for people to simultaneously be great liars and deceivers but also act perfectly as though they have high integrity.)&nbsp;</p>", "parentCommentId": "RKYrS7wG8DB5sHyK6", "user": {"username": "Lukas_Gloor"}}, {"_id": "wQhpXunoLdq8wppGP", "postedAt": "2022-11-12T00:33:05.798Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I do see a significant moral difference between allowing &nbsp;people to make potentially risky decisions and deceiving them about how much risk is involved. As an exchange, FTX was theoretically just serving to coordinate buyers and sellers who wanted to transact in the first place. If you believe that at least a portion of crypto is merely volatile and not fraudulent, then you're just facilitating risky decisions, not scamming people. Doubly so if you believe even a tiny subset of DeFi provides net value, as many of FTX's customers still believe.</p><p>But in practice FTX was taking much more risky behavior, without telling its users, and in fact explicitly denying that such behavior was occurring. Nobody thought it was risky to deposit USD into FTX, if you hadn't bought any crypto. FTX assured users it wasn't. But if you have USD sitting on the site right now, there's a good chance you're never getting it back. To state the obvious: that's fraud, and it's wrong. And I think it's different than letting people take risks if they want to.</p>", "parentCommentId": "z9fXwgpAhGTBYKYTh", "user": {"username": "Zach Furman"}}, {"_id": "5qgAq2REb3ggnh6fz", "postedAt": "2022-11-12T00:42:38.187Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Counterpoint to \"had one looked into SBF activities with due diligence in mind, questionable behavior would be obvious to see\":&nbsp;</p><p>Many high profile VC firms invested in FTX (e.g. <a href=\"https://www.nytimes.com/2022/11/11/technology/ftx-investors-venture-capital.html\">Sequoia, SoftBank, BlackRock</a>). They raised at astronomical valuations as recently as <a href=\"https://techcrunch.com/2022/11/09/sequoia-capital-marks-its-ftx-investment-down-to-zero-dollars/\">January of this year</a>. &nbsp;It seems unlikely to me that any due diligence into the inner workings of the business by EA higher-ups would have come up with something that these VCs apparently did not.&nbsp;</p><p>OTOH, I've been following crypto closely for a little over a year now and I had heard rumblings along the lines of the top-level comment. It is my impression that most (maybe all) of the assumptions of bad behavior were based on speculation and circumstantial evidence rather than hard proof.&nbsp;</p><p>Perhaps that speculation and circumstantial evidence was enough to be careful with too closely associating with SBF/FTX, I don't know, but it seems unlikely to me that due diligence before the last few days would have revealed obvious bad behavior.&nbsp;</p>", "parentCommentId": "FxxkqyFgm9G3b72GG", "user": {"username": "Kevin_Cornbob"}}, {"_id": "3dW4PovPgPPpNiar4", "postedAt": "2022-11-12T01:35:32.536Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I doubt it's the clarity of EA's take on fraud that is the problem because there are real world consequences of committing fraud which includes a potential jail term which in most people's eyes is a bigger deterrent than EA's opinion on fraud. EA can be as clear as it wants on its normative positions but to the extent that senior folks in the EA community are able to convince people that the fate of humanity is on the line then there will be more norm breaking in the future. Think very hard of the entire distribution of things one can justify if they think that humanity is at risk of extinction. Most people will not try the extreme measures but you should take seriously the idea that some will try even the most extreme measures especially when the conventional tactics keeps failing and it seems like time is running out.</p>\n", "parentCommentId": null, "user": null}, {"_id": "5QseQqkfCeHLjXm6x", "postedAt": "2022-11-12T08:54:49.214Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Thanks, that seems really bad and deceptive. Do you also have examples of tweets or people that were paid off by FTX to promote one of those coins?</p>\n", "parentCommentId": "Cpvp5pi5AvEhKGQLk", "user": {"username": "Erich_Grunewald"}}, {"_id": "BypE96WpTS8Wupgkh", "postedAt": "2022-11-12T09:48:59.198Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>As far as I can tell there is no reason to condemn fraud, but not the stuff SBF openly endorsed, except that fraud happened and hit the \"bad\" outcome.&nbsp;<br><br>From https://conversationswithtyler.com/episodes/sam-bankman-fried/<br><br>COWEN: Okay, but let\u2019s say there\u2019s a game: 51 percent, you double the Earth out somewhere else; 49 percent, it all disappears. Would you play that game? And would you keep on playing that, double or nothing?&nbsp;<br>BANKMAN-FRIED: With one caveat. Let me give the caveat first, just to be a party pooper, which is, I\u2019m assuming these are noninteracting universes. Is that right? Because to the extent they\u2019re in the same universe, then maybe duplicating doesn\u2019t actually double the value because maybe they would have colonized the other one anyway, eventually.&nbsp;<br>COWEN: But holding all that constant, you\u2019re actually getting two Earths, but you\u2019re risking a 49 percent chance of it all disappearing.&nbsp;<br>BANKMAN-FRIED: Again, I feel compelled to say caveats here, like, \u201cHow do you really know that\u2019s what\u2019s happening?\u201d Blah, blah, blah, whatever. But that aside, take the pure hypothetical.&nbsp;<br>COWEN: Then you keep on playing the game. So, what\u2019s the chance we\u2019re left with anything? Don\u2019t I just St. Petersburg paradox you into nonexistence?&nbsp;<br>BANKMAN-FRIED: Well, not necessarily. Maybe you St. Petersburg paradox into an enormously valuable existence. That\u2019s the other option.<br><br>One of my friends literally withdrew everything from FTX after seeing this originally, haha. Pretty sure the EV on whatever scheme occurred was higher than 51/49, so it follows....</p>", "parentCommentId": null, "user": {"username": "Agrippa"}}, {"_id": "r9nt55cXJhMvKXvpM", "postedAt": "2022-11-12T09:54:56.762Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>As somebody in the industry I have to say Alameda/FTX pushing MAPS was surreal and cannot be explained as good faith investing by a competent team.&nbsp;</p>", "parentCommentId": "Cpvp5pi5AvEhKGQLk", "user": {"username": "Agrippa"}}, {"_id": "rBkf3atpSNxvvvzen", "postedAt": "2022-11-12T10:03:15.311Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>You really need to provide proof for these sweeping allegations. I know people are worried with the current situation and I agree fraud is likely, but I\u2019m concerned that someone making such extreme claims with 0 links or evidence besides claiming to be an insider is so highly upvoted.</p>\n<p>If you make an extreme claim, the burden of providing sources is on you.</p>\n", "parentCommentId": "rnpnzzBLKPbM6ZqxR", "user": {"username": "Wil Perkins"}}, {"_id": "9bCL6Tga9etD2dx6q", "postedAt": "2022-11-12T10:42:44.645Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>That\u2019s so interesting, I listened to this interview but don\u2019t remember this answer, I don\u2019t know if I stopped paying attention or just didn\u2019t find it noteworthy. Definitely something to reflect on if it\u2019s the latter.</p>\n", "parentCommentId": "BypE96WpTS8Wupgkh", "user": {"username": "bec_hawk"}}, {"_id": "iuirS7C9stspTB4TN", "postedAt": "2022-11-12T12:51:22.317Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>This seems to be a case for 'trust but verify' - it's also worth remembering that reputational risk and purposes rebound differently for different participants.</p>", "parentCommentId": "5qgAq2REb3ggnh6fz", "user": {"username": "cbz"}}, {"_id": "azQjHkqiM6M97usC2", "postedAt": "2022-11-12T15:23:38.782Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Counterpoint to this: a <i>lot</i> of VC investments in crypto were very dodgy. I can't recall exact project names, but I remember regularly seeing news of the form \"a16z just backed us with 300M!\" on projects which are clearly zero-sum and don't have the market cap to generate &gt;300M in fees, like blockchain games. VC investment doesn't seem like as strong a signal in the crypto space as in other spaces.</p>", "parentCommentId": "5qgAq2REb3ggnh6fz", "user": {"username": "Oliver Balfour"}}, {"_id": "P4ChvFamYeCS9p3yA", "postedAt": "2022-11-12T15:43:11.506Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote><p>Evan do we really have enough information to conclude this?</p></blockquote><p>I realise I have 18 hours more information at hand, but I think yes, we can conclude this with high confidence:</p><ol><li>SBF claimed FTX had enough cash to cover all withdrawals and FTX US was totally fine (tweets deleted; see <a href=\"https://cointelegraph.com/news/ftx-founder-sam-bankman-fried-removes-assets-are-fine-flood-from-twitter).\">https://cointelegraph.com/news/ftx-founder-sam-bankman-fried-removes-assets-are-fine-flood-from-twitter).</a></li><li>Now they are both in bankruptcy &nbsp;proceedings, along with Alameda. Proceedings (<a href=\"https://storage.courtlistener.com/recap/gov.uscourts.deb.188448/gov.uscourts.deb.188448.1.0.pdf\">https://storage.courtlistener.com/recap/gov.uscourts.deb.188448/gov.uscourts.deb.188448.1.0.pdf</a>). Several executives SBF reached out to to discuss bailouts have shared that the deposit windfall is $5-10b (can't find the link any more, but I've seen this claimed by several people). SBF has resigned.</li><li>$200M-1B of FTX's reserves have been withdrawn after bankruptcy filing. FTX claims they were hacked. (<a href=\"https://Some of FTX's reserves have just been stolen (https://www.coindesk.com/business/2022/11/12/ftx-crypto-wallets-see-mysterious-late-night-outflows-totalling-more-than-380m/\">https://www.coindesk.com/business/2022/11/12/ftx-crypto-wallets-see-mysterious-late-night-outflows-totalling-more-than-380m/</a>).</li></ol><blockquote><p>I don't think that merely lending out deposits is 'fraudulent in spirit'.</p></blockquote><p>I don't think the bank analogy is super accurate, because fractional reserve banking is heavily regulated: you can only loan so much, you're restricted in how risky these loans can be, and you have the FDIC backstopping deposits in the case of crises/fraud. On the other hand, it seems very likely FTX violated their own ToS to loan <i>most </i>of their reserves to SBF's <i>insolvent crypto prop shop</i>. There's no backstop and no accountability</p>", "parentCommentId": "uQRJjw6xYQtpvywNR", "user": {"username": "Oliver Balfour"}}, {"_id": "qWcDnozPoTJEAzSNd", "postedAt": "2022-11-12T20:08:12.231Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>For those interested in discussions on this, linking out to other posts, too, see the question <a href=\"https://forum.effectivealtruism.org/posts/CcNaQmrtdeC9PPixK/under-what-conditions-should-ftx-grantees-voluntarily-return\">Under what conditions should FTX grantees voluntarily return their grants?</a> by sawyer.</p>", "parentCommentId": "CripXx3akQLJZKf5t", "user": {"username": "MichaelStJules"}}, {"_id": "nKWXKfcvT5sxrNi7o", "postedAt": "2022-11-12T20:18:21.051Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I agree that the arguments people are making here don't seem very scope-sensitive, and I'm not about to make a very scope-sensitive argument either. However, it's worth considering the possibility that the damage to the community and public trust in EA could be greater. How many potential EAs do we lose out on? How much harder is it to engage politically and with institutions? We've been having a hard time spending money well, at least within longtermism, so the extra donations (including extra donations had they not been caught) were plausibly worth much less per dollar than the marginal grants. Poor public perception will make using our resources effectively harder going forward.</p>", "parentCommentId": "RKYrS7wG8DB5sHyK6", "user": {"username": "MichaelStJules"}}, {"_id": "AaeaGhJCiTeRSmqaT", "postedAt": "2022-11-12T20:27:10.774Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote><p>I do see a significant moral difference between allowing &nbsp;people to make potentially risky decisions and deceiving them about how much risk is involved.</p></blockquote><p><br>To be clear, <i>I completely agree that the latter is worse than the former. </i>I am arguing that the two wrongs (the known Ponzi schemes and the unknown-till-now squandering of depositor funds) exist on the same spectrum of \"dishonesty\" and \"cheating people\".<br><br>That said, \"allowing people to make potentially risky decisions\" is not a fair representation of promoting and benefitting from Ponzi schemes. Ponzi schemes are fraud. People who knowingly promote them are acting as con men when they do so. SBF has publicly described the process and its absurdity in great detail... he knew exactly what he was selling.&nbsp;<br><br>I'm disturbed by the inability of many even now to acknowledge, in <i>retrospect (</i>and independent of whether they 'should' have known before the collapse), that these known schemes were fraudulent. I see a lot of scrambling to justify them under the guise of \"they weren't <i>technically </i>lying\" or \"they weren't <i>technically &nbsp;</i>illegal\" (which isn't entirely clear to me, though it is clear that if the same schemes had been happening in the open in US jurisdiction and not within the crypto-realm they would have been <i>massively and obviously illegal</i>, and the FTC/SEC would have <i>destroyed</i> them).<br>&nbsp;</p><blockquote><p>If you believe that at least a portion of crypto is merely volatile and not fraudulent, then you're just facilitating risky decisions, not scamming people</p></blockquote><p>This statement does not logically follow, and does not align with finance industry norms (and laws) which obligate brokers to conduct due diligence before selling a given security. If the head of NASDAQ went on the news and said \"Yeah, XYG [traded on our exchange] is basically a total Ponzi scheme, lol\" (as SBF basically did with Matt Levine), there would be an immediate and colossal legal and ethical shitstorm. The existence of all the remaining, legitimate companies also being traded on the NASDAQ would not be relevant for the ensuing lawsuits. You appear to be arguing that as long as SBF wasn't dealing <i>solely&nbsp;</i> in frauds, it's okay; whereas the sensible view for someone taking a strong moral stance is that it's only okay if SBF <i>wasn't knowingly </i>dealing in <i>any &nbsp;</i>frauds.</p>", "parentCommentId": "wQhpXunoLdq8wppGP", "user": {"username": "Chase Carter"}}, {"_id": "xqEiGm9n2j3WeGy69", "postedAt": "2022-11-12T21:02:23.012Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I agree here, since I don't think crypto is at all viable without crimes.</p>\n<p>Here's a link to why I dislike crypto:</p>\n<p><a href=\"https://www.currentaffairs.org/2022/05/why-this-computer-scientist-says-all-cryptocurrency-should-die-in-a-fire\">https://www.currentaffairs.org/2022/05/why-this-computer-scientist-says-all-cryptocurrency-should-die-in-a-fire</a></p>\n", "parentCommentId": "AaeaGhJCiTeRSmqaT", "user": {"username": "Sharmake"}}, {"_id": "MugYo6SeCmJieHKo2", "postedAt": "2022-11-13T04:52:36.771Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>These aren\u2019t as extreme as they seem. They are genuinely just the way crypto functions. Here is a link to SBF, this past April, explaining how one of the largest \u201cincome\u201d generating systems in crypto (that he also engaged heavily in, and in a way helped to popularize) is a ponzy scheme, and being totally unworried about stating this fact.\n<a href=\"https://www.bloomberg.com/news/articles/2022-04-25/sam-bankman-fried-described-yield-farming-and-left-matt-levine-stunned\">https://www.bloomberg.com/news/articles/2022-04-25/sam-bankman-fried-described-yield-farming-and-left-matt-levine-stunned</a></p>\n", "parentCommentId": "rBkf3atpSNxvvvzen", "user": {"username": "alice cristina "}}, {"_id": "jEu5AALjDsCxQuMoN", "postedAt": "2022-11-13T22:42:18.990Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>This is not 'just the way crypto functions'. There is very wide variance in the ethical integrity of different crypto protocols and projects.&nbsp;</p><p>Bitcoin is one thing.</p><p>Highly decentralized layer-1 protocols such as Cardano and Ethereum are another thing.</p><p>Oracle protocols such as Chainlink are another.</p><p>Centralized exchanges vary a lot -- Kraken seems to have quite high openness, integrity, transparency, and auditability; whereas FTX did not.</p><p>There are lots of scammers in crypto. There are also many highly ethical, honest, and constructive leaders.</p><p>Just as it would be a shame for outsiders to reject EA as fraudulent just because FTX was, it would be a shame for EAs to reject all crypto as fraudulent just because FTX was.</p>", "parentCommentId": "MugYo6SeCmJieHKo2", "user": {"username": "geoffreymiller"}}, {"_id": "DxL26fe6c8FDK9iBM", "postedAt": "2022-11-15T10:58:39.775Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>The main thesis of your post (we should unequivocally condemn fraud) is correct, but the way you defend it is in conflict with it (by saying it's wrong for instrumental reasons).</p><p>Here's the PR argument:</p><blockquote><p>I think the lasting consequences to EA\u2014and the damage caused by FTX to all of their customers and employees\u2014will likely outweigh the altruistic funding already provided by FTX to effective causes.</p></blockquote><p>This weakens the condemnation, by making it be about the risks of being found out, not the badness of the action.</p><p>When you explain that pre-committing to not commit fraud is an advantageous strategy, I read this as another instrumental argument.</p><p>It's hard to condemn things unequivocally from a purely utilitarian point of view, because then all reasons are instrumental. I'm not saying your reasons are untrue, but I think that when non-utilitarians read them, they won't see an unequivocal condemnation, but a pragmatic argument that in other contexts could be turned in defence of fraud, if the consequences come out the other way.</p><p>That said, Jack Malde's reply to me is a pretty good attempt at unequivocal condemnation from within a utilitarian frame, because it doesn't talk about conditions that might not hold for some instance of fraud. (But it's not necessarily correct.)</p>", "parentCommentId": "vBfs9yNFcJojZTW2C", "user": {"username": "David Mears"}}, {"_id": "wMHLCChL5SgWMaGyS", "postedAt": "2022-11-15T21:01:06.948Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>The portion you quote is included at the very end as an additional point about how even if you don't buy my primary arguments that fraud in general is bad, in this case it was empirically bad. It is not my primary reason for thinking fraud is bad here, and I think the post is quite clear about that.</p>\n", "parentCommentId": "DxL26fe6c8FDK9iBM", "user": {"username": "evhub"}}, {"_id": "axHhc8eMLyc8bFE4f", "postedAt": "2022-11-15T21:54:01.662Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>Earlier this year ARC received a grant for $1.25M from the FTX foundation. We now believe that this money morally (if not legally) belongs to FTX customers or creditors, so we intend to return $1.25M to them.</p><p>It may not be clear how to do this responsibly for some time depending on how bankruptcy proceedings evolve, and if unexpected revelations change the situation (e.g. if customers and creditors are unexpectedly made whole) then we may change our decision. We'll post an update here when we have a more concrete picture; in the meantime we will set aside the money and not spend it.</p><p>We feel this is a particularly straightforward decision for ARC because we haven't spent most of the money and have other supporters happy to fill our funding gap. I think the moral question is more complex for organizations that have already spent the money, especially on projects that they wouldn't have done if not for FTX, and who have less clear prospects for fundraising.</p><p>(<a href=\"https://alignment.org/funding-from-ftx/\">Also posted on our website</a>.)</p>", "parentCommentId": null, "user": {"username": "Paul_Christiano"}}, {"_id": "7h6GCWQt4oqjsFWcb", "postedAt": "2022-11-16T00:18:22.600Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<blockquote><p>I think the Utilitarian arguments you presented are quite strong, such as precommiting to certain principles being very advantageous, but surely they're not infinitely advantageous right? A few billion is quite a lot.</p></blockquote><p>To the people voting 'disagree', what OP said above is clearly true. Perhaps people are taking it to imply that the utilitarian course of action here is correct, but I see no such implication.<br><br>I think a better forum norm would be for someone to comment spelling out the perceived implication and why they disagree with it, and have other people upvote that.&nbsp;</p>", "parentCommentId": "RKYrS7wG8DB5sHyK6", "user": {"username": "Tom_Ash"}}, {"_id": "JZ7HnEDHxcqSn5aCH", "postedAt": "2022-12-02T12:05:49.521Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>As a note, while I agree people though that via Alamada, FTX was \"Using exchange data to trade against their own customers\", the fact that Alamaeda lost so much money confuses me as to if this was actually true.</p>", "parentCommentId": "rnpnzzBLKPbM6ZqxR", "user": {"username": "nathan"}}, {"_id": "mGJW2ZZwjCzfkDGWx", "postedAt": "2022-12-02T12:07:39.982Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": "<p>I want to agree with this, but I think that if SBF had \"gotten away with it\" we'd have taken his money, which makes me doubt our sincerity here. It sounds a lot more like \"don't get caught doing fraud\"</p>", "parentCommentId": null, "user": {"username": "nathan"}}, {"_id": "bsofLfREHuKD9pJw3", "postedAt": "2022-11-11T01:03:47.142Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": null, "parentCommentId": "RKYrS7wG8DB5sHyK6", "user": null}, {"_id": "nfmQzs9uSryeXdCJd", "postedAt": "2022-11-11T01:38:13.749Z", "postId": "XHrHsrQGyr4NnqCA7", "htmlBody": null, "parentCommentId": "bsofLfREHuKD9pJw3", "user": null}]