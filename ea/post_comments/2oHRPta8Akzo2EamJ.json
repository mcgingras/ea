[{"_id": "dJb2yNGFN83j4eYHG", "postedAt": "2014-11-05T12:06:47.389Z", "postId": "2oHRPta8Akzo2EamJ", "htmlBody": "<p>Relevant: <a href=\"https://intelligence.org/files/CognitiveBiases.pdf\">https://intelligence.org/files/CognitiveBiases.pdf</a></p>\n", "parentCommentId": null, "user": {"username": "RyanCarey"}}, {"_id": "Asw5qLddZdv62ohzj", "postedAt": "2014-11-05T17:19:44.722Z", "postId": "2oHRPta8Akzo2EamJ", "htmlBody": "<p>The biases which Peter Hurford discusses in his classic post <a href=\"http://www.effective-altruism.com/ea/53/why_im_skeptical_about_unproven_causes_and_you/\">Why I'm skeptical about unproven causes (and you should be too)</a> seem to be relevant here.</p>\n", "parentCommentId": null, "user": {"username": "arrowind"}}, {"_id": "a7RbKv6dcp8qbZQra", "postedAt": "2014-11-05T19:25:18.850Z", "postId": "2oHRPta8Akzo2EamJ", "htmlBody": "<p>Vaguely related point:</p>\n<p>I sometimes see proponents of cause X (for almost all X) say things like &quot;consider all the cognitive biases that would cause you not to think that cause X is the most important! Therefore you need to pay more attention to cause X.&quot; I think this is an extremely cheesy tactic--possibly even <a href=\"http://legacy.earlham.edu/~peters/writing/rudeness.htm\">logically rude</a> depending on how it's employed.</p>\n<p>For many reasonable propositions you can concoct an almost infinite list of biases pushing in both directions on it. Ironically, people who use this form of argument seem to be themselves suffering from confirmation bias about the proposition &quot;cognitive bias causes people not to believe that cause X is important&quot;! And also a <a href=\"https://en.wikipedia.org/wiki/Bias_blind_spot\">bias blind spot</a> (&quot;I'm less prone to cognitive bias than all those people who believe in cause Y&quot;).</p>\n", "parentCommentId": null, "user": {"username": "Ben_Kuhn"}}, {"_id": "46sFN9XKv7nAd3evP", "postedAt": "2014-11-07T01:39:19.002Z", "postId": "2oHRPta8Akzo2EamJ", "htmlBody": "<p>I think, as this illustrates, talking about biases usually isn't that helpful when working out what to do. There are often plausible biases on both sides.</p>\n<p>This is a pretty common criticism against behavioral finance, which attempts to use cog biases to better understand financial markets, and was one of the first major attempts at application. Theories based on biases are pretty weak unless backed up with a model or some relevant empirical evidence.</p>\n<p>At 80k, we don't find understanding biases to be that big a part of making good career decisions. The main ways it comes up is that it raises my credence that ppl tend not to consider enough options and that it's useful to use a checklist when comparing options (i.e. be more systematic). </p>\n", "parentCommentId": null, "user": {"username": "Benjamin_Todd"}}, {"_id": "9b5gjAaaCCzPR4tsy", "postedAt": "2014-11-12T00:37:49.223Z", "postId": "2oHRPta8Akzo2EamJ", "htmlBody": "<p>I think the biggest bias here is that most donors would like to be able to point to their clear successes and the people they helped. For most folks, this leans them against x-risk because a) you'll very likely fail to lower x-risk b) even if you succeed, you usually won't be able to demonstrate it.</p>\n<p>On the other hand, it's also harder to tell if you've failed.</p>\n<p>Like Ben, I doubt this kind of analysis is going to change people's minds much one way or the other.</p>\n", "parentCommentId": null, "user": {"username": "Robert_Wiblin"}}]