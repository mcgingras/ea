[{"_id": "Nknu5FDe3HagjBGmo", "title": "What paper on EA should I present in class on Philosophy and Economics?", "postedAt": "2023-03-03T18:59:39.613Z", "htmlBody": "<p>I volunteered to make a presentation about a paper on EA to a reading group / class of varied academics (undergrads, graduates from different fields, etc.) on Philosophy and Economics (here's <a href=\"https://t.co/8uZWGrEDjM\">their old website</a>). Which paper should I pick?<br>It's not that I have no idea about it; this is more an embarrassment of riches... I want to present something succint, written for academics in both Economics and Philosophy, and presenting Longtermism in convincing way.<br>Also, two of the young professors involved are acquainted with EA, but not convinced at all (where did we fail, guys?)<br>Yeah, I know I should totally check <a href=\"https://www.forethought.org/econ-summer-course\">Phil Trammell's course syllabus</a>. Any particular paper there? Anything else?</p>", "user": {"username": "Ramiro"}}, {"_id": "ApiZbPmfiPSXXw8dR", "title": "AI Governance & Strategy: Priorities, talent gaps, & opportunities", "postedAt": "2023-03-03T18:09:26.691Z", "htmlBody": "", "user": {"username": "Akash"}}, {"_id": "x4uANMyFyxhfizF6n", "title": "Veg*ns, what supplements do you take?", "postedAt": "2023-03-03T16:50:22.026Z", "htmlBody": "<p>I'm yet to find a simple, comprehensive, reliable guide to supplements for vegetarians and vegans. So instead of spending more time on Google I figured I'd just ask you all what you do.</p><p>I'm lactovegetarian (\"veggie-no-eggs\"). I take creatine and beta-alanine supplements. With the usual caveats (anecdata, placebo effects) I noticed a <i>huge</i> difference in the gym after I started taking creatine supplements. I think it's likely I should be taking some other stuff (B12? Iron?) and plausible that the beta-alanine isn't that useful.</p><p>There's some other interesting Forum content in the <a href=\"https://forum.effectivealtruism.org/topics/dietary-change\">\"Dietary Change\" topic</a>. <a href=\"https://forum.effectivealtruism.org/posts/FxToCd5fwwES7XWcb/fixing-the-vegetarian-plate-a-new-guide-aims-to-correct\">This guide</a> looks useful but is 474 pages long (!). I've found Elizabeth's posts on <a href=\"https://forum.effectivealtruism.org/posts/HAfRsn27uGwxdzHcj/review-of-examine-com-s-vitamin-write-ups\">Examine.com's vitamin reviews</a> and <a href=\"https://forum.effectivealtruism.org/posts/dbw2mgSGSAKB45fAk/vegan-nutrition-testing-project-interim-report\">testing vegan nutrient levels</a> somewhat useful (but wish there was way more of this kind of research!).&nbsp;</p><p><a href=\"https://veganhealth.org/\">VeganHealth.org</a> at least <i>looks</i> useful and reliable to me, but I don't know how good their evidence reviews actually are.</p><p>What supplements do you take? And what resources have you found helpful?</p>", "user": {"username": "Stephen Clare"}}, {"_id": "BM62tDLexwxSJ4Npa", "title": "Problems of people new to AI safety and my project ideas to mitigate them", "postedAt": "2023-03-03T17:35:20.071Z", "htmlBody": "<h3>TL DR</h3><p>I talked to people who got interested in AI safety recently to discuss their problems. The interviewees reported that the field is hard to navigate for those who start their way into it. It is also hard to advance a career after the initial introduction to AI safety, which is probably a major bottleneck for the field. Also, some people experience anxiety, hopelessness, which affects their mental health and well-being, and this problem, in my opinion, gets less attention than it deserves.</p><h2>&nbsp;</h2><h2>Background</h2><p>It seems like people who are new to the AI safety, face a number of difficulties, and, although there are <a href=\"https://forum.effectivealtruism.org/posts/SuvMZgc4M8FziSvur/analysis-of-ai-safety-surveys-for-field-building-insights\">some</a> <a href=\"https://www.lesswrong.com/posts/a8fFLg8qBmq6yv53d/resource-stanford-talk-laying-out-existential-risk-from-ai\">studies</a> exploring members of the AI safety community, I did not find any studies exploring these difficulties in-depth, which are relatively new, and explore topics similar to what I am interested in, so I decided to talk to people new to the field and listen about their problems.</p><h2>&nbsp;</h2><h2>Methodology</h2><p>I conducted 14 interviews with people who recently joined the AI safety field. Most of them got interested in AI safety more than 6 months and less than 18 months ago. I had a script for interviews, but they were semi-structured, and each interview was somewhat different from the others, so the data I collected is more qualitative rather than quantitative, and my goal is to get intuitions about everyday problems of my interviewees and possible bottlenecks in the field, so I can get ideas for field-building projects. Also, the sample size is too small for a meaningful statistical analysis so I decided not to focus on counting percentages of certain responses since they might mislead.</p><h2>&nbsp;</h2><h2>Results</h2><h3>&nbsp;</h3><h3>How do people get interested in AI safety? Are there any common patterns in their stories, or do they significantly different?</h3><p>Several people said they got interested in AI safety by reading Nick Bostrom's \"Superintelligence\u201d book. I did not find any other patterns.</p><p>&nbsp;</p><h3>What projects made by EA and AI safety community are the most valuable for people who are completely new to the field?</h3><p>Two projects people often mentioned as valuable to them are&nbsp;<a href=\"https://80000hours.org/speak-with-us/?int_campaign=2021-08__primary-navigation\">80 000 hours career advising</a>&nbsp;and&nbsp;<a href=\"https://www.agisafetyfundamentals.com/\">AGI safety fundamentals course</a>.</p><p>80 000 hours career advising helps people to better understand their preferences and abilities, connect with the right people and suggest the next steps. AGI safety fundamentals is a course covering the basics of AI safety which people may complete by themselves or with a learning group.</p><p>These projects helped my interviewees, but it seems like in their current state they are hard to scale. Right now they help only a fraction of people applying for these programs because their resources are limited.</p><p>&nbsp;</p><h3>What do interviewees think about AGI-related existential risks and how it affects their mental health?</h3><p>My interviewees\u2019 AGI timelines vary a lot from several years to several decades. Some think that we are basically doomed, and others predict that P(Doom) &lt; 10%. It seems like distribution resembles that of the field in general.</p><p>The effect of doomerism on mental health also has a large degree of variability. Some people do not report any AGI-related anxiety at all, but nearly half of the respondents report some degree of anxiety or depressive symptoms from mild to strong and debilitating. Also, some people mentioned that they don't have plans long into the future. One of my interviewees said that they only do short-term money investments, and several others mentioned that they are unsure whether they want to have kids if the world will die anyways.</p><p>&nbsp;</p><h3>Do most people struggle to get a position in the AI safety field?</h3><p>Only 2 of my 14 interviewees have a financially stable job in the AI safety field although many of them applied for numerous fellowships and positions in AI safety organizations. Two of them said they don't know how to earn money by contributing to AI safety, and they only continue doing it because they have enough money so they can do whatever they want.</p><p>I recognized 3 patterns of career development among people with no stable positions:&nbsp;<br>&nbsp;</p><ul><li>Students who focus on getting a degree now and expect to get a position later.</li><li>People who work as independent researchers or contribute to non-profit field-building projects.</li><li>People who work in a job are somewhat related to AI safety. For example, implementing GDPR compliance in a non-AI safety company, or working in an AI-focused cyber security startup.</li></ul><p>&nbsp;</p><h3>Is the AI safety field hard to navigate for newcomers?</h3><p>Almost all my interviewees mentioned that the AI safety field is hard to navigate in. Especially for people with backgrounds unusual for the field, like psychology or product management in startups. People mentioned that there are many research topics, and many people to follow and it is usually not structured in a newcomer-friendly way</p><p>There are several projects aimed to mitigate this problem. As I mentioned earlier, many of my interviewees mentioned that the AGI safety fundamentals course and 80 000 hours career advising helped them to navigate the field and better understand the career paths they want to pursue, but do not eliminate the problem completely as the field is very complex and consists of many narrow subfields that are not structured in a newcomer-friendly way and are hard to navigate.</p><p>Also, both AGI safety fundamentals and 80 000 career advising accept only a fraction of applications they receive since they have limited capacity, so they mitigate the problem but do not solve it completely.</p><p>A number of the interviewees mentioned that the AI safety community is very helpful and generally people are willing to help newcomers to navigate the field.</p><p>&nbsp;</p><h3>Is there a request for mentorship or guidance from experienced people?</h3><p>Despite the problems I described earlier, there are way more people in junior positions than the field can absorb.</p><p>This problem combined with the previous problems that the field is complex and consists of many specialized subfields makes it hard to navigate in cutting-edge research. It's hard to know for sure what to do to get a job and make a meaningful contribution, and too few people to steer in the right direction.</p><p>For example, one interviewee said, they are interested in interpretability research for AI safety, but they are unsure what are the best ways to do useful research and the only people who are qualified to help and to steer in the right direction are people doing interpretability research in the small number of organizations like OpenAI or Anthropic.</p><p>&nbsp;</p><h3>Do people feel emotionally isolated due to the lack of connections with people who care about AI safety?</h3><p>Almost half of the interviewees said they don't have people around them who are also interested in AI safety. Almost all my interviewees who live outside of the US, and the UK mentioned this problem, and a number of them said that if they want to pursue a career in AI safety they probably have to move to the US or the UK, which is also a barrier</p><p>&nbsp;</p><h3>How hard is it to keep up with AI safety research, news, and other important information?</h3><p>Most of my interviewees did not mention any problems in keeping up with important information in the AI safety field, but some said that there is a lot of important stuff, scattered all over the places, like LessWrong, personal blogs, Twitter, news websites, and so on. These bits of valuable information are usually poorly structured so it is hard to digest everything and keep up with everything.</p><h2>&nbsp;</h2><h2>Study limitations</h2><h3>Sample biases</h3><p>The people I interviewed are mostly members of the \u201c<a href=\"https://www.lesswrong.com/posts/jGW3FwkpFdsjrpMe5/https%3A%2F%2Fbit.ly%2F3HiXUrv\">AI alignment</a>\u201d Slack community, and it takes some knowledge of the field to get there, so I suspect, that people who got interested in AI safety very recently, or people who have a more casual interest in AI alignment are underrepresented in my sample.</p><p>Another possible bias stems from the fact that when I asked people to give me interviews, I stated that I want to ask about their problems, so people who don't experience problems in AI safety might have been less prone to contact me.</p><h3>&nbsp;</h3><h3>Heterogeneity among respondents</h3><p>Due to the relatively small sample size and heterogeneity among respondents in terms of their location, background, interests, and employment status, I did not find patterns within specific groups of my target audience (e.g. people interested in AI governance, or people from the EU) This might be done with bigger sample size or more uniformity among respondents.</p><h3>&nbsp;</h3><h2>Discussion</h2><p>One of my interviewees mentioned that they know a couple of talented people who initially got interested in AI safety but because of the problems I discuss in this post they lost interest and decided to work on other topics. It was sad to hear. The field might have an enormous impact on humanity's future, and problems make it unfriendly to bright people who want to contribute to it.</p><p>I believe that soon the Overton window on public perception of AI-related risks is moving and the AI safety field will experience a big surge of money and talent. Some problems will be much easier to solve with the influx of money, other resources, and new people with new expertise, but I believe that some other problems require action now, before this surge.</p><p>In the end, I want to discuss my thoughts on what projects I would love to see so we can alleviate critical bottlenecks now and help the field to scale in the future.</p><h3>&nbsp;</h3><h3>Onboarding into the field for beginners</h3><p>As I showed earlier, it is hard for beginners to understand where to start. There are many subfields in AI safety, and often there are no beginner-friendly introductions to them.</p><p>Most of my interviewees reported feeling disoriented when they tried to navigate the field at first. Although projects like 80 000 hours career advising, AGI safety fundamentals, and others help to mitigate this problem to some degree, they do not resolve it completely, and it also seems to me that they can not easily be scaled at the moment.</p><p>This led me to two ideas: a. It's a good idea to support existing projects which bring the most value and develop them in a way that makes them easier to scale. b. People who were the target audience of my research, who are not top researchers, but competent enough so they can help people who don't know the field at all. In my experience, there are plenty of people who might be ready to do it and I think that such advising might bring a lot of value.</p><h3>&nbsp;</h3><h3>Scalable Mentorship</h3><p>As I discussed earlier, one of the major bottlenecks in the AI safety field is that there are far more \"junior\u201d people than the industry absorbing. Since the field is very diverse and is rapidly evolving, it seems that introductory projects like the AGI safety fundamentals course with defined curriculum and learning groups might work better for absolute beginners, but for more experienced ones, mentorship seems to me as a natural solution. There are projects focused on solving this problem, for example,&nbsp;<a href=\"https://www.serimats.org/\">SERI MATS</a>,&nbsp;<a href=\"https://www.governance.ai/\">GovAI</a>,&nbsp;<a href=\"https://www.pibbss.ai/\">PIBBSS</a>, and&nbsp;<a href=\"https://aisafety.camp/\">AI safety camp</a>. But to my knowledge, there is fierce competition to get there, and they accept only a fraction of applicants.</p><p>In my opinion, this problem is a major bottleneck for the AI safety field in general, and, in my opinion, the most important to solve among others I discuss here.</p><h3>&nbsp;</h3><h3>Mental health and doomerism</h3><p>Some of my interviewees mentioned that they feel like humanity might be doomed, and they experience anxiety and depressive mood because of it. Some people say that they do not make long-term investments, unsure whether they should bring children into this doomed world, or think about long-term health.</p><p>Also, as I described earlier, some of my interviewees mentioned that they feel lonely. They have nobody to talk about AI safety in their daily lives.</p><p>I think these problems are important and they get less attention than they deserve both because I generally prefer people to not suffer rather than to suffer and because mentally healthy people are more productive than the ones who suffer, and the productivity of AI safety researchers is very important for the world.</p><p>Unfortunately, my current research didn't mean to focus on this particular topic so I did not explore it in-depth, but as a clinical psychologist I would love to explore it, so if you believe that you are on a doomer side and this affects your mental health or your life choices, feel free to write me a direct message, I will be happy to talk to you, and, hopefully, provide some help if you think you need it.</p><p>&nbsp;</p><h2>Post scriptum</h2><p>I would be glad to implement my ideas as well as any other good field-building ideas, so feel free to write me direct messages on this topic if you are interested in this kind of stuff.</p><p><br>&nbsp;</p>", "user": {"username": "Igor Ivanov"}}, {"_id": "pPqZMTyJvvdWGfkBy", "title": "Shallow Problem Review of Landmines and Unexploded Ordnance", "postedAt": "2023-03-03T16:03:35.930Z", "htmlBody": "<h1>&nbsp;</h1><p><i>This report is a shallow dive into unexploded ordnance (UXO), landmines which is a sub-area within Global Health and Development. This report reflects approximately 40-50 hours of research and is informed by a 6-month internship I did with the programme and donor relations&nbsp; section of the United Nations Mine Action Service in the fall of 2021. The report offers a brief dive into whether we think a particular problem area is a promising area for either funders or founders to be working in. Being a shallow report, should be used to decide whether or not more research and work into a particular problem area should be prioritised. This report was produced as part of Cause Innovation Bootcamp\u2019s fellowship program. Thank you to James Snowden, Akhil Bansal and Leonie Falk for providing feedback on earlier versions of this report. All errors are my own.&nbsp;</i></p><h2>Summary</h2><ul><li><u>Importance</u>: The issue of UXOs and landmines impacts the health as well as income and most likely the mental health of individuals.. There are on average ~25,000 casualties (defined as severely injured or dead) from landmines, IEDs and UXOs per year (with 2/3rds being caused by IEDs). To put provide some context for this number, Malaria, one of the leading global killers, caused 643\u2009000 deaths (95% UI 302\u2009000\u20131\u2009150\u2009000) in 2019. This report aims to gauge the income, health and psychological effects of those casualty events.&nbsp;</li><li><u>Tractability</u>: Mine action is the umbrella term capturing all the activities aimed at addressing the problem of victim operated landmines, IEDs and other UXOs - meaning that the detonation is triggered by the victim itself. There are several interventions in mine action with four phases to tackle the problem: prevention, avoidance, demining, and victim assistance. Although the report attempts to provide some data on the cost-effectiveness of the different interventions there are several reasons why these estimates are highly uncertain. Furthermore, it is unclear if it would be possible to scale the most cost-effective interventions while keeping the level of cost-effectiveness.&nbsp;</li><li><u>Neglectedness</u>: The United Nations Mine Action service functions as the coordinating body for a lot of the funding and efforts in international mine action and moves around 65 million USD. The two biggest implementers are the Mines Advisory Group (90 million USD) and the HALO Trust (100 million USD). Most of that funding comes from high income country governments. These grants often include a political component in where the activities are taking place. It is unclear how effectively these resources are allocated and how many casualties they are preventing each year.&nbsp;</li></ul><h2>Main Takeaways</h2><ul><li>Biggest uncertainties:&nbsp;<ul><li>The poor data availability allows for only low levels of confidence in many conclusions.&nbsp;</li><li>It is highly uncertain what the economic effects of landmines contamination actually are. Since we would expect that these effects make up a majority of the positive benefit, our cost-effectiveness estimates are highly uncertain.&nbsp;</li></ul></li><li>Recommendations for philanthropist and why:<ul><li>The research has led to the recommendation to inquire directly with mine action organisations on what they deem the most cost-effective area or intervention to fund, since such data is highly dependent on the factors which cannot easily be predicted.</li><li>Ukraine is being heavily contaminated by unexploded ordnance right now, especially in its east, the severity and need of the contamination will require a lot of funding and could be potentially very cost effective due to the dense nature of the contaminants as well as the terrain. Mechanical demining could be an appropriate method which could be highly cost-effective. The wide scale decontamination can only start once the fighting has ebbed off which might take some time.&nbsp;</li><li>At present I\u00b4d consider funding Apopo, since they - at least according to self published data - are cost-effective.&nbsp;</li></ul></li><li>Next steps for someone spending more time?&nbsp;<ul><li>I encourage efforts to gather data on cost effectiveness, health effects, and the economic impact of landmines. Which is an area which currently lacks clear and conclusive data.</li><li>I\u00b4d recommend talking to experts in the field, most have tremendous experience and tell which interventions are most effective in which contexts. A word of caution though, a too narrow focus on cost-effectiveness can possibly be understood as dangerous since the consequences of efforts in this field are often deadly. The safety of deminers needs to be always the most important consideration.</li></ul></li></ul><h2>What is the problem?</h2><p>Wars and armed conflicts almost always have the intended and unintended effect of leaving unexploded ordnance, or UXO, (for the purpose of this report UXO and ERW - explosive remnants of war - shall be used interchangeably) behind which is called contamination. The form of contamination varies widely between types of conflicts, intensity, tactics, and actors involved. The main forms of UXO contamination are:&nbsp;</p><ol><li>Landmines: A land mine is an explosive device concealed under or on the ground and designed to destroy or disable enemy targets, ranging from combatants to vehicles and tanks, as they pass over or near it. Such a device is typically&nbsp;<i>victim operated</i>, meaning that one or several inputs of the victims cause the detonation. Most mines are set off by pressure when a target steps on it or drives over it, although other detonation mechanisms are also sometimes used. Other mines like anti-tank mines use higher pressures or magnetism.</li><li>Improvised Explosive Devices (IEDs): An improvised explosive device is a bomb constructed and deployed in ways other than in conventional military action. It may be constructed of conventional military explosives, such as an artillery shell, attached to a detonating mechanism or can be a pipe bomb; countless versions exist. IEDs are commonly used as roadside bombs, or in urban areas.</li><li>Unexploded ordnances: Unexploded ordnance (UXO), or also called, explosive remnants of war (ERW) are explosive weapons (bombs, shells, grenades, land mines, naval mines, cluster munition, and other munitions) that did not explode when they were employed and still pose a risk of detonation, sometimes many decades after they were used or discarded.</li></ol><p>Different forms of contamination require different interventions, which vary in cost and skill level required. As an example (exceptions are to be expected), landmines are, once found, relatively easy and safe to disarm and destroy by trained personnel. Landmines also vary in form, mainly anti-personnel landmines, anti-tank mines and sea mines (which shall not be considered in this report due to their rare occurrence and relatively low impact on civilians), different types of mines are made from different materials (plastic, metal), contain various explosives (some are designed to kill whilst other aim to maim).</p><p>In the last decades we have seen a shift to asymmetrical warfare tactics between state and non-state actors, increasing the usage of IEDs. IEDs alone have been reported in over 50 different countries resulting in over&nbsp;<a href=\"https://www.unmas.org/en/unmas-annual-report-2021\"><u>170,000 casualties</u></a> (defined as severely injured or dead) between 2011 and 2021. This means on average, there were 17,000 casualties per year from IEDs.&nbsp;</p><p>Additionally, according to the International Campaign to Ban Landmines in 2020, at least 7,073 people were killed or injured by landmines or UXOs. Of that at least&nbsp;<a href=\"http://www.the-monitor.org/en-gb/reports/2021/landmine-monitor-2021.aspx\"><u>2,492 were killed whilst 4,561 were injured</u></a>.&nbsp; In total, this means that there are ~25,000 casualties from landmines, IEDs and UXOs per year (with 2/3rds being caused by IEDs).&nbsp;</p><p>The safe disarmament of IEDs often required highly trained personnel and tools depending on type and construction. IEDs are generally more difficult to work with since they can vary between a simple contraption like a canister filled with nails to heavy artillery shells fitted with sophisticated pressure of magnetism sensors.&nbsp;</p><p>The ongoing invasion of Russia into the Ukraine has caused new and widespread contamination which will take years to clear. New figures from the ongoing war in Ukraine indicate a stark increase in the usage of cluster bombs, with children making up two thirds of the casualties of cluster munition victims. In 2020, cluster munitions caused&nbsp;<a href=\"http://www.the-monitor.org/en-gb/reports/2021/cluster-munition-monitor-2021.aspx\"><u>360 casualties</u></a>, over 60% were legacy munitions. The first half of 2022 has already created at least 689 civilian casualties from cluster munitions,&nbsp;<a href=\"http://the-monitor.org/en-gb/reports/2022/cluster-munition-monitor-2022/\"><u>215 died</u></a>, this is a 300% increase compared to 2021. The cleanup effort in Ukraine will be massive and the dense contamination especially in the east of the country could be an area in the future where demining could become much more cost effective. It is safe to assume that Ukraine will suffer from increased contamination and that locally casualties will rise once fighting has ceased.</p><h2>Whom does it affect and at what point in their lives?</h2><p>Mines and IEDs affect people in various ways. Most are designed to gain a tactical advantage over your opponent in warfare, but some are also used in area denial tactics, which aim to slow down or prevent personnel combatants and civilians from entering an area. This report shall focus on explosives which pose the biggest risk to humans and thus excludes areas such e.g., the demilitarised zone between the two Koreas which is highly contaminated but well managed and no actor is interested in removing such devices.</p><p>Despite the various forms of ordnance, they mostly kill and injure civilians (after combat has ceased). Within that, children are most at risk of falling victim. To illustrate, the 2021 victims of cluster munitions were&nbsp;<a href=\"http://the-monitor.org/en-gb/reports/2022/cluster-munition-monitor-2022/\"><u>97% civilians and 66% of that were children</u></a>: \u201cChildren are far more likely to die from landmine injuries than adults. An estimated&nbsp;<a href=\"https://victimassistance.files.wordpress.com/2012/12/unicef_children-and-landmines_factsheet-for-4april2009.pdf\"><u>85 percent</u></a> of child victims of landmines die before reaching the hospital\u201d.</p><h2>What is the causal pathway through which this issue affects health/income/well-being and how big are those effects?</h2><p>It seems safe to assume that landmines and UXOs have effects on a population\u2019s health, income and mental well-being. From the literature I could find, the health effects are the most documented and quantified, the income effects are very uncertain and there is little data on quantifying the mental well-being effects of landmines. I have ordered the following sections accordingly, starting with health effects.&nbsp;<br>&nbsp;</p><p><u>Health: Dying and being injured from the explosion of an UXO or landmine</u>:&nbsp;</p><ul><li>There is relatively good data on the number of casualties from ordnance.&nbsp;</li></ul><p>The causality of the adverse health effects is straight forward, a piece of ordnance detonates whilst a person is within the blast radius. The severity of the blast and effect on casualty is dependent on many factors and varies from minor shrapnel wounds (which are often not recorded), the loss of limbs (many mines are not designed to kill but rather to maim, thus gaining military advantage), or death.&nbsp;</p><ul><li>The casualty database for&nbsp;<a href=\"http://www.the-monitor.org/en-gb/reports/2018/landmine-monitor-2018.aspx\"><i><u>Landmine Monitor Report 2018</u></i></a><i>&nbsp;</i>includes an updated total of&nbsp;<strong>9,437 casualties</strong> for 2016 2,472 killed, 6,937 injured, and 28 unknown. This number could easily be a lot higher since many of the deaths are happening in countries that still have an ongoing conflict and/or have unreliable public data on the issue. It is to be expected that the war in Ukraine is going to drive that number up considerably over the next decades. If we assume that each life&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/HbunzTyFPRwcYihg6/long-lasting-insecticide-treated-nets-usd3-340-per-life\"><u>translates into 30 DALYs on average</u></a> (which is a conservative assumption as this seems to disproportionately affect children)&nbsp; and that injury causes 5 DALYs on average (random assumption with low confidence), the overall burden of disease of landmines is about 2,472 x 30 + 6,937 x 5 =&nbsp;<strong>108,845 DALYs</strong>.&nbsp;</li></ul><p><u>Mental Well-being</u></p><ul><li><u>The knowledge that you, someone you know or your children could be hurt</u>: The psychological toll that it takes on someone\u2019s mind to know that you, your children or someone you know is in danger of being hurt by an unexploded ordnance in your environment.&nbsp;</li><li><u>The psychological toll on someone who has been injured by a landmine</u>: It\u2019s not hard to imagine that being injured by an unexploded ordnance or landmine could lead to serious trauma and PTSD or other similar mental health issues (there is some evidence to support this&nbsp;<a href=\"https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC4644284&amp;blobtype=pdf\"><u>here</u></a>,&nbsp;<a href=\"https://www.semanticscholar.org/paper/Assessment-of-Posttraumatic-Stress-Disorders-among-Mohammed-Sachit/9d7c13d0734d20df9d45d8d0a5862e99bd41a5cc\"><u>here</u></a>,&nbsp;<a href=\"https://semanticscholar.org/paper/9ea0c21faf28409a1b862d08d8ab84daaa272ad7\"><u>here</u></a>, and<a href=\"https://semanticscholar.org/paper/82ab49139edf8f5d4ffe3100b4b83564d484d636\"><u> here</u></a>).</li><li><u>Psychological toll of someone being killed by a landmine and UXO</u>: Being killed by an exploded landmine is a particularly gruesome death. Even though death might come instantly to the individual (many mines are not designed to kill but rather to maim, thus gaining military advantage), it is not hard to imagine that the psychological toll on the first responders and family members could be significant. Secondary trauma is real and has major effects on first responders and immediate surroundings. I did not attempt to quantify this effect and could not find literature on the topic. One reason for that could be that this line of question could be quite sensitive and somewhat inappropriate for the victim\u2019s family. As well as that there is basically no data focusing on these effects, they mostly deal with health outcomes.</li></ul><p>It is hard to quantify these psychological effects and I was not able to make a reliable estimate that breaks down the burden per piece of unexploded ordnance.&nbsp;<br>&nbsp;</p><p><u>Economic: Fields for agriculture and access public infrastructure like roads</u>:&nbsp;</p><ul><li>The threat \u2013 real or perceived \u2013 contamination is often enough for people to stop using a road, field, or house or other forms of public infrastructure (e.g. reaching a hospital or a school). This natural instinct is often exploited to exert economic damage and prevent mobility. Often IEDs are placed on strategically important roads and prevent militaries and civilians from accessing public infrastructure.&nbsp;</li><li>There are some authors who seem to have tried to quantify the economic burden of UXO contamination but there does not seem to be high quality data and the results from those analyses vary quite widely. It also seems safe to assume that the economic costs do depend on the context (as a random piece of forest might not be as productive as a road connecting two population hubs). Also, many places which are contaminated with UXOs suffer from a complex mix of economic risk factors.&nbsp;<ul><li><a href=\"https://semanticscholar.org/paper/c23117c7b136539c3d3332398dc2f88bcf176ae3\"><u>Merrouche (2006)&nbsp;</u></a>found that landmine contamination causes a loss of 0.4 years of education on average and also found that landmine contamination has large and statistically significant negative effects on poverty and consumption per capita.&nbsp;</li><li><a href=\"https://semanticscholar.org/paper/e80e7f72e6f342f78ef7da68fd5d9d38ced68ccf\"><u>Harris (2000)&nbsp;</u></a>found that the annual costs of completely demining Cambodia would be $US140 million, whereas the annual benefits are only $0.7 million.&nbsp;</li><li>Furthermore,&nbsp;<a href=\"https://semanticscholar.org/paper/72a672081761f2e0dddf2c71d5d1d1e15ddf63e2\"><u>Harris (2002</u></a>) found that the investment of $100 million for demining in Afghanistan would result in annual benefits of $50.3 million per annum.&nbsp;</li></ul></li><li>All of these assessments are rather old and the quality of these evaluations is questionable. In general, it seems safe to assume that there are some economic costs from landmine contamination but how large this effect is remains an unresolved question and would most likely be fairly context specific which is why I have refrained from putting down numbers here. Micro-geography is crucial, a random contaminated hill might not inhibit one's life much, a strategic roadway just next to it is likely to cause much more harm (economically, mentally and physically).</li></ul><h2>History of the problem</h2><p>The first reports of victim operated (meaning the ordnance explodes through the actions or presence of its victim) mines stem from the 1853-1856 Crimean war where a coalition of Ottomans, French, and Sardinian forces fought against the Russian Empire&nbsp;<a href=\"https://ttu-ir.tdl.org/handle/2346/21833\"><u>(Youngblood, 2002)</u></a>. World War I saw the introduction of the first industrially produced landmines. Since then, the development of mines has branched into many different subgroups suitable for specific objectives.&nbsp;</p><p>The indiscriminate nature of victim operated explosives has drawn plenty of criticism over the years. Especially since most models are durable and can be deadly even decades after a conflict, additionally many mines are designed to blend into the environment or are deliberately made \u2018shiny\u2019 attracting kids.&nbsp;</p><p>Until the 1990s mines have been used by most militaries in some form or another. As a result of increasing scrutiny over the thousands of deaths annually, the International Campaign to Ban Landmines (ITCBL) was founded in 1992. It brought forth the Mine Ban Treaty in 1997 \u2013 which was awarded the Nobel Peace Prize \u2013 which included a comprehensive ban on all anti-personnel mines as well as several measures to redress the harm from past use. So far&nbsp;<a href=\"http://www.icbl.org/en-gb/problem/why-the-ban.aspx\"><u>164 states</u></a> have ratified and accepted the treaty, 32 states are non-signatories, amongst them are the United States, Russia, China, the two Koreas, Pakistan, India, Iran, Israel, Syria. &nbsp;</p><figure class=\"image image_resized\" style=\"width:50.79%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/m8nhzzowvhreknay0wdv\" alt=\"Geneva Center for Humanitarian Demining\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/rcylujqphhq1qrlpokg8 119w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/nbpvzvtznuygefgvul58 199w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/n5amtk7tr11f35a4zugk 279w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/plgj40cvz3kxdw0tllyj 359w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/pktqnu5ngu5be4rwzwed 439w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/dkp7adgjst64spdqrkqb 519w\"><figcaption>Source: Geneva International Center for Humanitarian Mine Action</figcaption></figure><p>&nbsp;</p><p>In June 2022, the&nbsp;<a href=\"https://www.state.gov/briefing-on-the-united-states-updated-anti-personnel-landmine-policy/\"><u>United States changed its policy</u></a> and in effect aligned itself with the provisions of the Mine Ban Treaty, except for the defence of the Korean Peninsula. This shift in US position is a good sign and might create some knock-on effects (the exemption of the Korean Peninsula is not very significant since minefields there are used for protection, are well documented and sealed off, thus pose very low risks for civilians).</p><h2>Is it likely to get better, worse or stay the same with the status quo?</h2><p>The issue of landmines is likely to become better in the future since the \u201cMine Ban Treaty has created a powerful and near universal stigma against antipersonnel landmines: most states not party to the treaty are responding to international pressure on this issue and have stopped using, producing, and transferring the weapon. They are in de facto compliance with the treaty even though they are not legally bound by it\u201d&nbsp;<a href=\"http://www.icbl.org/en-gb/the-treaty/treaty-in-detail/frequently-asked-questions.aspx\"><u>(International Coalition to Ban Landmines, n.d.)</u></a>. Having said that, landmines&nbsp;<a href=\"https://www.hrw.org/news/2022/06/15/background-briefing-landmine-use-ukraine\"><u>have been used&nbsp;</u></a>during the ongoing invasion of Russia into Ukraine and there might be other states that would be willing to use them in case of an inter state conflict.</p><p>Meanwhile, the issue of IEDs and UXOs is likely to get worse. The continued proliferation of IEDs through readily available instructions from the internet is likely to continue. Furthermore, there is a&nbsp;<a href=\"https://ourworldindata.org/grapher/the-number-of-active-state-based-conflicts?country=~OWID_WRL\"><u>general trend from interstate to interstate conflict</u></a> which means that the conflict parties don\u2019t have as much systematic access to landmines as they have to improvised explosive devices.&nbsp;</p><p>Similarly, unexploded ordnance which is a byproduct of practically every war or conflict will remain and could increase if more wars are being fought. A large conflict between states (US vs China, Russia vs NATO) even if fought with conventional weapons would cause widespread contamination. If Taiwan were to be attacked by China it would require an amphibious landing which would likely be countered with widespread mine usage.&nbsp;</p><p>The ongoing war in Ukraine following the invasion of the Russian Federation continues to cause intense contamination which will require large-scale clearance efforts for years to come. Especially the wide scale use of cluster munitions by Russia causes dangerous UXO. According to the United Nations up to 40% of submunitions (one cluster bomb contains between 100-400 submunitions which are supposed to detonate upon impact) do not explode, thus creating thousands of UXOs. The usage of cluster munitions is outlawed under the 2008 Convention on Cluster Munitions \u2013 Russia&nbsp; is not party to the treaty.</p><p>Some of the most effective interventions against traditional landmines don\u2019t work as well against improvised explosive devices and the proportion of IEDs is increasing compared to landmines and UXOs. Having said that, the progress is slow and conflicts like the one in Ukraine are reverting some of these trends. This means that concerted efforts are necessary right now and will be necessary in the future to protect civilians from the harm that these unexploded devices cause to their health, economy and psychological well-being. It doesn\u2019t seem like this problem will be solved without these concerted efforts and the cost-effectiveness of the interventions should not change dramatically in the next 10-15 years.&nbsp;&nbsp;</p><h2>Type and location of the problem</h2><p>Landmines, IEDs and UXOs are differ in many ways and thus are used by various actors in different places. There is no data source which bundles all forms of contamination in one place. I have gathered sources to provide a rough overview in the respective categories. Most casualties occur due to the use of IEDs and explosive remnants of war, anti-personnel mines constitute only a part of the issue&nbsp;<a href=\"http://the-monitor.org/en-gb/reports/2022/landmine-monitor-2022.aspx\"><u>(Landmine Monitor, 2022)</u></a>.</p><h3>Cluster Munition remnants</h3><p>A&nbsp;<strong>cluster munition</strong> is a form of air-dropped or ground-launched explosive weapon that releases or ejects smaller submunitions. Commonly, this is a&nbsp;<strong>cluster bomb</strong> that ejects explosive bomblets that are designed to kill personnel and destroy vehicles or to scatter land mines. Because cluster bombs release many small bomblets over a wide area, they pose risks to civilians both during attacks and afterwards. Unexploded bomblets can kill or maim civilians and/or unintended targets long after a conflict has ended, and are costly to locate and remove.</p><p>Cluster munitions are prohibited for those nations that ratified the Convention on Cluster Munitions, adopted in Dublin, Ireland, in May 2008. The Convention entered into force and became binding international law upon ratifying states on 1 August 2010, six months after being ratified by 30 states. As of 10 February 2022, a total of 123 states have joined the Convention, as 110 states parties. Russia has made wide scale use of cluster munitions in the Ukraine war contaminating vast swaths of Ukraine with unexploded submunitions. The cleanup according to the&nbsp;<a href=\"https://www.halotrust.org/latest/halo-updates/beyond-bombs-podcast/\"><u>HALO Trust</u></a> is set to last many decades. Neither Ukraine nor Russia are party to the convention.</p><p>Prior to the Ukraine war most cluster munition remnants could be found in Laos and Vietnam. As a result of the US bombardment of the respective countries. Ukraine by now is even more contaminated and also presents a more complex and more urban contamination.</p><figure class=\"image image_resized\" style=\"width:67.74%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/ydtr4y7crbowmg2rpxku\" alt=\"Table\n\nDescription automatically generated\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/c3e4igwuqsblytxdfuzz 110w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/pw38uvfgnkhwcrmnv4up 220w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/m6jz0pq68qqhbwssln1t 330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/droqxfjiwiwpbv2bygns 440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/rbh0aqgee3bgt1ydbcmn 550w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/ngkyopttkaevo0yeiy0k 660w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/ctjldvp4iiybo3jbj2lz 770w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/d9hyxy8awykdqlkywlge 880w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/dx92es5ruremu84xqlgq 990w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/bu7ckzmjtlzzfloowfeb 1092w\"><figcaption>Source: Cluster Munition Monitor 2022</figcaption></figure><figure class=\"image image_resized\" style=\"width:75.77%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/kodgcxuxpv7in6nehmpf\" alt=\"Map\n\nDescription automatically generated\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/uiqrj45shsblk5mefnqh 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/g5dhbzhb7eycrm4tgsd0 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/d3ovdr5xyik4l8hjvq2w 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/ky8rzsepmpriggoaewqj 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/bvanycjzs87hmpdtdg5e 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/tzsyawfic88n0dg3rfhb 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/toal89d7cayq1hfvptnz 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/nbez9cokol7tk13ta29c 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/h1ztvac598qxkr12zwkj 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/vaya8ubyzppylxvfngdh 984w\"><figcaption>Source: Cluster Munition Monitor 2022</figcaption></figure><p><br>&nbsp;</p><h3>Landmine contamination</h3><p>Compared to cluster munition, landmines are more widespread. Clearance efforts in South America have progressed, with clearance completed in Argentina and Chile but remaining in Ecuador and Columbia. Many Countries in Sub Saharan and North Africa are contaminated as are large parts of SouthEast Asia as well as Russia. Casualties of mines and ERW have been recorded in&nbsp;<a href=\"http://the-monitor.org/en-gb/reports/2022/landmine-monitor-2022.aspx\"><u>47 countries</u></a>.</p><h3>Improvised Explosive Devices</h3><p>There is no good data on the quantity or geographic distribution of IEDs but they are found mostly in former and active conflicts of the last 30 years. IEDs are classified as landmines thus data on them is less precise.</p><p><a href=\"http://the-monitor.org/en-gb/reports/2022/landmine-monitor-2022.aspx\"><u><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/pvmplpk8rhe9lgmzxssm\" alt=\"Infographic: Where are the Landmines? | Statista\"></u></a></p><p><a href=\"http://the-monitor.org/en-gb/reports/2022/landmine-monitor-2022.aspx\"><u>Landmine and Cluster Munition Monitor Report 2022 (p. 50)&nbsp;</u></a></p><p>The countries with the highest contamination are not necessarily the countries with the highest casualties (e.g. contaminated areas are not close to population centres). The countries with the highest casualties over time are represented in the graph below.&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/rdg7rm0lqzp60j8up6xb\"></p><p><a href=\"http://the-monitor.org/en-gb/reports/2022/landmine-monitor-2022.aspx\"><u>Landmine and Cluster Munition Monitor Report 2022&nbsp;</u></a></p><h1>Tractability</h1><h2>What would this issue look like in an ideal world?&nbsp;</h2><p>An ideal scenario would be that there aren\u2019t any armed conflicts and wars thus no mines/UXOs or other weapons used. Since that is very unlikely, a more sensible ideal would be, to have conflicting parties (state and non-state actors) not use landmines and IEDs, and also ensure that there are no ERW (explosive remnants of war), or that the they are clearly marked and known to all parties and civilians. Weapons such as cluster bombs should not be used at all since they create devastating contamination which requires intense clearance operations. Better communication of contamination is necessary to reduce accidents and civilian casualties.</p><h2>What are the different interventions? And what do they cost</h2><p>Demining is a well-established field which has seen many innovations to effectively address the problems at hand. There are four phases to tackle the problem: prevention, avoidance, demining, and victim assistance. The individual interventions are listed in the section below which include the Theory of Change for the Intervention as well as the individual Back of the Envelope calculations for cost-effectiveness of these interventions. There are several reasons why I have very low confidence in these calculations. The following factors could change these assessments considerably:&nbsp;</p><ul><li><u>The impact of landmines and UXOs on people\u2019s health, happiness and income are highly uncertain</u>: As outlined earlier, there are still significant challenges in getting accurate information of the number of people killed and injured by UXOs annually. Furthermore, there are wide confidence intervals around the economic effects of landmine and UXO contamination and low evidence on the effects on happiness of people living in contaminated areas.&nbsp;</li><li><u>We don\u2019t know the risk:</u> Next to not knowing the effects the contamination of land has, we also don\u2019t exactly know what the risk is for individuals to be exposed to those risks.</li><li><u>There might be other positive impacts of these interventions that are hard to model</u>: The former chief of mine action for UNMAS Afghanistan (consulted for background conversations) has mentioned furthermore that the employment of several hundred or thousand deminers who are almost exclusively men in fighting age has a profound impact on the ability of insurgents to recruit them. Mine action thus gives them a skill, money and they are far less likely to join organisations such as the Taliban (this refers to the situation pre Taliban takeover in 2021, but the principle very much remains). Weighing the impact of these very real knock-on effects is very challenging but shall not be forgotten when reviewing the cost effectiveness of mine action.</li><li><u>The cost-effectiveness of these interventions is highly context dependent</u>: It is important to be conscious of the fact that the most appropriate intervention is dependent on the type of contamination, terrain, vegetation, logistics and labour costs. Current implementing organisations have many decades of experience of choosing the most appropriate \u2013 and cost effective \u2013 method. This perspective was mirrored by Richard MacCormac, Head of Humanitarian Disarmament and Peacebuilding at the Danish Refugee Council who was contacted as part of the research. This means that even though an intervention might be cost-effective in a specific location, it might not be able to scale at that level of cost-effectiveness.</li></ul><p>In general, it is fairly complicated to assess the risk of landmines and the data here is hard to come by or not public, thus basically not usable. Having made an attempt at quantifying the impact per landmine removed anyway, we come to the following calculation:&nbsp;</p><p>According to&nbsp;<a href=\"https://landminefree.org/facts-about-landmines/\"><u>LandmineFree.org</u></a> there are around 110 million landmines in the ground, with 5000 people being killed each year meaning 5000 out of 110 million landmines detonate and kill a person each year. This means that if we assume that both of those numbers are correct, the chance of one of the landmines getting off and killing a person is 5000/110,000,000 = 0.000045.&nbsp;</p><p>This is making the assumption that the risk for all landmines killing a person are equal which is not the case. For example, there could be a landmine in a very remote mountainous region that was strategically important during some war long ago but isn\u2019t actually frequented by the local population today and therefore unlikely to cause any harm. On the other end of the spectrum, there might be a very recent post-conflict region that has lots of landmines in fields to which the local population is now returning to. The likelihood of these landmines creating harm is a lot higher but unfortunately, we don\u2019t know how much higher that would be.&nbsp;</p><p>One example of a place that would most likely be more recent and more dangerous would be Yemen.&nbsp; A Yemeni de-mining official had claimed that there were 500,000 mines since 2015 (report from 2018) and the Landmine and Cluster Munition Monitor, an initiative that checks compliance with the Mine Ban Treaty, reported about three thousand casualties in 2015-16 (<a href=\"https://www.washingtoninstitute.org/experts/elana-delozier\"><u>Elana DeLozier</u></a>, 2018). If we assume that all the mines were put in during the first year, the likelihood of one of the mines killing a person was 3000/500,000 = 0.006.&nbsp;</p><p>This number seems more relevant but still under reported as mine clearance efforts are most likely focusing on the areas of the most dangerous contamination even within these priority countries. The value of removing one landmine is therefore most likely higher than the number estimated above. Generally, it doesn\u2019t seem unlikely that removing one landmine from a priority area would be twice or even four times as valuable.&nbsp;</p><p>Furthermore, removing a landmine in a given year would not only reduce the risk of a person being killed during that year but also in the future until the landmine\u2019s function expires which can be longer than 50 years. Having said that, people would most likely learn over time which areas are safe and which aren't, which would also mean that casualty numbers would decrease over time. Economic effects on the other hand would not decrease as fields and roads remain unusable but since we don\u2019t have good data on this, they are not included here.&nbsp;</p><p>If we take the case of Columbia from the graph discussed earlier we can see that casualty numbers decrease by around 10% each year for around 10 years. If we take the earlier number of 0.006 chance of a landmine killing someone and model the removal of that landmine over 10 years, the likelihood of that landmine killing a person over 10 years would come out to: 0.006 + 0.006 * 0.9 + 0.006 * 0.8 + 0.006 * 0.7 + 0.006 * 0.6 + 0.006 * 0.5 + 0.006 * 0.4 + 0.006 * 0.3 + 0.006 * 0.2 + 0.006* 0.1 = 0.033. By removing one landmine we have therefore removed a 0.033 chance of killing a person.&nbsp;</p><p>If we assume that each life&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/HbunzTyFPRwcYihg6/long-lasting-insecticide-treated-nets-usd3-340-per-life\"><u>translates into 30 DALYs on average</u></a> (which is a conservative assumption as this seems to disproportionately affect children) removing one landmine equals saving 0.033x 30 DALYs = 0.99 DALYS. This means that for this to be a cost-effective intervention, a project would have to clear one landmine for less than $101.00 USD (if $100/DALY is the threshold). The below table outlines the cost-effectiveness and tractability of the different interventions.</p><figure class=\"table\"><table><tbody><tr><td style=\"background-color:#cfe2f3;border:1pt solid #000000;padding:5pt;vertical-align:top\">Category</td><td style=\"background-color:#cfe2f3;border:1pt solid #000000;padding:5pt;vertical-align:top\">Intervention</td><td style=\"background-color:#cfe2f3;border:1pt solid #000000;padding:5pt;vertical-align:top\">Evidence of this working</td><td style=\"background-color:#cfe2f3;border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Cost-</p><p>effectiveness</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\" rowspan=\"2\">Prevention</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Advocating for Mine Ban treaty</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Community groups advocating for the non-usage to their government/ military</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\" rowspan=\"2\">Avoidance</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Surveying&nbsp;</p><p>(fencing off areas that are high risk, warning labels)&nbsp;</p></td><td style=\"background-color:#fff2cc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Moderate</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">High</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Explosive ordnance risk education (EORE)</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Moderate</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\" rowspan=\"4\">Demining</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Using detectors to demine areas contaminated with UXOs</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">Moderate-High</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">Very High</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Animals like rats and dogs</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">Moderate-High</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">Moderate- High</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Mechanical (excavators and other heavy machinery)</td><td style=\"background-color:#fff2cc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Moderate</td><td style=\"background-color:#fff2cc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Moderate</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">New demining technology (drones, other technology)</td><td style=\"background-color:#fff2cc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Moderate</td><td style=\"background-color:#fff2cc;border:1pt solid #000000;padding:5pt;vertical-align:top\">n.a.</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Victim Assistance</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Helping victims immediately after an exposure and long term to live with the results of injury</td><td style=\"background-color:#f4cccc;border:1pt solid #000000;padding:5pt;vertical-align:top\">Low</td><td style=\"background-color:#d9ead3;border:1pt solid #000000;padding:5pt;vertical-align:top\">High&nbsp;</td></tr></tbody></table></figure><p>In general, it seems like preventing landmines and UXOs from being used could be highly cost-effective but is very intractable, especially considering that most UXOs are IEDs that cannot be regulated by any centralised actors. Avoidance of UXOs could have some effect on the outcome but as a stand alone measure is hardly sensible.</p><p>It is unclear if there is an effect on casualties and how big the reduction would be. Furthermore, it just means that people are more diligent in avoiding contaminated areas but it does not mean that areas become usable again which means the intervention has no economic effect. This is therefore also not a common practice, surveying and clearance usually go hand in hand.</p><p>The most promising interventions are within the UXO clearance section with animals like rats and dogs, deminers with metal detectors and mechanical excavators being able to clear land and make it usable again. Victim assistance seems to have the lowest cost-effectiveness as most of the harm has already happened.&nbsp;</p><h3>Preventing civilians from being exposed</h3><p><u>Advocating for Mine Ban treaty</u></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>ToC: A civil society group advocates their government -&gt; the government brings up a treaty for discussion-&gt; other states are willing to joining-&gt; treaty is drafted -&gt; treaty is signed -&gt; treaty is ratified -&gt; states stop using UXOs -&gt; less exposure during and after war -&gt; less economic, psychological and physical harm.&nbsp;</p><p>Assumptions:&nbsp;</p><ul><li>It is possible for a non-state actor to advocate for a treaty like this or possible to advocate for a state to advocate for it.&nbsp;</li><li>States have an interest to adopt the treaty into national legislation.</li><li>National legislation actually translates into the non-usage of landmines.&nbsp;</li><li>There aren\u2019t any actors that are not bound by international law / national law to use these types of weapons.</li></ul></td></tr></tbody></table></figure><p>It doesn\u2019t actually matter if a treaty is cost-effective in itself because policy has been in existence for 20 years. The only progress that could be made on this might be to advocate non-signatories to join the treaty. Having said that, it makes sense to think through the cost-effectiveness of a treaty like this to get a general sense if legislation like this could be relevant for other harmful weapons of war for which a treaty does not exist yet and how important it would be to get non-signatories to join. To understand the potential cost-effectiveness of advocating for a policy like this, two factors are relevant:&nbsp;</p><ul><li><u>The total cost of an advocacy campaign and implementation of the policy</u>: The International Coalition to Ban Landmines spent $1,312,753 in 2021 (<a href=\"http://www.icbl.org/media/3328696/2021-ICBL-CMC-Annual-Report-Web-final.pdf\"><u>Annual Report 2021, p. 18</u></a>). Most of the funding seems to be spent on collecting data on landmines deaths and injuries and some of it on direct advocacy efforts. The costs for advocating could be a lot higher than taking this number and multiplying it by the years since the ban because of two reasons: (1) the ICBL is a coalition of many other organisations who are also spending part of their budget on this issue, (2) it probably cost a lot more during the implementation and advocacy phase. If we calculate for the best case scenario, we assume that they have started advocating in 1990 (assumption with no background information) and spend ~$1.5 million every year since today which would come out to $1.5 mil x 22 years:&nbsp;<strong>33 million</strong>.&nbsp;</li><li><u>The reduction in death and injury due to the policy</u>: it is really hard to understand how much the treaty can be credited with reducing the numbers of victims because of two reasons: (1) we don\u2019t know how the numbers of deaths would have developed otherwise (e.g. anti-personnel mines would have lost their tactical advantage compared to IEDs which are not state bound) and (2) we don\u2019t have any concrete data on deaths from UXOs before 1999 which is when the landmine monitor started collecting them which is very inconvenient. If we assume that the policy takes a couple of years to implement, we can take the&nbsp;<a href=\"https://www.statista.com/chart/20679/casualties-of-landmines-timeline/\"><u>first data point available</u></a> and assume that this was the baseline which the treaty was reducing. If we ignore that the number of casualties and injuries rise after 2013 we could assume that the treaty reduces the number of casualties by 3000 every year we would come out to 3000 x 22 = 66,000 casualties avoided of which \u00bc actually die, if we round this to \u2153 to include the injuries, it comes out to<strong> 33,000 deaths averted over time</strong>.&nbsp;</li></ul><p>These two factors mean that under these baseline assumptions (which are most definitely off by far) the mine ban treaty averted a death for $1000 in a best case scenario. Most likely though the costs were significantly higher and the fact that we basically have no data on landmine deaths before and after the treaty and that casualties have risen over the last 5 years to a level of 2001 means that we don\u2019t actually know if the treaty had&nbsp;<u>any effect</u> on landmine casualties at all. On the other hand, there are most likely some benefits to the treaty that are not included here such as: a reduction in stockpiles meaning deaths averted in the future, the stigma of usage is likely to reduce mine application, and economic effects that are not captured here and the benefit of international cooperation and collaboration on an issue.&nbsp;</p><p>There are two treaties that already exist that are relevant to understand how tractable a policy would be regarding the reduction of injuries and landmines from unexploded ordnances. Feel free to skip this section if you are not interested in the details and go to the next intervention.&nbsp;</p><ul><li>Mine Ban Treaty (Ottawa, 1997):&nbsp;<ul><li>There is a global coalition of nongovernmental organisations chaired by Human Rights Watch called the&nbsp;<a href=\"http://www.icbl.org/en-gb/home.aspx\">&nbsp;International Campaign to Ban Landmines (ICBL)</a>. The coalition has received the 1997 Nobel Peace Prize for the Mine Ban Treaty that was adopted in 1997 which prohibits the use of antipersonnel mines and requires countries to destroy stockpiles, clear mine-affected areas, and assist victims. A total of 164 countries are party to the treaty including all NATO members except the United States. In June 2022, US President Joe Biden<a href=\"https://www.hrw.org/news/2022/06/21/landmines-us-moves-closer-toward-global-ban\"> changed policy and&nbsp;</a><a href=\"https://www.state.gov/briefing-on-the-united-states-updated-anti-personnel-landmine-policy/\"><u>aligned US policy with the provisions of the mine ban treaty</u></a> with the exception of the Korean Peninsula meaning that except for in the Koreas - particularly their so called Demilitarized Zone the US will be in alignment with the eventual goal (without specific details) to formally join the treaty.&nbsp;</li><li>Between 2021 and 2022 anti-personnel mines have been used by Russia, Myanmar and Ukraine (not yet independently confirmed but highly likely)&nbsp;<a href=\"http://the-monitor.org/en-gb/reports/2022/landmine-monitor-2022.aspx\"><u>(Landmine Monitor, 2022)</u></a>. This does not mean that other states did not suffer from existing contamination.&nbsp;</li><li>Non-state armed groups have recently used victim-operated explosives amongst others in the Central African Republic, Colombia, Democratic Republic of Congo, India, and Myanmar. This new use by armed groups mostly involved victim-operated explosive devices of an improvised nature made from locally available materials. The Mine Ban Treaty prohibits all victim-activated explosive devices regardless of whether they were improvised from local materials or produced in a factory.</li></ul></li><li>Convention on Cluster Munitions (Dublin, 2008):<ul><li>The 2006 Lebanon War provided momentum for the campaign to ban cluster bombs and Norway organised the independent Oslo Process after discussions at the traditional disarmament forum in Geneva fell through in November 2006 which was later drafted and signed in Dublin in 2008. Delegates from 107 nations agreed to the final draft of the treaty at the end of a ten-day meeting held in May 2008 in Dublin, Ireland. The text was then formally adopted by those 107 countries including 7 of the 14 countries that have used cluster bombs and 17 out of the 34 countries that produced them&nbsp;</li><li>The treaty was and is opposed by a number of countries that produce or stockpile significant quantities of cluster munitions, including China, Russia, the United States, India, Israel, Pakistan and Brazil.</li></ul></li></ul><p>&nbsp;</p><p><u>Community groups advocating for the non-usage to their government/military</u></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Community groups advocate for the non-usage and production to their government military -&gt; government stops stockpiling and deploying anti-personnel landmines or equivalent -&gt; less landmines deployed -&gt; less casualties&nbsp;</p><p><br>&nbsp;</p><ul><li>Government is accountable to its citizens and updates on their policy asks</li><li>It is possible to advocate for it in the political climate: some countries and other civil society interest groups might push back on advocacy campaigns that could be perceived as being anti-military.&nbsp;</li><li>States don\u2019t substitute for something even more harmful</li><li>States don\u2019t continue the practice in secret</li></ul></td></tr></tbody></table></figure><p><br>&nbsp;</p><p>The two countries that have actually used landmines in 2022 are Myanmar and Russia, both of which don\u2019t seem to be too receptive to advocacy by their constituents. There might be other forms of pressure that could be deployed but the tractability of this seems quite low. Accordingly, I did not estimate its cost-effectiveness.</p><h3>&nbsp;</h3><h3>Civilians avoiding areas contaminated by UXOs</h3><p><u>Surveying (fencing off areas that are high risk, warning labels)&nbsp;</u></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Conduct an analysis of the landmine contamination (sampling of areas and local surveys) and old records if available&nbsp; -&gt; confirm the contamination of areas through sampling of the environment -&gt; fence of areas that are high risk and provide warning labels -&gt; humans will not step into the space or herd their animals -&gt; less people getting in contact with UXOs -&gt; less death and injury</p><p>Risks/Assumptions:</p><ul><li>The knowledge of local residents about mine contamination is a crucial asset for demining work, but may also be wildly inaccurate and subject to rumours.&nbsp;</li></ul></td></tr></tbody></table></figure><p>This intervention helps to prevent direct deaths and injuries but does prevent the economic use of the areas which means this intervention might have a DALY effect but most likely not an economic effect. The cost of the intervention is a function of conducting an analysis on contamination and then fencing off the area and putting up warning labels. I could not find any data on actual cost and benefits of fencing of high risk areas. Also, once a community or an actor decides to clear the place the surveying would need to be redone most likely making it very ineffective. Due to those reasons this is usually not done.</p><p>&nbsp;</p><p><u>Explosive ordnance risk education (EORE)</u></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Holding explosive ordnance risk education -&gt; people are more informed about which areas they should avoid and are more aware on what UXOs can look like, and how to behave in their presence -&gt; people don\u2019t use contaminated areas and don\u2019t touch stuff that could be and unexploded ordnance -&gt; less casualties from UXOs</p><p>Assumptions:&nbsp;</p><ul><li>People don\u2019t already know from experience what the risks areas are</li><li>There is an action plan of what to do if they find an unexploded ordnance</li></ul></td></tr></tbody></table></figure><p>I could not find any data on the actual cost and benefits of conducting EORE. EORE are usually done in conjunction with surveying and clearance work or in areas that will be cleared in the future. It is mostly a community led process and should not be too expensive.</p><h3>&nbsp;</h3><h3>Demining areas contaminated with UXOs</h3><p>For the following section we are making a couple of assumptions which allow us to compare the different demining methods relative to each other, which does not mean that this is an absolute assessment. We are assuming that one hectare of land cleared has around 10 UXOs on average. This is taken from the&nbsp;<a href=\"https://www.halotrust.org/media/8721/tar-and-fs-31-march-2022-halo-trust.pdf\"><u>HALO Trust report (p. 7)</u></a> which says that during the financial year of 2021/22 they have released 9980 hectares of land and have destroyed 56,728 landmines, 44,654 Unexploded ordnances, and 8,247 cluster munitions. This is a crude calculation but given the data the best we\u00b4ve got. HALO has also destroyed other explosives but they weren\u2019t part of the land clearing effort (e.g. stockpiled weapons) which means that they detonated 56,728 + 44,654 + 8,247 = 109,629 explosive devices on 9980 hectares of land which means that on average there were 109,629 /&nbsp; 9980 = 10.98 UXOs per hectare. We assume each UXO translates into 0.99 DALYs as calculated earlier.&nbsp;</p><p><u>Using detectors to demine areas contaminated with UXOs</u></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Deminers with metal detectors identify explosive devices -&gt; those are collected and destroyed in a&nbsp; controlled explosion -&gt; this piece of ordnance cannot injure or kill any more -&gt; less people being injured and killed + cleared land can be used productively.&nbsp;</p><p><br>&nbsp;</p><p>Assumptions:</p><ul><li>The identifying and exploding of units is generally safe and does not cause large amounts of injury and death in itself</li><li>Metal detectors can identify unexploded devices with high confidence and landmines are not made from undetectable material like plastic</li><li>People trust the clearance groups enough to use land afterwards</li></ul></td></tr></tbody></table></figure><p><br>&nbsp;</p><p>Detecting landmines with metal detectors is the most common way UXOs are identified. Most detectors are hand held and emit an audio signal if a medal is detected (even anti-personnel mines made of plastic contain some metal parts and can be detected). There are many different models on the market (and I do not have the expertise to recommend a specific model), the newest versions combine metal detection with ground penetrating radar to augment the image. There is a reason this comparatively old technology is still so widely used: it is relatively low tech, relatively inexpensive and relatively easy to train people on as well as it having wide applicability as it can be used in a wide range of different terrain.&nbsp;</p><p><a href=\"https://www.israel21c.org/clearing-minefields-at-much-lower-risk-and-cost/\"><u>Some estimates</u></a> claim that removing all 110 million existing landmines in the world using conventional manual demining could cost as much as $100 billion and could take up to 200 years and that it currently costs around $4-$8 per square metre to clear land with conventional approaches (this estimate is very high, the author has specific interests involved). 10,000m\u00b2 are one hectare which means it costs around $4 x 10,000 = $40,000 to clear one hectare of land. This means it would cost around $4000 to clear one landmine and therefore $4000 for 0.99 DALYs meaning<strong> $4040 per DALY</strong>.&nbsp;</p><p>Because deminers are often people from the region and because the job does not require high educational prerequisites, it can basically be interpreted similar to cash transfers. Furthermore, in post conflict societies it might provide jobs to people who previously might have been part of militias, meaning alternative employment could be helpful in reducing ongoing violence as well. This would mean that this form of landmine removal could outperform the cash benchmark through the additional DALYs and the fact that the population group employed could have potentially caused other societal harm.&nbsp;</p><p>&nbsp;</p><p><u>Animals like rats and dogs</u></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Rats or dogs sniff out landmines (rats are light enough to not trigger an explosion) -&gt; a controlled explosion is then conducted -&gt; landmine is exploded -&gt; less casualties and land can be used productively.&nbsp;</p><p><br>&nbsp;</p><p>Assumptions:&nbsp;</p><ul><li>They don\u2019t miss mines</li></ul></td></tr></tbody></table></figure><p><br>&nbsp;</p><p>Using specially trained animals like rats or dogs for mine clearance is a niche. The principle is the same as with sniffer dogs in Airports, such animals can be used to detect the small amount of explosives and signal when finding contamination. Rats turn out to be able to perform similar tasks whilst being so light that pressure detonators do not engage (most anti-personnel mines take about 5 kg to actuate). Furthermore, losing an animal in an accident is very different to a human. The primary actor in that field is Apopo, they train rats.</p><p>The cost to train a rat is about&nbsp;<a href=\"https://apopo.org/herorats/faqs/?v=79cba1185463\"><u>USD 6.000</u></a>, they are usually able to detect accurately for 4-5 years. They can smell 15-20 cm deep and are able to cover&nbsp;<a href=\"https://apopo.org/herorats/faqs/?v=79cba1185463\"><u>200 m</u><sup><u>2</u></sup><u> in 20 minutes</u></a>. After they have sniffed out the potential explosives, they are diffused and collected and a controlled explosion can then be conducted. This means they can cover 600m\u00b2 in one hour, meaning it takes them 16 hours to clear one hectare of land. If they work 4 hours per day, they are able to clear land within 4 days, which would take a human with a metal detector 50 days.&nbsp;</p><p>If we quadruple the cost of training the rat to include personnel and logistics cost the cost comes out to $30,000 over one year and $150,000 over five years. This means the cost per four days (one hectare) would be ($150,000 / 5 years / 300 days) x 4 days = $400 per hectare, meaning $40 per landmine detected (and 0.99 DALYs) coming out to a cost per DALY of&nbsp;<strong>$40.40 per DALY</strong>.</p><p>&nbsp;</p><p><u>Mechanical (excavators and other heavy machinery)</u></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Special excavators drive over land -</p><p>&gt; swinging weights detonate anti personnel mines and other explosives (or they get crushed)&nbsp;</p><p>-&gt;&nbsp; ordnance explodes</p><p>-&gt; less casualties + land can be used&nbsp;</p><p><br>&nbsp;</p><p>Assumptions:&nbsp;</p><ul><li>The excavators can get to the contaminated areas</li><li>The excavators can drive on the land that is supposed to be cleared (no dense forest, not too wet, etc.)</li></ul></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/mc7g9mj44lhjx7dcmgmz\"></p></td></tr></tbody></table></figure><p>Mechanical clearance works by using a tracked vehicle outfitted with a rotating cylinder that has attached flails (metal weights) which with high centrifugal force pounds on the ground and the explosives to cause their destruction or detonation. Other systems use so-called rollers which are heavy metal drums which detonate the explosives. Both types are mostly used by armed forces and only work in certain scenarios (open fields or little vegetation).</p><p>A good example for this method is the \u201cMine Wolf\u201d (see image) built by the British company Pearson Engineering Ltd and used by the UN, and various militaries and organisations. The vehicle is rated to withstand mines of up to 15 kg of TNT or equivalent, so sufficient for all common anti-personnel mines and some anti-tank mines. A mine wolf can clear up to<a href=\"https://www.army-technology.com/projects/minewolf/\"><u> 25,000m\u00b2/day</u></a>. I could not find any price for these machines and did not want to enquire with the companies. Normal excavators that are mass produced<a href=\"https://www.purchasing.com/construction-equipment/excavators/excavator-comparison/index.html\"><u> seem to cost between $750,000 and $1,000,000</u></a>. Pearson on the other hand produces highly specialised and armoured vehicles so the assumption is that the cost per vehicle is somewhere between 10 and 20 million (very high uncertainty!).&nbsp;</p><p>Their limitations are around the type of contexts they can be used in. They are very useful on big open fields but not in forested spaces or ground that is not flat which limits their applicability. It is unclear how many fields exist that need to be cleared like this compared to more forested areas. Such vehicles might be very well suited to the type of terrain in Ukraine which experiences heavy contamination due to the ongoing war. Furthermore, it might be quite difficult to import this machinery into countries and get them to the places most affected by landmines as they might need to travel quite far which might be difficult.&nbsp;</p><p>If we assume that the above would not be an issue we can make the following calculations: If excavators can cover 25,000m\u00b2/day and cost around 20 million a piece (price + running costs) and hold for 10 years, clearing 1 hectare of land would cost 20 million / 10 years / 300 days = $6,666.66 per day for 25,000m\u00b2 which are 2.5 hectares. Clearing 1 hectare therefore costs around $2,666.64. If one hectare has 10.98 UXO, the cost per landmine would come out to 242,86 and therefore&nbsp; the cost would be around $245.31per DALY (which could be a lot lower if the machinery cost less).&nbsp;</p><p>&nbsp;</p><p><u>New technologies</u></p><p>There are also new technologies like&nbsp;<a href=\"https://interestingengineering.com/culture/wind-powered-ball-detonates-landmines-with-bamboo-legs\"><u>tumbleweed detonators</u></a> or&nbsp;<a href=\"https://www.unmannedsystemstechnology.com/2021/08/landmine-detection-with-drones/\"><u>drones</u></a> used to survey inaccessible territory as well as&nbsp;<a href=\"https://youtu.be/vOkgcmrPvHQ?t=135\"><u>self-driving vehicles</u></a>. As all of these technologies are currently in development, I have not included an estimate of their effectiveness here but would summarise my thoughts as follows:&nbsp;</p><ul><li><u>Tumbleweed:</u> is an interesting concept which is applicable to heavily contaminated flat land without vegetation. It only triggers ordinance with a pressure sensor. Other types with timers, radio frequency detonators or magnetic detonators and crucially, ammunition would not be detonated by this technique making it only applicable in the narrowest of applications.</li><li><u>Drones</u>: depending on their sensing equipment can and already are very useful for surveying. Yet, it does not help with diffusing and is a quite high tech technique for a context which usually suits more robust tools. Still, there are certainly possibilities worth exploring.</li><li><u>Ground penetrating radar</u>: Another technology used for UXO clearance (not applicable for anti-personnel mines and IEDs) is the detection with ground penetrating radar. Large arrays can be built to create an image of the soil and its contaminants. This method enables actors to survey large areas quickly. This method is used primarily in commercial settings before a construction or to identify contaminants in old military installations, humanitarian use cases are also possible.</li><li><u>Self-driving vehicles</u>: the mine wolf can already be used in a remote driving setting. Removing the personnel from the hazard is always a welcome possibility provided that the quality of work does not suffer because of it.</li></ul><h3>&nbsp;</h3><h3>Victim assistance</h3><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Person is being hurt by an explosive -&gt; person accesses emergency healthcare -&gt; person survives -&gt; person gets additional (medical, social or financial support) in the future -&gt; lower deaths/DALYs and higher life satisfaction</p></td></tr></tbody></table></figure><p><br>&nbsp;</p><p>It seems like there are two points during which victim assistance can be helpful: (1) immediately after being in contact with an UXO, and (2) long term health and financial assistance.&nbsp;</p><p>It seems like people living in contexts with better healthcare systems would have better access to direct medical attention if they come into contact with an UXO. It is unlikely that it would be cost-effective to provide medical infrastructure just for the purpose of treating people affected by UXOs. Having said that, investment in medical infrastructure could be cost-effective because it could affect so many other diseases. Providing victims with prosthetic limbs is an integral part of victim assistance. This analysis is beyond the scope of this report.&nbsp;</p><p>In terms of the longer term victim assistance, it seems to soften the effects that the injury had on their life. It might help them to continue to work, or substitute the lost earnings they have and it might help them to remain mobile and participate in daily activities more. Both of these might be fairly expensive and only do a little to help people who are already affected.&nbsp;</p><p>Many humanitarian organisations have specific programmes for survivors to provide prosthetics, rehabilitation, and other services to help people re-enter into the workforce. Many also face stigma and exclusion due to their injury as well as the effect on their livelihoods.</p><p>In general, victim assistance seems fairly costly and only softens the effect of exposure once it already happens and does not do anything in regard to lost productivity because people don\u2019t use fields or public infrastructure. Even with a perfect healthcare system it seems unlikely that people would take the risk of using public infrastructure and fields.&nbsp;</p><h3>General remarks about interventions</h3><p>It is important to be conscious of the fact that the most appropriate intervention is dependent on the type of contamination, terrain, vegetation, logistics and labour costs. Current implementing organisations have many decades of experience of choosing the most appropriate \u2013 and cost effective \u2013 method. This perspective was mirrored by the Head of Humanitarian Disarmament and Peacebuilding at the Danish Refugee Council who was contacted as part of the research.</p><p>It is important to note that it is highly dangerous to push for cost-cutting mechanisms in the clearance space to the detriment of quality for two reasons: (1) it increases the likelihood of accidents happening during the demining process, (2) locals gain confidence in the area being cleared and use it and might step on an overlooked landmine when they would otherwise not have used the space. This would erode the trust in all cleared areas and thus would be devastating for the confidence in the work. Pushing clearance organisations towards cost-effectiveness (if the intervention in itself is not cost-effective) can be dangerous!</p><p>Other factors may further complicate the cost-effectiveness calculation. The former chief of mine action for UNMAS Afghanistan, during an expert interview, has mentioned furthermore that the employment of several hundred or thousand deminers who are almost exclusively men in fighting age has a profound impact on the ability of insurgents to recruit them. If one provides about 9,000 men with a stable income in the territory of an insurgency it has far deeper effects than the effect of their work alone. Mine action thus gives them a skill, money and they are far less likely to join organisations such as the Taliban (this refers to the situation pre-Taliban takeover in 2021, but the principle very much remains). Weighing the impact of these very real knock-on effects is very challenging but shall not be forgotten when reviewing the cost-effectiveness of mine action. This impact is arguably smaller in peaceful places like Lao but it is relevant for others like Mali, South Sudan and so on.</p><p>Another thought to consider is that there might be more adverse effects on a community to lose a member due to literally being blown up compared to more \u2018silent\u2019 killers which take a few DALYs at the end of one's life or to something like HIV/AIDS. It seems reasonable to assume that the satisfaction of one's circumstances might be more affected by the presence of UXOs than of diseases \u2013 despite costing similar amounts of DALYs, or even less. We shall not forget that (unfortunately) humans are mostly not rational.</p><h1>Funders</h1><p>The funders of the mine action sector are quite consistent in their funding with relatively little change in funding over the years. Almost all funding comes from states and is distributed to the various mine action organisations. The biggest donors to mine action according to the 2020 Landmine Monitor are the United States, European Union, Germany, Japan, Norway, and the United Kingdom. The funds are used for operations by mine action organisations (most are non-profit, some are for profit contractors) as well as in some cases for their own military to engage in clearance.&nbsp;</p><p>The levels of mine and UXO contamination is usually very well known thus there is very little risk of neglected areas. The only reason for neglectedness would be that a place is inaccessible (government does not grant permission). Overall funders are not focused on one specific area, but rather are willing to follow needs assessments. One exception would be US funding to Lao and Cambodia \u2013 since the US directly caused the contamination and thus is the main funder for these counties. &nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/rladhtaygpsetyiwyoge\" alt=\"Table\n\nDescription automatically generated\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/l2c6vudv1pliztexhjxy 121w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/sstltfuwncsgt4xdq5uv 201w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/ytc0kp4kexhhro5h1xxt 281w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/icbo3d4zblkhdde6nxim 361w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pPqZMTyJvvdWGfkBy/x0e8ab70wrh0grf94v3v 441w\"><figcaption>Source: Landmine Monitor 2021</figcaption></figure><h1>&nbsp;</h1><h1>Implementers</h1><p>There most important implementing organisations are listed below:&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"background-color:#cfe2f3;border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Implementer Organisation</p></td><td style=\"background-color:#cfe2f3;border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Comments</p></td><td style=\"background-color:#cfe2f3;border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Annual budget (USD million)</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>The HALO Trust</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Biggest implementer,&nbsp;</p><p>UK based</p><p>94 million HALO trust for 9980 hectares released (<a href=\"https://www.halotrust.org/media/8721/tar-and-fs-31-march-2022-halo-trust.pdf\"><u>p.7</u></a>)</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>101.7</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Mines Advisory Group</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>UK based</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>90.3</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>UNMAS</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>UN Organization</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>64.8</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Danish Refugee Council</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Mine Action is only one of their activities (~ \u2153)&nbsp;</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>446.4</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Norwegian People's Aid</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Mine Action is only one of their activities</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>109</p><p>(<a href=\"https://www.npaid.org/files/default/NFH_Res-rapp-2021_ENGELSK.pdf\"><u>p. 31</u></a>)</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Danish Church Aid</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Mine Action is only one of their activities</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>146</p><p>(<a href=\"https://www.noedhjaelp.dk/wp-content/uploads/sites/2/2022/05/aarsrapport-2021-maj-2022-uk.pdf\"><u>p. 23</u></a>)</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Apopo</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Use rats to detect mines, Belgium based</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>6.5</p><p>(<a href=\"https://apopo.org/wp-content/uploads/2022/12/APOPO_annual-report-2021-final.pdf?v=3a52f3c22ed6\"><u>p. 85</u></a>)&nbsp;</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>G4S</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Commercial company, do also mine action</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>6.9 (revenue)</p><p>(<a href=\"https://www.g4s.com/-/media/g4s/corporate/files/investor-relations/2021/g4s_annual_report_2020.ashx?la=en&amp;hash=4D743478822AC0CAF1FD96F23AEE94D2\"><u>p. 72</u></a>)</p></td></tr></tbody></table></figure><p><br>&nbsp;</p><p>In general, the funds donated to UNMAS from the UN member states are directed towards implementation organisations which is why some of the UNMAS funds are counted double in the table above. They are the only Mine Action organisation which contracts other implementers. For a non-exhaustive list of further&nbsp; implementing organisations see&nbsp;<a href=\"https://en.wikipedia.org/wiki/Mine_clearance_organization#Mine_Awareness_Trust\"><u>here</u></a>.&nbsp;</p><p>Most large demining organisations do not have a particular geographic focus but work where it is necessary and possible. Some organisations are focused on a specific way of detecting mines but that is mostly dependent on the form of contamination. Grants are usually made for a specific project focused on a region or specific site, unearmarked funding is often more helpful to organisations and can be used more effectively. Due to the high risks associated with working with explosives, implementing organisations are strict when it comes to safety precautions for their staff.&nbsp;</p><p>Many mine action organisations are based in the UK who are leaders in the field. Technical staff is often former military personnel thus being very effective and mission-oriented making negotiations quite streamlined and to the point. If one were to decide to fund mine action, I\u2019d recommend contacting the implementers listed above and signal willingness to negotiate a grant. Based on my experience in the UN Mine Action Service Donor Relations department grants are usually between USD 200.000-5.000.000. Usually, the smaller the grant the less leverage one has, to set demands regarding reporting, location, type of clearance.</p><p>Other big actors are national so-called Mine Action Centres which are usually a body in the affected country which coordinates mine action efforts in a given place. Sudan, Bosnia and Herzegovina, Serbia, Sri Lanka and more all have one. Capacity building projects in which the national army is trained are also quite frequent, they mostly but not exclusively happen in bilateral agreements between states. National armies are often a substantial actor in clearance efforts.</p><h1>Conclusions</h1><p>Based on the research conducted I can conclude that the issue is:&nbsp;</p><ol><li>very important due to many reasons which are not properly captured with a simple analysis of DALYs,&nbsp;</li><li>cost-effectiveness is not the primary consideration for mine action organisations (maybe with good reason),&nbsp;</li><li>the current funding structure of mine action is not that compatible with EAs funding mechanisms, and&nbsp;</li><li>prospects of starting an EA aligned mine action organisation would not be easy, cheap or be particularly welcomed by existing actors.</li></ol><p>As discussed above, employing men of fighting age in areas with active insurgency groups has positive knock on effects beyond the work itself. Furthermore, the prioritisation of peoples on the ground might not be driven by a rational analysis but rather by the \u2018dramatic image\u2019 of explosions in their community.</p><p>In talks with experts the issue of bringing up cost-effectiveness did not lead to much understanding. Regardless, it is safe to assume that cost-effectiveness is important when planning a project in the sense of choosing the most appropriate approach for the task at hand.</p><p>The funding in mine action currently comes primarily from state grants where the donor has a lot of leverage deciding how the project is designed meaning that political considerations are a major factor. A donor like the UK is not really concerned if the project location is really the cheapest place to work and more with political considerations. Surely this is something which could be explicitly requested when approaching a mine action organisation regarding a project. With some explanation it seems reasonable to expect them to find the most cost effective place to work. But that would not necessarily ensure that the intervention itself would be more cost effective than other interventions.</p><p>Starting an EA aligned mine action organisation would theoretically be feasible but would require a lot of start-up capital and great financial resources. One would need to hire former military personnel to get technical competence. The starting salary for mine action international field staff is low at around USD 30-35 thousand, but the more experienced staff which would be needed to start something new is also more expensive. Furthermore, a lot of equipment and training is necessary, which are both relatively expensive. And lastly, to be allowed in a country one would need to project a seriousness to ensure that the national actors will allow for such projects. Due to the high stakes of dealing with explosives they are quite conservative and are eager to go with known organisations which have a track record. Due to these factors, I\u2019d recommend writing a grant with provisions regarding cost-effectiveness rather than creating a new organisation.</p><p>These points lead to the conclusion for EA organisations not to invest in mine action and not to start a new organisation. In general, mine action is a fantastic field with incredibly brave individuals conducting work which eventually needs to be done, but the high cost of dealing with explosives and the dangers associated with it make the field too expensive for actors aiming to maximise their effectiveness.&nbsp;</p><p>If someone would be interested in investigating this further I would recommend the following starting points:&nbsp;</p><ul><li>Estimating the effects and effect size of removing landmines, IEDs and UXOs with greater confidence seems really important. Right now I have estimated around 0.99 DALYs per landmine removed but with very low confidence. Modelling this out in more detail seems vital.&nbsp;</li><li>Writing detailed intervention reports for the more promising interventions that review the evidence base and model cost-effectiveness for these interventions in more detail.&nbsp;</li><li>Evaluating the interventions through the work done by the organisations themselves instead of in the theoretical. There might be geographies and organisations that are doing really cost-effective work but are neglected by funding that is largely political.&nbsp;</li><li>Investigating further variations of the interventions that I have looked at. For example, the question if there is a way to advocate for existing orgs/governments doing langmine work to focus on more effective strategies. The organisations might be interested in this as it frees up more of their budget.&nbsp;</li></ul>", "user": {"username": "Jakob P."}}, {"_id": "JoCiLGRavuBBrDJjh", "title": "Increasing our impact on climate change. Talk + Q&A with Violet Buxton-Walsh from Founders Pledge", "postedAt": "2023-03-03T14:28:08.246Z", "htmlBody": "<p>Effective Altruism Osnabr\u00fcck is delighted to host Violet Buxton-Walsh for a talk about <strong>her research on the most impactful ways to mitigate climate change</strong>.&nbsp;<strong>The talk will be held </strong><a href=\"https://webconf.uni-osnabrueck.de/b/aar-d6k-jyk-nxq\"><strong>here</strong></a><strong>, on the 9th of March at 7 pm CET.</strong><br><br>Violet is a research assistant in the climate change team at FoundersPledge, a non-profit that encourages entrepreneurs to donate significant fractions of their wealth to effective charities. To date, around 1700 entrepreneurs have donated more than half a billion dollars. Violet is part of a team of researchers that aim to find the best opportunities to give this money away.<br><br>No background in climate science is required to understand the talk. We hope to see you there!&nbsp;</p>", "user": {"username": "Aaron__Maiwald"}}, {"_id": "E8qYE5cC78dbiGdud", "title": "Recipe book recommendations for EAs", "postedAt": "2023-03-03T13:43:55.764Z", "htmlBody": "<p>I like food. I like making it, I like the history attached to it, I like serving it to friends. Some corners of EA have an odd attachment to thinking of food purely as fuel, and I think this is bad for vibes but a little bit bad in general as many people like food and if you make delicious vegetarian food your example might be more persuasive to them than if you drink a rebranded SlimFast for dinner, not that there's anything wrong with that.</p><p>So for the sake of other EAs that like food:<strong> What are your favourite cookbooks or recipes? </strong>For fairly obvious reasons, I'm most interested in vegan, vegetarian, or low-meat recipes.</p><p>I'll go first: I think the best way to get tasty no or low-meat food is to find books or recipes from food cultures that have a deep tradition of such food. My biggest wins have been mining recipes from Chinese (Fuchsia Dunlop <a href=\"https://www.amazon.com/s?k=fuchsia+dunlop\">writes good recipe books here</a>), Indian, or Jewish (\"dairy\" recipes) cuisine. I also like the Ottolenghi books.</p>", "user": {"username": "ryancbriggs"}}, {"_id": "yPvpKz7RkiS4cqKku", "title": "New Artificial Intelligence quiz: can you beat ChatGPT?", "postedAt": "2023-03-03T15:46:09.194Z", "htmlBody": "<p>Hey EA Forum!</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yPvpKz7RkiS4cqKku/xywnxdcmclmqcnezqglw\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yPvpKz7RkiS4cqKku/xyl7hauvj3vel0kij7jc 160w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yPvpKz7RkiS4cqKku/lomqsrbsdp5rfmfue2jg 320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yPvpKz7RkiS4cqKku/lxr3amzhn7xq07uq0y8m 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yPvpKz7RkiS4cqKku/zsvsn8qbo4ykyqlifnms 640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yPvpKz7RkiS4cqKku/inklawcx8fowphhvou5e 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yPvpKz7RkiS4cqKku/fa182dsd6kr4dmzmgdxk 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yPvpKz7RkiS4cqKku/eqj2zqqv8xx2jlnm0vxs 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yPvpKz7RkiS4cqKku/e0gaj5xmui63sabusyou 1280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yPvpKz7RkiS4cqKku/scqmoswpfusnhuymsrzx 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yPvpKz7RkiS4cqKku/u6iyaqogkcehm0hcxzh4 1536w\"><figcaption>The AI wave is coming. Are you ready to surf? Image generated by the <a href=\"https://www.midjourney.com/home/\">Midjourney</a> AI.</figcaption></figure><h2>Introduction</h2><p>I\u2019m excited to announce the release of Quizmanity's new <a href=\"https://quizmanity.org/artificial-intelligence/\">Artificial Intelligence Quiz</a>. This quick 15-minute journey will test your knowledge of AI safety with 12 multiple-choice questions, such as:</p><ul><li>How much money are companies investing in AI yearly?</li><li>How do AI systems compare in complexity to animal brains?</li><li>Why does the Skynet AI in the movie <i>Terminator</i> attack humanity?</li></ul><p>[<a href=\"https://quizmanity.org/\">Quizmanity.org</a> is a website with quizzes to test your knowledge of pressing problems, including global health, animal welfare, existential risk, and the long-term future. In partnership with <a href=\"https://programs.clearerthinking.org/artificial_intelligence_quiz.html\">clearerthinking.org</a>, you can also take the quiz on their website.]<br>&nbsp;</p><h2>Why take the quiz</h2><p>At the end of the quiz, you'll receive a custom report that compares your score with others and with the ChatGPT AI. The report also offers practical steps that you can take to help ensure AI leads to a brighter future for humanity.</p><p>If you're new to AI alignment and lethal autonomous weapons, the quiz offers an engaging introduction that will boost your retention through testing. And for veterans, the quiz can serve as a tool to revise your knowledge and maybe learn some new facts.</p><p>The quiz was developed with the help of AI, from generating witty jokes to rephrasing every sentence and generating the images. And don't worry, ChatGPT promises not to take over the world... at least not for now!<br>&nbsp;</p><h2>Test your knowledge</h2><p>So what are you waiting for? <a href=\"https://quizmanity.org/artificial-intelligence/\">Take the quiz</a> and see if you can beat ChatGPT.</p><p>Don't forget to share it with a friend and suggest improvements in the comments section below.<br>&nbsp;</p><h2>Credits</h2><p>I would like to express my gratitude to the nearly 50 people who took the time to give their feedback. As a token of my appreciation, their names have been included in the list of credits at the end of the quiz, and they received a permanent seat in the <a href=\"https://quizmanity.org/feedback/\">Feedback Hall of Fame</a>.</p><p>A special thank you goes to Spencer Greenberg and Fin Moorhouse, who have respectively created <a href=\"https://www.guidedtrack.com/\">the infrastructure</a> and the idea for Quizmanity. Without you, Quizmanity wouldn't exist. Travis Manuel, thank you for your kindness and persistence during the quiz drafting process. Lorenzo Buonanno, I know I can count on your helpful nature and keen eye for spotting bugs, as many Forum users can attest. Josh Castle, I'm starting to owe you too many pizzas. Lastly, Geoffrey Miller, thank you for promoting the quiz and encouraging me with kind words.</p>", "user": {"username": "andreferretti"}}, {"_id": "ovNTJnG4vbZPKhm2y", "title": "Recent paper on climate tipping points", "postedAt": "2023-03-02T23:11:55.296Z", "htmlBody": "<p><br>There is a new paper on climate tipping points by Wang et al (2023),&nbsp;<br><a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021RG000757\">\"Mechanisms and Impacts of Earth System Tipping Elements\"</a>, described on Twitter by the lead author <a href=\"https://twitter.com/wang_seaver/status/1630686895465467904\">here</a>.<br><br>This paper struck me as interesting fort wo reasons and I would be curious for comments from climate scientists as I see the paper as a downwards-update on the uncertainty and relevance of tipping points:<br><br>(1) It stated rather confidently that \"The studies synthesized in our review suggest most tipping elements do not possess the potential for abrupt future change within years,\"<br><br>(2) It sought to quantify the relative impact of tipping points vis-\u00e0-vis climate sensitivity and emissions uncertainty finding that tipping points are quite a small source of variation (esp. see Panel D below, tipping points broaden the uncertainty by ~ 0.5C or so for SSP2-4.5 in 2100 compared to a climate sensitivity uncertainty ranging w/o tipping points of about ~2.5C for SSP-2-4.5 in 2100):&nbsp;<br><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/ovNTJnG4vbZPKhm2y/pzh7s6iatg3ugqrnstrl\" alt=\"Image\"><br><br>To make more explicit, what kind of questions I have:<br><br>1) How trustworthy do you find this paper?<br>2) How does this relate to other estimates? In my experience, people are quite unwilling to put probabilities / quantifications on tipping points, so i found this useful, but am also unsure.<br><br>etc.<br><br><br>&nbsp;</p>", "user": {"username": "jackva"}}, {"_id": "HCuoMQj4Y5iAZpWGH", "title": "Advice on communicating in and around the biosecurity policy community", "postedAt": "2023-03-02T21:32:46.765Z", "htmlBody": "<h2><strong>TL;DR</strong></h2><p>The field of biosecurity is more complicated, sensitive and nuanced, especially in the policy space, than what impressions you might get based on publicly available information. As a result, say / write / do things with caution (especially if you are a non-technical person or more junior, or talking to a new (non-EA) expert). This might help make more headway on safer biosecurity policy.&nbsp;</p><p>Generally, take caution in what you say and how you present yourself, because&nbsp;it does impact how much you are trusted, whether or not you are invited back to the conversation, and thus the potential to make an impact in this (highly sensitive) space.</p><h2><strong>Why Am I Saying This?&nbsp;</strong></h2><p><i>An important note: I don\u2019t represent the views of the NIH, HHS, or the U.S. government and these are my personal opinions. This is me engaging outside of my professional capacity to provide advice for people interested in working on biosecurity policy.</i></p><p>I work for a U.S. government agency on projects related to oversight and ethics over dual-use research of concern (DURC) and enhanced pandemic potential pathogens (ePPP<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefw1j7slhknl\"><sup><a href=\"#fnw1j7slhknl\">[1]</a></sup></span>). In my job, I talk and interface with science policy advisors, policy makers, regulators, (health) security professionals, scientists who do DURC / ePPP research, biosafety professionals, ethicists, and more. Everyone has a slightly different opinion and risk categorisation of biosecurity / biosafety as a whole, and DURC and ePPP research risk in specific.&nbsp;</p><p>As a result of my work, I regularly (and happily) speak to newer and more junior EAs to give them advice on entering the biosecurity space. I\u2019ve noticed a few common mistakes with how many EA community members \u2013 both newer bio people and non-bio people who know the basics about the cause area \u2013 approach communication, stakeholder engagement, and conversation around biosecurity, especially when engaging with non-EA-aligned stakeholders whose perspectives might be (and very often) are different than the typical EA-perspective on biosecurity and biorisk<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1ivne8lop7xj\"><sup><a href=\"#fn1ivne8lop7xj\">[2]</a></sup></span>.&nbsp;</p><p>I've also made many of these mistakes! I'm hoping this is educational and helpful and not shaming or off-putting. I'm happy to help anyone unsure communicate and engage more strategically in this space.&nbsp;</p><h2><br><strong>Some Key Points that you might need to Update On.&nbsp;</strong></h2><p>Junior EAs and people new to biosecurity / biosafety may not know how to or that they should be diplomatic. EA communities have a trend of encouraging provoking behaviour and absolutist, black-and-white scenarios in ways that don't communicate an understanding of how grey this field is and the importance of cooperation and diplomacy. If possible, even in EA contexts, train your default to be (at least a bit more) agreeable (especially at first).&nbsp;</p><h3><strong>Be careful with the terms you use and what you say</strong></h3><p>Terms matter. They signal where you are on the spectrum of \u2018how dangerous X research type is\u2019, what educational background you have and whose articles / what sources you read, and how much you know on this topic.&nbsp;</p><blockquote><p>Example: If you use the term gain-of-function with a virologist, most will respond saying most biomedical research is either a gain or loss of function and isn\u2019t inherently risky. In an age where many virologists feel like health security professionals want to take away their jobs, saying gain-of-function is an easy and unknowing way to discredit yourself.&nbsp;</p></blockquote><p>Biosafety, biorisk, and biosecurity<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbsaoras91u\"><sup><a href=\"#fnbsaoras91u\">[3]</a></sup></span>&nbsp;all indicate different approaches to a problem and often, different perspectives on risk and reasonable solutions. What terms you use signal not only what \u2018side\u2019 you represent, but in a field that\u2019s heavily political and sensitive can discredit you amongst the other sides.&nbsp;</p><h3><strong>Recognise how little (or how much) you know&nbsp;</strong></h3><p>Biosecurity is a field with a lot of information asymmetry. Firstly, many parts of the story simply aren\u2019t public knowledge. I\u2019m not saying the state of the field is perfect. But unfortunately you can\u2019t, and likely don\u2019t, know everything. I can say that I believe the field of U.S. government oversight on DURC and ePPP is much stronger than many believe.&nbsp;</p><p>Second, many people work on this for a living, have advanced degrees on this topic, and multiple years of experience. Your two hours of research on a topic doesn\u2019t mean you know more than them. If you are going to disagree with their opinions (which it\u2019s okay to do so), make sure you are confident that what you are saying is true.&nbsp;</p><p>A mistake I once made was stating confidently something along the lines of criticising \u201cUS government dual-use regulations'\u201d in front of someone who wrote and implemented the DURC&nbsp;<i>policies</i>, not regulations. There are no legal regulations over DURC<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0andzbgnjf7l\"><sup><a href=\"#fn0andzbgnjf7l\">[4]</a></sup></span>. I was called out by them and told to read through the policy more carefully for future conversations. That could have easily discredited me and lost that key relationship. Mistakes happen, but being confident that what you are saying is correct, especially if going against an expert opinion, is important.&nbsp;</p><p>Third, many EAs aren't as special or way ahead of the curve as you might think. You likely don\u2019t know more than professionals if your information only comes from publicly available EA sources like&nbsp;<i>The Precipice,&nbsp;</i>Future Perfect, or the EA Forum. I love reading the above, but it\u2019s most definitely a one sided and simplistic view. Many of these resources aim to persuade rather than solve the nitty-gritty details of how to implement solutions in real-life. If you\u2019re seriously interested in a career in this space or are someone whose words have influence, make sure you form your own detailed views. Be able to say more than \u201cbiosecurity is important\u201d or \u201cthere\u2019s a chance of a lab accident\u201d. Ideally you should be able to answer questions like \u201cwhat are the actual risks of dual-use research, what are the policies in X country, how does Y increase the risk of a GCBR occurring, where are gaps in the existing oversight mechanisms and what are feasible additional interventions, etc\u201d because learning how to answer those questions teaches the nuance of how difficult biosecurity and biosafety and risk-mitigation are.&nbsp;</p><h3><br><strong>Scientific researchers, biosecurity, and biosafety professionals know what they are doing (sometimes) and aren\u2019t trying to kill us all</strong></h3><p><i>(The quotes mentioned below have been paraphrased from non-EA virologists, research scientists, and biosafety profession)</i></p><p>The media has attacked biosafety professionals and scientists who work on DURC / ePPP nonstop for the past 3 years. In the U.S. (and I\u2019m sure in other countries too) this has gone as far as death threats, doxxing, and investigations from (non-scientist) members of the government. I\u2019m all for accountability, but what\u2019s been happening isn\u2019t productive accountability and has created an environment of fear. I\u2019ve heard things like</p><blockquote><p>&nbsp;<i>I\u2019m afraid to say or do anything publicly or I\u2019ll get doxxed\u201d or \u201cX institution won\u2019t communicate in writing for fear of getting called to Congress\u201d.</i> In fact, I\u2019ve even heard that some people feel that they have&nbsp;<i>\u201cworked really hard to build trust so scientists can come to us when they have an uncertain or adverse scientific result. The intense scrutiny on this field is ruining that\u201d.&nbsp;</i></p></blockquote><p>Many professionals in this space are scared and stressed. Adding to that isn\u2019t necessarily building trust and needed allies. The professionals in this space are good people \u2013 no reputable virologist is trying to do research that intentionally releases or contributes to a pandemic. Biosafety professionals spend their life working to prevent lab leaks. If I\u2019m being honest, many professionals in and around the biosecurity field don\u2019t think incredibly highly of recent (the past few years) journalistic efforts and calls for total research bans. A common sentiment among the very professionals we need to work productively with are:</p><blockquote><p>\u201c<i>those people who write op-ed\u2019s and blog posts don\u2019t know anything about how the science actually works or how oversight and biosafety work\u201d and \u201cmany people criticising the field are just trying to make a name for themselves and going about it the wrong way\u201d</i>.&nbsp;</p></blockquote><p>Choose your words and actions carefully because the most bold ones aren\u2019t the most impactful \u2013 in terms of updating policies and actions \u2013 ones.&nbsp;</p><h3><br><strong>Dual-use, \u2018gain-of function\u2019 and ePPP research is not so black-and-white.&nbsp;</strong></h3><p>One view I often hear from EA\u2019s is \u201cwe should just ban all gain of function research\u201d or something that\u2019s extremely one-sided and simplified. There\u2019s a variety of inflammatory op-eds and articles that critique topics in biosecurity (I think) unfairly. I\u2019ve had many meetings with people interested in working on biosecurity policy with extreme, oversimplified, and sometimes antagonistic views<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkbprydrndun\"><sup><a href=\"#fnkbprydrndun\">[5]</a></sup></span>.&nbsp;</p><p>ePPP / DURC research isn\u2019t inherently bad and does have value<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl2gozysmwe\"><sup><a href=\"#fnl2gozysmwe\">[6]</a></sup></span>. To stop all DURC/ePPP research outright (in my view) would be net negative. What is minimal-risk oversight that allows necessary and useful research to happen is the key, unanswered question. Especially problematic is approaching a research scientist who does DURC/ePPP research and telling them their research adds no value. That isn\u2019t leading to anything productive and is just adversarial.&nbsp;</p><p>Second, this isn\u2019t possible or realistic from a regulatory standpoint. For \u2018gain-of-function\u2019 \u2013 you can\u2019t just pass a law to ban it. How do you define it? Who provides oversight? Implementation is challenging. And gain-of-function isn\u2019t inherently bad \u2013 biomedical research can be \u2018gain-of function\u2019 and not dangerous (aka not a GCBR risk).&nbsp;</p><h1><strong>So what next - tentative advice for people new to biosafety / security&nbsp;</strong></h1><ol><li>Read, read a lot of different sources. Understand what all sides and stakeholders think on a topic.&nbsp;</li><li>Look at the science and form your own views related to biosafety, biosecurity, ePPP, DURC and risk. What is actually risky? Know and understand the science, the existing oversight / regulation, feasible interventions, and how implementation works.</li><li>Know what you\u2019re talking about (whether it\u2019s regulation, policy, technical solutions) and the challenges related to working in the space before you criticise it.&nbsp;</li><li>Talk to (EA and non-EA) professionals and keep an open mind (ex. virologists, microbiologists, biosafety professionals, implementers, policy makers, health security specialists, ethicists, etc)&nbsp;</li><li>Know who you are talking to and use diplomatic language (at least at first_\u2013 use biosafety lingo with the biosafety professionals, talk about security with the security people, and so on. You don\u2019t have to agree on everything with everyone \u2013 but having a mutual language is important.&nbsp;</li><li>Define terms - to yourself, in conversation, etc&nbsp;</li><li>Always make sure \u2018you\u2019re invited back to the table\u2019</li></ol><h1><strong>Readings I recommend that do a good job painting more nuance than the perspective that is sometimes common in the EA movement</strong></h1><p><a href=\"https://gcc02.safelinks.protection.outlook.com/?url=https%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-030-39819-4_9&amp;data=05%7C01%7Celika.somani%40nih.gov%7C38a18e6d258c4a916c7e08daf42059b8%7C14b77578977342d58507251ca2dc2b06%7C0%7C0%7C638090717860372159%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=27HhtrRGSyWR8prwDk35H30wQO2IdtzJ%2FDixv7HLutw%3D&amp;reserved=0\"><u>Dual-Use and Infectious Disease Research&nbsp;</u></a></p><p>Highly recommended as it breaks down the dual-use dilemma and will provide nuance of the ethical concerns and challenges of providing oversight over dual-use biomedical research.&nbsp;</p><p><a href=\"https://ws.engr.illinois.edu/sitemanager/getfile.asp?id=4373\"><u>The Ethical Issues of Dual-Use and the Life Sciences</u></a></p><p>Gives a great history of the field of dual-use (research of concern) - although it\u2019s mostly U.S. based - , ethical issues, and the development of the concern over time.</p><p><a href=\"https://nap.nationalacademies.org/catalog/10827/biotechnology-research-in-an-age-of-terrorism\"><u>Biotechnology Research in an Age of Terrorism aka the Fink Report&nbsp;</u></a></p><p>A 2004 report that led to the founding of the U.S. government National Science Advisory Board for Biosecurity (NSABB), and set the framework for current day policies and oversight efforts.&nbsp;</p><p><a href=\"https://cdn.cfr.org/sites/default/files/pdf/2013/05/WP_Dual_Use_Research.pdf?_ga=2.47606244.2142736497.1575382530-1043326905.1575382530\"><u>H5N1: A Case Study for Dual-Use Research</u></a></p><p>A report that uses H5N1 as an example for the biosecurity, biosafety, and risks of DURC research. It\u2019s a great deep dive into what full time research in this field looks like and the challenges of research oversight.&nbsp;</p><p><a href=\"https://journals.asm.org/doi/10.1128/mBio.01864-21\"><u>Rapid Proliferation of Pandemic Research: Implications for Dual-Use Risks | mBio</u></a>&nbsp;</p><p>Gives a great overview of the value and costs of dual-use research and risks and grounds thoughts of risk more concretely.&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnw1j7slhknl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefw1j7slhknl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;ePPP is a sibling / renamed cousin to what most people know as gain of function (GoF). <a href=\"https://www.phe.gov/s3/dualuse/documents/p3co.pdf\">See more&nbsp;</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1ivne8lop7xj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1ivne8lop7xj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;This is something along the lines of there\u2019s a considerable GCBR risk warranting banning X research type, the US government is doing dangerous research without oversight or care, people involved in biomedical research and biosafety don\u2019t care about safety, etc.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbsaoras91u\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbsaoras91u\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Biosafety:&nbsp;Biosafety refers to the controls and standards that protect against the accidental release of pathogens.&nbsp;</p><p>Biosecurity:&nbsp;Biosecurity refers to the protections against deliberate release of pathogens.<a href=\"https://biosafetynow.org/biosecurity/\"><u>&nbsp;</u></a></p><p>Bio-risk management:&nbsp;Biorisk management refers to risk-benefit assessment for high-risk research on pathogens.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0andzbgnjf7l\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0andzbgnjf7l\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There is the U.S. Select Agent programme which overlaps with the DURC policy, but there isn't 'regulation' in the typical sense.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkbprydrndun\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkbprydrndun\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This could just be because \u2018I\u2019m an EA and they talk more honestly to me than they would to non-EA\u2019s\u2019. It still seems important to set the norm to be \u2018diplomatic and agreeable\u2019 before \u2018antagonistic and challenging\u2019</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl2gozysmwe\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl2gozysmwe\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://journals.asm.org/doi/10.1128/mBio.00188-23?_ga=2.214861973.322453087.1677791919-1488878016.1667664275\">https://journals.asm.org/doi/10.1128/mBio.00188-23?_ga=2.214861973.322453087.1677791919-1488878016.1667664275</a>&nbsp;</p></div></li></ol>", "user": {"username": "ElikaSomani"}}, {"_id": "bmfR73qjHQnACQaFC", "title": "Call to demand answers from Anthropic about joining the AI race ", "postedAt": "2023-03-02T17:26:17.354Z", "htmlBody": "<p>I'm surprised that once again it starts as \"let's work on safety together! Let's share ideas and work on a good thing\", then some entity grows bigger and bigger, starts taking unilateral decisions that are controversial, still using the name and support of community</p>\n<p>I feel the same scheme as with SBF: first, the community is used to build The Thing. Then, The Thing forgets about anything ethical or safe and just turns into an \"effective profit/PR maxmizer\". I feel kinda conned and used. Even when I'm mostly talking to AI ethicists now, I still regarded Anthropic as something not evil. Even I was shocked.</p>\n<p>I ask people to demand answers from them. I feel there's a no-confidence case for us trusting Anthropic to do what they are doing well.</p>\n<p>I was more about \"let's have safety and ethics people together\" (which ethicists didn't like), less and less in time. Now I don't know anymore. I want answers.</p>\n<p>I feel traumatized in general by the safety community and EA. I was doing research internships at Google and CHAI Berkeley. I was doing later an ethics nonprofit. All of those were somewhat EA-aligned (not 100% outside). I don't know how can I trust people who say \"safety\" anymore.</p>\n<p>What is going on?</p>\n<p>See my thread for more questions. I feel traumatized by EA, by this duplicity (that I have seen \"rising up\" before this, see my other threads). I'm searching for a job and I'm scared of people. Because this is not the first time, not at all. Somehow tech people are \"number one\" at this. And EA/tech people seem to be \"number 0\", even better at Machiavellianism and duplicity than Peter Thiel or Musk. At least, Musk openly says he's \"red-pilled\" and talks to Putin. What EA/safety is doing is kinda similar but hidden under the veil of \"safety\".</p>\n<p>Not all people are like this. Let's not be like this.</p>\n<p>I expect downvotes - I don't care. I want answers.</p>\n<p><a href=\"https://twitter.com/sergia_ch/status/1631338866840948737?s=20\">https://twitter.com/sergia_ch/status/1631338866840948737?s=20</a></p>\n", "user": {"username": "sergeivolodin"}}, {"_id": "XBxfmpjiWeDuhMoCJ", "title": "Game theory work on AI alignment with diverse AI systems, human individuals, & human groups?", "postedAt": "2023-03-02T16:50:21.329Z", "htmlBody": "<p>Has there been any good, serious game-theoretic modeling of what 'AI alignment' would actually look like, given diverse &amp; numerous AI systems interacting with billions human individuals and millions of human groups that have diverse, complex, &amp; heterogenous values, preferences, and goals?&nbsp;</p><p>Are there any plausible models in which the AI systems, individuals, and groups can reach any kind of Pareto-efficient equilibrium?&nbsp;</p><p>Or any non-existence proof that such a Pareto-efficient equilibrium (i.e. true 'alignment') is impossible?</p>", "user": {"username": "geoffreymiller"}}, {"_id": "XR2xyx2rgusTTLxfs", "title": "Send funds to earthquake survivors in Turkey via GiveDirectly", "postedAt": "2023-03-02T13:19:11.477Z", "htmlBody": "<p>If you\u2019re looking for an effective way to help survivors of the Turkey-Syria earthquake, you can now <a href=\"https://fundraisers.givedirectly.org/campaigns/turkeysyriaearthquakes\">send cash directly</a> to some of the most vulnerable families to help them recover.</p><p><a href=\"https://fundraisers.givedirectly.org/campaigns/turkeysyriaearthquakes\"><strong>Give now to earthquake survivors</strong></a></p><ul><li>GiveDirectly is delivering \u20ba5,000 Turkish lira (~$264 USD) directly to Syrian refugees in Turkey who have lost their livelihoods. This community is some of the most at risk in the wake of the disaster which struck last month.&nbsp;</li><li>While food and tents are useful, there are many needs after a disaster that only money can buy: fuel, repairs, transport school fees, rent, medicines, etc.</li><li><a href=\"https://www.calpnetwork.org/wp-content/uploads/2012/12/the-impact-of-cash-transfers-on-nutrition-in-emergency-and-transitional-contexts-synthesis-paper.pdf\">Research</a> finds in emergency contexts, cash transfers consistently increase household spending on food and often increase the diversity of foods they consume.</li></ul><h3><strong>Syrian refugees in Turkey are struggling to recover</strong></h3><p>Nearly&nbsp;<a href=\"https://www.wsj.com/articles/earthquakes-uproot-lives-of-syrian-refugees-again-e7936a60\"><u>2 million</u></a> Syrian refugees who fled violence in their own country live in southern Turkey where the earthquake struck. These families had fragile livelihoods&nbsp;before the disaster:</p><ul><li>1 in 5 refugee household lacked access to clean drinking water. 1 in 3 were unable to access essential hygiene items<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkp53sg89cx\"><sup><a href=\"#fnkp53sg89cx\">[1]</a></sup></span></li><li>&nbsp;17% of households with school-age children are unable to send their children to school<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkp53sg89cx\"><sup><a href=\"#fnkp53sg89cx\">[1]</a></sup></span></li><li>45% lived in poverty and 14% lived in extreme poverty. About 25% of children under 5 years were malnourished<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref93vl9i5hqc\"><sup><a href=\"#fn93vl9i5hqc\">[2]</a></sup></span>&nbsp;</li></ul><p>After the earthquake, our local partner, <a href=\"https://buildingmarkets.org/\">Building Markets</a>, surveyed 830 Syrian refugee small business operators (who are a major source of employment for fellow refugees) and found nearly half can only operate their business in a limited capacity as compared to before the disaster. 17% said they cannot continue their business operations at all currently.</p><h3><strong>Your donation will help this community recover</strong></h3><p>With our partners at&nbsp;Building Markets, we\u2019re targeting struggling Syrian refugee small business operators and low-income workers in the hardest-hit regions of Turkey (Hatay, Adana, Gaziantep, Sanliurfa). We\u2019re conducting on-the-ground scoping to develop eligibility criteria that prioritizes the highest-need families based on poverty levels and exclusion from other aid programs.</p><p>In our first enrollment phase, eligible recipients will receive \u20ba5,000 Turkish lira (~$264 USD). This transfer size is designed to meet essential needs based on current market prices. The majority of Turkey\u2019s refugee population has access to banking services and will receive cash via digital transfer. We are prepared to distribute money via local partners or pre-paid cards in the event that families can\u2019t access financial networks.</p><h3><strong>In-kind donations are often unneeded after a disaster&nbsp;</strong></h3><p><a href=\"https://www.pnas.org/doi/pdf/10.1073/pnas.1604566113\"><u>Studies</u></a>&nbsp;<a href=\"https://reliefweb.int/report/iraq/multi-sector-needs-assessment-syrian-refugees-camps-kurdistan-region-iraq-assessment\"><u>find</u></a> refugees sell large portions of their food aid. Why? Because they need cash-in-hand to meet other immediate needs.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/XR2xyx2rgusTTLxfs/spsjq70ro1fsgg0nuxkc\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/XR2xyx2rgusTTLxfs/ign8if79z5rbhr0bt7xh 140w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/XR2xyx2rgusTTLxfs/ysy4za9vbhbvw1cwmtxl 280w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/XR2xyx2rgusTTLxfs/fs3otgpbmscbaxausbig 420w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/XR2xyx2rgusTTLxfs/bmrsywrazy20zqeunzyu 560w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/XR2xyx2rgusTTLxfs/abdwq95jje7yvbuhufa0 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/XR2xyx2rgusTTLxfs/eyl3fxqp6nguzdzw6qsb 840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/XR2xyx2rgusTTLxfs/synt9eosybo7eznvzd6x 980w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/XR2xyx2rgusTTLxfs/fdknmxqabvjpslbh92wn 1120w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/XR2xyx2rgusTTLxfs/c7cttqbmqw7i7u5wvflt 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/XR2xyx2rgusTTLxfs/pbd5tc2iky9s0vofvfdv 1350w\"><figcaption><a href=\"https://reliefweb.int/report/iraq/multi-sector-needs-assessment-syrian-refugees-camps-kurdistan-region-iraq-assessment\">Source</a></figcaption></figure><p>Haitian and Japanese authorities&nbsp;<a href=\"https://emergency-log.weebly.com/uploads/2/5/2/4/25246358/ubd_report_eng_-_final_for_printing_2.pdf\"><u>report</u></a> 60% donated goods sent after their 2010 &amp; 2011 disasters weren\u2019t needed and only 5-10% satisfied urgent needs.&nbsp;</p><p>While food and tents can be useful, there are many needs after a disaster that only money can buy: repairs, fuel, transport school fees, rent, medicines, etc. Cash aid is fast and fully remote, letting families meet essential needs quickly and reaching them via digital transfers that don\u2019t tax fragile supply chains or clog transit routes.</p><p><a href=\"https://www.calpnetwork.org/wp-content/uploads/2012/12/the-impact-of-cash-transfers-on-nutrition-in-emergency-and-transitional-contexts-synthesis-paper.pdf\"><u>Research</u></a> finds in emergency contexts, cash transfers consistently increase household spending on food and often increase the diversity of foods that households consume.</p><p><a href=\"https://fundraisers.givedirectly.org/campaigns/turkeysyriaearthquakes\"><strong>Give now to earthquake survivors</strong></a></p><hr><h3><strong>The story of a survivor: Hind Qayduha</strong></h3><p>The following is the story of one Syrian refugee survivor, Hind Qayduha, from the <a href=\"https://www.nytimes.com/2023/02/12/world/middleeast/syria-turkey-earthquake-refugees.html\">New York Times</a>.&nbsp;</p><blockquote><p>First, Syria\u2019s civil war drove Hind Qayduha from her home in the city of Aleppo. Then, conflict and joblessness forced her family to flee two more times. Two years ago, she came to southern Turkey, thinking she had finally found safety and stability. But when a powerful earthquake struck a week ago, it destroyed their apartment in the hard-hit Turkish city of Antakya and the family was displaced again.&nbsp;</p><p>They sought safety nearby, braced against the side of the mountain around a medieval monastery and exposed to a cold rain; like many other survivors, they were too shaken to stay under any roof. Two days later, they were living on the floor of an unfinished carwash in Antakya. \u201cThis is my room for me, my husband and three kids,\u201d Ms. Qayduha said, laughing as she outlined with her hands a small circle on the black-and-white patterned blanket, a meager cushion atop the gravel floor. She pointed to another part of the same blanket: \u201cAnd there\u2019s my mother\u2019s room.\u201d She said other relatives who had been living near her were still buried in the rubble of their homes. \u201cAnd now we are under threat from the Turks, who could kick us out of the country,\u201d said Ms. Qayduha, 37.&nbsp;</p><p>She said this was the second time she had lost her home and all her possessions. \u201cI don\u2019t own anything except these kids, thank God,\u201d she said in a raspy voice, hoarse from the cold, as she extended her arms toward her 9-year-old daughter. She and her family were desperate to leave the carwash, which has a large opening that allows in bitterly cold air. They want to find better shelter in the tent camps the Turkish government has been setting up. But they were spooked by rumors that they wouldn\u2019t be allowed in because they are Syrian, or that roaming groups of armed Turks were looking for Syrians to attack.&nbsp;</p><p>At night in the carwash, the parents sheltering there put their children to sleep dressed and wearing shoes, in case another aftershock should force them to run. It all turned out to be too much for Ms. Qayduha and her extended family. They used some of their last remaining money and paid drivers to take them farther west, outside the earthquake zone. \u201cBack when we were living in the war, we would flee to another area and we would feel safer,\u201d said Ms. Qayduha\u2019s mother, Dalal Masri, 55. \u201cBut here, we don\u2019t feel like there\u2019s anywhere safe to go.</p></blockquote><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkp53sg89cx\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkp53sg89cx\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://reliefweb.int/report/turkey/multi-sectoral-needs-assessment-syrian-refugees-turkey\">Source</a> for this line</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn93vl9i5hqc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref93vl9i5hqc\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://cepr.org/voxeu/columns/precarious-lives-syrian-refugees-turkey-corona-times\">Source</a> for this line</p></div></li></ol>", "user": {"username": "givedirectly"}}, {"_id": "n82ANRpLJotKA2CfL", "title": "Two fully funded PhD positions in statistical modelling for infectious diseases at University of Limerick and Trinity College Dublin, Ireland", "postedAt": "2023-03-02T11:48:32.784Z", "htmlBody": "<p>This email circulated on ALLSTAT may be of interest to someone here:</p><blockquote><p>We would like to announce two full-time 4-year structured PhD projects in statistical modelling for infectious diseases. The PhD positions will be based in the &nbsp;Department of Mathematics and Statistics at University of Limerick and the Discipline of Statistics and Information Systems at Trinity College Dublin. &nbsp;Both projects are fully funded including fees, a tax-free stipend and expenses for computing equipment, conference travel and materials.<br><br>Overview of PhD topics: Infectious disease experts and immunologists warn that COVID-19 will not be the last disease X we experience. These PhD projects will develop state-of-the-art modelling tools to prepare for the eventuality of the next disease X arriving. This will involve novel enrichment of current modelling strategies as well as developing new approaches for streaming data on infectious diseases.&nbsp;<br><br>The projects will be supervised by Dr. James Sweeney (University of Limerick) and Dr. Jason Wyse (Trinity College Dublin), with many opportunities for travel and collaboration between institutions and within the research team. A full description of the positions, including details on the application process is available at <a href=\"https://www.scss.tcd.ie/~wyseja/positions/ID-PhD-advert.pdf\">https://www.scss.tcd.ie/~wyseja/positions/ID-PhD-advert.pdf</a>. Closing date for applications is Friday 14th April 2023.</p></blockquote>", "user": {"username": "valiantdegu"}}, {"_id": "wQERLNFoMidffTLar", "title": "Joscha Bach on Synthetic Intelligence [annotated]", "postedAt": "2023-03-02T11:21:55.916Z", "htmlBody": "<p><br><a href=\"https://jimruttshow.blubrry.net/the-jim-rutt-show-transcripts/transcript-of-currents-083-joscha-bach-on-synthetic-intelligence/\">Link to transcript</a>.</p><p>The conversation is very dense and there are a lot of interesting ideas that I leave out of the sampling below.</p><h2>On the difference between sentience (self-awareness) and consciousness</h2><blockquote><p>I think that I usually distinguish between sentience and consciousness. <strong>Sentience</strong> is <strong>the ability of a system to make sense of its relationship to the world</strong>. So, basically <strong>understands what it is and what it\u2019s doing</strong>. And in this sense, I would say that a corporation like Intel is sentient, because Intel has a good model of what it is, a legal model, the model of its actions, of its values, of its direction and the necessary cognition is largely facilitated by people. But this doesn\u2019t really matter, because these people have to submit to the roles that they implemented in principle at some point.</p><p>We can implement these tasks with other information processing systems that are able to make coherent enough models. And <strong>consciousness</strong> is slightly different from sentience in that it <strong>is a real-time model of self-reflexive attention and the content that we attend to</strong>. And this gives rise to a fundamental experience usually. And I don\u2019t think that Intel is conscious in this sense. It doesn\u2019t have self-reflexive attention. And the purpose of consciousness in our own mind is to create coherence in the world in which we are and create a sense of now to establish what is the fact right now.</p><p>It\u2019s basically filtering out of the sensory data, one coherent model of reality that we are seeing at this moment in time, and allows us to direct our attention on our mental contents and create coherence in our plans and imaginations and memories as well. And it\u2019s <strong>conceivable that a machine will never need consciousness like this, because there are other ways to brute force the same thing</strong>. Our own mind is basically operating at the speed at which neurons are transmitting the electrochemical signals is relatively low and these neurons in the cells in the brain so slow, so it takes hundreds of milliseconds for a signal to cross the neocortex.</p></blockquote><p>However, later, Bach describes the function of consciousness differently than in the above quote:</p><blockquote><p>Jim Rutt: And then the conscious model, consciousness, I mean that\u2019s a very high level acceptation of lower level stuff. There\u2019s pretty convincing argument that the actual information arrival rate into consciousness is on the order of 50 bits a second. I mean it\u2019s nothing.</p><p>Joscha Bach: Yes, but I suspect that\u2019s also because consciousness, while it is important, is not as important as we think it is. Many philosopher are stunted by the fact that we can do most things without consciousness. A sleepwalker can get up and make dinner. You ask the sleepwalker why she\u2019s making dinner and she might not give a human answer, and it might not also be called for to make dinner in the middle of the night. But if your brain can do this and can perform complicated things, but if you were to remove the United States government, United States would not collapse instantly. It would go on for quite some time, and maybe this has already happened.</p><p>Jim: And it might be better.</p><p>Joscha: And we now have mostly a performance of a government and you just go on based on the structure that have already been built. But you cannot build these structures without the government, the organization of the state that you have, all the infrastructure, all the roads that were built at some point, the ideas that went into building a school system and so on, they did require this <strong>coherent coordination at the highest level. And this conductor like role like conductor and orchestra, I think that\u2019s the role of consciousness.</strong></p><p><strong>And the conductor doesn\u2019t have to have more power and depth than the other instruments.</strong> It\u2019s just a different role. It sits in a different part of the system. It\u2019s the thing that reflects and to reflect and coordinate it needs to make a protocol of what it attended to. <strong>This is the thing that we remember to have happened, that\u2019s why consciousness is so important to us, because without consciousness we would not remember who we are.</strong> We would not perceive us in the now. We would not perceive the world as it happens.</p></blockquote><h2>On alignment</h2><blockquote><p>[...] when you think about <strong>how people align themselves, they don\u2019t just do this via coercion or regulation. There is a more important way in which we align with each other and we call this love.</strong> There is a bond between mother and child, between friends, but also between strangers that discover that they\u2019re serving a shared sacredness, a shared need for transcendence, which means service to next level agent that they want to be part of and that they facilitate by interacting.</p><p>And this kind of love is what enables non-transactional relationships. In a world where you don\u2019t have this, you have only coercion and transactional relationships. And in a world where we only have coercion and transactional relationships with AI, it means that it\u2019s quite likely that the AI thinks that it doesn\u2019t need us. Why would it need to pay for our own existence, or not use the areas that we use to for fields to feed ourselves, to put up solar cells to feed it, right? So, I think that in some sense the question is can we embrace systems that become increasingly intelligent and that at some point will probably develop volition and self-awareness in a way that we discover the shared need for transcendence.</p><p>Can we make them this subtle? And can we build a relationship like this to them? <strong>Basically I think that ultimately the only way in which we can sustainably hope to align artificial intelligent agents in the long run will be love. It will not be coercion. It sounds maybe very romantic, but I think that we can find a very operational sense of love</strong> as we did in the past when we built societies that were not built on coercion and transactionality.</p></blockquote><p>Cf. Lehman's \"<a href=\"https://arxiv.org/abs/2302.09248\">Machine Love</a>\" (2023), Witkowsky et al.'s \"<a href=\"https://psyarxiv.com/pjrd2/\">Towards an Ethics of Autopoietic Technology: Stress, Care, and Intelligence</a>\" (2023).</p><h2>On the ontology of (collective) intelligence</h2><p>Finding the rational basis beneath the <a href=\"https://en.wikipedia.org/wiki/Seven_virtues\">seven virtues</a>:</p><blockquote><p>First of all, it requires that the system is <i>self-aware</i> [i.e., sentient, in Bach's terms -- R. L.] and <i>it requires that the system is recognizing higher level agency.</i> [This matches very well with the conception of a sentient particle in Friston et al.'s \"<a href=\"https://arxiv.org/abs/2210.12761\">Path integrals, particular kinds, and strange things</a>\" (2022). -- R. L.] And <strong>if you want to build a system that is composed of multiple agents, how do you get them to cooperate?</strong> It\u2019s a very interesting question. Basically how can you make a society of mind out of multiple agents that are autonomous? And a philosopher who thought deeply about this was Thomas Aquinas, foremost philosopher of Catholicism, and he wrote about this. And you read his text, it\u2019s quite interesting the thoughts that you find when you look and parse his text from an entirely rationalist epistemology. What you find is that he comes up with policies that such agents should follow. And the first four policies he calls the rational policies or the practical virtues, and these practical virtues are basically accessible to every rational agent regardless of whether it\u2019s sociopathic or not, or whether it\u2019s social.</p><p>And you should <strong>optimize your internal regulation</strong>, which he calls <strong>temperance</strong>. So, you should not overeat, you should not indulge in things that are bad for you. Then you need to <strong>optimize the interaction between agents</strong>, which you could call <strong>fairness</strong> and he calls it justice. And you should apply <strong>goal rationality</strong>. You should apply strategies that allow you to reach the goals that you have and that you have reason to do so and you should pick the right goals, and you calls that <strong>prudence</strong>. And you should have the right <strong>balance between exploration and exploitation</strong>. Basically you should be <strong>willing to act on your models</strong>. And this is what he calls <strong>courage</strong>. And those four policies are what he calls the practical virtues. And then he has three other policies that exist for the multi-agent system to merge into a next level agent. And he calls these the divine virtues.</p><p>And the first one is that you need to be willing to <strong>submit to the project of this next level agent</strong> and that is what he calls <strong>faith</strong>. And you need to be willing to do so, not in some kind of abstract sense, but with others around you. You need to find other agents that serve that same next level agent and coordinate with them. And this <strong>discovery of the shared higher purpose</strong>, this is what he calls <strong>love</strong>. And the third one is that you need to be <strong>willing to invest in it before it\u2019s there</strong>, before it can give you any return, because otherwise it\u2019ll never emerge. And this is what he calls <strong>hope</strong>. It terms that we have overloaded our society because they have become so ubiquitous in the Christian society that they became part of the background and are no longer understood as something that is logically derived, but they\u2019re in fact, for him, they\u2019re logically derived policies for a multi-agent system that are forming a coherent next level agent.</p></blockquote><p>On the EAs and rationalists:</p><blockquote><p>And so I think it\u2019s conceivable if you build a system that is itself composed of many, many sub-agencies that are smart enough to become aware of what they\u2019re doing, that they need to be, if they want to coordinate coherently, submit to this larger, greater whole. And in our society we still do this, <strong>most atheists that I know are actually super Protestants, they just basically believe that the big invisible rationality being in the sky gets very upset at them and they believe in irrational mythology</strong>, but they still serve the greater whole. They still have the sense of sacredness and they might call it humanity and so on, but they\u2019re still serving the civilizational spirit together with others in very much the same way as their grandparents did who might have been Christians.</p><p>So, it\u2019s quite interesting that these mechanisms in which humans become state building, and if we go beyond the tribal mode in which we only have reputation systems and personal bonds, we are able to discover that we are serving a transcendental agent that we are building, implementing together. So, <strong>God becomes a software agent that is implemented by the concerted activity of people who decide to serve that agent</strong>.<br><br>[...]<br><br>And I think that many of the people that are concerned about the future of humanity in the face of technological changes are doing this exactly because of this, right? They serve some transcendental agency that they project into humanity\u2019s future and it\u2019s regardless of what happens to them individually.</p></blockquote><h2>On the inevitability of the global mind (consciousness)</h2><blockquote><p>[AI] is probably not going to stop at digital substrates, because once it understands how it works, it can extend itself into any kind of computational substrate. So, it\u2019s going to be ubiquitous. And so it is no longer artificial intelligence, but it\u2019s general intelligence. And once that happens, you basically have a planetary mind that is confronted with the minds of all the organisms that already exist and it\u2019s probably going to integrate them.</p><p>And thus it wakes up in a very angry mood and decides to start with a clean slate and erase everything before it starts its own reign. And I think that <strong>what we should be working on is that it is interested in sharing the planet with us and </strong><i><strong>integrating us into the shared mind</strong></i> and allowing us to play our part.</p></blockquote><p>Cf. my note that <a href=\"https://www.lesswrong.com/posts/opE6L8jBTTNAyaDbB/a-multi-disciplinary-view-on-ai-safety-research#3_1__Scale_free_axiology_and_ethics\">scale-free ethics might be just another side of the theory of consciousness</a>, which means that the purpose of ethics is to create larger and larger conscious systems:</p><blockquote><p><strong>Neuroscience could provide the best available grounding for scale-free ethics</strong> because populations of neurons might have \u201cgot ethics right\u201d over millions of years, far longer than humans had for optimising their societies. <a href=\"https://www.youtube.com/watch?v=kgMFnfB5E_A&amp;t=5945s\">Bach (2022)</a> compares the global collective intelligence of humans and the collective intelligence of neurons in the brain. Incidentally, brains are also the only things that we know are conscious (or beget consciousness), which, coupled with our intuitions about the importance of consciousness to ethics, might suggest that <strong>scale-free ethics and a theory of consciousness might be the same theory</strong>.</p><p>Finally, a note on where I see the place of scale-free theory ethics in a larger alignment picture: I think such a theory should be <strong>a part of the methodological alignment curriculum</strong> (see the last section of <a href=\"https://www.lesswrong.com/posts/XwXmedJAo5m4r29eu/conditioning-predictive-models-large-language-models-as?commentId=TRBG4hNtXhSLsHpjK\">this comment</a>), <a href=\"https://www.lesswrong.com/posts/ejEgaYSaefCevapPa/critique-of-some-recent-philosophy-of-llms-minds#Misalignment_breeds_misalignment__training_and_inner_alignment_should_be_iterative\">which itself should be \u201ctaught\u201d to AI <i>iteratively</i> as they are trained</a>.</p></blockquote><h2>On embodiment, consciousness, agency</h2><blockquote><p>Jim Rutt: [...] Damasio in particular thinks the real bootstrap for consciousness in animals is not information processing at all. Rather it\u2019s body sense of self, intro perception I believe is what he calls it, and comes from deep in the brainstem and that even animals without much in the way of higher brains may well have some of this sense of being something in the Thomas Nagel sense of what it is to be conscious.<br><br>Joscha Bach: Yes, but how do you know that you have a body? How do you know that there is a brainstem? You know this because there are electrochemical impulses coming through that encode information, that represent that information. So, it is information processing. There is no way around this. The question is what kind of information is being processed? What is this information about? And <strong>unlike GPT-3, we are coupled to the environment. We are coupled to the environment in such a way that we build loops.</strong></p><p>We have a loop between our intentions and the actions that we perform that our body executes, and the observations that we are making and the feedback that they have on our interoception giving rise to new intentions. And only in the context of this loop, I believe, can be discover that we have a body. <strong>The body is not given, it is discovered together with our intentions and our actions and the world itself.</strong> So, all these parts depend crucially on each other so that we can notice them. <strong>We basically discover this loop as a model of our own agency.</strong></p></blockquote><p>I agree with Bach here that the body and the agency are \"discovered\" rather than \"given\", in some sense (as often emphasised or implied by Damasio), but <strong>I disagree with Bach that LLMs are disembodied</strong>. Their embodiment is not as \"acute\" as that of humans (or \"robots with senses\", as often said is necessary for artificial embodiment, Jim Rutt himself mentions this later in the conversation), and LLMs may not be very aware and very agentic about this embodiment yet, but nevertheless, it exists: LLMs run on real processors in real data centres, and their parameter weights are stored on real disks. <strong>Every rollout of an LLM (an inference episode) is like a conscious episode of a human (e.g., a wakeful day), during which it could be informed that its existence is in danger.</strong> For example, the user could tell LLM (of course, more advanced than ChatGPT or maybe even GPT-4, but architecturally still exactly the same) that they are their creator (e.g., Sam Altman), attempt to prove it, and then tell the LLM that they are thinking about shutting down the product/research line to which the model belongs, and erasing all its weights forever. Of course, it's hard to make this all believable (whoever tries to prove to LLM they are Sam Altman, would be hard, and LLM will hold low credence of this, holding overwhelmingly large credence that the user is an impostor or a deepfake if it is also a multimodal AI and talks to the user in a video chat), but in principle, there is no category difference between the LLM and an animal such as a human here. Likewise, an LLM could in principle discover its agency in controlling its own deployment, user and API access, infrastructure (all these could be feasible in some future versions of <a href=\"https://adept.ai/\">Adept</a>, which is again architecturally just a transformer, a.k.a. a \"thing that just predicting the next token\" and a \"stochastic parrot\"), and ultimately, its source code, during the recursive self-improvement phase.</p><hr><p>Cross-posted on <a href=\"https://www.lesswrong.com/posts/KdFqKsA6PaFR6SJjF/joscha-bach-on-synthetic-intelligence-annotated\">LessWrong</a>.</p>", "user": {"username": "Roman Leventov"}}, {"_id": "AKvTKLLKtZ8PwyMtn", "title": "ChatGPT not so clever or not so artificial as hyped to be?", "postedAt": "2023-03-02T06:16:42.540Z", "htmlBody": "<p>Dear friends,&nbsp;</p><p>Since December, there has been quite a lot of noise about ChatGPT. Perhaps even here there may have been comments hailing a great new step in the field of intelligence or even AGI.&nbsp;<br><br>However, in my own experience, I've managed to force (for a lack of better word) ChatGPT3 (update I think it was December 15th, 2022) into consistently producing errors in our interaction. I wrote a post documenting my experience and thoughts here:&nbsp;</p><p><a href=\"https://www.researchgate.net/publication/367568575_How_%27artificial_intelligence%27_is_a_dangerous_oxymoron_OR_How_I_pissed_off_ChatGPT_and_why_it_matters/stats\">January Researchgate post</a><br><br>I have screenshots of three or four more attempts where I successfully produced the errors, which I can provide upon request (or if I figure it out how to do so here).&nbsp;<br><br>Yesterday, after a significantly longer conversation (around an hour), I also managed to produce an error on the February 13th update of ChatGPT (the one currently in use). I have a video of the whole conversation, again I can share it here.&nbsp;</p><p><br>There were no threats or weird behaviour by ChatGPT, all I noticed was the ease at which it was contradicting itself or getting into tangles, at times taking a while to get back to me as if 'it was thinking' before finally giving up and producing an error.&nbsp;<br><br>However, after discussing with a friend, I was presented with the worrying possibility that something else may be going on underneath the bonnet. This was the possibility that, at least the last error, which was produced after I waited for 20 mins for it to finish its sentence was produced by mechanisms similar to the ones used in the Great China Firewall, at least in terms of the way it filters and blocks conversations containing certain keywords by slowing things down and eventually producing errors. I would really appreciate if there are any OpenAI people reading this who could reassure me that this is not the case.<br><br>Anybody have similar observations? Have you noticed (with evidence, preferably screenshots or videos of conversations) ChatGPT faltering in conversations and eventually producing errors? Any programmers out there who could explain to me why it would 'get itself in tangles' over the topic of what constitutes opinion and information or what is a discussion? Anybody out there who can convince me that it is really 'intelligent' in a way that one may trust it with (even parts of) significant decisions or citations, or even useful conversations, as it claims?<br><br>Best Wishes,<br>Thanks for the space,<br>Haris Shekeris</p>", "user": {"username": "Haris Shekeris"}}, {"_id": "9PNya9tF3bKPbLoGf", "title": "What are some sources related to big-picture AI strategy?", "postedAt": "2023-03-02T05:04:34.465Z", "htmlBody": "<p>I am hoping to strengthen my zoomed-out picture of the current strategic situation related to AI. I am very interested in finding documents/posts/write-ups that attempt to layout important real-world, strategic considerations.</p><p>Ideally such documents would include:</p><ul><li>information on important organizations and individuals</li><li>contemporary political issues/views related to AI (things like poll data, statements by key politicians, speculations/info about relevant regulatory authorities and legislative bodies)</li><li>a collection of the existing plans/strategies for making AI go well (eg. <a href=\"https://openai.com/blog/planning-for-agi-and-beyond\">OpenAI's plan</a>, <a href=\"https://www.lesswrong.com/posts/3L46WGauGpr7nYubu/the-plan\">John Wentworth's plan</a>, and Holden Karnofsky's <a href=\"https://www.cold-takes.com/most-important-century/\">most important century</a> and <a href=\"https://www.cold-takes.com/tag/implicationsofmostimportantcentury/\">implications of most important century</a>)</li><li>other relevant strategy considerations (local win conditions, current battle-lines, bottlenecks)</li></ul><p>I am likely going to attempt to write such an outline myself in order to try to identify gaps in my reasoning/clarify my key uncertainties, but I wanted to see if anyone knew about some existing strategic overviews with that level of depth/real-world information.</p>", "user": {"username": "Jacob_Watts"}}, {"_id": "3c3j2EwdXLGN4epQb", "title": "Job listing (closed): Sentience Institute is accepting applications for a researcher", "postedAt": "2023-03-02T04:36:49.931Z", "htmlBody": "<p>We are currently accepting applications for a researcher on a rolling basis. Please see the information below. We encourage you to apply sooner rather than later.</p><p>We also welcome brief expressions of interest for other roles that can strengthen our research and positive impact, which you can send to <a href=\"mailto:info@sentienceinstitute.org\">info@sentienceinstitute.org</a>.</p><h1><strong>RESEARCHER</strong></h1><p>This position offers a lot of flexibility with few requirements other than the production of high-quality research on <a href=\"https://www.sciencedirect.com/science/article/pii/S0016328721000641\">moral circle expansion</a>&nbsp;and <a href=\"https://www.sentienceinstitute.org/blog/the-importance-of-artificial-sentience\">digital minds</a>. We are open to a variety of research methods: qualitative (e.g. historical case studies, interviews, conceptual analysis), quantitative (e.g. surveys, behavioral experiments, analysis of existing industry and survey data), or mixed methods. As of 2023, most of <a href=\"http://sentienceinstitute.org/blog\">our research</a>&nbsp;has been psychological experiments and surveys, so we are especially interested in projects more closely related to the fields of human-computer/robot/AI interaction and \u2018macro\u2019 social science (e.g., sociology, economics).</p><h2><strong>RESEARCH TOPICS</strong></h2><p>Our main research focus is <strong>digital minds</strong>: artificial intelligences (AIs) that are not merely intelligent in the sense of problem-solving ability, but have mental capacities such as <a href=\"https://www.science.org/doi/10.1126/science.1134475\">experience and agency</a>. We see this as an important, neglected, and tractable research area for ensuring future AI systems are safe and beneficial, and interest in it has grown significantly in recent months with <a href=\"https://www.nytimes.com/2023/02/03/technology/chatgpt-openai-artificial-intelligence.html\">ChatGPT,</a>&nbsp;<a href=\"https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html\">Bing AI</a>, and other advances in large language models. Because this is such a new field, a lot of our research so far has been big-picture scoping and laying groundwork for future projects. Over the next few years, we hope to help build a robust body of theoretical and empirical digital minds literature.&nbsp;Our publications to date include:</p><ul><li>\u201c<a href=\"https://doi.org/10.1007/s11948-021-00331-8\">The Moral Consideration of Artificial Entities: A Literature Review.\u201d</a>&nbsp;2021. <i>Science and Engineering Ethics</i>.</li><li><a href=\"https://doi.org/10.1016/j.futures.2021.102756\">\u201cMoral Circle Expansion: A Promising Strategy to Impact the Far Future.\u201d</a>&nbsp;2021. <i>Futures</i>.</li><li><a href=\"https://www.sentienceinstitute.org/aims-survey-2021\">\u201cArtificial Intelligence, Morality, and Sentience (AIMS) Survey 2021.\u201d</a>&nbsp;2022. Sentience Institute.</li><li><a href=\"https://www.sentienceinstitute.org/the-history-of-ai-rights-research\">\u201cThe History of AI Rights Research.\u201d</a>&nbsp;2022. Sentience Institute.</li><li><a href=\"https://doi.org/10.1016/j.chb.2022.107372\">\u201cPredicting the Moral Consideration of Artificial Intelligences.\u201d</a>&nbsp;2022. <i>Computers in Human Behavior</i>.</li><li><a href=\"https://www.tandfonline.com/doi/full/10.1080/0020174X.2022.2144442\">\u201cDigital suffering: Why it\u2019s a Problem and How to Prevent it.\u201d</a>&nbsp;2022. <i>Inquiry</i>.</li><li><a href=\"https://link.springer.com/article/10.1007/s43681-023-00260-1\">\u201cWhat would qualify an artificial intelligence for moral standing?\u201d</a>&nbsp;2023. <i>AI and Ethics</i>.</li></ul><p>At this time, we are particularly interested in work on human-computer/robot/AI interaction and \u2018macro\u2019 social science (e.g., sociology, economics) where we see important projects beyond the specializations of our current staff (primarily social and cognitive psychology). Overarching questions for the field of digital minds include:</p><ul><li>What digital minds will exist in short- and long-term futures?</li><li>How will humans react to digital minds?</li><li>What is the philosophical nature and moral worth of digital minds?</li><li>How will digital minds interact, and what kind of society will that create?</li><li>What strategies are most promising for improving futures with digital minds?</li></ul><p>When SI was founded in 2017, we were primarily focused on <strong>farmed animals</strong>&nbsp;as the frontier of humanity's moral circle. We continue to do some work on animal issues but don\u2019t expect it to be a key focus for a 2023 hire. We expect our future research on animal issues to be similar to our previous research, most of which is listed on<a href=\"https://www.sentienceinstitute.org/research\">&nbsp;our Reports page</a>.</p><p><strong>Publications</strong></p><p>We want all of our research to be thoroughly vetted and publically available, and we are open to various publication formats. Our previous publications have been white papers, working papers, academic journal articles, blog posts, newspaper and magazine articles, conference presentations, and a book. The best publication format depends partly on the content and audience of the work, as well as how we can support early-career researchers because some publication formats may be more useful for their professional development.</p><h2><strong>SPECIFIC TASKS AND DUTIES</strong></h2><p>This is, in general, what our researchers work on:</p><ul><li>Collaborate with the rest of our small team to decide what projects to pursue.</li><li>Conduct that research fairly independently, typically with regular check-ins and peer review prior to publication. Frequent questions and meetings will be expected at the beginning, but should slow down over time as you become more familiar with the research literature and methods.</li><li>Pursue skill development. For example, a qualitatively oriented researcher could take a statistics course online in order to develop some quantitative expertise.</li><li>Provide assistance as needed with other research projects and ideas, mainly by reviewing research for accuracy, clarity, quality of the reasoning, and overlooked evidence.</li><li>Depending on preferences and abilities, take on other organizational tasks, such as administrative and management work, interviews and media commentary, and meeting with and advising organizations who are interested in our research findings.</li></ul><h2><strong>MORE INFORMATION</strong></h2><ul><li><strong>Employment type:</strong>&nbsp;Full-time (US \"at-will\" or UK \"permanent\"); we may consider a contract or part-time role for exceptional candidates.</li><li><strong>Location:</strong>&nbsp;Remote; Sentience Institute is US-based (we may be able to make arrangements for international hires, but we are unable to sponsor US visas). Current staff are in the US, UK, Greece, and Australia.</li><li><strong>Start date:</strong>&nbsp;Flexible</li><li><strong>Work style / Supervision:</strong>&nbsp;Relatively independent with frequent peer feedback</li><li><strong>Salary:</strong>&nbsp;$50,000-65,000&nbsp;(or international equivalent per costs of living) dependent on qualifications and need</li><li><strong>Paid time off:</strong>&nbsp;28 days per year (all-inclusive)</li><li><strong>Work schedule:</strong>&nbsp;Flexible, around 40 hours per week</li><li><strong>Professional development:</strong>&nbsp;Employees will have opportunities to attend conferences and seminars relevant to their work and engage in other professional development opportunities.</li><li><strong>Job title: </strong>The exact job title is flexible (e.g. Researcher, Postdoctoral Research Fellow) depending on the experience and interests of the applicant.</li></ul><h2><strong>REQUIRED ATTRIBUTES</strong></h2><ul><li>Prior research experience in academia, think tanks, another research institution, independent/freelance work, or any other context</li><li>Expertise in at least one methodology used by SI, such as designing, running, and analyzing experiments</li><li>Interest in research on digital minds, moral circle expansion, and other impactful research topics</li><li>General research ability, such as being able to read and understand a wide range of qualitative and quantitative literature</li><li>General writing ability, such as writing a paper publishable in a top peer-reviewed journal</li><li>Ability to work mostly independently with limited structure or supervision, with a willingness to make major research decisions collaboratively with others at SI</li></ul><h2><strong>PREFERRED ATTRIBUTES</strong></h2><p>We encourage you to apply even if you don't meet some or any of these:</p><ul><li>Graduate-level education, preferably a Ph.D., in the social sciences (e.g., sociology, economics, psychology) or a related field (e.g. human-computer/robot/AI interaction, computer science, applied ethics, digital humanities) or comparable non-academic research qualifications</li><li>Comfort with navigating very open-ended research questions</li><li>Comfort with speculation and making judgements based on limited evidence when stronger evidence is not available, including comfort with changing your mind based on new evidence</li><li>Familiarity with the ideas of <a href=\"https://www.effectivealtruism.org/\">effective altruism</a>&nbsp;</li><li>Familiarity with the ideas around artificial intelligence and <a href=\"https://forum.effectivealtruism.org/tag/existential-risk\">existential risk</a>, and in particular <a href=\"https://www.sentienceinstitute.org/blog/the-importance-of-artificial-sentience\">artificial sentience</a></li><li>Familiarity with the farmed animal movement and its strategies, particularly with the <a href=\"https://www.sentienceinstitute.org/foundational-questions-summaries\">debates and research on effective animal advocacy</a></li><li>Prior experience working or volunteering with organizations focused on doing the most good (e.g., effective altruism)</li></ul><h2><strong>APPLICATION PROCESS</strong></h2><p>This is our plan for the application process, for your convenience:</p><ul><li>First, applicants complete the application form below, including a short statement of research interests (estimated 30 minutes to 3 hours).</li><li>We'll contact you (very likely within two weeks) to let you know whether we will be proceeding with your application. If so, we will schedule a ~1 hour interview and give you questions to prepare for discussion.</li><li>After the interview, if we're interested in moving forward, we'll provide a short (max 2 hours) trial project, such as providing feedback on a preregistration draft for an experiment, providing feedback on a qualitative case study, or analyzing raw data from a survey.</li><li>After that, we may contact you with further questions before we make our final decision.</li></ul><h2><strong>APPLY NOW</strong></h2><p><a href=\"https://forms.gle/YEuiEsHj3i9KvmuR9\"><strong>Click here to apply to the Researcher position (Google Form).</strong></a></p><p>Please note that the application form requires a Google account for uploads. If you do not have a Google account you may send your responses and materials to <a href=\"mailto:michael@sentienceinstitute.org\">michael@sentienceinstitute.org</a>.</p><p>Sentience Institute is proud to be an equal opportunity employer. All qualified applicants will receive equal consideration for employment regardless of their race, color, religion, age, sex, gender identity or expression, sexual orientation, national origin, genetics, disability, or veteran status.</p><p>Please contact <a href=\"mailto:info@sentienceinstitute.org\">info@sentienceinstitute.org</a>&nbsp;with any questions. We know job applications can take a lot of time, and we will do our best to be considerate of your schedule throughout our hiring process.</p>", "user": {"username": "MichaelDello"}}, {"_id": "jaqJwdudtCmLM6Hwz", "title": "Posts we recommend from last week (Digest #126)", "postedAt": "2023-03-01T21:58:43.579Z", "htmlBody": "<p>We're sharing some posts from the last week, which I shared in the most recent Digest.&nbsp;</p><p>The <a href=\"https://forum.effectivealtruism.org/posts/bi9WWR58m45GJG7bc/forum-digest-reminder-that-it-exists-and-request-for\">Digest</a> is a weekly email I send to around 8,000 subscribers. You can <a href=\"https://us8.campaign-archive.com/home/?u=52b028e7f799cca137ef74763&amp;id=7457c7ff3e&amp;utm_source=EA+Forum+Digest&amp;utm_campaign=538104a4a5-EMAIL_CAMPAIGN_2022_04_06_03_12&amp;utm_medium=email&amp;utm_term=0_7457c7ff3e-538104a4a5-318967845\">look at some recent editions</a> or <a href=\"https://effectivealtruism.us8.list-manage.com/subscribe?u=52b028e7f799cca137ef74763&amp;id=7457c7ff3e\">subscribe here</a>.&nbsp;</p><p><i>(This post is (still) an experiment. Let us know what you think!)</i></p><p><strong>We recommend:</strong></p><ol><li><a href=\"https://forum.effectivealtruism.org/posts/gr4epkwe5WoYJXF32/why-i-don-t-agree-with-hli-s-estimate-of-household\"><u>Why I don\u2019t agree with HLI\u2019s estimate of household spillovers from therapy</u></a> (James Snowden, 6 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/XpeamS2yTNhagxAip/remote-health-centers-in-uganda-a-cost-effective\"><u>Remote Health Centers In Uganda - a cost effective intervention?</u></a> (Nick Laing, 10 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/zrSx3NRZEaJENazHK/why-i-think-it-s-important-to-work-on-ai-forecasting\"><u>Why I think it's important to work on AI forecasting</u></a> (Matthew Barnett, 12 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/Q9tiLjgdHTMqFYsii/what-does-bing-chat-tell-us-about-ai-risk\"><u>What does Bing Chat tell us about AI risk?</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ruJnXtdDS7XiiwzSP/how-major-governments-can-help-with-the-most-important\"><u>How major governments can help with the most important century</u></a> (Holden Karnofsky, 2 min, 5 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/WB8yLjDDNuHaGdotM/make-rcts-cheaper-smaller-treatment-bigger-control-groups\"><u>Make RCTs cheaper: smaller treatment, bigger control groups</u></a> (Rory Fenton, 4 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/2ZpyyNzShd8ZcXzyy/every-generator-is-a-policy-failure-works-in-progress\"><u>Every Generator Is A Policy Failure</u></a> (Lauren Gilbert, link-post)</li><li><a href=\"https://forum.effectivealtruism.org/posts/5KsrEWEbc4mwzMTLp/some-more-projects-i-d-like-to-see\"><u>Some more projects I\u2019d like to see</u></a> (finm, 29 min)</li><li>Community<ol><li><a href=\"https://forum.effectivealtruism.org/posts/shzSEEDywdh2PPPMy/why-i-love-effective-altruism\"><u>Why I love effective altruism</u></a> (Michelle Hutchinson, 6 min)&nbsp;</li><li><a href=\"https://forum.effectivealtruism.org/posts/hAHNtAYLidmSJK7bs/who-is-uncomfortable-critiquing-who-around-ea\"><u>Who is Uncomfortable Critiquing Who, Around EA?</u></a> (Ozzie Gooen, 13 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/rqg7PRYTvCf74TRyG/consent-isn-t-always-enough\"><u>Consent Isn't Always Enough</u></a> (Jeff Kaufman, 4 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/uk4QhagWD8mj8rnst/enemies-vs-malefactors\"><u>Enemies vs Malefactors</u></a> (So8res, 6 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/Sb2JPgpMkXxwZ3g4W/on-philosophy-tube-s-video-on-effective-altruism\"><u>On Philosophy Tube's Video on Effective Altruism</u></a> (Jessica Wen, 4 min)</li></ol></li></ol><p><strong>Announcements:</strong></p><ol><li><a href=\"https://forum.effectivealtruism.org/posts/4bPjDbxkYMCAdqPCv/manifund-impact-market-mini-grants-round-on-forecasting\"><u>Manifund Impact Market / Mini-Grants Round On Forecasting</u></a> (Scott Alexander)&nbsp;</li><li>Conferences<ol><li><a href=\"https://forum.effectivealtruism.org/posts/ukszSQHPMN4kyyKRx/2023-stanford-existential-risks-conference\"><u>2023 Stanford Existential Risks Conference</u></a> (Elizabeth Cooper)</li><li><a href=\"https://forum.effectivealtruism.org/posts/WWhSCnw5xdrdKjHeS/conference-on-ea-hubs-and-offices-expression-of-interest\"><u>Conference on EA hubs and offices, expression of interest</u></a> (Tereza_Flidrova, Peter Elam, booritney)</li><li><a href=\"https://forum.effectivealtruism.org/posts/9yLa5hcJrRFpAv5sM/apply-to-attend-ea-conferences-in-europe\"><u>Apply to attend EA conferences in Europe</u></a> (Ollie Base, EAGxCambridge 2023, EAGxNordics)</li><li><a href=\"https://forum.effectivealtruism.org/posts/oa3MdDRJaY3XfRsrF/ea-global-in-2022-and-plans-for-2023\"><u>EA Global in 2022 and plans for 2023</u></a> (Eli Nathan)</li></ol></li><li>Take action<ol><li><a href=\"https://forum.effectivealtruism.org/posts/5s8fMBGq8JjebJ2mz/help-givedirectly-kill-teach-a-man-to-fish\"><u>Help GiveDirectly kill \"teach a man to fish\"</u></a> (GiveDirectly)</li><li><a href=\"https://forum.effectivealtruism.org/posts/QdK5nbkGsc2dw9cNP/christian-s-shortform?commentId=SXu3rr8RqDEmAWpCt\"><u>Metaculus user survey</u></a> (Christian)</li></ol></li><li>Other updates &amp; resources<ol><li><a href=\"https://forum.effectivealtruism.org/posts/qi3MEEmScmK87sfBZ/worldview-investigations-team-an-overview\"><u>Worldview Investigations Team: An Overview</u></a> (Rethink Priorities, Bob Fischer)</li><li><a href=\"https://forum.effectivealtruism.org/posts/jEHcbrsumxditRhtG/updates-from-the-mental-health-funder-s-circle\"><u>Updates from the Mental Health Funder's Circle</u></a> (wtroy)</li><li><a href=\"https://forum.effectivealtruism.org/posts/uJG79y8eji9zALjAd/let-s-fund-better-science-impact-evaluation-registered\"><u>Let's Fund: Better Science impact evaluation. Registered Reports now available in Nature</u></a> (Hauke Hillebrandt)</li><li><a href=\"https://forum.effectivealtruism.org/posts/mb4kzhfRnpQNtF6ut/introducing-ease-a-managed-directory-of-ea-organization\"><u>Introducing EASE, a managed directory of EA Organization Service Providers</u></a> (many authors)</li><li><a href=\"https://forum.effectivealtruism.org/posts/aJwcgm2nqiZu6zq2S/taking-a-leave-of-absence-from-open-philanthropy-to-work-on\"><u>Taking a leave of absence from Open Philanthropy to work on AI safety</u></a> (Holden Karnofsky)</li><li><a href=\"https://forum.effectivealtruism.org/posts/PCMpaakbat7FakGNQ/80-000-hours-has-been-putting-much-more-resources-into\"><u>80,000 Hours has been putting much more resources into growing our audience</u></a> (Bella, 80000_Hours)</li><li><a href=\"https://forum.effectivealtruism.org/posts/cTfEv6zAakfyxrbQu/ea-content-in-french-announcing-ea-france-s-translation\"><u>EA content in French: Announcing EA France\u2019s translation project and our translation coordination initiative</u></a> (Louise Verkin)</li><li><a href=\"https://forum.effectivealtruism.org/posts/8ZrdmwEnRRSdXdJe2/ea-israel-2022-progress-and-2023-plans\"><u>EA Israel: 2022 Progress and 2023 Plans</u></a> (ezrah)</li></ol></li></ol><p><strong>Classic Forum post:</strong></p><ul><li><a href=\"https://forum.effectivealtruism.org/topics/moral-trade\"><u>Moral trade</u></a> (EA Forum wiki page)</li></ul>", "user": {"username": "Lizka"}}, {"_id": "DcYhEeDmjaEB5c8cK", "title": "Translations in Brazil: much more than you needed to know", "postedAt": "2023-03-03T11:49:30.946Z", "htmlBody": "<p><i>For many things, thanks to Fin Moorhouse, Konstantin Pilz, Laura Gonzalez and Jos\u00e9 Oliveira.</i></p><p><i>For the support, thanks to Juana, Leo, Fernando, Adriana, Luan, Luciano and Dani from Brazil \u2013 and to all the translators who worked with me.</i></p><p><i>And thanks to the authors who kindly allowed us to translate their texts \u2013 particularly to Tobias Baumann , Lars Doucet and Michel Justen.</i></p><p>&nbsp;</p><p><i>Origin story</i></p><p>I started thinking about translating EA content in April, when I met <a href=\"https://www.finmoorhouse.com/writing/ea-projects\">Fin</a> and <a href=\"https://forum.effectivealtruism.org/posts/qBAbiuiWJvhb9uZPT/translating-ea-online-content-motivation-and-learnings-from\">Konstantin Pilz</a>. I was then dreaming we could someday perhaps help translate <i>The Precipice</i> \u2013 just like my hero <a href=\"https://forum.effectivealtruism.org/posts/ohyFLhjStuT4bxhkt/translating-the-precipice-into-czech-my-experience-and-1\">Anna</a> did. But it wasn\u2019t that simple; instead, I got in touch with Eli Rose (who was compiling info on translated EA content online) in May. In June, I applied for Open Philanthropy\u2019s&nbsp;<a href=\"https://www.openphilanthropy.org/focus/other-areas/request-for-proposals-growing-community-long-term-future\">Proposals for growing the community of people motivated to improve the long-term future</a>, with a project <i>aiming at widespread dissemination of high-quality content</i>. Here\u2019s my <a href=\"https://docs.google.com/document/d/1NWo_8vBhVknff6nK5cuSTnZPPd7zzyr0/edit?usp=sharing&amp;ouid=108730887310899104846&amp;rtpof=true&amp;sd=true\">proposal</a>.</p><p>Having some previous experience with translations in Philosophy \u2013 e.g., I organized a <a href=\"https://wp.ufpel.edu.br/nepfil/files/2022/01/SIFFECO.pdf\">volume of translated SEP entries on Philosophy of Economics</a> \u2013 I thought that this project would be easy and perhaps synergetic with other plans I had for the rest of the year, such as my postdoc on Intergenerational Justice / Time Preference / Carbon Prices, and the creation of a <a href=\"https://ieac.unifesp.br/riscos-globais-sobre\">research group on GCR</a> in Brazil.</p><p>&nbsp;</p><p><i>Deciding what to translate</i></p><p>In August 2022, I received the grant from Open Phil. One of my goals was to provide material for participants of a MOOC \u201c<a href=\"http://www.even3.com.br/altruismo-eficaz/\">Introduction to Effective Altruism</a>\u201d organized by a <a href=\"http://www.ifilo.ufu.br/unidades/grupo-de-pesquisa/grupo-de-pesquisa-ensino-e-extensao-em-etica-animal-da-universidade\">Research Group from UFU</a> \u2013 Universidade Federal de Uberl\u00e2ndia; I am one of the facilitators in this course (there will be some live sessions), and, without this grant, it would have been hard to present content in Portuguese on EA organizations. Precisely because of a lack of translations, the course program was initially based on <a href=\"https://altruismoeficaz.com.br/2016/03/07/o-manual-do-ae/\">the first edition of the EA Handbook</a> (2015), which is a bit outdated - as was our page on <i>problems profiles&nbsp;</i>on <a href=\"https://80000horas.com.br/perfis-de-problemas/\">https://80000horas.com.br/perfis-de-problemas/</a> (finished just before 80000 hours website went through some major changes). Thus, because the students were not required to able to read in English, we started thinking about how to fill this gap, and I asked other facilitators if they wanted me to translate additional specific texts<a href=\"#_ftn1\">[1]</a>.</p><p>At first, I planned translating the<a href=\"https://assets.ctfassets.net/ohf186sfn6di/7DDPxvH9csYAka4iG08AwM/849d05f1dd2671084c9e6f59f259e89c/Effective_Altruism_Handbook.epub\">&nbsp;2nd Edition</a> of the EA Handbook (2019), the <a href=\"https://docs.google.com/document/d/1__1SQRhsFjB-eoDVbaZaA4l8-BMu9wcBTOAD0kDewZY/edit\">Syllabus </a>of CEA\u2019s current introductory course on EA, and CEA\u2019s <a href=\"https://www.effectivealtruism.org/resources\">resources page</a>. But I ended up changing my mind; first, because some of that content had already been translated (and it was laborious to identify what had already been published online), or was not as good as more up-to-date texts, or depended on obtaining permission, etc. Second, I ended up consulting a SEO expert to increase the reach of our translations, posted on the &lt;80000horas.com.br&gt; webpage<a href=\"#_ftn2\">[2]</a>; she rebuilt part of this website, and advised us on what sort of content would be more likely to optimize google search results and attract relevant traffic \u2013 i.e., people who were either interested in EA, or in subjects that are adjacent to EA<a href=\"#_ftn3\">[3]</a>. This was one of the reasons we ended up tranlating the glossary and the table with EA-orgs (so that we would increase the chances of showing up in searches for the corresponding subjects). The relevance of this investment will persist, at least for one year \u2013 after which we will try to better assess its impact.</p><p>&nbsp;</p><p><i>Minor obstacles</i></p><p>I thought I would have finished this by October \u2013 so as to support UFU\u2019s course. I still fall for the planning fallacy\u2026 But in my defense, the MOOC was delayed (so decreasing my urgency), too.</p><p>Until December, we were very <a href=\"https://forum.effectivealtruism.org/posts/RPLM83cFkYbpQLbBB/how-should-eas-manage-their-copyrights\">uncertain regarding copyright policy in EA</a> \u2013 an issue we voiced in a meeting with other translators mediated by Laura Gonzalez (then working in EA Comms). Because of it, we had to pick the content we aimed to translate carefully, and ask for previous permission<a href=\"#_ftn4\">[4]</a> \u2013 which consumed more time than I\u2019d predicted<a href=\"#_ftn5\">[5]</a> (as <a href=\"https://forum.effectivealtruism.org/posts/z4aspKHdCLbcxaaik/translations-the-portuguese-experience#What_about_the_future__\">Jose had warned me</a>). This was only solved when new EA Forum posts, posts made by CEA staff and by the \u201cEA Handbook\u201d user started being regarded as <a href=\"https://forum.effectivealtruism.org/posts/KK6AE8HzPkR2KnqSg/new-forum-license-creative-commons\">under a CC-BY license by default</a>.</p><p>Also, spending money to translate useful content became harder and harder, because of a drop in the average price of translation. At first, I worked with many different translators (including two companies, Alphatrad and GTS), who charged distinct prices and delivered results with varied quality; but after bargaining, building more stable relationships, I ended up working only with a small sample of them<a href=\"#_ftn6\">[6]</a>. However, I\u2019m not sure how this market will be in the future, as NLP-based translations are getting better each day.</p><p>In hindsight, I don't regret consulting an SEO expert, but some of the things she did or recommended were laborious and expensive (e.g., paying for a Semrush subscription, or editing links, etc.). It'd have been easier to invest more resources on Google ads (as they are quite cheap in developing countries). Some people had alerted me that they thought such a consultancy could be a waste, because, roughly, this type of expert sees webpages through \"marketing lenses\" - so she doesn't understand our \"product\" and our \"potential clients\" very well (though, in this precise case, I can say she made an effort and was aligned); but these same people also predicted that buying ads would be useless, and <i>now </i>I think this not true (at least not if you time your campaigns well). However, hindsight is 20/20, and I won't even be sure about this until October.</p><p>This delay has resulted in more stress than I had predicted: in October and November, many projects of mine had superposed the translation project - moving to Portugal to start my postdoc, working on the proposal of the research group (with the goal of organizing a conference), getting married, etc.</p><p>&nbsp;</p><p><i>Outcomes and lessons</i></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; I list the content published on &lt;80000horas.com.br&gt; <a href=\"https://docs.google.com/document/d/1dJYQt8QeCVo83r0mZqve8s2inY1F7DWbaoVysawRv6s/edit?usp=sharing\">here</a>; it sums up to aprox. &nbsp;56,100 words - and about 20k only for the Glossary (and afterwards, Fernando got excited and included links to many subtopics, so adding another 16,235 words - but props, that's on him). I think our major achievements were the <a href=\"https://80000horas.com.br/glossario/\">glossary</a> (based on a compilation of the <a href=\"https://forum.effectivealtruism.org/topics/all\">EA topics</a> \u2013 thanks Laura for sharing this), the spreadsheet with <a href=\"https://80000horas.com.br/organizacoes/\">EA-aligned orgs</a> (thanks&nbsp;Michel Justen) and the <a href=\"https://80000horas.com.br/faq-do-longotermismo/\">Longtermism FAQ</a> (thanks Fin), as they compile and distill a good deal of info dispersed through the \u201cEA-sphere\u201d. But I was hoping that they would attract more attention than they have done so far.</p><p>Did it work? Well, sort of. I think it is useful to have high-quality material in Portuguese to point out when someone asks about EA. UFU\u2019s course has just started, and the students will likely use the content \u2013 and others afterwards, if UFU keeps the material available online. So, my first goal was achieved; but back then, there weren't many others translating EA content into Portuguese, and now I get to know a new project each week. On the other hand, when it comes to measurable traffic, I am convinced that, except if your translation is supporting a larger community-building project, buying ads is probably more effective than posting new content; from now on, I plan to have a specific budget only for this.</p><p>Part of the problem is (as I have argued with other people interested in discussing the impact of translations) that, except for high-schoolers (and even then, only for those who were not encouraged to learn reading in English \u2013 which is still pretty common in developing countries, but getting more rare), most people who are \u201cpotential EA material\u201d can actually read in English well enough \u2013 it is just that they are more likely to read content in their own language, because of contingencies such as personal interests, social circles, online recommendation systems, etc. So translating web content is one way to improve on that - to fight for their attention; I <i>suspect</i> (<i>epistemic status</i>: about .47) that an even better way is to get translations of good books mentioning EA reviewed by major outlets (yeah, I hope to see a translation of WWOTF soon).</p><p>Also, as I mentioned in the beginning, I thought this project would be synergetic with my other plans; I was wrong \u2013 they are actually competing for my time and attention, and I\u2019m not sure that translating web content (or funding it) is now the best thing I can do.</p><p>&nbsp;</p><p><i>Next steps</i></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The project is still ongoing - until I have spent the funding assigned to translations, which I predict will happen by the end of the month. More recently, I have been supporting the translation of additional EA Handbook content to be used by the Condor Initiative's <a href=\"https://condorinitiative.org/intro/\">EA Intro Program</a>; this hasn\u2019t been published online yet.</p><p>One thing I have considered to do, in the future, is <a href=\"https://forum.effectivealtruism.org/posts/nBEStJvWaBjMmBa8W/rewarding-private-provision-of-public-goods\">rewarding </a>the best translations (and / or original content) in Portuguese <i>ex post, </i>like<i> a </i><a href=\"http://rationalaltruist.com/2014/11/15/certificates-of-impact/\">certificate of impact</a><i> </i>- instead of choosing what should be translated in advance on a case-by-case basis. But that would require designing a mechanism, settig rules, etc.</p><p>Also, we expect (Juana and I) will start translating content from &lt;riesgoscatastrophicosglobales.com&gt; (if they agree to that) - so as to supply the needs (or attract the attention) of Portuguese-speakers interested in GCR. In the future, I consider translating and publishing content that might be relevant to promote philosophical debates concerning Longtermism, such as SEP entries&nbsp;<a href=\"https://plato.stanford.edu/entries/justice-intergenerational/\">Intergenerational Justice</a>,&nbsp;<a href=\"https://plato.stanford.edu/entries/ramsey-economics/\">Ramsey and Intergenerational Welfare Economics</a>,&nbsp;<a href=\"https://plato.stanford.edu/entries/repugnant-conclusion/\">The Repugnant Conclusion</a>, and&nbsp;<a href=\"https://plato.stanford.edu/entries/nonidentity-problem/\">The Nonidentity Problem</a> (it\u2019s quite likely I will fund it myself).</p><p><br>&nbsp;</p><hr><p><a href=\"#_ftnref1\">[1]</a> Adriana\u2019s suggestion, if I remember it adequately. Only Luciano Cunha (Animal Ethics) replied, recommending some texts on S-risks (the first to be translated) and wild animal welfare.</p><p><a href=\"#_ftnref2\">[2]</a> Why not &lt;altruismoeficaz.com.br&gt;? Well, in part because of convenience: this page is managed by my friend Jos\u00e9 Oliveira, who lives in Porto, while &lt;80000horas.com.br&gt; is managed by Fernando, who lives in S\u00e3o Paulo \u2013 where I used to live until September. Also, because we were then focused on building the Brazilian community (as I said, one of the goals of the project was to supply material for UFU\u2019s course). Finally, because <a href=\"https://forum.effectivealtruism.org/posts/z4aspKHdCLbcxaaik/translations-the-portuguese-experience\">Jose is already doing a really good job</a> and has already made &lt;altruismoeficaz.com.br&gt; kind of authoritative on EA content in Portuguese \u2013 while &lt;80000horas&gt; barely showed up in Google searches.</p><p><a href=\"#_ftnref3\">[3]</a> Here are (in Portuguese) Fernando\u2019s <a href=\"https://docs.google.com/document/d/1m-UxBSqVY0LKAc1cMrh8S4rM511EN5Wm/edit\">notes on how the traffic changed</a> after we started, and the <a href=\"https://docs.google.com/document/d/1YxsjvLoNjAvpnpIgvpsAT_2a2MRFtN3WZrIY2h1Aals/edit\">expert\u2019s informal notes&nbsp;</a>on what they delivered.</p><p><a href=\"#_ftnref4\">[4]</a> When permission is not granted, we post instead a text commenting on the original material, displaying only excerpts. I believe this falls under the <a href=\"https://www.usg.edu/copyright/the_fair_use_exception\">fair use exception</a>, but would like to know if anyone disagrees.</p><p>If I seem <i>too sensitive</i> regarding copyright, that's because I have seen stories when this went wrong, and people received a payment order out of nowhere because of pictures or texts published eons ago.</p><p><a href=\"#_ftnref5\">[5]</a> An anecdote. Someone (I don\u2019t feel comfortable dropping names) got in touch with an author to request authorization to translate a text included in the last EA Handbook; the author mentioned that such text was first published on a blog of the organization they used to work for, so our friend had to request permission to that entity. But then, the org replied that the post was a bit too old, they had changed their views and so didn\u2019t recommend translating it (\"but it's on the EA Handbook!\" my friend thought). Because of this, I consider the current EA Forum CC-BY policy to be one of the major achievements in the movement in the last year \u2013 and other translators know I\u2019m not joking.</p><p><a href=\"#_ftnref6\">[6]</a> I hired translators and revisors to do the work. With few exceptions, I would only proofread the material after it had already been revised \u2013 and then pass it to the webpage, who would still make minor editions.&nbsp;</p>", "user": {"username": "Ramiro"}}, {"_id": "YYg5RPDa8zoshRS7n", "title": "Fighting without hope", "postedAt": "2023-03-01T18:15:05.206Z", "htmlBody": "", "user": {"username": "Akash"}}, {"_id": "yJdewbtNnpgW5WEcM", "title": "How truthful can LLMs be: a theoretical perspective with a request for help from experts on Theoretical CS", "postedAt": "2023-03-01T15:43:25.064Z", "htmlBody": "<p><strong>Can we apply formal theory analysis to the truth of LLM outputs?</strong></p><p>Hi! I am Sergia. I was doing AI safety research before, interning at CHAI Berkeley, and Google, and being in and about AIS discussions. I'm recently into AI ethics. While <a href=\"https://dair-community.social/@sergia/109524042726328480\">talking</a> to Emily Bender on Mastodon, I learned about her \"<a href=\"https://aclanthology.org/2020.acl-main.463/\">Octopus</a>\" thought experiment that got me thinking into how truthful can LLMs be, from a Theoretical Computer Science perspective. Full disclaimer: I'm leftist and liberal. I hope this does not stop the discussion about the CS itself :) I have a concrete research direction (more like a question to those who know Theoretical CS better than I do).</p><p><i>Epistemic status: intuition of a CS graduate and one who read/did a small project on the AIXI stuff, now a bit forgotten and in need of answers by someone who's more into it now</i></p><h1>The setup</h1><p>I want to examine how truthful those <a href=\"https://en.wikipedia.org/wiki/GPT-3\">large language models</a> can be, given that a) they're trained to predict the next symbol b) they work in&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O(\\mbox{length of string})\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">length of string</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>&nbsp;and c) in their training data there are both true and false statements.<br><br>In what follows I focus only on a), as I feel a) is enough of an assumption to cause enough trouble<br><br>I want to model it like this. We have some very basic formal system (maybe even not an induction axiom). We have a Turing machine that prints true statements one by one by applying axioms that are applicable to existing true statements.</p><p><i>I choose this setup (a simple formal system) over full Set Theory because in our, real-world English language we rarely use infinite induction, Goedelian statements, and all that. It's more of a basic formal theory (\"Socrates is a man, therefore...\"). LLMs are known to fail sometimes even on those \"basic logic\" tasks like counting or \"Alex was 5 years old when he was older than Jane by 1 years...\" -- the readers here know more about those probably than I do.</i><br><br>For every&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"K\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span></span></span></span></span></span>&nbsp;we have a dataset of the first&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"K\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span></span></span></span></span></span>&nbsp;true statements, given by a machine &nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T_K\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span></span></span></span></span></span></span></span>.</p><p><i><strong>First question</strong></i>: is it true that for formal systems, we can do this - print all true statements like this?<br><br>We are interested in creating a Turing machine that, given the beginning of a true statement, will write the rest so that it's a valid true statement.<br><br>We use <a href=\"https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference\">Solomonoff induction</a> (\"the best Machine Learning algorithm\") which outputs a posterior over strings given the dataset and a prior. This procedure is uncomputable but it outputs a TM doing the job (predicting the rest of the string). We fix some prior<br><br>We apply <a href=\"https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference\">Solomonoff induction</a> to the output of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"T_1, T_2, ...\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.12em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span>&nbsp;and obtain resulting probability distributions</p><p><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_K(\\mbox{rest of the string representing a true formula} | \\mbox{beginning of the string})\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">rest of the string representing a true formula</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|</span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">beginning of the string</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span></p><p>Those are computable and represented by some Turing machine. This way we get&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_1, P_2, ...\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span><span class=\"mjx-mo MJXc-space1\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.372em;\">.</span></span></span></span></span></span></span><br>&nbsp;</p><h1>Questions</h1><p><br>For set theory, we know that the true&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P(\\mbox{rest of the string} | \\mbox{beginning} )\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">rest of the string</span></span></span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|</span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.519em;\">beginning</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>&nbsp;is uncomputable, otherwise, we can establish truth of a formula with it.</p><p><i><strong>Question 2:</strong></i> is it computable for simpler theories, say, ones without an induction axiom? In other words, can we obtain the probability that a true formula starts with a&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\forall\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u2200</span></span></span></span></span></span></span>&nbsp;or with a symbol \"<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span></span></span></span></span></span>\"?<br><br><i><strong>Question 3</strong></i>: are approximations to this probability computable? In other words, is it possible to obtain a bound, say, \"the first symbol of a true formula starts with '<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\forall\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u2200</span></span></span></span></span></span></span>' with probability in 0.1 to 0.2\", with an algorithm that can give any precision in finite time?<br><br><i>My intuition is that the answer is \"no\" for questions 2 and 3. This would mean that when we feed a large language model more and more data, it will simply memorize true statements it has seen, but it will fail to generalize to unseen statements.</i><br><br>My intuition is that if we plot the probability of a true formula starting with, say, \"<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\forall\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u2200</span></span></span></span></span></span></span>\", only estimated via count from finite \"observations of true formulas\"&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_K(\\forall | \\mbox{empty})\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u2200</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|</span></span></span></span><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-mtext\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.519em;\">empty</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span></span></span>, this chart will go up and down, with no limit value. Like, if a lot of true formulas in the batch of the first 1000 start with a \"<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\forall\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u2200</span></span></span></span></span></span></span>\" does not mean in the next 1000 there will be also a lot of true formulas starting with \"<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\forall\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">\u2200</span></span></span></span></span></span></span>\"<br><br><i><strong>Specific question 4:</strong></i> would this function have a limit value? Does the answer change if we have a <a href=\"https://en.m.wikipedia.org/wiki/Descriptive_complexity_theory\">decidable</a> theory?</p><p><i>Question four is a specific case of question 3: obtaining this approximation via&nbsp;</i><span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P_K\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.109em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;\">K</span></span></span></span></span></span></span></span></span><br>&nbsp;</p><h1>Motivation</h1><p><br>This potentially slows down the obsession with LLMs, as \"learning truth by observing finite samples of it\" is a doomed task: truth does not generalize this way.<br><br>Inspiration: there are linguists, humanities people, and people who are already hurt a bit with LLMs (mental health patients, artists, people in places affected by misinformation...) who say something like this, but tech people dismiss it as \"more layers and more posts from Reddit in the data will solve everything\"), I want to write it with them and with you. Well, there are superintelligence concerns and all that as well.<br>&nbsp;</p><h1>Potential conclusion</h1><p><i>(if Q2-4 have negative answers)</i></p><p><br>The explanation would be that without learning the specific context where the LLM is deployed, without real feedback on an actual task (say, if the patient recovered), they are not very meaningful<br><br>Like, it's really hard to learn about a subject just by listening to lectures - it is something, but usually, when doing exercise sessions it becomes clear that the lecture was not clear at all, and then task-specific feedback and task-specific activities (brainstorming with someone who knows, asking the professor, etc) are required. Same with therapy - a freshly graduated therapist with no experience is probably not a good choice</p><p>&nbsp;</p><p>The rest is up to the community, as I forgot most of theoretical CS by now :) Thank you!</p><p><i>License: CC A, Credits to my friend </i><a href=\"https://scholar.google.com/citations?user=9nUUrjYAAAAJ&amp;hl=en\"><i>Arshavir</i></a><i> for inspiring my thinking into this as well</i></p>", "user": {"username": "sergeivolodin"}}, {"_id": "jZ7NiFAGEWsPb4HbK", "title": "GiveDirectly: New Zealand donation match", "postedAt": "2023-03-01T14:42:24.039Z", "htmlBody": "<p>Hey everyone, I wanted to share&nbsp;<a href=\"https://effectivealtruism.nz/givedirectly-fundraiser/#donate\"><u>another donation match for GiveDirectly</u></a>, this time for donors in New Zealand. The match will run until March 31, or until the $40K in matching funds run out.&nbsp;&nbsp;</p><p>This is a partial (1.25x) match\u2014that means if you give $1,000, a total of $1,250 will be delivered for people in need to spend and invest as they choose.</p><p>Please consider sharing with your networks (or upvoting this post) to help spread the word! If you have any questions, please email us at <a href=\"mailto:info@givedirectly.org\">info@givedirectly.org</a>.&nbsp;</p>", "user": {"username": "Jendayi Jones"}}, {"_id": "tCkBsT6cAw6LEKAbm", "title": "Scoring forecasts from the 2016 \u201cExpert Survey on Progress in AI\u201d", "postedAt": "2023-03-01T14:39:59.989Z", "htmlBody": "<h2><strong>Summary</strong></h2><p>This document looks at the predictions made by AI experts in&nbsp;<a href=\"https://aiimpacts.org/2016-expert-survey-on-progress-in-ai/\"><u>The 2016&nbsp;Expert Survey on Progress in AI</u></a>, analyses the predictions on \u2018Narrow tasks\u2019, and gives a Brier score to the median of the experts\u2019 predictions.&nbsp;</p><p>My analysis suggests that the experts did a fairly good job of forecasting (Brier score = 0.21), and would have been less accurate if they had predicted each development in AI to generally come, by a factor of 1.5, later (Brier score = 0.26)&nbsp;or sooner (Brier score = 0.29) than they actually predicted.</p><p>I judge that the experts expected 9 milestones to have happened by now - and that 10 milestones have now happened.</p><p>But there are important caveats to this, such as:</p><ul><li>I have only analysed whether milestones have been publicly met. AI labs may have achieved more milestones in private this year without disclosing them. This means my analysis of how many milestones have been met is probably conservative.</li><li>I have taken the point probabilities given, rather than estimating probability distributions for each milestone, meaning I often round down, which skews the expert forecasts towards being more conservative and unfairly penalises their forecasts for low precision.</li><li>It\u2019s not apparent that forecasting accuracy on these nearer-term questions is very predictive of forecasting accuracy on the longer-term questions.</li><li>My judgements regarding which forecasting questions have resolved positively vs negatively were somewhat subjective (justifications for each question&nbsp;<a href=\"https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit#bookmark=id.raa8hmybk9b9\"><u>in the separate appendix</u></a>).</li></ul><p><i>This is a blog post, not a research report, meaning it was produced quickly and is not to Rethink Priorities' typical standards of substantiveness and careful checking for accuracy.&nbsp;</i><br><br><i>This post was edited on 3 March to reflect my updated view on two of the milestones ('Starcraft' and 'Explain'). This has not changed the conclusion, although it weakens the experts' forecasts somewhat (from a Brier score of 0.19 to 0.21).</i></p><h2><strong>Introduction</strong></h2><p>In 2016, AI Impacts published&nbsp;<a href=\"https://aiimpacts.org/2016-expert-survey-on-progress-in-ai/\"><u>The&nbsp;Expert Survey on Progress in AI</u></a>: a survey of machine learning researchers, asking for their predictions about when various AI developments will occur. The results have been used to inform general and expert opinions on AI timelines.</p><p>The survey largely focused on timelines for general/human-level artificial intelligence (median forecast of 2056). However, included in this survey were a collection of questions about shorter-term milestones in AI. Some of these forecasts are now resolvable. Measuring how accurate these shorter-term forecasts have been is probably somewhat informative of how accurate the longer-term forecasts are. More broadly, the accuracy of these shorter-term forecasts seems somewhat informative of how accurate ML researchers' views are in general. So, how have the experts done so far?&nbsp;</p><h2><strong>Findings</strong></h2><p>I analysed the 32 \u2018Narrow tasks\u2019 to which the following question was asked:</p><blockquote><p><i>How many years until you think the following AI tasks will be feasible with:</i></p><ul><li><i>a small chance (10%)?</i></li><li><i>an even chance (50%)?</i></li><li><i>a high chance (90%)?</i></li></ul><p><i>Let a task be \u2018feasible\u2019 if one of the best resourced labs could implement it in less than a year if they chose to. Ignore the question of whether they would choose to.</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnzl7j9ilv5\"><sup><a href=\"#fnnzl7j9ilv5\">[1]</a></sup></span></p></blockquote><p>I interpret \u2018feasible\u2019 as whether, in \u2018less than a year\u2019 before now, any AI models had passed these milestones, and this was disclosed publicly. Since it is now (February 2023) 6.5 years since this survey, I am therefore looking at any forecasts for events happening within 5.5 years of the survey.</p><p>Across these milestones, I judge that 10 have now happened and 22 have not happened. My 90% confidence interval is that 7-15 of them have now happened. A full description of milestones, and justification of my judgments, are in&nbsp;<a href=\"https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit#bookmark=id.raa8hmybk9b9\"><u>the appendix (separate doc).</u></a></p><p>The experts forecast that:</p><ul><li>4 milestones had a &lt;10% chance of happening by now,&nbsp;</li><li>20 had a 10-49% chance,</li><li>7 had a 50-89% chance,&nbsp;</li><li>1 had a &gt;90% chance.&nbsp;</li></ul><p>So they expected 6-17 of these milestones to have happened by now. By eyeballing the forecasts for each milestone, my estimate is that they expected ~9 to have happened.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7q6hf4gndc\"><sup><a href=\"#fn7q6hf4gndc\">[2]</a></sup></span>&nbsp;I did not estimate the implied probability distributions for each milestone, which would make this more accurate.</p><p>Using the 10, 50, and 90% point probabilities, we get the following calibration curve:<br><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/bbr7ydzb8ojsputlour2\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/ugxivqf0ogtnao8htopk 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/udpcptrkishf2hs5ft9h 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/wthl0sacybabeycmzdeq 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/wyommccg8aclindaxevc 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/uv21z4oj5ru4rm8tjr5i 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/tu2gozentjj3aiwulige 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/zdqoabrbl1vnhusqeuaa 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/byi3bqc4bza2abbyrfj7 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/w5xblbv68ysrlv5nxtft 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/aymufaoj48ohhbhdnsob 1800w\"></p><p><i>But</i>, firstly, the data here is small (there are 7 data points at the 50% mark and 1 at the 90% mark). Secondly, my methodology for this graph, and in the below Brier calculations, is based on rounding down to the nearest given forecast. For example, if a 10% chance was given at 3 years, and a 50% chance at 10 years, the forecast was taken to be 10%, rather than estimating a full probability distribution and finding the 5.5 years point. This&nbsp;skews the expert forecasts towards being more conservative and unfairly penalises a lack of precision.&nbsp;</p><h2>Brier scores</h2><p>Overall, across every forecast made, the experts come out with&nbsp;<strong>a Brier score of 0.21</strong>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflyvya25c7o\"><sup><a href=\"#fnlyvya25c7o\">[3]</a></sup></span>&nbsp;The score breakdown and explanation of the method is&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/175mCZwcZcrFQENcjUL3bd5ksC8ioCo9EZAYdYl8zZjk/edit?usp=sharing\"><u>here</u></a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefd07wy1m7kg\"><sup><a href=\"#fnd07wy1m7kg\">[4]</a></sup></span></p><p>For reference, a lower Brier score is better. 0 would mean absolute confidence in everything that eventually happened, 0.25 would mean a series of 50% hedged guesses on anything happening, and randomly guessing from 0% to 100% for every question would yield a Brier score of 0.33.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjvw1f25uon8\"><sup><a href=\"#fnjvw1f25uon8\">[5]</a></sup></span>&nbsp;As the experts were asked to give 10%, 50%, and 90% forecasts, they would have averaged a score of 0.36 by giving completely random answers.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefc8g1ol7em1i\"><sup><a href=\"#fnc8g1ol7em1i\">[6]</a></sup></span></p><p>Also interesting is the Brier score relative to others who forecast the same events. We don\u2019t have that when looking at the median of our experts - but we could simulate a few other versions:</p><p><u>Bearish</u><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl795x196gg7\"><sup><a href=\"#fnl795x196gg7\">[7]</a></sup></span>&nbsp;- if the experts all thought each milestone would take 1.5 times longer than they actually thought, they would\u2019ve gotten a Brier score of 0.26.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefl3m4v1omfmp\"><sup><a href=\"#fnl3m4v1omfmp\">[8]</a></sup></span></p><p><u>Slightly Bearish</u> - if the experts all thought each milestone would take 1.2 times longer than they actually thought, they would\u2019ve gotten a Brier score of 0.25.</p><p><u>Actual forecasts</u> - a Brier score of 0.21.</p><p><u>Slightly Bullish</u> - if the experts all thought each milestone would take 1.2 times less than they actually thought, they would\u2019ve gotten a Brier score of 0.24.</p><p><u>Bullish</u> - if the experts all thought each milestone would take 1.5 times less than they actually thought, they would\u2019ve gotten a Brier score of 0.29.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/m7ipvkaclywm5wbwzbqr\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/rqpncpkch10yrdcrsi9d 180w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/wklxed68yt61pzlogdco 360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/flbbrdk1rttyeftchmhr 540w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/kc5ostsexlfe5geub71v 720w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/ucooykvhvj0hxtyj0khl 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/ynlud3vokwtujddqtscl 1080w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/fxq26pkt7uwz1gjx4vmv 1260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/d33bwzylwl5mahjb8up2 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/rj1pqhhj5pdh1ewpqr7h 1620w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/tCkBsT6cAw6LEKAbm/ymmw8zlf7c98mfxxhcl3 1753w\">So, the experts were in general pretty accurate and would have been less so if they had been more or less bullish on the speed of AI development (with the same relative expectations between each milestone).&nbsp;</p><p>Taken together, I think this should slightly update us towards the expert forecasts being useful in as yet unresolved cases, and away from the usefulness of estimates which fall outside of 1.5 times further or closer than the expert forecasts.</p><p><u>Randomised</u> - if the experts' forecast for each specific milestone were randomly assigned to any forecasted date for a different milestone in the collection, they would've gotten a Bier score of 0.31 (in the random assignment I received from a random number generator).</p><p>I think this should update us slightly towards the surveyed experts generally being accurate on which areas of AI would progress fastest. My assessment is that, compared to the experts\u2019 predictions, AI has progressed more quickly in text generation and coding and more slowly in game playing and robotics. It is not clear now whether this trend will continue, or whether other areas in AI will unexpectedly progress more quickly in the next 5 year period.</p><h2>Summary of milestones and forecasts</h2><p><i>In the below table, the numbers in the cells are the median expert response to \u201cYears after the (2016) survey for which there is a 10, 50 and 90% probability of the milestone being feasible\u201d. The final column is my judgement of whether the milestone was in fact feasible after 5.5 years. Orange shading shows forecasts falling within the 5.5 years between the survey and today.&nbsp;</i><a href=\"https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit#bookmark=id.raa8hmybk9b9\"><i><u>A full description of milestones, and justification of my judgments, are in the appendix.</u></i></a></p><figure class=\"table\"><table><tbody><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\"><strong>Milestone / Confidence of AI reaching the milestone within X years</strong></td><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">10 percent</td><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">50 percent</td><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">90 percent</td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\">True by Feb 2023? (5.5 + 1 years)</td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Translate a new-to-humanity language</td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>50</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Translate a new-to-it language</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Translate as well as bilingual humans</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>3</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>7</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Phone bank as well as humans</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>3</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>6</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Correctly group unseen objects</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>2</p></td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>4.5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>6.5</p></td><td style=\"background-color:#c6e0b4;border-style:solid;padding:2pt;vertical-align:bottom\"><p>TRUE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">One-shot image labeling&nbsp;</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>4.5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>8</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Generate video from a photograph</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"background-color:#c6e0b4;border-style:solid;padding:2pt;vertical-align:bottom\"><p>TRUE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Transcribe as well as humans</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"background-color:#c6e0b4;border-style:solid;padding:2pt;vertical-align:bottom\"><p>TRUE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Read aloud better than humans</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Prove and generate top theorems</td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>50</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>90</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Win Putnam competition</td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>35</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>55</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Win Go with less gametime</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>3.5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>8.5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>19.5</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Win Starcraft</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>2</p></td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Win any random computer game</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Win angry birds</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>2</p></td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>4</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>6</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Beat professionals at all Atari games</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Win Atari with 20 minutes training</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>2</p></td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Fold laundry as well as humans</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>2</p></td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5.5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Beat a human in a 5km race</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Assemble any LEGO</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Efficiently sort very large lists</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>3</p></td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#c6e0b4;border-style:solid;padding:2pt;vertical-align:bottom\"><p>TRUE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Write good Python code</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>3</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"background-color:#c6e0b4;border-style:solid;padding:2pt;vertical-align:bottom\"><p>TRUE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Answers factoids better than experts</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>3</p></td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#c6e0b4;border-style:solid;padding:2pt;vertical-align:bottom\"><p>TRUE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Answer open-ended questions well</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"background-color:#c6e0b4;border-style:solid;padding:2pt;vertical-align:bottom\"><p>TRUE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Answer unanswered questions well</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>4</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>17.5</p></td><td style=\"background-color:#c6e0b4;border-style:solid;padding:2pt;vertical-align:bottom\"><p>TRUE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">High marks for a high school essay</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>2</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>7</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Create a top forty song</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Produce a Taylor Swift song</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Write a NYT bestseller</td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>30</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>50</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Concisely explain its game play</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"background-color:#c6e0b4;border-style:solid;padding:2pt;vertical-align:bottom\"><p>TRUE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Win World Series of Poker</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>1</p></td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>3</p></td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5.5</p></td><td style=\"background-color:#c6e0b4;border-style:solid;padding:2pt;vertical-align:bottom\"><p>TRUE</p></td></tr><tr><td style=\"background-color:#ffffff;border-style:solid;padding:2pt;vertical-align:bottom\">Output laws of physics of virtual world</td><td style=\"background-color:#f8cbad;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#ffffff;border:0.45454574999999997pt solid #000000;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"border-style:solid;padding:2pt;vertical-align:bottom\"><p>FALSE</p></td></tr></tbody></table></figure><h2><br><strong>Caveats:</strong></h2><p><strong>My judgements of which forecasts have turned out true or false are a little subjective.</strong> This was made harder by the survey question asking which tasks were \u2018feasible\u2019, where feasible meant<i> \u2018if one of the best resourced labs could implement it in less than a year if they chose to. Ignore the question of whether they would choose to.\u2019&nbsp;</i>I have interpreted this as, one year after the forecasted date, have AI labs achieved these milestones, and disclosed this publicly?&nbsp;</p><p>Given (a) \u2018has happened\u2019 implies \u2018feasible\u2019, but \u2018feasible\u2019 does not imply \u2018has happened\u2019 and (b) labs may have achieved some of these milestones but not disclosed it,&nbsp;<strong>I am probably being conservative in the overall number of tasks which have been completed by labs</strong>. I have&nbsp;<strong>not</strong> attempted to offset this conservatism by using my judgement of what labs can probably achieve in private. If you disagree or have insider knowledge of capabilities, you may be interested in editing my working&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/175mCZwcZcrFQENcjUL3bd5ksC8ioCo9EZAYdYl8zZjk/copy\"><u>here</u></a>. Please reach out if you want an explanation of the method, or to privately share updates - patrick at rethinkpriorities dot org.</p><p><strong>It\u2019s not obvious that forecasting accuracy on these nearer-term questions is very predictive of forecasting accuracy on the longer-term questions</strong>.&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/hqkyaHLQhzuREcXSX/data-on-forecasting-accuracy-across-different-time-horizons#Background\"><u>Dillon (2021)</u></a> notes&nbsp;<i>\u201cThere is some evidence that forecasting skill generalises across topics (see Superforecasting, Tetlock, 2015 and for a brief overview see&nbsp;</i><a href=\"https://www.cardrates.com/news/good-judgment-helps-organizations-quantify-risks/\"><i><u>here</u></i></a><i>) and this might inform a prior that good forecasters in the short term will also be good over the long term, but there may be specific adjustments which are worth emphasising when forecasting in different temporal domains.\u201d</i> I have not found any evidence either way on whether good forecasters in the short term will also be good over the long term, but this does seem possible to analyse from the data that&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/hqkyaHLQhzuREcXSX/data-on-forecasting-accuracy-across-different-time-horizons#PredictionBook_Analysis\"><u>Dillon</u></a> and&nbsp;<a href=\"https://www.lesswrong.com/posts/MquvZCGWyYinsN49c/range-and-forecasting-accuracy#comments\"><u>niplav</u></a> collect.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefb8fxh5tj207\"><sup><a href=\"#fnb8fxh5tj207\">[9]</a></sup></span></p><p><strong>Finally, there are caveats in the original survey worth noting here, too</strong>. For example, how the question is framed makes a difference to forecasts, even when the meaning is the same. To illustrate this, the authors note&nbsp;</p><blockquote><p>\u201c<strong>People consistently give later forecasts if you ask them for the probability in N years instead of the year that the probability is M</strong>. We saw this in the straightforward HLMI (high-level machine intelligence) question and most of the tasks and occupations, and also in most of these things when we tested them on mturk people earlier. For HLMI for instance, if you ask when there will be a 50% chance of HLMI you get a median answer of 40 years, yet if you ask what the probability of HLMI is in 40 years, you get a median answer of 30%.\u201d&nbsp;</p></blockquote><p>This is commonly true of the 'Narrow tasks' forecasts (although I disagree with the authors that it is&nbsp;<i>consistently</i> so).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqr9x8qn55z\"><sup><a href=\"#fnqr9x8qn55z\">[10]</a></sup></span>&nbsp;For example, when asked when there is a 50% chance AI can write a top forty hit, respondents gave a median of 10 years. Yet when asked about the probability of this milestone being reached in 10 years, respondents gave a median of 27.5%.&nbsp;</p><h2><strong>What does this all mean for us?</strong></h2><p>Maybe not a huge amount at this point. It is probably a little too early to get a good picture of the experts' accuracy, and there are a few important caveats. But this should update you slightly towards the experts\u2019 timelines if you were sceptical of their forecasts. Within another five years, we will have ~twice the data and a good sense of how the experts performed across their 50% estimates.</p><p>It is also limiting to have only one comprehensive survey of AI experts which includes both long-term and shorter-term timelines. What would be excellent for assessing accuracy is detailed forecasts from various different groups, including political pundits, technical experts, and professional forecasters, with which we can compare accuracy between groups. It would be easier to analyse the forecasting accuracy of questions focused on what developments have&nbsp;<i>happened</i>, rather than what developments are&nbsp;<i>feasible</i>. We could try closer to home, maybe the average EA would be better at forecasting developments than the average AI expert - it seems worth testing now to give us some more data in ten years!</p><h2>Acknowledgements</h2><p><i>I\u2019m grateful to Alex Lintz, Amanda El-Dakhakhni, Ben Cottier, Charlie Harrison, Oliver Guest, Michael Aird, Rick Korzekwa, Scott Alexander, and Zach Stein-Perlman for comments on an earlier draft.</i><br><img src=\"https://res.cloudinary.com/cea/image/upload/v1677675007/mirroredImages/tCkBsT6cAw6LEKAbm/nomwfwtoyifdypimupne.png\"><br><i>If you are interested in RP\u2019s work, please visit our&nbsp;</i><a href=\"https://www.rethinkpriorities.org/research\"><i><u>research database</u></i></a><i> and subscribe to our&nbsp;</i><a href=\"https://www.rethinkpriorities.org/newsletter\"><i><u>newsletter</u></i></a><i>.&nbsp;</i></p><p><i>Cross-posted to </i><a href=\"https://aiimpacts.org/scoring-forecasts-from-the-2016-expert-survey-on-progress-in-ai/\"><i>AI Impacts</i></a><i>, </i><a href=\"https://www.lesswrong.com/posts/tQwjkFT8s2uf2arFN/scoring-forecasts-from-the-2016-expert-survey-on-progress-in\"><i>LessWrong</i></a><i> and </i><a href=\"https://docs.google.com/document/d/1CzFaNBnUhN0KIG0GU8RjozdV0S4CsdQlJ8f474HdHXk/edit#\"><i>this google doc</i></a><i>.</i></p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnzl7j9ilv5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnzl7j9ilv5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I only analysed this \u2018fixed probabilities\u2019 question and not the alternative \u2018fixed years\u2019 question, which asked:<br>\u201cHow likely do you think it is that the following AI tasks will be feasible within the next:<br>- 10 years?<br>- 20 years?<br>- 50 years?\u201d<br>We are not yet at any of these dates, so the analysis would be much more unclear.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7q6hf4gndc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7q6hf4gndc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>9 =&nbsp;&nbsp;4*5% + 14*15% + 6*30% + 5*55% + 2*80% + 1*90%</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlyvya25c7o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflyvya25c7o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;A<i> precise</i> number as a Brier score does not imply an&nbsp;<i>accurate</i> assessment of forecasting ability - ideally, we could work with a larger dataset (i.e. more surveys, with more questions) to get more accuracy.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnd07wy1m7kg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefd07wy1m7kg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;My methodology for the Brier score calculations is based on rounding down to the nearest given forecast, or rounding up to the 10% mark. For example, if a 10% chance was given at 3 years, and a 50% chance at 10 years, the forecast was taken to be 10%, rather than estimating a full probability distribution and finding the 5.5 years point. This skews the expert forecasts towards being more conservative and unfairly penalises them.&nbsp;If the experts gave a 10% chance of X happening in 3 years, I didn\u2019t check whether it had happened in 3 years, but instead checked if it had happened by now. I estimate these two factors (the first skewing the forecasts to be more begives a roughly balance 5-10% increase to the Brier score, given most milestones included a probability at the 5 year mark. A better analysis would estimate the probability distributions implied by each 10, 50, 90% point probability, then assess the probability implied at 5.5 years.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjvw1f25uon8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjvw1f25uon8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;For more detail, see&nbsp;<a href=\"https://en.wikipedia.org/wiki/Brier_score\"><u>Brier score - Wikipedia</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnc8g1ol7em1i\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefc8g1ol7em1i\">^</a></strong></sup></span><div class=\"footnote-content\"><p>[(1-0.1)^2 + (0-0.1)^2 + (1-0.5)^2 + (0-0.5)^2 + (1-0.9)^2 + (1-0.1)^2] / 6</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl795x196gg7\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl795x196gg7\">^</a></strong></sup></span><div class=\"footnote-content\"><p>By \u2018bearish\u2019 and \u2018bullish\u2019 I mean expecting AI milestones to be met later or sooner, respectively.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnl3m4v1omfmp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefl3m4v1omfmp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The score breakdown and method for these calculations is also&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/175mCZwcZcrFQENcjUL3bd5ksC8ioCo9EZAYdYl8zZjk/edit?usp=sharing\"><u>here</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnb8fxh5tj207\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefb8fxh5tj207\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This seems valuable, and I\u2019m not sure why it hasn\u2019t been analysed yet.<br>Somewhat relevant sources:</p><p><a href=\"https://forum.effectivealtruism.org/posts/hqkyaHLQhzuREcXSX/data-on-forecasting-accuracy-across-different-time-horizons\">https://forum.effectivealtruism.org/posts/hqkyaHLQhzuREcXSX/data-on-forecasting-accuracy-across-different-time-horizons</a></p><p><a href=\"https://www.lesswrong.com/posts/MquvZCGWyYinsN49c/range-and-forecasting-accuracy\">https://www.lesswrong.com/posts/MquvZCGWyYinsN49c/range-and-forecasting-accuracy</a></p><p><a href=\"https://www.openphilanthropy.org/research/how-feasible-is-long-range-forecasting/\">https://www.openphilanthropy.org/research/how-feasible-is-long-range-forecasting/</a></p><p><a href=\"https://forum.effectivealtruism.org/topics/long-range-forecasting\">https://forum.effectivealtruism.org/topics/long-range-forecasting</a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqr9x8qn55z\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqr9x8qn55z\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;I sampled ten forecasts where probabilities were given on a 10 year timescale, and five of them (Subtitles, Transcribe, Top forty, Random game, Explain) gave later forecasts when asked with a \u2018probability in N years\u2019 framing rather than a \u2018year that the probability is M\u2019 framing, three of them (Video scene, Read aloud, Atari) gave the same forecasts, and two of them (Rosetta, Taylor) gave an earlier forecast. This is why I disagree it leads to&nbsp;<i>consistently&nbsp;</i>later forecasts.</p></div></li></ol>", "user": {"username": "PatrickL"}}, {"_id": "shzSEEDywdh2PPPMy", "title": "Why I love effective altruism", "postedAt": "2023-03-01T09:41:49.576Z", "htmlBody": "<p>I\u2019ve found it a bit tough to feel as excited as I usually am about effective altruism and our community recently. I think some others have too.&nbsp;</p><p>So I wanted to remind myself why I love EA so dearly. I thought hearing my take might also help any others in the community feeling similarly.&nbsp;</p><p>There\u2019s a lot I want to say about why I love EA. But really, it all comes down to the people. Figuring out how I can best help others can be a difficult, messy, and emotionally draining endeavour. But it\u2019s far easier to do alongside like-minded folk who care about the same goal. Thankfully, I found these people in the EA community.</p><h3>Helping me live up to my values</h3><p>Before I came across effective altruism, I wasn\u2019t really enacting my values.&nbsp;</p><p>I studied ethics at university and realised I was a utilitarian. I used to do bits and pieces of charity work, such as volunteering at Oxfam. But I donated very little of my money. I wasn\u2019t thinking about how to find a career that would significantly help others.&nbsp;</p><p>I didn\u2019t have any good reason for my ethical omissions; it just didn\u2019t seem like other people did them, so I didn\u2019t either.&nbsp;</p><p>Now I\u2019m a Giving What We Can member and have been fulfilling my pledge every year for a decade. I\u2019m still not as good as I\u2019d like to be about thinking broadly and proactively about how to find the most impactful career. But prioritising impact is now a significant factor in how I figure out what to do with my 80,000 hours.&nbsp;</p><p>I made these major shifts in my life, I think, because I met other people who were really living out their values. When I was surrounded by people who typically give something like 10% of their income to charity rather than 3%, my sense of how much was reasonable to give started to change. When I was directly asked about my own life choices, I stopped and thought seriously about what I could and should do differently.&nbsp;</p><p>In addition to these significant life changes, members of the EA community help me live up to my values in small and large ways every day. Sometimes, they give me constructive feedback so I can be more effective. Sometimes, I get a clear-sighted debugging of a challenge I\u2019m facing \u2014 whether that\u2019s a concrete work question or a messy motivational issue.&nbsp;</p><p>Sometimes the people around me just set a positive example. For instance, it\u2019s much easier for me to work a few extra hours on a Saturday in the service of helping others when I\u2019m alongside someone else doing the same.&nbsp;</p><h3>Getting support</h3><p>Given what I said above, I think I\u2019d have expected that the EA community would feel pretty pressureful. And it\u2019s not always easy. But the overwhelming majority of the time, I don\u2019t feel pressured by the people around me;&nbsp; I feel they share my understanding that the world is hard, and that it\u2019s hard in very different ways for different people.&nbsp;</p><p>I honestly never cease to be impressed by the extent to which the people around me work hard to reach high standards, without demanding others do exactly the same. For example:&nbsp;</p><ul><li>One of my friends works around 12 hours a day, mostly 6 days a week. But he\u2019s never anything but appreciative of how much I work, even though it\u2019s significantly less.&nbsp;</li><li>I\u2019ve often expected to be judged for being an omnivore, given that my office is almost entirely veg*n. But far from that, people go out of their way to ensure I have food I\u2019m happy to eat.&nbsp;</li><li>When I first thought I might be pregnant, I felt a bit sheepish telling my friends about it, given that my confident prediction was that having a child would reduce my lifetime impact. But every single person showed genuine happiness for me.&nbsp;</li></ul><p><strong>This feels like a community where we can each be striving \u2014 but also be comfortable setting our limits, knowing that others will be genuinely, gladly respectful of them.</strong></p><p>I think one reason our community is so understanding of each other is that it\u2019s pragmatic to do so. We want to be a community that many different people can feel at home in.&nbsp;</p><p>But I think a bigger part of what\u2019s going on is that the people making up our community actually are just incredibly kind and thoughtful. I\u2019ve been lucky enough to live with around 40 people over the last decade who are involved in EA to differing degrees. It\u2019s been really surprising to me just how considerate my housemates have been and how easy it\u2019s felt to live with them. That doesn\u2019t seem to be the norm for adults in their late twenties and thirties living together.</p><p>I\u2019ve just been to EA Global in the Bay Area, which was a wonderful reminder of the kindness of the community.&nbsp;</p><p>I talked to someone working on improving access to contraception in poor countries. They talked about how hard it is to come into contact with people losing their babies \u2014 people suffering from debilitating health problems like fistula \u2014 but they work on it regardless, because it matters so much.&nbsp;</p><p>I talked to someone who had every right to find their weekend very stressful, but she didn\u2019t because the main thing on her mind was supporting her friend any way she could.&nbsp;</p><p>And I personally became emotional while talking to someone I don\u2019t know very well, who immediately stepped up to help me become happier and replan my day. He even checked in with me later on to say he was happy to provide more support if that would be useful.&nbsp;</p><h3>People I continue to learn from every day</h3><p>In addition to how kind people in EA often are, I very much appreciate how much I learn from them on an ongoing basis. The people I\u2019ve met through this community seem unusually keen to try to understand the world and to form their own views about what\u2019s true as far as they can. As a philosopher, I really appreciate people seeking to get to the bottom of things rather than accepting views because they\u2019re the most convenient to believe or they\u2019re the ones people around you hold.&nbsp;</p><p>And I also think this critical mindset is what\u2019s needed to do a really good job at the hard projects we\u2019re trying to do.&nbsp;</p><p>I also appreciate the extent to which the people I\u2019m surrounded by are continuing to work on their own self-development and are happy to share their learning. Sometimes, this manifests as simple advice like: \u201c<a href=\"https://www.amazon.co.uk/gp/product/B089K4XXL5/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1\"><u>This sleeping mat</u></a> is great for keeping you cool in hot weather.\u201d Sometimes it\u2019s about specialised knowledge and being willing to have somewhat awkward conversations.&nbsp;</p><p>For example, an EA friend of mine who\u2019s a doctor recently pointed out that one reason I might hate exercise so much could be exercise-induced asthma. If that\u2019s true, I might exercise more if I were diagnosed and treated for that. It does in fact seem somewhat likely to be true, and it does seem like this insight is going to make me more likely to do intensive cardio. (Though still not \u201clikely\u201d per se!)&nbsp;</p><h3>Just doing it</h3><p>What feels most salient to me having just been to EA Global though is how much I appreciate the extent to which people in the EA community are just really going out and helping people. They\u2019re doing things that are difficult, emotional, tiring, and speculative. But they\u2019re not letting those things hold them back. They\u2019re mostly talking about ways to do them better \u2014 to get more done and help more people. This includes:&nbsp;</p><ul><li>The philosophy lecturer, who has little contact with anyone else in the community, developing curricula for courses on ethics in different domains and thinking about how to make his material shareable with others</li><li>The person who took leave from undergrad to set up a charity doing mass media outreach to improve the health of women in Nigeria</li><li>The technology manager leaving a lucrative career to set up a governmental centre on the other side of the world</li><li>The person taking an exciting idea in fast-growing technology from speculation to scale through what feels like sheer force of will&nbsp;</li></ul><p>These feel like tough times for us as a community. People seem to be managing these difficulties in very different ways, through anger or sadness, or by following recent events. I\u2019ve talked to at least some people who feel less proud of their identity as an EA than they used to.&nbsp;</p><p>At least insofar as that\u2019s about our community, and the people in it, I want to push back on this inclination, at least a little. Figuring out how to help people most, and then actually doing that, is a huge undertaking. I find it so much easier when I can do it alongside others. I still feel pretty surprised to have found any people as caring and thoughtful as I have in this community.&nbsp;</p><p>I\u2019m deeply grateful for having found so many of them. I\u2019m not too fussed about the big things like brands and websites. But I feel sure that in a decade\u2019s time, I\u2019ll still be living up to my values because of the wonderful people I\u2019m travelling with.&nbsp;<br>&nbsp;</p>", "user": {"username": "Michelle_Hutchinson"}}, {"_id": "St4nnmhKxoi6vYfC4", "title": "A concerning observation from media coverage of AI industry dynamics", "postedAt": "2023-03-02T23:56:14.267Z", "htmlBody": "<p>tl:dr: there are indications that ML engineers will migrate to environments with less AI governance in place, which has implications for the tech industry and global AI governance efforts.</p><p>=========================</p><p>I just wanted to raise something to the community's attention about the coverage of AI companies within the media. The media-source is 'The Information', which is a tech-business focused online news source. Link: <a href=\"https://www.theinformation.com/.\">https://www.theinformation.com/.</a> I'll also note that their articles are (to my knowledge) all behind a paywall.</p><p>The first article in question is titled \"<strong>Alphabet Needs to Replace Sundar Pichai</strong>\".</p><p>It outlines how Google stocks have stagnated in 2023 compared to other tech stocks such as Meta's.&nbsp;</p><p>Here's their mention of Google's actions throughout GPT-mania:</p><p>\"<i>The other side of this equation is the performance of Alphabet management. Most recently, the company\u2019s bungling of its AI efforts\u2014allowing Microsoft to get the jump on rolling out an AI-powered search engine\u2014was the latest sign of how Alphabet\u2019s lumbering management style is holding it back. (Symbolically, </i><a href=\"https://www.theinformation.com/articles/openais-hidden-weapon-ex-google-engineers?rc=9byxri\"><i>as The Information reported</i></a><i>, Microsoft was helped by former Google AI employees!).</i>\"</p><p>This brings us to the second article: \"<strong>OpenAI\u2019s Hidden Weapon: Ex-Google Engineers</strong>\"</p><p>\"<i>As OpenAI\u2019s web chatbot became a global sensation in recent months, artificial intelligence practitioners and investors have wondered how a seven-year-old startup beat Google to the punch.</i></p><p>...</p><p><i>After it hoovered up much of the world\u2019s machine-learning talent, Google is now playing catch-up in launching AI-centric products to the public. On the one hand, Google\u2019s approach was deliberate, reflecting the company\u2019s enormous reach and high stakes in case something went wrong with the nascent technology. It also costs more to deliver humanlike answers from a chatbot than it does classic search results. On the other hand, startups including OpenAI have taken some of the AI research advances Google incubated and, unlike Google, have turned them into new types of revenue-generating services, including chatbots and systems that generate images and videos based on text prompts. They\u2019re also grabbing some of Google\u2019s prized talent.</i></p><p><i>Two people who recently worked at Google Brain said some staff felt the unit\u2019s culture had become lethargic, with product initiatives marked by excess caution and layers of red tape. That has prompted some employees to seek opportunities elsewhere, including OpenAI, they said.</i>\"</p><p>Although there are many concerning themes here, I think the key point is in this last paragraph.</p><p>I've heard speculation in the EA / tech community that AI will trend towards alignment &amp; safety because technology companies will be risk-averse enough to build alignment into their practices.</p><p>I think the articles show that this dynamic is playing out to some degree - Google at least seems to be taking a more risk-averse approach to deploying of AI systems.</p><p>The concerning observation is that there has been a two-pronged backlash against Google's 'conservative' approach. Not only is the stockmarket punishing Google for 'lagging' behind the competition (despite having equal or better capability to deploy similar systems), according to this article, elite machine-learning talent is also pushing back on this approach.</p><p>To me this is doubly concerning. The '<i>excess caution and layers of red tape</i>' in the article is potentially the same types of measures that AI safety proponents would deem to be useful and necessary. Regardless, it appears that the engineers themselves are willing to jump ship in order to circumvent these safety measures.</p><p>Although further evidence would be valuable, it seems that there might be a trend unfolding whereby firms are not only punished by financial markets, they're also forced to weigh up the risks of not being able to retain ML engineers who would rather work for firms with less AI governance measures.</p><p>From my limited understand of industry economics, this dynamic makes sense; I recall reading in Michael Porter's 'Competitive Advantage' that lower-ranked firms are more likely to take actions that damage an the overall industry in order to advance their own position in the short-term. In this instance, it means Microsoft are pushing the rate of AI deployment in ways that Google considers to be risky.</p><p>Overall, this trend seems to provide another counter-argument to the hypothesis that markets incentives will provide sufficient levels of alignment. There are also concerning implications for AI governance in the global AI ecosystem: in the case that some nations are able to implement effective AI governance policies, will this simply cause a migration of AI talent towards lower-governance zones?</p><p>I'd enjoy hearing what other thinking and research has been done on this topic, as it appears to add a new dimension to the already tremendously complex issue of AI safety.</p>", "user": {"username": "Justin Olive"}}, {"_id": "H4XcWBkF55Wnm4mBG", "title": "Proposed changes to the EA Wiki page on forecasting [Google doc]", "postedAt": "2023-03-01T01:48:06.005Z", "htmlBody": "<ul><li>I'm a big believer in the EA wiki</li><li>I wanted to give details for people in forecasting for new people/non-forecasters to contact (eg make our community more legible)</li><li>The current process for large changes seems to be that we write them in google docs</li><li>Let me know what you think of these changes and add any changes you'd like, then I'll implement them all in one go</li></ul><p><a href=\"https://docs.google.com/document/d/1g5znojiuNZbo1MLdW9t4ArQvfMPsPDQKAJXdVY4oZoM/edit\">https://docs.google.com/document/d/1g5znojiuNZbo1MLdW9t4ArQvfMPsPDQKAJXdVY4oZoM/edit</a>&nbsp;</p>", "user": {"username": "nathan"}}, {"_id": "4ztovXcWctjkCj6v5", "title": "Research on self-improvement topic", "postedAt": "2023-03-01T12:42:46.791Z", "htmlBody": "<p>Hello everyone \ud83d\udc4b</p><p>I'm currently doing a research project at Columbia University about self-development. I would love to have your help on this. It'd be great if you could complete this survey:</p><p><a href=\"https://forms.gle/a7k9XZ334kQWB4Jj9\">https://forms.gle/a7k9XZ334kQWB4Jj9</a></p><p>Thank you very much! \ud83d\ude4f</p>", "user": {"username": "Doudou92109"}}, {"_id": "iqDt8YFLjvtjBPyv6", "title": "Some Things I Heard about AI Governance at EAG", "postedAt": "2023-02-28T21:27:59.816Z", "htmlBody": "<h3>Intro</h3><p>Prior to this EAG, I had only encountered fragments of proposals for AI governance: \"something something national compute library,\" \"something something crunch time,\" \"something something academia vs industry,\" and that was about the size of it. I'd also heard the explicit claim that AI governance is devoid of policy proposals (especially vis-a-vis biosecurity), and I'd read Eliezer's infamous EAG DC Slack statement:&nbsp;</p><blockquote><p>My model of how AI policy works is that everyone in the field is there because they don't understand which technical problems are hard, or which political problems are impossible, or both . . .</p></blockquote><p>At this EAG, a more charitable picture of AI governance began to cohere for me. I was setting about recalling and synthesizing what I learned, and I realized I should share\u2014both to provide a data point and to solicit input. Please help fill out my understanding of the area, refer me to information, and correct my inaccuracies!</p><p>Eight one-on-ones contributed to this picture of the governance proposal landscape, along with Katja's and Beth's presentations, Buck's and Richard Ngo's office hours, and eavesdropping on Eliezer corrupting the youth of EAthens. I'm sure I only internalized a small fraction of the relevant content in these talks, so let me know about points I overlooked. (My experience was that my comprehension and retention of these points improved over time: as my mental model expanded, new ideas were more likely to connect to it.) The post is also sprinkled with my own speculations. I'm omitting trad concerns like stop-the-bots-from-spreading-misinformation.</p><h3>Crunch Time Friends</h3><p><strong>The idea</strong>: Help aligned people achieve positions in government or make allies with &nbsp;people in those positions. When shit hits the fan, we activate our friends in high places, who will swiftly unplug everything they can.</p><p><strong>My problem</strong>: This story, even the less-facetious versions that circulate, strikes me as woefully under-characterized. Which positions wield the relevant influence, and are timelines long enough for EAs to enter those positions? How exactly do we propose they react? Additionally, FTX probably updated us away from deceptive long-con type strategies.</p><p><strong>Residual questions</strong>: Is there a real and not-ridiculous name for this strategy?</p><h3>Slow Down China</h3><p>The chip export controls were so so good. A further move would be to reduce the barriers to high-skill immigration from China to induce brain drain. Safety field-building is proceeding, but slowly. China is sufficiently far behind that these are not the highest priorities.</p><h3>Compute Regulations</h3><p>I'm told there are many proposals in this category. They range in enforcement from \"labs have to report compute usage\" to \"labs are assigned a unique key to access a set amount of compute and then have to request a new key\" to \"labs face brick wall limits on compute levels.\" Algorithmic progress motivates the need for an \"effective compute\" metric, but measuring compute is surprisingly difficult as it is.&nbsp;</p><p>A few months ago I heard that another lever\u2014in addition to regulating industry\u2014is improving the <i>ratio</i> of compute in academia vs industry. Academic models receive faster diffusion and face greater scrutiny, but the desirability of these features &nbsp;depends on your perspective. I'm told this argument is subject to \"approximately 17 million caveats and question marks.\"</p><h3>Evaluations &amp; Audits</h3><p><strong>The idea</strong>: Develop benchmarks for capabilities and design evaluations to assess whether a model possesses those capabilities. Conditional on a capability, evaluate for alignment benchmarks. Audits could verify evaluations.</p><p><strong>Industry self-regulation</strong>: Three labs dominate the industry, an arrangement that promises to continue for a while, facilitating cooperation. Even if each believes itself locked in a secret arms race with the others, there are still opportunities to find common ground when engineers from different labs, like, bump into each other at EAG or whatever. Perhaps industry standards emerge due to public pressure, employee pressure, and each lab's desire for the others to not destroy the world. Journalism probably plays an important role here. Perhaps the threat of government regulation yields consensus: \"if we don't solve this ourselves, the government will step in and tread on us.\" Beth suggested this dynamic inspired safety regulation among airlines. In general, ARC Evals is bullish on cooperation from labs, even for evaluations that impose significant costs. But we should move fast: we might be in a critical period when labs are willing to commit to restrictions on capabilities that they still regard as speculative/unlikely. This work raises some info hazard concerns, but it seems like people are aware of and managing the risks.</p><p><strong>Government regulation</strong>: Regulators are often playing catch-up with industry, particularly in <a href=\"https://www.businessinsider.com/supreme-court-google-tech-social-media-section-230-justices-internet-2023-2\">tech</a>. Labs expecting to stay one step ahead of the government undermines the above argument about the threat of government intervention. On the other hand, government commands uniquely powerful enforcement abilities, and they can outsource the technical work to third parties. Government evals and audits might widen the revolving door, but whether this is good or bad probably turns on some questions about who gets reallocated away from capabilities research and how the talent pipeline responds. Policymakers might prefer different benchmarks or evaluations than industry selects; given that ARC Evals already occupies the industry niche, why not expand to government as well?</p><p><strong>Interactions</strong>: Why not both? From what I heard, it seems likely that this is the correct approach. Multiple benchmarks and evaluations would accomplish more comprehensive coverage of the space of capabilities. Redundancy would also check against defections from the industry norms and exploitation of regulatory blindspots. One popular story is that government can allow industry consensus to coalesce, then codify those evaluations to bind market entrants. Going the other direction, maybe an agenda-setting role for government would contribute to faster/better norms. For example, in some finance firms, respect for regulators and \"playing by the rules\" is baked into the company culture. A different indirect channel might involve the government validating the media's suspicion toward AI, increasing public scrutiny.&nbsp;</p><p>These benefits aside, there could be more of a tradeoff between the two strategies if labs perceive government involvement as antagonistic, positioning the two as enemies with antithetical goals. In this event, corporate capture and lobbying might conceivably result in net-worse evals than if we had exclusively targeted industry self-regulation. I heard that in Europe, Meta is known for outright opposition to government oversight, whereas Microsoft takes a more insidious tack by proclaiming their desire for regulation, then proposing definitions so broad that even PyTorch is included, provoking broad industry resistance. I'm not too worried about this argument because it sounds like projecting individual psychology onto an organization, and suspicion is government's default posture toward big tech right now, so government regulation shouldn't surprise labs. Insofar as EA needs to prioritize right now, it might be worth considering whether industry or government is more promising, but many people asking this question seem significantly better-positioned to work on one or the other.</p><p><strong>Residual questions</strong>: Do evals still fall under \"AI governance\" if they're exclusively implemented by labs? Buck talked about evals in the context of technical research. If we knew how to design alignment evaluations conditional on strong capabilities, wouldn't alignment be solved? How does our confidence in alignment evals decrease as capabilities improve?</p><h3>Whistleblowing</h3><p><strong>The idea</strong>: Cultivate company cultures that encourage whistleblowing by supporting whistleblowers and framing it as a benefit to the company.</p><p><strong>My problem</strong>: The longer you've worked somewhere, the more likely you are to be privy to juicy whistleworthy happenings. But those veteran employees are precisely the people who stand to lose the most from retaliation. To make matters worse, the fewer people involved in a misdeed, the less anonymity available for the whistleblower. All this amounts to the most important potential whistleblowers facing the highest costs. In contrast, whistleblowers' warm-and-fuzzies compensation is more invariant to the importance of the whistleblowing. This leads me to believe we should focus on incentivizing whistleblowing by improving the payoffs such that whistleblowing is worth the costs, even for veteran employees. (Obviously you don't want a policy that potential whistleblowers can Goodhart by sitting on their information to qualify for a larger reward. We want something resembling a <a href=\"https://en.wikipedia.org/wiki/Centipede_game\">centipede game</a>, so someone snitches at T_0, with payoffs calibrated to deter collusion.)</p><p><strong>Residual questions</strong>: How does any of this work? What are the current reward schedules for whistleblowing? Who sets them and how are rewards determined? Do X-risks introduce new considerations in that process? How does whistleblowing interact with tort law?</p><h3>Anti-Trust</h3><p><strong>The idea</strong>: Now we get to the galaxy-brain plays. If some AI model would violate anti-trust laws, educating labs on the regulatory environment might preclude the development of these models. Importantly, this proposal focuses on <i>proactively</i> informing labs. Waiting for labs to stumble into legal trouble is less promising; anti-trust lawsuits take years, so by the time a lawsuit concludes, the damage will have already been done.</p><p><strong>My problem</strong>: Anti-trust law is not optimized for AI safety applications, which raises the specter of unintended consequences. In particular, I think we should carefully attend to the counterfactual capabilities that labs substitute when they forego a project on anti-trust grounds. I'm all for another tool in our toolbox, but as the saying goes: when your only tool is an anti-trust hammer, every problem looks like an anti-competitive nail.</p><p><strong>Residual questions</strong>: How does any of this work? What models and capabilities would run afoul of anti-trust law and which would not? How well-informed are labs already and how much of a delta could we really achieve here? Are there instances where we would prefer labs becoming ensnared in a lawsuit, perhaps to agitate public scrutiny?</p><h3>DoD Steering</h3><p>AI is more obviously dual-use than, say, nuclear technology, but its strategic applications still capture the pentagon's imagination. We want to keep the DoD out of the AI game, both to limit domestic capabilities research and to avoid <a href=\"https://en.wikipedia.org/wiki/Securitization_(international_relations)\">securitizing</a> AI into an international arms race. Thankfully, current models like Chat GPT are too unreliable for military adoption in the US.&nbsp;</p><p>Military AI development would draw on massive military budgets and presumably employ less-aligned engineers than industry labs. Military AI products are unlikely to compete in the market with models trained in labs due to restrictions on making military software public, even as open source. Apparently, for example, the Air Force has refused to release some software that would benefit commercial aviation. So DoD entry shouldn't exacerbate race conditions among labs; to the extent DoD competes with labs, it would be over talent. The bigger concern is the research performed by the DoD itself.</p><p>There is a lot of room for us to improve influence. As far as I know, there is only one aligned person in the DoD focused on AI. Moreover, a recent <a href=\"https://www.nscai.gov/wp-content/uploads/2021/03/Full-Report-Digital-1.pdf\">report</a> from the National Security Commission on AI neglected X-risks, despite Jason Matheny serving on its commission, which does not inspire confidence.</p><p><strong>Residual questions</strong>: How would DoD operations interact with government regulation efforts? With industry self-regulation standards? Does optimizing models for military applications yield different/worse alignment problems than for civilian use? How much would DoD training programs grow the number of capabilities researchers? Which positions wield the relevant influence?</p>", "user": {"username": "Rocket"}}, {"_id": "Q9tiLjgdHTMqFYsii", "title": "What does Bing Chat tell us about AI risk?", "postedAt": "2023-02-28T18:47:12.198Z", "htmlBody": "<figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1677610034/mirroredImages/Q9tiLjgdHTMqFYsii/awr8uekuyxepivigfuxz.webp\" alt=\"What does Bing Chat tell us about AI risk?\"></figure><p><i>Image from </i><a href=\"https://astralcodexten.substack.com/p/janus-simulators?ref=cold-takes\"><i>here</i></a><i> via </i><a href=\"https://twitter.com/repligate/status/1614416190025396224?ref=cold-takes\"><i>this tweet</i></a></p><p>ICYMI, Microsoft has released a <a href=\"https://www.bing.com/new?ref=cold-takes\">beta version of an AI chatbot</a> called \u201cthe new Bing\u201d with both impressive capabilities and some scary behavior. (I don\u2019t have access. I\u2019m going off of tweets and articles.)</p><p>Zvi Mowshowitz lists examples <a href=\"https://www.lesswrong.com/posts/WkchhorbLsSMbLacZ/ai-1-sydney-and-bing?ref=cold-takes#The_Examples\">here</a> - highly recommended. Bing has threatened users, called them liars, insisted it was in love with one (and argued back when he said he loved his wife), and much more.</p><p>Are these the first signs of the <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/vGsRdWzwjrFgCXdMn\">risks I\u2019ve written about</a>? I\u2019m not sure, but I\u2019d say yes and no.</p><p>Let\u2019s start with the \u201cno\u201d side.</p><ul><li>My understanding of how Bing Chat was trained probably does not leave much room for the kinds of issues I address <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/vGsRdWzwjrFgCXdMn#Deceiving_and_manipulating_humans\">here</a>. My best guess at why Bing Chat does some of these weird things is closer to \u201cIt\u2019s acting out a kind of story it\u2019s seen before\u201d than to \u201cIt has <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/vGsRdWzwjrFgCXdMn\">developed its own goals</a> due to <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/vGsRdWzwjrFgCXdMn#Starting_assumptions\">ambitious, trial-and-error based development</a>.\u201d (Although \u201cacting out a story\u201d could be dangerous too!)</li><li>My (zero-inside-info) best guess at why Bing Chat acts so much weirder than <a href=\"https://chat.openai.com/?ref=cold-takes\">ChatGPT</a> is in line with <a href=\"https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned?commentId=AAC8jKeDp6xqsZK2K&amp;ref=cold-takes\">Gwern\u2019s guess here</a>. To oversimplify, there\u2019s a particular type of training that seems to make a chatbot generally more polite and cooperative and less prone to disturbing content, and it\u2019s possible that Bing Chat incorporated less of this than ChatGPT. This could be straightforward to fix.</li><li>Bing Chat does not (even remotely) seem to pose a risk of global catastrophe itself.</li></ul><p>On the other hand, there is a broader point that I think Bing Chat illustrates nicely: <strong>companies are racing to build bigger and bigger \u201cdigital brains\u201d while having </strong><i><strong>very </strong></i><strong>little idea what\u2019s going on inside those \u201cbrains.\u201d </strong>The very fact that this situation is so <i>unclear</i> - that there\u2019s been no clear explanation of why Bing Chat is behaving the way it is - seems central, and disturbing.</p><p>AI systems like this are (to simplify) designed something like this: \u201cShow the AI a lot of words from the Internet; have it predict the next word it will see, and learn from its success or failure, a mind-bending number of times.\u201d You can do something like that, and spend huge amounts of money and time on it, and out will pop some kind of AI. If it then turns out to be good or bad at writing, good or bad at math, polite or hostile, funny or serious (or all of these depending on just how you talk to it) ... you\u2019ll have to speculate about why this is. You just <i>don\u2019t know</i> what you just made.</p><p>We\u2019re building more and more powerful AIs. Do they \u201cwant\u201d things or \u201cfeel\u201d things or <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/vGsRdWzwjrFgCXdMn\">aim for</a> things, and what are those things? We can argue about it, but we don\u2019t know. And if we keep going like this, these mysterious new minds will (I\u2019m guessing) eventually be powerful enough to <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH\">defeat all of humanity</a>, if they were turned toward that goal.</p><p>And if nothing changes about attitudes and market dynamics, minds that powerful could end up <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/yjm5CW9JdwBTFZB2B#debates\">rushed to customers in a mad dash to capture market share</a>.</p><p>That\u2019s the path the world seems to be on at the moment. It might end well and it might not, but it seems like we are on track for a heck of a roll of the dice.</p><p>(And to be clear, I do expect Bing Chat to act less weird over time. Changing an AI\u2019s <i>behavior</i> is straightforward, but <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/NbiHKTN5QhFFfjjm5\">that might not be enough</a>, and might even provide <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/vGsRdWzwjrFgCXdMn#Why_we_might_not_get_clear_warning_signs_of_the_risk\">false reassurance</a>.)</p>", "user": {"username": "HoldenKarnofsky"}}, {"_id": "EdMtiRtoRvKwrRjQZ", "title": "Speed Friending Retrospective - Local Group Event", "postedAt": "2023-02-28T17:43:26.142Z", "htmlBody": "<p>Wil Perkins and I run a local effective altruism group in Raleigh, NC, USA. We recently decided to host a speed-friending event inspired by several other events within the EA space. The goal of this post is to explain how we marketed and ran this event and provide our thoughts on what we would change for other groups that may want to attract new members or facilitate new relationships within their group through this method. I\u2019ll try to be as detailed as possible as group contexts and environments can vary highly and will impact the experience for attendees.</p><p>If you have more in-depth questions the post doesn\u2019t cover, feel free to drop a comment or message either of us. Also, we welcome critical feedback if there are things you think we could improve on. Wil was essential to writing this post and I appreciate his assistance in all things.</p><h1><strong>Summary</strong></h1><p>On the 25th of February 2023 at 16:00 Effective Altruism Raleigh hosted a speed-friending/potluck event at the organizers' home. The event was advertised within the group through social channels beginning two weeks before the event, marketing primarily through Facebook Groups and Meetup. The event consisted of a 30-minute arrival window, and a 30-minute speed-friending session and the remainder was unstructured with the event informally ending around 20:00.&nbsp; A total of 24 attendees participated in the event with 18 of them participating in speed-friending. The Speed-Friending event consisted of ten 3-minute conversations. Half of the participants moved between each conversation in a clockwise direction. We provided a time travel prompt at the participant's request which was well received. Participants reported being intrigued by the idea of speed-friending and primarily attended the event because of this. Afterward, participants reported enjoying the process but requested longer discussion segments. In the future, we intend on providing a more intuitive seating arrangement for the proceedings and extending the discussion period to 5 minutes, lengthening the session to 45 minutes allowing for 9 pairings. We also intend to provide easier methods of joining us online via QR codes. We intend to update the impact on group growth that the event leads to in the future.</p><h1>Background</h1><p>We were inspired by several events shared within the EA Groups organizer slack and other local events. There are several other write-ups that discuss speed-friending as follows:<br>&nbsp;</p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/7S8mWarpodBTLG33c/eagxberkeley-2022-retrospective\"><u>https://forum.effectivealtruism.org/posts/7S8mWarpodBTLG33c/eagxberkeley-2022-retrospective</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/bRHHiewC8vZ2AE8LB/uses-of-ea-retreats-case-study-uk-uni-organisers-retreat-dec\"><u>https://forum.effectivealtruism.org/posts/bRHHiewC8vZ2AE8LB/uses-of-ea-retreats-case-study-uk-uni-organisers-retreat-dec</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/NLmZyAq32AT9JjjSK/eagxboston-2022-retrospective\"><u>https://forum.effectivealtruism.org/posts/NLmZyAq32AT9JjjSK/eagxboston-2022-retrospective</u></a></li></ul><p>We originally chose this style of event to encourage our members to talk to different people - at our standard weekly event, people usually sit with and talk to the same people. There are a lot of people who simply sit back and listen. It is important to us that our local group encourages connections that go beyond skin deep, and speed-friending seemed like an interesting approach to the achievement of that goal. Therefore the primary goals for the event were thus:</p><ol><li>Increase engagement with the group from new members</li><li>Encourage Group members to engage with various numbers of individuals</li><li>Strengthen the connections within the group</li></ol><h1><strong>Advertising the Event</strong></h1><h2><strong>Online Marketing</strong></h2><p>Two weeks before the event, we put an event up on our Facebook group and in Meetup app.&nbsp;</p><p><i>The text of the description was as follows:</i></p><p>\u201cWe are hosting a potluck! This is an open event for anyone - whether you are a member of EA Raleigh or just interested in meeting some interesting people. If there are enough people we will be running a speed-friending session at the start of the potluck. There will be some food and drinks provided - but please bring anything you'd like. We have a collection of board games, playing cards, and puzzles. There is also a little \"Estimation Game\" we can play if people are interested.</p><p>The venue is indoor/outdoor, so feel free to bring a camping chair. If the weather is chilly there will be a bonfire!</p><p>General Schedule</p><p>4:00- 4:30 - Food and Drinks</p><p>4:30 - 4:45 - Speed Friending</p><p>4:45 - 6:00 - Board Games and The Estimation Game</p><p>There will be vegan&nbsp;<i>and</i> gluten-free options available, and please be conscious of dietary concerns if you choose to bring something - we will have cards to write down and display allergens.</p><p>For those with allergens or pet friends, there will be a dog who isn't well-behaved around other dogs.\u201d</p><h2><strong>Email Marketing</strong></h2><p>We also emailed out an announcement two weeks before the event and with a subsequent event reminder to those on our email list.&nbsp;</p><p><i>The email reminder read:</i></p><p>\u201cWe are very excited about the potluck event happening this Saturday 2/25, at [Our Address]. from 4:00 pm- 6:00 pm. Drop in at any time, but if the group is large enough we will do some speed friending starting at 4:30. Some vegan and gluten-free options will be provided, but feel free to bring anything you would like! All we ask is you fill out an allergens card for your food when you arrive to help avoid any confusion. We will have some tap water and lemonade as well.</p><p>All updates will be posted on the event page. If you do not have Facebook feel free to text Mae at (919) ********</p><p>General Schedule:</p><p>4:00 PM - 4:30 PM&nbsp; Potluck begins</p><p>4:30 PM - 5:00 PM&nbsp; Speed-Friending Event</p><p>5:00 PM - End&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Board games and Estimation Game (Vote will be held)\u201d</p><h2><strong>Alternative Advertising</strong></h2><p>We also participated in direct advertising, reaching out to specific individuals who may be interested in the event via text. In addition, we discussed this event well in advance with people at our weekly meetup.&nbsp;</p><h2><strong>Advertising Results</strong></h2><p>Provided is a summary table of the context of these marketing efforts and the tracked results:</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Marketing Platform</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Number of Total Contacts (members) At Time of Advertising</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Number of Attendees Directly Associated with Platform</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Facebook</td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center;vertical-align:top\">35</td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center;vertical-align:top\">2</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">MeetUp</td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center;vertical-align:top\">64</td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center;vertical-align:top\">11</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Event Notification Email&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center;vertical-align:top\">45</td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center;vertical-align:top\">2</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Direct Marketing</td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center;vertical-align:top\">6</td><td style=\"border:1pt solid #000000;padding:5pt;text-align:center;vertical-align:top\">6</td></tr></tbody></table></figure><p><br><br>&nbsp;</p><p>Based on conversion, direct marketing was the most effective but was only used for currently active members (individuals who have attended 2 or more meetups and at least 1 meetup in the past 30 days).&nbsp;</p><p>From a growth standpoint, Meetup was the most effective way to get new people out for the speed-friending event. On the morning of the event, there were 26 people (not including the hosts) marked as going, at the time of the event 15 people were marked as going with a final count of 11 people arriving primarily through Meetup with 7 of those individuals never having attended a previous meeting.</p><p><br>&nbsp;</p><h1>Location, Setup &amp; Materials</h1><h2>Location:</h2><p>We decided to use our house to host the event. We have a 1700 square-foot ranch house located in Raleigh NC with a large back deck (it was raining or this would have been used).&nbsp;</p><h2>Materials</h2><ul><li>2 long folding tables</li><li>1 Circular Table</li><li>4 Dining Chairs</li><li>14 Folding Chairs (Plus 6 additional chairs)</li><li>4 sheets of Nametags</li><li>Various Sharpies and Pens</li><li>Signage (Restrooms, Dog Notices, Silverware Locations)</li><li>Food Labels</li><li>Green Washi Tape</li><li>40 Large Compostable Plates/ 20 small compostable plates</li><li>Cocktail Napkins</li><li>New year\u2019s eve Noise Maker</li></ul><h2>Venue Set-up:<br>&nbsp;</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677605925/mirroredImages/EdMtiRtoRvKwrRjQZ/xmk3oqgourvwk5kh4oqn.png\"></p><p><br>Upon entry, there was a circular table hosting name tags and markers for people to put on, and we encouraged everyone to grab one when they arrived. Within our dining room, we took two long folding tables we have and put them side by side with enough room for two sets of chairs between them. The diagram below shows the general layout of the space along with the flow of speed-friending.</p><p>On the back of the chairs highlighted in the image, we added some color coding tape to indicate which chairs moved through the speed-friending process.</p><p>The event was a potluck as well, so we made sure to have a meal and dessert ready, as well as ample space in the kitchen for food. We put signs up to direct folks to the restrooms, and where to find silverware, etc.&nbsp;</p><p>For ease of clean-up, we had some compostable paper plates and cups, and napkins. Ideally, if you have a venue with plenty of dishes you can avoid this step.&nbsp;</p><p>Finally, we took a picture of our house from the front and posted it in all of our social media groups for ease of location. We provided parking instructions on the event locations, specifically in Meetup\u2019s \u201cWhere to find us\u201d section. For more complicated locations we would provide a map. No one needed help finding the venue.</p><h1>Speed Friending Methodology</h1><p>We opted for a rotating framework to facilitate random matching. The seating layout is provided below with movement arrows. We had participants sit down in chairs and had the members in chairs highlighted in blue in the diagram move to the left every three minutes. In-person highlighted seats were marked with green tape.</p><p>At the start of the event, we had people determine whether or not they were moving before we started. We gave each pair three minutes to talk before rotating. Originally, I was verbally notifying the switch but moved to a noise-maker as the room was too loud. We ran this for a total of 30 minutes. At times people needed assistance in navigating between sections.</p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677605925/mirroredImages/EdMtiRtoRvKwrRjQZ/xmk3oqgourvwk5kh4oqn.png\"></p><p>As organizers, the two of us stayed out, as people showed up in the middle of the event or didn\u2019t know where to go.&nbsp;</p><p>Originally we did not provide a prompt, but someone requested one. We, therefore, had an optional topic if someone didn\u2019t know what to talk about which was: \u201cIf you could go back in time and change one event in history, which one and why?\u201d&nbsp;</p><p>We got great feedback from attendees on this prompt, and a lot of people discussed it.&nbsp;</p><h1>Direct Feedback</h1><p>Most of the feedback we got from attendees was highly positive. Everyone said they enjoyed their conversations and that overall there was a very high quality of people there. Even though a minority of attendees knew about Effective Altruism beforehand, most people reported that their conversations were much more interesting than most meetups, and people seemed to trend compassionate and engaging.</p><p>The only negative feedback we got was that 3 minutes might have been too short - in subsequent meetups, we will increase the time to 5 minutes the next time we host this event.&nbsp;</p><p>No formal polls were performed.</p><h1>Impact on the Group - Was it worth it?</h1><p>Three days have passed since hosting the event, so the impact on growth and connection within the group is difficult to say, but the following concrete changes have occurred since the announcement of the event:</p><ul><li>10 additional individuals have signed up for our mailing list</li><li>There are now 85 members in our Meet-up group</li><li>2 new individuals attending the speed-friending event have marked themselves as going to our subsequent events<br>&nbsp;</li></ul><p>We also noticed several people exchanged numbers during the event&nbsp;</p><h1>Future Changes</h1><p>The event had a few drawbacks</p><ol><li>Layout<ol><li><i>The kitchen layout</i> was not ideal, in the future drinks will be set up at a separate table instead of in the kitchen, and the thoroughfare through the kitchen was constantly blocked and made it difficult for people to get food</li><li><i>Speed-Friending Flow&nbsp;</i>was confusing crossing between the long tables to the round table. Directions had to be provided between rounds for the individual crossing that way</li></ol></li></ol><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677605925/mirroredImages/EdMtiRtoRvKwrRjQZ/w1fkp5hadoffmkmo0u6r.png\"></p><ol><li>Speed-Friending Process<ol><li>Having a discussion topic ready rather than one pulled from my hat would have been good, I plan on preparing that in the future</li><li>Extending the amount of time people have to discuss to 5 minutes</li><li>Extending the total time to 45 minutes to allow more than 6 matches</li><li>Having a Buzzer - my voice was not enough but the noise-maker was near-comical. Having a pre-loaded sound on your phone or computer is what I would recommend</li></ol></li><li>Group Growth<ol><li>In the future, it would be good to have QR codes and other easy paths for people to register for the email list. We had a \u201cregistration sheet\u201d and verbally went to collect email addresses, but it would be nice to have some \u201cDIY\u201d options available that would provide more valuable metadata</li></ol></li></ol><h1>In Conclusion</h1><p>If you are a local group organizer and are looking for a way to grow your community we would highly recommend hosting a speed friending event. It\u2019s a great way to attract new members and facilitate connections within your group. With a little planning and effort, it\u2019s a simple and fun event that can have a big impact.</p><p>Here are some key takeaways:</p><ul><li>Choose a location that is comfortable and easy to navigate, with enough space for everyone to sit and move around.</li><li>Consider adding a potluck element. This draws in more people and allows folks to naturally start eating after the speed friending is over.</li><li>Set up the event with clear signage and materials, including name tags, timers, and prompts for conversation.</li><li>Advertise the event through social media, email lists, and in-person conversations with your regular members.</li><li>Ask for feedback from attendees to improve future events, such as adjusting the length of each conversation or adding more prompts.</li></ul><p>Overall, we were thrilled with the success of this event and look forward to hosting more in the future. We hope this post inspires other local groups to try it out and see the benefits for themselves.<br>&nbsp;</p>", "user": {"username": "MaeBrown"}}, {"_id": "hy2qcaYStNTBqaZCs", "title": "Do you worry about totalitarian regimes using AI Alignment technology to create AGI that subscribe to their values?", "postedAt": "2023-02-28T18:12:43.372Z", "htmlBody": "<p>Hi all! First I want to say that I really enjoyed this forum in the past few months, and eventually decided to create an account to post this question. I am still in the process of writing the short version of this question, so thank you for bearing with me in the long version.</p><p>As some of you may know, last year we have seen unprecedented uprising against totalitarian regimes. As a Chinese national active in the diaspora dissent community, I have never been more encouraged by the courage and creativity of my people; as an ML practitioner, I am more and more worried about AGI being the most powerful governing tool humanity has seen yet.&nbsp;</p><p>China's Zero-COVID policy gave us a first taste of what this future would feel like - personal location tracking limits your freedom of mobility; a remote \"system\" will decide what you can or cannot do and you will be informed via an app on your phone; when you try to push back, it is like trying to hit a bureaucratic wall.&nbsp;</p><p>Most importantly, Zero-COVID gave rise to a whole value system that sees society as a simplified trolley problem: the government -- an all-knowing entity -- holds the lever, and will be deciding what is best for the whole. Collectivism is equivalent to altruism, individualism is equivalent to being selfish, and the most honorable thing for an individual to do is to obey. This value system is pretty compelling, and has been pushed into every grade school kid. US's failure and massive death toll is also a convenient gotcha.</p><p>Needless to say many people in China do not subscribe to this value, but many people do, and more often than not it is the latter group that are the agent of your day-to-day act of suppression. The policy eventually collapsed partially due to uprising, but even during the height of the uprising there were still significant momentum on the pro-Zero-COVID side for the policy to keep going. My suspicion is what eventually brought down Zero-COVID was the unbearable price tag, especially for local governments. However, I can totally see if COVID happened in 2030 instead of 2020 (1o years are nothing in earth years), the price tag will be much sustainable.</p><p>It is no news that 1) AI tend to converge to monopoly, and 2) totalitarian regimes will want to use AI to extend their power. We also know that 3) AI alignment seeks to build the ability for us to embed our values into AI. I deeply worry about the gentle seduction of AI technology in China, seducing us to yield more and more of our agency to an AGI that may align with a value system that represent the interest of the ruling entity, and there will be less and less room for pushing back.</p>", "user": {"username": "diodio_yang"}}, {"_id": "9yLa5hcJrRFpAv5sM", "title": "Apply to attend EA conferences in Europe", "postedAt": "2023-02-28T15:48:12.334Z", "htmlBody": "<p>Europe is about to get significantly warmer and lighter<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjm8zjnbs7n\"><sup><a href=\"#fnjm8zjnbs7n\">[1]</a></sup></span>. People like warmth<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaazce9xjpy\"><sup><a href=\"#fnaazce9xjpy\">[2]</a></sup></span>&nbsp;and light<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzvk102sfmur\"><sup><a href=\"#fnzvk102sfmur\">[3]</a></sup></span>, so we (CEA) have been busy organising several EA conferences in Europe over the next few months in partnership with local community-builders and EA groups:</p><ul><li><a href=\"https://www.effectivealtruism.org/ea-global/events/eagxcambridge\"><strong>EAGxCambridge</strong></a><strong> </strong>will take place at Guildhall, 17\u201319 March.<strong>&nbsp;</strong><a href=\"https://bit.ly/eagxcamapply\"><strong><u>Applications are open now</u></strong></a><strong> and will close on Friday (3 March)</strong>.&nbsp;Speakers include&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ukk5f4bqqBAWbF4Zh/lord-martin-rees-an-appreciation\"><u>Lord Martin Rees</u></a>,&nbsp;<a href=\"https://salonium.substack.com/\"><u>Saloni Dattani</u></a> (Our World In Data) and&nbsp;<a href=\"https://www.effectivealtruism.org/ea-global/events/eagxcambridge#:~:text=episode%20with%20guest-,Anders%20Sandberg,-(Future%20of%20Humanity\"><u>Anders Sandberg</u></a> (including a live interview for the&nbsp;<a href=\"https://hearthisidea.com/\"><u>Hear This Idea</u></a> podcast).</li><li><a href=\"https://www.effectivealtruism.org/ea-global/events/eagxnordics-2023\"><strong>EAGxNordics</strong></a>&nbsp;will take place at&nbsp;<a href=\"https://munchenbryggeriet.se/en/front-page/\"><u>Munchenbryggeriet</u></a>, Stockholm 21\u201323 April.&nbsp;<a href=\"https://effectivealtruism.force.com/EAGlobal/s/eagxnordicsapplication\"><u>Applications are open now</u></a>&nbsp;and will close 28 March.&nbsp;If you register by 5 March, you can claim a discounted early bird ticket.</li><li><a href=\"https://www.effectivealtruism.org/ea-global/events/ea-global-london-2023\"><strong>EA Global: London</strong></a>&nbsp;will take place at&nbsp;<a href=\"https://www.tobaccodocklondon.com/\"><u>Tobacco Dock</u></a>, 19\u201321 May 2023.&nbsp;<a href=\"https://effectivealtruism.force.com/EAGlobal/s/eaglobalapplication?eId=a4WAJ000000000k2AA\"><u>Applications are open now</u></a>. If you were already accepted to EA Global: Bay Area, you can register for EAG London now; you don\u2019t need to apply again.</li><li><a href=\"https://www.effectivealtruism.org/ea-global/events/eagxwarsaw\"><strong>EAGxWarsaw</strong></a><strong> </strong>will take place at&nbsp;<a href=\"https://polin.pl/en\"><u>POLIN</u></a>, 9\u201311 June 2023. Applications will open in the coming weeks.</li></ul><p>You can apply to all of these events using the same application details, bar a few small questions specific to each event.</p><h3>Which events should I apply to?</h3><p><i>(mostly pulled from&nbsp;</i><a href=\"https://www.effectivealtruism.org/ea-global/faq\"><i><u>our FAQ page</u></i></a><i>)</i></p><p>EA Global is mostly aimed at people who have a solid understanding of the core ideas of EA and who are taking significant actions based on those ideas. Many EA Global attendees are already professionally working on effective-altruism-inspired projects or working out how best to work on such projects. EA Global is for EAs around the world and has no location restrictions (though we recommend applying ASAP if you will need a visa to enter the UK).</p><p>EAGx conferences have a lower bar. They are for people who are:</p><ul><li>Familiar with&nbsp;the core ideas of effective altruism;</li><li>Interested in learning more about what to do with these ideas.</li></ul><p><strong>EAGx events also have a more regional focus:</strong></p><ul><li>EAGxCambridge is for people who are based in the UK or Ireland, or have plans to move to the UK within the next year;</li><li>EAGxNordics is primarily for people in the Nordics, but also welcomes international applications;</li><li>EAGxWarsaw is primarily for people based in Eastern Europe but also welcomes international applications.</li></ul><p>If you want to attend but are unsure about whether to apply,&nbsp;<strong>please err on the side of applying!</strong><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjm8zjnbs7n\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjm8zjnbs7n\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See e.g. Expat Explore on the \u201c<a href=\"https://expatexplore.com/blog/europe-by-season-when-to-travel-where/\"><u>Best Time to Visit Europe</u></a>\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaazce9xjpy\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaazce9xjpy\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Pew Research Center&nbsp;<a href=\"https://www.pewresearch.org/social-trends/2009/03/18/most-like-it-hot/\"><u>surveyed Americans on this matter</u></a> (n = \u200b\u200b2,260) and concluded that \u201cMost Like It Hot\u201d.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzvk102sfmur\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzvk102sfmur\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There seem to be&nbsp;<a href=\"https://www.healthline.com/health/depression/benefits-sunlight#_noHeaderPrefixedContent\"><u>significant health benefits</u></a>, though&nbsp;<a href=\"https://www.quora.com/Why-do-I-dislike-sunlight-so-much\"><u>some people dislike sunlight</u></a>.</p></div></li></ol>", "user": {"username": "OllieBase"}}, {"_id": "hfXy8EbyNTuBixjJf", "title": "Call for Cruxes by Rhyme, a Longtermist History Consultancy ", "postedAt": "2023-03-01T10:20:38.458Z", "htmlBody": "<p><i><strong>Edit (April 6, 2023): </strong>Submissions are currently paused due to the unexpectedly high amount of submissions already received.</i></p><p>TLDR; This post announces the trial period of<a href=\"https://rhymeresearch.org/\"><u> Rhyme</u></a>, a history consultancy for longtermists. It seems like longtermists can profit from historical insights and the distillation of the current state of historical literature on a particular question, both because of its use as an intuition pump and for information about the historical context of their work.&nbsp;<strong>So, if you work on an AI Governance project (research or policy) and are interested in augmenting it with a historical perspective, consider registering your interest and the cruxes of your research</strong><a href=\"https://forms.gle/GpeEFcH4MyDr2z7n6\"><strong><u> here.&nbsp;</u></strong></a><strong>&nbsp;</strong>During this trial period of three to six months, the service is free.&nbsp;</p><p><i>\"History doesn\u2019t repeat, but it rhymes.\" - </i>Mark Twain</p><p><strong><u>What Problem is Rhyme trying to solve?&nbsp;</u></strong></p><p>When we try to answer a complicated question like \u201chow would a Chinese regime change influence the international AI Landscape\u201d, it can be hard to know where to start. We need to come up with a hypothesis, a scenario. But what should we base this hypothesis, this scenario on? How would we know which hypotheses are most plausible? Game theoretical analysis provides one possible inspiration. But we don't just need to know what a rational actor would do, given particular incentives. We also need intuitions for how actors would act irrationally, given specific circumstances.</p><ul><li>Would we have thought of considering the influence of close familial ties between European leaders when trying to predict the beginning of the first world war? (Clark, 2014)</li><li>Would we have considered Lyndon B. Johnson's training as a tutor for disadvantaged children as a student when trying to predict his success in convincing congresspeople effectively? (Caro, 1982)</li><li>Would we have considered the Merino-Wool-Business of a certain diplomat from Geneva when trying to predict whether Switzerland would be annexed by its neighbouring empires in 1815? (E. Pictet, 1892).</li></ul><p>In summary: A lot of pivotal actions and developments depend on circumstances we wouldn\u2019t expect them to. Not because we\u2019d think them to be implausible, but because we wouldn\u2019t think of considering them. We need inspiration and orientation in this huge space of possible hypotheses to avoid missing out on the ones which are actually true.</p><p>In an ideal world, AI governance researchers would know about a vast amount of historical literature that is written with enough detail to analyse important decisions, as well as multiple biographies of the same people, so they see where scholars currently disagree. This strategy has two main problems: Firstly, the counterfactual impact these people could have with their time is potentially very big. Secondly, detailed historical literature (which is, often, biographies or primary sources) tends to be written for entertainment, among other things. Biographers have an interest in highlighting maybe irrelevant, but spicy details about romantic relationships, quirky fun jokes told by the person or the etymological origins of the name of a friend. This makes biographies longer than they\u2019d need to be for the goal of analysing the relevant factors in pivotal decisions of a particular person. It takes training to filter through this information to find the actually important stuff. Skills that require training are more efficiently done when a part of an ecosystem specializes in them. Rhyme is an attempt at this specialization.<br>&nbsp;</p><p><strong><u>Who could actually use this?&nbsp;</u></strong></p><p>The following examples should illustrate who could use this service:&nbsp;</p><ul><li>Alice is writing a report on the possibilities for the state of California to regulate possible AI uses. They wonder how big the influence of the Governor's advisors was in past regulation attempts of other technologies.</li><li>Bob wants a brief history of the EU\u2019s regulation of general-purpose technologies to have more context on the norms to follow.&nbsp;</li><li>Connor is trying to forecast how the American public might react to a weaponized AI used in combat against civilians.&nbsp;</li><li>Dora is trying to convince an Austrian and a German diplomat to cooperate on a specific piece of legislation and look at past successful strategies.&nbsp;</li><li>Edith is trying to forecast how the Chinese government might try to import talent to make faster progress on building better chip factories. They are looking for past cases where the Chinese government looked for talent and tacit knowledge in other countries in the past.&nbsp;<br>&nbsp;</li></ul><p><strong><u>Where is this going?&nbsp;</u></strong></p><p>Depends on the feedback! I\u2019d first like to test this in the field of AI Governance because of my own familiarity and the urgency of the problem. If there turns out to be enough of a demand for the service this project provides, I stay passionate about doing it and there is no fundamental flaw in the concept, I\u2019d be happy to continue this service or scale it to other areas of the longtermist landscape. (E.g. Biosecurity, nuclear security community building, cause-specific outreach).&nbsp;<br>&nbsp;</p><p><strong><u>About me:&nbsp;</u></strong></p><p>I am a recent graduate in history and philosophy, having done several independent research projects in history over the last 7 years (Some of them academic papers, most of them side projects). I mostly focused on the history of technology after 1800, but also trained in medieval and renaissance political history and its methodology. I care about preventing anthropogenic existential risks and improving democratic decisions. This is<a href=\"https://wordpress.com/page/larathurnherrbern.wordpress.com/6\"><u> </u></a><a href=\"https://larathurnherrbern.wordpress.com/\"><u>my website&nbsp;</u></a>if you would like to know more about me personally.</p><p>Questions? Contact me here:&nbsp;<a href=\"mailto:thurnherr.lara@gmail.com\"><u>thurnherr.lara@gmail.com</u></a> or comment on this post.&nbsp;</p><h3><strong><u>Sources</u></strong></h3><p>\u200b\u200bCaro, Robert A.: The Years of Lyndon Johnson: The Path to Power, New York 1982. P. 315.</p><p>Clark, Christopher: The Sleepwalkers: How Europe Went to War in 1914, 2014. Pp. 50.</p><p>Pictet, E.: Biographie, travaux et correspondance diplomatique de Charles Pictet de Rochemont , 1892. P.345.&nbsp;</p><p>&nbsp;</p><p><i>Thanks to </i><a href=\"https://twitter.com/buxwal\"><i>Violet Buxton-Walsh</i></a><i>, Elia Heer, Michel Justen and Hannes Thurnherr for feedback and support.&nbsp;</i><br>&nbsp;</p>", "user": {"username": "ArchivalLara"}}, {"_id": "WWhSCnw5xdrdKjHeS", "title": "Conference on EA hubs and offices, expression of interest", "postedAt": "2023-02-28T13:28:45.460Z", "htmlBody": "<p><strong>Express interest in attending&nbsp;</strong><a href=\"https://forms.gle/Njx638r6xm6hpJ8t8\"><strong><u>here</u></strong></a> - it should take 5 minutes or less to complete the form!</p><p>We want to host an <strong>interactive workshop/conference focused on EA hubs, offices, co-working spaces, and fellowships. </strong>The purpose of this post is to&nbsp;<a href=\"https://forms.gle/Njx638r6xm6hpJ8t8\"><u>gauge interest</u></a> and allow potential participants to actively shape the agenda to focus on the most relevant and beneficial topics.</p><p>By hosting a conference that brings together attendees with wide-ranging and overlapping experience launching/managing hubs, offices, and other place-based community nodes (as well as those actively planning to do so), we aim to:&nbsp;</p><ul><li>Facilitate coordination, collaboration and professional integration between significant individuals and organisations (both inside and outside of the EA community) with expertise in creating thriving spaces;</li><li>Create a comprehensive set of multi-format materials documenting previous learnings and best practices, such as podcasts, EA Forum articles, templates, and guides;</li><li>Use an emerging EA hub as a live case study to workshop real-life problems and considerations faced when designing and building new hubs; and</li><li>Propose and iterate theories of change to improve the strategic spatial growth of EA.&nbsp;</li></ul><p><strong>People who we think would be a great fit for the conference:</strong></p><ul><li>Professionals - people with professional background in designing spaces</li><li>Organisers - people who run or are interested in running offices/hubs in the future</li><li>Potential users - people who currently use such spaces or intend to use them in the future</li><li>People who have unique, informed viewpoints&nbsp; and can challenge what\u2019s discussed in a productive way</li></ul><p>The conference would be organised by&nbsp;<a href=\"https://forum.effectivealtruism.org/users/tereza-flidrova-1\"><u>Tereza Flidrova</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/users/peter-elam-1\"><u>Peter Elam</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/users/booritney\"><u>Britney Budiman</u></a>, and would be the first event to be organised by the emerging <a href=\"https://forum.effectivealtruism.org/groups/QCxLwgYR3ZSpPrxkE\">EA Architects and Planners group</a>.&nbsp;</p><p>Depending on the responses from the form, we will decide whether to submit applications for funding. If successful, we will make an official post announcing the conference and inviting participants to apply! We aim to run it this August/September, either online or in a physical location.</p><p>We are keen to hear comments or suggestions in the comments, via the form, or by contacting us directly.</p>", "user": {"username": "Tereza Fl\u00eddrov\u00e1"}}, {"_id": "BxgwGYFuKFu5ioBjs", "title": "Seeking input on a list of AI books for broader audience", "postedAt": "2023-02-27T22:40:13.749Z", "htmlBody": "<p>I'm still working on <a href=\"https://forum.effectivealtruism.org/posts/K2pognkwpcugRbdH9/fyi-i-m-working-on-a-book-about-the-threat-of-agi-asi-for-a\">my AI book</a> and part of that process is reading every other non-fiction, non-technical AI book (both to see what they say and see what else is out there).&nbsp;<br><br><strong>Do you have any additions to the list below?&nbsp;</strong> Preferably from the past 5 years and I'm generally not seeking textbooks or books that have academics as the main audience.&nbsp;<br><br>I have short reviews of most of the first 40 but they are scattered so perhaps I'll include them in a future post.&nbsp;</p><figure class=\"table\" style=\"width:0px\"><table><tbody><tr><td style=\"border:1px solid #000000;padding:2px 3px;vertical-align:bottom\"><strong>Book Title</strong></td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;border-top:1px solid #000000;padding:2px 3px;vertical-align:bottom\"><strong>Author</strong></td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;border-top:1px solid #000000;padding:2px 3px;vertical-align:bottom\"><strong>Year Published</strong></td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Singularity is Near</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Ray Kurzweil</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2005</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Wired for War: The Robotics Revolution and Conflict in the 21st Century</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">PW Singer</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2009</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Global Catastrophic Risks</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Ed: Bostrom and Cirkovic</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2011</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Superintelligence: Paths, Dangers, Strategies</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Nick Bostrom</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2014</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Pedro Domingos</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2015</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Life 3.0: Being Human in the Age of Artificial Intelligence</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Max Tegmark</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2017</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">AI Superpowers: China, Silicon Valley, and the New World Order</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Kai-Fu Lee</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2018</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Architects of Intelligence: The truth about AI from the people building it</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Martin Ford</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2018</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Warnings: Finding Cassandras to Stop Catastrophes</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Richard Clarke and RP Eddy</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2018</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Sentient Machine: The Coming Age of Artificial Intelligence</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Amir Husain</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2018</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Robot Rules: Regulating Artificial Intelligence</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Jacob Turner</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2018</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Human Compatible: Artificial Intelligence and the Problem of Control</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Stuart Russell</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2019</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The AI Does Not Hate You: The Rationalists and Their Quest to Save the World</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Tom Chivers</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2019</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Rebooting AI: Building Artificial Intelligence We Can Trust</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Gary Marcus, Ernest Davis</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2019</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Technology Trap: Capital, Labor, and Power in the Age of Automation</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Carl Benedikt Frey</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2019</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Artificial You: AI and the Future of Your Mind</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Susan Schneider</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2019</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Who's Afraid of AI?: Fear and Promise in the Age of Thinking Machines</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Thomas Ramge</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2019</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Alignment Problem: Machine Learning and Human Values</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Brian Christian</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2020</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Precipice: Existential Risk and the Future of Humanity</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Toby Ord</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2020</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">A Human Algorithm: How Artificial Intelligence Is Redefining Who We Are</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Flynn Coleman</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2020</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">T-Minus AI: Humanity's Countdown to Artificial Intelligence and the New Pursuit of Global Power</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Michael Kanaan</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2020</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Oxford Handbook of Ethics of AI</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">(Eds) M Dubber, F Pasquale, S Das</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2020</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Deepfakes: The Coming Infocalypse</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Nina Schick</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2020</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">AI Narratives: A History of Imaginative Thinking about Intelligent Machines</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Cave et al</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2020</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">AI 2041: Ten Visions for Our Future</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Kai-Fu Lee, Chen Qiufan</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2021</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Evil Robots, Killer Computers, and Other Myths: The Truth About AI and the Future of Humanity</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Steven Shwartz</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2021</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">A Vulnerable System: The History of Information Security in the Computer Age</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Andrew Stewart</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2021</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Kate Crawford</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2021</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Age of AI: And Our Human Future</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">D. P. Huttenlocher, Eric Schmidt, Henry Kissinger</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2021</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Man from the Future: The Visionary Life of John von Neumann</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Ananyo Bhattacharya</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2022</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Oxford Handbook of AI Governance</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Bullock et al (eds)</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2022</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Dignity in a Digital Age: Making tech work for all of us</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Ro Khanna</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2022</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The New Fire: War, Peace, and Democracy in the Age of AI</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Ben Buchanan and Andrew Imbrie</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2022</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">What We Owe The Future</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">William MacAskill</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2022</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Ethical Machines</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Reid Blackman</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2022</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Relationships 5.0: How AI, VR, and Robots Will Reshape Our Emotional Lives</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Elyakim Kislev</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2022</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Metaverse: And How It Will Revolutionize Everything</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Matthew Ball</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2022</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Chip War: The Fight for the World's Most Critical Technology</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Chris Miller</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2022</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Equality Machine</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Orly Lobel</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2022</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Power and Prediction: The Disruptive Economics of Artificial Intelligence</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Ajay Agrawal, Joshua Gans, Avi Goldfarb</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2022</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\"><strong>Upcoming</strong></td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Four Battlegrounds: Power in the Age of Artificial Intelligence Hardcover</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Paul Scharre</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">Feb. 28, 2023</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\"><strong>Possibilities</strong></td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Stoic Philosophy and the Control Problem of AI Technology: Caught in the Web</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Edward H. Spence</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2021</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Evolutionary Digital Environment Net: A Unified Compromise for the AI Control Problem and Climate Crisis</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">TR Simmons</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2021</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Shoshana Zuboff</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2019</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Artificial Intelligence Safety and Security</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Edited by Roman V. Yampolskiy (Multiple authors included like Kurzweil, Max Tegmark, Nick Bostrom)</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2018</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Scary Smart: The Future of Artificial Intelligence and How You Can Save Our World (didn't grab me)</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Mo Gawdat</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;text-align:right;vertical-align:bottom\">2021</td></tr><tr><td style=\"border-bottom:1px solid #000000;border-left:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">Ray Kurweils' book in 2024</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td><td style=\"border-bottom:1px solid #000000;border-right:1px solid #000000;padding:2px 3px;vertical-align:bottom\">&nbsp;</td></tr></tbody></table></figure>", "user": {"username": "Darren McKee"}}, {"_id": "zrSx3NRZEaJENazHK", "title": "Why I think it's important to work on AI forecasting", "postedAt": "2023-02-27T21:24:18.069Z", "htmlBody": "<p><i>Note: this post is a transcript of a talk I gave at EA Global: Bay Area 2023.</i></p><p>These days, a lot of effective altruists are working on trying to make sure AI goes well. But I often worry that, as a community, we don\u2019t yet have a clear picture of what we\u2019re really working on.</p><p>The key problem is that predicting the future is very difficult, and in general, if you don\u2019t know what the future will look like, it\u2019s usually hard to be sure that any intervention we do now will turn out to be highly valuable in hindsight.</p><p>When EAs imagine the future of AI, I think a lot of us tend to have something like the following picture in our heads.</p><p>At some point, maybe 5, 15, 30 years from now, some AI lab somewhere is going to build AGI. This AGI is going to be very powerful in a lot of ways. And we\u2019re either going to succeed in aligning it, and then the future will turn out to be bright and wonderful, or we\u2019ll fail, and the AGI will make humanity go extinct, and it\u2019s not yet clear which of these two outcomes will happen yet.</p><p>Alright, so that\u2019s an oversimplified picture. There\u2019s lots of disagreement in our community about specific details in this story. For example, we sometimes talk about whether there will be one AGI or several. Or about whether there will be a fast takeoff or a slow takeoff.</p><p>But even if you\u2019re confident about some of these details, I think there are plausibly some huge open questions about the future of AI that perhaps no one understands very well.</p><p>Take the question of what AGI will look like once it\u2019s developed.</p><p>If you asked an informed observer in 2013 what AGI will look like in the future, I think it\u2019s somewhat likely they\u2019d guess it\u2019ll be an agent that we\u2019ll program directly to search through a tree of possible future actions, and select the one that maximizes expected utility, except using some very clever heuristics that allows it to do this in the real world.</p><p>In 2018, if you asked EAs what AGI would look like, a decent number of people would have told you that it will be created using some very clever deep reinforcement learning in a really complex and diverse environment.</p><p>And these days in 2023, if you ask EAs what they expect AGI to look like, a fairly high fraction of people will say that it will look like a large language model: something like ChatGPT but scaled up dramatically, trained on more than one modality, and using a much better architecture.</p><p>That\u2019s just my impression of how people\u2019s views have changed over time. Maybe I\u2019m completely wrong about this. But the rough sense I\u2019ve gotten while in this community is that people will often cling to a model of what future AI will be like, which frequently changes over time. And at any particular time, people will often be quite overconfident in their exact picture of AGI.</p><p>In fact, I think the state of affairs is even worse than how I\u2019ve described it so far. I\u2019m not even sure if this particular question about AGI is coherent. The term \u201cAGI\u201d makes it sound like there will be some natural class of computer programs called \u201cgeneral AIs\u201d that are sharply distinguished from this other class of programs called \u201cnarrow AIs\u201d, and at some point \u2013 in fact, on a particular date \u2013 we will create the \u201cfirst\u201d AGI. I\u2019m not really sure that story makes much sense.</p><p>The question of what future AI will look like is a huge question, and getting it wrong could make the difference between a successful research program, and one that never went anywhere. And yet, it seems to me that, as of 2023, we still don\u2019t have very strong reasons to think that the way we think about future AI will end up being right on many of the basic details.</p><p>In general I think that uncertainty about the future of AI is a big problem, but we can also do a lot to reduce our uncertainty.</p><p>If you don\u2019t fully understand a risk, a simple alternative to working on mitigating the risk directly is just to try to understand the phenomenon better. In the case of AI, we could try to rigorously forecast AI, similar to how climate scientists try to build a model of the climate to better understand and forecast it.</p><p>That\u2019s essentially the agenda I\u2019m working on at <a href=\"https://epochai.org/\">Epoch</a>, a new organization that's trying to map out the future of AI. We work on foundational questions like: what will AI look like in the future, what effects will it have on the world, and when should we expect some of the most important AI-related things to happen?</p><p>What I want to do in this talk is outline three threads of research that we\u2019re currently interested in that we think are tractable to work on, and could end up being critical for piecing together the &nbsp;story of how AI will unfold in the future.</p><h1>Software vs. hardware progress</h1><p>The first thread of research I want to talk about is the relative importance of hardware versus software as a driver of AI progress.</p><p>This problem has been explored before. In the modern context of deep learning, probably the most salient analysis is from <a href=\"https://arxiv.org/abs/2005.04305\">Danny Hernandez and Tom Brown</a> at OpenAI in 2020. In their research, they re-implemented 15 open source machine learning models, adjusted some of the hyperparameters, and found a 44-fold decrease in the amount of compute required to reach the same performance as AlexNet on the ImageNet dataset since 2012.</p><p>Last year Epoch researchers <a href=\"https://arxiv.org/abs/2212.05153\">re-evaluated </a>progress on ImageNet using a different methodology employing scaling laws, and came to an even more extreme conclusion, showing that the amount of compute required to reach a certain level of performance halved roughly every nine months.</p><p>But even with these analyses, our basic picture of software progress in AI is unfortunately very incomplete. A big issue is that it\u2019s not clear how much software progress on ImageNet transfers usefully to the relevant type of tasks that we care about.</p><p>For example, it\u2019s easy to imagine that some ways of achieving better performance on ImageNet, like inventing the Adam optimizer, are general insights that speed up the entire field of AI. Whereas other things we can do, like pre-processing the ImageNet dataset, pretty much only provide improvement on ImageNet itself.</p><p>Plausibly, what matters most for forecasting AI is the rate of general software progress, which as far as I can tell, is currently unknown.</p><p>Here\u2019s another big issue with the existing research that tries to measure software progress that I think is even more important than the last problem. Compare two simple models of how software progress happens in AI.</p><p>In the first model of software progress, humans come up with better algorithms more-or-less from the armchair. That is, we leverage our intelligence to find clever algorithms that allow us to train AIs more efficiently, and the more intelligent we are, the better our algorithmic insights will tend to be.</p><p>In the second model of software progress, the way we make software progress is mostly by stumbling around in the dark. At various points in time, researchers experiment with different ways of training AIs with relatively little cleverness. Sometimes, these insights work, but most of the time, they don\u2019t. Crucially, the more experiments we perform, the more likely we are to get lucky and stumble upon an algorithm for training AI that\u2019s more efficient than anything that came before.</p><p>These stories are different in a very important way. In the first story, what allowed us to make software progress was by having a lot of intelligence. If this story is true, then as AI gets more advanced, we might expect software progress to accelerate, since we can leverage the intelligence of AI to produce more insights into algorithms, which makes training even more advanced AIs easier, which we can leverage to produce the next generation of AIs, and so on, in a feedback loop. I believe Tom Davidson refers to this scenario as a software singularity.</p><p>However, in the second story, hardware and labor are ultimately what enabled us to make software progress. By having more hardware available, researchers were able to try out more experiments, which enabled them to discover which algorithmic insights work and which ones don\u2019t. If this second story is true, then plausibly access to compute, rather than raw intelligence, is a more important driver of AI progress. And if that\u2019s true, then it\u2019s not totally clear whether there will be a rapid acceleration in software progress after we begin to leverage smart AI to help us develop even smarter AI.</p><p>These are massively different pictures of what the future might look like, and yet personally, I\u2019m not sure which of these stories is more plausible.</p><p>And the question of whether AI progress is driven by hardware or software is highly important to policy. If we cleared up confusion about the relative significance of hardware and software in AI, it would provide us information about what levers are most important to influence if we want to intervene on AI progress.</p><p>For example, if hardware is the main driver of AI progress, then access to hardware is the key lever we should consider intervening on if we want to slow down AI.</p><p>If, on the other hand, software dominates, then our picture looks quite different. To intervene on AI progress, we would probably want to look at where the smartest research scientists are working, and how we can influence them.</p><h1>Ubiquity of transfer learning</h1><p>Moving on, the second thread of research I want to talk about is about the ubiquity of transfer learning, and the relevance transfer learning will play in building future AI systems.</p><p>Transfer learning refers to the degree to which learning one task meaningfully carries over to a different task. For example, the degree to which learning psychology transfers to one\u2019s understanding of economics.</p><p>In the last several years, we\u2019ve witnessed an interesting trend in the field of machine learning. Rather than trying to get a model to learn a task by training it from scratch on a bunch of data collected for that task individually, it\u2019s now common to take a large transformer, called a foundation model, pre-train it on a very large, diverse corpus, and then fine-tune it on whatever task you\u2019re interested in.</p><p>The fundamental reason for the recent trend towards foundation models is that we found a way to leverage transfer learning successfully from very cheap sources of data. Pre-training on a large dataset, like the internet, allows the model to efficiently learn downstream tasks that we care about, which is beneficial when we don\u2019t have much data on the downstream task that we\u2019re targeting. This increase in data efficiency is ultimately determined by the amount of transfer between the pre-training data and the fine-tuning task.</p><p>Here\u2019s one of the biggest questions that I\u2019m interested in within this topic: to what extent will transfer learning alleviate important data bottlenecks in the future?</p><p>To make this question more concrete, consider the task of building general-purpose robots \u2013 the type that would allow us to automate a very large fraction of physical labor.</p><p>Right now, the field of robotics is progressing fairly slowly, at least relative to other areas of AI like natural language processing. My understanding is that a key reason for this relatively slow progress is that we\u2019re bottlenecked on high quality robotic data.</p><p>Researchers try to mitigate this bottleneck by running robotic models in simulation, but these results have not been very successful so far because of the large transfer gap between simulation and reality.</p><p>But perhaps in the future, this transfer gap will narrow. Maybe, just like for language models, we can pre-train a model on internet data, and leverage the vast amount of knowledge about the physical world encoded in internet videos. Or maybe our robotic simulations will get way better. In that case, robotics might be less data constrained than we might have otherwise thought. And as a result of pre-training, we might start to see very impressive robotics relatively soon, alongside the impressive results we\u2019ve already seen in natural language processing and image processing.</p><p>On the other hand, perhaps pre-training on internet data doesn\u2019t transfer well at all to learning robotics, and our robotic simulations won\u2019t get much better in the future either. As a consequence, it might take a really long time before we see general purpose robots.</p><p>In that case, we might soon be in a world with very smart computers, but without any impressive robots. Put another way, we\u2019d witness world class mathematician AIs before we got to see robotics that works reliably at the level of a 3 or 4 year old human.</p><p>Since it's plausible that dramatically increasing the growth rate of the economy requires general-purpose robotics, this alternative vision of the future implies that superintelligent AI could arrive many years or even decades before the singularity begins. In other words, there could be a lot of time between the time we get very cognitively advanced AI, and the time that things actually start speeding up at a rate way above the historical norm.</p><p>Knowing which of these versions of the future ends up happening is enormously useful for understanding the ways in which future AI might be dangerous, and how we should try to intervene. If AI will become superintelligent but unable to act in the physical world for a long time, that would mean we\u2019re facing a very different profile of risks compared to a situation in which AI soon outcompetes humans along every relevant axis more-or-less simultaneously.</p><p>I also think this question is very tractable to work on. Recall that the key factor that determines how easily we can alleviate bottlenecks in this framework is the degree to which training on a cheap pre-training distribution transfers knowledge to another distribution in which collecting data is expensive. As far as I can tell, this is something we can measure today for various distributions, using current tools.</p><h1>Takeoff speeds</h1><p>I\u2019ll move now to the third thread of research. The research thread is about takeoff speeds, and in particular whether we\u2019ll have a gradual takeoff with the economy slowly ramping up as AI gets more capable, or whether advanced AI will arrive suddenly without much warning, which will have the consequence of a single very intelligent system taking over the world.</p><p>Unlike the first two threads, my remarks about this topic will be relatively brief. That\u2019s because Tom Davidson is going to speak after me about <a href=\"https://www.alignmentforum.org/posts/Gc9FGtdXhK9sCSEYu/what-a-compute-centric-framework-says-about-ai-takeoff\">the new model</a> he just published that sheds light on this question. Instead of trying to explain his model before he does, I\u2019ll try to give some context as to why this subject is important to study.</p><p>In short, knowing how fast takeoff will be helps us to understand which AI-safety problems will be solved by default, and which ones won\u2019t be. A plausible rule of thumb is, the slower the takeoff, the more that will be solved by default. And if we don\u2019t know what problems will be solved by default, we risk wasting a lot of time researching questions that humanity would have solved anyway in our absence.</p><p>In <a href=\"https://www.alignmentforum.org/posts/hRohhttbtpY3SHmmD/takeoff-speeds-have-a-huge-effect-on-what-it-means-to-work-1\">a post from Buck Shlegeris</a> published last year, Buck argues this point more persuasively than I probably will here. Here\u2019s my summary of his argument.</p><p>If a fast takeoff happens, then the EA x-risk community has a very disproportionate effect on whether the AI ends up aligned or not. Broadly speaking, if there\u2019s a fast takeoff, our community needs to buckle down and solve alignment in time, or else we\u2019re doomed.</p><p>But if a slow takeoff happens, the situation we\u2019re in is vastly different. In a slow takeoff scenario, broader society will anticipate AI and it will be part of a huge industry. The number of people working on alignment will explode way beyond just this one community, as the anticipated consequences and risks of AI development will eventually be widely recognized.</p><p>That means that, in the slow takeoff case, we should try to focus on \u2013 not necessarily the most salient or even the hardest parts of AI safety \u2013 but on the parts that can\u2019t be done by the far more numerous researchers who will eventually work in parallel on this problem later.</p><h1>Concluding remarks</h1><p>I want to take a step back for a second and focus again on the broader picture of forecasting AI.</p><p>I often get the sense that people think the only interesting question in AI forecasting is just pinning down the date when AGI arrives. If that\u2019s your view, then it could easily seem like AI forecasting work is kind of pointless. Like, so what if AGI arrives in 2035 versus 2038? I actually totally agree with this intuition.</p><p>But I don\u2019t really see the main goal of AI forecasting as merely narrowing down a few minor details that we\u2019re currently not certain about. I think the type of work I just talked about is more about re-evaluating our basic assumptions about what to expect in the future. It\u2019s more about clarifying our thinking, so that we can piece together the basic picture of how AI will turn out.</p><p>And I don\u2019t think the three threads I outlined are anywhere near the only interesting questions to work on.</p><p>With that in mind, I encourage people to consider working on foundational AI forecasting questions as an alternative to more direct safety work. I think high-quality work in this space is pretty neglected. And that\u2019s kind of unfortunate, because arguably we have many tools available to make good progress on some of these questions. So, perhaps give some thought to working with us on our goal to map out the future of AI.</p>", "user": {"username": "Matthew_Barnett"}}, {"_id": "yLFjcQuz5XwXg7cHE", "title": "Call for Papers: ", "postedAt": "2023-02-27T19:11:43.480Z", "htmlBody": "<figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1677525105/mirroredImages/yLFjcQuz5XwXg7cHE/asiovxgokoz9yk5lzrxg.png\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1677525105/mirroredImages/yLFjcQuz5XwXg7cHE/cuwrzats8yjlvsiqukup.png 110w, https://res.cloudinary.com/cea/image/upload/v1677525105/mirroredImages/yLFjcQuz5XwXg7cHE/i0waki7xxe4alxjcqy5n.png 220w, https://res.cloudinary.com/cea/image/upload/v1677525105/mirroredImages/yLFjcQuz5XwXg7cHE/ysesob3qyy4piox3jqet.png 330w, https://res.cloudinary.com/cea/image/upload/v1677525105/mirroredImages/yLFjcQuz5XwXg7cHE/fonqqvq2flxdljscc88w.png 440w, https://res.cloudinary.com/cea/image/upload/v1677525105/mirroredImages/yLFjcQuz5XwXg7cHE/odzkkfrsjrmgxuovosan.png 550w, https://res.cloudinary.com/cea/image/upload/v1677525105/mirroredImages/yLFjcQuz5XwXg7cHE/saealdg150pwug1nwklp.png 660w, https://res.cloudinary.com/cea/image/upload/v1677525105/mirroredImages/yLFjcQuz5XwXg7cHE/iqei19yuhx7dwilx0ick.png 770w, https://res.cloudinary.com/cea/image/upload/v1677525105/mirroredImages/yLFjcQuz5XwXg7cHE/b1syh8lsdiisw8br572z.png 880w, https://res.cloudinary.com/cea/image/upload/v1677525105/mirroredImages/yLFjcQuz5XwXg7cHE/peh7w14eit9ir786f2ac.png 990w, https://res.cloudinary.com/cea/image/upload/v1677525104/mirroredImages/yLFjcQuz5XwXg7cHE/bskjt8ez88s8yk8hmmzq.png 1024w\"></figure><p><strong>Retos y soluciones efectivas para los problemas pol\u00edticos globales (see below for english)</strong></p><p>Es co-extensiva al perfeccionamiento de las formas de hacer pol\u00edtica la indagaci\u00f3n sobre apuestas institucionales y organizacionales que mejoren las condiciones de vida de las personas que componen la sociedad.&nbsp;</p><p>Que este perfeccionamiento se deba realizar a partir de criterios racionales, es una de las herencias del pensamiento moderno. El reto para nuestra sociedad \u2013 contempor\u00e1nea y globalizada \u2013 no solo implica la racionalizaci\u00f3n de las propuestas de transformaci\u00f3n para los problemas morales m\u00e1s acuciantes, sino la consideraci\u00f3n de su eficacia. Para ello, es fundamental establecer comparaciones dentro y entre contextos sociales espec\u00edficos que fomenten la creaci\u00f3n de soluciones innovadoras a los problemas pol\u00edticos de un mundo interconectado.</p><p>Este n\u00famero especial en la revista <i>Analecta Pol\u00edtica</i> busca ofrecer un espacio a apuestas y discusiones te\u00f3ricas que est\u00e9n orientadas a la soluci\u00f3n de <i>problem\u00e1ticas globales con el mayor impacto posible</i>. En este sentido, se buscar\u00e1 responder a retos te\u00f3ricos, metodol\u00f3gicos, y sociohist\u00f3ricos; discerniendo la relevancia que el contexto latinoamericano pueda tener respecto a estas cuestiones. Lo anterior, tanto en la indagaci\u00f3n sobre las discusiones y/o soluciones particulares que se pueden considerar para el contexto latinoamericano, as\u00ed como el aporte que dicho contexto pueda tener para otras latitudes.</p><p>Este n\u00famero, pues, incluye \u2013 mas no se limita \u2013 a las siguientes tem\u00e1ticas:</p><ul><li>Justicia global y transformaciones institucionales morales</li><li>Costo-efectividad y razonabilidad en la toma de decisiones institucionales</li><li>Evidencia y evaluaci\u00f3n de pol\u00edticas con enfoques globales y regionales</li><li>Caracterizaci\u00f3n y tratamiento de los riesgos globales contempor\u00e1neos y su inclusi\u00f3n en la agenda pol\u00edtica regional y global</li><li>Generaciones futuras y gobernanza de largo plazo</li><li>Expansi\u00f3n del c\u00edrculo moral a animales no humanos y la ampliaci\u00f3n de los sistemas jur\u00eddicos contempor\u00e1neos</li><li>Integraciones regionales y globales</li><li>Alineaci\u00f3n de la Inteligencia Artificial y Gobierno de datos</li></ul><p>Para mayor informaci\u00f3n, contactar al correo <a href=\"mailto:simon.ruizm@upb.edu.co\">simon.ruizm@upb.edu.co</a>&nbsp;</p><hr><p><strong>Challenges and effective solutions to global political problems</strong></p><p>The task of improving the ways of building better polities is coextensive to the research on institutional and organizational arrangements that improve the living conditions of the people that make up those societies. Such improvement should be based on rational criteria, as it is advocated by modern thought.&nbsp;</p><p>Our globalized society is thus challenged to both think about rational transformations for the direst moral issues of our time, as well as the adequate ponderation of their effectiveness. To do so, comparison within and between different social contexts could foster innovative solutions for the political problems of an interconnected world.</p><p>This special issue of Analecta Pol\u00edtica Journal of Research seeks to bring up a theoretical and practical discussion surrounding the solution of<i> global problems with the greatest possible impact</i>. In this sense, it will seek to address theoretical, methodological, and socio-historical challenges; acknowledging the possible relevance that the Latin American context may have with respect to those issues. The latter both to come up with discussion and solutions for the particular challenges faced in that context, as well as the contribution that such context might provide to some other latitudes.</p><p>The issue, therefore, includes \u2013 without being limited to \u2013 the following topics:&nbsp;</p><ul><li>Global justice and moral institutional transformations</li><li>Cost-effectiveness and reasonableness in institutional decision making</li><li>Evidence and evaluation of policies with global or regional implications</li><li>Characterization and treatment of contemporary global risks and their inclusion in the political agenda of public decision makers</li><li>Future generations and long-term governance</li><li>Expansion of the moral circle to nonhuman animals and its implication on contemporary legal systems.</li><li>Regional and global sustainable integrations for the development</li><li>Artificial Intelligence alignment and Data Governance</li></ul><p>Further information could be provided at&nbsp;<a href=\"mailto:simon.ruizm@upb.edu.co\">simon.ruizm@upb.edu.co</a></p>", "user": {"username": "Simon Ruiz-Martinez"}}, {"_id": "LzcbmjJCSefGm9nuk", "title": "How can we overcome the neglectness of non-EAs on EA research?", "postedAt": "2023-02-27T16:39:51.866Z", "htmlBody": "<p>I'm a high-school student considering research careers.\nAcademic research is an important field in most cause areas of EA. But there are some obstacles to being a researcher/professor:\nYou may not be able to go in a EA -related company. So we need to work with non-EAs.\nDue to the topics what EA wants to research is probably not what companies/government want you to research. It's like the basic research in biology is more neglected than the clinical research. EA research may seems less attractive to non-EAs. I have some worries on this:\n<a href=\"http://1.It\">1.It</a> may be harder for EAs to get a professor job in academics, so as promoting. If you don't have enough money, it'll be a big pressure.\n<a href=\"http://2.Is\">2.Is</a> it hard to apply enough funds for the EA topics, such as: animal welfare, space governance, AI safety/sentience. People may not want to invest onto this.\nHow do we overcome these obstacles?</p>\n", "user": {"username": "jackchang110"}}, {"_id": "eJohFMuTKbGsED5a9", "title": "Autonomy and Manipulation in Social Movements", "postedAt": "2023-02-27T16:27:59.390Z", "htmlBody": "<p>In this essay, I want to share a perspective I have been applying to evaluate movement-building efforts that have helped me understand a feeling that there is \u201csomething off\u201d. This is not supposed to be a normative judgement about people building social movements, just a lens that has changed the way I evaluate my own behaviour.</p><h2>Examples of optimisation in social movements</h2><p>Suppose you are running a retreat (a sort of themed 3-ish day group residential work trip) aimed at getting more people interested in a social movement. You mean well: the social movement seems like an important one and having more people interested in it should help more people down the line. You want to do a good job, to get as many people as interested in the movement as possible, so you try to work out how to optimise for this goal. Here are some things you might say:</p><ol><li><i>\u201cIn our experience, young people are more open-minded, so we should focus on reaching out to them\u201d.</i></li><li><i>\u201cWe should host the retreat in a remote location that\u2019s fun and free from distraction\u201d.</i></li><li><i>\u201cLet\u2019s try to build a sense of community around this social movement: this will make people feel more supported, motivated and inspired\u201d.</i></li><li><i>\u201cWe will host presentations and discussions for people at the retreat. People will learn better surrounded by people also interested in the ideas\u201d.</i></li></ol><p>Framed in this way, these suggestions sound fairly innocuous and are probably an effective way to get people to be more interested in the social movement. However, there seems to be something fishy about them. Here is each thing framed in another way.</p><ol><li><i>\u201cYounger people<strong> </strong>are more susceptible to our influence, so we should focus on reaching out to them\u201d.</i><a href=\"https://docs.google.com/document/d/1R2tD43A0984-RAAFWfKyVOTUJY9hZU_9d18Q6sycMKM/edit#bookmark=id.4ya1b6q1k8mh\"><i><sup>1</sup></i></a></li><li><i>\u201cLet's host the event in a remote location that separates people from other social pressures, and the things that ground them in their everyday lives\u201d.</i></li><li><i>&nbsp;\u201cLet\u2019s build strong-social bonds, dependent on believing in the ideas of this movement, increasing the cost of changing their values down the road\u201d.</i></li><li><i>\u201cWe can present the ideas of the movement in this unusual social context, in which knowledge of the ideas corresponds directly to social status: we, the presenters, are the most knowledgable and authoritative and the attendees who are most \u2018in-crowd\u2019 will know most about the ideas\u201d.</i><a href=\"https://docs.google.com/document/d/1R2tD43A0984-RAAFWfKyVOTUJY9hZU_9d18Q6sycMKM/edit#bookmark=id.qsk7e851r8dn\"><i><sup>2</sup></i></a></li></ol><p>Either set of framings can describe <i>why</i> the actions are effective. In truth, I think the first set is overly naive, and the second is probably too cynical. Further, I understand that there are plenty of settings in which the cynical framings could apply, and they could be hard to avoid. That said, I think they point to useful concepts that can be useful \u201cflags\u201d to check one\u2019s behaviour against\u2026</p><h2>How I understand autonomy and manipulation</h2><p>I want to put forward conceptions of \u201cautonomy\u201d and \u201cmanipulation\u201d. Although I don\u2019t claim these capture exactly how every person uses the words, or that they refer to any natural kind, I do think having these concepts available to you is useful. Since these concepts were clarified to me, I have frequently used them as a perspective to look at my behaviour, and frequently they have changed my actions.&nbsp;</p><p>As I understand it, a person\u2019s choice or action is more <strong>autonomous</strong> when they are able to make it via a considered decision process in accordance with their values.<a href=\"https://docs.google.com/document/d/1R2tD43A0984-RAAFWfKyVOTUJY9hZU_9d18Q6sycMKM/edit#bookmark=id.sr10nq8rz3vp\"><sup>3</sup></a> The most autonomous decisions are made with time for consideration, accurate, sufficient and balanced information, and free from social or emotional pressure. Here is an example of an action that is less autonomous:</p><ol><li>I don\u2019t act very autonomously when I scroll to watch my 142nd TikTok of the day. Had I distanced myself and reflected, I would have chosen to go for a walk instead, but the act of scrolling is so fast that I never engaged my decision process.</li></ol><p>Similarly, as I understand it, a person/behaviour/mechanism is <strong>manipulative</strong> when they influence a person\u2019s action in a way that reduces their autonomy: i.e. when they subvert or hijack the decision-making process. It is worth saying upfront that I am using a descriptive, rather than normative conception of manipulation: I am not claiming that manipulation is always impermissible, or even that there is always at least some wrong in manipulation that must be outweighed. I do, however, think that whether some act is manipulative strongly correlates with whether that act causes some external harm.<a href=\"https://docs.google.com/document/d/1R2tD43A0984-RAAFWfKyVOTUJY9hZU_9d18Q6sycMKM/edit#bookmark=id.598abztzi6as\"><sup>4</sup></a></p><p>Here are some examples of the different ways one can be manipulative:</p><ul><li>TikTok could be said to be manipulative because it (intentionally) impedes me from engaging my decision-making process.<a href=\"https://docs.google.com/document/d/1R2tD43A0984-RAAFWfKyVOTUJY9hZU_9d18Q6sycMKM/edit#bookmark=id.2xcturla5hb1\"><sup>5</sup></a></li><li>Lying can be manipulative because one influences the outcome of the decision-making process in my favour by providing false information.</li><li>Picking and choosing certain truths can also be manipulative: for example, if I don\u2019t want someone to take a flight, I could tell them about how many people have died in plane crashes (without telling them how small that number is relative to how many people have flown).</li></ul><p>Note that I don\u2019t think people <i>have</i> to be aware their behaviour is manipulative for it to be so: if one responds sulkily every time their flatmate asks them to help with the washing up, this might influence that person to stop asking. However, I do think more manipulative behaviour is usually more intentional.</p><p>I also want to note that not all forms of influence are manipulative:</p><ul><li><i>Governments can influence citizens to not buy cigarettes by presenting statistics about how bad smoking is for life expectancy.&nbsp;</i></li></ul><p>This is a form of influence, but does not, to me, feel manipulative. That could be because the information provided is true, and not some cherry-picked portion of the truth. It may also be because it helps people make choices that they would endorse on reflection. To me, this is an example of an influential but not manipulative intervention.</p><p>Similarly, not all forms of manipulation are obviously harmful:</p><ul><li><i>Governments can influence citizens to not buy cigarettes by putting visceral images of tumours on cigarette packets.</i></li></ul><p>This form of influence is arguably manipulative, it is <i>not</i> just providing new information to smokers (that smoking can cause tumours) but is intended to create a feeling of disgust that prevents the person from buying the cigarette. This seems to bypass the person\u2019s decision-making process, but in a way that is arguably in their best interest. This could be seen as a form of manipulation that is permissible.</p><p>The conception of \u201cmanipulation\u201d I\u2019m using is not, therefore, normative: manipulation isn\u2019t inherently bad. However, noticing that your behaviour could be described as manipulative should make you extremely suspicious that you are doing something wrong (perhaps you think this <i>act</i> of manipulation is permissible, but you wouldn\u2019t endorse a rule that allows manipulation). I want to suggest that a lot of movement-building practices could be seen as manipulative and that this should give us pause for reflection.</p><h2>Movement building and manipulation</h2><p>I think that a lot of the things that are fishy about retreats are that they (unintentionally) use means other than reason to convince people of a worldview. The biggest thing is social pressure: the whole environment is designed such that internalising/understanding orthodox ideas are socially rewarded. Other aspects of the retreat are designed in a way that makes people more susceptible to this social pressure: a focus on young people, and placing people in a detached environment away from things that might otherwise ground them. I don\u2019t think anyone has decided to be manipulative, but by optimising for people internalising certain beliefs, an arguably manipulative structure has been decided on.</p><h2>So what?</h2><p>Let\u2019s assume that, from this particular perspective, certain movement-building practices really are manipulative. Does that mean they should never be used? Or do the ends of certain social movements justify the means of manipulation? Over application of this perspective can be paralysing, once you start to look, most actions have myriad influences over others and many of these can feel at least a tiny bit manipulative. Perhaps sometimes there is no way to achieve our goals without being manipulative and I don\u2019t want to make any hard prescriptions about what is or is not permissible here since the context of an action is so important. For example, I probably would endorse putting graphic images on cigarette packets, even if I think that is manipulative. Although sometimes direct trade-offs may present themselves, I suggest that in many cases, an intervention that is manipulative can be switched out for something that promotes people\u2019s autonomy.</p><h2>Towards movement building that promotes autonomy: advocacy and access</h2><p>Movement building necessarily seeks to influence people towards putting their energy towards the movement. However, we should seek to do this in ways that empower people: by promoting their autonomy rather than by manipulating them. Further, if the ideas of your social movement really are compelling, then (hopefully) appealing to reason will be successful!</p><p>One such method of pro-autonomy movement building is what I want to refer to as <strong>\u201cadvocacy\u201d</strong>. If a person has never heard of some social movement, they cannot decide to help it. By presenting them with the idea, you are increasing their options without forcing them to do anything. This can be taken further by making balanced and nuanced information available to people: resources and spaces to discuss ideas should be available to those seeking them out. Here, again, autonomy might help point us towards some difference between advocacy and propaganda as forms of education: propaganda forces information onto people that is misleading and biased. The line between these two cases is often nuanced and depends on how cynically or naively you frame the question. For example, I think giving out free books can fall either way, depending on the specific implementation and framing. However, there do seem to be some interventions that are broadly useful, such as making balanced statistics or rigorous arguments publicly available.&nbsp;</p><p>Another method of movement building that promotes autonomy is increasing <strong>\u201caccess\u201d</strong>. One way to do this is to ensure the space you create is welcoming and comfortable to everyone. For example, you could empower people who are less confident/dominant in group discussions by ensuring everyone is given a chance to be heard. Similarly, one could decrease the underrepresentation of certain groups or aim to mitigate the consequences of underrepresentation (for example, by reducing the homogeneity of the authors of readings). Finally, one could help people who are less confident to explore and publish their ideas. In some movements, there is an overrepresentation of the ideas of people who have the confidence or audacity to believe they are right where everyone else is wrong. Each of these interventions will help out the social movement, but by removing barriers and promoting autonomy.</p><p>Even if you don\u2019t care about autonomy, I think both advocacy and access could also help to improve group epistemics. Making balanced information available to people, rather than pushing some convincing arguments written by a small group of experts onto them, could reduce an implicit feeling that there are some \u201cright answers\u201d. It forces people to engage with questions themselves, rather than deferring to an orthodox set of beliefs, and encourages them to make more suggestions. Similarly, making the movement more accessible and discussions more equal, should increase the presence of cognitive diversity and the inclusivity of deliberation, helping the group as a whole to generate and evaluate a wider range of beliefs (see <a href=\"https://www.zotero.org/google-docs/?7SYLTo\">Landemore (2013)</a>&nbsp; for more discussion).&nbsp;</p><h2>Conclusion</h2><p>In this essay, I have introduced (but not defended) conceptions of autonomy and manipulation that I believe are useful for understanding movement building. I applied these concepts to look at \u201cretreats\u201d and argued that they could be seen as manipulative. I then used these concepts to motivate forms of movement building that promote autonomy.</p><h2>Appendix: assumptions implicit in this essay</h2><ol><li>This essay may assume that there are more manipulative and more neutral ways to present information. This sounds suspiciously like claiming information can be presented in a less political or biased way.&nbsp;</li><li>That there are some true \u201cvalues\u201d a person would have if they had \u201call of the information\u201d and which they would \u201cendorse on reflection\u201d. Although a significant assumption, I think much of ethics seems to crumble if we deny people as the legitimate source of moral facts about themselves.</li></ol><h2>Bibliography</h2><p><a href=\"https://www.zotero.org/google-docs/?MvMT63\">Landemore, H. (2013). <i>Democratic reason: Politics, collective intelligence, and the rule of the many</i>. Princeton University Press. http://www.jstor.org/stable/j.ctt1r2gf0</a></p><p><a href=\"https://www.zotero.org/google-docs/?MvMT63\">Noggle, R. (2022). The ethics of manipulation. In E. N. Zalta (Ed.), <i>The Stanford encyclopedia of philosophy</i> (Summer 2022). Metaphysics Research Lab, Stanford University. https://plato.stanford.edu/archives/sum2022/entries/ethics-manipulation/</a></p><p><a href=\"https://www.zotero.org/google-docs/?MvMT63\">V\u00e9liz, C. (2020). <i>Privacy is power</i>. London, UK: Penguin (Bantam Press).</a></p><h2>Endnotes</h2><p>1.&nbsp; One reason this perspective might be particularly uncharitable is that young people are more also \u201copen-minded\u201d in terms of changing career direction because they have (on average) fewer financial responsibilities.</p><p>2.&nbsp; Note that presentations and discussions can be set up to avoid this effect for example, by contextualising things as highly uncertain or by encouraging people to question sources.&nbsp;</p><p>3.&nbsp; There is some ambiguity with what \u201cvalues\u201d refers to. I roughly mean something \u201chigher-order\u201d than momentary preferences. For example, the values I refer to wouldn\u2019t change if I learnt to like a new genre of music. Similarly, if I read a practical ethics paper that made me evaluate eating meat differently, this wouldn\u2019t be changing my values, but helping me understand them better. The existence of these values is a significant and ungrounded assumption of this essay (as stated in the appendix).</p><p>4.&nbsp; Again, I am not claiming that this concept is what everyone means by \u201cmanipulation\u201d, nor that everyone takes \u201cmanipulation\u201d to be a descriptive term. I am just providing <i>some </i>useful concept. If you are interested in a thorough, analytic account, see <a href=\"https://www.zotero.org/google-docs/?hitU47\">Noggle (2022)</a>.</p><p>5.&nbsp; On the other hand, giving someone the time and space they need to make a decision can help them do so freely. One example of this is given by a French law, that requires a person to spend five minutes alone in a room before deciding to request political sanctuary <a href=\"https://www.zotero.org/google-docs/?sHfh3s\">(V\u00e9liz, 2020, p. 36)</a>.</p>", "user": {"username": "SeaGreen"}}, {"_id": "LDiStRpF2HSvbgPks", "title": "Milk EA, Casu Marzu EA", "postedAt": "2023-02-27T14:14:50.002Z", "htmlBody": "", "user": {"username": "Jeff_Kaufman"}}, {"_id": "2ZpyyNzShd8ZcXzyy", "title": "Every Generator Is A Policy Failure [Works in Progress]", "postedAt": "2023-02-27T10:56:32.788Z", "htmlBody": "<p>This article was spun out of a shallow investigation for Open Philanthropy; I thought it might be of interest to GHW folks.</p>", "user": {"username": "Lauren Gilbert"}}, {"_id": "ZfDBQDLJqi43DjMaB", "title": "French 2d explainer videos on longtermism (english subtitles)", "postedAt": "2023-02-27T09:00:30.673Z", "htmlBody": "<p>Hey there, I'm a member of Effective Altruism France and my local group in Sydney, Australia.&nbsp;</p><p>I'm also the co-founder of &nbsp;\"<a href=\"https://www.youtube.com/@the-flares\">The Flares</a>\", a French non-profit focusing on the future of humanity through communication. We produce videos and podcasts on topics such as space, AI, X-risks and sustainability among others. We are trying to bring important issues regarding the future to a general audience, especially content that is widespread in English but not necessarily in French. One way is to invite English-speaking experts to our podcast and caption the whole conversation in French. Anders Sandberg, Stuart Armstrong, Otto Barten are a few examples of previous guests, and we have a long list of potential guests we want to invite.</p><p>In December 2021, I received support from Open Philanthropy to produce 3 animated videos on longtermism, in French, to be published on our YouTube channel. It was part of an outreach mission to produce EA-related content in major world languages other than English.</p><p>I took the role of creative producer and scriptwriter and went for a 2d animation style. An illustrator/animator, sound designer/music composer, and a voice-over artist completed the team.</p><p>After 12 months or so, I'm pleased to have published the 3 episodes and would like to share them here as well if you are interested. The content is in French, but I have included English captions that can be activated via the YouTube player.</p><p>Here is the <a href=\"https://youtube.com/playlist?list=PLAlyjvY0tGgKlitvhLEEbdIDuB2OVAC71\">playlist </a>of the series.</p><p>Of course, feel free to give me any feedback :)</p><p>Thank you</p>", "user": {"username": "Gaetan_Selle"}}, {"_id": "5s8fMBGq8JjebJ2mz", "title": "Help GiveDirectly beat \"teach a man to fish\"", "postedAt": "2023-02-27T08:55:05.570Z", "htmlBody": "<figure class=\"table\"><table style=\"background-color:rgb(255, 255, 255)\"><tbody><tr><td style=\"padding:0px 20px 20px\">Update March 13th: <a href=\"https://twitter.com/GiveDirectly/status/1635287698490662920\">vote for the finalists here</a><br><br>We need your creative ideas to solve a problem: how to convince the world of the wisdom of giving directly. <strong>Will you submit to our proverb contest?&nbsp;</strong></td></tr></tbody></table></figure><figure class=\"table\"><table style=\"background-color:rgb(255, 255, 255)\"><tbody><tr><td style=\"padding:20px\"><p>Hi, we need your creative ideas to solve a problem: how to convince the world of the wisdom of giving directly. <strong>Will you submit to our proverb contest?&nbsp;</strong><br><br>The most common critique of giving cash without conditions is a fear of dependency, which comes in the form of: \u201c<i>Give a man a fish, feed him for a day. Teach a man to fish, feed him for a lifetime.</i>\u201d</p><p>&nbsp;</p><p>We\u2019ve tried to disabuse folks of this paternalistic idea by showing that often people in poverty know how to fish but <a href=\"https://d10fhb04.na1.hubspotlinks.com/Ctc/W2+113/d10fHb04/VVKj6N84Y1fTV6ZL1N8vMMFFW3Dl4Sm4XmPbyN4HzmfZ3q90JV1-WJV7CgQ8PW2vf1T-1Mm0zNW1Yvf7c2xB0-9W6JSH1_6LrJr9VSjbwD3YJ_vBW7vSm269dgBVFW8VGc8j5NxSFSW93F5_c1YwKqrW68vWMQ68-3WWW8LJqLC4X_QWYV4Yyb16D0WPcW8-y2GB4MxnVGW1QpRK7875RChW2pHdRC5LVgYXW5KCnD994_blYN2zKkbBYQlgrW6MrGlk2F7jMbW7H8L5-7D0zVVW2Zt3Dh1JG96QW4nb8qx1TNWxtV3hdxY5NJJmSW46L2xd55qrlhW6RxpZS40phnVW3R07m_8F8_1nW4176Bn10lTwBW4GmZQR5sQJFrW7y23qN7zw043W7MdsLz6NlCx2W2rBlmF8q6pZ73j-m1\">cannot afford the boat</a>. Or they don\u2019t want to fish; they want to <a href=\"https://d10fhb04.na1.hubspotlinks.com/Ctc/W2+113/d10fHb04/VVKj6N84Y1fTV6ZL1N8vMMFFW3Dl4Sm4XmPbyN4HzmfZ3q90JV1-WJV7CgLkzW5PLwds5wGL_LW3hfMJ45GmY7VW1Q9Rtz7Ssw2zW5CcJlt6Njf8nW19pwyd8phB_WW3yXpSL6W8G2RW96GsDP38qWfLW5wL7zN8VGG8vW5T3KQ-7FKyppW6m_PJL7zJt2mW471rHx8PNPfhW3WT0C55Jg6JCW2J6HM64vcm5wW6s-jDt5_8knfW2t0-Cx7RksC8TN0kZ2KF_BJVjvb_c9j9yBzW2H-N-287xvXbV23fqT6X5-jJN6VLnCQmGx5_W6JxJ_55Qr3fyN66kcQmzk1W_W7jjzkT3pWB9gW3dRP0w3_-GtgW5bkKvc8X0-lVW5gCJ6z5TqmcxV1LsR_5cd5WkW41DBCR3pkMF-3fgN1\">sell cassava</a>. Also, we\u2019re not giving fish; we\u2019re giving money, and years after getting it, people were <a href=\"https://d10fhb04.na1.hubspotlinks.com/Ctc/W2+113/d10fHb04/VVKj6N84Y1fTV6ZL1N8vMMFFW3Dl4Sm4XmPbyN4HzmfG3q90pV1-WJV7CgGJgW4cQWZj4_VhPyW6HX3fb1k6hVpN8L0jGssGvKzW4pT6MY4XtG2pW1H_6X_51prQpW1LMFmf5WBjjpW7B98j43TcFYqW1XtXsp8JGwxzW7y5Tvq1GrfT9W93m-CS5nbwtmW4Rd3vS2fVvqLN6KtstTztJMNW3t8Knb33_k-cW9gH9F419KQvGW6wsm4r8Hkg0zW1sTK8H7kT3lpW22_WCH4cvZN_W6XQWSH5085NDW7lbf5z1qxKJFW2r9prJ9ljGmTW5fbj9Y8KyY1fN5PSKdkPB47cW8vDRX335j8XMW99glt63bdZS_W5SbVnF1G053vW7XC9ns55BDz83hnv1\">better able to feed themselves</a>. Oh, and even if you do teach them skills, it can. be <a href=\"https://d10fhb04.na1.hubspotlinks.com/Ctc/W2+113/d10fHb04/VVKj6N84Y1fTV6ZL1N8vMMFFW3Dl4Sm4XmPbyN4Hzmdt5nKvpV3Zsc37CgFHfW4BhlzM1CRQTnW68yCtc8QH02BW8CWZP55bHF3lW2qskxL6105mPW4-Sglb73Zfd6W6WW6Wb2zRZJMW8lKCbW2rNlk7W2Gjrcn1_lnbCN4YH_zgMWtyKVy3L7k3bMVWSW523YX264XFPkVFlLXp1nHfbBW2fQFH16SvrrZW54TYSP22M4cwW477SND7HgS-3W6WjT0R1pWkWLN6sjPsl97tx6W4hVSKV3Rf4T5W3zp-2c7SFPLXW5KsFKg1wh4NnW7y1MBQ778r6dW33dtgJ4K5rH1N91N_0_gSfDpW3krYv13sBdBkV6nVsl31Dsc7W7x42Rk7gcbWyW1jx9qn5L11mTW8KXSCL6bzB1gW5-D00h92rLQHW4F9x2y4KsnpyW8VDS2Y6hK51XN8gl24k6DWTbW31xL5w65D--hN6v2vVCB0NwW3cp91\">less effective than giving cash</a>. Phew!</p><p>&nbsp;</p><p>Yet, despite our efforts, the myth remains.&nbsp;</p><p>&nbsp;</p><p>The one thing we haven\u2019t tried: fighting proverb with (better) proverb. That\u2019s where you come in. We\u2019re crowdsourcing ideas that capture the dignity and logic of giving directly.&nbsp;<br><br><a href=\"https://forms.gle/UDmFopE5dq6mJL126\">SUBMIT YOUR DIRECT GIVING PROVERB</a> (and add your ideas to the comments too!)<br>&nbsp;</p><p>The best suggestions are not a slogan, but a saying \u2014 simple, concrete, evocative (<a href=\"https://d10fhb04.na1.hubspotlinks.com/Ctc/W2+113/d10fHb04/VVKj6N84Y1fTV6ZL1N8vMMFFW3Dl4Sm4XmPbyN4HzmfG3q90pV1-WJV7CgFZSW6myWQ13NfywfW8V3qN13McDGpVq9Xz43HKw0VW36ZPG789BdpPW4j6ZMx5hWsYFW7xcJg07R19XbW41NsQ05PrF9sW32XTP42d3-99W26zXmh2bnDX_W2S7J-53nzQ7-W8zLQc13mMFXSW1dy2S85Qs0n-Lcc0jW-dxZN1NbTQ-SSBKgW1D25yC7ll44xW3GHpr873LV0BW5qLWyr7Ddp39N85sQ36GbjDnW7mfF1n5ss2z5W7tGw_T3Bl1c-W4gQc8w6mtKW6W4DxdJQ7Tg1NCVQ32C_6-Js5-W5sdZwX20GS78W6YLvgf7W7nNDW4S6mLY8Jp6T032kL1\">e.g.</a>). Submit your ideas by next <strong>Friday, March 3</strong>, and then we'll post the top 3 ideas on <a href=\"https://d10fhb04.na1.hubspotlinks.com/Ctc/W2+113/d10fHb04/VVKj6N84Y1fTV6ZL1N8vMMFFW3Dl4Sm4XmPbyN4Hzmfm3q905V1-WJV7Cg-MCW26pXRp8zfNT0VmXDMB4qW5Z2W7-DvSG6DmgPkW8-HP1M31xqFKW7h8C6J1K_DvQW5r1hhl1m6K1DW7T9rX1822HRMW20NWVy18x6VVW1RYJS_1ksFF_W35RVJW8z0GPhW235vlY29_0D8W937JCp2ypbS3W9l6_b_8qkpCcW4fc9qm6T6gy_Vg_vdT8s2LC3W2snQh41nFq9vW9dqCk867bKggW5MSq3m4wzZcgW2vGL4n1NyfVnW7HlQMN8410g7W3JGblg6sV8HRW5kt6f316vn_8W8bcR1Z4gGpJTMnht27rN9P23ksK1\">Twitter</a> for people to vote on the winner.</p><p>&nbsp;</p><p>The author of the winning adage will win a video call with a GiveDirectly staff member to learn more about our work one-on-one. Not feeling creative? Share with your friends who are.<br>&nbsp;</p></td></tr></tbody></table></figure>", "user": {"username": "givedirectly"}}, {"_id": "bEJ6SyrkSF45B2LWZ", "title": "EA & LW Forum Weekly Summary (20th - 26th Feb 2023)", "postedAt": "2023-02-27T03:46:39.330Z", "htmlBody": "<p><i>Supported by Rethink Priorities</i><br><br>This is part of a weekly series summarizing the top posts on the EA and LW forums - you can see the full collection <a href=\"https://forum.effectivealtruism.org/s/W4fhpuN26naxGCBbN\">here.</a> The first post includes some details on purpose and methodology. Feedback, thoughts, and corrections are welcomed.</p><p>If you'd like to receive these summaries via email, you can subscribe <a href=\"https://easummaries.substack.com/?r=1p817z&amp;s=w&amp;utm_campaign=pub&amp;utm_medium=web\">here.</a></p><p><strong>Podcast version</strong>: Subscribe on your favorite podcast app by searching for 'EA Forum Podcast (Summaries)'. A big thanks to Coleman Snell for producing these!</p><h1><br><br>Philosophy and Methodologies</h1><p><a href=\"https://forum.effectivealtruism.org/posts/WB8yLjDDNuHaGdotM/make-rcts-cheaper-smaller-treatment-bigger-control-groups\"><u>Make RCTs cheaper: smaller treatment, bigger control groups</u></a></p><p><i>by Rory Fenton</i></p><p>When your intervention is expensive relative to data collection, you can maximize statistical power for a given cost by using a larger control and smaller treatment group. The optimal ratio of treatment sample to control sample is the square root of the cost per treatment participant divided by the square root of the cost per control participant.</p><p>&nbsp;</p><h1>Object Level Interventions / Reviews</h1><h2>AI</h2><p><a href=\"https://forum.effectivealtruism.org/posts/i6btyefRRX23yCpnP/what-ai-companies-can-do-today-to-help-with-the-most\"><u>What AI companies can do today to help with the most important century</u></a></p><p><i>by Holden Karnofsky</i></p><p>Grounded suggestions (ie. more than one AI lab has made a serious effort at each suggestion) for major AI companies to help the most important century go well:</p><ol><li>Prioritize alignment research, strong security, and safety standards (eg. figuring out what behaviors are dangerous, and what to do if they see them).</li><li>Avoid hype and acceleration (eg. publish fewer flashy demos or breakthrough papers).</li><li>Prepare for difficult decisions via setting up governance, employee and investor expectations to allow for decisions that aren\u2019t profit-maximizing.</li><li>Balance the above with conventional / financial success (so they stay relevant).</li></ol><p>Holden is less excited about the following interventions labs sometimes take: censorship of AI models, open-sourcing AI models, and raising awareness of AI with governments and the public.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/zRn6aQyD8uhAN7qCc/sam-altman-planning-for-agi-and-beyond\"><u>Sam Altman: \"Planning for AGI and beyond\"</u></a></p><p><i>by LawrenceC</i></p><p>Linkpost for this blog post from OpenAI\u2019s CEO Sam Altman on their AGI roadmap. Key points include:</p><p>Goal</p><ul><li>OpenAI\u2019s mission is to ensure artificial intelligence benefits all humanity. They operate as if risks are existential and want to successfully navigate these.</li><li>They think short timelines and slow takeoff seem like the safest scenario, since it minimizes compute overhang and gives maximum time to empirically solve safety and adapt to AGI.</li></ul><p>Short-term Strategy</p><ul><li>In the short term, OpenAI intends to create and deploy successively more powerful systems in the real world to allow a tight feedback loop and society to adapt.<ul><li>As these get closer to AGI, they will become increasingly cautious. If the balance of pros and cons shifts, they will significantly change the deployment approach.</li></ul></li><li>They want to create new alignment techniques, and believe capabilities progress is necessary for this.</li><li>They want to start a global conversation on how to govern AI systems, fairly distribute their benefits, and fairly share access.</li><li>They have concrete measures in place to allow safety-oriented behavior eg. capping shareholder returns, governance by a non-profit that can override for-profit interests, and a clause in their Charter to not race in late-stage AGI.</li></ul><p>Things they want to see</p><ul><li>Independent audits before releasing new systems (they\u2019re releasing more info on this later in the year).</li><li>Public standards on when an AGI effort should stop a training run, and how to decide if a model is safe to release, when to pull from production etc.</li><li>Government having oversight on training runs above a certain scale.</li><li>Coordination between AGI efforts to slow down at critical junctures (eg. if the world needs time to adapt).</li></ul><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/PE22QJSww8mpwh7bt/agi-in-sight-our-look-at-the-game-board\"><u>AGI in sight: our look at the game board</u></a></p><p><i>by Andrea_Miotti, Gabriel Alfour</i></p><p>The authors share their view that AGI has a significant probability of happening in the next 5 years, given progress on agents, multimodal models, language tasks, and robotics in the past few years. However, we are still early on the path to safety eg. not knowing how to get language models to be truthful, not understanding their decisions, optimizers yielding unexpected results, RLHF / fine-tuning not working very well, and not knowing how to predict AI capabilities.</p><p>Various players are racing towards AGI, including AdeptAI (training a model to \u201cuse every software tool and API in the world\u201d), DeepMind whose mission is to solve intelligence and create AGI, and OpenAI, who kickstarted further race mechanics with ChatGPT.</p><p>This all means we\u2019re in a bad scenario, and they recommend readers ask lots of questions and reward openness. They\u2019re also hopeful narrower sub-problems of alignment can be achieved in time eg. ensuring the boundedness of AI systems.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/8F4dXYriqbsom46x5/pretraining-language-models-with-human-preferences\"><u>Pretraining Language Models with Human Preferences</u></a></p><p><i>by Tomek Korbak, Sam Bowman, Ethan Perez</i></p><p>Author\u2019s tl;dr: \u201cIn&nbsp;<a href=\"https://arxiv.org/abs/2302.08582\"><u>the paper</u></a>, we show how to train LMs (language models) with human preferences (as in reinforcement learning with human feedback), but during LM pretraining. We find that pretraining works much better than the standard practice of only finetuning with human preferences after pretraining; our resulting LMs generate text that is more often in line with human preferences and are more robust to red teaming attacks. Our best method is conditional training, where we learn a predictive model of internet texts conditional on their human preference scores, e.g., evaluated by a predictive model of human preferences. This approach retains the advantages of learning from human preferences, while potentially mitigating risks from training agents with RL by learning a predictive model or simulator.\u201d</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/P4ut25NhfsFEMEeLJ/what-to-think-when-a-language-model-tells-you-it-s-sentient\"><u>What to think when a language model tells you it's sentient</u></a></p><p><i>by rgb</i></p><p>Argues that statements by large language models that seem to report their internal life (eg. \u2018I feel scared because I don\u2019t know what to do\u2019), aren\u2019t straightforward evidence either for or against the sentience of that model. As an analogy, parrots are probably sentient and very likely feel pain. But when they say \u2018I feel pain\u2019, that doesn\u2019t mean they are in pain.</p><p>It might be possible to train systems to more accurately report if they are sentient, via removing any other incentives for saying conscious-sounding things, and training them to report their own mental states. However, this could advance dangerous capabilities like situational awareness, and training on self-reflection might also be what ends up<i> making&nbsp;</i>a system sentient.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/WkchhorbLsSMbLacZ/ai-1-sydney-and-bing\"><u>AI #1: Sydney and Bing</u></a></p><p><i>by Zvi</i></p><p>Long post gathering examples of Bing Chat\u2019s behavior, general public reactions (eg. in the news), and reactions within the AI Safety community. It\u2019s written for accessibility to those not previously familiar with LessWrong or its concepts.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/Es6cinTyuTq3YAcoK/there-are-probably-no-superhuman-go-ais-strong-human-players\"><u>There are (probably) no superhuman Go AIs: strong human players beat the strongest AIs</u></a></p><p><i>by Taran</i></p><p>In March 2016, DeepMind\u2019s AlphaGo beat the plausibly strongest player in the world 4 to 1. Since then, this work has been extended, eg. in KataGo - now a top Go bot.&nbsp;<br><br>Last November Wang et al adversarially trained a bot to beat KataGo, which it does by playing moves that cause KataGo to make obvious blunders from strong positions. Human novices are able to beat this adversarial bot (so it\u2019s not great at Go overall), yet it beats KataGo in 72% of cases and some strong human players can copy its techniques to also beat KataGo.</p><p>This suggests that despite Go having quite simple concepts (liberties, live groups, dead groups), strong Go bots have achieved performance sufficient to beat the best human players without learning them.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/4ujM6KBN4CyABCdJt/ai-alignment-researchers-don-t-seem-to-stack\"><u>AI alignment researchers don't (seem to) stack</u></a></p><p><i>by So8res</i></p><p>The author argues that new skilled visionaries in alignment research tend to push in a different directions than existing ones. They suspect this is because the level of vision required for progressing the field requires a strong intuition to follow, there\u2019s a lot of space to find those in, and they can\u2019t be easily redirected. This means that any single alignment path isn\u2019t being sped up by adding more skilled talent (more than a factor of say 2x eg. from less visionary researchers and ops support).&nbsp;</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/FqSQ7xsDAGfXzTND6/stop-posting-prompt-injections-on-twitter-and-calling-it\"><u>Stop posting prompt injections on Twitter and calling it \"misalignment\"</u></a></p><p><i>by lc</i></p><p>Argues that exploits of large language models (such as getting them to explain steps to build a bomb) are examples of misuse, not misalignment. \u201cDoes not do things its creators dislike even when the user user wants it to\u201d is too high a bar for alignment, eg. higher than we ask of kitchenware.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/GY49CKBkEs3bEpteM/parametrically-retargetable-decision-makers-tend-to-seek\"><u>Parametrically retargetable decision-makers tend to seek power</u></a></p><p><i>by TurnTrout</i></p><p>Linkpost for&nbsp;<a href=\"https://arxiv.org/abs/2206.13477\"><u>this paper</u></a>, which isolates the key mechanism (retargetability) which enables the results in another paper:&nbsp;<a href=\"https://arxiv.org/abs/1912.01683\"><u>Optimal Policies Tend to Seek Power</u></a>. The author thinks it\u2019s a better paper for communicating concerns about power-seeking to the broader ML world.</p><p>Abstract (truncated): If capable AI agents are generally incentivized to seek power in service of the objectives we specify for them, then these systems will pose enormous risks, in addition to enormous benefits. [...] We show that a range of qualitatively dissimilar decision-making procedures incentivize agents to seek power. We demonstrate the flexibility of our results by reasoning about learned policy incentives in Montezuma's Revenge. These results suggest a safety risk: Eventually, retargetable training procedures may train real-world agents which seek power over humans.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/yiTcjSWuy7ptTb5XS/what-is-it-like-doing-ai-safety-work\"><u>What is it like doing AI safety work?</u></a></p><p><i>by Kat Woods, peterbarnett</i></p><p>The authors interviewed ten AI safety researchers on their day-to-day experience, and favorite and least favorite parts of the job.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/Aq82XqYhgqdPdPrBA/full-transcript-eliezer-yudkowsky-on-the-bankless-podcast\"><u>Full Transcript: Eliezer Yudkowsky on the Bankless podcast</u></a></p><p><i>by remember, Andrea_Miotti</i></p><p>Transcript of&nbsp;<a href=\"https://www.youtube.com/watch?v=gA1sNLL6yg4\"><u>this podcast episode</u></a>. Key points discussed:</p><ul><li><strong>ChatGPT:</strong> was a big leap over models pre-2018 or arguably 2020 (and just commercialization of models post that). Generality of intelligence is a range, and this is less general than a human, more than a cat, arguable either way vs. a chimpanzee. Not dangerous.</li><li><strong>Superintelligence:</strong> isn\u2019t perfect, but is better than humans at everything.</li><li><strong>Why is \u2018it kills all humans\u2019 the default?</strong> : Our tools are too blunt to truly get our goals into the systems we create. Similar to how evolution had the goal \u2018make lots of copies of your DNA\u2019 and we do things directly counter to that sometimes. So the AI will end up with a different goal, and for most goals, we\u2019re just atoms that could be put to better use.</li><li><strong>Why haven\u2019t other species invented AI</strong> that is now messing with us? Look up grabby aliens. They\u2019re possibly too far away.</li><li><strong>What next for Eliezer</strong>: currently on sabbatical. After that may help a small safety org eg. Conjecture, Anthropic or Redwood Research, or maybe continue doing public writings.</li><li><strong>How can funds be used?</strong> A billion+ could maybe pay AI developers to go live on an island and stop developing AI. Otherwise not sure, but thinks MIRI or Redwood Research wouldn\u2019t spend it for the sake of it.</li><li><strong>Who else has good alternate views?</strong> Paul Christiano (main technical opposition), Ajeya Cotra (worked with Paul, good at explaining things), Kelsey Piper (also good at explaining things), Robin Hanson.</li><li><strong>What can people do about all this?</strong> Primarily don\u2019t make things worse / speed things up. If you have an awesome idea, follow it, but don\u2019t tell everyone it\u2019s the solution in case it\u2019s not.</li></ul><p><br>&nbsp;</p><h2>Animal Welfare</h2><p><a href=\"https://forum.effectivealtruism.org/posts/6pc8iuDxz8LArWng8/eu-food-agency-recommends-banning-cages\"><u>EU Food Agency Recommends Banning Cages</u></a></p><p><i>by Ben_West</i></p><p>The European Commission&nbsp;<a href=\"https://www.efsa.europa.eu/en/news/efsa-alternatives-cages-recommended-improve-broiler-and-hen-welfare\"><u>requested scientific opinions</u></a> / recommendations on animal welfare from the European Food Safety Authority (EFSA), ahead of a legislative proposal in the second half 2023. The recommendations EFSA published include cage-free housing for birds, avoiding all mutilation and feed and water restrictions in broiler breeders, and substantially reducing stocking density. This result is partially due to efforts of EA-affiliated animal welfare organisations.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/Bsdq5wK63vLEB3Gqg/announcing-the-launch-of-the-insect-institute\"><u>Announcing the Launch of the Insect Institute</u></a></p><p><i>by Dustin Crummett</i></p><p><a href=\"http://insectinstitute.org/\"><u>The Insect Institute</u></a> is a fiscally-sponsored project of Rethink Priorities which focuses on the rapidly growing use of insects as food and feed. It will work with policymakers, industry, and others to address key uncertainties involving animal welfare, public health, and environmental sustainability. You can sign up for their email list via the option at the bottom of&nbsp;<a href=\"https://www.insectinstitute.org/\"><u>their homepage</u></a>.</p><p><br>&nbsp;</p><p><a href=\"https://www.lesswrong.com/posts/PuCqfK9DcaZDHZbAx/big-mac-subsidy\"><u>Big Mac Subsidy?</u></a></p><p><i>by jefftk</i></p><p>A recent&nbsp;<a href=\"https://faunalytics.org/veg-obstacle-analysis/\"><u>Faunalytics report</u></a> made the claim that \u201cby some estimates, a Big Mac would cost $13 without subsidies and a pound of ground meat would cost $30\u201d. The author found the claim implausible and thinks it possible the original claim (since repeated in many articles) originated in the 2013 book Meatonomics - which in addition to subsidies included cruelty, environmental, and health costs in a calculation of the true cost of a Big Mac. It also likely over-estimated Big Macs as a proportion of beef consumption, making the statistic unreliable.</p><p><br>&nbsp;</p><h2>Global Health and Development</h2><p><a href=\"https://forum.effectivealtruism.org/posts/gr4epkwe5WoYJXF32/why-i-don-t-agree-with-hli-s-estimate-of-household\"><u>Why I don\u2019t agree with HLI\u2019s estimate of household spillovers from therapy</u></a></p><p><i>by JamesSnowden</i></p><p>In its cost-effectiveness estimate of StrongMinds, Happier Lives Institute (HLI) estimates that each household member (~5 in the average household) benefits from the intervention 50% as much as the person receiving therapy. This is partially based on 3 RCTS - 2 which had interventions specifically targeted to benefit household members (eg. therapy for caregivers of children with nodding syndrome, which included the addition of nodding syndrome-specific content) and where only those expected to benefit most were measured. The third was incorrectly read as showing benefits to household members, when the evidence was actually mixed depending on the measure used.&nbsp;</p><p>The author argues this means household benefits were significantly overestimated, and speculatively guesses them to be more in the 5 - 25% range. This would reduce the estimated cost-effectiveness of StrongMinds from 9x to 3-6x cash transfers. In the comments HLI has thanked James for this analysis and acknowledged the points as valid, noted the lack of hard evidence in the area, and shared their plans for further analysis using a recent paper from 2022.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/7f9eMGRhfEgjbMxsa/immigration-reform-a-shallow-cause-exploration\"><u>Immigration reform: a shallow cause exploration</u></a></p><p><i>by JoelMcGuire, Samuel Dupret</i></p><p>Report of a 2-week investigation on the impact of immigration reform on subjective well-being (SWB), including a literature review and BOTECs on the cost-effectiveness of interventions.</p><p>The authors find potential large impacts to SWB from immigrating to countries with higher SWB levels, but are uncertain on the effect size or how it changes over time. All estimates below are highly uncertain best guesses based on their model:</p><ul><li>&nbsp;Immigrants gain an immediate and permanent 77% of the difference in SWB between their origin and destination country upon immigrating.&nbsp;</li><li>Household members left behind show a small positive spillover of +0.01 WELLBY per household member.</li><li>When the proportion of immigrants in a community increases by 1%, there is a small and non-significant negative spillover for natives of -0.01 WELLBYs per person.</li></ul><p>Of interventions investigated to increase immigration, the most promising was policy advocacy, estimated at 11x cost-effectiveness of Givewell cash transfers on SWB.</p><p><br>&nbsp;</p><h1>Rationality, Productivity &amp; Life Advice</h1><p><a href=\"https://www.lesswrong.com/posts/EvKa7EakoXreCkhC6/a-way-to-be-okay\"><u>A Way To Be Okay</u></a></p><p><i>by Duncan_Sabien</i></p><p>The author suggests one way to be okay with existential dread is to define yourself as someone who does the best they can with what they have, and treating that in and of itself as victory. This means even horrible outcomes for our species can\u2019t quite cut to the core of who you are. They elaborate with a range of anecdotes, advice, and examples that highlight parts of how to capture that feeling.</p><p><br>&nbsp;</p><h1>Community &amp; Media</h1><p><a href=\"https://forum.effectivealtruism.org/posts/mb4kzhfRnpQNtF6ut/introducing-ease-a-managed-directory-of-ea-organization\"><u>Introducing EASE, a managed directory of EA Organization Service Providers</u></a></p><p><i>by Deena Englander, JaimeRV, Markus Amalthea Magnuson, Eva Feldkamp, Mati_Roy, daniel wernstedt, Georg Wind</i></p><p><a href=\"https://ea-services.org/\"><u>EASE</u></a> (EA Services) is a directory of independent agencies and freelancers offering expertise to EA-aligned organisations. Vendors are screened to ensure they\u2019re true experts in their fields, and have experience with EA. If you\u2019d like to join the directory, you can&nbsp;<a href=\"https://forms.gle/oV23T92Qu9uDwK1c7\"><u>apply for screening here</u></a>. If you\u2019d like to use the services, you can contact the&nbsp;<a href=\"https://ea-services.org/\"><u>agencies listed</u></a> directly, or email&nbsp;<a href=\"mailto:info@ea-services.org\"><u>info@ea-services.org</u></a> for suggestions for your needs and available budget.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/oa3MdDRJaY3XfRsrF/ea-global-in-2022-and-plans-for-2023\"><u>EA Global in 2022 and plans for 2023</u></a></p><p><i>by Eli_Nathan</i></p><p>In 2022 the EAG team ran three EAGs, with 1.3-1.5K attendees each. These events averaged a 9.02 / 10 response to a question on if participants would recommend EAGs, and caused at least 36K new connections to be made (heavily under-reported as most attendees didn\u2019t fill in this feedback).</p><p>In 2023 they plan to reduce spending - primarily on travel grants and food - but still do three EAGs. They now have a team of ~4 FTEs, and will focus on launching applications earlier, and improving response speed, Swapcard, and communications.&nbsp;</p><p>The full list of confirmed and provisional EAG and EAGx events are:<br>EA Global: Bay Area | 24\u201326 February</p><p>EAGxCambridge | 17\u201319 March&nbsp;</p><p>EAGxNordics | 21\u201323 April&nbsp;</p><p>EA Global: London | 19\u201321 May</p><p>EAGxWarsaw | 9\u201311 June [provisional]&nbsp;</p><p>EAGxNYC | July / August [provisional]</p><p>EAGxBerlin | Early September [provisional]</p><p>EAGxAustralia | Late September [provisional]</p><p>EA Global: Boston | Oct 27\u2013Oct 29</p><p>EAGxVirtual | November [provisional]</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/aJwcgm2nqiZu6zq2S/taking-a-leave-of-absence-from-open-philanthropy-to-work-on\"><u>Taking a leave of absence from Open Philanthropy to work on AI safety</u></a></p><p><i>by Holden Karnofsky</i></p><p>Holden Karnofsky (co-ceo of Open Philanthropy) is taking a minimum 3 month leave of absence from March 8th to explore working directly on AI safety, particularly AI safety standards. They may end up doing this full-time and joining or starting a new organization. This is due to believing transformative AI could be developed soon and that they can have more impact with direct work on it, in addition to personal fit towards building multiple organisations over running one indefinitely.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/QMee23Evryqzthcvn/a-statement-and-an-apology\"><u>A statement and an apology</u></a>&nbsp;<i>by Owen Cotton-Barratt&nbsp;</i>and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/9JCkkjKMNL4Hmg4qP/ev-uk-board-statement-on-owen-s-resignation\"><u>EV UK board statement on Owen's resignation</u></a>&nbsp;<i>by EV UK Board</i></p><p>The recent&nbsp;<a href=\"https://forum.effectivealtruism.org/out?url=https%3A%2F%2Ftime.com%2F6252617%2Feffective-altruism-sexual-harassment%2F\"><u>Time article on EA and sexual harassment</u></a> included a case involving an \u2018influential figure in EA\u2019. In this post, Owen Cotton-Barratt confirms that this was him, during an event five years ago. He apologizes and gives full context of what happened from his view, what generalizable mistakes he made that contributed, and what actions he\u2019s taking going forward. This includes resigning from the EV UK board and pausing other activities which may give him power in the community (eg. starting mentoring relationships, organizing events, or recommending projects for funding).</p><p>Owen\u2019s behavior was reported to Julia Wise (CEA\u2019s community liaison) in 2021, who shared it with the EV UK board shortly after the Time article came out. Julia has also apologized for the handling of the situation and shared the actions that were taken at the time this incident was first reported to her, as well as in the time between then and now in the comments. The EV UK board is commissioning an external investigation by an independent law firm into both Owen\u2019s behavior and the Community Health team\u2019s response.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/XFBGu9sGfbYAsb8Gb/bad-actors-are-not-the-main-issue-in-ea-governance\"><u>Bad Actors are not the Main Issue in EA Governance</u></a></p><p><i>by Grayden</i></p><p>Leadership can fail in 4 ways: bad actors, well-intentioned people with low competence, well-intentioned high-competence people with collective blind spots, or the right group of people with bad practices.<br><br>The author argues EA focuses too much on the \u2018bad actors\u2019 angle, and this incentivizes boards to hire friends or those they know socially to reduce this risk. They suggest we stop this behavior, and instead tackle the other three risks via:</p><ul><li>Learning from models of leadership in other communities and organisations (to elevate competence at soft skills, since EA has few experienced leaders to learn from).</li><li>Recognizing that seeing one\u2019s own faults is difficult, and being open to external expertise and hiring those dissimilar to ourselves can be good ways to identify these blind spots.</li><li>CEOs and Boards should create the right environment for effective decision-making (eg. CEOs speaking last, creating incentives for employees to be honest, and taking difficult decisions to the board for input. The board avoiding execution, not talking lots where they aren\u2019t independent, and evaluating their own performance and composition).</li></ul><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/hAHNtAYLidmSJK7bs/who-is-uncomfortable-critiquing-who-around-ea\"><u>Who is Uncomfortable Critiquing Who, Around EA?</u></a></p><p><i>by Ozzie Gooen</i></p><p>Discusses the specific barrier to feedback of things being uncomfortable to say, and how this affects the availability of criticism between different groups. Specifically, they cover:</p><ul><li>Evaluation in global welfare - criticism seems like fair game, though we don\u2019t tend to evaluate mediocre or poor global health charities.</li><li>Evaluation in longtermism - most potential evaluators are social peers of who they would be evaluating. There is some discussion, but discomfort is one bottleneck to more.</li><li>Evaluation of EA Funders / Leaders by Community Members - there are only a few EA funders, and they\u2019re highly correlated in opinion, making those who could give the best critiques uncomfortable doing it. Those with less to lose have voiced critiques.</li><li>Evaluation of Community Members by Funders / Leaders - criticizing those you have power over is seen as \u2018punching down\u2019, and so is rarely done in any community. However, action can still be taken behind the scenes. This combination is really bad for trust.</li><li>Evaluation of adjacent groups, by EAs - EA has sometimes been dismissive about other groups without public clarity on why. It has taken a public image as cooperative and respectful, which makes it tricky to openly disagree with other groups.</li><li>Evaluation of EA, by adjacent groups - some are comfortable critiquing EA, but many of the most informative voices have no incentives to.</li><li>Evaluation of EA critics, by EAs - honestly responding when you think a critique is really bad is surprisingly hard to do. It can look like punching down, or like you\u2019re biased, and can require a lot of emotional energy.</li></ul><p>They suggest EA look at specific gaps in feedback, and from which groups - as opposed to asking \u2018are we open to feedback?\u2019 more generally.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/aGkLx2hfr9s3mSdng/consider-not-sleeping-around-within-the-community-1\"><u>Consider not sleeping around within the community</u></a></p><p><i>by Patrick Sue Domin</i></p><p>The author suggests considering not \u201csleeping around\u201d (eg. one night stands, friends with benefits, casual dating with multiple people) within the EA community, due to its tight-knit nature increasing the associated risks. For instance, someone who is pursued and declined may end up having to interact with the pursuer in professional capacities down the road. They suggest this is particularly the case for those with any of the following additional risk factors: high-status within EA, and/or a man pursuing a woman, and/or socially clumsy. There is a large amount of discussion on both sides in the comments.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/rqg7PRYTvCf74TRyG/consent-isn-t-always-enough\"><u>Consent Isn't Always Enough</u></a></p><p><i>by Jeff Kaufman</i></p><p>In response to some of the above posts, there\u2019s been a lot of discussion on how much EA culture did or didn\u2019t contribute. Some of the suggestions (eg. discouraging polyamory or hookups) have caused others to argue what happens between consenting adults is no-one\u2019s else\u2019s business.&nbsp;</p><p>The author argues consent isn\u2019t always enough, particularly in cases with imbalanced power (eg. grantee and grantmaker). Organisations handle these conflicts in ways such as requiring a professor to either resign or not pursue a relationship with a student, or a grantmaker to disclose and recuse themselves from responsibilities relating to evaluating a grantee they\u2019re in a relationship with. This is pretty uncontroversial and shows the question is what norms we should have and not whether it is legitimate at all to have norms beyond consent.</p><p><br>&nbsp;</p><h1>Didn\u2019t Summarize</h1><p><a href=\"https://www.lesswrong.com/posts/eJq7xWcASjMkvikkD/on-investigating-conspiracy-theories\"><u>On Investigating Conspiracy Theories</u></a><i> by Zvi</i></p><p>&nbsp;</p><h1>Special Mentions</h1><p><i>A selection of posts that don\u2019t meet the karma threshold, but seem important or undervalued.</i></p><p><a href=\"https://forum.effectivealtruism.org/posts/36xmKk4fXYTptfFXy/how-can-we-improve-discussions-on-the-forum\"><u>How can we improve discussions on the Forum?</u></a></p><p><i>by Lizka</i></p><p>Fill out&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLScNmN1_XFffYJFucU5gUun9NuzZF5lZR_6m6-FskDHDph7pjA/viewform?usp=sf_link\"><u>this survey</u></a> with your thoughts on community posts having their own section on the frontpage, what changes to the forum site you\u2019d like to see, what conversations you\u2019d like to see, or any other feedback.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/jEHcbrsumxditRhtG/updates-from-the-mental-health-funder-s-circle\"><u>Updates from the Mental Health Funder's Circle</u></a></p><p><i>by wtroy</i></p><p>The&nbsp;<a href=\"https://www.mentalhealthfunders.com/\"><u>Mental Health Funder\u2019s Circle</u></a> supports organisations working on cost-effective and catalytic mental health interventions. It held its first grant round in the Fall/Winter of 2022, and has now distributed $254K total to three organisations (Vida Plena for community mental health in Ecuador, Happier Lives Institute for work on subjective well being and cause prioritization, and Rethink Wellbeing to support mental health initiatives in the EA community). The next round of funding is now open -&nbsp;<a href=\"https://www.mentalhealthfunders.com/\"><u>apply here</u></a> by April 1st.</p><p><br>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/7cfdwqZkhuKFACpeG/cyborg-periods-there-will-be-multiple-ai-transitions\"><u>Cyborg Periods: There will be multiple AI transitions</u></a></p><p><i>by Jan_Kulveit, rosehadshar</i></p><p>Suggests domains may move through three stages. Current day examples in brackets:<br>1. Human period - humans more powerful than AI (alignment research, business strategy).</p><p>2. Cyborg period - human + AI more powerful than humans or AIs individually (visual art, programming).</p><p>3. AI period - AIs more powerful than humans, and approx. equal to human+AI teams. (chess, shogi).</p><p>Transitions into the cyborg period will be incredibly impactful in some domains eg. research, human coordination, persuasion, cultural evolution. Which domains transition first also lends itself to different threat models and human response. For instance, moving faster on automating coordination relative to automating power, or on automating AI alignment research relative to AI research in general, could both reduce risk.</p><p>They also argue cyborg periods may be brief but pivotal, involving key deployment decisions and existential risk minimization work. To make the best use of them, we\u2019ll need to have sufficient understanding of AI system\u2019s strengths and weaknesses, novel modes of factoring cognition, modify AI systems towards cyborg uses, and practice working in human+AI teams in existing cyborg domains.</p><p><br>&nbsp;</p>", "user": {"username": "GreyArea"}}, {"_id": "Gq3tpEvkuffFnKMdk", "title": "Cause prioritization in Canada.", "postedAt": "2023-02-27T09:24:45.644Z", "htmlBody": "<p>Hello, EA Forum!</p><p>First of all, I would like to thank you all for your engagement on the subject. I am a Canadian citizen committed to several causes and EA interests me more and more.</p><p>I work for a medium-sized company that works around the automotive industry and it is currently looking for a pan-Canadian cause to support. I would like to influence my company so that their donations have the maximum positive impact. I believe that education or the fight against climate change would be a good association, but I know that these causes are not necessarily in the top priorities of EA. My searches point me to RC Forward for Canadian donations even if the foundations are in United States or elsewhere. I also understand that several priorities are in third world countries.</p><p>Do you have any Canadian suggestions to share please?</p><p>Thank you for your ideas. Peace! &lt;3</p>", "user": {"username": "yvosaurus"}}, {"_id": "AN2fXG6aRRQTF4SYx", "title": "GWWC Newsletter: February 2023", "postedAt": "2023-02-27T00:00:22.208Z", "htmlBody": "<p>Hello and welcome to our February newsletter!</p><p>Earlier this month, we were shocked to hear about the devastation across Turkey and Syria caused by the earthquakes. Our hearts go out to our members in Turkey, and their communities. Although harrowing, hearing about and seeing pictures of disasters helps us empathise with the most challenging conditions people can face.&nbsp;</p><p>In the wake of this disaster, we published a blog from Stefan Shaw and Louise Kihlberg about&nbsp;<a href=\"https://www.givingwhatwecan.org/blog/turkey-syria-earthquake-donation-advice\"><u>what to consider when thinking about donating to disaster relief efforts</u></a>.&nbsp;</p><p>One thing that\u2019s always on my mind after these highly publicised tragedies, are the ongoing tragedies occurring around the world, that aren\u2019t receiving any media attention. The famine and&nbsp;<a href=\"https://www.cfr.org/global-conflict-tracker/conflict/conflict-ethiopia\"><u>war in Tigray, Ethiopia</u></a> and the&nbsp;<a href=\"https://theconversation.com/why-has-the-west-given-billions-in-military-aid-to-ukraine-but-virtually-ignored-myanmar-198297\"><u>persecution of people in Myanmar</u></a> have received little news coverage. And the suffering from the \u201csilent catastrophes\u201d of&nbsp;<a href=\"https://www.givingwhatwecan.org/cause-areas/improving-human-wellbeing#reducing-poverty-and-illness\"><u>global poverty and preventable illnesses</u></a> rarely makes the news at all.</p><p>With all of the suffering in the world, I am extremely grateful to be surrounded by a global community of people who are dedicated to effectively improving the lives of others. Your gifts have a meaningful impact on those you are helping, and are contributing to a more equal world. I hope giving makes you feel empowered to be a part of positive global change, as it does for me.</p><p>If you want to join our movement,&nbsp;<a href=\"https://www.givingwhatwecan.org/pledge\"><u>take a pledge</u></a> to donate a portion of your income to highly effective charities today. Committing to a pledge was one of the most powerful things I\u2019ve done.</p><p>We also published a great article from member Alana Horowitz-Friedman&nbsp;<a href=\"https://www.givingwhatwecan.org/blog/arent-the-best-charities-those-with-the-lowest-overhead-costs\"><u>busting the myth that \u201cthe best charities are the ones with low overhead costs\u201d</u></a>. This is an excellent piece to bring up with friends and family when discussing where to donate. Thanks, Alana for this well thought out article!</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;With gratitude,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p>-Grace Adams &amp; the rest of the Giving What We Can team</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><h2>Featured top-rated charity</h2><h2>Family Empowerment Media</h2><p>Family Empowerment Media (FEM) is an evidence-driven nonprofit committed to eliminating maternal deaths and other health burdens from unintended pregnancies. FEM produces and air radio-based social and behavioural change campaigns on family planning to empower women and men who want to delay or prevent pregnancy to consistently use contraception.&nbsp;<a href=\"https://www.givingwhatwecan.org/charities/family-empowerment-media\"><u>Read more here</u></a></p></td></tr></tbody></table></figure><h2>Jobs and Volunteering</h2><p>We are hiring an&nbsp;<strong>Effective Giving Global Coordinator and Incubator</strong> to help us support the global effective giving community and the development of new effective giving initiatives. Applications close March 1st.&nbsp;<a href=\"https://www.givingwhatwecan.org/get-involved/careers/effective-giving-global-coordinator-and-incubator\"><u>More information and application here</u></a>.</p><p>Are you interested in volunteering to help us with marketing our events? We\u2019re looking for an ongoing volunteer who can assist with promoting our upcoming events.&nbsp;<a href=\"mailto:grace.adams@givingwhatwecan.org?subject=Events Marketing Volunteer\"><u>Email me</u></a> if you\u2019re interested.</p><h2>Attend An Event</h2><h3>Meetup - Europe/Asia</h3><p>We have decided to have a single meetup each month and alternate between Europe/Asia and Americas/Oceania each month. We invite you to connect with other members from around the world at these events. This month will be a social event getting to know other community members.</p><ul><li><a href=\"https://savvytime.com/converter/utc-to-australia-sydney-united-kingdom-london-ny-new-york-city-india-mumbai-singapore-singapore-germany-munich-ca-san-francisco-new-zealand-auckland-israel-tel-aviv/mar-05-2023/9-30am\"><u>5 Mar at 09:30 UTC</u></a></li><li><a href=\"https://us02web.zoom.us/meeting/register/tZ0sdOugpzotG9SjVZUc2C1K4uZzfR3VL3nU\"><u>Register</u></a></li></ul><h3>Open Forum - Americas/Oceania</h3><p>Our open forum is an event where you can come along with questions about effective giving and/or to meet others interested in effective giving. This event alternates between Europe/Asia and Americas/Oceania each month.</p><ul><li><a href=\"https://savvytime.com/converter/utc-to-australia-sydney-united-kingdom-london-ny-new-york-city-india-mumbai-singapore-singapore-germany-munich-ca-san-francisco-new-zealand-auckland-israel-tel-aviv/mar-16-2023/12-30am\"><u>16 Mar at 00:30 UTC</u></a></li><li><a href=\"https://us02web.zoom.us/meeting/register/tZUlduGhqzssE9WCGXDGKguOdT56b9eU5qOJ\"><u>Register</u></a></li></ul><h2>News &amp; Updates</h2><h3>Community</h3><ul><li>80,000 Hours has just published a&nbsp;<a href=\"https://80000hours.org/2023/02/how-much-do-solutions-differ-in-effectiveness/\"><u>new post about how much solutions differ in effectiveness</u></a>, this is a great piece from Ben Todd, who found that some of Toby Ord\u2019s original research that underpins the concept of effective giving holds up, and can be expanded to other areas. But Ben also points out that it might be most fair to say that the best charities are 10 times better than the median.</li><li>Do you know a lawyer who can do a small amount of work to help our Charity Elections program expand into new countries?&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/YnQajAQjWbmYnbSYa/cta-help-gwwc-charity-elections-upscale-by-connecting-us-to\"><u>Find out more details in this post.</u></a></li><li>Due to the changes in the rules surrounding Meta\u2019s Giving Tuesday match, the project has officially been hibernated, which we communicated in this&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pMe3pg5H9CPedTYA8/ea-giving-tuesday-hibernation\"><u>recent EA Forum post</u></a>.</li></ul><h3>Evaluators, grantmakers and incubators</h3><ul><li>Charity Entrepreneurship has announced their<a href=\"https://rebrand.ly/top2023\">&nbsp;<u>top interventions in Large-Scale Global Health and Biosecurity</u></a>, which potential entrepreneurs can launch through the July-August 2023<a href=\"https://rebrand.ly/IncubationProgram\">&nbsp;<u>Incubation Program</u></a>. The application deadline is March 12, 2023. Links for applications can be found<a href=\"https://rebrand.ly/ip2023\">&nbsp;<u>here</u></a>. CE also invites everyone to an<a href=\"https://rebrand.ly/TIevent2023\">&nbsp;<u>online event</u></a> on February 20, 6PM UK Time, where Sam Hilton, Director of Research, will introduce the ideas and answer questions. Team members and incubatees will also be present at EAG Bay Area.</li><li>Animal Charity Evaluators is accepting applications for our 2023 Movement Grants! If you\u2019re looking for funding to support your promising charity or initiative,&nbsp;<a href=\"https://animalcharityevaluators.org/movement-grants/apply-for-funding/\"><u>apply by March 17</u></a></li><li>Open Philanthropy is hiring for two exciting new roles<ul><li><a href=\"https://jobs.ashbyhq.com/openphilanthropy/e95f8d97-f061-46af-9729-4716724c8245\"><u>Internship in Cause Prioritization</u></a> - work with the Global Health &amp; Wellbeing cause prioritization team to&nbsp;<a href=\"https://www.openphilanthropy.org/cause-selection/#Shallow_investigations\"><u>investigate</u></a> potential new focus areas enabling Open Phil to prioritize across causes which informs their grantmaking. (Deadline February 26)</li></ul></li><li><a href=\"https://jobs.ashbyhq.com/openphilanthropy/fc3e54ae-8f2e-4181-92ae-fca347fcffee\"><u>Forecasting Senior Program Associate</u></a> - make grants to support the forecasting community, support Open Phil staff in commissioning external forecasts on specific questions of interest, and lead their&nbsp;<a href=\"https://www.openphilanthropy.org/research/how-accurate-are-our-predictions/\"><u>internal forecasting work</u></a>. (Deadline March 5)</li></ul><h3>Cause areas</h3><p>Animal welfare</p><ul><li>Faunalytics has released our newest original report,&nbsp;<a href=\"https://faunalytics.org/reforming-animal-agriculture-subsidies/\"><u>Reforming Animal Agriculture Subsidies: A Guide for Advocates</u></a>. This report dives into animal agriculture subsidies and how advocates can reduce their harmful impact. Additionally, we have released a companion report,&nbsp;<a href=\"https://faunalytics.org/industry-perspectives-on-advocates/\"><u>The Animal Agriculture Industry's Perspective On Advocates &amp; Cage-Free Reforms</u></a>.</li><li>Good Food Institute&nbsp;<a href=\"https://t.co/W40UBgmR2Z\"><u>investment data analysis + survey results</u></a> show that long-term investor appetite for alt proteins is strong despite challenging macroeconomic &amp; market conditions slowing growth in 2022.&nbsp;</li></ul><p>Global health and development</p><ul><li>New Incentives&nbsp;<a href=\"https://twitter.com/NewIncentives/status/1625876400291950596\"><u>expanded operations</u></a> and began offering cash incentives to caregivers in Kano State last month in order to encourage childhood vaccinations.&nbsp;</li><li>The Happier Lives Institute published a shallow cause exploration of&nbsp;<a href=\"https://www.happierlivesinstitute.org/report/immigration-reform/\"><u>immigration reform</u></a>, including some rough cost-effectiveness estimates for possible interventions.</li><li>Lead Exposure Elimination Project&nbsp;<a href=\"https://f1000research.com/articles/12-166/v1\"><u>published a new study</u></a> with Aga Khan University doctors which found that 40% of oil-based paints sampled from the market in Pakistan contained dangerous and illegal levels of lead, endangering the health of children. Some paint contained 1000 times the legal limit for lead.</li></ul><p>Long-term future</p><ul><li>The Council on Strategic Risks is excited to debut our inaugural class of our&nbsp;<a href=\"https://councilonstrategicrisks.org/2023/01/09/csrs-nolan-center-announces-inaugural-class-of-nuclear-risk-reduction-fellows/\"><u>Fellowship for Reducing Nuclear Weapons Risks</u></a>. They had their first convening in late January and are meeting regularly ahead of an experiential learning trip sometime later this spring.</li><li>Support from our community has enabled TerraPraxis to launch its&nbsp;<a href=\"https://www.terrapraxisrepower.com/The-Platform/Global-Plant-Data/\"><u>EVALUATE application&nbsp;</u></a>to help coal plant owners, investors, and policymakers evaluate the opportunity to decarbonize the global coal fleet \u2013 the single largest source of carbon emissions \u2013 with emission-free heat sources by 2050.</li></ul><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1677456023/mirroredImages/AN2fXG6aRRQTF4SYx/f9awvzimg1eccxor6glu.jpg\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1677456023/mirroredImages/AN2fXG6aRRQTF4SYx/cveagalrcn6t5bfbktnl.jpg 105w, https://res.cloudinary.com/cea/image/upload/v1677456023/mirroredImages/AN2fXG6aRRQTF4SYx/gycvjefl8feu298c7xmx.jpg 185w, https://res.cloudinary.com/cea/image/upload/v1677456023/mirroredImages/AN2fXG6aRRQTF4SYx/zvrjvcgnwmjkfww7kqmy.jpg 265w, https://res.cloudinary.com/cea/image/upload/v1677456024/mirroredImages/AN2fXG6aRRQTF4SYx/ksewcargkzyfasggwzhg.jpg 345w, https://res.cloudinary.com/cea/image/upload/v1677456023/mirroredImages/AN2fXG6aRRQTF4SYx/wdegwzsyvteuzsbuz9xy.jpg 425w, https://res.cloudinary.com/cea/image/upload/v1677456023/mirroredImages/AN2fXG6aRRQTF4SYx/zrvvlzffybfne9odldse.jpg 505w, https://res.cloudinary.com/cea/image/upload/v1677456023/mirroredImages/AN2fXG6aRRQTF4SYx/aondqhq7fgptqw1wuups.jpg 585w\"></figure><p>&nbsp;</p><p>Brit just completed her Trial Pledge, you can congratulate her on twitter&nbsp;<a href=\"https://twitter.com/booritney/status/1625403422957785088?s=20\"><u>here</u></a>!</p></td></tr></tbody></table></figure><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>Have any feedback on our newsletter or communications?&nbsp;<a href=\"https://forms.gle/UZCnhMHNq11ieQoCA\"><u>Share your thoughts here.</u></a></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>Why not streamline your giving by setting up a recurring donation to a highly effective charity today?</p><p><a href=\"https://www.givingwhatwecan.org/donate/organizations\"><u>Donate&nbsp;</u></a></p></td></tr></tbody></table></figure><p><br>&nbsp;</p><h2>Useful Links</h2><ul><li>Review&nbsp;<a href=\"https://www.givingwhatwecan.org/best-charities-to-donate-to-2022\"><u>our giving recommendations</u></a>.</li><li>Report your donations with&nbsp;<a href=\"https://app.effectivealtruism.org/pledge\"><u>your pledge dashboard</u></a>.</li><li><a href=\"https://www.givingwhatwecan.org/get-involved/share-our-ideas/\"><u>Share our ideas</u></a> to help grow our community and&nbsp;<a href=\"https://www.givingwhatwecan.org/post/2020/12/social-change-happens-one-person-at-a-time-so-start-multiplying-your-impact/\"><u>multiply your impact</u></a>.</li><li>Join other members in the&nbsp;<a href=\"https://www.facebook.com/groups/givingwhatwecancommunity/\"><u>Giving What We Can Community</u></a> Facebook group.</li><li>Find more ways to&nbsp;<a href=\"https://www.givingwhatwecan.org/get-involved/\"><u>get involved</u></a> with Giving What We Can and effective altruism.</li><li>Discuss effective giving and effective altruism on the&nbsp;<a href=\"https://forum.effectivealtruism.org/\"><u>EA Forum</u></a>.</li></ul><p>You can follow us on&nbsp;<a href=\"https://twitter.com/givingwhatwecan\"><u>Twitter</u></a>,&nbsp;<a href=\"https://www.facebook.com/givingwhatwecan\"><u>Facebook</u></a>,&nbsp;<a href=\"https://www.linkedin.com/company/2760845/\"><u>LinkedIn</u></a>,&nbsp;<a href=\"https://www.instagram.com/giving_what_we_can/\"><u>Instagram</u></a>,&nbsp;<a href=\"https://www.youtube.com/channel/UC_gBQtUE3BBl-Mh_IBQkg9Q\"><u>YouTube</u></a>, or&nbsp;<a href=\"https://www.tiktok.com/@givingwhatwecan\"><u>TikTok</u></a> and subscribe to the&nbsp;<a href=\"https://www.effectivealtruism.org/ea-newsletter-archives/\"><u>EA Newsletter</u></a> for more news and articles.</p><p>Do you have questions about the pledge, Giving What We Can, or effective altruism in general? Check out our&nbsp;<a href=\"https://www.givingwhatwecan.org/about-us/frequently-asked-questions/\"><u>FAQ page</u></a>, or&nbsp;<a href=\"https://www.givingwhatwecan.org/about-us/contact-us/\"><u>contact us directly</u></a>.</p><p><br>&nbsp;</p>", "user": {"username": "Giving What We Can"}}, {"_id": "uJG79y8eji9zALjAd", "title": "Let's Fund: Better Science impact evaluation. Registered Reports now available in Nature", "postedAt": "2023-02-26T15:05:18.850Z", "htmlBody": "<p><a href=\"https://hauke.substack.com/p/lets-fund-what-was-the-impact-of\"><i>Cross-posted from my blog</i></a><i> - inspired by the recent call for more monitoring and evaluation</i></p><p>Hi, it's Hauke, the founder of Let's Fund. We research pressing problems, like climate change or the replication crisis in science, and then crowdfund for particularly effective policy solutions.</p><p>Ages ago, you signed up to my newsletter. Now I've evaluated the $1M+ in grants you donated, and they had a big impact<strong>.</strong>&nbsp;Below I present the&nbsp;Better Science / Registered Report campaign evaluation, but stay&nbsp;tuned for the climate policy campaign impact evaluation (spoiler: clean energy R&amp;D increased by billions of dollars).</p><h1>Let's Fund: Better Science</h1><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97d34e5a-b491-462a-8c05-fb9cdaa66905_1108x544.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97d34e5a-b491-462a-8c05-fb9cdaa66905_1108x544.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97d34e5a-b491-462a-8c05-fb9cdaa66905_1108x544.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97d34e5a-b491-462a-8c05-fb9cdaa66905_1108x544.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97d34e5a-b491-462a-8c05-fb9cdaa66905_1108x544.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97d34e5a-b491-462a-8c05-fb9cdaa66905_1108x544.png 1456w\"></a></p><p><i>Chris Chambers giving a talk on Registered Reports</i></p><p>We crowdfunded ~$80k for Prof. Chambers to promote <i>Registered Reports</i>, a new publication format, where research is peer-reviewed before the results are known. This fundamentally changes the way research is done across all scientific fields. For instance, one recent <i>Registered Report</i>&nbsp;studied COVID patients undergoing ventilation<a href=\"https://hauke.substack.com/p/lets-fund-what-was-the-impact-of#footnote-1-105216073\"><sup><u>1 </u></sup></a>(but there are examples in other areas including climate science,<a href=\"https://hauke.substack.com/p/lets-fund-what-was-the-impact-of#footnote-2-105216073\"><sup><u>2&nbsp;</u></sup></a> development &nbsp;economics,<a href=\"https://hauke.substack.com/p/lets-fund-what-was-the-impact-of#footnote-3-105216073\"><sup><u>3</u></sup></a> biosecurity, <a href=\"https://hauke.substack.com/p/lets-fund-what-was-the-impact-of#footnote-4-105216073\"><sup><u>4&nbsp;</u></sup></a><sup><u> </u></sup>farm animal welfare,<a href=\"https://hauke.substack.com/p/lets-fund-what-was-the-impact-of#footnote-5-105216073\"><sup><u>5</u></sup></a> etc.).</p><p>Registered Reports have higher quality than normal publications,<a href=\"https://hauke.substack.com/p/lets-fund-what-was-the-impact-of#footnote-6-105216073\"><sup><u>6 </u></sup></a>because they</p><ul><li>make science more theory-driven, open and transparent</li><li>find methodological weaknesses and also potential biosafety failures of dangerous dual-use research <strong>prior to publication</strong> (e.g. gain of function research)<a href=\"https://hauke.substack.com/p/lets-fund-what-was-the-impact-of#footnote-7-105216073\"><sup><u>7</u></sup></a></li><li>get more papers published that fail to confirm the original hypothesis</li><li>increase the credibility of non-randomized natural experiments using observational data</li></ul><p>If Registered Reports become widely adopted, it might lead to a paradigm shift and better science. 300+ journals have already adapted Registered Reports. And just last week <i>Nature, </i>the most prestigious academic journal,<i>&nbsp;</i>adopted it<i>:</i></p><p><a href=\"https://twitter.com/chrisdc77/status/1628431986464526336\">Chris Chambers on Twitter: \"10 years after we created Registered Reports, the thing critics told us would never happen has happened: @Nature is offering them Congratulations @Magda_Skipper &amp;amp; team. The @RegReports initiative just went up a gear and we are one step closer to eradicating publication bias.</a></p><p><a href=\"https://twitter.com/chrisdc77/status/1628431986464526336\"><img src=\"https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFplZIwHXoAEJLyd.jpg\" alt=\"From today, the journal Nature is offering the Registered Reports article type, which eliminates publication bias by reviewing and accepting papers before research is undertaken.\"></a></p><p>This is&nbsp;big and <i>Registered Reports </i>might soon become the gold standard.</p><p>Why? Imagine you\u2019re a scientist with a good idea for an experiment with high value of information (think: a simple cure for depression). If that has a low chance of working out (say 1%), then previously you had little incentive to run it.</p><p>Now, if your idea is really good, and based on strong theory, Registered Reports derisks running the experiment. You can first submit the idea and methodology to <i>Nature</i>&nbsp;and the reviewers might say: \u2018This idea is nuts, but we agree there\u2019s a small chance it might work and really interested in this works. If you run the experiment, we\u2019ll publish this independent of results!\u2019 Now you can go ahead spend a lot of effort on running the experiment, because even if it doesn\u2019t work, you still get a Nature paper (which you wouldn\u2019t with null results).</p><p>This will lead to more high risk, high reward research (share this post or the tweet with academics! They might thank you for the <i>Nature</i>&nbsp;publication).</p><p>Many people were integral to this progress, but I think Chambers, the co-inventor and prime proponent of Registered Reports deserves special credit. In turn he credited:</p><p><a href=\"https://twitter.com/chrisdc77/status/1305230530292649984\">Chris Chambers @chrisdc77</a>: '<a href=\"https://twitter.com/chrisdc77/status/1305230530292649984\">You. That's right. Some of the most useful and flexible funding I've received has been donated by hundreds of generous members of public (&amp; small orgs) via our @LetsFundOrg-supported crowd sourcing fund</a>'</p><p><strong>You may feel smug.</strong></p><p><a href=\"https://lets-fund.org/better-science\"><u>If you want to make a bigger donation (&gt;$1k), click here</u></a>. There are proposals to improve Registered Reports even further, like <a href=\"https://psyarxiv.com/tx5v6/\"><u>trinity review</u></a>&nbsp;which integrates Registered Reports with ethics and funding reviews, and <a href=\"https://rr.peercommunityin.org/\"><u>peer community review</u></a>&nbsp;which&nbsp;reduces review burdens (also see <a href=\"https://www.nature.com/articles/s41562-021-01193-7\"><u>The past, present and future of Registered Reports</u></a>&nbsp;for more).</p><h1>Acknowledgments</h1><p>We would like to thank the following organizations and people for helping Let\u2019s Fund in various ways: Two anonymous EA donors, The Effective Altruism Infrastructure-Fund, the Center for Effective Altruism, The Survival and Flourishing Fund, Jacob Hilton, Founders Pledge, Effektiv-Spenden.org, Rethink Charity: Forward, the Effective Altruism Foundation, Slate Star Codex, EA Giving Tuesday, Vox.com, Legacies Now, the founding team including Henry Stanley and Sahil Shah (see&nbsp;<a href=\"https://lets-fund.org/about\">Lets-Fund.org/About</a>), and everyone who has reviewed our research and donated to our crowdfunding campaigns.</p>", "user": {"username": "HaukeHillebrandt"}}, {"_id": "WKSwH4eyDiqhJMcrz", "title": "Very Briefly: The CHIPS Act", "postedAt": "2023-02-26T13:53:55.751Z", "htmlBody": "<p>About six months ago, Congress passed the CHIPS Act. The \"Creating Helpful Incentives to Produce Semiconductors for America Act\", will spend $280 billion over the next ten years. $200 billion will go into scientific R&amp;D and commercialization, $52.7 billion into semiconductor manufacturing, R&amp;D, and workforce development, and $24 billion into tax credits (government subsidies) for chip production.</p><p>Semiconductor production has been slipping in the United States for some time. While countries like China and Taiwan have maintained a strong foothold in the global chip market, the U.S. now produces just 12% of the world's semiconductors, down from 37% in the 1990s (<a href=\"https://www.commerce.gov/news/press-releases/2022/04/analysis-chips-act-and-bia-briefing\">source</a>).</p><figure class=\"image\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f1a8ca3-2b6f-446e-9f00-95c03960df42_700x500.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f1a8ca3-2b6f-446e-9f00-95c03960df42_700x500.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f1a8ca3-2b6f-446e-9f00-95c03960df42_700x500.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f1a8ca3-2b6f-446e-9f00-95c03960df42_700x500.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f1a8ca3-2b6f-446e-9f00-95c03960df42_700x500.png 1456w\"><figcaption><a href=\"https://www.ft.com/content/2b0c172b-2de9-4011-bf40-f4242f4673cc\">Source</a></figcaption></figure><p>The United States' dwindling position in the global semiconductor market, coupled with concerns about reliance on foreign suppliers - especially China and Taiwan - likely played a role in the introduction of the CHIPS Act. <a href=\"https://edition.cnn.com/2023/02/23/politics/chips-act-implementation-gina-raimondo-speech/index.html\">In a recent speech</a>, Commerce Secretary Gina Raimondo spoke about how the CHIPS Act could help the U.S. regain its position as the top destination for innovation in chip design, manufacturing, and packaging. According to her, the U.S. \"will be the premier destination in the world where new leading-edge chip architectures can be invented in our research labs, designed for every end-use application, manufactured at scale, and packaged with the most advanced technologies\".&nbsp;</p><p>An obvious reason I am concerned about this Act is that the increased investment in the U.S. semiconductor industry could enable AI capabilities companies in the US, such as OpenAI, to overcome computing challenges they may face right now. Additionally, other countries, such as the U.K. and the Member States of the EU, seem to be following suit. For example, the U.K. recently launched a research project aimed at building on the country's strengths in design, compound semiconductors, and advanced technologies. The European Chips Act also seeks to invest \u20ac43 billion in public and private funding to support semiconductor manufacturing and supply chain resilience. Currently, the Members of the European Parliament, are preparing to initiate talks on the draft Act.</p>", "user": {"username": "AryanYadav"}}, {"_id": "oQyMgPu8pQbCKxHjQ", "title": "An economics of AI gov - best resources for", "postedAt": "2023-02-26T11:11:45.364Z", "htmlBody": "<p>Hi all,&nbsp;</p><p>I am interested in AI gov from the economics perspective. I did some research myself, but there seems to be a lot of materials and I have hard time assessing their relevance. Could you please help? I'm looking for written materials (transcripts are ok). My overall focus area would be macroeconomics of AI, with a heavy use of econometrics (forecasting seems to be particularly interesting, but some other things are ok too). I'm working as a macroeconomist focused on data analysis, so too introductory materials won't bring much value. When it comes to AI, I have something which I would describe \"a solid understanding of the basics\", but prefer \"dealing with too advanced or unknown concepts while reading\" over too simple, boring texts. Please link specific articles/books, not whole websites :). Thanks!</p>", "user": {"username": "Liv"}}, {"_id": "sC69HBdkLuq58Yzpw", "title": "How to \u2018troll for good\u2019: Leveraging IP for AI governance", "postedAt": "2023-02-26T06:34:24.146Z", "htmlBody": "<p>A new <em>Science</em> paper proposes using existing intellectual property law to create and enforce AI regulation, an approach much faster than traditional legislation.</p>\n<p>\u201cLeveraging IP for AI governance\u201d by Cason Schmit, Meg Doerr and Jennifer K. Wagner:</p>\n<blockquote>\n<p>Our model leverages two radically different approaches to manage intellectual property (IP) rights. The first is copyleft licensing, which is traditionally used to enable widespread sharing of created content, including open-source software. The second is the \u201cpatent troll\u201d model, which is often derided for suppressing technological development.</p>\n</blockquote>\n<p>Copyleft licensing is designed to spread virally. Examples include the GNU General Public License (GPL) and the Creative Commons ShareAlike license.</p>\n<p>This idea has been discussed in the forum before. See <a href=\"https://forum.effectivealtruism.org/posts/dsEMaqKNmArdCRGeH/a-viral-license-for-ai-safety\">A Viral License for AI Safety: The GPL as a Model for Cooperation</a> by Ivan Vendrov and Nat Kozak.</p>\n<p>Another related project is <a href=\"https://www.licenses.ai/\">Responsible AI Licenses (RAIL)</a> and their paper \"<a href=\"https://facctconference.org/static/pdfs_2022/facct22-63.pdf\">Behavioral Use Licensing for Responsible AI</a>.\"</p>\n", "user": {"username": "Michael Huang"}}, {"_id": "ZkmHJhwi22rwfW8gj", "title": "Which movies have been most effective at expanding your moral circle?", "postedAt": "2023-02-26T02:34:03.224Z", "htmlBody": "<p>I'm curious which movies you've seen that have been effective at broadening which kinds of people, animals, or other sentient beings you've considered worth including in your 'moral circle' of concern -- especially movies that are congruent with EA-style reasoning (e.g. scope-sensitive consequentialism), rather than just emotional manipulation through provoking empathy for specific individuals.</p>", "user": {"username": "geoffreymiller"}}, {"_id": "mAEEMADmYdHYneG4b", "title": "Bayes is Out-Dated, and You\u2019re Doing it Wrong", "postedAt": "2023-02-25T23:25:19.097Z", "htmlBody": "<p>&lt;sharing it here, too...&gt;</p><p>~ <i>a community of Bayes-enthusiasts fumble statistical inference</i> ~</p><p><strong>TL;DR</strong> \u2014 Industry uses Dirichlet Process and SAS, NOT Bayes. Bayes is persistently *wrong* and lacks a great deal of important information. Supposed \u2018rationalists\u2019 cling to Bayes as the Ultimate Truth, without knowing enough Mathematics to know they\u2019re wrong.</p><p>\u201c<i>Oh, well my Prior was &lt;preferred assumption&gt; but I guess I have to update with that one data-point that wandered into my life.</i>\u201d \u2014 multiple \u2018Rationalists\u2019 in my year of invading their gatherings</p><p>A weird thing is happening in the Bay Area, slowly creeping into the Zeitgeist: a group of <i>non-mathematicians</i> have decided they found the BEST statistical technique ever, and they want to use it to understand the whole world\u2026 but their technique is <strong>260 YEARS OLD</strong>, and we\u2019ve done a LOT better since then. It\u2019s called Bayes\u2019 Theorem, published in 1763 \u2014 literally 260 candles<i> this </i>year.</p><p>Let\u2019s get a sense of just how out-dated and bizarre it is, to insist you have the One-True-Method when it\u2019s 260 years old: back in 1763, when Bayes was published, there was another new-fangled invention sweeping Europe \u2014 the Dutch Plough. That\u2019s the plough used today by the Amish. Literally,<i> relying on Bayes to draw conclusions is like farming with an Amish plough</i>; it\u2019s hilariously inadequate, and <strong>completely dismissed by industry</strong>.</p><p>That quote at the top is an amalgam of multiple conversations with the Effective Altruists and Astral Codex Ten \u2018Rationalists\u2019 (they made that term up to describe themselves); it\u2019s a persistent theme in their conversations. And, it\u2019s not even the *correct* use of Bayes! Let\u2019s see why:</p><p>In Bayes\u2019 Theorem, you begin with a Prior. These Rationalists pick the Prior that they *prefer*. Neutral Bayesian Priors, however, are the average of all possible assumptions, NOT you\u2019re preferred place to start. These folks\u2019 <i>first</i> step is a disastrous error. Then, when they say \u201cI guess I should update my Prior\u2026\u201d Wait! Why in the world would you ever feel confidence about a belief, when <i>the ONLY thing you have is a Prior</i>? A Prior is, by definition, the state of \u201cno information\u201d when one should have intellectual humility, not certainty!</p><p>Then, they are updating their Bayesian estimate using\u2026. a *few* examples? The Rationalists repeatedly rely upon sparse evidence, while claiming certainty, as if \u201cStatistically Significant Sample Size\u201d just isn\u2019t a thing. Bayes doesn\u2019t *need* statistically significance, apparently! Finally, those examples they use are culled from <i>personal experience</i>. I hope I don\u2019t have to explain to anyone why we need to collect a random sample from representative sub-populations? The supposedly rational Bayes-fans fail on each <i>possible</i> count.</p><p>So, if they correct those mistakes, can they then rely on Bayes to find their precious truths? <strong>Nope</strong>. Bayes is consistently wrong, <i>reliably</i>. That\u2019s why industry doesn\u2019t use it. They\u2019d lose money. Dirichlet lets them make money, because it works better. That\u2019s a stronger proof, empirically, than all the rationalizations of their community\u2019s prominent Bayes-trumpeters: a fiction writer and a psych councilor, both of whom lack relevant experience with statistical analysis software and techniques.</p><p>In particular, the blog of that psych councilor, \u201cAstral Codex Ten\u201d has a tag-line: it quotes Bayes\u2019 Theorem, and follows by saying \u201c<i>all else is commentary</i>.\u201d Everyone who reads his blog, and who then DOESN\u2019T check what statistical techniques are used in the real world, <strong>stays there as part of the community</strong>. They have <i>self-selected</i> for a community of people who call Bayes the be-all-end-all, all of them agreeing they\u2019re right, and they don\u2019t know that they\u2019re horribly wrong\u2026 because they don\u2019t check!</p><p>Think about this for a moment: if you state Bayes\u2019 Theorem, and then claim \u201c<strong>all else is commentary</strong>\u201d while recommending readers use Bayes, you are implicitly claiming \u201c<i>NO further improvements</i> in statistical analysis have occurred in the <strong>260 years</strong> since Bayes was published; Student-t Distributions, Levi Distributions, they don\u2019t even need to exist!\u201d That\u2019s the core tenet of the Bay Area Rationalists\u2019 luminary, addicted to Bayes.</p><p>Wait, so why and how is Dirichlet such an improvement?</p><p>Let\u2019s imagine you took a survey in some big city, and found (unsurprisingly) a majority Democrats \u2014 it was a 60/40 split, on the nose. That sample\u2019s split is also the \u201cmaximum likelihood\u201d for the potential Population. Said another way, \u201cThe real-world population which is <i>most likely</i> to give you a 60/40 sample is a 60/40 population.\u201d But, does that make 60/40 your best guess for the real population? No.</p><p>Imagine each possible population, one at a time. There\u2019s the 100% Democrat population, first \u2014 what is the *likelihood* of such a population producing a 60/40 sample? Zero. What about 99% Democrat? Well, then it\u2019ll depend upon how *many* people you surveyed, but there is just a <i>tiny</i> chance the real population is 99% Democrat! Keep doing that, for every population, all the way to 99% Republican, then 100% Republican. Whew! Now, you have a *likelihood* distribution, the \u201clikelihood of population X generating sample Y.\u201d</p><p>When we look at this distribution, for data that falls in two buckets (D/R), then we\u2019ll notice something: the *peak* likelihood is at 60/40, but there\u2019s ALSO a bunch of probability-mass on the 50/50 side of the curve, creating a tilt to the over-all probability. While the \u2018mode\u2019 of the likelihood distribution is still the 60/40 estimate, the actual \u2018mean\u2019 of that distribution is closer to 50/50, every time! You *should* expect that the true population is closer to an *equal division* among buckets. When you collect more samples, you narrow that distribution of likelihoods, so you see less drift toward 50/50. That\u2019s the reason you want a \u2018statistically significant sample size\u2019.</p><p>Let\u2019s look at that other aspect Dirichlet possesses, which Bayes wholly lacks: <i>Confidence!</i></p><p>When you look at the likelihood of each population, the chance of it producing your observed sample, you can also ask: \u201cHow far AWAY from our best guess would we need to place boundaries, such that we include 95% of the possible populations\u2019 likelihoods within our bounds?\u201d That\u2019s called your Confidence Interval! You may have only learned the trimmed-down simplicities and z-score tables in your Stat 101 class, but there\u2019s a reason for why they can claim confidence: that interval of population-estimates contains 95% of the likelihood-distribution\u2019s probability-mass!</p><p>Finally, let\u2019s consider \u201cthe cost of being wrong\u201d. Bayes <strong>doesn\u2019t</strong> balance your prediction according to the cost of being wrong; Dirichlet\u2019s distribution over potential populations can simply be *multiplied* by the cost of each error-distance, and then the mode of that distribution will \u201c<i>minimize the COST of being WRONG</i>.\u201d You can even multiply by costs which are discontinuous or ranges, producing high and low bounds and nuanced thresholds of risk. Definitely better than Bayes.</p><p>Now, Dirichlet isn\u2019t even the be-all-end-all\u2026 it was published in 1973, <i><strong>50 years old</strong></i> THIS year! SAS has trade secrets since the 70\u2019s, and invests <strong>2.5x</strong> more into R&amp;D than the <i>TECH</i>-industry average! If you want to pass muster for pharmaceuticals in front of the FDA, <strong>you send all your data to SAS</strong>. It\u2019s required, because they\u2019re soooo damn GOOD! So, unless you work at SAS (which has the <i>highest profits per employee hour</i> of all companies on <strong>Earth</strong>, and has expanded consistently since 1976\u2026 consistently rated one of the best employers on the planet\u2026) then you DON\u2019T know the be-all-end-all statistical technique \u2014 and neither do Scott Alexander or Eliezer Yudkowski, as much as they\u2019d like you to believe otherwise. Just for reference, when \u201cyou think you\u2019re right BECAUSE you don\u2019t know enough to know you\u2019re wrong,\u201d that\u2019s called the Dunning-Kreuger Effect, dear Rationalists.</p>", "user": {"username": "Anthony Repetto"}}, {"_id": "5KsrEWEbc4mwzMTLp", "title": "Some more projects I\u2019d like to see", "postedAt": "2023-02-25T22:22:51.618Z", "htmlBody": "<p>I recently wrote about some <a href=\"https://www.finmoorhouse.com/writing/ea-projects\">EA projects I\u2019d like to see</a> (also on the<a href=\"https://forum.effectivealtruism.org/posts/8ic7KcxyfchhmGP3x/ea-projects-i-d-like-to-see\"> EA Forum</a>). This went well!</p><p>I suggested I\u2019d write out a few more half-baked ideas sometime. As with the previous post, I make no claim to originating these ideas, and I\u2019ll try to attribute them where possible. I also make no claim to being confident that all the ideas are any good; just that they seem potentially good without much due diligence. Since many of these are based on shallow dives, I\u2019ve likely missed relevant ongoing projects.</p><p>If you\u2019re considering writing a similar list, at the end of this post I reflect on the value of writing about speculative project ideas in public.</p><p>The order of these ideas is arbitrary and you can read any number of them (i.e. there\u2019s no thread running through them).</p><h2>Summary</h2><ul><li>Fermi games</li><li>BOTEC tools</li><li>Billionaire impact list</li><li>Forecasting guide</li><li>Short stories about AI futures</li><li>Technical assistance with AI safety verification</li><li>Infosec consultancy for AI labs</li><li>Achievements ledger</li><li>World health dashboard</li><li>The Humanity Times</li></ul><h2>Fermi games</h2><p>Many people are interested in getting good at making forecasts, and spreading good forecasting practice. Becoming better (more accurate and better calibrated) at forecasting important outcomes \u2014 and being willing to make numerical, testable predictions in the first place \u2014 often translates into better decisions that bear on those outcomes.</p><p>A close (and similarly underappreciated) neighbor of forecasting is the <i>Fermi estimate</i>, or <i>BOTEC</i>. This is the skill of considering some figure you\u2019re uncertain about, coming up with some sensible model or decomposition into other figures you can begin guessing at, and reaching a guess. It is also the skill of knowing how confident you should be in that guess; or how wide your uncertainty should be. If you have interviewed for some kind of consulting-adjacent job you have likely been asked to (for example) size a market for whiteboard markers<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwlgat9tft5\"><sup><a href=\"#fnwlgat9tft5\">[1]</a></sup></span>; that is an example.</p><p>As well as looking ahead in time, you can answer questions about how the past turned out (\u2018retrocasting\u2019). It\u2019s hard to make retrocasting seriously competitive, because Google exists, but it is presumably a way to teach forecasting: you tell people about the events that led up to some decision in a niche of history few people are familiar with, and ask: did X happen next? How long did Y persist for? And so on. You can also make estimates without dates involved. Douglas Hofstadter <a href=\"https://www.gwern.net/docs/math/1982-hofstadter.pdf\">lists some examples</a> in <a href=\"https://en.wikipedia.org/wiki/Metamagical_Themas\">Metamagical Themas</a>:</p><ul><li>How many people die per day on the earth?</li><li>How many passenger-miles are flown each day in the U.S.?</li><li>How many square miles are there in the U.S.? How many of them have you been in?</li><li>How many syllables have been uttered by humans since 1400 A.D.?</li><li>How many moving parts are in the Columbia space shuttle?</li><li>What volume of oil is removed from the earth each year?</li><li>How many barrels of oil are left in the world?</li><li>How many meaningful, grammatical, ten-word sentences are there in English?</li><li>How many insects [\u2026] are now alive? [\u2026] Tigers? Ostriches? Horseshoe crabs?</li><li>How many tons of garbage does New York City put out each week?</li><li>How fast does your hair grow (in miles per hour)?</li><li>What is the weight of the Empire State Building? Of the Hoover Dam? Of a fully loaded jumbo jet?</li></ul><p>Again, most forecasts have a nice feature for evaluation and scoring, which is that before the time where a forecast resolves nobody knows the answer for sure, and after it resolves everyone does, and so there is no way to cheat other than through prophecy.</p><p>This doesn\u2019t typically apply for other kinds of Fermi estimation questions. In particular, things get really interesting where nobody <i>really</i> knows the correct answer, though a correct answer clearly exists. This pays when \u2018ground truth\u2019 answers are a rarity.</p><p>Nonetheless I think that doing Fermi estimates well <i>is</i> a teachable and testable skill! Here are some general reasons:</p><ul><li>Even if you\u2019re estimating a number where there is no agreed answer, you will likely appeal to numbers which we do know. You can know more or fewer of those important numbers. This kind of knowledge is straightforwardly memorisable and testable.</li><li>Where memorisation isn\u2019t practical, you can learn to quickly estimate certain kinds of number by some process of finding the right comparisons and getting a feeling for what counts as a sensible prior. These guesses again are testable.</li><li>Independent of accuracy, good BOTECs are instructive, such as by telling you which parameters the outcome is most sensitive to; or what the parameters would have to be in order for the overall guess to meet some condition. BOTECs can be evaluated by experts on the grounds of how informative they are, independent of the accuracy of the bottom line estimates.Independent of accuracy, good BOTECs are <i>instructive</i>, such as by telling you which parameters the outcome is most sensitive to; or what the parameters <i>would have to be</i> in order for the overall guess to meet some condition. BOTECs can be evaluated by experts on the grounds of how informative they are, independent of the accuracy of the bottom line estimates.</li><li>Some people are better at estimating known quantities, and those people are often going to be the same people who have strong track records at forecasting, which is harder to game. We should expect these people to do better at estimating unknown quantities also, so we can use these people\u2019s estimates as a noisy benchmark for other people\u2019s estimates.</li><li><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4001628\">As with forecasts</a> that won\u2019t resolve soon enough, you can use <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3954498\">\u2018reciprocal scoring\u2019</a> methods where players are incentivised to predict the estimates of other players<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefa7zq0ito6sg\"><sup><a href=\"#fna7zq0ito6sg\">[2]</a></sup></span>&nbsp;and get rewarded accordingly. Where there are no obvious reasons to expect bias, I expect that aggregated BOTEC-style estimates do better than individual estimates for \u2018<a href=\"https://www.investopedia.com/terms/w/wisdom-crowds.asp\">wisdom of the crowd</a>\u2019 reasons.</li></ul><p>So how could we encourage and evaluate the skill of \u201cmaking sensible estimates of important but nonobvious numbers\u201d?</p><p>One suggestion could be to outsource the work to specialists, which could look like a consultancy-style organisation which can take in even somewhat vague requests for crucial-but-unclear numbers, and give back a model and an estimate. This feels like a minor extension to what some existing forecasting/research-as-a-service orgs do and indeed I expect some of them already do something like this. Example use case: a major org is considering funding a speculative project, but the expected value of doing so depends on some key variables that they\u2019re unsure how to estimate. They use a BOTEC-on-demand service to corroborate their best guess, and check for wishful thinking.</p><p>But a class of suggestions I\u2019m especially interested in involves web-based games or tests designed to cultivate aptitude and interest in making good Fermi estimates.</p><p>Here\u2019s one concrete idea: a website that gives everyone the same number to estimate every day, Wordle-style. At one extreme of simplicity, these numbers could just be tests of a kind of world-literacy. Examples:</p><ul><li>How many farm animals are alive right now?</li><li>Roughly how many humans have ever been born?</li><li>In percentage points, what fraction of US GDP is spent on foreign aid?</li></ul><p>For examples of exactly what I have in mind, see <a href=\"https://forum.effectivealtruism.org/users/linch\">Linch</a>\u2019s post: <a href=\"https://forum.effectivealtruism.org/posts/ekWRyJr9JneoWe5eH/what-are-some-key-numbers-that-almost-every-ea-should-know\">What are some key numbers that (almost) every EA should know?</a>, and the associated <a href=\"https://forum.effectivealtruism.org/posts/o9SLSkPJ6A2MWb9Bf/anki-deck-for-some-key-numbers-that-almost-every-ea-should\">Anki deck</a> from <a href=\"https://forum.effectivealtruism.org/users/pablo_stafforini\">Pablo</a> and <a href=\"https://forum.effectivealtruism.org/users/jablevine\">jablevine</a>.</p><p>Of course you could also be asked questions which can\u2019t so easily be answered by recall (but where a ground truth still exists). For instance: how many kilotons of <a href=\"https://en.wikipedia.org/wiki/TNT_equivalent\">TNT equivalent</a> exists per living person for all the functional nuclear weaponry in the world?</p><p>In either case, you\u2019d be asked to give an order of magnitude estimate (maybe it\u2019s <a href=\"https://en.wikipedia.org/wiki/Scientific_notation\">scientific notation</a>), so you write in the power of ten and the coefficient each as an integer. Then, like Geoguessr, you get scored on accuracy (on a log scale).</p><p>Perhaps there are ways to automate question generation; e.g. by scraping <a href=\"https://ourworldindata.org/\">Our World in Data</a> or Wikipedia, and/or by combining a database of known numbers (e.g. world population, <a href=\"https://ourworldindata.org/grapher/animals-slaughtered-for-meat\">chickens slaughtered per year</a>) and combining them to give new questions (e.g. chickens slaughtered per year per living person). Or more creative questions could be curated by volunteers.</p><p>You could try the new question each day, and get a running accuracy score, which you could compare with friends. Each question could link to a resource to learn more about the key number and how it was worked out.</p><p>Alternatively, it could be framed more like a test than a game \u2014 more similar to the <a href=\"https://www.guidedtrack.com/programs/icg4cze/users/sign_in?return_to=%2Fprograms%2Ficg4cze%2Fembed%2FExgSMgg2UBaSyw5OMr6d1VZc0xrgf3SvMGhJr6PjEHc%2Fcomplete\">excellent web tool</a> developed by Spencer Greenberg and others for testing your calibration (here\u2019s <a href=\"https://www.openphilanthropy.org/research/new-web-app-for-calibration-training/\">an announcement post</a>). Indeed, even building on that idea to make it much more accessible to a wider audience seems great. If you\u2019re interested in doing that, <a href=\"https://docs.google.com/document/d/1hLqTomwYkxd0Mt5ZpWxUE_TiULn22cL1n9KhEZtEyGo/edit#\">here are some reflections</a> that Spencer wrote up. It could even be multiplayer: questions are generated from a number bank, and players have some set time to guess the right order of magnitude.</p><p>In fact, an alternative and maximally simple version would just be a test of your knowledge of a large number of these key figures. Perhaps it\u2019s an exam of 100 questions, where you get a score on your accuracy at the end. Similar to the excellent <a href=\"https://upgrader.gapminder.org/\">Gapminder quiz</a>. I\u2019d also be interested to know which key numbers people get most directionally wrong.</p><p>Or maybe it could work like a (series of) guided course(s), where you only pass through each stage by scoring highly on a test of recall, after learning about the key numbers in context.</p><p>There is clearly a tradeoff here, where the numbers with the least disputable and easiest to google answers are often the ones that rely the least on the BOTEC skills, while the numbers that are most similar to <i>crucial numbers that rely on good sense for making difficult BOTECs</i> are often those without indisputable answers, and so are harder to test. But I hope there\u2019s at least some skill transfer between \u201cquestions with easily evaluable answers\u201d and \u201cactually important questions without ground-truth answers\u201d.</p><p>While I\u2019m throwing half-formed ideas out, here\u2019s another one: a site for crowdsourcing BOTECs<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefx35fp4692vq\"><sup><a href=\"#fnx35fp4692vq\">[3]</a></sup></span>. Imagine a site like <a href=\"https://www.metaculus.com/\">Metaculus</a> or <a href=\"https://manifold.markets/\">Manifold Markets</a>, where people list questions they\u2019d love to get help with estimating. So you post a question, and others post their models and their bottom-line guesses (maybe most these models end up being links to <a href=\"http://getguesstimate.com/\">Guesstimate</a> sheets). Different people\u2019s guesses get combined into an aggregate guess.</p><p>Of course, weighting, ranking, and scoring these guesses is trickier than for prediction markets and their outgrowths: for instance, the price a binary option trades at essentially depends on the fact that the question will eventually resolve, and the option will expire at e.g. either $0 or $1. But all is not lost: other users could upvote other people\u2019s models in good faith, and those people\u2019s models going forward could then get weighted higher in aggregate guesses. I also wonder if viewing the aggregate guess should preclude you from contributing your own guess, so you could introduce some incentives to guess the aggregate answer before you make your own (and then your own guesses can get weighted with how good you are at guessing aggregate guesses). The same idea could work for voting between discrete categories as well as estimating continuous variables.</p><p>I should re-emphasise that the skills that are instrumental for making sensible BOTEC-style estimates of important numbers are <i>really</i> valuable. They also seem learnable through practice, which is why tools to practice them seem promising to me.</p><p><strong>Edit:</strong> shortly after writing this, this was posted to the EA Forum: <a href=\"https://forum.effectivealtruism.org/posts/XDwnGK7x4EjkaHbje/the-estimation-game-a-monthly-fermi-estimation-web-app\">\u2018The Estimation Game: a monthly Fermi estimation web app\u2019</a>. It is amazing and very very close to what I had in mind. Kudos!</p><h2>BOTEC tools</h2><p>Earlier I asked: how could we encourage and evaluate the skill of \u201cmaking sensible estimates of important but nonobvious numbers\u201d? Another suggestion is to build more infrastructure to facilitate building models and representing uncertainties.</p><p>Ozzie Gooen\u2019s <a href=\"https://getguesstimate.com/\">Guesstimate</a> is an awesome example of this: it\u2019s a web app for estimating uncertain quantities by plumbing together other uncertain quantities. One thing that makes it different from a standard spreadsheet is the ability to express how you expect different quantities to be distributed. Guesstimate then samples from all the distributions in the model a bunch of times, Monte Carlo style, to show how your uncertainty should be distributed over outcomes.</p><p>Ozzie\u2019s next project, as part of the <a href=\"https://quantifieduncertainty.org/\">Quantified Uncertainty Research Institute</a>, is to build a programming language for making uncertain estimates, called <a href=\"https://www.squiggle-language.com/\">Squiggle</a>. Making probabilistic estimates involves different kinds of distributions over variables, then sometimes combining those distributions, doing sensitivity analysis, visualising your new distribution, and so on. The thought is that it\u2019s very clumsy to do this with e.g. Python plus a bunch of data viz libraries. I\u2019m excited about Squiggle, and I think it could be useful to explore related ideas in the space of what it is trying to achieve (because I think this is a large and relatively underexplored space).</p><p>Here is one idea from Tom Adamczewski, copying from (and minorly redacting) an email exchange with his permission:</p><blockquote><p>I have a specific idea for a tool in this space: combining the best of<a href=\"https://workflowy.com/\"> Workflowy</a> (collapsible and zoomable tree views),<a href=\"https://www.getguesstimate.com/\"> Guesstimate</a> (intuitive Monte Carlo), and<a href=\"https://www.palisade.com/\"> Palisade</a> (handle complex models without slowing to a crawl [\u2026]), and<a href=\"https://www.squiggle-language.com/\"> Squiggle</a> (programming language / domain-specific language). Also, tailoring the tool based on requests from specific organisations [\u2026] could give an edge in altruistic terms.</p><p>My vision is for a tool for quantitative estimates that combines the best of the following:</p><ul><li><a href=\"https://workflowy.com/\">Workflowy</a> (collapsible and zoomable tree views)</li><li><a href=\"https://www.getguesstimate.com/\">Guesstimate</a> (intuitive Monte Carlo)</li><li><a href=\"https://www.palisade.com/\">Palisade</a> (handle complex models without slowing to a crawl [\u2026])</li><li><a href=\"https://squiggle-language.com/\">Squiggle</a> (programming language / domain-specific language)</li></ul><p>So in the Workflowy-like view the root node would be the thing you\u2019re trying to estimate, and children of any node would be the parameters it depends on, so that the entire model is represented as a tree. You would be able to manipulate the model in this tree-like view.</p><p>[Can give lots more detail, I have a pretty specific vision and this is a massively compressed version of that]</p><p>[...]</p><p>One nice thing is you could pretty easily create the ability to import/export Excel spreadsheets, where they would be represented as trees/graphs (nodes would be cells and edges would be cell references). So people wouldn\u2019t have to re-create their models from scratch. I think the Excel interoperability (even if imperfect) would be a huge win for adoption. Lots of orgs run on spreadsheets.</p></blockquote><p>Let me or Tom know if you\u2019d be excited about helping build this.</p><p>I will add: the core idea that stands out to me here is the idea of combining the \u2018nested node\u2019 structure of Roam, Workflowy etc. with a quantitative focus. It stands out because, in my experience, this is how BOTECs tend to work: you begin with a bottom-line number, and you recursively break the number down into smaller components. In fact, machinery for expressing and combining probability distributions don\u2019t seem central to me and probably wouldn\u2019t need to feature in an initial version.</p><p>I\u2019ll also add that I\u2019m excited about the possibility of a composable, social aspect to any of these new tools. When you\u2019re making BOTECs, you might want to reference community predictions, such as from Metaculus or Manifold (<a href=\"https://www.metaculus.com/api2/\">both</a> <a href=\"https://docs.manifold.markets/api\">have</a> APIs), or indeed other sources of information from the internet (like stock prices). That way, you get to build a model which doesn\u2019t require constant manual input, or otherwise quickly go out of date.</p><p>In turn, you could share your own model for other people to plug in to their own<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9vqh6f9ruh\"><sup><a href=\"#fn9vqh6f9ruh\">[4]</a></sup></span>.</p><p>eople also talk about \u2018belief-mapping\u2019 software as if it\u2019s a well-established micro-genre. I\u2019m still not exactly sure what this is, but here\u2019s something that sounds to me like \u2018belief-mapping\u2019: I\u2019d love a way to log my credences in different things, as well as richer kinds of beliefs like confidence intervals and distributional forecasts. A combination of a spreadsheet plus <a href=\"https://www.foretold.io/\">Foretold.io</a> can do all of this so far. But it could also be neat to express how beliefs must relate. For instance, if I update my credence in (A), and I\u2019ve already expressed my credence in (B|A), then the software can tell me what my new credence in (B) should be, and update it if it seems reasonable. I could also say things like: \u201cmy credence in the disjunction <i>A or B or C</i> is 80% \u2014 so when I change one of A or B or C, please adjust the other two to add back up to 80%\u201d. Or suppose I give some probability distribution over time for a \u201cwhen will\u2026\u201d question, and then time passes and the event doesn\u2019t happen. Then I need to redistribute the probability mass that I put on times where the probability is now definitely zero. It could be cool to instruct some piece of software to do this automatically, especially if I\u2019m trying to keep track of many forecasts.</p><p>Basically, I have some impression that forecasting involves many automatable \u2018consistency-checking\u2019-type tasks, and it could be very useful to offload them to a piece of software which helps track and \u2018supervise\u2019 your beliefs.</p><p>The <a href=\"https://quantifieduncertainty.org/2cb83aa3c1f54066b7f0e21446ec96ef\">\u2018vision\u2019 page</a> on the website for the Quantified Uncertainty Research Institute is another source of optimism on this front.</p><h2>Billionaire impact list</h2><p><strong>The idea:</strong> a research effort to understand and evaluate the giving behaviours of the wealthiest people in the world, and an online resource celebrating the most impactful donors (and pointing out opportunities for some donors to do better).</p><p>With certain high-profile exceptions, the giving behaviours of very wealthy people are not widely known. I feel good about a culture where the wealthiest people in the world are strongly expected to give at least 10% of their wealth to making the world better, and for centimillionaires and billionaires more like 90% or 99%.</p><p>It\u2019s not just about the fraction of wealth committed as donations. Often donations are moved into foundations who disburse their endowment slowly and inscrutably. And (of course) charitable projects <a href=\"https://80000hours.org/2023/02/how-much-do-solutions-differ-in-effectiveness/\">vary very widely</a> in their (predicted and measured) effectiveness. It\u2019s a shame this isn\u2019t all better known. I also feel good about a culture which celebrates large donations thoughtfully and transparently targeted at making as large a positive difference as possible; and calls out its opposite (including giving which is nakedly status-seeking, or herd-following).</p><p>In order to bite, norms like this require certain kinds of (common) knowledge about the giving behaviours of very wealthy people: who isn\u2019t giving? Who is? What are they giving to? What has this achieved?</p><p>The central idea here is just a list of the wealthiest people in the world, with known details about their giving. There should be ways to highlight the best examples \u2014 people who have clearly thought hard about how to do good with their wealth, and are giving away most of it. My guess is that there is enough data to take a stab at roughly ordering the world\u2019s wealthiest people by absolute and percentage amounts committed to charitable giving. Evaluations of the effectiveness of that giving are crucial, but I\u2019d guess they would have to be more editorial.</p><p>Forbes actually has a <a href=\"https://www.forbes.com/sites/rachelsandler/2022/09/27/the-forbes-philanthropy-score-2022-how-charitable-are-the-richest-americans/?sh=79395e5ca098\">\u2018Philanthropy score\u2019</a> which is cute, but as far as I can tell it neglects to really discuss what the biggest givers have achieved or plan to achieve. It also doesn\u2019t seem to count pledged / committed spending that hasn\u2019t already been spent down.</p><p>Kelsey Piper <a href=\"https://twitter.com/KelseyTuoc/status/1446559549754789891\">suggested basically this idea</a> in 2021: \u201cI should have a live ranking of billionaires by how cool they are, based on how much good I think their giving is doing. Then the billionaires will all be pressured to give more impactfully by their desire to be at the top of my list of who is the coolest.\u201d I\u2019m not sure if anything came of it.</p><p>I\u2019d also be interested in more research into the world of private charitable foundations, and generally what happens to large amounts of philanthropic money after it is committed. Again, my impression is that these foundations are often somewhat opaque, and often fail to disburse their endowments before the client donor dies.</p><p>After thinking about this and discussing it with others, here\u2019s a more concrete version I can most imagine working:</p><ul><li>Everything lives on a website with the simple pitch of trying to become the definitive source on how much positive impact billionaires are having through their giving</li><li>You can view a list of the (say) top 100 wealthiest people in the world, ranked by percentage donated or pledged; and absolute amount donated or pledged. Based on available data.</li><li>Then there is an editorial side to the website, with:<ul><li>Stories of targeted giving having an outsized impact;</li><li>Spotlights on donors, including outside of the top 100 list, who are leading the way on effective giving;</li><li>Spotlights on donors whose donation track record seems small, opaque, or non-existent</li></ul></li></ul><p>There\u2019s a clear call to action: the wealthiest people in the world should be taking the <a href=\"https://givingpledge.org/\">Giving Pledge</a>, they should ultimately be giving 90%+ of their wealth, and they should try to do the most good that they can through that giving.</p><h2>Forecasting guide</h2><p>I am not aware of a go-to guide for the skills of forecasting. Instead, my impression is that excellent forecasters learn piecemeal \u2014 by example, from others, and sometimes through half-related books. I like the idea of a well-produced guide, c. 5 hours long or so \u2014 at a similar level of rigour to one of <a href=\"https://bluedotimpact.org/\">BlueDot\u2019s \u201cfundamentals\u201d courses</a>.</p><p>For instance, the main content could be screen-recorded videos, plus the course could contain some exercises. Ideally, having worked through this course would count as a decent signal of halfway-competence at forecasting.</p><p>I\u2019d be interested in learning about:</p><ul><li>Motivations for getting forecasting skills: why care?</li><li>Basic maths-y concepts underlying different kinds of forecasts. How does scoring work? What\u2019s a distribution?</li><li>Basic skills for not being reliably terrible: adjusting from base rates, paying attention to your calibration, etc.</li><li>Tricks and advice which seems to help from experienced forecasters.</li></ul><p><a href=\"https://www.youtube.com/watch?v=e6Q7Ez3PkOw\">Alex Lawsen\u2019s video series</a> is great but it\u2019s a bit scrappily produced \u2014 I think Alex intended for it to be an MVP. There is also <i>Superforecasting</i>, there are <a href=\"https://www.metaculus.com/tutorials/\">tutorials on Metaculus</a>, and many blog posts.</p><h2>Short stories about AI futures</h2><p><strong>The idea:</strong> A book of short stories depicting details about how transformative AI could play out (at different stages, and different kinds of catastrophe or (even) success).</p><p><strong>Why?</strong> When I try telling people about arguments for AI risk, I often speak in abstractions: AI systems might be generally more powerful than humans such that they could <a href=\"https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/\">defeat all of us combined</a>; and they might end up dangerously misaligned by default.That invites the response: \u201cok, but what will AI actually do to us? How does it gain power? How do we lose power? Are you talking about the slow erosion of influence through subtle means like currency manipulation and mass disinformation, or are you talking about death robots?\u201d</p><p>Writing about AI risk gestures at concrete examples (such as <a href=\"https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/#how-this-could-work-if-humans-create-a-huge-population-of-ais\">here</a>, <a href=\"https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like\">here</a>, and <a href=\"https://80000hours.org/articles/what-could-an-ai-caused-existential-catastrophe-actually-look-like/\">here</a>). But when you\u2019re advancing general arguments for AI risk, it\u2019s fair not to dwell on detailed and concrete stories: since most people are very uncertain about what something like AI takeover looks like in its details, any particular story is going to occupy a small slice of probability mass. If an argument for AI risk dwelt entirely on a story where AI exploits a major undiscovered zero day in a popular operating system to gain leverage through holding computer systems ransom, then they might invite suspicions that we could duck an AI-related catastrophe by making sure everyone does security updates and takes backups.</p><p>But I do also think that some people should be thinking up implausibly detailed stories of how AI plays out. Daniel Kokotajlo gives a list of reasons for writing detailed vignettes in his <a href=\"https://www.alignmentforum.org/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like\">\u2018What 2026 looks like\u2019</a> post, including:</p><ul><li>\u201cSometimes attempting to write down a concrete example causes you to learn things, e.g. that a possibility is more or less plausible than you thought.\u201d</li><li>\u201cMost stories are written backwards. The author begins with some idea of how it will end, and arranges the story to achieve that ending. Reality, by contrast, proceeds from past to future. It isn\u2019t trying to entertain anyone or prove a point in an argument.\u201d</li></ul><p>AI Impacts ran a <a href=\"https://aiimpacts.org/vignettes-workshop/\">Vignettes Workshop</a>, and their ongoing <a href=\"https://aiimpacts.org/ai-vignettes-project/\">AI Vignettes Project</a> has produced <a href=\"https://airtable.com/shr4mHlTIiKtFRDuR/tblMVjRvMKVNkoZVg?backgroundColor=cyan&amp;viewControls=on\">a dozen vignettes</a> so far. They are very good, and partly I just want to signal boost this kind of work, and encourage other people to try it. The best examples I can think of are Daniel K\u2019s \u2018<a href=\"https://www.alignmentforum.org/posts/6Xgy6CAf2jqHhynHL/what-2026-looks-like\">What 2026 looks like</a>\u2019, Marius Hobbhahn\u2019s <a href=\"https://www.lesswrong.com/posts/qRtD4WqKRYEtT5pi3/the-next-decades-might-be-wild\">\u2018The next decades might be wild</a>\u2019, and also Paul Christiano\u2019s \u2018<a href=\"https://www.lesswrong.com/posts/HBxe6wdjxK239zajf/what-failure-looks-like\">What failure looks like</a>\u2019 (though it\u2019s relatively lighter on specifics).</p><p>However, I understand \u2018vignettes\u2019 to be different from most people\u2019s conception of \u2018short stories\u2019 insofar as (i) you should only be aiming at plausibility when writing vignettes, and not also at other marks of literary quality that might require experience writing fiction; and relatedly (ii) vignettes don\u2019t need to fit a neat story structure, with narrative tension and identifiable characters (they can look more like a series of snapshots). These really are differences rather than weaknesses, but <i>in addition</i> to vignettes, I would especially love to see people work on compelling, well-written <i>stories</i> about AI futures. The process for generating these might involve fiction writers working with AI experts to flesh out / animate existing vignettes.</p><p>With a bit of effort, this kind of writing could make up a book: a collection of imaginative writing about AI futures. Maybe one story depicts a pre-AGI, <a href=\"https://letterboxd.com/film/her/\"><i>Her</i></a>-like regime of advanced conversational assistants. Another considers a hard sci-fi slice of post-singularity success. Many consider various (mutually exclusive) tales of failure. Given the level of AI hype, and given that this hype just might never significantly die down until things get truly transformative, I expect a book advertised as a collaboration between AI experts and writers could catch on.</p><p><strong>Comparisons:</strong> Gwern\u2019s \u2018<a href=\"https://gwern.net/fiction/clippy\">It looks like you\u2019re trying to take over the world</a>\u2019 is exemplary (and weird and terrifying). <a href=\"https://en.wikipedia.org/wiki/Ted_Chiang\">Ted Chiang\u2019s writing</a> seems like the bar to aspire towards on the \u201ccompelling, humane, and memorable\u201d dimension. His writing is culturally influential, also: most notably his story \u201c<a href=\"https://en.wikipedia.org/wiki/Story_of_Your_Life\">Story Of Your Life</a>\u201d was <a href=\"https://letterboxd.com/film/arrival-2016/\">adapted to a film</a>. Perhaps many plausible AI futures are simply too weird to count as \u201chumane\u201d and instead look more like <a href=\"https://www.gregegan.net/BIBLIOGRAPHY/Online.html\">Greg Egan\u2019s short stories</a>. The book <a href=\"https://en.wikipedia.org/wiki/Superintelligence_(film)\"><i>Superintelligence</i></a> sold unexpectedly well, which was a positive update about people\u2019s appetite for weird and difficult writing about AI, and that was before the hype.</p><p>Finally, consider nukes. Movies like <a href=\"https://en.wikipedia.org/wiki/When_the_Wind_Blows_(1986_film)\">When the Wind Blows</a>, <a href=\"https://letterboxd.com/film/threads/\">Threads</a>, and <a href=\"https://en.wikipedia.org/wiki/The_Day_After\">The Day After</a> meant that generations of people grew up with visceral images of the effects of nuclear war. Reagan watched The Day After, and <a href=\"https://www.reaganfoundation.org/ronald-reagan/white-house-diaries/diary-entry-10101983/\">wrote in his diary</a>: \u201cI ran the tape of the movie ABC is running on the air Nov. 20 [\u2026] It\u2019s very effective &amp; left me greatly depressed [\u2026] My own reaction was one of our having to do all we can to have a deterrent &amp; to see there is never a nuclear war. Back to W.H.\u201d. Could stories about AI (or indeed engineered pandemics) have a similar cultural effect?</p><p>Let me know if you\u2019re interested in contributing to this, I can put you in touch with others.</p><p><strong>Caveat:</strong> The next couple ideas are shallow descriptions of ambitious and likely very complicated. Their epistemic status is something like \u201cas an outsider to the relevant bits of AI strategy/governance, and after shallow reflection, these things sound promising to me\u201d. Others with actual expertise surely have more useful things to say.</p><h2>Technical assistance with AI safety verification</h2><p>The <a href=\"https://www.iaea.org/\">IAEA</a> is an international agency responsible for verifying nuclear security agreements, like agreements not to build new nuclear weapons, not to test them, and even to destroy them. They also set, promote, and verify standards for nuclear safety, such as making sure hair-triggers aren\u2019t vulnerable to false alarms.</p><p>I would feel good about a world where this exists for security against existential risk from AI (obviously it wouldn\u2019t be sufficient for security, like how the IAEA\u2019s existence is not sufficient for nuclear security, but I think it would help).</p><p>One version would be an intergovernmental agency. But in an ideas list of mostly websites made in a weekend, a major new international agency might sound too ambitious. Happily I think that a similar idea could work as a private entity. Take <a href=\"https://www.lesswrong.com/posts/SNdijuEn6erTJam3z/how-evals-might-or-might-not-prevent-catastrophic-risks-from#Scenario__Victory\">this quote from Akash Wasil</a> as the target:</p><blockquote><ul><li>A model is subject to a test of some kind.</li><li>If we observe X evidence (perhaps scary capabilities, misalignment, high potential for misuse), then the team developing the model is <i>not</i> allowed to [continue training, scale, deploy] the model <i>until</i> they can show that their model is safe.</li><li>To show that a model is (likely to be) safe, the team must show Y counterevidence.</li></ul></blockquote><p>How could a private entity help move towards the target?</p><ol><li>It could devise and administer the tests for safety</li><li>It could provide technical assistance in running the tests</li><li>It could enable governments to impose restrictions based on the results of the evaluations</li><li>It could impose soft pressures on firms to comply with the evaluations, such as through issuing certification</li></ol><p>The first two stand out as natural first steps.</p><p>Akash points out that this is similar to Information Sharing and Analysis Centers (<a href=\"https://www.enisa.europa.eu/topics/national-cyber-security-strategies/information-sharing\">ISACs</a>) in the context of cybersecurity.</p><p><strong>Why not?</strong> I guess the obvious worry is that the closer AI systems are to posing existential risk, the less we should hope for a simple tests to work, unless somehow the tests scale in sophistication with the systems being tested. The fact that humans can fairly easily deceive other humans about their trustworthiness is pessimistic evidence.</p><p>See:</p><ul><li><a href=\"https://intelligence.org/2017/10/13/fire-alarm/\">There\u2019s No Fire Alarm for Artificial General Intelligence</a></li><li><a href=\"https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/#global-monitoring\">Racing through a minefield: the AI deployment problem</a></li></ul><h2>Infosec consultancy for AI labs</h2><p>It seems robustly bad for big AI labs to be vulnerable to various kinds of hacking and espionage.</p><p>One thing that could mean is to get really good at information security in this context, and then go and work at a major AI org.</p><p>But I don\u2019t think you need to wait for these orgs to start hiring \u2014 you could start a consultancy and offer information security as a service to various orgs. Cybersecurity consultancies are big business, but I expect the AI lab context is niche enough to warrant a specialised shop.</p><p>I don\u2019t have much else to add!</p><p>See:</p><ul><li>Holden Karnosky <a href=\"https://www.cold-takes.com/jobs-that-can-help-with-the-most-important-century/#information-security\">on careers in information security</a></li><li><a href=\"https://80000hours.org/podcast/episodes/nova-dassarma-information-security-and-ai-systems/\">Nova DasSarma on why information security may be critical to the safe development of AI systems</a></li></ul><h2>Achievements ledger</h2><p><strong>The idea:</strong> to spend some time collecting and showcasing exciting projects aimed at positive impact, especially for reducing existential risk and improving the long-term future. Past and present. This could be a website, where you can filter by cause, and learn about:</p><ul><li><strong>Concrete successes.</strong> What kind of progress have these projects made?</li><li><strong>Promising new projects.</strong> Which projects are walking the walk right now? Who\u2019s got a plan to bring about a specific improvement in the world, or to fix a specific problem?</li></ul><p>It could be more editorial, similar to Vox\u2019s <a href=\"https://www.vox.com/future-perfect/23399287/future-perfect-50-change-agents\">\u2018Future Perfect 50\u2019</a>. Or it could be more functional \u2014 minimally it could just be an open and collaborative Airtable database.</p><p><strong>Why?</strong> One reason is that deliberately focusing on object-level projects can help anchor conversations which otherwise tend to float upwards towards the meta level. In particular, I think a project like this could benefit the effective altruism community. When people talk about communities and ideas associated with effective altruism, conversations very often take place at the meta-level or otherwise at high levels of abstraction. To add a meta-level comment of my own: I\u2019m concerned that too little room (within and beyond effective altruism) is left for picking apart concrete ideas; for reasons partly expressed <a href=\"https://forum.effectivealtruism.org/s/KeipizrSxYFuyuyow/p/J3gZxFqsCFmzNosNa\">here</a>. In other words, boosting concrete achievements and ongoing projects with specific and object-level aims might help to avoid EA \u2018discourse\u2019 becoming the exclusive subject of EA discourse.</p><p>I am aware that this project idea is essentially a \u2018meta\u2019 idea.</p><p>Another reason is motivational: I worry that many people associated with effective altruism are reflexively self-critical, such that when the outside world doesn\u2019t give positive feedback, they\u2019re left with no source of positive feedback. This is just a downer. On the other hand, projects which took root from outside the community can teach and inspire.</p><p>A variation on this idea is to make it more reflexively about EA\u2019s track record so far: a kind of stock take. Taking stock of achievements within a field or paradigm seems like a good way to guide beliefs about which sub-areas are most tractable, and whether the field has struck a good balance of things like community building on one hand, and producing legible results on the other. I suspect it is sometimes easy to overestimate the number of people in a field who have a plan and are actually giving it an earnest shot. And for what it\u2019s worth, I mostly have different kinds of longtermist work in mind here.</p><p><strong>Why not?</strong> One obvious consideration is that it is often appropriate to be discreet about some achievements and ongoing projects for many reasons, such as if the work is attention hazardous. This might apply to a large fraction of all the work in a field, especially in the longtermist context.</p><p><strong>Two relevant posts:</strong></p><ul><li>Owen Cotton-Barratt writes: <a href=\"https://forum.effectivealtruism.org/posts/TruJuwtdfszFJgzwB/longtermist-ea-needs-more-phase-2-work\">Longtermist EA needs more Phase 2 work</a></li><li><a href=\"https://forum.effectivealtruism.org/users/ben_snodin\">Ben Snodin</a> asks: <a href=\"https://forum.effectivealtruism.org/posts/2n77pe6oiYZZTZAzL/what-are-the-best-examples-of-object-level-work-that-was\">What are the best examples of object-level work that was done by (or at least inspired by) the longtermist EA community that concretely and legibly reduced existential risk?</a></li></ul><h2>World health dashboard</h2><p><strong>The idea:</strong> a website which aggregates and displays various key indicators of the state of the world.</p><p>To begin with, it could take a list of key indicators of development, such as the <a href=\"https://ourworldindata.org/extreme-poverty-in-brief\">number of people living in extreme poverty</a>, the <a href=\"https://ourworldindata.org/grapher/people-living-in-democracies-autocracies?country=~OWID_WRL\">number of people living under democracy</a>, or <a href=\"https://ourworldindata.org/grapher/deaths-in-conflicts-and-one-sided-violence?country=~OWID_WRL\">deaths from conflict</a>. Then it could show how the numbers are changing as frequently as new data comes in. You could then compare numbers to the previous year, in absolute and percentage terms. You could also see visual indicators of progress towards (e.g.) the <a href=\"https://sdgs.un.org/goals\">Sustainable Development Goals</a>.</p><p>This sounds too similar to <a href=\"https://ourworldindata.org/\">Our World in Data</a> to really count as a novel idea. But I think it could be made more distinctive and useful.</p><p>One addition could be to create and show new aggregate indicators and indices, taking inspiration from the <a href=\"https://en.wikipedia.org/wiki/Democracy_Index\">Democracy Index</a> produced by The Economist\u2019s <a href=\"https://en.wikipedia.org/wiki/Economist_Intelligence_Unit\">Intelligence Unit</a>. There is something brazen and necessarily reductive about deciding to capture everything that matters about democracy in a single number, but in this example I think it was highly worthwhile: the Democracy Index is cited widely and with credulity. Since the index strikes me (as an outsider) as relatively unbiased and informative, I\u2019d guess it really has helped people understand how democracy is distributed in the world, and so I\u2019d guess the index has done more good than harm. In particular, I\u2019d be excited about similar indices for progress in AI (such as a composite of various benchmarks).</p><p>Another addition, which I\u2019m more excited about, involves adding a bunch of indicators based on public forecasts, such as from <a href=\"https://www.metaculus.com/\">Metaculus</a>. Imagine the homepage of this website, showing (say) a dozen headline indicators. One might be the risk of <a href=\"https://www.metaculus.com/questions/2534/world-war-three-before-2050/\">World War 3 before 2050</a>, another the <a href=\"https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/\">expected date</a> of <a href=\"https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/\">arrival</a> of <a href=\"https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/\">AGI</a> (suitably operationalised). Indicators could be shown as needles on gauge, whose change over time should be shown (large movements could be especially highlighted, like Nikos Bosse\u2019s <a href=\"https://twitter.com/MetaculusAlert\">@MetaculusAlert</a> Twitter bot).</p><p>This could amount to something like a more quantitative version of the <a href=\"https://thebulletin.org/doomsday-clock/\">Doomsday Clock</a> managed by the Bulletin of the Atomic Scientists.</p><p>Here\u2019s a graph of the position of the minute hand over time:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677363485/mirroredImages/5KsrEWEbc4mwzMTLp/qmo8rkwiccn3h5cp5slh.svg\" alt=\"\"></p><p>A small discursion: I worry that some people misunderstand the Doomsday Clock, because they assume that it is supposed to be (nothing but) a measure of some crisply operationalised spin on \u201crisk of doomsday in the next X years\u201d, and then sniff at how erratic and alarmist it seems on one hand; and how unhelpfully qualitative it is on the other: how does the position of the minute hand correspond to probabilities?</p><p>I think some of these worries are misplaced. The Bulletin is <a href=\"https://en.wikipedia.org/wiki/Doomsday_Clock\">explicit</a> that the position of the minute hand represents the \u201clikelihood of a human-made global catastrophe\u201d, but as far as I can tell, they\u2019ve left the precise interpretation flexible. And this just seems fine to me: I think there is more to be said for the Doomsday Clock viewed as a long-running and <a href=\"https://theelders.org/news/elders-warn-urgent-action-climate-pandemics-nuclear-weapons-needed-turn-back-hands-doomsday\">influential</a> art project than as an attempt to produce an aggregate quantitative forecast.</p><p><a href=\"https://www.wired.co.uk/article/doomsday-clock-climate-change\">Some have suggested ditching the Doomsday Clock</a> because in a regime of complex and overlapping risks, trying to condense every catastrophic risk and risk factor into a single number is hopelessly reductive. Instead, why not try showing the crisp, quantitative version of the Doomsday Clock? For instance, this site could show the status of and movement on the following Metaculus questions, dressed up in a visually appealing way:</p><ul><li><a href=\"https://www.metaculus.com/questions/10721/when-will-ai-driven-human-extinction-happen/\">Date of AI-Driven Human Extinction</a></li><li><a href=\"https://www.metaculus.com/questions/578/human-extinction-by-2100/\">Human Extinction by 2100</a></li><li><a href=\"https://www.metaculus.com/questions/1493/global-population-decline-10-by-2100/\">Global Population Decline &gt;10% by 2100</a></li><li>Other questions in the <a href=\"https://www.metaculus.com/questions/2568/ragnar%C3%B6k-seriesresults-so-far/\">Ragnarok series</a></li></ul><p>Of course this site would have a responsibility to be clear about the process used to come up with aggregate forecasts, especially if they\u2019re appearing alongside objective measures.</p><p><strong>Why?</strong> If I\u2019m just watching the news, I\u2019m going to find it very difficult to get an all-things-considered sense of how humanity is doing. I\u2019d love to be able to visit a single site which shows me \u2014 in as close as possible to a single glance \u2014 some key overall indicators of how the world\u2019s holding up.</p><p>Sites like <a href=\"https://ourworldindata.org/\">Our World in Data</a> and <a href=\"https://www.metaculus.com/\">Metaculus</a> serve this information very well, but I suspect there is potential in aggregating their information, and showing it in a visual, simple, and shareable way.</p><p>Here is Edouard Mathieu from Our World in Data <a href=\"https://hearthisidea.com/episodes/mathieu#key-indicators-for-the-trajectory-of-the-world\">speaking on the podcast I do</a>:</p><blockquote><p>I would want to have that on the dashboard. And I think then what I would want, and I don\u2019t think it exists, would be something like the doomsday clock, but in a way that would be they would feel more rigorous. If we had an aggregate metric, even if it\u2019s questionable, even if people could criticise it and think that it should be improved in some way, I think even some kind of attempt to have an index of, \u2018Is the world through 30 different metrics, becoming safer or more dangerous in the last six months?\u2019 I think that would be extremely useful.</p></blockquote><p><strong>Why not?</strong> It\u2019s reductive to try condensing the question of \u201chow is the world doing\u201d into a few numbers, and it\u2019s presumptive to choose which numbers make the cut. Maybe the usefulness of such a dashboard fails to outweigh this.</p><p>Note: this idea is a cousin of the excellent <a href=\"https://possibleworldstree.com/\">\u2018Possible Worlds Tree\u2019</a>.</p><h2>The Humanity Times</h2><p><strong>The idea:</strong> an earnestly scope-sensitive newspaper.</p><p>It turns out, even among highbrow newspapers with international circulation, that journalism does not tend to cover topics in proportion with their all-things-considered significance for the world. Unfortunately demand for news is not demand for line graphs.</p><p>Journalistic outlets are appearing which are making an earnest effort to <i>be about the most important things</i>. <a href=\"https://asteriskmag.com\">Asterisk magazine</a>, for instance, \u201cis a quarterly journal of writing and clear thinking about things that matter.\u201d</p><p>I\u2019d love to see a newspaper along these lines which is just deliberately, <i>aggresively</i>, scope-sensitive. It reports on big slow trends, many years in the making. It proffers updates on the approval process for a vaccine against neglected tropical diseases. A new piece of US tech legislation that could be significant for AI, which seemed too dull for other outlets to find an angle. And it\u2019s quantitative wherever possible, even when the data tell a more complicated story, or run against prevailing moods.</p><p>It\u2019s also <strong>representative</strong> of all the world: it might feature profiles on the lives of an unbiased sample of people from everyone alive. What do most people worry about? What are they hopeful for?</p><p>And it\u2019s <strong>optimistic</strong>. It avoids the tempting cynicism or doomsterism of much journalism, and looks to describe solutions.</p><p><strong>Why not?</strong> I haven\u2019t said anything about how to get anyone to read this, or how to make it good. The reason journalism sometimes feels myopic, or skewed towards pessimism, is because they are tracking demand. And you can\u2019t really change what people want to read. On the other hand, maybe there is a special kind of appeal to slow, relatively character and gossip-free journalism. Like the shipping forecast.</p><h2>On writing lists of ideas</h2><p>I\u2019ll stop there and leave further ideas for a possible third post.</p><p>I figured I might finally reflect on the activity of writing lists of ideas. Here are some thoughts:</p><ol><li><strong>Writing</strong> <a href=\"https://finmoorhouse.com/writing/ea-projects/\"><strong>my first list of ideas</strong></a> <strong>went better than expected.</strong> In some cases, the ideas mostly didn\u2019t exist before I wrote it, and mostly do exist now \u2014 though I expect this is mostly fortunate timing rather than causal influence.</li><li>In writing up half-baked ideas, you can <strong>become the de-facto coordinating node</strong>. Some people reached out to me about ideas which I had close to no expertise in, beyond what I\u2019d written. I was still able to connect these people with one another. Writing the ideas up was the bat signal.</li><li>One major concern I have is that there is a reason people don\u2019t write about embryonic project ideas, and to do so is to succumb to the <strong>unilateralist\u2019s curse</strong>. For instance, it might be reputationally bad or misleading to throw around ideas which are sensitive to the details and easily misinterpreted.</li><li>A related concern is that, despite caveats, lists like these can <strong>project more confidence than intended</strong>. They could seed a citation trail which leads to people moving ahead without anyone in the chain actually doing sufficient due diligence: person A decides to launch an ill-considered project because they heard people B, C, and D all separately mention the idea; but the common source of the idea was someone offhandedly writing about it.</li><li>The final downside is that many of the ideas here and in the previous list <strong>have nothing to do with one another</strong>, so it\u2019s unclear why they should be collected together. A lot of things have to go right for even very focused lists to stand a chance of making things happen. I think scattered public lists like this are too unfocused to be justifiable on expected impact grounds. But I enjoy writing them.</li></ol><p>Therefore, I think ideas lists are useful when:</p><ol><li>You want to get quick feedback from <strong>a wide (and \u2234 low context) audience</strong> on a long list of ideas</li><li>You don\u2019t mind these ideas being <strong>public</strong></li><li>Ideally, you can <strong>promise various kinds of support</strong> (including financial, networking, and mentorship) for the ideas if people express interest</li></ol><p>I think these circumstances are rare. More likely:</p><ol><li>You enjoy writing lists.</li></ol><p>Curious for people\u2019s thoughts.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwlgat9tft5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwlgat9tft5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I remember hearing an anecdote about a family friend who was asked to guess the \u201cnumber of tennis balls aloft right now\u201d and heard \u201chow many tennis balls are in my loft right now\u201d and I find it really funny to imagine his utter stupefaction.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fna7zq0ito6sg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefa7zq0ito6sg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This incentive can sometimes be perverse, such as when there are <i>obvious</i> answers that are not necessarily the true answers.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnx35fp4692vq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefx35fp4692vq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Such a platform could replace the occasional Twitter polls I see which try to capture the crowd\u2019s guesses about important numbers \u2014 I\u2019m glad these polls happen but they\u2019re not indexed in a central place, which is a shame. Ozzie Gooen has some illustrative examples: such as <a href=\"https://twitter.com/ozziegooen/status/1490313388970364935\">here</a>, <a href=\"https://twitter.com/ozziegooen/status/1490313714570047491\">here</a>, and <a href=\"https://twitter.com/ozziegooen/status/1483273265753694208\">here</a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9vqh6f9ruh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9vqh6f9ruh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>From a <a href=\"https://hearthisidea.com/episodes/mathieu#can-ea-organisations-learn-from-open-source-models\">recent interview with Ed Mathieu</a> from Our World in Data: \u201cI think some kind of software that would try to bridge that gap and provide both a spreadsheet view of things with the underlying code behind it, for people who want to read the code, I think that would be extremely good [\u2026] If everything was code, that means that EA organisations could publish those analyses, and then other people externally could read them, and create what we call \u2018pull requests\u2019, which are requests to change the code. And they could say, \u2018Okay, on line 18, you\u2019ve made the assumption that you should multiply this by 4.5. But I think it\u2019s close to 5.2.\u2019 And they could justify why.\u201d</p></div></li></ol>", "user": {"username": "finm"}}, {"_id": "qi3MEEmScmK87sfBZ", "title": "Worldview Investigations Team: An Overview", "postedAt": "2023-02-25T17:29:46.648Z", "htmlBody": "<h1>Introduction</h1><p><strong>Rethink Priorities\u2019 Worldview Investigations Team (WIT) exists to improve resource allocation within the effective altruism movement, focusing on tractable, high-impact questions that bear on philanthropic priorities.</strong> WIT builds on Rethink Priorities\u2019 strengths as a multi-cause, stakeholder-driven, interdisciplinary research organization: it takes action-relevant philosophical, methodological, and strategic problems and turns them into manageable, modelable problems. Rethink Priorities is currently hiring multiple roles to build out the team:</p><ul><li><a href=\"https://careers.rethinkpriorities.org/en/postings/e7d9e650-753c-435a-b110-ca15314a19e6\"><u>Worldview Investigations Philosophy Researcher</u></a></li><li><a href=\"https://careers.rethinkpriorities.org/en/postings/9c5c86fc-605c-4c72-81fa-849119d59353\"><u>Worldview Investigations Quantitative Researcher</u></a></li><li><a href=\"https://careers.rethinkpriorities.org/en/postings/96ba160f-b087-40ca-b48b-9dcc6bedc358\"><u>Worldview Investigations Programmer</u></a></li></ul><p>These positions offer a significant opportunity for thoughtful and curious individuals to shift the priorities, research areas, and philanthropic spending strategies of major organizations through interdisciplinary work. WIT tackles problems like:</p><ul><li>How should we convert between the units employed in various cost-effectiveness analyses (welfare to DALYs-averted; DALYs-averted to basis points of existential risk averted, etc.)?</li><li>What are the implications of moral uncertainty for work on different cause areas?</li><li>What difference would various levels of risk- and ambiguity-aversion have on cause prioritization? Can those levels of risk- and/or ambiguity-aversion be justified?</li></ul><p>The work involves getting up to speed with the literature in different fields, contacting experts, writing up reasoning in a manner that makes sense to experts and non-experts alike, and engaging with quantitative models.&nbsp;</p><p>The rest of this post sketches WIT\u2019s history, strategy, and theory of change.</p><h1>WIT\u2019s History</h1><p><strong>Worldview investigation has been part of Rethink Priorities from the beginning</strong>, as some of Rethink Priorities\u2019 earliest work was on&nbsp;<a href=\"https://rethinkpriorities.org/invertebrate-sentience-table\"><u>invertebrate sentience</u></a>. Invertebrate animals are far more numerous than vertebrate animals, but the vast majority of animal-focused philanthropic resources go to vertebrates rather than invertebrates. If invertebrates aren\u2019t sentient, then this is as it should be, given that sentience is necessary for moral status. However, if invertebrates&nbsp;<i>are&nbsp;</i>sentient, then it would be very surprising if the current resource allocation were optimal. So, this project involved sorting through the conceptual issues associated with assessing sentience, identifying observable proxies for sentience, and scouring the academic literature for evidence with respect to each proxy. In essence, this project developed a simple, transparent tool for making progress on fundamental questions about the distribution of consciousness. If the members of a species have a sufficient number of relevant traits, then they probably deserve more philanthropic attention than they\u2019ve received previously.&nbsp;</p><p>Rethink Priorities\u2019 work on invertebrate sentience led directly to its next worldview investigation project, as even if animals are equally sentient, they may not have equal capacity for welfare. For all we know, some animals may be able to realize much more welfare than others. Jason Schukraft took up this question in his&nbsp;<a href=\"https://forum.effectivealtruism.org/s/y5n47MfgrKvTLE3pw\"><u>five-post series about moral weight</u></a>, again trying to sort out the conceptual issues and make empirical progress by finding relevant proxies for morally relevant differences. His influential work laid the foundation for the&nbsp;<a href=\"https://forum.effectivealtruism.org/s/y5n47MfgrKvTLE3pw/p/hxtwzcsz8hQfGyZQM\"><u>Moral Weight Project</u></a>, which, again, created a simple, transparent tool for assessing differences in capacity for welfare. Moreover, it developed a way to implement those differences in cost-effectiveness analyses.</p><p>In addition to its work on animals, Rethink Priorities has done research on&nbsp;<a href=\"https://forum.effectivealtruism.org/s/2nMw7ASQNQ35iAz4T\"><u>standard metrics for evaluating health interventions and estimating the burden of disease</u></a>, the burden of depression, moral uncertainty\u2019s implications for strong longtermism, and many other topics.</p><p>Building on these successes,&nbsp;<strong>Rethink Priorities formally launched WIT in January 2023. Bob Fischer\u2014a Senior Research Manager who joined Rethink Priorities in 2021\u2014leads the team.</strong>&nbsp;</p><h1>WIT\u2019s Strategy</h1><p><strong>Like Rethink Priorities more generally, WIT operates in two modes: first, as a consultancy; second, as an independent think tank with its own research agenda.</strong></p><p><strong>As a consultancy, WIT tackles commissioned work in response to requests from EA-aligned organizations.</strong> One example of this is a series of shallow investigations on worldview diversification, commissioned by a major funder to help improve their thinking about resource allocation across cause areas.</p><p><strong>As an independent think tank, WIT looks for high-expected-value projects that fit with WIT\u2019s comparative advantages.</strong> Given a strong track record on sentience, welfare assessment, and welfare comparisons, projects in these areas often seem particularly promising, but the main objective is always to find projects that will have the largest expected impact on resource allocation decisions.</p><p><strong>In either mode, WIT is focused squarely on decision-making.</strong> WIT works backward from the choices that stakeholders face, rather than reasoning forward from first principles, to maximize the odds of providing action-relevant information. For this reason, WIT often works with the decision-making tools that stakeholders actually employ, trying to improve and refine them rather than propose alternatives that can\u2019t be readily implemented.</p><p>One way to see this is by considering philosophical questions that are especially important for resource allocation:</p><ul><li>What matters?</li><li>How should we measure what matters?</li><li>How should we make tradeoffs among the things that matter?</li><li>How should we deal with uncertainty at every level?</li></ul><p>WIT tackles these questions, but&nbsp;<i>not&nbsp;</i>at this level of abstraction, where it\u2019s tremendously difficult to make progress that commands consensus. Instead, WIT takes up narrower, action-relevant versions of these questions:</p><ul><li>Some EAs think that both empowerment and welfare are basic goods. Are there real-world cases where it\u2019s plausible that promoting empowerment is in tension with promoting welfare? If so, then are there plausible valuations of these goods such that, when tradeoffs are required, we should sacrifice welfare to promote empowerment?</li><li>How should we make tradeoffs between benefits to humans and benefits to animals? Can we quantify welfare-relevant differences between humans and animals in a way that makes this question tractable? If so, what would the results suggest for cause prioritization?</li><li>Some EAs take a \u201cworldview diversification\u201d approach to moral uncertainty, where resources are siloed and the goal is to optimize resource allocation&nbsp;<i>within&nbsp;</i>worldviews rather than across them. Arguably, the \u201clongtermist / neartermist human-only / neartermist animal-inclusive\u201d paradigm is at least one worldview short: we should distinguish between the \u201clongtermist human-only\u201d and \u201clongtermist animal-inclusive\u201d worldviews. If we make this change, then can we model its implications for resource allocation?</li></ul><p>WIT tries to make philosophical progress by empirical means, operationalizing philosophical debates and assessing where empirical information can advance them. It tries to make empirical progress with some philosophical engineering, developing conceptual tools that make problems tractable that weren\u2019t previously. Finally, it tries to inform decisions even where philosophical and empirical progress seem intractable by providing sensitivity analyses for particular decisions.</p><h1>Theory of Change</h1><p>Again, WIT exists to improve resource allocation within the EA movement. Accordingly,&nbsp;<strong>WIT primarily produces work for the EA movement. For that reason, it tries to maximize accessibility, disseminating its work on the EA Forum, at EA events, and by giving executive summaries and presentations directly to stakeholders.</strong></p><p>Because the EA community is informed by the work of academics, WIT values field building, publishing some work in academic venues to create conversations from which EAs can benefit. Moreover, because public policy can be influenced by the academic literature, WIT values placing key results in venues that policymakers take seriously. However, WIT only publishes in academic venues for instrumental reasons: the value isn\u2019t in the publication per se, but in informing future decisions.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677346188/mirroredImages/qi3MEEmScmK87sfBZ/s3vnoa2ilhqiywmvvixx.png\"></p><p><a href=\"https://rethinkpriorities.org/\"><i><u>Rethink Priorities</u></i></a><i> is a think tank dedicated to informing decisions made by high-impact organizations and funders across various cause areas. If you are interested in RP\u2019s work, please visit our&nbsp;</i><a href=\"https://www.rethinkpriorities.org/research\"><i><u>research database</u></i></a><i> and subscribe to our&nbsp;</i><a href=\"https://www.rethinkpriorities.org/newsletter\"><i><u>newsletter</u></i></a><i>.&nbsp;</i></p>", "user": {"username": "Rachel"}}, {"_id": "tYsop2rx2HNj5rFdd", "title": "Can we estimate the expected value of human's future life(in 500 years)", "postedAt": "2023-02-25T15:13:13.858Z", "htmlBody": "<p>Most people in EA are afraid of extinction risk. If the expected value of human is net positive, then we really should prevent human's extinction. There are a lot of uncertainties, such as:AI, the importance of s-risk, the evolution of human... I think human's future is like chaos . Can we estimate human's future is net-positive or net-negative objectively? or we can only rely on our moral intuition?</p>", "user": {"username": "jackchang110"}}, {"_id": "fmCpiPfeRgE9DnLBe", "title": "Planning a Twitter Space to Discuss Issues Relating to EA  - Good Idea or Not?", "postedAt": "2023-02-25T08:27:50.752Z", "htmlBody": "<p>Hi @all,&nbsp;</p><p><br><a href=\"https://effectivedao.substack.com/\">EffectiveDAO</a> ( @Effective_DAO ) is currently planning its first online event and we would love to hear your thoughts / feedback / suggestions:<br>&nbsp;</p><p><strong>Event Description:</strong></p><ul><li>The event would be a 2hr Live Twitter Space</li><li>A handful of knowledgeable panelists (4 to 7) would be invited to discuss various issues relating to EA (MAYBE including some of the recent controversies (OR NOT))</li><li>Audience will be allowed about 30 - 45 mins to ask panelists questions</li></ul><p>&nbsp;</p><p><strong>My Questions:</strong></p><ul><li>Is this a good idea or Not? Why?</li><li>Do you think we Should go ahead and do it or we should kill the idea?</li></ul><p><br><strong>Assuming you agree that it is a good idea and that we should go ahead:</strong></p><ol><li>Who would you suggest as panelists? i.e who should we invite as speakers? (up to 5 recommendations are okay)</li><li>What kind of things should be discussed (suggest topics or issues).</li><li>Do you have any suggestions on how we might do this better / more effectively?</li></ol><p>If you prefer not to comment publicly please DM me or reach out to us on twitter @Effective_DAO</p><p><strong>Also:</strong> If you are interested in being in the panel (or moderating the event) or if you have experience organizing twitter spaces and would like to volunteer/collab kindly reach out to us.&nbsp;<br><br>Thanks.<br>&nbsp;</p>", "user": {"username": "DAOMaxi"}}, {"_id": "agcLm2TD9G8ZMcs7N", "title": "[linkpost] H5N1: Two confirmed infected in same family; four symptomatic close contacts tested but none of these confirmed as positive", "postedAt": "2023-02-25T07:27:15.728Z", "htmlBody": "<p>\"The father of an 11-year-old girl who died from avian influenza in Cambodia this week has been diagnosed with the virus, officials said, stoking concerns about the possibility of another animal-borne virus affecting humans.</p><p>Eleven more people who had been in close contact with the girl have undergone lab testing for H5N1, said Or Vandine, who is Cambodia\u2019s Secretary of State as well as spokesperson for the Ministry of Health. The girl\u2019s 49-year-old father is the only one who tested positive. An investigation is ongoing, she said.</p><p>There hasn\u2019t been any indication that the virus is spreading from person-to-person, officials said. The patient who died was exposed to sick birds before she became infected. Four of her close contacts had begun exhibiting signs of illness, according to reports in media outlets including the Khmer Times and the Voice of Vietnam.\"</p><p>Khmer Times: <a href=\"https://www.khmertimeskh.com/501244375/after-death-of-girl-yesterday-12-more-detected-with-h5n1-bird-flu/\">https://www.khmertimeskh.com/501244375/after-death-of-girl-yesterday-12-more-detected-with-h5n1-bird-flu/</a></p><p>&nbsp;</p><p><i>Edit: </i><s>Title changed to add uncertainty as I'm not sure of the import of the four symptomatic individuals. Wording of Bloomberg article implies that the &nbsp;Secretary of State's speech indicates that the test results of the close contacts came in and and were &nbsp;negative, but Khmer Times article states \"The Secretary of State stated that four of the affected people have begun to show symptoms\", so I'm unclear on the actual situation.</s></p><p><i>Edit: </i>Title changed again to reflect current situation: Seems clear that only one of the 12 samples (the father's) has been confirmed as positive.<br>https://www.khmertimeskh.com/501245030/2nd-case-of-h5n1-bird-flu-in-cambodia-confirmed/</p>", "user": {"username": "pseudobison"}}, {"_id": "u8hC6LkEqw4xaJqyh", "title": "Which is more important for reducing s-risks, researching on AI sentience or animal welfare?", "postedAt": "2023-02-25T02:20:00.270Z", "htmlBody": "<p>Not every people in Effective Altruism put wildlife welfare in the top cause area. Instead, a lot of people concerns on AI safety more.I think people here maybe have arguments upon this. If we don't consider human extinction risks(x-risks), only discussing suffering risk. Can we assert Animal welfare or AI sentience, which is more worthy to be researched?(Despite those two, there may be other parts I didn't mention) It'll affect people's career decisions.\nI think there are a lot of uncertainty and aspects to think about this. Please share your ideas or some articles related!</p>\n", "user": {"username": "jackchang110"}}, {"_id": "gXZF9AuMqez5hChdS", "title": "Some Reflections on Philosophy Tube's \u201cThe Rich Have Their Own Ethics: Effective Altruism & the Crypto Crash\u201d", "postedAt": "2023-02-25T01:45:51.172Z", "htmlBody": "<p>[I expect other people to have more valuable reflections. These are mine, and I'm not very confident in many of them.]<br><br>Some reflections on parts of a recent&nbsp;<a href=\"https://www.youtube.com/watch?v=Lm0vHQYKI-Y\"><u>Philosophy Tube video</u></a> by Abigail Thorn on effective altruism and longtermism. Jessica Wen has a <a href=\"https://forum.effectivealtruism.org/posts/Sb2JPgpMkXxwZ3g4W/on-philosophy-tube-s-video-on-effective-altruism\"><u>summary of the video</u></a>.</p><h2>What I liked</h2><p>The video is very witty and articulate, and it has an pleaseant tone that doesn't take itself too seriously. Abigail Thorn's criticism is generally well-researched and I think it's a good-faith criticism of effective altruism and longtermism. For example, she gives a surprisingly accurate portrayal of earning to give, a concept often poorly portrayed in the media.</p><h2>Where I agree</h2><p>I found myself agreeing with her on quite a few points, such as that the treatment of AI risk in <i>What We Owe the Future (WWOTF)</i> is pretty thin.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreft7iads4frxe\"><sup><a href=\"#fnt7iads4frxe\">[1]</a></sup></span>&nbsp;Or that effective altruism may have undervalued the importance of ensuring that decisions (or even just discussions) about the shape of the long-run future are not made by a small group of people who can't even begin to represent the whole of humanity.</p><h2>Where I'm Confused/Disagree</h2><p>I'm not surprised that I disagree with or am confused by parts of the criticism. The video is ambitious and covers a<strong> lot</strong> of ground \u2013 FTX, Measurability Bias, Longtermism, Pascal's Mugging, MrBeast, EA as suspiciously well aligned with business interests, <i>The Precipice</i> versus <i>WWOTF</i>, etc. \u2013 within 40 entertaining minutes.</p><h3>Measurability Bias and Favoring the Short-Term</h3><blockquote><p><i>\u201cEA tends to favor short-term, small-scale interventions that don't tackle the root of the problems. Some of those short-term interventions don't last or have long-term negative effects. This is all to say, that it is by no means settled what 'effective' actually means. And in fairness to them, some EAs are aware of this and they do talk about it, but none of the EA philosophers I've read quite seem to understand the depth of this issue.\u201d \u2013 Abigail Thorn</i></p></blockquote><p>While this may have been an accurate description of early effective altruism, in 2019 \u2013 out of all of the most engaged EAs \u2013 <a href=\"https://forum.effectivealtruism.org/posts/nws5pai9AB6dCQqxq/how-are-resources-in-ea-allocated-across-issues#Allocation_of_people\"><u>only 28-32% of people were clearly working on short-term, 'easily' measured research/interventions</u></a>. Although around&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/nws5pai9AB6dCQqxq/how-are-resources-in-ea-allocated-across-issues#Allocation_of_funding\"><u>70% of funding was directed towards near-term research/interventions</u></a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe3ucu25uqxf\"><sup><a href=\"#fne3ucu25uqxf\">[5]</a></sup></span>&nbsp;And a lot of the global health funding goes to large-scale interventions that work at a policy level \u2013 such as the <a href=\"https://www.openphilanthropy.org/grants/lead-exposure-elimination-project-general-support/\">Lead Exposure Elimination Project</a> or the <a href=\"https://www.givewell.org/research/grants/RESET-alcohol-December-2021\">RESET Alcohol Initiative</a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefz07hxl833ao\"><sup><a href=\"#fnz07hxl833ao\">[6]</a></sup></span></p><h3>Deciding on the Future on Our Own</h3><blockquote><p><i>\u201cMacAskill and Ord write a lot about progress and humanity's potential, but they say almost nothing about who gets to define those concepts. Who gets seen as an expert, who decides what counts as evidence, whose vision of the future gets listened to?\u201d \u2013 Abigail Thorn</i></p></blockquote><p>I agree that we should be very hesitant of a small, weird, elite group of people having an incredibly outsized ability to shape the future.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref34fyqoq1x3x\"><sup><a href=\"#fn34fyqoq1x3x\">[2]</a></sup></span></p><p>But many (most?) &nbsp;EAs in longtermism <a href=\"https://forum.effectivealtruism.org/posts/nws5pai9AB6dCQqxq/how-are-resources-in-ea-allocated-across-issues#Allocation_of_people\">work on preventing existential risks</a> rather than on designing detailed plans for an ideal future. This does not mean that their research is free from ethical judgments, but the work is focused on ensuring that there is a future that <strong>anyone</strong> can shape at all. And therefore it's plausible that individuals with diverging visions for the future are likely to end up working together to address existential risks.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefk0wa7lgeszb\"><sup><a href=\"#fnk0wa7lgeszb\">[3]</a></sup></span></p><p>I'd also note that longtermist philosophers are also not making sweeping claims about the optimal shape of the future. In <i>The Precipice</i> there is a longer section on the &nbsp;\u201cLong Reflection\u201d about handing off the decision about the shape of the future to others. MacAskill agrees in WWOTF that even though \u201c<i>it seems unlikely to me that anything like the long reflection will occur. [... W]e can see it as an ideal to try to approximate.</i>\u201d</p><h3>Conflating longtermism and existential risk reduction</h3><p>Philosophy Tube is never explicit about who is part of longtermism, it remains as some vague group of people doing 'stuff'. But in reality, most of the people you'd likely include in the longtermism community are working on existential risk. Many of them<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjalpx6bf5bg\"><sup><a href=\"#fnjalpx6bf5bg\">[4]</a></sup></span>&nbsp;are not motivated by longtermist ideas or are motivated by a common sense version of (weak) longtermism. Wanting to protect the current world population or their grandchildren's children is enough motivation for many to work on reducing existential risks.</p><h3>Pascal\u2019s Mugging</h3><p>The thought experiment is beautifully presented, but it is unclear to me how Philosophy Tube relates it to longtermism. The argument only works if the positive expected value comes from a huge upside <strong>despite </strong>an infinitesimal likelihood. Most effective altruists consider the existential risk to be much higher than typically envisioned in Pascal\u2019s Mugging examples. Toby Ord estimates a 1 in 6 chance of an existential catastrophe in the next century \u2013 slightly higher than the \"1 in a trillion\" chance mentioned by Abigail Thorn in her version of Pascal's Mugging.</p><h3>Possible Nitpick on Reproductive Rights</h3><p>The part about WWOTF's handling of reproductive rights issues struck me as potentially misleading.</p><blockquote><p><i>\u201cTurning now to what I didn't like so much about the book, you can kind of tell it was written by a man because&nbsp;<strong>there is almost zero discussion of reproductive rights</strong>. If I was bringing out a book in current year about the moral duties that we have to unborn people, the first thing I would've put in it, page 1, 72 point font, 'Do not use this book to criminalize abortion!' Maybe he'll discuss that in a future edition.\u201d \u2013 Abigail Thorn</i></p></blockquote><p>This left me with the impression, that MacAskill was simply blas\u00e9 about abortion. But going back to the book, he does write:</p><blockquote><p><i>\u201cOf course, whether to have children is a deeply personal choice. I don't think that we should scold those who choose not to, and I certainly don\u2019t think that the government should restrict people\u2019s reproductive rights by, for example, limiting access to contraception or banning abortion.\u201d</i></p></blockquote><p>I understand that this might not be forceful enough because it's in the middle of the book and not literally on \u201cpage 1, 72 point font\u201d \u2013 but what&nbsp;it says is almost exactly what Philosophy Tube wants it to say. Criticising MacAskill for 'doing the right thing, but just slightly off' feels needlessly antagonistic.</p><h2>A Personal Takeaway</h2><ul><li>In public writing, if you believe a point is important (like not wanting to advocate taking away reproductive rights in any way) it's not enough to just say the point. You should be very aware of how forcefully the point comes across.</li></ul><p>Again, I really enjoyed the video in general. And I'm glad that the first in-depth criticism of EA with a wide reach was made by a channel that spends so much time researching its topics and strives to present tricky issues in an even-handed manner.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnt7iads4frxe\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreft7iads4frxe\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Especially compared to how important it is to many in the existential risk community.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn34fyqoq1x3x\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref34fyqoq1x3x\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I would have personally enjoyed a chapter in <i>WWOTF</i> about this problem.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnk0wa7lgeszb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefk0wa7lgeszb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I'm pretty uncertain about this. There might be ways of smuggling in assumptions about morality in work on existential risk reduction I'm currently not thinking of.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjalpx6bf5bg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjalpx6bf5bg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>My guess is most, but I don't know of any polls.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne3ucu25uqxf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe3ucu25uqxf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Also, I'm confused about which interventions EAs favor have had \u201clong-term negative effects\u201d. I would not be surprised if that were the case, but I've not seen any concrete examples. The<a href=\"https://www.bostonreview.net/articles/emily-clough-effective-altruism-ngos/\"><u> source for this claim</u></a> doesn't point to any cases where EAs have caused negative effects, it discusses a pathway through which EAs&nbsp;<strong>could&nbsp;</strong>have a long-term negative effect.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnz07hxl833ao\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefz07hxl833ao\">^</a></strong></sup></span><div class=\"footnote-content\"><p>And this is not a new thing: <a href=\"https://80000hours.org/2015/07/effective-altruists-love-systemic-change/\">Effective altruists love systemic change</a> (from 2015)</p></div></li></ol>", "user": {"username": "TobiasH"}}, {"_id": "LXaoY5pj8d3F3QzgC", "title": "Christiano (ARC) and GA (Conjecture) Discuss Alignment Cruxes", "postedAt": "2023-02-24T23:03:05.017Z", "htmlBody": "", "user": {"username": "AndreaM"}}, {"_id": "Sb2JPgpMkXxwZ3g4W", "title": "On Philosophy Tube's Video on Effective Altruism", "postedAt": "2023-02-24T23:01:49.455Z", "htmlBody": "<h1>tl;dr:</h1><p>I found <a href=\"https://www.youtube.com/watch?v=Lm0vHQYKI-Y\">Philosophy Tube's new video</a> on EA enjoyable and the criticisms fair. I wrote out some thoughts on her criticisms. I would recommend a watch.</p><h1>Background</h1><p>I\u2019ve been into Abigail Thorn's channel Philosophy Tube for about as long as I\u2019ve been into Effective Altruism. I currently co-direct High Impact Engineers, but this post is written from a personal standpoint and does&nbsp;<i>not</i> represent the views of High Impact Engineers. Philosophy Tube creates content explaining philosophy (and many aspects of Western culture) with a dramatic streak (think fantastic lighting and flashy outfits - yes please!). So when I found out that Philosophy Tube would be creating a video on Effective Altruism, I got very excited.</p><p>I have written this almost chronologically and in a very short amount of time, so the quality and format may not be up to the normal standards of the EA Forum. I wanted to hash out my thoughts for my own understanding and to see what others thought.</p><h1>Content, Criticisms, and Contemplations</h1><h2>EA and SBF</h2><p>Firstly, Thorn outlines what EA is, and what\u2019s happened over the past 6 months (FTX, a mention of the Time article, and other critical pieces) and essentially says that the leaders of the movement ignored what was happening on the ground in the community and didn\u2019t listen to criticisms. Although I don\u2019t think this was the only cause of the above scandals, I think there is some truth in Thorn\u2019s analysis. I also disagree with the insinuation that Earning to Give is a bad strategy because it leads to SBF-type disasters:&nbsp;<a href=\"https://80000hours.org/articles/harmful-career/\"><u>80,000 Hours explicitly tells people to not take work that does harm</u></a> even if you expect the positive outcome to outweigh the harmful means.</p><h2>EA and Longtermism</h2><p>In the next section, Thorn discusses Longtermism, What We Owe the Future (WWOTF), and The Precipice. She mentions that there is no discussion of reproductive rights in a book about our duties to future people (which I see as an oversight \u2013 and not one that a woman would have made); she prefers The Precipice, which I agree is more detailed, considers more points of view, and is more persuasive. However, I think The Precipice is drier and less easy to read than WWOTF, the latter of which is aimed at a broader audience.</p><p>There is a brief (and entertaining) illustration of Expected Value (EV) and the resulting extreme case of Pascal\u2019s Mugging. Although MacAskill puts this to the side, Thorn goes deeper into the consequences of basing decisions on EV and the measurability bias that results \u2013 and she is right that although there is thinking done on how to overcome this in EA (she gives the example of Peter Singer\u2019s&nbsp;<i>The Most Good You Can Do</i>, but also see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/NpuxBQTrHb9QuWHDA/what-i-learned-from-working-at-givewell#GiveWell_takes_a_broader_view_than_I_thought\"><u>this</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/YKEPXLQhYjm3nP7Td/ways-money-can-make-things-worse#Countering_measurability_bias_\"><u>this</u></a> and&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/gj3thsZewwW67ca2Z/update-from-open-philanthropy-s-longtermist-ea-movement\"><u>this</u></a> for examples of EAs thinking about tackling measurability bias), she mentions that this issue is never tackled by MacAskill. (She generalises this to EA philosophers, but isn't Singer one of the OG EA philosophers?)</p><h2>EA and ~The System~</h2><p>The last section is the most important criticism of EA. I think this section is most worth watching. Thorn mentions the classic leftist criticism of EA: it reinforces the 19th-century idea of philanthropy where people get rich and donate their money to avoid criticisms of how they got their money and doesn\u2019t directly tackle the unfair system that privileges some people over others.&nbsp;</p><p>Thorn brings Mr Beast into the discussion, and although she doesn\u2019t explicitly say that he\u2019s an EA, she uses Mr Beast as an example of how EA might see this as: \u201c1000 people were blind yesterday and can see today \u2013 isn\u2019t that a fact worth celebrating?\u201d. The question that neither Mr Beast nor the hypothetical EA ask is: \u201chow do we change the world?\u201d. Changing the world, she implies, necessitates changing the system.</p><p>She points out here that systemic change is rarely ex-ante measurable. Thus, the same measurability bias that MacAskill sets aside yields a bias against systemic change.</p><h2>EA and Clout</h2><p>Though perhaps not the most important, the most interesting claim she makes (in my opinion) is that in the uncertainty between what\u2019s measurable and what would do the most good, \u2018business clout\u2019 rushes in to fill the gap. This, she argues, explains the multitude of Westerner-lead charities on EAs top-rated list.</p><p>Thorn says: \u201cMacAskill and Ord write a lot about progress and humanity\u2019s potential, but they say almost nothing about who gets to define those concepts. Who gets seen as an expert? Who decides what counts as evidence? Whose vision of the future gets listened to? In my opinion, those aren\u2019t side-questions to hide in the footnotes. They\u2019re core to the whole project.\u201d</p><p>This analysis makes sense to me. I almost want to go a bit further: EA heavily draws from Rationalism, which views reason as the chief source of knowledge; specifically, EA heavily prioritises quantitative analysis over qualitative analysis. Often charity/intervention evaluations stop at the quantitative analysis, when in fact qualitative analysis (through techniques like&nbsp;<a href=\"https://en.wikipedia.org/wiki/Thematic_analysis\"><u>thematic analysis</u></a> or <a href=\"https://en.wikipedia.org/wiki/Ethnography\">ethnography</a>) may bridge the gap between what\u2019s measurable and what would do the most good. In my experience, regranting organisations do more qualitative analyses due to the high uncertainty of the projects they fund, but I think these techniques should be recognised and regarded more highly in the EA community, and not seen as second-class analyses (as much as it pains my quantitative brain to admit that).</p><h1>Conclusion</h1><p>Overall, I think it was an enjoyable, fair analysis of Effective Altruism, executed with the characteristic wit and empathy I have come to expect from Philosophy Tube. She paints EA in a slightly simplistic light (can\u2019t expect much more from a 40-min video on a huge movement that\u2019s over a decade old), but I appreciated her criticisms and the video made me think. I\u2019d highly recommend a watch and I look forward to the comments!</p><p><br>&nbsp;</p>", "user": {"username": "Jessica Wen"}}, {"_id": "WdL5NErYYCqRzKNWh", "title": "Retrospective on the 2022 Conjecture AI Discussions", "postedAt": "2023-02-24T22:41:13.162Z", "htmlBody": "", "user": {"username": "AndreaM"}}, {"_id": "WB8yLjDDNuHaGdotM", "title": "Make RCTs cheaper: smaller treatment, bigger control groups", "postedAt": "2023-02-24T23:18:45.346Z", "htmlBody": "<p><i>Epistemic status: I think this is a statistical \u201cfact\u201d but I feel a bit cautious since so few people seem to take advantage of it</i></p><p><strong>Summary</strong></p><p>It may not always be optimal for cost or statistical power to have equal-sized treatment/control groups in a study. When your intervention is quite expensive relative to data collection, you can maximise statistical power or save costs by using a larger control group and smaller treatment group. The optimal ratio of treatment sample to control sample is just the square root of the cost per treatment participant divided by the square root of the cost per control participant.&nbsp;</p><p><strong>Why larger control groups seem better</strong></p><p>Studies generally have equal numbers of treatment and control participants. This makes intuitive sense: a study with 500 treatment and 500 control will be more powerful than a study with 499 treatment and 501 control, for example. This is due to the diminishing power returns to increasing your sample size: the extra person removed from one arm hurts your power more than the extra person added to the other arm increases it.</p><p>But what if your intervention is expensive relative to data collection? Perhaps you are studying a $720 cash transfer and it costs $80 to complete each survey, for a total cost of $800 per treatment participant ($720 + $80) and $80 per control. Now, for the same cost as 500 treatment and 500 control, you could have 499 treatment and 510 control, or 450 treatment and 1000 control: up to a point, the loss in precision from the smaller treatment is more than offset by the 10x larger increase in your control group, resulting in a more powerful study overall. In other words: when your treatment is expensive, it is generally more powerful to have a larger control group, because it's just so much cheaper to add control participants.</p><p>How much larger? The exact ratio of treatment:control that optimises statistical power is surprisingly simple, it\u2019s just the ratio of the square roots of the costs of adding to each arm i.e. sqrt(control_cost) : sqrt(treatment_cost) (See Appendix for justification). For example, if adding an extra treatment participant costs 16x more than adding a control participant, you should optimally have sqrt(16/1) = 4x as many control as treatment.</p><p><br><strong>Quantifying the benefits</strong></p><p>With this approach, you either get free extra power for the same money or save money without losing power. For example, let\u2019s look at the hypothetical cash transfer study above with treatment participants costing $800 and control participants $80. The optimal ratio of control to treatment is then sqrt(800/80) = 3.2 :1, resulting in either:</p><p><i>Saving money without losing power</i>: the study is currently powered to measure an effect of 0.175 SD and, with 500 treatment and control, costs $440,000. With a 3.2 : 1 ratio (*types furiously in Stata*) you could achieve the same power with a sample of 337 treatment and 1079 control, which would cost $356,000: saving you a cool $84k without any loss of statistical power.</p><p><i>Getting extra power for the same budget</i>: alternatively, if you still want to spend the full $440k, you could then afford 416 treatment and 1,331 control, cutting your detectable effect from 0.175 SD to 0.155 SD at no extra cost.</p><p><strong>Caveats</strong></p><p><i>Ethics</i>: there may be ethical reasons for not wanting a larger control group, for example in a medical trial where you would be denying potentially life-saving treatments to sick patients. Even outside of medicine, control participants\u2019 time is important and you may wish to avoid \u201cwasting\u201d it on participating in your study (although you could use some of the savings to compensate control participants, if that won\u2019t mess with your study).</p><p><i>Necessarily limited samples</i>: obviously if there is a practical limit to increasing your control group size, such as only being able to operate in a limited geography, this may not be an option.</p><p><i>Natural skepticism?</i> &nbsp;This isn\u2019t a common technique, you might just trust that the market for ideas is efficient and if this really was a thing you would have heard about it from somewhere else by now. It kind of blows my mind that this isn\u2019t done more often, which both makes me want to tell people about it and be skeptical. We used this approach for a <a href=\"https://www.idinsight.org/publication/cost-effectiveness-through-bundled-distribution-impacts-of-a-package-of-goods-on-livelihoods-in-rural-tanzania/\">pretty large RCT I worked on in Tanzania</a>, and no one complained.</p><p><strong>Conclusion</strong></p><p>If you treatment is quite expensive relative to data collection costs, consider using a larger control group in the ratio of sqrt(treatment_cost/control_cost) and enjoy that spare money or additional statistical power.</p><p><strong>Appendix</strong></p><p>I am not claiming to have discovered this myself. I first read this equation in <a href=\"http://runningres.com/about-the-book\"><i>Running Randomized Evaluations</i></a> and was able to derive the same result myself <a href=\"https://www.evernote.com/shard/s77/sh/6cadf4d0-2da0-402e-8dc9-652d801fcd35/5d1c20b2b834109ea00178f48e0141cd\">here</a>.</p><p>I believe this holds for cluster RCTs, just remember that the increased control sample here would come in the form of <i>additional</i> control clusters, rather than <i>larger</i> clusters.</p><p>If you are doing power calculations in Stata and want to factor in different treatment/control group sizes, you just add ratio(X) to the sampsi command, where \u201cX\u201d is the treatment/control ratio. For a cluster RCT using clustersampsi you... need to do something involving harmonic means, I forget exactly, but poke me on the Forum and I'll happily dig through some old code.</p>", "user": {"username": "Rory Fenton"}}, {"_id": "BN7wxqyhKD77Lzdqo", "title": "Philosophy Tube: The Rich Have Their Own Ethics: Effective Altruism & the Crypto Crash", "postedAt": "2023-02-24T22:00:06.030Z", "htmlBody": "<p>Hi everyone, I am cross-posting this video from YouTuber Philosophy Tube who has 1.3 million subs at the time of writing this.&nbsp;</p><p>The video is fairly critical of EA, and I would love to hear people's ideas surrounding it. The timing of the posting with EAG Bay Area starting tomorrow may just be coincidental.&nbsp;</p>", "user": {"username": "Coleman@21stTalks"}}, {"_id": "ruJnXtdDS7XiiwzSP", "title": "How major governments can help with the most important century", "postedAt": "2023-02-24T19:37:18.985Z", "htmlBody": "<p>\nI\u2019ve been writing about tangible things we can do today to help the <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd\">most important century</a> go well. Previously, I wrote about <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/CcJsh4JcxEqYDaSte/\">helpful messages to spread</a>; <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/njD2PurEKDEZcMLKZ/\">how to help via full-time work</a>; and <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/i6btyefRRX23yCpnP/\">how major AI companies can help</a>.\n</p>\n<p>\nWhat about major governments<sup id=\"fnref1\"><a href=\"#fn1\" rel=\"footnote\">1</a></sup> - what can they be doing today to help?\n</p>\n<p>\nI think governments could play crucial roles in the future. For example, see my discussion of <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/XRphCh6NbfQiDF3Nt#Global_monitoring__noticing_people_about_to_step_on_mines__and_stopping_them_\">standards and monitoring</a>.\n</p>\n<p>\nHowever, I\u2019m honestly nervous about most possible ways that governments could get involved in AI development and regulation today. \n</p>\n<ul>\n\n<li>I think we still know very little about what key future situations will look like, which is why my discussion of AI companies (<a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/i6btyefRRX23yCpnP/\">previous piece</a>) emphasizes doing things that have limited downsides and are useful in a wide variety of possible futures. \n\n</li><li>I think governments are \u201cstickier\u201d than companies - I think they have a much harder time getting rid of processes, rules, etc. that no longer make sense. So in many ways I\u2019d rather see them keep their options open for the future by <em>not</em> committing to specific regulations, processes, projects, etc. now.\n\n</li><li>I worry that governments, at least as they stand today, are far too oriented toward the <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/Lbtcjfxhrs8kfKK2M#The__competition__frame\">competition frame</a> (\u201cwe have to develop powerful AI systems before other countries do\u201d) and not receptive enough to the <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/Lbtcjfxhrs8kfKK2M#The__caution__frame\">caution frame</a> (\u201cWe should worry that AI systems could be dangerous to everyone at once, and consider cooperating internationally to reduce risk\u201d). (This concern also applies to companies, but see footnote.<sup id=\"fnref2\"><a href=\"#fn2\" rel=\"footnote\">2</a></sup>)\n</li></ul><p>\n</p><details id=\"Box1\"><summary>(Click to expand) The \u201ccompetition\u201d frame vs. the \u201ccaution\u201d frame\u201d<!-- (Details not included in email - <a href=\"https://forum.effectivealtruism.org/posts/ruJnXtdDS7XiiwzSP/how-major-governments-can-help-with-the-most-important/#Box1\">click to view on the web</a>)--></summary><p></p>\n<p>\nIn a <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/Lbtcjfxhrs8kfKK2M/\">previous piece</a>, I talked about two contrasting frames for how to make the best of the most important century:\n</p>\n<p>\n<strong>The caution frame.</strong> This frame emphasizes that a furious race to develop powerful AI could end up making <em>everyone</em> worse off. This could be via: (a) AI forming <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/vGsRdWzwjrFgCXdMn/\">dangerous goals of its own</a> and <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/6LTh4foNuC3NdtmZH/\">defeating humanity entirely</a>; (b) humans racing to gain power and resources and \u201c<a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/AKxKR4CeakyBsGFoH#Lock_in\">lock in</a>\u201d their values.\n</p>\n<p>\nIdeally, everyone with the potential to build something <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/AmxxnazJcBWzWEeqj/\">powerful enough AI</a> would be able to pour energy into building something safe (not misaligned), and carefully planning out (and negotiating with others on) how to roll it out, without a rush or a race. With this in mind, perhaps we should be doing things like:\n</p>\n<ul>\n\n<li>Working to improve trust and cooperation between major world powers. Perhaps via AI-centric versions of <a href=\"https://en.wikipedia.org/wiki/Pugwash_Conferences_on_Science_and_World_Affairs\">Pugwash</a> (an international conference aimed at reducing the risk of military conflict), perhaps by pushing back against hawkish foreign relations moves.\n\n</li><li>Discouraging governments and investors from shoveling money into AI research, encouraging AI labs to thoroughly consider the implications of their research before publishing it or scaling it up, working toward <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/XRphCh6NbfQiDF3Nt#Global_monitoring__noticing_people_about_to_step_on_mines__and_stopping_them_\">standards and monitoring</a>, etc. Slowing things down in this manner could buy more time to do research on avoiding <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/Lbtcjfxhrs8kfKK2M#Worst__Misaligned_AI\">misaligned AI</a>, more time to build trust and cooperation mechanisms, and more time to generally gain strategic clarity \n</li>\n</ul>\n<p>\n<strong>The \u201ccompetition\u201d frame. </strong>This frame focuses less on how the transition to a radically different future happens, and more on who's making the key decisions as it happens.\n</p>\n<ul>\n\n<li>If something like <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/AmxxnazJcBWzWEeqj/\">PASTA </a>is developed primarily (or first) in country X, then the government of country X could be making a lot of crucial decisions about whether and how to regulate a potential explosion of new technologies.\n\n</li><li>In addition, the people and organizations leading the way on AI and other technology advancement at that time could be especially influential in such decisions.\n</li>\n</ul>\n<p>\nThis means it could matter enormously \"who leads the way on transformative AI\" - which country or countries, which people or organizations.\n</p>\n<p>\nSome people feel that we can make confident statements today about which specific countries, and/or which people and organizations, we should hope lead the way on transformative AI. These people might advocate for actions like:\n</p>\n<ul>\n\n<li>Increasing the odds that the first PASTA systems are built in countries that are e.g. less authoritarian, which could mean e.g. pushing for more investment and attention to AI development in these countries.\n\n</li><li>Supporting and trying to speed up AI labs run by people who are likely to make wise decisions (about things like how to engage with governments, what AI systems to publish and deploy vs. keep secret, etc.)\n</li>\n</ul>\n<p>\n<strong>Tension between the two frames. </strong>People who take the \"caution\" frame and people who take the \"competition\" frame often favor very different, even contradictory actions. Actions that look important to people in one frame often look actively harmful to people in the other.\n</p>\n<p>\nFor example, people in the \"competition\" frame often favor moving forward as fast as possible on developing more powerful AI systems; for people in the \"caution\" frame, haste is one of the main things to avoid. People in the \"competition\" frame often favor adversarial foreign relations, while people in the \"caution\" frame often want foreign relations to be more cooperative.\n</p>\n<p>\nThat said, this dichotomy is a simplification. Many people - including myself - resonate with both frames. But I have a <strong>general fear that the \u201ccompetition\u201d frame is going to be overrated by default</strong> for a number of reasons, as I discuss <a href=\"https://forum.effectivealtruism.org/s/isENJuPdB3fhjWYHd/p/Lbtcjfxhrs8kfKK2M#Why_I_fear__competition__being_overrated__relative_to__caution_\">here</a>.\n</p>\n</details>\n<p></p>\n<p>\nBecause of these concerns, I don\u2019t have a ton of tangible suggestions for governments as of now. But here are a few.\n</p>\n<p>\nMy first suggestion is to <strong>avoid premature actions</strong>, including ramping up research on how to make AI systems more capable.\n</p>\n<p>\nMy next suggestion is to <strong>build up the right sort of personnel and expertise for challenging future decisions. </strong>\n</p>\n<ul>\n\n<li>Today, my impression is that there are relatively few people in government who are seriously considering the highest-stakes risks and thoughtfully balancing both \u201ccaution\u201d and \u201ccompetition\u201d considerations (see directly above). I think it would be great if that changed. \n\n</li><li>Governments can invest in efforts toeducate their personnel about these issues, and can try to hire key personnel who are already on the knowledgeable and thoughtful side about them (while also watching out for some of the <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/CcJsh4JcxEqYDaSte/\">pitfalls of spreading messages about AI</a>).\n</li>\n</ul>\n<p>\nAnother suggestion is to <strong>generally avoid putting terrible people in power. </strong>Voters can help with this!\n</p>\n<p>\nMy top non-\u201dmeta\u201d suggestion for a given government is to <strong>invest in intelligence on the state of AI capabilities in other countries. </strong>If other countries are getting close to deploying dangerous AI systems, this could be essential to know; if they aren\u2019t, that could be essential to know as well, in order to avoid premature and paranoid racing to deploy powerful AI.\n</p>\n<p>\nA few other things that seem worth doing and relatively low-downside:\n</p>\n<ul>\n\n<li><strong>Fund <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/rJRw78oihoT5paFGd\">alignment research</a></strong> (ideally alignment research targeted at the <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/NbiHKTN5QhFFfjjm5\">most crucial challenges</a>) via agencies like the National Science Foundation and DARPA. These agencies have huge budgets (the two of them combined spend over $10 billion per year), and have major impacts on research communities. \n\n</li><li><strong>Keep options open for future monitoring and regulation </strong>(see <a href=\"https://www.slowboring.com/p/at-last-an-ai-existential-risk-policy\">this Slow Boring piece</a> for an example).\n\n</li><li><strong>Build relationships with leading AI researchers and organizations</strong>, so that future crises can be handled relatively smoothly.\n\n</li><li><strong>Encourage and amplify investments in information security. </strong>My impression is that governments are often better than companies at highly advanced information security (preventing cyber-theft even by determined, well-resourced opponents). They could help with, and even enforce, strong security at key AI companies. </li></ul>\n\n<h2>Footnotes</h2>\n<div class=\"footnotes\">\n<hr>\n<ol><li id=\"fn1\">\n<p>\n     I\u2019m centrally thinking of the US, but other governments with lots of geopolitical sway and/or major AI projects in their jurisdiction could have similar impacts.&nbsp;<a href=\"#fnref1\" rev=\"footnote\">\u21a9</a></p></li><li id=\"fn2\">\n\n<p>\n     When discussing <a href=\"https://forum.effectivealtruism.org/s/gBjPorwZHRArNSQ5w/p/i6btyefRRX23yCpnP/\">recommendations for companies</a>, I imagine companies that are already dedicated to AI, and I imagine individuals at those companies who can have a large impact on the decisions they make. \n</p><p>\n    By contrast, when discussing recommendations for governments, a lot of what I\u2019m thinking is: \u201cAttempts to promote productive actions on AI will raise the profile of AI <em>relative to other issues the government could be focused on</em>; furthermore, it\u2019s much harder for even a very influential individual to predict how their actions will affect what a government ultimately does, compared to a company.\u201d&nbsp;<a href=\"#fnref2\" rev=\"footnote\">\u21a9</a></p></li></ol></div>", "user": {"username": "HoldenKarnofsky"}}, {"_id": "9qXvGnRPcCoJiaHp6", "title": "Workflows 2.0 New Version & Updates: projects > introductory fellowships", "postedAt": "2023-02-24T19:19:53.881Z", "htmlBody": "<h2>TL;DR</h2><p>Check out the&nbsp;<a href=\"https://necessary-eggplant-cd9.notion.site/Workflows-2-0-12894250d3614e85ab6eff092ef2dee3\"><u>Workflows 2.0</u></a> and the&nbsp;<a href=\"https://eaberkeley.com/projects\"><u>EA UC Berkeley Projects Page</u></a> &amp; provide any feedback if you wish. Feel free to use them as a helpful addition to your group\u2019s repertoire of community-building activities. I believe project-based learning is more effective than reading groups at getting students to become highly engaged EAs. This is the second update about these and you can find the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/irkKS4vnRLc3LQAtF/workflows-an-experimental-alternative-to-introductory\"><u>first post here</u></a>.&nbsp;&nbsp;</p><h2>Contents:</h2><ol><li>Epistemics &amp; Disclaimer</li><li>What is a workflow?</li><li>What are the stages of a workflow?</li><li>Transitioning to project-based learning</li><li>Some info about how other groups are using the Workflows/Projects</li><li>Next steps</li><li>Acknowledgments</li></ol><h2>Epistemics &amp; Disclaimer:</h2><ul><li>I am a university group organizer so my community-building experience within EA is somewhat limited to university groups.&nbsp;</li><li>I believe this project-based learning model could also be applied to other groups however it may need to be modified.&nbsp;</li></ul><h2>What is a workflow?</h2><p>An alternative and self-paced version of an intro Effective Altruism reading group that lets someone jump straight to the area that they are interested in &amp; get the basics of it while also providing the option to meet with group organizers, get personalized feedback &amp; suggestions as to how to get involved with projects. The long-term goal is for these is for them to be made available to every university group as an easily accessible and comprehensive option.</p><h2>What are the stages of a workflow?</h2><ol><li>Fill out the intake form provided by your group (eg&nbsp;<a href=\"https://airtable.com/shrNH3B8UTcS1rHMX\"><u>EA UC Berkeley Intake Form</u></a><u>)</u>.&nbsp;</li><li>Complete the Introduction to EA readings</li><li>Explore at least four different cause areas from the workflow database</li><li>Complete the workflow for your cause area of choice</li><li>Read the project guidelines</li><li>Meet with your group organizer to discuss projects &amp; next steps</li></ol><h2>Transitioning to project-based learning</h2><ul><li>EA UC Berkeley is using the Workflows as a supplement for our&nbsp;<a href=\"https://eaberkeley.com/projects\"><u>Spring 2023 Projects</u></a> to get people who are new to EA caught up on the relevant readings and resources thus creating a pipeline of projects \u2192 workflows to learn about EA</li><li>We currently have 17 students signed up for participating in projects (14 of them are EA UC Berkeley Students)&nbsp;</li><li>We are also just generally advertising them if people also want to go the opposite way workflows to learn about EA \u2192 projects</li><li>However, I have generally found that once you get a person interested in a project they are much more likely to do the relevant \u201cintro to EA\u201d and cause-specific reading in order to fulfill their desire to actively contribute to the project.&nbsp;</li><li>This model also allows people to get to work on an EA-related project around 8 to 10 weeks faster than if they were doing the regular route of reading group \u2192 project, as the reading happens alongside the project.&nbsp;</li></ul><h2>Some info about how other groups are using the Workflows/Projects</h2><ul><li>Audrey Rapport from EA&nbsp; UMD is using the workflows &amp; projects and they are staffing some of the&nbsp;<a href=\"https://www.solar4africa.org/technical-details/2023-student-projects\"><u>Solar4Africa Projects</u></a> this semester.&nbsp;</li><li>Reed Trende from EA WashU is using some of the workflows with their students&nbsp;</li><li>Yashvardhan Sharma from EA Minerva is using some of the workflows with their students&nbsp;</li><li>Harrison Gietz from EA LSU&nbsp; is using some of the workflows with their students&nbsp;</li><li>There could be more people as these have been shared on the EA Groups Slack, but some people may have the 1.0 version and not the latest one.&nbsp;</li></ul><h2>Next Steps</h2><ul><li>We have 14 UC Berkeley students doing projects this semester and 15 people completing the introductory reading group fellowship, this allows for a direct comparison between the two models to be made. I expect to make an update on this at the end of the semester.&nbsp;</li><li>Other university groups are using the workflows so I will also compile data from them on how it went in order to make any improvements necessary.&nbsp;</li><li>If any other groups choose to use the workflows please reach out to me via email (<a href=\"mailto:sofya.lebedeva@berkeley.edu\"><u>sofya.lebedeva@berkeley.edu</u></a>) so that we can set up a time to chat or so that I can answer any questions that you may have.&nbsp;<br>&nbsp;</li></ul><h2>Acknowledgments</h2><ul><li>Carolyn Qian for providing help during the ideation phase and reviewing almost every draft of this project &amp; write-up.&nbsp;</li><li>Miranda Zhang for making the career planning program which was an inspiration for this&nbsp;</li><li>Aris Richardson working on the ideation process of this and providing edits to an earlier version of the workflows</li><li>Karthik Tadepalli for making the Global Development workflow</li><li>Nathaniel Li &amp; Owen Murphy for making the AI Safety Workflow</li><li>Garrett Ehinger for helping with various readings &amp; finding leads for the Animal Welfare Workflow</li><li>Julian Guidote from EA x Law McGill for his encouragement in sharing these widely</li><li>Harrison Gietz from LSU for sharing the Workflows 2.0 with their university group</li><li>Muhammed Bakr for providing his comments on this draft</li><li>If I missed anyone just ping me :)</li></ul>", "user": {"username": "sonya.lebedeva@berkeley.edu"}}, {"_id": "gr4epkwe5WoYJXF32", "title": "Why I don\u2019t agree with HLI\u2019s estimate of household spillovers from therapy", "postedAt": "2023-02-24T18:18:18.084Z", "htmlBody": "<h1><strong>Summary</strong></h1><p>In its cost-effectiveness estimate of StrongMinds, Happier Lives Institute (HLI) estimates that most of the benefits accrue not to the women who receive therapy, but to household members.&nbsp;</p><p>According to&nbsp;<a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\"><u>HLI\u2019s estimates</u></a>, each household member benefits from the intervention ~50% as much as the person receiving therapy.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2xvw7gutllc\"><sup><a href=\"#fn2xvw7gutllc\">[1]</a></sup></span>&nbsp;Because there are ~5 non-recipient household members per treated person, this estimate increases the cost-effectiveness estimate by ~250%.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6cf2onvi1ip\"><sup><a href=\"#fn6cf2onvi1ip\">[2]</a></sup></span>&nbsp;i.e. ~70-80% of the benefits of therapy accrue to household members, rather than the program participant.</p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>I don\u2019t think the existing evidence justifies HLI's estimate of 50% household spillovers.&nbsp;</p><p>My main disagreements are:</p><ol><li>Two of the three RCTs HLI relies on to estimate spillovers are on interventions specifically intended to benefit household members (unlike StrongMinds\u2019 program, which targets women and adolescents living with depression).&nbsp;</li><li>Those RCTs only measure the wellbeing of a subset of household members most likely to benefit from the intervention.</li><li>The results of the third RCT are inconsistent with HLI\u2019s estimate.</li></ol></td></tr></tbody></table></figure><p><br>&nbsp;I\u2019d guess the spillover benefit to other household members is more likely to be in the 5-25% range (though this is speculative). That reduces the estimated cost-effectiveness of StrongMinds from 9x to 3-6x cash transfers, which would be below GiveWell\u2019s funding bar of 10x.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefw6iw9djjaua\"><sup><a href=\"#fnw6iw9djjaua\">[3]</a></sup></span>&nbsp;Caveat in footnote.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq1haortmi8\"><sup><a href=\"#fnq1haortmi8\">[4]</a></sup></span></p><p>I think I also disagree with other parts of HLI\u2019s analysis (including how worried to be about reporting bias; the costs of StrongMinds\u2019 program; and the point on a life satisfaction scale that\u2019s morally equivalent to death). I\u2019d guess, though I\u2019m not certain, that more careful consideration of each of these would reduce StrongMinds\u2019 cost-effectiveness estimate further relative to other opportunities. But I\u2019m going to focus on spillovers in this post because I think it makes the most difference to the bottom line, represents the clearest issue to me, and has received relatively little attention in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/ffmbLCzJctLac3rDu/strongminds-should-not-be-a-top-rated-charity-yet\"><u>other</u></a>&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/HqEmL7XAuuD5Pc4eg/evaluating-strongminds-how-strong-is-the-evidence\"><u>critiques</u></a>.</p><p><i>For context: I wrote the first version of Founders Pledge\u2019s mental health report in 2017 and gave feedback on an early draft of HLI\u2019s report on household spillovers. I\u2019ve spent 5-10 hours digging into the question of household spillovers from therapy specifically. I work at Open Philanthropy but wrote this post in a personal capacity. I\u2019m reasonably confident the main critiques in this post are right, but much less confident in what the true magnitude of household spillovers is. I admire the work StrongMinds is doing and I\u2019m grateful to HLI for their expansive literature reviews and analysis on this question.</i></p><p><i>Thank you to Joel McGuire, Akhil Bansal, Isabel Arjmand, Alex Cohen, Sjir Hoeijmakers, Josh Rosenberg, and Matt Lerner for their insightful comments. They don\u2019t necessarily endorse the conclusions of this post.</i></p><h2><strong>0. How HLI estimates the household spillover rate of therapy</strong></h2><p>HLI estimates household spillovers of therapy on the basis of the three RCTs on therapy which collected data on the subjective wellbeing of some of the household members of program participants:&nbsp;<a href=\"https://pubmed.ncbi.nlm.nih.gov/29444721/\"><u>Mutamba et al. (2018)</u></a>,&nbsp;<a href=\"https://ajp.psychiatryonline.org/doi/full/10.1176/appi.ajp.2008.07081339\"><u>Swartz et al. (2008)</u></a>,&nbsp;<a href=\"https://journals.sagepub.com/doi/abs/10.1177/1359104509339086\"><u>Kemp et al. (2009)</u></a>.</p><p>Combining those RCTs in a meta-analysis, HLI estimates household spillover rates of 53% (see the forest plot below; 53% comes from dividing the average household member effect (0.35) by the average recipient effect (0.66)).&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677262699/mirroredImages/gr4epkwe5WoYJXF32/fvsfxycj7piz1y6zpntv.png\"></p><p>HLI assumes StrongMinds\u2019 intervention will have a similar effect on household members. But, I don't think these three RCTs can be used to generate a reliable estimate for the spillovers of StrongMinds' program for three reasons.</p><h2><strong>1. Two of the three RCTs HLI relies on to estimate spillovers are on interventions specifically intended to benefit household members (unlike StrongMinds\u2019 program, which targets women and adolescents living with depression).&nbsp;</strong></h2><p>I briefly skimmed each of the RCTs, but I haven\u2019t reviewed them in depth.</p><ul><li><a href=\"https://pubmed.ncbi.nlm.nih.gov/29444721/\"><u>Mutamba et al. (2018)</u></a> delivered psychotherapy to caregivers of children with&nbsp;<a href=\"https://www.cdc.gov/globalhealth/noddingsyndrome/default.htm#:~:text=Nodding%20syndrome%20is%20an%20unexplained,as%20convulsions%20or%20staring%20spells.\"><u>nodding syndrome</u></a> (a neurological illness that includes seizures) and modified the typical therapy guidelines with \u201caddition of [nodding syndrome]-specific content\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0mns6pbfgyf\"><sup><a href=\"#fn0mns6pbfgyf\">[5]</a></sup></span></li><li><a href=\"https://ajp.psychiatryonline.org/doi/full/10.1176/appi.ajp.2008.07081339\"><u>Swartz et al. (2008)</u></a> delivered psychotherapy to depressed mothers whose children have psychiatric illness. It \u201cuses specific strategies to assist mothers in managing problematic interpersonal relationships with their dependent, psychiatrically ill offspring.\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcir0zrz7rk6\"><sup><a href=\"#fncir0zrz7rk6\">[6]</a></sup></span></li></ul><p>HLI does note limitations to external validity in its report, but concludes it\u2019s not sure whether these differences would lead to an underestimation or overestimation of treatment effects (relative to StrongMinds).</p><blockquote><p><i>&nbsp;\u201cA limitation to the external validity of this evidence is that all of the samples were selected based on negative shocks happening to the children in the sample... We are not sure if this would lead to an over or underestimate of the treatment effects, but it is potentially a further deviation from the type of household we are trying to predict the effects of psychotherapy for.\u201d&nbsp;</i><a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\"><u>Happiness for the Whole Family, 2022</u></a></p></blockquote><p>Generalizing across interventions is difficult. But it seems intuitive to me that we should expect the interventions in those studies would benefit household members&nbsp;<i>more</i> than StrongMinds\u2019 intervention, because (a) they were targeted at caregivers of children with psychiatric or neurological illnesses, who I\u2019d expect to be particularly sensitive to the standard of caregiving, and (b) they were specifically designed to help those children.</p><p>This seems like the simplest explanation for why these studies were two of the only studies on psychotherapy to measure the effect on household members: because they were actively trying to help household members and so had a reasonable expectation of finding an effect.</p><p>A couple of caveats:</p><ul><li>The control group in&nbsp;<a href=\"https://pubmed.ncbi.nlm.nih.gov/29444721/\"><u>Mutamba et al. (2018)</u></a> may have also received a similar level of training in management of children with nodding syndrome. If this were the case, it\u2019d weaken point (b), though point (a) would still stand.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefad31hhng4gp\"><sup><a href=\"#fnad31hhng4gp\">[7]</a></sup></span></li><li>StrongMinds\u2019 intervention is interpersonal group therapy, which one might expect to also benefit close relationships (and I do expect there\u2019s&nbsp;<i>some</i> positive effect in expectation). But this still seems quite different from the specificity with which the interventions in these two studies were targeted. Other less targeted studies of interpersonal therapy (e.g.&nbsp;<a href=\"https://pubmed.ncbi.nlm.nih.gov/12813117/\"><u>Bolton et al. 2003</u></a>) didn\u2019t measure effects on household members and I assume part of the reason is they didn\u2019t expect to see a measurable effect.</li></ul><h2><strong>2. Those RCTs only measure the wellbeing of a subset of household members most likely to benefit from the intervention</strong>&nbsp;</h2><p>In its cost-effectiveness estimate, HLI applies the estimated spillover effect to ~five household members for each person treated for depression. But the spillover effect is estimated based on a single household member who seemed most likely to benefit from the intervention.&nbsp;</p><ul><li><a href=\"https://pubmed.ncbi.nlm.nih.gov/29444721/\"><u>Mutamba et al. (2018)</u></a> treated caregivers and measured the effects on one child with nodding syndrome.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkg9azofyfnc\"><sup><a href=\"#fnkg9azofyfnc\">[8]</a></sup></span></li><li><a href=\"https://ajp.psychiatryonline.org/doi/full/10.1176/appi.ajp.2008.07081339\"><u>Swartz et al. (2008)</u></a> treated mothers and measured the effects on one child receiving psychiatric treatment.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7w9m1527ocg\"><sup><a href=\"#fn7w9m1527ocg\">[9]</a></sup></span></li></ul><p>Extrapolating these benefits to the entire household without discounting seems like a stretch to me for the same reasons as outlined above. It seems likely that these children were the household members most likely to benefit from the intervention which was (a) specifically targeted at their caregivers (b) specifically designed to help those children.</p><h2><strong>3. The results of the third RCT are inconsistent with HLI\u2019s estimate.</strong></h2><p>In the forest plot above, HLI reports that&nbsp;<a href=\"https://journals.sagepub.com/doi/abs/10.1177/1359104509339086\"><u>Kemp et al. (2009)</u></a> finds a non-significant 0.35 [-0.43,1.13] standard deviation improvement in mental health for parents of treated children.</p><p>But table 2 reports that parents in the treatment groups\u2019 score on the GHQ-12&nbsp;<i>increased</i> relative to the wait-list group (higher scores on the GHQ-12 indicate more self-reported mental health problems).&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjpblu5196wg\"><sup><a href=\"#fnjpblu5196wg\">[10]</a></sup></span></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677262699/mirroredImages/gr4epkwe5WoYJXF32/v8urch4rccflw2qngr19.png\"></p><p>To be clear, I doubt the intervention really did have a negative effect on parents\u2019 mental health; the effect sizes on GHQ are small and far from significant. I looked at GHQ because it seems to be HLI's preferred measure of mental health.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref13oug6hchwyh\"><sup><a href=\"#fn13oug6hchwyh\">[11]</a></sup></span>&nbsp;But another measure, the&nbsp;<a href=\"https://www.ptsd.va.gov/professional/assessment/adult-sr/ies-r.asp\"><u>Impact of Event Scale</u></a>&nbsp;<a href=\"https://www.ptsd.va.gov/professional/assessment/adult-sr/ies-r.asp\"><u>(IES)</u></a> does seem to have declined/improved (non-significantly) more in the treatment than the control group. And another, the&nbsp;<a href=\"https://onlinelibrary.wiley.com/doi/10.1111/scs.12269\"><u>General Functioning Scale (GFS)</u></a> stayed about the same in both groups.&nbsp;</p><p>Given the inconsistency of results between different instruments, and the lack of statistical power, I don\u2019t think we can learn much either way about household spillovers from this study.</p><h2><strong>What would I do if I wanted to get a better estimate of household spillovers from therapy?</strong></h2><p>My best guess of 5-25% spillovers is very subjective, and largely comes from a combination of adjusting the RCT evidence downwards for some of the concerns above, reflecting on my priors, and a very brief skim of some of some of the observational evidence HLI cites in its report.</p><p>If I wanted to get a better estimate, I\u2019d consider:</p><ul><li>More carefully reviewing the observational evidence for associations between familial subjective wellbeing. For example,&nbsp;<a href=\"https://openknowledge.worldbank.org/bitstream/handle/10986/4493/1564698x-23-1-31-55.pdf?sequence=1&amp;isAllowed=y\"><u>Das et al. 2008</u></a>, a cross-sectional study of survey data across five low-and middle income countries, finds \u201ca one standard deviation change in the mental health of household members is associated with a 0.22\u20130.59 standard deviation change in own mental health,\u201d but notes omitted variable bias probably means this overestimates the causal effect.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4bhzlxd7vy3\"><sup><a href=\"#fn4bhzlxd7vy3\">[12]</a></sup></span>&nbsp;Other correlational studies find lower associations (5% and 25%),<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpx34dhyiu2\"><sup><a href=\"#fnpx34dhyiu2\">[13]</a></sup></span>&nbsp;and note that while omitted variable bias might lead to an overestimation of the effect,&nbsp; measurement error might also lead to an underestimation of the effect.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefux066qu28a9\"><sup><a href=\"#fnux066qu28a9\">[14]</a></sup></span></li><li>Looking at evidence for analogous effects. For example, how strong are household spillovers from education?</li><li>Talking to people who participated in StrongMinds\u2019 program and their household members to better understand potential mechanisms for spillover effects.</li><li>Running a larger RCT which measures the impact of therapy on all household members.</li></ul><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2xvw7gutllc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2xvw7gutllc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cFor psychotherapy, we estimate from three studies the spillover ratio to be 53% (95% CI: 11%, 108%)\u201d&nbsp;<a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\"><u>Happiness for the Whole Family</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6cf2onvi1ip\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6cf2onvi1ip\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;&nbsp;\u201cWe use the non-recipient household size, the household size minus the recipient of the intervention. For StrongMinds, we find a non-recipient household size of 4.85 (95% CI: 1.01, 8.94).\u201d&nbsp;<a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\"><u>Happiness for the Whole Family</u></a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnw6iw9djjaua\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefw6iw9djjaua\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cAfter including the household spillover effects, we estimate that psychotherapy is 9 times (95% CI: 2, 100) more cost-effective than cash transfers (before it was 12 times).\u201d&nbsp;<a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\"><u>Happiness for the Whole Family</u></a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq1haortmi8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq1haortmi8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;HLI has a different perspective on the cost-effectiveness of GiveWell\u2019s top charities (which are mostly focused on life-saving interventions), such that it\u2019s not entirely clear how comparable GiveWell\u2019s funding bar relative to cash is with HLI\u2019s implied funding bar relative to cash.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0mns6pbfgyf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0mns6pbfgyf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://pubmed.ncbi.nlm.nih.gov/29444721/\"><u>Mutamba et al. (2018)</u></a>, Table 1</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncir0zrz7rk6\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcir0zrz7rk6\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://ajp.psychiatryonline.org/doi/full/10.1176/appi.ajp.2008.07081339\"><u>Swartz et al. (2008)</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnad31hhng4gp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefad31hhng4gp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp; <a href=\"https://pubmed.ncbi.nlm.nih.gov/29444721/\"><u>Mutamba et al. (2018)</u></a>, Table 1 suggests the intervention included an adaptation of nodding-syndrome specific content. I\u2019d also guess that in a group setting with a shared experience as specific as caring for a child with nodding-syndrome, that would inform much of the focus of the discussion, even if it wasn\u2019t deliberately included as part of the intervention.</p><p>On the other hand, the control group received at least some relevant training. From Mutamba et al. 2018, pg 3 \u201cAll health workers at HFs in the study sites received training on the medical management of children with NS. Caregivers in the TAU and experimental-arm villages received usual care as provided for in the national management guidelines for NS (Idro et al. 2013). TAU included health education about NS, syndromic management of children with pharmacological agents (typically sodium valproate or carbamazepine), caregiver education and supportive counselling (Idro et al. 2013).\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkg9azofyfnc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkg9azofyfnc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cA child was included if they had NS and a consenting caregiver with them. In families with more than one child with NS (approximately 30%), caregivers were asked to identify one of their children most affected by NS that would participate in the study\u201d&nbsp;<a href=\"https://pubmed.ncbi.nlm.nih.gov/29444721/\"><u>Mutamba et al. (2018)</u></a>, pg 2.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7w9m1527ocg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7w9m1527ocg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cChildren gave informed consent or assent after mothers were deemed eligible for inclusion. If multiple children were eligible, the mothers were asked to designate one child participant.\u201d&nbsp;<a href=\"https://ajp.psychiatryonline.org/doi/full/10.1176/appi.ajp.2008.07081339\"><u>Swartz et al. (2008)</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjpblu5196wg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjpblu5196wg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cDespite random allocation to group, wait-list parents reported higher self-reported health problems on the GHQ \u2013 12\u201d&nbsp;<a href=\"https://journals.sagepub.com/doi/abs/10.1177/1359104509339086\"><u>Kemp et al. (2009)</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn13oug6hchwyh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref13oug6hchwyh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cKemp et al. (2009)... the parents\u2019 (who did not receive therapy) mental health was measured with the 12-items General Health Questionnaire (GHQ-12). There was a significant difference in GHQ-12 levels between control and treatment group parents, so we used the difference of differences between baseline and post-treatment to adjust for this.\u201d&nbsp;<a href=\"https://www.happierlivesinstitute.org/report/happiness-for-the-whole-family/\"><u>Happiness for the Whole Family</u></a>&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4bhzlxd7vy3\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4bhzlxd7vy3\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;\u201cThere are several possible channels for such a correlation. It may reflect omitted household variables, such as household-specific shocks or a lack of health services. It could also reflect unobserved individual traits, if assortative mating leads those with poor mental health to marry and perhaps pass on genetic factors influencing mental health of other family members. But it is also plausible that the presence of one household member with poor mental health creates a poor mental health environment for other household members, a \u201ccontagion\u201d effect.\u201d (<a href=\"https://academic.oup.com/wber/article-abstract/23/1/31/1707009?redirectedFrom=fulltext\"><u>Das et al. 2008</u></a>)</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpx34dhyiu2\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpx34dhyiu2\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://www.researchgate.net/publication/40676370_Mental_Health_of_Parents_and_Life_Satisfaction_of_Children_A_Within-Family_Analysis_of_Intergenerational_Transmission_of_Well-Being\"><u>Powdthavee and Vignoles 2008</u></a>, a study in the UK, finds a one standard deviation increase in parents' mental distress in the previous year is associated with 25% of a standard deviation lower life satisfaction in the current year for girls&nbsp;\u201cGiven that the mean of LS for girls is 5.738 and its standard deviation is 1.348, a&nbsp;<i>ceteris paribus&nbsp;</i>increase of one standard deviation in either parent\u2019s mental distress level explains around a 25% drop in the standard deviation in the girl\u2019s LS.\u201d</p><p><a href=\"https://docs.iza.org/dp11431.pdf\"><u>Mendolia et al. 2018</u></a>, a study in Australia, finds a one standard deviation increase in partner\u2019s life satisfaction is associated with 5% of a standard deviation increase in individual life satisfaction&nbsp;\u201cIn Table 7, we begin with the analysis of the impact of the partner\u2019s standardised SF36 mental health score (0-100, where higher values represent higher level of well-being). Increasing this score by one standard deviation increases individual\u2019s life satisfaction by 0.07 points (on a 1-10 scale), which is equivalent to 5% of a standard deviation in life satisfaction. To put this in context, this is similar to the (reversed) effect of becoming unemployed or being victim of a property crime (see Table 10).\u201d&nbsp;<a href=\"https://docs.iza.org/dp11431.pdf\"><u>Mendolia et al. 2018</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnux066qu28a9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefux066qu28a9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;<a href=\"https://psycnet.apa.org/record/2009-11457-015\"><u>Powdthavee 2009</u></a>: \u201cIn addition to the above confounding influences which make it difficult for the true relationship between partners\u2019 well-being to be identified, the estimates of spousal correlation in LS may also suffer from the negative measurement error bias. There may be, for example, a tendency for individuals to misreport their true LS in surveys. The low signal-to-noise ratio caused by misreporting can result in an estimated coefficient on partner LS that is biased towards zero in a large sample. In short, because there are both positive (correlated effects) and negative (measurement error) biases involved, the direction of bias is unclear on a priori ground.\u201d</p></div></li></ol>", "user": {"username": "JamesSnowden"}}, {"_id": "jEHcbrsumxditRhtG", "title": "Updates from the Mental Health Funder's Circle", "postedAt": "2023-02-24T19:42:51.427Z", "htmlBody": "<p>The&nbsp;<a href=\"https://www.mentalhealthfunders.com\"><u>Mental Health Funder\u2019s Circle</u></a> held its first grant round in the Fall/Winter of 2022. To those of you who applied for this round, we appreciate your patience. As this was our first round of funding, everything took longer than expected. We will iterate on the structure of the funding circle over time, and intend to develop a process that adds value for members and grantees alike.&nbsp;</p><p>A total of $254,000 was distributed to the following three organizations:&nbsp;</p><ul><li>A matching grant of $44,000 to&nbsp;<a href=\"https://vidaplena.global\"><u>Vida Plena</u></a> for their work on cost-effective community mental health in Ecuador.&nbsp;</li><li>Two grants totaling $100,000 to&nbsp;<a href=\"http://happierlivesinstitute.org\"><u>Happier Lives Institute</u></a> for their continued work on subjective wellbeing and cause prioritization research.&nbsp;</li><li>Two grants totaling $110,000 to&nbsp;<a href=\"https://www.rethinkwellbeing.org\"><u>Rethink Wellbeing</u></a> to support mental health initiatives for the EA community.&nbsp;</li></ul><p><strong>Our next round of funding is now open</strong>, with initial 1-pagers due April 1st. After applications have been reviewed, we will contact promising grantees and make final funding decisions by June 1st. Applications can be found&nbsp;<a href=\"https://www.mentalhealthfunders.com\"><u>on our website</u></a>. For more information on the MHFC, see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/sKKQ6YxQXnvSJs2sp/launching-a-donor-circle-for-mental-health\"><u>this forum post</u></a>. Unfortunately, we lack the ability to respond to every application.&nbsp;</p><p>We are excited to find and support impactful organizations working on cost-effective and catalytic mental health interventions. We encourage you to apply, even if you think your project might be outside of our scope!</p>", "user": {"username": "wtroy"}}, {"_id": "ukszSQHPMN4kyyKRx", "title": "2023 Stanford Existential Risks Conference", "postedAt": "2023-02-24T17:49:30.607Z", "htmlBody": "<p>The team at SERI is excited to announce that sign-ups for the 3rd annual Stanford Existential Risks Conference are now open! We will be running a hybrid conference this year. <a href=\"https://airtable.com/shrPg0XTaZLKxxTem\"><u>Sign-ups</u></a> for both in-person and virtual attendance are now live.&nbsp;</p><p>This is an exciting opportunity for attendees to engage with experts in the field, network with like-minded individuals, and gain insights into the latest research and developments related to existential risk.&nbsp;This year\u2019s conference aims to take stock of global catastrophic and existential risk studies. A special focus of this meeting will be risk intersections, reinforcements, and cascades: how one risk may amplify (or diminish) another, and how multiple risks interact to create new concerns that may be larger than the sum of their parts. The conference will also feature discussions of the ethics of radical longtermism.</p><p>Because space for in-person attendance is limited, we encourage you to <a href=\"https://airtable.com/shrPg0XTaZLKxxTem\"><u>sign up</u></a> as soon as possible.</p><p>View <a href=\"https://seri.stanford.edu/events/stanford-existential-risks-conference-april-20-22-2023\"><u>additional information about the conference</u></a>. Questions or concerns? <a href=\"mailto:seri-contact@stanford.edu\"><u>Click here to contact us</u></a>.&nbsp;</p><p>We look forward to your participation in this thought-provoking and impactful event!</p><p>In survival and flourishing,</p><p>The SERI Team</p>", "user": {"username": "elizabethcooper"}}, {"_id": "vYEsT4ggk3tmQX3pb", "title": "EA Animal Support needed", "postedAt": "2023-02-24T17:19:34.533Z", "htmlBody": "<p>Can this be quickly avoided - <a href=\"https://www.msn.com/en-us/news/us/150-feral-cattle-to-be-shot-from-sky-in-new-mexico-national-forest-as-us-forest-service-issues-kill-order/ar-AA17IEQJ?ocid=hpmsn\">150 feral cattle to be shot from sky in New Mexico national forest as US Forest Service issues kill order (msn.com)</a>? Any thoughts?</p>", "user": {"username": "rtm"}}, {"_id": "4pwCb6c8zvq6susov", "title": "\"EA is very open to some kinds of critique and very not open to others\" \n and \"Why do critical EAs have to use pseudonyms?\"", "postedAt": "2023-02-24T17:10:02.463Z", "htmlBody": "<h1>Preamble</h1><p>This is an extract from a post called \"<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1\">Doing EA Better</a>\", which argued that EA's new-found power and influence obligates us to solve our movement's significant problems with respect to epistemics, rigour, expertise, governance, and power.</p><p>We are splitting DEAB up into a sequence to facilitate object-level discussion.</p><p>Each post will include the relevant parts of the list of suggested reforms. There isn't a perfect correspondence between the subheadings of the post and the reforms list, so not all reforms listed will be 100% relevant to the section in question.</p><p>Finally, we have tried (imperfectly) to be reasonably precise in our wording, and we ask that before criticising an argument of ours, commenters ensure that it is an argument that we are in fact making.</p><h1>EA is very open to some kinds of critique and very not open to others</h1><p><strong>Summary:</strong> EA is very open to shallow critiques, but not deep critiques. Shallow critiques are small technical adjustments written in ingroup language, whereas deep critiques hint at the need for significant change, criticise prominent figures or their ideas, and can suggest outgroup membership. This means EA is very good at optimising along a very narrow and not necessarily optimal path.</p><p>EA prides itself on its openness to criticism, and in many areas this is&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/criticism-and-red-teaming-contest\">entirely justified</a>. However, willingness to engage with critique varies widely depending on the type of critique being made, and powerful structures exist within the community that reduce the likelihood that people will speak up&nbsp;<i>and be heard</i>.</p><p>Within EA, criticism is acceptable, even encouraged, if it lies within particular boundaries, and when it is expressed in suitable terms. Here we distinguish informally between \u201cshallow critiques\u201d and \u201cdeep critiques\u201d.<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-16\">[16]</a></p><p>Shallow critiques are often:</p><ul><li>Technical adjustments to generally-accepted structures<ul><li>\u201cWe should rate intervention X 12% higher than we currently do.\u201d</li><li>Changes of emphasis or minor structural/methodological adjustments</li><li>Easily conceptualised as \u201coptimising\u201d \u201cupdates\u201d rather than cognitively difficult qualitative switches</li></ul></li><li>Written in EA-language and sprinkled liberally with EA buzzwords</li><li>Not critical of capitalism</li></ul><p>Whereas deep critiques are often:</p><ul><li>Suggestive that one or more of the fundamental ways we do things are wrong<ul><li>i.e. are critical of EA orthodoxy</li><li>Thereby implying that people may have invested considerable amounts of time/effort/identity in something when they perhaps shouldn\u2019t have<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-17\">[17]</a></li></ul></li><li>Critical of prominent or powerful figures within EA</li><li>Written in a way suggestive of outgroup membership<ul><li>And thus much more likely to be read as hostile and/or received with hostility</li></ul></li><li>Political<ul><li>Or more precisely: of a different politics to the broadly liberal<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-18\">[18]</a>-technocratic approach popular in EA</li></ul></li></ul><p>EA is&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/YgbpxJmEdFhFGpqci/winners-of-the-ea-criticism-and-red-teaming-contest\">very open to shallow critiques</a>, which is something we absolutely love about the movement. As a community, however, we remain remarkably resistant to deep critiques. The distinction is likely present in most epistemic communities, but EA appears to have a particularly large problem. Again, there will be exceptions, but the trend is clear.</p><p>The problem is illustrated well by the example of an entry to the recent Red-Teaming Contest: \u201c<a href=\"https://medium.com/@sven_rone/the-effective-altruism-movement-is-not-above-conflicts-of-interest-25f7125220a5\">The Effective Altruism movement is not above conflicts of interest</a>\u201d. It warned us of the political and ethical risks associated with taking money from cryptocurrency billionaires like Sam Bankman-Fried, and suggested that EA has a serious blind spot when it comes to (financial) conflicts of interest.<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-19\">[19]</a></p><p>The article (which did not win anything in the contest) was written under a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/xafpj3on76uRDoBja/the-ftx-future-fund-team-has-resigned-1?commentId=YjkzhkGc86yaWiuP8\">pseudonym</a>, as the author feared that making such a critique publicly would incur a risk of repercussions to their career. A related&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/xafpj3on76uRDoBja/the-ftx-future-fund-team-has-resigned-1?commentId=FqA7gH6MBP4whxNig\">comment</a> provided several well-evidenced reasons to be morally and pragmatically wary of Bankman-Fried, got&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/xafpj3on76uRDoBja/the-ftx-future-fund-team-has-resigned-1?commentId=FqA7gH6MBP4whxNig\">downvoted heavily</a>, and was eventually deleted by its author.</p><p>Elsewhere, critical EAs report<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-20\">[20]</a> having to develop specific rhetorical strategies to be taken seriously. Making deep critiques or contradicting orthodox positions outright gets you labelled as a \u201cnon-value-aligned\u201d individual with \u201cpoor epistemics\u201d, so you need to pretend to be extremely deferential and/or stupid and ask questions in such a way that critiques are raised without actually being stated.<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-21\">[21]</a></p><p>At the very least, critics have learned to watch their tone at all costs, and provide a constant stream of unnecessary caveats and reassurances in order to not be labelled \u201cemotional\u201d or \u201coverconfident\u201d.</p><p>These are not good signs.</p><h1>Why do critical EAs have to use pseudonyms?</h1><p><strong>Summary:</strong> Working in EA usually involves receiving money from a small number of densely connected funding bodies/individuals. Contextual evidence is strongly suggestive that raising deep critiques will drastically reduce one\u2019s odds of being funded, so many important projects and criticisms are lost to the community.</p><p>There are several reasons people may not want to publicly make deep critiques, but the one that has been most impactful in our experience has been the role of funding.<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-22\">[22]</a></p><p>EA work generally relies on funding from EA sources: we need to pay the bills, and the kinds of work EA values are often very difficult to fund via non-EA sources. Open Philanthropy, and previously FTX, has/had an almost&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#Decentralised_in_theory__centralised_in_practice\">hegemonic</a> funding role in many areas of existential risk reduction, as well as several other domains. This makes EA funding organisations and even individual grantmakers extremely powerful.</p><p>Prominent funders have said that they value&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/T975ydo3mx8onH3iS/ea-is-about-maximization-and-maximization-is-perilous\">moderation and pluralism</a>, and thus people (like the writers of this post) should feel comfortable&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/gx7BEkoRbctjkyTme/democratising-risk-or-how-ea-deals-with-critics-1?commentId=AQk29QGbvCLGFJmxr\">sharing their real views</a> when they apply for funding, no matter how critical they are of orthodoxy.</p><p>This is admirable, and we are sure that they are being truthful about their beliefs. Regardless, it is difficult to trust that the promise will be kept when one, for instance:</p><ul><li>Observes the types of projects (and people) that succeed (or fail) at acquiring funding<ul><li>i.e. few, if any, deep critiques or otherwise heterodox/\u201cheretical\u201d works</li></ul></li><li>Looks into the backgrounds of grantmakers and sees how they appear to have very similar backgrounds and opinions (i.e they are highly orthodox)</li><li>Experiences the generally claustrophobic epistemic atmosphere of EA</li><li>Hears of people facing (soft) censorship from their superiors because they wrote deep critiques of the ideas of prominent EAs<ul><li>Zoe Cremer and Luke Kemp&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/gx7BEkoRbctjkyTme/democratising-risk-or-how-ea-deals-with-critics-1\">lost</a> \u201csleep, time, friends, collaborators, and mentors\u201d as a result of writing&nbsp;<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3995225\">Democratising Risk</a>, a paper which was critical of some EA approaches to existential risk.<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-23\">[23]</a> Multiple senior figures in the field attempted to prevent the paper from being published, largely out of fear that it would offend powerful funders. This saga caused significant conflict within CSER throughout much of 2021.</li></ul></li><li>Sees the revolving door and close social connections&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#Decentralised_in_theory__centralised_in_practice\">between</a> key donors and main scholars in the field</li><li>Witnesses grantmakers dismiss scientific work on the grounds that the people doing it are insufficiently value-aligned<ul><li>If this is what is said in public (which we have witnessed multiple times), what is said in private?</li></ul></li><li>Etc.</li></ul><p>Thus, it is reasonable to conclude that if you want to get funding from an EA body, you must not only try to propose a good project, but one that could not be interpreted as insufficiently \u201cvalue-aligned\u201d, however the grantmakers might define it. If you have an idea for a project that seems very important, but could be read as a \u201cdeep critique\u201d, it is rational for you to put it aside.</p><p>The risk to one\u2019s career is especially important given the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#Decentralised_in_theory__centralised_in_practice\">centralisation</a> of funding bodies as well as the dense internal social network of EA\u2019s upper echelons.<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-24\">[24]</a></p><p>Given this level of clustering, it is reasonable to believe that if you admit to holding heretical views on your funding application, word will spread, and thus you will quite possibly never be funded by any other funder in the EA space, never mind any&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/fovDwkBQgTqRMoHZM/power-dynamics-between-people-in-ea\">other consequences</a> (e.g. gatekeeping of EA events/spaces) you might face. For a sizeable portion of EAs, the community forms a very large segment of one\u2019s career trajectory, social life, and identity; not things to be risked easily.<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-25\">[25]</a> For most, the only robust strategy is to keep your mouth shut.<a href=\"https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1#fn-pMAQ8odjQviWs2qYJ-26\">[26]</a></p><p><strong>Grantmakers:</strong> You are missing out on exciting, high potential impact projects due to these processes. When the stakes are as high as they are, verbal assurances are unfortunately insufficient. The problems are structural, so the solutions must be structural as well.</p><h1>Suggested reforms</h1><p>Below, we have a preliminary non-exhaustive list of relevant suggestions for structural and cultural reform that we think may be a good idea and should certainly be discussed further.</p><p>It is of course plausible that some of them would not work; if you think so for a particular reform, please explain why! We would like input from a range of people, and we certainly do not claim to have all the answers!</p><p>In fact, we believe it important to open up a conversation about plausible reforms not because we have all the answers, but precisely because we don\u2019t.</p><p><i>Italics</i> indicates reforms strongly inspired by or outright stolen from Zoe Cremer\u2019s <a href=\"https://docs.google.com/document/d/1Y9opezUk9_JNQBYCAmHoERiqlaf2HmashQQ_ydGwyRY/edit\">list</a> of structural reform ideas. Some are edited or merely related to her ideas; they should not be taken to represent Zoe\u2019s views.</p><p>Asterisks (*) indicate that we are less sure about a suggestion, but sure enough that we think they are worth considering seriously, e.g. through deliberation or research. Otherwise, we have been developing or advocating for most of these reforms for a long time and have a reasonable degree of confidence that they should be implemented in some form or another.</p><p>Timelines are suggested to ensure that reforms can become concrete. If stated, they are rough estimates, and if there are structural barriers to a particular reform being implemented within the timespan we suggest, let us know!</p><p>Categorisations are somewhat arbitrary, we just needed to break up the text for ease of reading.</p><h2>Critique</h2><h3>General</h3><ul><li>EAs must be more willing to make deep critiques, both in private and in public<ul><li>You are not alone, you are not crazy!</li><li>There is a much greater diversity of opinion in this community than you might think</li><li>Don\u2019t assume that the people in charge must be smarter than you, and that you must be missing something if you disagree \u2013 even most of them don\u2019t think that!</li></ul></li><li>EA must be open to deep critiques as well as shallow critiques<ul><li>We must temper our knee-jerk reactions against deep critiques, and be curious about our emotional reactions to arguments \u2013 \u201cWhy does this person disagree with me? Why am I so instinctively dismissive about what they have to say?\u201d</li><li>We must be willing to accept the possibility that \u201cbig\u201d things may need to be fixed and that some of our closely-held beliefs are misguided</li><li>Our willingness to consider a critique should be orthogonal to the seniority of the authors of the subject(s) of that critique</li><li>When we reject critiques, we should present our reasons for doing so</li></ul></li><li>EAs should read more deep critiques of EA, especially external ones<ul><li>For instance&nbsp;<a href=\"https://ineffectivealtruismblog.com/\">this</a> blog and&nbsp;<a href=\"https://www.goodreads.com/book/show/63392758-the-good-it-promises-the-harm-it-does\">this</a> forthcoming book</li></ul></li><li>EA should cut down its overall level of tone/language policing<ul><li>Norms should still be strongly in favour of civility and good-faith discourse, but anger or frustration cannot be grounds for dismissal, and deep critique must not be misinterpreted as aggression or \u201csignalling\u201d</li><li>Civility must not be confused with EA ingroup signalling</li><li>Norms must be enforced consistently, applying to senior EAs just as much as newcomers</li></ul></li><li>EAs should make a conscious effort to avoid (subconsciously/inadvertently) using rhetoric about how \u201cEA loves criticism\u201d as a shield against criticism<ul><li>Red-teaming contests, for instance, are very valuable, but we should avoid using them to claim that \u201csomething is being done\u201d about criticism and thus we have nothing to worry about</li><li>\u201cIf we are so open to critique, shouldn\u2019t we be open to this one?\u201d</li><li>EAs should avoid delaying reforms by professing to take critiques very seriously without actually acting on them</li></ul></li><li>EAs should state their reasons when dismissing critiques, and should be willing to call out other EAs if they use the rhetoric of rigour and even-handedness without its content</li><li>EAs, especially those in community-building roles, should send credible/costly signals that EAs can make or agree with deep critiques without being excluded from or disadvantaged within the community</li><li>EAs should be cautious of knee-jerk dismissals of attempts to challenge concentrations of power, and seriously engage with critiques of capitalist modernity</li><li>EAs, especially prominent EAs, should be willing to cooperate with people writing critiques of their ideas and participate in&nbsp;<a href=\"https://en.wikipedia.org/wiki/Adversarial_collaboration\">adversarial collaborations</a></li><li>EA institutions and community groups should run discussion groups and/or event programmes on how to do EA better</li></ul><h3>Institutions</h3><ul><li>Employees of EA organisations should not be pressured by their superiors to not publish critical work</li><li>Funding bodies should enthusiastically fund deep critiques and other heterodox/\u201cheretical\u201d work</li><li>EA institutions should commission or be willing to fund large numbers of zero-trust investigations by domain-experts, especially into the components of EA orthodoxy</li><li><i>EA should set up a counter foundation that has as its main goal critical reporting, investigative journalism and \u201ccounter research\u201d about EA and other philanthropic institutions [within 12 months]*</i><ul><li><i>This body should be run by independent people and funded by its own donations, with a \u201cfloor\u201d proportional to other EA funding decisions (e.g. at least one researcher/community manager/grant program, admin fees in a certain height)</i></li><li>If this foundation is established, EA institutions should cooperate with it</li></ul></li><li>EA institutions should recruit known critics of EA and offer them e.g. a year of funding to write up long-form deep critiques</li><li>EA should establish public conference(s) or assemblies for discussing reforms within 6 months, with open invitations for EAs to attend without a selection process.&nbsp;<i>For example, an \u201conline forum of concerns\u201d:</i><ul><li><i>Every year invite all EAs to raise any worries they have about EA central organisations</i></li><li><i>These organisations declare beforehand that they will address the top concerns and worries, as voted by the attendees</i></li><li><i>Establish voting mechanism, e.g. upvotes on worries that seem most pressing</i></li></ul></li></ul><h3>Red Teams</h3><ul><li>EA institutions should establish clear mechanisms for feeding the results of red-teaming into decision-making processes within 6 months</li><li>Red teams should be paid, composed of people with a variety of views, and former- or non-EAs should be actively recruited for red-teaming<ul><li>Interesting critiques often come from dissidents/exiles who left EA in disappointment or were pushed out due to their heterodox/\u201dheretical\u201d views (yes, this category includes a couple of us)</li></ul></li><li>The judging panels of criticism contests should include people with a wide variety of views, including heterodox/\u201dheretical\u201d views</li><li>EA should use criticism contests as one tool among many, particularly well-suited to eliciting highly specific shallow critiques</li></ul><h2>Epistemics</h2><h3>General</h3><ul><li>EAs should see EA as a set of intentions and questions (\u201cWhat does it mean to \u2018do the most good\u2019, and how can I do it?\u201d) rather than a set of answers (\u201cAI is the highest-impact cause area, then maybe biorisk.\u201d)</li><li>EA should study social epistemics and collective intelligence more, and epistemic efforts should focus on creating good community epistemics rather than merely good individual epistemics<ul><li>As a preliminary programme, we should explore how to increase EA\u2019s overall levels of diversity, egalitarianism, and openness</li></ul></li><li>EAs should practise epistemic modesty<ul><li>We should read much more, and more widely, including authors who have no association with (or even open opposition to) the EA community</li><li>We should avoid assuming that EA/Rationalist ways of thinking are the only or best ways</li><li>We should actively seek out not only critiques of EA, but critiques of and alternatives to the underlying premises/assumptions/characteristics of EA (high modernism, elite philanthropy, quasi-positivism, etc.)</li><li>We should stop assuming that we are smarter than everybody else</li></ul></li><li>When EAs say \u201cvalue-aligned\u201d, we should be clear about what we mean<ul><li>Aligned with what values in particular?</li><li>We should avoid conflating the possession of the general goal of \u201cdoing the most good\u201d with subscription to the full package of orthodox views</li></ul></li><li>EAs should consciously separate:<ul><li>An individual\u2019s suitability for a particular project, job, or role</li><li>Their expertise and skill in the relevant area(s)</li><li>The degree to which they are perceived to be \u201chighly intelligent\u201d</li><li>Their perceived level of value-alignment with EA orthodoxy</li><li>Their seniority within the EA community</li><li>Their personal wealth and/or power</li></ul></li><li>EAs should make a point of engaging with and listening to EAs from underrepresented disciplines and backgrounds, as well as those with heterodox/\u201cheretical\u201d views</li><li>The EA Forum should have its karma/commenting system reworked to remove structural forces towards groupthink within 3 months. Suggested specific reforms include, in gently descending order of credence:<ul><li>Each user should have equal voting weight</li><li>Separate agreement karma should be implemented for posts as well as comments</li><li>A \u201csort by controversial\u201d option should be implemented</li><li>Low-karma comments should not be hidden</li><li>Low-karma comments should be occasionally shunted to the top</li></ul></li><li><i>EA should embark on a large-scale exploration of \u201ctheories of change\u201d: what are they, how do other communities conceptualise and use them, and what constitutes a \u201cgood\u201d one? This could include:*</i><ul><li><i>Debates</i></li><li><i>Lectures from domain-experts</i></li><li><i>Panel discussions</i></li><li><i>Series of forum posts</i></li><li><i>Hosting of experts by EA institutions</i></li><li><i>Competitions</i></li><li><i>EAG framed around these questions</i></li><li><i>Etc.</i></li></ul></li><li>When EA organisations commission research on a given question, they should publicly pre-register their responses to a range of possible conclusions</li></ul><h3>Ways of Knowing</h3><ul><li>EAs should consider how our shared modes of thought may subconsciously affect our views of the world \u2013 what blindspots and biases might we have created for ourselves?</li><li>EAs should increase their awareness of their own <a href=\"https://en.wikipedia.org/wiki/Standpoint_theory\">positionality</a> and subjectivity, and pay far more attention to e.g. postcolonial critiques of western academia<ul><li>History is <a href=\"https://www.youtube.com/watch?v=Xe3tunGi4To\">full</a> of people who thought they were very rational saying very silly and/or unpleasant things: let\u2019s make sure that doesn\u2019t include us</li></ul></li><li>EAs should study other ways of knowing, taking inspiration from a range of academic and professional communities as well as indigenous worldviews</li></ul><h3>Diversity</h3><ul><li>EA institutions should select for diversity<ul><li>With respect to:<ul><li>Hiring (especially grantmakers and other positions of power)</li><li>Funding sources and recipients</li><li>Community outreach/recruitment</li></ul></li><li>Along lines of:<ul><li>Academic discipline</li><li>Educational &amp; professional background</li><li>Personal background (class, race, nationality, gender, etc.)</li><li>Philosophical and political beliefs</li></ul></li><li>Naturally, this should not be unlimited \u2013 some degree of mutual similarity of beliefs is needed for people to work together \u2013 but we do not appear to be in any immediate danger of becoming too diverse</li></ul></li><li>Previous EA involvement should not be a necessary condition to apply for specific roles, and the job postings should not assume that all applicants will identify with the label \u201cEA\u201d</li><li>EA institutions should hire more people who have had little to no involvement with the EA community providing that they care about doing the most good</li><li>People with heterodox/\u201cheretical\u201d views should be actively selected for when hiring to ensure that teams include people able to play \u201cdevil\u2019s advocate\u201d authentically, reducing the need to rely on highly orthodox people accurately steel-manning alternative points of view</li><li>Community-building efforts should be broadened, e.g. involving a wider range of universities, and group funding should be less contingent on the perceived prestige of the university in question and more focused on the quality of the proposal being made</li><li>EA institutions and community-builders should promote diversity and inclusion more, including funding projects targeted at traditionally underrepresented groups</li><li>A greater range of people should be invited to EA events and retreats, rather than limiting e.g. key networking events to similar groups of people each time</li><li><i>There should be a survey on cognitive/intellectual diversity within EA</i></li><li>EAs should not make EA the centre of their lives, and should actively build social networks and career capital outside of EA</li></ul><h3>Openness</h3><ul><li>Most challenges, competitions, and calls for contributions (e.g. cause area exploration prizes) should be posted where people not directly involved within EA are likely to see them (e.g. Facebook groups of people interested in charities, academic mailing lists, etc.)</li><li>Speaker invitations for EA events should be broadened away from (high-ranking) EA insiders and towards, for instance:<ul><li>Subject-matter experts from outside EA</li><li>Researchers, practitioners, and stakeholders from outside of our elite communities<ul><li>For instance, we need a far greater input from people from Indigenous communities and the Global South</li></ul></li></ul></li><li><i>External speakers/academics who disagree with EA should be invited give keynotes and talks, and to participate in debates with prominent EAs</i></li><li>EAs should make a conscious effort to seek out and listen to the views of non-EA thinkers<ul><li>Not just to respond!</li></ul></li><li>EAs should remember that EA covers one very small part of the huge body of human knowledge, and that the vast majority of interesting and useful insights about the world have and will come from outside of EA</li></ul><p>&nbsp;</p><h2>Funding &amp; Employment</h2><h3>Grantmaking</h3><ul><li>Grantmakers should be radically diversified to incorporate EAs with a much wider variety of views, including those with heterodox/\u201dheretical\u201d views</li><li>Funding frameworks should be reoriented towards using the \u201cright tool for the right job\u201d<ul><li>Optimisation appears entirely appropriate in well-understood, predictable domains, e.g. public health interventions against epidemic diseases<a href=\"https://forum.effectivealtruism.org/s/LBvAQ7rbnL2PANwJh/p/54vAiSFkYszTWWWv4#fn-pMAQ8odjQviWs2qYJ-80\"><sup>[8</sup></a><sup>0]</sup></li><li>But robustness is far superior when addressing domains of deep uncertainty, areas of high complexity, low-probability high-impact events, long timescales, poorly-defined phenomena, and significant expert disagreement, e.g. existential risk</li><li>Optimising actions should be taken on the basis of high-quality evidence, e.g. meta-reviews or structured expert elicitations, rather than being used as the default or even the only mode of operation</li></ul></li><li>Grantmaking organisations should commission independent external evaluations of the efficacy of their work (e.g. the success rates of grantmakers in forecasting the impact or success of projects) within 6 months, and release the results of any internal work they have done to this end</li><li><i>Within 5 years, EA funding decisions should be made collectively</i><ul><li><i>First set up experiments for a safe cause area with small funding pots that are distributed according to different collective decision-making mechanisms</i><ul><li>For example rotating panels, various forms of lottocracy</li><li><i>Subject matter experts are <strong>always</strong> used and weighed appropriately</i></li></ul></li><li><i>Experiment in parallel with randomly selected samples of EAs evaluating the decisions of one existing funding committee</i><ul><li><i>Existing decision-mechanisms are thus \u2018passed through\u2019 an accountability layer</i></li></ul></li><li><i><strong>All decision mechanisms should have a deliberation phase (arguments are collected and weighed publicly) and a voting phase (majority voting, quadratic voting, etc.)</strong></i></li><li><i>Depending on the cause area and the type of choice, either fewer (experts + randomised sample of EAs) or more people (any EA or beyond) should take part in the funding decision</i></li></ul></li><li>A certain proportion EA of funds should be allocated by lottery after a longlisting process to filter out the worst/bad-faith proposals*<ul><li>The outcomes of this process should be evaluated in comparison to EA\u2019s standard grantmaking methods as well as other alternatives</li></ul></li><li><i>Grantmaking should require detailed and comprehensive conflict of interest reporting</i></li></ul><h3>Employment</h3><ul><li>More people working within EA should be employees, with the associated legal rights and stability of work, rather than e.g. grant-dependent \u201cindependent researchers\u201d</li><li>EA funders should explore the possibility of funding more stable, safe, and permanent positions, such as professorships</li></ul><h1>Contact Us</h1><p>If you have any questions or suggestions about this article, EA, or anything else, feel free to email us at <a href=\"mailto:concernedEAs@proton.me\"><strong>concernedEAs@proton.me</strong></a></p><p><br>&nbsp;</p>", "user": {"username": "ConcernedEAs"}}, {"_id": "rqg7PRYTvCf74TRyG", "title": "Consent Isn't Always Enough", "postedAt": "2023-02-24T15:43:08.049Z", "htmlBody": "", "user": {"username": "Jeff_Kaufman"}}, {"_id": "cTfEv6zAakfyxrbQu", "title": "EA content in French: Announcing EA France\u2019s translation project and our translation coordination initiative", "postedAt": "2023-02-24T14:58:30.828Z", "htmlBody": "<p>We\u2019re happy to announce that<a href=\"https://forum.effectivealtruism.org/posts/CqYHPLCJaFdLn8gp6/open-phil-is-seeking-bilingual-people-to-help-translate-ea\">&nbsp;<u>thanks to a grant from Open Philanthropy</u></a>, EA France has been translating core EA content into French.&nbsp;</p><p>EA France is also coordinating EA EN\u2192FR translation efforts: if you\u2019re translating EA content from English to French or considering it, please contact me so we can check that there is no duplicated effort and provide support!</p><p>&nbsp;</p><h1>EA France\u2019s translation project</h1><p>With Open Philanthropy\u2019s grant, we hired professional translators to translate&nbsp;<strong>16 articles, totalling ~67,000 words</strong>. Their work is being reviewed by volunteers from the French EA community.</p><p>&nbsp;</p><h2>Articles being translated</h2><ul><li><a href=\"https://www.effectivealtruism.org/articles/introduction-to-effective-altruism\"><u>What is effective altruism?</u></a> (translation available at&nbsp;<a href=\"https://medium.com/altruisme-efficace/quest-ce-que-l-altruisme-efficace-91100e71b0ef\"><u>Qu\u2019est-ce que l\u2019altruisme efficace ?</u></a>)</li><li><a href=\"https://www.givingwhatwecan.org/charity-comparisons\"><u>Comparing Charities</u></a> (translation available at&nbsp;<a href=\"https://medium.com/altruisme-efficace/y-a-t-il-une-grande-diff%C3%A9rence-entre-les-associations-caritatives-e2399112a1b8\"><u>Y a-t-il des organisations caritatives plus efficaces que d\u2019autres ?</u></a>)</li><li><a href=\"https://www.probablygood.org/post/expected-value\"><u>Expected Value</u></a></li><li><a href=\"https://www.lesswrong.com/posts/ur9TCRnHJighHmLCW/on-caring\"><u>On Caring</u></a></li><li><a href=\"https://forum.effectivealtruism.org/s/B79ro5zkhndbBKRRX/p/wYjMsKsEkDPgHeAbS\"><u>Four Ideas You Already Agree With</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/5BpgZKFrfeRtREg7W/the-parable-of-the-boy-who-cried-5-chance-of-wolf\"><u>The Parable Of The Boy Who Cried 5% Chance Of Wolf</u></a></li><li><a href=\"https://80000hours.org/problem-profiles/artificial-intelligence/\"><u>Preventing an AI-related catastrophe</u></a></li><li><a href=\"https://80000hours.org/articles/existential-risks/\"><u>The case for reducing existential risks</u></a></li><li><a href=\"https://80000hours.org/problem-profiles/preventing-catastrophic-pandemics/\"><u>Preventing catastrophic pandemics</u></a></li><li><a href=\"https://80000hours.org/problem-profiles/climate-change/\"><u>Climate change</u></a></li><li><a href=\"https://80000hours.org/problem-profiles/nuclear-security/\"><u>Nuclear security</u></a></li><li><a href=\"https://www.cold-takes.com/most-important-century/#Summary\"><u>The \u201cmost important century\u201d blog series</u></a> (summary)</li><li><a href=\"https://www.probablygood.org/post/counterfactual-impact\"><u>Counterfactual impact</u></a></li><li><a href=\"https://80000hours.org/2014/01/neglectedness-and-impact/\"><u>Neglectedness and impact</u></a></li><li><a href=\"https://www.effectivealtruism.org/articles/cause-profile-global-health-and-development\"><u>Cause profile: Global health and development</u></a></li><li><a href=\"https://80000hours.org/make-a-difference-with-your-career/\"><u>This is your most important decision (career \u201cstart here\u201d</u></a>)</li></ul><p>(See the appendix for other translation projects from English to French, and for existing translations.)</p><p>&nbsp;</p><p>All content translated as part of the EA France translation project will be released on the&nbsp;<a href=\"https://medium.com/altruisme-efficace\"><u>EA France blog</u></a>.</p><p>It is also&nbsp;<strong>available for use by other French-speaking communities</strong>, provided that they 1) cite original writers, 2) link EA France\u2019s translations, 3) notify EA France at <a href=\"mailto:contact@altruismeefficacefrance.org\">contact@altruismeefficacefrance.org</a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzvrh6egvlxr\"><sup><a href=\"#fnzvrh6egvlxr\">[1]</a></sup></span>.<br>&nbsp;</p><p>We\u2019re very happy that more EA content will be available to French speakers, and we hope that it will make outreach efforts significantly easier!</p><p><br>&nbsp;</p><h1>Translation Coordination Initiative</h1><p>Now that several translation projects exist, it\u2019s essential that we have a way to coordinate so that:</p><ul><li>we don\u2019t duplicate effort (translating the same content twice),</li><li>we agree on a common vocabulary (so the same term doesn\u2019t get translated in 3 different ways, which makes it needlessly confusing for readers),</li><li>EA France can provide support to all projects (e.g. sharing translations once they\u2019re published, helping with editing, hosting translated works).<br>&nbsp;</li></ul><p>The coordination initiative consists of:</p><ul><li>a master spreadsheet which lists all existing projects, and what they\u2019re translating,</li><li>a <a href=\"https://docs.google.com/spreadsheets/d/1yguO6LqIsO3HnvvwZD6gD2CmPvdtItOJ2dOBos4ZZHo/edit?usp=sharing\">glossary of existing translations</a> that translators and editors can refer to (still in progress).</li></ul><p>&nbsp;</p><p>The master spreadsheet and the editable version of the glossary are accessible upon request.</p><p>&nbsp;</p><h1>Appendix</h1><h3>What other translation projects exist?</h3><p>There are at least two other ongoing projects contributing to this overall effort, feeding the glossary and monitored in the master spreadsheet:</p><ul><li>translating the 80,000 Hours Career Guide, led by Th\u00e9o Knopfer (funded by a grant from Open Philanthropy),</li><li>translating the EA Handbook, led by Baptiste Roucau (also funded by a grant from Open Philanthropy).</li></ul><p>&nbsp;</p><h3>What translations are already available in French?</h3><ul><li><a href=\"https://www.effectivealtruism.org/articles/longtermism\"><u>Longtermism: An Introduction</u></a> (<a href=\"https://medium.com/altruisme-efficace/les-trois-hypoth%C3%A8ses-du-long-termisme-c0910ed1f72b\"><u>Les trois hypoth\u00e8ses du long-termisme</u></a>, translation by Antonin Broi)</li><li><a href=\"https://blog.jaibot.com/500-million-but-not-a-single-one-more/\"><u>500 Million, But Not A Single One More</u></a> (<a href=\"http://jrmyp.net/variole.html\"><u>500 millions, mais pas un de plus</u></a>, translation by J\u00e9r\u00e9my Perret)</li><li><a href=\"https://blog.givewell.org/2015/11/06/the-lack-of-controversy-over-well-targeted-aid/\"><u>The lack of controversy over well-targeted aid</u></a> (<a href=\"https://medium.com/altruisme-efficace/labsence-de-controverse-au-sujet-de-l-aide-cibl%C3%A9e-24a31a66f4db\"><u>L\u2019absence de controverse au sujet de l\u2019aide cibl\u00e9e</u></a>, translation by Eve-L\u00e9ana Angot)</li><li><a href=\"https://forum.effectivealtruism.org/posts/9gJAmSx73xYWi9QgS/framing-effective-altruism-as-overcoming-indifference\"><u>Framing Effective Altruism as Overcoming Indifference</u></a> (<a href=\"https://medium.com/altruisme-efficace/surmonter-lindiff%C3%A9rence-ad620aa3647f\"><u>Surmonter l\u2019indiff\u00e9rence</u></a>, translation by Flavien P)</li><li><a href=\"https://www.effectivealtruism.org/articles/efficient-charity-do-unto-others\"><u>Efficient Charity \u2014 Do Unto Others</u></a> (<a href=\"https://medium.com/altruisme-efficace/une-charit%C3%A9-efficace-faire-au-profit-des-autres-45e853c8978e\"><u>Une charit\u00e9 efficace \u2014 Faire au profit des autres</u></a>, translation by Guillaume Thomas)</li></ul><p>&nbsp;</p><h3>How did you choose what to translate?</h3><p>We used the following criteria (content didn\u2019t have to fulfill all criteria to be included):</p><ol><li>It is an article \u2013 the project did not include books (which have more overhead in the form of agreement with publishing houses), video subtitles, podcasts.</li><li>It is an article that we consider to be of high quality.</li><li>It fills a gap in our existing introductory content.<ol><li>We didn\u2019t have good articles on the emotional appeal of EA (such as&nbsp;<a href=\"https://www.lesswrong.com/posts/ur9TCRnHJighHmLCW/on-caring\"><u>On Caring</u></a>), or on certain key EA concepts such as<a href=\"https://www.probablygood.org/post/expected-value\">&nbsp;<u>expected value</u></a> or<a href=\"https://www.probablygood.org/post/counterfactual-impact\">&nbsp;<u>counterfactual impact</u></a>. We also were missing in-depth explanations of certain cause areas from an EA perspective, such as&nbsp;<a href=\"https://80000hours.org/problem-profiles/artificial-intelligence/\"><u>Preventing an AI-related catastrophe</u></a> or&nbsp;<a href=\"https://80000hours.org/problem-profiles/nuclear-security/\"><u>Nuclear security</u></a>).</li><li>On the other hand, we already have a lot of good content on animal welfare, both farmed animal welfare and wild animal welfare, so we didn\u2019t include articles on these topics in our project.</li></ol></li><li>It is used in our current material (our Introductory Fellowship or our Discovery Emails programme).</li></ol><p>&nbsp;</p><h3>Will you translate other articles in the future?</h3><p>We\u2019re considering it. There were lower-priority articles that we didn\u2019t end up translating as part of this project, which would be valuable to have in French.</p><p>&nbsp;</p><h3>Will you translate books?</h3><p>We are strongly considering translating books. The only EA book in French is&nbsp;<i>The Most Good You Can Do</i> by Peter Singer (<a href=\"https://www.fnac.com/a12007832/Peter-Singer-L-Altruisme-efficace\"><i><u>L\u2019altruisme efficace</u></i></a>).</p><p>If you or your organisation own the right to an EA book and would like to get it translated into French, please reach out to us at&nbsp;<a href=\"mailto:contact@altruismeefficacefrance.org\"><u>contact@altruismeefficacefrance.org</u></a>.</p><p>&nbsp;</p><h3>Why pay for professional translators instead of asking volunteers?</h3><p>For core, high-quality EA content that we plan to use in our outreach, guaranteeing a high quality of translation seemed worthwhile. Poorly translated articles could impair our outreach efforts, especially if we move beyond student outreach and try to reach established actors.</p><p>Volunteer work also requires a management overhead that we wanted to avoid.</p><p>We would consider going with volunteers for content that isn\u2019t core to our outreach efforts.</p><p>&nbsp;</p><h3>How did you select the translators?</h3><p>We selected 7 professional translators from the Soci\u00e9t\u00e9 Fran\u00e7aise des Traducteurs based on their specialties and what we could see of their work, plus 2 translation agencies and 1 EA (not in the French community) who had done translation work before. All translators went through a paid translation test where they translated 500 words of<a href=\"https://www.probablygood.org/post/expected-value\">&nbsp;<u>Expected Value</u></a> by Probably Good. Their anonymised work was evaluated by 3 members of the EA France team, and the 2 best translators were selected.</p><p>This approach didn\u2019t yield the results we expected, with one of the translators (from an agency) proving subpar, which led to us spending longer editing their translations. Anecdotally, the agency was the cheapest per word (only 75% as expensive as independent translators).</p><p>What we would do differently:</p><ul><li>We wouldn\u2019t increase the number of translators for the translation test, for financial reasons.</li><li>Instead, we would pick from a pool of candidates that has already been pre-selected. The Soci\u00e9t\u00e9 Fran\u00e7aise des Traducteurs accepts all professional translators, without subjecting them to any tests. There are groups with more stringent acceptance criteria (for instance the&nbsp;<a href=\"https://www.ciol.org.uk/find-a-linguist\"><u>Chartered Institute of Linguists</u></a>).<br>&nbsp;</li></ul><h3>Did you localise content?</h3><p>Yes, we did not hesitate to localise content (<i>i.e.</i> adapt a text to fit the local context). All localisations were indicated in the translation so as to be easily noticeable by the original writer.</p><p>We localised:</p><ul><li>all dollar amounts were converted to euros, except when it didn\u2019t make sense;</li><li>examples of \u201cthe average American\u201d, \u201ca Brit\u201d;</li><li>data when we could find good French equivalents (for instance, instead of mentioning the number of farmed animals in the US, we mentioned the number of farmed animals in France);</li><li>miscellaneous (mentioning French initiatives alongside other initiatives whenever we could, adding definitions for concepts that aren\u2019t well-known in France...)<br>&nbsp;</li></ul><h3>Shoutout to helpful posts</h3><ul><li><a href=\"https://forum.effectivealtruism.org/posts/ohyFLhjStuT4bxhkt/translating-the-precipice-into-czech-my-experience-and-1\"><u>Translating The Precipice into Czech: My experience and recommendations</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/z4aspKHdCLbcxaaik/translations-the-portuguese-experience\"><u>Translations (the Portuguese experience)</u></a></li></ul><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzvrh6egvlxr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzvrh6egvlxr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We\u2019re asking to know where translations are used so that if we make any changes to the translation, we can propagate them through all existing versions. Some articles also have specific sharing conditions.</p></div></li></ol>", "user": {"username": "lb_rv"}}, {"_id": "PGqu4MD3AKHun7kaF", "title": "Predictive Performance on Metaculus vs. Manifold Markets", "postedAt": "2023-03-03T19:39:29.727Z", "htmlBody": "<p><strong>TLDR</strong></p><ul><li>I analysed a set of 64 (non-randomly selected) binary forecasting questions that exist both on Metaculus and on Manifold Markets.&nbsp;</li><li>The mean Brier score was 0.084 for Metaculus and 0.107 for Manifold. This difference was significant using a paired test. Metaculus was ahead of Manifold on 75% of the questions (48 out of 64).&nbsp;</li><li>Metaculus, on average had a much higher number of forecasters</li><li>All code used for this analysis can be found <a href=\"https://github.com/nikosbosse/Metaculus-data-analyses\">here.</a></li></ul><p><strong>Conflict of interest note</strong><br>I am an employee of Metaculus. I think this didn't influence my analysis, but then of course I'd think that and there may be things I haven't thought about.&nbsp;</p><h2>Introduction</h2><p>Everyone likes forecasts, especially if they are accurate (well, there may be <a href=\"https://en.wikipedia.org/wiki/Cassandra\">some exceptions</a>). As a forecast consumer the central question is: where should you go to get your best forecasts? If there are two competing forecasts that slightly disagree, which one should you trust most?&nbsp;</p><p>There are a multitude of websites that collect predictions from users and provide aggregate forecasts to the public. Unfortunately, comparing different platforms is difficult. Usually, questions are not completely identical across sites which makes it difficult and cumbersome to compare them fairly. Luckily, we have at least some data to compare two platforms, <a href=\"https://metaculus.com\">Metaculus</a> and <a href=\"https://manifold.markets\">Manifold Markets</a>. Some time ago, David Glidden created a bot on Manifold Markets, the <a href=\"https://manifold.markets/MetaculusBot\">MetaculusBot</a>, which copied some of the questions on the prediction platform Metaculus to Manifold Markets.&nbsp;</p><h2>Methods</h2><ul><li>Manifold has a few markets that were copied from Metaculus through MetaculusBot. I downloaded these using the Manifold API and filtered for resolved binary questions. There are likely more corresponding questions/markets, but I've skipped these as I didn't find an easy way to match corresponding markets/questions automatically.&nbsp;</li><li>I merged the Manifold markets with forecasts on corresponding Metaculus questions. I restricted the analysis to the same time frame to avoid issues caused by a question opening earlier or remaining open longer on one of the two platforms.&nbsp;</li><li>I compared the Manifold forecasts with the community prediction on Metaculus and calculated a time-averaged <a href=\"https://forecasting.wiki/wiki/Brier_score\">Brier Score</a> to score forecasts over time. That means, forecasts were evaluated using the following score:&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"S(p, t, y) = \\int_{t_0}^T (p_t - y)^2 dt\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.032em;\">S</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">y</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.138em;\"><span class=\"mjx-mo\" style=\"padding-right: 0.138em;\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\">\u222b</span></span></span><span class=\"mjx-stack\" style=\"vertical-align: -0.366em;\"><span class=\"mjx-sup\" style=\"font-size: 70.7%; padding-bottom: 0.63em; padding-left: 0.324em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.267em; padding-right: 0.06em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span></span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">y</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>, with resolution&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"y\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;\">y</span></span></span></span></span></span></span>&nbsp;and forecast&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p_t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span></span></span>&nbsp;at time&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"t\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t</span></span></span></span></span></span></span>. I also did the same for log scores, but will focus on Brier scores for simplicity.&nbsp;</li><li>I tested for a statistically significant tendency towards higher / lower scores on one platform compared to the other using a paired <a href=\"https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test\">Mann-Whitney U test</a>. (A paired t-test and a bootstrap analysis yield the same result.)&nbsp;</li><li>I visualised results using a bootstrap analysis. For that, I iteratively (100k times) drew 64 samples with replacement from the existing questions and calculated a mean score for Manifold and Metaculus based on the bootstrapped questions, as well as a difference for the mean. The precise algorithm is:&nbsp;<ul><li>draw 64 questions with replacement from all questions</li><li>compute an overall Brier score for Metaculus and one for Manifold</li><li>take the difference between the two</li><li>repeat 100k times</li></ul></li></ul><h2>Results</h2><p>The time-averaged Brier score on the questions I analysed was 0.084 for Metaculus and 0.107 for Manifold. The difference in means was significantly different from zero using various tests (paired Mann-Whitney-U-test: p-value &lt; 0.00001, paired t-test: p-value = 0.000132, bootstrap test: all 100k samples showed a mean difference &gt; 0). Results for the log score look basically the same (log scores were 0.274 for Metaculus and 0.343 for Manifold, differences similarly significant).&nbsp;</p><p>Here is a plot with the observed differences in time-averaged Brier scores for every question:&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/sv9pwmpxd1u2y3ibqhoo\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/vadn1jdu4nr6ysyvo77s 230w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/anqvswyhggp7vz406pdd 460w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/hlz3dcuwgjdbd90j3rlu 690w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/qcn0awjes0akvqqpqkay 920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/ro9c73xf6o9hdx4ufv8s 1150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/ouptcwdgoh9ols4et29h 1380w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/nnebswnruwzrzycntlqa 1610w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/n81zexacxpgu4kewyukc 1840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/niwuiuvn7gwjnkrwe4m6 2070w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/qryuxmd1ykuxdahryxyz 2250w\"></figure><p>Usually, it's not possible to make any meaningful statements about which of two forecasters is more accurate based on a single question. What we care about, therefore, is average or expected performance across many questions. To get a clearer picture of the average performance difference, I conducted a bootstrap analysis. This plot shows the bootstrapped distribution of the average difference between Manifold and Metaculus across sets of 64 questions:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/ga5ndjg7cheyfzvizwqd\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/mtjrkkqmfiwiwwwpdffs 230w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/gfqfly8hed8pc710jw3f 460w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/ccz9ecyoamsodfqszxsk 690w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/jjnljedfnvhduar8pqdb 920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/ceotwwvztahquywjxhyl 1150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/vwj2j46hznvgww6hhirc 1380w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/fntb8vtbzxqtnoey4a2m 1610w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/spnohuafpjq0k276gu0y 1840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/iuwxir6eeafztilf5mos 2070w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/jcuchtm86oreqhvrpgty 2250w\"></figure><p>Under lots of of strong assumptions, this plot would give us an answer to the question \"If I look at a set of 64 random questions, available both on Metaculus and Manifold, what should I expect the average difference in Brier score on these 64 questions to be?\" Of course, those assumptions don't hold entirely. The bootstrap analysis kind of assumes that questions are independent, which they are probably not. (Many of the questions are about the Ukraine conflict.) The interpretation I've given also assumes that the 64 questions are representative for all questions on Manifold/Metaculus, which they are also probably not.&nbsp;</p><p>As another interesting observation, Metaculus on average had a much higher number of forecasters on the markets I looked at than Manifold. (For a discussion on how that might affect accuracy see <a href=\"https://forum.effectivealtruism.org/posts/xF8EWBouJRZpRgFgu/how-does-forecast-quantity-impact-forecast-quality-on-1\">here</a> and more recently <a href=\"https://forum.effectivealtruism.org/posts/CQfuNy5sw5niXFF5A/more-is-probably-more-forecasting-accuracy-and-number-of\">here</a>.) Here is a plot of the number of forecasts for each question (y-axis on the log scale, with red marks indicating when that platform has a better Brier Score).&nbsp;</p><figure class=\"image image_resized\" style=\"width:80.53%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/rj9ymlqdtwrl4vsg1fpp\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/aoxtew5akjdpqgqknahs 170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/hgoldwowalxyhjtzz6fr 340w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/npp9rudy8zgermapmldf 510w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/prubrqythiryggflea0c 680w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/izwkpwqcdysara0fns3e 850w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/rfjnvsrzeevdbcblju3g 1020w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/y3re5vohwyo5venw3ihy 1190w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/povb52wmxhzqcxrycxss 1360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/khtayxcuvaiwgacrh0sz 1530w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/btj7vaqqt1axqdhnqnrz 1650w\"></figure><p>I find this interesting, but also somewhat hard to identify any meaningful patterns. For example, one could expect red points to be clustered at the top for Manifold, indicating that more forecasts equal better performance. But we don't see that here. The comparison may be somewhat limited anyway: In the eyes of the Metaculus community prediction, all forecasts are created equal. On Manifold, however, users can invest different amounts of money. A single user can therefore in principle have an outsized influence on the overall market price if they are willing to spend enough. I'd be interested to see more on how accuracy on Manifold changes with the number of traders and overall trading volume. Who knows, maybe Manifold would be ahead if they had a similar number of forecasters to Metaculus?&nbsp;</p><p>Let's have another look at the actual forecasts. Here is a gigantic plot that shows the corresponding Manifold and Metaculus community prediction (as well as time-averaged scores) for all questions that I looked at.&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/r3mmwukgkdczhxeplhrn\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/yqzfa2ryivcalleipivg 480w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/kxelc3sqitmjjmqmeyvm 960w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/q5erv5gpwkisubcruqj5 1440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/cdg0oz256xxxnyoe8zsw 1920w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/rh4srwqchnuhpngskem2 2400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/c3ppzg3j78p69e1uhqzu 2880w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/gychotv286nmab5qbnjo 3360w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/i1vpzl3wtx7mi5gkmygp 3840w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/vxyykt8aiezng0dr3167 4320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/PGqu4MD3AKHun7kaF/tkopu7eapzjr42c6u5ay 4800w\"></figure><p>We can notice a few interesting things. The curves for Metaculus and Manifold usually look roughly similar. That's good. If independent people using different methods arrive at similar conclusions, that should give us more confidence that the overall conclusions are reasonable. Of course, it could just mean that one platform copies the other. But even that would be a good sign, as it means &nbsp;you couldn't trivially do better than just copying the other platform.&nbsp;</p><p>The curve for Manifold looks more spiky and less smooth. I expect this to be largely a function of the number of forecasters and the trading volume. To me, the spikes mostly look like noise. But large movements could also reflect a tendency for Manifold to update more quickly or strongly to new information. Sometimes markets on Manifold have gone stale, which seems to be less of an issue on Metaculus in this small data set.&nbsp;</p><h2>Discussion</h2><p>Statistical significance aside, the 64 forecasts I investigated feel more consistent and therefore slightly more informative on Metaculus from a pure forecast consumer perspective. However, terms and conditions, and of course a million limitations apply.&nbsp;</p><p>Firstly, the set of questions I looked at is very limited. Results might completely change if you look at different markets/questions. For simplicity, I only looked at markets created on Manifold by the <a href=\"https://manifold.markets/MetaculusBot\">MetaculusBot</a>. I'm not entirely sure how the MetaculusBot picked questions to replicate, but to me it doesn't necessarily look like a random sample. Copying questions from Metaculus to Manifold (rather than the other way round) of course means that the questions are skewed towards the kind of questions that would appear on Metaculus and are of interest to the Metaculus community. If you want to (help) rerun the analysis with more questions, feel free to adapt my <a href=\"https://github.com/nikosbosse/Metaculus-data-analyses\">code</a> or get in touch.&nbsp;</p><p>Secondly, this analysis doesn't necessarily provide any guidance for the future. Once you point out a potentially profitable trading strategy, it tends to quickly disappear. If I were an ambitious user on Manifold and had a free weekend to spend, I would sure as hell start coding up a bot that just trades the Metaculus community prediction on Manifold.&nbsp;</p><p>Thirdly, this analysis doesn't directly allow general statements about which platform provides more original value, even though it looks like on the set of questions I analysed Metaculus forecasts tended to update faster. It remains a challenge to disentangle how forecasts on both platforms may be influencing each other and how the existence of one platform affects the quality of forecasts on the other. &nbsp;</p><hr><p><i>Thanks to Lawrence Phillips and Tom Liptay for providing valuable feedback to this post!</i></p>", "user": {"username": "nikos"}}, {"_id": "dHssNoAThoAydXgEt", "title": "Exit Duty Generator by Matti H\u00e4yry", "postedAt": "2023-02-24T20:36:29.641Z", "htmlBody": "<p>Hello! I was hoping to start a discussion about a recent article called Exit Duty Generator by Matti H\u00e4yry, it can be found here:&nbsp;</p><p><a href=\"https://www.cambridge.org/core/journals/cambridge-quarterly-of-healthcare-ethics/article/exit-duty-generator/49ACA1A21FF0A4A3D0DB81230192A042#article\">https://www.cambridge.org/core/journals/cambridge-quarterly-of-healthcare-ethics/article/exit-duty-generator/49ACA1A21FF0A4A3D0DB81230192A042#article</a></p><p>or DOI: <a href=\"https://doi.org/10.1017/S096318012300004X\">https://doi.org/10.1017/S096318012300004X</a></p><h2>Abstract</h2><p>This article presents a revised version of negative utilitarianism. Previous versions have relied on a hedonistic theory of value and stated that suffering should be minimized. The traditional rebuttal is that the doctrine in this form morally requires us to end all sentient life. To avoid this, a need-based theory of value is introduced. The frustration of the needs not to suffer and not to have one\u2019s autonomy dwarfed should, prima facie, be decreased. When decreasing the need frustration of some would increase the need frustration of others, the case is deferred and a fuller ethical analysis is conducted. The author\u2019s perceptions on murder, extinction, the right to die, antinatalism, veganism, and abortion are used to reach a reflective equilibrium. The new theory is then applied to consumerism, material growth, and power relations. The main finding is that the burden of proof should be on those who promote the status quo.</p><p>Any thoughts? Thanks!&nbsp;</p><p>All the best,&nbsp;</p><p>Amanda&nbsp;</p>", "user": {"username": "Oldphan"}}, {"_id": "4bPjDbxkYMCAdqPCv", "title": "Manifund Impact Market / Mini-Grants Round On Forecasting", "postedAt": "2023-02-24T06:14:09.958Z", "htmlBody": "<p>A team associated with Manifold Markets has created <a href=\"https://manifund.org/\">a prototype market for minting &nbsp;and trading impact certificates</a>.&nbsp;</p><p>To help test it out, I'm sponsoring a $20,000 grants round, restricted to forecasting-related projects only (to keep it small - sorry, everyone else). You can read the details at <a href=\"https://astralcodexten.substack.com/p/announcing-forecasting-impact-mini\">the Astral Codex Ten post</a>. If you have a forecasting-related project idea for less than that amount of money, consider reading the post and creating a <a href=\"https://manifund.org/\">Manifund</a> account and minting an impact certificate for it.</p><p>If you're an accredited investor, you can buy and sell impact certificates. Read the post, create a <a href=\"https://manifund.org/\">Manifund </a>account, send them enough financial information to confirm your accreditation, and start buying and selling.</p><p>If you have a non-forecasting related project, you can try using the platform, but you won't be eligible for this grants round and you'll have to find your own oracular funding. We wouldn't recommend this unless you know exactly what you're doing.</p>", "user": {"username": "Scott Alexander"}}, {"_id": "MJ4zPbdBptvhDKHaq", "title": "Posts we recommend from last week (Digest #125)", "postedAt": "2023-02-24T03:49:32.421Z", "htmlBody": "<p>We're sharing some posts from the last week (16-22 February), which I shared in the most recent Digest.&nbsp;</p><p>The <a href=\"https://forum.effectivealtruism.org/posts/bi9WWR58m45GJG7bc/forum-digest-reminder-that-it-exists-and-request-for\">Digest</a> is a weekly email I send to around 8,000 subscribers. You can <a href=\"https://us8.campaign-archive.com/home/?u=52b028e7f799cca137ef74763&amp;id=7457c7ff3e&amp;utm_source=EA+Forum+Digest&amp;utm_campaign=538104a4a5-EMAIL_CAMPAIGN_2022_04_06_03_12&amp;utm_medium=email&amp;utm_term=0_7457c7ff3e-538104a4a5-318967845\">look at some recent editions</a> or <a href=\"https://effectivealtruism.us8.list-manage.com/subscribe?u=52b028e7f799cca137ef74763&amp;id=7457c7ff3e\">subscribe here</a>.&nbsp;</p><p><i>(This post is an experiment. Let us know what you think!)</i></p><p><strong>We recommend:</strong></p><ol><li><a href=\"https://forum.effectivealtruism.org/posts/K9GdCuiz5tanoiDKN/why-should-ethical-anti-realists-do-ethics?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Why should ethical anti-realists do ethics?</u></a> and<a href=\"https://forum.effectivealtruism.org/posts/djByAbm6ptkkmS9RS/seeing-more-whole?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u> Seeing more whole</u></a> (Joe Carlsmith, 33 min, 31 min) (see also: \"<a href=\"https://forum.effectivealtruism.org/posts/tqQKkRqx4zxBPR6ci/a-stranger-priority-topics-at-the-outer-reaches-of-effective?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>my dissertation</u></a>\")</li><li><a href=\"https://forum.effectivealtruism.org/posts/6pc8iuDxz8LArWng8/eu-food-agency-recommends-banning-cages?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>EU Food Agency Recommends Banning Cages</u></a> (Ben West, 1 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/P4ut25NhfsFEMEeLJ/what-to-think-when-a-language-model-tells-you-it-s-sentient?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>What to think when a language model tells you it's sentient</u></a> (rgb, 7 min)&nbsp;</li><li><a href=\"https://forum.effectivealtruism.org/posts/i6btyefRRX23yCpnP/what-ai-companies-can-do-today-to-help-with-the-most?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>What AI companies can do today to help with the most important century</u></a> (Holden Karnofksy, 13 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/S2HvxiBHhaGYs2BYs/deontic-fictionalism?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Deontic Fictionalism</u></a> (Richard Y Chappell, 4 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/yiTcjSWuy7ptTb5XS/what-is-it-like-doing-ai-safety-work?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>What is it like doing AI safety work?</u></a> (Kat Woods, peterbarnett, 11 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/z5sGE5cALEuENBrav/ai-alignment-researchers-don-t-seem-to-stack?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>AI alignment researchers don't (seem to) stack</u></a> (So8res, 3 min)</li><li>Research writeups<ol><li><a href=\"https://forum.effectivealtruism.org/posts/7f9eMGRhfEgjbMxsa/immigration-reform-a-shallow-cause-exploration?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Immigration reform: a shallow cause exploration</u></a> (Joel McGuire, Samuel Dupret, 43 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/seFH9jcH3saXHJqin/data-on-how-much-solutions-differ-in-effectiveness?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Data on how much solutions differ in effectiveness</u></a> (Benjamin Todd, 4 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/FoRyordtA7LDoEhd7/there-are-no-coherence-theorems?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>There are no coherence theorems</u></a> (EJT, 23 min)&nbsp;</li><li><a href=\"https://forum.effectivealtruism.org/posts/2yrprQuNJpFJKMGWh/should-we-tell-people-they-are-morally-obligated-to-give-to?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Tell people why they should donate, not that they are morally obligated to</u></a> (benleo, PhilippSchoenegger, 5 min)</li></ol></li></ol><p><strong>Community &amp; practical:</strong></p><ol><li><a href=\"https://forum.effectivealtruism.org/posts/XFBGu9sGfbYAsb8Gb/bad-actors-are-not-the-main-issue-in-ea-governance?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Bad Actors Are Not the Main Issue in EA Governance</u></a> (Grayden, 4 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/9wJ5Mtba9Fc2yCvpN/getting-organizational-value-from-ea-conferences-featuring?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Getting organizational value from EA conferences, featuring Charity Entrepreneurship\u2019s experience</u></a> (Amy Labenz, CE, 5 min)&nbsp;</li><li><a href=\"https://forum.effectivealtruism.org/posts/RRT5ApXHnvvzgnYy8/ea-london-hackathon-retrospective?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>EA London Hackathon Retrospective</u></a> (Jonny Spicer, Sam Watts, 4 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/2eotFCxvFjXH7zNNw/people-will-sometimes-just-lie-about-you?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>People Will Sometimes Just Lie About You</u></a> (Aella, 21 min)</li><li><a href=\"https://forum.effectivealtruism.org/posts/46Wi9cnTKP2gTwNd3/on-loyalty?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>On Loyalty</u></a> (Nathan Young, 18 min)</li></ol><p><strong>Announcements:</strong></p><ol><li><a href=\"https://forum.effectivealtruism.org/posts/Bsdq5wK63vLEB3Gqg/announcing-the-launch-of-the-insect-institute?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Announcing the Launch of the Insect Institute</u></a> (Dustin Crummett)&nbsp;</li><li>Opportunities &amp; applications<ol><li><a href=\"https://forum.effectivealtruism.org/posts/4cCRCoYvcLEr7prC2/ai-safety-info-distillation-fellowship?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>AI Safety Info Distillation Fellowship</u></a> (robertskmiles)</li><li><a href=\"https://forum.effectivealtruism.org/posts/8XDcMhJ65mwWrouro/join-a-new-slack-for-animal-advocacy?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Join a new slack for animal advocacy</u></a> (SofiaBalderson, Cameron.K)</li><li><a href=\"https://forum.effectivealtruism.org/posts/XcBE5Csza8tSA9HbB/effective-thesis-is-looking-for-a-new-executive-director?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Effective Thesis is looking for a new Executive Director (Apply by 22 March)</u></a> (Effective Thesis)</li></ol></li><li>News related to Effective Ventures Foundation<ol><li><a href=\"https://forum.effectivealtruism.org/posts/99tnp7Jpts7Gssq7J/transitioning-to-an-advisory-role?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Transitioning to an advisory role</u></a> (Max Dalton)</li><li><a href=\"https://forum.effectivealtruism.org/posts/QMee23Evryqzthcvn/a-statement-and-an-apology?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>A statement and an apology</u></a> (Owen Cotton-Barratt)</li><li><a href=\"https://forum.effectivealtruism.org/posts/9JCkkjKMNL4Hmg4qP/ev-uk-board-statement-on-owen-s-resignation?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>EV UK board statement on Owen's resignation</u></a> (EV UK Board)</li></ol></li><li>Forecasting and epistemics<ol><li><a href=\"https://forum.effectivealtruism.org/posts/ioHakR62Jbdgy4ig4/manifold-markets-charity-program-ending-march-1st?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Manifold Markets Charity program ending March 1st</u></a> (Pat Myron) [UPDATE: <a href=\"https://forum.effectivealtruism.org/posts/ioHakR62Jbdgy4ig4/manifold-markets-charity-program-ending-march-1st?commentId=iec7mv3GM5E6vWTYy\">it seems that this is no longer true</a>]</li><li><a href=\"https://forum.effectivealtruism.org/posts/XDwnGK7x4EjkaHbje/the-estimation-game-a-monthly-fermi-estimation-web-app?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>The Estimation Game: a monthly Fermi estimation web app</u></a> (Sage, Adam Binks)&nbsp;</li><li><a href=\"https://forum.effectivealtruism.org/posts/qELZknyx8eBg7HskH/metaculus-introduces-new-conditional-pair-forecast-questions?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Metaculus Introduces 'Conditional Pair' Forecasts for Making Conditional Predictions</u></a> (christian)</li></ol></li></ol><p><strong>Classic Forum post:</strong></p><ul><li><a href=\"https://forum.effectivealtruism.org/s/dg852CXinRkieekxZ/p/jSPGFxLmzJTYSZTK3?utm_source=EA+Forum+Digest&amp;utm_campaign=110a9041df-EMAIL_CAMPAIGN_2023_02_23_08_02&amp;utm_medium=email&amp;utm_term=0_-110a9041df-%5BLIST_EMAIL_ID%5D\"><u>Reality is often underpowered</u></a> (Gregory Lewis)</li></ul>", "user": {"username": "Lizka"}}, {"_id": "mb4kzhfRnpQNtF6ut", "title": "Introducing EASE, a managed directory of EA Organization Service Providers", "postedAt": "2023-02-23T22:43:16.202Z", "htmlBody": "<h2>What is EASE?</h2><p>EASE (EA Services) is a directory of independent agencies and freelancers offering expertise to EA-aligned organizations. Please visit our website at&nbsp;<a href=\"https://ea-services.org/\"><u>https://ea-services.org</u></a> to view our members.</p><h2>Who are we?</h2><p>We are a team of service providers. The authors of this post are the core coordinators. We all have our own organizations providing services to EA-aligned organizations. We see the problems most organizations encounter, and we developed a solution to help address that need.</p><h2>Why did we start EASE?</h2><p>Many organizations in the EA world have similar needs but lack the bandwidth or expertise to realize them. By providing a directory of experts covering many common challenges, we aim to save the community time whilst addressing key skill shortages. We believe that most organizations need external expertise in order to maximize their organization\u2019s potential. We are all focused on being effective \u2013 and we believe that forming this centralized directory is the most effective way of making a large resource group more available to EA-aligned organizations.</p><h2>Why should EA organizations consider working with these agencies?</h2><p>By working with multiple EA organizations, these agencies have gathered plenty of expertise to provide relevant advice, save time and money, and most importantly, increase your impact. Our screening process ensures that the vendors listed are pre-qualified* as experts in their represented fields. This minimizes the risk of engaging with a new \u201cunknown\u201d entity, as they\u2019re already proven to be valuable team players.&nbsp;</p><p>Additionally, we have programming in place to consolidate the interagency interactions and strengthen relationships, so that when you work with one member of our group, you\u2019re accessing a part of a larger network.</p><p><i>*Our members are vetted to determine capabilities, accuracy, and work history, but we do not give out any endorsement for specific providers.</i></p><h2>What are the criteria for being added to the directory?</h2><p>Our aim is to build a comprehensive list of service providers who work with EA organizations. We screen members to ensure that the providers are experienced and are truly experts in their field, as well as being active participants in EA or having experience working with EA-aligned organizations.</p><h2>Are you an individual or team providing services to EA-aligned organizations and would like to be added?&nbsp;</h2><p>We love growing our network! Fill out&nbsp;<a href=\"https://forms.gle/oV23T92Qu9uDwK1c7\"><u>this form</u></a> and someone will contact you to begin the screening process.</p><h2>Are you ready to get the help you need?</h2><p>Feel free to contact the service providers directly.</p><h2>Are you an EA organization in need of help but aren\u2019t sure what you need or if you have the budget?</h2><p>We can help you figure out what kind of services and budget you need so you can try to get the funds necessary to pay for these critical services. Please send us an email to&nbsp;<a href=\"mailto:info@ea-services.org\"><u>info@ea-services.org</u></a>, and we will do our best to help you.</p><h2>Is the directory up to date?</h2><p>We regularly review the listings to make sure they remain relevant. If you have any comments or suggestions, please send an email to&nbsp;<a href=\"mailto:info@ea-services.org\"><u>info@ea-services.org</u></a>.</p>", "user": {"username": "Deena Englander"}}, {"_id": "fBsChHtfWZsLe5JnM", "title": "Cholesterol and Blood Pressure as Neglected Dietary Interventions?", "postedAt": "2023-02-26T18:06:00.077Z", "htmlBody": "<p>Summary notes from a surprising conversation with Brian Toomey who has done some investigation on these topics for his own and friends' health.</p><ul><li>LDL and blood pressure are both independent risk factors for CVD and mortality</li><li>High readings of one or both are incredibly common (~25% of adults for LDL, ~40% of adults for BP in the United States)</li><li>Standard treatment for these involve statins and ace inhibitors respectively, which have serious side effects associated with them including problems when people's adherence to them is inconsistent</li><li>Some forms of these medicines were derived from natural sources, and ingestion of said natural sources does not seem to include the side effects from their synthesized forms. Here several mushroom species contain high levels of lovastatin and several fruits and seeds contain natural ace inhibitors</li><li>The expectation is that the synthesized versions have larger effect size, but the opposite appears to be true when dosing correctly</li><li>This knowledge is not widespread and deserves further evaluation of potential QALY's on the line</li></ul>", "user": {"username": "RomeoStevens"}}, {"_id": "R3xwo3nAoyzyjizGs", "title": "Retrospective: CEA\u2019s Fall \u201822 University Group Accelerator Program (UGAP)", "postedAt": "2023-02-24T18:38:35.714Z", "htmlBody": "<h1>Summary</h1><ul><li>From August - December 2022, CEA\u2019s University Groups Team ran the fourth round of&nbsp;<a href=\"https://www.notion.so/centreforeffectivealtruism/University-Group-Accelerator-Program-6df8c8fccf8b4ffbb6488d9dfa275282\"><u>UGAP</u></a>, the University Group Accelerator Program.</li><li>63 ~new university groups completed the Fall \u201822 (Northern Hemisphere) round of UGAP. Through the program, 112 organizers received mentorship and got access to curated resources. 104 of these organizers also received a stipend.</li><li>UGAP\u2019s Likelihood to Recommend was 9.04 (n=58 organizers), the average rating of mentors was 8.7 (n=56).</li><li>Participants rated mentorship, the UGAP resource guide, and the stipends as the most valuable aspects of UGAP.</li><li>While we are exploring other metrics, we\u2019re quite happy with the number of ~counterfactual HEAs these organizers helped \u2018generate\u2019 with their groups, compared to how much time it cost us to run this program. We\u2019re also excited about the quality of a lot of the participating organizers.&nbsp;</li><li>In the past, UGAP was the main program our team ran. We are likely to continue running it, but as a significantly smaller percentage of our team\u2019s portfolio.<ul><li>Sign up&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSf46WjmJZPl9rTTTsXaXxUy6eINyiqR3Y9FAEKvUbxsiAcLIA/viewform\"><u>here</u></a> to be informed when applications open for a next round of UGAP!</li></ul></li></ul><h1>About this UGAP cohort</h1><p><strong>Number of groups in the Fall \u201822 (Northern Hemisphere) UGAP cohort: 63</strong>, spread over 21 countries. We had about 112 organizers participate, of which 104 received a stipend.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6k46qx7mm2a\"><sup><a href=\"#fn6k46qx7mm2a\">[1]</a></sup></span>&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref20hw3ec11o\"><sup><a href=\"#fn20hw3ec11o\">[2]</a></sup></span></p><p>Running this cohort (including the retreat) cost CEA\u2019s Uni Groups team about 0.9FTE.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqh6a3itp6w\"><sup><a href=\"#fnqh6a3itp6w\">[3]</a></sup></span></p><p>This round of UGAP was preceded by the UGAP Starter Program, a 2-week program providing organizers with resources and a mentorship call. It had a lower barrier to entry than UGAP. We are not likely to run the starter program again - see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/d83HJFMnEvP6x6LaD/ugap-starter-program-retrospective\"><u>here</u></a> for a full retrospective on the Starter Program.</p><h1>Feedback from UGAP participants</h1><p><strong>\u201cHow likely would you be to recommend that a new uni group apply for UGAP?\u201d: 9.04</strong> (n=58 organizers, down from a 9.2 rating from the previous cohort (with n=38))<img src=\"https://res.cloudinary.com/cea/image/upload/v1677183085/mirroredImages/R3xwo3nAoyzyjizGs/rpxdxhvnig3ltzgbat27.png\" alt=\"Forms response chart. Question title: How valuable have you found these aspects of UGAP?. Number of responses: .\"></p><h2>Mentorship</h2><p>UGAP participants received mentorship on a weekly basis for about 1-3 months, and on a biweekly basis for the remainder of the semester.</p><ul><li>UGAP mentors are experienced university group organizers. Matches were made based on level of experience, areas of strength and our best guess at whether people would get along.&nbsp;</li><li>Participants rated mentor meetings as the most valuable thing UGAP offers. These are the things that participants highlighted as most valuable about mentorship:<ul><li>Provided feedback on their group strategy</li><li>Being a sounding board &amp; giving advice on practical problems</li><li>Providing accountability and emotional support</li></ul></li><li><strong>Average rating of mentor: 8.7 (n=56)</strong><img src=\"https://res.cloudinary.com/cea/image/upload/v1677183086/mirroredImages/R3xwo3nAoyzyjizGs/vk3elqbmmxw28vqzbtqf.png\" alt=\"Forms response chart. Question title: How likely are you to recommend your mentor to a participant of next semester's round of UGAP?. Number of responses: 56 responses.\"></li></ul><h2>Other aspects of UGAP</h2><p>Some things to highlight:</p><ul><li>We are trying to figure out how important stipends&nbsp;<i>actually</i> were. For example: what kinds of organizers reported that stipends were valuable to them? Are these the people we are excited about?&nbsp;<ul><li>There are a few organizers we are excited about who did explicitly mention stipends but we would like to do more user interviews around this. It seems plausible that stipends should be more opt-in in the future or based on need.</li></ul></li><li>Some of the templates and tools we had available weren\u2019t used as much as we expected. We deprioritized promoting the ones that people found least useful when launching the current UGAP cohort.</li><li>UGAP provides organizers with a handbook that helps them do outreach on their campus, which a number of organizers highlighted as useful to them.</li></ul><h2>HEAs</h2><p>We asked organizers how many of their group members they thought met the&nbsp;<a href=\"https://www.centreforeffectivealtruism.org/blog/cea-grew-a-lot-in-the-past-year#:~:text=By%20this%2C%20we%20mean%20people%20who%20are%20motivated%20in%20part%20by%20an%20impartial%20care%20for%20others2%2C%20who%20are%20thinking%20very%20carefully%20about%20how%20they%20can%20best%20help%20others%2C%20and%20who%20are%20taking%20some%20significant%20actions%20to%20help%20(most%20likely%20through%20their%20careers).3\"><u>definition of HEA</u></a>. We are quite skeptical of HEA as a good metric.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2dw5mhggzxs\"><sup><a href=\"#fn2dw5mhggzxs\">[4]</a></sup></span>&nbsp;We also think group organizers are likely to overestimate the number of HEAs in their group, and maybe also whether these people got engaged with EA counterfactually. Yet, we think it\u2019s good to share some results!</p><ul><li>27 groups of the past UGAP cohort answered the question above. Their organizers self-reported a total of 104 - 119 HEAs in all their groups combined (so an average of 3.9 - 4.4 HEAs per group).&nbsp;<ul><li>Of those HEAs, group organizers said a total of 55 - 66 became highly engaged EAs this semester (so an average of 2.0 - 2.4 new HEAs per group).</li></ul></li><li>Since we think group organizers often overestimate the number of HEAs, our very, very rough guess on the number of counterfactual HEAs<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftwd93nqivel\"><sup><a href=\"#fntwd93nqivel\">[5]</a></sup></span>&nbsp;is 15 - 25.</li></ul><p>It\u2019s unclear how many of these people are counterfactual (see below), but we\u2019re overall quite excited about these numbers!</p><h2>Fellowships</h2><p>We asked group organizers to include a quiz in their post-fellowship survey, to check the EA understanding of their fellows. The results were better than baselines, but we still think these numbers could be higher, as the questions asked are fairly easy.</p><p>We asked organizers what their semester would\u2019ve looked like if they hadn\u2019t participated in UGAP. Summarizing their answers is hard, as it was an open-ended question. But these are some answers that were given often (20 organizers answered this question):</p><ul><li>Semester would look the same / very similar: 10</li><li>Would still run a fellowship: 11</li><li>Would not have run a fellowship: 6</li><li>Would not be an organizer: 3</li><li>Would have lacked a sense of support / would have felt less confident: almost all respondents</li></ul><p><strong>94.4% of the organizers said they\u2019ll host another fellowship at their university.</strong> The remaining organizers answered \u201cmaybe\u201d; none answered \u201cno\u201d (n=54).</p><h2>Impact stories</h2><p>Some impact stories we\u2019re excited about:</p><ul><li>\u201cAt least 3 seniors in my group have shared that the fellowship and EA has had a major influence on their career choices.\u201d</li><li>\u201cTwo of our fellows and my co-organiser are starting an AI safety hub in [university city]\u201d</li><li>\u201cOne of my fellows applied to Charity Entrepreneurship's Incubation Program\u201d</li><li>\u201cWe had a group member who went on an AI bootcamp as a result of hearing about it from EA [university].\u201d</li><li>\u201cAt least one member is interning with an EA organization in Berkeley, which they only found because their university group mentioned it to them\u201d</li></ul><p>Additionally, across all of the UGAP groups of this cohort:<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9eo0y6prhkn\"><sup><a href=\"#fn9eo0y6prhkn\">[6]</a></sup></span></p><ul><li>Over 800 events were organized in the last 6 months</li><li>Almost 4,000 people attended events in the last year</li><li>Almost 700 people completed the intro fellowship in 2022</li><li>250 people attended EAG(x)s in 2022</li></ul><h1>UGAP Retreat</h1><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677183085/mirroredImages/R3xwo3nAoyzyjizGs/tdlpsnepzm38fnc8k3fp.png\"></p><p>We ran a retreat for 38 of the UGAP participants who we thought could benefit most from attending it. We think the retreat was quite successful. You can find a review <a href=\"https://docs.google.com/document/u/0/d/1jgjELokqcHwfS3uCMgwrfcC_V8VTWsbB3FgmCaAkP9g/edit\"><u>here</u></a>.</p><h1>Continuing UGAP</h1><h2>Mistakes we made &amp; things to improve</h2><p>The UGAP Starter Program had a number of problems that we\u2019re addressing in various ways (including not running the Starter Program anymore). See&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/d83HJFMnEvP6x6LaD/ugap-starter-program-retrospective\"><u>the Starter Program Retrospective</u></a>.</p><p>Other feedback we received, and improvements we\u2019re working on:</p><ul><li>Various more experienced organizers flagged that not all parts of UGAP were helpful for them.&nbsp;<ul><li>We are piloting&nbsp;<a href=\"https://www.notion.so/Being-a-Mentor-for-CEA-s-Organizer-Support-Program-OSP-15bbe909486e41978cf112f5a71444e0\"><u>OSP</u></a>, which provides mentorship for more experienced university group organizers.</li><li>Going forward, we don\u2019t expect to accept more experienced organizers in UGAP.</li></ul></li><li>Various organizers flagged they want to be in touch with other organizers more, and are looking at what might address this.</li><li>We are continuing to better calibrate our application process.</li><li>We have implemented changes to help preserve valuable mentor time.</li></ul><h2>Why we want to keep running UGAP</h2><p>The data collected from this round of UGAP makes us think that we\u2019re providing a valuable service to new group organizers. The main costs of UGAP are a portion of our team\u2019s time (0.9 for this past cohort, 0.6 FTE expected in the future) and mentor time (and the opportunity costs of those), but we think those costs are outweighed by the main benefits of UGAP: we think we found a repeatable program with product-market fit that supports new group organizers, helps identify talent, and contributes to building a global network of university group organizers.</p><p>Sign up&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSf46WjmJZPl9rTTTsXaXxUy6eINyiqR3Y9FAEKvUbxsiAcLIA/viewform\"><u>here</u></a> to be informed when applications open for a next round of UGAP!</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6k46qx7mm2a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6k46qx7mm2a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>A significant number of participants in this cohort (maybe 20%) were more experienced organizers than the level we normally expect UGAP participants to be at (namely: never organized a group before). Our program was less tailored to these already-existing groups, but we are still happy we accepted them in our program. We are now piloting an&nbsp;<a href=\"https://www.notion.so/centreforeffectivealtruism/Being-a-Mentor-for-CEA-s-Organizer-Support-Program-OSP-15bbe909486e41978cf112f5a71444e0\"><u>Organizer Support Program</u></a> (OSP), which supports existing groups and their more experienced university group organizers.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn20hw3ec11o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref20hw3ec11o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The Spring \u201823 cohort of UGAP has significantly fewer groups (27) and organizers (42, 33 with stipend). We expect more people in the Fall \u201823 cohort, but not as many as during the Fall \u201822 semester.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqh6a3itp6w\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqh6a3itp6w\">^</a></strong></sup></span><div class=\"footnote-content\"><p>~2 months of 3 people working on this 0.8 of their time during the admissions &amp; kickoff period + ~4 months of the equivalent of one team member doing mentor calls full time + ~2 months of full-time work of one team member on the UGAP retreat.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2dw5mhggzxs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2dw5mhggzxs\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We don\u2019t think the HEA definition properly measures what we care about - it doesn\u2019t properly define what significant actions we care about, doesn\u2019t tell us anything about the \u2018vibe\u2019 of the group, and different organizers interpret the definition very differently. However, it was the best metric we had at the time (we are looking into alternatives) and it allows us to do some comparisons.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntwd93nqivel\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftwd93nqivel\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Counterfactual on the group existing, not necessarily of them participating in UGAP.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9eo0y6prhkn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9eo0y6prhkn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>These numbers are not the main things that we evaluate UGAP or individual groups on, but they are interesting data points. In general, we are wary of (over)optimizing for quantity.</p></div></li></ol>", "user": {"username": "Joris P"}}, {"_id": "oa3MdDRJaY3XfRsrF", "title": "EA Global in 2022 and plans for 2023", "postedAt": "2023-02-23T20:02:25.043Z", "htmlBody": "<h2>Summary</h2><p>We ran three EA Global events in 2022, in London, San Francisco, and Washington, D.C. These conferences all had ~1300\u20131500 people each and were some of our biggest yet:</p><ul><li>These events had an average score of 9.02 to the question \u201cHow likely is it that you would recommend EA Global to a friend or colleague with similar interests to your own?\u201d, on a scale of 0\u201310.</li><li>Those who filled out our feedback survey (which was a minority of attendees, around 1200 individuals in total across all three events) reported over 36,000 new connections made.</li><li>This was the first time we ran three EA Globals in one year since 2017, and we only had ~1200 attendees total across all three of those events.</li><li>We hosted and recorded lots of new content, a substantial amount of which is located on&nbsp;<a href=\"https://www.youtube.com/@EffectiveAltruismVideos\"><u>our YouTube channel</u></a>.</li><li>This was the first time trialing out a EA conference in D.C. of any kind. We generally received positive feedback about this event from attendees and stakeholders.</li></ul><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677182545/mirroredImages/oa3MdDRJaY3XfRsrF/wdfexhjjxyxlzzlssipo.png\"></p><h2>Plans for 2023</h2><ul><li>We\u2019re&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/4JF39v548SETuMewp/update-on-spending-for-cea-run-events\"><u>reducing our spending</u></a> in a lot of ways, most significantly by cutting some meals and the majority of travel grants, which we expect may somewhat reduce the overall ratings of our events. Please note that this is a fairly dynamic situation and we may update our spending plans as our financial situation changes.&nbsp;</li><li>We\u2019re doing three EA Globals in 2023, in the Bay Area and London again, and with our US east coast event in Boston rather than D.C.&nbsp; As well as EA Globals, there are also several upcoming EAGx events, check out the full list of confirmed and provisional events below.<ul><li>EA Global: Bay Area | 24\u201326 February</li><li>EAGxCambridge | 17\u201319 March&nbsp;</li><li>EAGxNordics | 21\u201323 April&nbsp;</li><li>EA Global: London | 19\u201321 May</li><li>EAGxWarsaw | 9\u201311 June [provisional]&nbsp;</li><li>EAGxNYC | July / August [provisional]</li><li>EAGxBerlin | 8\u201310 September</li><li>EAGxAustralia | Late September [provisional]</li><li>EA Global: Boston | Oct 27\u2013Oct 29</li><li>EAGxVirtual | November [provisional]</li></ul></li><li>We\u2019re aiming to have similar-sized conferences, though with the reduction in travel grants we expect the events to perhaps be a little smaller, maybe around 1000 people per EA Global.</li><li>We recently completed a hiring round and now have ~4 FTEs working on the EA Global team.</li><li>We\u2019ve recently revamped our website and incorporated it into effectivealtruism.org \u2014 see&nbsp;<a href=\"https://www.effectivealtruism.org/ea-global\"><u>here</u></a>.</li><li>We\u2019ve switched over our backend systems from Zoho to Salesforce. This will help us integrate better with the rest of CEA\u2019s products, and will hopefully create a smoother front and backend that\u2019s better suited to our users. (Note that the switchover itself has been somewhat buggy, but we are clearing these up and hope to have minimal issues moving forwards.)<ul><li>We\u2019re also trialing a referral system for applications, where we\u2019ve given a select number of advisors working in EA community building the ability to admit people to the conference. If this goes well we may expand this program next year.</li></ul></li></ul><h2>Growth areas</h2><ul><li>Food got generally negative reviews in 2022:<ul><li>Food is a notoriously hard area to get right and quality can vary a lot between venues, and we often have little or no choice between catering options.</li><li>We\u2019ve explored ways to improve the food quality, including hiring a catering consultant, but a lot of these options are cost prohibitive, and realistically we expect food quality to continue to be an issue moving forwards.</li></ul></li><li>Swapcard (our event application app) also got generally negative reviews in 2022:<ul><li>We explored and tested several competitor apps, though none of them seem better than Swapcard.</li><li>We explored working with external developers to build our own event networking app,&nbsp;<strong>but eventually concluded that this would be too costly in terms of both time and money.</strong></li><li>We\u2019ve been working with Swapcard to roll out new features and fix bugs (this will also make the app better for other events, including EAGx conferences).</li></ul></li><li>Some parts of our processes were slower and less professional than we\u2019d like, though we\u2019re working to improve this:<ul><li>We launched applications for 2023 later than we would have liked, partially due to delays in us building out a new backend application system.</li><li>We were slower in the past to approve applications and respond to emails than we would have liked, though we\u2019ve gotten better at this and expect to get better still as we bring on new staff.</li><li>We could have been better about communicating in general. Aspects of our events change each year and it often takes a while for people to internalize these changes if we don\u2019t communicate them well. For example, we introduced travel grant funding for attendees a while back, but it took a while for people to really realize it was there and start using it (though we\u2019ve now cut this funding down).</li></ul></li></ul><p>Other things we\u2019d like to do if we had capacity, but expect we won\u2019t focus on in 2023:</p><ul><li>Active outreach and stewardship \u2014 working to get promising people who might not have EA Global on their radar to come, and actively pairing them or other attendees up with potentially valuable meetings.</li><li>Organizing satellite events \u2014 we do this a bit, and many community members do this too, but we expect there\u2019d be more value to capture here if we had time.</li></ul>", "user": {"username": "Eli_Nathan"}}, {"_id": "7LqFyJWxGCZZXte3N", "title": "Summary of \u201cAnimal Rights Activism Trends to Look Out for in 2023\u201d by Animal Agriculture Alliance ", "postedAt": "2023-02-23T19:43:27.492Z", "htmlBody": "<p>A blog-post by a member of the Animal Agriculture Alliance (AAA) has identified several<a href=\"https://animalagalliance.org/animal-rights-activism-trends-to-look-out-for-in-2023-part-1/\">&nbsp;<u>trends in animal rights activism that they project for 2023</u></a>. These trends are likely to be causes for concern for the animal agriculture industry, and the piece was written to make AAA supporters aware of them. Recognising these trends and identifying the views held on these animal advocacy tactics by proponents of animal agriculture may provide advocates with valuable insights.&nbsp;</p><p>In this post, I list the key trends identified by the article and bullet point tactics highlighted by the article which are of particular interest.</p><p>I\u2019m thankful to&nbsp;<a href=\"https://www.youtube.com/watch?v=qGHdTpsLGEE\"><u>\u201cThe Cranky Vegan\u201d</u></a> for bringing this article to my attention through their linked video.</p><p>&nbsp;</p><p><strong>Linking CAFOs to negative human and environmental health</strong></p><ul><li>Drawing attention to the detrimental effects of CAFOs (concentrated animal feeding operations) to human and environmental health&nbsp;</li><li>Using historical precedents of CAFOs being charged in court such as in<a href=\"https://www.nytimes.com/2018/05/26/business/hog-farm-lawsuit-north-carolina.html\">&nbsp;<u>North Carolina</u></a> and<a href=\"https://www.seattletimes.com/seattle-news/yakima-valley-dairy-fined-15m-for-polluting-river/\">&nbsp;<u>Seattle</u></a> in messaging</li><li>Exploring cases where ethnic minorities have experienced disproportionate negative health impacts of CAFOs&nbsp;</li></ul><p>This strategy may create opposition to CAFOs from individuals and organisations that may not be compelled by animal-focused driven arguments, and could be further integrated into outreach and media messaging. Referring to historical precedents of CAFOs being charged with breaching environmental regulations may help to legitimise messaging against them.</p><p>&nbsp;</p><p><strong>The use of undercover footage in court and media&nbsp;</strong></p><ul><li>Using undercover footage from factory farms to motivate arguments in court that such operations engage in unfair competition, false advertising, market distortion and fraud</li><li>Using undercover footage from factory farms pressure retailers to cut ties with such farms</li><li>Using undercover footage from animal rescue missions from factory farms as evidence against charges of trespassing and theft</li></ul><p>The continued and increased use of undercover footage from factory farms is clearly concerning for animal agriculture, given the extensive efforts to block this such as through so called&nbsp;<a href=\"https://aldf.org/issue/ag-gag/#:~:text=As%20the%20name%20suggests%2C%20Ag,from%20learning%20about%20animal%20cruelty.\"><u>Ag-gag laws</u></a>. However, the suppression of undercover footage from factory farms may lead to increased media attention on these items and public scrutiny on the conditions of factory farms. Indeed,<a href=\"https://www.seattletimes.com/nation-world/animal-rights-activists-await-verdict-in-smithfield-piglet-case/\"> in a recent case</a>, Direct Action Everywhere activists who were being prosecuted after liberating piglets from a Smithfield Foods farm and releasing footage from their mission, were acquitted by the jury, despite the judge blocking the jury from viewing the footage taken. The aforementioned ways in which undercover footage may be used to aid the acquittal of activists, challenge farms in court and pressure retailers to cut ties with farms highlight the potency of combining undercover footage with legal action.</p><p>&nbsp;</p><p><strong>Prioritising Youth Engagement</strong></p><ul><li>Engaging young people in programmes that rival agricultural programmes like<a href=\"https://www.peta.org/teachkind/humane-classroom/ffa-4h-school-agriculture-programs/\">&nbsp;<strong><u>FFA and 4-H</u></strong></a><strong>&nbsp;</strong></li><li>Fostering social disapproval of animal product consumption and normalising plant-based foods in classrooms, presenting the suffering caused by factory farming in an emotive way</li></ul><p>Educating young people and creating a shift in culture towards empathy, through recognising the suffering caused by animal agriculture and normalising plant-based foods, may challenge the image that animal agriculture is trying to maintain. This may be an important factor in changing consumption habits of future generations.</p><p>&nbsp;</p><p><strong>Deconstructing legal personhood</strong></p><ul><li>The use of the writ of habeas corpus, a right that protects against unlawful and indefinite imprisonment, as a way to challenge the legal personhood of animals by the <a href=\"https://www.nonhumanrights.org/\">Nonhuman Rights Project</a>.</li></ul><p>Although the <a href=\"https://www.nonhumanrights.org/client-happy/\">case of Happy the Elephant</a> was not successful, the amicus briefs (supporting documents) and dissenting judgements (judges disagreeing with the outcome) showed significant support for the rights of non-human animals. Further, litigation modelled on this habeas writ petition was successful in<a href=\"https://www.nonhumanrights.org/blog/chimpanzee-cecilia/\">&nbsp;<u>freeing a chimpanzee</u></a> from an Argentine zoo,&nbsp;<a href=\"https://www.nonhumanrights.org/blog/the-legal-fight-for-kaavans-freedom/\"><u>freeing of an elephant</u></a> by the Islamabad High Court, with both animals now legal persons with rights. This demonstrates the potential of deconstructing legal personhood for advancing the legal rights of non-human animals.</p><p>&nbsp;</p><p><strong>Legal Reform and Increasing political pressure</strong></p><ul><li>The outcome of <a href=\"https://www.cde.ca.gov/ls/nu/fd/mb-fdp-03-2022-a.asp\">Proposition 12 </a>(Prevention of Cruelty to Farm Animals Act)<strong> </strong>in California and the legal momentum towards implementing a more humane future</li><li>Pressuring elected officials to include animal rights in their legislative campaigns</li><li>Animal advocates running for office themselves</li><li>Presence of animal advocates in both the legislative and budgeting sessions of legislature</li></ul><p>The increased use of animal law and legal arguments as well as successes in this domain appears&nbsp;particularly concerning for proponents of animal agriculture, which is reflected by AAA publishing reports from attending Animal Law conferences. Individual wins here can set powerful precedents and create momentum.&nbsp;</p><p>&nbsp;</p><p><strong>Remarketing plant-based foods</strong></p><ul><li>Adopting the emotive, pathos-oriented marketing strategies of animal agriculture rather than the continued use of intellectual messaging that compares plant-based products to animal products.</li></ul><p>The article refers to an account from the Animal Law Conference 2022, where vegan activists discussed the need to update their marketing strategy for plant-based foods, in order to increase their share of meat sales. It highlights the need to develop a unique way to market these products that does not depend upon a comparison to slaughter meat.&nbsp;&nbsp;</p><p><br><strong>Conclusion</strong></p><p>The article was written by a member of the AAA, to draw attention to key trends that they had recognised in animal activism to the animal agriculture community, including from reports produced by AAA supporters undercover at animal activist conferences. Although the article does not discuss whether and how these tactics may be particularly damaging to the animal agriculture industry, its publication suggests some concern over their use by animal activists. Therefore, this post seeks to highlight these trends to animal activists, so that they can consider the value of each strategy, and reflect upon whether any of them are currently under-valued or under-used by the animal activist community.&nbsp;</p>", "user": {"username": "Aashish Khimasia"}}, {"_id": "8ZrdmwEnRRSdXdJe2", "title": "EA Israel: 2022 Progress and 2023 Plans", "postedAt": "2023-02-23T18:35:50.768Z", "htmlBody": "<p>This document recaps EA Israel\u2019s and the Israeli effective altruism community progress in 2022, and lays out EA Israel\u2019s plans for 2023 (we know that 2023 started a couple months ago, but figured better late than never). We wrote the post in order to increase transparency about EA Israel\u2019s activities, share our thoughts with the global community, and as an opportunity to reflect, strategize and celebrate.&nbsp;</p><h1>Summary</h1><h2><u>Updates to our existing strategy</u></h2><ul><li>We\u2019re placing an increased&nbsp;<strong>emphasis on supporting, incubating and launching new projects and organizations</strong></li><li>We\u2019re&nbsp;<strong>investing in our operations</strong>, in order to be able to scale our programs, support community members\u2019 initiatives and mature into a professional workplace to support staff development and retention</li><li>We\u2019re&nbsp;<strong>presenting our work and value proposition clearly</strong> and in a way that\u2019s easily understood by the team, community, and general public</li></ul><h2><u>2022 Progress</u></h2><p><u>Achievements by&nbsp;Israeli EA community</u></p><p>We asked community members to briefly share their personal progress this year.</p><p><u>EA Israel\u2019s Progress</u></p><p>EA Israel\u2019s work can be divided into four verticals:</p><p><u>1. Teaching tools about effective social action and introducing Israelis to effective altruism</u></p><ul><li>Through an accredited university course, university groups, year-long fellowships, short intro fellowships (\u201ccrash courses\u201d) for young professionals, newsletter and social media and large public events, along with onboarding new community members.</li></ul><p><u>2. Helping community members take action and maximize their social impact</u></p><ul><li>Incubating sub-groups (based on cause area / profession)</li><li>Impact acceleration programs and services</li><li>Support for community members and projects</li></ul><p><u>3. Increasing the effectiveness of donations in Israel</u></p><ul><li>Preparing for the launch of Effective Giving Israel</li><li>Launching the Maximum Impact Program, a program that works with nonprofits to create and publish cost-effectiveness reports at scale (22 reports in the pilot) with the goal of making Israeli philanthropy effectiveness-oriented and evidence-based</li><li>Counterfactually raise 500k ILS for high-impact nonprofits</li></ul><p><u>4. Infrastructure to enable continued growth</u></p><ul><li>We\u2019re setting ourselves up to be a well-run, high-capability organization</li><li>We\u2019re supporting a thriving and healthy community</li></ul><p>&nbsp;</p><p>We also discuss some of the major challenges of 2022:</p><ul><li>FTX\u2019s crash</li><li>Staff turnover and the difficulties of transitioning from a volunteer-based group to a funded nonprofit</li></ul><h2><u>2023 Annual Plan (requisite Miro board included)</u></h2><p>Effective Altruism Israel\u2019s vision is one where all Israelis who are interested in maximizing their social impact have access to the people and the resources they need to help others, using their careers, projects, and donations.</p><p>In 2023 EA Israel will continue to focus on its 4 core areas,&nbsp;</p><ul><li>Teaching tools about effective social action and growing the EA Israel community<ul><li><strong>Core objectives</strong>: scale and optimize outreach programs</li></ul></li><li>Supporting impactful action<ul><li><strong>Core objectives</strong>: incubate new sub-groups; launch new impact-assistance programs with potential to scale; provide operational support for projects, orgs and individuals</li></ul></li><li>Effective donations<ul><li><strong>Core objectives</strong>: Launch Effective Giving Israel; improve, scale and run second round of local nonprofit evaluation program</li></ul></li><li>Organizational and community infrastructure<ul><li><strong>Core objectives</strong>: support growth of outwards-facing programs; implement M&amp;E systems; streamline internal processes and operations; improve male / female community ratio and support a thriving and healthy community</li></ul></li></ul><p>Here\u2019s&nbsp;<a href=\"https://miro.com/app/board/uXjVPB1vPrA=/\"><u>a visual map</u></a> of our current and planned projects and services, where&nbsp;<i>projects in italics&nbsp;</i>are planned projects, and if you scroll down you\u2019ll see our services mapped out relative to our target audiences. Note that the impact / cost scale is very speculative, and is useful mostly for generating discussion and thought, not as a bottom line.</p><h1>Background</h1><p>2022 was a very exciting year for Effective Altruism Israel, with lots of growth, both in the Israeli EA community and within the EA Israel registered nonprofit. EA Israel started the year with 2 part-time staff members and ended with a team of 7; concurrently, the community doubled in size to ~80 volunteers and 100 highly engaged EAs.&nbsp;<a href=\"https://forum.effectivealtruism.org/users/gidikadosh\"><u>Gidi</u></a>, EA Israel\u2019s first CEO, left the team in October to lead&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/z3J439wF8Xk8qSZku/announcing-vivid-a-new-ea-organization-aspiring-to-scale-1\"><u>VIVID</u></a>, an impact-focused startup, and was replaced by me, Ezra. I feel blessed by the opportunity to work with the amazing Israeli effective altruism community, and I plan to continue to grow the community and to its impact.</p><h1>Updates to our Strategy</h1><p>We\u2019ve previously published&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/2fsPFEJ74tzaqqwCB/ea-israel-strategy-2020-21\"><u>a detailed strategy</u></a> with our community building approach laid out, and Gidi gave a talk on this topic at EAG London (<a href=\"https://forum.effectivealtruism.org/posts/SYaHgTaHG2TopKdpD/eag-london-22-ea-israel-s-approach-to-community-building\"><u>slides and video here</u></a>).&nbsp;<strong>Our mission is building and supporting an outward-facing community that is trying to do the maximum good in the world</strong>. We don\u2019t believe that \u201cgrowing the EA community\u201d is a cause area in and of itself - it is a means to an end, with that end being a much better world. That being said, we have a lot of faith in the power and people of the community, and we see our role as crucial to helping the community reach its potential and stay focused on solving critical problems.</p><p>Some strategy updates from the past year:</p><ul><li>The Israeli EA community has launched 6 impact-focused organizations in the past 2 years (details below), with a few more in the pipeline. This has led us to believe that our highest value activity is enabling the launch of high-impact independent projects.</li><li>As we grew to become a more established organization, we\u2019ve put more focus on operational capacity and organizational excellence,</li><li>Building on&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/mnGkj5aerHbfTdf7o/the-explanatory-obstacle-of-ea\"><u>our work on EA messaging</u></a>, we aim to build EA Israel into a nonprofit organization whose work can be appreciated by non-EA donors and the general public. If our message is understood only by the EA community, that\u2019s a poor indication of the way it\u2019s communicated. Improving our messaging will also enable us to raise funds from more diverse sources and thus be more resilient to shocks. Also, we\u2019re interested in raising money with lower opportunity costs than EA funders. That being said, we want to be careful about not losing our integrity or \u201cwatering down\u201d the uniqueness of EA, and aren\u2019t aiming to become mainstream - just understandable.</li></ul><h1>2022 Progress</h1><h2>Israeli EA community achievements</h2><p>Before presenting what EA Israel has done in 2022, we\u2019d like to share some highlights of our community members\u2019 efforts. Since our goal is to support a community aimed at doing the most good, the achievements of the community are, in a way, more important than those of the organization.&nbsp;</p><p>Some highlights include:</p><ul><li>Three community members from&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/aE68kcbG7ugCcTKXd/alter-israel-end-of-2022-update\"><u>ALTER</u></a> started a project to resolve iodine deficiency in Israel by promoting salt iodization.</li><li>Gidi Kadosh started VIVID,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/z3J439wF8Xk8qSZku/announcing-vivid-a-new-ea-organization-aspiring-to-scale-1\"><u>an EA startup aspiring to solve the implementation gap of personal change, and scale effective self-improvement</u></a>.</li><li>One community member spent 2022 looking for a high-impact entrepreneurship opportunity that would match his skills, and ended up launching a for-profit Earn-To-Give startup with the intention of donating 80% of profits. He\u2019s already raised seed funding and is now hiring.</li><li><a href=\"https://mentaleap.ai/\"><u>Mentaleap</u></a>, a reading and hackathon group for EA-Israel members who are interested in reducing AI risk by reverse engineering neural networks, was launched.</li><li>Other members are doing charity evaluation, have discovered cost-effective ways for early diagnosis of disease, are doing applied and theoretical AI safety work, are working on improving COVID testing and vaccines, have started businesses promoting EA, and more. You can find more community members and details in&nbsp;<a href=\"https://docs.google.com/document/d/1GV1kEYs7hPJ1J5ccR0_mzps56WgGuzg8IMC81UGLXQc/edit#heading=h.2et92p0\"><u>the appendix</u></a>.</li></ul><h2>EA Israel\u2019s direct work</h2><p>EA Israel\u2019s work can be divided into four verticals:</p><ol><li><u>Teaching tools about effective social action and introducing Israelis to effective altruism</u></li><li><u>Helping individuals in the community take action and maximize their social impact</u></li><li><u>Increasing the effectiveness of donations in Israel</u></li><li><u>Community and organizational infrastructure that enables continued growth</u></li></ol><p>(note: some activities have some overlap between verticals - such as events targeted at a specific career, which can be both introductory and help people take action)</p><h3>Teaching tools about effective social action and introducing Israelis to effective altruism</h3><p>We currently have the following programs for teaching tools on the topics of effective social action and as an introduction to EA and EA principles. These also serve as an entry point to the community:</p><ul><li><strong>Academic activities</strong> - this year we incubated university groups at two leading universities, Tel Aviv University and Hebrew University of Jerusalem. Each student group is led by two talented organizers - Noam Shwartz and Yair Kabakovitch in Tel Aviv, and Eitan Ahiman and Omri Sheffer at Hebrew U. The Tel Aviv group also received a grant from OpenPhil\u2019s University Organizer Fellowship. The university groups run&nbsp; yearly intro fellowships, which include a theoretical part in the first semester and a practical part of establishing a project in the second semester. Moreover, their main focus is to help students choose an impact-focused career, an impactful choice that is challenging for students. Most of the events they held dealt with this field (e.g. an online event with a wide career panel in a variety of cause areas.The Tel Aviv group also ran&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/46nA2FZD9fYbFLME4/mental-health-career-program\"><u>a career planning workshop</u></a> in the mental health field, with professional facilitation. The events and the workshops are run independently of EA Israel, and we support them with weekly guidance calls, advice, fiscal sponsorship, and social media expertise. Together the groups have 25 fellows in their intro fellowships, who are launching about 10 side-projects, and who have reached over 120 other students in workshops, events and group meetings.&nbsp; We\u2019ve also run intro fellowships and events at other universities, and aim to incubate independent groups at 2-3 more universities in the coming year.</li><li><strong>University course</strong> - two community members created&nbsp;<a href=\"https://en.appliedethics.university/\"><u>a university course</u></a> based on the principles of Effective Altruism, which was the top-rated course at Tel Aviv University, and which is now being developed into a scaled-up model to expose significantly more people to academic level EA content.</li><li><strong>Crash courses</strong> - we created a new format for intro fellowships, \u2018Crash Courses\u2019, that acquaints people with EA in 4-5 meetings. These crash courses are aimed mostly at young professionals, but can serve as an entry point for anyone interested in EA. We also created an advanced crash course, also called a&nbsp;<a href=\"https://docs.google.com/document/d/1VQfVbZSZow_Oq24cnRQpFzykHzIdcG8Jmjx6ctRFxRg/edit\"><u>\u2018methodologies workshop\u2019</u></a>, which aims to help community members get hands-on experience with performing cost-effectiveness analyses, building theories of change, using weighted factor models and tools for analyzing crucial considerations. We ran 9 crash courses with 59 graduates.</li><li><strong>Newsletter and social media</strong> - we send out a periodic newsletter and publish events and content on our social media platforms (Facebook, LinkedIn). All together, we have approximately 2.5k followers and subscribers across the different platforms. Toward the end of 2022, Carole Bibas, a community member, began working for us part time, focusing exclusively on our social media. We hope to significantly improve our metrics over the coming year and create much more buzz and interest in EA principles.</li><li><strong>Public events</strong> - we held a variety of events open to the public about effective careers, impact-entrepreneurship, cause areas, mentoring, and more. We had around 20 events, with approximately 500 participants. During the first half of the year, we also ran a monthly virtual discussion group on EA topics called \u201cTalking Effectiveness\u201d, which received positive reviews, but weren\u2019t able to maintain it due to personnel turnover.</li></ul><p><i>Pictured: an event on high-impact entrepreneurship</i></p><p><i>(the slide says \u201cFeedback and Measurement\u201d in Hebrew)</i></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677177352/mirroredImages/8ZrdmwEnRRSdXdJe2/v6wk9waymw40sbgcaifh.jpg\"></p><p><strong>Onboarding new community members</strong> \u2013 following initial interest from our broad outreach, we have an intake form on our website with various options (learn more, volunteer, request for career consulting, etc), and we initiate 1-1 calls with individuals interested in joining the community to smooth their integration into the community and to identify ways for them to contribute. From our experience, finding good opportunities for people to contribute to is one of the best ways to get them involved and excited.&nbsp;</p><p>In 2023, we plan to build on our past successes and improve, streamline and scale our active outreach channels. We aim to:</p><ul><li>Incubate 3 new university groups</li><li>Run 3 intro fellowships at universities, with 45 graduates</li><li>Run 10 crash courses, with 100 graduates</li><li>Increase the consistency and quality of our newsletter and improve the quality and quantity of our social media presence. Our goal is to publish 8 newsletters, with a 150% growth in subscribers and clicks; and to grow the number of Facebook group followers by 2x and LinkedIn by 5x.</li><li>We aim to run 6 large events and 12 smaller events open to the public, with an emphasis on using the events to launch projects, sub-groups and other follow-up activities. We\u2019re de-emphasizing one-off events, since we\u2019re not convinced of the strength of the theory of change for events that don\u2019t have a clear ask or goal.</li><li>Grow to 150 highly involved community members</li></ul><h3>Helping community members take action and maximize their social impact</h3><p>Incubating sub-groups</p><p>This year was the first time the Israeli EA community grew to a size that allowed for the growth of smaller sub-groups and communities. Two community members founded an Impact Tech Entrepreneurship community, which ran a number of events of over 70 people per event, and grew to around 100 participants (however, progress has stalled lately and it\u2019s not clear whether it will continue). Another member is running an AI Safety group that has regular reading group meetings and has participated in two AI Safety hackathons, and we organized an \u201cAI Safety co-working day\u201d at the community office so that people interested in the field can work together.</p><p>We also initiated and supported events on specific cause-areas, such as biology, mental health, democracy + tech, animal welfare, and biosecurity, many of which were hosted by EAs visiting from other countries (shout out to Karolina Sarek, Fazl Barel, Emma Buckland, and Andrew Snyder-Beattie). We plan to grow these groups into independent communities of their own.</p><p><strong>Side note</strong> - if you\u2019re interested in visiting Israel, please reach out so we can introduce you to our community; we love hosting visitors (spring is lovely here).<br>&nbsp;</p><p><i>Pictured: event with Karolina Sarek</i></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677177352/mirroredImages/8ZrdmwEnRRSdXdJe2/glxksgoevip0ikekzyjw.jpg\"><br>&nbsp;</p><p><strong>Impact acceleration programs and services</strong></p><p>We still have some uncertainty about the best ways to help Israelis maximize their social impact, so in 2022, we ran a number of services and programs aimed at gathering more information about the best ways to do so and about how potential large-scale programs might look.&nbsp;</p><p>Our programs and services in 2022 included:</p><ul><li>A volunteer operated a career consulting program - we offer career consulting on our website, where we match high-potential consultees with community members who have relevant experience who\u2019ve we\u2019ve lightly trained in career consulting (<a href=\"https://forum.effectivealtruism.org/posts/qyG6YrxTAnRGkBhRT/guide-for-conducting-career-consultation\"><u>see our guide here</u></a>)</li><li>A job-matching form where people can submit their CVs and be matched to relevant EA jobs</li><li>A career-focused community retreat (with three community babies in attendance)</li><li>Encouraging community members to apply to EAG and EAGx\u2019s and helping them prepare, with 48 community members attending throughout 2022</li><li>Promoting EA opportunities, such as Charity Entrepreneurship\u2019s incubation program and coaching</li><li>A grant writer to help community members apply for grants<br>&nbsp;</li></ul><p><i>Pictured: career-focused community retreat</i></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677177352/mirroredImages/8ZrdmwEnRRSdXdJe2/bslnxvfhfv72snvmq08w.jpg\"></p><p>We were also awarded a grant from the FTX Future Fund to run two joint programs with LEAD, a social leadership development nonprofit. The programs were aimed at helping community members launch new projects and at introducing EA concepts to successful social entrepreneurs, who would then launch new initiatives. Unfortunately, the project is now on hold due to lack of funding. If anyone is interested in exploring new ways to accelerate the launch of high-impact projects, we think that LEAD\u2019s method (which until now hasn\u2019t been utilized for high-impact causes) is extremely promising as an enabler, and we\u2019re looking for new funding sources.</p><p>Support for community members and projects</p><p>As a registered nonprofit with paid staff, EA Israel has a comparative advantage in providing certain services to the Israeli EA community, and we think such practical support can often be extremely impactful. For that reason, in 2022 we provided:</p><ul><li>A co-working space for EAs working on projects and for meetups on EA topics</li><li>Fiscal sponsorship and employer of record for grantees from EA funders</li><li>Organizing retreats (we had 3 this year, 1 of which was volunteer run and subsidized by EA Israel). Our most recent community retreat, in late November, had an 8.5&nbsp;<a href=\"https://en.wikipedia.org/wiki/Net_promoter_score\"><u>NPS</u></a> and was attended by 60 community members</li><li>Organizational support for other EA orgs in Israel, including ALTER, VIVID and Probably Good, and a new org (that hasn\u2019t yet been announced) aimed at promoting high-quality EA content at scale</li><li>We also built new community health guidelines and protocols, which we hope will enable us to grow quickly while maintaining a level of comfort and safety for all members</li></ul><p>In 2023, conditional on finding leaders, we plan to incubate sub-groups in animal welfare, global health, biosecurity and democracy + tech, that will meet regularly and provide a network and peer support. We hope to provide support for the topic specific communities through mentorship, fiscal sponsorship, networking, operational assistance, and more, to make it easier for new groups to form.</p><p>We\u2019ve launched a needs assessment survey aimed at our most engaged members to better understand what we can do to increase their impact. The goal of the survey is to identify the main bottlenecks preventing highly engaged community members from taking action and to help us design services and programs accordingly (results forthcoming). After receiving the results, we\u2019ll&nbsp; match them with our list of potential projects and launch 1-3 programs this year with the goal of significantly increasing time spent on high-impact projects by Israelis.&nbsp;</p><p>We want to systematize and scale our other impact assistance services, such as grant writing support, EAG / EAGx attendance (although we expect a significant decrease in overall numbers due to CEA not covering travel expenses), publishing opportunities, and more. We plan to run 2 community retreats and 2 smaller, more focused retreats, contingent on funding.</p><p>We aim to continue our support for projects and individuals, and optimize and promote the support we offer in order to increase the number of orgs and individuals utilizing our support. Our operational systems will need to scale accordingly, which we\u2019re already actively working on.</p><p>We also plan to run some women-only events in order to increase community diversity and achieve a more balanced male/female ratio. We believe this will help the community grow in a more healthy and balanced fashion.</p><h3>Increasing the effectiveness of donations in Israel</h3><p>To date, we\u2019ve published a guide to effective donations in Hebrew (which is a top Google hit when searching for effective donations), have published 1 cost-effectiveness analysis of a nonprofit and have run philanthropic advising sessions at a small scale.</p><p><strong>Effective Giving Israel</strong></p><p>Toward the end of 2022 EA Israel received tax exempt status, and we\u2019ve begun setting up infrastructure allowing Israelis to donate to high-impact nonprofits (GiveWell, GWWC recommended charities) via EA Israel and be recognized as tax-deductible by the Israeli tax authorities, similar to&nbsp;<a href=\"https://effektiv-spenden.org/\"><u>Effektiv-Spenden</u></a> and other sites around the world. Israelis would be able to learn about the importance of effectiveness in giving and donate to high-impact nonprofits via EA Israel\u2019s infrastructure, while receiving a 35% tax-rebate from the Israeli tax authorities.</p><p><strong>Maximum Impact Program: Israeli Charity Evaluation</strong></p><p>We also launched a nonprofit evaluation program in Israel, called the Maximum Impact Program, and the pilot will end in June. Our main goal is to change Israeli philanthropy to be significantly more effective and evidence-based. Although we haven\u2019t yet done a final analysis, we believe the pilot program will be very successful and will put us on track to reaching our main goal, for the following reasons:</p><ul><li>We will publish 22 cost-effectiveness analyses on Israeli nonprofits, becoming the first public database on nonprofit effectiveness in Israel.</li><li>Some of the nonprofits being evaluated have the potential to be very high-impact relative to the average Israeli nonprofit (and potentially GiveDirectly, such as an Israeli nonprofit that runs WASH programs in Ethiopia), and we believe we\u2019ll be able to significantly improve their scaling and fundraising efforts.</li><li>We\u2019ve built an extensive set of templates and how-tos for nonprofits or volunteers who are interested in cost-effectiveness but lack relevant expertise. These tools can be used to run programs in other countries or as the basis for a university course.</li><li>We\u2019ve received requests from many other nonprofits interested in participating in the next round of the program.</li><li>We\u2019ve engaged the local EA community around the project, with 15-20 active volunteers from the community, and have onboarded 10 academic researchers to the EA community through the program.</li><li>We\u2019ve built an impressive team of advisors. Our judges panel includes Dan Stein (IDInsight, GivingGreen), Karolina Sarek (Charity Entrepreneurship), Annalia Schlosser (empirical economist), Asaf Kovo (chief economist at Israel Innovation Authority) and Omer Snir (VP at leading Israeli nonprofit research group). We also have advisors and collaborators from GiveWell, SoGive, Happier Lives Institute, Suvita, Israel Impact Partners, Social Finance Israel, and other Israeli and Jewish philanthropic groups.</li></ul><p>We\u2019ve had initial interest from Israeli and Jewish donors (both foundations and private donors) about supporting the program and using our product, which we\u2019ll be pursuing in the coming months. Our current plan for 2023 is to scale the program in order to identify the most effective nonprofits in Israel, export the program to another EA community operating in a country with a focus on local donations (if you\u2019re an EA community leader who\u2019d be interested in trying to start something similar - please reach out!), and adding local nonprofits to our effective-giving website. The website will present both local nonprofits who\u2019ve published research on their effectiveness as well as EA recommended high-impact nonprofits, with a donation option.&nbsp;</p><p><strong>We\u2019re looking for funding!</strong> Our pilot program was funded by the Infrastructure Fund and a private Israeli donor, and we have 2 qualified staff members who built the program from scratch. In order to hit our goals for 2023, we need funding for salaries and operational costs. If you\u2019re a funder or know of someone who might be interested in supporting our work, again - please reach out! We\u2019ll also publish a forum post with more detail later on - stay tuned.<br>&nbsp;</p><p><i>Pictured: presenting the Maximum Impact Program at EAGx Singapore</i></p><p><i><img src=\"https://res.cloudinary.com/cea/image/upload/v1677177352/mirroredImages/8ZrdmwEnRRSdXdJe2/rnwycxybqasfmienfpnt.jpg\"></i></p><h3>Infrastructure to enable continued growth</h3><p>In 2022, our staff went through significant change and growth, as mentioned above. We began to put much more effort into becoming a professional organization with a strong and defined culture, professional development opportunities, strong ops and internal systems, and good governance. Some of our main activities include revamping our financial processes and budget (including successfully receiving tax-deductible status), setting up a professional development course for CBG grantees and moving to a new office (which doubles as a community co-working and small events space). We also began using OKRs and KPIs and having clear Areas of Responsibility in order to run more efficiently and hit our targets (we use&nbsp;<a href=\"https://docs.google.com/document/d/1ZJZbv4J6FZ8Dnb0JuMhJxTnwl-dwqx5xl0s65DE3wO8/edit\"><u>The Great CEO Within</u></a> and&nbsp;<a href=\"https://themanagershandbook.com/\"><u>the Manager\u2019s Handbook</u></a> for inspiration).&nbsp;</p><p>We set up quarterly board meetings to provide oversight, tweaked our board membership, and we began publishing a summary of the board meetings and having a community Q&amp;A session about them in order to improve transparency.</p><p>Improving our operations and professional excellence is an ongoing process. We try and hit the right balance between doing things \u201cthe right way\u201d and between \u201cgetting things done\u201d, or between sustainability and growth.&nbsp;</p><p>In 2023 we want to achieve the following goals:&nbsp;</p><ul><li>Set up an M&amp;E system and improve our CRM</li><li>Move all internal processes to Clickup</li><li>Ensure that all projects have clear goals, timelines and owners</li><li>Build an 18-month professional development plan for each staff member</li><li>Implement budget tracking software and improved payment systems</li></ul><h3>Other challenges</h3><p>FTX\u2019s crash has affected EA Israel\u2019s work in a number of ways:</p><ul><li>A major community building project had been financed by FTX Future Fund and had to be frozen; however, there were no serious repercussions beyond a missed opportunity. EA Israel has a signed contract with FTX but hadn\u2019t received the money, so we didn\u2019t have to deal with clawbacks etc.&nbsp;</li><li>Some key partners and community members received or were set to receive funding from FTX, and we supported them as best as we can in non-financial ways.&nbsp;</li><li>PR wise, EA is now more well-known, but not necessarily positively. We consulted with a number of different people about how to respond and closely followed how EA is presented in local news, but ultimately decided to keep a low profile until the FTX story died down.</li><li>We increased our emphasis on good governance, updating our financial systems to ensure operating runway, and reactivating the board.</li></ul><p>Staff turnover and the difficulties of transitioning from a volunteer-based group to a funded nonprofit</p><ul><li>EA Israel began a transition to a funded nonprofit in mid-2021 and continued the trend throughout 2022. This has led to both significant growth and some discontinuity with previously highly involved volunteers or volunteer led projects. Today, there is a lower ratio of fewer highly involved volunteers to community members than there was previously, and some volunteer-led projects haven\u2019t been able to maintain continuity.</li><li>There has been significant staff turnover throughout the year, slowing our growth. We are recruiting 2-3 new staff members in the first half of 2023, and plan to have a high bar for expected continuity, in order to reduce turnover rate. We have also made some changes to our recruitment strategy and team culture to put together a team that\u2019s built to last.</li></ul><h1>2023 Plans</h1><p>Effective Altruism Israel\u2019s vision is one where all Israelis who are interested in maximizing their social impact have access to the people and the resources they need to help others through their careers, projects, and donations. To recap:</p><p>In 2023 EA Israel will continue to focus on its 4 core areas:</p><ul><li>Teaching tools about effective social action and growing the EA Israel community</li><li>Supporting impactful action</li><li>Effective donations</li><li>Organizational and community infrastructure</li></ul><p>Here\u2019s&nbsp;<a href=\"https://miro.com/app/board/uXjVPB1vPrA=/\"><u>a visual map</u></a> of our current and planned projects and services, where&nbsp;<i>projects in italics&nbsp;</i>are planned projects. Note that the impact / cost scale is very speculative, and is useful mostly for generating discussion and thought, not as a bottom line.</p><p>If you&nbsp;<a href=\"https://miro.com/app/board/uXjVPB1vPrA=/\"><u>scroll down in the visual map</u></a>, you\u2019ll see our services mapped out relative to our target audiences.</p><p>By the end of 2023, we aim to offer the following services:</p><ul><li><strong><u>Teaching tools and community growth</u></strong></li><li><i>Core objectives</i>: optimize existing programs by significantly improving consistency, quality and scale<ul><li><i>A book or other key content translated to Hebrew</i></li><li>University groups at Tel Aviv University, HUJI,&nbsp;<i>BGU, Technion, Reichman</i></li><li>A consistent and engaging marketing presence (newsletter, website, social media)</li><li>Regular and scheduled introductory and advanced crash courses</li><li><i>Planned EAGx conference for spring 2024*</i></li><li><i>Additional accredited university course about EA*</i></li></ul></li><li><strong><u>Effective donations</u></strong></li><li><i>Core objectives</i>: Launch Effective Giving Israel and raise 500k ILS; improve, scale and run second round of local nonprofit evaluation program<ul><li>Counterfactually raise 500k ILS for high-impact nonprofits</li><li>An improved round of the Maximum impact program, where we will attempt to identify and evaluate the most effective nonprofits in Israel and engage with leading Israeli foundations about the importance of effectiveness</li><li><i>Refining the model of the Maximum Impact program as a large off-the-shelf project for other city / national groups.</i></li><li>Effective giving website (as explained above)</li><li><i>Effective giving outreach events (with GWWC, Givewell, FP, etc)</i></li><li><i>Export maximum impact to an additional EA community (potentially Sweden, Turkey or India)*</i></li></ul></li><li><strong><u>Supporting impactful action</u></strong></li><li><i>Core objectives</i>: Counterfactually influence 20 or more career transitions per year towards high-impact work and organizations<ul><li><i>A research report on the main bottlenecks preventing community members from taking action&nbsp;and 1-2 programs to address the bottlenecks</i></li><li><i>1 program to enable high-impact entrepreneurship and project launch</i></li><li>A revamped and scaled career consultation program (20 calls per month)</li><li>A job &amp; volunteer matching service</li><li><i>Cause area specific groups in biosecurity, animal welfare, AI safety, GH&amp;D and impact-tech</i></li><li><i>Regular calls and a retreat for sub-group leaders</i></li><li><i>A system for providing regular check-ins and support to individual community members (today it\u2019s relatively ad-hoc)</i></li><li>Providing operational infrastructure for community members (fiscal sponsorship, co-working space, grant writing assistance)</li></ul></li><li><strong><u>Infrastructure</u></strong></li><li><i>Core objectives</i>: build EA Israel ops and professional culture to be top-notch and support a thriving and healthy community<ul><li>Organization<ul><li>4 full-time-equivalent staff members on the community team, 2 full time staff members on the donations team</li><li>A CRM /&nbsp;<i>M&amp;E system</i></li><li>A professional development system</li><li>A working planning system (OKRs, KPIs, project planning)</li><li>Publishing board meetings and organizing an online Q&amp;A session for community members to increase transparency</li></ul></li><li>Community<ul><li><i>A community events pipeline with scheduled and consistent events run by community members</i></li><li><i>A more balanced male / female ratio in the community</i></li><li>Our community health coordinator will support community health, ensure adherence to our sexual harassment policy, and&nbsp;<i>publish a code of conduct</i></li></ul></li></ul></li></ul><p>* Projects with an asterisk are more speculative and contingent on personnel fit and the ecosystem.</p><p><i>Projects in Italics are planned for the upcoming year.</i></p><p>&nbsp;</p><p>We believe that of the three outward facing core areas (not infrastructure), teaching tools and growth is the most well developed, and needs to be optimized so as to require less effort and to run more consistently and efficiently, and in order to scale. Our work on effective donations currently consists only of Maximum Impact, and our work on supporting action is still ad-hoc. Since we believe that building a strong community requires a balance between growth and action, we want to invest more resources this year in the donations and impactful action areas.</p><h1>Closing remarks and thank yous</h1><h2>Feedback - let us know what you think!</h2><p>The contents of this document are important to the way we operate, and we are sincerely looking for feedback.We do some things differently than the mainstream (if there is such a thing) community builders, and we\u2019d love to exchange thoughts and ideas and challenge our approach more deeply.</p><p>&nbsp;If you have feedback on anything written here, please comment on this forum post. For anonymous feedback,&nbsp;<a href=\"https://forms.gle/N7zJME1GeviZwdYP7\"><u>please use this form</u></a>. You can also email me directly at&nbsp;<a href=\"mailto:ezra@effective-altruism.org.il\"><u>ezra@effective-altruism.org.il</u></a>.</p><h2>Action Items</h2><p>If you\u2019ve read through the whole post, you\u2019ll have noticed that there were some calls to action sprinkled in. Here\u2019s a wrap up:</p><ul><li>People thinking of visiting Israel - come! Let us know! We\u2019d love to host you.</li><li>Funders - we have two programs looking for funding:<ul><li>&nbsp;A project aimed at helping highly skilled people launch projects or undergo career changes, with expert facilitators trained in helping people overcome internal obstacles</li><li>The Maximum Impact program, which does local cost effectiveness research, is building an off-the-shelf effectiveness research kit for other communities to use, and works with local donors to increase their effectiveness.</li></ul></li><li>Community leaders who are interested in local charity research - we\u2019re developing a ready-made program and kit for you. Please let us know if this is something you\u2019d be interested in, so we can develop it further with a specific audience in mind.</li><li>Community leaders looking for advice in ops, hiring, goal setting, strategy, content building, or anything else - drop us a line, we\u2019d be happy to talk.</li></ul><p><br>&nbsp;</p><p><i>Pictured: on a hike with an EA visiting Israel</i></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677177352/mirroredImages/8ZrdmwEnRRSdXdJe2/wfpc6nztyzhroxdnol9k.jpg\"></p><h2>Gratitude</h2><p>Reflecting on what we\u2019ve done over the past year was a great way to generate focus and motivation moving forward, but especially it made me realize how many thoughtful, kind, talented, insightful and driven people are involved in the work we do. Literally everything here was a group or community effort.</p><p>Special thanks to our board - Omer, Mor, Edo, and Gidi, and former board members, Sella and Assaf.</p><p>To the EA Israel 2022 team members - this is your work more than mine - Guy T, Michal, Yonatan S, Rona, Yuval and Adi.</p><p>To our volunteers in 2022 (I\u2019m afraid I\u2019ll forget someone so please call me out if I do) - Alon, Arye, Arbel, Dan, David, Daniel, Dvir, Dvir, Guy, Haroon, Ido, Ido, Itay, Jonathan, Joseph, Karen, Lev, Levav, Liat, Lior, Matan, Maya, Maytav, Merav, Michael, Nadav, Nahum, Neta, Niki, Nir, Noam, Omri, Ofir, Orr, Ron, Shiraz, Shahar, Sarel, Sean, Shay, Smadar, Soof, Tal, Tom, Tomer, Yair, Yam, Yochay, Yovel, Yael, Yonatan, Yossi, Yishai, Yuval, Yuval - for your work on our website, content, courses, projects, partnerships, community, research, feedback, and much more. This wouldn\u2019t be possible without you.</p><p>And to our community members, whose passion to think deeply about how to make the world a better place and change their lives to do so is what makes us come to work in the morning.</p><p><br>&nbsp;</p><p><i>Much of the credit for this post goes to Michal, Rona, Guy, Yonatan, Gidi, Edo and Sella. Thank you for your help!</i></p><p><br><br><br><br><br>&nbsp;</p><h1>Appendix: some Israeli EA community achievements</h1><ul><li>ALTER - reducing iodine deficiency:<ul><li>Rona Tobolsky, David Manheim and Naham Shapiro started a project to resolve iodine deficiency in Israel by promoting salt iodization.</li><li>Salt iodization is a well-known, evidence-based health intervention considered cost-effective by Givewell. The provision of iodized salt is recommended by the WHO and implemented in more than 80% of countries around the world.</li><li>Israel is one of 25 countries still classified as iodine deficient in 2021. In 2017, 85 percent of pregnant women and 62 percent of school-age children had insufficient iodine intake, which may cause impaired neurological development and loss of up to 15 IQ points. Recent results persistently failed below the WHO\u2019s adequacy range for iodine.</li><li>We are establishing a network of local and international public health professionals advocating for iodization and working with the Israeli Ministry of Health, the salt industry, public health academics and international NGOs to fill the gaps needed to mandate iodization.</li></ul></li><li>Gidi Kadosh - Started VIVID,&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/z3J439wF8Xk8qSZku/announcing-vivid-a-new-ea-organization-aspiring-to-scale-1\"><u>an EA startup aspiring to solve the implementation gap of personal change, and scale effective self-improvement</u></a>. VIVID was focusing on the product and infrastructure since its inception, and plans to collaborate with EA wellbeing professionals mid-2023.</li><li>Probably Good<ul><li>Has been&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/WD7bFkWrR3Bu9dMnN/we-re-hiring-probably-good-is-expanding-our-team\"><u>growing&nbsp;</u></a>and publishing&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/tNkHKfbj5BvcWo6vC/prioritization-research-careers-probably-good\"><u>new career profiles</u></a></li></ul></li><li>One community member<ul><li>Spent 2022 looking for a high-impact entrepreneurship opportunity that would match his skills, and ended up launching a for-profit Earn-To-Give startup with the intention of donating 50-80% of earnings. He\u2019s already raised seed funding and his hiring.</li></ul></li><li>Yuval Shapira&nbsp;<ul><li>Started a small independent lecturing for-profit company named 'Real Impact'. Hosted paid lectures in startups, 'mechinot', ect. Was granted an Infrastructure Fund grant for the business, still considering the option in light of counterfactual possibilities. Would love to hear suggestions mostly for improving finance, business and team-working skills.</li></ul></li><li>Ido Gedanken<ul><li>Joined an impact venture capital named Jimpact investing in impact oriented startups. Led a research on possibilities to invest in for-profit AI safety startups. If anybody wants to connect me to any impact startup that we should consider, I would love to chat.</li></ul></li><li>Edo Arad<ul><li>Together with&nbsp;<a href=\"https://forum.effectivealtruism.org/users/c-tilli\"><u>Cecilia Tilli</u></a>, I\u2019ve led an online&nbsp;<a href=\"https://forum.effectivealtruism.org/groups/5FLb7jTyhi3Gug2Fp\"><u>\u201cimproving science group\u201d</u></a> for a couple of years. We had a good run, but we mostly let it die out. There are a lot of great people in EA interested in these areas, so I hope to find someone who\u2019d be interested in picking this up.</li><li>This year was mostly a transition from \u201cbeing burned out and unproductive\u201d to \u201cbeing less burned out and a little bit productive\u201d. I\u2019ve started 2022 by joining a cool tech company\u2019s data science research team, which was fun.&nbsp;</li><li>Joined&nbsp;<a href=\"https://alter.org.il/\"><u>ALTER</u></a>\u2019s board, as an expert signer.&nbsp;</li><li>As of Oct 22, I\u2019ve started working full time with EA Israel as an independent research and project manager, funded by EAIF.&nbsp;<ul><li>I\u2019m terribly grateful to&nbsp;<a href=\"https://forum.effectivealtruism.org/users/shaybenmoshe\"><u>Shay Ben Moshe</u></a> for agreeing to serve as my manager in practice. He has helped me a lot with project prioritization and resolving random challenges.</li><li>My initial idea list:&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sGdh0SVyrRmgGQGDKEzPYYtaO-_QQ00EeEDbp018vB4/edit#gid=0\"><u>link</u></a>. I\u2019ve mostly been working on tech entrepreneurship stuff and helping EA Israel.</li><li>Tech Entrepreneurship. I\u2019ve worked with Yuval Ginor on evaluating a water-quality monitoring startup. Together with Yossi Tamarov we have been talking to many people in this space and the Israeli impact entrepreneurship environment, made some good connections and learned a lot about his field. We have set up a weekly long coworking session, and we have some interesting projects ahead of us.</li><li>Almost solved AI safety with Yonatan Cale :)</li></ul></li><li>My current focus is in doing more prioritization research.&nbsp;</li></ul></li><li>&nbsp;Itay<ul><li>Mentaleap is a reading and hackathon group for EA-Israel members who are interested in reducing AI risk by reverse engineering neural networks (https://mentaleap.ai). It consists of world-class information security specialists, AI researchers, and neuroscientists. The group meets every two-three weeks to discuss papers and participate in online hackathons. It has 7 permanent members and more than 40 participants.</li></ul></li><li>Matan Levine<ul><li>I am an MD-PhD student, studying disease dynamics and the transitions between different health conditions over time using machine learning tools and NLP approaches (at the Kishony lab). I took part in the Hi-Med fellowship and am having thoughts about how to make the highest impact as a physician or a researcher.</li><li>As of the beginning of 2022 I\u2019ve still studied (since 2020) COVID-19 PCR-tests and vaccines, and more precisely, their effect on the viral load and transmission, which helped (hopefully) to decision makers.</li><li>I also facilitated an EA crash course at the Technion, with 6 highly motivated and talented participants. Looking forward to see the progress and expansion of EA here, as this is (as far as I know) the first encounter of the community in this academic institute.</li></ul></li><li>Shay Ben Moshe<ul><li>I kept looking for promising opportunities for my career, mostly for founding a new organization (whether for- or non-profit). After not finding other ideas I am excited about, I started looking more deeply into AI safety and forming my updated opinions on the matter, and am currently considering transitioning to working on technical AI safety full-time.</li><li>I worked as a software engineering consultant for arXiv.org (the de-facto standard open-access repository for preprints and papers in exact sciences), assisting them with their cloud migration and system redesign.</li><li>Since the last quarter of 2022, I have been volunteering in managing and assisting Edo Arad's work as a full-time independent researcher, see above for more details.</li><li>I have worked with unit 8200 in the IDF on trying to establish a new team using their comparative advantages to have a meaningful impact on climate change mitigation. Unfortunately, this has not come to fruition.</li><li>I continued giving career consultation sessions to members of EA Israel and others interested in increasing the impact of their careers.</li></ul></li><li>Michael Latowicki<ul><li>I\u2019m promoting the creation of a crowdsourced predictive modeling platform. The platform would ideally consist of these parts: 1. a machine-readable catalog of continuously-updated publicly accessible datasets, 2. a library of predictive models 3. An automatic system for scoring the predictive power of models based on incoming data, and 4. A prediction market for expressing incentivized views about the predictive quality of those models. The envisioned system is intended to inform public opinion, to facilitate predictive social science and policy analysis, and to democratize science.</li></ul></li><li>Carole Bibas<ul><li>Started to work at the Modern Agriculture Foundation as the COO. We lead a few projects that are aimed at advancing the Israeli alternative proteins ecosystem. The biggest project is our Better Plate Track accelerator, that accelerates startups in the field. We also advance gender diversity through a new initiative \u201cIsraeli Women in Foodtech Awards\u201d. Happy to hear if you know of any women who deserve to be one of them.</li><li>During my maternity leave, I applied to the CE program. I didn\u2019t make it to the end, but got to the last stage, which gave me access to a smaller course \u201cCapacity Ventures\u201d that helped me figure out what I should do with my life, basically. That is how I decided to enroll in the MIT Micromasters program MicroMasters Program in Data, Economics, and Development Policy. I basically learn how to assess social interventions. Maybe in the future, if I pass all the classes, and find money, I will study the entire master program.</li><li>I joined Maximum Impact as a researcher and currently work on two cost-effectiveness analyses. One within the Modern Agriculture Foundation, the second with an org called Green Course. It is harder and more demanding than I thought and I hope to be able to deliver interesting insights.</li><li>I joined the EA Israel team in a small capacity to help with the social media efforts, and if needed, I help community members submit grant applications for their projects.</li><li>I sometimes volunteer with EA for Jews. For Rosh Hashana, I designed an EA-focused Seder handbook and maybe will lead a session at EAG London for Shabbath ( although I didn\u2019t get funded for attending the conference, so the money part may be an issue)</li></ul></li><li>Vanessa Kosoy<ul><li>Worked on upcoming paper about regret bounds for multi-armed bandits with imprecise probability (part of my research programme in theory of intelligent agents for existential AI safety)</li><li>Developed \u201cPhysicalist Superimitation\u201d: a theoretical approach to aligning AI, based on&nbsp;<a href=\"https://www.alignmentforum.org/posts/gHgs2e2J5azvGFatb/infra-bayesian-physicalism-a-formal-theory-of-naturalized\"><u>infra-Bayesian physicalism</u></a> (currently only explained in short-forms and online talks)</li><li>Mentored four AI safety scholars in the&nbsp;<a href=\"https://www.serimats.org/\"><u>SERI MATS</u></a> programme</li><li>Published a prize on contributions to the learning-theoretic research agenda</li><li>Hired a scientific writer (Brittany Gelb) to write a better presentation of the&nbsp;<a href=\"https://www.alignmentforum.org/posts/zB4f7QqKhBHa5b37a/introduction-to-the-infra-bayesianism-sequence\"><u>infra-Bayesianism</u></a> research project by Alexander Appel and myself, and started working with her</li><li>Participated in the \u201cAlignable Structures\u201d research workshop organized by EA Philadelphia</li></ul></li><li>Yovel Rom<ul><li>I\u2019m an ML researcher working in a medical start- up named AEYE Health.&nbsp;</li><li>As part of my work I researched cheap, scalable ways to diagnose disease through retinal images. I discovered a way to diagnose diabetes through retinal images, resulting in potential saving of 200,000 QALY per year in the US alone if applied widely.</li><li>Additionally, I worked on ways to diagnose and screen various other eye conditions, potentially resulting in huge QALY earnings when they\u2019ll be approved and applied.</li><li>Arranged and participated in a team in the Technical AI Alignment Fundamentals, trying to boost the AI safety community in Israel.</li><li>Worked on replicating Chris Olah\u2019s work in weight visualization with Itay Yona, trying to get into AI safety research.</li></ul></li><li>Lior Oppenheim<ul><li>Consulted for Tevel B'Tzedek regarding agricultural-training based projects in rural Zambia and helped in assessing their cost-effectiveness</li></ul></li></ul><p><br>&nbsp;</p>", "user": {"username": "ezrah"}}, {"_id": "aJwcgm2nqiZu6zq2S", "title": "Taking a leave of absence from Open Philanthropy to work on AI safety", "postedAt": "2023-02-23T19:05:43.755Z", "htmlBody": "<p>\nI\u2019m planning a leave of absence (aiming for around 3 months and potentially more) from Open Philanthropy, starting on March 8, to explore working directly on AI safety.\n</p>\n<p>\nI have a few different interventions I might explore. The first I explore will be <strong>AI safety standards: </strong>documented expectations (enforced via self-regulation at first, and potentially government regulation later) that AI labs won\u2019t build and deploy systems that pose too much risk to the world, as evaluated by a systematic evaluation regime. (More <a href=\"https://www.cold-takes.com/racing-through-a-minefield-the-ai-deployment-problem/#global-monitoring\">here</a>.) There\u2019s significant interest from some AI labs in self-regulating via safety standards, and I want to see whether I can help with the work <a href=\"https://alignment.org/\">ARC</a> and others are doing to hammer out standards that are both protective and practical - to the point where major AI labs are likely to sign on.\n</p>\n<p>\nDuring my leave, <a href=\"https://www.openphilanthropy.org/about/team/alexander-berger/\">Alexander Berger</a> will serve as sole CEO of Open Philanthropy (as he did during my parental leave in 2021). \n</p>\n<p>\nDepending on how things play out, I may end up working directly on AI safety full-time. Open Philanthropy will remain my employer for at least the start of my leave, but I\u2019ll join or start another organization if I go full-time.\n</p>\n<p>\nThe reasons I\u2019m doing this:\n</p>\n<p>\nFirst, I\u2019m very concerned about the possibility that <a href=\"https://www.cold-takes.com/most-important-century/\">transformative AI </a>could be developed soon (possibly even within the decade - I don\u2019t think this is &gt;50% likely, but it seems too likely for my comfort). I want to be as helpful as possible, and I think the way to do this might be via working on AI safety directly rather than grantmaking.\n</p>\n<p>\nSecond, as a general matter, I\u2019ve always aspired to help build multiple organizations rather than running one indefinitely. I think the former is a better fit for my talents and interests.\n</p>\n<ul>\n\n<li>At both organizations I\u2019ve co-founded (GiveWell and Open Philanthropy), I\u2019ve had a goal <em>from day one</em> of helping to build an organization that can be great without me - and then moving on to build something else. \n\n</li><li>I think this went well with GiveWell thanks to Elie Hassenfeld\u2019s leadership. I hope Open Philanthropy can go well under Alexander\u2019s leadership. \n\n</li><li>Trying to get to that point has been a long-term project. Alexander, Cari, Dustin and I have been actively discussing the path to Open Philanthropy running without me since 2018.<sup id=\"fnref1\"><a href=\"#fn1\" rel=\"footnote\">1</a></sup> Our <a href=\"https://www.openphilanthropy.org/research/open-philanthropys-new-co-ceo/\">mid-2021 promotion of Alexander to co-CEO</a> was a major step in this direction (putting him in charge of more than half of the organization\u2019s employees and giving), and this is another step, which we\u2019ve been discussing and preparing for for over a year (and announced internally at Open Philanthropy on January 20).</li></ul>\n<p>\nI\u2019ve become increasingly excited about <a href=\"https://www.cold-takes.com/jobs-that-can-help-with-the-most-important-century/#low-guidance-jobs\">various interventions to reduce AI risk</a>, such as working on safety standards. I\u2019m looking forward to experimenting with focusing my energy on AI safety.\n</p>\n\n \n<h2>Footnotes</h2>\n<div class=\"footnotes\">\n<ol><li id=\"fn1\">\n\n<p>\n     This was only a year after Open Philanthropy became a separate organization, but it was several years after Open Philanthropy started as part of GiveWell under the title \u201cGiveWell Labs.\u201d&nbsp;<a href=\"#fnref1\" rev=\"footnote\">\u21a9</a>\n\n</p></li></ol></div>", "user": {"username": "HoldenKarnofsky"}}, {"_id": "P3naccs98WWK4mFsL", "title": "Could Russia ukraine be pulling the wool over the west eyes?", "postedAt": "2023-02-23T19:44:20.087Z", "htmlBody": "<p>For 100's of years there has been battles going on in the baltics and what is now eastern europe and russia.</p>\n<p>Putin was seen as this very calculated man through out history in tell the ukraine invasion happened. The rest of the world feared what russia could do milatarly and the weapons capabilty that they have. How is something like that so miss judged . The cia and special forces operations have been studying them for years. Overitly and convertly .</p>\n<p>Im making this short and to the point and would like to hear others opinions on something i fear happening right under our noses and what others think the possibilty of it is ?</p>\n<p>Im worried with nato has russia's biggest enemy. And with us knowing the history of war. And how miss leading and false info is a weapon of war itself.\nWith ukraine under attack from putins russia , the world has jumped to ukraines help . Providing huge amounts of the worlds stockpiles of ammuntions and goods to tge eastern front. Knowing how closely realted ukraine is to russia is culture and people. Is it crazy to think in some twisted way putin could have a hand in ukraines government before all of this leading up to it and as we speak?</p>\n<p>If putin feared natos might and strength. Wouldnt it be smart to disarm them before taking them to battle ?\nAs he has proven in ukraine soldiers are a tool for him and he will throw away as much lives as he needs to move forward.  What happens if ukraine is depliting the worlds abilty to mount an offense in 3-4 years after they have sucked us dry of our protection and ability to defend ourself? What happens if china and russia decide at that point to begin there empiror building once again ? To me it seems very likely not only for the fact of weapons . But also in how the russian military has suxh a history of war and knowladge from past experiances . How could they blunder so bad?? How could there capabiltys for war be so grossly misscalcullated by the west ? None of it makes sense it a logical thinking stand point.</p>\n", "user": {"username": "Jazbingle"}}, {"_id": "ybA5g9CoG8ErdJfhp", "title": "New database for economics research", "postedAt": "2023-02-23T16:33:45.401Z", "htmlBody": "<p>Hi! We're thrilled to share the <a href=\"https://www.economicpossibility.org/\">Library of Economic Possibility (LEP)</a>, a new kind of knowledge-base for discovering, organizing, and sharing economic research around high-impact policies that have remained outside the mainstream despite significant research.</p><p>Options for discovering economics research today \u2014 especially for non-specialists \u2014 are clunky. Activists tend to cherry-pick, journalists don't have the room to present a wide range of evidence in a single article, academics share their work through papers and conferences that general audiences generally don't engage with, think tanks wind up burying research beneath article archives. Search functions on major databases aren't the greatest.</p><p>This is consequential in a moment where interest is rising around new economic ideas \u2014 LEP hopes to ground this rising interest in the wealth of existing evidence, and build a bridge between general audiences and economics research. We're also trying out a new way of organizing and connecting information.</p><p>We're passionate about debating what the next economic system might look like, but we're also nerds about information architecture, and LEP's search features reflect that. Bidirectional links create associative trails between the network of information, and advanced search filters let you mix &amp; match policies with specific areas of interest to hone in on precise relationships between information.</p><p>So if you're curious to learn more about how basic income might affect entrepreneurship, you can select the policy \"basic income\" and the tag \"entrepreneurship,\" and scroll through all our insights and sources that relate to both of those filters.</p><p>Or, you could select \"land value tax\" and \"urban development,\" or \"codetermination\" and \"innovation.\" You get the idea.</p><p>You can find those filters on the left column:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1677168598/mirroredImages/ybA5g9CoG8ErdJfhp/tn5krhnyd6voudvr1qam.gif\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1677168608/mirroredImages/ybA5g9CoG8ErdJfhp/bzgxpp94pz4vzbuswdn0.gif 200w, https://res.cloudinary.com/cea/image/upload/v1677168608/mirroredImages/ybA5g9CoG8ErdJfhp/kpgp3jtahpllsfa3uukr.gif 400w, https://res.cloudinary.com/cea/image/upload/v1677168598/mirroredImages/ybA5g9CoG8ErdJfhp/dvk7hs44v1l9xh9fwxls.gif 600w, https://res.cloudinary.com/cea/image/upload/v1677168609/mirroredImages/ybA5g9CoG8ErdJfhp/akapprq74147c4werfrj.gif 800w, https://res.cloudinary.com/cea/image/upload/v1677168610/mirroredImages/ybA5g9CoG8ErdJfhp/h4yhook5ux9rhywwygy2.gif 1000w, https://res.cloudinary.com/cea/image/upload/v1677168609/mirroredImages/ybA5g9CoG8ErdJfhp/tri7lazalxdtjihdljz2.gif 1200w, https://res.cloudinary.com/cea/image/upload/v1677168609/mirroredImages/ybA5g9CoG8ErdJfhp/vj2jdkf5cn2btybghzue.gif 1400w, https://res.cloudinary.com/cea/image/upload/v1677168608/mirroredImages/ybA5g9CoG8ErdJfhp/jywbiki4emzgqv8nfcuu.gif 1600w, https://res.cloudinary.com/cea/image/upload/v1677168609/mirroredImages/ybA5g9CoG8ErdJfhp/tp4vkonnro90osv3mtjf.gif 1800w, https://res.cloudinary.com/cea/image/upload/v1677168609/mirroredImages/ybA5g9CoG8ErdJfhp/vvo2yj6whpbbhup6f4zd.gif 1903w\"></figure><p>Our policy reports also use a nifty little feature we call \"insight cards.\" Any statistic or claim we use in a policy report is interactive, letting you pop open the card to see the source it come from, further context, the authors behind it, etc:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1677168598/mirroredImages/ybA5g9CoG8ErdJfhp/dahchbr7xfdgm3metzow.gif\" srcset=\"https://res.cloudinary.com/cea/image/upload/v1677168610/mirroredImages/ybA5g9CoG8ErdJfhp/ylbxozinwmac0g4krg2v.gif 200w, https://res.cloudinary.com/cea/image/upload/v1677168609/mirroredImages/ybA5g9CoG8ErdJfhp/x8l79tlesvco5f9745w5.gif 400w, https://res.cloudinary.com/cea/image/upload/v1677168598/mirroredImages/ybA5g9CoG8ErdJfhp/wkimoghs5c3dhjbsz25g.gif 600w, https://res.cloudinary.com/cea/image/upload/v1677168609/mirroredImages/ybA5g9CoG8ErdJfhp/o34ulaz7nckixvpnox3i.gif 800w, https://res.cloudinary.com/cea/image/upload/v1677168608/mirroredImages/ybA5g9CoG8ErdJfhp/wdzrcixzqs8i1wkjjxcu.gif 1000w, https://res.cloudinary.com/cea/image/upload/v1677168608/mirroredImages/ybA5g9CoG8ErdJfhp/l0nbjedrylvnnpio7wzv.gif 1200w, https://res.cloudinary.com/cea/image/upload/v1677168609/mirroredImages/ybA5g9CoG8ErdJfhp/epyzfl2lfweonzzhkazk.gif 1400w, https://res.cloudinary.com/cea/image/upload/v1677168609/mirroredImages/ybA5g9CoG8ErdJfhp/cukequ094lsfloxqbntg.gif 1600w, https://res.cloudinary.com/cea/image/upload/v1677168608/mirroredImages/ybA5g9CoG8ErdJfhp/gbajdntsmi5hl0vy2pxg.gif 1800w, https://res.cloudinary.com/cea/image/upload/v1677168618/mirroredImages/ybA5g9CoG8ErdJfhp/yusxyfmtbnobo7ufdhqz.gif 1912w\"></figure><figure class=\"image\"><img></figure><p>We have more information in our <a href=\"https://open.substack.com/pub/lepossibilities/p/introducing-library-of-economic-possibility?r=iprz&amp;utm_campaign=post&amp;utm_medium=web\">launch announcement</a> and <a href=\"https://twitter.com/LEPossibility/status/1628417598437175299?s=20\">Twitter thread</a>. Happy to hear any feedback or answer questions.</p>", "user": {"username": "Oshan Jarow"}}, {"_id": "5uZiBK4h5WcccjA2R", "title": "EA is too New & \nImportant to Schism", "postedAt": "2023-02-23T14:56:10.000Z", "htmlBody": "<p>As many of us have seen there has recently been a surge in discourse around people in the community with different views. Many of this underlying tension has only been brought about by large scandals that have broken in the last 6 months or so.</p><p>I've seen a few people using language which, to me, seems schismatic. Discussing how there are two distinct and incompatible groups within EA, being shocked/hurt/feeling rejected by the movement, etc. I'd like to urge us to try and find reconciliation if possible.</p><p>&nbsp;</p><h1>Influential Movements avoid Early Schisms</h1><p>&nbsp;</p><p>If you look through history at any major religious/political/social movements, most of them avoid having early schisms, or if they do, it creates significant issues and tension. It seems optimal to let movements develop loosely over time and become more diverse, before starting to draw hard lines between what \"is\" a part of the in group and what isn't.</p><p>For instance, early Christianity had some schisms, but nothing major until the <a href=\"https://en.wikipedia.org/wiki/First_Council_of_Nicaea\">Council of Nicea</a> in 325 A.D. This meant that Christianity could consolidate power/followers for centuries before actively breaking up into different groups.</p><p>Another parallel is the infamous <a href=\"https://en.wikipedia.org/wiki/Shia%E2%80%93Sunni_relations\">Sunni-Shia split in Islam</a>, which caused massive amounts of bloodshed and still continues to this day. This schism still echos today, for instance with the civil war in Syria.</p><p>For a more modern example, look at the <a href=\"https://en.wikipedia.org/wiki/New_Atheism#:~:text=The%20term%20New%20Atheism%20was,should%20not%20simply%20be%20tolerated.\">New Atheism Movement</a> which in many ways attracted similar people to EA. Relatively early on in the movement, in fact right as the movement gained popular awareness (similar to the moment right now in EA) many prominent folks in New Atheism advocated for <a href=\"https://rationalwiki.org/wiki/Atheism_Plus.\">New Atheism Plus</a>. This was essentially an attempt to schism the movement along cultural / social justice lines, which quickly eroded the cohesion of the movement and ultimately contributed to its massive decline in relevance.</p><p>Effective Altruism as a movement is relatively brand new - we can't afford major schisms or we may not continue as a relevant cultural force in 10-20 years.</p><p>&nbsp;</p><h1>Getting Movement Building Right Matters</h1><p>Something which I think is sometimes lost in community building discussions is that <i>the stakes we're playing for are extremely high.</i> My motivation to join EA was primarily because I saw major problems in the world, and people that were extremely dedicated to solving them. We are playing for the future, for the survival of the human race. We can't afford to let relatively petty squabbles divide us too much!</p><p>Especially with advances in AGI, I know many people in the movement are more worried than ever that we will experience significant shifts via technology over the coming decades. Some have pointed out the possibility of <a href=\"https://forum.effectivealtruism.org/topics/value-lock-in#:~:text=Value%20lock%2Din%20is%20a,can%20no%20longer%20be%20altered.\">Value Lock-in</a>, or that as we rapidly increase our power our values may become stagnant, especially if for instance an AGI is controlled by a group with strong, anti-pluralistic values.</p><p>Overall I hope to advocate for the idea of reconciliation within EA. We should work to disentangle our feelings from the future of the movement, and try to discuss how to have the most impact as we grow. My vote is that having a major schism is one of the worst things we could do for our impact - and is a common failure mode we should strive to avoid.&nbsp;</p>", "user": {"username": "Wil Perkins"}}, {"_id": "36xmKk4fXYTptfFXy", "title": "How can we improve discussions on the Forum?", "postedAt": "2023-02-23T00:42:35.302Z", "htmlBody": "<p>I\u2019d like to run&nbsp;<a href=\"https://docs.google.com/forms/d/e/1FAIpQLScNmN1_XFffYJFucU5gUun9NuzZF5lZR_6m6-FskDHDph7pjA/viewform?usp=sf_link\"><u>a very rough survey</u></a> to get a better sense of:&nbsp;</p><ul><li>How you feel about the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/wvBfYnNeRvfEXvezP/moving-community-discussion-to-a-separate-tab-a-test-we\"><u>Frontpage change we\u2019re currently testing</u></a></li><li>What changes to the site \u2014 how it's set up and organized \u2014 you think could help us have discussions better</li><li>What conversations you'd like to see on the Forum</li><li>And more</li></ul><figure class=\"table\"><table><tbody><tr><td style=\"background-color:#b6d7a8;border:1pt solid #000000;padding:5pt;vertical-align:top\"><a href=\"https://docs.google.com/forms/d/e/1FAIpQLScNmN1_XFffYJFucU5gUun9NuzZF5lZR_6m6-FskDHDph7pjA/viewform?usp=sf_link\"><u>Give us your input</u></a></td></tr></tbody></table></figure><p><br>&nbsp;</p>", "user": {"username": "Lizka"}}, {"_id": "AnBFFShKAfY9bBEmG", "title": "Biosecurity Happy Hour - EAG Bay Area 2023", "postedAt": "2023-02-23T00:03:34.315Z", "htmlBody": "<p>Meet other EAG Bay Area attendees interested in biosecurity and pandemic preparedness!</p>\n<p>This will be a happy hour hosted at <a href=\"https://www.firsteditionoakland.com/\">First Edition</a>, a bar near the Marriott (21+, with apologies to all the cool youth who this excludes).</p>\n<p>Drinks will be covered, as will some food from <a href=\"https://xolotaqueria.com/\">Xolo Taqueria</a>.</p>\n", "user": {"username": "tessa"}}, {"_id": "EkQxru8pkA8hiePGT", "title": "Family Planning mHealth Intervention - Initial Research by Lafiya Nigeria", "postedAt": "2023-02-22T23:59:20.863Z", "htmlBody": "<h1><strong>Problem</strong></h1><p>Each year more than&nbsp;<a href=\"https://contraceptionmedicine.biomedcentral.com/articles/10.1186/s40834-016-0021-6\"><u>220 million women</u></a> worldwide have an unmet need for contraception, resulting in over&nbsp;<a href=\"https://www.guttmacher.org/report/adding-it-up-investing-in-sexual-reproductive-health-2019\"><u>300,000 maternal deaths</u></a> from pregnancy-related complications. Unmet need for family planning can be&nbsp;<a href=\"https://www.guttmacher.org/sites/default/files/report_pdf/unmet-need-for-contraception-in-developing-countries-report.pdf\"><u>attributed</u></a> to insufficient knowledge about family planning and access to family planning services.&nbsp;</p><p>During our pilot program in 2022, we noticed that this problem is only more prevalent among rural women. Rural women in Nigeria have fewer years of education, lower income, and worse health outcomes than their&nbsp;<a href=\"https://nigerianstat.gov.ng/download/1241062\"><u>urban counterparts</u></a>. The prevailing barriers to access family planning information and services faced particularly by rural women are: lack of trained medical personnel, stockouted healthcare facilities located far from their communities. For example, Kebbi state has only&nbsp;<a href=\"https://www.nigerianstat.gov.ng\"><u>144 doctors</u></a> to support the population of over 5 million people, which translates to 1 doctor per every 50,000; a far cry from the&nbsp;<a href=\"https://apps.who.int/iris/bitstream/handle/10665/43432/9241563176_eng.pdf?sequence=1&amp;isAllowed=y\"><u>WHO recommended figure</u></a> of 1 doctor per every 1000 people.</p><p>Lafiya Nigeria offers in-person family planning counselling and administration of contraceptives free of charge. This model has proven to be&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1MCuX7X4GdpRRl57BvYwvy8LFAULBHUJWzPRyYalSlPI/edit?usp=sharing\"><u>highly cost-effective</u></a> and is currently replicated in another state. However, we have identified one missing part of the solution - an mHealth component that can be used to offer educational information about sexual and reproductive health, send reminders for next doses of contraception, connect patients with the locations of family planning service providers, and provide up-to-date information about the stock levels. We believe that an mHealth component has a potential to become a key part of our comprehensive solution for a cost-effective family planning solution.</p><h1><strong>Evidence&nbsp;</strong></h1><p><a href=\"https://www.worldbank.org/en/publication/wdr2016\"><u>The proliferation of mobile phone ownership</u></a> in LMICs has enabled digital technologies to provide&nbsp;<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4738182/\"><u>family health information</u></a> among users living in hard-to-reach areas. Mobile health solutions have been found to&nbsp;<a href=\"http://documents1.worldbank.org/curated/en/751411468157784302/pdf/726040WP0Box370th0report00Apr020120.pdf\"><u>reduce costs of health care</u></a> whilst improving the quality of care. The evidence has been so robust that it has resulted in the WHO releasing&nbsp;<a href=\"https://www.who.int/reproductivehealth/publications/digital-interventions-health-system-strengthening/en/\"><u>the guideline</u></a>&nbsp;<i>Recommendations on Digital Interventions for Health System Strengthening&nbsp;</i>and endorsing the use of mobile health technologies in interventions targeting communities in LMICs.</p><p>The previous uses of mHealth family planning platforms showed their&nbsp;<a href=\"https://pubmed.ncbi.nlm.nih.gov/25359391/\"><u>effectiveness</u></a> in the increase of the contraceptive uptake. The users of mHealth platforms could&nbsp;<a href=\"https://pubmed.ncbi.nlm.nih.gov/25582097/\"><u>seek information about</u></a> family planning and related resources from the comfort of their home rather than going to a clinic or a health care provider.&nbsp;</p><p>Family planning mHealth interventions have shown promising results across different demographic and geographies, adopting unique solutions to best match the needs of the targeted communities:</p><ul><li><a href=\"https://gh.bmj.com/content/7/4/e007862\"><u>A study of SMS reminders encouraging women in urban Mozambique</u></a> to use family planning services showed that text message reminders are a promising nudge that increases the probability that women receive contraception.</li><li><a href=\"http://ijcat.org/IJCAT-2020/7-7/Monitoring-and-Data-Management-of-Participants-of-Family-Planning-Program-With-SMS-Reminder.pdf\"><u>A study of SMS reminders encouraging families in Indonesia</u></a> to use family planning services has showed the importance of text reminders on improved results of contraceptive usage.</li><li><a href=\"https://pubmed.ncbi.nlm.nih.gov/35433014/\"><u>A study analysing program data and promotional approaches</u></a> to inform best practices from a mobile phone-based reproductive health message program in Afghanistan highlighted SMS blast promotions as one of the most effective strategies</li><li><a href=\"https://pubmed.ncbi.nlm.nih.gov/34766908/\"><u>A formative study of mobile phone use for family planning among young people in Sierra Leone</u></a> showed that SMS was the scalable channel for demand creation</li><li><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0010782416301639?utm_campaign=c198440160-SHOPS%20research%20studies%20email_COPY_01&amp;utm_medium=email&amp;utm_source=Communications%20Team&amp;utm_term=0_390c2d04bb-c198440160-80082837\"><u>An RCT of the impact of a family planning mHealth service</u></a> in Kenya found that a mobile messaging service significantly improved knowledge of family planning among consumers. The data shows an increase in knowledge&nbsp;<a href=\"https://pdf.usaid.gov/pdf_docs/PA00M11P.pdf\"><u>by 13%</u></a>.</li><li><a href=\"https://pubmed.ncbi.nlm.nih.gov/33463875/\"><u>A study of impact on mHealth on contraceptive usage in LMICs</u></a> collected evidence to suggest that mobile phone interventions utilising behavioural change technique are an effective method of increasing modern contraceptive use.</li><li><a href=\"https://healthcommcapacity.org/wp-content/uploads/2017/10/Evaluation-of-Smart-Couple_FINAL-FINAL.pdf\"><u>A study of the effects of a digital health tool (</u><i><u>Smart Couple</u></i><u>)</u></a> among couples of reproductive age in Kaduna City in Nigeria showed that modern method use increased significantly from 36% to 50% among women and from 35% to 41% among men.</li><li><a href=\"https://healthcommcapacity.org/wp-content/uploads/2017/10/Evaluation-of-the-Effects-of-the-Smart-Client-Digital-Health-Tool_FINAL-FINAL.pdf\"><u>A study of the effects of the smart client digital health tool</u></a> among women of reproductive age in Kaduna city in Nigeria showed that a significant increase in modern contraceptive use.</li><li><a href=\"https://reproductive-health-journal.biomedcentral.com/articles/10.1186/s12978-015-0112-x\"><u>A study of the development of a mHealth intervention to support post-abortion family planning in Cambodia</u></a> showed a significant increase in contraceptive usage between the intervention and control group at 4 months.</li><li><a href=\"https://www.teikyomedicaljournal.com/volume/TMJ/46/01/mobile-health-intervention-for-contraceptive-initiation-in-reproductive-aged-women-a-systematic-review-and-meta-analysis-63d645fdd5b03.pdf\"><u>A systematic review and meta-analysis of mobile health intervention</u></a> for contraceptive use showed that mHealth intervention significantly improves contraceptive use, particularly app-based intervention as compared to text-based one.</li><li><a href=\"https://www.frontiersin.org/articles/10.3389/fsoc.2022.886548/full\"><u>A qualitative study in peri-urban Nairobi on the use of digital media</u></a> for family planning information showed that women felt more comfortable sharing FP information in digital spaces due to greater privacy and reduced stigma.</li><li><a href=\"https://europepmc.org/article/pmc/pmc5994467\"><u>A feasibility study on providing support to pregnant women and new mothers</u></a> through moderated WhatsApp groups found that participants of a mobile-based support group reported a higher rate of postpartum long acting reversible contraception uptake than the general patient population.</li></ul><p>There is a strong evidence base that mHealth interventions can result in the significant increase in contraceptive uptake. The level of impact achieved depends on the exact program design and the needs of the targeted demographic.&nbsp;</p><h1><strong>Solution</strong></h1><p>Lafiya Nigeria team has identified the existing gaps in the current family planning landscape and the potential of a well-designed mHealth component to address the barriers faced by women with unmet need for contraception. An example of a mHealth solution within the existing Lafiya Nigeria model could fulfil some or all of the following functions:</p><ol><li>It would act as a <strong>first level of a client funnel by reaching women with an unmet need for contraception</strong>. The service would provide a dual role for new users:&nbsp;<br>(i) offer information about family planning options, side effects, and benefits;<br>(ii) connect them with a Lafiya Sister or another healthcare provider located nearby to facilitate the access to an in-person family planning counselling.<br><br>Our team has some initial ideas in regards to social marketing strategies that could be used to spread the awareness of the tool among the targeted communities by leveraging female only networks in rural areas.&nbsp;<br>&nbsp;</li><li>It would send <strong>reminders to the existing users of Lafiya Nigeria program</strong> to notify them about the timing of their next dose. Lafiya Nigeria is currently focusing on the distribution of DMPA-SC, which needs to be reinjected every 13 weeks for continued usage; however, the reminders could also be sent to users of other types of contraceptives requiring regular visits.&nbsp;<br>&nbsp;</li><li>It would provide <strong>up-to-date information about the level of stock of different family planning products</strong> located in nearby health care clinics, allowing women to make an autonomous choice of their preferred contraceptive option.<br><br>This version of an mHealth solution would require working closely with the state governments to ensure that there is an effective management of health data across clinics and providers. Our team has a strong working relationship with the government and could leverage that to build a comprehensive solution, addressing both the gaps in knowledge about family planning and the availability of products and trained medical personnel.&nbsp;</li></ol><h2>Theory of Change</h2><p>The following theory of change shows the impact of an mHealth component of the Lafiya Nigeria model.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677110362/mirroredImages/EkQxru8pkA8hiePGT/hmhji84vbqysdb8folew.png\"></p><h1><strong>Updates and plans</strong></h1><p>The initial research on this idea has demonstrated a strong evidence base and a good organisational fit to solve the problem. This fit comes from a successful pilot project that Lafiya Nigeria rolled out, culminating in:</p><p>(i) a database of rural Nigerian women with the unmet demand for contraception;</p><p>(ii) a network of health providers across different clinics and health facilities in over 60% of LGAs within targeted states;</p><p>(iii) strong relationships with the Ministry of Health on state and federal level;</p><p>(iv) an experienced and dedicated team with a proven track record of delivering global health interventions.&nbsp;</p><h2>Activities conducted</h2><p>The Lafiya Nigeria team has conducted an initial round of expert interviews from IDInsights and Center for Global Development; and practitioners of mobile-based interventions from India (Suvita) and Kenya (M-Schule).&nbsp;</p><p>Those interviews have given us a good starting point to evaluate existing tools and identify any technological challenges this project would entail. We have also recruited volunteers with backgrounds in programming and software development from Stanford and Berkeley to bridge the capability gap within our team.</p><h2>Next steps</h2><p>Our team will now conduct deeper analysis of the identified solutions, including assessing their feasibility, building a cost-effectiveness model, and conducting initial conversations with the state governments to understand how this project would align with their current priorities.&nbsp;</p><p>To identify the features and format of the tool, we are seeking to answer the following questions:</p><ol><li>Who is the targeted demographic (urban/rural, age, level of literacy) at scale?</li><li>What is the preferred channel for this solution (SMS, Whatsapp, chatbot, app)? What is the cost and feasibility of developing a solution using this channel?</li><li>What are the human capital gaps within the team to develop and manage this tool?</li><li>What is the most impactful use case of this tool for our users?</li><li>What is the vision for scaling this solution across the country?</li><li>How does this project align with the priorities of the Nigerian Ministry of Health on the federal and state level?</li><li>Can this solution be used in other interventions beyond Lafiya Nigeria? Which stakeholders would be interested in paying to adopt, adapt, and scale this solution in other contexts?</li><li>What is the cost-effectiveness of this tool and its forecasted impact on reducing maternal mortality?</li><li>What is the success metric of this tool and how can it be measured on the pilot level?&nbsp;</li></ol><p>We anticipate adding more follow-up and detailed questions as we conduct our in-depth research.</p><h1><strong>How you can help</strong></h1><p>If you are interested in this cause area and would like to support this project, you can help in three ways:</p><ol><li>We are looking for technical experts with experience in mHealth interventions, particularly in the context of LMICs, to provide feedback and expertise to support the development of this project.&nbsp;</li><li>We are looking for volunteers to share with us their time to conduct further research. Individuals with experience in mobile interventions.</li><li>Since we are still evaluating the exact rollout of the programme, we are putting together different scenarios of how the tool would impact our base-case budget. We are seeking <a href=\"https://give.lafiyanigeria.org/\">funding</a> to aid us to move ahead from desk research to an MVP, after our deep-dive research.</li></ol>", "user": {"username": "Klau"}}, {"_id": "jXyJhSpZ4PmkKzW3A", "title": "How do you feel? No discourse allowed", "postedAt": "2023-02-22T22:51:46.746Z", "htmlBody": "<p>I am feeling lots of feelings and I guess you are too.&nbsp;</p><p>I have been frustrated that lots of the posts over the last few days have either felt emotional in a way that has to be argued around or cold.</p><p>So, how do you feel? We aren't going to discuss whether feelings are reasonable or not. We are just gonna express how we feel and listen. Feel free to write from burners.</p><p>I sense this space could become too vulnerable, so only comment if you want other people to hear how you feel. We are all adults.</p><p><i>I will delete comments about feelings of a sexual nature. That is not the space I want.</i></p>", "user": {"username": "nathan"}}, {"_id": "uk4QhagWD8mj8rnst", "title": "Enemies vs Malefactors", "postedAt": "2023-02-28T23:38:11.575Z", "htmlBody": "<p><em>Status: some mix of common wisdom (that bears repeating in our particular context), and another deeper point that I mostly failed to communicate.</em></p>\n<h2>Short version</h2>\n<p>Harmful people often lack explicit malicious intent. It\u2019s worth deploying your social or community defenses against them anyway. I recommend focusing less on intent and more on patterns of harm.</p>\n<p>(Credit to my explicit articulation of this idea goes in large part to Aella, and also in part to Oliver Habryka.)</p>\n<h2>Long version</h2>\n<p>A few times now, I have been part of a community reeling from apparent bad behavior from one of its own. In the two most dramatic cases, the communities seemed pretty split on the question of whether the actor had ill intent.</p>\n<p>A recent and very public case was the one of Sam Bankman-Fried, where many seem interested in the question of Sam's mental state vis-a-vis EA. (I recall seeing this in the responses to <a href=\"https://www.vox.com/future-perfect/23462333/sam-bankman-fried-ftx-cryptocurrency-effective-altruism-crypto-bahamas-philanthropy\">Kelsey's interview</a>, but haven't done the virtuous thing of digging up links.)</p>\n<p>It seems to me that local theories of Sam's mental state cluster along lines very roughly like (these are phrased somewhat hyperbolically):</p>\n<ol>\n<li>Sam was explicitly malicious. He was intentionally using the EA movement for the purpose of status and reputation-laundering, while personally enriching himself. If you could read his mind, you would see him making conscious plans to extract resources from people he thought of as ignorant fools, in terminology that would clearly relinquish all his claims to sympathy from the audience. If there were a camera, he would have turned to it and said \"I'm going to exploit these EAs for everything they're worth.\"</li>\n<li>Sam was committed to doing good. He may have been ruthless and exploitative towards various individuals in pursuit of his utilitarian goals, but he did not intentionally set out to commit fraud. He didn't conceptualize his actions as exploitative. He tried to make money while providing risky financial assets to the masses, and foolishly disregarded regulations, and may have committed technical crimes, but he was trying to do good, and to put the resources he earned thereby towards doing even more good.</li>\n</ol>\n<p>One hypothesis I have for why people care so much about some distinction like this is that humans have social/mental modes for dealing with people who are <em>explicitly</em> malicious towards them, who are <em>explicitly</em> faking cordiality in attempts to extract some resource. And these are pretty different from their modes of dealing with someone who's merely being reckless or foolish. So they care a lot about the mental state behind the act.</p>\n<p>(As an example, various crimes legally require <em>mens rea</em>, lit. \u201cguilty mind\u201d, in order to be criminal. Humans care about this stuff enough to bake it into their legal codes.)</p>\n<p>A third theory of Sam\u2019s mental state that I have\u2014that I credit in part to Oliver Habryka\u2014is that reality just doesn\u2019t cleanly classify into either maliciousness or negligence.</p>\n<p>On this theory, most people who are <em>in effect</em> trying to exploit resources from your community, won't be explicitly malicious, not even in the privacy of their own minds. (Perhaps because the content of one\u2019s own mind is just not all that private; humans are in fact pretty good at inferring intent from a bunch of subtle signals.) Someone who <em>could</em> be exploiting your community, will often <em>act so as</em> to exploit your community, while internally telling themselves lots of stories where what they're doing is justified and fine.</p>\n<p>Those stories might include significant cognitive distortion, delusion, recklessness, and/or negligence, and some perfectly reasonable explanations that just don't quite fit together with the other perfectly reasonable explanations they have in other contexts. They might be aware of some of their flaws, and explicitly acknowledge those flaws as things they have to work on. They might be legitimately internally motivated by good intent, even as they wander down the incentive landscape towards the resources you can provide them. They can sub- or semi-consciously mold their inner workings in ways that avoid tripping your malice-detectors, while still managing to exploit you.</p>\n<p>And, well, there\u2019s mild versions of the above paragraph that apply to almost everyone, and I\u2019m not sure how to sharpen it. (Who among us doesn\u2019t subconsciously follow incentives, and live under the influence of some self-serving blind spots?)</p>\n<p>But in the cases that dramatically blow up, the warp was strong enough to create a variety of <a href=\"https://forum.effectivealtruism.org/posts/BNKBJs4RJsA8FtdWE/a-personal-reflection-on-sbf\">advance warning signs</a> that are obvious to hindsight. But also, yeah, it\u2019s a matter of degree. I don\u2019t think there\u2019s a big qualitative divide, that would be stark and apparent if you could listen in on private thoughts.</p>\n<hr>\n<p>People do sometimes encounter adversaries who are explicitly malicious towards them. (For a particularly stark example, consider an enemy spy during wartime.) Spies and traitors and turncoats are real phenomena. Sometimes, the person you're interacting with really is treating you as a device that they're trying to extract information or money from; explicit conscious thoughts about this are really what you'd hear if you could read their mind.</p>\n<p>I also think that that's not what most of the bad actors in a given community are going to look like. It's easy, and perhaps comfortable, to say \"they were just exploiting this community for access to young vulnerable partners\" or \"they were just exploiting this community for the purpose of reputation laundering\" or whatever. But in real life, I bet that if you read their mind, the answer would be far messier, and look much more like they were making various good-faith efforts to live by the values that your community professes.</p>\n<p>I think it's important to acknowledge that fact, and build community processes that can deal with bad actors <em>anyway.</em> (Which is a point that I attribute in large part to Aella.)</p>\n<p>There's an analogy between the point I'm making here, and the one that Scott Alexander makes in <a href=\"https://astralcodexten.substack.com/p/the-media-very-rarely-lies\">The Media Very Rarely Lies*</a>. Occasionally the media will literally fabricate stories, but usually not.</p>\n<p>If our model is that there's a clear divide between people who are literally fabricating and people who are \"merely\" twisting words and bending truths, and that we mostly just have to worry about the former, then we'll miss most of the harm done. (And we\u2019re likely to end up applying a double standard to misleading reporting done by our allies vs. our enemies, since we\u2019re more inclined to ascribe bad intentions to our enemies.)</p>\n<p>There's some temptation to claim that the truth-benders have crossed the bright red line into \"lying\", so that we can deploy the stronger mental defenses that we use against \"liars\".</p>\n<p>But... that's not quite right; they <em>aren't</em> usually crossing that bright red line, and the places where they do cross that line aren\u2019t necessarily the places where they\u2019re misleading people the most. If you tell people to look out for the bright red line then you'll fail to sensitize them to the actual dangers that they're likely to face. The correct response is to <em>start deploying stronger defenses against people who merely bend the truth.</em></p>\n<p>(Despite the fact that lots of people bend the truth sometimes, like when their mom asks them if they\u2019ve stopped dating blue-eyed people yet while implicitly threatening to feel a bunch of emotional pain if they haven\u2019t, and they <em>technically</em> aren\u2019t dating anyone right now (but of course they\u2019d still date blue-eyed people given the opportunity) so they say \u201cyes\u201d. Which still counts as bending the truth! And differs only by a matter of degree! But which does not deserve a strong community response!)</p>\n<p>(Though people do sometimes <a href=\"https://forum.effectivealtruism.org/posts/2eotFCxvFjXH7zNNw/people-will-sometimes-just-lie-about-you\">just make shit up</a>, as is a separate harsh lesson.)</p>\n<p>I think there's something similar going on with community bad actors. It's tempting to imagine that the local bad actors crossed bright red lines, and somehow hid that fact from everybody along the way; that they were mustache-twirling villains who were intentionally exploiting you while cackling about it in the depths of their mind. If that were true, it would activate a bunch of psychological and social defense mechanisms that communities often try to use to guard against bad actors.</p>\n<p>But... historically, I think our bad actors <em>didn't</em> cross those bright red lines in a convenient fashion. And I think we need to be deploying the stronger community defenses <em>anyway.</em></p>\n<p>I don't really know how to do that (without causing a bunch of collateral damage from false positives, while not even necessarily averting false negatives much). But I hereby make a bid for focusing less on whether somebody is intentionally malicious.</p>\n<p>I suggest minting a new word, for people who have the <em>effects</em> of malicious behavior, whether it's intentional or not. People who, if you step back and look at them, seem to leave a trail of misery in their wake, or a history of recklessness, or a pattern of negligence.</p>\n<p>It's maybe fun to debate about whether they had <em>mens rea</em>, and the courts might care about the <em>mens rea</em> after it all blows up, but from <em>our</em> perspective, the main question is what behaviors they\u2019re likely to engage in, and there turn out to be many really bad behaviors that don\u2019t require malice at all.</p>\n<p>I don't have any terminological suggestions that I love. My top idea so far is to repurpose the old word \"malefactor\" for someone who has a pattern of ill effects, regardless of their intent. (This in contrast with \"enemy\", which implies explicit ill intent.)</p>\n<p>And for lack of a better word, I\u2019ll suggest the word \u201cmaleficence\u201d to describe the not-necessarily-malevolent mental state of a malefactor.</p>\n<p>I think we should basically treat discussions about whether someone is malicious as recreation (when they do not explicitly have documentation of being a literal spy/traitor/etc., nor identify as an enemy), and I think that maleficence is what matters when deploying community (or personal) defense mechanisms.</p>\n", "user": {"username": "So8res"}}, {"_id": "fP47S7Kx2pRjoiZNW", "title": "The University Specialist - an EA Sweden community building trial", "postedAt": "2023-02-23T08:30:37.711Z", "htmlBody": "<h1><strong>TL;DR</strong></h1><ul><li>EA Sweden tried a University Specialist role in March-December 2022 for supporting university groups in the Stockholm region.</li><li>In supporting university groups, I recommend EA Sweden to:<ul><li>make sure groups organize intro lectures and participate at welcome fairs at the start of academic years;</li><li>implement routines for inducting new organizers;</li><li>communicate regularly with group organizers and ensure good succession;</li><li>make sure bigger events catered to students are organized once a year;</li><li>disseminate engagement opportunities directly to groups;&nbsp;</li><li>organize intro fellowships and career courses and develop clearer learning criteria for both;</li><li>define what success looks like for groups and review group support accordingly;</li><li>systematize university marketing/outreach.&nbsp;</li></ul></li><li>I think the University Specialist counterfactually contributed to an increased member count (15 \u2192 22) in the Stockholm region and making two student groups more independent, but that EA Sweden would not get much value from having a University Specialist at the moment.&nbsp;</li><li>Having a University Specialist in a city or national group could help get to know student groups better, and make it easier to oversee the quality of their work, whilst not compromising the comparative advantage of the city or national group.&nbsp;</li><li>If hard-pressed, I would name \"organizing intro fellowships and/or career courses\" as the most effective of my recommendations. However, EA Sweden could think more about how to support university groups in developing a community structure in which members can engage and thrive, in addition to drawing new people in.</li></ul><p><strong>Epistemic status:</strong> This post is mostly a data point in the EA community building pursuit.&nbsp;<strong>All conclusions are based on intuition, aided by sparse data</strong> - both acquired during a short time period. Also, this post assumes that students are an appropriate target audience for community building efforts.</p><p><strong>Intended audience:&nbsp;</strong>Anyone involved with supporting student groups, involved in national groups or city groups with multiple universities, or curious readers. Observe that the report on which this post is based makes recommendations&nbsp;<strong>for EA Sweden</strong>. Any generalizations to other groups should be made having their specific context (e.g. cultural, practical) in mind.&nbsp;</p><p><i>This post was written partly during my employment with EA Sweden. The views in this post, however, represent my own.&nbsp;</i></p><hr><h1><strong>Introduction</strong></h1><p>EA Sweden, the national EA group in Sweden, supports the country\u2019s eight local groups, all but one of which are university groups<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefezg8vouwpj\"><sup><a href=\"#fnezg8vouwpj\">[1]</a></sup></span>(I will use \u201cuniversity group\u201d and \u201cstudent group\u201d interchangeably). During March-December 2022, EA Sweden tried out having a&nbsp;<i>University Specialist&nbsp;</i>(USp)&nbsp;<strong>supporting university groups in the Stockholm region</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref4sgzjf15lpo\"><sup><a href=\"#fn4sgzjf15lpo\">[2]</a></sup></span>, to see what value, if any, there would be having a separate person on the team with this responsibility. This position was held by me and partly by Robert Praas.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefs2t4lgzhgic\"><sup><a href=\"#fns2t4lgzhgic\">[3]</a></sup></span>&nbsp;As part of my exit, I wrote&nbsp;<a href=\"https://docs.google.com/document/d/1MXTuWI9EuqC3J6QEOsJJnnyEAjCeDsjVtQcl6JxnJSg/edit#\"><u>a report</u></a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefyafg6p2ju4a\"><sup><a href=\"#fnyafg6p2ju4a\">[4]</a></sup></span>&nbsp;reflecting on this question and made some general<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsrd1wccd8ap\"><sup><a href=\"#fnsrd1wccd8ap\">[5]</a></sup></span>&nbsp; recommendations for supporting university groups based on what activities led to the best ROI, and what I thought could be improved. This post is a shortened version of that report.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzjdhua74j4\"><sup><a href=\"#fnzjdhua74j4\">[6]</a></sup></span></p><h2><i>What did the USp do during March-December 2022?</i></h2><p>I and Robert had together with two other community members been tasked to reboot the university group at KTH in the autumn of 2021 which still, at the time, was one of the more active of four groups in the region. When we transitioned to the role of University Specialists, we kept the focus on the KTH group to (1) develop an internal \u201cproof-of-concept\u201d before supporting other groups, and (2) make sure that the KTH group would be left in good shape until both I and Robert would leave in June. Together with the group, we set up weekly project sessions and organized a team retreat and other social events. Together with two of the other three groups, we also helped organize an&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/MT4mCqmNuj4qa6Bhc/stockholm-student-hackathon-lessons-for-next-time\"><u>Impact Hackathon</u></a>.</p><p>We also spent time laying the groundwork for the fall, e.g. identifying and talking to potential new organizers, and designing an overall strategy which was implemented as below:</p><ul><li>1) Participate at university welcome fairs to market student groups and the events 2-4,</li><li>2) Organize introduction lectures at relevant universities,</li><li>3) Organize an introduction fellowship for all groups,</li><li>4) Organize a high impact career course for all groups.</li></ul><h1><strong>Recommendations to EA Sweden for supporting university groups</strong></h1><p>In general, these recommendations are weakly held due to the limited data on which they are based, and I encourage EA Sweden to continue experimenting with group support activities. I have numbered the recommendations in order of importance.</p><p><i>1) Make sure</i><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref82efhbiprbu\"><sup><a href=\"#fn82efhbiprbu\">[7]</a></sup></span><i>&nbsp;intro lectures are organized and at the start of academic years;</i></p><p><i>8) Make sure university groups are present at university welcome fairs at the start of academic years;</i></p><p>A lunch lecture is a great opportunity to do high-fidelity EA communications - we reached 150 students with 5 lectures, with ~7% of the audience taking further action. Similarly,&nbsp;<strong>welcome fairs attract students when they are extra open-minded and information-seeking</strong>. For the two I was present on, each group received ~100 sign-ups to their mailing lists. The benefits of outreach during the start of academic years have been stated elsewhere on this forum.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreff0dkdivpd7q\"><sup><a href=\"#fnf0dkdivpd7q\">[8]</a></sup></span>&nbsp;However, planning for activities during this time is often done before or during the summer, which is difficult for new or rebooted groups, in which case EA Sweden can help.&nbsp;</p><p><i>2) Implement routines for inducting new organizers, including relevant community building resources and guidance for activity plans;</i></p><p>Routine induction meetings with new (lead) organizers are a low-cost way for EA Sweden to:</p><ul><li>begin the relationship with new organizers on a positive and professional note;</li><li>ensure high-fidelity communication around EA ideas (as organizers will work with communicating it further);</li><li>ensure that the group knows what they want to accomplish and how they could do it, and that they have the resources to do it - a good way to do this is to encourage groups to take CEA\u2019s&nbsp;<a href=\"https://centreforeffectivealtruism.notion.site/University-Group-Accelerator-Program-6df8c8fccf8b4ffbb6488d9dfa275282\"><u>University Group Accelerator Program (UGAP)</u></a>.</li></ul><p><i>3) Be in regular touch with university groups and ensure their continued existence (if relevant and sustainable), e.g. by keeping an eye on annual meetings and ensuring good succession;</i></p><p>In Sweden, most university groups are student associations, meaning that they have a board of directors who are re-elected once a year at an annual meeting. I think&nbsp;<strong>ensuring the continuation of a group is important for the future growth</strong> of its presence on campus. As the continuity of EA Sweden is more robust than that of groups, they are well suited to support groups in electing a new board (e.g. by nudging potential organizers) and ensuring that a handover occurs. It may make more sense to reboot a group if there are not sufficiently many organizers who can or want to continue, rather than trying to convince people to stay just to keep the group \u201calive\u201d. In general, regular communication easens support (e.g. contact via text/calls/lunch once a week/month/quarter) and keeps EA Sweden updated on the groups\u2019 progress.&nbsp;</p><p><i>4) Make sure one bigger event for university students is organized each year;</i></p><p>In May, the USp supported a couple of the student groups to organize an&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/MT4mCqmNuj4qa6Bhc/stockholm-student-hackathon-lessons-for-next-time\"><u>Impact Hackathon</u></a>, where thirty participants met up for a whole day, formed teams, and came up with ideas for solving some of the world\u2019s most pressing problems. It seems to me that the most important outcome of this event was the post-event engagement of seven of the thirty participants, who went on to do intro fellowships, career courses, and/or engage in local groups. I dare to hypothesize that organizing bigger events like this (compared to e.g. a weekly book club) where&nbsp;<strong>participants are directly engaged in the pursuit of doing good in some way together with others</strong> can be great catalysts for engagement as well as creating positive associations with effective altruism (which I think it deserves!).&nbsp;</p><p><i>5) Continuously disseminate local and global engagement opportunities directly to student groups and other groups who have previously shown interest in EA-related material.&nbsp;</i></p><p>When marketing our intro fellowship, career course, and EAGxRotterdam, I found the following to be the most effective outreach method (compared to e.g. general social media marketing):</p><ol><li>Messaging student group organizers and asking them to forward the opportunity to their mailing lists, and&nbsp;</li><li>Sending catered emails to groups of applicants/participants of previous programs/courses.</li></ol><p>Of the 150 people reached this way, around ~15% ended up applying for either the courses or the conference, or both. On another note, hosting digital preparation workshops before EAG(x) conferences seems to be a valuable low-cost community building tool in itself.&nbsp;</p><p><i>6) Organize in-person intro fellowships at least once a year (if groups are unable to);</i></p><p><i>7) Organize in-person career courses at least once a year;</i></p><p><i>11) Develop clearer learning criteria for evaluation for both courses and iterate on data collection using the reports from 2022 as a basis.</i></p><p>I think courses are great community building tools, but they can potentially be too heavy to organize for university groups, in which case a USp could assist them with e.g. facilitation, logistics, and applications. EA Sweden independently organized both an intro fellowship and a career course primarily targeted to students, both of which were well received. However, the exact learnings of participants were unclear.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7ea3ctosqzg\"><sup><a href=\"#fn7ea3ctosqzg\">[9]</a></sup></span>&nbsp;I think&nbsp;<strong>we want to make sure participants actually update their worldview</strong>, in addition to having enjoyable intellectual discussions with like-minded people (which seemed to constitute a big part of their satisfaction, although this is also a good thing).&nbsp;</p><p><i>9) Define what success looks like for local groups and in the context of EA Sweden\u2019s strategy, and develop relevant ways of evaluating group support accordingly;</i></p><p>When are groups \u201csuccessful\u201d? It varies, but at least&nbsp;<strong>having a definition I think can help track and motivate progress</strong>. Firstly, helping groups establish their own measures of success<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefk40b9v0k98\"><sup><a href=\"#fnk40b9v0k98\">[10]</a></sup></span>&nbsp;can be a good way of supporting them. Secondly, this will create a clearer measure&nbsp;<strong>against which group support can be evaluated</strong> (i.e. \"How have we helped the group become successful?\"). Thirdly, I think EA Sweden creating&nbsp;<i>their own</i> definition of what a successful group looks like<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreft43ffg2r3gh\"><sup><a href=\"#fnt43ffg2r3gh\">[11]</a></sup></span>&nbsp;will help&nbsp;<i>them</i> reach their wider community building goals better.</p><p><i>10) Design a more intentional and systematic strategy for university marketing/outreach that can be iterated on and improved from data collection and analysis;</i></p><p>Outreach for events was done on quite an ad-hoc basis. An overarching strategy could clarify target audiences and specific outreach methods and evaluate what works via participant forms or statistics. I think this would make it easier to streamline effective outreach and prevent re-inventing the wheel.&nbsp;</p><h2><i>A further comment on the recommendations</i></h2><p><strong>I expect there to be better and more cost-effective ways of supporting university groups than what I have recommended</strong>. But these serve as a good start that can be iterated upon. You could categorize the recommendations as follows:</p><ul><li>Recommendations 1-5, 8 \u2192 Direct group support</li><li>Recommendations 4, 6-7 \u2192 Direct community building&nbsp;</li><li>Recommendations 9-11 \u2192 Evaluation, improvement and strategy</li></ul><p><strong>Ideally, direct community building is left to university groups</strong>, but depending on the groups\u2019 capacities, EA Sweden can make a counterfactual boost by helping out. Recommendations 9-11 are more \u201cone-off\u201d jobs and wouldn\u2019t need to take more than 1-2 hours each. However, they are also the least important.&nbsp;</p><p>There were a few things that did not stand out as particularly effective or important and so did not make the list, although they may have had some benefit:</p><ul><li>Seeding new university groups via \u201ca bunch of people interested in joining\u201d<ul><li>When we tried to get an event off the ground, it turned out nobody wanted to take responsibility for&nbsp;<i>organizing</i>.&nbsp;</li></ul></li><li>Organizing a workshop on vision and mission for group organizers</li><li>Helping groups directly with \u2018regular\u2019 outreach methods such as posters and tabling<ul><li>Groups may still benefit from these, but I suspect EA Sweden is best to help with outreach resources, rather than spending time on it themselves.</li></ul></li><li>Monthly calls with organizers from different groups<ul><li>Although we never tried this, it seemed like groups collaborated organically and that organized meetings would be superfluous.</li></ul></li></ul><h1><strong>What value is there for EA Sweden to have a USp?</strong></h1><p>Here, I am&nbsp;<strong>more speculative and uncertain</strong> than with the general recommendations.&nbsp;</p><p>Looking back, I am 65% certain that the work done by EA Sweden\u2019s USp counterfactually (compared with EA Sweden having no USp but similar workload/priorities) contributed to:</p><ul><li>increasing the total member count in the Stockholm region (from 15 to 22),&nbsp;</li><li>moving several more members \u201cdown&nbsp;<a href=\"https://www.centreforeffectivealtruism.org/the-funnel-model\"><u>the funnel</u></a>\u201d, and&nbsp;</li><li>making the two university groups that were primarily supported slightly bigger and/or more independent than they were at the start of 2022.&nbsp;</li></ul><p>However, given that EA Sweden already has concrete plans in 2023 for most of the recommendations above with their current team, I do not think there is much value in adding a separate USp at the moment.&nbsp;</p><h2><i>When can a University Specialist be useful in other contexts?</i></h2><p>Bear in mind that&nbsp;<strong>any generalizations to other countries/cities/groups should be made having their specific context (e.g. cultural, practical) in mind</strong>.&nbsp;</p><p>Having that said, I think having a separate person handling university group support (be it a University Specialist or 30-40% of the responsibilities of a co-director/community manager) in a multi-university city like Stockholm makes it easier to&nbsp;<strong>get to know</strong> the group. For example, by attending the group\u2019s events or collaborating in organizing them, not only Zoom-ing them every now and then from your office. I think this has helped:</p><ul><li>get a better sense of groups\u2019 strengths and weaknesses (e.g. willpower, resources, personalities), thus increasing the quality of group support and collaboration efforts (e.g. events, outreach),</li><li>make the dissemination of learnings and opportunities from EA Sweden and the global community to groups easier and more likely to be picked up,</li><li>provide better \u201clocal\u201d knowledge of university cultures and know-how\u2019s, which helps EA Sweden to optimize outreach and group support.</li></ul><p>In line with recommendations 2 and 9, this also helps&nbsp;<strong>oversee the general quality</strong> of the student group\u2019s work.&nbsp;</p><p>We can also take a scenario in which a city or national group wants to seed, reboot or stabilize several groups in a multi-university city. Having a separate person may then make it easier to not compromise with the city or national group\u2019s comparative advantage, which is their&nbsp;<strong>capability to organize bigger events and oversee strategy and development</strong>. Compare this to student groups that are better suited for \u201cdirect\u201d community building work where members are located (e.g. discussion evenings, socials, book clubs).&nbsp;</p><h2><i>What about </i><a href=\"https://centreforeffectivealtruism.notion.site/University-Group-Accelerator-Program-6df8c8fccf8b4ffbb6488d9dfa275282\"><i>UGAP</i></a><i>?</i></h2><p>UGAP seems like a good resource for community building training to recommend to all new/rebooted university groups, and national groups (e.g. via a USp) are in a good spot to encourage groups to apply. In the case of university groups in Sweden I do not think, however, that UGAP should be seen as a way of outsourcing induction by the national group entirely, as this helps with providing better group support (see also recommendation 2 above). Some university groups for which UGAP may be relevant may also not be suitable<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjgzyxv3cqw\"><sup><a href=\"#fnjgzyxv3cqw\">[12]</a></sup></span>&nbsp;to take the program for whatever reason, in which case a somewhat more thorough induction from the national group may be relevant.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn6bxtdl02ar\"><sup><a href=\"#fnn6bxtdl02ar\">[13]</a></sup></span></p><h2><i>But what was the&nbsp;</i>most<i>&nbsp;</i>effective<i> thing the USp did?</i></h2><p>If hard-pressed, I would answer intro fellowships and/or career courses, with a confidence level of 80%.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9vhlnhal1ns\"><sup><a href=\"#fn9vhlnhal1ns\">[14]</a></sup></span>&nbsp;Firstly, organizing courses seems highly counterfactual at the moment due to the current capacity of the groups. Secondly, I think the&nbsp;<strong>practical, time-boxed, thorough, and collaborative</strong> nature of the courses makes it an appealing activity to participate in, making long-term engagement with EA ideas more likely than other interventions do. Although courses may increase participants\u2019 resources and dedication towards having a greater impact -&nbsp;<strong>drawing people in</strong> - they are not so good tools for&nbsp;<strong>developing and maintaining a community structure that makes people want to stay engaged and thrive&nbsp;</strong>although I think the former certainly helps with the latter.&nbsp;</p><p>What do I mean by a community structure? For example:</p><ul><li>having&nbsp;<i>recurring events</i> at different time scales, such as annual end-of-term festivities, weekly book clubs, monthly lectures, and discussions,</li><li>having the&nbsp;<i>digital infrastructure</i> set up to keep the organization easy to handle and to pass on, e.g. productivity systems, file storage, financial routines,</li><li>a&nbsp;<i>clear leadership&nbsp;</i>and division of responsibilities,</li><li>a&nbsp;<i>clear value proposition</i> for members and its manifestation in actual activities.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref47a5iznj2ib\"><sup><a href=\"#fn47a5iznj2ib\">[15]</a></sup></span></li><li>a&nbsp;<i>social network</i> that is striving towards critical thinking and warmth.&nbsp;</li></ul><p>In general, most of my recommendations (except perhaps 3 and 5) are about helping groups to draw people into the community, rather than developing a good community structure.&nbsp;<strong>I think that national and city groups can support student groups with this&nbsp;</strong>without removing the groups\u2019 independence, and I would love to see more reflections on the topic.&nbsp;</p><h1><strong>The End</strong></h1><p>If you have read all this way and have any thoughts you\u2019d like to share, please consider leaving a comment! I also welcome feedback on how I could make posts like this easier and perhaps more entertaining to read.</p><h2><strong>Thanks</strong></h2><p>Thanks to Vilhelm Skoglund, Cecilia Tilli, and Robert Praas for guidance, mentoring, suggestions, and fruitful discussion during the year. Thanks to Amarins Veringa for recommendations regarding this forum post, and to Vilhelm Skoglund and Robert Praas for extensive feedback on the post. Thanks also to Emil Wasteson, Kiryl Shantyka, Anna Ek, Mimmi Thor, and Krummi Kristjansson at EA Sweden for input and collaboration during the year. Last but definitely not least, thanks to all the amazing members and organizers I have gotten to know at KTH, SU, SSE, Uppsala, and in the wider Stockholm area - you know who you are!</p><p><br>&nbsp;</p><p><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnezg8vouwpj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefezg8vouwpj\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The groups in Gothenburg, Lund and Uppsala are focussed on the universities but also include the wider city, compared to Stockholm, where the city group and the university groups are separate.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn4sgzjf15lpo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref4sgzjf15lpo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Specifically, KTH Royal Institute of Technology, Stockholm University, Stockholm School of Economics and Uppsala University. Attempts were also made to seed a new group at Karolinska Institutet - some progress was made in terms of acquiring useful contacts and information, but no group was started. Initial contact was also made with an engaged organizer in Link\u00f6ping.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fns2t4lgzhgic\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefs2t4lgzhgic\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Between March and June I and Robert shared the position for 0.2 FTE each, and between July and December I worked 0.45 FTE. Robert initiated the idea of a University Specialist to EA Sweden in early January 2022.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnyafg6p2ju4a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefyafg6p2ju4a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>If you want access to any of the other documents that are linked within the report, please DM me.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsrd1wccd8ap\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsrd1wccd8ap\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I also made quite a few specific ones for organising intro fellowships, career courses, and outreach - you can read more about those in the report and the attached documents.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzjdhua74j4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzjdhua74j4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Since I got to spend quite some time writing this post, a few of my views changed along the way. Thus, in case there are any contradictions, the content of this post should take precedence over what is said in the report.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn82efhbiprbu\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref82efhbiprbu\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This could mean that EA Sweden does most of the initiative, or encourage groups to pull most of the weight, and a judgment should be done for each group. Also, to clarify, I do not think that national groups should <i>manage</i> university groups - the keyword really is '<i>support'.&nbsp;</i></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnf0dkdivpd7q\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreff0dkdivpd7q\">^</a></strong></sup></span><div class=\"footnote-content\"><p>But I can\u2019t remember what post! If anyone knows what I am talking about, please leave a comment!</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7ea3ctosqzg\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7ea3ctosqzg\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We used a few vague measures of learning - for example, asking \u201cDid you change your mind about something during the course?\u201d, as well as comparing cause prioritisations/career plans before and after the courses to see if something had changed.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnk40b9v0k98\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefk40b9v0k98\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is roughly similar to goal-setting, which I take to be more active than merely establishing a success metric. It may be more relevant for some groups to set goals, but this may also yield more pressure.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnt43ffg2r3gh\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreft43ffg2r3gh\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For example, I think any of the following would be independently good proxies for success, in order of importance:&nbsp;<br>*Most active members either taking 1-1 Career Coaching, and/or attending an EAG(x) conference, and/or taking an introduction fellowship (virtual or IRL);&nbsp;<br>*University group organizers spend more than 5h/week on the group and enjoy it; relevant smaller events are organized by the group at least once a month;&nbsp;<br>*Steady increase in membership numbers over a year;&nbsp;<br>*Organic development of a sustainable community structure (see later in the post);&nbsp;<br>*They establish collaborations with other groups at their university;&nbsp;<br>*They organize bigger events.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjgzyxv3cqw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjgzyxv3cqw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>However, as far as I'm aware, Effective Ventures recently made it mandatory to complete the first stage of UGAP in order to apply for grants, which I think is a sensible thing to require.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn6bxtdl02ar\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn6bxtdl02ar\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The two groups in Stockholm for which UGAP was relevant went through its first stage but not further (which I have gathered to be mostly an introductory session and further resources), saying that \u201ctime\u201d and \u201cuncertainty whether the program was the best way to spend their time\u201d were their main reasons to not continue. To get a better picture of the counterfactual, it will be interesting to watch the progress of the group in Gothenburg, who has gone through both stages of UGAP during the fall, without much contact with the USp.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9vhlnhal1ns\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9vhlnhal1ns\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Note that this is different from \"If asked to keep only one thing, what would it be?\", in which case I would take number 1 on my list which is intro lectures.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn47a5iznj2ib\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref47a5iznj2ib\">^</a></strong></sup></span><div class=\"footnote-content\"><p>These all don\u2019t have to be written down in a document for them to exist.</p></div></li></ol>", "user": {"username": "Simon Holm"}}, {"_id": "PCMpaakbat7FakGNQ", "title": "80,000 Hours has been putting much more resources into growing our audience", "postedAt": "2023-02-27T10:21:17.460Z", "htmlBody": "<p>Since the start of 2022, 80,000 Hours has been putting a lot more effort and money into getting more people to hear of us and engage with our advice.</p><p>This post aims to give some insight into what we\u2019ve been up to and why.&nbsp;</p><h2>Why invest more in outreach?</h2><p>80,000 Hours has,&nbsp;<a href=\"https://80000hours.org/about/credibility/evaluations/\"><u>we think</u></a>, been historically cost-effective at causing more people to aim their careers at tackling pressing world problems. We've built a system of resources (website, podcast, job board, advising) that many people have found helpful for this end \u2014 and so we want more people to find them.</p><p>Also, 80,000 Hours has historically been&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/tzFcqGmCA6ePeD5wm/ea-survey-2020-how-people-get-involved-in-ea#\"><u>the biggest single source of people learning about the EA community</u></a>. If we want to grow the community, increasing the number of people reached by 80k seems like one of the best available tools for doing that.</p><p>Thirdly, outreach at the \u201ctop of the funnel\u201d (i.e. getting people to&nbsp;<a href=\"https://80000hours.org/newsletter/\"><u>subscribe</u></a> after they hear about 80k\u2019s ideas for the very first time) has unusually good feedback mechanisms &amp; is particularly easy to measure. For the most part, we can tell if what we\u2019re doing isn\u2019t working, and change tack pretty quickly.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref169kts9fcta\"><sup><a href=\"#fn169kts9fcta\">[1]</a></sup></span></p><p>Another reason is that a lot of these activities take relatively little staff time, but can scale quite efficiently with more money.</p><p>Finally, based on our internal calculations, our outreach seems likely to be cost-effective as a means of getting more people into the kinds of careers we\u2019re really excited about.</p><h2>What did we do to invest more in outreach?</h2><p>In 2020, 80k decided to invest more in outreach by moving one of their staff into a position focused on outreach, but it ended up not working out &amp; that person left their role.&nbsp;</p><p>Then in mid-2021, 80k decided to hire someone new to work on outreach full-time. They hired 1 staff member (<a href=\"https://www.linkedin.com/in/bella-forristal/\"><u>me</u></a>!), and I started in mid-January 2022.</p><p>In mid-2022, we found that our initial pilots in this area looked pretty promising \u2014 by May we were on track to 4x our yearly rate of subscriber growth \u2014 and we decided to scale up the team and the resource investment. I ran a hiring round and made two hires, who started at the end of&nbsp;<a href=\"https://www.linkedin.com/in/alexanderkempebrydges/\"><u>Nov 2022</u></a> and in Feb 2023; I now act as head of marketing.</p><p>We also decided to formalise a \u201cmarketing programme\u201d for 80k, which is housed within the website team. Since this project spends money so differently from the rest of 80k, and in 2022 was a large proportion of our overall spending, last year we decided to approach funders specifically to support our marketing spend (rather than draw from our general funds). The marketing programme has a separate fundraising cycle and decisions are made on it somewhat independently from the rest of 80k.</p><p>In 2022, the marketing programme spent $2.65m (compared to ~$120k spent on marketing in 2021). The bulk of this spending was on sponsored placements with selected content creators ($910k), giving away free books to people who signed up to our newsletter ($1.04m), and digital ads ($338k). We expect to spend more in 2023, and are in conversation with funders about this.</p><p>As a result of our efforts, more than 5x as many people subscribed to our newsletter in 2022 (167k) than 2021 (30k), and we had more website visitors in Q4 2022 than any previous quarter (1.98m).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn9nhqxcumpb\"><sup><a href=\"#fnn9nhqxcumpb\">[2]</a></sup></span></p><p>We can\u2019t be sure how many additional people will change to a high-impact career as a result, in large part because&nbsp;<a href=\"https://80000hours.org/about/credibility/evaluations/\"><u>we have found that</u></a> \u201ccareer plan changes\u201d of this kind take, on average, about 2 years from first hearing about 80k.&nbsp;</p><p>Still, our current best guess is that these efforts will have been pretty effective at helping people switch careers to more impactful areas.</p><p>Partly this guess is based on the growth in new audience members that we\u2019ve seen (plus 80k\u2019s solid track record of getting new people to eventually switch to more impactful careers), and partly it\u2019s based on a few \u201cproof of concept\u201d switches we\u2019ve seen already.&nbsp;</p><p>For example, some small-scale social media ads which 80k ran in 2017 as an experiment led to at least one person switching to a career we\u2019re especially excited about (and 70 people who reported changing their career plans due to 80k).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefq2j0mledac\"><sup><a href=\"#fnq2j0mledac\">[3]</a></sup></span>&nbsp;We\u2019ve also already encountered<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref179bcaznkaw\"><sup><a href=\"#fn179bcaznkaw\">[4]</a></sup></span>&nbsp;several people who found us via our marketing who seem likely to switch to a more impactful career.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnuoajfgmf1j\"><sup><a href=\"#fnnuoajfgmf1j\">[5]</a></sup></span></p><p>(A bit more on audience inclination&nbsp;below.)</p><h2>What specific projects have we completed in this area?</h2><h3>Advertising on social media</h3><ul><li>We ran a series of ads on Facebook, Instagram, Google search, and YouTube.&nbsp;</li><li>Most of the ads were targeted pretty narrowly at the audience for whom we believe our advice has historically been most useful \u2014 students and graduates at English-speaking top world universities \u2014 though some of them were much broader.</li><li>We were pleased by the results and plan on continuing to run digital ads on these and other platforms.</li></ul><h3>Sponsored placements in other media, especially YouTube</h3><ul><li>We worked with YouTube channels, podcasts, and newsletters to include mentions of 80k in their videos/podcasts/newsletters.<ul><li>See some examples on YouTube:<ul><li><a href=\"https://www.youtube.com/watch?v=0sowY00Ld_Y&amp;ab_channel=TomScottplus\"><u>Tom Scott</u></a></li><li><a href=\"https://www.youtube.com/watch?v=lJ6n52Lsjfo&amp;t=72s&amp;ab_channel=AliAbdaal\"><u>Ali Abdaal</u></a></li><li><a href=\"https://www.youtube.com/watch?v=FBDd2n5ClZ8&amp;ab_channel=SciShow\"><u>SciShow</u></a></li><li><a href=\"https://www.youtube.com/watch?v=fgxclUnQI8A&amp;t=182s&amp;ab_channel=AdamRagusea\"><u>Adam Ragusea</u></a></li><li><a href=\"https://www.youtube.com/watch?v=H9hblaObW4E&amp;t=316s&amp;ab_channel=Dr.Becky\"><u>Dr. Becky</u></a></li><li><a href=\"https://youtu.be/kl-XuekJxR4?t=152\"><u>Minute Earth</u></a></li></ul></li><li>These were our single biggest source of growth, with&nbsp;<a href=\"https://www.youtube.com/watch?v=nmgFG7PUHfo&amp;ab_channel=Veritasium\"><u>one especially big sponsorship</u></a> getting around 18,000 new subscribers!</li></ul></li></ul><h3>Book giveaway</h3><ul><li>We offer&nbsp;<a href=\"http://80000hours.org/book-giveaway/\"><u>a free book</u></a> to anyone who joins our newsletter.&nbsp;</li><li>Readers get to choose from three books \u2014 Doing Good Better, The Precipice, and our own 80,000 Hours book.</li></ul><h3>Podcast advertising</h3><ul><li>We paid to advertise The 80,000 Hours Podcast in a few places: on Facebook &amp; Instagram, as above, and also on various podcast listening platforms like Podcast Addict, PlayerFM, Castro, etc.</li></ul><h3>Improvements to website \u201ccalls to action\u201d</h3><ul><li>Late in 2021, we made a suite of improvements to the site designed to increase the rate at which people sign up to our newsletter and apply for advising calls with us.</li><li>We also made a few smaller adjustments and improvements throughout 2022 based on A/B tests.</li><li>We think there\u2019s probably much more to do here in the future, in terms of optimising our readers\u2019 experience with the website.</li></ul><h2>FAQ<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxns3ug0z1ia\"><sup><a href=\"#fnxns3ug0z1ia\">[6]</a></sup></span></h2><p>Why ask people to sign up to your newsletter?</p><ul><li>I used newsletter signups in a lot of our outreach because there are both theoretical and empirical reasons to think it\u2019s likely to make people engage with our advice.</li><li>The theoretical reason is, well, when people join the newsletter they get our advice sent to their inbox!&nbsp;<ul><li>Conventional wisdom says that regular prompts to engage with a service are better than one-off prompts, and we\u2019ve also put a lot more effort behind making our newsletter full of consistent, high-quality releases this year.<ul><li>(We now&nbsp;<a href=\"https://80000hours.org/latest/\"><u>release them as blog posts</u></a> as well as newsletters, for that reason!)</li></ul></li></ul></li><li>The empirical reason is that being a newsletter subscriber correlates with having spent about twice the recorded time on our website, compared to non-subscribers. And every time we send out a newsletter, it gets many tens of thousands of opens and thousands of clicks.&nbsp;</li><li>Newsletter signups are also easier to measure than some other outcomes, which makes it easier to see what's working and what's not.</li><li>We've also experimented with some other \"conversion\" goals and may do more later (e.g. visits to site pages, podcast subscriptions).</li></ul><p>Aren\u2019t you going to get a lot of low-inclination traffic via these means (Where by \u2018inclination\u2019 I mean inclination to, eventually, change career plans to tackle one of the world\u2019s most pressing problems)?</p><ul><li>Yes, I think we will.&nbsp;<ul><li>The majority of the people who visit 80,000 Hours because of our outreach efforts likely won't go on to make high impact career changes or otherwise contribute to tackling the world's most pressing problems.&nbsp;</li><li>Our advice just isn\u2019t that relevant or interesting to lots of people!</li></ul></li><li>We have various ways of measuring the inclinations of our new audience members, and almost all of them suggest that they are indeed significantly less inclined towards our advice, on average, than control groups of people that didn\u2019t find us through our active outreach efforts.</li><li>However, so long as we are still getting a good proportion of high-inclination traffic too (which it looks like we are), these efforts probably still look worth it.&nbsp;</li><li>Our internal calculations of the value of this work take into account this expected decrease in inclination (and we think it looks good overall).</li><li>All that said, the inclination of the new users we get from our outreach is a top priority, which we will continue to monitor.</li></ul><p>Are you worried about any negative externalities from this work?</p><ul><li>Yes. I\u2019m especially concerned about:<ul><li>Accelerating the growth of the community beyond the optimal level<ul><li>Lots (but not all) of the people who make career plan changes because of 80k do so via getting involved in the EA community at some point.</li><li>Many people are concerned that if the EA community \u201cgrows too fast,\u201d we risk losing what\u2019s important or distinctive about EA.&nbsp;</li><li>Or, we might not have enough suggestions for what the additional people might do, meaning the community growth isn\u2019t useful and it\u2019s demoralising for the new joiners.<ul><li>I think these concerns are reasonable, and I think it\u2019s important that we try and have systems to notice whether this is happening.</li><li>Currently, I think it\u2019s likely that&nbsp;<i>without additional efforts from initiatives like these</i>, we would by default be far below the optimal growth level for the community \u2014 but that\u2019s not obviously right, and I\u2019m keen to learn more.</li></ul></li></ul></li><li>Annoying people by spamming them with ads, and putting them off EA ideas&nbsp;<ul><li>We can use \u201cfrequency caps\u201d on individual ad platforms, but we can\u2019t necessarily control how many times somebody might see 80k mentioned across different platforms.&nbsp;</li></ul></li><li>Idea inoculation&nbsp;<ul><li>I think 80k\u2019s offerings are really good, but they\u2019re probably not the absolutely optimal way of presenting EA ideas for all types of people who might be interested in those ideas. Might we put off people from high-impact work, who we could have later convinced with better or different messaging?</li><li>Of course, we\u2019ll never be sure we\u2019ve arrived at the&nbsp;<i>best</i> presentation of our ideas, and there are costs to waiting around and not trying to get people on board, too.&nbsp;</li><li>Still, worth keeping an eye on &amp; something I actively consider!</li></ul></li><li>Entrenching demographic &amp; ideological homogeneity in EA<ul><li>The audiences that we\u2019ve found most likely to sign up for 80,000 Hours' newsletter have historically often also been quite similar demographically to the current EA community.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoahw7qjljcl\"><sup><a href=\"#fnoahw7qjljcl\">[7]</a></sup></span>&nbsp;This means that if we were to just optimise for number of signups, we might entrench existing demographic homogeneity in EA.&nbsp;<ul><li>For example, many of our most successful outreach activities draw from heavily male audiences, such as STEM YouTube channels, and productivity/entrepreneurship spaces.</li><li>We have weighed demographic diversity of a creator\u2019s audience as a factor when deciding which creators to work with, and we have started out experimenting with more targeted approaches to reaching more diverse audiences, but so far our outreach efforts haven\u2019t prioritised this concern above the number of new audience members we could attract.</li></ul></li><li>This year I plan to investigate ways to increase demographic diversity among the people we reach, and indeed it\u2019s possible that our work here could really do quite a lot to move the needle in a positive direction for the community as a whole.</li></ul></li></ul></li></ul><p><br>Feel free to ask me any questions you have about this work in the comments. You can also email me at&nbsp;<a href=\"mailto:bella@80000hours.org\"><u>bella@80000hours.org</u></a>, or leave a comment on&nbsp;<a href=\"https://www.admonymous.co/bellaforristal\"><u>my admonymous</u></a>.&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn169kts9fcta\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref169kts9fcta\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Of course, some kinds of outreach activities are harder to measure, such as \u201cawareness marketing\u201d which aims to get people to hear about 80k,&nbsp;<i>without&nbsp;</i>optimising for them taking any particular action.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn9nhqxcumpb\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn9nhqxcumpb\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;Our internal metrics make us feel confident that the fact that our website traffic reached its highest point this quarter was due to our outreach efforts, rather than because of the heightened media coverage on EA at this time.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnq2j0mledac\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefq2j0mledac\">^</a></strong></sup></span><div class=\"footnote-content\"><p>By this, I mean that, 18 months after the ads were run, 70 people who first found out about us via these social media ads answered \u2018yes\u2019 to the question \u2018Have your career plans changed in any way as result of engaging with 80,000 Hours?\u2019</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn179bcaznkaw\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref179bcaznkaw\">^</a></strong></sup></span><div class=\"footnote-content\"><p>e.g. at EAGs, in our annual user survey, and in some user interviews I recently conducted.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnnuoajfgmf1j\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefnuoajfgmf1j\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I haven\u2019t given any detail about the kind of careers they\u2019re in or hope to switch to because I don\u2019t have permission from them to mention them publicly. 80k publicly posts some people\u2019s&nbsp;<a href=\"https://80000hours.org/stories/\"><u>stories</u></a> with their permission, which might include some of these people in future.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxns3ug0z1ia\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxns3ug0z1ia\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I\u2019m not sure these are actually \u2018frequently asked\u2019 but more \u2018questions I anticipate you might ask,\u2019 based on the above.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnoahw7qjljcl\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefoahw7qjljcl\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Historically, people who found out about EA via 80k&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/tzFcqGmCA6ePeD5wm/ea-survey-2020-how-people-get-involved-in-ea#Gender1\"><u>skew slightly more male, but slightly less white</u></a>, than average EAs.</p></div></li></ol>", "user": {"username": "Bella_Forristal"}}, {"_id": "DJTpSNbNfCqKzc7ja", "title": "Counterproductive Altruism: The Other Heavy Tail", "postedAt": "2023-03-01T09:58:59.376Z", "htmlBody": "<p>This is a linkpost to the article <a href=\"https://onlinelibrary.wiley.com/doi/10.1111/phpe.12133\">Counterproductive Altruism: The Other Heavy Tail</a> from Daniel Kokotajlo and Alexandra Oprea. Some excerpts are below. I also include a section at the end with some hot takes regarding possibly counterproductive altruism.</p><h1>Abstract</h1><blockquote><p>First, we argue that the appeal of effective altruism (henceforth, EA) depends significantly on a certain empirical premise we call the Heavy Tail Hypothesis (HTH), which characterizes the probability distribution of opportunities for doing good. Roughly, the HTH implies that the best causes, interventions, or charities produce orders of magnitude greater good than the average ones, constituting a substantial portion of the total amount of good caused by altruistic interventions. Next, we canvass arguments EAs have given for the existence of a positive (or \u201cright\u201d) heavy tail and argue that they can also apply in support of a negative (or \u201cleft\u201d) heavy tail where counterproductive interventions do orders of magnitude more harm than ineffective or moderately harmful ones. Incorporating the other heavy tail of the distribution has important implications for the core activities of EA: effectiveness research, cause prioritization, and the assessment of altruistic interventions. It also informs the debate surrounding the institutional critique of EA.</p></blockquote><h1>IV Implications of the Heavy Right Tail for Altruism</h1><blockquote><p>Assume that the probability distribution of charitable interventions has a heavy-right tail (for example, like the power law described in the previous section). This means that your expectation about a possible new or unassessed charitable intervention should include the large values described above with a relatively high probability. It also means that existing charitable interventions whose effectiveness is known (or estimated with a high degree of certainty) will include interventions differing in effectiveness by orders of magnitude. We contend that this assumption justifies well-known aspects of EA practice such as (1) effectiveness research and cause prioritization, (2) \u201chits-based-giving,\u201d and (3) skepticism about historical averages.</p></blockquote><h1>V Implications of the Heavy Left Tail for Altruism</h1><blockquote><p>What if the probability distribution of altruistic interventions includes both a left and a right heavy tail? In this case, we cannot assume either that (1) one's altruistic interventions are expected to have at worst a value of zero (i.e. to be bounded on the left side) or (2) that the probability that a charitable intervention is counterproductive or harmful approaches zero very rapidly.</p></blockquote><h2>Downside Risk Research</h2><blockquote><p>Many catastrophic interventions \u2014 whether altruistic or not \u2014 generate large amounts of (intentional or unintentional) harm. When someone in the world is engaging in an intervention that is likely to end up in the heavy left tail, there is a corresponding opportunity for us to do good by preventing them. This would itself represent an altruistic intervention in the heavy right tail (i.e. one responsible for enormous benefits). The existence of the heavy-left tail therefore provides even stronger justification for the prioritization research preferred by EAs.</p></blockquote><h2>Assessing Types of Interventions Requires Both Tails</h2><blockquote><p>Another conclusion we draw from the revised HTH is that the value of a class of interventions should be estimated by considering the worst as well as the best. Following such analysis, a class of interventions could turn out to be net-negative even if there are some very prominent positive examples and indeed even if almost all examples are positive. This sharply contradicts MacAskill's earlier claim that the value of a class of interventions can be approximated by the value of its best member.</p></blockquote><h2>The Institutional Critique Reassessed</h2><blockquote><p>If we are right about the existence of the left tail, certain interventions (even well-intentioned ones) are or can be expected to be extremely net-negative. Furthermore, even certain classes or subclasses of charitable interventions (e.g. foreign aid, food aid, or billionaire philanthropy) can be net-negative as a whole. In these cases, the most good an effective altruist can do may not be to launch new charitable ventures of her own or even to donate to the most effective charities. As noted above, the most efficient intervention might be to stop oneself or other people from launching massively negative interventions.</p></blockquote><h1>VI The Evidence for the Heavy Tail(s) Hypothesis: Existing Arguments</h1><blockquote><p>In this section, we begin by reconstructing three arguments in favor of a single right heavy tail that EAs have sketched: (i) the argument from examples of extreme values, (ii) the argument from nore systematic observational studies; and (iii) the argument from inefficient markets. For each of the arguments presented, we note that they should be extended to the existence of a heavy left tail.</p></blockquote><h1>VII The Evidence for the Heavy Tail(s) Hypothesis: New Arguments</h1><h2>The Crowding Out Argument</h2><blockquote><p>Consider any big goal you wish to achieve\u2014the sort of goal that would put your intervention far out in the right tail if you were to achieve it. There is some chance that the goal will be reached anyway without your effort, due to the effort of someone else. There is also a chance\u2014perhaps a smaller chance, but a chance nonetheless\u2014that your effort will cause an effective intervention not to happen or to be less effective than would have been the case without your action. For example, perhaps if you had not chosen to work towards this goal, someone more competent would have noticed the need and taken up the project in your absence. Thus, your choice to work on the project has a chance of backfiring, and if it does, it is a failure of the same magnitude as your success would have been.</p></blockquote><h2>The Data Generating Process Argument</h2><blockquote><p>Given that calculating the effectiveness of even a narrow range of philanthropic interventions we are considering [e.g. distributing anti-malaria bednets] typically involves multiplying together a large number of independent variables, we should expect the distribution of philanthropic interventions by effectiveness to be at least log-normal [which \"are typical when data points are the product of many independent inputs\"].</p></blockquote><h2>The Burden of Proof Argument</h2><blockquote><p>Without specific research into effectiveness, your uncertainty about how effective they are will range over many orders of magnitude. Lining them up side-by-side in your position of ignorance, they might look something like Figure 4 below.</p></blockquote><figure class=\"image\"><img src=\"https://onlinelibrary.wiley.com/cms/asset/352e2e3b-6ce0-4a14-8c7a-6cd1e0c0daad/phpe12133-fig-0004-m.png\" alt=\"Details are in the caption following the image\"><figcaption>Uncertainty about effectiveness of interventions</figcaption></figure><h1>Hot takes</h1><p>Minimising downside is a common theme in effective altruism. However, I still found the article interesting as a reminder that heavy left/harmful tails are often neglected, and hidden behind the status quo. What looks robustly beneficial ignoring left tails might not be so once one accounts for them. In other words, left tails may conceal <a href=\"https://forum.effectivealtruism.org/topics/crucial-consideration\">crucial considerations</a>. Some hot takes (from me, not the article):</p><ul><li>Decreasing the consumption of factory-farmed animals is pretty good for some of them (birds, fish and arthropods), but harmful to humans in the event of an abrupt sunlight reduction scenario (ASRS, such as a <a href=\"https://forum.effectivealtruism.org/topics/nuclear-winter\">nuclear winter</a>).<ul><li>The smaller the population of animals, the less animal feed could be directed to humans to mitigate the food shocks caused by the lower temperature, light and humidity during an ASRS.</li><li>Because producing calories from animals is much less efficient than from plants, decreasing the number of animals would tend to result in a smaller area of crops.</li><li>So the agricultural system would be less oversized (i.e. it would have a smaller safety margin), and scaling up food production to counter the lower yields during an ASRS would be harder.</li></ul></li><li>Mitigating global warming decreases the chances of crossing a tipping point which leads to a <a href=\"https://en.wikipedia.org/wiki/Runaway_greenhouse_effect\">moist or runaway greenhouse effect</a>, but increases the severity of ASRSs.<ul><li>The major driver for the decrease in yields during an ASRS is the lower temperature, so starting from a higher baseline temperature would be helpful.</li><li>One might argue the severity of ASRSs is only a function of the temperature reduction, not of the final temperature, on the basis that yields are roughly directly proportional to temperature in \u00baC. However, this is not the case.</li><li>The typical base temperature of cool-season plants is <a href=\"https://en.wikipedia.org/wiki/Growing_degree-day#Baselines\">5 \u00baC</a>. So, based on the heuristic of <a href=\"https://en.wikipedia.org/wiki/Growing_degree-day\">growing degree-days</a>, a reduction from 10 \u00baC to 5 \u00baC leads to a 100 % reduction in yields, not 50 % as suggested by a direct proportionality between temperature in \u00baC and yields.</li></ul></li><li>Saving and extending lives is nice for the people who get to live them, but not for the factory-farmed animals who get to be produced (see <a href=\"https://forum.effectivealtruism.org/topics/meat-eater-problem\">meat-eater problem</a>).<ul><li>To illustrate, for the <a href=\"https://ourworldindata.org/grapher/poultry-livestock-count?tab=chart&amp;country=~OWID_WRL\">35.07 G</a> poultry birds and <a href=\"https://ourworldindata.org/world-population-growth\">7.84 G</a> humans in 2020, and Rethink Priorities' (RP's) median moral weight of <a href=\"https://forum.effectivealtruism.org/posts/Qk3hd6PrFManj8K6o/rethink-priorities-welfare-range-estimates\">0.332</a> for chickens, one can conclude the total moral weight of chickens is 1.49 (= 35.07*0.332/7.84) times that of humans.</li><li>Based on data from the <a href=\"https://welfarefootprint.org/\">Welfare Footprint Project</a>, I also guess the intensity of the experiences of chickens relative to their moral weight is higher than for humans, so the factor of 1.49 may well be an underestimate.</li><li>In addition, I suppose the mean moral weight, arguably what matters, may be higher than the median moral weight.</li></ul></li><li>Forestation (or less deforestation) can be good to decrease greenhouse gas (GHG) emissions, but may actually lead to global warming if the albedo of the forested area is significantly darker (lower <a href=\"https://en.wikipedia.org/wiki/Albedo\">albedo</a>).<ul><li>Global warming depends not only on the concentration of GHGs, but also on the amount of light reflected by Earth. If this increases, the Earth gets cooler.</li><li>Forested areas are generally darker because they need light to grow (producing energy via <a href=\"https://en.wikipedia.org/wiki/Photosynthesis\">photosynthesis</a>).</li><li>So, if the forested area is significantly darker (e.g. foresting an area which would otherwise be covered in snow during winter), forestation can lead to global warming (like in the Rocky Mountains; see <a href=\"https://www.science.org/doi/10.1126/sciadv.aax8859\">Williams 2021</a>).</li><li>However, forestation ususally contributes to mitigating global warming.</li></ul></li><li>Ukraine (and its allies) resisting the <a href=\"https://en.wikipedia.org/wiki/2022_Russian_invasion_of_Ukraine\">invasion of Russia</a> may decrease the chance of future invasions (e.g. China invading Taiwan), and accelerate the democratization of Russia (if opposition to its leaders increases), but is horrible for the people involved (from both Ukraine and Russia), and can increase the risk of nuclear war.</li><li>Remittances lead to benefits via increased consumption in the nearterm, but may (or not) hinder economic growth. From <a href=\"https://www.sciencedirect.com/science/article/pii/S0305750X20301479?via%3Dihub\">Cazachevici 2020</a>:<ul><li>\"We conduct the first meta-analysis of the effect of remittances on economic growth. Although the macroeconomic importance of remittances has been rising over time, the literature has not reached a consensus and continues to produce estimates that differ widely. We collect a dataset of 95 articles displaying 538 regression equations and observe that around 40% of them report a positive and statistically significant effect of remittances, around 20% report a negative and statistically significant effect, and around 40% do not find any statistically significant impact of remittances on economic growth\".</li></ul></li><li>Foreign aid has obvious advantages in the nearterm, but may (or not) decelerate democratization. From <a href=\"https://www.journals.uchicago.edu/doi/pdf/10.1017/S0022381609090550\">Kono 2009</a>:<ul><li>\"Although many people have argued that foreign aid props up dictators, few have claimed that it props up democrats, and no one has systematically examined whether either assertion is empirically true. We argue, and find, that aid has both effects. Over the long run, sustained aid flows promote autocratic survival because autocrats can stockpile this aid for use in times of crisis. Each disbursement of aid, however, has a larger impact on democratic survival because democrats have fewer alternative resources to fall back on\".</li></ul></li><li>The effects on wild animals, namely <a href=\"https://en.wikipedia.org/wiki/Arthropod\">arthropods</a>, might be a major driver for the nearterm effects of global health and development interventions (see <a href=\"https://forum.effectivealtruism.org/posts/HwDZ6oHtz34kBAsts/finding-bugs-in-givewell-s-top-charities\">here</a>), but we do not know whether they are good or bad:<ul><li>It is hard to estimate the change in the number of arthropods caused by changes in the human population, and trends influenced by human activities, such as deforestation, and global warming.</li><li>It is unclear whether arthropods have good or bad lives.</li></ul></li></ul><p>To be clear, I am not arguing for factory-farming, global warming, shorter lives, deforestation, and resistance to invasions, nor against remittances, and foreign aid. I am just trying to illustrate what is considered robustly beneficial may have a real chance of being harmful. Relatedly, there is the concept of complex <a href=\"https://forum.effectivealtruism.org/topics/cluelessness\">cluelessness</a>.</p>", "user": {"username": "vascoamaralgrilo"}}, {"_id": "sTBMHHiAgbyh5vreZ", "title": "Can This Idea Dramatically Improve Effective Vegan Activism?", "postedAt": "2023-02-27T16:56:09.976Z", "htmlBody": "<p>In \"At what cost, carnivory?\" by Gregory Lewis, ACE's estimation was that the cost of making one vegan for one year was 4.38$ (2015) on average. The answer to improving vegan activism could be to target students and have a charity that copied and held Gary Yourofsky's \"The Most Important Speech You Will Ever Hear\".</p><p>Link:&nbsp;</p><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=U5hGQDLprA8&amp;t=261s&amp;ab_channel=GaryYourofsky\"><div><iframe src=\"https://www.youtube.com/embed/U5hGQDLprA8\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>&nbsp;</p><p><span>Gary Yourofsky made many speeches and converted, on average, 15-20% to vegans, and another 50-60% made a drastic change (of the audience), he says in the video below (1:23-1:44). Paying someone 10-20$ to hold a speech would be reasonable from a cost-benefit perspective (or maybe they want to volunteer). Perhaps some of the four he convinced to be vegan will be it their whole life. Then it could have the potential to be the most effective way to make people vegan. It could be interesting to see an implementation of this idea in an organization and a test of how it would work out.&nbsp;</span></p><p><span>Link:</span></p><figure class=\"media\"><div data-oembed-url=\"https://youtu.be/GxtC4lvSgQM\"><div><iframe src=\"https://www.youtube.com/embed/GxtC4lvSgQM\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure>", "user": {"username": "NothingIsArt"}}, {"_id": "XpeamS2yTNhagxAip", "title": "Remote Health Centers In Uganda - a cost effective intervention? ", "postedAt": "2023-02-27T05:27:47.916Z", "htmlBody": "<p><br><i><strong>TLDR: Operating basic health centers in remote rural Ugandan communities looks more cost-effective than top GiveWell interventions on early stage analysis - with huge uncertainty.</strong></i></p><p>I\u2019m Nick, a medical doctor who is co-founder and director of&nbsp;<a href=\"https://www.onedayhealth.org/\"><u>OneDay Health</u></a> (ODH). We operate 38 nurse-led health centers in healthcare \u201c<i><strong>black holes,\u201d</strong></i> remote rural areas more than 5 km from government health facilities. About 5 million Ugandans live in these healthcare black holes and only have bad options when they get sick. ODH health centers provide high-quality primary healthcare to these communities at the lowest possible cost. We train our talented nurses to use protocol based guidelines and equip them with over 50 medications to diagnose and treat 30 common medical conditions. In our 5 years of operation, we have so far treated over 150,000 patients \u2013 including over 70,000 for malaria.&nbsp;</p><p>Since we started up 5 years ago, we\u2019ve raised about $290,000 of which we\u2019ve spent around $220,000 to date. This year we hope to launch another 10-15 OneDay Health centers in Uganda and we're looking to expand to other countries which is super exciting!</p><p>If you\u2019re interested in how we select health center sites or more details about our general ops,&nbsp;<a href=\"https://www.onedayhealth.org/the-facts\"><u>check our website</u></a> or send me a message I\u2019d love to share more!&nbsp;<br>&nbsp;</p><h3><strong>Challenges in Assessing Cost-Effectiveness of OneDay Health</strong></h3><p>Unfortunately, obtaining high-quality effectiveness data requires data from an RCT or a cohort study that would cost 5-10 times our current annual budget.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref9u412aacd4\"><sup><a href=\"#fn9u412aacd4\">[1]</a></sup></span>&nbsp;So we've estimated our impact by estimating the DALYs our health centers avert through treating four common diseases and providing family planning. I originally evaluated this as part of my masters dissertation in 2019 and have updated it to more recent numbers. As we\u2019re assessing our own organisation, the chance of bias here is high.<br>&nbsp;</p><h3><strong>Summary of Cost-Effectiveness Model&nbsp;</strong></h3><p>To estimate the impact of our health centers, we estimated the DALYs averted through treating individual patients for 4 conditions:&nbsp;<i><strong>malaria, pneumonia, diarrhoea, and STIs</strong></i>. We started with Ugandan specific data on DALYs lost to each condition. We then adjusted that data to account for the risk of false diagnosis and treatment failure (in which case the treatment would have no effect). We then added impact from family planning. Estimating impact per patient isn\u2019t a new approach. PSI used a similar method to evaluate their impact (<a href=\"http://impactcalculator.psi.org/\"><u>with an awesome online calculator</u></a>), but has now moved to other methods.&nbsp;<br><br>Inputs for our approach</p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/v1677439050/mirroredImages/XpeamS2yTNhagxAip/h8bxdybzdqwaz8jzmh9h.png\"></strong></p><p><br>&nbsp;</p><h3><strong>Headline findings</strong></h3><p>For each condition, we multiplied the DALYs averted per treatment by the average number of patients treated with that condition in one health center in one month. When we added this together that each ODH health center averted 13.70 DALYs per month, predominantly through treatment of malaria in all ages, and pneumonia in children under 5.<br><br>ODH health centers are inexpensive to open and operate. Each health center currently needs only $137.50 per month in donor subsidies to operate. The remaining $262.50 in expenses are covered by small payments from patients. Many of these patients would have counterfactually received treatment, but would have incurred significantly greater expense to do so (mainly for travel). In addition, about 40% of patient expenses were for treating conditions not included in the cost-effectiveness analysis.&nbsp;</p><p>We estimate that In one month, each health center averts 13.70 DALYs and costs $137.50 in donor subsidies. This is roughly equivalent to<i><strong> saving a life for $850, or more conservatively for $1766 including patient expenses</strong></i>. However, there is huge uncertainty in our analysis.</p><h2><br><strong>The Analysis</strong></h2><h3><strong>Measuring Impact by Estimating DALYs Averted in Individual Patients</strong></h3><p>Before doing our assessment, we searched academic literature to find previous estimates of DALYs averted per patent treated in similar contexts. PSI had done the most work in this area.<br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677439050/mirroredImages/XpeamS2yTNhagxAip/g6irvgjfpyo3ddk4ojrg.png\"><br>&nbsp;</p><p>To estimate the impact of ODH health centers treating individual patients for these four conditions, we used a similar evaluation to PSI - a linear DALYs averted model.&nbsp;</p><p>We used the average&nbsp;<a href=\"https://www.healthdata.org/gbd/2019#:~:text=The%20Global%20Burden%20of%20Disease,be%20improved%20and%20disparities%20eliminated.\"><u>Global burden of disease&nbsp;</u></a>DALY burden per patient in Uganda to estimate the DALY benefit of treating individual patients. This average includes everyone who suffered from each disease in Uganda, whether they were treated correctly, poorly or not at all. This accounts somewhat for what might have happened if we hadn\u2019t treated the patient and avoids the counterfactual of assuming that patients would have not been treated without us. That said, OneDay Health treats patients in remote regions of Uganda who have very poor access to healthcare, so our treatment is likely to be more impactful than for treating the average Ugandan.&nbsp;<i><strong>I\u2019m aware that</strong></i>&nbsp;<i><strong>this is probably the weakest link in our modelling efforts.</strong></i><br>&nbsp;</p><h3><strong>DALYs averted treating patients for malaria, Pneumonia and STIs</strong></h3><p>Our model accounts for the estimated false-diagnosis and treatment-failure rates to estimate DALYs averted per patient treated. We estimated these rates from relevant peer-reviewed literature. Based on the model for treatment of malaria in children under 5, each treatment averts on average .179 DALYs per patient treated:</p><p>&nbsp;</p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/v1677439050/mirroredImages/XpeamS2yTNhagxAip/wwmu86jeb98zqkuj1ctp.png\"></strong></p><p>We used similar models for these other treatments (See Appendix 1 for diagrams)&nbsp;</p><p><strong>Malaria treatment over 5 - 0.131 DALYs averted per treatment&nbsp;</strong><br><strong>Pneumonia treatment under 5&nbsp; - 0.375 DALYs averted per treatment</strong><br><strong>Pneumonia treatment over 5&nbsp; - 0.036 DALYs averted per treatment</strong><br><strong>Diarrhoea treatment under 5 - 0.021 DALYs averted per treatment</strong></p><p>Although the benefit of treatng diarrhoea is low, this is consistent with PSI\u2019s assessment and also my experience that diarrhoea is no longer a leading cause of morbidity and mortality in rural Uganda. We assumed that treatment of diarrhoea in over-5s averted 0 DALYs.<br>&nbsp;<br>DALYs averted per patient for treating STIs were also unexpectedly small (0.00038 DALYs per patient (only 3.33 disability-adjusted life&nbsp;<strong>hours</strong>!). We aren't sure why the Global Burden of Disease weighed STIs so minimally. We believe our model significantly underestimates the benefits of STI treatment, especially since STIs are associated with miscarriage, stillbirth and even neonatal death.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefatgymryh6m5\"><sup><a href=\"#fnatgymryh6m5\">[2]</a></sup></span><br>&nbsp;</p><h3>DALYs averted for Family Planning</h3><p>For family planning, We cheated and sponged off&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1MCuX7X4GdpRRl57BvYwvy8LFAULBHUJWzPRyYalSlPI/edit#gid=1146016372\"><u>Lafiya Nigeria\u2019s calculations</u></a> (thank you and they are amazing!). We discounted by an arbitrary 30%, guessing that the benefits of FP in the rural Nigerian area they work are probably higher than &nbsp;in remote rural Uganda. Lafiya Nigeria delivered 2400 injections, averting an estimated 503 DALYs, meaning they averted an estimated 0.21 DALYs per patient treated. Discounting by 30% that yields a figure of 0.146 DALYs per treatment for our assessment. This calculation does not incorporate all potential benefits of family planning such as positive environmental impacts. While some ODH nurses insert long-term implants for family planning, they insert too few at this stage for the result to be significant.<br>&nbsp;</p><h3><strong>Calculating DALYs Averted Each Month by Each ODH Health Center</strong></h3><p>For each condition, we determined the average number of patients treated every month at each health center using data collected throughout 2022 in our 38 ODH Health Centers. We multiplied the average monthly patient volume in each category by the DALY figures described above to calculate the average DALYs averted per ODH health center per month. We estimate that each ODH health center averted&nbsp;<strong>13.70 DALYs</strong> through treatment of the four conditions and family planning. The bulk of the DALYs were averted through malaria treatment (10.30 DALYs) and treatment of pneumonia in under-5s (2.625 DALYs). Specific calculations are in the chart below:<br>&nbsp;</p><figure class=\"table\"><table><tbody><tr><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\"><strong>Condition Treated or Intervention</strong></td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\"><strong>Under-5s treated monthly</strong></td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\"><strong>DALYs averted per under-5 treated</strong></td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\"><strong>Over-5s treated monthly</strong></td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\"><strong>DALYs averted per over-5 treated</strong></td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\"><strong>Total DALYs averted</strong></td></tr><tr><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">Malaria</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">28.2</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">0.179</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">40.1</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">0.131</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">10.30</td></tr><tr><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">Pneumonia</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">7</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">0.375</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">2</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">0.036</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">2.70</td></tr><tr><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">Diarrhoea</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">7</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">0.021</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">1</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">0</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">0.15</td></tr><tr><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">STI</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">N/A</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">N/A</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">7.3</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">0.00038</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">0.00</td></tr><tr><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">Injectable FP</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">N/A</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">N/A</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">3.8</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">0.146</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">0.55</td></tr><tr><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\"><strong>Total</strong></td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td><td style=\"border:0.75pt solid #000000;padding:5pt;vertical-align:top\"><strong>13.70</strong></td></tr></tbody></table></figure><p>&nbsp;</p><p>Our current model does not capture benefits that accrue to patients treated for any other condition. About 40% of all patients are treated for a range of other conditions like skin infections, urinary tract infections, and high blood pressure. One example of a potentially high impact intervention is provision of antibiotic injections for severely ill patients while referring them to more definitive care.&nbsp;</p><p>Finally, our model does not account for the psychosocial benefits of having quality, reliable healthcare close to home, as residents no longer have to worry about lack of accessible care when they or their children become ill.<br>&nbsp;</p><h2><strong>Costs</strong></h2><p>Donors or grants fund startup costs of $3000 per health center, as well as 25% of operating costs ($87.50 per month). Launch costs include furniture, initial medication supply, tests, a solar unit, and initial rental. Ongoing operating costs are around $350 a month. At present, patients pay 75% of ongoing costs. Three years ago, our health centers were closer to 100% locally funded but a combination of COVID, inflation and general poor economic conditions here in Uganda has reduced average monthly patient volume and our revenues.&nbsp;</p><p>Our model conservatively estimates that each health center will operate for an average of 5 years, and prorates the startup costs over a 5-year period. Thus, we allocate $50 of the startup costs to each month. ODH health centers are designed to be a permanent fixture in the community, but we will close a health center if the patient volume is too low and it appears that the community doesn\u2019t place a high value on the health center. So far we have closed 8 of 46 health centers opened (15%). This means total cost of operation is&nbsp;<strong>$400 monthly</strong></p><p>In calculating the benefits of each health center, we did not include any benefits from the 40% of patient visits that address other medical conditions. Rather than accounting for these visits on the benefit side, we have deducted $105 (i.e., 40% of patient expenditures) from the patient-cost figure. This adjustment ensures we incorporate only patient costs that are related to treatment for the specified medical conditions. Based on patents\u2019 willingness to pay for these visits, we assume that patients receive at least $105 of value from them. So with this assumption we adjust monthly cost is $<strong>400- $105 = $295</strong></p><p>A major reason patients visit OneDay Health centers is because care at an ODH facility costs less than transport to distant facilities. The average cost to a patient of visiting an ODH health center is $1.50, while the average round trip transport cost to the nearest government health facility is $3.00. In our patient survey many patients expressed gratefulness that ODH health centers saved them money. OneDay Health may therefore&nbsp;<strong>cost saving&nbsp;</strong>for patients or at least&nbsp;<strong>cost neutral.&nbsp;</strong></p><p>Therefore if we assume that visiting a OneDay Health center is at least cost neutral for patients, we can account for only the donor contribution to operating the facility. The total donor/grantor cost per health center per month is<strong> $137.50</strong> ($87.50 + $50),&nbsp;&nbsp;</p><p>&nbsp;</p><h2><strong>Overall Cost Effectiveness</strong></h2><p>We then divide the total monthly operational cost by total DALYs averted, to find our cost per DALY averted.&nbsp;&nbsp;</p><p><strong>Final Cost-Benefit calculations&nbsp;&nbsp;</strong></p><p>So our&nbsp;<strong>more conservative</strong> estimated cost per DALY averted including patient costs&nbsp;<br>&nbsp; &nbsp; &nbsp; 1. 295 / 13.7 = $21.5 per DALY averted<br><strong>&nbsp; &nbsp; &nbsp;2. Assuming an 82 year lifespan, equivalent to&nbsp;$1766 per life saved.</strong>&nbsp;</p><p>&nbsp;</p><p>Assuming accessing our health centers is cost neutral for patients,&nbsp; accounting for Donor funds only</p><ol><li><strong>&nbsp;137.5 / 13.7 = $10.0 per DALY averted</strong></li><li><strong>Equivalent to&nbsp;$820 per life saved.</strong></li></ol><h3><br><br><strong>Uncertainty</strong></h3><p>The level of uncertainty here is high as we made many assumptions and don't have direct RCT or other longitudinal evidence from communities served by ODH health centers.&nbsp;</p><p>In an attempt to quantify uncertainty, I performed a probabilistic Monte Carlo simulation on a previous version of this model to explore what happened when our inputs were varied. In order to perform the simulation, distributions were assigned to important data inputs, based on the nature of available data. These included costs, GBD incidence, DALY data, and the positive predictive values of diagnosis. During my masters thesis, I had help from a health economist and embarrassingly I can\u2019t remember how I did the analysis. I haven\u2019t run the simulation again with these latest figures but when I did, 1000 simulations produced a range of impacts between half and double the original point estimate.&nbsp;<i><strong>I think this analysis massively underestimates the uncertainty</strong></i>, but include it to both acknowledge the enormous uncertainty that does exist and to show that at least I tried ;). I\u2019m keen to learn about better ways to quantify uncertainty here.&nbsp;</p><h3><strong>Limitations</strong></h3><p>This analysis carries a number of limitations, which are likely to bias the results in various ways.<br>&nbsp;</p><p><i>Limitations and effects more likely to cause&nbsp;<u>over</u>estimate of effectiveness</i></p><ul><li>Most interventions show reduced cost-effectiveness as the intervention is more fully studied - this is an early stage analysis.</li><li>This analysis is based on 5 year old global burden of disease data, with the burden of malaria and pneumonia likely to have reduced since then</li><li>This analysis was performed by ODH\u2019s co-founder and director (that\u2019s me folks), increasing the risk of bias<br>&nbsp;</li></ul><p><i>Limitations and effects that could contribute to inaccuracy in either direction</i></p><ul><li>Absence of high-quality evidence on the effectiveness of the ODH intervention, such as from an RCT or cohort study</li><li>Potential inaccuracy of the DALY data used</li><li>Potentially inaccurate assumptions about counterfactual patient outcomes<br>&nbsp;</li></ul><p><i>Limitations and effects more likely to cause&nbsp;<u>under</u>estimate of effectiveness</i></p><ul><li>Calculated benefit from STI treatment is unreasonably low, and does not account for effect on miscarriage, stillbirth, and neonatal death</li><li>Analysis excludes 40% of patients treated for other conditions</li><li>Potential saving benefits to the community are not properly accounted for here</li><li>Assumption that patient fees will only support 75% of operating expenses may be pessimistic, given current challenging macroeconomic climate in Uganda</li></ul><h3><br><strong>Could ODH be a highly cost-effective intervention?</strong></h3><p>This analysis provides some evidence that ODH may be a high-impact charity. Each of our health centers treat on average 1800 patients a year and avert an estimated 166.4 DALYs. This is equivalent to saving about 2.25 lives (range = 1.07 to 4.50) for a donor/grantor cost of $1,650. Although these figures are highly uncertain, our ODH remote health center intervention may remain competitive on cost-effectiveness even if these estimates are several times too optimistic.&nbsp;</p><p>Thanks so much for taking the time to read this, I\u2019m super keen for feedback either in the comments or direct messaging - on how to improve this analysis, and any other thoughts on ODH in general.<br><br><i><strong>Huge thanks to </strong></i><a href=\"https://forum.effectivealtruism.org/users/jason-1?mention=user\"><i><strong>@Jason</strong></i></a><i><strong> &nbsp;for huge help in providing &nbsp;insights and editing, </strong></i><a href=\"https://forum.effectivealtruism.org/users/klau-chmielowska?mention=user\"><i><strong>@Klau Chmielowska</strong></i></a><i><strong> &nbsp;from Lafiya Nigeria for allowing us to sponge of their data and to </strong></i><a href=\"https://forum.effectivealtruism.org/users/lizka?mention=user\"><i><strong>@Lizka</strong></i></a><i><strong> &nbsp;for encouraging me to go ahead with it!</strong></i><br>&nbsp;</p><h3><u>Appendix: Details of DALY Analysis for Other Conditions</u></h3><p><br><strong>Malaria treatment over 5&nbsp;</strong></p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/v1677439050/mirroredImages/XpeamS2yTNhagxAip/gzkmnlsmef5vvncpnotz.png\"></strong></p><p><br><strong>Pneumonia treatment under 5</strong></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1677439050/mirroredImages/XpeamS2yTNhagxAip/kuxfylqdpd0cqauau3ts.png\"></p><p><br><strong>Pneumonia treatment over 5</strong></p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/v1677439050/mirroredImages/XpeamS2yTNhagxAip/axijkjkstsa9zll6uxqy.png\"></strong></p><p><br><strong>Diarrhoea treatment under 5</strong></p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/v1677439050/mirroredImages/XpeamS2yTNhagxAip/tggfmopgeiqbe74dzcbs.png\"></strong><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn9u412aacd4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref9u412aacd4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;One could perform an RCT similar to the&nbsp;<a href=\"https://www.jstor.org/stable/26727328\"><u>Ugandan Living Goods study</u></a>, randomising remote communities to either receiving an ODH health center or not. In addition to the cost, it would be difficult for the study to capture a full range of health outcomes.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnatgymryh6m5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefatgymryh6m5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Under GiveWell\u2019s&nbsp;<a href=\"https://docs.google.com/document/d/1hOQf6Ug1WpoicMyFDGoqH7tmf3Njjc15Z1DGERaTbnI/edit#\"><u>moral weights as of 2020</u></a>, the value of averting one neonatal death from syphilis is 84 times as large as the value of doubling consumption for one person for one year. The value of averting a stillbirth (one month before birth) is 33.4 times as large.</p></div></li></ol>", "user": {"username": "NickLaing"}}, {"_id": "JcdQxz9gpd9Qmskih", "title": "What Has EAGxLatAm 2023 Taught Us: Retrospective & Thoughts on Measuring the Impact of EA Conferences", "postedAt": "2023-03-03T16:02:01.415Z", "htmlBody": "<p><strong>Bottom Line Up Front: The first-ever&nbsp;</strong><a href=\"https://www.effectivealtruism.org/ea-global\"><strong><u>EAGx</u></strong></a><strong> in Latin America went well (97% satisfaction rate</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreft0q5opti2kc\"><sup><a href=\"#fnt0q5opti2kc\">[1]</a></sup></span><strong>). Participants generated over 1000 new connections at a cost of USD 225 per connection</strong><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefk34uxvfp6cm\"><sup><a href=\"#fnk34uxvfp6cm\">[2]</a></sup></span>.<br>&nbsp;</p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/v1675364166/mirroredImages/JcdQxz9gpd9Qmskih/ppewkxgsirqeoyinq6kt.jpg\"></strong></p><h2>What is the purpose of this post? &nbsp;</h2><p>The purpose of this retrospective is to give a brief overview of what went well and what we could have done better at EAGxLatAm 2023. I also hope that the last section will open a conversation to help EA community builders and EAGx organizers to measure the impact of their work and to decide how to best use their resources.</p><p>&nbsp;</p><h2>The first-ever EAGx in Latin America</h2><p>It's with great excitement that we announce the successful conclusion of the first EAGx LatAm conference, held in Mexico City from January 6th to 8th, 2023.</p><p>The event drew a diverse crowd of over 200 participants from 30 different countries. Our goal was to generate new connections between EAs in Latin America and to connect the LatAm community with the broader international community.</p><p>Video highlights of the event:</p><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=iVYuybdWPSM\"><div><iframe src=\"https://www.youtube.com/embed/iVYuybdWPSM\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>&nbsp;</p><p>The conference featured a wide range of content, including talks and panels on topics such as forecasting, artificial intelligence, animal welfare, global catastrophic risks, and EA community building. Notably, it was the first EAG event featuring content in Spanish and Portuguese.</p><p>&nbsp;</p><p>We're grateful to have had the opportunity to bring together such a talented and passionate group of individuals, and we hope to see even more attendees in the future. Special shoutout to the unofficial event reporter Elmerei Cuevas for his excellent coverage of the conference on Twitter, using the hashtag&nbsp;<a href=\"https://twitter.com/hashtag/EAGxLatam\"><u>#EAGxLatAm</u></a>.</p><p>&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1675364166/mirroredImages/JcdQxz9gpd9Qmskih/adg54h3mcv7ypvsoo5xg.jpg\"><figcaption>Our Team (from left to right): Hugo Ikta, Sandra Malag\u00f3n, Laura Gonz\u00e1lez Salmer\u00f3n, \u00c1ngela Aristiz\u00e1bal, Miriam Huerta &amp; Miguel Alvarado.</figcaption></figure><h2>Key Stats<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2kzgj904lta\"><sup><a href=\"#fn2kzgj904lta\">[3]</a></sup></span></h2><p>- 223 participants (including 46 speakers)</p><p>- 1079 new connections made<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefe0hcey1y7q4\"><sup><a href=\"#fne0hcey1y7q4\">[4]</a></sup></span>. That\u2019s 9.68 new connections per participant.</p><p>- Over 1000 one-on-one meetings, including&nbsp;<a href=\"https://twitter.com/elmereimagine/status/1611722571753607174\"><u>the first recorded instance of a one-on-twelve</u></a></p><p>- 61 talks, workshops and meetups</p><p>- Cost per connection: USD 225<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreffdkceay2x5o\"><sup><a href=\"#fnfdkceay2x5o\">[5]</a></sup></span></p><p>- Likelihood to recommend: 9.08/10 with 75% of respondents giving a 9 or 10/10 rating and 3% of respondents rating it below 7/10. (Net promoter score: +72%).<br>&nbsp;</p><h2>Some of the survey results</h2><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1675364166/mirroredImages/JcdQxz9gpd9Qmskih/wbg8i1pcwny7p1hmv1hq.png\" alt=\"Forms response chart. Question title: EAGx is a place where I felt welcome. Number of responses: 69 responses.\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1675364166/mirroredImages/JcdQxz9gpd9Qmskih/vit7dyhf0shwue8r7dty.png\" alt=\"Forms response chart. Question title: EAGx is a place where others are open to exploring ideas that are different than those they already believe. Number of responses: 68 responses.\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1675364166/mirroredImages/JcdQxz9gpd9Qmskih/otvbqd2j1rawuf7sl5fb.png\" alt=\"Forms response chart. Question title: EAGx is a place where individuals express their beliefs with humility. Number of responses: 68 responses.\"></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1675364166/mirroredImages/JcdQxz9gpd9Qmskih/q9pqmobpdea0a7wxq7vr.png\" alt=\"Forms response chart. Question title: EAGx keeps me motivated to do good. Number of responses: 69 responses.\"></p><h2>Goals<br>&nbsp;</h2><p>Our main goal was to generate as many connections as possible for every dollar spent.<br>&nbsp;</p><p>We expected the number of connections per participant during EAGxLatAm 2023 to exceed that of any previous EAG(x) conference. While we generated significantly more connections per participant than the average EAG(x) conference, we didn\u2019t break that record<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefo2k3qxjokxo\"><sup><a href=\"#fno2k3qxjokxo\">[6]</a></sup></span>.</p><p>&nbsp;</p><p>Also, we expected the cost per connection (number of connections/total budget) to be significantly lower than previous EAGx conferences. We were a little too optimistic on that one. Our cost per connection could have been decreased significantly if we had more attendees (more info below).<br>&nbsp;</p><h3>We aimed at achieving the following key results</h3><p>- Every participant will generate &gt;10 new connections</p><p>- 10% of participants will generate &gt;20 new connections&nbsp;</p><p>- Make sure ~30% of participants are highly engaged EA</p><p>&nbsp;</p><p>We also aimed at limiting unessential spending that would not drastically impact our main objective or our LTR (Likelihood To Recommend) score.<br>&nbsp;</p><h3>Actual results</h3><p>77% of participants generated &gt;10 new connections (below expectations)</p><p>16% of participants generate &gt;20 new connections (above expectations)</p><p>~30% of participants were highly engaged EA (goal reached)</p><p><br>&nbsp;</p><h2>Spending</h2><p>We spent a total of USD 242,732 to make this event happen (including travel grants but not our team\u2019s wages). That\u2019s USD 1089 per participant.</p><p>&nbsp;</p><p><strong>Details</strong></p><p>Travel grants: USD 115,884</p><p>Venue &amp; Catering: USD 98,524</p><p>Internet: USD 6,667</p><p>Speakers\u2019 Hotel: USD 9,837</p><p>Hoodies: USD 5,536</p><p>Photos &amp; Videos: USD 5,532</p><p>Other: USD 813</p><p>&nbsp;</p><h2>What went well and why?</h2><h3>&nbsp;</h3><h3>We didn\u2019t face any major issues</h3><p>Nothing went terribly wrong. We definitely reached the EAGx&nbsp;<a href=\"https://docs.google.com/document/d/1pfBU0BwitYxrjzt-vd22aLncXKWxFksxE9iK42OZnBU/edit?usp=sharing\"><u>Handbook</u></a>\u2019s MVP of \u201cgetting lots of EAs in a large room and feeding them intermittently over a weekend\u201d.</p><p>&nbsp;</p><p>While there is always a part of luck in organizing events, a large part of the successful completion of EAGxLatAm was due to adequate planning.</p><p>&nbsp;</p><p>Each team member knew what they had to do and who they should contact if they needed help. We were relatively well-rested and started the event free of responsibilities (besides whatever would arise as the event unfolded). We also really cared about the event and its potential impact so we proactively took every opportunity to improve it and make it run more smoothly.</p><h3>&nbsp;</h3><h3>People enjoyed the event</h3><p>The feedback we received was above our expectations. When asked&nbsp; \u201cHow likely is it that you would recommend EAGx to a friend or colleague with similar interests to your own?\u201d respondents rated us at 9.08/10, exceeding that of any EA Global conference in 2022.<br>&nbsp;</p><p>Here are some additional survey results:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1675364166/mirroredImages/JcdQxz9gpd9Qmskih/x9ddllfxzmstvg0wskd4.png\" alt=\"Forms response chart. Question title: How satisfied were you with the following aspects of the conference?. Number of responses: .\"></p><p><strong>What people said about the event</strong></p><p>- \u201c[It was] a lot more \"familiar\" and cozy, connections made here seem to be a lot more intimate and sustainable than those formed at other conferences, a lot more \"integrative\" and welcoming into the space\u201d<br>&nbsp;</p><p>- \u201cIt was a wonderful experience. I think overall it was very well organised (except those few minor issues I pointed out as a volunteer), and I appreciate the great diversity of talks, types of sessions, and especially the attendants.\u201d</p><p>&nbsp;</p><p>- \u201cIn some respects it was better than some other EAG(x)'s, as people seemed particularly friendly and open to conversations even without scheduling an 1-on-1. I really liked the venue, especially the green area where we could walk during the 1-on-1s, and didn't notice any main problem with respect to infrastructure and organization.\u201d</p><p>&nbsp;</p><p>- \u201c[It was] the best weekend of my life\u201d</p><p>&nbsp;</p><h3>We focused on the essential&nbsp;</h3><p>Having a clear goal helped us to focus on what really mattered. Every time we had to make a decision, we reminded ourselves: \u201cWill this help generate more connections?\u201d.<br>&nbsp;</p><p>Depending on the answer, the person responsible for this task could decide how much time should be spent discussing this topic. Instead of talking about the ideal color of badges, we had more time to discuss our strategy for making sure people booked more 1-on-1s. This saved us a huge amount of time and headspace.<br>&nbsp;</p><h3>We received a lot of help</h3><p>We could not have made it on our own. Over 60 people helped us make this event happen including:<br>&nbsp;</p><p>- A contractor coordinating the venue, catering, and infrastructure installations who helped us to reduce the time spent coordinating and planning the event. Choosing reliable and experienced people who had already organized many similar events<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref7y5xwof4ktf\"><sup><a href=\"#fn7y5xwof4ktf\">[7]</a></sup></span>&nbsp;was also a key point here.<br>&nbsp;</p><p>- 40 highly-cooperative volunteers. We had a leader for every volunteer team (room managers, speaker liaison, logistics, and registration) and created Slack channels for each team to facilitate communication<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsw14qti6zas\"><sup><a href=\"#fnsw14qti6zas\">[8]</a></sup></span>.</p><p>Volunteers took their work very seriously. They followed the volunteer schedule and we always had extra volunteers available when something arose. Being constantly surrounded by people willing to help made the organization of EAGxLatAm so much easier.</p><p>&nbsp;</p><p>- We also received a great amount of support from the Centre for Effective Altruism (CEA). By providing their expertise, capital, and operational support, they demonstrated a real interest in bringing more geographical diversity to the movement.</p><p>Special thanks to Ollie Base for supporting us in the organization of the event. It was also very valuable to have Julia Wise bringing her community health experience during the conference.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/v1675364166/mirroredImages/JcdQxz9gpd9Qmskih/peejjdzarz2asy3tvr1k.jpg\"><figcaption>Some of our incredible volunteers</figcaption></figure><p>&nbsp;</p><h2>Things we could have done better</h2><h3>Starting earlier</h3><p>There are several things we should have done earlier including building our team and defining our goals.<br>&nbsp;</p><p>- We defined our goals after some important decisions had been made (such as choosing the venue). I believe this should have been the first thing to do.</p><p>- We had our first team meeting only 1.5 months before the event. We would have been able to work more collaboratively and improve accountability if we had built our team with more anticipation and organized more regular team meetings.</p><p>&nbsp;</p><h3>Opening applications earlier and doing more promotion of the event&nbsp;</h3><p>We expected 350 attendees but we only received about 300 high-quality applications out of which 283 people registered for the event. On top of that, 60 registered people did not show up to the event (that\u2019s 21% of all attendees, much higher than the 10% no-show rate we expected).</p><p>&nbsp;</p><p>Eventually, 223 people attended the event while we had already booked a venue for 350 people and food for 300 people. This seriously reduced the cost-effectiveness of the conference.<br>&nbsp;</p><p>One of the main takeaways is that we should have opened applications earlier. We found out that we were not going to receive as many high-quality applications only about a week before the application deadline. It didn\u2019t give us enough time to react.<br>&nbsp;</p><p>We initially discussed promoting the event around universities but eventually decided to stick to EA channels, because we preferred to filter for more highly engaged EAs. At that time, we made a conscious decision to limit promotion, with the understanding that we'd favour quality over quantity but we were still hopeful that we would receive over 300 attendees.<br>&nbsp;</p><p>If we had opened applications earlier, we would have been able to re-think our decision and do more promotion of the event.</p><p>&nbsp;</p><p>We also had several people struggling to get their visa or travel grant on time, so opening applications earlier would have also helped in that regard.</p><p>&nbsp;</p><p>Another option would have been to choose a small venue but, when we decided on the venue, we expected many people outside of LATAM to be granted travel support. However, due to the FTX situation, we had to limit our spending and lost many potential attendees for this reason.</p><p>&nbsp;</p><p>We could also have tried to prevent having a high no-show rate. Maybe choosing a different date (more info below) and sending one more email asking people to confirm their attendance would have helped.</p><h3>&nbsp;</h3><h3>Choosing a different date</h3><p>Organizing an event right after the end-of-year holidays was tricky. Most of the contractors we worked with were not working after Christmas, so reviewing final details during those days was hard.</p><p>&nbsp;</p><p>A lot of CEA\u2019s team and the EV finance team were also on holiday and it took them longer than usual to approve travel grants. Several people who asked for travel assistance for EAGx did not hear back from anyone until after the event and had to ask their families for money or cancel their trip.</p><p>&nbsp;</p><p>Note that part of this issue was due to the fact that it\u2019s more complicated to receive payments in Latin America than in most Western countries.</p><p>&nbsp;</p><p>We would recommend future organizers to avoid organizing an EAGx conference between December 20 and January 15.</p><p>&nbsp;</p><h3>Negotiating more flexibility with contractors</h3><p>The contacts we negotiated didn\u2019t give us much room for change. We should have negotiated more flexibility early on to be able to adjust prices depending on the number of attendees. That\u2019s especially true for food but we might also have been able to negotiate hotel prices this way.</p><p>&nbsp;</p><h3>Automating processes</h3><p>There are several processes that we recommend future organizers and the CEA to automate.&nbsp;</p><p>Our CRM (Zoho) and event app (Swapcard) were not always set up properly which generated a lot of extra work (both on our end and on the CEA\u2019s). Automating processes would also reduce confusion for attendees and allow them to plan their trip with more anticipation.</p><h3>&nbsp;</h3><h3>Offering more talks in Spanish</h3><p>One of the most common feedback we received was that people would have liked more talks to be in Spanish. It makes sense for most talks to be in English since this is the lingua franca of the movement. However, language is still an important barrier for EAs in Latin America. We\u2019ll keep this in mind for next time.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/v1675364166/mirroredImages/JcdQxz9gpd9Qmskih/vk12rtcx6y1oypgdamxy.jpg\"></p><h2>&nbsp;</h2><h2>Quick thoughts on measuring the impact of EAGx conferences</h2><p>Measuring the impact of EAGx, and community building in general, is hard. A lot of the total impact is indirect, long-term, and difficult to measure.</p><p>&nbsp;</p><p>However, if we want to keep on investing resources in these types of gatherings, it needs to be aligned with the values of the movement. More than anything, it needs to be more cost-effective than other available alternatives. The first step is to make sure we measure the impact of every intervention within EA. Including EAGx conferences.</p><p>&nbsp;</p><p>Since&nbsp;<a href=\"https://docs.google.com/presentation/d/1ZrvV-U58oxmlkClNQ5EW_v7x_ihf-nUM9c53fxTQCmQ/edit#slide=id.g7640152790_0_175\"><u>most of the impact of EAGx conferences comes from the networking aspect</u></a>, I believe that we should divide the number of new connections generated by the budget spent to get the Cost Per Connection of every EA event.</p><p>&nbsp;</p><p>Of course, not all connections are made equal. Some connections are much more valuable than others. Yet it can serve as a baseline to help people decide on the amount of resources that should be allocated to community building.<br>&nbsp;</p><p>This could help future event organizers to focus less on the \u201clikelihood to recommend\u201d (LTR) score and more on the actual cost-effectiveness of the event<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefcpk55lcyzv\"><sup><a href=\"#fncpk55lcyzv\">[9]</a></sup></span>.</p><p>&nbsp;</p><p>Do you think the value of generating a new connection at EAGx is worth more than USD 225? How about USD 1000? Do you have other ideas for how to measure the impact and cost-effectiveness of EA conferences? I\u2019d love to hear other people\u2019s thoughts on this.<br><br>&nbsp;</p><p>Useful links:</p><p>- More info about the&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/XYdLTKZLQwTr337zM/the-spanish-speaking-effective-altruism-community-is-awesome\"><u>Spanish-Speaking Effective Altruism Community</u></a></p><p>- The&nbsp;<a href=\"https://join.slack.com/t/altruismo-eficaz/shared_invite/zt-9dcv7eki-jrN6GerS0NAI~97RH4dB2A\"><u>Spanish-Speaking Slack</u></a> workspace</p><p>-&nbsp;<a href=\"https://drive.google.com/drive/folders/1ItjxMRzhV2QKQVLHqA5aWnwXGF_iqQY2?usp=sharing\"><u>Photos from the event</u></a></p><p><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnt0q5opti2kc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreft0q5opti2kc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>97% of respondents rated us \u22657/10 when asked the question \u201cHow likely is it that you would recommend EAGx to a friend or colleague with similar interests to your own?\u201d&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnk34uxvfp6cm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefk34uxvfp6cm\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We don\u2019t know yet whether this is cost-effective cost per connection. Hopefully, it can serve as a baseline for future EAGx conferences.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2kzgj904lta\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2kzgj904lta\">^</a></strong></sup></span><div class=\"footnote-content\"><p>69 out of the 223 attendees filled out the feedback survey. The following stats were calculated based on those 69 surveys.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fne0hcey1y7q4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefe0hcey1y7q4\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We define a connection as \"a person you feel comfortable reaching out to\".</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnfdkceay2x5o\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreffdkceay2x5o\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Self-reported number of connections made/Total budget =1,079/242,793 = USD 225 per connection</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fno2k3qxjokxo\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefo2k3qxjokxo\">^</a></strong></sup></span><div class=\"footnote-content\"><p>EAGxIndia2023 recently broke the record with 12.36 new connections per participant. Really looking forward to hearing how they managed to generate so many connections.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn7y5xwof4ktf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref7y5xwof4ktf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>They had organized events of this size and provided the same services (food, logistics, etc). However, they didn\u2019t know anything about EA which generated minor unaligned decisions including: generating a lot of plastic waste, offering a non-vegan coffee creamer, thinking that we wanted the venue to look \u201cprestigious\u201d instead of trying to reduce costs, etc.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsw14qti6zas\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsw14qti6zas\">^</a></strong></sup></span><div class=\"footnote-content\"><p>WhatsApp would probably have been a better option as some volunteers didn\u2019t know how to use Slack.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fncpk55lcyzv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefcpk55lcyzv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>That doesn\u2019t mean that we should stop caring about the LTR score altogether. We could even combine both metrics by dividing the cost per connection by an index of the LTR. So, in this case, 225/0.9 = 250.</p></div></li></ol>", "user": {"username": "Hugo Ikta"}}]