[{"_id": "ifAvtwtJaa9jefEb9", "postedAt": "2022-10-23T18:02:49.356Z", "postId": "SZBhfy2fh3GwSLvyJ", "htmlBody": "<blockquote>\n<p>substituting poultry for beef</p>\n</blockquote>\n<p>Unfortunately, climate concerns and animal welfare concerns are inversed for that substitution:\n<a href=\"https://foodimpacts.org/\">https://foodimpacts.org/</a></p>\n", "parentCommentId": null, "user": {"username": "Pat Myron"}}, {"_id": "MuHuf6NBrvxKzai3u", "postedAt": "2022-10-23T19:28:03.573Z", "postId": "SZBhfy2fh3GwSLvyJ", "htmlBody": "<p>Also, doesn't substituting poultry for beef mean replacing beef with poultry? (I always found the word \"substitute\" confusing when used in this way.)</p>\n", "parentCommentId": "ifAvtwtJaa9jefEb9", "user": {"username": "Erich_Grunewald"}}, {"_id": "wdcKfwgDTQoRcnPeG", "postedAt": "2022-10-24T07:10:14.506Z", "postId": "SZBhfy2fh3GwSLvyJ", "htmlBody": "<p>If you haven't already seen them, you might find some of the posts tagged \"task y\" interesting to read.</p>\n", "parentCommentId": null, "user": {"username": "alexrjl"}}, {"_id": "QbkcYHKTqLoitptg3", "postedAt": "2022-10-24T11:49:21.727Z", "postId": "SZBhfy2fh3GwSLvyJ", "htmlBody": "<p>I think something like \"<i>only a minority of people [specific researchers, billionaires, etc.] are highly influential, so we should spend a lot of energy influencing them</i>\" is a reasonable claim that implies we maybe shouldn't spend as much energy empowering everyday people. But I haven't seen any strong evidence either way about how easy it is to (say) convert 1,000 non-billionaires to donate as much as one billionaire.&nbsp;</p><p>I do think the above view has some optics problems, and that many people who 'aren't highly influential' obviously could become so if they e.g. changed careers.&nbsp;</p><p>As somebody strongly convinced by longtermist arguments, I do find it hard to 'onboard' new EAs without somebody asking \"<i>do you really think most people will sit and have a protracted philosophical discussion about longtermism?</i>\" at some point. I think there are two reasonable approaches to this:</p><ol><li>If you start small (suggest donating to the AMF instead of some other charity, and maybe coming to some EA meetings), some people will become more invested and research longtermism on their own who would have otherwise been put off.</li><li>It's useful to have two different pitches for EA for different audiences; discuss longtermism with people who are in philosophy or related fields, and something easier to explain the rest of the time. My impression is this is your pitch in this post?</li></ol><p>I'm not currently convinced of either view, but would be interested to hear about other peoples' experiences.&nbsp;</p>", "parentCommentId": null, "user": {"username": "brook"}}, {"_id": "KLoii2ZqoSzsBk7cS", "postedAt": "2022-11-19T13:46:42.577Z", "postId": "SZBhfy2fh3GwSLvyJ", "htmlBody": "<p>This is my personal opinion on the arguments made in the post.</p><p>Agree/Like the argument:</p><ul><li>Reducing information costs increases network effects.</li><li>Having effective charities as shareholders can promote good business practices along with positive incentives (making a profit, so charities have more funds)</li><li>Not making strong asks, Ex: Veganism but rather more minor changes, such as switching to poultry from beef, drastically increases the probability of mass adoption, potentially increasing the expected impact.</li></ul><p>Disagree/ Unsure/ Would like clarity on:</p><ul><li>Labelling of EAs vs common people. I think effective altruism is a question about how to do more good rather than a set of rules that people adopt, which makes them an \"EA\". Also, I am doubtful about the assumption that people involved with EA are more rational or better at navigating their Biases.</li><li>I would really like to see a mathematical model of how the indirect effects of community building or spreading the word lead to a higher expected impact rather than optimising personal behaviour.&nbsp;</li><li>Political Candidates are a subjective choice. In my opinion, people will perceive it differently, no matter how unbiased the information is. Agree with spreading factual information but don't think there is a \"right\" political candidate.</li></ul><p>&nbsp;</p><p>I would love to hear what others think of this. Also, please let me know if there is something I misunderstand about the arguments in the post.</p>", "parentCommentId": null, "user": {"username": "pg1206"}}, {"_id": "t2p6txucjsnYzaYBw", "postedAt": "2022-11-19T13:54:39.052Z", "postId": "SZBhfy2fh3GwSLvyJ", "htmlBody": "<p>I think the distinction between everyday people and EAs may be a harmful one in the realm of politics. We're assuming that EAs automatically have the authority to decide which information is \"honest\", \"unbiased\", or \"high-quality\". Couldn't someone in EA not only be biased in a specific direction, but also better than non-EAs at rationalising their biases? It may be best to have a think tank within EA to ensure that there is a specific subset of people actually willing to comb through political science research, find truly objective information, and distill it into something most people are willing to engage with.&nbsp;</p>", "parentCommentId": null, "user": {"username": "andrew_goldbaum"}}]