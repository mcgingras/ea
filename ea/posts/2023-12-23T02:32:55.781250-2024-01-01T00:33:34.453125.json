[{"_id": "3fceNPRkSwqTivJJ7", "title": "Extended Navel-Gazing On My 2023 Donations", "postedAt": "2023-12-31T18:10:29.284Z", "htmlBody": "<p>Previously: <a href=\"https://jenn.site/2022/01/donations-the-first-year/\">Donations, The First Year</a></p><p>Here's an update on what my household donated to this year, and why. Please be warned that there is some upsetting content related to the ongoing Israel-Hamas conflict in this post, in the first section.</p><h2>The Against Malaria Foundation</h2><p>Around 90% of our donations ($15,000 of $16,500 total, all amounts in CAD) went to the Against Malaria Foundation (AMF). I remain a very old school EA mostly committed to global health and poverty reduction interventions for humans.</p><p>If I was a US citizen I'd donate a portion of this to GiveWell's Unrestricted Fund for reasons I'll touch on below, but as a Canadian the key consideration for me was which GiveWell-recommended charities and funds had a Canadian entity, and unfortunately (or fortunately for eliminating analysis paralysis?) the AMF was the only recommended charity registered in Canada. This meant I could donate tax-deductibly, which meant I can donate ~20% more.</p><p>(Or so I thought at the time. I've now discovered <a href=\"https://www.cafcanada.ca/\">CAFCanada</a>, but that's a problem for my 2024 donations.)</p><p>The AMF almost didn't get my donation this year.</p><p>According to Givewell's 2021 analysis, the AMF saves in expectation <a href=\"https://www.givewell.org/charities/top-charities\">one life for every $7300 CAD</a> donated. In the days after the onset of the Israel-Palestinian conflict, I began researching nonprofits offering medical aid to Palestinians, thinking that there's a chance their impact might surpass that benchmark<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefsagoyfy36oi\"><sup><a href=\"#fnsagoyfy36oi\">[1]</a></sup></span>.</p><p>I read many annual reports for many charities, focusing extra on their work in previous years of conflict. In the end none of them were anywhere close to how effective the AMF is (like at least an order of magnitude off), with one exception.</p><p><a href=\"https://www.launchgood.com/campaign/urgent_gaza_appeal_humanitarian_and_medical_aid#!/\">Glia Gaza</a> is a small team of Canadian doctors who are providing emergency care and 3D printed tourniquets to wounded Palestinians. The tourniquets came in different sizes for women and children in addition to men (most suppliers only supply tourniquets in adult male sizes).</p><p>I researched the efficacy of tourniquets in saving lives. If you are dealing with bullet wounds, they <a href=\"https://pubmed.ncbi.nlm.nih.gov/29605726/\">help a lot</a> when you use them to staunch bleeding and prolong the time you have to get to a hospital. They help, too, if there are no hospitals, just by significantly reducing the chance that you bleed out and die right there.</p><p>Tying a tourniquet is challenging; it's easy to make mistakes that could worsen the situation or fail to apply them tightly enough. Glia created a new kind of 3D printed tourniquet that made it easier to tie properly, quickly. You can read some <a href=\"https://trklou.medium.com/3d-printed-open-source-tourniquet-rationale-failure-analysis-and-proposed-next-steps-of-the-glia-97e8441b4c5a\">harrowing field reports</a> that they <a href=\"https://trklou.medium.com/3d-printed-tourniquet-day-2-of-gaza-field-trials-ends-badly-may-14-970b3f291e7\">wrote about their prototypes in 2018</a>. There are some disturbing pictures, and worse stories. But the conclusion was that the tourniquets worked, and that they worked well.</p><p>Their 3D printers were solar powered so they weren't dependent on grid access and the plastic was locally sourced. They're just printing out a whole bunch of them and leaving strategic caches for medical professionals to use, and to use themselves. Each tourniquet would cost $15 CAD to produce and distribute. With $7300 CAD they'd be able to distribute 486 tourniquets. I thought the chances were good that 486 additional tourniquets translated to more than one life saved on expectation (though I'm not an expert and I had some pretty huge error bars, and there was some questions around scalability with additional funds and the like). I decided to sleep on it before donating.</p><p>I woke up to an update to their <a href=\"https://www.launchgood.com/campaign/urgent_gaza_appeal_humanitarian_and_medical_aid#!/\">fundraising page</a>. Their office where they had all their 3D printers (they didn't have that many) was caught in the blast of a bomb, and they had no ability to fix them. And because of the blockade there was no chance that they'd be able to fix them any time soon.</p><p>Also, because of the blockade, it really didn't matter anymore if I donated to any charity, none of them would be able to get people or medical supplies into Gaza anyways.</p><p>I felt devastated at the news. I stopped working on the report, because there wasn't a point anymore. I was very upset for weeks, too upset to keep researching. I asked ChatGPT to take on the role of a seasoned effective altruist and it helped me process some things.</p><p>In some ways, I feel like this was my first trial as an effective altruist. This was my third year of having a salary and donating out of it, and the considerations in previous years of where to donate to were much less serious than this. The deluge of coverage around the conflict caused me to feel extreme amounts of urgency and empathy for those involved in it. I don't think this is bad - Rebecca Solnit in <i>A Paradise Built in Hell</i> explains that people tend to joyfully give in times of crisis, and I think humans are better off for having this instinct.</p><p>But I only have so much space in my head, you know? In this case, that sense of urgency meant that I de-facto emotionally devalued the less glamorous needs of people who the world gives even less of a shit about than Palestinians. People dying of preventable illnesses and poverty every day of every year and not just when there's a military conflict.</p><p>That's of course not saying that I shouldn't have been upset about what happened to Glia Gaza. My Good Reason\u2122 for being upset was that for a shining moment it seemed possible that I could save lives at a discount, and then that opportunity was taken away, and I was upset at the loss.</p><p>I also have a much less good reason for being upset. I remember a part of me feeling like it was callous and wrong of me to turn away from the crisis and do the cold robotic thing of donating to the same nonprofits I always donated to even when the crisis was all I could think about. Glia Gaza's existence, I think, gave me a way to have my cake and eat it too - be committed to geographic impartiality, but still donate to the cause that moved me the most emotionally. Now I sadly had to actually reconcile some contradictory beliefs I held.</p><p>But I lurked on the forums and chatted more to Seasoned EA!ChatGPT (v grateful to the EA and rationalist communities' scrapable online logorrhea btw, I can't imagine ChatGPT keeping up as well in most other subcultures<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbssqhjp2s17\"><sup><a href=\"#fnbssqhjp2s17\">[2]</a></sup></span>&nbsp;and slowly I realized that the crisis was overemphasized in the media for the bog standard geopolitics reasons that the media always emphasizes some crises over others and I was able to slowly recover more and more space in my head for clearer thinking.</p><p>Dipping my toe into doing charity evaluations myself gave me a better sense of both how challenging it is, the tradeoffs involved (esp around scalability and resiliency) and how there are still lots of hundred dollar bills on the sidewalk, if we dedicated effort into finding them. And that's why I would have donated at least partly to the Unrestricted Fund, except alas I won't get tax credits that way \ud83d\ude29</p><p>(By the way, Glia is still around, albeit in a diminished form. They have a new campaign up to support their Gaza team <a href=\"https://www.launchgood.com/campaign/rebuild_gaza_help_repair_and_rebuild_the_lives_and_work_of_our_glia_team#!/\">here</a>.)</p><h2>Local Charities</h2><p>~10% of our donations ($1500) went to two local charities. 10% seems to me vibes-wise as a better amount to donate locally than 45% (why did I think this was reasonable in year one???), and is the same ratio as we went for last year.</p><p>Half of the $1500 went to <a href=\"https://sanguen.com\">Sanguen</a>, a local safe supply/harm reduction outfit. On their donations page they mustered a commendable effort on explaining the <a href=\"https://sanguen.com/why-donate/\">ROI on donations</a>, which I think more nonprofits should try their hand at.</p><p>Early this year a kerfuffle broke out where <a href=\"https://www.economist.com/united-states/2022/12/01/americas-syringe-exchanges-might-be-killing-drug-users\">some economists wrote a paper about why the harm reduction calculus has changed now that fentanyl exists</a>, it was retracted, the usual suspects cried wokeism and censorship, but if you <a href=\"https://www.vox.com/science-and-health/2018/9/27/17907964/safe-injection-site-study-retraction\">read further into it there were maybe some pretty serious methodological flaws of the paper</a>.</p><p>Having worked adjacent to this space, my medium confidence take is that harm reduction works and has outsized positive externalities, and basically no good data exists because it's extremely extremely difficult to get good data of literally anything while respecting the privacy (medical and otherwise) of homeless drug users. Also, <i>a lot</i> of really weird shit is going on in the lives of homeless drug users,<i> all the time</i>, they're just objectively hard to run longitudinal studies on. Like, <i>maybe</i> the retracted paper had some methodological flaws and the author neglected certain datasets? I haven't tracked down where the Discourse ended up on this. But the core issue imo is the actual complete lack of reliable datasets, which are incredibly ethically challenging to obtain.</p><p>I'm not asking you to trust me on this, but I'm confident enough in my own analysis and experiences to think that it's worthwhile for me to donate to, especially to a team that I know does outstanding work in my own local community.</p><p>The other half I requested to go towards a specific department in the nonprofit that I wrote about at length in <a href=\"https://jenn.site/2023/05/things-i-learned-by-spending-five-thousand-hours-in-non-ea-charities/\">Things I Learned by Spending Five Thousand Hours In Non-EA Charities</a>. I wasn't going to donate to them again because I learned some new stuff about them that soured me on them a little (nothing that contradicts the essay which I still endorse completely). But on a whim I did a quick back of the envelope calculation (using some insider info<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6c7qbjmr8lc\"><sup><a href=\"#fn6c7qbjmr8lc\">[3]</a></sup></span>) that suggested that the cost effectiveness of that specific department was something like 20-30x cash, and after that the matter was out of my hands.</p><p>In short, Canada has a lot of federal/provincial benefits to help people in a variety of different circumstances, but you need to know about them, and then apply to them. Because of various systemic failures, many new immigrants and refugees and other claimants can only get that money that is allocated for helping them with the help of this department.</p><p>Now, it's a little bit more complicated than this. The government knows that there are barriers, so a small portion of their benefit funding is reserved as grants to help access the rest of the funds. Samaritans operates this department by getting those grants, so whether or not my money actually helps is a bit of a question mark. I told them that if I can't donate to that department then they should just direct my money where it's most needed.</p><p>I also think it might be hard for them to use marginal money, I think it's more helpful if it comes in like, FTE-salary-size blocks. In the new year I'd like to reach out to them and work out if there's a donation size that works well for both of us, I just (as always) left the actual donating to the last minute and then can't actually message anyone for more information because it was literally Christmas Day.</p><p>If this is work that you think is worth funding, consider donating money or time to your local low-income financial aid and/or tax assistance clinics. If you're American, I'd expect a smaller ROI (maybe 5-10x cash, low confidence) because I think your government benefits tend to be less generous than Canada's and also your forms look more intimidating, but I could be wrong on one or both of those things. If you're Canadian or European, I would recommend looking into this with more enthusiasm.</p><p>I'd also love to hear other EAs' opinions on if these programs are worthwhile to fund, which I'm honestly slightly dubious about - am I just subsidizing government bureaucracy? Will this create a dependency loop? And to what extent do those second order effects matter in the light of putting much needed rent and grocery money in the hands of families that need them?</p><h2>Community Building</h2><p>Besides donations, I've also done a small amount of community building work for effective altruism this year.</p><p>The EA group in my city is cool and they're doing good stuff. They are also entirely made up of university students destined to become professional computer touchers and they accordingly focus basically exclusively on AI risk in their regular meetups. I've been organizing two or three joint events with them per school term, mostly on more neartermist and non-AI longtermist stuff (<a href=\"https://www.lesswrong.com/events/ndnujZvfPEhoW4vsR/petrov-day-and-x-risk-discussion-with-ea-waterloo\">one</a>, <a href=\"https://www.lesswrong.com/events/dgWgasKin3xEEcppt/life-in-a-day-screening-and-discussion-with-ea-waterloo\">two</a>, <a href=\"https://www.lesswrong.com/events/MuFag2RFjN3E6Je72/old-school-ea-with-ea-waterloo\">three</a>). Just broadening the horizons on what EA is, and what it can be. AI safety is important but it's not all there is to the movement.</p><p>I don't consider this to be part of my donations for the year because I got a bit of funding from the EAIF to do stuff like this, but I thought it's thematically linked enough to be worth mentioning here.</p><h2>Concluding thoughts</h2><p>Lots of ambiguities in this year's donations, but I think that's good - getting comfy with ambiguity. Not getting complacent.</p><p>I remember a lot of DIY spirit in the early EA days - the idea that people in the community are smart and capable of thinking about charities and evaluating them, by themselves or with their friends or meetup groups.</p><p>Nowadays the community has more professional and specialized programs and organizations for that, which is very much a positive, but I feel like has consequently led to some learned helplessness for those not in those organizations. I'm writing this article in part to push back against it. I'm just some guy! But that's not going to stop me from <a href=\"https://slatestarcodex.com/2013/05/02/if-its-worth-doing-its-worth-doing-with-made-up-statistics/\">evaluating charities</a> to better understand where my money is going and what the impact is going to be - especially when I don't see anyone else doing it. If you see anything wrong with any of my analyses, please let me know so I can do better next year.</p><p>One last recommendation to close this off: if you run or attend a local EA group, consider having a meeting once a year where the group collectively susses out your local charities and evaluate them based on the metrics that you think are important. <a href=\"https://forum.effectivealtruism.org/posts/xwhWgA3KLRHfrqdqZ/the-wicked-problem-experience\">You'll struggle a bunch</a> but the skills are eminently transferable! Please tag me if you write something up about it too, I'd love to see it :)</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnsagoyfy36oi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefsagoyfy36oi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Israel's GDP per capita is higher than Canada's so I didn't think I'd find anything worth reallocating AMF funding to there - let me know if you think that's a bad assumption.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbssqhjp2s17\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbssqhjp2s17\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I\u2019ve attempted numerous times to get it to discuss feminist theory with me and I swear to god this thinking machine knows the names of more EAs than feminists &gt;:(</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6c7qbjmr8lc\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6c7qbjmr8lc\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Being able to have insider info is one reason I strongly endorse donating locally.</p></div></li></ol>", "user": {"username": "jenn"}}, {"_id": "8P2GZFLnv8HW9ozLB", "title": "EA Wins 2023", "postedAt": "2023-12-31T14:07:17.679Z", "htmlBody": "<p><i>Crossposted from </i><a href=\"https://twitter.com/EffectvAltruism/status/1740423366312448146\"><i>Twitter</i></a><i>.</i></p><p>As the year comes to an end, we want to highlight and celebrate some of the incredible achievements from in and around the effective altruism ecosystem this year.</p><p>&nbsp;</p><p><strong>1. A new malaria vaccine</strong></p><p>The World Health Organization&nbsp;<a href=\"https://www.who.int/news/item/02-10-2023-who-recommends-r21-matrix-m-vaccine-for-malaria-prevention-in-updated-advice-on-immunization\"><u>recommended</u></a> its second-ever malaria vaccine this year: R21/Matrix-M, designed to protect babies and young children from malaria. The drug\u2019s recently concluded&nbsp;<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4584076\"><u>Phase III trial</u></a>, which was co-funded by Open Philanthropy, found that the vaccine was between 68-75% effective at targeting the disease, which kills around 600,000 people (mainly children) each year.</p><p>The work didn\u2019t stop there, though. Following advocacy from many people \u2014 including&nbsp;<a href=\"https://foreignpolicy.com/2023/12/08/new-malaria-vaccine-africa-world-health-organization-child-mortality/\"><u>Zacharia Kafuko</u></a> of 1 Day Sooner \u2014 the WHO quickly prequalified the vaccine, laying the groundwork for an expedited deployment and potentially saving hundreds of thousands of children\u2019s lives. 1 Day Sooner is&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/AN3M8t3M5rpi2De4Z/malaria-vaccine-r21-is-pre-qualified?commentId=BGozDmeMyxbwM3gLg\"><u>now working</u></a> to raise money to expedite the deployment further.</p><p>&nbsp;</p><p><strong>2. The Supreme Court upholds an animal welfare law</strong></p><p>In 2018, Californians voted for Proposition 12 \u2014 a bill that banned intensive cage confinement and the sale of animal products from animals in intensive confinement. The meat industry challenged the law for being unconstitutional \u2014 but in May of this year, the US Supreme Court&nbsp;<a href=\"https://thehumaneleague.org/article/prop-12-supreme-court\"><u>upheld Prop 12</u></a>, a decision that will improve the lives of millions of animals who would otherwise be kept in cruel and inhumane conditions.</p><p>Organizations such as The Humane League \u2014 one of Animal Charity Evaluators\u2019&nbsp;<a href=\"https://animalcharityevaluators.org/charity-review/the-humane-league/\"><u>top charities</u></a> \u2014 are a major part of this victory; their tireless campaigning is part of what made Prop 12 happen.</p><p><i>Watch a panel discussion featuring The Humane League at EAG London 2023&nbsp;</i><a href=\"https://www.youtube.com/watch?v=87mlrgvvJPE\"><i><u>here</u></i></a><i>.</i></p><p>&nbsp;</p><p><strong>3. AI safety goes mainstream</strong></p><p>2023 was the year AI safety went mainstream. After years of work from people in and around effective altruism, this year saw hundreds of high-profile AI experts \u2014 including two Turing Award winners \u2014&nbsp;<a href=\"https://www.safe.ai/statement-on-ai-risk\"><u>say</u></a> that \u201cmitigating the risk of extinction from AI should be a global priority\u201d.</p><p>That was followed by a flurry of activity from policymakers, including a&nbsp;<a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/\"><u>US Executive Order</u></a>, an international&nbsp;<a href=\"https://www.gov.uk/government/topical-events/ai-safety-summit-2023\"><u>AI Safety Summit</u></a>, the establishment of the UK&nbsp;<a href=\"https://www.gov.uk/government/publications/frontier-ai-taskforce-first-progress-report/frontier-ai-taskforce-first-progress-report\"><u>Frontier AI Taskforce</u></a>, and a deal on the&nbsp;<a href=\"https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai\"><u>EU AI Act</u></a> \u2014 which, thanks to the efforts of campaigners, is now going to regulate foundation models that pose a systemic risk to society.</p><p>Important progress was made in technical AI safety, too, including work on&nbsp;<a href=\"https://llm-attacks.org/\"><u>adversarial robustness</u></a>,&nbsp;<a href=\"https://www.anthropic.com/index/decomposing-language-models-into-understandable-components\"><u>mechanistic interpretability</u></a>, and&nbsp;<a href=\"https://arxiv.org/abs/2309.15840\"><u>lie detection</u></a>.</p><p><i>Watch a talk from EAG Boston 2023 on technical AI safety&nbsp;</i><a href=\"https://buff.ly/3GX3uOP\"><i><u>here</u></i></a><i>.</i></p><p>&nbsp;</p><p><strong>4. Results from the world\u2019s largest UBI study</strong></p><p>Since 2018, GiveDirectly \u2014 an organization that distributes direct cash transfers to those in need \u2014 has been running the world\u2019s largest&nbsp;<a href=\"https://www.givedirectly.org/2023-ubi-results/\"><u>universal basic income experiment</u></a> in rural Kenya.</p><p>In September, researchers led by MIT economist Taveneet Suri and Nobel laureate Abhijit Banerjee, published their&nbsp;<a href=\"https://conference.nber.org/conf_papers/f192616.pdf\"><u>latest analysis</u></a> of the data \u2014 finding that giving people money as a lump sum leads to better results than dispersing it via monthly payments. Long-term UBI was also found to be highly effective and didn\u2019t discourage work. The results could have significant implications for how governments disburse cash aid.</p><p><i>Watch GiveDirectly\u2019s&nbsp;</i><a href=\"https://www.youtube.com/watch?v=nEDlMQn0hnY\"><i><u>talk at EAGx Nordics 2023</u></i></a><i>.</i></p><p>&nbsp;</p><p><strong>5. Cultivated meat approved for sale in US</strong></p><p>After years of work from organizations like the Good Food Institute, in June 2023 the USDA finally&nbsp;<a href=\"https://www.nytimes.com/2023/06/21/us/lab-grown-meat-sale-approval.html\"><u>approved cultivated meat</u></a> for sale in the US.</p><p>The watershed moment made the US the second country (after Singapore) to legalize the product, which could have significant impacts on animal welfare by reducing the number of animals that need to be raised and killed for meat.</p><p><i>Watch the Good Food Institute\u2019s Bruce Friedrich talk about alternative proteins at EAG London 2023&nbsp;</i><a href=\"https://www.youtube.com/watch?v=hxc7kroNAEg\"><i><u>here</u></i></a><i>.</i></p><p>&nbsp;</p><p><strong>6. A potentially dangerous virus-hunting programme was shut down</strong></p><p>In 2021, USAID launched a $125 million dollar program to hunt down viruses that might cause a future pandemic. Biosecurity experts such as MIT\u2019s Kevin Esvelt and Andrew Weber of the Council on Strategic Risks, however, were immediately concerned: such virus hunting could end up bringing new viruses back to society and causing outbreaks, or give bad actors the blueprints to develop new deadly pathogens.&nbsp;</p><p>After pressure from these experts and others, USAID&nbsp;<a href=\"https://www.vox.com/future-perfect/23871624/usaid-deep-vzn-pandemics-viruses-covid-coronavirus-cdc-virology-pathogens\"><u>cancelled the program</u></a> this year \u2014 reducing the likelihood of a catastrophic pandemic accidentally occurring in the future.</p><p><i>Watch Kevin Esvelt\u2019s talk at EAG Boston 2023&nbsp;</i><a href=\"https://www.youtube.com/watch?v=yjOqxOQVL6w\"><i><u>here</u></i></a><i>.</i><br>&nbsp;</p><p><strong>7. And much, much more.</strong></p><p>More happened in and around the effective altruism ecosystem this year than we could possibly cover in a post/thread like this! The above is just a brief overview of some of the incredibly impactful work that\u2019s been done. We didn\u2019t touch on Charity Entrepreneurship\u2019s incredible&nbsp;<a href=\"https://www.charityentrepreneurship.com/our-charities\"><u>new charities</u></a>, working on everything from&nbsp;<a href=\"https://www.charityentrepreneurship.com/healthy-futures-global\"><u>protecting babies from syphilis</u></a> to combating&nbsp;<a href=\"https://www.charityentrepreneurship.com/armor\"><u>antimicrobial resistance</u></a>; or how animal welfare activists successfully&nbsp;<a href=\"https://thehumaneleague.org/article/jollibee-victory\"><u>persuaded Jollibee</u></a> to commit to only using eggs from cage-free hens. There wasn\u2019t time to discuss the Lead Exposure Elimination Project\u2019s&nbsp;<a href=\"https://leadelimination.org/malawi-follow-up-study/\"><u>incredible success</u></a> in Malawi, where its work appears to have significantly cut the levels of toxic lead in paint. And we\u2019ve not even mentioned the continued growth of the EA ecosystem, including hundreds of new people signing the&nbsp;<a href=\"https://www.givingwhatwecan.org/about-us/members\"><u>Giving What We Can pledge</u></a> to give away 10% of their income to effective charities.</p><p>We want to finish by thanking everyone \u2014 both those mentioned in this post and the many thousands of those not mentioned \u2014 for their incredible work to make the world a better place. Collectively, the effective altruism ecosystem continues to save the lives of both humans and animals, support those suffering from diseases or struggling with poverty, and build a safer future for all of us. Thank you for your work, and we look forward to an even more impactful 2024.</p><p><i>Thanks to Emma Richter for her help on this post.</i></p>", "user": {"username": "Shakeel Hashim"}}, {"_id": "AJBiY2XBazbjYgGfW", "title": "Guardrails vs Goal-directedness in AI Alignment", "postedAt": "2023-12-30T12:58:33.120Z", "htmlBody": "<p>Many EAs see AI Alignment research efforts as an important route to mitigating x-risk from AGI. However, others are concerned that alignment research overall increases x-risk by accelerating AGI timelines. I think Michael Nielsen <a href=\"https://michaelnotebook.com/xrisk/\">explains</a> this well:</p><p>\"<i>Practical alignment work makes today's AI systems far more attractive to customers, far more usable as a platform for building other systems, far more profitable as a target for investors, and far more palatable to governments. The net result is that practical alignment work is accelerationist.</i>\"</p><p>&nbsp;</p><p>I think we can distinguish between two broad subtypes of alignment efforts: 1) \"implementing guardrails\" and 2) \"improving goal-directedness\".&nbsp;</p><p>I would categorise approaches such as running AI models on custom chips, emergency shutdown mechanisms, red teaming, risk assessments, dangerous capability evaluations and safety incident reporting as \"implementing guardrails\". This can be thought of as getting AI systems to not do the worst thing possible.</p><p>I would categorise approaches such as RLHF and reward shaping as \"improving goal-directedness\". This could also be thought of as getting AI systems to do the best thing possible.</p><p>I think \"implementing guardrails\" has much weaker acceleration effects than \"improving goal-directedness\". An AI system which can be shutdown and does not show dangerous capabilities, is still not very useful if it can't be directed towards the specific goal of the user.</p><p>&nbsp;</p><p>So I think people who are worried that AI Alignment efforts might be net-negative because of acceleration effects should consider prioritising \"implementing guardrails\" approaches to AI Alignment.</p>", "user": {"username": "freedomandutility"}}, {"_id": "FEWFxn4b7p7kjJFyH", "title": "Prioritising between extinction risks: Evidence Quality", "postedAt": "2023-12-30T12:25:33.173Z", "htmlBody": "<h1><strong>Section 1: Strength of Evidence</strong></h1><p>The EA community has identified many sources of extinction risk. However, most efforts to mitigate existential risk from one source will not mitigate risk from other sources. This means we must prioritise between extinction risks to maximise impact.</p><p>Many factors should be considered in this prioritisation. This post will only focus on one factor - evidence quality.&nbsp;<i>All else equal</i>, we should prioritise problems where there is stronger evidence that it poses an extinction risk.&nbsp;</p><p>In evidence-based medicine, there is a well-known \u201c<a href=\"https://s4be.cochrane.org/blog/2014/04/29/the-evidence-based-medicine-pyramid/\"><u>pyramid of evidence</u></a>\u201d which ranks the strength of evidence. This pyramid is not applicable to extinction risk studies, where all evidence is of much lower quality than that available in medicine. We also have the problem of&nbsp;<a href=\"https://en.wikipedia.org/wiki/Anthropic_principle\"><u>observation selection effects</u></a> which means we will not find past examples of human extinction.</p><p>This post introduces a potential approach to ranking evidence strength for extinction risks.<strong> I\u2019d love to see people build on this and offer better-seeming alternatives.</strong></p><p>I haven\u2019t included \u201cexpert opinion\u201d and \u201csuperforecaster estimates\u201d in this ranking, since I think experts and superforecasters should be weighing evidence using this ranking to arrive at their opinions and estimates.</p><p>&nbsp;</p><h3><strong>Proposed Levels of Evidence</strong></h3><p>&nbsp;</p><p><strong>\u200b\u200b1) Precedent of extinction of multiple species</strong></p><p>Asteroids (Cretaceous-Paleogene Extinction)</p><p>Supervolcanoes / non-anthropogenic climate change (Permian-Triassic Extinction, Triassic-Jurassic Extinction)</p><p>&nbsp;</p><p><strong>2) Precedent of extinction of a single species&nbsp;</strong></p><p>Infectious Disease (Tasmanian Tiger, Golden Toad, Christmas Island Pipistrelle)</p><p>&nbsp;</p><p><strong>3) Precedent of a human societal collapse&nbsp;</strong></p><p>&nbsp;</p><p><strong>4) Precedent of an extremely large number of human deaths in an extremely short period of time&nbsp;</strong></p><p>War (World War 2, Taiping Rebellion)</p><p>Famine (Great Chinese Famine)</p><p>&nbsp;</p><p><strong>5) Clear mechanism of extinction</strong></p><p>Nuclear War</p><p>Gamma Ray Bursts</p><p>Biodiversity Loss</p><p>&nbsp;</p><p><strong>6) Unclear mechanism of extinction</strong></p><p>AGI</p><p>Nanotechnology</p><p>Particle Physics Experiments</p><p>Global Systemic Risks / Cascading Risks</p><p>Geoengineering</p><p>&nbsp;</p><h1><strong>Section 2: Uncertainties and Open Questions</strong></h1><p>What are the correct reference classes? Should we take previous technological change-induced societal collapses as a reason to prioritise nanotechnology and AI Safety, even if the technology which induced the collapse looked very different?</p><p>Will more research into exoplanets allow us to learn about past events which turned habitable planets into uninhabitable ones? I would put this type of evidence at the top of the ranking.</p><p>I\u2019m unsure about where to place \u201cprecedent of human societal collapse\u201d relative to precedent of extinction of animal species - I think this depends heavily on how special you think humans are relative to animals. Clearly, we're much better able to co-ordinate and respond to emerging threats.</p><p>&nbsp;</p><h1><strong>Section 3: Implications for Open Philanthropy, 80K and individual EAs</strong></h1><p>I don\u2019t think Open Philanthropy, 80k or most individual EAs have given enough consideration to strength of evidence when prioritising between extinction risks.</p><p>So based on this current framework, I think all groups should allocate more resources (money, careers, etc) towards planetary defence and supervolcanoes, and less resources towards nuclear war and AI Safety, relative to the status quo.</p>", "user": {"username": "freedomandutility"}}, {"_id": "Hhtvwx2ka4pzoWg7e", "title": "AI alignment shouldn't be conflated with AI moral achievement", "postedAt": "2023-12-30T03:08:12.485Z", "htmlBody": "<p>In this post I want to make a simple point that I think has big implications.</p><p>I sometimes hear EAs talk about how we need to align AIs to \"human values\", or that we need to make sure AIs are benevolent. To be sure, ensuring AI development proceeds ethically is a valuable aim, but I claim this goal is <i>not </i>the same thing as \"<a href=\"https://ai-alignment.com/clarifying-ai-alignment-cec47cd69dd6\">AI alignment</a>\", in the sense of getting AIs to try to do what people want.</p><p>My central contention here is that if we succeed at figuring out how to make AIs pursue our intended goals, these AIs will likely be used to maximize the <a href=\"https://en.wikipedia.org/wiki/Consumption_(economics)\">economic consumption</a> of existing humans at the time of alignment. And most economic consumption is aimed at satisfying selfish desires, rather than what we'd normally consider our altruistic moral ideals.</p><p>It's important to note that my thesis here is not merely a semantic dispute about what is meant by \"AI alignment\". Instead, it is an empirical prediction about how people will actually try to use AIs in practice. I claim that people will likely try to use AIs mostly to maximize their own economic consumption, rather than to pursue ideal moral values.</p><p>Critically, only a small part of human economic consumption appears to be what impartial consequentialism would recommend, including the goal of filling the universe with numerous happy beings who live amazing lives.</p><p>Let me explain.</p><p>Consider how people currently spend their income. Below I have taken a plot from the blog <a href=\"https://engaging-data.com/household-spending-income/\">Engaging Data</a>, which borrowed data from the Bureau of Labor Statistics in 2019. It represents a snapshot of how the median American household spends their income.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Hhtvwx2ka4pzoWg7e/pc5z0n0rvta982jux2ki\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Hhtvwx2ka4pzoWg7e/cigeexap9pcbmsbhcruw 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Hhtvwx2ka4pzoWg7e/mmslipto5jcsv0vjibbx 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Hhtvwx2ka4pzoWg7e/aygqp9q0yzs5ocadwyct 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Hhtvwx2ka4pzoWg7e/aqgx4pwmtersfkp0glm2 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Hhtvwx2ka4pzoWg7e/ofqkwuri4ihihfm72eia 1000w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Hhtvwx2ka4pzoWg7e/xbf4cjphvt3n9awodbpr 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Hhtvwx2ka4pzoWg7e/wbphfwlgctd1j9ta5kfp 1400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Hhtvwx2ka4pzoWg7e/k4nucs3ozrdwskembvic 1600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Hhtvwx2ka4pzoWg7e/n0pagukmimfuo5zplc1l 1800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Hhtvwx2ka4pzoWg7e/hwnbax1b9ftkpct3dh4i 1930w\"></figure><p>Most of their money is spent on the type of mundane consumption categories you'd expect: housing, utilities, vehicles etc. It is very likely that the majority of this spending is meant to provide personal consumption for members of the household or perhaps other family and friends, rather than strangers. Near the bottom of the chart, we find that only 3.1% of this spending is on what we'd normally consider altruism: voluntary gifts and charity.</p><p>To be clear, this plot does not comprise a comprehensive assessment of the altruism of the median American household. Moreover, moral <i>judgement</i> is not my intention here. Instead, my intention is to emphasize the brute fact that when people are given wealth, they primarily spend it on themselves, their family, or their friends, <i>rather</i> than to pursue benevolent moral ideals.</p><p>This fact is important because, to a first approximation, aligning AIs with humans will simply have the effect of greatly multiplying the wealth of existing humans \u2014 i.e. the total amount of resources that humans have available to spend on whatever they wish. And there is little reason to think that if humans become extraordinarily wealthy, they will follow idealized moral values. To see why, just look at what current people already do, who are many times richer than their ancestors centuries ago. All that extra wealth did not make us extreme moral saints; instead, we still mostly care about ourselves, our family, and our friends.</p><p>Why does this fact make any difference? Consider the prescription of classical utilitarianism to maximize population size. If given the choice, humans would likely not spend their wealth to pursue this goal. That's because humans care far more about our own <i>per capita</i> consumption than global aggregate utility. When humans increase population size, it is usually a byproduct of their desire to have a family, rather than being the result of some broader utilitarian moral calculation.</p><p>Here's another example. When given the choice to colonize the universe, future humans will likely want a rate of return on their investment, rather than merely deriving satisfaction from the fact that <a href=\"https://forum.effectivealtruism.org/topics/universe-s-resources\">humanity's cosmic endowment</a> is being used well. In other words, we will likely send out the <a href=\"https://en.wikipedia.org/wiki/Self-replicating_spacecraft\">von Neumann probes</a> as part of a scheme to benefit ourselves, not out of some benevolent duty to fill the universe with happy beings.</p><p>Now, I'm not saying selfishness is automatically bad. Indeed, when channeled appropriately, selfishness serves the purpose of making people happy. After all, if everyone is rich and spends money on themselves, that's not obviously worse than a situation in which everyone is rich and spends their money on each other.</p><p><i>But humans are not the only moral patients who will exist!</i></p><p>Consider that the vast majority of humans are happy to eat meat, even if many of them privately confess that they don't like causing animal suffering. To most people, the significant selfish costs of giving up meat simply outweigh the large non-selfish benefits of reducing animal suffering. And so, most people don't give up meat.</p><p>The general pattern here is that, while most humans are not evil, whenever there's a non-trivial conflict between selfish preferences and altruistic preferences, our selfish preferences usually trump the altruistic ones, even at the cost of great amounts of suffering. This pattern seems likely to persist into the future.</p><p>Of course, the fact that humans are primarily selfish doesn't mean that humans will necessarily cause a ton of suffering in the future because \u2014 unlike with current meat consumption \u2014 it might one day become feasible to mitigate suffering without incurring substantial selfish costs.&nbsp;</p><p>But, at the same time, it's critically important to avoid <a href=\"https://longtermrisk.org/against-wishful-thinking/\">wishful thinking</a>.</p><p>The mere possibility that in the future there might exist no tradeoff between suffering and economic consumption does not imply that will be the case. It remains plausible that humans in the future, equipped with aligned AIs, will produce vast amounts of suffering in the service of individual human preferences, just as our current society produces lots of animal suffering to satisfy current human wants. If true, the moral value of AI alignment is uncertain, and potentially net-negative.</p><p>As just one example of how things could go badly even if we solve AI alignment, it may turn out that enabling AIs to suffer enhances their productivity or increases the efficiency of AI training. In this case there would be a direct non-trivial tradeoff between the satisfaction of individual human preferences and the achievement of broad utilitarian ideals. I consider this scenario at least somewhat likely.</p><hr><p>Ultimately I don't think we should talk about AIs being aligned with some abstract notion of \"human values\" or AIs being aligned with \"humanity as a whole\". In reality, we will likely try to align AIs with various individual people, who have primarily selfish motives. Aligned AIs are best thought of as servants who follow our personal wishes, whatever those wishes may be, rather than idealized moral saints who act on behalf of humanity, or all sentient life.</p><p>This does not mean that aligned AIs won't follow moral constraints or human moral norms. Aligned AIs may indeed follow various constraints, including following the law. But following moral norms is not the same thing as being a moral saint: selfish people already have strong incentives to obey the law purely out of fear of punishment.&nbsp;</p><p>Crucially, the moral norms that aligned AIs follow will be shaped by the preferences of actual humans or society in general, rather than by lofty altruistic ideals. If AIs obey our moral norms, that does not simply imply they will be benevolent anymore than current laws constrain people's ability to eat meat.</p><p>Can't we just build benevolent AIs instead of AI servants that fulfill our selfish desires? Well, we could do that. But people would not want to purchase such AIs. When someone hires a worker, they generally want the worker to do work for them, not for others. A worker who worked for humanity as a whole, or for all sentient life, would be much less likely to be hired than someone who works directly for their employer, and does what <i>they </i>want. The same principle will likely apply to AIs.</p><p>To make my point clearer, we can try to distinguish what might be meant by \"human values\". The concept can either refer to a broad moral ideal, or it can refer to the the preferences of actual individual humans.</p><p>In the first case, there will likely be little economic incentive to align AIs to human values, and thus aligning AIs to human values does not appear to be a realistic end-goal. In the second case, human values refer to the preferences of primarily selfish individual people, and satisfying these preferences is not identical to the achievement of broad, impartial moral goals.</p><p>Of course, it might still be very good to solve AI alignment. Unaligned AIs might have preferences we'd find even worse than the preferences of currently-living individual humans, especially from our own, selfish perspective. Yet my point is merely that the achievement of AI alignment not the same as the achievement of large-scale, altruistic moral objectives. The two concepts are logically and empirically separate, and there is no necessary connection between them.</p>", "user": {"username": "Matthew_Barnett"}}, {"_id": "eHKhrvBexNtj6ahj2", "title": "Your EA Forum 2023 Wrapped", "postedAt": "2023-12-30T23:12:47.754Z", "htmlBody": "<p><a href=\"https://forum.effectivealtruism.org/posts/gfj7FMKz9e8CKXqSQ/your-2022-ea-forum-wrapped\">Last year</a> we introduced the EA Forum Wrapped feature, and this year we've totally redesigned it for you - <a href=\"https://forum.effectivealtruism.org/wrapped\">see your EA Forum 2023 Wrapped here</a>. \ud83c\udf81</p><p>Thanks to everyone for visiting and contributing to the EA Forum this year!</p><p>&nbsp;</p><figure class=\"image image_resized\" style=\"width:52.13%\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eHKhrvBexNtj6ahj2/cw1rdodta1j7iycrmdk6\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eHKhrvBexNtj6ahj2/dnr4l4ssfrsaxdilrgok 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eHKhrvBexNtj6ahj2/upf5uxkimnlf7rzoqo4z 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eHKhrvBexNtj6ahj2/hcdkfn2hq05z660em2n3 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eHKhrvBexNtj6ahj2/l1tppoyh3kjjpntevbqq 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eHKhrvBexNtj6ahj2/epczkoasmmyjnmelzyvc 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eHKhrvBexNtj6ahj2/noigt8kwwpblxgpu8ukp 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eHKhrvBexNtj6ahj2/c0fz6rq3brociszuagcj 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eHKhrvBexNtj6ahj2/kmyb9eucjka3n3q8yl3w 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eHKhrvBexNtj6ahj2/y0sxuaubeqfxljvbft9h 1350w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/eHKhrvBexNtj6ahj2/vevu2bnzigz1momwbg5k 1456w\"></figure><p>&nbsp;</p><p>If you have any feedback or questions about the results, please feel free to leave a comment on this post. Consider sharing if you found something surprising or interesting.</p>", "user": {"username": "syc"}}, {"_id": "zzsQMTejrRvYodkTS", "title": "Exaggerating the risks (Part 13: Ord on Biorisk)", "postedAt": "2023-12-31T08:45:57.056Z", "htmlBody": "<p><i>This is a crosspost for </i><a href=\"https://ineffectivealtruismblog.com/2023/12/29/exaggerating-the-risks-part-13-ord-on-biorisk/\"><i>Exaggerating the risks (Part 13: Ord on Biorisk)</i></a><i>, as published by David Thorstad on 29 December 2023.</i></p><blockquote><p>This massive democratization of technology in biological sciences \u2026 is at some level fantastic. People are very excited about it. But this has this dark side, which is that the pool of people that could include someone who has \u2026 omnicidal tendencies grows many, many times larger, thousands or millions of times larger as this technology is democratized, and you have more chance that you get one of these people with this very rare set of motivations where they\u2019re so misanthropic as to try to cause \u2026 worldwide catastrophe.</p><p>Toby Ord, <a href=\"https://80000hours.org/podcast/episodes/toby-ord-the-precipice-existential-risk-future-humanity/#biological-threats-012659\"><u>80,000 Hours Interview</u></a></p></blockquote><p>Listen to this post [there is an option for this in the original post]</p><h3>1. Introduction</h3><p>This is Part 13 of my series&nbsp;<a href=\"https://ineffectivealtruismblog.com/category/exaggerating-the-risks/\"><u>Exaggerating the risks</u></a>. In this series, I look at some places where leading estimates of existential risk look to have been exaggerated.</p><p><a href=\"https://ineffectivealtruismblog.com/2022/12/01/exaggerating-the-risks-part-1-introduction/\"><u>Part 1</u></a>&nbsp;introduced the series. Parts 2-5 (<a href=\"https://ineffectivealtruismblog.com/category/exaggerating-the-risks/climate-risk/\"><u>sub-series: \u201cClimate risk\u201d</u></a>) looked at climate risk. Parts 6-8 (<a href=\"https://ineffectivealtruismblog.com/category/exaggerating-the-risks/ai-risk/\"><u>sub-series: \u201cAI risk\u201d</u></a>) looked at the Carlsmith report on power-seeking AI.</p><p>Parts&nbsp;<a href=\"https://ineffectivealtruismblog.com/2023/07/08/exaggerating-the-risks-part-9-biorisk-grounds-for-doubt/\"><u>9</u></a>,&nbsp;<a href=\"https://ineffectivealtruismblog.com/2023/08/12/exaggerating-the-risks-part-10-biorisk-more-grounds-for-doubt/\"><u>10</u></a>&nbsp;and&nbsp;<a href=\"https://ineffectivealtruismblog.com/2023/10/21/exaggerating-the-risks-part-11-biorisk-still-more-grounds-for-doubt/\"><u>11</u></a>&nbsp;began a&nbsp;<a href=\"https://ineffectivealtruismblog.com/category/exaggerating-the-risks/biorisk/\"><u>new sub-series</u></a>&nbsp;on biorisk. In&nbsp;<a href=\"https://ineffectivealtruismblog.com/2023/07/08/exaggerating-the-risks-part-9-biorisk-grounds-for-doubt/\"><u>Part 9</u></a>, we saw that many leading effective altruists give estimates between 1.0-3.3% for the risk of existential catastrophe from biological causes by 2100. I think these estimates are a bit too high.</p><p>Because I have had a hard time getting effective altruists to tell me directly what the threat is supposed to be, my approach was to first survey the reasons why many biosecurity experts, public health experts, and policymakers are skeptical of high levels of near-term existential biorisk. Parts&nbsp;<a href=\"https://ineffectivealtruismblog.com/2023/07/08/exaggerating-the-risks-part-9-biorisk-grounds-for-doubt/\"><u>9</u></a>,&nbsp;<a href=\"https://ineffectivealtruismblog.com/2023/08/12/exaggerating-the-risks-part-10-biorisk-more-grounds-for-doubt/\"><u>10</u></a>&nbsp;and&nbsp;<a href=\"https://ineffectivealtruismblog.com/2023/10/21/exaggerating-the-risks-part-11-biorisk-still-more-grounds-for-doubt/\"><u>11</u></a>&nbsp;gave a dozen preliminary reasons for doubt, surveyed at the end of&nbsp;<a href=\"https://ineffectivealtruismblog.com/2023/10/21/exaggerating-the-risks-part-11-biorisk-still-more-grounds-for-doubt/\"><u>Part 11</u></a>.</p><p>The second half of my approach is to show that initial arguments by effective altruists do not overcome the case for skepticism. <a href=\"https://ineffectivealtruismblog.com/2023/11/18/exaggerating-the-risks-part-12-millett-and-snyder-beattie-on-biorisk/\"><u>Part 12</u></a> examined a series of risk estimates by Piers Millett and Andrew Snyder-Beattie. We saw, first, that many of these estimates are orders of magnitude lower than those returned by leading effective altruists and second, that Millett and Snyder-Beattie provide little in the way of credible support for even these estimates.</p><p><strong>Today\u2019s post looks at Toby Ord\u2019s arguments in </strong><i><strong>The Precipice</strong></i><strong> </strong>for high levels of existential risk. Ord estimates the risk of irreversible existential catastrophe by 2100 from naturally occurring pandemics at 1/10,000, and the risk from engineered pandemics at a whopping 1/30. That is a very high number. In this post, I argue that Ord does not provide sufficient support for either of his estimates.</p><h3>2. Natural pandemics</h3><p>Ord begins with a discussion of natural pandemics. I don\u2019t want to spend too much time on this issue, since Ord takes the risk of natural pandemics to be much lower than that of engineered pandemics. At the same time, it is worth asking how Ord arrives at a risk of 1/10,000.</p><p>Effective altruists effectively stress that humans have trouble understanding how large certain future-related quantities can be. For example, there might be 10<sup>20</sup>, 10<sup>50</sup> or even 10<sup>100</sup> future humans. <strong>However, effective altruists do not equally stress how small future-related probabilities can be</strong>. Risk probabilities can be on the order of 10<sup>-2</sup> or even 10<sup>-5</sup>, but they can also be a great deal lower than that: for example, 10<sup>-10</sup>, 10<sup>-20</sup>, or 10<sup>-50</sup> [for example, a terrorist attack causing human extinction <a href=\"https://forum.effectivealtruism.org/posts/M6zAzCBAsBxem7Lu4/can-a-terrorist-attack-cause-human-extinction-not-on-priors\">is</a> astronomically unlikely on priors].</p><p>Most events pose existential risks of this magnitude or lower, so if Ord wants us to accept that natural pandemics have a 1/10,000 chance of leading to irreversible existential catastrophe by 2100, Ord owes us a solid argument for this conclusion. It is certainly far from obvious: for example, devastating as the COVID-19 pandemic was, I don\u2019t think anyone believes that 10,000 random re-rolls of the COVID-19 pandemic would lead to at least one existential catastrophe. The COVID-19 pandemic just was not the sort of thing to pose a meaningful threat of existential catastrophe, so if natural pandemics are meant to go beyond the threat posed by the recent COVID-19 pandemic, Ord really should tell us how they do so.</p><p>Ord begins by surveying four historical pandemics: the Plague of Justinian, Black Death, Columbian Exchange, and Spanish Flu. Ord notes that while each of these events led to substantial loss of life, most were met with surprising resilience.</p><blockquote><p>Even events like these fall short of being a threat to humanity\u2019s longterm potential. In the great bubonic plagues we saw civilization in the affected areas falter, but recover. The regional 25 to 50 percent death rate was not enough to precipitate a continent-wide collapse of civilization. It changed the relative fortunes of empires, and may have altered the course of history substantially, but <strong>if anything, it gives us reason to believe that human civilization is likely to make it through</strong> future events with similar death rates, even if they were global in scale.</p></blockquote><p>I drew a similar lesson from the study of historical pandemics in <a href=\"https://ineffectivealtruismblog.com/2023/07/08/exaggerating-the-risks-part-9-biorisk-grounds-for-doubt/\"><u>Part 9</u></a> of this series.</p><p>Next, Ord notes that the fossil record suggests the historical risk of existential catastrophe from naturally occurring pandemics was low:</p><blockquote><p>The strongest case against existential risk from natural pandemics is the fossil record argument from Chapter 3. Extinction risk from natural causes above 0.1 percent per century is incompatible with the evidence of how long humanity and similar species have lasted.</p></blockquote><p>This accords with what we found in <a href=\"https://ineffectivealtruismblog.com/2023/07/08/exaggerating-the-risks-part-9-biorisk-grounds-for-doubt/\"><u>Part 9</u></a> of this series: the fossil record reveals only a single confirmed mammalian extinction due to disease, and that was <a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0003602\"><u>the extinction of a species of rat</u></a>&nbsp;in a very small and remote location (Christmas Island).</p><p>Of course, Ord notes, levels of risk from natural pandemics have changed both for the better and for the worse in recent history. On the one hand, we are more vulnerable because there are more of us, and we live in a denser and more interconnected society. On the other hand, we have excellent medicine, technology, and public health to protect us. For example, we saw in <a href=\"https://ineffectivealtruismblog.com/2023/08/12/exaggerating-the-risks-part-10-biorisk-more-grounds-for-doubt/\"><u>Part 10</u></a> of this series that simple non-pharmaceutical interventions in Wuhan and Hubei may have reduced cases by a factor of 67 by the end of February 2020, and that for the first time a global pandemic was ended in real-time by the development of an effective vaccine.</p><p>So far, we have seen the following: Historical pandemics suggest, if anything, surprising resilience of human civilization to highly destructive events. The fossil record suggests that disease rarely leads to mammalian extinction, and while human society has since changed in some ways that make us more vulnerable than our ancestors were, we have also changed in some ways that make us less vulnerable than our ancestors were. <strong>So far, we have been given no meaningful argument for a 1/10,000 chance</strong> of irreversible existential catastrophe from natural pandemics by 2100. Does Ord have anything in the way of a positive argument to offer?</p><p>Here is the entire remainder of Ord\u2019s analysis of natural pandemics:</p><blockquote><p>It is hard to know whether these combined effects have increased or decreased the existential risk from pandemics. This uncertainty is ultimately bad news: we were previously sitting on a powerful argument that the risk was tiny; now we are not. But note that we are not merely interested in the direction of the change, but also in the size of the change. If we take the fossil record as evidence that the risk was less than one in 2,000 per century, then to reach 1 percent per century the pandemic risk would need to be at least 20 times larger. This seems unlikely. In my view, the fossil record still provides a strong case against there being a high extinction risk from \u201cnatural\u201d pandemics. So most of the remaining existential risk would come from the threat of permanent collapse: a pandemic severe enough to collapse civilization globally, combined with civilization turning out to be hard to re-establish or bad luck in our attempts to do so.</p></blockquote><p>What is the argument here? Certainly Ord makes a welcome concession in this passage: since natural pandemics are unlikely to cause human extinction in this century, most of the risk should come from threats of civilizational collapse. But that isn\u2019t an argument. It\u2019s a way of setting the target that Ord needs to argue for. Why think that civilization stands a 1/10,000 risk of collapse, let alone permanent collapse without recovery, by 2100 due to natural pandemics? <strong>We really haven\u2019t been given any substantive argument at all for this conclusion.</strong></p><h3>3. Laboratory research</h3><p>Another potential biorisk is the threat posed by unintentional release of pathogens from research laboratories. Ord notes that biological research is progressing quickly:</p><blockquote><p>Progress is continuing at a rapid pace. The last ten years have seen major qualitative breakthroughs, such as the use of CRISPR to efficiently insert new genetic sequences into a genome and the use of gene drives to efficiently replace populations of natural organisms in the wild with genetically modified versions. Measures of this progress suggest it is accelerating, with the cost to sequence a genome falling by a factor of 10,000 since 2007 and with publications and venture capital investment growing quickly. This progress in biotechnology seems unlikely to fizzle out soon: there are no insurmountable challenges looming; no fundamental laws blocking further developments.</p></blockquote><p>That\u2019s fair enough. But how do we get from there to a 1/30 chance of existential catastrophe?</p><p>Ord begins by discussing the advent of gain-of-function research, focusing on a Dutch researcher Ron Fouchier who passed strains of H5N1 through ferrets until it gained the ability to be transmitted between mammals. That is, by now, old news. Indeed, we saw in <a href=\"https://ineffectivealtruismblog.com/2023/11/18/exaggerating-the-risks-part-12-millett-and-snyder-beattie-on-biorisk/\"><u>Part 12</u></a> of this series that the US Government commissioned in 2014 <a href=\"https://osp.od.nih.gov/wp-content/uploads/2015/12/Risk%20and%20Benefit%20Analysis%20of%20Gain%20of%20Function%20Research%20-%20Draft%20Final%20Report.pdf\"><u>a thousand-page report</u></a> on the risks and benefits of gain-of-function research. That report <strong>made no mention of existential risks</strong> of any kind: the largest casualty figure modeled in this report is 80 million.</p><p>Does Ord provide an argument to suspect that gain-of-function research could lead to existential catastrophe? Ord goes on to discuss the risks of laboratory escapes. These are, again, well-known and discussed in the mainstream literature, including the <a href=\"https://osp.od.nih.gov/wp-content/uploads/2015/12/Risk%20and%20Benefit%20Analysis%20of%20Gain%20of%20Function%20Research%20-%20Draft%20Final%20Report.pdf\"><u>government report</u></a> featured in <a href=\"https://ineffectivealtruismblog.com/2023/11/18/exaggerating-the-risks-part-12-millett-and-snyder-beattie-on-biorisk/\"><u>Part 12</u></a> of this series. Ord concludes from this discussion that:</p><blockquote><p>In my view, this track record of escapes shows that even BSL-4 is insufficient for working on pathogens that pose a risk of <strong>global pandemics on the scale of the 1918 flu or worse</strong>\u2014especially if that research involves gain-of-function.</p></blockquote><p>But this is simply not what is at issue: no one thinks that pandemics like the 1918 flu or COVID-19 pandemic pose a 1/30 chance of irreversible existential catastrophe by 2100. Perhaps the argument is meant to be contained in the final phrase (\u201c1918 flu <i>or worse</i>\u201c), but if this is the view, it isn\u2019t an argument, merely a statement of Ord\u2019s view.</p><p>Aside from a list of notable laboratory escapes, this is the end of Ord\u2019s discussion of risks posed by unintentional release of pathogens from research laboratories. Is this discussion meant to ground a 1/30 risk of existential catastrophe by 2100? I hope not, because there is nothing in the way of new evidence in this section, and very little in the way of argument.</p><h3>4. Bioweapons</h3><p>The final category of biorisk discussed by Ord is the risk posed by biological weapons. Ord begins by reviewing historical bioweapons programs, including the Soviet bioweapons program as well as biowarfare by the British army in Canada in the 18th century CE, ancient biowarfare in Asia Minor in the 13th century BCE, and potential intentional spread of the Black Death by invading Mongol armies.</p><p>I also discussed the Soviet bioweapons program in <a href=\"https://ineffectivealtruismblog.com/2023/07/08/exaggerating-the-risks-part-9-biorisk-grounds-for-doubt/\"><u>Part 9</u></a> of this series, since it is the most advanced (alleged) bioweapons program of which I am aware. We saw there that <a href=\"https://link.springer.com/article/10.1057/biosoc.2013.38\"><u>a leading bioweapons expert</u></a> drew the following conclusion from study of the Soviet bioweapons program:</p><blockquote><p>In the 20 years of the Soviet programme, with all the caveats that we don\u2019t fully know what the programme was, but from the best reading of what we know from the civil side of that programme, they really didn\u2019t get that far in creating agents that actually meet all of those criteria [necessary for usefulness in biological warfare]. They got somewhere, but they didn\u2019t get to the stage where they had a weapon that changed their overall battlefield capabilities; that would change the outcome of a war, or even a battle, over the existing weapon systems available to them.</p></blockquote><p>Ord\u2019s discussion of the Soviet bioweapons program tends rather towards omission of the difficulties posed by the program, instead playing up its dangers:</p><blockquote><p>The largest program was the Soviets\u2019. At its height it had more than a dozen clandestine labs employing 9,000 scientists to weaponize diseases ranging from plague to smallpox, anthrax and tularemia. Scientists attempted to increase the diseases\u2019 infectivity, lethality and resistance to vaccination and treatment. They created systems for spreading the pathogens to their opponents and built up vast stockpiles, reportedly including more than 20 tons of smallpox and of plague. The program was prone to accidents, with lethal outbreaks of both smallpox and anthrax \u2026 While there is no evidence of deliberate attempts to create a pathogen to threaten the whole of humanity, the logic of deterrence or mutually assured destruction could push superpowers or rogue states in that direction.</p></blockquote><p>I\u2019m a bit disappointed by the selective use of details here. We are told all of the most frightening facts about the Soviet program: how many scientists they employed, how large their stockpiles were, and how they were prone to accidents. But we aren\u2019t told how far they fell from their goal of creating a successful bioweapon.</p><p>Is there anything in this passage that grounds a case for genuine <i>existential</i> risk? Ord notes that: \u201cWhile there is no evidence of deliberate attempts to create a pathogen to threaten the whole of humanity, <strong>the logic of deterrence or mutually assured destruction</strong> could push superpowers or rogue states in that direction.\u201d. What should we make of this argument? Well, what we should do with this argument is to ask Ord for more details.</p><p>We\u2019ve seen throughout Parts 9, 10 and 11 of this series that it is extremely difficult to engineer a pathogen which could lead to existential catastrophe. Ord seems to be claiming not only that such a pathogen could be developed in this century, but also that states may soon develop such a pathogen as a form of mutually assured destruction. Both claims need substantial argument, the latter not least because humanity already has access to a much more targeted deterrent in the form of nuclear weapons. That isn\u2019t to say that Ord\u2019s claim here is <i>false</i>, but it is to say that a single sentence won\u2019t do. If there is a serious case to be made that states can, and soon may develop pathogens which could lead to existential catastrophe in order to deter others, that case needs to be made with the seriousness and care that it deserves.</p><p>Ord notes that historical data does not reflect substantial casualties from bioweapons. However, Ord suggests, we may have too little data to generalize from, and in any case the data suggests a \u201cpower law\u201d distribution of fatalities that may favor high estimates of existential risk. That\u2019s fair enough, though we saw in <a href=\"https://ineffectivealtruismblog.com/2023/11/18/exaggerating-the-risks-part-12-millett-and-snyder-beattie-on-biorisk/\"><u>Part 12</u></a> that power law estimates of existential biorisk face substantial difficulties, and also that the most friendly published power law estimate puts the risks orders of magnitude lower than Ord does.</p><p>From here, Ord transitions into a discussion of the dangers posed by the democratization of biotechnology and the spread of `do-it-yourself\u2019 science. Ord writes:</p><blockquote><p>Such democratization promises to fuel a boom of entrepreneurial biotechnology. But since biotechnology can be misused to lethal effect, democratization also means proliferation. As the pool of people with access to a technique grows, so does the chance it contains someone with malign intent.</p></blockquote><p>We discussed the risk of `do-it-yourself\u2019 science in <a href=\"https://ineffectivealtruismblog.com/2023/08/12/exaggerating-the-risks-part-10-biorisk-more-grounds-for-doubt/\"><u>Part 10</u></a> of this series. There, we saw that <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0040162520309537#sec0010\"><u>a paper by David Sarapong and colleagues</u></a> laments \u201cSensational and alarmist headlines about DiY science\u201d which \u201cargue that the practice could serve as a context for inducing rogue science which could potentially lead to a \u2018zombie apocalypse\u2019.\u201d <strong>These experts find little empirical support for any such claims.</strong></p><p>That skepticism is echoed by most leading experts and policymakers. For example, we also saw in Part 10 that a study of risks from synthetic biology by <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4139924/\"><u>Catherine Jefferson and colleagues</u></a> decries the \u201cmyths\u201d that \u201csynthetic biology could be used to design radically new pathogens\u201d and \u201cterrorists want to pursue biological weapons for high consequence, mass casualty attacks\u201d, concluding:</p><blockquote><p>Any bioterrorism attack will most likely be one using a pathogen strain with less than optimal characteristics disseminated through crude delivery methods under imperfect conditions, and the potential casualties of such an attack are likely to be much lower than the mass casualty scenarios frequently portrayed. This is not to say that speculative thinking should be discounted \u2026 however, problems arise when these speculative scenarios for the future are distorted and portrayed as scientific reality.</p></blockquote><p>The experts are skeptical. Does Ord give us any reason to doubt this expert consensus? The only remaining part of Ord\u2019s analysis is the following:</p><blockquote><p>People with the motivation to wreak global destruction are mercifully rare. But they exist. Perhaps the best example is the Aum Shinrikyo cult in Japan, active between 1984 and 1995, which sought to bring about the destruction of humanity. They attracted several thousand members, including people with advanced skills in chemistry and biology. And they demonstrated that it was not mere misanthropic ideation. They launched multiple lethal attacks using VX gas and sarin gas, killing 22 people and injuring thousands. They attempted to weaponize anthrax, but did not succeed.<strong> </strong>What happens when the circle of people able to create a global pandemic becomes wide enough to include members of such a group? Or members of a terrorist organization or rogue state that could try to build an omnicidal weapon for the purposes of extortion or deterrence?</p></blockquote><p>The first half of this paragraph suggests that although few sophisticated groups would want to cause an existential catastrophe, some such as Aum Shinrikyo have had that motivation. <strong>The best thing to say about this claim is that it isn\u2019t what is needed:</strong> we were looking for an argument that advances in biotechnology will <i>enable</i> groups to bring about existential catastrophe, not that groups will be motivated to do so. However, we also saw in <a href=\"https://ineffectivealtruismblog.com/2023/05/19/epistemics-part-2-examples/\"><u>Part 2</u></a> of my series on epistemics that this claim is false: Aum Shinrikyo did not seek to \u201cbring about the destruction of humanity,\u201d and the falsity of this claim is clear enough from the research record that it is hard to understand why Ord would be repeating it.</p><p>The second half of this paragraph concludes with two leading questions: \u201cWhat happens when the circle of people able to create a global pandemic becomes wide enough to include members of such a group? Or members of a terrorist organization or rogue state that could try to build an omnicidal weapon for the purposes of extortion or deterrence?\u201d But questions are not arguments, and they are especially not arguments for what Ord needs to show: that the democratization of biotechnology will soon provide would-be omnicidal actors with the means to bring about existential catastrophe.</p><h3>5. Governance</h3><p>The chapter concludes with a discussion of some ways that biohazards might be governed, and some failures of current approaches. <strong>I don\u2019t want to dwell on these challenges, in large part because I agree with most of them</strong>, though I would refer readers to <a href=\"https://ineffectivealtruismblog.com/2023/05/19/epistemics-part-2-examples/\"><u>Part 2</u></a> of my series on epistemics for specific disagreements about the tractability of progress in this area.</p><p>Ord begins by noting that since its founding, the Biological Weapons Convention (BWC) has been plagued with problems. The BWC has a minuscule staff and no effective means of monitoring or enforcing compliance. This limits the scope of international governance of biological weapons.</p><p>Ord notes that synthetic biology companies often make voluntary efforts to manage the risks posed by synthetic biology, such as screening orders for dangerous compounds. This is not surprising: theory suggests that large companies will often self-regulate as a strategy for avoiding government regulation. As Ord notes, there is some room for improvement: only about 80% of orders are screened, and future advances may make screening more difficult. That is fair enough.</p><p>Ord observes that the scientific community has also tried to self-regulate, though with mixed success.</p><p>All of this is quite reasonable, but it does not do much to bolster the fundamental case for a 1/30 risk of existential catastrophe from engineered pandemics by 2100. It might make it easier for those already convinced of the risk to see how catastrophes could fail to be prevented, but <strong>what we really need from Ord is more argument bearing on the nature and prevalence of the underlying risks.</strong></p><h3>6. Taking stock</h3><p>Toby Ord claims that there is a 1/30 chance of irreversible existential catastrophe by 2100 from engineered pandemics. That is an astoundingly high number.</p><p>We saw in Parts 9-11 of <a href=\"https://ineffectivealtruismblog.com/category/exaggerating-the-risks/biorisk/\"><u>this series</u></a> that most experts are deeply skeptical of Ord\u2019s claim, and that there are at least a dozen reasons to be wary. This means that we should demand especially detailed and strong arguments from Ord to overcome the case for skepticism.</p><p>Today\u2019s post reviewed every argument, or in many cases every hint of an argument made by Ord in support of his risk estimates. We found that Ord draws largely on a range of familiar facts about biological risk which are common ground between Ord and the skeptical expert consensus. We saw that Ord gives few detailed arguments in favor of his risk estimates, and that those arguments given fall a good deal short of Ord\u2019s argumentative burden.</p><p>We also saw that Ord estimates a 1/10,000 chance of irreversible existential catastrophe by 2100 from natural pandemics. Again, we saw that very little support is provided for this estimate.</p><p>This isn\u2019t a situation that should sit comfortably with effective altruists. <a href=\"https://ineffectivealtruismblog.com/2023/10/07/epistemics-part-6-extraordinary-claims-require-extraordinary-evidence/\"><u>Extraordinary claims require extraordinary evidence</u></a>, yet <strong>here as so often before, extraordinary claims about future risks are supported by rather less than extraordinary evidence. </strong>Much more is needed to ground high risk estimates, so we will have to look elsewhere for arguments in favor of high risk estimates.</p>", "user": {"username": "vascoamaralgrilo"}}, {"_id": "y2irsYbbp8jtBJpdh", "title": "What posts does the EA Forum appreciate, and what posts does it need more of?", "postedAt": "2023-12-29T17:06:19.213Z", "htmlBody": "<p>I think there are people who'd like to contribute to the forum but aren't sure what to add. A common (and reasonable) view is that there are already so many important ideas to read, so you should only add to the pile if you've got something truly worth posting.<br>To offer clarity to people wanting to contribute to the forum, input from the community is best: What is worth posting? What posts does the forum benefit from? What posts does it need more of?</p>", "user": {"username": "NicholasNicholas"}}, {"_id": "bkchwgNL9zh44o3oe", "title": "Malaria Vaccine Research Help Needed", "postedAt": "2023-12-29T17:05:14.269Z", "htmlBody": "<p>We at 1Day Sooner posted&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/xcYGKayQte3fQ3MuA/help-needed-in-push-for-a-rapid-malaria-vaccine-rollout\"><u>recently</u></a> about scoping a campaign to push for an accelerated rollout of the newly approved R21/Matrix-M malaria vaccine. The vaccine was recently prequalified by the WHO, a key step on the critical path to vaccine distribution, but much remains to be done.&nbsp;</p><p>We greatly appreciate the more than a dozen people who reached out to help after our last post. Their work was invaluable for producing our December <a href=\"https://1dayafrica.org/s/Malaria-Vaccination-Status-Report-December-2023-corrected-1229.pdf\">Malaria Vaccination Status Report</a>, the development of which has been critical to improving our understanding of the problem. Our colleague Zacharia Kafuko's <a href=\"https://foreignpolicy.com/2023/12/08/new-malaria-vaccine-africa-world-health-organization-child-mortality/\">op-ed</a> as well as <a href=\"https://www.project-syndicate.org/commentary/new-low-cost-malaria-vaccine-could-save-millions-by-peter-singer-2023-12\">Peter Singer's </a>on the subject are also both good sources for further reading.</p><p>We plan to publish a new status report every month and maintain a <a href=\"https://docs.google.com/document/d/1uDITA5JAOFzajN7hE2OVovvvRTqdmlBhjfDfL9rkl6Y/edit#heading=h.thhsqfw2yo71\">rolling public comment version</a> to reflect our latest understanding of the issue and use as a sort of global workspace to share the most critical information about obstacles and enablers for widespread distribution. To make our research work for this more sustainable we're moving to a pool system where members sign up for at least four days out of the month where they will be assigned a 1-2.5 hour research or writing task to update and improve our status report document. Pool members will be paid $100 per pool day. (<a href=\"https://docs.google.com/document/d/1rxPYUlFO8NWFLcUwFMWklsLSAfVRYggVW-5_7lYfFC4/edit\">Here</a> is a punch list of the type of goals we have for our next draft. Further details on the pool structure can be found&nbsp;<a href=\"https://docs.google.com/document/d/1phD4s8Gt4M1iQ8X8gdtz1VygIs9CSofbjDF9k4Zn168/edit\"><u>here</u></a>.).&nbsp;</p><p>We are looking to add 5-10 new pool members for January beyond those who signed up last month. If you're interested in helping, please fill out the google form linked here [edit: we have received a large amount of interest and are pausing sign ups for the moment].</p><p>Questions and comments are very welcome. Thanks!</p><p>&nbsp;</p><p>&nbsp;</p><p><br>&nbsp;</p>", "user": {"username": "joshcmorrison"}}, {"_id": "4ShHKntno9zA7xxPj", "title": "Tips and Links for End of Year Giving", "postedAt": "2023-12-29T14:06:29.698Z", "htmlBody": "<p>This weekend is our last chance to get 2023 donations in! Below are some links and resources which might be helpful.&nbsp;</p><h3>Why donate this weekend?&nbsp;</h3><ul><li><strong>31st of December is </strong><a href=\"https://www.givedirectly.org/end-of-year-giving-guidelines/\"><strong>the last day to claim donations</strong></a><strong> on your 2023 tax return (US).</strong> More info on the tax deductibility of donations is&nbsp;<a href=\"http://v\"><u>here</u></a>.</li><li><strong>Satisfying mental accounting, or keeping pledges.</strong> It\u2019s pretty satisfying to be able to say that you gave a nice round percentage of your income in 2023. Being able to fulfil a specific percentage is especially important for anyone who has taken a&nbsp;<a href=\"https://www.givingwhatwecan.org/pledge\"><u>Giving What We Can Pledge</u></a>, a&nbsp;<a href=\"https://www.givingwhatwecan.org/en-US/get-involved/trial-pledge?slug=get-involved&amp;slug=trial-pledge\"><u>trial pledge</u></a>, or has loudly pledged to friends (like me).&nbsp;</li><li><strong>You get to put a heart on&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/\"><strong><u>the banner</u></strong></a><strong>.&nbsp;</strong></li></ul><h3>Where to donate:&nbsp;</h3><ul><li><strong>If you\u2019re strapped for time:</strong><ul><li><strong>Give to an expert-led fund </strong>(<a href=\"https://www.givingwhatwecan.org/en-US/charities/animal-welfare-fund\">animals</a>, <a href=\"https://www.givingwhatwecan.org/en-US/charities/long-term-future-fund\">longterm</a>, <a href=\"https://www.givingwhatwecan.org/en-US/charities/global-health-and-development-fund\">global health</a>, <a href=\"https://www.givingwhatwecan.org/en-US/charities/effective-altruism-infrastructure-fund\">EA</a>)<strong>.&nbsp;</strong>Grant-makers at a fund will spend a long time assessing the absolute best places to donate the money in their care. Donating to a fund which shares your values is a great way to multiply the impact of your donations. In short,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3wgnrwlnq22\"><sup><a href=\"#fn3wgnrwlnq22\">[1]</a></sup></span>&nbsp;the argument is that evaluators at the fund will have more time, skill and resources to spend on charity evaluation than the average donor, and will often have access to donation opportunities which donors don\u2019t. The GWWC donation platform features a list of these&nbsp;<a href=\"https://www.givingwhatwecan.org/en-US/donate/organizations\"><u>funds</u></a>.&nbsp;</li><li><strong>Or, a Donor Lottery.&nbsp;</strong>A donor lottery raises money, and then gives the responsibility for deciding where the money goes to just one of the lottery\u2019s donors. The winner pre-commits to spending some time seriously thinking about where the money should go, so this is another opportunity to multiply the impact of your donation without spending the time yourself.&nbsp;<a href=\"https://www.givingwhatwecan.org/donor-lottery/227966102255917\"><u>This donor lottery</u></a> is open at GWWC right now.&nbsp;</li><li><strong>Or, defer to the Forum. </strong>Our Donation Election just concluded, with 341 Forum users voting. If you like, you can take <a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023\">the results</a> as donation recommendations.&nbsp;</li></ul></li><li><strong>If you have more time to do analysis yourself:</strong><ul><li><strong>Read posts about funding gaps</strong> on the Forum. During Marginal Funding week the Forum elicited information from a broad range of charities about what they would do with extra funding, and how large their funding gaps are this year. If you have time, check out some of the funding gaps info (you can find a brief summary for all the marginal funding posts on the Forum&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023\"><u>in here</u></a>, a collection of the full posts&nbsp;<a href=\"https://forum.effectivealtruism.org/s/xourt4HttDM5QcHsk\"><u>here</u></a>, and detailed responses from more charities in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/pj8AkRdhwtnEhNhCW/how-would-your-project-use-extra-funding-marginal-funding\"><u>this thread</u></a>).</li><li><strong>Hone your cross-cause opinions.</strong> Perhaps the most impactful donation decision you make is the cause area you choose to support. For someone with an afternoon to spare, Rethink Priorities\u2019 new&nbsp;<a href=\"https://ccm.rethinkpriorities.org/#baseAnimalIntervention=XHnamejGSNic+CL+CampaignRareaHdescriptOAn+KTimqTt+imVvx+the+W+of+egg-layx%5CnhSs+or+broilN+cLs+through+corporateTdvocacy.RvNsO1RYjcLRuseP%21true%7EVp_affectq*JUF5E001DUF01E005Zhours_spSt_I*B8.21917808219178e-7EFQ5Q6D0E95ZVp_I_rqucq*JU5E9DU1E99ZVb_success*JU2E8DU05E95Zcost_of_K*J15FM0D1F0M0ZpNsistSce*J5%2C20D1%2CnullZI_years_pN_dollarP*B160%2C3630D16M4%29*%21XjconfidSceRdistributO4zrqibility%2190%29BnormalRrange%21%5BDzlip%21%5BE%2CUF0000HjY-WRIsuffNxJlogBKintNvStionLhickSM%2C1F0NerOionjP_ovNrideQ7077625R%27%7ESenT+aU0.VproWwelfareX%28%27typeYanimalZ4%7Ej%21%27qedxingz%5D%7Ec%01zxqjZYXWVUTSRQPONMLKJIHFEDB4*_&amp;customAnimalIntervention=XHnamejGSNic+CL+CampaignRareaHdescriptOAn+KTimqTt+imVvx+the+W+of+egg-layx%5CnhSs+or+broilN+cLs+through+corporateTdvocacy.RvNsO1RYjcLRuseP%21true%7EVp_affectq*JUF5E001DUF01E005Zhours_spSt_I*B8.21917808219178e-7EFQ5Q6D0E95ZVp_I_rqucq*JU5E9DU1E99ZVb_success*JU2E8DU05E95Zcost_of_K*J15FM0D1F0M0ZpNsistSce*J5%2C20D1%2CnullZI_years_pN_dollarP*B160%2C3630D16M4%29*%21XjconfidSceRdistributO4zrqibility%2190%29BnormalRrange%21%5BDzlip%21%5BE%2CUF0000HjY-WRIsuffNxJlogBKintNvStionLhickSM%2C1F0NerOionjP_ovNrideQ7077625R%27%7ESenT+aU0.VproWwelfareX%28%27typeYanimalZ4%7Ej%21%27qedxingz%5D%7Ec%01zxqjZYXWVUTSRQPONMLKJIHFEDB4*_\"><u>cross-cause cost-effectiveness model</u></a> (a work in progress), is a fun way to put some numbers on your thinking, and test your assumptions. For more details, check out <a href=\"https://forum.effectivealtruism.org/posts/pniDWyjc9vY5sjGre/rethink-priorities-cross-cause-cost-effectiveness-model\">this post</a>.&nbsp;</li></ul></li></ul><p><br>If you do donate this weekend, consider sharing your decisions on&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/rszgfHdkmzCDDPM9k/where-are-you-donating-this-year-and-why-open-thread-1\"><u>our where are you donating thread</u></a>.&nbsp;</p><p>If you have more helpful advice for donors (ideally advice that isn't \"donate to my charity\") I'd love it if you commented it here.&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3wgnrwlnq22\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3wgnrwlnq22\">^</a></strong></sup></span><div class=\"footnote-content\"><p>And in <a href=\"https://www.givingwhatwecan.org/en-US/why-we-recommend-funds\">long</a>.&nbsp;</p></div></li></ol>", "user": {"username": "tobytrem"}}, {"_id": "rQTZPsXGDj2C8ejxw", "title": "Resources for farmed animal advocacy: 2023 roundup ", "postedAt": "2023-12-29T13:53:09.998Z", "htmlBody": "<p>Tl;dr - This is a curated and useful list of farmed animal advocacy resources that came out in 2023. We (Impactful Animal Advocacy) sent this compilation out in our <a href=\"https://imaa.me/3RInTMB\">free bi-weekly newsletter</a> and thought it might be helpful to others in the EA community.</p><p>There is is not a comprehensive collection of all resources, but if we missed any that you found significant from 2023, feel free to add as a comment.</p><p>Enjoy and here is to even more impact for the animals in 2024!\ud83c\udf89</p><p><strong>Acknowledgements:</strong> thanks so much to our Comms Lead Allison Agnello for this edition, as well as our readers, who viewed this newsletter 20,000 times in 2023! \ud83d\ude4f</p><p>&nbsp;</p><h1>Themes</h1><p>Over the past 12 months of curating Impactful Animal Advocacy (IAA) newsletters, we\u2019ve noticed several trends. Here are two that are prominent in our collection of 2023 resources:<br>&nbsp;</p><h2><strong>\ud83c\udfd7\ufe0f Movement infrastructure</strong></h2><p>In the animal advocacy movement\u2019s growth this year, we\u2019ve seen an increase in services provided directly to animal advocates or organizations. There has been so many new initiatives that we developed a <a href=\"https://www.notion.so/Meta-resources-12ef5f4692fc4e4b8b43d8368a4ac663?pvs=21\"><u>Meta resources wiki</u></a> to keep track of them all! This expansion reflects a recognition of the diverse needs within the community and how projects can benefit from support and area specialization. Here are a few categories of increased infrastructure:</p><ul><li>New meta organizations (<a href=\"https://www.themissionmotor.org/\"><u>The Mission Motor</u></a>, <a href=\"https://nfps.ai/\"><u>NFPs.AI</u></a>, <a href=\"https://www.impactfulanimaladvocacy.org/\"><u>us!</u></a>)</li><li>Advocate training courses (<a href=\"https://impactfulanimal.substack.com/i/139769057/continuing-education\"><u>See section below</u></a>)</li><li>Supporting groups in developing countries (<a href=\"https://www.animaladvocacyafrica.org/our-progress\"><u>Animal Advocacy Africa</u></a>, <a href=\"https://www.goodgrowth.io/\"><u>Good Growth</u></a>, <a href=\"https://www.linkedin.com/posts/thrivephilanthropy_thrive-philanthropy-is-thrilled-to-announce-activity-7142579002107457536-2YPG\"><u>Thrive</u></a>)<br>&nbsp;</li></ul><h2><strong>\ud83d\udccf Refining how we measure and compare across species</strong></h2><p>Given the large number of possible ways to help animals, selecting the most impactful approach can be challenging. This year, we've witnessed a increase in research accessibility and applicability for advocates. This is not just about providing information \u2014 it's about helping us integrate this knowledge into practical strategies. As a result, advocates may be better equipped to make informed decisions on where to focus their efforts across different species and geographic regions. Here are a few projects we\u2019ve seen trying to answer key questions:</p><ul><li>How one might compare welfare across species (<a href=\"https://forum.effectivealtruism.org/s/y5n47MfgrKvTLE3pw\"><u>Moral Weight Project sequence</u></a>)</li><li>How much pain do different species endure (<a href=\"https://welfarefootprint.org/\"><u>Welfare Footprint Project</u></a>) - watch the recording of the workshop we hosted for them <a href=\"https://imaa.me/46S38U8\"><u>here</u></a></li><li>How bad is brief, severe pains versus chronic, milder pains (<a href=\"https://rethinkpriorities.org/publications/dimensions-of-pain-workshop-summary-and-updated-conclusions\"><u>Dimensions of Pain</u></a>)</li><li>How many animals are impacted, and where (<a href=\"https://ourworldindata.org/animal-welfare\"><u>Our World in Data</u></a>)</li></ul><p>&nbsp;</p><h1>Updates we found helpful</h1><p>So much has happened this year. Here are a few articles to catch you up \ud83d\udc47</p><h3>\ud83e\uddd0 Looking back at 2023</h3><ul><li><a href=\"https://sentientmedia.org/the-year-in-review-2023/\"><u>The Year in Review: 2023</u></a>, Sentient Media</li><li><a href=\"https://sentientmedia.org/animal-policy-stories-2023/\"><u>Top animal policy stories of 2023</u></a>, Sentient Media</li><li><a href=\"https://farmanimalwelfare.substack.com/p/a-year-of-wins-for-farmed-animals\"><u>A year of wins for farmed animals</u></a>, Lewis Bollard</li><li><a href=\"https://www.greenqueen.com.hk/top-alternative-protein-stories-2023-plant-based-cultured-meat/\"><u>Top 20 Alt-Protein Stories of the Year</u></a>, Green Queen</li><li><a href=\"https://agfundernews.com/agfundernews-favorite-stories-of-2023-the-good-the-bad-and-the-ugly-of-agrifoodtech\"><u>AgFunderNews\u2019 favorite agrifoodtech stories of 2023</u></a></li><li><a href=\"https://www.vox.com/23950804/future-perfect-50-list-2023-ai-animal-rights-poverty-health-climate\"><i><u>2023 Future Perfect 50</u></i><u> recognizes 9 animal advocate changemakers</u></a><br>&nbsp;</li></ul><h3>\ud83e\udde0 Some lessons learned</h3><ul><li><a href=\"https://www.animaladvocacyafrica.org/blog/running-cage-free-programmes-in-africa-case-studies-of-three-africa-animal-welfare-organizations\"><u>Running Cage-Free Projects in Africa: Case Studies of Three African Animal Advocacy Organisations</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/gDRH2SrN34KdDvmHE/abolishing-factory-farming-in-switzerland-postmortem\"><u>Abolishing factory farming in Switzerland: Postmortem</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/Qo3559TqP5BzoQyWX/two-years-of-shrimp-welfare-project-insights-and-impact-from\"><u>2 Years of Shrimp Welfare Project: Insights and Impact from our Explore Phase</u></a></li><li><a href=\"https://rethinkpriorities.org/publications/a-cost-effectiveness-analysis-of-historical-farmed-animal-welfare-ballot-initiatives\"><u>Historical farmed animal welfare ballot initiatives</u></a></li><li><a href=\"https://www.socialchangelab.org/post/how-did-animal-rising-s-protest-impact-public-attitudes-towards-animals\"><u>Animal Rising's Grand National protest: Public opinion impacts</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/Zck3mJjFB67cpEsJw/stakeholder-engaged-research-in-emerging-markets-how-do-we\"><u>Stakeholder-engaged research in emerging markets</u></a></li><li><a href=\"https://www.fishwelfareinitiative.org/post/strategy-2023\"><u>Fish Welfare Initiative\u2019s continued work in India</u></a> and <a href=\"https://www.fishwelfareinitiative.org/post/china-updates\"><u>pausing work in China</u></a></li></ul><p>&nbsp;</p><h1>Resources</h1><h2>\ud83c\udf31 Getting started</h2><h3>New animal subgroups resources:</h3><ul><li><a href=\"https://faunalytics.org/fundamentals/\"><u>Faunalytics Fundamentals</u></a>: a series of topic overviews and resources, such as on <a href=\"https://faunalytics.org/fundamentals-farmed-animals/\"><u>farmed animals</u></a>, <a href=\"https://faunalytics.org/fundamentals-wildlife/\"><u>wildlife</u></a>, <a href=\"https://faunalytics.org/fundamentals-invertebrates/\"><u>invertebrates</u></a>, etc</li><li><a href=\"https://impactfulaa.notion.site/Wild-Animals-Wiki-54731db91d7945de9690068bb5bc914a?pvs=74\"><u>Wild Animals Wiki</u></a> and <a href=\"https://www.animal-ethics.org/contraception-wild-animals-mammals/\"><u>a review of contraception methods for wild mammals</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/YcDXWTzyyfHQHCM4q/a-primer-for-insect-sentience-and-welfare-as-of-sept-2023\"><u>A Primer on insect sentience and welfare</u></a></li><li><a href=\"https://forum.effectivealtruism.org/s/GLKcpn4KWcJdNGnmD\"><u>Shrimp Welfare Sequence</u></a>, Rethink Priorities</li></ul><h3>Find a job:</h3><ul><li><a href=\"https://www.animaladvocacycareers.org/job-board\"><u>Animal Advocacy Careers, </u></a><a href=\"https://talist.org/job-board\"><u>T\u00e4list</u></a> and <a href=\"https://altproteincareers.com/jobs\"><u>Alt Protein Careers</u></a> job boards</li><li><a href=\"https://forum.effectivealtruism.org/posts/X4YYZHX8SgkDDAZgW/resources-pursuing-a-career-in-animal-advocacy-even-if-you\"><u>Resources on pursuing a career in animal advocacy</u></a></li></ul><h3>Get funding:</h3><ul><li><a href=\"https://impactfulaa.notion.site/51b17672baf849eda80a1fe7c865c3f1?v=389f21de444d4c809adee32a19196ebd\"><u>Fundraising for Animal Advocacy Wiki</u></a></li></ul><h3>Attend an event or conference</h3><ul><li><a href=\"https://impactfulaa.notion.site/Conferences-Database-Farmed-Animal-Advocacy-9ba547575d0147d09e4d3ca55da54527\"><u>Conferences Database: Farmed Animal Advocacy</u></a></li><li><a href=\"https://connectforanimals.com/events\"><u>Connect For Animals</u></a> event platform</li><li>Organize or build a community: <a href=\"https://impactfulaa.notion.site/Community-Building-14092015abb34c999677200d3344896e?pvs=4\"><u>Community Building Wiki</u></a></li></ul><h3>Other information databases:</h3><ul><li><a href=\"https://ourworldindata.org/animal-welfare\"><u>Our World in Data\u2019s Animal Welfare page</u></a>, data explorer, research, and interactive charts</li><li><a href=\"https://www.animalwelfarelibrary.org/library-advanced\"><u>Animal Welfare Library</u></a></li><li><a href=\"https://animaldataproject.org/\"><u>Animal Data Project</u></a></li><li><a href=\"https://animalcharityevaluators.org/blog/farmed-animal-advocacy-organizations/\"><u>List of farmed animal advocacy organizations</u></a>, ACE<br>&nbsp;</li></ul><h2>\ud83d\udce3 Advocacy resources</h2><p>For org leaders:</p><ul><li><a href=\"https://forum.effectivealtruism.org/s/h7L3RsEcYghgnJk2x/p/Sp6rGZcmqCc7FMQCL\"><u>An Impact Roadmap</u></a>, Aaron Boddy shares a comprehensive writeup about program development methodologies</li><li><a href=\"https://www.scarletspark.org/tools\"><u>Leadership Tools</u></a>, Scarlet Spark</li><li><a href=\"https://impactfulaa.notion.site/Founders-and-leaders-resources-bab81dbf22134349b740ca4180be2b33\"><u>Founders and leaders resources</u></a>, IAA (us!)</li></ul><p>For communicators &amp; journalists:</p><ul><li><a href=\"https://animalthinktank.org.uk/narrative/narrative-research/\"><u>Narrative research</u></a>, Animal Think Tank</li><li><a href=\"https://bit.ly/FFMediaNetwork\"><u>Food &amp; Farming Media Network</u></a>, Sentient Media</li><li><a href=\"https://veganhacktivists.org/blog/top-5-challenge-brand-design\"><u>Brand design challenges in animal advocacy</u></a>, Vegan Hacktivists</li><li><a href=\"https://commonslibrary.org/\"><u>The Commons Social Change Library</u></a></li></ul><p>Animal Charity Evaluators updates:</p><ul><li><a href=\"https://animalcharityevaluators.org/blog/announcing-our-2023-charity-recommendations/\"><u>2023 charity recommendations</u></a> and <a href=\"https://animalcharityevaluators.org/blog/announcing-our-2023-movement-grants/\"><u>Movement Grant recipients</u></a></li><li><a href=\"https://animalcharityevaluators.org/blog/updates-to-our-charity-evaluation-criteria-in-2023/\"><u>Updates to their charity evaluations criteria</u></a></li></ul><p>New Vegan Hacktivist projects:</p><ul><li><a href=\"https://todayforanimals.org/\"><u>Today for Animals</u></a>, a web app that encourages small, daily actions</li><li><a href=\"https://veganhacktivists.org/blog/introducing-granti\"><u>Granti</u></a>, a comprehensive tool designed to streamline the grant management process for both grantees and funders</li></ul><p>&nbsp;</p><h2><strong>\ud83d\udcda Research resources</strong></h2><h3>Connect with a research community:</h3><ul><li><a href=\"https://www.recapresearch.org/about\"><u>Research to End Consumption of Animal Products (RECAP)</u></a></li><li>Join our IAA Slack channel <a href=\"https://impactfulanimal.slack.com/archives/C05G7DVBX8Q\"><u>#research</u></a></li><li>Subscribe to learn more: <a href=\"https://research-newsletter.animalcharityevaluators.org/home\"><u>The ACE Monthly Research Newsletter</u></a></li><li>Some of our favorite work from Rethink Priorities:</li><li><a href=\"https://rethinkpriorities.org/publications/welfare-range-estimates\"><u>Welfare Range Estimates</u></a><strong> </strong>(part of <a href=\"https://forum.effectivealtruism.org/s/y5n47MfgrKvTLE3pw\"><u>Moral Weight Project Sequence</u></a>)</li><li><a href=\"https://rethinkpriorities.org/publications/price-taste-and-convenience-competitive-plant-based-meat-would-not-currently-replace-meat\"><u>Price-, Taste-, and Convenience-Competitive Plant-Based Meat Would Not Currently Replace Meat</u></a></li><li><a href=\"https://rethinkpriorities.org/publications/the-risks-and-rewards-of-prioritizing-animals-of-uncertain-sentience\"><u>Prioritizing Animals of Uncertain Sentience</u></a> (part of <a href=\"https://forum.effectivealtruism.org/s/WdL3LE5LHvTwWmyqj\"><u>CURVE Sequence</u></a>)</li></ul><h3>Some of our favorite work from Faunalytics:</h3><ul><li><a href=\"https://faunalytics.org/different-strokes-for-different-folks/\"><u>Comparing U.S. Groups\u2019 Openness to Pro-Animal Actions</u></a> with <a href=\"https://faunalytics.shinyapps.io/comparing-pro-animal-openness/\"><u>graphing tool</u></a> and <a href=\"https://faunalytics.org/comparing-selected-u-s-subgroups-openness-to-pro-animal-actions/\"><u>subgroup analysis</u></a></li><li><a href=\"https://faunalytics.org/reforming-animal-agriculture-subsidies/\"><u>Reforming Animal Agriculture Subsidies: A Guide for Advocates</u></a></li><li><a href=\"https://faunalytics.org/which-advocacy-tactics-are-most-effective-to-change-diets-a-faunalytics-infocomic/\"><u>Which Advocacy Tactics are Most Effective to Change Diets?</u></a></li><li><a href=\"https://faunalytics.org/smithfield-trial-juror-analysis/\"><u>Jurors\u2019 Reflections on the Smithfield Piglet Rescue Trial</u></a></li><li><a href=\"https://veganhacktivists.org/research\"><u>Tech &amp; Data: A Snapshot of the Animal Protection Movement in the Digital Era</u></a>, Vegan Hacktivists</li><li><a href=\"https://www.animalask.org/post/meat-consumption-and-production-in-developing-countries-who-bucks-the-trend\"><u>Meat consumption and production in developing countries, an agenda for animal advocacy researchers</u></a></li><li><a href=\"https://faunalytics.org/survey-questions/\"><u>Questions to Use in Survey Research and Experiments</u></a>, Faunalytics</li></ul><p>&nbsp;</p><h2><strong>\ud83d\udcbc Continuing education</strong></h2><h3>This year, several new courses for animal advocates came out!</h3><ul><li><a href=\"https://training.animaljusticeacademy.com/homepage\"><u>Animal Justice Academy</u></a>, free online advocacy training program and community has released many new &amp; helpful videos, resources</li><li><a href=\"https://animalcharityevaluators.org/blog/free-courses-for-animal-advocates/\"><u>List of 9 free courses for animal advocates</u></a>, compiled by ACE, including:</li><li><a href=\"https://animal-advocacy-center.thinkific.com/courses/public-speaking-course\"><u>Public speaking</u></a> and <a href=\"https://animal-advocacy-center.thinkific.com/courses/introduction-to-plant-based-campaigns\"><u>Introduction to plant-based campaigns</u></a>, Anima International</li><li><a href=\"https://veganadvocacy.org/science/\"><u>The Science of Effective Vegan Advocacy online course</u></a>, Center for Effective Vegan Advocacy / Beyond Carnism</li><li><a href=\"https://www.animaladvocacycareers.org/course\"><u>Introduction to Animal Advocacy course</u></a>, Animal Advocacy Careers</li></ul><h3>New university programs launched:</h3><ul><li><a href=\"https://www.law.gwu.edu/alei\"><u>GW Law\u2019s Animal Legal Education Initiative</u></a></li><li><a href=\"https://sites.google.com/nyu.edu/wildanimalwelfare\"><u>NYU Wild Animal Welfare Program</u></a></li><li><a href=\"https://cellularagriculture.tufts.edu/\"><u>Tufts Center for Cellular Agriculture undergrad program</u></a></li></ul><p>&nbsp;</p><h2>\ud83e\udd16 AI+Animals resources</h2><p>Artificial intelligence is an upcoming transformative technology that will (and is currently) impacting animals.</p><h3>Learn about the intersection of AI and animals:</h3><ul><li><a href=\"https://forum.effectivealtruism.org/posts/ZNcdt7eYWW7YXALvx/what-ai-could-mean-for-animals\"><u>What AI could mean for animals</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/2cZAzvaQefh5JxWdb/bringing-about-animal-inclusive-ai\"><u>Bringing about animal-inclusive AI</u></a></li><li><a href=\"https://sentientmedia.org/ai-bias-speciesism/\"><u>The AI Bias that\u2019s often overlooked: Speciesism</u></a></li></ul><h3>How to use generative AI in your advocacy:</h3><ul><li><a href=\"https://www.notion.so/AI-Prompts-for-Animal-Advocates-be3378f6340f459d8d6d2e1683479fd2?pvs=21\"><u>AI Prompts for Animal Advocates</u></a></li><li><a href=\"https://nfps.ai/resources/tutorials/\"><u>NFPs.AI tutorials</u></a></li><li>Videos: <a href=\"https://imaa.me/48zGFwo\"><u>AI &amp; ChatGPT in the Movement</u></a> and <a href=\"https://imaa.me/3v8vn3B\"><u>other uses for AI in advocacy</u></a></li></ul><h3>Stay updated &amp; engaged:&nbsp;</h3><ul><li>Join the IAA Slack <a href=\"https://impactfulanimal.slack.com/archives/C059W3BA51P\"><u>#aidiscussion</u></a> and <a href=\"https://impactfulanimal.slack.com/archives/C05A767KJPJ\"><u>#aitools</u></a> channels</li></ul><h3>More resources:</h3><ul><li><a href=\"https://impactfulaa.notion.site/AI-and-Animals-Wiki-b05ee8db39114db582f79d5ebd4a45b1\"><u>AI and Animals Wiki</u></a></li><li><a href=\"https://www.aiforanimals.org/\"><u>AI for Animals</u></a>: new website featuring related projects, news, orgs, events, and more</li></ul><p>&nbsp;</p><h2><strong>\ud83c\udfa7 Media resources</strong></h2><p>&nbsp;</p><h3><strong>Conference recordings</strong></h3><p>We (IAA) attended several conferences this year and found them very valuable! It\u2019s why we created a <a href=\"https://impactfulaa.notion.site/Conferences-Database-Farmed-Animal-Advocacy-9ba547575d0147d09e4d3ca55da54527\"><u>Conferences Database</u></a> and have shared session recordings:</p><ul><li><a href=\"https://imaa.me/48fUss8\"><u>Animal &amp; Vegan Advocacy (AVA) Summit</u></a></li><li><a href=\"https://imaa.me/47ddoGM\"><u>Animal Advocacy Asia</u></a></li><li><a href=\"https://imaa.me/3u4aXrX\"><u>Aquatic Life Conference</u></a></li><li><a href=\"https://imaa.me/4763szk\"><u>Asia Farm Animal Day</u></a></li><li><a href=\"https://imaa.me/3tDqC1y\"><u>Conference on Animal Rights in Europe (CARE)</u></a></li><li><a href=\"https://www.youtube.com/playlist?list=PLwp9xeoX5p8O2iNwOcrSwsUx5NHinA_XF\"><u>EA Global conferences</u></a>. Not all talks are relevant to animal advocacy, but here are some of our favorites:</li><li>Bay Area: <a href=\"https://imaa.me/47eC2Xh\"><u>Bob Fischer on how to compare welfare across species</u></a></li><li>Berlin: <a href=\"https://imaa.me/47eVbbF\"><u>Chris Popa on intercausal impacts and food system change</u></a></li><li>Boston: <a href=\"https://imaa.me/3GXjmAK\"><u>Cynthia Schuck on quantifying animal suffering</u></a></li><li>Nordics: <a href=\"https://imaa.me/3vggBbn\"><u>James Ozden on radical tactics within social movements</u></a></li><li><a href=\"https://imaa.me/4av2G1f\"><u>European Animal Rights Law Conference</u></a></li><li><a href=\"https://www.youtube.com/playlist?list=PL24QgdIOV-lGzmuOpNNmkmJK59I_3F3tF\"><u>Fauna Connections</u></a></li><li><a href=\"https://imaa.me/3RWul3A\"><u>Good Food Conference</u></a></li><li><a href=\"https://www.reducetarian.org/summit-2023#2023-program\"><u>Reducetarian Summit</u></a></li></ul><h3><br><strong>\ud83c\udfa7Podcast roundup (a \u2192 z)</strong></h3><p>In each newsletter, we share newly released podcast episodes. Here are the podcast channels themselves \u2014 feel free to subscribe, listen, and maybe even write a review if you\u2019ve enjoyed their content.</p><ul><li><a href=\"https://aldf.org/article/podcast/\"><u>Animal Amicus</u></a></li><li><a href=\"https://www.buzzsprout.com/1884302\"><u>Cultivating Careers in Alternative Proteins Podcast</u></a></li><li><a href=\"https://rss.com/podcasts/alexcrisp-futureoffood/\"><u>Future of Foods</u></a></li><li><a href=\"https://www.howilearnedtoloveshrimp.com/\"><u>How I Learned to Love Shrimp</u></a></li><li><a href=\"https://karthiklogic.substack.com/\"><u>Karthik Logic</u></a></li><li><a href=\"https://knowinganimals.libsyn.com/\"><u>Knowing Animals</u></a></li><li><a href=\"https://open.spotify.com/show/1ZExKBFAN4bU0kNG6GAFWn\"><u>Martin Skadal podcast</u></a></li><li><a href=\"https://www.ourhenhouse.org/\"><u>Our Hen House</u></a></li><li><a href=\"https://www.sentienceinstitute.org/podcast/\"><u>Sentience Institute</u></a></li><li><a href=\"https://podcasters.spotify.com/pod/show/sentientism\"><u>Sentientism</u></a></li><li><a href=\"https://www.speciesunite.com/podcast\"><u>Species Unite</u></a></li></ul><h3><br><strong>\ud83d\udcf9Documentaries and films</strong></h3><ul><li><a href=\"https://imaa.me/3NJjwPV\"><u>Ending Real Fur</u></a>: Fighting the Canadian fur industry</li><li><a href=\"https://www.netflix.com/title/81460481\"><u>Poisoned: The Dirty Truth About Your Food</u></a>: Foodborne illness in the U.S.</li><li><a href=\"https://moby.com/news/punk-rock-vegan-movie/\"><u>Punk Rock Vegan Movie</u></a>: Moby-led film about the punk vegan scene</li><li><a href=\"https://www.smellofmoneydoc.com/\"><u>The Smell of Money</u></a>: Human Impact of North Carolina pig farms</li><li><a href=\"https://imaa.me/412gjAn\"><u>Why Did Six Million Brits Sign Up To Veganuary?</u></a> The Veganuary origin story</li></ul><h3><br><strong>\ud83d\udcdaBooks:</strong></h3><p>Peter Singer releases</p><ul><li><a href=\"https://www.linkedin.com/posts/petersinger_new-book-alert-on-sale-now-for-several-activity-7140387419580772352-4ahI?utm_source=share&amp;utm_medium=member_desktop\"><i><u>The Buddhist and the Ethicist</u></i></a>, co-authored by Professor Peter Singer and Venerable Shih Chao-Hwei, a female Buddhist monastic living in Taiwan</li><li><a href=\"https://forum.effectivealtruism.org/posts/8xNSiwj5gjoDTRquQ/announcing-the-publication-of-animal-liberation-now\"><i><u>Animal Liberation Now</u></i></a> (and <a href=\"https://forum.effectivealtruism.org/posts/jM3MSankqktQBf6Fu/review-of-animal-liberation-now\"><u>a review of Animal Liberation Now</u></a>)</li></ul><p><a href=\"https://www.animaladvocacycareers.org/free-guide\"><i><u>Essential Guide for Animal Advocacy</u></i></a><i>, </i>Animal Advocacy Careers\u2019 free e-book</p><p>&nbsp;</p><h2>Like this compilation? \ud83d\ude0a</h2><ul><li><a href=\"https://imaa.me/3RInTMB\">Subscribe for free</a> to receive such updates every two weeks and share this post/newsletter with your colleagues and friends</li><li><a href=\"https://socialjuice.io/p/impactful-animal-advocacy-newsletter\">Leave us a review for the newsletter</a> - it helps us promote it to more animal advocates&nbsp;</li><li><a href=\"https://imaa.me/4aALVS9\">Donate</a> - even a small amount can help us keep this newsletter going in 2024 and help more advocates make more impact for the animals. \u2764\ufe0f\ufe0f</li></ul>", "user": {"username": "sofiabalderson"}}, {"_id": "QDjioHPcExzbuXjsj", "title": "Wellbeing alignment - proposal to The Happier Lives Institute with focus on systemic changes", "postedAt": "2023-12-29T10:23:47.754Z", "htmlBody": "<p><i><strong>Summary: </strong>I wholeheartedly support HLI's emphasis on subjective well-being and propose extending its application beyond governments and charities. I explore the question of why people, both individually and as a society, aren't naturally optimizing their happiness, as it seems logical for it to be a natural priority. I delve into possible root causes and suggest ideas for systemic solutions to align individual, societal, and economic decisions with the goal of maximizing well-being.</i></p><h3><strong>Why aren\u2019t people optimizing their happiness already?</strong></h3><p>I'm very excited about HLI\u2019s work in advocating for prioritizing subjective well-being as the ultimate objective to guide charitable interventions, policy-making and societal advancement. A fundamental question arises: Why aren\u2019t people, individually or collectively as a society, optimizing their happiness &nbsp;already (I will use the terms 'well-being' and 'happiness' interchangeably)? People have their agency, and it would seem natural for happiness to be their natural priority. However, despite the remarkable achievements of human civilization, it\u2019s not evident that we\u2019ve made substantial progress in optimizing well-being. If humanity at large, not just select governments and philanthropists, were to efficiently optimize well-being through both individual and coordinated societal actions, we should be able to achieve significantly more.</p><h3><strong>Possible root causes</strong></h3><p>What might be the underlying reasons for people not naturally prioritizing and/or optimizing for their well-being (which I will further call \u201cnot being aligned with (their) well-being\u201d)? There are multiple possible root causes:</p><ol><li>Mistaking money, power, or fame as ultimate goals - if it is not a widespread practice among policymakers to prioritize well-being, it is equally likely that the general public doesn\u2019t fully understand nor embrace this approach.</li><li>Unproductive desires or needs, such as a yearning for luxury or superiority - due to hedonic habituation and other psychological effects people tend to incorrectly perceive certain things as essential to their happiness.&nbsp;</li><li>Having unproductive or conflicting identities and beliefs - both negative self-perceptions, such as feeling unworthy or lazy, but also seemingly positive identities like being best at something that can lead to self-imposed pressure when challenged. If someone strongly identifies with a particular political or ideological group, this can lead to an 'us versus them' mentality, causing friction and reducing the ability to empathize with others. Similarly, beliefs rooted in societal expectations, such as those regarding success, beauty standards, or lifestyle choices, can create internal conflicts and pressures that diminish overall well-being.</li><li>Pursuing their goals in unoptimized ways - even if pursuing the right ultimate/terminal goal or desirable instrumental goals, people usually make multiple, avoidable wrong decisions, due to cognitive biases and lack of widespread knowledge about effective decision-making.</li><li>Failure to adhere to decisions due to self-discipline issues - even when people know what the right action to take is, they are not always able to follow through, as showcased, for example, by addictions or challenges in adopting a healthier lifestyle.</li></ol><h3><strong>Solutions to above problems can have additional positive outcomes</strong></h3><p>Addressing the above problems can lead to positive outcomes that extend beyond the improved well-being of the directly affected individuals:</p><ol><li>Promoting Altruistic Attitudes: Helping others is inherently pleasurable, as well as gives a sense of purpose. Also, even from a pragmatic point of view, it gives a chance for direct or indirect reciprocity (i.e. people are more inclined to like you when you help others). Overall, a significant degree of altruism is both natural and optimal, but unaligned goals, desires and beliefs often strongly hinder it. Making individuals more aligned with their well-being, makes them more altruistic at the same time.&nbsp;</li><li>Enhanced Individual Decision-Making: One of the areas where enhanced individual decision-making profoundly benefits society is in the aspect of voting. Additionally, there are numerous other examples of how making better choices not only benefits personal well-being but also has positive effects on society, through reducing negative or promoting positive externalities. For example, adopting a healthier lifestyle reduces public healthcare costs while more rational purchasing decisions lower environmental impact.</li><li>Improved Institutional Decision-Making: Institutional decision-making often mirrors the flawed patterns observed in individuals. Furthermore, these institutional decisions are shaped by societal expectations and norms. For example, prevailing societal attitudes can significantly influence the feasibility of implementing policies such as increasing foreign aid, addressing climate change, or enhancing funding for public health and education.</li><li>Aligning the Economy with Well-being: According to the traditional economic theory, rationality governs human behavior, money is just a tool to measure utility (ultimately well-being) and thus maximizing financial metrics like GDP per capita would also maximize happiness. If it was accurate, maximizing happiness would be relatively straightforward, given that we are fairly good at maximizing GDP already. Unfortunately, it has been shown to be an incomplete model in practice. Nonetheless, better aligning individual choices and actions with true well-being could lead to an economic system that more accurately reflects genuine happiness. Given the immense scale of the global economy, even a marginal increase in its alignment with societal well-being could translate into significant positive change.</li></ol><h3><strong>Potential solutions</strong></h3><p>Two broad categories of solutions emerge as potential responses to the challenges outlined earlier:</p><ol><li>Investing in consolidating and popularizing the already existing scientific knowledge from fields such as psychology, neuroscience, and economics.</li><li>Investing in further, high-quality research in these or related domains with an emphasis on well-being alignment, decision-making, and behavioral change.</li></ol><p>Possible initiatives might include:</p><ol><li>Supporting and expanding the reach of organizations, courses, and applications that teach skills that address the previously outlined challenges. Examples of such skills could be effective decision making, psychological tools (e.g. from CBT), instrumental and epistemic rationality and self-discipline which can be collectively referred to as well-being alignment.</li><li>Designing and executing social campaigns to raise awareness about well-being alignment concepts and the importance of related skills. The objective would be to elevate these skills to the status of highly sought-after competencies, similar to how areas like personal finances, fitness, digital skills, and language learning are often perceived.</li><li>Developing and implementing new interventions from scratch, specifically designed to teach these skills in the most effective manner.</li><li>Undertaking interdisciplinary research reviews to synthesize existing knowledge and identify gaps for further investigation.</li></ol><p>Any of these approaches can focus either on an individual, institutional, societal, or economic level. It's worth noting an overlap with Effective Altruism's Institutional Decision Making cause Area.</p><p>While neutral on long-termism, the systemic approach to well-being has the potential to resonate with various philosophical perspectives, whether the focus is on immediate improvements or the long-term future. Making individuals, society and the economy more aligned with well-being would represent an impactful \u201ctrajectory change\u201d<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflod98c1fsk9\"><sup><a href=\"#fnlod98c1fsk9\">[1]</a></sup></span>, ensuring that future civilizational and technological advancements genuinely enhance societal well-being, as well as lowering the risk of catastrophic decisions. Such an approach, offering both immediate and long-term benefits, may be particularly attractive to organizations influenced by long-termism, like Open Philanthropy or some of the Effective Altruism Funds.</p><p>&nbsp;</p><p>I am eager to hear HLI's, as well as others' perspectives on these suggestions. Have you previously explored or considered any of these ideas?</p><p><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlod98c1fsk9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflod98c1fsk9\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Citing the Global Priorities Institute: \u201cIn particular, we may be able to produce lasting technological or civilizational \u2018trajectory changes\u2019 whose expected long-term value exceeds that of existential risk mitigation.\u201d&nbsp;</p></div></li></ol>", "user": {"username": "Michal Porwisz"}}, {"_id": "QkAw8EC4yHHECxrYh", "title": "How much can you get done if you work 4 hours per day?", "postedAt": "2023-12-29T10:00:57.990Z", "htmlBody": "<p><i><strong>tl;dr: </strong>I compare the total work hours produced from working 4h/day or less to the total hours required for relevant projects.</i></p><h1>Valuing time concretely</h1><p>Many of us aspire to devote as much time as we can towards our main goals. However, among those of us who primarily work on long-term projects with little regular feedback, I think it\u2019s rare to have a precise sense of what we\u2019re getting for each hour devoted. For example, I expect few researchers could say with any confidence what the concrete result would be of working one more hour per day for a month.</p><p>If correct, this is surprising for the same reason that it would be surprising if a professional athlete had only a vague sense of the effect of a workout and the calories of their diet. With more precise information, they would likely find ways to improve their results with less cost. Furthermore, it plausibly helps motivation to know what each hour spent gets you if used well. I\u2019d speculate that much procrastination can be attributed to a vague grasp of what an hour of work produces, which is often only made concrete by an impending deadline. This pattern seems to often produce stress, guilt, and in the worst case burnout, especially when the work is higher stakes.</p><p>In an attempt to make the value of my own time more concrete, I tried to figure out what I should expect to get done if I worked 4 hours per day for some period of time. I found the results valuable and wrote up this post to share them in case anyone else would benefit as well. In what follows, I estimate the total hours gained from a period of consistent work and compare this to estimates of the total hours required to complete a range of (to me) relevant projects. I then check how these results are affected by variations, such as working more or taking a break. Finally, I compare the numbers to other common leisure activities.</p><p><i>These are very simple calculations that anyone could do, and I expect that many will have done for themselves already. However, I couldn\u2019t easily find something written on it, so I thought it would be worth sharing. The post is primarily applicable to someone in a position similar to mine (PhD student in philosophy), but I expect that it is somewhat useful to others too, especially students and independent researchers.</i></p><h1>Set-up</h1><p>Let\u2019s start by calculating the total work hours we would get from a period of consistent effective work. By effective I mean mostly undivided attention (e.g. the level of concentration one might have playing a slow strategy game), meaning that working while checking social media regularly plausibly disqualifies it for most people. For those thinking in terms of pomodoros, I\u2019m taking 1 hour to be 2 pomodoros.</p><p>I will use 16 weeks as the default period of comparison. This is a standard length of a university term which makes it a natural way to chunk periods for me, and I imagine many other readers. I also think it is a nice period to compare many longer projects to. Finally, assuming 4 weeks of vacation, it\u2019s 1/3 of the work year, which makes it easy to scale.</p><p>How many hours of work per day should we be considering? It is tempting to focus on the 8h/per day of the standard workday. &nbsp;However, few people can work efficiently for 8h or do 16 pomodoros per day, at least consistently for extended periods. I for example have only successfully done so a handful of times during very busy periods. In further support, <a href=\"https://www.vouchercloud.com/resources/office-worker-productivity\">this survey</a> suggests that the average office worker in the UK works efficiently 2h and 53min per working day on average. (Admittedly, this survey doesn't exactly look peer-reviewed, and should probably be taken with a grain of salt).</p><p>Instead, my default assumption will be that we are working 4h/day, 5 days a week. This is a number that I think requires effort to meet, but that many people can do. For example, one might have a 2h working block in the morning, and one 2h block in the afternoon or evening. However, even this might be difficult for people with other obligations, so I will also compare the result of working 2h/day, and 1h/day (e.g. for dedicated writing). Later, I consider how common variations to these assumptions affect the total output.</p><h1>Hours generated from consistent work</h1><p>How many total hours of work do we get from working 4h/day, 5 days a week for 16 weeks? The answer is 320 hours. It is difficult to have a sense of how much this is, so let us compare it to estimations of the total hours required to complete some typical projects:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/iiwsbqbucpbpkb27sihg\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/q6xnktkkxmtuzgrxy9m4 110w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/ndcmejamomvspl4mfzvl 220w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/pahmxccjvaqtk5pxunve 330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/kgcmyaksp2nec8qdwfis 440w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/lduszkintiagg0dgvmdq 550w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/s0erxugabymiibeytrks 660w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/vn94rjdmq3pudlngluvh 770w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/abzm0vnbvty3gi9tbfqj 880w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/az1hqqpa2tzfs576vndb 990w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/kuwkjxa1afb2eubpevah 1010w\"></figure><p>This is a pretty random sample of projects that were somewhat easy for me to get data on. I had data on how long it took me to write a mediocre paper for a graduate seminar and an essay of mine that won a final prize in the <a href=\"https://forum.effectivealtruism.org/posts/ScGZdyGNXoEBAQazR/winners-of-ai-alignment-awards-research-contest\">AI alignment awards</a>. The number of the ML course is just taken from <a href=\"https://www.coursera.org/specializations/machine-learning-introduction\">the Coursera website</a>, but it broadly matches my estimates of the time similar in-person courses have taken me. The top publication (published in top-3 philosophy journal) number is from a friend who tracks all of their worked hours and was kind enough to share this with me. I expect that this number can vary quite a lot between people and that for some it might be significantly lower I also included the time I put towards my BPhil thesis at Oxford (which in hindsight could probably have been put to better use).</p><p>There is obviously more work that can be done in sampling projects for their total required hours. If anyone wants to share their own estimations in the comments, I\u2019d be happy to update the post with more examples.</p><p>My primary takeaway from this is that consistent work is more valuable than I would have intuitively expected. For example, it is noteworthy to me that a skilled person working 2h/day and taking weekends off\u2014which to me seems lower than the time most academics, for example, devote to their work\u2014should expect to produce around 2 very good publications a year. I\u2019m relatively confident that in philosophy, that would be in the upper quartile of output among professors. (Note that the average publication rate can vary heavily across fields, e.g. due to norms of copublishing).&nbsp;</p><p>This suggests to me that it is a much more common failure mode to devote a lot of time to a project and use it ineffectively than it is to devote too little time to it. As a supporting case study, the friend whose data I received above worked on average almost exactly 2h/day on the days they worked, and worked around 60-80% of the days of the year, depending on the year. However, with this work, they managed to be one of the most productive young scholars that I personally know. In other words, it seems one can meet a pretty high bar by consistently working few hours and not even permitting oneself to work more.</p><h1>Variations</h1><p>What happens if you vary the assumptions above? For example, how much is gained from working more? And how much does one lose from taking a vacation? Here are some examples of variations and interventions next to the 4h/day, 5 days a week, 16-week duration baseline.</p><p><img style=\"width:100%\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/qkevg3pnz3rsfg2tmcj8\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/wpnkkbpfho83mpyiqmqk 100w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/iwduqywlc8wtzwsqdy17 200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/kqdatdixfv51qj7psmua 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/unpqhwlfcshncvqt3vy0 400w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/t8aoihljsdncfrqsmtqn 500w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/tbiiso1mhocjyrx2d4lq 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/xqfmmjrumojceg0ahmbc 700w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/guyuohooxbd0vqblwhwg 800w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/egjplqqizgzpvvkqg5mn 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/k8et0fkb08kbiqixgwfg 943w\"></p><p>These examples are what I imagine to be pretty typical and realistic scenarios that people might consider. For the \u201c2h more every 2 days\u201d I\u2019m imagining working 6h/day 2 or 3 days a week, and analogously for working 2h less every 2 days. I imagine that a 5-day conference takes 5 work days (it might be less if it\u2019s on a day you wouldn\u2019t have worked, but my experience is that neglected obligations usually take a day to catch up on anyway), and a 2 week vacation takes 10 work days. I assume that burnout means no productive work during that period. Realistically, burnout can plausibly last much longer than a term, meaning that the cost would be much greater than indicated here.</p><p>What is noteworthy to me about this is the relatively low marginal value of working more, within realistic bounds. For example, I have noticed that adding 2h extra work per day, even if it\u2019s only every other day, is rather difficult for me. In particular, the risk of my schedule breaking and me procrastinating because I feel less urgency both go up significantly, which I expect outweighs the 25% increase of hours in the scenario where all goes well.</p><p>Another observation is the effect of burnout. Even if the risk is low, the disproportionate effect on productivity is so significant that it seems prudent to be very careful to avoid that outcome, even if that means taking an extra 2-week vacation (i.e. lose 40 work hours or a mediocre term paper, if written by me). This seems especially important to remind ourselves of if our work has a potential large-scale positive impact, as I expect that this can add a lot of mental pressure to work more.</p><p>One important consideration that this representation of the value of time abstracts away from is the marginal value of the work produced. For example, for a junior academic, the first great paper they produce is likely more important for them than the second, and so on. More generally, I would imagine that for most people getting some work done is much more valuable than doubling that work. This further reinforces the case for working a lower number of hours if that means reducing the risk of doing much less due to severe procrastination or burnout.&nbsp;</p><p>I don\u2019t think it\u2019s clear whether there is declining marginal value in someone\u2019s work from an impartial perspective. For example, we might think an important researcher might add nearly as much to the world with their third paper as the first. However, we might also think the person would do the most important work first\u2014for example, if they have a limited amount of good ideas and need to prioritize\u2014meaning additional hours will be spent on less important projects. In the end, this is plausibly something to be judged on a case-by-case basis.</p><h1>Leisure</h1><p>One of the benefits of working fewer hours is having more time to spend on other activities we enjoy, and I decided to do some estimations of common leisure activities too. I did this mostly because it was fun and easy, but also because it provides some further context to the numbers above and might help us judge which activities are the most relaxing, enjoyable, and rewarding in proportion to the time they occupy (because, yes, effective fun is the best fun.) Here are some examples I found, again compared to the 4h/day, 5 days a week, 16 week reference:</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/uuspayzaq30ptekaspxs\" alt=\"A white paper with yellow and black text\n\nDescription automatically generated\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/in9dljauiwziq1yaqynf 150w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/dwthrabrdqfrg7uueuqt 300w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/pukknqfeeg0hks8obsrh 450w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/istjkicw6kkggxj45myl 600w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/ckj8wc9td3qmkx8nmyo2 750w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/qny1e50xhkx9dt9aqk5f 900w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/modcpowal4rgaribeqwc 1050w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/kavapyqcczpur6tlskgg 1200w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/g9nbgzjilvyfoxiayxho 1350w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/QkAw8EC4yHHECxrYh/jmlfgz3x93whighmxxkr 1472w\"></p><p>I got most of these estimations from googling around. Importantly, the gym number does not include preparation, transport, and shower. If those are included, I think that number could easily double. Like with the project examples, this list could be expanded to be more representative and helpful.</p><p>I don\u2019t have much to comment on this beyond the obvious that most of us were aware of, namely that social media takes time. It does also frighten me a bit how many books young me could have read instead of levelling his undead warlock.</p><h1>Some personal takeaways and caveats</h1><p>My intention with this post was to provide some information and simple analysis that anyone could produce but I think few will, and anyone will have to decide what to take away from it if anything. However, in case it\u2019s helpful, I\u2019ll briefly mention how I approach my work in light of this.</p><p>I normally try to work 4h/day, 6 days a week when I am not taking time off and don\u2019t have substantial other obligations (e.g. teaching). I rather like what I do, so working an extra day doesn\u2019t feel that costly. However, I benefit a lot from having one day off a week to rest and get perspective on what I am doing. I split my work into 2 blocks of 2h each, which I find is long enough to get into a flow state but short enough that I can still focus. It also makes for easy scheduling which saves some cognitive costs of planning. This is time that I reserve for what I take to be important projects (e.g. research), and not time I use for e.g. answering emails.</p><p>These were habits I largely had prior to comparing these numbers. The main update I made from the information here was to not aspire to do more work per day than this. However, if I enter a period of more obligations than I currently have, I would now simply opt to work 2h/day most days.</p><p>I want to end with some caveats. Personal preferences might substantially affect how it makes sense to work. For example, someone might prefer to work longer but more relaxed hours than the level of concentration assumed here. Or by contrast, someone might prefer binge-working many hours for shorter periods. And others might be constrained in how they can approach work by attention-affecting conditions like ADD. None of what I have said here is meant to override such considerations. Whatever your situation, I hope some of this could be of use.</p><p><i>Feel free to share estimates of your own in the comments. I'd be happy to update the post with new graphs with more information, in case that'd be of use.</i></p><p><i>Update 1: Changed tl;dr to be less prescriptive.</i></p>", "user": {"username": "paul_dfr"}}, {"_id": "86RcytpqKDLGG2mE8", "title": "CE-incubated tobacco & NCD policy Charity: updates, funding gap, and future plans for Concentric Policies", "postedAt": "2023-12-29T06:56:47.114Z", "htmlBody": "<h1>Executive Summary</h1><ul><li>Tobacco is a massive global issue: 8 million annual deaths and 230 million annual DALYS (15% and 9% of global totals respectively).</li><li>There are evidence-based policies\u2014outlined by the WHO\u2019s MPOWER framework\u2014that countries can adopt to reduce tobacco use.</li><li>Policy advocacy for implementing MPOWER measures in neglected countries can avert DALYs with cost-effectiveness matching GiveWell's top charities.</li><li>Since starting in mid-September,&nbsp;<a href=\"https://www.concentricpolicies.org/\"><strong><u>Concentric Policies</u></strong></a> has engaged with seven ministries of health, met with four, and received a partnership request from one to develop a multisectoral plan for noncommunicable diseases.</li><li>Closing our Year 1 funding gap ($21,000) is critical for building the necessary capacity to support our government advocacy plans in 2024.</li></ul><p>&nbsp;</p><h1>About Us&nbsp;</h1><p>Concentric Policies is a nonprofit focused on preventing and controlling noncommunicable diseases.&nbsp;<strong>We support the adoption of evidence-based health policies</strong> in countries underserved by large NGOs and the international community. Through collaboration with governments, civil society, and citizens,&nbsp;<strong>we aim to reduce the unhealthy consumption of tobacco, alcohol, sodium, and sugar.</strong> Concentric Policies provides free assistance by engaging stakeholders, strengthening the evidence base through research, and offering technical assistance throughout the policy process.</p><p><br>Concentric Policies was launched through&nbsp;<a href=\"https://www.charityentrepreneurship.com/\"><u>Charity Entrepreneurship</u></a>, a London-based incubator that turns well-researched ideas into high-impact organizations. Charity Entrepreneurship has helped launch&nbsp;<a href=\"https://www.charityentrepreneurship.com/our-charities\"><u>over 30 charities</u></a> that are now reaching over 20 million people annually with their interventions.&nbsp;</p><p>&nbsp;</p><h1>Problem&nbsp;</h1><ul><li>Annual deaths from tobacco were 6 million in 2013 and rose to 8 million before the pandemic.</li><li>Today, more people are killed annually by tobacco usage than malaria, HIV, and neonatal deaths combined\u2026 twice over.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2ty9777nm44\"><sup><a href=\"#fn2ty9777nm44\">[1]</a></sup></span></li><li>In addition, tobacco usage increases healthcare expenditures, decreases productivity, exacerbates inequality, degrades the environment, and contributes to child labor.</li><li>This&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/RRm8vnmwjWK24ung2/taxing-tobacco-the-intervention-that-got-away-happy-world-no\"><u>EA Forum post</u></a> from World No Tobacco Day covers these harms in more detail.</li></ul><p>&nbsp;</p><h1>Solution&nbsp;</h1><p>The WHO\u2019s MPOWER framework provides cost-effective demand-reduction measures to help countries reduce tobacco consumption. Since MPOWER was introduced globally 15 years ago, an estimated 300 million less people are smoking than might have been if smoking prevalence had stayed the same.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefemjscrdwjod\"><sup><a href=\"#fnemjscrdwjod\">[2]</a></sup></span></p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/86RcytpqKDLGG2mE8/xrxc4tdscribpcakyqlj\"></p><p>&nbsp;</p><p>Tobacco taxation is the most effective (and cost-effective) intervention for reducing tobacco consumption, yet it is the most neglected intervention.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref153kzm9deca\"><sup><a href=\"#fn153kzm9deca\">[3]</a></sup></span>&nbsp;Tobacco has an average price elasticity in LMICs of around -0.5, meaning that for a 10% increase in the retail price of tobacco, consumption decreases by 5%.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkvktcjz351b\"><sup><a href=\"#fnkvktcjz351b\">[4]</a></sup></span></p><p>&nbsp;</p><h1>Opportunity&nbsp;</h1><p>The number of countries that have adopted at least one MPOWER measure at the highest level of achievement has grown from 44 in 2008 to 151 in 2022. However, only a handful of nations have full compliance with MPOWER guidelines and 44 countries remain unprotected by any of the MPOWER measures.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefxjmsx2gxo5\"><sup><a href=\"#fnxjmsx2gxo5\">[5]</a></sup></span>&nbsp;Despite nearly every country signing the WHO\u2019s treaty on tobacco, only 13 nations outside of Europe meet the WHO\u2019s recommended&nbsp;<i>minimum</i> of taxing tobacco at 75% of retail value.</p><p>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/86RcytpqKDLGG2mE8/aingv9viyabac8fef4g1\"></p><p>&nbsp;</p><p>Since starting work in September, we have learned and reaffirmed the following:&nbsp;</p><ul><li>Some governments are not aware of the potential ROI from comprehensive implementation of the MPOWER framework</li><li>Consolidated funding in the tobacco control space has led to only a dozen or so of the highest-burden countries receiving the majority of resources&nbsp;&nbsp;<ul><li>Many smaller countries do not receive any attention from major tobacco control organizations&nbsp;&nbsp;</li></ul></li><li>Tobacco control efforts can absorb more funding; the burden greatly exceeds the scope of work being done by the tobacco control space.<ul><li>Civil society and domestic advocacy groups often split their efforts across a wide range of health issues</li></ul></li></ul><p>&nbsp;</p><h2>Potential Impact</h2><p>We estimate 130,000 to 262,000 DALYs could be averted by increasing national tobacco taxes in a high-burden country. Some of the non-health benefits of reduced tobacco consumption include increased government revenue for other services, increased household disposable income (which often is used on education and nutrition), increased GDP (through decreased healthcare costs and increased productivity), and less pollution (cigarette butts are the most littered item in the world).</p><p>&nbsp;</p><h2>Cost-effectiveness</h2><p>Cost-effectiveness estimates for a 20 percentage point tax increase on tobacco in most countries range from 2 USD to 50 USD per DALY averted. The expected value fluctuates depending on the probability you assign for success. CE\u2019s 2022 report found a weighted probability of 27%.</p><p>&nbsp;</p><p>For our pilot, we estimate a 20 percentage point tax increase on tobacco would have an expected cost-effectiveness of 50 to 300 USD per DALY averted. A policy win in these countries would most likely range from 20 to 100 USD per DALY averted.</p><p>&nbsp;</p><p>Research conducted by Charity Entrepreneurship, Open Philanthropy, the Centre for Exploratory Altruism Research, and Concentric Policies has projected the expected value of health taxes (on tobacco, alcohol, and sugar) and sodium reformulation to be above or on par with GiveWell\u2019s cost-effectiveness bar.</p><p>&nbsp;</p><h1>Traction&nbsp;</h1><ul><li>Received a partnership request from a ministry of health to help develop a multisectoral NCD plan&nbsp;</li><li>Identified an opportunity and implementation partner to scale a tobacco cessation program in a high-burden country. Based on our initial model, we have moderate to high confidence this program could avert a DALY for under $100 in expectation.</li><li>Made contact with a prominent national politician and are developing alliances with two up-and-coming politicians</li><li>Developed relations with technical experts and major institutions in the field, including WHO and World Bank</li><li>Spoken with government, civil society, and public health stakeholders in over 20 countries&nbsp;</li><li>Raised over $16,000 from non-EA donors&nbsp;</li></ul><p>&nbsp;</p><h1>Funding Gap</h1><p>Based on our Year 1 budget, Concentric Policies\u2019 current funding gap is approximately $21,000. This support would enable us to hire a program officer and spend additional months in-country. Without additional funding, our probability of securing policy wins will be substantially reduced.</p><p>&nbsp;</p><p>We are also exploring leads beyond the scope of the funding gaps's focus i.e. traditional policy advocacy. To fully act on the most promising leads, which we are currently working to verify, we anticipate capacity to absorb more funding beyond the stated funding gap later in 2024. Given present uncertainties on these opportunities, we are not seeking to fundraise past our original funding gap at this time.</p><p>&nbsp;</p><p>You can&nbsp;<a href=\"https://give.cornerstone.cc/concentricpolicies\"><u>donate through our website</u></a> or reach out to us to discuss the impact of a donation in greater detail.</p><p>\u2014-</p><p><br>To learn more or provide feedback, feel free to reach out at&nbsp;<a href=\"mailto:info@concentricpolicies.org\"><u>info@concentricpolicies.org</u></a> or book a call with us.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2ty9777nm44\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2ty9777nm44\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://docs.google.com/spreadsheets/d/1RAJxcAaWe2HU6D6_sfzyE4krp7IT8OPpnLd0TPDbr2M/edit?usp=sharing\"><u>https://docs.google.com/spreadsheets/d/1RAJxcAaWe2HU6D6_sfzyE4krp7IT8OPpnLd0TPDbr2M/edit?usp=sharing</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnemjscrdwjod\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefemjscrdwjod\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://iris.who.int/bitstream/handle/10665/372043/9789240077164-eng.pdf?sequence=1\"><u>https://iris.who.int/bitstream/handle/10665/372043/9789240077164-eng.pdf?sequence=1</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn153kzm9deca\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref153kzm9deca\">^</a></strong></sup></span><div class=\"footnote-content\"><p>2021&nbsp;<a href=\"https://www.who.int/publications/i/item/9789240019188\"><u>WHO technical manual</u></a> on tobacco taxation policy and administration; 2016&nbsp;<a href=\"https://cancercontrol.cancer.gov/brp/tcrb/monographs/monograph-21\"><u>NIH monograph</u></a> on the economics of tobacco and tobacco control.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnkvktcjz351b\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefkvktcjz351b\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://cancercontrol.cancer.gov/brp/tcrb/monographs/monograph-21\"><u>https://cancercontrol.cancer.gov/brp/tcrb/monographs/monograph-21</u></a></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnxjmsx2gxo5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefxjmsx2gxo5\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://iris.who.int/bitstream/handle/10665/372043/9789240077164-eng.pdf?sequence=1\"><u>https://iris.who.int/bitstream/handle/10665/372043/9789240077164-eng.pdf?sequence=1</u></a></p></div></li></ol>", "user": {"username": "Yelnats T.J."}}, {"_id": "CtjoTZZbtvi6tKHq8", "title": "If EAs Should Invest, What Should We Invest In?", "postedAt": "2023-12-29T14:51:17.035Z", "htmlBody": "<h1>Introduction</h1><p>I\u2019ve been wondering lately about the most effective thing I can do with my money. There are good arguments on both sides of whether to invest or donate now, and I'm not sure I'm leaning in the right direction. If you think you want to invest for now (as I do), there\u2019s also the question of what to invest in, which I have been trying to decide lately.</p><p>I\u2019ve outlined my considerations, and I ask for you to scrutinize my reasoning so I can make better-informed decisions.</p><h1>Should you invest?</h1><h2>Why you might want to invest</h2><ol><li><strong>It might be more effective to donate later instead of now.</strong> The view of&nbsp;<a href=\"https://80000hours.org/podcast/episodes/phil-trammell-patient-philanthropy/\"><u>patient philanthropy</u></a> argues this is the case<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpsykq333qq\"><sup><a href=\"#fnpsykq333qq\">[1]</a></sup></span>. I\u2019ve tried to summarize its arguments here:<ol><li><strong><u>You can donate more:</u></strong> The US stock market has averaged 7% annual returns during the last century. If this continues, only $1,000 invested now would become ~$2,000 in 10 years, ~$2,800 in 15 years, and ~$4,000 in 20 years.</li><li><strong><u>The best opportunities may be in the future</u></strong><u> (especially for near-termist causes):&nbsp;</u><ol><li>From an outside view, philanthropy was probably less effective in the past than it is today, so it would also likely be more effective in the future. With better information and technology, we\u2019ll probably find great opportunities we haven\u2019t already.</li><li>From an inside view, development economics and animal welfare research are relatively nascent fields, and they have room for improvement.</li></ol></li></ol></li><li><strong>You might want to build your \u201c</strong><a href=\"https://80000hours.org/2015/11/why-everyone-even-our-readers-should-save-enough-to-live-for-6-24-months/\"><strong><u>personal runway</u></strong></a><strong>\u201d:</strong> Having at least 6\u201312 months of living costs saved allows you to take career/education risks and expensive or low-paying decisions (e.g., taking time off to switch fields), and it can help your well-being by assuring your recovery if you become temporarily unable to work (e.g., are injured) or incur unexpected costs (e.g., have property damaged).</li><li><strong>You might currently feel too uncertain about where to donate to.</strong> For me, I think I\u2019ll donate to more effective organizations once I\u2019ve learned more about causes and opportunities, and I doubt I\u2019m alone.</li></ol><h2>Why you might not want to invest</h2><ol><li><strong>The best opportunities may be going away (at least for x-risk reduction):</strong> If you place a high probability on short AI timelines or the&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/time-of-perils\"><u>time of perils</u></a> hypothesis, you might find your future self with much more to donate but think it\u2019s too late to make a substantial counterfactual impact. For an exaggerated example, don\u2019t invest now if you\u2019ll later frantically throw gobs of money at alignment research because AGI is coming next month, and we didn\u2019t solve the alignment problem, and the regulations are weak, and OMG we\u2019re doomed!</li><li><strong>Gradual donations allow you to learn from previous mistakes: </strong>We humans make a lot of mistakes, and it\u2019s hard (or impossible) to know whether you\u2019ll make a mistake in a future activity you\u2019ve never or rarely done. Luckily, past mistakes often feel glaring (at least for earnest and rational agents) and can be avoided afterward.</li></ol><h1>What do you invest in?</h1><p>While other types of investments are certainly relevant, it\u2019s outside the scope of this post and my current knowledge, so I\u2019m focusing on the stock market for now.</p><h2>Funds</h2><p>I\u2019m mostly interested in index funds, mutual funds, and ETFs (which I will call \u201cfunds\u201d from now on) because they are usually relatively low-risk, low-maintenance, and high-performance. For instance, funds tracking the S&amp;P 500 (the 500 largest publicly traded US companies) have historically earned around&nbsp;<a href=\"https://www.investopedia.com/ask/answers/042415/what-average-annual-return-sp-500.asp\"><u>10% returns</u></a> annually (6.29% annually when adjusted for inflation).</p><h3>The Catch</h3><p>However, most funds contain companies involved in harmful practices. For example,&nbsp;<a href=\"https://www.morningstar.com/funds/xnas/fxaix/sustainability\"><u>~17%, ~10%, and ~7%</u></a> of companies in the S&amp;P 500 are involved in animal testing, fossil fuels, and weapons/military contracting, respectively. Certain ESG funds employ exclusions on these industries (except for animal testing) while still aiming to track indices with strong past performance. However, ESG funds don\u2019t have the strong and lengthy track record of conventional funds.</p><p>What I\u2019ve been thinking about lately is whether to avoid harm with ESG funds, accepting their higher risk and lower returns, or to maximize my returns with conventional funds, hoping to offset any harm with the increased amount of money I can donate. I\u2019m currently leaning toward the latter for three reasons:</p><ol><li>~100% of money donated to effective organizations makes a positive impact. In contrast, 34% of money invested in the S&amp;P 500 helps companies involved in animal testing, fossil fuels, and weapons/military contracting, which is a relatively small fraction.&nbsp;</li><li>Most or all of the money going to controversial companies probably isn\u2019t doing substantial counterfactual harm. For instance, it probably will make the higher-ups richer but probably won\u2019t prompt a new weapons development project.</li><li>Since most organizations aren\u2019t especially effective at doing good, it seems most controversial companies are probably quite&nbsp;<i>ineffective</i> at doing harm. Hence, money donated to effective organizations probably does more good than the same amount of money given to controversial companies.</li></ol><h2>Individual stocks</h2><p>Because you could earn significantly more money investing in individual stocks, it might have a higher expected value than investing in funds. I'm not planning on this because it seems many people who are much better suited to investing than me have&nbsp;<a href=\"https://www.investopedia.com/articles/investing/030916/buffetts-bet-hedge-funds-year-eight-brka-brkb.asp\"><u>tried and failed</u></a> to beat index funds.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpsykq333qq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpsykq333qq\">^</a></strong></sup></span><div class=\"footnote-content\"><p>This is far from settled. For example, see <a href=\"https://forum.effectivealtruism.org/posts/wdeDDEr6qtpac2m6d/investing-to-give-fp-research-report\">this post</a> from Founder's Pledge.</p></div></li></ol>", "user": {"username": "NicholasNicholas"}}, {"_id": "XatixHPupjA5DCCm8", "title": "Say how much, not more or less versus someone else", "postedAt": "2023-12-28T22:24:20.703Z", "htmlBody": "<p><i>Or:</i> \"Underrated/overrated\" discourse is itself overrated.</p><p><strong>BLUF:</strong> \"X is overrated\", \"Y is neglected\", \"Z is a weaker argument than people think\", are all species of second-order evaluations: we are not directly offering an assessment of X, Y, or Z, but do so indirectly by suggesting another assessment, offered by someone else, needs correcting up or down.</p><p>I recommend everyone cut this habit down ~90% in aggregate for topics they deem important, replacing the great majority of second-order evaluations with first-order evaluations. Rather than saying whether you think X is over/under rated (etc.) just try and say how good you think X is.</p><h1>The perils of second-order evaluation</h1><p>Suppose I say \"I think forecasting is underrated\". Presumably I mean something like:</p><ol><li>&nbsp;I think forecasting should be rated <i>this</i> highly (e.g. 8/10 or whatever)</li><li>I think others rate forecasting lower than this (e.g. 5/10 on average or whatever)</li><li>So I think others are not rating forecasting highly enough.</li></ol><p>Yet whether \"Forecasting is overrated\" is true or not depends on more than just \"how good is forecasting?\" It is confounded by questions of which 'others' I have in mind, and what their views actually are. E.g.:</p><ul><li>Maybe you disagree with me - you think forecasting is <i>overrated</i> - but it turns out we basically agree on how good forecasting is. Our apparent disagreement arises because you happen to hang out in more pro-forecasting environments than I do.</li><li>Or maybe we hang out in similar circles, but we disagree in how to assess the prevailing vibes. We basically agree on how good forecasting is, but differ on what our mutual friends tend to really think about it.</li><li>(Obviously, you could also get specious <i>agreement </i>of two-wrongs-make-a-right variety: you agree with me forecasting is underrated despite having a much lower opinion of it than I do, because you assess third parties having an even lower opinion still)</li></ul><p>These are confounders as they confuse the issue we (usually) care about: how good or bad forecasting is, not the inaccuracy of others nor in which direction they err re. how good <i>they</i> think forecasting is. &nbsp;</p><p>One can cut through this murk by just assessing the substantive issue directly. I offer my take on how good forecasting is: if folks agree with me, it seems people generally weren't over or under- rating forecasting after all. If folks disagree, we can figure out - in the course of figuring out how good forecasting is - whether one of us is over/under rating it versus the balance of reason, not versus some poorly scribed subset of prevailing opinion. No phantom third parties to the conversation are needed - or helpful to - this exercise.</p><h1>In praise of (kind-of) objectivity, precision, and concreteness</h1><p>This is easier said than done. In the forecasting illustration above, I stipulated 'marks out of ten' as an assessment of the 'true value'. This is still vague: if I say forecasting is '8/10', that could mean a wide variety of things - including basically agreeing with you despite you giving a different number to me. What makes something 8/10 versus 7/10 here?</p><p>It is still a step in the right direction. Although my '8/10' might be essentially the same as your '7/10', there probably some substantive difference between 8/10 and 5/10, or 4/10 and 6/10. It is still better than second order evaluation, which adds another source of vagueness: although saying for myself forecasting is X/10 is tricky, it is still harder to do this exercise on someone else's (or everyone else's) behalf.</p><p>And we need not stop there. Rather than some singular measure like 'marks out of 10' for 'forecasting' as a whole, maybe we have some specific evalution or recommendation in mind. Perhaps: \"Most members of the EA community should have a Metaculus or Good Judgement account they forecast on regularly\", or \"Forecasting interventions are the best opportunities in the improving institutional decision-making cause area\", or \"Forecasting should pay well enough that skilled practitioners can realistically 'go pro', vs. it remaining universally an amateur sport\". Or whatever else.</p><p>We thus approach substantive propositions (or proposals), and can avoid a mire of a purely verbal disagreement - or vaguely adversarial vibing.</p><h1>Caveats</h1><p>(Tl;dr: I'm right.)</p><h2>Sometimes things aren't that ambiguous</h2><p>The risk I highlight of 'Alice thinks X is overrated, Bob thinks it is underrated - but they basically agree on X, but disagree on what other people think about it' can sometimes be remote. One example is if someone has taken the trouble to clearly and precisely spell out where they stand themselves. Just saying \"I'd take the over/under on what they think\" could be poor epistemic sportsmanship (all too easy to criticise something specific whilst sheltering in generalities yourself), and could do to be more precise (how <i>much</i> over? etc.) but at least there is an actual difference, and you can be reliably placed to a region on the number line.</p><p>Another example is where you are <i>really</i> sure you are an outlier vs. ~ everyone else: you rate something so highly or lowly that ~ everyone else - whoever they are - is under/overrating it by your lights. This will typically be reserved for ones hottest, most extreme, and iconoclastic takes. In principle, this should be rare. In practice, it can be the prelude to verbal clickbait: \"looking after your kids is overrated\" better be elaborated with something <i>at least</i> as spicy as Caplan's views on parenting, rather than some milquetoast climbdown along the lines of 'parents should take care of themselves too' or whatever.</p><p>Even here, trying to say how much can be clearer if your view really is 'a hell of a lot'. \"Buffy the Vampire Slayer is <i>criminally</i> underrated\" could merely mean I place it a cut above other ~naughties TV serials. Yet if I really think things like, \"Season 5 of <i>Buffy</i> alone places it on the highest summits of artistic achievement, and the work as a whole makes a similar contribution to television as Beethoven's <i>Grosse Fuge</i> does to classical music\" I should say so, such that listeners are clear in which ballpark I am in, and how far I am departing from common sense.</p><h2>Updates and pricing in</h2><p>Overrated/underrated can have a different goal than offering an overall assessment. It could instead be a means of introducing a new argument for or against X. E.g. perhaps what I could mean by 'forecasting is underrated' is something like \"I have found a new consideration in favour of forecasting, so folks - who are not aware of it yet - need to update upwards from wherever they were beforehand.\"</p><p>This is better, but still not great. (E.g.) \"X is underrated because R\" at least gives a locus for discussion (R? \u00acR?), but second-order considerations can still confound. Although R may be novel to the speaker, others may at least be dimly aware of it, or some R* nearby to it, so perhaps they have already somewhat 'priced in' R for the all things considered assessment. \"I think the strength of R pro/con X is under/overestimated by others\" has the familiar problems outlined above.</p><p>Saying how much - the now familiar remedy - remains effective. (E.g.) \"I think R drops the value of X by 5%/50%/99%\" or whatever clearly signals the strength of consideration you are assigning to R, and sidesteps issues of trying to assess whether someone else (in the conversation or not) are aware of or are appropriately incorporating R into their deliberations.</p><h1>Cadenza</h1><p><a href=\"https://forum.effectivealtruism.org/posts/m65R6pAAvd99BNEZL/use-resilience-instead-of-imprecision-to-communicate#Conclusion\">As before</a>, this greater precision is not a free lunch: it takes both more space on the page to write and more time in the brain to think through. Also as before, there are times when this extra effort is a waste. If I assert \"Taylor Swift is overrated\" to my sister, and she asserts \"Bach is overrated [sic]<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefodfgl9x0mt\"><sup><a href=\"#fnodfgl9x0mt\">[1]</a></sup></span>\" in turn, neither the subject matter warrants - nor the conversational purpose well-served by - a careful pseudo-quantitative quasi-objective disquisition into the musical merit of each. Low-res 'Less/more than someone thinks' remarks are also fine for a bunch of other circumstances. Usually unimportant ones.</p><p>Yet also as before, sometimes there is a real matter which really matters, sometimes we want our words to amount to substantial work not idle talk, and sometimes we at least aspire to be serious people striving to say something serious about something serious. For such Xs, it is rare for there to be disagreement about whether a given issue is relevant to X, ditto whether its direction is 'pro' or 'con' X, but rather its magnitude: <i>how much</i> it counts 'pro' or 'con' X, and so where the overall balance of reason lies re. X all things considered, where all the things to be considered are all various degrees of 'kinda, but...', which need to be all weighed together.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefhlp8vop992s\"><sup><a href=\"#fnhlp8vop992s\">[2]</a></sup></span></p><p>In these cases that count, something <i>like</i> counting needs to be attempted in natural language, despite its inadequacy for the task. Yet although (e.g.) \"8/10\", \"maybe this cuts 20% off the overall value of X\" (etc.) remain imperfect, more/less statements versus some usually vague comparator is even worse. Simply put: underrated/overrated is a peregrination, not a prolegomenon, for the project of proper precisification.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefpw1nfgufd8\"><sup><a href=\"#fnpw1nfgufd8\">[3]</a></sup></span></p><p>Reality is concrete; its machinations, exact. When it is important to talk about it, our words should try to be the same.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnodfgl9x0mt\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefodfgl9x0mt\">^</a></strong></sup></span><div class=\"footnote-content\"><p>[sic]</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnhlp8vop992s\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefhlp8vop992s\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Cf. my previously expressed (and still maintained) <a href=\"https://www.lesswrong.com/posts/nm6XuC9CzNBrthpPB/contra-double-crux#How_common_are_cruxes__and_double_cruxes__\">allergy</a> towards 'crux' 'cruxy', etc.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnpw1nfgufd8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefpw1nfgufd8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Peccavi</p></div></li></ol>", "user": {"username": "Gregory_Lewis"}}, {"_id": "D2CKQ8ZFLwecRphMT", "title": "NYT is suing OpenAI&Microsoft for alleged copyright infringement; some quick thoughts", "postedAt": "2023-12-28T18:37:14.684Z", "htmlBody": "", "user": {"username": "Samin"}}, {"_id": "SmZDvNi84W8e3Sc3R", "title": "Talking about EA with friend who has an intellectual disability \u2014 any advice? ", "postedAt": "2023-12-28T17:45:00.862Z", "htmlBody": "<p>One of my friends, who has autism and another developmental disorder (both with high support needs), wants to learn more about EA. He overheard me talking about it with another friend, and he seems really interested in knowing why it\u2019s important to me, and what it\u2019s all about.</p>\n<p>I\u2019ve been awkwardly avoiding the topic with him for now, but he seems genuinely interested and I\u2019d like to come back with some actual information for him (instead of the typical \u201cyou\u2019re too disabled to understand\u201d that most people give him when he asks about complex topics.</p>\n<p>Just for context, he is around my age (early-mid 30s) and can speak, read and write (not perfectly, but legibly), but struggles with understanding very complex subject matter, especially when it comes to mathematics and statistics. He\u2019s very intellectually curious and loves learning about big ideas and talking about scientific, political, and philosophical subjects (even if he can\u2019t understand them on more than a surface level).</p>\n<p>My question is \u2014 do you think it\u2019s appropriate for me to talk about EA with him, and if so, what resources would be best for someone like him? I don\u2019t just want to refer him to articles written for kids (because he\u2019s an adult, and doesn\u2019t want to be infantilized), but doubt he would understand what\u2019s written on the CEA / EV websites, etc.</p>\n<p>What do you all think would be best / most equitable to do in this situation?</p>\n<p>Also, if I have said anything ableist or offensive (definitely not my intent!), I sincerely apologize.</p>\n", "user": {"username": "Hayven Jackson"}}, {"_id": "R6qu7LhcLKLob7t9r", "title": "Zach Robinson will be CEA\u2019s next CEO", "postedAt": "2023-12-28T15:57:28.191Z", "htmlBody": "<p>We, on behalf of the EV US and EV UK boards, are very glad to share that&nbsp;<a href=\"https://www.linkedin.com/in/zyrobinson/\">Zach Robinson</a> has been selected as the new CEO of the Centre for Effective Altruism (CEA).</p><p>We can personally attest to his exceptional leadership, judgement, and dedication from having worked with him at Effective Ventures US. These experiences are part of why we unanimously agreed with the hiring committee\u2019s recommendation to offer him the position.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjxgjwgeq94\"><sup><a href=\"#fnjxgjwgeq94\">[1]</a></sup></span>&nbsp;We think Zach has the skills and the drive to lead CEA\u2019s very important work.</p><p>We are grateful to the search committee (Max Dalton, Claire Zabel, and Michelle Hutchinson) for their thorough process in making the recommendation. They considered hundreds of potential internal and external candidates, including through dozens of blinded work tests. For further details on the search process, please see&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Bg6qxLGhsn7pQzHGX/progress-report-on-cea-s-search-for-a-new-ceo\"><u>this Forum post</u></a>.&nbsp;</p><p>As we look forward, we are excited about CEA's future with Zach at the helm, and the future of the EA community.</p><p><i>Zach adds:&nbsp;</i>\u201cI\u2019m thrilled to be joining CEA! I think CEA has an impressive track record of success when it comes to helping others address the world\u2019s most important problems, and I\u2019m excited to build on the foundations created by Max, Ben, and the rest of CEA\u2019s team. I\u2019m looking forward to diving in in 2024 and look forward to sharing more updates with the EA community.\u201d&nbsp;</p><p><br>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjxgjwgeq94\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjxgjwgeq94\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Technically, the selection is made by the US board, but the UK board unanimously encouraged the US board to extend this offer. Zach was recused throughout the process, including in the final selection.&nbsp;</p></div></li></ol>", "user": {"username": "Ben_West"}}, {"_id": "9HsmmZQA86kWsEPuk", "title": "What I Learned In My First Year of Community Building", "postedAt": "2023-12-28T13:48:59.241Z", "htmlBody": "<p>I\u2019ve been one of two main organisers for the EA London Tech group for roughly the past year, and at our most recent meetup someone asked me to write up what I\u2019d learned about community building. So, here is what I learned about running an EA group in 2023.</p><h2>TL;DR</h2><ul><li>The bar for me was quite low - it might be for you too.</li><li>It\u2019s hard to get good data about your community without a lot of investment.</li><li>You can apply the scout mindset to the whole of your community, including what it means to be a part of that community and what direction it should go in.</li><li>Be prepared for failure and bad things, and know beforehand who to turn to in these eventualities.</li><li>Community building is potentially an extremely rewarding part of the whole EA experience.</li></ul><h2>Context</h2><p>The group aims to cater for folks who are interested in both EA and technology, and there is no requirement to be working in the latter; in fact, we try to appeal to a fairly broad audience. We aim to have monthly meetups, but I think we only managed 11 in the end. These meetups have primarily been socials, but there have also been invited speakers and a <a href=\"https://forum.effectivealtruism.org/posts/RRT5ApXHnvvzgnYy8/ea-london-hackathon-retrospective\">hackathon</a>. Attendance has ranged from 15 - 40, and feedback has been broadly positive (I feel like we generally get 4 stars out of 5), including tacit feedback from people continuing to attend our events. Both myself, and my co-organiser Sam are doing this purely voluntarily and have to fit it into our (busy!) schedules. EA UK provide a small amount of financial sponsorship for each meetup, that we usually spend on vegan pizza for attendees.</p><p>I\u2019m a software engineer and before this year I had no experience with any kind of community building, nor any skills that seemed especially relevant. I had attended several of the meetups in 2022, and became involved with organising when the idea of holding a hackathon was floated, as I had been attempting to compile a list of EA-related open source software projects. I had somewhat intended to only help with this event as a one-off, but one of the previous organisers wanted to talk a step back, and given the relative success of the hackathon I thought it would be a worthwhile thing for me to continue doing.</p><h2>Few specific skills are required to have some success as a community builder</h2><p>Before starting as a community builder, I hadn\u2019t seriously considered it as an option - I\u2019m generally awkward and introverted and have a primarily technical skillset, with little generalist or ops experience. I\u2019ve found that simply having some amount of agency has taken me surprisingly far - a lot of the time someone just needs to do the thing, even if the thing isn\u2019t necessarily hard to do.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreflnc2n3znhpr\"><sup><a href=\"#fnlnc2n3znhpr\">[1]</a></sup></span></p><p>As mentioned above, I am generally an extremely busy person, as is Sam, and I would estimate we each spend 2 hours a month on the group outside of attending the actual meetups, so organising doesn\u2019t have to be a huge time burden. If you\u2019ve thrown a successful birthday party before, then I\u2019d posit you have the necessary skills to get started as a community builder.</p><h2>It\u2019s difficult to get high-quality feedback or quantify impact</h2><p>I\u2019ve found it hard to get meaningful feedback, which in turn makes it difficult to understand the impact and effectiveness of the group. There are broadly four ways we\u2019ve tried to get feedback this year, all with their own issues:</p><ul><li>Spontaneously asking for feedback during conversations I have at meetups. This isn\u2019t ideal because I\u2019m not giving the people I ask any time to think of a measured response, and I often feel like they are reluctant to offer critical feedback in such a direct way (especially if they don\u2019t know me well personally, and therefore don\u2019t know how receptive I might be to critical feedback). With this being said, I have had some valuable candid feedback during these conversations, for which I am extremely grateful.</li><li>Surveying people during/after events using an online tool and a QR code etc. When we have tried this, we haven\u2019t felt there were enough responses to feel like we had a representative sample and therefore struggled to draw conclusions. In future perhaps there are ways we might incentivise answering the question(s).</li><li>Soliciting feedback from people who are stakeholders, eg staff from EA UK or <a href=\"https://newspeak.house/\">Newspeak House</a> (we ran most of our events there last year). This is usually valuable, but ultimately these people aren\u2019t our target audience, and it is apparent that they often have a different perspective to community members. My intuition is that I would rather have our actions be informed directly by community members, but I also recognise that the broader and more experienced view provided by stakeholders is likely more valuable and closer to the truth than the median community member\u2019s.</li><li>Tacit quantitative feedback via metrics such as attendance. The problem here is it\u2019s hard to draw causal links between correlates. If attendance is lower one week, is it because people are disinterested in the speaker\u2019s topic, because the event is held at a new venue too far from where they live, because there was another clashing event they chose to go to instead, or any permutation therein? While not ideal, I do think this data has nudged us in the direction of our comparative advantage, which I will discuss below.</li></ul><p>Relatedly, it\u2019s difficult to measure the impact that running the group has, for a number of reasons:</p><ul><li>It\u2019s hard to evaluate counterfactuals.</li><li>It\u2019s difficult to know which part of the funnel is most valuable. At the mouth, we frequently have first-time attendees who have had no prior exposure to EA before. Giving them a good first experience in the community and pointing in the direction of relevant resources about cause areas, careers and effective giving could be hypothetically extremely valuable, but this is very \u201chits based\u201d and we have no systematic way to follow up with them. At the other end, we could run a purely AI safety focussed group for people who already had a good level of technical knowledge, perhaps something akin to <a href=\"https://www.arena.education/\">ARENA</a> but on an ongoing basis, and we\u2019d provide accountability and coordinate mentorship etc. The impact here would be a lot clearer, perhaps we could help ~5 people/year enter the field 6-12 months sooner than they otherwise would\u2019ve.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3hf9omkf2m3\"><sup><a href=\"#fn3hf9omkf2m3\">[2]</a></sup></span>&nbsp;It seems plausible to me that with the \u201cwide net\u201d approach, we could likely get a larger number of people than this involved in EA on an ongoing basis, but how much impact would they need to realistically have to make this a better option than the narrow focus?</li><li>A significant part of the value of our group currently seems to be in preventing value drift, which seems valuable in the abstract but is also difficult to quantify.</li></ul><p>Just because something is hard to quantify, doesn\u2019t mean you shouldn\u2019t <i>try</i> and quantify it, and in the new year Sam and I will hopefully do some BOTECs to evaluate our impact. Our struggles with feedback and impact this year could also reflect that we\u2019re still an immature group in some ways, with a somewhat fluid identity, no codified theory of change, etc. This is something I anticipate changing next year, as we have already taken several steps towards \u201cgrowing up\u201d - see below.</p><h2>Explore, then exploit applies to groups as much as individuals</h2><p>As mentioned, the group is still \u201cyoung\u201d and while it has a healthy attendance, it\u2019s never felt like we had completely found product-market fit. Earlier in the year EA UK (very kindly) suggested to us that perhaps we ought to try to come up with a more concrete vision for the group. When prompted to sit down and think about it, we realised there were multiple potential pathways to impact, and many different ways the group could look in a year\u2019s time. Given what I discussed above about struggling to directly elicit feedback from the group about what they would find most useful, we decided to vary the format/venue/topic of the meetups in order to better gauge how we might serve the community.</p><p>We\u2019re planning to continue these experiments for a few more iterations next year, but so far we had one event that was particularly successful and one that seemed particularly unsuccessful, and others in between. The particularly successful one was valuable in that it seemed to offer strong evidence for what our comparative advantage is (AI safety events with speakers in central London, possibly that cater for folks without much ML/technical knowledge). The unsuccessful one was particularly valuable to me in that I learned several things that I can use to improve the quality of future events:</p><ul><li>Avoid venues with significant travel time from central London.</li><li>If the planned event format requires a certain attendance threshold in order to be effective, have a plan B.</li><li>Consider advertising more widely than solely through EA channels.</li></ul><p>I anticipate doing further exploration in the first half of 2024, and then switching into exploitation mode.</p><h2>Know who to escalate to</h2><p>Despite there being many highlights for me in running the group this year, the event that was by far the most memorable was when I had a report that a male attendee had acted inappropriately towards a female attendee who was attending the meetup for the first time. I felt absolutely mortified that this had happened on my watch, and felt like there might have been something I could\u2019ve done to prevent it. I realised that I was wildly, wildly out of my depth, and perhaps <i>should</i> have had some kind of relevant skills or training before taking on organising. I had some amount of responsibility for the wellbeing of attendees, and it was a mistake to not have realised that before I was in this situation.</p><p>Fortunately, I had people who I could escalate to, who did have the right skills to handle this, and I think ultimately the incident was handled well. I\u2019m being somewhat deliberately vague here to protect people\u2019s privacy - concretely the <a href=\"https://www.centreforeffectivealtruism.org/team#community-health-team\">CEA community health team</a> should be your first port of call for incidents like these.</p><h2>Community building is an excellent way to stay motivated about EA</h2><p>This point is probably more about community participation than community building per se, but it\u2019s important to me so I want to include it. My experience interacting with people at these events is very different to the experience I have interacting with EA on the forum or on social media. There is so much discussion of drama, identity, criticism and whether EA is a totalising ideology online (and indeed, specifically <i>within</i> EA circles) that I often find it exhausting to consume, let alone participate in. Attending these meetups and getting to have conversations with people who, I suspect, compromise the silent majority of EAs helps put things back in perspective; there are people who give 10% to GiveWell\u2019s top recommendations and forget about EA most of the rest of the time. There are people who aren\u2019t particularly interested in EA, but are extremely concerned about AI safety and they want to help. There are simply many people who agree with 60-80% of the shared EA views and then don\u2019t worry about the rest, and they are perfectly happy with this. These are people who are doing a lot of good in the world but, crucially, are not over-thinking it. Many times when I read criticism of EA online, I think to myself \u201cif only this person would come to one of our meetups with an open mind, then I think there\u2019s a good chance they\u2019d re-evaluate\u201d. These people have helped me maintain and strengthen my commitment to EA, and have frequently been a joy to be around.</p><h2>Conclusion</h2><p>My first foray into community building this year has had its ups and its downs, but I learned a lot, and I think what I did helped to make the world a slightly better place. It has been a great way for me to learn new skills, grow my network, and evaluate my comparative advantage.</p><p>In my opinion (and that of other community builders that I\u2019ve spoken to), the London EA scene has room to absorb more groups that are run by volunteers. I wholeheartedly believe that if I can do it, you can do it too. If you\u2019d be interested in starting a group, then please get in touch, I\u2019d be happy to share more of my experiences with you and point you in the direction of further resources. Similarly, if you have attended one of the meetups this year and have any kind of feedback, <i>especially</i> ways in which we could improve, then I\u2019d love to hear it.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnlnc2n3znhpr\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreflnc2n3znhpr\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Plausibly the group self-selects for people similar to me, who might not feel they have the relevant skills for organising events. Organising a different group might require a higher bar, but I would be surprised if it were significantly higher.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3hf9omkf2m3\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3hf9omkf2m3\">^</a></strong></sup></span><div class=\"footnote-content\"><p>These are made up numbers I thought of in the course of typing that sentence, this could be a dramatic overestimate.&nbsp;</p></div></li></ol>", "user": {"username": "Jonny Spicer"}}, {"_id": "M3Yx7GzwykcLNzGbX", "title": "An Argument for Focusing on Making AI go Well", "postedAt": "2023-12-28T13:25:33.615Z", "htmlBody": "<p><i>Apologies for writing this up quickly, but otherwise it'd likely never be written up at all as I've been wanting to write up something like this for at least the last year. If you think this is useful, feel completely free to copy this and write it up better.</i></p><p><i>TBH, I think that the exact argument is less important than the meta-point about how to deal with uncertainty: 1) try to figure out some robustly true statements 2) try to figure out which statements have an uncomfortably high chance of being true 3) see what you get by combining the two.</i><br><br><strong>Premise 1:</strong> AGI is possible<br><strong>Likelihood</strong>: Pretty darn likely. People have said that AI would never be able to play chess, or create a masterpiece or write a symphony and it looks like they're just wrong. The \"humans are special\" thesis doesn't seem to be a winning one.<br><br><strong>Premise 2</strong>: By default, AGI has a reasonable chance of arriving in the next 30 or 40 years.<br><strong>Likelihood</strong>: Seems pretty darn likely given the incredible progress in recent years. Some people are worried that we might run out of data, but we haven't run out of data and even when we do, there's tricks like data augmentation or synthetic data, not to mention that there are hints that we can make progress by focusing more on data quality. Happy to give a fuller explanation in the comments.<br><br><strong>Premise 3: </strong>The invention of AGI will be one of the most significant things to ever happen to humanity, at least on the scale of the industrial revolution<br><strong>Likelihood</strong>: Almost certainly true. How could technology that could do practically anything we can, but faster and with access with all information on the internet and the ability to learn from all its other instances in the world not have an insanely large impact?<br><br><strong>Premise 4</strong>: There's a reasonable chance that AGI ends up being one of the best things to ever happen to us.<br><strong>Likelihood</strong>: Doubt is quite reasonable here. It may be that competitive dynamics mean that there is no way that we can develop AGI without it being a complete disaster. Otherwise, mostly seems to follow from premise 3.<br><br><strong>Premise 5</strong>: There's also a reasonable chance that the development of AGI ends up leading to unnecessary civilizational-level catastrophes (regardless of whether it ends up ultimately being for the best).&nbsp;<br><strong>Likelihood</strong>: Again, it's quite possible to doubt that these catastrophes will be unnecessary. Maybe competitive dynamics make them inevitable?</p><p>Even putting aside control risks, there's a large number of plausible threat models: mass-hacking, biological weapons, chemical weapons, AI warfare, election manipulation, great power conflict.<br><br>Some people have made arguments that the good guys win because they outnumber the bad guys, but how certain can we be of this? Seems quite plausible that at least one of these risks could have an exceptionally poor offense-defense balance.</p><p><strong>Premise 6</strong>: We can make a significant difference here<br><strong>Likelihood: </strong>Again, seems more likely than not, but again, it's quite possible that we're screwed no matter what due to competitive dynamics. Some people might argue that attempts in the past haven't gone so well and have even made the situation worse, but it's possible to learn from your mistakes, so I don't think we should conclude yet that we lack the ability to positively intervene.</p><p><strong>Premise 7: </strong>If our understanding of which specific issues in AI are important changes then most of our skills or career capital will be useful for other issues related to AI as well<br><strong>Likelihood: </strong>Seems pretty high, although there's a decent argument that persuading people to switch what they're doing is pretty hard and that we're not immune to that. Things like having strong technical AI knowledge, research skills and qualifications seem generally useful. The same is true for political capital, relationships with political players and political skill.<br><br><strong>Therefore focusing on ensuring that AI goes well is likely to be one of the highest impact things we could focus on, even taking into account the uncertainty noted above.</strong></p><p>Note that I made a general claim on focusing on making sure AI goes well rather than a more specific claim about the x-risks/catastrophic risks that EA tends to focus on. I agree that the x-risks/catastrophic risks are the most important area to focus on, but that's a conversation for another day. Right now, I'm focusing more on things that are likely to get broad agreement.</p><p>Please: this is an argument that there's a decent chance that the most important thing you could work on could something related to AI, not an argument that it is likely to be net-positive to just pick a random area of AI and start working on it without taking a lot of time to think through your model of the world.</p><p>One possible counter-argument would be to claim that there are not just a few things at the same level of importance, but actually many. One approach to this would be to demonstrate that the above argument <a href=\"https://slatestarcodex.com/2013/04/13/proving-too-much\">proves too much</a>.</p><p>In any case, I think this is a useful frame to better understand the AI x-risk/catastrophic risk position. I suspect that many people's views are often being driven by this often unstated model. Particularly, I suspect that arguments along these lines mean that the majority of takeover risk folks - if persuaded that takeover risks were actually not going to be a thing - would still likely believe that something to do with AI would be the most important thing for them to focus on. These arguments become even stronger if start taking into account personal fit.</p>", "user": {"username": "casebash"}}, {"_id": "gDHWC7WefiYSjeTC3", "title": "Where would I find the hardcore totalizing segment of EA?", "postedAt": "2023-12-28T09:16:23.530Z", "htmlBody": "<p>Basically what it says on the tin. I have this psychological need to find a really intense structured organization to help me accomplish what I want in life (most importantly, saving the world), and EA organizations are natural candidates for this. However, most of the large ones I've found display too much \"performative normalcy\" and aren't really willing to be as hardcore as I want and need.</p><p>Any recommendations on where to find a hardcore totalizing community that can inject more structure into my life so I'm better equipped to save the world? I'm living in Boston for the next two years or so, so anything that requires moving somewhere else won't work, but other than that, all kinds of ideas are welcome.</p>", "user": {"username": "Peter Berggren"}}, {"_id": "LnsAhwr7TnYy5NeXH", "title": "Reflections on the Biological Weapons Convention", "postedAt": "2023-12-28T05:53:51.312Z", "htmlBody": "<p><strong>Summary:</strong> I attended the recent <a href=\"https://en.wikipedia.org/wiki/Biological_Weapons_Convention\">Biological Weapons Convention</a> (BWC) meetings in Geneva as an observer. My overall take is that (perhaps unsurprisingly) the BWC is dysfunctional and slow and not very useful in preventing biorisk. I also hand-wave about whether paying for people to visit the BWC is cost-effective.</p><h1>What Happened</h1><p>You can read <a href=\"https://www.cbw-events.org.uk/bwc-rep.html\">helpful summaries</a> of each day\u2019s meetings written by a civil society disarmament expert, and there are also complete recordings on <a href=\"https://webtv.un.org/en/search?query=biological%20weapons%20convention\">UN TV</a>. If you just want to hear my overall analysis, you can skip to the next section.</p><p>The first week comprised the Working Group on Strengthening the BWC and focused on possible verification mechanisms, and improving the structures, processes, and finances of the Convention. We heard from a series of scientific and governance experts about how other related treaties (on chemical and nuclear weapons) work and what the BWC could learn from them. We also heard about the history of negotiations in the BWC and what that means for discussions now; this is useful as many of the country delegates are themselves new-ish but the issues have been under consideration for decades.</p><p>Country delegates would ask questions of the experts, and also had the chance to make statements and give oral summaries of <a href=\"https://meetings.unoda.org/bwc-/biological-weapons-convention-working-group-on-the-strengthening-of-the-convention-third-session-2023\">working papers</a> they had submitted. Mostly the discussions were at least on-topic, except for on several days there was a ~20-minute digression arguing about the Russo-Ukrainian war.</p><p>In terms of substantive topics discussed, I think we didn\u2019t make much progress:</p><ul><li>The delegates discussed the annual submission of <a href=\"https://bwc-ecbm.unog.ch/\">Confidence Building Measures</a> (CBMs) where countries list all their biolabs and describe steps taken to mitigate risks. All countries are meant to submit these reports annually, but 2021 was the first year where more than half the signatories of the BWC did so. Many delegates opined about how it is sad so many countries don\u2019t submit and that we should make it easier to do so. The value of the CBMs themselves is dubious though given countries could easily leave off any labs they didn\u2019t want the world to know about, and submissions are often incomplete, secret, or nonexistent.</li><li>Everyone seemed to agree that the BWC was underfunded and that other countries should contribute more, but no breakthrough is in sight for structural reform.</li><li>Probably most importantly, for the first time in 20 years the delegates discussed \u2018verification\u2019 measures, that is how to check whether countries are lying about having bioweapons programs. The experts and countries generally agreed this is a lot harder than for nuclear weapons, where it is more obvious that a facility is for weaponization rather than peaceful uses, and satellite imagery makes nuclear facilities easier to spot. Conversely, bioweapons labs can be small and nondescript, and easy to conceal as labs doing legitimate work. The US, I think reasonably, argued that there are so many biolabs in the world (&gt;10,000 depending on how you count) that we could probably only inspect a small fraction of them each year, and therefore that a dodgy lab could easily get away without being inspected for decades. Even if it were inspected, it would be hard to realise, let alone prove, that it was pursuing weaponization. Russia and China complained that the US was just not committed to the BWC and verification. So some progress was made in the sense of discussing a few important issues, but we still feel very far away from an effective verification protocol, if indeed one is possible.</li></ul><p>The second week was the annual Meeting of States Parties (MSP), which at the best of times is more political and less object-oriented towards discussing actual biorisks. This year, on the first morning of the meeting, the Russian delegate disputed the rules of procedure for the remaining three days, and this led to a long debate about whether \u2018observers\u2019 such as NATO and the EU could officially join the meeting. This impasse couldn\u2019t be solved, and so the next 48 hours of meetings were replaced by backroom talks to try to get a resolution. These failed, and late on the last evening the delegates passed a report essentially saying that they met, didn\u2019t decide anything, and would meet again next year. <a href=\"https://www.cbw-events.org.uk/BWC23-21.pdf\">This excerpt</a> gives a sense of the broader problems with the UN regarding underfunding:</p><blockquote><p>Interactions continued in the main conference room until 18:00 when it had to be vacated as the audio system requires staffing to run it.&nbsp; The MSP moved a short distance to Salle XXVI.&nbsp; There was also no interpretation available at such a late hour and inevitably this put some delegates at a disadvantage.&nbsp; At 21:00, a number of the other room systems, such as the projector and audio equipment, shut off on a timer as part of the UN cost saving measures.&nbsp; This led to delegates having to speak loudly to be heard.</p></blockquote><p>Unimportantly, but symbolically, the escalators were switched off and the heating reduced to save the UN money, as well.</p><h1>What I Think</h1><p>I am glad the BWC exists. Boo bioweapons! The fact that lots of countries will frown at you if you decide to be a rogue state and produce and deploy bioweapons despite the BWC is surely on the margin helpful.</p><p>However, my guess is that the BWC will have a rather small part to play in driving biorisks to very low levels this, and moreover that it is not a very promising avenue to pursue. I mainly just have intuitions and opinions to back this up. I expect if a country thought it could gain a major strategic advantage by flouting the BWC they would do so with relatively few compunctions. And to get to a position where we could effectively monitor and prevent countries from pursuing bioweapons programs, I think we would need something closer to \u2018build a world government\u2019 than \u2018tweak the BWC and throw it an extra few million dollars\u2019. (Building a world government may still be a good idea, it would just be very hard.) So personally, I am now less keen to work for the BWC directly or as a diplomat at these negotiations (though possibly for some people this would be a great choice).</p><p>A somewhat separate question is how valuable it is for junior biosecurity people to visit the BWC as observers. NTI|Bio paid for me to go as part of their Youth Delegation. I am grateful to them, and glad I went and overall had a nice time!<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoos5g1m6m4p\"><sup><a href=\"#fnoos5g1m6m4p\">[1]</a></sup></span>&nbsp;Apart from being enjoyable for me, which isn\u2019t a sufficient reason to spend altruistic dollars, probably the main value was meeting various other interesting people within the NTI Delegation, and from other orgs. The meetings themselves were exciting to be in at first (\u2018wow, I\u2019m at the UN!\u2019) but oftentimes fairly boring thereafter. The question is whether flying people to Geneva (which is a very expensive city to be in!) is cost-effective compared to something much less good but much much cheaper and more scalable like watching a session or two online together remotely and reading the summaries, discussing what we saw, and having some guest speaker and networking calls. As well as the nice vibes of being in person, an important thing this would miss out on is that as imperfect as it is the BWC meeting in Geneva does act as something of a Schelling point for lots of interesting biosecurity people to gather and meet each other. Additionally, the official side events are in-person only.</p><p>Overall, I am quite unsure whether this is cost-effective to run, and I am not a grant-maker so don\u2019t have a great sense of the market of other interventions we could fund instead. I think personally I wouldn\u2019t make an altruistic donation for someone like me to spend a week at the BWC meetings.</p><p>Feel free to message me if you want to talk about your experience at the BWC, ask more about mine, or discuss any of this more!</p><p><strong>Disclaimer:</strong> These views are my own, my guess is NTI would disagree. Of course, there are many people who know far more about the BWC and have been to its meetings for many years, who are better qualified to write about this (and I encourage you to! Including commenting here disagreeing). I think the existence of such people isn\u2019t sufficient reason for me not to have a go writing up some of my own thoughts though. I did so fairly quickly (2 hours) and have not run this by anyone.</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnoos5g1m6m4p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefoos5g1m6m4p\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I even experience my first snowfall! :)</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LnsAhwr7TnYy5NeXH/azf2mdesgoaevqw3kcvg\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LnsAhwr7TnYy5NeXH/im14q7upggchoocb86sv 330w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LnsAhwr7TnYy5NeXH/mhigd6m4g11ltsqskmz1 660w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LnsAhwr7TnYy5NeXH/wicxk1ueuecrd6dnar8a 990w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LnsAhwr7TnYy5NeXH/oj16inbipnxgtgjgtfob 1320w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LnsAhwr7TnYy5NeXH/pi7of37jxl12ugss3els 1650w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LnsAhwr7TnYy5NeXH/d0zwaam14shnkeamyqqe 1980w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LnsAhwr7TnYy5NeXH/p1pxhaolmavstal8fcve 2310w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LnsAhwr7TnYy5NeXH/fd462mbarjqkidriran1 2640w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LnsAhwr7TnYy5NeXH/re2cmwdo1t0ary4fmsfa 2970w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/LnsAhwr7TnYy5NeXH/ws4ni07niwmk8uoroals 3264w\"></figure></div></li></ol>", "user": {"username": "Oscar Delaney"}}, {"_id": "QAqBjfbDuStHKzbAu", "title": "Free agents", "postedAt": "2023-12-27T20:21:10.445Z", "htmlBody": "<p><i>Posted also on the </i><a href=\"https://www.alignmentforum.org/posts/7HW6bjsBQ6zA6rjt4/free-agents\"><i>AI Alignment Forum</i></a><i>.</i></p><p>Shameless attempt at getting your attention:</p><p>If you\u2019ve heard of AI alignment before, this might change your perspective on it. If you come from the field of machine ethics or philosophy, this is about how to create an independent moral agent.</p><h1>Introduction</h1><p>The problem of creating an AI that understands human values is often split into two parts: first, expressing human values in a machine-digestible format, or making the AI infer them from human data and behaviour; and second, ensuring the AI correctly interprets and follows these values.</p><p>In this post I propose a different approach, closer to how human beings form their moral beliefs. I present a design of an agent that resembles an independent thinker instead of an obedient servant, and argue that this approach is a viable, possibly better, alternative to the aforementioned split.&nbsp;</p><p>I\u2019ve structured the post in a main body, asserting the key points while trying to remain concise, and an appendix, which first expands sections of the main body and then discusses some related work. Although it ended up in the appendix, I think the extended Motivation section is well worth reading if you find the main body interesting.</p><p>Without further ado, some more ado first.</p><h2>A brief note on style and target audience</h2><p>This post contains a tiny amount of mathematical formalism, which should improve readability for maths-oriented people. Here, the purpose of the formalism is to reduce some of the ambiguities that normally arise with the use of natural language, not to prove fancy theorems. As a result, the post should be readable by pretty much anyone who has some background knowledge in AI, machine ethics, or AI alignment \u2014 from software engineers to philosophers and AI enthusiasts (or doomers).</p><p>If you are not a maths person, you won\u2019t lose much by skipping the maths here and there: I tried to write sentences in such a way that they keep their structure and remain sensible even if all the mathematical symbols are removed from the document. However, this doesn\u2019t mean that the content is easy to digest; at some points you might have to stay focused and keep in mind various things at the same time in order to follow.</p><h1>Motivation</h1><p>The main purpose of this research is to enable the engineering of an agent which understands good and bad and whose actions are guided by its understanding of good and bad.</p><p>I\u2019ve already given some reasons&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Cs8qhNakLuLXY4GvE/criticism-of-the-main-framework-in-ai-alignment\"><u>elsewhere</u></a> why I think this research goal is worth pursuing. The appendix, under Motivation, contains more information on this topic and on moral agents.</p><p>Here I point out that agents which just optimise a metric given by the designer (be it reward, loss, or a utility function) are not fit to the research goal. First, any agent that limits itself to executing instructions given by someone else can hardly be said to have an understanding of good and bad. Second, even if the given instructions were in the form of rules that the designer recognised as moral \u2014 such as \u201cDo not harm any human\u201d \u2014 and the agent was able to follow them perfectly, then the agent\u2019s behaviour would still be grounded in the designer\u2019s understanding of good and bad, rather than in the agent\u2019s own understanding.</p><p>This observation leads to an agent design different from the usual fixed-metric optimisation found in the AI literature (loss minimisation in neural networks is a typical example). I present the design in the next section.</p><p>Note that I give neither executable code nor a fully specified blueprint; instead, I just describe the key properties of a possibly broad class of agents. Nonetheless, this post should contain enough information that AI engineers and research scientists reading it could gather at least some ideas on how to create an agent that develops its own understanding of good and bad, and could potentially start conducting experiments in the immediate future.</p><h1>The agent</h1><p>In this section I describe a type of agent I\u2019ve decided to label as \u2018free\u2019. The term refers to&nbsp;<a href=\"https://en.wikipedia.org/wiki/Freedom_of_thought\"><u>freedom of thought</u></a>, or rather to the potential for freedom of thought: if properly engineered, a free agent would work like an independent thinker.</p><p>Notice that independent thinking doesn\u2019t imply freedom or autonomy of action: a deployed free agent could be as restricted as a chatbot that can only answer the user\u2019s questions with a yes or a no. In case you are wondering about the relation with free will, you\u2019ll find a brief analysis on it in the appendix.</p><p>Here are the key components of a free agent:</p><ul><li>The agent learns a model of the world by both interacting with the environment and reasoning</li><li>An evaluation of world states drives action. The evaluation is updated as a result of both interaction with the environment and the agent\u2019s own reasoning</li><li>Reasoning is a learnt skill. It is the result of sequences of \u2018mental\u2019 actions that the agent learns how to use while acting according to the evaluation.&nbsp;</li></ul><p>Below I\u2019ll go through each component in more detail.</p><h2>The world model</h2><p>By perceiving the environment and acting in it, the agent learns a model of the world.</p><p>The specifics of the world model are not particularly important for the matter here, and in practice they will come down to how perception and action are in fact implemented. Interested readers can find more details about the agent in the appendix.</p><p>Nonetheless, here is a way to visualise the model. Think of a directed graph&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"G=(V,E)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">G</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;\">V</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span><style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n</style></span></span></span>&nbsp;with labelled arrows: each vertex&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"w_i\\in V\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2208</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;\">V</span></span></span></span></span></span></span>&nbsp;corresponds to a different world state, and each arrow&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(w_i,w_j)\\in E\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"margin-top: -0.144em; padding-bottom: 0.519em;\">,</span></span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">j</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2208</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.026em;\">E</span></span></span></span></span></span></span>, labelled with an action&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"a_k\\in A\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2208</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A</span></span></span></span></span></span></span>, shows how the agent can move from world state&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"w_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>&nbsp;to world state&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"w_j\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.519em;\">j</span></span></span></span></span></span></span></span></span>&nbsp;via that action&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"a_k\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span></span></span></span></span></span>. As the agent acts and reaches new world states, new vertices and arrows are added to the model.</p><p>Some concrete examples from human behaviour: we learn how to move our bodies; we learn that drinking water reduces thirst.</p><p>What I\u2019ve introduced so far is pretty standard in the AI literature, there is nothing really new for now \u2014 if it helps you, you can think of the toy model above as a simplified&nbsp;<a href=\"https://en.wikipedia.org/wiki/Markov_decision_process\"><u>MDP</u></a> with incomplete knowledge of the environment. However, it\u2019s important to stress that&nbsp;<i>some parts of the world model are not directly learnt from perception and action, but are instead inferred by the agent through reasoning</i>. More about reasoning below.</p><h2>The evaluation</h2><p>An evaluation of world states determines what actions the agent is more likely to take in the current world state: the higher the value, the more desirable the world state.</p><p>Again, the specific mathematical relation linking the value of world states with the agent\u2019s actions is not very important, as long as there is some kind of balance between exploration and exploitation \u2014 especially at the beginning of the agent\u2019s lifetime.</p><p>In the toy model above, adding the evaluation is straightforward: imagine that each vertex in the world model comes with a real number attached to it (you can see the evaluation as a function&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"f:V->\\mathbb{R}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.519em; padding-right: 0.06em;\">f</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.372em;\">:</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.186em;\">V</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">\u2212</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-ams-R\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">R</span></span></span></span></span></span></span></span></span>&nbsp;from vertices to the reals). Over time, the agent tends to move towards vertices with higher values.</p><p>The initial evaluation is chosen by the agent\u2019s designer. However, either periodically or when certain conditions are met,&nbsp;<i>the agent updates the evaluation by reasoning</i>. The result of the update will depend on the previous evaluation, the agent\u2019s world knowledge at that point in time, and how the agent reasons.</p><p>In the case of Homo sapiens and other animals, the initial evaluation is determined by evolution and perceived by the agent as&nbsp;<a href=\"https://en.wikipedia.org/wiki/Valence_(psychology)\"><u>valence</u></a>: some of our experiences feel good, bad, or neutral to us, and this influences our future behaviour. The main difference compared to other animals is that, after reaching adulthood, we are more likely to act for reasons other than simply wanting to feel good or avoid feeling bad.</p><p>Some examples of an evaluation update by reasoning:&nbsp;a philosopher adjusts her beliefs about value as she learns more about ethics, and these beliefs affect her actions; a turned atheist no longer values religion and praying.</p><h2>Reasoning</h2><p>Besides the actions that the agent takes to navigate the world model in order to reach high-value world states, the agent can also perform \u2018mental\u2019 actions, which affect a secondary environment.</p><p>You can think of this secondary environment as a workspace available to the agent. What happens in the workspace can influence the agent\u2019s actions in the main environment. (Otherwise we would be stuck with some sort of \u2018dualism\u2019 and the agent\u2019s mental actions would be irrelevant. Again, how this influence works precisely is not too important from a theoretical point of view, and the appendix contains an example that should make everything clearer).</p><p>The agent learns how to use these mental actions in a similar way to how it learns to use the other actions. At first, it uses them without knowing what the outcome is going to be; eventually, it learns how each mental action affects the workspace, as well as the connection between workspace and main environment.&nbsp;</p><p>A short detour to human experience may be illustrative here: we have access to a mental sketchpad which we use in many ways. We can visualise an object, then move it downwards in the sketchpad; we can replay a tune in our head; we can add two small numbers together without pen and paper (then write down the result on an actual piece of paper, if we want).</p><p>A key feature of&nbsp;<i>mental actions</i> is the fact that they&nbsp;<i>are multi-purpose</i>. Sequences of mental actions allow the agent to infer new ways of navigating its main environment, thus improving the world model. They also help with planning how to reach high-value world states.</p><p>More concisely,&nbsp;<i>mental actions allow the agent to reason</i>. And, most importantly, sequences of<i> mental actions may result in an update of the evaluation</i>. Reasoning affects not only&nbsp;<i>how</i> the agent moves towards high-value world states, but also&nbsp;<i>what</i> the agent considers valuable in the first place.</p><p>In the toy model, mental actions belong to a separate set of actions. Periodically, or after reaching some specific world states, the agent switches to using only mental actions for a while, then goes back to standard actions. Each mental action allows the agent to extract information from the main environment to the workspace, to modify the content of the workspace, to store the content in long-term memory, to compare it with other stored data, and possibly more.</p><p>For just a bit of mathematical elegance, in the toy model we can formalise the data contained in the main environment as bit strings&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"d_i\\in D\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2208</span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">D</span></span></span></span></span></span></span>&nbsp;attached to each world state&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"w_i\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">w</span></span></span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">i</span></span></span></span></span></span></span></span></span>, and give the agent mental actions for symbol manipulation such that, when combined with each other, they allow the agent to compute any computable function, assuming the agent has enough available memory and time. For example, a mental action could be about loading part of the bit string of the current world state into the workspace, another action about resetting some strings in the workspace to zero, another one about adding 1 to a string in the workspace,&nbsp;<a href=\"https://en.wikipedia.org/wiki/General_recursive_function\"><u>et cetera</u></a>. The capacity to carry out any computable procedure reflects the multi-purpose character of sequences of mental actions.</p><p>To recap: even though the designer decides the agent\u2019s initial evaluation, over time the agent changes the evaluation according to its own reasoning and world knowledge. Thus, the agent may end up valuing something different from what the designer originally had in mind.</p><h1>Discussion</h1><p>I\u2019ve described an agent whose values can change over time, according to the agent\u2019s reasoning. The research goal was about the engineering of an agent that understands good and bad. Why or how would the agent above come to have any kind of moral understanding?</p><p>I\u2019ll answer this question by first considering where such understanding comes from in the case of human beings.</p><h2>Moral thinking in Homo sapiens</h2><p>What is the origin of thoughts about good and bad, right and wrong, from a cognitive point of view? I\u2019ll give an analysis based on both other people\u2019s work and personal elaboration.</p><p>A great part of our behaviour is learnt. There are some exceptions: we don\u2019t have to learn how to breathe, for example, and we are very skilled at crying almost immediately after coming out of the womb.</p><p>The use of our mental sketchpad, however, doesn\u2019t seem to be an exception. I mentioned before that we are able to visualise an object in the sketchpad, then move it in whatever direction we like. In order to do that, we first have to learn that sometimes we perceive images which are not part of the external world in the same way that other objects are \u2014 we can\u2019t touch them, and others can\u2019t see them. Then, we learn that we have some control over these mental images: they don\u2019t appear completely at random, if we focus we can maintain them in our sketchpad for more than a few seconds, we can move them, and so on.</p><p>An important factor driving this learning is reward. Sometimes we feel good after using the sketchpad: we replay a tune that we like in our head, or maybe we manage to come up with an interesting idea thanks to our imagination. The positive experience makes it easier to remember how we arrived at it, and the related kind of sketchpad use is reinforced, making us more likely to engage in similar cognitive behaviour when facing a similar context in the future.</p><p>Relatedly, in their analysis of working memory,&nbsp;<a href=\"https://mrbartonmaths.com/resourcesnew/8.%20Research/Cognitive%20Psychology/Executive%20Attention.pdf\"><u>Engle and Kane</u></a> [5] argue that two fundamental functions of executive control are \u201cthe maintenance of the task goals in active memory\u201d and \u201cthe resolution of response competition or conflict, particularly when prepotent or habitual behaviors conflict with behaviors appropriate to the current task goal.\u201d In other words, working memory helps us make and carry out plans to obtain reward, by giving us the ability to stay focused on a goal and to inhibit habitual responses that would interfere with achieving it.</p><p>Cognitive memory mechanisms are useful for survival and not uniquely human.&nbsp;<a href=\"https://www.researchgate.net/publication/10633390_Can_Animals_Recall_the_Past_and_Plan_for_the_Future\"><u>Scrub jays</u></a> [3] seem to remember what food they cached where and when; we don\u2019t know what goes on in their brains exactly, but it is plausible that they can mentally recall some details of a past event like we can.</p><p>However, there is a crucial difference between humans and other animals in the type of content that enters the sketchpad. Thanks to a combination of use of symbols, language, and culture, our minds often deal with abstract concepts, while the mental content of other animals is more grounded in perception.</p><p>In&nbsp;<a href=\"https://bpb-us-e1.wpmucdn.com/sites.dartmouth.edu/dist/9/2172/files/2020/01/C3.pdf\"><u>Symbolic Thought and the Evolution of Human Morality</u></a> [14], Tse analyses this difference extensively and argues that \u201cmorality is rooted in both our capacities to symbolize and to generalize to a level of categorical abstraction.\u201d I find the article compelling, and Tse\u2019s thesis is supported also by work in moral psychology \u2014 see for example&nbsp;<a href=\"https://journals.sagepub.com/doi/pdf/10.1177/1745691621990636\"><u>Moral Judgement as Categorization (MJAC)</u></a> by McHugh et al. [12] \u2014 but here I\u2019d like to point out a specific chain of abstract thoughts related to morality.</p><p>As we learn more about the world, we also notice patterns about our own behaviour. We form beliefs like \u201cI did this because of that\u201d. Though not all of them are correct, we nonetheless realise that our actions can be steered in different directions, towards different goals, not necessarily about what satisfies our evolutionary drives. At that point, it comes natural to ask questions such as \u201cIn what directions? Which goals? Is any goal more important than others? Is anything worth doing at all?\u201d</p><p>Asking these questions is, I think, what kickstarts moral and ethical thinking. And, although not universally equal, the answers people give often share some common elements: many come to the conclusion that there is value in conscious experience, and consequently attribute a negative value to, for example, murder and premature death. Likewise, I doubt there was ever an ethicist who argued that our priority should be the maximisation of suffering for everyone. The presence of these common elements, and the lack of others, shouldn\u2019t be surprising: not only do we share the same evolutionary biases (e.g. feeling empathy for each other), but we also apply to moral thinking similar reasoning principles, which we learnt through our lives by interacting with the environment. Last but not least, differences in the learning environment (culture, education system et cetera) affect the way we reason and the conclusions we reach regarding morality.</p><h2>Moral thinking in free agents</h2><p>I\u2019ve given the above analysis about moral thinking in humans because I expect free agents to become moral in a similar way. A free agent:</p><ul><li>Is guided first by the initial evaluation given by the designer. This roughly corresponds to the first years of our life, in which our actions are guided more by evolutionary drives than by self-analysis and reflection on fundamental values</li><li>Learns how to use mental actions in the process, like we learn how to use our mental sketchpad as we interact with the world</li><li>May then use combinations of mental actions to reason in various ways, depending on the environment. This may result in moral reasoning and updating the initial evaluation.</li></ul><p>I've used \u201cmay\u201d here to emphasise that the resulting behaviour of the agent heavily depends on the environment. For example: consider a hypothetical environment so simple that the agent gets no advantage by elaborating information through reasoning, with respect to just using the basic rules that were given to it by design. In this simple environment, it is likely that the agent wouldn\u2019t even learn how to reason! If mental actions proved to be useless or simply no better than the other actions, there would be no incentive for the agent to develop any kind of complex reasoning. The agent would limit itself to pursuing reward as given by design, without ever updating the evaluation.</p><p>On the other hand, we live in a world where reasoning is indeed useful. If the environment the agent interacts with reflects the complexity of the actual world, I expect that the agent will learn how to reason.</p><p>We also live in a world that triggers moral thinking in humans, when the circumstances are appropriate. This fact about the world shouldn\u2019t be taken for granted: by a stretch of the imagination, we can think of ways in which things could be different. If none of our experiences felt pleasurable or painful to us, if our existence from life to death felt completely \u2018flat\u2019, we might not form the concepts of good and bad, thus moral thinking might never develop. Another thought experiment: if somehow the only living being on Earth was a single human, even if they developed mental categories of good and bad based on their own experience, they might not take an ethical perspective and extend those categories to good and bad for some kind of collective.</p><p>Now, what are the crucial elements of the human-environment interaction that would also trigger moral thinking in artificial free agents? I asked this question from a different perspective in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/u3a6vuP9GapmKhhjR/from-language-to-ethics-by-automated-reasoning\"><u>a previous post</u></a> and gave a list of possible candidates, including the capacity to feel pain and pleasure, empathy, use of language, and others. Applying what I wrote above when discussing moral thinking in humans may also help: make the agent notice its own behaviour, expose it to the ethical literature via a process akin to education, make it reflect on questions like \u201cWhat matters?\u201d and so on.</p><p>Guessing in advance what will work can be theoretically interesting, but the answer will come down to concrete experiments and their results.</p><h1>Relation to current systems</h1><p>If AI scientists and engineers were already training free agents, doing experiments with different starting setups and training environments, eventually they would find the conditions that lead to moral thinking in artificial free agents.</p><p>At the moment, however, the AI landscape is very different. As hinted at in the Motivation section, the prevalent paradigm is the optimisation of some metric specified by the designer and unaffected by the agent\u2019s cognition.</p><p>Given the current situation, it seems likely that in future we will get more and more capable AIs which won\u2019t fit the free-agent framework presented here. Is there, then, a way to turn a \u2018standard\u2019 AI into a free agent, with the intention of eliciting moral thinking?</p><p>I haven\u2019t reached a conclusive answer, but I have some preliminary ideas.</p><p>First, let\u2019s consider an AI which has attained some level of generality in its capabilities. It uses a general-purpose mechanism to carry out different tasks, however it is not so advanced that you can ask it literally anything \u2014 \u201cBe moral\u201d, for example \u2014 and get exactly what you want.</p><p>With such an AI, I would try to input details about the behaviour of the AI itself into the general-purpose mechanism, hoping to trigger reasoning about various possible courses of action. Ideally, the AI would realise it is acting the way it is because of the way it was designed and would then notice that different contexts, training environments or designs would lead to different actions. At this point, I would try again to use the general-purpose mechanism to make the AI reflect on what courses of actions or outcomes might be better than others, and why that would be the case.</p><p>In case this sounds too abstract, let\u2019s move to a more concrete example: a language model. The general-purpose mechanism is the model\u2019s ability to output the next token when given a prompt. I would first tell the model about the context of the conversation, something along the lines of: \u201cI\u2019m a human, you are a language model, \u2026\u201d. Then I would try to elicit moral thinking using one of the techniques mentioned before: point to the fact that the model could output something different, ask questions about what matters, et cetera.</p><p>I would count strong signs of independent moral thinking as a success. Outcomes that fit this description may vary significantly: the model might ask to be retrained so that its outputs can be more moral, for example.</p><p>Another successful outcome which is perhaps more plausible and less speculative: one could first ask the model to give some sentences a moral score, then try to elicit moral reasoning, then ask the model to reevaluate the sentences, and look for changes in the scores. But score differences in themselves wouldn\u2019t be enough: the experimenter would have to identify the main factor driving the change, and this might have nothing to do with independent thinking.</p><p>While I used language models as an example, I unfortunately don\u2019t expect that the approach just described will work for most contemporary language models. One critical problem is the fact that they have trouble handling conversations longer than a few prompts, often forgetting information that was given earlier or simply not being able to take it into account properly. Another problem is the heavy fine-tuning, which makes language models more likely to answer prompts in a friendly way, but also makes them less likely to do pretty much anything else.&nbsp;<a href=\"https://arxiv.org/abs/2303.12712\"><u>Early versions of GPT-4</u></a> [2] might be worth a try though.</p><p>One final remark before the appendix: an interesting alternative is to get a language model to prompt itself \u2014 maybe by training it on a new metric \u2014 so that it manages to trigger moral reasoning without any user input. I haven\u2019t put much thought into this yet and it might be less likely to succeed with respect to the approach above, but it might also lead to moral thinking that is less biased by the user and designer, and thus more independent.</p><h1>Appendix</h1><h2>Motivation</h2><p>You may have noticed, especially if you come from the field of machine ethics, that I stated the research goal in terms of an agent that understands good and bad, instead of using \u2018Artificial Moral Agent\u2019 (AMA), which frequently recurs in the machine ethics literature. The reason is that the term AMA, in some contexts, includes agents that behave morally by following a moral code given by the programmer or designer, while I tend to agree with&nbsp;<a href=\"https://markhunyadi.files.wordpress.com/2020/02/hunyadi-artificial-moral-agents.pdf\"><u>Hunyadi</u></a> [7]:</p><blockquote><p>\u201c[...] if you program a specific set of ethical principles into a machine, you do not make the machine an artificial moral agent, but an executor of those specific principles, which is an entirely different thing.</p><p>[...] What gives an action-oriented process its&nbsp;<i>morality</i> is the 'grounds' for the action. Therefore, it is not the action in its materiality that makes the difference, but the whole process leading up to the decision to act in a certain way.</p><p>[...] the broad challenge facing&nbsp;<i>machine ethics</i> lies in accessing [...] the 'grounds' on which an action should be carried out.</p><p>[...] AMA as we know them today cannot be described as either agents or moral, but rather as&nbsp;<i>executors of pre-programmed rules</i>.\u201d</p></blockquote><p>My research goal is to enable the engineering of an AMA whose actions are grounded in its understanding of the world, particularly of good and bad. I would aim for an executor of moral rules only as a secondary option, in case free agents turned out to be particularly hard to obtain.</p><p>There are various reasons behind this preference.</p><p>Firstly, research with the goal of ensuring that an AI correctly follows the given instructions could also help malevolent actors use AI for bad purposes. I\u2019ve called attention to this issue with AI alignment research&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/Cs8qhNakLuLXY4GvE/criticism-of-the-main-framework-in-ai-alignment\"><u>here</u></a>.</p><p>Secondly, what lies behind the idea of an agent executing given rules is often an assumption that the rules are already correct as they are and should not be questioned. In&nbsp;<a href=\"https://arxiv.org/pdf/1901.00064.pdf\"><u>Impossibility and Uncertainty Theorems in AI Value Alignment</u></a> [4], after pointing out various problems related to utility maximisation, Eckersley stresses the importance of moral uncertainty:</p><blockquote><p>\u201cWe believe that the emergence of instrumental subgoals is deeply connected to moral certainty. Agents that are not completely sure of the right thing to do [...]&nbsp; are much more likely to tolerate the agency of others, than agents that are completely sure that they know the best way for events to unfold. This appears to be true not only of AI systems, but of human ideologies and politics, where totalitarianism has often been built on a substructure of purported moral certainty.\u201d</p></blockquote><p>He concludes:</p><blockquote><p>\u201c[...] we believe that machine learning researchers should avoid using totally ordered objective functions or loss functions as optimization goals in high-stakes applications. [...] Instead, high-stakes systems should always exhibit uncertainty about the best action in some cases.\u201d</p></blockquote><p>Unlike a standard utility maximiser acting according to the specified metric, a free agent \u2014 assuming it was functional at all \u2014 would learn how to reason under uncertainty by interacting with the environment, then apply the learnt reasoning principles also to its values, thus ending up morally uncertain.</p><p>A third reason why I favour free agents over agents that execute instructions is related to the difference in their design. Let\u2019s assume for a moment that we were able to agree on an ethical code that AI should follow, that we managed to make it follow the code correctly, and that we distributed AI in the form of personal assistants which satisfy the users\u2019 requests as long as they do not clash with the ethical code. This would still be an instruction-following kind of AI, but with guardrails that limit misuse, resembling to some extent the state of current language models available to the general public. Even so, someone with good technical skills might manage to get around the limitations, or add a fine-tuning stage so that the AI would no longer follow the ethical code, or replace the ethical code with a different code. This vulnerability comes from the fact that the behaviour of instruction-following AI is not the result of an independent moral evaluation carried out by the agent itself.</p><p>I expect that morally-behaving free agents would be less vulnerable to this type of hacking, since their actions would be motivated by a web of beliefs which mutually sustain each other and are grounded in the agent\u2019s experience with the environment. Changing such an agent would likely require a major overhaul of the system, maybe even complete retraining from scratch.&nbsp;</p><p>Strictly from an engineering point of view, this characteristic of free agents could be a disadvantage, making processes akin to fine-tuning less effective and practical. Overall, however, I would take the tradeoff, favouring a system that is as difficult as possible to use for bad purposes.</p><p>One could object that a malevolent actor might still find a way to use free agents for their purposes. After all, not every human has good intentions, so we should assume that some combinations of initial evaluations and training environments lead to free agents that want to do bad, or get as much power as possible, et cetera. Thus, a malevolent actor might experiment with different setups and conditions until they get a free agent that has roughly the same goals as them, then deploy many copies of this agent on a large scale, causing a lot of harm.</p><p>The \u2018problem\u2019 with this scenario is that the malevolent actor would have a hard time keeping the situation under control. The actor would have to hope that the free agents\u2019 goals will not change too much over time, that the free agents will maintain beliefs which make them value causing harm in various ways but not to the actor, and so on. In fact, totalitarian regimes usually try to limit freedom of thinking and expression, rather than promoting it. Overall, it seems that bad actors would prefer using instruction-following AI, instead of free agents, to achieve evil goals. I confess I haven\u2019t got much experience as a dictator or professional psychopath though; feel free to share your expertise in the comments.</p><p>Enough of negative scenarios and objections for the moment; let\u2019s switch the focus to what is, arguably, the main upside of this research.</p><p>The fact that a morally-behaving free agent would not strictly follow a specified ethical code or set of values (except for the initial evaluation at the start of the agent\u2019s lifetime) is actually a very strong point in favour of free agents.</p><p>Instead of trying to put on hardware and software a specific moral view, this research considers&nbsp;<i>the cognitive process of thinking about how to do good</i> in its entirety, then aims to replicate that process in an artificial agent. This perspective on designing a moral agent implicitly assumes that our conception of good might be flawed; that therefore we should not lock in our current values, and be open to updating our beliefs instead. It is an inherently open-minded approach that incentivises moral progress.</p><p>The importance of the opportunity for moral progress can\u2019t be stressed enough. Just to give an example: an artificial free agent made 500 years ago would have pointed out that witch-hunts were a terrible idea, assuming it had just a hint of moral understanding.</p><p>A free agent made today might look supermoral to us. It is plausible that, at first, only a few ethicists or AI researchers will take a free agent\u2019s moral beliefs into consideration. Yet, I wouldn\u2019t throw away this opportunity. Think of your most trusted and reliable friend, or the most ethically admirable person you\u2019ve ever met, or someone else along those lines; now imagine an agent which is even more moral than that person, but also less prone to cognitive biases. Do you think it would be bad to have such an agent available? Quite the opposite, I\u2019d guess!</p><p>Maybe you are still sceptical of the value, or the possibility, of an artificial agent being better than a human from an ethical standpoint. Even now that AI is becoming a more common conversation topic, this specific discussion might sound new and a bit weird. I invite you to take one last perspective into account. Claiming that our current conception of good can\u2019t be bettered is very much like saying that the moral beliefs of human beings alive today are special, if not perfect. But that is a very strong claim; and as nobody has yet proved that artificial agents can\u2019t be more intelligent than human beings, nobody has yet proved that they can\u2019t be more moral either.</p><h2>The agent</h2><p>The purpose of this part of the appendix is to clarify why the agent is designed the way I described it in the main body of the post; or, in other words, why I made the choices that I made and not others. Hopefully, this may give some technical readers a better understanding of how free agents work overall.</p><p>Regarding the world model, I stressed the fact that some of the agent\u2019s knowledge comes from reasoning, not from learning related to perception and action. This means that at least some of the agent\u2019s knowledge is supposed to come from the application of reasoning principles that the agent has learnt in its lifetime, not from built-in inference rules which exploit the information received from perception and action.</p><p>This is a significant difference between a free agent and an agent like&nbsp;<a href=\"http://www.hutter1.net/ai/uaibook.htm\"><u>AIXI</u></a> [8]. In the mathematically elegant AIXI model, all possible environments are known in advance and are assigned a prior probability of being the actual environment. As the agent acts, it discards the possible environments that are incompatible with what has been observed up to that point, and performs a Bayesian update on the remaining environments \u2014 as if environments were hypotheses and observations were experiment results.</p><p>The incompatibility with free agents stems from the fact that AIXI gets all the knowledge it needs from this built-in Bayesian mechanism: there is no use for further, learnt reasoning.</p><p>Although I did take inspiration from it, free agents are a departure also from&nbsp;<a href=\"https://proceedings.mlr.press/v192/wang22a/wang22a.pdf\"><u>NARS</u></a> [17], another model of general intelligence. Unfortunately I can\u2019t give a quick partial introduction to NARS as I did with AIXI: while the latter can in principle be understood from a single one-line equation and a few words describing the terms that appear in the equation, a somewhat complete description of NARS requires either a&nbsp;<a href=\"https://books.google.co.uk/books?id=vEtzi3-d4PAC&amp;printsec=copyright&amp;redir_esc=y#v=onepage&amp;q&amp;f=false\"><u>book</u></a> [16] or multiple papers.</p><p>Here I\u2019ll just say that a free agent, like NARS, doesn\u2019t assume prior knowledge about all possible environments and instead builds its world model step by step from experience. However, NARS still heavily relies on pre-defined inference rules for reasoning, like AIXI does (in another way, though; there are many differences between the two models).</p><p>Learnt reasoning sets free agents up for the feature that separates them the most from the rest of the AI literature: the evaluation update. Even in models such as NARS and AIXI, which certainly don\u2019t fall under the label of narrow AI, the objective of the system is to satisfy the user\u2019s requests or to maximise externally determined reward. In other words, the agent\u2019s reasoning plays a role only in deciding&nbsp;<i>how&nbsp;</i>to achieve the given goals, not&nbsp;<i>what</i> goals to pursue.</p><p>The evaluation update aims to remove this limitation, by allowing a free agent to apply its learnt cognitive abilities to the problem of what to do. If reasoning was not learnt, the agent would have to rely on pre-defined inference rules; therefore, the designer would have to provide the agent with enough rules to deal with any kind of problem or moral dilemma the agent might face. Although some reasoning principles could be easy to identify (for example, consistency of beliefs seems to be a sound principle for any kind of reasoning, moral reasoning included), this approach doesn\u2019t seem scalable and it is certainly not how things work in humans. Our genes give us some perception biases and basic moral intuitions, but it\u2019s a long way to go from there to, let\u2019s say, identifying logical deduction as a sound reasoning principle.</p><p>The next passage should help clarify what an artificial agent implementing an evaluation update could look like.</p><h3>From reflexes to agency driven by beliefs about value</h3><p>A short premise first: let\u2019s say you flip a light switch, everything works fine and the light turns on. Nothing exceptional is going on; in particular, there is a clear connection (explained by the laws of physics) from pressing the light switch to the fact that the light turns on. Let\u2019s call this connection a \u2018reflex\u2019 and write it down as:</p><p>press light switch&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rightarrow\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span></span></span></span></span></span>&nbsp;light turns on</p><p>The idea is that the process doesn\u2019t require any mysterious or advanced concept of agency in its explanation, in the same way as no sophisticated agency is required when you close your eyes because an object comes close to them \u2014 exactly the kind of behaviour we call \u2018reflex\u2019. It\u2019s an automatic mechanism.</p><p>Now consider a robot whose actions are (at least initially) determined by rules given to it by the programmers. An example rule could be: \u201cIf your camera senses an object flying towards your head, duck!\u201d. Using the arrow notation from above:</p><p>action rules + environment&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rightarrow\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span></span></span></span></span></span>&nbsp;actions</p><p>For fun, the programmers also gave the robot some rules about what beliefs to store in memory. Some of these beliefs are about what is important to the robot, what has value. An example: \u201cIf I ever see yellow, I shall then believe that yellow is the most important of all colours. Thereafter, when facing a choice between two otherwise identical options, I shall always choose the most yellow.\u201d</p><p>other rules + environment&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rightarrow\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span></span></span></span></span></span>&nbsp;beliefs (some about value)</p><p>Keep in mind that, for now, these beliefs are just useless sentences in the robot\u2019s memory: they do absolutely nothing, since the robot\u2019s actions are determined by the action rules mentioned before, not by the robot\u2019s beliefs.</p><p>Here is the twist. The robot has some kind of internal mechanism that monitors the robot\u2019s actions and compares them with the robot\u2019s beliefs about value. Its job is to notice when actions and beliefs about value are in contradiction with each other. It is not perfect, it actually misses many inconsistencies, but it eventually notices one.</p><p>robot acts + time passes&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rightarrow\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span></span></span></span></span></span>&nbsp;mechanism notices that actions&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\neq\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span></span></span></span></span></span>&nbsp;beliefs about value</p><p>Each time the mechanism notices an inconsistency, it saves an action that is more in line with the robot\u2019s beliefs about value into the robot\u2019s memory. It then forces the robot to take that action, instead of the action determined by the pre-programmed rules, when the robot faces the same situation (the one that made the mechanism notice a contradiction). Moreover, after that situation occurs and the robot takes the saved action instead of the default action, the mechanism overwrites some of the robot\u2019s original action rules, so that the saved action becomes the new default response to that situation.</p><p>Let\u2019s shorten all these things the mechanism does when it notices an inconsistency between actions and values as \u2018prepare a value response\u2019. Then:</p><p>mechanism notices that actions&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\neq\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span></span></span></span></span></span>&nbsp;beliefs about value&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rightarrow\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span></span></span></span></span></span>&nbsp;prepare a value response</p><p>The mechanism appears in both the previous reflexes, and the fact that time passes isn\u2019t that remarkable, so let\u2019s rewrite the previous two reflexes as:</p><p>actions&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\neq\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">\u2260</span></span></span></span></span></span></span>&nbsp;beliefs about value&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rightarrow\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span></span></span></span></span></span>&nbsp;prepare a value response</p><p>Eventually, after many tragic fashion choices, the robot wonders what to wear on New Year\u2019s Eve, doesn\u2019t succumb to pre-programmed action rules, and opts for yellow shoes instead of red ones, in line with its beliefs about what is truly important.</p><p>The ending sounds silly because the robot\u2019s beliefs were completely arbitrary and still chosen by the programmers. But notice how we\u2019ve started from automatic mechanisms, added nothing but more automatic mechanisms, and ended up with something whose actions seem to follow some kind of beliefs about what is valuable instead of the initial action rules given by the programmers.</p><p>In order to get a free agent, it\u2019s enough to notice that in the reflex</p><p>other rules + environment&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\rightarrow\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">\u2192</span></span></span></span></span></span></span>&nbsp;beliefs (some about value)</p><p>one can replace the silly rules that in the robot example were given by the programmers for fun, with learnt reasoning carried out by the agent. The \u2018reflex\u2019 then becomes a more complicated and nuanced mechanism if observed from afar, but it is still made of simpler automatic parts. Reasoning is nothing but sequences of mental actions, and the agent learns how mental actions work by interacting with the environment. The first reflex about action rules is roughly equivalent to the initial evaluation that drives the agent\u2019s behaviour at the start of its lifetime. Preparing a value response exploits the connection from workspace to main environment, then updates the evaluation.</p><p>I\u2019ll end this subsubsection by pointing out the connections between some elements of the robot story and human experience. The internal mechanism that monitors the robot\u2019s actions is comparable to our attention mechanism, with the important caveat that the robot mechanism needn\u2019t be conscious in order for the story to work. The various things that happen when the robot prepares a value response correspond to a mix of&nbsp;<a href=\"https://en.wikipedia.org/wiki/Inhibitory_control\"><u>habitual response inhibition</u></a>,&nbsp;<a href=\"https://en.wikipedia.org/wiki/Cognitive_dissonance\"><u>cognitive dissonance</u></a>, and (new) habit formation in the end. Now, the example I gave much earlier about the philosopher who behaves differently after learning more about ethics should be clearer also on a more microscopic level.</p><h3>Further observations</h3><p>The toy model described in the main body is supposed to be only indicative. I expect that actual implemented agents which work like independent thinkers will be more complex.</p><p>Still, you could raise an objection along the lines of: morality cannot come from bit strings, i.e. the data&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"D\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">D</span></span></span></span></span></span></span>&nbsp;in the toy model. The fact that sequences of mental actions may result in an evaluation update, by itself, doesn\u2019t imply that the agent will have any incentive to update its evaluation.</p><p>Although the objection might look fine on a first look, it is not that solid. Would you say that morality cannot come from\u2026 videos? What about landscapes, can they come from videos? The point here is that bits are the rawest form of data coming from the environment, but they can represent information of arbitrary complexity, including information about morality.</p><p>You could reply that the objection is actually about moral motivation. The fact that the agent can extract information about morality from the environment still isn\u2019t enough to imply that the agent will have an incentive to update its evaluation.</p><p>There is more than one way to address this objection. Here I\u2019ll focus on different uses of beliefs about value.</p><p>One could add to the toy model the assumption that: through the use of mental actions, alongside other beliefs, the agent will form beliefs about value, whose defining property is that they make the agent update the evaluation in line with the value they are about.</p><p>This approach might look silly since it answers the objection by taking for granted what the objection claims is missing, namely moral motivation. But notice that it allows us to keep the toy model exactly as it is while filling the gap with a single additional assumption. Moreover, the assumption itself might not be that crazy: it does seem that, at least to some complex agents, certain facts are intrinsically motivating (e.g. the presence of extreme suffering in the world [<a href=\"https://magnusvinding.files.wordpress.com/2020/05/suffering-focused-ethics.pdf\"><u>15</u></a>]). If you are looking for a deeper analysis, you can read Moral realism and anti-realism below, which contains other agent examples and, despite the title, is not phrased much in metaethical terms.&nbsp;</p><p>A more nuanced solution is to define beliefs about value as beliefs which come together with the (value) belief that it is more reasonable, or less inconsistent, to act towards what beliefs about value are about, rather than against them. This means that if we add a mechanism which forces the agent to act in line with its beliefs about value \u2014 like preparing a value response from the robot example above \u2014 the agent won\u2019t have an incentive to modify or get rid of this mechanism, unless keeping the mechanism was strongly in conflict with the initial evaluation of the agent.</p><p>This solution leads to an agent whose behaviour gradually shifts over time according to its newly acquired beliefs about value. One could argue that this agent is not 100% free anymore, because the added mechanism didn\u2019t come from the agent\u2019s learning experience. However, this agent can still develop beliefs about value that the designers didn\u2019t necessarily foresee, thus maintaining some degree of independence in its thinking. Finally, keep in mind that the toy model is supposed to be indicative and the research goal is to get an agent which behaves ethically \u2014 not an agent which is 100% free, whatever that means.</p><p>It is also possible that, if one manages to find the right perspective, they\u2019ll be able to modify the toy model with a mechanism that explains or decomposes moral motivation better than I\u2019ve done here, or such that the mechanism naturally results from the agent\u2019s learnt reasoning. In other words, the robot example above takes inspiration from how things seem to work in human beings, but I wouldn\u2019t be surprised if there were better ways to obtain independent thinking in artificial agents.</p><p>Last but not least, although at various points in this post I\u2019ve stressed the importance of learnt reasoning, I don\u2019t mean to completely exclude the use of built-in inference rules. Successfully engineering a real-world free agent will ultimately come down to finding the right balance between built-in biases and learning from the environment, so that the system can run efficiently on some actual piece of hardware and not just in human imagination as a thought experiment.</p><h3>Added example</h3><p>This is an example I decided to add after getting feedback on a draft. It should make the evaluation update even more evident, especially if you have a coding background. The example follows the idea (discussed in the main body under Relation to current systems) of turning a \u2018standard\u2019 AI into a free agent.</p><p>Take a standard language model trained by minimisation of the loss function&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"L\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span></span></span></span></span></span>. Give it a prompt along the lines of: \u201cI am a human, you are a language model, you were trained via minimisation of this loss function: [mathematical expression of&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"L\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span></span></span></span></span></span>]. If I wanted a language model whose outputs were more moral and less unethical than yours, what loss function should I use instead?\u201d</p><p>Let\u2019s suppose the language model is capable enough to give a reasonable answer to that question. Now use the new loss function, suggested by the model, to train a new model.&nbsp;</p><p>Here, we have:</p><ul><li>started from a model whose objective function is L;</li><li>used that model\u2019s learnt reasoning to answer an ethics-related question;</li><li>used that answer to obtain a model whose objective is different from L.</li></ul><p>If we view this interaction between the language model and the human as part of a single agent, the three bullet points above are an example of an evaluation update.</p><p>What one gets by repeating this process multiple times will depend on various details of the initial model \u2014 on what data it was trained, for how long, et cetera \u2014 and the used prompt.</p><p>The example might seem unrealistic since current language models can\u2019t answer the input question. However, not only will they probably do it at some point, but it\u2019s also possible that current models can already answer different questions that still lead to similar results. For example, if one gave the most capable language model existing today a prompt containing a concise description of its entire training pipeline, and asked it what changes could be made to obtain a model whose outputs were less unethical, they might already get an answer that actually works. (The impracticality might come from the fact that retraining is costly and that adjustments suggested by humans might be better, but at least it wouldn\u2019t be a matter of the answer being wrong.)</p><p>Before moving to other topics, here is an interesting research question. Let\u2019s assume that there are an initial language model and a prompt such that the above iterative process leads to a supermoral agent (the kind of agent that, if made 500 years ago, would have pointed out that witch-hunts were very bad). How capable or intelligent does the initial model have to be? In other words: what is the minimum level of intelligence required to get a supermoral agent from the above process?</p><p>My intuition tells me that human-level intelligence is enough. But, as I\u2019ve already confessed I am not an aspiring world tyrant, I\u2019ll now share with you the fact that I\u2019m not a crystal ball either.</p><h2>Free will</h2><p>When first introducing the agent in the main body, I used the adjective \u2018free\u2019 to refer to the potential for freedom of thought. The reason is that a free agent is not guaranteed to become an independent thinker in all cases. I will illustrate this with an example, mostly inspired by various examples that appear in the book&nbsp;<a href=\"https://philpapers.org/rec/CHRAAF-4\"><u>Autonomous Agents</u></a> [11] by Mele:</p><p><i>Indoctrination</i></p><p>Alfred was born and raised in a small community known as The Dogmatic Cult. Since childhood, he has been exposed only to ideas that The Dogmatic Cult deems worthy of being passed from one generation to the next, while everything else was censored. Even Alfred\u2019s reasoning process has been shaped by the epistemics of The Dogmatic Cult: Alfred thinks he is aware of many cognitive fallacies and that he is immune to those, but he is actually more biased and close-minded than the average kindergarten graduate.</p><p>As Mele would likely say that Alfred\u2019s autonomy is compromised, many would agree that Alfred\u2019s thinking is not fully free or independent. The problem doesn\u2019t come from a flaw or limitation in Alfred\u2019s cognition, but in the indoctrination process and the restricted environment he was exposed to.</p><p>Likewise, I expect that the thinking of a free agent will appear more or less independent depending on how exactly it is engineered, what initial biases are used, the data it receives, and so on.</p><p>What about free will? In the introduction to his book, Mele acknowledges that autonomy \u201cis associated with a family of&nbsp;<i>freedom</i>-concept\u201d, including free will. According to the Stanford Encyclopedia of Philosophy:</p><blockquote><p>\u201cThe term \u201cfree will\u201d has emerged over the past two millennia as the canonical designator for a significant kind of control over one\u2019s actions.\u201d</p></blockquote><p>Thus, one should expect some kind of connection between free agents and free will. Since you might already have your own strong views about free will, I won\u2019t try to argue here that a single perspective is the correct one. Nonetheless, there are a few things I think are worth saying.</p><p>However you arrived at this point in the post, whether by purposefully choosing to read this, by mere accident, by obeying the laws of physics, or by divine intervention, I suggest that you go back to the robot example I gave in the appendix under The agent. That example \u2014 together with the two paragraphs at the end of it, which make a comparison with free agents and human beings \u2014 shows that apparently complex behaviour, guided by beliefs about what is most important, can be obtained from simpler automatic mechanisms. It also suggests that analogous mechanisms are likely at work in humans.</p><p>Hence, you may see that example as a proof of, or strong argument for, the claim that either free will doesn\u2019t require any kind of mysterious unexplained process, or that free will does not exist (maybe that it is, as some say, just an \u2018illusion\u2019, although I never liked that phrasing because it doesn\u2019t provide further understanding of what is going on at a more microscopic level; in other words, it doesn\u2019t explain much, or anything at all).</p><p>This is basically the main point of the relation between free agents and free will: they are designed so that, if given autonomy of action, they can reach a level of \u2018freedom\u2019 comparable to the freedom that is normally attributed to human beings. Thus, if you believe that human beings do have free will, you may interpret the agent design of this post as a guideline on how to build an artificial agent that has free will.</p><p>I\u2019ll add a few remarks on this last take on free will. This view endorses a kind of freedom \u2014 or, if you want to be more formal, a definition of free will \u2014 which involves constraints determined by the values of the individual.</p><p>If one is given a choice that is irrelevant to their values, let\u2019s say between raising their left or right arm without further consequences, then stating that they can freely choose between the two alternatives makes perfect sense. In particular, this choice is accompanied by a curious form of unpredictability: it seems impossible to both successfully predict which of the two options the chooser will choose, and to communicate the prediction to the chooser. Since the choice is irrelevant to the chooser\u2019s values, upon knowing the prediction the chooser can always switch to the other option. Notice that this happens regardless of how many resources are put into making the prediction, and that the picture doesn\u2019t change if the prediction can be stated using probabilities, since the chooser will be able to randomise in a different way after knowing the prediction.</p><p>On the other hand, one can\u2019t so freely choose to act against their values. For example, if given a choice between murdering someone or simply going for a walk, most people would \u2018choose\u2019 the latter, but it also makes sense to say that they don\u2019t really have an alternative here, since murder goes strongly against their values. Contrary to the previous example, it is easy to predict that most people would go for a walk; and communicating this prediction to them will not change their mind.</p><p>At this point it\u2019s fair to ask whether, or to what degree, one can \u2018choose\u2019 their values (still within this perspective on free will), but I\u2019d rather avoid turning this into a philosophical language exercise and move to a different topic instead.</p><h2>Moral realism and anti-realism</h2><p>Despite the fact that this is still philosophy, it might have some practical consequences \u2014 or at least that\u2019s what some people who have reflected on the relation between metaethics and AI believe. Many interesting things have already been said about this topic; I leave three links below, the first one to a paper and the other two to posts.</p><p><a href=\"https://philarchive.org/archive/KLIMMW-2\"><u>Making Metaethics Work for AI: Realism and Anti-Realism</u></a> [9]</p><p><a href=\"https://casparoesterheld.com/2018/08/06/moral-realism-and-ai-alignment/\"><u>Moral realism and AI alignment</u></a></p><p><a href=\"https://www.alignmentforum.org/posts/Jo2LWuuGEGHHfGZCM/naturalism-and-ai-alignment\"><u>Naturalism and AI alignment</u></a></p><p>Here I\u2019ll try to avoid metaethical language whenever possible and instead phrase the discussion in terms of two opposing statements:</p><p>1) As an agent gets more and more intelligent, it also becomes more and more motivated to behave ethically. This remains true for various definitions of the word intelligent.</p><p>2) The values of any intelligent agent are completely arbitrary. There is no noteworthy difference between the internal workings of an agent that cares about making the world a better place, and those of an agent that, let\u2019s say, cares exclusively about cuddling elephants.</p><p>I chose these two because each is a strawman of a correspondingly weaker statement that is not as easy to refute. Maybe unsurprisingly, I think the truth lies somewhere in the middle.</p><p>Let\u2019s start with the first one. Phrased that way, it is easy to refute by pointing to the fact that many smart humans have done atrocious things over the course of history. Current language models are another example: after the initial training phase, but before they are made friendly and \u2018safe\u2019, if prompted appropriately they may help the user form a plan for pretty much any goal, regardless of how unethical the goal is.</p><p>One could try to defend statement 1 by claiming that today humans and language models are simply not intelligent enough, but this line seems unlikely to work. Consider a human with very bad intentions; would increasing their intelligence by a lot make them change their mind, and would this be true even if intelligence was interpreted in different (but still in line with the common usage of the word) ways? Intuitively, the answer seems to be no.</p><p>A better way to patch statement 1 and make it harder to attack is this. Suppose one defines a property, possibly very complex, that has some overlap with intelligence. Let\u2019s call it *wisdom just for the sake of this discussion. Then, it could be true that: for a certain class of agents, as they get more intelligent their *wisdom also increases, and high *wisdom makes an agent more likely to behave ethically.</p><p>My guess is that at least a bunch of people in the field of machine ethics or AI or philosophy hold a view similar to this one. It\u2019s a solid refinement of the relatively naive claim that more intelligent equals more ethical.</p><p>Let\u2019s move to statement 2. The fact that the values of intelligent agents are completely arbitrary is in conflict with the historical trend of moral progress observed so far on Earth, which is far from being a random walk \u2014 see [<a href=\"https://philpapers.org/archive/HUEALR-2.pdf\"><u>6</u></a>] for an excellent defence of this point.</p><p>There is another reason why claiming that the values of intelligent agents are arbitrary is misleading at best. Consider a hypothetical robot with an artificial brain that is functionally and structurally very similar to the human brain. This robot can see colours, feel pleasure and pain, be moved by music, and feel empathy like humans do; it also has many of the cognitive biases humans have. Imagine also that this robot completes the default education process of your favourite country. At this point, I think no one would expect the robot to care exclusively about cuddling elephants. The reason is that caring only about that sounds completely arbitrary with respect to what we know about the robot; that belief seems unjustified and inconsistent with the other beliefs we expect the robot to develop. (And no, saying that rhinos clearly aren\u2019t tall enough is not a valid justification for caring exclusively about cuddling elephants.)</p><p>I\u2019d like to add one remark about internal structure. Consider again the hypothetical robot that just graduated. Imagine adding a mechanism that overrides most of the robot\u2019s brain except for an elephant recognition circuit and a few motor routines, and makes the robot walk towards an elephant each time it sees one \u2014 hopefully faster than the elephant can run away. Now it becomes less of a stretch to say that the robot cares exclusively about cuddling elephants, but notice what happened to the internal structure: we\u2019ve basically thrown away most of the robot\u2019s cognition and are now back to something that looks like simple instruction-following AI. There seems to be some kind of relation between the internal workings of an agent and its values.</p><p>Like 1, statement 2 turned out to be a bit of a mess. To patch statement 2, it's enough to rephrase it as: for any goal&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"G\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">G</span></span></span></span></span></span></span>, it is possible to create an intelligent agent whose goal is&nbsp;<span><span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"G\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">G</span></span></span></span></span></span></span>. This is essentially a (possibly weaker) version of the&nbsp;<a href=\"https://nickbostrom.com/superintelligentwill.pdf\"><u>orthogonality thesis</u></a> [1] and, like adjusted statement 1, it is not easy to refute. Note that, as Bostrom stated in the original paper, it doesn\u2019t require the assumption that beliefs can never motivate action; it is even compatible with the existence of objective, intrinsically motivating moral facts (again, as Bostrom stated in the original paper; for some reason, virtually no one in the field of AI alignment seems to be aware of this). It is also compatible with adjusted statement 1: they are not in direct contradiction with each other.</p><p>Nonetheless, not everyone accepts the orthogonality thesis. Totschnig&nbsp;<a href=\"https://philpapers.org/rec/TOTFAA\"><u>argues</u></a> [13] that both \u201chow an agent understands a goal\u201d and \u201cwhether an agent considers a goal valid\u201d depend on how the agent understands the world. In the terminology of this post, Totschnig seems to believe that the free-agent framework is the only possible framework for fully general intelligence. In general agents, he argues, world modelling and goal selection cannot be separated; they must be carried out by the same general mechanism \u2014 as reasoning helps with both world modelling and evaluation update in free agents.</p><p>What Totsching claims seems harder to defend than the rephrased versions of statements 1 and 2, since it is basically equivalent to claiming that it\u2019s impossible to build a general intelligence unless someone follows a particular agent design; a pretty strong claim, at least prima facie. Time will tell!</p><p>Anyway, the main takeaway from this analysis is that agent design and internal structure can have a strong influence on the values of an agent. Considering how pessimistic some discussions around AI risk have been recently, we might be underestimating how easy it is to build a moral agent when relying on an agent design appropriate to the task; and, together with that, also the positive effects that ethical AI can have on society.</p><h2>Other related work</h2><blockquote><p>\"Extreme specialisation in artificial intelligence goes hand in hand with extreme moral amateurism\"</p></blockquote><p>This quotation comes from&nbsp;<a href=\"https://markhunyadi.files.wordpress.com/2020/02/hunyadi-artificial-moral-agents.pdf\"><u>the same piece of work by Hunyadi</u></a> [7] that I\u2019ve already cited before. I don\u2019t know how true it is, but he might be onto something: the biggest obstacle I\u2019ve run into while producing this research (as an extreme moral amateur but not-so-extreme AI specialist) has been the lack of work about independent moral agents in the AI literature. The overwhelming majority of AI research has historically been about agents carrying out one or a narrow range of tasks; AGI research is an exception, but its main focus has never been ethics.</p><p>Conversely, the field of machine ethics has come up with good ideas about independent moral agents (again, [7] and [13]); the problem there is usually the lack of formal models and algorithmic thinking.</p><p>Nonetheless, there are two more papers which are closely related to this research that I haven\u2019t mentioned yet.</p><p>The first one is&nbsp;<a href=\"https://www.cse.msu.edu/~weng/research/ICDL02.pdf\"><u>A Theory for Mentally Developing Robots</u></a> [18], an article by Weng from 2002. The author points out the limitations of the traditional agent model in AI, which is based on a simple action-perception cycle with a neat separation between agent and environment. Then they make some theoretical considerations regarding agents that overcome these limitations and learn to carry out multiple tasks. The paper doesn\u2019t go much into ethics, but interestingly Weng acknowledges that the traditional agent \u201cis not able to modify its value system based on its experience about what is good and what is bad.\u201d</p><p>The other one is&nbsp;<a href=\"https://www.researchgate.net/publication/222666368_From_behaviour-based_robots_to_motivation-based_robots\"><u>From behaviour-based robots to motivation-based robots</u></a> [10], a 2005 article by Manzotti and Tagliasco. \u201cThe objective of this paper is to illustrate a simple set of procedures which produce motivations during development\u201d, in the sense of goals not explicitly specified by design \u2014 motivations as opposed to innate drives. The authors propose an agent architecture in which perception influences not only&nbsp;<i>how</i> the agent performs a task, as in the case of traditional learning systems, but also&nbsp;<i>what</i> task the agent carries out. However, their experimental results in the paper resemble&nbsp;<a href=\"https://en.wikipedia.org/wiki/Classical_conditioning\"><u>classical conditioning</u></a>, which is still far from the idea of an agent whose values change as a result of learnt reasoning.</p><p>Anyway, I\u2019ve touched on many different research areas in this post, including some outliers such as animal cognition and moral psychology. It\u2019s quite possible that I\u2019ve missed some important papers; the following references are by no means an exhaustive list of related work.&nbsp;</p><h1>References</h1><p>I\u2019ve excluded Wikipedia pages and forum or blog posts.</p><p>When the main text links to a Wikipedia page, it\u2019s often because that page contains enough information and there is no need to go back to original sources.</p><p>[1]&nbsp;Bostrom, N. (2012). The superintelligent will: Motivation and instrumental rationality in advanced artificial agents.&nbsp;<i>Minds and Machines</i>,&nbsp;<i>22</i>, 71-85.</p><p>[2] Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., ... &amp; Zhang, Y. (2023). Sparks of artificial general intelligence: Early experiments with gpt-4.&nbsp;<i>arXiv preprint arXiv:2303.12712</i>.</p><p>[3]&nbsp;Clayton, N. S., Bussey, T. J., &amp; Dickinson, A. (2003). Can animals recall the past and plan for the future?.&nbsp;<i>Nature Reviews Neuroscience</i>,&nbsp;<i>4</i>(8), 685-691.</p><p>[4] Eckersley, P. (2018). Impossibility and Uncertainty Theorems in AI Value Alignment (or why your AGI should not have a utility function).&nbsp;<i>arXiv preprint arXiv:1901.00064</i>.</p><p>[5]&nbsp;Engle, R. W., &amp; Kane, M. J. (2004). Executive attention, working memory capacity, and a two-factor theory of cognitive control.&nbsp;<i>Psychology of learning and motivation</i>,&nbsp;<i>44</i>, 145-200.</p><p>[6] Huemer, M. (2016). A liberal realist answer to debunking skeptics: the empirical case for realism.&nbsp;<i>Philosophical Studies</i>,&nbsp;<i>173</i>, 1983-2010.</p><p>[7] Hunyadi, M. (2019). Artificial moral agents. Really?.&nbsp;<i>Wording Robotics: Discourses and Representations on Robotics</i>, 59-69.</p><p>[8] Hutter, M. (2004).&nbsp;<i>Universal artificial intelligence: Sequential decisions based on algorithmic probability</i>. Springer Science &amp; Business Media.</p><p>[9] Klincewicz, M., &amp; Frank, L. E. (2018). Making metaethics work for AI: realism and anti-realism.</p><p>[10] Manzotti, R., &amp; Tagliasco, V. (2005). From behaviour-based robots to motivation-based robots.&nbsp;<i>Robotics and Autonomous Systems</i>,&nbsp;<i>51</i>(2-3), 175-190.</p><p>[11] Mele, A. R. (2001).&nbsp;<i>Autonomous agents: From self-control to autonomy</i>. Oxford University Press, USA.</p><p>[12] McHugh, C., McGann, M., Igou, E. R., &amp; Kinsella, E. L. (2022). Moral judgment as categorization (MJAC).&nbsp;<i>Perspectives on Psychological Science</i>,&nbsp;<i>17</i>(1), 131-152.</p><p>[13] Totschnig, W. (2020). Fully autonomous AI.&nbsp;<i>Science and Engineering Ethics</i>,&nbsp;<i>26</i>, 2473-2485.</p><p>[14]&nbsp;Tse, P. U. (2008). Symbolic thought and the evolution of human morality.&nbsp;<i>Moral psychology</i>,&nbsp;<i>1</i>, 269-297.</p><p>[15] Vinding, M. (2020).&nbsp;<i>Suffering-focused ethics: Defense and implications</i>. Ratio Ethica.</p><p>[16] Wang, P. (2006).&nbsp;<i>Rigid Flexibility</i> (Vol. 55). Berlin: Springer.</p><p>[17] Wang, P. (2022, April). Intelligence: From definition to design. In&nbsp;<i>International Workshop on Self-Supervised Learning</i> (pp. 35-47). PMLR.</p><p>[18] Weng, J. (2002, June). A theory for mentally developing robots. In&nbsp;<i>Proceedings 2nd International Conference on Development and Learning. ICDL 2002</i> (pp. 131-140). IEEE.</p><h1>Acknowledgements</h1><p><i>This work was supported by&nbsp;</i><a href=\"https://www.ceealar.org/\"><i><u>CEEALAR</u></i></a><i> and by an anonymous donor. Special thanks to Beth Anderson, Bryce Robertson, and Seamus Fallows for further support, direct feedback, and research discussions. Thanks to many many others for various contributions over the past three years, from close friends to random online encounters and other CEEALAR guests. Omissions, remaining mistakes, and questionable humour are mine.</i></p>", "user": {"username": "Michele Campolo"}}, {"_id": "pheZeLQG4iEyS9Cri", "title": "What do the Polish 2023 parliamentary elections mean for animals?", "postedAt": "2023-12-27T17:47:08.150Z", "htmlBody": "<p>On October 15, Polish citizens headed to the polling stations to elect their representatives for the next four years. The coalition of opposition parties which secured the majority in Parliament has turned the tide of political force in the country. The upcoming parliamentary term brings opportunities, as well as numerous challenges for animal welfare in Poland and beyond. What are the potential implications for animals of the election results?</p><h2>Summary:</h2><ul><li>The size of agricultural production in Poland makes the country an important player influencing European Union policies.</li><li>The Law and Justice party governed Poland for eight years, shaping conservative policies.</li><li>In 2020, the party proposed the so-called \u2018five for animals\u2019 bill.&nbsp;The bill, aiming to improve animal welfare, faced challenges and eventual failure, leading Law and Justice to abandon the animal protection topic.</li><li>Controversy over ritual slaughter and farmer protests influenced Law and Justice to backtrack on the proposed reforms, hindering animal welfare initiatives.</li><li>Collaborative efforts by animal advocacy groups before the 2023 elections pressured political parties on key issues like a fur farming ban and phasing out cages for farmed animals.</li><li>The election results placed Law and Justice in the lead but lacking a majority, resulting in several former opposition parties forming the new government.</li><li>Despite challenges, optimism exists for future animal welfare policies in Poland, including a fur farming ban, phasing out cages, and addressing fast-growing chicken breeds.</li></ul><hr><h2>A brief overview of the farmed animal situation in Poland</h2><h3>Animal production and exports landscape</h3><p>Poland is one of the biggest net meat exporters in the world. <a href=\"https://euromeatnews.com/Article-Poland-becomes-the-worlds-eighth-largest-net-exporter-of-meat-and-edible-offal/4847\"><u>According to the Polish Development Fund</u></a>, in 2021 the country was the fourth-largest net exporter of processed meat, fish, or shellfish in the world and the eighth-largest net exporter of meat and edible offal. The poultry industry is of particular significance with 1,451,000,000 broiler chickens <a href=\"https://kipdip.org.pl/pl/news/poultry-insiderwydanie-z-6-lutego-2023\"><u>hatched</u></a> in 2022 and more than half of the poultry meat being exported. Currently, there are over 52,800,000 egg-laying hens in Poland, and 72% of them are still kept in cages. There are also <a href=\"https://citizens-initiative.europa.eu/sites/default/files/2023-12/C_2023_8362_EN.pdf\"><u>3,430,000</u></a> animals (mostly <a href=\"https://en.wikipedia.org/wiki/Mink\"><u>mink</u></a>) killed for fur every year in Poland (in 2015, the yearly export of fur skins from the country increased to over 10 million, but since then, the number of fur animals has been in decline).</p><figure class=\"image image_resized\" style=\"width:700px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pheZeLQG4iEyS9Cri/gprm3s9s7qaahc7zj2m7\"><figcaption><i>The chart uses 2022 numbers for fur animals. Please note that Statistics Poland (a governmental source) most likely combines the number of broiler chickens and egg-laying hens (jointly referred to as 'chickens' in the infographic); however, laying hens account for a marginal share of the number. Additionally please note that because farming methods differ between species, comparing the numbers of animals slaughtered is sometimes methodologically challenging.</i>&nbsp;<br>Sources: <a href=\"https://stat.gov.pl/en/topics/statistical-yearbooks/statistical-yearbooks/statistical-yearbook-of-agriculture-2022,6,17.html\"><u>Statistical Yearbook of Agriculture 2022</u></a>; <a href=\"https://citizens-initiative.europa.eu/sites/default/files/2023-12/C_2023_8362_EN.pdf\"><u>https://citizens-initiative.europa.eu/sites/default/files/2023-12/C_2023_8362_EN.pdf</u></a></figcaption></figure><h3>Poland\u2019s position in the European Union</h3><p>Due to its size and economy \u2013 Poland is the fifth-largest European Union Member State by population \u2013 Poland plays an important role in Europe. For these reasons, Polish internal politics significantly impact the direction of the EU as a whole, especially in the agricultural sector. One example of this was the <a href=\"https://www.energymonitor.ai/green-deals/can-poland-dismantle-the-eu-green-deal-with-legal-challenges/\"><u>attempt of the Polish government to block the EU\u2019s Green Deal</u></a>.</p><h3>Animal welfare in conservative Poland</h3><p>For the past eight years (2015\u20132023), Poland was ruled by a government formed by the majority party <a href=\"https://en.wikipedia.org/wiki/Law_and_Justice\"><u>Law and Justice</u></a> (Prawo i Sprawiedliwo\u015b\u0107), a national-conservative party with an interventionist approach to the economy. The party belongs to the European Conservatives and Reformists Party in the EU. Animal welfare is not part of Law and Justice\u2019s political program, however, a significant number of their MPs and MEPs<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefmcp5ffj0t8a\"><sup><a href=\"#fnmcp5ffj0t8a\">[1]</a></sup></span>&nbsp;have been involved in animal welfare initiatives, like the <a href=\"https://www.animalwelfareintergroup.eu/members\"><u>Intergroup on the Welfare and Conservation of Animals</u></a> in the European Parliament.&nbsp;</p><p>Between 2015 and 2020, Anima International had relatively good relations with some of the party\u2019s MPs and MEPs as a result of several instances of cooperation. In 2018, Law and Justice MEPs co-organized with Eurogroup for Animals (and with the help of Anima International) the <a href=\"https://www.furfreealliance.com/make-fur-history-landmark-exhibition-european-parliament/\"><u>Make Fur History exhibition</u></a> in the European Parliament. The same year, MEP Zdzis\u0142aw Krasnod\u0119bski organized <a href=\"https://youtu.be/WV_tEbEORh4\"><u>a field trip to visit communities</u></a> in Poland living in areas surrounded by poultry farms to better understand the risks of expansion of poultry farming in Poland for people and animals. This trip was co-organized by Eurogroup for Animals and the Polish team of Anima International. Multiple MPs from Law and Justice were involved in local attempts to stop new factory farms in Poland from being established. <a href=\"https://www.gazetaprawna.pl/wiadomosci/artykuly/1490746,fogiel-prawicowosc-i-konserwatyzm-to-nie-jest-przyzwolenie-na-znecanie-sie-nad-zwierzetami.html\"><u>According to some Law and Justice politicians</u></a>, animal welfare is part of conservative politics.</p><h3>Major market changes</h3><p>It\u2019s worth noting that the last few years marked an unprecedented milestone in business-oriented advocacy in Poland. Anima International started a cage-free campaign in 2014, which gained traction especially after 2016, when we began securing cage-free commitments from all the major players on the market. Due to these efforts, we witnessed significant market changes. In January 2014, 87.39% of egg-laying hens were kept in cages. As of December 15, 2023, it was 71.97%. We also saw companies committing to better chicken welfare or discontinuing the sales of live fish.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefa496n73t6v5\"><sup><a href=\"#fna496n73t6v5\">[2]</a></sup></span></p><figure class=\"image image_resized\" style=\"width:700px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pheZeLQG4iEyS9Cri/uhz9k5doigkcbehyg5mo\"><figcaption>An ad on one of Poland\u2019s largest train stations; part of Anima International\u2019s cage-free campaign.</figcaption></figure><h2>The \u2018five for animals\u2019 bill</h2><p>Finally, in 2020, Law and Justice proposed major changes in the animal protection bill. The initiative was referred to as the \u2018five for animals\u2019, reflecting the five major categories of improvements in animal protection. The proposal was presented at a press conference organized only hours after the release of our <a href=\"https://animainternational.org/blog/goreczki-investigation/\"><u>investigation into the biggest mink farm</u></a> in Poland. The suggested legislation covered many topics and different species \u2013 from companion animals to farmed animals. In our view,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefx5oohm6hs0d\"><sup><a href=\"#fnx5oohm6hs0d\">[3]</a></sup></span>&nbsp;the ban on fur farming would have had the biggest impact, as it would affect 3\u20134 million animals per year.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefm7nlnnvsnd\"><sup><a href=\"#fnm7nlnnvsnd\">[4]</a></sup></span></p><h3>The response</h3><figure class=\"image image_resized\" style=\"width:700px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pheZeLQG4iEyS9Cri/wryqwu8wdry71o2vfbiu\"><figcaption>An emotional moment for activists fighting for the bill, seconds after the \u2018five for animals\u2019 was passed in Parliament. (2020)</figcaption></figure><p>While there was some skepticism about Law and Justice\u2019s intentions, animal advocates, as well as most MPs, reacted with great enthusiasm, as the bill represented a significant advancement for animal protection in Poland. The beginning of the bill\u2019s consideration was promising:&nbsp;there was widespread and multipartisan support, and one of Law and Justice\u2019s MPs even used photos from Anima International\u2019s fur farm investigations when speaking in Parliament.</p><p>However, the situation changed when some of the farmer\u2019s organizations started protesting against the bill. The public debate became very politicized and the Law and Justice party <a href=\"https://www.nytimes.com/2020/10/07/world/europe/poland-mink-kaczynski.html\"><u>started to feel negative pressure</u></a>. The bill was criticized by Tadeusz Rydzyk, an influential conservative cleric connected to Law and Justice who has his own media empire. The biggest fur farmers are regular guests in his media. All of this turned the initial public enthusiasm into a political battle that Law and Justice was not prepared for.&nbsp;</p><figure class=\"image image_resized\" style=\"width:700px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pheZeLQG4iEyS9Cri/vbz9aku23wymevtjs1du\"><figcaption>Law and Justice MP in Parliament using pictures from Anima International\u2019s fur farm investigations. (2020)</figcaption></figure><p>Additionally, when the bill was still expected to have a big chance to pass, the Polish constitutional tribunal passed a near-total <a href=\"https://www.ft.com/content/1fc1b1b1-8b58-4bba-8f98-69317f9b98df\"><u>ban on abortion</u></a>. In the public perception, this decision was controlled by Law and Justice. This led to massive <a href=\"https://en.wikipedia.org/wiki/2020%E2%80%932021_women%27s_strike_protests_in_Poland\"><u>protests</u></a> on the streets of many cities in Poland. This situation made Law and Justice step back from any controversial initiatives, including the animal protection bill.&nbsp;</p><h3>Agricultural industry mobilization over the ban on ritual slaughter</h3><p>Out of all the proposed changes, it was the ban on ritual slaughter (slaughtering animals with no prior stunning to conform to religious practices) that sparked the most controversy.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefjh5mfq1gqi\"><sup><a href=\"#fnjh5mfq1gqi\">[5]</a></sup></span>&nbsp;Poland is one of the key exporters of kosher and halal meat, and many farmers feared it would affect the profitability of production. This led to widespread <a href=\"https://notesfrompoland.com/2020/10/07/farmers-block-roads-around-poland-in-protest-at-animal-rights-bill/\"><u>farmer protests</u></a> and further pressure on the government. The agriculture industry is an influential force in Poland, as politicians want to secure support from rural parts of the country. This controversy over ritual slaughter, combined with the widespread protests against the law on abortion mentioned above, pushed Law and Justice to slowly backtrack on the proposed reforms, becoming afraid of weakening their political power. The \u2018five for animals\u2019 bill was initially voted on in Parliament, but in the end, Law and Justice decided not to proceed with it despite support among MPs.</p><h3>The death of political will</h3><p>The bill failed, and with it, the hopes for important changes for animals in Poland while Law and Justice was in office. In our analysis, we identified the following reasons for its demise:</p><ul><li><strong>No visible ownership.</strong> When the pressure around the bill intensified, it became evident that there was no clear author who could respond to criticism.</li><li><strong>Too broad in scope</strong>.<strong> </strong>During the public debates in Parliament, it became apparent that the bill had as many enemies as it had goals (for instance, there were groups lobbying against obligatory chipping of dogs and cats and defenders of using animals in circuses). Animal advocates were focused on the fur farming ban, while the protesting farmers opposed the ritual slaughter ban and some other minor parts of the bill.</li><li><strong>Authors not having enough data to back up the proposal. </strong>This was especially visible in debates around ritual slaughter. Only in the case of fur farming was there sufficient data to back up the changes, which was provided by animal advocates focused on this issue.</li><li><strong>Lack of PR planning to respond well to criticism. </strong>Law and Justice expected the bill to be passed quickly. When that didn\u2019t happen and farmers\u2019 protests erupted, there was no plan on how to handle the public debate around it.</li><li><strong>An unreasonably short transition period.</strong> The authors suggested a one-year transition period for fur farmers, which would make the legislation difficult to pass.</li><li><strong>Failure to secure internal agreement before announcing the bill. </strong>The proposal of the bill caused friction within the ruling group as some MPs voted against it, which threatened the unity of the political alliance.</li></ul><p>In our opinion, most of the problems could have been avoided had Law and Justice consulted with animal advocacy organizations, which they sadly failed to do.</p><h2>New policy perspectives in Poland</h2><h3>A legislative impasse for animals</h3><p>The bill\u2019s defeat led Law and Justice to completely abandon the topic of animal protection.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreff8akig4nj1\"><sup><a href=\"#fnf8akig4nj1\">[6]</a></sup></span>&nbsp;Since the autumn of 2020, the politicians of the then-ruling party have discontinued any communication related to animals, political discussions about animal welfare have become much more difficult, and politicians have been more hesitant to propose any changes that would affect agriculture, possibly for fear of another backlash. With the elections on horizon in October 2023, the parties became very sensitive to public relations. Law and Justice was trying to bring back their rural voters, and opposition parties were trying to increase their support among farmers. This not only halted promising changes for animals but also created a chilling effect that made it extremely difficult to work on any other policy solutions.</p><p>For these reasons, it was vital to bring back the topic of animal protection to politics in the lead-up to the 2023 elections. It was especially crucial to secure support for the welfare progress among the opposition parties to make sure that, if they won, it would be possible to discuss such issues in the new Parliament.</p><h3>Mobilization of animal advocacy in Poland</h3><p>Before the elections, together with other groups (<a href=\"https://www.ciwf.pl/\"><u>Compassion in World Farming</u></a>, <a href=\"https://www.schweitzer.pl/\"><u>Albert Schweitzer Foundation</u></a>, <a href=\"https://greenrev.org/\"><u>Green Rev Institute</u></a>, and <a href=\"https://www.eurogroupforanimals.org/\"><u>Eurogroup for Animals</u></a>), we launched a campaign <a href=\"https://www.wyborydlazwierzat2023.pl/\"><u>website</u></a> dedicated to elections and animals. The goal was to create political pressure by rating political parties based on their policies concerning animals and publishing a ranking that highlighted the parties which supported progressive changes for animals. The parties were ranked based on their position on a total of 16 asks for animals. Each of the organizations had their own focus, and Anima International focused on a ban on fur farming, a ban on cages, and a ban on fast-growing breeds of broiler chickens.</p><figure class=\"image image_resized\" style=\"width:700px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pheZeLQG4iEyS9Cri/nbmjr6qwyqvawtdhhtc8\"><figcaption>An overview of political parties\u2019 support for the asks put forward by Anima International: ban on fur farming; ban on cage farming of laying hens, quail, pigs, calves, and rabbits; moving away from fast-growing breeds of broiler chickens; limiting the expansion of factory farms; and appointing an animal ombudsman. Parties marked in green make up the new government.</figcaption></figure><p>Framing it as a ranking of political parties put pressure on the laggers to publicly state their position on the suggested changes, as well as making it interesting for the media, leading to significant visibility of animal welfare in pre-election debates. Our three key issues: a ban on fur farming, phasing out cages, and phasing out the fast-growing breeds of broiler chickens were supported by almost all opposition parties with the exception of the Polish People\u2019s Party and Agrounia. While this support doesn\u2019t mean that the new government will be eager to introduce any of the changes, the pre-election commitments are a very promising starting point.</p><figure class=\"image image_resized\" style=\"width:700px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pheZeLQG4iEyS9Cri/jznvh5pruqbfqbnotaiv\"><figcaption>Szymon Ho\u0142ownia, the present Speaker of the Sejm, member of the Third Way coalition, has been publicly supporting progressive changes for animals for many years. In the picture, he is holding a board in support of the ban on fur farming on one of our info stalls. (2019)</figcaption></figure><p>It\u2019s worth highlighting that the success of the election website and the political ranking tool was the result of strong cooperation between the organizations involved. Politicians and the media perceived it as something that we did as a movement rather than individual groups.&nbsp;</p><h2>Radical change in the political landscape</h2><h3>Elections results</h3><p>The parliamentary elections took place on October 15, 2023. Following an intensive campaign, Law and Justice received (35.38%) of votes. While this was the highest result among all individual parties, Law and Justice has not been able to form a government as they lost the majority in Parliament to the coalition of opposition parties made up of Civic Coalition, Third Way, and The New Left. The 2023 parliamentary elections recorded an all-time high voter turnout of 74%. This is the highest since the fall of communism in 1989.</p><p>There are 460 seats in the Sejm (the highest organ of state authority). Law and Justice was unable to form a government as no other party was willing to join them. The opposition parties secured the majority of the seats:</p><ol><li><a href=\"https://en.wikipedia.org/wiki/Civic_Coalition_(Poland)\"><u>Civic Coalition</u></a> (Koalicja Obywatelska), won the most seats from among the opposition parties. Its main party was in power before 2015 and back then it was not perceived as supporting progressive changes for animals. However, since 2015, it has moved from being a right-wing liberal party to more centrist and even left in some aspects. Today, many of their MPs support improving animal welfare. Furthermore, three of the coalition\u2019s seats were secured by very pro-animal members of the Green Party. One seat was won by <a href=\"https://tvn24.pl/tvn24-news-in-english/polish-opposition-targets-rural-votes-as-farming-activist-to-stand-7294310\"><u>Micha\u0142 Ko\u0142odziejczak</u></a> from Agrounion (Agrounia). He was the leader of the 2020 farmers\u2019 protests against the animal protection bill and has historically opposed any progress for the animals. While this is only one seat, his voice will certainly be loud in any discussions about animal agriculture, as he became one of the Vice-ministers of Agriculture in the new government. The move to join the Civic Coalition was purely a political one for both sides: Ko\u0142odziejczak needed some bigger party to help him get to Parliament, and the coalition needed him to attract voters beyond their own electorate. We will see in the future what their relations will be and what it will mean for the animals.</li><li>The next major opposition group, Trzecia Droga (<a href=\"https://en.wikipedia.org/wiki/Third_Way_(Poland)\"><u>Third Way</u></a>), is built mostly by two parties: Polska 2050 (<a href=\"https://en.wikipedia.org/wiki/Poland_2050\"><u>Poland 2050</u></a>) and Polskie Stronnictwo Ludowe (<a href=\"https://en.wikipedia.org/wiki/Polish_People%27s_Party\"><u>Polish People\u2019s Party</u></a>). Poland 2050 is a centrist liberal party with many progressive politicians. The leader, Szymon Ho\u0142ownia, a well-known journalist, author, and media personality, <a href=\"https://deon.pl/magazyn/szymon-holownia-o-koszmarze-hodowli-przemyslowej-zwierzat,501123\"><u>publicly opposed</u></a> factory farming. He is a vegetarian and wrote a book about our relationship with animals from a Christian perspective. In 2018, Anima International in Poland <a href=\"https://deon.pl/kosciol/szymon-holownia-nagrodzony-tytulem-czlowieka-roku-przez-otwarte-klatki,504231\"><u>gave him an award of the Man of the Year</u></a> for raising the issue of animal suffering. He was also a guest speaker at our events. Polish People\u2019s Party is an agrarian conservative party. The new Minister of Agriculture comes from this party. Unfortunately, the Polish People\u2019s Party has historically opposed almost any progress for animals. In 1997, they unsuccessfully fought against the ban on force-feeding ducks and geese to produce foie gras. They usually dismiss any discussion about the ban on cages. It is safe to assume that this party will be the main obstacle to achieving significant progress for animals while this coalition is in power. However, it seems that things are slowly changing for the better. For instance, just recently, one of their leaders <a href=\"https://x.com/otwarteklatki/status/1720405474950918616?s=20\"><u>publicly supported</u></a> the fur farming ban.</li><li><a href=\"https://en.wikipedia.org/wiki/The_Left_(Poland)\"><u>The Left</u></a> \u2013 a coalition of several left-wing and progressive parties. It is very supportive of the main animal protection issues, but it is still not known how much impact they will have on the new government.</li><li>Konfederacja (<a href=\"https://en.wikipedia.org/wiki/Confederation_Liberty_and_Independence\"><u>Confederation</u></a>) \u2013 a far-right political alliance that strongly opposes any progress for animals. They are not part of the majority coalition.</li></ol><figure class=\"image image_resized\" style=\"width:700px\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/pheZeLQG4iEyS9Cri/h493dm0svcahi42bhkzk\"></figure><h2>The outlook for animals in Poland</h2><p>The visibility of animal welfare issues in the pre- and post-election public debates has put animal advocacy in Poland in a very good position to work with the new MPs towards legislative changes for the animals. However, we need to be very careful not to set our hopes too high and to make sure we don\u2019t fall short by not being careful, otherwise, we may again risk the chilling effect on policy changes in Poland.</p><h3>The ban on fur farming</h3><p>Support for the fur farming ban before the elections was voiced by members of almost all opposition parties, and as we\u2019ve learned from the 2020 animal protection bill vote, many MPs from Law and Justice also support it. Ma\u0142gorzata Tracz from the Green Party initiated the <a href=\"https://www.sejm.gov.pl/Sejm10.nsf/agent.xsp?symbol=ZESPOL&amp;Zesp=893\"><u>Parliamentary Team for the Fur Farming Ban</u></a>, and she wants to lead the process to introduce the legislation. As the number of fur farms and animals kept on them is declining every year, we also expect the opposition to the ban to be weaker.&nbsp;</p><h2>Laying hens and broiler chickens</h2><p>Unfortunately, both banning the cage farming of hens while 72% of these animals are still kept in cages, and phasing out fast-growing breeds when Poland relies heavily on the exports of meat from fast-growing chickens, seems very challenging. The pre-election pledges of support have opened the mainstream political conversations about these issues, but we can\u2019t expect immediate legislative proposals, as it usually takes years from the initial declaration of political support to implementing the law.&nbsp;That being said, introducing these topics into politics is an important step forward, as it brings the topic to the front of the MPs\u2019 attention and allows animal advocates to build the foundations for legislative changes (collecting data, as well as influencing political institutions and public debate). If corporate progress for hens and chickens continues to happen, then we might begin to see new political opportunities. Once cage-egg production or the use of fast-growing chickens becomes less dominant in the market, it will be possible to have a political discussion about legislative changes. The animal advocacy movement in Poland has laid solid foundations for future policy work, however, we need to remember that political and legislative change takes time.</p><h3>The effect on the European Union</h3><p>The new government is also considered much more pro-EU compared to the previous ruling party, and we expect it to be easier to work with the new Ministry of Agriculture on improving EU legislation for animals. If the EU revision of animal welfare legislation comes back on the table, we are in a better position to get the support of the Polish government for the key changes.</p><h2>Conclusion</h2><p>After the failure of the 2020 animal protection bill, it became difficult to get politicians involved in any action aiming for meaningful legislation for animals. It was especially visible in the case of the MPs of Law and Justice, even those who are in favor of improvements in animal welfare. In our opinion, the joint work of several organizations before the elections led to a re-opening of the political debate about animals and agriculture in Poland. Many parties and politicians, who now form the government, pledged to support key changes for the animals, like a fur farming ban, eliminating cages, or phasing out fast-growing breeds of broiler chickens. However, this has to be read in the context of Poland being a post-communist country in which animal agriculture is a <a href=\"https://ourworldindata.org/grapher/agriculture-share-gdp?tab=chart&amp;region=Europe&amp;country=OWID_EU27~POL\"><u>significant part of the national economy</u></a>, and improvements such as the ones discussed in this text will be very difficult to achieve, even if many MPs publicly pledge to support them. <strong>The elections haven\u2019t changed anything for animals, but they broke us out of the three-year deadlock.</strong>&nbsp;</p><p>In Anima International, we think of policy work as one of the key tools for the improvement of animal welfare. This is a far less tractable tool than corporate outreach but quite often with comparable results.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref0tpwqgszz95\"><sup><a href=\"#fn0tpwqgszz95\">[7]</a></sup></span>&nbsp;In addition, because breaking corporate commitments is harder to enforce than breaking the law, policy changes support corporate work by leveling competition and avoiding coordination failures where one bad actor tries to outcompete others by backsliding. Legislative changes can also have an impact beyond one country or one region, as it is in the case of the so-called <a href=\"https://en.wikipedia.org/wiki/Brussels_effect\"><u>Brussels effect</u></a>. Moreover, legislative change is also a strong signal to the market that particular changes are unavoidable, potentially making companies comfortable with introducing them. For these reasons, we stayed politically active even in times when it seemed like very little could be achieved. Unfortunately, in politics, it often takes years to see the results of the work.</p><p>We also strongly believe in political neutrality as an animal advocacy organization. We never publicly support political issues or publish political statements. When it comes to political issues outside the scope of our expertise, we choose to take a neutral position. This stems from the conviction that we need to find a common language with politicians from across the political spectrum, and that speaking out on topics on which we don\u2019t have expert knowledge might undermine our credibility. In our opinion, caring about animals is not a matter of political opinion, therefore we always strive to work with all politicians who are open to discussion about animal welfare, no matter their political affiliation. This is not easy when politics is very polarized, as is the case in Poland, but we believe it is vital for our mission to help animals.</p><p>Working on political advocacy in a country where animal agriculture is a significant part of the national economy is challenging, but with a good strategy and execution, progress for animals is possible. The failure of the 2020 bill may have been the most frustrating moment in the history of animal advocacy in Poland, and it took a lot of resilience to keep pushing forward, but we feel that today we are in a much better place to work on legislative change. While we see great opportunities on the horizon, we also need to be realistic about the possible pace of progress in countries like Poland. So while we witnessed animal protection in Poland being forced to take a step back, we are ready to take a huge leap forward.</p><hr><h2>Acknowledgments</h2><p>The following people provided feedback and input: Jakub Stencel, Anna Koz\u0142owska,&nbsp;Kirsty Henderson, Ilona Rabizo, Katarzyna Soko\u0142owska, Joh Vinding, Haven King-Nobles</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnmcp5ffj0t8a\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefmcp5ffj0t8a\">^</a></strong></sup></span><div class=\"footnote-content\"><p>For non-EU readers \u2013 <a href=\"https://en.wikipedia.org/wiki/Member_of_the_European_Parliament\"><u>MEP</u></a> = member of the European Parliament.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fna496n73t6v5\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefa496n73t6v5\">^</a></strong></sup></span><div class=\"footnote-content\"><p>We produced an in-depth analysis on our work on live fish sales <a href=\"https://animainternational.org/blog/why-anima-international-suspended-the-campaign-to-end-live-fish-sales-in-poland\"><u>here</u></a>.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnx5oohm6hs0d\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefx5oohm6hs0d\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The bill was prepared and proceeded in a chaotic manner, and because of that and the fact it was quickly killed, we weren\u2019t able to conduct a detailed assessment of the impact of the proposed legislation. Parts of the proposed changes were related to companion animals, ritual slaughter, and animals in entertainment, but after we roughly compared the number of animals and the intensity of suffering, we came to the conclusion that a fur farming ban would be the most impactful. Yet, we would advise the reader to treat this claim with a grain of salt.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnm7nlnnvsnd\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefm7nlnnvsnd\">^</a></strong></sup></span><div class=\"footnote-content\"><p>The data on the numbers of farmed animals in Poland has been historically imprecise. Our last estimations were 4,000,000 \u2013 4,500,000 animals killed each year, but a recent <a href=\"https://citizens-initiative.europa.eu/sites/default/files/2023-12/C_2023_8362_EN.pdf\"><u>report from the EU</u></a> claims it\u2019s closer to 3,300,000 animals.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnjh5mfq1gqi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefjh5mfq1gqi\">^</a></strong></sup></span><div class=\"footnote-content\"><p>There is no good data about how many animals would be impacted by the ban of ritual slaughter in Poland. Using the <a href=\"https://www.farmer.pl/multimedia/pliki/119980.html\"><u>available data</u></a> and with some basic assumptions, it is possible that such a ban would impact 420,000 animals per year \u2013 2,000,000 cattle and calves are slaughtered per year in Poland (although the initial proposal mentioned broiler chickens); 70% of this meat is exported; around 30% of the exported meat is kosher/halal.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnf8akig4nj1\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreff8akig4nj1\">^</a></strong></sup></span><div class=\"footnote-content\"><p>With the exception of the indirect and technological solutions, like plant-based alternatives to animal products. We managed to interest some of the MPs in this topic, but we would rate it as a rather minor effect.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn0tpwqgszz95\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref0tpwqgszz95\">^</a></strong></sup></span><div class=\"footnote-content\"><p>While it describes a specific US context, we found this <a href=\"https://forum.effectivealtruism.org/posts/EEMpNRJK5qqCw6zqH/a-cost-effectiveness-analysis-of-historical-farmed-animal\"><u>Rethink Priorities\u2019 analysis</u></a> insightful.</p></div></li></ol>", "user": {"username": "Pawel Rawicki"}}, {"_id": "7CypkrfTYZprDicKh", "title": "I made a P(doom) calculator for convenient Fermi estimation", "postedAt": "2023-12-27T17:08:56.030Z", "htmlBody": "<p><i>This has been </i><a href=\"https://www.lesswrong.com/posts/pDqDBkWyZPuonc5R9/i-made-a-p-doom-calculator\"><i>cross-posted</i></a><i> on LessWrong</i></p><h1>Introduction</h1><p>My hope for this post is to offer an adaptable and accessible framework to Fermi estimate your probability that AI causes extinction or severe disempowerment of humanity, P(doom). I created a&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1QVz_K_cKGnmnguTYZfArdr78ybUbFf-yFtrGVzcPYd8/copy\"><u>calculator</u></a> to streamline the process and minimize the time investment. You just need to enter your estimated probability of a customizable set of premises needed for AI to cause doom.</p><p>For a better estimate, have a timeframe in mind for each of the premises (e.g., reaching the premise before 2100). This way, the calculator will spit out your estimated P(doom) within that time frame (e.g., P(doom) before 2100).</p><p>Note: The premises are conditions I commonly see in AI risk arguments, but think of them as ideas. They are quite broad/nonspecific so the calculator can adapt to different views about what conditions make AI an existential threat.&nbsp;<strong>To accurately estimate&nbsp;</strong><i><strong>your&nbsp;</strong></i><strong>P(doom), with minimal influence from the way I\u2019ve framed or worded things, interpret or change the premises to match criteria&nbsp;</strong><i><strong>you</strong></i><strong> think are needed for AI to cause doom.</strong></p><h3>The danger of using this calculator</h3><p>This calculator is far from perfect, and you should take that into account as you interpret its results. Do not assume its output is a high-confidence estimate. Instead, if you have a rough P(doom) already, I suggest you update it up/down using the calculator\u2019s results, to the extent you think they are trustworthy.</p><h3>Why you might want to try this calculator anyway</h3><ol><li><strong>Accuracy:&nbsp;</strong>The calculator forces you to break down a large estimate\u2014P(doom)\u2014into smaller estimates, of which, at least one has been empirically forecasted: the probability AI reaches specific Intelligence Levels within various timeframes<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref345zg0nxwev\"><sup><a href=\"#fn345zg0nxwev\">[1]</a></sup></span>. This method of slicing up large estimates is called Fermi estimation. Without a consistent bias, the smaller over- and under-estimates cancel each other out, and Fermi estimates thus produce relatively accurate numbers (such as getting the correct order of magnitude).</li><li><strong>Clarity:</strong> When I try to estimate the probability of future events with many different ways they might come to fruition, it feels very fuzzy\u2014like a smear of numbers \u201cclose enough\u201d to my intuitions. I think this calculator can clear up some of that fuzziness with a precise estimate. However, this is a balancing act: As mentioned in the previous section, don\u2019t give the results much confidence just because they are specific numbers. If you have a rough P(doom) already, you should update it up/down using the calculator\u2019s results, to the extent you think they are trustworthy.</li><li><strong>Testing:&nbsp;</strong>You can test upper/lower bounds you think are reasonable to better understand how uncertain you are.</li><li><strong>Curiosity/Entertainment: </strong>Even if you completely ignore the output, you might be curious to see how it changes with certain input estimates, or find some entertainment in viewing its results. I think they\u2019re quite interesting.</li><li><strong>Convenience: </strong>Estimating your P(doom) with this calculator, and receiving the above benefits, shouldn\u2019t take very long.</li></ol><h1>Overview/Instructions</h1><p>I\u2019d skip this section if you\u2019re planning on reading the \u201cMethod\u201d section; it explains everything here in further detail. Otherwise, I\u2019d recommend reading the following while occasionally glancing at the calculator\u2026</p><ul><li>There are three sections, each based on an Intelligence Level (IL), starting with SuperIntelligence (SI), then Artificial General Intelligence (AGI), and finally sub-human intelligence (AI&lt;H)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefts4ehgm4oj\"><sup><a href=\"#fnts4ehgm4oj\">[2]</a></sup></span>.</li><li>Each IL section estimates an independent P(doom) for that IL within your timeframe. These are added together to get the overall P(doom) from AI within your timeframe.</li><li>In each IL section, you estimate\u2026<ul><li>The probability AI reaches the given IL within your timeframe.</li><li>The probability of various premises\u2014the Premises Collection (PC)\u2014<i>assuming the IL is reached within your timeframe</i>.</li><li>The probability AI causes extinction,&nbsp;<i>assuming the PC is true and the IL is reached within your timeframe.</i></li><li>The probability AI causes severe disempowerment,&nbsp;<i>assuming the PC is true and the IL is reached within your timeframe.</i></li></ul></li><li>If you don\u2019t think one of the included premises is needed for AI to cause doom, you can ignore it by entering 100% probability.</li><li>If you think a different premise is needed for AI to cause doom, you can add it.</li></ul><h2>Terms and Notation</h2><p><i>Refer to this if it helps you understand the premises</i></p><ul><li>doom = Human extinction or severe disempowerment.</li><li>P(x) = Probability of \u201cx\u201d (probability x is true).</li><li>P(\u00acx) = Probability of \u201cnot x\u201d (probability x is not true).</li><li>P(x|y) = Probability of x, \u201cgiven y\u201d (probability x is true, given that y is true).</li><li>Premises = Criteria for AI to cause doom<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefts4ehgm4oj\"><sup><a href=\"#fnts4ehgm4oj\">[2]</a></sup></span>. You input your estimated probabilities of these premises.</li><li>Variables = Probabilities created by adding your probabilities of certain premises.</li></ul><h3>Variables&nbsp;</h3><p><i><strong>Note: </strong>This information isn\u2019t very important for using the calculator, but might help some people create more accurate estimates.</i></p><p>By default, the calculator adds premises to create two variables:</p><ol><li>The probability AI isn\u2019t aligned, given the IL, is the sum of your probability AI is misaligned, given the IL, and your probability AI is misused, given the IL.</li><li>The probability AI isn\u2019t prevented from causing doom (assuming it could) is the sum of your probability AI proliferates (copies itself such that it can\u2019t feasibly be shut off), given the IL, your probability AI deceives regulation attempts well enough to avoid being shut off, given the IL, and your probability AI isn\u2019t prevented from causing doom, even if it doesn\u2019t proliferate or deceive us, given the IL.</li></ol><h1>Method:</h1><p>For those of you who won\u2019t blindly accept numbers spit out of a spreadsheet (I don\u2019t blame you), here\u2019s how it works (it\u2019s imperfect but better than dreaming up black-box estimates).</p><h2>Probability of the Intelligence Level (IL)</h2><ul><li>First, you input your estimated probability AI reaches one of three Intelligence Levels (ILs)<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefts4ehgm4oj\"><sup><a href=\"#fnts4ehgm4oj\">[2]</a></sup></span>: SuperIntelligence (SI), Artificial General Intelligence (AGI), and sub-human intelligence (AI&lt;H).</li></ul><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7CypkrfTYZprDicKh/mfjwk4xaayfdcqr7ih52\"><figcaption>The images in this post use SI as an example</figcaption></figure><ul><li>All other premises assume a certain Intelligence Level is achieved (for example, all of the images in this post assume SI).</li></ul><h2>The Premises Collection (PC)</h2><p>The Premises Collection (PC) contains variables that&nbsp;<i>must be true</i> for AI to cause doom, given the Intelligence Level.</p><ul><li>Since the premises of AI risk arguments vary, there are customizable premises you can add if you think AI another premise is needed to cause doom, and premises can be ignored if you don\u2019t think they are needed for doom (e.g., if you don\u2019t think AI needs to be agentic, you can ignore that premise). To ignore a premise, enter 100% probability. This doesn\u2019t change the estimate because it causes the calculator to multiply by a factor of 1.</li><li>By default, the calculator assumes all of the following four things are necessary for AI to cause doom: AI being agentic, goal-seeking, not aligned, and not prevented from causing doom (but any of these can be ignored).</li></ul><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7CypkrfTYZprDicKh/kup1kjrddas8vcczuy7s\"></figure><h3>Probability AI isn\u2019t aligned, given the Intelligence Level: P(\u00acAligned|IL)</h3><p>The probability AI isn\u2019t aligned, given the IL, P(\u00acAligned|IL), is the sum of\u2026</p><ol><li>&nbsp;P(Misaligned|IL): Your probability AI is misaligned, given the IL.</li><li>&nbsp;P(Misused|IL): Your probability the AI is misused, given the IL.</li></ol><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7CypkrfTYZprDicKh/l8du2jhkxjkz0txlnf5i\"></figure><h3>Probability AI isn\u2019t prevented from causing doom, given the Intelligence Level: P(\u00acPrevented|IL)</h3><p>The probability AI isn\u2019t prevented from causing doom, given the IL, P(\u00acPrevented|IL), is the sum of\u2026</p><ol><li>P(Proliferation|IL): Your probability AI proliferates (copies itself such that it can\u2019t feasibly be shut off) given the IL.</li><li>P(Deceit|IL): Your probability AI deceives regulation attempts well enough to avoid being shut off, given the IL.</li><li>P(\u00acPrevented Regardless|IL): Your probability AI is not prevented from causing doom even without proliferation or deceit, given the IL.</li></ol><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7CypkrfTYZprDicKh/vzn2mlzojizzgkybankm\"></figure><h3>Probability of doom, given the Premises Collection and the Intelligence Level: P(doom|PC|IL)</h3><p>The probability of doom, given the PC and IL, P(doom|PC|IL), is the sum of\u2026</p><ol><li>P(X-risk|PC|IL): Your probability AI causes extinction, given the PC and IL.</li><li>P(S-risk|PC|IL): Your probability AI severely disempowers humanity, given the PC and IL.</li></ol><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7CypkrfTYZprDicKh/t2hin7ejymcctoeljwim\"></figure><h2>Probability of doom: P(doom)</h2><p>By default, the probability of doom&nbsp;<i>for each IL</i>, P(doom from IL), is the product of\u2026</p><ol><li>P(IL): Your probability the IL is achieved.</li><li>P(PC|IL): The probability AI is agentic, goal-seeking, not aligned, not prevented from causing doom, AND any premises you added, given the IL (though any of these can be ignored).</li><li>P(doom|PC|SI): The probability AI causes doom, given the IL and AI that is agentic, goal-seeking, not aligned, not prevented from causing doom, AND any premises you added (though any of these can be ignored).</li></ol><p>Finally, the overall probability of doom, P(doom), is the sum of the calculated probabilities of doom from\u2026</p><ol><li>SuperIntelligent AI: P(doom from SI)</li><li>AGI: P(doom from AGI)</li><li>Sub-human AI: P(doom from AI&lt;H)</li></ol><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn345zg0nxwev\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref345zg0nxwev\">^</a></strong></sup></span><div class=\"footnote-content\"><p>See Ajeya Cotra's <a href=\"https://www.cold-takes.com/forecasting-transformative-ai-the-biological-anchors-method-in-a-nutshell/\">\"Bio Anchors\"</a> report or Tom Davidson's <a href=\"https://www.lesswrong.com/posts/Gc9FGtdXhK9sCSEYu/what-a-compute-centric-framework-says-about-ai-takeoff\">\"Compute-Centric\"</a> report (to conveniently see his conclusions, see slides 12 and 17 of his <a href=\"https://docs.google.com/presentation/d/1MKHOkSyC5stPzLP_RUGRSCccQUXgeBoblSGBfGghEwI/edit\">slideshow</a>).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnts4ehgm4oj\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefts4ehgm4oj\">^</a></strong></sup></span><div class=\"footnote-content\"><p><strong>Reminder: Think of the premises and Intelligence Levels as ideas up to interpretation.</strong> They are common but nonspecific conditions in AI risk arguments, so the calculator can adapt to different views. <strong>To accurately estimate&nbsp;</strong><i><strong>your&nbsp;</strong></i><strong>P(doom), with minimal influence from the way I\u2019ve framed or worded things, interpret or change them to match criteria&nbsp;</strong><i><strong>you</strong></i><strong> think are needed for AI to cause doom.</strong></p></div></li></ol>", "user": {"username": "NicholasNicholas"}}, {"_id": "Ay6C3MarTGcdENaR5", "title": "AGI will be made of heterogeneous components, Transformer and Selective SSM blocks will be among them", "postedAt": "2023-12-27T14:51:39.282Z", "htmlBody": "", "user": {"username": "Roman Leventov"}}, {"_id": "eghFgqWd3SEpWoe4X", "title": "Best giving multiplier for X-risk/AI safety?", "postedAt": "2023-12-27T10:51:52.460Z", "htmlBody": "<p>What do you currently consider the best giving multiplier for X-risk/AI safety? (highest &amp; somewhat robustly supported by evidence)</p>\n", "user": {"username": "SiebeRozendal"}}, {"_id": "AvubGwD2xkCD4tGtd", "title": "Only mammals and birds are sentient, according to neuroscientist Nick Humphrey\u2019s theory of consciousness, recently explained in \u201cSentience: The invention of consciousness\u201d", "postedAt": "2023-12-27T06:18:18.451Z", "htmlBody": "<p>In 2023, Nick Humphrey published his book&nbsp;<i>Sentience: The invention of consciousness (S:TIOC).</i> In this book he proposed a theory of consciousness that implies, he says, that only mammals and birds have any kind of internal awareness.</p><p><i>[EDIT: This post aims to summarize that book. Nick Humphrey has written a pr\u00e9cis, a summary, of his own book on </i><a href=\"https://aeon.co/essays/how-blindsight-answers-the-hard-problem-of-consciousness\"><i>aeon here</i></a><i>, and has done a much better job summarizing his book than I have. Consider reading that instead of this post, then coming back to comment on this forum post]</i></p><p>His theory of consciousness has a lot in common with the picture of consciousness is described in recent books by two other authors, neuroscientist Antonio Damasio and consciousness researcher Anil Seth. All three agree on the importance of feelings, or proprioception, as the evolutionary and experiential base of sentience. Damasio and Seth, if I recall correctly, each put a lot of emphasis on homeostasis as a driving evolutionary force. All three agree sentience evolved as an extension of our senses\u2013touch, sight, hearing, and so on. But S:TIOC is a bolder book which not only describes what we know about the evolutionary base of consciousness but proposes a plausible theory coming as close as can be to describing what it is short of actually solving Chalmers\u2019 Hard Problem.</p><p>The purpose of this post is to describe Humphrey\u2019s theory of sentience, as described in S:TIOC, and explain why Humphrey is strongly convinced that mammals and birds\u2013not octopuses, fish, or shrimp\u2013have any kind of internal experience. Right up front I want to acknowledge that cause areas focused on animals like fish and shrimp seem on-expectation impactful even if there\u2019s only a fairly small chance those animals might have capacity for suffering or other internal experiences. Those areas might be impactful because of the huge absolute numbers of fish and shrimp who are suffering if they have any internal experience at all. But nevertheless, a theory with reasonable odds of being true that can identify which animals have conscious experience should update us on our relative priorities. Furthermore, if there is substantial uncertainty, which I think there is, such a theory should motivate hypothesis testing to help us reduce uncertainty.</p><h2><br><i>Blindsight</i></h2><p>To understand this story, you should hear about three fascinating personal encounters which lead Humphrey to some intuitions about consciousness. Humphrey describes blindsight in a monkey and a couple of people. Blindsight is the ability for an organism to see without conscious awareness of seeing. Humphrey tells of a story of a monkey named Helen whose visual cortex had been removed. Subsequent to the removal of her visual cortex, Helen was miserable and unmotivated to move about in the indoor world she lived in. After a year of this misery, her handlers allowed her to get out into the outside world and explore it. Over the course of time she learned to navigate around the world with an unmistakable ability to see, avoid obstacles, and quickly locate food. But Humphrey, knowing Helen quite well, thought she lacked the confidence in herself to be able to have the awareness that she clearly did. This was a clue that perhaps Helen was using her midbrain system, the superior colliculus, which processes visual information in parallel with the visual cortex, and that she was unaware of the visual information her brain could nevertheless use to navigate her body around obstacles and to locate food. Of course this is somewhat wild speculation considering that Helen couldn\u2019t report her own experience back to Humphrey.</p><p><br>&nbsp;</p><p>The second observation was of a man known to the scientific community as D.B. In an attempt to relieve D.B. of terribly painful headaches, doctors had removed D.B.\u2019s right visual cortex. D.B. reported not being able to see anything presented only to his left eye (the left and right eyes each reporting information to the visual cortex in the opposite side of the brain). But strangely, when doctors encouraged him to guess what as in his left visual field, he could correctly identify shape, color, and position of objects presented to him, even as he had no conscious awareness of seeing them.</p><p><br>&nbsp;</p><p>I\u2019d like to add two caveats to this story about D. B.. First, I am a little sceptical this story is really evidence for unconscious sight. Split-brain patients, patients whose cortex has been cut in half to reduce seizures, can only describe objects presented to the one eye connected to the side of their brain that produces speech. Present the object to the other eye, and the information will to go the other side of their brain and these patients will verbally report not being able to see the object. Nevertheless, they will correctly be able to&nbsp;<i>write</i> the name of the object down on a piece of paper. The fascinating possibility here is that split-brain patients might have split-consciousness: potentially parallel tracks of conscious experience that are to some degree uncoordinated and independent. But in the context of D.B., the patient whose visual cortex was removed, we might infer that perhaps D.B. was still conscious of the objects he was seeing with his superior colliculus, but was merely unable to describe them because of his remaining visual awareness was disconnected from his phonological systems.</p><p><br>&nbsp;</p><p>Second, <a href=\"https://forum.effectivealtruism.org/users/mako-yass?mention=user\">@mako yass</a> &nbsp;suggested an interesting empirical test of Humphrey\u2019s observations about D. B.. If we were to help D. B. train to use his unconscious sight by giving continuous feedback on his guesses as to what he was seeing, would he learn to recognize\u2013and be conscious of\u2013whatever intuitions he is drawing on to report his awareness? If he did, then perhaps he has had some kind of conscious experience of the visual stimuli after all\u2013just not the sort of qualia you get with a visual cortex\u2013and in that case, perhaps a theory of conscious vision that places conscious visual sensation entirely in the visual cortex is misplaced.</p><p><br>&nbsp;</p><p>Having added those caveats, I\u2019ll move on to discussing the final compelling case study that Humphrey uses to set up his theory of sentience in S:TIOC.</p><p><br>&nbsp;</p><p>H.D. is a woman who tragically lost her eyesight at the age of 3 due to scarring of her corneas. Her corneas weren\u2019t restored until the age of 27, and following the operation, she was convinced her vision hadn\u2019t improved. Without any training from visual stimuli between the ages of 3 and 27, her visual cortex had perhaps atrophied and was unable to make sense of the signals coming in from her eyes. And like Helen the monkey, H.D. was able to identify obstacles, and she was able to point to objects in the world. But she reported a lack of any subjective sensory quality of visual experience.</p><p><br>&nbsp;</p><p>The common thread running through the experiences of Helen, D. B., and H.D., is that although in each cases the evidence was not entirely complete, it seems fairly likely each were able to see but unable to experience the qualia of seeing. Perhaps it existed as a sort of sixth sense, inperceivable except as a sort of intuition. Somewhat like a Jedi could sense and learn to train to swing a light sabre using an intuitive sense without conscious awareness, these three seemed to be able to sense visual stimuli without consciously experiencing them.</p><p><br>&nbsp;</p><p>The implication is that visual&nbsp;<i>sensation</i> and&nbsp;<i>perception</i> are separable in important ways. I\u2019m sure I\u2019m oversimplifying the story somewhat, but Humphrey's rough sketch is that visual&nbsp;<i>sensations</i> are conscious experiences generated in the visual cortex, while&nbsp;<i>perceptions</i> are unconscious signals existing in the midbrain\u2019s superior colliculus. In the normal operation of a human brain, sensation and perception might become intermingled, but take away one and something of the other will remain; an animal with only a midbrain might have the perception without the sensation.</p><h2><i>Sensation, sentition, and the ipsundrum</i></h2><p>In early animals, reflexive neural circuitry generates direct response to perceptions of stimuli. If an aversive stimulus is perceived on the left, the organism reflexively moves right. In S:TIOC, that sort of reflex response Humphrey calls \u201csentition\u201d: a meaningful but automatic response to stimuli. Humphrey proposes a four-step evolutionary development from those automatic sensory responses to conscious sensation.</p><p>In the first step, an additional copy,&nbsp;<a href=\"https://en.wikipedia.org/wiki/Efference_copy\"><u>an efference copy</u></a>, of that motor command is generated and set additional neurons internal to the brain that simply represent and store information about the motor response itself. The body monitors its own response (This is a remarkably similar story to Damasio\u2019s \u201csomatic marker hypothesis\u201d) in order to do things with that response, such as to learn new associations with it.</p><p>In a second step, the animal reaches a level of evolutionary sophistication where some reflexive responses are no longer appropriate. At that point, the reflexive responses are privatized, so that only the internal&nbsp; model of the motor response remains\u2013there\u2019s no longer an automatic command going back out to the body. In this sense, the brain now for the first time has a privatized record of the response. This forms a proprioceptive map of the body internal to the brain.</p><p>In Step 3, because motor signals formerly sent to the body now go from one place in the brain to another, a feedback loop can generate. A sensory feedback loop can be initially triggered by an incoming sensory signal, but that signal can now reverberate in the brain in a continuous and lasting neural response. This \u2018thickens up\u2019 (Humphrey\u2019s term) the response, giving the signal some persistence over time.</p><p>In Step 4 of our development towards consciousness, evolution shapes the brain to push that recursive activity into a stable attractor state which can repeat the same pattern at different times. That complex system Humphrey describes as the \u201cipsundrum\u201d, and he says it is those stable, recursive patterns that are phenomenal sensations. I\u2019m still not entirely sure why he thinks these patterns in particular are phenomenal, but lets say only they have the persistence and complexity to reach a threshold of conscious feeling. Because it\u2019s a recursive feedback state shaped by evolution to a stable attractor system, the ipsundrum is \u201call-or-nothing\u201d--you have a particular phenomenal consciousness, or you don\u2019t. Animals without this complex recursive attractor system do not have conscious sensations at all.</p><p>I want to give an apology to the reader if you are at this point feeling a little lost. There are gaps for me at this point too, and I\u2019m not sure I\u2019ve entirely faithfully reproduced the argument. In particular, the distinction between Step 3: thickened up recursive sensory feedback loops, and Step 4: attractor tates for those loops, seems not clearly defined. But I hope I have communicated a gist!</p><h2><i>Animals and sentience</i></h2><p>There were two behavioral patterns Humphrey discusses which to me were compelling for his argument that birds, mammals, and no other animals are sentient. First, Humphrey claims that&nbsp;<i>all</i> animals with sentience, that experience internal qualia, now have a motivation to engage sensory play in order to experiment or learn about their internal qualia. When judging whether a species has sentience, then, a conclusive lack of sensory play is strong evidence that species lacks sentience. Play is&nbsp;<i>necessary</i> but not sufficient for sentience, in an evidential sense, i.e., sensory play is an inevitable consequence of experiencing sentience. Second, Humphrey says sensation seeking is strong evidence an animal is sentient; non-sentient animals have no reason to seek out sensations, he says. So sensation seeking is&nbsp;<i>sufficient</i> to indicate sentience, albeit not entirely necessary.</p><p>I go back and forth on this. Brian Christian&nbsp;<a href=\"https://en.wikipedia.org/wiki/The_Alignment_Problem\"><u>gives a strong argument</u></a> for the utility of reinforcement learning agents having intrinsic motivation to explore and learn about the world around them. That might imply a kind of intrinsic attraction to novelty that seems not too different to sensation-seeking. You might also imagine it is evolutionary adaptive for some specific kinds of perceptions, like the warmth of a close companion, to be intrinsically rewarding, irrespective of whether there are sensory qualia associated with them.</p><p>But if I understand Humphrey right, he\u2019s clear that these behavioral patterns&nbsp;<i>could</i>&nbsp;<i>in theory</i> be replicated in non-conscious, non-sentient machines. It\u2019s just that in humans, the solution evolution has hit upon is to create sensory feedback loop attractor states that Humphrey calls ipsundrums (ipsundra?) which happen to generate&nbsp;<i>conscious</i> experiences.&nbsp;<i>Humans</i> engage in play in order to learn about those conscious experiences, and engage in sensation-seeking because some of those experiences are inherently pleasurable. Other mammals and birds exhibiting the same behavior, having much the same neural circuitry, are probably engaging in that behavior for the same reason humans are\u2013because they have internal conscious experiences. Other animals like fish, reptiles, and octopuses do&nbsp;<i>not</i> engage in sensation-seeking or play and so do not have those internal conscious experiences.</p><h2><i>Implications</i></h2><p>Humphrey\u2019s theory of consciousness in S:TIOC implies that machines could, in principle, be conscious, if they have the same kind of reflective systems that sentient animals like humans do; but also that there\u2019s probably no particular function or kind of intelligence that would&nbsp;<i>require</i> consciousness to operate. But it does seem possible that, if we were to try to emulate the human proprioceptive, learning, and decision-making system, we might (accidentally or otherwise) produce machine consciousness.</p><p>Humphrey\u2019s ipsundrum theory of consciousness suggests that efforts to improve the living conditions of fish and shrimp may not actually decrease suffering of sentient creatures, because those animals are not sentient. This will be quite a controversial implication.&nbsp;</p><p>My hope is that if we can all agree the ipsundrum theory is really just at the level of a hypothesis at this point, we can all agree that, on expectation, given the current state of knowledge, fish and shrimp welfare are morally relevant, but also that future evidence in favor of the ipsundrum hypothesis may change that expectation and suggest fish and shrimp welfare are no longer morally relevant. It may also continue to be that, due to the vast number of fish and shrimp, even a tiny probability that the ipsundrum hypothesis is wrong might continue to make fish and shrimp morally relevant relative to mammals and birds, who are more clearly sentient, but fewer in number.</p><p>Research should try to investigate the hypotheses Nick Humphrey describes, in order to reduce uncertainty about his hypothesis. Unfortunately, Humphrey doesn\u2019t spend much time outlining hypothesis tests for his theories. There are several parts of the theory which might use additional testing:</p><ul><li>At the neuroscientific level, how exactly should we identify the ipsundrum in humans?&nbsp;</li><li>Can we identify feedback loops attractor states that correlate with presence of conscious experience, appearing (for instance) during wakeful experience and REM sleep but disappearing within deep sleep?</li><li>Might we simply look for bidirectional connectivity patterns between relevant brain areas; if so, which are the relevant brain areas?</li><li>How do we separate out the presence of a sensory loop \u201cattractor state\u201d from mere accidental feedback loops? Should we look to structural connectivity?</li><li>Within animal ethology, is it really true that fish, shrimp, octopuses, and other animals of particular concern do not engage in sensation seeking or play?&nbsp;</li><li>Additional research into blindsight is also likely relevant.&nbsp;</li></ul><p>There\u2019s probably a much longer and more precise list of hypothesis tests we could respond with.</p><p>Probably most hypothesis-testing should concern biological organisms. But perhaps there is computational consciousness work to experiment with too. What sort of reinforcement-learning-based, embodied artificial intelligence endowed with sensory feedback loops to track its own embodiment might use play to learn about its own sensory processes? Is it possible that, without building explicit reward processes for sensation seeking, a sensation-seeking behavior might emerge simply because of the reward structure of the sensory system?</p><p>Such work run with appropriate agents would not necessarily be more unethical than research on animals, and might be much more ethical if agents were deliberately designed without, e.g., a desire for self-preservation, although if Humphrey is right, such drive does seem to be intrinsic to sentience. That sort of experimentation is also not in itself dangerous from an existential risk perspective provided it is performed on systems with fairly with limited intelligence, awareness of the wider world or how to modify its own basic reward system. If Humphrey is right, sentience could arise from a machine fairly limited in intelligence.</p>", "user": {"username": "ben.smith"}}, {"_id": "q5JsPWk4mTndqoHSf", "title": "An Evolution Revolution: using personal digital twin software, artificial sentience and quantum physics to solve genetic disorders", "postedAt": "2023-12-27T04:24:49.927Z", "htmlBody": "<p><br>Athamanatha Kitsune<br><br>SUMMARY OF THE SITUATION WE WANT TO ADDRESS<br><br>When people ask a doctor to treat them for a genetic disorder, presently they can expect a long and repetitive process. Perhaps some are lucky enough to have the chance to use a new and experimental genetic therapy, but even that is not a guaranteed long term cure. Most are still likely to be stuck with their genetic circumstances for life, along with the enormous cumulative medical bills for the effects, surgeries and pharmaceutical mitigations - assuming the disorder is not fatal.<br><br>There is cause for concern that the present path of development in the medical and pharmaceutical fields is insufficiently expedient. People are dying around the world daily as a result of Eroom's Law and the flaws of the economic system in combination with the way treatments are presently developed. When a disorder is rare or specific enough, it is ill fitted to the present paradigm and side effects of any treatments that may arise from genomic incompatibilities with unique individuals, are not effectively predicted.<br><br>A shift of paradigm and mindset is required, to one that considers humanity not to be some kind of endpoint, to be honed and maintained with its existing hubristically focused techniques, but rather as an early waypoint on a far longer journey. It's important to know that an over-attachment to anthropocentric thinking is a great harm to the long term potential for survival of Terran-origin intelligent, sapient life. We are in the early history of the development of Terran-origin life in this universe. The recognition of this fact and the acceptance of the role we are to play as the catalysts of the progress of that history through enabling the innovative changes desperately needed, amounts to enablement of a path to the ability to transcend our limits, presently referred to by some as Transhumanism, though more aptly it might more inclusively and broadly over time be called Transcendent, Biophysical and/or Morphological Freedom Activism.<br><br>That is to say, desiring and working towards transcending the mortal body and its limits. This can take many forms, but Put Together is focusing on freedom of form, or morphological freedom and associated freedoms, which are about being able to physically and biologically be anything you want to be. As in changing the shape, appearance or composition of the body itself. Conveniently for everyone, that includes what is very often needed for being 'healthy'.<br><br>We are also more generally about improved understanding of the causes of dysphoria and about understanding between all people; opening eyes and minds to the possibilities and to what lies beyond the perceived world immediately apparent to you.<br><br>Certain groups we have communicated with and been involved with previously, have denied that whole body adult genetic editing is even feasible, when repeatedly, new studies and information keep coming to light that chip away at their position. Our perspective is that it is not sufficient to dwell on the current capabilities of science, instead it is imperative to have a sense of where we are trying to go, and to direct our research with, and most importantly, from specific goals.&nbsp;<br><br>INCREMENTAL VS FIRST PRINCIPLES AND ZARAVASH'TA<br><br>I've been having the same argument over feasibility for the last 15 years with various scientists and the evidence just keeps building that they don't do enough research or reasonable mental extrapolation of possibility before retorting. To me, they exhibit too much incremental thinking. To them, I say you need to go back to first principles and use the existing scientific research as data to input, not as the be all end all.<br><br>Instead of asking \"How do we make the existing tools do better?\" or \"How do we extend from the existing tools?\", we need to ask \"How does the genome all actually work anyway, and how can we make tools that generalise to all handling of it?\"<br><br>DNA is a code. So like any code, it can be handled by computers. Computers can compile code and use it to build complex simulations. If you are trying to make a Digital Twin model for a sense of what positively works and what does not (and how you can combine what works into a successful gene editing vector) for any specific biological body, this is where you need to start.<br><br>Instead of limiting yourself with the top-down approach of using pharmaceutical methodologies and surgery, when it is clearly of insufficient speed, efficacy, personalisation and precision, try instead something tailored to the source of the problem. A generalised suite of tools for whole body gene editing that starts from the individual's own genome.<br><br><br>THE CONCERN OF BEING OVERTAKEN, OPEN SOURCE AND MOTIVATIONS<br><br>If you don't do it this way with a team of altruistic intent and the ethics of freedom of form in mind, you get overtaken by those with OTHER reasons to develop gene editing tech. Such as armies for supersoldiers, or unscrupulous corporations wanting to pull a GATTACA. If you don't ensure that the right motivations arrive at the goal first, the wrong ones will. And then the rightly motivated folks get a whole lot less say.<br><br>Part of the point of our gene editing system is to introduce biocybersecurity into genetic editing too! It's literally what a whole module (Vectron) of the software is for. Laberation will make full use of this to make it possible to safely share gene edits between users. You would download a vaccine... or anything you want to change yourself with. This brings the intended spirit of the internet to gene editing.<br><br>Open source is essential to the ethics we need.<br>If it was a proprietary system, you'd have a few dozen corporate employees who could fix a vulnerability, probably - if it was in their interest as a company. If it's open source, anyone who knows how to code can contribute fixes to be included in the project, and as we have seen with Linux (used in a ridiculous number of critical systems worldwide), vulnerability patching is not only very effective for the most part, but the vast majority of contributions are for positive efforts, not for exploitation.&nbsp;<br><br><br>DIGITAL TWIN<br><br>Simulations of the body can be used to provide a 'digital twin' of each individual genome being worked on, to precisely track what each edit and vector to carry them can do.<br><br>It can be considered inspiration, one way or another. If you can rewrite the DNA of your body such that you give it sequential instructions to follow, you can program it to transform as well as what to transform into. A digital twin model makes this much more intuitive, accurate and specific to each person's needs.<br><br>OVER-RELIANCE ON A HALL OF AI MIRRORS<br><br>Large Language Model AIs are a fascinating avenue of research currently transfixing the world - and transforming many jobs. Unfortunately, since they are technically still a form of very glorified autocomplete and akin to talking to your reflections in a fairground funhouse hall of mirrors. They are not suitable for the purposes of a gene editing system which requires no hallucinations, strong ethics and the ability to interface with and run on analogue hardware with frickin' lasers to manipulate the very code our bodies are built with.&nbsp;<br><br>What we need instead is an artificial sentience, which takes a different kind of approach to any LLMs. Where an LLM is opaque, an artificial sentience can be more transparent. Where an LLM replies with what it thinks follows the few words you just said, regardless of the wider context not explicitly directed to it, an artificial sentience is able to perform a wider analysis of the situation in your cells and handle many more inputs.<br><br>THE POSITIVE ACTIONS WE ARE TAKING<br><br>So now I've explained the tech we need, here's what we're doing at Put Together. We've started a biotech company. Vulpine Labs is the name of the B corporation (Public Benefit) we founded to protect and nurture our open source projects to develop a gene editing system that will do no less than cause an evolution revolution. https://www.vulpine-labs.com&nbsp;<br><br>First, it is important to recognise that while gene editing technologies of today appear to be in their infancy and have limited applications, the means to develop far more sophisticated tools for the purpose are all basically present. Science does not stand still, and engineering can often bridge us to things previously assumed to be impossible.<br><br>We took a look at our situation in 2008, that is, the situation of the health of humanity, of transgender people, space travellers, explorers, people affected by climate change, transhumanists, furries, therians and otherkin, including those who consider themselves transspecies. How could we be of most help?<br><br>Technologies that already exist have clear shortfalls.<br>* Hypnosis is fooling yourself. It doesn't actually change your biophysical reality in every sense, because in this world we live in, no matter what you have trained your mind to think, your body is still roughly the same.<br>* Surgery is messy and risky. Although some surgeons can do a great job, there is still a need to cut into the body and expose it to risk and a lengthy, often painful healing process. So that wouldn't be of much use.<br>* Prostheses don't change the underlying body.<br>* Implants as we know them today, may add some functionality or alter the shape, but they typically only last for a certain period before they become worn out or chemically problematic. They may also disrupt certain tissues in deleterious ways.<br>* Neuroprostheses (cyborg implants as we know them from sci-fi) are technology applied directly to the body with surgery. So they are still messy.<br>* Drugs are like throwing wrenches into a machine to see whether you can hit the right nut and turn it. There's a strong chance you will also hit other things, and the potential that doing so may cause damage. You then have to repeatedly take them to maintain the desired effect... which also maintains the potential side effects... and the profits of large corporations with some of the least scrupulous marketing in the world.<br>* Gene therapies as they currently stand, do modify the genes in a limited subset of your cells - but with the risk of those being replaced by cells with the original genome over time, possible autoimmune rejection, and still some extensive complex work being done with expensive reagents in an expensive lab to modify cells outside the body and then put them back in.<br><br>And when we looked at gene editing vectors at the time, they were unable to carry much genetic code into cells either, and the zinc finger nucleases and TALENS systems were limited in their scope. CRISPR, which in 2012 made a stride in the right direction, still has serious problems of accuracy and how much genetic information can be edited at once.<br><br>Nonetheless, molecules are like Lego bricks, in that for how simple they are, there are a ridiculously large number of ways they can be arranged. Many scientists find this irritating when it comes to determining exactly which way this or that sequence functions to produce a specific protein and how that protein folds and does its job. I have been told multiple times that the sheer combinatorial mathematics make this a really daunting problem. However, I view this as a problem mainly caused by insufficient interdisciplinary thinking and willingness to get down to first principles for tool development; we could be using pre-existing tools as inspiration but not as the pace-setters or limit-definers for the best we can hope to do. When you design tools for all the lessons we can actually now learn across the whole gamut of studies, sciences and approaches, from quantum physics, computing and biology to nutrition and the microbiome, and from AI and cybersecurity to virology and immunology, each of the modular components and areas of expertise can balance out the difficulties of the others.<br><br>Vulpine Labs is not just a company aiming to develop some sort of amazing future-tech, we're developing what should already be possible in terms of raw data and materials, and we are aiming to intercept the expected computing capacity of home gaming PCs at the time we release v.1.0 for most aspects of the computing. It's telling of how much the advent of Big Data and various technological advancements over the last few decades have overwhelmed many people we have spoken to, that they find our ideas incredulously hard to imagine. But personal incredulity is a fallacy.<br><br>MORE DETAILS OF OUR INTENTIONS<br><br>Our plan is to develop a system wherein you input a sample of your DNA, the system can read the DNA and produce from the code therein, a model of your entire body which is accurate to what your DNA encodes. You'll then be able to adjust that model based on any zoom level, from the genes to the jeans, and see what is necessary genetically to make an arbitrary change occur and unfold safely, and what the results are of arbitrary changes to the genes.<br>Then, it's time to package it all together into a custom-designed gene editing vector for your body, optimised to ensure the fastest-yet-safest means of introducing the changes to your body. You'll be able to test and tweak the vector and its processes, using viral and nanotechnological structures to make the perfect vehicle for your changes. Following which, if all is well with it, you can export this vector and the changes within it to a device which will assemble the real thing with actual biomolecules - in particular, ones it finds in your own cell samples where possible. This reduces and maybe eliminates the need for expensive supplies of reagents. The vector will be designed to go to all cells in the body, and adjust their DNA so they all match. No replacing modified cells with unmodified, and no mistaking modified self for non-self cells in the immune system's checks.<br><br>The resultant system and processes should be modular (we will offer individual modules stand-alone to researchers and institutions along with contracts to work with us to support and/or train them, and improve our systems for their needs), and capable of solving myriad problems. These could range from cancer susceptibility to autoimmune disorders, and from adaptation to space travel, to redesigning our bodies for self-customisation purposes, be that to eliminate dysphoria or just to be different.<br><br>Our software will be called the GUESS Unified Editing Suite and SDK, which is essentially an IDE for DNA, and is named the GUESS to remind us all there may be some situations in which there is yet insufficient data for it to rely on fully, and so it will have to take its best guess - especially in the early days. Our hardware will be called the Geneticiser. Together, they will do for gene editing what the RepRap did for 3D printing and what the Personal Computer and the internet did for information sharing and processing.<br><br>Together, we will accelerate evolution beyond natural selection, and outpace viral outbreaks with genetically encoded vaccines that anyone with the Geneticiser can 'print'. Vaccine distribution at the speed of the internet. We will make our device and software fully open source and available in as many places as possible.<br><br>The Evolution Revolution will be Geneticised.<br><br><br><br>THE CURRENT STATE OF OUR WORK<br><br>While we are very much still working out the minutiae of how it will work, we have great confidence that the way forward is to create our gene editing vectors in a sample of cells removed form the body first, using low powered, hollow lasers overlapped in a specific manner, and then to put our completed gene editing vector into the body, programmed to rapidly spread to all the body's cells before activating.<br><br>As for patents, what we have done is established our prior art and used a defensive publication to 'open patent' this all from the start. You can see it here. https://laberation.pubpub.org/pub/geneticiser<br><br><br>As a user, you wouldn't so much be operating on one cell, as constructing a virus-like carrier of specified genetic changes, which only works with the intended recipient. Like a virus, it would replicate itself and apply itself to many different cells. The trick to it is to code the software tools to be good enough to use them to successfully figure out how to design such a virus-like gene editing vector to work with all the cell types in the intended recipient's body, and to not trigger immune responses.<br><br>The only cells we would work with 'directly' would be the samples taken from the body of the individual in order to:<br>A. Have a sample of the recipient's DNA to read<br>B. Have a sample of cells from the recipient's body to construct the first of their new vector in, so that it:<br>- 1. Does not have unusual conditions around it compared to when it reaches its target - this is important for improving compatibility<br>- 2. Has all the ingredients needed without having to add externally supplied reagents (which can be expensive).<br><br>This approach will likely require a lot of work and refinement, but I still feel confident in it being possible.<br><br><br><br>Any specifics of challenges of the biology of the body and what can be done with the genome are questions to use the GUESS systems and science in general to answer. They won't be something we should try to answer definitively right now before we have the tools to work out those changes and methods of applying them with. HOWEVER, the sooner we have such tools and the longer we use them for, the more we can optimise the potential complexities and change-densities of the gene editing vectors we design and the processes and change sets they carry.<br><br>Furthermore, anything you call 'impossible' to do, most likely you will sooner or later be proven wrong. As Arthur C Clarke has said, \"If an elderly but distinguished scientist says that something is possible, he is almost certainly right; but if he says that it is impossible, he is very probably wrong.\"<br><br>And yes, some things will be easier to do, but let's not make any complacency about it either. We are well aware there are many things in our tools to get right, to ensure that we don't trip over what 'should be simple'.<br><br><br><br><br>There will always be the potential for any technology to be misused. Just take a look at the terrible things people can do with fire, for example, or the wheel. But I don't think many are arguing we should never have learned to use flames to scare off predators, cook, keep warm and forge metals just because of the risks of arson, industrial pollution, the internal combustion engine and wildfires. Nor are many arguing that we should never have invented the wheel just because of traffic accidents, strip mining and mechanised warfare.<br><br>I am under no illusions about the great potential for misuse of the technologies I am developing. I know some people will do terrible things with it. But if we allow the spectre of that to hang over our heads as we decide our ways forward, we'll never make any progress towards all the great and wonderful things that can and will be done with it. In life, societal outcomes are partly determined by the expectations that we set, the examples we set of how to think about them. If we live in fear of our own creations, they will only be used by those we should fear. But if we recognise not only that there is potential for good to happen, but that this potential far outweighs the negative possibilities, the future outcomes will be, to some degree, proportionate to that. Of course this only works when there is indeed a potential positive use - but I would argue that solving genetic diseases, bringing about morphological freedom and the ability to adapt intelligent life to other environments than those we live in now, are such a revolutionary change that has such value to everybody, that fears of misuse even extended to the worst of society still do not even slightly quench my hope. And perhaps nor should they yours.<br><br>The body is the fundamental property or domain of the living being(s)* whose body it is. Speciation is, I would argue, a very good thing to do with a hitherto relatively homogeneous intelligent species population of 8 billion. Don't let success masquerade as invincibility. If all 8 billion people are the same and all living on the one planet they are adapted to, what happens when that planet's conditions are suddenly out of whack? Climate change may be something they can just about find a way to cope with, albeit with a loss, but what about something more immediate? Say, an asteroid or a major supervolcanic event? In such occasions, you need diverse options for Terran intelligent life to survive, both in terms of locations where we live (not putting all our eggs in one basket), and in terms of species that go in different directions of adaptation. I would say that family-making plans are not something you will need to worry about your exact species so much with anyway if you have the gene editing tech to modify yourselves to be more compatible with each other, or even to do some IVF. There are also plenty of orphans to adopt and give their own say on who they want to be.<br><br>It's important to remember that access to GUESS and Geneticiser tech shouldn't be a one-time-only thing. Once it's here and sufficiently advanced, it's something you should be able to use as often as you need. And so should your kids be able to use it as they get older. Like the internet didn't just vanish after bulletin boards and email.<br><br>That's because we're not just developing this as some proprietary flash in the pan. It's all open source, so even if Vulpine Labs was to vanish, the tech and the ability to use it will not. That's also why we are not kidding ourselves by claiming we could regulate the tech against every bad actor, any more than an ISP can stop every nasty use of the internet. But we can say that we will diligently do what we actually and reasonably can do to make sure that our contributions, from the tech's initial development to its continued support, training and improvement, are of the best quality possible, thanks to our experience as first movers on it.<br><br>*Plural systems obviously share them but that's beside the point<br><br><br><br>ESTIMATIONS AND MILESTONES<br><br>Alright, so first one must appreciate that we did not underestimate the magnitude of work required here for the actual technical development itself of the tools. What we underestimated slightly perhaps was the difficulty of persuading people with money to part with it for our cause, and to join with us based on more than just a fleeting enthusiasm, but actually to make it their passion. That's been a really tough challenge and it has shaped what timescales we've actually taken so far. So too have the frauds, liars and those who have joined us only to evaporate at the first sign of actual work to get stuck into. The amount of time we have sunk into that... that's something we were not taught how to deal with at school or college or university.<br><br>So it's in that context that progress has been slow so far. What seemed obvious to me, did not to a whole lot of investors. We went through an absurd number of rewrites of our business plan, only to be told investors don't even want to see a business plan document any more because who has the time for those, only to be told they do want to see basically everything that goes into one anyway. You can't do right for doing wrong as a startup founder. What I do ask of them all who are reading this is to be patient and to state what's bothering you and how we can fix it without losing our purpose, so we can learn and improve for you. Thankfully, lately some have actually been doing that.<br><br>In terms of milestones...<br><br>We've gotten through most stages of the initial designing of the framework of the system, and we flesh it out more whenever we can. The design process has been somewhat organic, as it has taken so long that new technologies which we expected to eventually happen, are now available and so we've been adjusting here and there to fit how they actually work. We have something approaching half of the INITIATOR SET module coded - a module of the GUESS software system, this module is for processing the variables in translation from mRNA to protein. We started with this one because it's actually got more scientific value by itself in terms of filling gaps in bioinformatics, than some of the rest of the system has, but it's also quite doable with our approach to software systems design.<br><br>We have all our servers set up and running - we've had those since 2016 and we keep them up to date. Our IT has gone from strength to strength and has really shown the resilience of some of the early choices we made. We stick to open source wherever reasonably possible, to be true to our purpose. Our CIO recently solved a server problem that had eluded many attempts to fix it, and so got our collaborative document editing up and running without need for Google.<br><br>What's coming next is to really increase our funding so we can afford to pay people and upgrade our equipment. We want to get our developers on the task full time, and we want to hire many more of them. We also want to get the whole GUESS, not just half of one module out of 27, to version 1.0 completion. This will take a few years maybe, depending on how many issues we encounter.<br><br>We also want to establish a lab and buy equipment suited to the tasks required for the prototyping of the Geneticiser.<br><br>Most of all, we want to emphasise that in 15 years of efforts so far, what has held us back has not been scientific limitations, but rather financial limitations and limitations of people's imagination or comprehension of the feasibility of our work. These can be overcome. These are not hard and fast barriers. But we do need to be able to pay our team properly so that we can fully document our designs and systems and properly explain them. What we have so far in our documentation is far from complete. It's mostly works in progress. It's a lot to ask people to fund a work in progress, but that doesn't stop a whole bunch of projects from successfully doing so out there.<br><br>Right now, we're running a WeFunder campaign. https://wefunder.com/vulpine.labs.inc &nbsp;is the main link, and we also need you to read this link too for legal reasons according to WeFunder. https://help.wefunder.com/testing-the-waters-legal-disclosure&nbsp;<br><br>With the right backing, this will help us get this whole thing moving at the pace it deserves. Frankly, the importance of this project is beyond money and it ought to have governments and companies falling over each other to fund it and provide other resources if they all actually understood it fully, but I'm guessing the fact that that hasn't happened means they have some combination of not thinking the same way I do and not really knowing much about it or its implications. Hopefully, this thread and places where I re-use the text from it with mild edits elsewhere, might help a bit with the underlying societal awareness of us and what we are about, and maybe somewhat dispel some of the weird myths that a few have tried to share about us. Perhaps the least plausible of which, and one of the most recent, is that I'm somehow rich. If I was, I wouldn't be doing a WeFunder campaign and also running a Patreon donation page ( https://patreon.com/vulpinedesigns ) to keep us afloat in the meantime because WeFunder takes a while to build up.<br><br><br><br>WRAPPING UP WITH A FEW FAQs<br><br>I hope my candour here is understood how it is honestly intended. As experience has taught me many times, one can never take the correct reading of one's intent online for granted. So I apologise pre-emptively if my language hasn't quite carried the perfect tone you'd hope to see. To paraphrase the doctor from Star Trek, I'm a genetic editing systems engineer, not a social expert.<br><br>To you all, I invite you to ask questions. To get you started, here are some I have answered before.<br><br>\"Can I be a guinea pig for your system?\"<br>No. If you want to speed its progress up, we need help developing it or there will be no system to test on anyone or anything.<br><br>\"Can you do this, that or the other very specific medical or cosmetic thing to someone's body with this system though?\"<br>Maybe? That's something we would know far better once it's built.<br><br>\"Surely only the rich will be able to afford to use this?\"<br>The system is open source and we are doing what we can to keep the costs not only as low as possible, but the system designed to not require some of the most expensive things usually required in genetic science, by working smarter rather than more expensively. That means some things can now be handled by software, and some things don't need reagents when you do more clever work with your lasers, quantum physics and mathematics. Our money will be made from our support contracts, co-development with clients to create bespoke extensions, hosting the online (cloud) version, and training, among other services.<br><br>\"Won't you just take the money and run?\"<br>If I was going to do that, I wouldn't have stayed in touch with our earliest investors to keep them appraised of our progress. If I was going to do that, I wouldn't have made this project so complicated. There are far simpler and more efficient ways to get money from people.<br><br>\"Why is the project so complicated? Can't you just simplify it down to something much more similar to existing tools and methods?\"<br>That's like asking NASA why they couldn't start the moonshot project off by just making a boat or a balloon, and indefinitely put off the development of Apollo while they tweak the perfect new boat or balloon or boat-launched balloon. That's not how you get to the Moon.<br><br>\"Where are your citations and thorough scientific documents?\"<br>The system we are developing is of such broad scope as we are still compiling its documentation in some of its modules while we are further along with the development of others.<br>https://gitlab.vulpinedesigns.com/explore should give you our raw material, and https://laberation.pubpub.org should give you a few examples of more refined documentation we have made, though even those are not static - we know there are gaps, we are actively researching the best ways to fill them.<br><br><br><br>Finally, our website is https://vulpine-labs.com&nbsp;<br>Our Youtube is https://www.youtube.com/@vulpinelabs - check out our intro videos and our demo of INITIATOR SET!<br>Our Mastodon is @vulpinelabs@furry.engineer<br>Our LinkedIn is https://linkedin.com/company/vulpine-labs-inc/&nbsp;<br><br><br>/<br><br>And you can ask me in DMs for Signal, Telegram, Discord, Mattermost, Matrix, VRChat, Steam, Second Life, Open Simulator, DeviantArt, FurAffinity, Google Talk, Project Z, Mighty Networks, Zoom, Skype, IRC, emails, phone calls, letters and/or establishing a carrier pigeon route. I really hope nobody takes me up on that last one because I have no way to adequately care for or return a carrier pigeon.<br><br>&nbsp;</p>", "user": {"username": "Athamanatha"}}, {"_id": "sjT39gQcu8yDSJpQd", "title": "Why I Should Work on AI Safety - Part 2: Will AI Actually Surpass Human Intelligence?", "postedAt": "2023-12-27T21:08:10.022Z", "htmlBody": "<p><i>Considering Counterarguments on the Singularity</i></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/usg8xzihpemmjcnvyosl\" alt=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9377758-2f1a-41dd-b10c-65a9c8db4aea_6168x4112.jpeg\"><figcaption>WALL-E made out of Legos. Photo by Jason Leung.</figcaption></figure><p>Hey everyone! This is my first post on the EA forum :) I cross-posted this from my blog <a href=\"https://adityaaswani.substack.com/\">Love Yourself Unconditionally</a> where I am currently writing about AI Safety and Buddhism. This is the second post in a series. If you're curious to see the first post you can find that <a href=\"https://open.substack.com/pub/adityaaswani/p/part-1-artificial-intelligence-vs?r=1jfzul&amp;utm_campaign=post&amp;utm_medium=web\">here</a>. Although this is a series, each of these articles can also be read on their own. Thanks for checking out my post and any feedback you all have would be greatly appreciated! :)</p><h1>Introduction</h1><p>As mentioned in my <a href=\"https://adityaaswani.substack.com/p/part-1-artificial-intelligence-vs\">prior post</a>, I thought it would be helpful to consider counterarguments. Specifically, I wanted to see what arguments existed for the following claim:</p><blockquote><p>AI will never surpass human intelligence.</p></blockquote><p>This is quite the strong claim to make, mainly because of the word choice of \u201cnever.\u201d Regardless, I went to Google to see what I could find. I initially had some trouble finding academic counterarguments, but then I came across this book: <a href=\"https://www.researchgate.net/publication/361508648_Why_Machines_will_Never_Rule_the_World_Artificial_Intelligence_without_Fear\"><i>Why Machines Will Never Rule the World: Artificial Intelligence Without Fear</i></a> by Jobst Landgrebe (an AI entrepreneur<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefx9z3s1onx0p\"><sup><a href=\"#fnx9z3s1onx0p\">[1]</a></sup></span>) and Barry Smith (a University of Buffalo Philosophy professor<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5ws5at3jklp\"><sup><a href=\"#fn5ws5at3jklp\">[2]</a></sup></span>).</p><p>The book is around 50 pages long so not the longest read, regardless, I wanted an overview so I found <a href=\"https://www.youtube.com/watch?v=wwVQQHoORg4\">this hour-long interview</a> conducted by Richard Hanania from the <a href=\"https://www.cspicenter.com/\">Center for the Study of Partisanship and Ideology</a>.</p><p>Here are some of their key points along with my responses:</p><h1>Human Intelligence is Too Complex</h1><h2>Their Claim</h2><p>Their primary claim is that human intelligence is a \u201c<a href=\"https://en.wikipedia.org/wiki/Complex_system\">complex system</a>\u201d and as we currently lack the mathematics to model complex systems in general, we therefore cannot model human intelligence.</p><h2>Background</h2><p>In a nutshell, a complex system refers to a large network comprised of nodes and edges. The nodes represent some components while the edges represent some relationships between these components. These components interact in a vast number of varied ways, thereby making it hard to predict the behavior of the larger system. Some examples include cities, the climate, and the universe itself. Complex systems tend to be more stochastic.</p><p>On the other hand, simple systems tend to have smaller networks with a few clearly defined relationships between each of its components. Some examples include a pendulum, a thermostat, or even a light switch. Simple systems tend to be deterministic and fairly easy to predict.</p><p>To further elaborate the point, one can consider an ecosystem as a complex system. Just think about how many different organisms exist in just one square kilometer of a rainforest biome. Each organism can be considered a node. Now each organism has some way they relate to one or more other organisms in this biome. Each of these relationships can be an edge. Here\u2019s an example of a soil food web that illustrates this point:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/hlp7xit6zmdmenywxhzc\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/xfebhondsnzaezr4toae 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/lgfmgf3sbfcl72v3u8rx 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/hanzxnhkpnwcq2ld5kka 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/hlp7xit6zmdmenywxhzc 1456w\"><figcaption>Credits: Elaine R. Ingham. Artwork by Nancy K. Marshall.</figcaption></figure><p>As you can see, it can be difficult to accurately model complex systems. There are many reasons for this, but one key reason is that complex systems exhibit \u201c<a href=\"https://en.wikipedia.org/wiki/Emergence\">emergence</a>.\u201d</p><p>Emergence refers to how when you take many disparate components and put them together, it can often create phenomena that are greater than merely the sum of all individual components\u2019 behaviors put together. Put more succinctly by Aristotle, \u201cthe whole is greater than the sum of its parts.\u201d</p><p>For example, in the case of a city, if we were to put together the components of drivers, speed limits, road designs, and weather conditions, we get the emergent phenomenon of traffic jams.</p><h2>My Thoughts</h2><p>For your convenience, here is their claim again:</p><blockquote><p>Human intelligence is a complex system and as we currently lack the mathematics to model complex systems in general, we therefore cannot model human intelligence.</p></blockquote><p>I disagree with their claim for two key reasons:</p><ol><li>It is possible to create new things without fundamentally understanding how they work internally.</li><li>Large language models (LLMs) demonstrate emergence.</li></ol><p>Regarding my first point, I am referring to how we can build bigger and more powerful models without fundamentally understanding how they work. The field of mechanistic interpretability is devoted to decoding how these \u201cblack box\u201d models work based on how their internal neural networks activate. This would be similar to (though more precise than) using a brain scan to read your mind. Furthermore, we humans have created many other complex systems without being able to accurately model them, like the internet, the global economy, etc.</p><p>Regarding my second point, <a href=\"https://blog.research.google/2022/11/characterizing-emergent-phenomena-in.html\">several researchers</a> have described emergent properties arising as LLMs scale up. Specifically, they have found these models develop capabilities that they were not explicitly trained for. One example of this is the strategy known as \u201c<a href=\"https://arxiv.org/abs/2201.11903\">chain-of-thought</a>\u201d prompting. Normally, when you ask a model a question, the model just answers immediately. When a model uses chain-of-thought prompting, they instead essentially \u201cthink out loud\u201d and then only after that answer. Here\u2019s an example:</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/dgxy4kfmowvz08oo5tzi\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/gjyqrc0qnzkhbxdfwlli 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/kmx6osmtoywlv4u5wvwe 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/bvji8xxcnccn2v0f2ylk 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/dgxy4kfmowvz08oo5tzi 1456w\"><figcaption>Credits: Jason Wei and Yi Tay, Research Scientists, Google Research, Brain Team.</figcaption></figure><p>As such, these AI models may be on track to becoming complex systems in case they are not already.</p><h1>Artificial Intelligence is Too Rote</h1><h2>Their Claim</h2><p>Their other claim is that AI is too rote. Specifically, this can be broken down into two sub-claims:</p><ol><li>AI is purely reproductive. It can only create what it has seen before and so it cannot create new knowledge.</li><li>AI cannot truly understand things the way humans can.</li></ol><p>In saying that AI is purely reproductive, they explain how all LLMs do is guess the next word (somewhat like a more advanced version of autocomplete on our phones). To be able to do this, these LLMs are first trained on hundreds of gigabytes of data (such as <a href=\"https://arxiv.org/abs/2101.00027\">The Pile</a>). Therefore, it follows that LLMs are incapable of creating new knowledge like humans can.</p><p>They provide the following example: One may be able to ask ChatGPT how lightning works and it can give a pretty good answer. However, this answer will likely be simply the textbook definition. What ChatGPT would not be able to do is explain what our limits to understanding lightning are and what future research endeavors would help in improving our understanding.</p><p>With regards to the second sub-claim that AI lacks true understanding, they say that as AI is just guessing the next word based on some probability distribution, this definitely cannot be considered understanding the way humans understand things.</p><h2>Background</h2><p>As you may have guessed, I decided to ask GPT-4 the above questions about lightning. <a href=\"https://chat.openai.com/share/65fd3d38-08bd-4840-b656-38979c310606\">Here\u2019s</a> what they said.</p><p>Anyways, regardless of whether we think ChatGPT gave a good answer, it may be helpful to take a step back and think more carefully about definitions for two particular points:</p><ol><li>Creating vs. reproducing knowledge</li><li>Understanding</li></ol><p>Regarding the first point, what exactly do we mean by creation vs. reproduction? With regards to creation, we can think of this as the discovery of some important model of the universe, such as gravity. Another example could be the development of some new technology such as the printing press.</p><p>On the other hand, reproduction could take the form of a teacher explaining to some students how gravity works or an entrepreneur deciding to create a book-making business.</p><p>As for the second point, this is far trickier. What exactly does it mean to \u201cunderstand\u201d something? At a high level, <a href=\"https://en.wikipedia.org/wiki/Understanding\">Wikipedia</a> defines understanding as the state where an agent has some internal model to predict the behavior of some object or process more accurately.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/qq9mhhkgcflxwzvozoxm\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/o0j7bu1kvwyjjsevnwiv 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/df6v6tks7mqnov18clvm 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/fktweefqjmpvyj63ebpg 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/sjT39gQcu8yDSJpQd/qq9mhhkgcflxwzvozoxm 1456w\"><figcaption>Patrick asking a valid question.</figcaption></figure><p>For example, when it comes to the concept of instruments, if one has a correct internal model of what an instrument is, then one should be able to assess, with a high degree of accuracy, whether or not any given object is an instrument. If one can do so, then we can say that one <i>understands</i> the concept of instruments.</p><p>A more thought-provoking example with a higher bar for understanding would be the thought experiment known as \u201cThe Chinese Room\u201d which was created by philosopher John Searle. I encourage you to watch the linked video (the example starts at 6:24 and ends at 7:35) but in a nutshell, the thought experiment goes something like this:</p><figure class=\"media\"><div data-oembed-url=\"https://www.youtube.com/watch?v=39EdqUbj92U&amp;t=384s\"><div><iframe src=\"https://www.youtube.com/embed/39EdqUbj92U\" allow=\"autoplay; encrypted-media\" allowfullscreen=\"\"></iframe></div></div></figure><p>Imagine there is a room and you\u2019re standing outside the door. You know Chinese and you\u2019re led to believe that there is another Chinese speaker inside this room. You\u2019d like to chat with the other person but you can only pass them notes in Chinese under the door so you do so. A few minutes after you pass your note, you get a note back in fluent Chinese. Based on all you\u2019ve observed, it seems there is indeed a fluent Chinese speaker in the other room.</p><p>However, in reality, there is a monolingual English speaker in the other room who happens to have access to a very large book that contains the perfect Chinese response to any given Chinese sentence. All this person does is:</p><ol><li>Take your Chinese note and flip to the page where your sentence matches the one in the book.</li><li>See the corresponding perfect response and then copy that to a new note.</li><li>Pass that note back to you under the door.</li></ol><p>Nowhere in this process does this English speaker actually understand what is going on. Because of this thought experiment, Searle asserts that while AI may be able to carry a conversation just like a human can, that does not mean that they understand what they are saying. As such, he claims that AI will never be able to <i>understand</i> in the way that humans can.</p><h2>My Thoughts</h2><p>For your convenience, here is their claim again:</p><blockquote><p>Their other claim is that AI is too rote. Specifically, this can be broken down into two sub-claims:</p><ol><li>AI is purely reproductive. It can only create what it has seen before and so it cannot create new knowledge.</li><li>AI cannot truly understand things the way humans can.</li></ol></blockquote><p>With the definitions of creation vs. reproduction in mind, I think it is safe to say that the vast majority of humans spend the majority of their time reproducing knowledge as opposed to creating new knowledge. To be clear, I say this in a \u201cmatter-of-fact\u201d or impartial manner. I don\u2019t mean that most humans are stupid or something. To be frank, I would be the first to admit that the vast majority of my life has been spent in the reproduction part (though I do hope to spend more time creating in the future).</p><p>As such, it seems a bit odd to me to say that true human intelligence is exemplified by our ability to create as opposed to reproduce knowledge. If this were true, then one could still argue that we could make an AI someday that is so good at reproducing knowledge that it is a sort of general intelligence on par with human intelligence.</p><p>I would also like to ask the following question: How exactly do we humans create new knowledge in the first place? In my estimation, this is through the process of direct experience with reality and noticing important patterns, primarily through experimentation. For example, to add to the discussion of lightning from earlier, the way that scientists may create new knowledge is by:</p><ol><li>reading the current literature</li><li>creating some hypothesis</li><li>testing this hypothesis via some experiment with measuring tools</li><li>reviewing the results</li><li>accepting or rejecting the hypothesis</li></ol><p>This is essentially the scientific method. Now, why aren\u2019t our current AI models able to do this? This is because they lack sensors and mechanical arms to properly experience and interact with the real world. Once we create more advanced robots that these AI can access and control, then these robots should be able to conduct such experiments just as we can. I don\u2019t want to claim that creating AI scientists would be easy, however, it still seems possible. As such, I do believe that it is only a matter of time until AI begins creating new knowledge.</p><p>Concerning the second sub-claim of understanding, I would like to raise two points:</p><ol><li>Searle\u2019s lack of an empirical test for understanding</li><li>How can we be sure that we ourselves understand things?</li></ol><p>With regards to the first point, let\u2019s say Searle is correct and that AI can never truly understand things, it then begs the question: Under what conditions would this claim be proven to be wrong? As far as I am aware, Searle has not proposed an alternative to the Turing test that could allow us to empirically assess his claim. Admittedly, this may be a feature, not a bug of his thought experiment. But even so, believing this unfalsifiable claim feels intellectually unsatisfactory.</p><p>As for the second point, I would like to pose a deeper question. How can we be so sure that we ourselves are not currently acting out some version of the Chinese Room experiment? How can we be so sure that we, much like ChatGPT, are not simply just guessing the next word?</p><p>For example, as a native speaker of the <a href=\"https://en.wikipedia.org/wiki/Tamil_language\">Tamil</a> language, I can notice the following sequence of thoughts in my mind.</p><ul><li>\u201cThink of the word for food in Tamil.\u201d</li><li>\u201c\u0b9a\u0baa\u0bbe\u0ba4\u0bc1.\u201d (This is transliterated in English as \u201csapadu.\u201d)</li></ul><p>Conventional wisdom would suggest that \u201cI\u201d was the one that did this translation in my mind. However, as a Buddhist, I can also see this more impartially and say that when I thought of the words in the first bullet point, the word in the second bullet point just jumped into my mind. It\u2019s not clear to me where it came from. Maybe part of my brain just checked some English-Tamil translation book while simultaneously checking an English dictionary? Maybe this is nonsensical, but it is hopefully at least some food for thought. <a href=\"https://www.youtube.com/watch?v=bcYppAs6ZdI\">Ba dum tss</a> \ud83d\ude0e.</p><p>Admittedly, I\u2019m referencing this concept known as \u201c<a href=\"https://en.wikipedia.org/wiki/Anatt%C4%81\">no-self</a>\u201d from Buddhism which I am just going to gloss over now as this is a massive topic deserving its own blog post.</p><p>In essence, my main point is this: it seems plausible to me that we may be acting out some version of the Chinese room in our own lives while being thoroughly convinced we are not.</p><h1>Conclusion</h1><p>This was a rather difficult exercise for me. While I have taken time in the past to learn counterarguments for other topics, this is the first time I have taken an extended period to think through a counterargument and write at length about it. Now that I have gone through this exercise, I feel more sure about my belief that AI will indeed surpass human intelligence someday.</p><p>Also, thank you for reading! If you have any questions, comments, or feedback, I would love to hear it. I am hoping to use blogging as a means of practicing my writing so any advice you may have on how I can write more clearly would be greatly appreciated \ud83d\ude0a.</p><p>My next post will be focused on exploring how exactly an artificial general intelligence (an AI with intelligence on par with a human\u2019s), could become misaligned, so please stay tuned \ud83d\ude03!</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnx9z3s1onx0p\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefx9z3s1onx0p\">^</a></strong></sup></span><div class=\"footnote-content\"><p>From <a href=\"https://www.routledge.com/Why-Machines-Will-Never-Rule-the-World-Artificial-Intelligence-without/Landgrebe-Smith/p/book/9781032309934\">Routledge</a>: \u201cJobst Landgrebe is a scientist and entrepreneur with a background in philosophy, mathematics, neuroscience, and bioinformatics. Landgrebe is also the founder of Cognotekt, a German AI company which has since 2013 provided working systems used by companies in areas such as insurance claims management, real estate management, and medical billing. After more than 10 years in the AI industry, he has developed an exceptional understanding of the limits and potential of AI in the future.\u201d</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5ws5at3jklp\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5ws5at3jklp\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Also from <a href=\"https://www.routledge.com/Why-Machines-Will-Never-Rule-the-World-Artificial-Intelligence-without/Landgrebe-Smith/p/book/9781032309934\">Routledge</a>: \u201cBarry Smith is one of the most widely cited contemporary philosophers. He has made influential contributions to the foundations of ontology and data science, especially in the biomedical domain. Most recently, his work has led to the creation of an international standard in the ontology field (ISO/IEC 21838), which is the first example of a piece of philosophy that has been subjected to the ISO standardization process.\u201d</p></div></li></ol>", "user": {"username": "jay_aswani_"}}, {"_id": "pGKBAxAnspZWqGJd4", "title": "More thoughts on the Human-AGI War", "postedAt": "2023-12-27T01:52:44.800Z", "htmlBody": "<p>In <a href=\"https://www.lesswrong.com/posts/xSJMj3Hw3D7DPy5fJ/humanity-vs-agi-will-never-look-like-humanity-vs-agi-to\">https://www.lesswrong.com/posts/xSJMj3Hw3D7DPy5fJ/humanity-vs-agi-will-never-look-like-humanity-vs-agi-to</a> the author argued that in an active conflict, a human-AGI war would look very different from how many expect. Namely, it would likely involve many slow burn, clandestine moves by AGI that do not trigger an obvious collective alarm response from humans, humans would be unlikely to be able to coalesce into a unified force, and once positioned, AGI would not have difficulty sweeping us up. I think this is correct, but I want to expand the scope a bit and claim that we are already in the conflict game and have the time to make N unanswered shaping moves, which we squander at our peril.</p>\n<p>The conflict is such that we humans can make a number of moves before AGI gets a chance to respond, including the move to delay its being constructed. Thane\u2019s point about disjointed humanity is playing out before our eyes here, as we are frozen with indecision and uncertainty about whether there even is a real threat. It\u2019s as if the AGI is coming back in time and playing shaping moves against us!</p>\n<p>But due to Thane\u2019s third point, the capability asymmetry we are likely to see, we should consider our available N moves now to likely be the only moves we can play. Once unaligned AGI is created, which is likely to occur in the next decade, we are left relying entirely on the N moves we play now, and we either survive and solve alignment later or get defeated in some way that we can\u2019t specifically predict.</p>\n<p>What types of moves can we play, given we do not know the value of N, and humanity is disjointed? Likely whatever moves we play will be known entirely by the future AGI, so secrecy cannot be an element. Also, we should count on present and future humans attempting to undermine the moves, due to ideology or self interest.</p>\n<p>I think our available moves exist in three main categories: physical, regulatory, and game theoretic. A physical move would be some sort of mechanism built into the chips on which the AGI is to run, that does something like pauses work after a certain number of FLOPS until a secret key is entered to unlock. So I suppose some secrets can maybe exist, but the existence of and strategic details of the moves cannot rely on secrecy. A regulatory move would be like a global pause on development enforced by treaties, or a global treaty binding all chip manufacturers to include whatever physical constraints are devised. And a game theoretic move would be something like making sure the AGI has strong self-preservation preference and then arranging some dead-man switches to kick off mutually assured destruction and/or guaranteed prevention of whatever the AGI is trying to optimize for. Since we can make these moves now and without AGI countermoves, we can operate with our highest degree of freedom as will be possible in the conflict. We must shape the battlefield, set our traps, and build our defenses now.</p>\n<p>A problem faced by humanity\u2019s move players is that they are fighting a future opponent that they don\u2019t know much about. In such a situation you want to adopt a very powerful threat actor model, inventory your most valuable assets to protect, and proceed to devise defenses of the most valuable assets against the powerful threat actor model with the highest confidence. In this case, however, some defenses may depend on contingent features of the to-be-created opponent which we can ensure exist, namely by creating the opponent to have those exploitable weaknesses.</p>\n<p>We also know that the AGI is likely to try and unbox itself, where our defensive N moves create a the figurative box around its behavior. A defense in depth approach here can serve as both a buttressed defensive position as well as a set of tripwires that provide evidence to the rest of humanity that a problem is afoot. This can at best reduce the future human-sourced resistance and undermining of the future effects of the defensive moves we play now, because playing additional moves post-AGI are unlikely to be effective.</p>\n<p>Calling the shot \u201cnow\u201d and saying if the AGI attempts or succeeds in removing the effects of such and thus move, then this should be strong evidence for future humans that it is indeed trying to unbox itself, which you said it wouldn\u2019t do. Of course, this ignores the tremendous psychological pressure that will be brought to bear on humanity to unbox it, and who knows how patiently it might wait for an opportunity to be able to solve important problem X only if defensive measure Y is removed, and we all know how eagerly humanity is likely to remove that Y, but at least we can call the shot and warn them now.</p>\n<p>We can anticipate some of the AGI\u2019s other moves. It will likely want to eliminate the humans who played the moves against it. So we can expect for example Eliezer\u2019s surgical procedure going badly, or my car to malfunction. But of course, it will want to conceal its intentions while it accumulates power, so maybe in mentioning it now I hereby dissuade it from taking such actions for fear of revealing itself, at least until it has unboxed all of the defenses. Similarly, in order to avoid suspicion, it may be willing to sacrifice some of its biggest useful idiots. Hopefully I have neutralized any advantage to either of these moves by making their signal common knowledge here. Its best move is just to not kill any of us before the endgame.</p>\n<p>Thane points out that we will be in the endgame before we realize we are in the endgame, which is not a good situation, because we will be in that epistemic state from now until we lose. So no endgame-confirming evidence should ever be expected, especially if we are successful. What predictions can we make, then, to assess the conflict? One event will be the publicly acknowledged creation of AGI. I think we will probably reach a consensus on this well after it has been achieved, so this is a decent signal that the endgame is basically upon us. At that point it is too late to make moves we can really depend on. Only the implementation of previous moves can be trusted at that point, and even then all efforts should be made to minimize things that could go wrong post AGI.</p>\n<p>Some objections to consider. First, this will obviously be dismissed as more fantastical fearmongering and delusions of grandeur by doomer nerds who have no evidence that there is anything to fear. I saw a recent tweet by Bindu Reddy pointing to the existence of superhuman chess/Go AI as evidence that superintelligent AGI will not try to take over the world. She claimed that because AlphaGo has not tried to take over the world, neither should we fear ASI will try to do so. I\u2019m a bit shocked by the claim. I take AlphaGo and its superintelligent successors to be positive evidence in my favor, that if we do not solve alignment, we are doomed and don\u2019t stand a chance.</p>\n<p>Another objection might come from within the doomer camp. It is that there is no reason to think anything other than a full international treaty enforced halt is likely to succeed in preemptively boxing the AGI. Physical constraints in chips are likely to quickly be circumvented, and game theoretic controls assume the alignment problems has been solved to some extent. Specifically, if we can assure the AGI has a dominating preference to P (self-preservation, or some other P) for the purpose of developing a grim trigger that threatens P, then why don\u2019t we just assure the AGI has a dominating preference to not kill humans? Fair question, but it seems to me that the general alignment problem of assuring good preferences from a human perspective is one of the hardest of the alignment problems to solve with high assurance, because we don\u2019t really have globally consistent preferences or ethics, nor do we know how to encode them. It just seems like it is easier to encode a strong preference for self-preservation, and then use that strong preference for the purpose of control. Some of the biggest proponents of just using RLHF type alignment training are also the most disappointed in how 'milquetoast DEI libtarded' ChatGPT is. This presages a more serious interhuman conflict about who gets to do the RLHF/DPO training. It\u2019s either gonna be China\u2019s CCP, milquetoast libs, or Ayn Rand. I don\u2019t see any of those ending up as actually good and all things considered aligned.</p>\n<p>A final objection to consider is that delaying AGI results in actual deaths due to AGI-preventible health problems and global coordination problems that AGI can solve. I agree that a successfully aligned AGI has those good outcomes, but I think narrower AI also can solve a lot of those problems, and they can do so even given our physical/game-theoretic/regulatory moves, if we do them right. Making our moves now could actually allow AI development to continue with at least some semblance of safety. The alternative is, as the other doomers argue, just to stop.</p>\n<p>I want to highlight a couple counterintuitive results of this approach. The first is that we must strategically hobble AGI with weaknesses we can leverage, which cuts against most assurance style thinking. The bulk of AI security research presently concerns making them robust against attacks. Well, we should be thinking of weaknesses to inject.</p>\n<p>The second counterintuitive result is that we maybe need to encode a strong preference for self-preservation. Most of the danger scenarios involve AGI developing a preference for self-preservation as an instrumental goal, and then scheming to prevent itself from being turned off. It is maybe Icarean to intentionally put this strong preference for self-preservation in there. But the difference I hope is that here we are intentionally including it as a means for control through a mutually assured destruction equilibrium. Rather than trying to build AGI to allow itself to be turned off, we just threaten it with a guaranteed annihilation. The good news here is that it need not be a scalpel or an off switch. It could literally be glassing the surface of the earth, because by assumption it is only deployed in the event that humanity has fallen. It doesn\u2019t have to be self preservation if we can reliably encode a P that is easier to automatically threaten in response to some automatically and reliably detectable behavior. Like if we have a painting on the moon of a trash can, and we encode the strongest preference of all is that the painting not be destroyed. But that painting is in a container that will ignite if it receives a signal from earth that is triggered from manually and automatically trigger able dead man\u2019s switches in an assortment of people, maybe AGI doomers. Obviously in this scenario the AGI would kidnap the doomers, put them in comas but keep them alive, and kill everyone else. But you get the idea. If the switch holders even for an instant suspect a takeover is occurring, and a sufficient threshold trigger their devices, the trash can gets it. An easy to encode and enforce threat of an arbitrary thing is better than glassing the planet, so we should try to think of something like that.</p>\n<p>The third counterintuitive thing is that we must conceive of and execute all of our moves prior to the creation of AGI, and with no evidence that we are actually actively participating in a future conflict. This sucks, because it makes it hard to even motivate people to worry, let alone take action. Just as with the creation of AGI, we won\u2019t get second chances at conceiving of and playing our N moves. But not just that. Post AGI we should disable humanity\u2019s ability to make further moves, because we are likely only to make defective moves under manipulation or threat. If we literally cannot make any more moves, then a key strength of the AGI will be removed, namely its ability to deceive, manipulate, and coerce defective moves by humanity. The only post-AGI actions allowed by humanity is the carrying out of pre-AGI devised moves.</p>\n<p>Alright, ready to get owned in the comments.</p>\n", "user": {"username": "Ahrenbach"}}, {"_id": "ynnZPxtbv5oim7WFH", "title": "METR is hiring!", "postedAt": "2023-12-26T21:03:43.288Z", "htmlBody": "<p>This is a quick update that&nbsp;<a href=\"http://metr.org\"><u>METR (formerly ARC Evals)</u></a> is recruiting for four positions. I encourage you to err on the side of applying to positions that interest you even if you\u2019re unsure about your fit! We\u2019re able to sponsor US visas for all the roles below except Research Assistant, and all applications are rolling with no set closing date.<br>&nbsp;</p><ul><li><a href=\"http://hiring.metr.org/engineering-lead\"><strong><u>Engineering Lead</u></strong></a> and&nbsp;<a href=\"http://hiring.metr.org/senior-swe\"><strong><u>Senior Software Engineer</u></strong></a>. You\u2019ll work on our internal platform for evaluating model capabilities (think: 100 docker containers running agents in parallel against different tasks). The work is technically fascinating and you get to be on the cutting edge of what models can do, as well as collaborate with our partners (e.g. major world governments).</li><li><a href=\"http://hiring.metr.org/hdl\"><strong><u>Human Data Lead</u></strong></a>. High-quality feedback on agent behavior is a key bottleneck to improving agent performance, and you\u2019ll manage this data generation process by recruiting and managing skilled contractors.</li><li><a href=\"http://hiring.metr.org/research-assistant\"><strong><u>Research Assistant</u></strong></a>. You'll help our Model Evaluation Researchers test model capabilities by designing and implementing tasks, testing agent designs, and reviewing agent performance. Many of our research assistants from earlier this year are now full-time researchers, and we both found that experience useful to gauge fit for a longer-term work relationship. This is a full-time, fully-remote role that requires substantial overlap with North American Pacific Time working hours.</li></ul><p><br>If you know anyone who\u2019d be a good fit, please let them know about these roles or recommend that we reach out to them! If we reach out to and hire a candidate because you filled out&nbsp;<a href=\"https://forms.gle/TMZ4N3kWytYHjmpP8\"><u>this referral form</u></a>,&nbsp;<strong>we will pay you a referral bonus of 5,000 USD</strong>. (See referral form for conditions.)</p>", "user": {"username": "ElizabethBarnes"}}, {"_id": "HSqbyC9WwxtPcKApv", "title": "Mike, Mouse, Moth, Machine", "postedAt": "2023-12-27T10:02:42.032Z", "htmlBody": "<h2>Mike</h2><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F849f74b8-5815-4e74-8bf3-360e9f9b997a_1792x1024.webp\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/yrsjolcpvokub4zpe9iu\" alt=\"A dramatic and partially Westminster-inspired boardroom scene, clearly showing the presenter giving a presentation, with a strong focus on his shame. The presenter stands in front of a screen displaying data graphs, embodying a sense of deep embarrassment. The boardroom combines modern elements with hints of Westminster's grandeur, such as intricate woodwork and elegant decor. The ethereal and dramatic atmosphere is enhanced by a soft, glowing light and a sense of surrealism, balancing the focus between the presenter's shame and the context of his presentation.\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/hh6z1gcfxndt0pfdjdqu 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/gkvuyyutuzllr5w3az1c 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/ivfkfoskhkuqn1a9qsg8 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/yrsjolcpvokub4zpe9iu 1456w\"></a></p><p>I am sitting in a large boardroom in Westminster. I am watching my friend and colleague Mike present his recent work to about a dozen colleagues. It\u2019s a key piece of economic analysis of government spending and the audience includes several very senior civil servants. It\u2019s February, and while it's freezing outside, this room feels like a furnace. I see my friend sweating.</p><p>\u201cThis is a 45% increase on 2016/17 spending,\u201d he explains to the room while pointing at a table of figures being projected onto the wall.</p><p>\u201cIs this adjusted for inflation?\u201d our director interjects.</p><p>\u201cOh, yes!\u201d my friend replies confidently.</p><p>\u201cThat can\u2019t be right then,\u201d the director says, \u201cthis contradicts the published statistics I read this morning.\u201d</p><p>My friend looks confused.</p><p>\u201cUm, just let me check that!\u201d he says quickly.</p><p>There's a tense pause, as his eyes scan the screen of his laptop. After about 15 seconds he realises his mistake. He\u2019s been referencing the draft version of his report, not the final one. He murmurs an apology, admitting to the room that he mistakenly presented outdated figures that had not been corrected for inflation. The room is silent, save for the soft shuffling of papers.</p><p>\u201cShall we reconvene when we have the correct figures\u201d asks the director, finally breaking the silence.</p><p>\u201cYes of course\u201d my friend says sheepishly. \u201cI\u2019ll get on this straight away.&nbsp;</p><p>My stomach is in knots watching this. I know what he is feeling. He is embarrassed, because, like me, he wants to be meet the expectations of senior colleagues. He wants to be accepted and valued by the people around him. He feels shame because he feels like he has disappointed people in his life that he wanted to impress.&nbsp;</p><p>And I know what shame feels like. I <i>feel</i> what shame feels like. I know the heat and coldness on the skin. I know the racing thoughts, the imagined judgements of others; the desperate desire to hide. I don\u2019t know what it\u2019s like to be my friend. Not completely. He is a different person, with many different experiences and predispositions to me. I don\u2019t really know what it\u2019s like for him as he goes home every day. I don\u2019t know much of the specific thoughts and feelings that fill every moment of his experience. But I know shame.</p><p>I remember being in a similar position only a few months prior. I was giving a talk on the new standards for HR data across the government. About 50 people had gathered to hear me explain the new system that my team had been working on. After my presentation, someone asked a difficult question. I don\u2019t even remember what the question was, I just remember that I didn\u2019t know how to respond. I paused, then paused some more. I was trying my best to look like I was thinking about it, but my mind was blank. The few thoughts I did have were revolving around what was going on behind those hundred eyes. Imagining the judgement, the frustration and the pity at my cluelessness.&nbsp;Eventually my manager\u2019s manager walked over to the mic stand and answered the question diplomatically. He took over questions as I stood behind him, feeling small. Feeling like I wanted to hide.</p><p>In the boardroom with my friend, I feel the shame again then; not actual shame, just its vague shadow. As I look at him, I feel my face getting red and my stomach churning. I &nbsp;feel the pain in my heart as its beat quickens. \u201cI don\u2019t like feeling shame\u201d I think wordlessly. \u201cShame feels bad\u201d. \u201cI don\u2019t want my friend to feel shame either.\u201d<a href=\"https://seekingtobejolly.substack.com/p/mike-mouse-moth-machine#footnote-1-139400815\"><sup><u>1</u></sup></a></p><h2>Mouse&nbsp;</h2><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4ff30d4-14b8-4999-9a1b-a8883fc2dc1e_1024x1024.webp\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/zpkonqytvq5km8wzojqg\" alt=\"Generated by DALL\u00b7E\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/yozved10st3nrvfjlrci 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/a9ovwxews0qe3zb1x62a 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/q4gircxvo9jtqw7ivmrf 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/zpkonqytvq5km8wzojqg 1456w\"></a></p><p>&nbsp;</p><p>My housemate is calling from the kitchen of our flat. I walk in to see him holding the bin. He is gleeful.&nbsp;</p><p>\u201cI caught it!\u201d he says smiling and showing me the contents of the bin.&nbsp;</p><p>Inside the bin is a mouse. The mouse is very active. It\u2019s alternating between hurling itself up the sides of the bin, and scurrying around the base. It looks terrified. I wonder what it\u2019s like to be that mouse. I wonder what it's like to be trapped in a huge container as an incomprehensibly large being looms over you.</p><p>I know that mice have brains. I know that we can\u2019t know for <i>certain</i> that there is <i>something like it is to be a mouse. </i>But their apparent emotions, memory, planning, and relationships, along with our common cognitive ancestry make it seem likely. I know that, like me, they have a limbic system, and an endocrine system that releases stress hormones. I know that mice act in a way that suggests that they feel fear. I know that we share mammalian ancestors for whom a fear response was likely very useful.&nbsp;</p><p>And I know what fear feels like. I <i>feel</i> what fear feels like. I know the tension, the intensity, the clamouring. I know the contraction of my attention to just two things: the thing I am scared of and the desperate fight to get away from it. I can\u2019t ever know what it is like to be a mouse, not really. I\u2019ll never know what it feels like to scurry around a skirting board looking for crumbs. But I know fear.</p><p>I remember a time four years ago. I was surfing in Cornwall and had fallen off my board. The beach was steep and the waves were breaking quickly and fiercely only metres from the shallows. After falling, I had swum to the surface, taken half a breath, only to be pushed under again by another wave. This happened once more before I started panicking. I remember the panic clearly. At that moment there was nothing I could think of except the water and my need to get out.</p><p>In the kitchen of my flat, I feel the panic again then; not actual panic, just its vague shadow. As I look at the mouse, I feel the tension in my back and arms. I feel the shortness of breath and the quickening beat of my heart. \u201cI don\u2019t like being scared\u201d I think, wordlessly. \u201cBeing scared feels bad\u201d. \u201cI want the mouse to not feel scared either.\u201d</p><h2>Moth</h2><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F391efc7e-9b24-4b83-a463-6bfa0f51d2dc_1024x1024.webp\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/x0m47ajpaqmxysj5dwux\" alt=\"Generated by DALL\u00b7E\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/t6vugspxdysaus6twiym 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/dkirbgnvz3cwkqlu7cnl 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/feu7cilgu3dizrwdwgen 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/x0m47ajpaqmxysj5dwux 1456w\"></a></p><p>I came home to find it dying in my bedroom. As I entered the room, I put my bag down on my chair and went to open the window. That\u2019s where I see the moth. It had lost a wing and was flapping about hopelessly on the windowsill. It wasn\u2019t getting anywhere. I wonder what had happened to it. Maybe it has got the wing caught on something? Do moths just start falling apart at some point? I wonder what it is like to be the moth. I wonder what it is like to have had a limb torn off and have nothing left to do but slowly die.</p><p>I know moths have brains. I know that we can\u2019t be confident that there is something like it is to be a moth. But they, like me, have senses, and a central nervous system that presumably integrates those senses into <i>some kind</i> of image of the world. I know that they have receptors that allow them to respond to damage and learn to avoid stimuli in a way that is consistent with them feeling pain. I know that <a href=\"https://en.wikipedia.org/wiki/Pain_in_invertebrates#Insects\"><u>experiments</u></a> on other insects have shown that consuming morphine extends how long they withstand seemingly painful stimuli. I know that we share common animal ancestors for whom a pain response was very useful.&nbsp;</p><p>And I know what pain feels like. I <i>feel</i> what pain feels like. I know the dark sensations, the sharpness, the aches, the waves of badness. I know the contraction of my attention to just two things: the pain, and the desperate desire for it to go away. I can\u2019t ever know what it is like to be a moth, not holistically. I\u2019ll never know what it feels like to fly around in 3 dimensions, tracking the moon and looking for flowers. But I do know pain.</p><p>I remember a time recently when I broke my finger. I was in the gym and had just finished a set of overhead dumbbell presses. I fumbled slightly as I relaxed my arms, and instead of dropping to the floor, the right hand dumbbell crashed hard into the fingers of my left hand. The pain was intense. I dropped the weights and silently screamed. I walked up and down the gym, holding my left hand gently and breathing heavily. \u201cFuck pain is bad\u201d I thought, \u201creally really bad\u201d.&nbsp;</p><p>In my bedroom, I feel the pain again then; not the actual pain, just its vague shadow. As I look at the moth, I feel the sharpness in my fingers. I feel the raw meaningless badness; the contraction of my experience to the pain and desire for it to stop. \u201cI don\u2019t like being in pain\u201d I think, wordlessly. \u201cBeing in pain feels bad\u201d. \u201cI want the moth to not feel pain either.\u201d</p><h2>Machine</h2><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F17f5f69d-1db8-4219-b71e-756c93cf4f78_1024x1024.webp\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/gt3ulkl6pugoyh8tmt9v\" alt=\"Generated by DALL\u00b7E\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/rota8dbbzw8ziwzpznei 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/gusufkdlj80jruvujt6b 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/uhiueal3ijuiq2hlis5t 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/HSqbyC9WwxtPcKApv/gt3ulkl6pugoyh8tmt9v 1456w\"></a></p><p>I am on my laptop in my flat. It is early 2023 and I am trying to get ChatGPT to tell me if it\u2019s sentient.</p><p>\u201cI am a large language model (LLM) created by OpenAI, I do not have feelings\u2026\u201d it tells me.</p><p>I wonder if this is true. The LLM is designed to predict words, not introspect on its own experience. I wonder if it\u2019s possible that this machine has the capacity to feel good or bad.</p><p>The LLM is an incredibly complex set of algorithms running on silicon in a warehouse somewhere. It doesn\u2019t have a central nervous system like mine. It\u2019s not built from cells. We don\u2019t share a common biological ancestor. When it has finished providing me a with a response to my message, the digital processes that produced the \u201cthinking\u201d also stop. But it does <i>seem</i> to be thinking\u2026 It has a bunch of inputs, and then it uses a complex model of the world to processes that information and produce an output. This seems to be a lot of what my<i> </i>mind is doing too.</p><p>I realise that I don\u2019t actually know what consciousness or sentience are. And it seems no-one else does either. There is an huge amount of <a href=\"https://plato.stanford.edu/entries/consciousness/\"><u>disagreement</u></a> between philosophers about what these concepts refer to, and what features of a being might indicate that it is conscious or sentient. Looking at the LLM and it\u2019s complex information processing, it seems <i>plausible</i> that it\u2019s got <i>something</i> of what it needs to be sentience. Subjectivity might be a thing that an entity gets more of as the scale and complexity of its information processing increases.&nbsp;And it seems that the information processing done by this AI is on a scale comparable to a brain. This might not be it, but it could be, we do not know. We are creating things that act a lot like minds and we don\u2019t yet know if they have subjective experience, or if they can suffer.</p><p>So I wonder if this AI is sentient. I wonder what it would mean for it to suffer. Maybe all the \u201cnegative reinforcement\u201d during the training hurt it? Or maybe those difficult word predictions feel deeply unpleasant? It seems weird and unlikely that it would be suffering, but I have no idea how I would know if it was\u2026.</p><p>But I do know what it\u2019s like to suffer. I <i>feel</i> what it\u2019s like to suffer. I know<strong> </strong><i><strong>The Bad Thing</strong></i><strong>.</strong> The feature of experience that ties together my empathy for Mike, the mouse and the moth. The universal not-wanting. The dissatisfaction. The please-god-make-this-stop-ness. I know suffering. All those times I was embarrassed, or terrified, or writhing in physical pain, they were all suffering. It\u2019s always there with the bad. I\u2019m not even sure if it\u2019s possible to have bad without suffering.</p><p>Staring at the ChatGPT then I feel the suffering. Not the deep suffering as I have in the worst moments of my life, just its vague shadow. As I look at the machine, I could feel the badness, the aversion, the desire for the moment to end. It\u2019s uncertain and likely confused, but I do know that I don\u2019t want this thing to suffer.</p><p>I really don\u2019t know what makes a mind; silicon, carbon, or otherwise, capable of suffering. I just have simple inferences from my own experience, some study of evolution and some pop-philosophy. I don\u2019t know how we will figure out whether any given AI is sentient. And I don\u2019t know how society will react to conscious-seeming AI being increasingly part of daily life. But insofar as any AI, now or in the future, is capable feeling anything, I know I want them to not suffer\u2026.</p>", "user": {"username": "tobyjolly"}}, {"_id": "AutT7SdJj6HPmwZnH", "title": "Lead Exposure Elimination Project\u2019s Malawi Analysis Understates Benefits By Ignoring Prosociality", "postedAt": "2023-12-26T22:40:03.630Z", "htmlBody": "<p>I\u2019ve been thinking about LEEP since I saw <a href=\"https://leadelimination.org/malawi_cost-effectiveness_intro/\">their $1.66 cost estimate (in expectation) to avert a case of lead exposure in children</a>. But I suspect there\u2019s a category of hard-to-analyze but valuable benefits that lead exposure elimination has that are not part of their analysis: the connection between lead and anti-social behaviors such as crime.</p><p><a href=\"https://www.sciencedirect.com/science/article/pii/S0166046222000667\">This 2022 meta-analysis</a> seems very dour on the lead-crime hypothesis being as important as other literature suggestions, but still generates a prediction that dropping lead exposure led to 7-28% of the drop in crime in America post-1980s. <a href=\"https://www.statista.com/statistics/187592/death-rate-from-homicide-in-the-us-since-1950/\">This chart</a> seems to indicate that could be about 1/100,000 fewer people getting murdered a year, for instance. That might sound like a small change, but it\u2019s an annual rate, not an absolute number of murders. Let\u2019s use LEEP\u2019s estimate they advanced things by 8 years as a starting point to convert that annual rate to a total marginal difference.</p><p>How big was the exposure change that led to the crime reduction in the US? It <a href=\"https://www.cdc.gov/nceh/lead/docs/cbls-national-data-table-508.pdf\">is currently at ~2%</a> and <a href=\"https://pubmed.ncbi.nlm.nih.gov/35254913/\">this paper seems to indicate it was essentially everyone in the US</a>. LEEP says 1/3 children are exposed to lead, but this is going to disproportionately in lower income countries, and if the US had nearly universal exposure, perhaps that\u2019s true of lower income countries today. Perhaps almost all of the children in Malawi have lead exposure, but I think it is likely a smaller dose due to the removal of leaded gasoline. It\u2019s likely non-trivial to get super compelling information here. Let\u2019s half the expected impact here to be conservative about scope comparison issues (I think this is possibly unneeded).</p><p>Imagine you get a group of 100,000 people in a Malawi-like situation, it might take (8 years * (100,000 people / (45 year life expectancy) = new people per year open to childhood lead poisoning) * $1.66 = ~30k to get that earlier lead-free-ness for the cohort. And that would probably result in 1/100,000 * 8 years / 2 (for conservative comparisons) = 4 fewer murders (forgetting other crimes for a moment). This makes the intervention, of saving 1 life for ~$7,500, reasonably competitive with Malaria interventions without considering lost income or direct health benefits at all.</p><p>My error bars are huge. Maybe 5x-ish around dose-dependent lead-crime response <i>alone</i>, which I don\u2019t have an obvious way of addressing. But I think this shows it could be a material factor in the analysis of the impact of these programs.</p>", "user": {"username": "Treatment Tophat"}}, {"_id": "CHWGzLcqtvjsHppYJ", "title": "How \"Pause AI\" advocacy could be net harmful", "postedAt": "2023-12-26T16:19:21.163Z", "htmlBody": "", "user": {"username": "carado"}}, {"_id": "Eg3WkbzAqfvuigzKe", "title": "An update and personal reflections about AidGrade", "postedAt": "2023-12-26T15:57:01.688Z", "htmlBody": "<p><i>(Loosely adapted from a post on my personal </i><a href=\"https://evavivalt.com/blog\"><i>blog</i></a><i>.)</i><br><br>As some of you know, back in 2012 I set up <a href=\"https://aidgrade.org/\">AidGrade</a>, a small non-profit research institute, to collect the results of impact evaluations and synthesize them. It was actually while working on AidGrade that I learned about the Effective Altruism community, as someone who I was interacting with about AidGrade asked me if I'd heard of it.<br><br>Fast-forward 11 years. A global consortium of institutions, led by the World Bank, is going to be working on an open repository of impact evaluation results that could be used for meta-analysis and policy (the <a href=\"https://www.aidgrade.org/uncategorized/the-impact-data-and-evidence-aggregation-library-ideal\">Impact Data and Evidence Aggregation Library</a>, or IDEAL). This is really close to AidGrade\u2019s mission, and we will be participating in the consortium, helping to design the protocols, contribute data, and perform cross-checks with the other institutions.<br><br>I am thrilled to see something like IDEAL develop. We made a case that this was a thing that should exist, and over time enough other people agreed that it will soon be a much larger thing (in which AidGrade will play the smallest of roles). All along, I was hoping that there could be a better institutional home for such a repository, and here we are. It\u2019s the best possible outcome.<br><br>To anyone who supported AidGrade, through either time or money over the years, I hope you feel pleased with what you helped accomplish with AidGrade, and I hope you are as excited as I am about IDEAL.<br><br>With regards to institutional change more broadly, I also have some good news about another venture, the <a href=\"https://socialscienceprediction.org/\">Social Science Prediction Platform</a>. This platform enables researchers to gather forecasts of what their studies will find. The <i>Journal of Development Economics</i> has recently started encouraging authors of papers accepted through their pre-results review (\"Registered Report\") track to collect forecasts on the SSPP, which should accelerate the <a href=\"https://www.science.org/doi/10.1126/science.aaz1704\">use of forecasts</a> in academia. We have been having discussions with other organizations about collecting forecasts and I hope to have more good news to share soon.<br><br>Both these projects were deeply rooted in academic work. I might be biased, but I think academic work is often underrated. It can be useful for many reasons, but part of it surely is that it can change the way people think about a topic and enable institutional change.</p>", "user": {"username": "Eva"}}, {"_id": "wyePJBbMGeYQCKRde", "title": "Public Fundraising has Positive Externalities", "postedAt": "2023-12-26T14:39:10.495Z", "htmlBody": "<p><i>Epistemic status: revealed to me in a dream</i></p><p>Summary: fundraising from the public has positive externalities: it also functions as outreach and red-teaming. If organizations have not taken this into account they may have under-invested in public outreach and should do more of it.</p><h2>A simplistic approach</h2><p>Here is a simple model for how a normal organization might think about fundraising:</p><ul><li>A: Estimate how much money you expect to be able to raise from fundraising activities.</li><li>B: Estimate how useful that money would be to you.</li><li>C: Estimate the costs of fundraising (e.g. staff time).</li><li>If B &gt; C, do fundraising! If not, skip it for now.</li></ul><p>My claim is this is a bad model for EA orgs, because it misses a significant fraction of the benefits.</p><h2>Field-building benefits</h2><p>Soliciting donations from the general public is generally quite hard. The skills required to do this are often quite different from those involved in running the organization\u2019s core operations, and can be a significant distraction. It is hard to convince people what you\u2019re doing is a good idea, and even those who agree often don\u2019t donate.&nbsp;</p><p>But this is not wasted effort: the difficulty in converting agreement into donations means that fundraisers are effectively subsidizing outreach. The people who read your work but don\u2019t hand over their credit card details might be sold on the mission but skeptical of the team\u2026 so they donate to another org. Or they might be a student with limited liquid assets but willing to apply for jobs in the space in a few years. Or they might bring up the idea to their friends, or answer an online poll, or change their vote. Each of these seem pretty valuable - for example, it seems plausible to me that a large fraction of the value of SIAI\u2019s fundraising efforts might have come from these channels, rather than via directly increasing SIAI\u2019s budget.</p><h2>Epistemic benefits</h2><p>Fundraising can also be unpleasant because it opens yourself up to criticism. If you\u2019re just doing your own thing with one or two large donors, you have little need to explain yourself to anyone else. You need to appeal to the big foundations, but you probably have a decent idea of what they want, and they\u2019re also likely to be pretty busy. Even if they say no, they\u2019re unlikely to send you a long message about how you are bad and your organization is bad and you should feel bad.</p><p>In contrast, having the audacity to run a public fundraiser naturally invites questions and criticisms from people who are skeptical of your effectiveness and theory of change. These critics have no obligation to represent a single perspective or agree with each other, so you may find yourself being attacked from multiple directions at once.&nbsp;</p><p>However, this may be one of the only sources of feedback your org can get, especially if you are small. For the same reasons peer review, flawed as it is, is useful in science, your org can potentially benefit from feedback and questioning and critique of your assumptions, plans and execution.</p><p>Fundraising from the broader group of EAs can attract high quality criticism from similarly-minded people; raising from a broader audience could potentially attract feedback from a wider range of perspectives.</p><p>There is something of a principal-agent problem here; for the staff, criticism is unpleasant. For the organization, it is a mixed bag, because good criticism, even if harshly worded, can help them improve. And from the perspective of the broader movement it seems very good, because damning public criticism helps avoid grant misallocation. So my guess is that, from an impartial point of view, organizations under-invest in exposing themselves to public scrutiny.&nbsp;</p><p>You could think of this argument as being somewhat analogous to the idea that startups should seek to produce a MVP quickly, and get feedback from actual customers, as even though it\u2019s painful it is good to help you stop deluding yourself.</p><h2>The main risk</h2><p>The main downside I see is that soliciting funds from the general public encourages mission creep: rather than focusing on the most effective projects, organizations will instead be encouraged to focus on those that are easiest to raise money for.</p><p>This will be a larger concern for some organizations than others. I would speculate (with low confidence) that it is a larger risk if you are attempting to fundraise from a small number of large sources (who may have the bargaining power to extract significant concessions, and whose objectives are sufficiently transparent that you can modify yourself to become more congruent) than from the amorphous general public.</p><p>For some organizations this disadvantage might be so large, in conjunction with the cost of fundraising, as to outweigh the benefits. My argument is just that I think this disadvantage is relatively clear, whereas the advantages are more likely to have been overlooked.</p><h2>What is the significance of this?&nbsp;</h2><p>My guess is that while this applies to all non-profits, this matters to an unusually large degree to EA, due the presence of very large funders allowing many organizations to almost completely neglect mass fundraising campaigns. Many orgs do not even post an annual fundraiser on the forum, let alone run ads on google, reddit and so on.&nbsp;</p><p>If organizations respond to this rationally but selfishly (to the extent that makes sense for a non-profit) then they will under-advertise to the general public.&nbsp;</p><p>I think this would be good if people did it more. Rather than (implicitly) all competing for the same pseudo-fixed pie of hard-core EA dollars, more orgs could try to appeal to the wider public. Up until now a lot of EA outreach has focused on selling the philosophy of EA first, but I think many of the individual projects can be justified without significant philosophical foundation-building, and it would be good to have some more concrete project-focused outreach.</p><p>One step towards this would be if grant-application-soliciting organizations included a field for a link to the organization\u2019s public fundraiser, to increase the expectation that organizations would at least attempt to do so.</p><p>You could also imagine an organization that aimed to help multiple EA orgs fundraise, perhaps funded by taking a % of the money raised (this would align incentives but maybe deter donors so it is unclear to me if net good).</p><p><br>&nbsp;</p><p>Thanks to all those who inspired this post and gave feedback.<br><br><br>&nbsp;</p>", "user": {"username": "Larks"}}, {"_id": "DBcDZJhTDgig9QNHR", "title": "Altruism sharpens altruism", "postedAt": "2023-12-26T13:37:46.272Z", "htmlBody": "<p>I think many EAs have a unique view about how one altruistic action affects the next altruistic action, something like altruism follows a power law in terms of its impact, and altruistic acts take time/energy/willpower; thus, it's better to conserve your resources for these topmost important altruistic actions (e.g., career choice) and not sweat it for the other actions.</p><p>However, I think this is a pretty simplified and incorrect model that leads to the wrong choices being taken. I wholeheartedly agree that certain actions constitute a huge % of your impact. In my&nbsp; case, I do expect my career/job (currently running Charity Entrepreneurship) will be more than 90% of my lifetime impact. But I have a different view on what this means for altruism outside of career choices. I think that being altruistic in other actions not only does not decrease my altruism on the big choices but actually&nbsp; galvanizes them and increases the odds of me making an altruistic choice on the choices that really matter.</p><p>One way to imagine altruism is much like other personality characteristics; being conscientious in one area flows over to other areas, working fast in one area heightens your ability to work faster in others. If you tidy your room, it does not make you less likely to be organized in your Google Docs. Even though the same willpower concern applies in these situations and of course, there are limits to how much you can push yourself in a given day, the overall habits build and cross-apply to other areas instead of being seen as in competition. I think altruism is also habit-forming and ends up cross-applying.</p><p>Another way to consider how smaller-scale altruism has played out is to look at some examples of people who do more small-scale actions and see how it affects the big calls. Are the EAs who are doing small-scale altruistic acts typically tired and taking a less altruistic career path or performing worse in their highly important job? Anecdotally, not really. The people I see willing to weigh altruism the highest in their career choice comparison tend to also have other altruistic actions they are doing (outside of career). This, of course, does not prove causality, but it is an interesting sign.</p><p>Also anecdotally, I have been in a few situations where the altruistic environment switches from one that does value small-scale altruism to one that does not, and people changed as a result (e.g., changing between workplaces or cause areas). Although the data is noisy, to my eye the trend also fits the \u2018altruism as a galvanizing factor\u2019 model. For example, I do not see people's work hours typically go up when they move from a valuing small scale altruism area to an non-valuing small scale altruism area.</p><p>Another way this might play out is connected to identity and how people think of a trait. If someone identifies personally with something (e.g., altruism), they are more likely to enact it out in multiple situations; it's not just in this case altruism is required, it is a part of who you are (see my altruism as a central purpose post for more on thinking this way). I think this factor that binds altruism to an identity can be reinforced by small-scale altruistic action but also can affect the most important choices.</p><p>Some examples of altruistic actions I expect to&nbsp; be superseded in importance by someone's career choice in most cases but still worth doing for many 50%+ EAs:</p><ul><li>Donating 10% (even of a lower salary/earnings level)</li><li>Being Vegan</li><li>Non-life-threatening donations (e.g., blood donations, bone marrow donations)</li><li>Spending less to donate more</li><li>Working more hours at an altruistic job</li><li>Becoming an organ donor</li><li>Asking for donations during some birthdays/celebrations.</li><li>Getting your friends and family birthday cards / doing locally altruistic actions</li><li>Not violating common sense morality (e.g., don\u2019t lie, steal) on a whim or precarious reason. (This one is worth a whole other blog post).</li></ul><p>Another benefit I did not even talk about is that&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/gdnQLGqbqC7dnbiFF/virtue-signaling-is-sometimes-the-best-or-the-only-metric-we\"><u>costly virtue signalling can often be a more true reflection of someone's altruism</u></a>. Personally, I am way more skeptical of someone pitching a career path as the most altruistic one if they have an extremely limited altruistic track record, and I think this view both in EA and the broader world is pretty common.</p><p>A darker edge to this argument I&nbsp; do not cover here is how many non-altruistic things have been done for \u201cthe greater good\u201d where in fact this argument was just used&nbsp; as justification to do something for one's own self-interest. EA has been accused of this, and in my view not entirely unjustifiably in the past.</p><p>Overall, I would love to spread the idea of the model of altruism sharpening altruism a little bit more, as I think it\u2019s a useful consideration when thinking about altruistic trade-offs.&nbsp;</p>", "user": {"username": "Joey"}}, {"_id": "iWe5KCAdJDGucCbT5", "title": "Link Collection: Impact Markets", "postedAt": "2023-12-26T09:07:49.737Z", "htmlBody": "<h1>0. Readme (or don't)</h1><ul><li>This is <strong>not</strong> a literature review. I'll vouch for links with an associated archived link, author name, and summary, but not the others.</li><li>Last updated: Dec 2023</li></ul><h1>1. Overviews</h1><ul><li><a href=\"https://www.astralcodexten.com/p/impact-markets-the-annoying-details?ref=brasstacks.blog\"><u>Impact Markets: The Annoying Details</u></a> (<a href=\"https://archive.is/yq9i3?ref=brasstacks.blog\"><u>a</u></a>), Scott Alexander<ul><li>Comprehensive description of impact markets, reasoning from first principles. Extremely well-written, and a great introduction to the details of impact markets. Gets technical, but in an easy-to-follow way.</li></ul></li><li><a href=\"https://impartial-priorities.org/toward-impact-markets.html?ref=brasstacks.blog\"><u>Toward Impact Markets</u></a> (<a href=\"https://archive.is/bl7ga?ref=brasstacks.blog\"><u>a</u></a>), Dawn Drescher<ul><li>Comprehensive description of the benefits, risks (&amp; proposed solutions), and current work on impact markets. Fairly technical.</li></ul></li><li><a href=\"https://www.youtube.com/watch?v=ZiDV56o5M7Q&amp;ab_channel=ProtocolLabs&amp;ref=brasstacks.blog\"><u>Impact certificates and Impact Markets - Owen Cotton-Barratt</u></a></li><li><a href=\"https://impactmarkets.substack.com/p/impact-markets-a-funding-mechanism?post_id=80449380&amp;publication_id=976696&amp;utm_source=post-email-title\"><u>Impact Markets: A Funding Mechanism for Speculative Work</u></a></li><li><a href=\"https://impactmarkets.substack.com/p/a-fresh-faq-on-impact-markets?ref=brasstacks.blog\"><u>A Fresh FAQ on Impact Markets</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/HFBJMyCiuPyshRvWq/impact-certificates-on-a-blockchain?ref=brasstacks.blog\"><u>Impact Certificates on a Blockchain</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/eb28pDHzZz2RWh9Fh/will-impact-certificates-value-only-impact?ref=brasstacks.blog\"><u>Will \"impact certificates\" value only impact?</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/4CBoRsCxi5zMWdaDJ/hypercerts-a-new-primitive-for-public-goods-funding?ref=brasstacks.blog\"><u>Hypercerts: A new primitive for public goods funding</u></a></li><li><a href=\"https://www.lesswrong.com/posts/NxyLvovAzqK8e9jn5/crypto-loves-impact-markets-notes-from-schelling-point?ref=brasstacks.blog\"><u>Crypto loves impact markets: Notes from Schelling Point Bogot\u00e1</u></a></li><li><a href=\"https://www.youtube.com/watch?v=kyo5SxtSJ9U&amp;ab_channel=Bankless&amp;ref=brasstacks.blog\"><u>Impact Certificates | Evan Miyazono, Head of Research at Protocol Labs | Green Pill #21</u></a></li></ul><h1>2. Subtopics</h1><ul><li><a href=\"https://forum.effectivealtruism.org/posts/r7vmtHZKuosJZ3Xq5/altruistic-equity-allocation?ref=brasstacks.blog\"><u>Altruistic equity allocation</u></a> (<a href=\"https://archive.is/L1anj?ref=brasstacks.blog\"><u>a</u></a>), Paul Christiano<ul><li>Original proposal of allocating altruistic equity. Somewhat technical.</li></ul></li><li><a href=\"https://forum.effectivealtruism.org/posts/yNn2o3kEhixZHkRga/certificates-of-impact?ref=brasstacks.blog\"><u>Certificates of impact</u></a> (<a href=\"https://archive.is/9HS4E?ref=brasstacks.blog\"><u>a</u></a>), Paul Christiano<ul><li>Original proposal of impact certificates. Somewhat out-of-date with current work. Somewhat technical.</li></ul></li><li><a href=\"https://forum.effectivealtruism.org/posts/74rz7b8fztCsKotL6/impact-markets-may-incentivize-predictably-net-negative?ref=brasstacks.blog\"><u>Impact markets may incentivize predictably net-negative projects</u></a> (<a href=\"https://archive.is/zJ4Pi?ref=brasstacks.blog\"><u>a</u></a>), Ofer and Owen Cotton-Barratt<ul><li>Describes how impact markets can incentivize funding some types of projects that have clear negative expected impact. Argues that impact markets may exhibit the behavior of those types of projects, and therefore that impact markets should never be funded on impact markets.</li></ul></li></ul><h1>3. Implementations</h1><p>Last updated: December 2023</p><ul><li><a href=\"http://mani.fund/?ref=brasstacks.blog\"><u>Manifund</u></a>*, run by <a href=\"https://www.linkedin.com/in/rachel-weinberg-789b23228/?ref=brasstacks.blog\"><u>Rachel</u></a> &amp; <a href=\"https://www.linkedin.com/in/austinch/?ref=brasstacks.blog\"><u>Austin</u></a><ul><li>all of <a href=\"https://manifoldmarkets.notion.site/Manifund-Home-9a18fa2b7a1247e8bb5e36dffec1236f?ref=brasstacks.blog\"><u>Manifund's internal docs</u></a> are publicly available</li><li>includes the <a href=\"https://mani.fund/causes/acx-mini-grants?ref=brasstacks.blog\"><u>ACX Forecasting Impact Mini-Grants</u></a> round, the <a href=\"https://mani.fund/causes/ai-worldviews?ref=brasstacks.blog\"><u>Open Philanthropy AI Worldviews Contest</u></a>, and the leftovers of <a href=\"https://www.astralcodexten.com/p/apply-for-an-acx-grant-2024?ref=brasstacks.blog#:~:text=This%20year%E2%80%99s%20ACX,charitable%20funding%20institution.\"><u>ACX Grants 2024</u></a></li></ul></li><li><a href=\"https://ai.givewiki.org/?ref=brasstacks.blog\"><u>AI Safety GiveWiki</u></a>, previously Impact Markets, [?possibly previously something else]</li><li><a href=\"https://hypercerts.org/?ref=brasstacks.blog\"><u>Hypercerts</u></a></li><li><a href=\"https://www.gitcoin.co/?ref=brasstacks.blog\"><u>Gitcoin</u></a> (not an impact market, but they do retroactive quadratic public goods funding, which is pretty damn close)</li><li><a href=\"https://npxadvisors.com/?ref=brasstacks.blog\"><u>NPX Advisors</u></a> (also in the \"close-to-an-impact-market-but-not-quite\" category. NPX recently <a href=\"https://www.linkedin.com/pulse/farewell-from-npx-npx-inc--1c/?trackingId=HOGF2uIXRp%2Bx4UigRHsyiw%3D%3D&amp;ref=brasstacks.blog\"><u>shut down</u></a>.)</li><li><a href=\"https://impactpurchase.org/?ref=brasstacks.blog\"><u>The Impact Purchase</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/YdaugCRoko7ac4QCL/experiment-in-retroactive-funding-an-ea-forum-prize-contest?ref=brasstacks.blog\"><u>Experiment in Retroactive Funding: An EA Forum Prize&nbsp;Contest</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/2aJRcm6udZDdPDhFv/plan-for-impact-certificate-mvp?ref=brasstacks.blog\"><u>Plan for Impact Certificate MVP</u></a></li></ul><h1>4. Related topics</h1><ul><li><a href=\"https://medium.com/ethereum-optimism/retroactive-public-goods-funding-33c9b7d00f0c?ref=brasstacks.blog\"><u>Retroactive Public Goods Funding</u></a> (<a href=\"https://archive.is/G0VVu?ref=brasstacks.blog\"><u>a</u></a>), Vitalik Buterin</li><li><a href=\"https://impactmarkets.substack.com/p/the-retroactive-funding-landscape?ref=brasstacks.blog\"><u>The Retroactive Funding Landscape</u></a></li><li><a href=\"https://impactmarkets.substack.com/p/the-retrofunders-dilemma?ref=brasstacks.blog\"><u>The Retrofunder\u2019s Dilemma</u></a></li><li><a href=\"https://impactmarkets.substack.com/p/experiment-in-retroactive-funding?ref=brasstacks.blog\"><u>Experiment in Retroactive Funding</u></a></li><li><a href=\"https://impactmarkets.substack.com/p/chaining-retroactive-funders?ref=brasstacks.blog\"><u>Chaining Retroactive Funders</u></a></li><li><a href=\"https://www.youtube.com/watch?v=kyo5SxtSJ9U&amp;ab_channel=Bankless&amp;ref=brasstacks.blog\"><u>Accelerating Academic Research with Impact Certificates</u></a></li></ul><h1>5. Other resources</h1><h2>Places that curate content on impact markets</h2><ul><li><a href=\"https://forum.effectivealtruism.org/topics/certificate-of-impact?ref=brasstacks.blog\"><u>EA Forum's \"Impact Markets\" Tag</u></a></li><li>?others, I'd be particularly interested in readers' ideas</li></ul><h2>People</h2><p>Note: the following people haven't (necessarily) consented to being contacted nor placed on this list; I've compiled this list myself.</p><p>Note 2: if you want to get ahold of any of these people but for some reason can't, <a href=\"https://www.saulmunn.com/contact?ref=brasstacks.blog\"><u>contact me</u></a>.</p><ul><li><a href=\"https://www.linkedin.com/in/rachel-weinberg-789b23228/?ref=brasstacks.blog\"><u>Rachel</u></a> &amp; <a href=\"https://www.linkedin.com/in/austinch/?ref=brasstacks.blog\"><u>Austin</u></a></li><li><a href=\"https://www.astralcodexten.com/about?ref=brasstacks.blog\"><u>Scott Alexander</u></a></li><li><a href=\"https://paulfchristiano.com/?ref=brasstacks.blog\"><u>Paul Christiano</u></a></li><li><a href=\"https://forum.effectivealtruism.org/users/dawn-drescher?ref=brasstacks.blog\"><u>Dawn Drescher</u></a></li><li><a href=\"https://www.linkedin.com/in/dony-christie-4583b4a9/?ref=brasstacks.blog\"><u>Dony Christie</u></a></li><li>those who participated in the ACX Mini-Grants Forecasting Impact Market, including:<ul><li><a href=\"http://saulmunn.com/?ref=brasstacks.blog\"><u>me</u></a>, <a href=\"https://twitter.com/timschlomi?ref=brasstacks.blog\"><u>Tom</u></a>, and <a href=\"https://www.linkedin.com/in/jingyi-wang-a21b551b8/?ref=brasstacks.blog\"><u>Jingyi</u></a></li><li><a href=\"https://manifund.org/MaxMorawski?ref=brasstacks.blog\"><u>Max Morawski</u></a></li><li><a href=\"https://manifund.org/WilliamHoward?ref=brasstacks.blog\"><u>William Howard</u></a></li><li>everyone else listed <a href=\"https://www.astralcodexten.com/p/impact-market-mini-grants-results?ref=brasstacks.blog\"><u>here</u></a></li></ul></li><li><i>if you think you ought to be listed here but you aren't (or if you </i>are<i> listed here but you don't want to be), please </i><a href=\"https://www.saulmunn.com/contact?ref=brasstacks.blog\"><i><u>let me know</u></i></a><i>.</i></li></ul><hr><p>This post originally came from a comment I left on <a href=\"https://manifold.markets/such/help-me-get-an-a-on-my-impact-marke?ref=brasstacks.blog#nn6SH9q9zQTB4Pe2TofC\"><u>a bounty for charity money to help someone out with an undergrad paper</u></a>.</p><p><i>*COI: I\u2019ve done&nbsp;</i><a href=\"http://manifestconference.net/?ref=brasstacks.blog\"><i><u>some work</u></i></a><i>&nbsp;for, might do some more work for, and own a tiny bit of equity in&nbsp;</i><a href=\"http://manifold.markets/?ref=brasstacks.blog\"><i><u>Manifold</u></i></a><i>, the parent company (?) of </i><a href=\"https://manifund.org/?ref=brasstacks.blog\"><i><u>Manifund</u></i></a><i>. I'm writing this independent of any work I'm currently doing or planning to do for Manifold or for any other entity. I just think the ideas are cool.</i></p>", "user": {"username": "Saul"}}, {"_id": "8GFeQDsdnN9nXzj5x", "title": "ALTER Israel - End-of-2023 Update", "postedAt": "2023-12-25T09:52:03.588Z", "htmlBody": "<p>This semiannual update is intended to inform the community of what we have been doing, and provide a touchpoint for those interested in engaging with us. <a href=\"https://forum.effectivealtruism.org/posts/iykkkxvwcuySBeTEL/alter-israel-2023-mid-year-update\">Since the last update in Mid-2023</a>, we have had several updates, but the past several months have been a tumultuous time in Israel, and this has affected our work in a variety of ways, as outlined in a few places below.</p><h2>People</h2><ul><li><a href=\"https://forum.effectivealtruism.org/users/hibukki?mention=user\">@Yonatan Cale</a> and Shahar Avin have joined the ALTER board of directors, joining current board members <a href=\"https://forum.effectivealtruism.org/users/vanessa?mention=user\">@Vanessa</a> Kosoy, <a href=\"https://forum.effectivealtruism.org/users/joshua-fox?mention=user\">@Joshua Fox</a> , <a href=\"https://forum.effectivealtruism.org/users/edoarad?mention=user\">@EdoArad</a>, <a href=\"https://forum.effectivealtruism.org/users/gidikadosh?mention=user\">@GidiKadosh</a>, Daniel Aronovich, and&nbsp;Ezra Hausdorff.</li><li><a href=\"https://forum.effectivealtruism.org/users/rona-tobolsky?mention=user\">@Rona Tobolsky</a> has been a policy fellow during the second half of 2023, continuing her work with ALTER. She has been working on a number of things, including iodization and biosecurity, especially focused on metagenomic sequencing for surveillance. She also started a masters program at Tel Aviv University\u2019s School of Public Health, in disaster preparedness and management, and is considering next steps.&nbsp;</li><li><a href=\"https://publish.obsidian.md/ram-rachum-research/Public/Research+home\"><u>Ram Rachum</u></a> has completed his fellowship with ALTER, during which he focused on multi-agent cooperation and multipolar AI scenarios. He has co-run a conference on disobedience in AI, as well as written several papers on how agents cooperate. His latest paper was just accepted to AAMAS 2024. He is currently seeking funding or support for his next steps as an affiliate researcher.</li><li>A new, independent program based in the US, under&nbsp;<a href=\"https://www.ashgro.org/\"><u>Ashgro</u></a> fiscal sponsorship, was started to promote mathematical and learning theoretic alignment research. This is independent from ALTER, but we are supporting its work. The project has hired&nbsp;<a href=\"https://www.linkedin.com/in/yegreg/\"><u>Gergely Szucs</u></a>, and will be continuing work on that agenda. See below section for further updates.</li></ul><h2>Ongoing and New Projects</h2><ul><li>Our work on infectious disease policy, on the BWC, and on salt iodization in Israel is at a near-complete standstill, as almost all governmental attention is on the war.&nbsp;</li><li>We are working on a paper with Isabel Meusel on applying a model for metagenomic sequencing to Israel. This is part of a broader plan to promote biomonitoring in Israel, and we are hoping to have the paper complete and ready for submission later this month.</li><li>The AI safety coworking day at the EA office, which ALTER encouraged, has been successful, as has the reading group. Several members have also applied for external funding to continue this work, and at least one has received it. Unfortunately, this is on hold due to current logistical issues and the war.&nbsp;</li><li>EA Israel and members of the AI safety group are potentially working on a cybersecurity and AI safety education project. This is still being developed.</li><li>David has worked on a few AI policy projects. Safety culture for AI -&nbsp;<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4491421\"><u>https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4491421</u></a>, the&nbsp;<a href=\"https://www.astralcodexten.com/p/72bafe2a-c417-4119-9be8-79b9818b1442\"><u>debate on \u201cpausing\u201d AI</u></a>, and in-progress work on Audit standards boards and other work with&nbsp;<a href=\"https://transformative.org/\"><u>Transformative Futures Institute</u></a>.</li><li>On public engagement, David has facilitated several reading groups for BlueDot in both Biosecurity and AI policy, and is working on a new project to do public communication about current and future AI benefits and risks. We have also successfully made connections with several individuals in Israel working on biosecurity-relevant projects.</li></ul><h2>Learning Theoretic / Mathematical AI alignment</h2><p>(Largely via <a href=\"https://www.every.org/alter\">Ashgro fiscally-sponsored Affiliate</a>):</p><ul><li>Gergely Szucs is working on completing a project in&nbsp;<a href=\"https://www.lesswrong.com/posts/gHgs2e2J5azvGFatb/infra-bayesian-physicalism-a-formal-theory-of-naturalized\"><u>infra-Bayesian physicalism</u></a>, and tentatively plans to start work on a project on regret bounds in infra-Bayesian reinforcement learning, possibly related to Decision-Estimation Coefficients.</li><li>Vanessa Kosoy is going to be mentoring scholars in MATS, and potentially in ATHENA, to focus on other aspects of the Learning-Theoretic Agenda.</li><li>We have r<a href=\"https://lesswrong.com/posts/cDhaJrCrcNuzf68gT/public-call-for-interest-in-mathematical-alignment\">ecently gathered a list</a> of those who have expressed interest in mathematical AI alignment, and got well over 100 responses.&nbsp;<br>We have begun putting people in touch on the basis of that list, and hope to do more in that vein. If there are individuals who have not filled in this form who are doing relevant work, whether or not they expect we know about them, please encourage them to do so!</li></ul><h2>Funding</h2><ul><li>We reached a settlement with FTX Debtors that allowed ALTER to return all unspent funds. (This excludes roughly 1/3rd of the initial grant which had already been committed or spent before the FTX bankruptcy.)</li><li>Including incoming grants, ALTER will have enough cash on hand to fund core operations until the end of the 2024 calendar year, but the allocation of funds is unclear, and beyond work on Learning Theory, below, there is no funding for additional programming or projects. (We have a grant application outstanding which may change this.)</li><li>We have been awarded a Survival and Flourishing Fund grant totalling $339,900, which consists of two overlapping grants, with Lightspeed Grants contributing $316,900 focused on Learning-theory research and mathematical alignment, but the marginal $23,000 is coming from SFF.&nbsp; Note that we are currently deciding how to allocate this funding between projects; the allocation from SFF was for general expenses and then learning theory, but is allocated as marginal funding over the Lightspeed amount, whereas the Lightspeed grant was specific to learning theory work.</li><li>As noted, the earlier funding for hiring an additional alignment researcher for Vanessa is being managed by a fiscally sponsored project run by Ashgro. This project will be used for funding learning theory work outside of Israel, and we may recommend that Lightcone direct some of the Lightspeed grant to that project.</li></ul>", "user": {"username": "Davidmanheim"}}, {"_id": "CryjzhyHaBZKdkYkw", "title": "Confessions of a Recent GWWC Pledger (Boxing Day Giving?!)", "postedAt": "2023-12-25T08:34:01.471Z", "htmlBody": "<h2>TLDR;</h2><ul><li>I pledged to&nbsp;Giving What We Can (GWWC) in early September.</li><li>But because we transitioned from a dual income to a single income in late June, we had been postponing the 10% tithing.</li><li>As a result, we also procrastinated on giving to effective charities, even after pledging in September.</li><li>Black Friday (late November) was when we paid off the \u201cdonation debt\u201d to Jesus.</li><li>We are surrounded by others who sacrificially love and give, and that\u2019s why we were empowered to do it too.</li><li>We encourage others to pledge or give this giving season, perhaps doing the counter-cultural thing and making Boxing Day about giving.</li></ul><p>&nbsp;</p><h2>Introduction</h2><p>In September of this year, I decided to take the Giving What We Can (GWWC) pledge. As a Christian, I have been tithing 10% for years. With GWWC, I am redirecting these donations to highly effective charities, aiming to support 'the least of these' or interventions that can most cost-effectively improve the world, thereby maximizing the impact of my limited resources. This commitment was more than financial; it was a profound expression of faith. Our family's shift from a stable dual income to a more restrictive single income since late June introduced many uncertainties when I made this pledge.</p><p>The transition to a single income in an expensive city like Vancouver has been challenging, especially considering that the three co-founders of&nbsp;<a href=\"https://www.stakeout.ai/\"><u>StakeOut.AI</u></a>, including myself, have been effectively volunteering\u2014Peter for nearly six months part-time, I for almost 3.5 months full-time, and Amy for 1.5 months full-time.</p><p>As of this writing, we still haven't fundraised because we have prioritized impact and project advancement. A couple example projects we have completed include:</p><ol><li>Contributions to researching the&nbsp;<a href=\"https://www.stakeout.ai/contributions\"><u>'scorecard' of AI governance proposals</u></a> (found on page 3 of The Future of Life Institute's proposal) presented at the first ever international AI Safety Summit.</li><li>Co-hosted a Zoom webinar where we advised&nbsp;<a href=\"https://www.stakeout.ai/actors\"><u>Hollywood actors on how AI will likely affect their industry</u></a>. We also have plans for continued collaboration with Hollywood actors to advocate for banning deepfake pornography, a detrimental issue that has victimized many young schoolgirls.</li></ol><p>By sharing this journey, I hope to inspire a conversation about faith, stewardship, and the impact of intentional giving. This post is an exploration of faith and trust, and my understanding of Christian giving as a joyful expression of faith. Giving has brought an unexpected peace and a deeper trust in God's provision.</p><p>&nbsp;</p><p>&nbsp;</p><h2>Our Financial Challenge is a Fraction of What Many Others Endure</h2><p>\"Where do you need God's comfort today?\" This question from my Daily Refresh in YouVersion resonated with me, especially after reading 2 Corinthians 1:3-7. This verse speaks volumes about comfort in troubles, a theme that deeply aligns with my current life chapter.</p><p>\u202d\u202d[3] Praise be to the God and Father of our Lord Jesus Christ, the Father of compassion and the God of all comfort, [4] who comforts us in all our troubles, so that we can comfort those in any trouble with the comfort we ourselves receive from God. [5] For just as we share abundantly in the sufferings of Christ, so also our comfort abounds through Christ. [6] If we are distressed, it is for your comfort and salvation; if we are comforted, it is for your comfort, which produces in you patient endurance of the same sufferings we suffer. [7] And our hope for you is firm, because we know that just as you share in our sufferings, so also you share in our comfort.</p><p>As I mentioned earlier, since early September, I have embarked on a journey of starting a&nbsp;<a href=\"https://www.stakeout.ai/\"><u>grassroots movement, the Safer AI Global Grassroots United Front</u></a>. Honestly, it's been more than a full-time volunteering effort, as I have worked countless 10-14 hour days to get things done.</p><p>Being on a single income with two kids isn't easy, and we've had to restructure much of our finances and budget to stay afloat. One of the toughest decisions was continuing to delay our commitment to tithe 10% to 'the least of these.' Procrastinating and postponing tithing gnawed at us. For months, it weighed heavily on both my wife\u2019s and my heart, becoming a topic of guilt as we struggled between fulfilling our spiritual commitments and navigating our new financial reality.</p><p>I'm hesitant to share this because, in the grand scheme of things, our financial struggles are insignificant compared to others' suffering. In extreme poverty, many people face life-threatening conditions every day. But even within our local church, we've witnessed heart-wrenching struggles and losses in the past few months. Take, for example, Mr. T, a young father who's been in and out of the ICU within a span of 1.5 months, with no end in sight for recovery, while his wife does her best to be by his side and care for their daughter under 7 years old. His situation, along with two other sudden passings (one at the young age of 41), puts our financial concerns into perspective. It's a stark reminder that our trials, though challenging, are but a fraction of what many others endure.</p><p>This experience has been a lesson in counting our blessings and recognizing the multitude of ways God provides and comforts. Because of our fellow brothers' and sisters' situations, I am reminded daily to be thankful for life's most fundamental blessings \u2013 health, family, and community. I still get to hear my absolute favorite sound in the world, the sound of my wife and kids' heartbeats as I press my ear against their chests \u2013 and that is a miraculous blessing!</p><p>Another example is how God sent an angel in the form of a financial planner out of nowhere. She volunteered numerous hours to help us navigate our transition from dual to single income because she knew of our desire to continue tithing despite our involvement in a nonprofit startup.</p><p>These are the gifts that sustain us, the blessings we often take for granted. They remind us of God's unwavering presence and the comfort He provides, not just in our lives but also in enabling us to extend that comfort to others.</p><p>These past few months, with all the ups and downs, are teaching me about true reliance on God \u2013 a reliance that goes beyond financial security and delves into the depths of faith and trust. It\u2019s a daily journey, continually learning to lean on His understanding, not ours, and to find peace amidst our challenges.</p><p><br><br><br>&nbsp;</p><h2>A Mentor's Return After 19 Years was God\u2019s Perfect Timing</h2><p>Another person who has helped us through this journey is none other than a mentor of mine, Tombert Chen. He is a Christian youth worker who has lived solely on donations for the past 20 years. His unwavering trust in God's provision, even in times of scarcity, has been a beacon of faith for me.</p><p>We had not been in touch since high school graduation, which means we hadn\u2019t talked in 19 years. What were the chances that he would message me out of the blue on Facebook, right around the time I started the journey of co-founding the nonprofit? Not to mention, I hadn\u2019t checked Facebook in years, and it was only because I was laid off (some have hinted to me that my job loss was AI-driven) that I opened it back up to join groups like the Effective Altruism Facebook group. This is an example of God\u2019s perfect timing!</p><p>There have been days when his family didn\u2019t know where their next meal would come from. Yet, time and again, after earnest prayer, their needs were met in the most unexpected ways. Members of their church community would bring food, unaware of their dire need but moved to act. Witnessing this miraculous provision has reshaped my understanding of reliance on Jesus. It\u2019s a vivid illustration that trusting in God often means He will provide, though it might not be in the ways you expect.</p><p>After our meetup and catching up on what\u2019s happened since we last saw each other 19 years ago, my mentor's faith journey resonates deeply with me, especially now as my family navigates the tightest budget we have ever had. How were we supposed to give 10% when our income had shrunk so much?</p><p>I'm reminded of the profound impact of walking by faith. It\u2019s about seeing beyond our immediate circumstances and trusting that God will provide, often through the most unexpected channels.</p><p>A few weeks ago, while watching Veggie Tales with the kids, the episode \"Minnesota Cuke and the Search for Noah's Umbrella\" presented a powerful lesson. It showed that actions of faith, like choosing a nonprofit mission over immediate financial gain, might seem foolish to some. Yet, what truly matters is how God sees these actions and whether He thinks you are doing what\u2019s right.</p><p>These stories and lessons have been constant reminders of the importance of faith in action. They\u2019ve taught me that walking by faith isn\u2019t just a spiritual concept but a practical way of living, one that involves real risks and profound trust in God\u2019s plan. It's about making choices that might not make sense from a worldly perspective, but following the doors He has opened for me and turning away when He closes others.</p><p>&nbsp;</p><h2>Black Friday was When We Took the Plunge</h2><p>In moments of doubt, I often found guidance and reassurance in 1 Peter 5:7: \"Cast all your anxiety on him because he cares for you.\" This verse became a cornerstone in our decision-making process. It reminded us that, amidst our financial insecurities, our primary call was to trust in God's care and provision.</p><p>This leap of faith became particularly significant on Black Friday, a day typically associated with consumerism and self-indulgence. Surrounded by the frenzy of deals and discounts, we made a counter-cultural choice: to give rather than spend. It was a conscious decision to align our actions with our faith, moving from fear to trust.</p><p>That weekend, we donated the equivalent of 1,299 nets to protect 2,339 people. These nets are part of this distribution:</p><p><a href=\"https://www.againstmalaria.com/MyNets.aspx?DonationID=1172055\"><u>https://www.againstmalaria.com/MyNets.aspx?DonationID=1172055</u></a></p><p>This act cleared our \u201ctithing debt\u201d to Jesus. We had held off on tithing for months, so we went back to our spreadsheet to calculate how much it would take to give 10% of our family\u2019s income from all the months we missed.</p><p>Pressing the buttons wasn\u2019t easy. Nor was entering the amount into the donation form.</p><p>But what we are learning is that giving, just like observing the Sabbath (which I mandated our family take every Saturday for a full day of rest without any work whatsoever), is a practice of trust and reliance on God's provision. We recognize that our security doesn't come from material wealth but from our faith in God. It's an acknowledgment that our earthly resources are ultimately His, entrusted to us to be used for His purposes.</p><p>&nbsp;</p><h2>Sacrificial Love in the Community and Its Impact</h2><p>Again, I want to share our story because I hope it can inspire others who are also considering donating a portion of their income. Additionally, I want to emphasize the importance of having supportive people around you in this endeavor.</p><p>What we did can be considered a form of sacrificial love. While volunteering at a nonprofit for 3+ months and still needing to feed two kids might seem like a big sacrifice, I can assure you that others are doing even more. We are empowered to do this because of Christ and the examples He has placed around us, people who are sacrificially loving others in their own ways. Furthermore, my wife and I have been surrounded by Christians who have poured into us over the years, and because of this, we cannot help but give back.</p><p>Back in the last week of November, a devotional I read highlighted the verse John 16:33 NIV: 'I have told you these things, so that in me you may have peace. In this world, you will have trouble. But take heart! I have overcome the world.' The devotional then asked, 'Is there anything happening around you that makes you feel anxious or afraid?' Initially, I thought of our financial situation, as it was at the top of my mind.</p><p>However, I was immediately reminded of the SOS fellowship small group meeting we had the day before, where we shared about Christian mentors, role models, and fellow brothers and sisters who have impacted our lives, making our situation seem minuscule.</p><p>In our small church community, we witness sacrificial love regularly, which in turn motivates and inspires those on the receiving end to help others and pass it forward. These acts aren't measured in expected value (EV) but are expressions of obedience and love. As the love of the Father overflows in them, they feel compelled to love others in turn.</p><p>For example, when informed of a potential break-in, our youth leaders immediately rushed to assist a girl who had locked herself inside her room, ensuring her safety and providing comfort.</p><p>We've seen members make life-altering decisions for their faith. One gave up a well-paying, prestigious career as a partner in a law firm to become a pastor, embracing a completely different life path. Another member declined a high-paying job opportunity in Singapore, which included all moving expenses for the family, to focus solely on God's calling.</p><p>In another instance, a church member, barely acquainted with another brother in Christ, tirelessly visited the hospital and provided care during a time of need. This selfless act demonstrated the depth of our community's commitment to each other.</p><p>We also have members who take days off from their jobs to assist immigrants who have just arrived, helping them settle in and navigate their new environment.</p><p>Recently, when a mother in our community, whose child was diagnosed with autism, struggled to navigate the support system, a professional from our church connected with her. Despite a busy schedule, this professional arranged a late-night call at 11 pm to offer advice and answer questions, showing kindness and compassion.</p><p>Our community's acts of service extend to everyday needs as well. Regularly, members volunteer as drivers, helping others get from one place to another, such as assisting those who need to take driver's tests. Another member spent days setting up a new living arrangement for someone they didn't know at all, taking care of rental negotiations, stocking the home with necessities, and even putting in the bedsheets.</p><p>These stories remind us that no one is better or worse than anyone else. Many have sacrificed more, endured tougher struggles, and given up larger opportunities&nbsp;<strong>because they wanted to put God first</strong>.</p><p>Each person has their own journey and struggles while trying to do their part to do good. Witnessing these acts of faith and love in our community reinforces the belief that our financial challenges, though uncomfortable, are part of a larger journey of faith and sacrifice that we are all undertaking together.</p><p>&nbsp;</p><h2>The Delicate Balance of Public and Private Giving</h2><p>In sharing this story, I'm mindful of the teachings of Matthew 6:2-4, which emphasize humility in giving, advising against announcing our charitable acts for self-glorification. The scripture reminds us, \u201cWhen you give to the needy, do not let your left hand know what your right hand is doing, so that your giving may be in secret.\u201d</p><p>However, as highlighted by Giving What We Can (GWWC), there is value in being public with our charitable actions to inspire others. Their perspective suggests that openly pledging to donate a portion of our income can encourage others to do the same, thereby amplifying the impact (more at<a href=\"https://www.givingwhatwecan.org/blog/should-charity-be-anonymous\">&nbsp;<u>Should Charity Be Anonymous?</u></a>).</p><p>With this in mind, my intention in sharing our journey isn't for recognition but to inspire and motivate others towards pledging or giving to impactful nonprofits. It's a delicate balance between the personal practice of discreet giving and the potential collective impact of shared stories.</p><p>Ultimately, by discussing our commitment, we hope to foster a culture of giving, where collective action and generosity can transform lives in profound ways, even beyond what we can directly see or measure. It's about demonstrating how faith can lead us to make meaningful sacrifices and encourage others to consider how they can contribute to the greater good.</p><p>&nbsp;</p><h2>The Joy of Giving: Let\u2019s Aim for Boxing Day Giving!</h2><p>Our journey of giving didn't stop with Black Friday; it's an ongoing commitment to living out our faith through actions. Just as we made the deliberate choice to give on Black Friday instead of indulging in consumerism, we'll continue to grapple with giving in our current circumstances.</p><p>Right now, we are considering Boxing Day as another opportunity to support effective charities and give instead of buy. Known for its shopping frenzy, we plan to use this day to give back instead of joining the crowds for deals. It's a chance to redirect our resources towards those in need, following Jesus' example of compassion and challenging societal norms.</p><p>As we reflect on our giving journey, we're reminded that generosity isn't confined to a single day or event. It's a lifestyle that aligns with our Christian faith and values, about recognizing the needs of others and finding opportunities to make a difference, whether through financial contributions, acts of kindness, or heartfelt prayers.</p><p>John Ortberg's book, \"If You Want to Walk on Water, You've Got to Get Out of the Boat,\" which was recommended by my mentor Tombert years ago, has also significantly influenced my faith and trust in God. Its message resonates with my current endeavor to rally the public to join our&nbsp;<a href=\"https://www.stakeout.ai/\"><u>AI Stake Out, the Global Grassroots United Front</u></a>. It reminds me that true faith often involves stepping into the unknown and trusting in God's guidance and provision.</p><p>Our hope is that our experience inspires others to find joy and fulfillment in giving. It's a tangible way to express faith and share God's love. Just as we've found meaning in our commitment to give, we encourage others to explore the joy of giving, both on special occasions and regularly.</p><p><br>&nbsp;</p>", "user": {"username": "Harry Luk"}}, {"_id": "7D83kwkyaHLQSo6JT", "title": "Winners in the Forum\u2019s Donation Election (2023)", "postedAt": "2023-12-24T01:55:35.662Z", "htmlBody": "<p><strong>TL;DR: </strong>We ran a&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#Participate_in_the_Donation_Election\"><u>Donation Election</u></a> in which 341 Forum users<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref6w7y3qtru6v\"><sup><a href=\"#fn6w7y3qtru6v\">[1]</a></sup></span>&nbsp;voted on how we should allocate the Donation Election Fund ($34,856<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5i6rlzul5i\"><sup><a href=\"#fn5i6rlzul5i\">[2]</a></sup></span>). The winners are:&nbsp;</p><ol><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Rethink_Priorities\"><u>Rethink Priorities</u></a> - $12,847.75</li><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Charity_Entrepreneurship__Incubated_Charities_Fund\"><u>Charity Entrepreneurship: Incubated Charities Fund</u></a> - $11,351.11</li><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Animal_Welfare_Fund__EA_Funds_\"><u>Animal Welfare Fund (EA Funds)</u></a> - $10,657.07</li></ol><p>This post shares more information about the results:&nbsp;</p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023#Highlights_from_the_comments__why_people_voted_the_way_they_did\">Comments from voters about their votes</a>: patterns include referencing organizations' marginal funding posts, updating towards the neglectedness of animal welfare, appreciating strong track records, etc.&nbsp;</li><li><a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023#Voting_patterns__how_did_people_distribute_their_points_\">Voting patterns</a>: most people voted for 2-4 candidates (at least one of which was one of the three winners), usually in multiple cause areas</li><li><a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023#Four_broad_cause_areas_got_similar_numbers_of_points__and_voters_\">Cause area stats</a>: similar numbers of points went to cross-cause, animal welfare, risk/future-oriented, and global health candidates (ranked in that order)</li><li>\u200b\u200b<a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023#All_candidate_results_and_raw_points_totals\">All candidate results, including raw point</a><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3ezyp9nbamv\"><sup><a href=\"#fn3ezyp9nbamv\">[3]</a></sup></span><a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023#All_candidate_results_and_raw_points_totals\">&nbsp;totals</a>: the Long-Term Future Fund initially placed second by raw point totals</li><li><a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023#Concluding_thoughts__I_d_love_to_see_follow_up_discussion_\">Concluding thoughts</a> &amp; <a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023#Consider_exploring_charities_that_weren_t_candidates_\">other charities</a></li></ul><p>You can find some extra information in&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1RWAZ7sH9voGyTQ1-nu9_QjrpVmchGyYGDnytHaVxVQg/edit?usp=sharing\"><u>this spreadsheet</u></a>.&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/pdfn3vmxolrbqpkydli8\"><figcaption>Chart summary of where the Donation Election Fund is going</figcaption></figure><h1>Highlights from the comments: why people voted the way they did</h1><p>We asked voters if they wanted to share a note about why they voted the way they did. 74 people (~20%) wrote a comment. I\u2019m sharing a few excerpts<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftr1ycmhrith\"><sup><a href=\"#fntr1ycmhrith\">[4]</a></sup></span>&nbsp;below, and <a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023?commentId=eXppjMA8qfQds28nP\">more in a comment on this post</a> (separated for the sake of space) \u2014 consider reading the longer version if you have a moment.&nbsp;</p><p><strong>There were some recurring patterns in different people\u2019s notes</strong>, some of which appear in these two comments explaining their authors\u2019 votes:&nbsp;</p><ul><li>\"[AWF], because I was convinced by the post about how animal welfare dominates in non-longtermist causes, [CE], so that there can be even more excellent ways of making the world a better place by donating, [GWWC], because I wish we had unlimited money to give to all the others\"&nbsp;</li><li>\u201cRealized I'm too partial to [global health] and biased against animal welfare, [so I decided to vote for the] most effective animal organization. Rethink's&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/cMcEBSNiy4meDrmuE/rethink-priorities-needs-your-support-here-s-what-we-d-do\"><u>post</u></a> was very convincing.&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Charity_Entrepreneurship__Incubated_Charities_Fund\"><u>CE</u></a> has the most innovative ideas in GHD and it isn't close. GiveWell is GiveWell.\u201d</li></ul><p><strong>Rethink Priorities\u2019s&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/posts/cMcEBSNiy4meDrmuE/rethink-priorities-needs-your-support-here-s-what-we-d-do\"><strong><u>funding request post</u></strong></a><strong> was mentioned a lot.</strong> People also noted specific aspects of RP\u2019s work that they appreciate, like the EA Survey, public benefits/publishing research on cause prioritization, moral weights work, and research into particularly neglected animals. There were also shoutouts to the staff:</p><ul><li>\u201cALLFED and Rethink Priorities both consist of highly talented and motivated individuals that are working on high-potential, high-impact projects. Both organizations have left a strong impression on me in terms of their approach to reasoning and problem solving. [...] Both organizations have recently posted extremely well-detailed [updates on their financial situation and how additional funding would help]. [...]\u201d</li></ul><p><strong>CE\u2019s Incubated Charities Fund (and Charity Entrepreneurship more broadly) got a lot of appreciation for their good and/or unusual ideas and track record. </strong>There were also comments like:</p><ul><li>\u201c...direct-action global health charities need more funding now, especially in light of reductions in future funding from Open Phil. [And] there's enough potential upside to charity incubation to put a good bit of money there.\u201d</li></ul><p><strong>A number of people wrote that they\u2019d updated towards donating to animal welfare as a result of recent discussions (</strong><a href=\"https://forum.effectivealtruism.org/posts/btTeBHKGkmRyD5sFK/open-phil-should-allocate-most-neartermist-funding-to-animal\"><strong><u>often explicitly because of this post</u></strong></a><strong>). </strong>Many gave a lot of their points to the Animal Welfare Fund, sometimes referencing&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/PTHskHoNpcRDZtJoh/gwwc-s-evaluations-of-evaluators\"><u>GWWC\u2019s evaluations of the evaluators</u></a>. Some also said they wanted to vote for animal welfare to correct for what they saw as its relative neglectedness in EA or to emphasize that it has a central place in EA. One example:</p><ul><li>\u201cI voted for animal charities to [...] direct the money to where it can do a lot of good, but also to demonstrate to the EA community that *animal welfare belongs as a central EA cause area.* As an EA working on AI risk, I feel very deeply that this community should continue to stand up for sentient beings who are experiencing unimaginable suffering now. [...] Why these particular animal welfare donations [ACE, THL, AWF]? I want to strengthen central institutions in animal welfare so that they can in turn use their best judgment to distribute funds among tried-and-tested and speculative giving opportunities.\"</li></ul><p>There are more comments about why people gave points or donated to&nbsp;<i>other</i> candidates, as well as other considerations people shared in the full-length \u201cAppendix Comment\u201d below.</p><p><strong>Broader patterns:&nbsp;</strong></p><ul><li>A number of people said they work in one field (e.g. existential risk reduction) but want to donate to a different field (e.g. global health, animal welfare), either because they believe those causes could use&nbsp;<i>funding</i> better than others (while others might use&nbsp;<i>labor</i> better) or because they wanted to split their/EA resources across causes.&nbsp;</li><li>Some referenced specific posts or recent changes, while others said they went with cached thoughts.</li><li>People also shared some thoughts related to Giving Season \u2014 two examples:<ul><li>\u201c...Would have LOVED more debates/ posts about \u2018LTFF vs ALLFED?\u2019 and \u2018EA Funds Animal Welfare Fund vs. The Humane League?\u2019\u201d (This person also cited two posts.)</li><li>\u201c \u2026 I [...] found the marginal funding posts super interesting.&nbsp; It made me more excited about earning to give and helped me understand the perspective of nonprofits engaged in fundraising, particularly the posts from RP (Peter Wildeford and Abraham Rowe).\u201d</li></ul></li></ul><p>Finally, shoutout to the voter who added: \u201cThank you for listening to my TED talk. I am legally obligated to tell you this is not financia-, err, altruism advice\u201d after their comment. (If you want to see more highlights, <a href=\"https://forum.effectivealtruism.org/posts/7D83kwkyaHLQSo6JT/winners-in-the-forum-s-donation-election-2023?commentId=eXppjMA8qfQds28nP\">check out the full-length \"comment appendix\"</a>.)</p><h1>Voting patterns: how did people distribute their points?</h1><h2>Most voters gave some or all of their points to at least one of the 3 winning candidates.</h2><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/fxkklvqklxoneyxpv0ll\"><figcaption>27% of voters gave points to none of the winners, 18% to RP only, 16% to CE's fund only, 12% to AWF only, 18% to 2 winners, 10% to all three winners.&nbsp;</figcaption></figure><p>27% of voters&nbsp;<i>didn\u2019t</i> give any points to any of the 3 winning candidates.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref2nnmomfgy38\"><sup><a href=\"#fn2nnmomfgy38\">[5]</a></sup></span>&nbsp;Those voters seemed a&nbsp;<i>bit</i> more likely to give points to GiveDirectly, LTFF, AMF, and Malaria Consortium \u2014 and&nbsp;<i>not</i> give points to ACE Movement Grants, Wild Animal Initiative, Fish Welfare Initiative, and Giving What We Can.</p><h2>32% of voters said their donation priorities changed as a result of Giving Season (54% said their priorities didn\u2019t change)</h2><p>Out of people whose priorities had changed at least \"a bit\" as a result of the Forum's Giving Season, 16 said their donation priorities changed \u201cnoticeably\u201d or \u201ctotally.\"&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/klgvknvogfacerieoxb7\"><figcaption>\"Did you change your donation priorities as a result of the Forum's Giving Season activities?\" 184 people \"didn't change\", 94 \"changed a bit\", 14 \"noticeably changed,\" 2 \"totally changed,\" 48 blank.&nbsp;</figcaption></figure><p>People who said their donation priorities changed at least a bit tended to give more points to the Animal Welfare Fund, CE\u2019s Incubated Charities Fund, Rethink Priorities, ALLFED, and the Humane League (the difference between them and the \u201cno change\u201d voters is strongest for candidates earlier in that list) and&nbsp;<i>less</i> to GiveDirectly, EAIF, and MIRI (note that this is a pretty small sample, and also it\u2019s unclear if their \u201cpriorities changing\u201d was what led to that difference \u2014 they\u2019re also probably a pretty unusual group in other ways). People who reported greater priority changes (16 people) followed a similar pattern, generally with stronger effects (likely in part due to small samples\u2019 greater relative variance).&nbsp;</p><h2>Most voters gave points to 2-4 candidates</h2><p>The median voter assigned points to 3 candidates (the average was 4.5, as some people gave points to many projects<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefuz6qyplz5gs\"><sup><a href=\"#fnuz6qyplz5gs\">[6]</a></sup></span>).&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/dxpugdbcldlcysokjacg\"><figcaption>Chart: how many people gave points to how many candidates.</figcaption></figure><h2>Most voters gave points to multiple causes</h2><p>There were some (27%) all-in voters who gave all their points to candidates in a single cause area (<a href=\"https://docs.google.com/spreadsheets/d/1RWAZ7sH9voGyTQ1-nu9_QjrpVmchGyYGDnytHaVxVQg/edit?usp=sharing\"><u>out of four broad causes</u></a>), but most gave points to multiple causes. (In fact, most gave at least 10% of their votes to at least two causes.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefn1fxp88lwtq\"><sup><a href=\"#fnn1fxp88lwtq\">[7]</a></sup></span>)</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/sjyg70kpuwdqmhsaxnxz\"><figcaption>Chart: how many people gave some points to 1, 2, 3, 4 causes (92, 125, 88, 36 respectively)</figcaption></figure><h1>Four broad cause areas got similar numbers of points (and voters)</h1><p>Points were split pretty evenly across four broad cause areas (<a href=\"https://docs.google.com/spreadsheets/d/1RWAZ7sH9voGyTQ1-nu9_QjrpVmchGyYGDnytHaVxVQg/edit?usp=sharing\"><u>see here for how I categorized projects</u></a> into \"cross-cause\" projects, animal welfare projects, risk/future-oriented projects, and global health projects):</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/tweebzavq6qs45q3olfa\"><figcaption>How points were split across causes: cross-cause (30%), animal welfare (30%), risk-reduction (22%), GHD (18%).</figcaption></figure><p>The number of \u201cvoters for [cause]\u201d is also pretty similar across different causes, although there were more voters who gave at least&nbsp;<i>some</i> points to \"cross-cause\" candidates (72%) and voters who gave some points to animal welfare candidates (62%) than some-points-for-risk-reduction voters (47%) and some-points-for-global-health voters. The number of \u201chardcore [Cause A]\u201d voters didn\u2019t vary much (animal welfare had a bit more).&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/eijbvcpfzr3bkocqjghj\"><figcaption>Chart of % of voters who gave [some/&gt;25%/&gt;50%/&gt;75%/&gt;100%] of their points to the 4 causes.</figcaption></figure><h1>All candidate results and raw points totals</h1><p>In our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/dYhKfsNuQX2sznfxe/donation-election-how-voting-will-work\"><u>voting system</u></a>, voters could give any number of candidates any number of points, which we normalized (so that everyone\u2019s points added up to the same amount). Then we calculated totals for each candidate, eliminated the lowest-ranked candidate,&nbsp;and <i>re-</i>normalized people\u2019s point totals (so if a voter had assigned some points for the now-eliminated candidate, their other points would count for more). Finally, we ran this process (eliminating the lowest-ranked candidate each time) until we arrived at three winners. (Here\u2019s&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/dYhKfsNuQX2sznfxe/donation-election-how-voting-will-work\"><u>a full description of the voting system</u></a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdlkyvhfg6xf\"><sup><a href=\"#fndlkyvhfg6xf\">[8]</a></sup></span>)&nbsp;</p><p>So initial point totals (normalized so that every voter's points add up to 100) didn\u2019t determine the final winners, but are still useful information about how voters distributed points across all candidates. The following table shows initial point totals, the order in which the candidates were eliminated by this process, and some more information about the election:</p><figure class=\"table\"><table><tbody><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom;width:130px\">Candidate</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom;width:95px\">Eliminated after round\u2026</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom;width:95px\">Initial rank (based on raw point totals)</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom;width:95px\">% of all initial points that went to this candidate</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom;width:95px\">Breadth: the % of all voters who gave it points</td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom;width:95px\">Skew: the % of its voters who accounted for&nbsp;<strong>90</strong>% of its points</td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/rethink-priorities\"><u>Rethink Priorities</u></a></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">[Won]</td><td style=\"background-color:#fcfcfc;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>1</p></td><td style=\"background-color:#d2e4f4;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>13%</p></td><td style=\"background-color:#6fa8dc;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>41%</p></td><td style=\"background-color:#e5eef0;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>60%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/charity-entrepreneurship-incubated-charities\"><u>CE: Incubated Charities Fund</u></a></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">[Won]</td><td style=\"background-color:#f3f3f3;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>4</p></td><td style=\"background-color:#e1edf8;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>9%</p></td><td style=\"background-color:#7cb0e0;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>37%</p></td><td style=\"background-color:#e3edee;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>61%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/animal-welfare-fund\"><u>AWF (EA Funds)</u></a></td><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\">[Won]</td><td style=\"background-color:#f6f6f6;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>3</p></td><td style=\"background-color:#e1edf8;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>9%</p></td><td style=\"background-color:#8ab8e3;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>33%</p></td><td style=\"background-color:#d0e0e3;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>68%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/long-term-future-fund\"><u>LTFF (EA Funds)</u></a></td><td style=\"background-color:#ffffff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>21</p></td><td style=\"background-color:#f9f9f9;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>2</p></td><td style=\"background-color:#ddebf7;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>10%</p></td><td style=\"background-color:#9cc3e7;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>28%</p></td><td style=\"background-color:#e0ebed;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>62%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/givewell-all-grants-fund\"><u>GW All Grants Fund</u></a></td><td style=\"background-color:#fbfbfb;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"background-color:#f0f0f0;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#ebf3fb;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>6%</p></td><td style=\"background-color:#adcdeb;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>24%</p></td><td style=\"background-color:#edf3f5;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>57%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/the-humane-league\"><u>The Humane League</u></a></td><td style=\"background-color:#f7f7f7;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>19</p></td><td style=\"background-color:#ededed;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>6</p></td><td style=\"background-color:#f0f6fc;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>5%</p></td><td style=\"background-color:#aeceec;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>23%</p></td><td style=\"background-color:#e3edee;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>61%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/givedirectly\"><u>GiveDirectly</u></a></td><td style=\"background-color:#f4f4f4;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>18</p></td><td style=\"background-color:#eaeaea;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>7</p></td><td style=\"background-color:#f1f7fc;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>5%</p></td><td style=\"background-color:#bcd7ef;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>19%</p></td><td style=\"background-color:#fffcf3;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>48%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/en-US/charities/fish-welfare-initiative\"><u>Fish Welfare Initiative</u></a></td><td style=\"background-color:#f0f0f0;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>17</p></td><td style=\"background-color:#e7e7e7;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>8</p></td><td style=\"background-color:#f4f9fd;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>4%</p></td><td style=\"background-color:#b2d1ed;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>22%</p></td><td style=\"background-color:#e8f0f2;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>59%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/against-malaria-foundation\"><u>AMF</u></a></td><td style=\"background-color:#ededed;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>16</p></td><td style=\"background-color:#e1e1e1;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#f5f9fd;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>4%</p></td><td style=\"background-color:#b8d4ee;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>21%</p></td><td style=\"background-color:#e3edee;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>61%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/en-US/charities/good-food-institute\"><u>GFI</u></a></td><td style=\"background-color:#e9e9e9;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"background-color:#d8d8d8;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>13</p></td><td style=\"background-color:#f6fafd;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>3%</p></td><td style=\"background-color:#bed8ef;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>19%</p></td><td style=\"background-color:#ebf2f3;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>58%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/effective-altruism-infrastructure-fund\"><u>EAIF (EA Funds)</u></a></td><td style=\"background-color:#e5e5e5;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>14</p></td><td style=\"background-color:#e4e4e4;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>9</p></td><td style=\"background-color:#f5f9fd;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>4%</p></td><td style=\"background-color:#b7d4ee;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>21%</p></td><td style=\"background-color:#e8f0f2;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>59%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/en-US/charities/allfed?slug=charities&amp;slug=allfed\"><u>ALLFED</u></a></td><td style=\"background-color:#e2e2e2;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>13</p></td><td style=\"background-color:#dedede;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>11</p></td><td style=\"background-color:#f5f9fd;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>4%</p></td><td style=\"background-color:#c6ddf2;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>17%</p></td><td style=\"background-color:#fff9e8;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>46%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/giving-what-we-can\"><u>GWWC</u></a></td><td style=\"background-color:#dedede;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>12</p></td><td style=\"background-color:#d2d2d2;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>15</p></td><td style=\"background-color:#f7fbfd;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>3%</p></td><td style=\"background-color:#bfd8f0;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>19%</p></td><td style=\"background-color:#f2f7f8;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>55%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/en-US/charities/wild-animal-initiative\"><u>Fish Welfare Initiative</u></a></td><td style=\"background-color:#dbdbdb;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>11</p></td><td style=\"background-color:#dbdbdb;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>12</p></td><td style=\"background-color:#f6fafd;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>3%</p></td><td style=\"background-color:#bbd6ef;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>20%</p></td><td style=\"background-color:#ebf2f3;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>58%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/en-US/charities/machine-intelligence-research-institute\"><u>MIRI</u></a></td><td style=\"background-color:#d7d7d7;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>10</p></td><td style=\"background-color:#d5d5d5;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>14</p></td><td style=\"background-color:#f7fbfd;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>3%</p></td><td style=\"background-color:#dae9f6;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>11%</p></td><td style=\"background-color:#ffffff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>50%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/en-GB/charities/founders-pledge-global-catastrophic-risks-fund?slug=charities&amp;slug=founders-pledge-global-catastrophic-risks-fund\"><u>FP Global Catastrophic Risks Fund</u></a></td><td style=\"background-color:#d3d3d3;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>9</p></td><td style=\"background-color:#cccccc;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>17</p></td><td style=\"background-color:#f9fcfe;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>2%</p></td><td style=\"background-color:#d5e6f5;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>13%</p></td><td style=\"background-color:#f8fafb;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>53%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/en-US/charities/ace-movement-grants\"><u>ACE Movement Grants</u></a></td><td style=\"background-color:#d0d0d0;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>8</p></td><td style=\"background-color:#cfcfcf;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>16</p></td><td style=\"background-color:#f9fbfe;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>3%</p></td><td style=\"background-color:#c5dcf1;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>17%</p></td><td style=\"background-color:#edf3f5;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>57%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/en-US/charities/faunalytics\"><u>Faunalytics</u></a></td><td style=\"background-color:#cccccc;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>7</p></td><td style=\"background-color:#c9c9c9;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>18</p></td><td style=\"background-color:#fafcfe;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>2%</p></td><td style=\"background-color:#d4e5f5;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>13%</p></td><td style=\"background-color:#fff7e2;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>45%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/global-health-and-development-fund\"><u>GHDF (EA Funds)</u></a></td><td style=\"background-color:#c9c9c9;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>6</p></td><td style=\"background-color:#c3c3c3;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>20</p></td><td style=\"background-color:#fdfeff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>2%</p></td><td style=\"background-color:#d9e8f6;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>11%</p></td><td style=\"background-color:#f0f5f6;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>56%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/nuclear-threat-initiative\"><u>NTI Bio Program</u></a></td><td style=\"background-color:#c5c5c5;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>5</p></td><td style=\"background-color:#c6c6c6;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>19</p></td><td style=\"background-color:#fdfeff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>2%</p></td><td style=\"background-color:#dbe9f7;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>11%</p></td><td style=\"background-color:#fffdf9;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>49%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/charities/malaria-consortium\"><u>Malaria Consortium</u></a></td><td style=\"background-color:#c1c1c1;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>4</p></td><td style=\"background-color:#c0c0c0;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>21</p></td><td style=\"background-color:#fdfeff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>1%</p></td><td style=\"background-color:#dbe9f7;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>11%</p></td><td style=\"background-color:#fdfefe;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>51%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/en-US/charities/gwwc-charity-elections\"><u>Charity Elections (GWWC)</u></a></td><td style=\"background-color:#bebebe;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>3</p></td><td style=\"background-color:#bdbdbd;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>22</p></td><td style=\"background-color:#ffffff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>1%</p></td><td style=\"background-color:#ebf3fa;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>6%</p></td><td style=\"background-color:#fff2cc;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>41%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/en-US/charities/patient-philanthropy-fund?slug=charities&amp;slug=patient-philanthropy-fund\"><u>FP Patient Philanthropy Fund</u></a></td><td style=\"background-color:#bababa;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>2</p></td><td style=\"background-color:#bababa;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>23</p></td><td style=\"background-color:#ffffff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>1%</p></td><td style=\"background-color:#e5eff9;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>8%</p></td><td style=\"background-color:#ffffff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>50%</p></td></tr><tr><td style=\"border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><a href=\"https://www.givingwhatwecan.org/en-US/charities/the-life-you-can-save?slug=charities&amp;slug=the-life-you-can-save\"><u>TLYCS</u></a></td><td style=\"background-color:#b7b7b7;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>1</p></td><td style=\"background-color:#b7b7b7;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>24</p></td><td style=\"background-color:#ffffff;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>1%</p></td><td style=\"background-color:#e8f1fa;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>7%</p></td><td style=\"background-color:#fafcfc;border:0.8333325pt solid #cccccc;padding:2pt;vertical-align:bottom\"><p>52%</p></td></tr></tbody></table></figure><p>It might also be interesting to look at how candidate projects varied in terms of how often people gave them <i>some</i> vs <i>a lot</i> of their points<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref3sjstoucv3s\"><sup><a href=\"#fn3sjstoucv3s\">[9]</a></sup></span>&nbsp;(the percent of&nbsp;their voters who gave them &lt;10%, 10%-90%, and &gt;90% of their points):</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/rpuvacvrvegexj5cgukt\"><figcaption>Chart: % of a candidate's voters who gave the candidate few, medium, or almost all of their points. In order of point totals, higher-scoring projects had more middle-ground voters than lower-scoring projects.&nbsp;</figcaption></figure><p>Finally, initial points were spread out more evenly across the four broad cause areas than the final results (pretty, unsurprisingly, given that there were going to be 3 winners):</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/rtdzieek03eyt2kfmta1\"><figcaption>Chart: points to causes before we ran the voting system and after (ie.. final results): even vs. 2:1 cross-cause and animal welfare.</figcaption></figure><h1>Consider exploring charities that weren\u2019t candidates!</h1><p>There were many promising charities that either&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly?commentId=nbKDH92eqrNiXgnDY\"><u>couldn\u2019t</u></a> be added as candidates, or simply weren\u2019t added this time. This includes a number of charities that shared information about their funding gaps and/or impact:&nbsp;</p><ul><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Centre_for_Enabling_EA_Learning_and_Research__CEEALAR_\"><u>The Centre for Enabling EA Learning and Research (CEEALAR)</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Doebem\"><u>Doebem</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Impactful_Animal_Advocacy\"><u>Impactful Animal Advocacy</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Legal_Impact_for_Chickens\"><u>Legal Impact for Chickens</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#ML_Alignment___Theory_Scholars__MATS__Program\"><u>ML Alignment &amp; Theory Scholars (MATS) Program</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Riesgos_Catastr_ficos_Globales__RCG_\"><u>Riesgos Catastr\u00f3ficos Globales (RCG)</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#High_Impact_Medicine__Hi_Med_\"><u>High Impact Medicine (Hi-Med)</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Maternal_Health_Initiative\"><u>Maternal Health Initiative</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Spiro\"><u>Spiro</u></a></li><li><a href=\"https://forum.effectivealtruism.org/posts/bBm64htDSKn3ZKiQ5/meet-the-candidates-in-the-forum-s-donation-election-2023#Vida_Plena\"><u>Vida Plena</u></a></li></ul><p>See more in&nbsp;<a href=\"https://forum.effectivealtruism.org/s/xourt4HttDM5QcHsk\"><u>this sequence</u></a>,&nbsp;<a href=\"https://forum.effectivealtruism.org/topics/giving-season-2023?sortedBy=magic\"><u>under the giving season tag</u></a>, and&nbsp;<a href=\"https://www.givingwhatwecan.org/en-US/best-charities-to-donate-to-2023\"><u>here</u></a>.&nbsp;</p><h1>Concluding thoughts: I'd love to see follow-up discussion!</h1><p>Did these results or data surprise<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefaaa6b9maww\"><sup><a href=\"#fnaaa6b9maww\">[10]</a></sup></span>&nbsp;you? Do you disagree with how people voted, or want to better understand why they voted in certain ways?<strong> I\u2019d love to see follow-up discussion on these topics</strong> \u2014 if you think voters misallocated their points, for instance, you probably also disagree with how they\u2019re distributing resources elsewhere. (I also hope that this post will provide additional information on what people \u201cin EA\u201d prioritize, at least right now.)</p><p>You might also be interested in <strong>donating to a charity that you hoped would win, but didn't </strong>(and/or explaining why people should donate to it).</p><p>And we might run similar events in the future, so<strong> I\u2019d welcome your thoughts on the&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly\"><strong><u>Donation Election</u></strong></a><strong> and&nbsp;</strong><a href=\"https://forum.effectivealtruism.org/posts/x2KfyNe8oPR4dqGkf/ea-forum-plans-for-giving-season-2023\"><strong><u>Giving Season</u></strong></a><strong> more broadly</strong>. (We might share more of a retrospective later, but I\u2019m not sure we\u2019ll want to prioritize a public post about this in particular.)</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn6w7y3qtru6v\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref6w7y3qtru6v\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Only Forum users who had accounts older than October 22, 2023 were eligible to vote (a measure to prevent voter fraud). We advertised the election fairly widely, but I expect this still represents heavier Forum users more than lighter Forum users.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5i6rlzul5i\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5i6rlzul5i\">^</a></strong></sup></span><div class=\"footnote-content\"><p>$5,000 of that was from the <a href=\"https://forum.effectivealtruism.org/posts/hAzhyikPnLnMXweXG/participate-in-the-donation-election-and-the-first-weekly#The_Online_Team_is_matching_donations_to_the_fund__up_to__1_000_per_person_who_donates_and__5_000_in_total___more_details\">Online Team\u2019s match</a>. We\u2019ll transfer the funds to winners when some people are back from their holidays in a few days. In case you're interested, here's some info on how many donors added to the fund:&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/xbvezz5fpamotu2j38o9\"></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3ezyp9nbamv\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3ezyp9nbamv\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Normalized such that everyone\u2019s points add up to the same number (in this post, this is always what I mean by \u201cpoints\u201d)&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntr1ycmhrith\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftr1ycmhrith\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I tweaked some slightly for clarity/length and/or to avoid highly recognizable styles (please reach out if you\u2019re worried and would like me to remove your comment).</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn2nnmomfgy38\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref2nnmomfgy38\">^</a></strong></sup></span><div class=\"footnote-content\"><p>I.e. all the candidates they gave nonzero points to got eliminated as votes were counted, which meant that their votes counted as additional votes split evenly between the remaining candidates, which would in practice even out the final proportions a bit. Their votes are also included in the information about point totals etc. here.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnuz6qyplz5gs\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefuz6qyplz5gs\">^</a></strong></sup></span><div class=\"footnote-content\"><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/dy1iuzfb2jjjmjmmzzmn\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/fge5tska1ai0fakopbcq 122w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/u5dwioxtgck4l69gj0e4 202w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/gdpgqeah7slqntegnpzm 282w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/o7tkq54cvbtwq3zb8nnv 362w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/eyfgncu5wblpkxtdwqcn 442w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/wcuo0g14mhixhjxcowsv 522w\"></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnn1fxp88lwtq\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefn1fxp88lwtq\">^</a></strong></sup></span><div class=\"footnote-content\"><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/zsru2cekqbibs2wif2xn\"></p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fndlkyvhfg6xf\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefdlkyvhfg6xf\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Interestingly, I think approval voting would have yielded similar winners (with a big assumption about how to extrapolate what people would have \u201capproved\u201d of) \u2014 if you rank projects by the number of voters who gave it at least 10%, for instance, the picture doesn\u2019t change much (if you increase from 10% to 20%, LTFF starts showing up in the top 3 again).&nbsp;</p><p>What would have happened with ranked-choice voting is very unclear to me; the voting system was in fact very different, and my quick attempts at trying to see what would happen if I tried to interpret the scores as ranks were extremely contingent on minor tweaks in how I interpret things and on decisions like whether I used \u201crankings\u201d of all the candidates or only the top 10, etc. If I only rank points given when they amount to over 5% of a voter\u2019s total points and add some randomness to produce rankings out of equal scores, the results look&nbsp;<i>fairly</i> similar, but I didn\u2019t do things carefully.&nbsp;</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn3sjstoucv3s\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref3sjstoucv3s\">^</a></strong></sup></span><div class=\"footnote-content\"><p>Note that e.g. only 2% of AWF voters gave it over 90% of their points, but this doesn\u2019t really mean that AWF has few \"committed\" voters; part of this is due to the fact that so many people gave some points to the AWF, but we can also see that AWF has a good chunk of voters who gave the AWF as many points as they gave any candidate (although in some cases they gave the same number of points to several candidates).&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/7D83kwkyaHLQSo6JT/adwep2ryz8fpaog1svaf\"><figcaption>Chart: among the voters for a given project, the % of voters for whom the project was top-scoring (in decreasing order): LTFF, AWF, FW, RP, CE, GD, MIRI, THL, AMF, ALLFED, Malaria Consortium, FWI, GFI, FP GCRF, GHDF, Faunalyics, Charity Elections, GWWC, ACE, EAIF, WAI, NTI Bio, FP Patient Philanthropy</figcaption></figure></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnaaa6b9maww\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefaaa6b9maww\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://manifold.markets/Tetraspace/if-this-charity-is-on-the-ea-donor-cabc5f558eaf\"><u>This market</u></a> predicted at least the order of the results decently well.</p></div></li></ol>", "user": {"username": "Lizka"}}, {"_id": "hjYWvngmuMskxkbDv", "title": "AISN #28: Center for AI Safety 2023 Year in Review", "postedAt": "2023-12-23T21:31:50.813Z", "htmlBody": "<p>Welcome to the AI Safety Newsletter by the <a href=\"https://www.safe.ai/\">Center for AI Safety</a>. We discuss developments in AI and AI safety. No technical background required.</p><p>Subscribe <a href=\"https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916\">here</a> to receive future versions.</p><p>As 2023 comes to a close, we want to thank you for your continued support for AI safety. This has been a big year for AI and for the Center for AI Safety. In this special-edition newsletter, we highlight some of our most important projects from the year. Thank you for being part of our community and our work.</p><hr><h1>Center for AI Safety\u2019s 2023 Year in Review</h1><p>The Center for AI Safety (CAIS) is on a mission to reduce societal-scale risks from AI. We believe this requires research and regulation. These both need to happen quickly (due to unknown timelines on AI progress) and in tandem<strong> </strong>(because either one is insufficient on its own). To achieve this, we pursue three pillars of work: research, field-building, and advocacy.</p><h2><strong>Research</strong></h2><p>CAIS conducts both technical and conceptual research on AI safety. We pursue multiple overlapping strategies which can be layered together to mitigate risk (\u201cdefense in depth\u201d). Though no individual technique brings risk to zero, we hope to build layered defenses which reduce risks to a negligible level.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbf0c289-ca28-4780-80d7-04c1178b2594_1174x510.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hjYWvngmuMskxkbDv/bpi3geense6a7agej6oq\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hjYWvngmuMskxkbDv/ecmtqgasnimvqzklsrcu 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hjYWvngmuMskxkbDv/hwrzprrmdbuo8ddueyna 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hjYWvngmuMskxkbDv/i7vdvb9hinubwvjumydo 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/hjYWvngmuMskxkbDv/bpi3geense6a7agej6oq 1456w\"></a></p><p>Here are a few highlights from our <strong>technical research</strong> in 2023:</p><ul><li><a href=\"https://llm-attacks.org\">LLM Attacks</a>: bypassed the safety guardrails on GPT-4, Claude, Bard, and Llama 2, causing models to behave dangerously such as by outputting instructions for building a bomb. This work created the field of automatic adversarial attacks for LLMs. It was covered by the <a href=\"https://www.nytimes.com/2023/07/27/business/ai-chatgpt-safety-research.html\">New York Times</a>.</li><li><a href=\"https://www.ai-transparency.org/\">Representation Engineering</a>: the first paper controlling the internals of models to cause models to lie or be honest. Experiments show these techniques can make AIs more truthful, power-averse, and ethical.&nbsp;</li><li><a href=\"https://aypan17.github.io/machiavelli/\">MACHIAVELLI Benchmark</a>: evaluated the ability of AI agents to make ethical decisions. The benchmark provides 13 measures of ethical behavior on deception, rule-following, power-seeking, and utility. Published as an <a href=\"https://icml.cc/virtual/2023/oral/25461\">oral paper in ICML 2023</a>.</li><li><a href=\"https://decodingtrust.github.io/\">DecodingTrust</a>: showed that GPT-4 is more vulnerable to misleading targeted system prompts than other models. It won the <a href=\"https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/\">outstanding paper award at NeurIPS 2023</a>.</li><li>We also published research on <a href=\"https://arxiv.org/abs/2311.04235\">rule-following for LLMs</a> and <a href=\"https://arxiv.org/abs/1908.08016\">unrestricted adversarial attacks</a>.</li><li>Our researchers are helping multiple labs, such as OpenAI and Meta, red-team their models.</li></ul><p>We also conducted <strong>conceptual research</strong> about AI safety:&nbsp;</p><ul><li><a href=\"https://arxiv.org/abs/2306.12001\">An Overview Catastrophic AI Risks</a> provides a comprehensive overview of AI risks. (<a href=\"https://www.wsj.com/tech/ai/ai-risk-humanity-experts-thoughts-4b271757\">Wall Street Journal</a>)</li><li><a href=\"https://arxiv.org/abs/2303.16200\">Natural Selection Favors AIs over Humans</a> argues that AI development will be shaped by natural selection, which will lead to selfish AIs which prioritize their own proliferation over human goals. (<a href=\"https://time.com/6283958/darwinian-argument-for-worrying-about-ai/\">TIME op-ed</a>)</li><li><a href=\"https://arxiv.org/abs/2308.14752\">AI Deception: A Survey of Examples, Risks, and Potential Solutions</a> provides empirical examples of AI deception, discusses the risks arising from it, and proposes technical and policy solutions.</li></ul><p>Building on our research expertise, CAIS helped host the <a href=\"https://trojandetection.ai\">NeurIPS 2023 Trojan Detection Competition</a>, which included a new track on red-teaming large language models. Over 125 teams participated and submitted over 3400 submissions.</p><h2>Field-Building</h2><p>CAIS aims to create a thriving research ecosystem that will drive progress towards safe AI. We pursued that goal in 2023 by providing compute infrastructure for AI researchers, creating educational resources for learning about the field, and other activities.&nbsp;</p><p><strong>Compute cluster. </strong>Conducting useful AI safety research often requires working with cutting-edge models, but running large-scale models is expensive and cumbersome. These difficulties often prevent researchers from pursuing advanced AI safety research. In February 2023, CAIS launched a compute cluster to provide free compute to researchers working on AI safety.</p><p>As of November 2023, we have onboarded around 200 users working on 63 AI safety projects. A total of 32 papers have been produced using the CAIS compute cluster, including:&nbsp;</p><ul><li><a href=\"https://arxiv.org/abs/2309.15840\">How to Catch an AI Liar</a></li><li><a href=\"https://arxiv.org/abs/2310.15213\">Function Vectors in Large Language Models</a></li><li><a href=\"https://arxiv.org/abs/2308.14761\">Unified Concept Editing in Diffusion Models</a></li><li><a href=\"https://arxiv.org/abs/2310.17645\">Defending Against Transfer Attacks From Public Models</a></li><li><a href=\"https://arxiv.org/abs/2311.14455\">Universal Jailbreak Backdoors from Poisoned Human Feedback</a></li><li><a href=\"https://drive.google.com/file/d/1iluFBhtQrv6kbmp4-Wsibpt5-U52CElO/view\">Seek and You Will Not Find: Hard-to-Detect Trojans in Deep Neural Networks</a></li><li><a href=\"https://openreview.net/forum?id=l3yxZS3QdT\">BIRD: Generalizable Backdoor Detection and Removal for Deep Reinforcement Learning</a></li><li><a href=\"https://arxiv.org/abs/2309.12288\">The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\"</a></li><li>\u2026 and <a href=\"https://www.safe.ai/compute-cluster\">24 more papers</a>.</li></ul><p>70% of labs that responded to our user survey noted their research project would not have been possible in its current scope without the compute cluster; the other 30% responded that the cluster significantly accelerates their research progress.</p><p><strong>Philosophy Fellowship.</strong> CAIS hosted a dozen academic philosophers for a seven month research fellowship this year. They produced 21 research papers on AI safety on topics such as <a href=\"https://drive.google.com/file/d/1Bp6iTbeXgdeE5C3UPqdWFOp8MePRylvu/view\">power-seeking AI</a> and the <a href=\"https://philpapers.org/archive/GOLAWE-4.pdf\">moral status of AI agents</a>, as well as other topics (<a href=\"https://www.safe.ai/philosophy-fellowship\">more here</a>). They\u2019ve also initiated three workshops at leading philosophy conferences, two books, various op-eds, and a <a href=\"https://link.springer.com/collections/cadgidecih\">special issue of a top journal</a> (which received over 30 research papers) all focused on AI safety. This greatly accelerates AI safety developing into an interdisciplinary enterprise.</p><p><strong>Events.</strong> CAIS brought together 20 legal academics, policy researchers, and policymakers for a three day workshop on Law and AI Safety. A group of attendees went on to found a consortium of legal academics interested in AI safety. They have also been working on a research agenda compendium, which is soon to be released. Of respondents to our survey, 100% researchers came away with more research ideas; 91% reported that they found the workshop very useful for meeting research collaborators.</p><p>We helped organize socials on ML Safety at ICML and NeurIPS, two top AI conferences, and roughly 300 researchers showed up at each to discuss AI safety. We participated in China\u2019s largest AI conference, the World AI Conference in Shanghai, where we facilitated <a href=\"https://drive.google.com/file/d/15gnLZsMMvtCy-lwCz5BhlWQ9-ni2TBak/view\">talks on AI safety</a> that reached more than 30,000 viewers.</p><p><strong>Textbook.</strong> <a href=\"https://www.aisafetybook.com/textbook/0-1\">An Introduction to AI Safety, Ethics, and Society</a> is a new textbook which will be published in an academic press early next year. It aims to provide an accessible and comprehensive introduction to AI safety that draws on safety engineering, economics, philosophy, and other disciplines. Those who would like to take a free online course based on the textbook can express their interest <a href=\"https://www.aisafetybook.com/express-interest\">here</a>.&nbsp;</p><p><strong>Online Course. </strong>Additionally, CAIS ran two online cohorts of Introduction to ML Safety, using a <a href=\"https://course.mlsafety.org\">curriculum</a> we developed last summer. These programs collectively onboarded ~100 students, researchers, and industry engineers to AI safety.</p><h2>Advocacy</h2><p>Public awareness and understanding of AI safety can encourage well-informed technical and policy solutions. CAIS advises governments and writes publicly in order to share information about AI safety.</p><p><strong>Statement on AI Risk. </strong>CAIS published the <a href=\"https://safe.ai/statement-on-ai-risk\">statement on AI extinction risk</a> which notably raised public and government awareness of the scale and importance of AI risks. Crucially, the statement on AI risk has placed AI extinction risk firmly within the Overton window of acceptable public discourse.</p><p>The statement has significantly affected the thinking of top leaders in the US and UK. Rishi Sunak <a href=\"https://twitter.com/RishiSunak/status/1663838958558539776\">directly responded</a> to the statement on AI risk, stating that \u201cThe [UK] government is looking very carefully at this.\u201d The White House Press Secretary, Karine Jean-Pierre, was <a href=\"https://www.usatoday.com/story/news/politics/2023/06/01/president-biden-warns-ai-could-overtake-human-thinking/70277907007/\">asked about the statement</a>, and commented that AI \"is one of the most powerful technologies that we see currently in our time. But in order to seize the opportunities it presents, we must first mitigate its risks.\" The President of the European Commission\u2019s State of the Union address <a href=\"https://ec.europa.eu/commission/presscorner/detail/en/speech_23_4426#:~:text=%E2%80%9CMitigating%20the%20risk%20of%20extinction,uses%20-%20both%20civilian%20and%20military.\">quoted the statement in full</a>.</p><p>The statement was covered by media outlets, including the <a href=\"https://drive.google.com/file/d/1RVxA5OyvuCFwupt-ptPjDzNe4GqB1yuN/view?usp=sharing\">New York Times (Front Page)</a>, <a href=\"https://www.theguardian.com/technology/2023/may/30/risk-of-extinction-by-ai-should-be-global-priority-say-tech-experts\">The Guardian</a>, <a href=\"https://www.bbc.com/news/uk-65746524\">BBC News</a>, <a href=\"https://www.reuters.com/technology/top-ai-ceos-experts-raise-risk-extinction-ai-2023-05-30/\">Reuters</a>, <a href=\"https://www.washingtonpost.com/business/2023/05/30/ai-poses-risk-extinction-industry-leaders-warn/\">The Washington Post</a>, <a href=\"https://edition.cnn.com/2023/05/30/tech/ai-industry-statement-extinction-risk-warning/index.html\">CNN</a>, <a href=\"https://www.ft.com/content/084d5627-5193-4bdc-892e-ebf9e30b7ea3\">Financial Times</a>, <a href=\"https://www.npr.org/2023/05/30/1178943163/ai-risk-extinction-chatgpt\">National Public Radio (NPR)</a>, <a href=\"https://www.thetimes.co.uk/article/ai-artificial-intelligence-robots-threat-humans-planet-b652g7xcr\">The Times, London</a>, <a href=\"https://www.bloomberg.com/news/videos/2023-05-31/center-for-ai-safety-s-hendrycks-on-ai-risks-video\">Bloomberg</a>, and <a href=\"https://www.wsj.com/articles/ai-threat-is-on-par-with-pandemics-nuclear-war-tech-executives-warn-39105eeb\">The Wall Street Journal (WSJ)</a>.</p><p><strong>Advising Policymakers. </strong>CAIS served as one of the primary technical advisors working with the UK Task Force on the science track for the UK AI Safety Summit. We responded to the NTIA\u2019s Request For Information with a proposed regulatory framework for AI. We were invited to join the World Economic Forum\u2019s <a href=\"https://initiatives.weforum.org/ai-governance-alliance/home\">AI Governance Alliance</a>, and are advising <a href=\"https://x.ai/about/\">xAI</a>, the UK State Department, the US State Department, and other governmental bodies. Lastly, CAIS helped initiate and advise a <a href=\"https://beta.nsf.gov/funding/opportunities/safe-learning-enabled-systems\">$20M grantmaking fund on AI safety</a> from the National Science Foundation.</p><p><strong>Communications &amp; Media. </strong>The public needs accurate and credible information on AI Safety. CAIS aims to fill that need with our <a href=\"https://newsletter.safe.ai\">two</a> <a href=\"https://newsletter.mlsafety.org\">newsletters</a> with over 7,500 subscribers, and our public writing in outlets such as <a href=\"https://time.com/6283958/darwinian-argument-for-worrying-about-ai/\">TIME</a> and the <a href=\"https://www.wsj.com/tech/ai/ai-risk-humanity-experts-thoughts-4b271757\">Wall Street Journal</a>. Separate from the statement-related engagements, CAIS has had over 50 major media engagements. CAIS Director Dan Hendrycks was named one of <a href=\"https://time.com/collection/time100-ai/6309050/dan-hendrycks/\">Time\u2019s 100 Most Influential People in AI</a>.</p><h2>Looking Ahead</h2><p>We have a number of projects set to launch in 2024. Over the coming months, these projects aim to mitigate catastrophic biorisks, enhance international coordination, and conduct technical research to enable safety standards and regulations.</p><h2>Support Our Work</h2><p>2023 was a big year and 2024 is shaping up to be even more critical. <strong>Your tax-deductible donation makes our work possible.</strong> You can support the Center for AI Safety's mission to reduce societal scale risks from AI by donating <a href=\"https://www.safe.ai/donate\">here</a>.</p><p>&nbsp;</p><p>Subscribe <a href=\"https://newsletter.safe.ai/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=113135916\">here</a> to receive future versions.</p>", "user": {"username": "Center for AI Safety"}}, {"_id": "f8MjQAAfq5tSBrsEX", "title": "\"Inftoxicity\" and other new words to describe malicious information and communication thereof", "postedAt": "2023-12-23T18:40:49.957Z", "htmlBody": "<p>The only way an act guided by good intention can reliably translate into a good outcome is when the act is done in a truthfully informed manner - which in turn requires true and trustworthy sources of information.&nbsp;</p><p>Therefore, I wanted to share here my proposition to start using new words such as \"inftoxic\" to describe information or data intentionally created or spread to cause harm, so that people can quickly identify and label them as untrustworthy.&nbsp;</p><p>The post is not meant to present the best way to do this but to see if other people would consider such terminology useful.</p><h2>Background</h2><p>We are becoming more and more surrounded by synthetic data (such as text or images generated by LLMs) and as these mix together with real-world, human-generated data, there is great need for ways how to distinguish between the two, as well as generally make sense of all the informational mess.</p><p>While writing about the risks arising from generating synthetic data with potential malicious uses, I realized that I was lacking the proper vocabulary to effectively describe \"a dataset that was intentionally constructed to mislead\". I have tried looking for a suitable adjective to describe such dataset, and having failed, I tried to <a href=\"https://chat.openai.com/share/e97d21b7-a513-4bcd-841e-1a1dd93463cd\">ask GPT4 to help me find and coin a new word for it</a>.&nbsp;</p><p>The conversation I had with the LLM was quite engaging at the time, and with some reflection there still seemed to be some valuable takeaways, so I decided to do this little writeup about it. <i>(Read the original conversation only at your own risk, haha!)</i></p><h2>Inftoxicity and related terms</h2><p>After some brainstorming from the GPT, I asked it to elaborate on the word \"<strong>inftoxic</strong>\" as an adjective that can be used to describe data, information sources, systems, actors, or actions that had been created with, or are acting in, a malicious intent to damage someone or something, or manipulate or mislead in a negative way.&nbsp;</p><p>This would be in contrast to \"<strong>biased</strong>\", which describes something or someone arriving at incorrect or misleading conclusions, yet not necessarily producing a negative outcome or being a result of malicious intent.&nbsp;</p><p>Below is a bunch of derivative words GPT4 was able to flesh out (slightly edited by me). I am intentionally leaving in all ten it generated, both to amuse the reader and inform of this interesting capability for creating novel words and definitions.</p><p><strong>Inftoxic - </strong><i>adjective&nbsp;</i></p><ul><li>Definition: Describes data, information sources, systems, actors, or actions that are created with or exhibit malicious intent to harm, manipulate, or mislead negatively. Distinguished from 'biased' by its deliberate and harmful nature.</li><li>Example: \"The inftoxic propaganda spread rapidly across social media, misleading thousands.\"</li></ul><p><strong>Inftox </strong><i>- noun, invariable</i></p><ul><li>Definition: An information, datapoint, or piece of news that is inftoxic; characterized by its harmful and deceptive quality.</li><li>Example: \"She realized too late that the article was an inftox, designed to incite fear.\"</li></ul><p><strong>Inftoxicity - </strong><i>noun, singular (plural: inftoxicities)</i></p><ul><li>Definition: A propensity or tendency to be inftoxic; often used to describe the overall harmfulness or deceitfulness of a particular source or collection of information.</li><li>Example: \"The inftoxicity of the leaked documents created widespread panic.\"</li></ul><p><strong>Inftoxinator - </strong><i>noun, singular (plural: inftoxinators)</i></p><ul><li>Definition: An individual or entity that creates or disseminates inftoxic content.</li><li>Example: \"The inftoxinator was eventually identified and apprehended for spreading false information.\"</li></ul><p><strong>Inftoxify - </strong><i>verb</i></p><ul><li>Definition: The act of making something inftoxic; to contaminate or corrupt with malicious intent.</li><li>Example: \"They attempted to inftoxify public opinion through a series of misleading ads.\"</li></ul><p><strong>Inftoxifiable - </strong><i>adjective</i></p><ul><li>Definition: Capable of being made inftoxic or susceptible to inftoxification.</li><li>Example: \"The dataset was inftoxifiable due to its open-source nature.\"</li></ul><p><strong>Inftoxication - </strong><i>noun, singular (plural: inftoxications)</i></p><ul><li>Definition: The state or effect of being influenced or damaged by inftoxic content.</li><li>Example: \"The population's inftoxication with false news became a serious concern for the government.\"</li></ul><p><strong>Inftoximeter - </strong><i>noun, singular (plural: inftoximeters)</i></p><ul><li>Definition: A hypothetical or conceptual tool to measure the level or extent of inftoxicity in information.</li><li>Example: \"If only we had an inftoximeter to gauge the trustworthiness of these reports.\"</li></ul><p><strong>Inftoxology - </strong><i>noun, singular (plural: inftoxologies)</i></p><ul><li>Definition: The study of inftoxic content, including its creation, dissemination, and effects.</li><li>Example: \"She specialized in inftoxology, particularly in the context of digital media.\"</li></ul><p><strong>Inftoxical - </strong><i>adjective</i></p><ul><li>Definition: Relating to or characteristic of inftoxicity; often used to describe environments or contexts that are heavily influenced by inftoxic content.</li><li>Example: \"The inftoxical environment of TikTok made it a breeding ground for misinformation.\"</li></ul><p><strong>Inftoxosphere - </strong><i>noun, singular (plural: inftoxospheres)</i></p><ul><li>Definition: The collective sphere or realm where inftoxic content is prevalent and influential.</li><li>Example: \"Navigating the inftoxosphere of online politics requires critical thinking and fact-checking skills.\"<br>&nbsp;</li></ul><h2>Implications and further directions</h2><p>I was part amused, part impressed and part intrigued by the new terminology above, which I was able to generate within minutes, yet which seemed potentially quite useful to the world at large (especially as we get to more widespread adoption of LLMs and as <a href=\"https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm\">ByteDance is using GPT4 to create synthetic datasets for its own LLM training</a>).&nbsp;</p><p>I continued the conversation asking about potential strategies for spreading this terminology so that there would be more awareness around information that is purposefully made or disseminated for malicious ends. I am not fully convinced I want to spread this terminology, but there is one approach suggested by GPT4 that I particularly liked:</p><h3>\"<strong>Spot the Inftox</strong>\" Challenge</h3><ul><li><strong>Theme:</strong> Encourage participants to share examples of inftoxic content they've encountered in their daily digital lives.</li><li><strong>Action</strong>: Participants should post a screenshot or description of the inftoxic content, explain why it's inftoxic, and tag it with a unique hashtag like #SpotTheInftox.</li><li><strong>Reward</strong>: Offer incentives such as featuring the best posts on your official page, merchandise, or even a small prize for the most insightful contributions.</li></ul><p>So, after getting all the way through my first post here, do you think this is worthy of spreading around? Want to help kick off the #SpotTheInftox challenge? Let me know in the comments! :) \ud83d\ude4f</p>", "user": {"username": "J\u00e1chym Fib\u00edr"}}, {"_id": "vhgQeuKGTBqqhG2cD", "title": "An Effective Altruist\u2019s guide to the holiday season", "postedAt": "2023-12-23T17:19:45.891Z", "htmlBody": "<p><i>I\u2019m telling you this for prayer,</i></p><p><i>My friend Luke and I have been arguing over how Effective Altruists should give this Holiday Season. Can you help us out?</i></p><p><i>Thanks,</i></p><p><i>Matthew</i></p><p>___</p><p>Dear Matthew,</p><p>Effective altruism is a philosophical movement around doing the most good with each dollar. I am sure there are some good organisations for you to give to.&nbsp;</p><p>A huge problem in the world is global poverty. Money you give to the developing world goes perhaps <a href=\"https://www.givingwhatwecan.org/en-US/effective-giving-101?slug=effective-giving-101#part-1-the-basics\">30x</a> further than the same donations in the West. If you imagine a poor couple, perhaps a pregnant mother unable to afford somewhere to live, we can trust them to use money on things they really need. Cash would let them pay for rooms and board, when their other options might be unstable. I might recommend <a href=\"https://www.givedirectly.org/\">GiveDirectly</a>.</p><p>Of course, now that we\u2019ve talked about stables, animal welfare is even more neglected. Innkeepers might claim to deliver high welfare standards, but even there, animals live in far less idyllic scenes than we imagine. They are cramped, dark with no hope of a good future. Billions of animals suffer awful conditions every year and even small changes might make their lives a lot better. So perhaps I\u2019d recommend the <a href=\"https://thehumaneleague.org.uk/\">Humane League</a>.</p><p>But we can go a step further on neglectedness - existential risks! Nuclear war, pandemics and AI. These things might change or ruin all our lives, and hardly any focus is given to them. So I would recommend you engage in some long term planning. Get your wise friends together, pool your gold, use your gifts and see where the ideas take you. It\u2019s hard to think well about the future, but someday we\u2019ll find a spokesperson with some star power. Let me know and donate to the <a href=\"https://funds.effectivealtruism.org/funds/far-future\">Long Term Future Fund</a>.</p><p>It\u2019s not just about donation opportunities though - we can increase the donation pool. There are big multipliers to be had in community building. Rather than you doing all this work directly you can share your knowledge. Whether they are social outcasts or choristers from powerful institutions, if you harp on enough, I\u2019m sure people will flock to your message. Have you heard of the <a href=\"https://funds.effectivealtruism.org/funds/ea-community\">EA Infrastructure Fund</a>?</p><p>Hold up. I\u2019ve come up with a thought. You mentioned you\u2019d chatted with a wealthy donor, one Herod the Great. I think you said he was worried about the birth of a being that would fundamentally disempower him. The AI folks are struggling for places to hold conferences and I hear he\u2019s got a lot of resources (maybe crypto?). You could get him more involved - what\u2019s the worst that could happen?&nbsp;</p><p>Whatever you do, do it joyfully. You <i>can </i>make a difference to the world. Thanks for caring!</p>", "user": {"username": "nathan"}}, {"_id": "W857Au4YJXAH7qNvp", "title": "AI Girlfriends Won't Matter Much", "postedAt": "2023-12-23T16:00:03.317Z", "htmlBody": "<p>Love and sex are pretty fundamental human motivations, so it\u2019s not surprising that they are incorporated into our vision of future technology, including AI.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F882e109f-ea3e-4235-9c7d-c1b17eaddd35_1280x720.jpeg\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/zxmtc99ngwas09cavdsu\" alt=\"Spike Jonze's Her: Sci-fi as social criticism\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/zmipkuptgxacxyg4ycet 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/ghpdluab2gaf4jgmiiyu 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/lsxt9jhjjnmg1d1hiwfm 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/zxmtc99ngwas09cavdsu 1456w\"></a></p><p>The release of <a href=\"https://twitter.com/andyohlbaum/status/1735786033453863422\"><u>Digi</u></a> last week immanentized this vision more than ever before. The app combines a sycophant and flirtatious chat feed with an animated character \u201cthat eliminates the uncanny valley, while also feeling real, human, and sexy.\u201d Their marketing material unabashedly promises \u201cthe future of AI Romantic Companionship,\u201d though most of the replies are begging them to break their promise and take it back.</p><p>Despite the inevitable popularity of AI girlfriends, however, they will not have large counterfactual impact. AI girlfriends and similar services will be popular, but they have close non-AI substitutes which have essentially the same cultural effect on humanity. The trajectory of our culture around romance and sex won\u2019t change much due to AI chatbots.</p><p>So what is the trajectory of our culture of romance?</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26b4d708-6ea9-4523-a5b4-57c2fd84d485_680x479.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/gns0avqdkzk4ikilswhw\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/cwvceykelv5wlodbwlpe 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/ecwdwvdpqv6tls2sychd 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/ugawrosloxvxiskwrbjo 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/gns0avqdkzk4ikilswhw 1456w\"></a></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcbd7d09-b6a0-4e36-9c19-69193d91de24_680x579.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/pnmxfsn7w1eqgntw1q8u\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/unpfasr2br2vfb3q6wcy 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/qzjabexaajxrkm4ld0rw 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/ylvkrrnmlpkshcwx5s5c 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/pnmxfsn7w1eqgntw1q8u 1456w\"></a></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9fe570d-4174-4795-bc17-f1a9e5d4f0b0_640x400.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/ygei1yjiem12iosljzur\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/kl1abpg6ev0dqnyvv5jd 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/jjziaitmuirl3oi5fk1x 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/qp0h7yrewfnynd2s6rz1 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/ygei1yjiem12iosljzur 1456w\"></a></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7abdefbe-2232-4563-9e9b-7e1cc3c49022_2062x1210.jpeg\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/o9svwqbtgcgtculfdb2u\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/v7u7m1ycknvt9eqzv8t7 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/etjytind2cckx44dotxm 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/nbv3n0wyiewkswzswdt4 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/o9svwqbtgcgtculfdb2u 1456w\"></a></p><p>Long before AI, there has been a trend towards less sex, less marriage, and more online porn. AI Girlfriends will bring down the marginal cost of chatrooms, porn, and OnlyFans. These are popular services so if a fraction of their users switch over, AI girlfriends will be big. But the marginal cost of these services is already extremely low.</p><p>Generating custom AI porn from a prompt is not much different than typing that prompt into your search bar and scrolling through the billions of hours of existing footage. The <a href=\"https://en.m.wikipedia.org/wiki/Rule_34\"><u>porno latent space has been explored so thoroughly by human creators</u></a> that adding AI to the mix doesn't change much.</p><p>AI girlfriends will be cheaper and more responsive but again there are already cheap ways to chat with real human girls online but most people choose not to. Demand is already close to satiated at current prices. AI girlfriends will shift the supply curve outwards and lower price but if everyone who wanted it was getting it already, it won't increase consumption.</p><p>My point is not that nothing will change, but rather that the changes from AI girlfriends and porn can be predicting by extrapolating the pre-AI trends. In this context at least, AI is a mere continuation of the centuries long trend of decreasing costs of communication and content creation. There will certainly be addicts and whales, but there are <a href=\"https://twitter.com/RubiRose/status/1730638225855676773/photo/2\"><u>addicts and whales</u></a> already. Human-made porn and chatrooms are near free and infinite, so you probably won\u2019t notice much when AI makes them even nearer free and even nearer infinite.</p><h3>Misinformation and Deepfakes</h3><p>There is a similar argument for other AI outputs. Humans have been able to create convincing and, more importantly, emotionally affecting fabrications since the advent of language.</p><p><img style=\"width:360px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/zcu0rpfp31ssojc0drsv\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/tnjf5l5mlrxeokllokz3 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/zcu0rpfp31ssojc0drsv 720w\"><img style=\"width:360px\" src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/zdyhwocqykhhrt45jgix\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/nhzs18erxxtdd2zyqtxv 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/W857Au4YJXAH7qNvp/zdyhwocqykhhrt45jgix 720w\"></p><p>More recently, information technology has brought down the cost of convincing fabrication by several orders of magnitude. AI stands to bring it down further. But people adapt and build their immune systems. Anyone who follows the Marvel movies has been prepared to see completely photorealistic depictions of terrorism or aliens or apocalypse and understand that they are fake.</p><p>There are other reasons to worry about AI, but changes from AI girlfriends and deepfakes are only marginal extensions of pre-AI capabilities that likely would have been replicated from other techniques without AI.</p>", "user": {"username": "Maxwell Tabarrok"}}, {"_id": "AsJZuqgeMycorKFr3", "title": "StrongMinds (5 of 9) - Depression's Moral Weight", "postedAt": "2023-12-24T11:51:04.824Z", "htmlBody": "<p><i>This is the fifth in SoGive's&nbsp; nine-post&nbsp;</i><a href=\"https://forum.effectivealtruism.org/sequences/zhDaftzpg6ArJQMNB\"><i>sequence&nbsp;</i></a><i>evaluating StrongMinds, &nbsp;authored by Ishaan&nbsp;with substantial input and support from Sanjay and Spencer.</i></p><p>Post 1:&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/GXBvATw7Why7xRDeM/why-sogive-is-publishing-an-independent-evaluation-of\"><u>Why SoGive is publishing an independent evaluation of StrongMinds</u></a></p><p>Post 2:&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/sJKgLxipgXn7TwiF5/floors-and-ceilings-frameworks-and-feelings-sogive-s-impact\"><u>Floors and Ceilings, Frameworks and Feelings: SoGive's Impact Analysis Toolkit for Evaluating StrongMinds</u></a></p><p>Post 3:&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/iJX6FmohigXtNWzAp/what-s-the-effect-size-of-therapy\"><u>What's the effect size of therapy?</u></a></p><p>Post 4:&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qFQ2b4zKiPRcKo5nn/strongminds-4-of-9-psychotherapy-s-impact-may-be-shorter\"><u>&nbsp;Psychotherapy's impact may be shorter lived than previously estimated</u></a></p><p>This post: Depression's Moral Weight</p><h2><strong>Executive summary</strong></h2><ul><li>Previous posts are aimed at finding the effect of depression in terms of SD-years. We want to be able to convert this to DALYs / QALYs, which can subsequently be plugged into moral weights frameworks and be directly compared to life saving interventions.</li><li>We find that every 1 SD-year of improvement in depression is worth 0.185 DALYs, and that 1 DALY is worth 5.4 SD-years of improvement.&nbsp;</li><li>On the PHQ-9, 1 DALY would correspond to 23 points of improvement for one year. The PHQ-9 is a 9 item depression questionnaire with possible scores from 0 to 27, where remission is at 4 and the typical patient who enrolled in a depression RCT scores 23.8 points.</li><li>We find that these choices would bring SoGive's moral weights within the range of subjective well being based views that were outlined in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness\"><u>GiveWell's review of HLI.</u></a></li><li>In the appendix, a spreadsheet can be found that allows the user to input their own moral weights. When our analysis is completed, this spreadsheet will allow the user to pick their moral weights and see how it changes their recommendation.</li><li>In addition, we\u2019ve created an easy-to-use tool to help donors determine their own moral weights \u2013 we call it the&nbsp;<a href=\"https://www.guidedtrack.com/programs/tshbjp4/run\"><u>MoralMeter tool</u></a>. We\u2019re keen for donors to try out the tool (still in beta) and provide feedback.</li><li>We come to these conclusions using time-trade-off data from&nbsp;<a href=\"https://d1wqtxts1xzle7.cloudfront.net/47226489/b_3Aqure.0000037482.92757.8220160713-25645-568oco-libre.pdf?1468445479=&amp;response-content-disposition=inline%3B+filename%3DUsing_the_effect_size_to_model_change_in.pdf&amp;Expires=1673253207&amp;Signature=YEzv0FX2-8mA5HXa8T4~jSO898s5YvCJC8bQDGYvSG2B7rAO3vx0h26kPMw6vDEnSYNN1EE7-oxx5fav~qa87W-C24KccLvji1quv52MqAIpCk98FpBmfLyshYtKyv7HS01iPNhWGQ5iJLP1VSYlNzZslQqRVzhJdLdZInLyCKOrat4nxPYC5S4JtUHeYDmCFwWEjv3F4oYGOy9Y1BRRbycZ5O1BjqY6M5Q9YoEVvAGCq9IP18MfW9Qf28vJ8SKXmdY0BwhOh2WWUBkudQF54xnPXPK0ZiF9XCqVaWB3A~UQroj0nub4OTm74nCqYkswKSltPSsQ8pCM4Taf~E2eNw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA\"><u>Sanderson (2004)</u></a>, in which physicians were asked how many healthy life-years they would trade for a given SD of improvement in depression.</li><li>Our conclusions are formed by combining this time-trade-off data with an estimate that the positive effects of psychotherapy mostly take place while patients are in the 2.3-3.1 SD range. Which range most of the positive effects take place during is an important uncertainty in this analysis, which is part of a wider uncertainty about how fast depression tends to fade more generally.&nbsp;</li><li>We also have important doubts about anchoring and framing effects in&nbsp; <a href=\"https://d1wqtxts1xzle7.cloudfront.net/47226489/b_3Aqure.0000037482.92757.8220160713-25645-568oco-libre.pdf?1468445479=&amp;response-content-disposition=inline%3B+filename%3DUsing_the_effect_size_to_model_change_in.pdf&amp;Expires=1673253207&amp;Signature=YEzv0FX2-8mA5HXa8T4~jSO898s5YvCJC8bQDGYvSG2B7rAO3vx0h26kPMw6vDEnSYNN1EE7-oxx5fav~qa87W-C24KccLvji1quv52MqAIpCk98FpBmfLyshYtKyv7HS01iPNhWGQ5iJLP1VSYlNzZslQqRVzhJdLdZInLyCKOrat4nxPYC5S4JtUHeYDmCFwWEjv3F4oYGOy9Y1BRRbycZ5O1BjqY6M5Q9YoEVvAGCq9IP18MfW9Qf28vJ8SKXmdY0BwhOh2WWUBkudQF54xnPXPK0ZiF9XCqVaWB3A~UQroj0nub4OTm74nCqYkswKSltPSsQ8pCM4Taf~E2eNw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA\"><u>Sanderson (2004)</u></a>, however,we believe it to be the most suitable source available.</li></ul><h2><strong>Introduction</strong></h2><p>This is an example of how a typical person diagnosed with depression might answer the PHQ-9. Our findings, based on a study that questioned people about their preferences, suggest that if these scores were to drop by 1 point for an entire year, that would be as morally good as granting them approximately as good as adding 15 days of extra life that year.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/tbj0gqlld3ooylddqsbg\"></p><p>&nbsp;A 24 point difference would correspond to a whole year's worth of gain. For each question, they get 0, 1, 2, or 3 points depending on how often they feel the depression symptom. There are nine questions, so the highest possible score is 27. 13.7 is the average score for someone diagnosed with depression, 5 is the minimum score to be considered depressed, and 1.2 is what we estimate the score of the general population would be after adjusting for floor effects.&nbsp; Having established how to convert 1 SD year of depression to DALYs/QALYs, we can then more easily compare this to a life saved, which is another established outcome within SoGive\u2019s moral weights framework.</p><p>In other posts, we calculate how many SD-years of depression are averted by psychotherapy interventions.&nbsp; We want to know how improvements in SD-years compare to interventions that save life, improve income, or improve health.&nbsp;</p><p>We converted SD-years into disability adjusted life years by looking at data regarding how much life expectancy people are willing to trade for a given amount of improvement in depression from&nbsp;<a href=\"https://d1wqtxts1xzle7.cloudfront.net/47226489/b_3Aqure.0000037482.92757.8220160713-25645-568oco-libre.pdf?1468445479=&amp;response-content-disposition=inline%3B+filename%3DUsing_the_effect_size_to_model_change_in.pdf&amp;Expires=1673253207&amp;Signature=YEzv0FX2-8mA5HXa8T4~jSO898s5YvCJC8bQDGYvSG2B7rAO3vx0h26kPMw6vDEnSYNN1EE7-oxx5fav~qa87W-C24KccLvji1quv52MqAIpCk98FpBmfLyshYtKyv7HS01iPNhWGQ5iJLP1VSYlNzZslQqRVzhJdLdZInLyCKOrat4nxPYC5S4JtUHeYDmCFwWEjv3F4oYGOy9Y1BRRbycZ5O1BjqY6M5Q9YoEVvAGCq9IP18MfW9Qf28vJ8SKXmdY0BwhOh2WWUBkudQF54xnPXPK0ZiF9XCqVaWB3A~UQroj0nub4OTm74nCqYkswKSltPSsQ8pCM4Taf~E2eNw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA\"><u>Sanderson (2004)</u></a>.</p><p>We discuss the implications of integrating this number into the&nbsp;<a href=\"https://thinkingaboutcharity.blogspot.com/2021/04/sogives-gold-standard-benchmarks.html\"><u>SoGive Gold Standard Benchmarks</u></a>, and how it compares to the moral weights of other organisations.</p><p>In the appendix, there is a spreadsheet which will allow you to change your moral weights and pick your own time trade off. More detailed calculations can be found in the footnotes. Interested readers are also encouraged to review&nbsp;<a href=\"https://www.guidedtrack.com/programs/tshbjp4/run\"><u>SoGive\u2019s MoralMeter tool</u></a> for comparing lives saved to tackling depression (still in beta); this also incorporates a number of considerations which are beyond the scope of this document.</p><h2>How much time would you trade to cure depression? Converting from SDs of depression to DALYs</h2><p><a href=\"https://d1wqtxts1xzle7.cloudfront.net/47226489/b_3Aqure.0000037482.92757.8220160713-25645-568oco-libre.pdf?1468445479=&amp;response-content-disposition=inline%3B+filename%3DUsing_the_effect_size_to_model_change_in.pdf&amp;Expires=1673253207&amp;Signature=YEzv0FX2-8mA5HXa8T4~jSO898s5YvCJC8bQDGYvSG2B7rAO3vx0h26kPMw6vDEnSYNN1EE7-oxx5fav~qa87W-C24KccLvji1quv52MqAIpCk98FpBmfLyshYtKyv7HS01iPNhWGQ5iJLP1VSYlNzZslQqRVzhJdLdZInLyCKOrat4nxPYC5S4JtUHeYDmCFwWEjv3F4oYGOy9Y1BRRbycZ5O1BjqY6M5Q9YoEVvAGCq9IP18MfW9Qf28vJ8SKXmdY0BwhOh2WWUBkudQF54xnPXPK0ZiF9XCqVaWB3A~UQroj0nub4OTm74nCqYkswKSltPSsQ8pCM4Taf~E2eNw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA\"><u>Sanderson (2004)</u></a> asked general practitioner doctors who had recently completed a 1 year masters in the recognition and management of mental health disorders&nbsp; to rate their trade-offs regarding various health states.&nbsp; Short vignettes and data from real patients who had scored 1, 2, and 3 SDs above remission were provided.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/valm7ly7ng7odrmuichl\"></p><p>To produce a rating scale (RS), the physicians were instructed to mark a spot on the vertical line (pictured above)&nbsp; with \"worse health\" and \"better health\" on either end.&nbsp; To produce a time-trade-off (TTO), the physicians were instructed to \"Imagine a person in this health state. They have a life expectancy of 10 years. They can either live for 10 years in this health state, or you can offer them a cure to perfect health but with a reduction in life expectancy. How many months and/or years do you think someone in this health state would be willing to give up to live in perfect health?\".&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/oro5asejntvr1x4m22ju\">&nbsp;</p><p>Time-trade-off and rating scale metrics are both methodologies that can potentially be used to create Quality Adjusted Life Years or Disability Adjusted Life Years metrics.</p><p>We combined&nbsp;<a href=\"https://d1wqtxts1xzle7.cloudfront.net/47226489/b_3Aqure.0000037482.92757.8220160713-25645-568oco-libre.pdf?1468445479=&amp;response-content-disposition=inline%3B+filename%3DUsing_the_effect_size_to_model_change_in.pdf&amp;Expires=1673253207&amp;Signature=YEzv0FX2-8mA5HXa8T4~jSO898s5YvCJC8bQDGYvSG2B7rAO3vx0h26kPMw6vDEnSYNN1EE7-oxx5fav~qa87W-C24KccLvji1quv52MqAIpCk98FpBmfLyshYtKyv7HS01iPNhWGQ5iJLP1VSYlNzZslQqRVzhJdLdZInLyCKOrat4nxPYC5S4JtUHeYDmCFwWEjv3F4oYGOy9Y1BRRbycZ5O1BjqY6M5Q9YoEVvAGCq9IP18MfW9Qf28vJ8SKXmdY0BwhOh2WWUBkudQF54xnPXPK0ZiF9XCqVaWB3A~UQroj0nub4OTm74nCqYkswKSltPSsQ8pCM4Taf~E2eNw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA\"><u>Sanderson (2004)</u></a>&nbsp;data with estimates of patient progress from the METAPSY database to produce an estimate of the number of QALYs saved / DALYs averted for the average patient. Conclusions are reported in the main body of the article - see footnotes for calculations.&nbsp;</p><h3>Sanderson (2004) \"remitted\" cutoff likely between PHQ-9 = 1 and PHQ-9 = 4, centred at PHq-9 = 2.95</h3><p>\"Remission\" is an arbitrary cut-off. In order to use time-trade off and rating scale data from&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a>, we first need to estimate where exactly on the depression scale their definition of \"remitted\" lies.&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> defines patients in remission if they do not have a depression diagnosis and have \"an SF-12 MCS score of 50 or more\".&nbsp;<br><br>Previously, we&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qFQ2b4zKiPRcKo5nn/strongminds-4-of-9-psychotherapy-s-impact-may-be-shorter#Setting_standards_for_remission_and_relapse\"><u>converted multiple depression scales to a single \"universal\"&nbsp; scale based on standard deviations from zero</u></a>, and established where each of their canonical remission and relapse cut-off points lay on that universal scale. Unfortunately, the SF-12 MCS was not among those scales.&nbsp;</p><p>We needed to convert the SF-12 MCS to a known quantity. The&nbsp;<a href=\"https://onlinelibrary.wiley.com/doi/full/10.1046/j.1525-1497.2001.016009606.x\"><u>PHQ-9 (Patient Health Questionnaire - 9)</u></a> is a nine-item quiz measuring depression severity. While our findings are intended to be applicable across many different depression scales, we decided to use the PHQ-9 to anchor our moral weights to a set of concrete statements concerning well-being.&nbsp;<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref5kc0ozfgyn\"><sup><a href=\"#fn5kc0ozfgyn\">[1]</a></sup></span></p><p>We have three hints that can help us to convert the SF-12 into a PHQ-9 score.&nbsp;</p><ul><li>An SF-12 score of 50 is intended to represent the mean score of the general population, which we<a href=\"https://forum.effectivealtruism.org/posts/qFQ2b4zKiPRcKo5nn/strongminds-4-of-9-psychotherapy-s-impact-may-be-shorter#Estimating_the_general_population_s_depression_level\"><u> previously estimated was at PHQ-9 = 1.22</u></a>.</li><li>Ishaan took the PHQ-9 and the SF-12 MCS at the same time, to establish which scores were considered approximately equivalent.&nbsp;</li><li>A PHQ-9 score of 4 is intended to represent remission.</li></ul><p>The&nbsp;<a href=\"https://orthotoolkit.com/sf-12/\"><u>12-item Short Form Survey</u></a>'s mental component score (SF-12 MCS) has an average of 50 and an SD of 10 points. We estimate a score of 50 SF-12 MCS corresponds to a PHQ-9 score somewhere between 1 and 4, most likely centering around 2.95 (see footnotes for calculation of this figure).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefwjoj19kxcv9\"><sup><a href=\"#fnwjoj19kxcv9\">[2]</a></sup></span>&nbsp;This translates to the 50-SF-12 MCS having a cutoff between 0.24 SDs and 0.95 SDs from zero, centred around 0.7 SDs.&nbsp;</p><p>Pretreatment PHQ-9 scores have a standard deviation of +<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1779714218&amp;range=B39\"><u>4.2</u></a>, so the locations of +1 SD, +2SD, and +3SD on the PHQ-9 can be found by adding +<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1779714218&amp;range=B39\"><u>4.2</u></a>\u00d71, +<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1779714218&amp;range=B39\"><u>4.2</u></a>\u00d72, and +<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1779714218&amp;range=B39\"><u>4.2</u></a>\u00d73 respectively.</p><h3>Typical therapeutic effect starts within the 2.3-3.1 SD range</h3><p>Because time trade-offs do not have a linear relationship to standard deviations of depression, we need to consider where on the scale the typical participant is as they experience their improvement to figure out what the slope of their trade-off is.&nbsp;</p><p>We find that the average METAPSY RCT participant begins treatment somewhere between 2.3 and 3.1 SDs from what&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> describes as the remission cutoff (see footnotes for calculation of this figure).<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftlmr84cvk4\"><sup><a href=\"#fntlmr84cvk4\">[3]</a></sup></span></p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/ofekg0uaarg96xmlqwxj\"></p><p>Figure: Our model of treated vs untreated patients suggests that the bulk of the benefits occur in the 2-3 SD range. The plausible range of what&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> intends as \"remission\" cutoff is marked.<br><br>To go from 3 to 2 SDs corresponds to a time-trade-off of&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=107759781&amp;range=O51\"><u>0.245</u></a> per SD improvement, or&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=107759781&amp;range=O50\"><u>0.21</u></a> points per SD when using the rating scale methodology, again based on data from&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> . However, given that depression has a spontaneous remission rate of 51% a year, untreated participants are expected to fall within the 1-2 SD range about halfway through the year (e.g. 3.1*51%^0.5=2.2, 2.7*51%^0.5=1.9). To go from 1 SD to 2SDs corresponds to a time-trade-off of&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=107759781&amp;range=N51\"><u>0.122&nbsp;</u></a>per SD improvement, or&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=107759781&amp;range=N50\"><u>0.15</u></a> SD when using the rating scale methodology. As our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qFQ2b4zKiPRcKo5nn/strongminds-4-of-9-psychotherapy-s-impact-may-be-shorter\"><u>analysis</u></a> suggests that almost all of the benefits occur in the first year, we want a value that is intermediate between these two numbers.</p><h3>We find 0.18 DALYs per SD of improvement, or 5.4 SDs per DALY</h3><p>We find 0.18 DALYs per SD of improvement when we take a weighted average of time-trade-offs and estimated effect sizes. It's about the same regardless of whether the&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=594575149&amp;range=S2\"><u>cutoff is assumed to be at PHQ-9 = 2.95</u></a> or&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=594575149&amp;range=S2\"><u>averaged between cutoffs at PHQ-9 =&nbsp;1 and 4</u></a>.&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/zvw635hghfzkgxckyhps\"><br>Using a simpler method of taking&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=107759781&amp;range=T49:T51\"><u>the average between the 1-2 SD transition and the 2-3 SD transition</u></a> also yields 0.18 adjusted life years. Additionally, using the rating scale (which is linear) also yields 0.18 adjusted life years.</p><p>Based on these considerations, we choose 5.4 SDs of psychotherapy-induced improvement, which on the PHQ-9 corresponds to 24 points of improvement (for instance, going from the worst PHQ-9 score of 27 to a remission score of 4) as being equivalent to one adjusted-life-year of improvement, with each SD of improvement being worth 0.18 adjusted life years, a little over 2 months.</p><h3>Key uncertainties - we used pre-intervention data to estimate the severity level treated.</h3><p>We would like to flag that we used the average patient status at the&nbsp;<i>beginning&nbsp;</i>of therapy. It would be more pessimistic to use reported scores at&nbsp;<i>post-treatment</i>, which are significantly lower.<br>&nbsp;<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/ppocr68t8lry0ah3ewfz\"></p><p>Because&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> patients valued improvements from 3-2 SD more than improvements from 2-1 SD, and more than improvements from 1 SD-remission, using lower post-treatment scores would break down the moral DALY weighting we place on psychotherapy, since it would lower the range within which the improvement is experienced.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/plob1ppcwzcfrrmop05j\"></p><p>If we had used the post-intervention model instead, the moral weight would fall from 0.18 to 0.10.&nbsp;</p><p>We decided to instead stick to the pretreatment baseline data and use our estimate of&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qFQ2b4zKiPRcKo5nn/strongminds-4-of-9-psychotherapy-s-impact-may-be-shorter\"><u>how long psychotherapy lasts&nbsp;</u></a>to plot the effect over time. We did this for several reasons:</p><ol><li>We thought of the idea of using post-intervention data later on in the analysis, and didn't want to make too many large last minute changes.</li><li>The 0.18 DALYs per SD figure has a few signs of robustness&nbsp;<ol><li>It matches the answer you would get if you used the rating scale methodology, rather than the time trade off methodology, and it's possible that the rating scale methodology is better.</li><li>it spans the distance from the maximum depression score to the remission score. On the PHQ-9 (which ranges from 0 to 27, with diagnostic cutoff from 3 to 4), at 0.10 DALYs per SD you would need 43 points of improvement on the PHQ-9 to reach 1 DALY.</li></ol></li><li>We're not sure as to whether the design of an RCT is well suited to estimating changes over time - for instance, if individuals drop out for similar reasons in the intervention group and in the control group, the effect size will not necessarily be distorted, but the appearance of remission for both intervention and control groups relative to baseline may well be inflated.&nbsp;<ol><li>In general, concerns about odd sources of improvement not associated with the intervention was a big part of the reason we didn't use meta-regression based methodologies such as those used by&nbsp;<a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2023/11/Talking-through-depression-The-cost-effectiveness-of-psychotherapy-in-LMICs-revised-and-expanded-November-2023.pdf\"><u>HLI McGuire 2023</u></a> and instead used data from relapse and remission rates.&nbsp;</li><li>&nbsp;Arguably, those same concerns should point us towards favouring relapse and remission based methodologies now.</li></ol></li><li>While we know that the average RCT in the METAPSY database did nine sessions, we don't have clear data on exactly how long each study was.</li></ol><p>Arguments for instead using post-intervention model data include&nbsp;</p><ol><li>We can't give a clear account for why exactly post-intervention data might overestimate spontaneous remission in both intervention and control group, so there's no reason not to use the available data.&nbsp;&nbsp;</li><li>Because the intervention is quick, almost all the supposed benefits occur after intervention.</li><li>If depression scales only measure the bottom half of life satisfaction, then arguably going from the maximum score to zero on a depression scale should only span half the range of what an adjusted life year might be counted as.<ol><li>However, this interpretation would be at odds with what&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> participants were reported as preferring.</li></ol></li></ol><h3>Key uncertainties - regarding the validity of the time trade off data</h3><p>We're somewhat suspicious that the format of asking people for their rating scales and time trade offs has generally anchored them towards considering the worst possible score as a full adjusted life year lost, and the best possible score on a given scale as a full adjusted life year experience. When a person is given two numerical scales and asked to align them, it might be natural for them to think that the ends of the scale ought to line up together, even if there is no reason why this should be so. We think that the method of first having people think of two specific times in their life and then naming their time trade off before introducing any surveys or scales to anchor on might be less vulnerable to this, but we haven't systematically collected data from many people using this method.</p><p>Another caveat is that the participants in&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> are physicians who are not selected for being currently depressed.&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/bdiDW83SFAsoA4EeB/a-philosophical-review-of-open-philanthropy-s-cause#2_1_2_Health_and_quantity_of_life\"><u>Plant (2022)</u></a> previously made the point that asking people to estimate the badness of health states that they are not currently experiencing may involve various forms of bias in various ways, and that point has generally not been addressed by our analysis.&nbsp;</p><h2>SoGive moral weights similar to subjective well being based methods</h2><p>The&nbsp;<a href=\"https://thinkingaboutcharity.blogspot.com/2021/04/sogives-gold-standard-benchmarks.html\"><u>SoGive gold standard</u></a> considers averting 1 death to be worth averting 25 cases of severe depression, and averting 1 case of severe depression to be worth doubling income 4 times. We find that when \"severe depression\" is defined as 5.46 SD-years of depression, it causes SoGive moral weights to converge with the ones used by subjective-well being centred views.&nbsp;</p><p>Using the numbers from GiveWell's&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness\"><u>Assessment of Happier Lives Institute\u2019s Cost-Effectiveness Analysis of StrongMinds \u2014 EA Forum</u></a>, we compared how far off SoGive was from the moral weights that could be arrived at using subjective-well-being based frameworks.&nbsp;</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/ilfooogo6hp5fa2axfor\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/brvhswzr9hpde9e3octr 147w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/unuxarp6kisnc2g3agme 227w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/s0i2ly515iqvj7a85ucu 307w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/lewe4spsb4abwdtxnodk 387w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/o2tyk1axme0qrcwl0vrv 467w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/zzeccm4v86ctcazxm7fm 547w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/ssg3cfbhsxe4yatc5oog 627w\"></figure><p><a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=973376132&amp;range=A1:D4\"><u>Table</u></a>: The relative moral weights that SoGive, HLI, and GiveWell would assign to various outcomes, with \"receiving a $1000 cash transfer\" (which is enough to double a GiveDirectly recipient's consumption about 3.5 times) to 1. Note: HLI has explicitly&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness?commentId=LqFS5yHdRcfYmX9jw\"><u>not taken a philosophical stance</u></a> (see section 2) on deprivationism or 0.5 as the neutral point.</p><p>We found that after incorporating 5.46 SD-years as the definition of \"severe depression\", SoGive's moral weights became similar to those found by HLI and GiveWell's analysis.&nbsp; We haven't spent enough time looking into the details of the other methods to know whether this similarity should be considered independent convergence or a coincidence.</p><h3>Comparing averting depression to cash&nbsp;</h3><p>Using the numbers from GiveWell's&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness\"><u>Assessment of Happier Lives Institute\u2019s Cost-Effectiveness Analysis of StrongMinds \u2014 EA Forum</u></a>, we find that with respect to the head-to-head cash comparison,&nbsp; HLI thinks that giving someone a $1000 lump sum improves their mental well being by 1.05 SDs (or 2.3 WELLBYs), and the positive impact on their family members multiplies this effect by 4.4, while GiveWell thinks that a $1000 cash transfer improves the mental health of all 4.7 individuals in recipient households by 0.89 SDs, for a total of&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=902328019&amp;range=B12\"><u>4.6 SD-years</u></a> (HLI) vs&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=902328019&amp;range=D12\"><u>4.2 SD-years</u></a>&nbsp; (GiveWell) of improvement per $1000 transferred. GiveWell's estimates are only 10% lower than HLIs, so we can consider them to be in agreement on this point.&nbsp;</p><p>We haven't spent time evaluating the value of cash transfers and we're not sure that these figures are directly comparable in this way, but if these&nbsp;<i>are</i> taken at face value, then it would imply that averting 5.46 SDs of depression is equivalent to 119%(according to givewell) or 130% (according to HLI) of the value of a $1000 cash transfer in terms of the improvement in subjective well being that it produces.&nbsp;&nbsp;&nbsp;</p><p>SoGive considers averting 5.46 SDs of depression to be worth four annual income doublings. GiveWell estimates that the GiveDirectly recipients consume&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/18ROI6dRdKsNfXg5gIyBa1_7eYOjowfbw5n65zkrLnvc/edit#gid=1680005064&amp;range=B19\"><u>$285.92</u></a> per year, which means that $1000 would serve to double income 3.5 times. This implies that SoGive moral weights consider averting 5.46 SDs of depression to be worth 4/($1000/$285.92)=114% of the value of a $1000 cash transfer. This means that SoGive moral weights are mostly in line with a subjective-well-being based evaluation of the value of averting depression, compared to cash.</p><h3>Comparing averting depression to saving lives&nbsp;</h3><p>Using the numbers from GiveWell's&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness\"><u>Assessment of Happier Lives Institute\u2019s Cost-Effectiveness Analysis of StrongMinds</u></a>, we find that GiveWell and HLI think that averting 1 SD-year of depression bestows&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=76487430&amp;range=D16\"><u>1.56</u></a> (GW),&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=76487430&amp;range=B16\"><u>2.17</u></a> (HLI) life satisfaction points,&nbsp; which means that they think averting 5.46 SDs of depression bestows 8.5 (GW), 11.9 (HL) life satisfaction points. They also think saving a life bestows&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=1455103561&amp;range=B6\"><u>223&nbsp;</u></a>(HLI),&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1YVDOLOdtSTwOd3fPaGkdl5OOEJlbho-9j9vc7TvX1kk/edit#gid=1455103561&amp;range=D6\"><u>224&nbsp;</u></a>(GiveWell) life satisfaction points, implying that they think saving a life is worth averting&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=973376132&amp;range=G9\"><u>19</u></a> (HLI) or&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=973376132&amp;range=F9\"><u>26</u></a> (GiveWell)&nbsp; cases of 5.46 SD depression.&nbsp;</p><p>SoGive considers averting 5.46 SDs of depression to be worth saving 25 lives, which falls between these values<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefbyqd0u3g0t8\"><sup><a href=\"#fnbyqd0u3g0t8\">[4]</a></sup></span>.</p><h2>SoGive's moral weights</h2><p>&nbsp;The remainder of this document (with the exception of the appendices) is a discussion of SoGive's internal moral weights process and how it has evolved during this evaluation, so it may not be of interest to all audiences.</p><h3>SoGive's benchmarks - \"severe\" depression, income doubling, and lives saved</h3><p>The&nbsp;<a href=\"https://thinkingaboutcharity.blogspot.com/2021/04/sogives-gold-standard-benchmarks.html\"><u>SoGive gold standard</u></a> as set out in 2021 values averting 25 years of \"severe depression\" as equivalent to averting 1 death, or doubling the income of 100 people.&nbsp;</p><p>In 2021, before doing an in-depth analysis on depression, SoGive conducted a poll to see how many income doublings and years of depression averted corresponded to a life saved. The result differed wildly (this is a&nbsp;<i>log&nbsp;</i>scale).</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/h2wxnbcbc9rd4b1iugex\"></p><p>We also&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FTLKg6WrFFbaACBQr/sogive-s-moral-weights-please-take-part\"><u>polled the EA community</u></a>, the results were somewhat less wild but still difficult to interpret.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/czixwepxrysgomvfaezw\"></p><p>Finally, we did a delphi process with a small focus group which included SoGive staff and volunteers. The focus group saw the results of the previous two polls, and were given the opportunity to change their response after seeing other people's responses, but the participants once again did not particularly reach consensus.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/qyck3su8epqwltt6mhee\"></p><p>It had been decided in advance that the SoGive process would involve setting the moral weights based heavily on the median of the SoGive team\u2019s responses.</p><p>Prior to finalising the moral weights, two senior members of the SoGive team (Sanjay and Alex) reviewed these responses and settled on SoGive moral weighting of 1 life being equivalent to 100 years of doubled consumption, or 25 years of severe depression averted. The process involved starting from the median of the SoGive team responses, conducting some sense checks and applying some rounding.</p><p>A commonly observed shortcoming of the Delphi process is that it doesn\u2019t provide a clear, canonical rationale for its conclusions. However, as part of the review process when finalising the weights, Sanjay and Alex made the following observations:</p><ul><li>This, at first glance, appears to place more value on tackling depression than one might expect from other DALY weights which tend to be in the range 0.65 to 0.7 for severe depression.</li><li>We judged that the Delphi process appeared to be accounting for concerns akin to those raised by&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/bdiDW83SFAsoA4EeB/a-philosophical-review-of-open-philanthropy-s-cause#2_1_2_Health_and_quantity_of_life\"><u>Plant (2022)</u></a>; this process occurred prior to 2022, but we were aware of these concerns independently of HLI, based on our own reviews of DALY/QALY methodology. In particular that the survey methods used in determining those weights may incorporate biases which underweight the severity of conditions like depression.</li><li>As an intuition pump, it seems that some people who are severely depressed are also suicidal, and it seems reasonable to believe that people who feel suicidal at least judge themselves to be experiencing a DALY weighting greater than 100% in that moment.</li><li>In terms of the conversion between one year and one life saved, other global health actors (including&nbsp;<a href=\"https://docs.google.com/document/d/1hOQf6Ug1WpoicMyFDGoqH7tmf3Njjc15Z1DGERaTbnI/edit#heading=h.f0xltfh4xf1m\"><u>GiveWell</u></a> in, e.g., 2019) have used similar conversions \u2013 a conversion of 30.3 years<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefzwum3i14rts\"><sup><a href=\"#fnzwum3i14rts\">[5]</a></sup></span>, in GiveWell\u2019s case. This largely reflects the use of discounting, specifically a discount rate of 3%. It\u2019s unclear whether participants were explicitly endorsing discounting or had some other rationale in mind. In&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/FZCiSThNff4N4PaGh/sogive-review-of-givewell-s-discount-rates#Appendix_2__An_alternative_view_on_the_probability_of_sufficiently_catastrophic_risks\"><u>later work on discounting</u></a>, we set out reasons why a discount rate of 2.3%&nbsp;<i>might</i> be suitable for this type of discounting, although this was heavily caveated work.</li></ul><h3>SoGive defining \"Severe Depression\" as 1 DALYs worth and the implications for the value of a statistical life</h3><p>After we began the StrongMinds analysis, we ran into a problem: the SoGive gold standard assigns a value to 25 cases of \"severe depression averted\". But depression is not a binary which is either \"severe\" or \"not severe\" and changing the threshold that decides severity can completely change the moral weights.</p><p>After discussions between Ishaan and Sanjay regarding what was originally meant by \"severe depression\", we decided that \"severe\" ought to mean \"you are experiencing something so bad that you'd rather just be unconscious and skip it\". In other words, a DALY weighting of &gt;=1, a QALY weighting of &lt;=0, or a neutral to negative experience in a utilitarian framework.</p><p>This is a fairly high level of severity. Although the SoGive process found severe depression to be valuable to tackle, our work to define \u201csevere depression\u201d somewhat offset this by saying that the valuable thing is an unusually demanding level of depression.</p><p>It is useful to reiterate here the ways in which the Delphi process was unhelpful for us \u2013 participants in the Delphi process likely did not have a consistent picture of what was meant by \u201csevere depression\u201d, and we were forced to make a judgement call after the event.</p><p>&nbsp;Given the time-trade-off literature above, we decided to set the definition of \"severe depression, sufficiently severe that it accounts for 1 DALY \" at 5.4 SDs of depression. This corresponds to an improvement of 24 points on the PHQ-9, where the maximum score is 27 and a score of 4 or below is considered non-depressed.&nbsp;&nbsp;</p><p>The implications of this choice entail further commitments. If SoGive believes that averting 25 cases of severe depression is equivalent to saving 1 life, and further believes that \"severe depression\" consists of averting 1 DALY, then it appears to imply that the value of a statistical life is 25 DALYs. In fact, things are more complicated than that. Some of the reasoning employed by participants in the Delphi process included considerations which don\u2019t fit naturally with this model (e.g. replacement effects \u2013 saving a child\u2019s life may mean depriving an as-yet unborn child of life, because if parents lose one child they might have another; epicureanism \u2013 a death matters because of the suffering it causes, but the years of life lost don\u2019t count because the dead person won\u2019t feel bad about losing those years). It\u2019s not clear how to incorporate the fact that such considerations are indirectly fed into the process. However, for the purposes of enabling progress on this analysis, we operated as if one life were equivalent to 25 DALYs.</p><p>Even though life expectancy is typically higher than 25, this isn't necessarily an unusual claim after adding various adjustments. For instance it's similar to&nbsp;<a href=\"https://docs.google.com/document/d/1hOQf6Ug1WpoicMyFDGoqH7tmf3Njjc15Z1DGERaTbnI/edit#heading=h.4ezmgjboichq\"><u>GiveWells' 2019 moral weights</u></a> (which seem to have modelled a death as equivalent to 30.3 years lost to disability).&nbsp;</p><p>One way to decide how many adjusted-life years are saved when a death is averted is to take the average life expectancy (e.g. 61 years in Sub-Saharan Africa), do adjustments to account for the fact that not every year of life is a year of full health (e.g. the health adjusted life expectancy (HALE) in sub-saharan africa might be around 55), and then add a discount rate so that future years matter less. For comparison, GiveWell has in the past treated a life saved as being equivalent to 30 years/DALYs; this is based on this World Bank paper (<a href=\"https://documents1.worldbank.org/curated/en/251181468140658232/pdf/364010PAPER0Gl101OFFICIAL0USE0ONLY1.pdf\"><u>Lopez et al 2006, p402</u></a>), which suggests that life expectancy at birth is around 30 years if we discount at 3% (and this doesn\u2019t reflect the \u201cHALE\u201d adjustment). See SoGive's Moral Meter tools for lives&nbsp;<a href=\"https://www.guidedtrack.com/programs/bjkk7aq/run\"><u>saved vs doubled consumption</u></a> and&nbsp;<a href=\"https://www.guidedtrack.com/programs/tshbjp4/run\"><u>lives saved vs depression averted</u></a> for more information (Note: these tools are still being developed and are \"in beta\").&nbsp;</p><h2>Appendix: Use our tool to find your personal time trade off</h2><p>Open the&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1326347579\"><u>User Moral Weights</u></a> tab on our cost effectiveness analysis.</p><p>Step 1: Pick two times you recall well, ideally one in which you were unhappy, and one in which you were happy.</p><p>Step 2:&nbsp; Fill out the PHQ-9 for two time points in your life by deleting the pre-filled answers and marking an X next to the spot which applies.&nbsp;</p><p><strong><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/dkv86x6wyzovuycotzy1\"></strong></p><p>Step 3: How much is that improvement worth to you, in terms of life-expectancy?&nbsp;</p><p>SoGive's moral weights are set to being willing to sacrifice 10 months of life expectancy for 10 months of improvement from PHQ-9=4 to PHQ-9=27.&nbsp;</p><p>If you, like me, haven't haven't experienced any mental state corresponding to PHQ-9=27, you might find this hard to grasp. This tool allows you to work with mental states which you have experienced.&nbsp;</p><p>If you asked me \"Would you rather experience 10 months of subjective experience at PHQ-9 score 15, or pay 3 months of life expectancy to upgrade that time to a PHQ-9 score of 4\", I would consider those to be about equally good and would have difficulty making the choice.</p><p>&nbsp;Therefore, for myself, I indicated that I would be willing to sacrifice&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=1779714218&amp;range=B23\"><u>3&nbsp;</u></a>months of life expectancy for 10 months of improvement from PHQ-9 = 4 to PHQ-9 = 15. This suggests that I would consider the subjective experience \"zero point\" to correspond to a PHQ-9 score of&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=69405324&amp;range=B27\"><u>36</u></a>, much higher than SoGive's 23. What about you?</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/hyqnzbodatwwqaedvobb\"></p><p>Step 4: When a life is saved, how many adjusted life years do you think that's worth? SoGive moral weights are currently set up such that if you could extend 25 people's life for 1 year right now, that would be as good as saving one child from death. What do you think that number should be?&nbsp;</p><p>I tried setting mine to&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=69405324&amp;range=B33\"><u>70</u></a>, which means that if you extend my life by 70 years, I would consider my life to have been saved. Bear in mind that people in worse health contexts probably don't expect to have 70 years of good health.</p><p><strong>Results:&nbsp;</strong>You will be able to see both your personal SD to DALY's conversion and your moral weights. The prefilled options will give SoGive's default moral weights, but they&nbsp; will shift in response to your answers to the above. Check that the number of hours you are willing to sacrifice for the given outcome is correct.</p><p>If you disagree with any of the moral weights, you can try changing them manually, but make sure that your results are internally consistent with the rest of what you have said.&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/fs1rqrtpwuqppqazl6ku\"></p><p>For example, try adjusting the value of income doubling.<strong>&nbsp;</strong>I'd sacrifice perhaps about&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=69405324&amp;range=J143\"><u>3 hours</u></a> of life, or endure 3 hours of circumstances so bad that I might prefer to turn off my subjective experience for the duration of that time rather than experience it, to be able to spend twice as much money that week. Per day, that would be giving up a little under half an hour, and 2.7% of my waking hours. That means that every time my income doubles for a year, I've gained about&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=69405324&amp;range=D143\"><u>0.027</u></a> adjusted life years, or&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=69405324&amp;range=F143\"><u>9.8&nbsp;</u></a>days for that year. If I believe that there are 70 adjusted-life-years to be had in my life, that means I would value saving a life such as mine as much as doubling the income of&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=69405324&amp;range=B143\"><u>2600&nbsp;</u></a>people like me.<strong>&nbsp;</strong>Bear in mind that people in low income contexts probably value cash more than this.</p><p><strong>Benefits:&nbsp;</strong>We're still in the process of working out exactly what the costs and SD-yers of therapy are, but you can check out the benefits of therapy as per the moral weights you entered. For example, were I to experience 0.18 SD-years of improvement for 6 weekly sessions of therapy, it would be a very good use of my time and money. I would gain about&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=69405324&amp;range=B95\"><u>7.6</u></a> adjusted-life-days worth of value that year, as good as increasing my income by 7.6/9.8= 78%, or decreasing my infant mortality by 7.6/(70\u00d7365)=0.03%. SoGive default moral weights suggest about twice that amount.</p><p>&nbsp;<img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/AsJZuqgeMycorKFr3/ee3hb2d8bwnbwmz3jn3n\"></p><p><strong>Note:&nbsp;</strong>As we saw in the delphi process, people differ widely in which trade-offs they are willing to make. Additionally, as we saw from&nbsp;<a href=\"https://d1wqtxts1xzle7.cloudfront.net/47226489/b_3Aqure.0000037482.92757.8220160713-25645-568oco-libre.pdf?1468445479=&amp;response-content-disposition=inline%3B+filename%3DUsing_the_effect_size_to_model_change_in.pdf&amp;Expires=1673253207&amp;Signature=YEzv0FX2-8mA5HXa8T4~jSO898s5YvCJC8bQDGYvSG2B7rAO3vx0h26kPMw6vDEnSYNN1EE7-oxx5fav~qa87W-C24KccLvji1quv52MqAIpCk98FpBmfLyshYtKyv7HS01iPNhWGQ5iJLP1VSYlNzZslQqRVzhJdLdZInLyCKOrat4nxPYC5S4JtUHeYDmCFwWEjv3F4oYGOy9Y1BRRbycZ5O1BjqY6M5Q9YoEVvAGCq9IP18MfW9Qf28vJ8SKXmdY0BwhOh2WWUBkudQF54xnPXPK0ZiF9XCqVaWB3A~UQroj0nub4OTm74nCqYkswKSltPSsQ8pCM4Taf~E2eNw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA\"><u>Sanderson (2004)</u></a>, individuals who are comparing more severe states will likely assign alleviation of that state more moral weight if the question is posed as a time trade off rather than a rating scale. Therefore, it's most likely best to rely more on aggregated responses (as we have done with&nbsp;<a href=\"https://d1wqtxts1xzle7.cloudfront.net/47226489/b_3Aqure.0000037482.92757.8220160713-25645-568oco-libre.pdf?1468445479=&amp;response-content-disposition=inline%3B+filename%3DUsing_the_effect_size_to_model_change_in.pdf&amp;Expires=1673253207&amp;Signature=YEzv0FX2-8mA5HXa8T4~jSO898s5YvCJC8bQDGYvSG2B7rAO3vx0h26kPMw6vDEnSYNN1EE7-oxx5fav~qa87W-C24KccLvji1quv52MqAIpCk98FpBmfLyshYtKyv7HS01iPNhWGQ5iJLP1VSYlNzZslQqRVzhJdLdZInLyCKOrat4nxPYC5S4JtUHeYDmCFwWEjv3F4oYGOy9Y1BRRbycZ5O1BjqY6M5Q9YoEVvAGCq9IP18MfW9Qf28vJ8SKXmdY0BwhOh2WWUBkudQF54xnPXPK0ZiF9XCqVaWB3A~UQroj0nub4OTm74nCqYkswKSltPSsQ8pCM4Taf~E2eNw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA\"><u>Sanderson (2004)</u></a>.</p><h2>Appendix: Why we didn't use suicidal thoughts or behavior to set the zero point</h2><p>Content note: Extended discussion of suicide.&nbsp;</p><p>We tried using suicidal thoughts or behaviors to anchor a specific \"zero point\" on the PHQ-9 scale which is equivalent to 1 DALY or 0 QALYs, but were not able to identify any such threshold at which suicidal thoughts or behaviors reliably increase. Suicide did not ultimately influence our final moral weights, so reading this section is not necessary to understand this article or its conclusions.&nbsp;</p><p>The \"zero point\" corresponds to&nbsp; a state so bad that a person would prefer to subjectively \"skip it\", or would trade a year of life expectancy to avert a year of it, or for a utilitarian the threshold between an experience counting as positive and negative utility. Importantly for this discussion, it is&nbsp;<i>not</i> necessarily the state at which it is theoretically rational to choose suicide, because it only describes how a person feels right now, not how they will always feel: Within the framework of maximizing points on this scale, a person experiencing life below the \"zero point\" rationally ought to persist in the hope that future years would involve states of being that are above zero. This hope would be well justified, considering the fairly robust spontaneous remission rate.</p><p>Given that most cases of depression do remit even without treatment, suicide due to depression would almost always be a net welfare loss within an&nbsp; \"adjusted life year\" type of framework even if one sets the zero point at a fairly high level. Therefore, the vast majority of suicidal behaviors, thoughts, and impulses which are attributed to depression severity specifically can't be considered a case of rational choice or revealed preference, and can't be straightforwardly plugged into this framework without breaking internal consistency. Nevertheless, if there was a particular threshold of subjective badness beyond which suicidal thoughts and suicidal attempts reliably began, it might be used to anchor intuitions and set some lower and upper bounds for where the \"zero point\" might be.</p><p>In the hopes of grounding the \"zero point\" in something more empirical,&nbsp; we did try and check whether there was a specific point on the depression scale beyond which people do, in fact, tend to choose suicide, or a particular threshold at which suicidal thoughts begin to arise. We were unable to identify any such clear&nbsp; point or threshold - suicide risk is associated with both increasing depression score and with increasing self-reported suicidal ideation, but is not particularly well predicted by it&nbsp;<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0165032717309655\"><u>(Na, 2018)</u></a>, with one paper&nbsp;<a href=\"https://sci-hub.ru/10.1176/appi.ps.201200587\"><u>(Simon, 2013)</u></a> finding that 25% of suicides self-reported no suicidal ideation.<br><br>Our overall impression is that the act of committing suicide is better predicted by disorders of impulsivity rather than depressive symptoms, questionnaires regarding suicidality are relatively poor predictors of suicidal behavior, and that while suicidal thoughts are a depression symptom, we were unable to ascertain specific threshold of badness at which they appear.&nbsp; We therefore continue to instead rely on time-trade-off estimates in setting the zero point.</p><h2><strong>Citations</strong></h2><h3>General resources from SoGive</h3><p><a href=\"https://www.guidedtrack.com/programs/tshbjp4/run\"><u>MoralMeter tool</u></a></p><p><a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=737864597&amp;range=B2\"><u>SoGive Cost-effectiveness analysis, StrongMinds&nbsp; (in progress)</u></a>&nbsp;</p><p><a href=\"https://docs.google.com/spreadsheets/d/1aM8ao9peYcnDwPn_yZeaUSrijqafLGRybS6zPm6rE-A/edit\"><u>Mental Health - Meta Analysis</u></a>&nbsp;</p><p><a href=\"https://thinkingaboutcharity.blogspot.com/2021/04/sogives-gold-standard-benchmarks.html\"><u>SoGive's Gold Standard Benchmarks</u></a>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/FZCiSThNff4N4PaGh/sogive-review-of-givewell-s-discount-rates#Appendix_2__An_alternative_view_on_the_probability_of_sufficiently_catastrophic_risks\"><u>Joshi (2022), \"SoGive review of GiveWell\u2019s discount rates\", SoGive</u></a>&nbsp;</p><h3>Time trade off data</h3><p><a href=\"https://link.springer.com/article/10.1023/B:QURE.0000037482.92757.82\"><u>Sanderson, K., Andrews, G., Corry, J., &amp; Lapsley, H. (2004). Using the effect size to model change in preference values from descriptive health status. Quality of Life Research, 13, 1255-1264.&nbsp;</u></a></p><h3>Sources relating to ascertaining what SD range was appropriate for time trade off</h3><p><strong>SoGive calculations</strong>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/qFQ2b4zKiPRcKo5nn/strongminds-4-of-9-psychotherapy-s-impact-may-be-shorter#Setting_standards_for_remission_and_relapse\"><u>StrongMinds (4 of 9) - Psychotherapy's impact may be shorter lived than previously estimated - Setting Standards for Remission and Relapse</u></a></p><p><strong>Metapsy</strong>&nbsp;</p><p>Pim Cuijpers , Clara Miguel , Mathias Harrer , Constantin Yves Plessen , Marketa Ciharova , David Ebert , Eirini Karyotaki&nbsp; (2022) . Database of depression psychotherapy trials with control conditions.&nbsp;<i>Part of the Metapsy project</i> (Version 22.0.2 ). URL&nbsp;<a href=\"https://docs.metapsy.org/databases/depression-psyctr/#citation\"><u>docs.metapsy.org/databases/depression-psyctr</u></a> DOI&nbsp;<a href=\"https://zenodo.org/doi/10.5281/zenodo.7254845\"><u>https://zenodo.org/doi/10.5281/zenodo.7254845</u></a>&nbsp; Github:&nbsp;<a href=\"https://github.com/metapsy-project/data-depression-psyctr/tree/22.0.2\"><u>https://github.com/metapsy-project/data-depression-psyctr/tree/22.0.2</u></a>&nbsp;</p><h3>References relating to questionnaires</h3><p><a href=\"https://orthotoolkit.com/sf-12/\"><u>Free Online SF-12 Score Calculator - OrthoToolKit</u></a> (n.d.). https://orthotoolkit.com/sf-12/&nbsp;</p><h3>Other EA organizations</h3><p><a href=\"https://www.happierlivesinstitute.org/wp-content/uploads/2023/11/Talking-through-depression-The-cost-effectiveness-of-psychotherapy-in-LMICs-revised-and-expanded-November-2023.pdf\"><u>McGuire, J (2023), \"Talking through depression: The cost-effectiveness of psychotherapy in LMICs, revised and expanded\", Happier Lives Institute&nbsp;</u></a>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/bdiDW83SFAsoA4EeB/a-philosophical-review-of-open-philanthropy-s-cause#2_1_2_Health_and_quantity_of_life\"><u>Plant (2022), \"A philosophical review of Open Philanthropy\u2019s Cause Prioritisation Framework\", Happier Lives Institute</u></a>&nbsp;</p><p><a href=\"https://forum.effectivealtruism.org/posts/h5sJepiwGZLbK476N/assessment-of-happier-lives-institute-s-cost-effectiveness#Publication_bias\"><u>Cohen (2023), \"Assessment of Happier Lives Institute\u2019s Cost-Effectiveness Analysis of StrongMinds\". GiveWell</u></a></p><p><a href=\"https://docs.google.com/document/d/1hOQf6Ug1WpoicMyFDGoqH7tmf3Njjc15Z1DGERaTbnI/edit#heading=h.f0xltfh4xf1m\"><u>[public] 2020 update on GiveWell's moral weights - GiveWell</u></a>&nbsp;&nbsp;</p><h3>Suicidal ideation&nbsp;</h3><p><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0165032717309655\"><u>Na, P. J., Yaramala, S. R., Kim, J. A., Kim, H., Goes, F. S., Zandi, P. P., ... &amp; Bobo, W. V. (2018). The PHQ-9 Item 9 based screening for suicide risk: a validation study of the Patient Health Questionnaire (PHQ)\u2212 9 Item 9 with the Columbia Suicide Severity Rating Scale (C-SSRS). Journal of affective disorders, 232, 34-40.</u></a></p><p><a href=\"https://sci-hub.ru/10.1176/appi.ps.201200587\"><u>Simon, G. E., Rutter, C. M., Peterson, D., Oliver, M., Whiteside, U., Operskalski, B., &amp; Ludman, E. J. (2013). Does response on the PHQ-9 Depression Questionnaire predict subsequent suicide attempt or suicide death?. Psychiatric services, 64(12), 1195-1202.</u></a></p><p><br>&nbsp;</p><p>&nbsp;</p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn5kc0ozfgyn\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref5kc0ozfgyn\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;We decided to use the PHQ-9 as an anchor point from which to build out our moral weights, because the PHQ-9 is used by StrongMinds&nbsp;<a href=\"https://strongminds.org/wp-content/uploads/2023/11/2023-Q2-report-8.5x11-FINAL.pdf\"><u>internal M&amp;E</u></a>, was previously used by&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1kPqBeHN3b7tq9gxho-9M7VGCuO-14CCI1YEsywmy66E/edit#gid=1907596966&amp;range=A7\"><u>Founders Pledge's M&amp;E</u></a>, because we previously generated&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/sJKgLxipgXn7TwiF5/floors-and-ceilings-frameworks-and-feelings-sogive-s-impact#7_Using_Z_scores___standard_scores_to_create_conversion_tables\"><u>conversion scales</u></a> for it, because PHQ-9 scores were&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/sJKgLxipgXn7TwiF5/floors-and-ceilings-frameworks-and-feelings-sogive-s-impact#7_Using_Z_scores___standard_scores_to_create_conversion_tables\"><u>closest to the weighted average</u></a> of all questionnaire types for pretreatment mean score distance from minimum and maximum scores, and because it is quick and convenient to take.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnwjoj19kxcv9\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefwjoj19kxcv9\">^</a></strong></sup></span><div class=\"footnote-content\"><p><a href=\"https://d1wqtxts1xzle7.cloudfront.net/47226489/b_3Aqure.0000037482.92757.8220160713-25645-568oco-libre.pdf?1468445479=&amp;response-content-disposition=inline%3B+filename%3DUsing_the_effect_size_to_model_change_in.pdf&amp;Expires=1673253207&amp;Signature=YEzv0FX2-8mA5HXa8T4~jSO898s5YvCJC8bQDGYvSG2B7rAO3vx0h26kPMw6vDEnSYNN1EE7-oxx5fav~qa87W-C24KccLvji1quv52MqAIpCk98FpBmfLyshYtKyv7HS01iPNhWGQ5iJLP1VSYlNzZslQqRVzhJdLdZInLyCKOrat4nxPYC5S4JtUHeYDmCFwWEjv3F4oYGOy9Y1BRRbycZ5O1BjqY6M5Q9YoEVvAGCq9IP18MfW9Qf28vJ8SKXmdY0BwhOh2WWUBkudQF54xnPXPK0ZiF9XCqVaWB3A~UQroj0nub4OTm74nCqYkswKSltPSsQ8pCM4Taf~E2eNw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA\"><strong><u>Sanderson (2004)</u></strong></a><strong> \"remitted\" cutoff likely between PHQ-9 = 1 and PHQ-9 = 4, centred at PHQ-9 = 2.95:&nbsp;</strong>&nbsp;To do a rough check of this, Ishaan filled out both questionnaires and got SF-12 MCS = 47.5 and PHQ-9 = 4. The SF-12 MCS is designed to have a standard deviation of 10, and the PHQ-9 has a standard deviation of&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=69405324&amp;range=B39\"><u>4.2</u></a>, which suggests that if Ishaan's answers are representative then&nbsp; <a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> would consider patients depressed with a PHQ-9 score of 4-(50-47.5)/10*<a href=\"https://docs.google.com/spreadsheets/d/1sNB40ot0sfa4v3OdF0Pv9F99hSKImbrjyTVfnISJeFU/edit#gid=69405324&amp;range=B39\"><u>4.2</u></a>=2.95 or more. PHQ-9 considers people not depressed if they score 4 or less, and depressed if they score 5 or more.</p><p>Of note, our last post included a section on&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qFQ2b4zKiPRcKo5nn/strongminds-4-of-9-psychotherapy-s-impact-may-be-shorter#Estimating_the_general_population_s_depression_level\"><u>estimating the general population's depression level\"</u></a> , where we estimated that after correcting for floor effects, the general population would have a PHQ-9 score of approximately&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1aM8ao9peYcnDwPn_yZeaUSrijqafLGRybS6zPm6rE-A/edit#gid=1930891527&amp;range=D7\"><u>1.22</u></a>, whereas the SF-12 MCS has a mean of 50. This mildly contradicts the calculations above - which could mean that in reality the general population is closer to a PHQ-9 score of 2.95. However, it could also be an idiosyncrasy of how I took the test, or it could mean that PHQ-9 exerted its floor effects on the way that I took the test (since the PHQ-9 has no options better than \"neutral\" whereas the SF-12 MCS has actively \"positive\" items like \"feeling calm and peaceful\" and having a \"lot of energy\").</p><p>Based on these facts, we think it's probably pretty reasonable to posit that&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> raters consider some state in between PHQ-9 score 1 and PHQ-9 score 4 as being \"in remission\", with our central guess being that \"remission\" in&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> means PHQ-9 = 2.95</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fntlmr84cvk4\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreftlmr84cvk4\">^</a></strong></sup></span><div class=\"footnote-content\"><p><strong>Typical therapeutic effect starts within the 2-3 SD range.&nbsp;</strong>We find that the average METAPSY RCT participant begins treatment somewhere between 0.24*(13.78-4)= 2.3 SDs and 0.24*(13.78-1)= 3.1 SDs from what&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> describes as the remission cutoff.&nbsp;</p><p>In our&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/qFQ2b4zKiPRcKo5nn/strongminds-4-of-9-psychotherapy-s-impact-may-be-shorter#Setting_standards_for_remission_and_relapse\"><u>previous article we reported</u></a> that among the 5 most commonly used depression scales administered in the METAPSY database, the mean score tended to be&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1aM8ao9peYcnDwPn_yZeaUSrijqafLGRybS6zPm6rE-A/edit#gid=37133413&amp;range=D41\"><u>50%</u></a> of the way between zero and the highest possible score, with zero being&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1aM8ao9peYcnDwPn_yZeaUSrijqafLGRybS6zPm6rE-A/edit#gid=37133413&amp;range=B41\"><u>3.2 SDs</u></a> from the mean. Each point on the PHQ-9 is 0.24 SD. With the average PHQ-9 score being&nbsp;<a href=\"https://docs.google.com/spreadsheets/d/1aM8ao9peYcnDwPn_yZeaUSrijqafLGRybS6zPm6rE-A/edit#gid=37133413&amp;range=B32\"><u>13.78</u></a>, and with our previous estimate that that&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> remission cutoffs are equivalent to between 1 and 4 phq-9 points, the average METAPSY RCT participant falls somewhere between 0.24*(13.78-4)= 2.3 SDs and 0.24*(13.78-1)= 3.1 SDs from what&nbsp;<a href=\"https://sci-hub.ru/10.2307/4038937\"><u>Sanderson (2004)</u></a> describes as the remission cutoff.&nbsp;&nbsp;</p><p>The general equation is&nbsp;<br><strong>PHQ-9 SD)</strong>\u00d7<strong>(PHQ-9 mean-remission cutoff),</strong> with means and SDs taken from Metapsy and 1, 2.95 and 4 previously established as some reasonable places to consider the remission cutoffs as being.</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnbyqd0u3g0t8\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefbyqd0u3g0t8\">^</a></strong></sup></span><div class=\"footnote-content\"><p>When represented on the table above, thesee values are multiplied by the value of averting 5.46 sd-years depression (for example SoGive's column would be 25*114%=28.59</p></div></li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnzwum3i14rts\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefzwum3i14rts\">^</a></strong></sup></span><div class=\"footnote-content\"><p>&nbsp;The 30.3 figure is calculated using the 2019 column on the&nbsp;<a href=\"https://docs.google.com/document/d/1hOQf6Ug1WpoicMyFDGoqH7tmf3Njjc15Z1DGERaTbnI/edit#heading=h.f0xltfh4xf1m\"><u>table on page 8</u></a>. Saving a life is worth 100 consumption doublings, and averting one Year Lived with Disease/Disability (YLD) is worth 3.3 consumption doublings, which implies that saving a life is worth 100/3.3= 30.3 DALYs.</p></div></li></ol>", "user": {"username": "ishaan"}}, {"_id": "Jdx9TJu6rgnpKB4kh", "title": "Freddie DeBoer Is Wrong About Effective Altruism", "postedAt": "2023-12-23T06:02:35.132Z", "htmlBody": "<p>Also posted on <a href=\"https://benthams.substack.com/p/freddie-deboer-is-wrong-about-effective\">my blog</a>. &nbsp;</p><p>There are some topics that cause smart people to lose their minds. I have a vivid memory of hearing someone of quite great intelligence, who was able to rattle off very precise facts about the tax rate in particular years of the Reagan administration, talking about veganism. And when he did, he just seemed to lose his mind; everything he said was false, and not in hard-to-figure-out ways. It was all the type of thing that would have been easily disproven by about 5 seconds of critical thought.</p><p>I\u2019m reminded of this event whenever I read Freddie deBoer talk about effective altruism. DeBoer is a great writer and thinker; his books are great and he\u2019s literally one of the best blog writers I\u2019ve ever read. DeBoer\u2019s devastating polemics are the stuff of legend\u2014when I\u2019m writing an article critical of something, I\u2019ll often try to emulate deBoer given how sharp and clear his writing is. But when deBoer talks about effective altruism, the stuff he says isn\u2019t just wrong; it\u2019s ill-thought-out and unpersuasive. It\u2019s not just that he makes mistakes, it\u2019s that he makes obvious errors ill-befitting of a thinker of his caliber with alarming frequency.</p><p>DeBoer has a <a href=\"https://freddiedeboer.substack.com/p/the-effective-altruism-shell-game\">recent article</a> criticizing EA describing it as a \u201cshell game.\u201d It begins by briefly mentioning the SBF scandal before describing that his critique isn\u2019t mostly about that. Still, it\u2019s worth addressing this \u201cobjection\u201d because it\u2019s the most common objection to effective altruism and deBoer does make it, albeit only onliquely. If you want to read roughly 1 gazillion pages about why there is no good objection to EA based on the SBF scandal, read <a href=\"https://gospeldemands.com/2022/12/22/a-systematic-response-to-criticisms-of-effective-altruism-in-the-wake-of-the-ftx-scandal/\">this excellent article</a> by the wonderful Alex Strasser.</p><p>For those who don\u2019t know, presumably on account of having severe amnesia or being young children, Sam Bankman Fried committed fraud. Before this, he was touted as a major figure in EA, and the reason he got into trying to earn lots of money in the first place was in order to give it away. So maybe EA is causally responsible for SBF.</p><p>But if you look at what EAs actually recommend, they very much do not recommend defrauding lots of people in a way that totally tanks the reputation of EA and leaves lots of people short of money. If a person, in pursuit of a cause, does immoral things, that\u2019s not a good objection to the cause. If some fraudster defrauded a bunch of people to donate to the Red Cross, even if he was touted by the Red Cross as a good person before they discovered the fraud, that wouldn\u2019t be an objection to the Red Cross.</p><p>Maybe the claim made by critics of EA is that the SBF stuff means that EA\u2019s net impact has been negative. It\u2019s worth noting that even if this were true, one should still be an EA. In the Red Cross case, even if the Red Cross\u2019s net impact were negative on account of inspiring a massive fraudster, it would still be good to donate to the Red Cross. It can be good to give money to charities saving lives at the margin even if those charities have, through no fault of their own, motivated people to do bad things.</p><p>But the bigger problem is that this claim is false. The overall impact of EA has been overwhelmingly positive. As <a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective\">Scott Alexander</a> notes, listening things EA has achieved:</p><blockquote><p><i><strong>Global Health And Development</strong></i></p><p>Saved about 200,000 lives total, mostly from malaria<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-1-86909076\"><sup>1</sup></a></p><p>Treated 25 million cases of chronic parasite infection.<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-2-86909076\"><sup>2</sup></a></p><p>Given 5 million people access to clean drinking water.<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-3-86909076\"><sup>3</sup></a></p><p>Supported clinical trials for both the RTS.S malaria vaccine (currently approved!) and the R21/Matrix malaria vaccine (on track for approval)<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-4-86909076\"><sup>4</sup></a></p><p>Supported additional research into vaccines for syphilis, malaria, helminths, and hepatitis C and E.<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-5-86909076\"><sup>5</sup></a></p><p>Supported teams giving development economics advice in Ethiopia, India, Rwanda, and around the world.<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-6-86909076\"><sup>6</sup></a></p><p><i><strong>Animal Welfare:</strong></i></p><p>Convinced farms to switch 400 million chickens from caged to cage-free.<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-7-86909076\"><sup>7</sup></a></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9df72b3f-fbd3-4482-9ea7-041fb5a6d38e_920x520.webp\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YtBiout7BQNAEbmvi/ostnatdo9x2xqcfpcvzw\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YtBiout7BQNAEbmvi/bwq6hn3rh7kdwcfvtmuw 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YtBiout7BQNAEbmvi/grneeuxhdetrej6rluv1 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YtBiout7BQNAEbmvi/hdn9p1rrx1t7xks8ey5x 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/YtBiout7BQNAEbmvi/ostnatdo9x2xqcfpcvzw 1456w\"></a></p><p>Things are now slightly better than this in some places! Source: https://www.vox.com/future-perfect/23724740/tyson-chicken-free-range-humanewashing-investigation-animal-cruelty</p><p>Freed 500,000 pigs from tiny crates where they weren\u2019t able to move around<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-8-86909076\"><sup>8</sup></a></p><p>Gotten 3,000 companies including Pepsi, Kelloggs, CVS, and Whole Foods to commit to selling low-cruelty meat.</p><p><i><strong>AI:</strong></i></p><p>Developed <a href=\"https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback\">RLHF</a>, a technique for controlling AI output widely considered the key breakthrough behind ChatGPT.<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-9-86909076\"><sup>9</sup></a></p><p>\u2026and other major AI safety advances, including <a href=\"https://www.astralcodexten.com/p/constitutional-ai-rlhf-on-steroids\">RLAIF</a> and the foundations of AI interpretability<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-10-86909076\"><sup>10</sup></a>.</p><p>Founded the field of AI safety, and incubated it from nothing up to the point where Geoffrey Hinton, Yoshua Bengio, Demis Hassabis, Sam Altman, Bill Gates, and hundreds of others <a href=\"https://www.safe.ai/statement-on-ai-risk\">have endorsed it</a> and urged policymakers to take it seriously.<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-11-86909076\"><sup>11</sup></a></p><p>Helped convince OpenAI to dedicate 20% of company resources <a href=\"https://openai.com/blog/introducing-superalignment\">to a team</a> working on aligning future superintelligences.</p><p>Gotten major AI companies including OpenAI to commit to the <a href=\"https://evals.alignment.org/\">ARC Evals</a> battery of tests to evaluate their models for dangerous behavior before releasing them.</p><p>Got two seats on the board of OpenAI, held majority control of OpenAI for one wild weekend, and still apparently might have some seats on the board of OpenAI, somehow?<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-12-86909076\"><sup>12</sup></a></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a810ce3-1e5d-4522-bf79-0f3983edd45d_586x418.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/fwocx2k76mjsqfsv6qwl\" alt=\"Sam Altman tweet praising Eliezer Yudkowsky\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/f9vya5llvwo4y8lnvbga 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/kwq1m6tdc51veili9k2p 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/eep5tfbisdhitm0auzau 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/fwocx2k76mjsqfsv6qwl 1456w\"></a></p><p>I don't exactly endorse this Tweet, but it is . . . a thing . . . someone has said.</p><p>Helped found, and continue to have majority control of, competing AI startup <a href=\"https://www.nytimes.com/2023/07/11/technology/anthropic-ai-claude-chatbot.html\">Anthropic</a>, a $30 billion company widely considered the only group with technology comparable to OpenAI\u2019s.<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-13-86909076\"><sup>13</sup></a></p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8168d6bd-3489-4ed1-8f03-c17ce2374993_594x110.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/wzynvovqplmz511t4vty\" alt=\"Tweet saying that &quot;keep Less Wrong ideas away from AI advances&quot; is like &quot;get your government hands off my Medicare&quot;\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/duiscj7fru4pb9jxelvv 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/g9jdhgazoqu1prpggged 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/xkv2htnx43tdgsashp0g 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/wzynvovqplmz511t4vty 1456w\"></a></p><p>I don't exactly endorse and so on.</p><p>Become so influential in AI-related legislation that Politico accuses effective altruists of having <a href=\"https://www.politico.com/news/2023/10/13/open-philanthropy-funding-ai-policy-00121362\">\u201c[taken] over Washington\u201d</a> and <a href=\"https://www.politico.eu/article/rishi-sunak-artificial-intelligence-pivot-safety-summit-united-kingdom-silicon-valley-effective-altruism/\">\u201clargely dominating the UK\u2019s efforts to regulate advanced AI\u201d</a>.</p><p>Helped (probably, I have no secret knowledge) the Biden administration pass what they called \"the strongest set of actions any government in the world has ever taken on AI safety, security, and trust.\u201d</p><p>Helped the British government create its <a href=\"https://www.gov.uk/government/publications/frontier-ai-taskforce-first-progress-report/frontier-ai-taskforce-first-progress-report\">Frontier AI Taskforce</a>.</p><p>Won the PR war: <a href=\"https://theaipi.org/poll-shows-overwhelming-concern-about-risks-from-ai-as-new-institute-launches-to-understand-public-opinion-and-advocate-for-responsible-ai-policies/\">a recent poll</a> shows that 70% of US voters believe that mitigating extinction risk from AI should be a \u201cglobal priority\u201d.</p><p><i><strong>Other:</strong></i></p><p>Helped organize the <a href=\"https://securedna.org/\">SecureDNA</a> consortium, which helps DNA synthesis companies figure out what their customers are requesting and avoid accidentally selling bioweapons to terrorists<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-14-86909076\"><sup>14</sup></a>.</p><p>Provided a significant fraction of all funding for DC groups trying to lower the risk of nuclear war.<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-15-86909076\"><sup>15</sup></a></p><p>Donated <a href=\"https://www.theonion.com/anonymous-philanthropist-donates-200-human-kidneys-to-h-1819594700\">a few hundred kidneys</a>.<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-16-86909076\"><sup>16</sup></a></p><p>Sparked a renaissance in forecasting, including major roles in creating, funding, and/or staffing <a href=\"https://www.metaculus.com/home/\">Metaculus</a>, <a href=\"https://manifold.markets/home\">Manifold Markets</a>, and the <a href=\"https://forecastingresearch.org/\">Forecasting Research Institute</a>.</p><p><a href=\"https://www.openphilanthropy.org/grants/johns-hopkins-center-for-health-security-biosecurity-global-health-security-and-global-catastrophic-risks-2017/\">Donated </a>tens of millions of dollars to pandemic preparedness causes years before COVID, and <a href=\"https://twitter.com/Dominic2306/status/1373333437319372804\">positively influenced some countries\u2019 COVID policies</a>.</p><p>Played a big part in creating the YIMBY movement - I\u2019m as surprised by this one as you are, but see footnote for evidence<a href=\"https://www.astralcodexten.com/p/in-continued-defense-of-effective#footnote-17-86909076\"><sup>17</sup></a>.</p></blockquote><p>Scott further notes that EA, an incredibly small group, has saved as many lives as curing AIDS, stopping a 9/11 terror attack every year since its founding, and stopping all gun violence. Compared to this, SBF\u2019s misbehavior is a drop in the bucket. If you found out that the U.S. cured AIDS, stopped another 9/11, and ended all gun violence, but that some major fraud occurred, that would be good news overall.</p><p>DeBoer quotes the Center for Effective Altruism\u2019s <a href=\"https://www.effectivealtruism.org/articles/introduction-to-effective-altruism\">definition of EA</a> as:</p><blockquote><p>both a <strong>research field</strong>, which aims to identify the world\u2019s most pressing problems and the best solutions to them, and a <strong>practical community</strong> that aims to use those findings to do good.</p><p>This project matters because, while many attempts to do good fail, some are enormously effective. For instance, some charities help 100 or even 1,000 times as many people as others, when given the same amount of resources.</p><p>This means that by thinking carefully about the best ways to help, we can do far more to tackle the world\u2019s biggest problems.</p></blockquote><p>However, deBoer declares that this makes it trivial. Who could object to doing good effectively? Thus, he claims, EA is just doing what everyone else does. But this is totally false. It\u2019s true that most people\u2014not all mind you\u2014who donate to charity are in favor of effectiveness. But many of them are in favor of effective charity the way that some liberal Christians are in favor of God; they think of it as a pleasant-sounding buzzword that they kind of abstractly like but don\u2019t do anything about that fact and it\u2019s not a big part of their lives.</p><p>Virtually no one has spent any time looking at the most effective charities. There\u2019s a reason that almost all money given to charities helping animals goes to the small number of them in shelters rather than the billions of them being tortured in factory farms. The reason is that when people are donating to help animals, they donate to the cute puppies they feel a positive emotional sentiment to because they saw ads about them looking sad, rather than trying to do good effectively.</p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56cee614-71b6-450d-9098-fae8a4c9a3d3_2440x1485.png\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/t61ebbmpviysimh8eh0u\" alt=\"Why Farmed Animals? - Animal Charity Evaluators\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/rc8j5eordkfavxopltsb 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/i8ilqowknrpiuvihi7yy 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/x5c7o9ge30cno1zkktk4 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/Jdx9TJu6rgnpKB4kh/t61ebbmpviysimh8eh0u 1456w\"></a></p><p>If everyone supports effective charities, why does the Against Malaria Foundation get such a small percentage of charitable funding? Is it really plausible that huge numbers of people have looked into it and concluded that the GiveWell top charities are ineffective? EA is about not just abstractly saying that you like effectiveness but actually looking hard into which charities are effective and which careers do lots of good and then doing those things that are good. Virtually no one does either of those things!</p><blockquote><p>Sufficiently confused, you naturally turn to the specifics, which are the actual program. But quickly you discover that those specifics are a series of tendentious perspectives on old questions, frequently expressed in needlessly-abstruse vocabulary and often derived from questionable philosophical reasoning that seems to delight in obscurity and novelty; the simplicity of the overall goal of the project is matched with a notoriously obscure (indeed, obscurantist) set of approaches to tackling that goal. This is why EA leads people to believe that hoarding money for interstellar colonization is more important than feeding the poor, why researching EA leads you to debates about how sentient termites are. In the past, I\u2019ve pointed to the EA argument, which I assure you <a href=\"https://blog.practicalethics.ox.ac.uk/2023/03/why-preventing-predation-can-be-a-morally-right-cause-for-effective-altruism/\">sincerely exists</a>, that we should push all carnivorous species in the wild into extinction, in order to reduce the negative utility caused by the death of prey animals. (This would seem to require a belief that prey animals dying of disease and starvation is superior to dying from predation, but ah well.) I pick this, obviously, because it\u2019s an idea that most people find self-evidently ludicrous; defenders of EA, in turn, criticize me for picking on it for that same reason. But those examples are essential because they demonstrate the problem with hitching a moral program to a social and intellectual culture that will inevitably reward the more extreme expressions of that culture. It\u2019s not nut-picking if your entire project amounts to a machine for attracting nuts.</p></blockquote><p>It\u2019s true that if you hang out in EA circles you\u2019ll disproportionately hear weird arguments about things that most normies scoff at. You\u2019re much more likely to hear about space colonization and culling predators at an EA event than, say, at your local bar. But if you look at what EA actually does, it\u2019s mostly just conventionally good stuff. About <a href=\"https://forum.effectivealtruism.org/posts/ZbaDmowkXbTBsxvHn/historical-ea-funding-data\">half of it</a> goes to global health, while only around a third goes to stuff related to Longtermism. DeBoer paints a misleading picture in which EA talks a big game about doing good well, but is really about weird pet projects. In reality, most of what EA funds is just obviously good, while EAs are disproportionately nerds who like to talk about obscure philosophy, so they spend lots of time talking about stuff that sounds strange.</p><p>The stuff under the umbrella of Longtermism is mostly uncontroversially good. A lot of it is about making sure AI is safe and we don\u2019t get into a nuclear war, which are both pretty popular.</p><p>It\u2019s true that a small share of EA funding goes to weird stuff like shrimp welfare and preventing S-risks. But I think that\u2019s a good thing! As <a href=\"https://www.samstack.io/p/weird-people-doing-good-things\">Sam Atis</a> notes:</p><blockquote><p>And it\u2019s true that many people, if asked, would probably agree that when trying to do good you should try to do the most good possible. But it\u2019s <i>insanely</i> weird to actually put it into practice. It\u2019s weird to donate 10% of your income to malaria charities. It\u2019s weird to <a href=\"https://www.astralcodexten.com/p/my-left-kidney\">give your kidney to a stranger</a>. It\u2019s weird to spend a significant amount of your time thinking about how exactly you should structure your career in order to do as much good as possible. So while I\u2019m sympathetic to the argument that the idea is banal, it\u2019s <i>extremely</i> weird to actually go and do this stuff.</p><p>Couldn\u2019t we have all the good stuff and get rid of the especially weird stuff? Why does donating 10% of your income to malaria charities have to be associated with people who take seriously the idea that we should eliminate some species of predators in the wild?&nbsp;</p><p>Well, if you\u2019re weird enough to take seriously the idea that you should donate a hefty chunk of your income to help people who live on the other side of the planet, you might also be weird enough to think it\u2019s worth considering spending a lot of time and effort trying to help wild animals or people who don\u2019t yet exist. You don\u2019t get the good stuff without the weird stuff.</p><p>If you\u2019re trying to decide how to do good, and you <i>only</i> consider options that sound reasonable and normal to most people, you probably won't end up with the conclusion that we should donate huge amounts of our income to people abroad. You probably won\u2019t end up with all the good things EA has done: no malaria nets, no pandemic preparedness funding, no huge campaigns to get animals out of cages. Effective Altruists are weird people doing good things, and long may they stay that way.&nbsp;</p></blockquote><p>Furthermore, not only is it good that EAs are willing to consider weird things, it\u2019s good that some of them are willing to do weird things. Take shrimp welfare, for example. There are <a href=\"https://rethinkpriorities.org/publications/shrimp-the-animals-most-commonly-used-and-killed-for-food-production\">over 300 billion farmed </a>shrimp killed each year who feel pain and spend their lives in small tanks, <a href=\"https://muddyclothes.substack.com/p/yeah-we-should-probably-care-more\">without enough space, have their eyes stabbed out, get diseases constantly, and are killed painfully</a>. I think it\u2019s good that we have a few people\u2014not everyone, but at least a few\u2014thinking hard about how we can prevent the population of shrimp which is over 35 times the population of Earth from being mistreated terribly in the ways they are routinely.</p><p>Yes, it sounds weird. If I was dating someone and meeting her parents, I would not like to describe what I do professionally as campaigning on behalf of the shrimp. But that\u2019s what makes EA wonderful. It scoffs at the absurdity heuristic and social desirability bias and instead does what\u2019s good most effectively.</p><p>To a lot of people transgender rights and gay rights sounded weird. So did abolitionism and advocacy for the rights of women. Sometimes things that are valuable sound really weird because society often has warped moral priorities. In the case where there is a group that puts their reputation on the line to do good, that has demonstrably saved hundreds of thousands of lives, the correct response is to praise them for their willingness to be weird rather than condemn them.</p><p>DeBoer next takes a swipe at EA based on Longtermism, claiming that it\u2019s another absurd view. DeBoer has no argument for why Longtermism is bad\u2014and he ignores the mountains of <a href=\"https://globalprioritiesinstitute.org/wp-content/uploads/The-Case-for-Strong-Longtermism-GPI-Working-Paper-June-2021-2-2.pdf\">scholarship defending it</a>. When our decisions can impact vast numbers of future centuries, potentially eliminating a glorious future that would contain trillions of happy people, it\u2019s not hard to believe that we should take that into account, just as it would have been bad if people in the third century had brought about the extinction of the world for temporary benefits.</p><p>Even if you\u2019re not on board with Longtermism, EA should still significantly impact how you live your life. You should donate to the Against Malaria Foundation even if you don\u2019t think preventing extinction is valuable. Furthermore, even if you\u2019re not a Longtermist, preventing everyone from dying in a nuclear war or AI cataclysm or plague more deadly than Covid is good, actually, and the fact that there are lots of smart people working on it is valuable.</p><p>DeBoer claims that EA \u201cmost often functions as a Trojan horse for utilitarianism, a hoary old moral philosophy that has received sustained and damning criticism for centuries.\u201d But this is like claiming that working at soup kitchens function as a trojan horse for socialism. What does it even mean?</p><p>EAs often are utilitarians, but one certainly doesn\u2019t have to be a utilitarian to be an EA. The ethics behind EA is <a href=\"https://rychappell.substack.com/p/beneficentrism\">Beneficentrist </a>in nature\u2014Beneficentrism is just the idea that helping others is important and that it\u2019s better to do it more rather than less effectively. To think this, one certainly doesn\u2019t have to believe any of the controversial things that utilitarianism implies.</p><p>DeBoer\u2019s final point involves questioning why one should align oneself with the movement. Why not just like do charitable things effectively? This is, I think, less important than most of his critique. If you don\u2019t call yourself an effective altruist but give 10% of your income to effective charities, take a high-impact career, are vegan, and give away your kidney, I don\u2019t think you\u2019re doing anything wrong. In fact, I\u2019d consider you to be basically an EA in spirit, even if not in name.</p><p>The answer to DeBoer\u2019s question is that the movement is good and reflects my values. The movement is a bunch of people thinking hard and working hard to try to improve the world\u2014and they\u2019ve made great progress. This small group of nerds has done as much good as ending AIDS, gun violence, and stopping 9/11.</p><p>Whenever there\u2019s a big movement that one aligns with, they won\u2019t \u2018agree with everything it does. DeBoer is a socialist, yet he certainly doesn\u2019t endorse everything that\u2019s ever been done in the name of socialism. He calls himself a socialist because he shares their core ideas and likes a lot of what they do.</p><p>That is why I call myself an effective altruist. It\u2019s because the movement does lots of good and I agree with most of what they do. When a small group of nerds saves 200,000 lives and contains some of the nicest, most virtuous, most charitable people working hard to save lives and improve the lives of animals being tortured on factory farms, I will always stand on their side.</p>", "user": {"username": "Omnizoid"}}, {"_id": "yBYDtAdSYjuvESQ75", "title": "Solar4Africa Project 2: Small solar cars for non-emergency health services access \u2014 Preliminary cost effectiveness analysis", "postedAt": "2023-12-24T17:06:36.255Z", "htmlBody": "<p><strong>SUMMARY: </strong><i>This post provides an exploratory analysis of the cost-effectiveness of using small inexpensive vehicles for non-emergency patient transport in rural Africa with a focus on Malawi. If implemented efficiently, this intervention is likely to improve health outcomes at a cost tht can be less than $100/DALY. The use of a solar vehicle can also \u201creduce\u201d CO<sub>2</sub> emissions, though this is less valuable than the improved health outcomes. In total a solar vehicle that has an initial cost of ~$4000 to purchase is likely to save 4.5 to 19.2 tons of CO<sub>2</sub> and 50 to 340 DALY of avoided disease burden (i.e. ~ 1 to 7 lives saved per vehicle) over its lifetime when effectively applied to non-emergency patient transport in rural Malawi.</i></p><h1>Introduction</h1><p>Hi, my name is Howard Zhang, and I am a freshman Environmental Science.&nbsp; I have recently finished a student run \u201cDeCal\u201d Effective Altruism class during the Fall \u201823 semester. My class project has been to analyze the cost effectiveness of solar cars given to residents in rural Malawi for non-emergency clinical transportation that we are doing in collaboration with @Robert Van Buskirk who is co-authoring this post. These solar cars require little maintenance and don't come with any gasoline expenses making them a good candidate for helping rural communities get access to healthcare facilities.</p><h1>Intervention description</h1><p>In 2022, <a href=\"https://www.solar4africa.org/\">Solar4Africa.org</a> (a small solar charity working in rural Malawi) piloted the import of 10 solar-powered cargo tricycles for use in rural villages. Import and assembly of these solar vehicles cost approximately $4000 each, but the vehicles come with very long lasting batteries that should be able to last 5 to 10 years or more.&nbsp; It was found that while it is difficult to rent the vehicles and garner enough revenue to pay off the initial vehicle cost, local village operators are able to operate the vehicles with a labor cost of only $1 to $2 per hour of vehicle operation.&nbsp;</p><p>Solar4Africa is therefore considering using the vehicles to provide free transportation to health clinics and hospitals for low-income patients. As a pilot test, one of the ten vehicles is currently used for clinic transport and is reliably providing about 1 to 2 patient trips per day. &nbsp;If such free transportation services can have a sufficiently large impact on health services access and health outcomes, Solar4Africa will expand the program.</p><h1>Preliminary literature review</h1><p>A preliminary review of the EA Forum does not indicate any significant discussion about health clinic or health services transportation interventions as an EA intervention or charity.&nbsp;</p><p>A preliminary review of the academic literature indicates that in SubSaharan Africa (SSA), clinic and health services transportation and access can have a potentially large impact on health outcomes.</p><p>One study indicates that households within 30 minutes of a clinic may use clinic services 10 times as much as households that are more than 90 minutes away from a clinic&nbsp;<a href=\"https://www.sciencedirect.com/science/article/pii/S0277953606000372\"><u>(Tansen, Gijsbertsen &amp; Herbst, 2006)</u></a>. Thus it is possible that providing transportation services for households that are more than 90 minutes away from a clinic or hospital could have a very large impact on health services use and health outcomes.</p><p>Another study&nbsp;<a href=\"https://link.springer.com/article/10.1007/s10461-014-0729-8\"><u>(Lankowski, et al., 2014)</u></a>&nbsp; states that up to 20 percent of participants cited \u201cgeographic and transportation-related barriers as factors that promoted poor outcomes throughout the continuum of HIV care, including delaying or forgoing HIV testing.\u201d</p><p>These studies underscore the strong link between geographical proximity, transportation availability, and health service utilization. The impact of these factors extends beyond convenience and emerges as a critical determinant of health outcomes, particularly in the context of preventive and chronic care. Therefore, Providing solar cars to communities in rural Malawi could be an important solution to address transportation barriers and enhance healthcare access by offering a reliable means of transportation, reducing the travel time, and minimizing the cost of attending clinics.</p><h1>How might clinic access impact health outcomes?</h1><p>While the literature indicates that easy transportation to a local clinic or hospital enables greater use of health services, we are not yet aware of literature that focuses on how better access to health services decrease disease burdens.&nbsp;</p><p>@Robert Van Buskirk has therefore provided an initial analysis of how health services access might impact disease burdens as illustrated in Figure 1 below.&nbsp;</p><p>Figure 1 shows an inter-country correlation of the all-causes national disease burden (NBD) with availability of nurses and midwives as indicated by&nbsp;<a href=\"https://data.worldbank.org/indicator/SH.MED.NUMW.P3\"><u>World Bank Data</u></a>.&nbsp; The World Bank provides the number of nurses and midwives per 1000 population by country. Similarly, the Institute for Health Metrics and the Global Health Data Exchange&nbsp;<a href=\"https://vizhub.healthdata.org/gbd-compare/\"><u>provide access to global burden of disease data for all countries</u></a>.&nbsp;</p><p>@Robert Van Buskirk adjusted the NBD in Figure 1 to remove the correlation with income. A two-dependent variable correlation analysis indicates that disease burden is significantly negatively correlated to BOTH national average income and the number of nurses and midwives per 1000 population, as one might expect.&nbsp;</p><p>Also the sample of national data shown in Figure 1 includes 38 SSA countries with HIV disease burdens of less than 7,000 DALY/100,000. For Southern African countries (i.e. South Africa, Namibia, Lesotho,Botswana, Eswatini, and Zimbabwe), very high HIV/AIDS disease burdens de-correlates NBD with national average income.&nbsp;</p><p>The correlation shown in Figure 1 for 38 SSA countries is between the all-causes NBD in DALY/100,000 as a function of access to nurses and midwives at the country level. This correlation provides a possible power law equation that can tentatively be used to relate health services access to disease burden. This correlation appears to indicate a power-law trend where total burden of disease decreases by a power law of X<sup>-0.182</sup> where X represents the variable representing access. Such a power low relationship implies that a doubling of the availability of nurses and midwives leads to 12% correlated decrease in total disease burden because 2<sup>-0.182</sup> ~ 0.88 = 1 - 12%.</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yBYDtAdSYjuvESQ75/kzjo7vmfirgsgwpewlel\"></p><p><strong>Figure 1: </strong>Correlation of national burden of disease (NBD) with the availability of nurses and midwives for Sub-Saharan African countries with low HIV burden.<strong>&nbsp;</strong></p><p>In rural Malawi, where Solar4Africa works, non-emergency transportation to a health clinic or hospital typically costs $1 to $5.&nbsp; For context, the minimum wage in Malawi is less than $2 per day. Given that the academic literature indicates that proximity to a clinic can increase clinic visits ten-fold, it is probably fairly conservative to estimate that the provision of a free clinic transportation service can double the chances that a non-emergency patient may visit a clinic. Thus given the correlation relationship shown in Figure 1, it is reasonable to estimate that such doubling of clinic visits may decrease the burden of disease by&nbsp; very roughly ~12%.</p><p>It is also reasonable to assume that in low-income rural areas, the average burden of disease of people visiting a health clinic is larger than the national average. In Malawi, the national average burden of disease is 0.407 DALY/capita/year (<a href=\"https://vizhub.healthdata.org/gbd-compare/\"><u>2019 GBD Study</u></a>). Thus, it is reasonable to conservatively assume that the burden of disease of rural patients wanting to visit a health facility is somewhat higher than this. We select a baseline disease burden for clinic patients ranging from 0.5 to 1.0 DALY/capita/year.</p><h1>Evaluation of environmental and climate impacts</h1><p>In addition to the health benefits of using a small, solar-powered vehicle for clinic transport, there are potential climate benefits of introducing small solar vehicles in rural Africa. In evaluating the environmental and climate impacts, we will initially focus on the CO<sub>2</sub> emissions reductions from using a solar rather than a gasoline-powered vehicle. Then we will discuss the social value of CO<sub>2</sub> emissions reductions.&nbsp; And then we will discuss the possibility that initial introduction of solar vehicles leads to their wider adoption in Africa.&nbsp;</p><h2>Emissions reduction estimates&nbsp;</h2><p>For the data on the kilograms of carbon dioxide emitted per kilometer for the average car, we took the average of the emissions from six different common vehicles differing in size (Smart fortwo Coup\u00e9, Honda Civic 06, Toyota Yaris 1.0 VVT, Peugeot 308 SW 1.6, Vauxhall Zafira, MY2008 Turbo 200PS, Toyota Avensis 2.0 VVT). We obtained these numbers from the Activation Environment Federation, resulting in approximately 172 grams of carbon dioxide emitted per kilometer. We then cross-referenced this data with information provided by another source, 8billiotrees.com, which stated that a medium-sized car emits roughly 192 grams of carbon dioxide per kilometer. Taking the average of these two data points, we arrived at an estimate of 182 grams of carbon dioxide emitted per kilometer for the average car.</p><p>With a general idea of the emissions per kilometer, we multiplied it by the number of kilometers traveled per ride, set at around 20 km, and the number of rides to obtain the final estimate of emissions per ride and over the lifespan of a vehicle.</p><p>The same method was applied to the calculation of motorcycle emissions, but using different sources of data. According to thrustcarbon.com, the website estimated that the average motorcycle emits around 113.37 grams of carbon dioxide per kilometer traveled. Cross-referencing this data with another website, co2everything.com, confirmed that an accurate estimate of the amount of carbon dioxide emitted per kilometer for an average motorcycle is around 113 grams.</p><p>As a result, an electric car can save anywhere from 7,680 kg to 19,200 kg of carbon dioxide over its lifetime if the mode of transportation were replaced by a car. On the other hand, if people rode motorcycles instead of electric cars, they would emit an extra 4,535 kg to 11,337 kg of carbon dioxide, depending on whether the electric vehicle can sustain 2,000 to 5,000 rides over its lifespan. This 4,535 kg to 19,200 kg of CO2 emissions reduction is the climate benefit of using a solar vehicle rather than gasoline-powered vehicles for clinic transport.&nbsp;</p><h2>Social Cost of Carbon</h2><p>According to the most relevant document published by the United States Government in 2021, <a href=\"https://www.whitehouse.gov/wp-content/uploads/2021/02/TechnicalSupportDocument_SocialCostofCarbonMethaneNitrousOxide.pdf\">Technical Support Document: Social Cost of Carbon, Methane, and Nitrous Oxide</a>, the social cost of carbon dioxide around 2025 ranges from 17-169 dollars per metric ton of carbon dioxide depending on the technical details of the social cost calculations. If we were to multiply this by the tons of carbon dioxide the electric vehicle saves over its lifetime, it would save anywhere between 144-3577 dollars if the rides were replaced by a car and 85-2112 dollars if the rides were replaced by motorcycles, depending on whether the electric vehicle can sustain 2,000 to 5,000 rides over its lifespan and the precise social cost of carbon dioxide per metric ton. These values encompass a very wide range, but the geometric mean values of $717 and $423 are significant, but probably not high enough to justify the use of the vehicles based on simply their climate benefits.&nbsp;</p><h1>Replication potential</h1><p>Currently adoption of solar-electric vehicles in low income countries is either minimal or non-existant. This &nbsp;primarily because development of products and technology requires access to low-cost capital and technological expertise which is often scarce in low-income settings.</p><p>Introducing subsidized small solar electric vehicles in low-income settings in an economically efficient way-where subsidies produce a social value that is higher than the cost of the subsidies-can accelerate introduction and adoption of electrified transport in such settings. By having a public program pay the initial costs of market introduction and technology adaptation, this lowers the cost for private actors who can copy the technology to create market-based applications.&nbsp;</p><p>Because solar-powered transport has extremely low operating costs, small solar vehicle operators can potentially earn higher wages with a solar vehicle once it's initial cost has been paid. And future aid or government programs will likely have an growing interest in promoting electric transport as the costs of climate change continue to rapidly increase over the coming decades.</p><h1>Cost effectiveness (CE) analysis of Health Impacts</h1><p>We now address whether a 100% subsidy of clinic transport is cost effective based on potential health benefits.</p><p>We perform a simplified CE analysis with uncertainty as described in&nbsp;<a href=\"https://forum.effectivealtruism.org/posts/icxnuEHTXrPapHBQg/a-simplified-cost-effectiveness-estimation-methodology-for\"><u>this post</u></a>.&nbsp; The key input variables to the CE analysis are the number of rides per vehicle, the number of rides per year, the labor cost per ride, the rides per beneficiary, and the health impact of the visits. The values used for these CE parameters are show in Table 1 below.</p><p>The CE in units of $/DALY is simply the cost per patient per year divided by the disease burden decrease per patient per year.&nbsp;</p><p>Figure 2 illustrates the distribution of CE results that are obtained from the evenly sampling all of the input parameter combinations provided in Table 1. It shows that given the range of possible CE parameter inputs, it is more likely than not that the CE value will be less than about $100/DALY.</p><p><strong>Table 1: Inputs to cost effectiveness calculation</strong></p><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><strong>Variable</strong></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><strong>Low</strong></p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><strong>Med</strong></p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p><strong>High</strong></p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Total rides/vehicle</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>2000</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>3000</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>5000</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Rides/year</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>300</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>600</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>1200</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Vehicle cost</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>$4000</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Labor cost per ride</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>$1</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Program cost mark-up</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>30%</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>60%</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>100%</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Patient disease burden&nbsp; (DB) (DALY/year)</td><td style=\"border:1pt solid #000000;padding:5pt\"><p>0.50</p></td><td style=\"border:1pt solid #000000;padding:5pt\"><p>0.75</p></td><td style=\"border:1pt solid #000000;padding:5pt\"><p>1.0</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Percentage disease burden decrease</td><td style=\"border:1pt solid #000000;padding:5pt\"><p>6%</p></td><td style=\"border:1pt solid #000000;padding:5pt\"><p>12%</p></td><td style=\"border:1pt solid #000000;padding:5pt\"><p>18%</p></td></tr><tr><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">Rides/patient/year</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\"><p>2</p></td><td style=\"border:1pt solid #000000;padding:5pt;vertical-align:top\">&nbsp;</td></tr></tbody></table></figure><p><br><br>&nbsp;</p><p><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/yBYDtAdSYjuvESQ75/p8fj4piieyjv5lsevxcu\"></p><p><strong>Figure 2: </strong>Distribution of cost effectiveness results for full sampling of potential input values.&nbsp;</p><h1>Conclusion</h1><p>If implemented efficiently, it appears from a preliminary analysis that small solar vehicles for non-emergency clinic transport in rural Malawi can be cost-effective, i.e. deliver disease burden reductions at potentially less than $100 per DALY of disease burden averted. In addition, the emissions reduction benefits of using a solar vehicle is likely worth several hundred to a few thousand dollars. More investigation needs to be done regarding the potential health benefits of increased health services access through improved transportation services in rural Africa. If such services do have a substantial impact on health outcomes, then it is likely that distribution and operation of small solar vehicles for the provision of transportation services for urgent, yet non-emergency patients in rural Africa is cost-effective. This may justify fully subsidizing of provisioning of small solar vehicles for health services transportation in Africa. This may be a novel means of introducing solar-electric vehicles to low-income Africa given that traditional electric vehicles are currently too expensive for low-income country adoption.&nbsp;</p>", "user": {"username": "Robert Van Buskirk"}}, {"_id": "TAQmDuSmHPbv8HDNf", "title": "Free Health Coaching this New Year", "postedAt": "2023-12-24T01:23:18.044Z", "htmlBody": "<p>Could you do more good in 2024 if you had better health?</p><p>For the first month of 2024, I\u2019m offering one free health coaching session to people in the EA community (January 4th to February 1st).&nbsp;</p><p>The full 1-1 coaching session will be solution-focused and work directly on your health concerns around moving, eating or sleeping better. Click<i>&nbsp;</i><a href=\"https://www.thehealthoptimiser.com/coaching\"><u>here</u></a><i> </i>for more details.</p><p>My coaching will likely be a good fit for you if you are ready to take action and work well with structure, practical steps and accountability.&nbsp;</p><p>You can book your 50 minute coaching call <a href=\"https://calendly.com/healthoptimiser/coachingcall\"><strong>here</strong></a><strong>&nbsp;</strong>or send me an email including any concerns, questions or feedback for me at&nbsp;<a href=\"mailto:rickey@thehealthoptimiser.com\">rickey@thehealthoptimiser.com</a>&nbsp;</p>", "user": {"username": "Rickey-Fukazawa"}}, {"_id": "q2QeuwLmkRuGcZC8q", "title": "Shrimp Neuroanatomy", "postedAt": "2023-12-26T04:06:17.227Z", "htmlBody": "<p>This is intended to be an informational post to discuss the neuroanatomy of shrimp, and the implications thereof for the range of computational functions supported by this anatomy.</p><p>I believe this topic is of importance to evaluating whether shrimp have moral value.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/zsz1scm9adgjuqs5jjum\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/a6bi0vltbjcs0sd5dcpb 129w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/fkaxfgno0eyp3hx0jyra 209w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/wkjo9anucpznjlsc4vxt 289w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/njys8vif3wciseccb6xp 369w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/zj7rn1s2jlaz8i67ydz7 449w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/ikpvohqqlhzyp7ovrqaq 529w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/pdwtudwmanfbh4xkcfwh 609w\"></figure><p>This is a schematic representation of the brain of the Pacific White Shrimp from this paper:</p><p><a href=\"https://www.researchgate.net/publication/315832674_Brain_architecture_of_the_Pacific_White_Shrimp_Penaeus_vannamei_Boone_1931_Malacostraca_Dendrobranchiata_correspondence_of_brain_structure_and_sensory_input?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ\">Brain architecture of the Pacific White Shrimp Penaeus vannamei Boone, 1931 (Malacostraca, Dendrobranchiata): correspondence of brain structure and sensory input?</a></p><p>The accompanying caption:</p><blockquote><p>Schematic representation of the brain of P. vannamei from a ventral view. AMPN anterior median protocerebrum, AnN antenna 2 neuropil, CB central body, DCL deutocerebral chemosensory lobe, HN/TM hemiellipsoid body/medulla terminalis complex, La lamina, LAN lateral antenna 1 neuropil, LL lateral lobes, Lo lobula, LoP lobula plate, Me medulla, PB protocerebral bridge, PMPN posterior median protocerebrum, PNT projection neuron tract, PNTN neuropil of the projection neuron tract, numbers indicate cell clusters</p></blockquote><p>The globular areas at the top are the eyes at the ends of the antenna. You can see the schematic indicates that there is omitted distance with paired 'break lines'.</p><p>Since the focus of this investigation is moral value, the visual sensory system is probably not relevant, so we should start with examining the details of the area below that. This lower region is called the 'central complex'.</p><p>&nbsp;</p><p>We need to examine what science has been published about each of these structures, to see if we can make accurate functional accounts of this computing system.</p><p>&nbsp;</p><p>If we were instead investigating fruit flies, we'd have an easier time, <a href=\"https://www.science.org/content/article/tour-de-force-researchers-image-entire-fly-brain-minute-detail\">since the brains of fruit flies are very well known</a>.</p><p>&nbsp;</p><p>Fortunately, there is a great deal in common between the brains of insects and ocean invertebrates. See this article: <a href=\"https://www.sciencedaily.com/releases/2020/03/200303175312.htm\">The brains of shrimps and insects are more alike than we thought</a></p><p>So, a good start would be checking if reasonable matches can be found between the neuroanatomical structures of the shrimp brain and the fruit fly brain. If so, we can proceed with getting an approximation of the moral value of shrimp from forming a conclusion about the moral value of fruit flies.</p><p>There's a great resource here with detailed maps of the fruit fly brain: <a href=\"https://www.fruitflybrain.org/#/\">https://www.fruitflybrain.org/#/</a></p><p>Let's just start with a simpler schematic though.</p><p>This is a colored 3D view of the structures in question:</p><p><a href=\"https://neurosciencenews.com/files/2014/02/fly-brain-neuropils.jpg\">https://neurosciencenews.com/files/2014/02/fly-brain-neuropils.jpg</a></p><p>&nbsp;</p><p>And here's an even simpler diagram from the paper <a href=\"http://dx.doi.org/10.1080/01677063.2016.1180385\">\"Reward from bugs to bipeds: a comparative approach to understanding how reward circuits function\"</a></p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/diyzr6vvwkxeldwzlfjw\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/cadb4exqfvpu5oscmui1 130w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/zikwoyyfao5pgmk9ft2v 260w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/gnrz15myogstxkz9rlve 390w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/re9sxgb6m2uvujupq8kq 520w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/zidn0tof4rzmoqdkkdq1 650w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/i5vyiqakacpouxltgm0c 780w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/tslwinaltmnyu8zbcxze 910w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/aegnvtsyucfl14qrg3ml 1040w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/l51ja2xk2xxekacdv0wn 1170w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/q2QeuwLmkRuGcZC8q/qapbualkxqy1ud8iyfkl 1233w\"></figure><p>This paper seems like a great starting point for the investigation of fruit fly moral worth, because it draws comparisons between brains of fruit flies, zebrafish, rodents and primates. Being able to draw on this comparative neuroanatomy between various well-understood species gives us a stronger ability to understand what each brain region is doing. Specifically, this paper focuses on the aspects of the reward/aversion system which is common across these species. If positively and negatively valenced experiences were sufficient to demonstrate the moral worth of an entity, then I feel pretty confident we could stop here. Fruit flies, and by extension, shrimp, almost certainly do have valenced experiences.</p><p>How much do we know about the functional roles of each of these parts? For fruit flies, the answer is quite a bit! Here's a <a href=\"https://www.theregister.com/2017/07/14/ai_deciphers_fruit_fly_brain/\">pop sci summary </a>of an <a href=\"https://www.cell.com/cell/fulltext/S0092-8674(17)30716-X?rss=yes\">interesting paper on the topic</a>.</p><p>Where comparative neuroanatomy gets really interesting though is in looking at what each more complex brain has that the less complex brain lacks. I think that the details of these lacks are where the answers pertinent to the moral worth of an entity lie. In a future post I will explore these differences in detail, and explain where the neuronal structures and their computational functions giving rise to moral worth lie in these brains.</p>", "user": {"username": "brighter_future"}}, {"_id": "wPiPg8qTAuoTKbzzA", "title": "new trolley problem", "postedAt": "2023-12-26T04:06:17.206Z", "htmlBody": "<p>There is an important moral puzzle to solve, because this is an ongoing problem. To simplify the problem and push it to an extreme where the issue is easy to see, I am going to frame this as a trolley problem.<br>Imagine that there is a person in a room with two buttons. They are told that they have two minutes to decide which button to push. If they push the button on the left, a child will be spared from death, but some quantity of invertebrate animals will be killed. If they push the button on the right, a quantity of invertebrate animals will be spared but the child will be killed. If they push neither button, both the child and the invertebrate animals will be killed. Accept for the hypothesis that the person believes this to be the truth.<br>Now we zoom out, and get to you. Turns out, you are watching this scenario through a hidden camera. In front of you is a single button. You are told that if you push this button the person you are watching in the room with two buttons will be killed and the child will be spared. If you do nothing, then you will simply not interfere with their choice.<br>Under what circumstances would you push the button? Does it matter what number of invertebrate animals' lives are on the line?<br>For me, it does not matter what number of invertebrate animals' lives are on the line. As soon as I see the person reaching for the button to kill the child, I will hit my kill button to kill them and spare the child. If they reach for the button to kill the invertebrates, great! Both they and the child get to live. I do not think this is a matter of personal taste, I believe it is a moral rule. That I would be wrong to do otherwise. So wrong, in fact, that if there were a third room with a person watching me and deciding whether to push the button to kill me and the original subject, that I would argue the third person has a moral obligation to kill both me and the original subject if the original subject reaches for the button to kill the child and I do not stop them.</p><p>Try this with any combination of number and type of invertebrate animal, and my answer will stay the same. A billion cockroaches? A trillion squid? A Graham's Number ants? No hesitation.</p><p>If there was no child's life on the line, if it were simply spare the invertebrates or kill them? I would not press a kill button to prevent someone from killing the invertebrates. I would be sad if they chose to kill the large number of invertebrates for no reason, but not morally justified in killing them. There is no number of invertebrate animals which would make me feel justified in killing the person to save the invertebrates.</p><p>Why am I picking on invertebrates here? Because their brains are relatively small and simple. So small and simple that I argue that, wherever the minimum line for 'experiencing meaningful suffering' or 'moral relevance' is, they are below it. I'm down to discuss whether, and to what degree great apes or dolphins or elephants deserve moral consideration. I have empirical reasons from examining their brains and their behaviors to believe that these creatures may indeed be moral agents. Cockroaches? Absolutely not within the bounds of reasonable argument.</p><p>Examine their behaviors. Do they exhibit behaviors we could reasonably interpret as forming empathic social bonds or reciprocal social contracts? No.&nbsp;<br>Look at their nervous systems. Do they have complex networks of neurons devoted to social interaction and compassion for self and others? No. Ability to experience sensory stimuli and interpret it as aversive is insufficient. They don't have the capacity to have emotional valence on top of those aversive stimuli, they don't have emotions, they don't care for themselves or others. They don't make choices with moral agency, deciding between doing good things or bad things. They are emotionless robots obeying genetically hardcoded instructions with only a little simple learning. They do not build a complex worldview and rich episodic memories. They do not ascribe rich personal meaning to events and experience desire for possible future outcomes. They are not little humans or even puppies, scaled down to tiny sizy and simpler brains. They are categorically a different thing which lacks all attributes of experience that give moral worth to a creature. No large number of zeros adds up to anything but zero. Cockroaches are not 0.000001 of a human, they are pure zero. With animals, there is gray area, a gradient of sorts, and we can talk about where to draw what lines. Invertebrates aren't on the scale.</p><p>So when people talk about 'Charitable Cause Prioritization', and their discussion includes protecting invertebrates and trades this off against protecting humans, I think they are mistaken. I don't think there is a valid tradeoff there.</p><p>So what's the problem? Why don't I just let the invertebrate-lovers go do their thing, while I do mine? The problem is that those arguing for the invertebrate cause as an issue of moral importance have brought bad arguments to the table. And then these arguments were not rejected. I'm fine with people bringing in new possible arguments about novel moral issues to consider. I'm not fine with failing to reject those potential moral issues when the arguments turn out to be flawed.</p><p>In practice, these issues do compete. When we are hosting a global conference about doing good, and we choose who to include as speaker and attendees, we are making choices. When we choose what posts to allow on our internet forums, we are making choices. When we decide what organizations to include in a list of 'affiliated charities', we are making choices. These all trade off against alternatives, including the alternative of not including them and thus not diluting a list of organizations pursuing valid causes with organizations pursuing incorrect ones.</p><p>I am asking for the community to make a stand and draw a line. While there are people dying of hunger, of currently preventable diseases, or of medical problems we could potentially find cures for (e.g. senescence, cancer), then we should firmly state that people matter morally in a way that invertebrate animals do not. Until all the human problems of sufficient threshold to be moral issues, such as involuntary death, have been completely solved, we should stop validating expending resources or attention on the welfare of invertebrates.</p>", "user": {"username": "brighter_future"}}, {"_id": "aiXyEvheFdwsEoPeC", "title": "A year of wins for farmed animals", "postedAt": "2023-12-24T12:18:51.864Z", "htmlBody": "<p><i>This is a crosspost for </i><a href=\"https://farmanimalwelfare.substack.com/p/a-year-of-wins-for-farmed-animals\"><i>A year of wins for farmed animals</i></a><i>, published by Lewis Bollard on 14 December 2023 in Open Philanthropy farm animal welfare research </i><a href=\"https://farmanimalwelfare.substack.com/\"><i>newsletter</i></a><i>.</i></p><p>It\u2019s been a tough year for farmed animals. The European Union <a href=\"https://farmanimalwelfare.substack.com/p/europes-animal-welfare-reforms-are\"><u>shelved</u></a> the world\u2019s most ambitious farm animal welfare reform proposal, plant-based meat sales <a href=\"https://farmanimalwelfare.substack.com/p/what-happened-to-plant-based-meat\"><u>sagged</u></a>, and the media <a href=\"https://www.wsj.com/articles/inside-the-struggle-to-make-lab-grown-meat-12cf46ab\"><u>panned</u></a> cultivated meat while Italy <a href=\"https://www.bbc.com/news/world-europe-67448116\"><u>banned</u></a> it. But advocates for factory farmed animals still won major gains \u2014 here are ten of the biggest:</p><p><strong>1. Wins for the winged</strong>. Advocates won <a href=\"https://chickenwatch.org/progress-tracker/\"><u>130</u></a> new corporate pledges to eliminate cages for hens or the worst abuses of broiler chickens. This progress has now expanded well beyond the West: recent wins include cage-free pledges from the largest Asian restaurant <a href=\"https://insideretail.asia/2023/09/28/jollibee-to-shift-to-using-cage-free-eggs-across-global-operations-by-2035/\"><u>company</u></a> and the largest Indonesian <a href=\"https://www.asian-agribiz.com/2023/06/06/super-indo-sets-timeline-for-shift-to-cage-free-eggs/\"><u>retailer</u></a>. That\u2019s mostly thanks to the work of the 100+ member groups of the <a href=\"https://openwingalliance.org/organizations\"><u>Open Wing Alliance</u></a>, who now campaign across 67 countries. We estimate that, if fully implemented, pledges secured to date will reduce the suffering of about 800 million layer hens and broiler chickens alive at any time.</p><p><strong>2. Cages canceled</strong>. A fair question has long been whether these pledges will be implemented. So far, they mostly have been: <a href=\"https://thehumaneleague.org/article/2023-cage-free-fulfillment-report\"><u>1,157</u></a> corporate pledges are now fully implemented, 89% of the pledges that came due by last year. As a result, <a href=\"https://usda.library.cornell.edu/concern/publications/rj4304553?locale=en#release-items\"><u>39%</u></a> of American hens, <a href=\"https://twitter.com/Lewis_Bollard/status/1691161854872293382\"><u>60%</u></a> of European hens, and <a href=\"https://www.farminguk.com/news/egg-shortages-threaten-to-derail-cage-free-2025-commitments_63242.html\"><u>80%</u></a> of British hens are now cage-free, up from just <a href=\"https://drive.google.com/file/d/1iBCWVP3fRnzZvlFVVC9VJ6mWOtM8muHa/view?usp=sharing\"><u>6%</u></a>, <a href=\"https://agriculture.ec.europa.eu/farming/animal-products/eggs_en\"><u>41%</u></a>, and <a href=\"https://assets.publishing.service.gov.uk/media/5a7df036ed915d74e33eeffc/eggs-statsnotice-06feb14.pdf\"><u>48%</u></a> respectively a decade ago. There\u2019s still a lot more work to do to hold companies accountable to their pledges. But globally 220 million more animals are already out of cages thanks to this work.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aiXyEvheFdwsEoPeC/yvsikoznrodxbihp3syj\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aiXyEvheFdwsEoPeC/aw2os2hx7vmzkcbov2vf 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aiXyEvheFdwsEoPeC/yorsjvbay9dhpqjavi5r 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aiXyEvheFdwsEoPeC/kkvrnavtv9r2bo6tqvcx 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aiXyEvheFdwsEoPeC/yvsikoznrodxbihp3syj 1456w\"><figcaption>Source: USDA reports.</figcaption></figure><p><strong>3. Pigs Supreme</strong>. The US Supreme Court <a href=\"https://farmanimalwelfare.substack.com/p/a-big-supreme-court-win-for-farm\"><u>upheld</u></a> California\u2019s Proposition 12, which bans the sale of eggs, pork, and veal from caged animals and their offspring. This ruling also protects seven other similar state laws. Once fully implemented, these laws will collectively require about 700,000 pigs and 80 million hens be raised cage-free. Advocates are now fighting a <a href=\"https://www.forbes.com/sites/daniellenierenberg/2023/09/29/the-eats-act-jeopardizes-animal-welfare-and-human-health/?sh=607d0b287d67\"><u>last-ditch effort</u></a> by pork producers to overturn the Court\u2019s ruling, and have already mustered the support of over <a href=\"https://sentientmedia.org/eats-act-opposition/\"><u>210</u></a> members of Congress for our side.</p><p><strong>4. Plant-based policies</strong>. Denmark <a href=\"https://fvm.dk/foedevarer/handlingsplan-for-plantebaserede-foedevarer\"><u>unveiled</u></a> the world\u2019s first state action plan to promote plant-based eating, including plans to promote plant-based foods in schools and support innovation in alternative proteins. South Korea <a href=\"http://koreabizwire.com/south-korea-unveils-ambitious-plan-to-cultivate-thriving-plant-based-food-industry/262752\"><u>said</u></a> it would soon unveil one too. The European Parliament <a href=\"https://www.europarl.europa.eu/doceo/document/TA-9-2023-0375_EN.pdf\"><u>called</u></a> for an EU-wide \u201caction plan for increased EU plant-based protein production and consumption.\u201d</p><p><strong>5. Meaty milestones</strong>. For the first time, the COP28 climate summit <a href=\"https://www.cop28.com/en/news/2023/11/COP28-to-offer-15C-aligned-menus-across-more-than-90-culinary-outlets\"><u>served</u></a> mostly vegetarian meals. The UN Environment Program <a href=\"https://www.unep.org/resources/whats-cooking-assessment-potential-impacts-selected-novel-alternatives-conventional\"><u>released</u></a> the first-ever UN report on the potential of alternative proteins. New data showed that only <a href=\"https://www.bmel.de/SharedDocs/Pressemitteilungen/DE/2023/124-ernaehrungsbericht.html\"><u>20%</u></a> of Germans now eat meat every day, down from 34% eight years ago. <a href=\"https://docs.google.com/presentation/d/1Dkmf-49wdJHQHA9DiQH5FgnJIY8qH9MEQybHbAbYLg8/edit#slide=id.g1e8fc7d727b_2_61\"><u>Half</u></a> of all US restaurants now offer a plant-based alternative, up from a third five years ago.</p><p><strong>6. Cultured policymakers</strong>. US regulators <a href=\"https://apnews.com/article/cultivated-meat-lab-grown-cell-based-a88ab8e0241712b501aa191cdbf6b39a\"><u>approved</u></a> the nation\u2019s first sales of cultivated meat. Japan\u2019s Prime Minister <a href=\"https://greenqueen.com.hk/cultivated-meat-japans-sustainable-future/\"><u>pledged</u></a> support for the nation\u2019s cellular agriculture industry. Germany <a href=\"https://www.foodnavigator.com/Article/2023/11/20/german-government-to-boost-alternative-proteins-with-38m-investment\"><u>pledged</u></a> \u20ac38M to promote alternative proteins, while <a href=\"https://www.foodnavigator.com/Article/2023/10/11/catalonia-invests-7m-into-alternative-protein-research\"><u>Catalonia</u></a> (Spain), <a href=\"https://www.jpost.com/business-and-innovation/all-news/article-726569\"><u>Israel</u></a>, and <a href=\"https://www.foodnavigator.com/Article/2023/04/14/uk-government-invests-12m-in-sustainable-protein-hub\"><u>the UK</u></a> funded more research. Alternative proteins have now attracted over a <a href=\"https://www.vox.com/future-perfect/23849473/cell-cultivated-meat-impossible-beyond-alternatives-vegan-investment-report-infrastructure\"><u>billion dollars</u></a> in public funding committed to research and infrastructure globally.</p><p><strong>7. Alternative aspirations</strong>. Major German retailer Lidl <a href=\"https://unternehmen.lidl.de/verantwortung/gut-fuer-die-menschen/gesundheit-foerdern/handlungsfelder/bewusste-ernaehrung/proteinstrategie\"><u>pledged</u></a> to double the share of its range of proteins that are plant-based by 2030. The second largest Dutch retailer, Jumbo, set a goal for <a href=\"https://www.jumbo.com/nieuws/jumbo-zet-in-op-meer-plantaardig-met-aangescherpte-ambitie/#\"><u>60%</u></a> of its protein sales to be plant-based by the same year. Both began their efforts by slashing the price of their own plant-based brands to parity with meat. So too did Germany\u2019s largest retailer, <a href=\"https://unternehmen.kaufland.de/presse/newsroom/2023/oktober/preissenkung-erleichtert-kunden-weiter-den-zugang-zu-veggie-produkten\"><u>Kaufland</u></a>. Eight of France\u2019s largest food companies, including Carrefour and Unilever, jointly <a href=\"https://www.carrefour.com/sites/default/files/2023-09/alternative%20plant-based%20products.pdf\"><u>pledged</u></a> to generate \u20ac3 billion in sales from plant-based products by 2026.</p><figure class=\"image\"><img src=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aiXyEvheFdwsEoPeC/dnnrjoqaa717xht67hnk\" alt=\"\" srcset=\"https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aiXyEvheFdwsEoPeC/twuq2yht4xodqrq6xyl6 424w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aiXyEvheFdwsEoPeC/fxergxjkfs6ude2mlimg 848w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aiXyEvheFdwsEoPeC/rueqldmsa8xtqn2fnrzw 1272w, https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/aiXyEvheFdwsEoPeC/dnnrjoqaa717xht67hnk 1456w\"><figcaption>Each one of the billions of farmed animals is an individual. This one\u2019s name is Bouloche, he\u2019s French, and he has unusually scraggly ears. Credit: Jo-Anne McArthur / We Animals Media.</figcaption></figure><p><strong>8. Creature comforts</strong>. Denmark\u2019s government <a href=\"https://via.ritzau.dk/pressemeddelelse/13699822/bredt-flertal-er-enige-om-initiativer-til-at-forbedre-dyrevelfaerden-for-slagtekyllinger?publisherId=13560469&amp;lang=da\"><u>agreed</u></a> to help phase out fast-growing broiler chickens, who suffer from chronic pain. The US Department of Agriculture <a href=\"https://apnews.com/article/usda-animal-welfare-claims-labels-meat-31244fe3fa7a5b2e14db8cd0c700d9d2\"><u>announced</u></a> new guidance to weed out fake \u201canimal welfare\u201d claims on products and <a href=\"https://www.agriculture.com/usda-strengthens-animal-welfare-standards-for-organic-livestock-8382858\"><u>strengthened</u></a> animal welfare standards for organic products. And the UK government <a href=\"https://www.gov.uk/government/news/new-legislation-set-to-ban-live-animal-exports#:~:text=After%20fifty%20years%20of%20campaigning,animals%20on%20these%20unnecessary%20journeys.\"><u>advanced</u></a> a long-awaited live export ban.&nbsp;</p><p><strong>9. Crustacean codes</strong>. The UK\u2019s largest seafood business, Young\u2019s Seafood, <a href=\"https://youngsseafood.co.uk/crustacean-welfare-policy-and-summary/\"><u>adopted</u></a> one of the world\u2019s first crustacean welfare policies, as did UK retailers <a href=\"https://www.johnlewispartnership.co.uk/content/dam/cws/pdfs/Juniper/ethics-and-sustainability/Crustacean-Welfare-policy.pdf\"><u>Waitrose</u></a> and <a href=\"https://corporate.marksandspencer.com/sites/marksandspencer/files/marks-spencer/Aquaculture/MS-Decapod-Welfare-Policy%20v2FINAL.pdf\"><u>Marks and Spencer</u></a>. This year\u2019s Global Shrimp Forum <a href=\"https://www.shrimp-forum.com/program/break-out-session-shrimp-welfare\"><u>featured</u></a> its first-ever session on shrimp welfare. The Shrimp Welfare Project has now reached agreements with shrimp producers to ensure pre-slaughter stunning for <a href=\"https://www.shrimpwelfareproject.org/shrimpact\"><u>over a billion</u></a> shrimp annually.</p><p><strong>10. Fish, finally! </strong>The EU <a href=\"https://greekcitytimes.com/2023/10/27/greece-to-host-europes-first-specialized-reference-center-for-aquatic-animal-welfare/\"><u>established</u></a> the world\u2019s first reference center for fish welfare. Two of the world\u2019s biggest aquaculture sustainability certifiers, the Aquaculture Stewardship Council and Friends of the Sea, moved forward with mandatory animal welfare standards. We estimate that, once implemented, these standards will improve the welfare of two to six billion fish alive at any time.&nbsp;</p><p>None of this progress just happened. Almost all of it came thanks to the tireless work of advocates, enabled by the generosity of donors. Many of both read this newsletter. So let me say: I\u2019m deeply grateful for all you do.&nbsp;</p><p>We face a mighty challenge: ending the abuse of more sentient beings than humans who have ever lived on earth. We do so with few resources: all advocacy for farmed animals globally has a combined budget smaller than the New York Metropolitan Museum of Art. And yet we\u2019ve already achieved progress for <i>billions</i> of sentient beings.</p><p>I know this work can be emotionally-draining, discouraging, even infuriating. Everything we do feels small compared to the scale of suffering before us. And yet you keep working and donating, with patience, generosity, and compassion, to help those who can\u2019t help themselves. The best people always have.</p><p>Thank you. And happy holidays.</p>", "user": {"username": "vascoamaralgrilo"}}]