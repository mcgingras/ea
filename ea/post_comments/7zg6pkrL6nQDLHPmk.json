[{"_id": "yuL3grLuDP9hgYpx6", "postedAt": "2022-10-01T14:53:37.695Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>Interestingly we both posted this on the same day but I have almost the entire opposite approach! Would appreciate your thoughts!</p>\n<p><a href=\"https://forum.effectivealtruism.org/posts/3Jm6tK3cfMyaan5Dn/ea-is-not-religious-enough-ea-should-emulate-peak-quakerism\">https://forum.effectivealtruism.org/posts/3Jm6tK3cfMyaan5Dn/ea-is-not-religious-enough-ea-should-emulate-peak-quakerism</a></p>\n", "parentCommentId": null, "user": {"username": "Lawrence Newport"}}, {"_id": "Kjw7Zsdpw8qn4My9T", "postedAt": "2022-10-01T15:17:15.248Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>It\u2019s also important to note that with many (I think 86% at last survey) EAs being nonreligious, it can be relatively easy for EA to play that role in people\u2019s lives. The cultural template is there, and it\u2019s powerful.</p>\n", "parentCommentId": null, "user": {"username": "Emily Dardaman"}}, {"_id": "9vJYvoe55Poz3rXnk", "postedAt": "2022-10-01T16:06:25.042Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>Needed to be said. I'm someone who gravitates to a lot of EA ideas, but I've avoided identifying as \"an EA\" for just this reason. Recently went to an EAG, which quelled some of my discomfort with EA's cultishness, but I think there's major room for improvement.</p><p>My lightly held hypothesis is that the biggest reason for this is EA's insularity. I think that using broader means of communication (publishing in journals and magazines, rather that just the EA forum) would go a really long way to enabling people to be merely inspired by EA, rather than \"EAs\" themselves. I like EA as a set of ideas and a question, not so much as a lifestyle and an all-consuming community. People should be able to publicly engage with (and cite!) EA rhetoric without having to hang out on a particular forum or have read the EA canon.</p>", "parentCommentId": null, "user": {"username": "Toby Weed"}}, {"_id": "aTuzTYXhFNbLCAyaw", "postedAt": "2022-10-01T20:05:42.369Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>I am not concerned too much with EA turning into a cult, for one reason:</p>\n<p>Cults/New Religious Movements are vastly less bad than most people think, and the literature on cults repudiates a lot of claims that the general population believes on cults, especially anything to do with harm.</p>\n<p>Link to it here:</p>\n<p><a href=\"https://www.lesswrong.com/posts/TiG8cLkBRW4QgsfrR/notes-on-brainwashing-and-cults\">https://www.lesswrong.com/posts/TiG8cLkBRW4QgsfrR/notes-on-brainwashing-and-cults</a></p>\n", "parentCommentId": null, "user": {"username": "Sharmake"}}, {"_id": "fjeGHyy4xfJphntHP", "postedAt": "2022-10-01T20:35:41.640Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>I think a great way to prevent us from turning into a cult is listening to criticism and have a diversity and opinions.</p>\n<p>I would say EAs for the most part are open to criticism but there are EAs who will unintentionally partake in fallacious reasoning when their EA cause or EA opinion is attacked.</p>\n<p>MacAskill once said EAs for the most part are social liberals. This is understandable considering most EAs come from fortunate backgrounds and have a college education.</p>\n<p>Matt Yglesias and Tyler Cowen noted in their fireside chats at EA Global that their is a sense of homogeneity and a common group. Tyler Cowen said most EAs are \u201ccoastal elites.\u201d I wouldn\u2019t use the term coastal, but most EAs definitely come from elite families, elite colleges, elite company, or some other form of elite group.</p>\n<p>There\u2019s nothing wrong with being a social liberal (I am one), college educated, wealthy, or elite, but it could create an echo chamber and result in a cult or something cult-like.</p>\n<p>I would like to see more libertarians, conservatives, and non-elites in EA so we can get different viewpoints, critiques, and a diversity of thought.</p>\n", "parentCommentId": null, "user": {"username": "Jeffrey Arana"}}, {"_id": "D4LkQQ7Hky3KZ4cRh", "postedAt": "2022-10-01T21:52:31.044Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>Yes the timing was funny (it looks like virtually everyone on the forum has something to say about EA culture nowadays :P)<br>I commented in your post.</p>", "parentCommentId": "yuL3grLuDP9hgYpx6", "user": {"username": "nadavb"}}, {"_id": "z5ykGdF3pgLiqnxaL", "postedAt": "2022-10-01T22:48:10.429Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>As a newcomer to EA, and a person with a fair amount of experience of cults and cult-like groups (and I'm 78 years old), I would like to report my experience.</p><p>I am very attracted to the ideas expressed in <i>Doing Good Better. </i>Having a science background, the idea of analyzing how effective my philanthropy may be is something I have pursued for many years, leading to many of the same conclusions.</p><p>On the other hand, many of the ideas of longtermism, trying to save human beings thousands of years in the future, being concerned about spreading to other planets, seeing malevolent AGI as among the most critical issues to address, strike me as similar to cults like Scientology and other groups whose vision and ideas seem contrary to common sense (if not downright wacky) but which seems to be common currency if not required by \"members.\"</p><p>In <i>What We Owe the Future, </i>MacAskill often expresses reservations about his ideas, points out alternatives or potential flaws, and in general shows somewhat more humility that I encounter on this Forum, for example. I certainly disagree with some of his conclusions and approaches, which I have begun to attempt to express in my few posts here to date, but I do respect his and others' efforts to think long-term when accompanied by express recognition of our limitations in trying to impact the future (except in set-in-stone certainties) more than a couple of decades out. Without those ongoing acknowledgments of our limitations, our uncertainty, and the weirdness of our perspectives (from a \"normal\" viewpoint), we are bound to come across as potentially cult-like.</p>", "parentCommentId": null, "user": {"username": "Wahhab Baldwin"}}, {"_id": "F7MHzDLSnqm9bh2An", "postedAt": "2022-10-01T22:58:46.891Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>Great point. The decline of religion has arguably left a cultural vacuum that new organizations can fill.</p>", "parentCommentId": "Kjw7Zsdpw8qn4My9T", "user": {"username": "Stephen McAleese"}}, {"_id": "7qK3wPt655DNGbLkx", "postedAt": "2022-10-02T00:02:12.145Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>I'm curious whether the reason why EA may be perceived as a cult while, e.g., environmentalist and social justice activism are not, is primarily that the concerns of EA are much less mainstream.</p><p>I appreciate the suggestions on how to make EA less cultish, and I think they are valuable to implement, but I don't think they would have a significant effect on public perception of whether EA is a cult.</p>", "parentCommentId": null, "user": {"username": "michaelchen"}}, {"_id": "BoNPYGvLskrJWsyKZ", "postedAt": "2022-10-02T03:35:43.311Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>Replying to this because I don't think this is a rare view, and I'm concerned about it. Met someone this week who &nbsp;seemed to openly view cults as a template (flawed, but useful) <i>and</i> was in the process of building a large compound overseas where he could disseminate his beliefs to followers who lived onsite. By his own admission, he was using EA as a platform to launch multiple(?) new genuine religions.&nbsp;</p><p>In light of the<a href=\"https://medium.com/@zoecurzi/my-experience-with-leverage-research-17e96a8e540b\"> Leverage Research incident</a>, we should expect and keep an eye out for folks using the EA umbrella to <i>actually start cults.</i></p>", "parentCommentId": "aTuzTYXhFNbLCAyaw", "user": {"username": "Emily Dardaman"}}, {"_id": "8b3aanXfv7x25MChH", "postedAt": "2022-10-02T12:33:31.774Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>My point is that contra the narrative in this post, cults are vastly less bad than the general public believes, so much so that the post is responding to a straw problem. I don't necessarily agree with the beliefs of the New Religious Movements/cults but the cult literature shows that they are vastly less bad then the general public thinks.</p>\n<p>I know it's a counterintuitive truth, but I want people to understand that the general public believing something is bad does not equal badness.</p>\n", "parentCommentId": "BoNPYGvLskrJWsyKZ", "user": {"username": "Sharmake"}}, {"_id": "c3CiY8S79DwTm6equ", "postedAt": "2022-10-02T17:05:16.079Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>I skimmed the link and it seems to be mostly about brainwashing not being effective. But cults do a lot of damage besides brainwashing. The insight that cults do provide some value to their members (otherwise why would anyone join?) is true, but does not mean that they don't do a lot of net harm.&nbsp;</p>", "parentCommentId": "aTuzTYXhFNbLCAyaw", "user": null}, {"_id": "YZt64rSNmeMyke9Gr", "postedAt": "2022-10-02T19:27:48.808Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>I'd find this post much more valuable if it argued that some parts of the EA community were bad, rather than arguing that they're cultish. Cultish is an imperfect proxy for badness. Sure, cults are bad and something being a thing which cults do is weak evidence of its badness (see <a href=\"https://www.lesswrong.com/posts/qNZM3EGoE5ZeMdCRt/reversed-stupidity-is-not-intelligence)\">Reversed Stupidity Is Not Intelligence</a>). Is, say, advertising EA too aggressively bad? Probably! But it is bad for specific reasons, not because it is also a thing cults do.</p><p>A particular way cultishness could be bad, which would make it directly bad for EA to be cultish, is if cults are an attractor in the space of organizations. This would mean that organizations with some properties of cults would feel pressure to gain more and more properties of cults. Still, I currently don't think is the case, and so I think direct criticisms are much more valuable than insinuations of cultishness.</p>", "parentCommentId": null, "user": {"username": "Tom Shlomi"}}, {"_id": "hYHLedeLWsKKNgChv", "postedAt": "2022-10-03T01:22:49.164Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>Interesting post, and some valid points.</p><p>I would also add: cults tend to micro-manage the sexual relationships and reproductive strategies of their members.&nbsp;</p><p>Sometimes this involves minimizing sexual activity, so cult members direct all of their energy and time into cult-propagation rather than mating effort. Sometimes it involves maximizing sexual connections or endogamous marriages within the cult, so people don't feel any tension between their relationship commitments and their cult commitments.</p><p>Sometimes cults are anti-natalist and strongly discourage reproduction in order to maximize energy and time directed into cultural cult-propagation (i.e. 'horizontal cultural transmission'). Sometimes they're pro-natalist and strongly encourage reproduction in order to create new recruits for the next generation (i.e. 'vertical cultural transmission').&nbsp;</p><p>An implication is that the more 'normal' EA seems in terms of relationship formation (e.g. a nice mix of 'cultural inbreeding' within the group and outbreeding outside the group), and family formation (e.g. people having kids, but not crazy numbers of kids), the less cult-like we'll seem.</p>", "parentCommentId": null, "user": {"username": "geoffreymiller"}}, {"_id": "enAZu3Dcoci592oG2", "postedAt": "2022-10-03T02:49:19.787Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>Something I think is really valuable is being upfront about mistakes and uncertainties. &nbsp;I really admire <a href=\"https://www.centreforeffectivealtruism.org/our-mistakes\">CEA's mistakes page</a>, for example. Cults often try to portray themselves and their leaders as infallible. Whereas admitting mistakes helps dispel that illusion and encourage critical thinking and a diversity of ideas.&nbsp;</p>", "parentCommentId": null, "user": {"username": "Peter Gebauer"}}, {"_id": "HEJjXwmPHhQZsnFxB", "postedAt": "2022-10-03T05:06:26.481Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>Maybe hiring nonEAs for certain roles (like \"communications assistant\" and not like \"board member\") could improve communications/appearances/maybe outreach?</p>\n", "parentCommentId": null, "user": {"username": "Ilverin"}}, {"_id": "SJR45K9aMbe9BKBdc", "postedAt": "2022-10-16T08:43:43.322Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>I think that the \"A narrative of EA as a cult\" section is helpful for steelmanning this narrative/perception. I also appreciate your suggestions and ideas in the \"How to make EA less cultish\" section.</p><p>As far as I can see, you don't explore any substantive reasons or evidence why \"the cult-like features of EA pose a real issue\" beyond optics; you note that \"the impression of a cult could also explain why some of the recent media attention on EA hasn\u2019t been very positive\", but this <i>is </i>about optics. So I'd be interested to hear/read you try to flesh out the \"other negative consequences\" that you allude to.&nbsp;</p><p>The easier option is to remove \"(and it's not just optics)\" from the title and rename \"It\u2019s not just optics\" to \"It might be more than optics\" or similar, but if you do have thoughts on the other negative consequences, these could be valuable to share.</p><p>(For context, I'm one of the people involved in reaching out to high school students, and I'm keen to understand the full implications -- pros and cons -- of doing so, and if there's anything we can do to mitigate the downsides while retaining the benefits.)</p><p>Thanks for this helpful post. Strong upvoted.</p>", "parentCommentId": null, "user": {"username": "Jamie_Harris"}}, {"_id": "c3WgAA4dMuoCscnJj", "postedAt": "2022-10-16T10:18:51.112Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": "<p>Thank you for this comment!</p><p>You are absolutely right. I didn't really explore any&nbsp;consequences&nbsp;of EA being cultish other than optics. As I said in the post, I don't really have a good mental model of all the&nbsp;ways in which it plays out, but I do have a strong intuitive sense that it does have other&nbsp;bad consequences (honestly, this entire post is based on intuitions and anecdotal evidence - none of my claims are based on rigorous studies).</p><p>Having said that, here's a very partial list of other consequences&nbsp;that I believe exist:</p><p>1. Making people with different levels of engagement with EA feel uncomfortable (you could say it's also just optics, but I think they have good reasons to feel uncomfortable).</p><p>2. Bad epistemics, groupthink and echo chamber effects (I develop this idea a bit further <a href=\"https://forum.effectivealtruism.org/posts/3voXaqvPutSrHvuCT/the-case-against-ea-cause-areas#More_independent_thinking_could_be_healthy_for_EA\">here</a>).</p><p>3. Not engaging enough with people and opinions outside EA.</p><p>4. Attracting mostly very specific types of people (again, maybe this could be labeled as optics).</p><p>5. Radical beliefs.</p><p>And just to clarify&nbsp;(I know that you know that, but just for the record) - I'm not saying that outreach to children is necessarily&nbsp;a bad idea. It has many pros and cons that should be weighed somehow. I hope that my post has been helpful in describing some potential risks.&nbsp;</p>", "parentCommentId": "SJR45K9aMbe9BKBdc", "user": {"username": "nadavb"}}, {"_id": "iFzdxDRoj5QjKvgj7", "postedAt": "2022-10-02T03:27:47.857Z", "postId": "7zg6pkrL6nQDLHPmk", "htmlBody": null, "parentCommentId": "F7MHzDLSnqm9bh2An", "user": null}]