[{"_id": "gjf9rYbLhD8TB5c8v", "postedAt": "2023-07-21T13:36:22.977Z", "postId": "74CkwGxmXaevwzhNG", "htmlBody": "<p>Here's the <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai/\">white house factsheet</a> link</p>", "parentCommentId": null, "user": {"username": "MHR"}}, {"_id": "xduD5fZptttFBj4mu", "postedAt": "2023-07-21T22:44:42.506Z", "postId": "74CkwGxmXaevwzhNG", "htmlBody": "<p>It's also very much worth reading the <a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/07/Ensuring-Safe-Secure-and-Trustworthy-AI.pdf\">linked pdf</a>, which goes into more detail than the fact sheet.</p>", "parentCommentId": "gjf9rYbLhD8TB5c8v", "user": {"username": "ThomasWoodside"}}, {"_id": "EynRr4eNRrkwKw4af", "postedAt": "2023-07-24T12:02:51.728Z", "postId": "74CkwGxmXaevwzhNG", "htmlBody": "<p>Pulling out highlights from PDF of the <a href=\"https://www.whitehouse.gov/wp-content/uploads/2023/07/Ensuring-Safe-Secure-and-Trustworthy-AI.pdf\">voluntary commitments</a> that AI safety orgs agreed to:</p><blockquote><p><i>The following is a list of commitments that companies are making to promote the safe, secure, and transparent development and use of AI technology. These voluntary commitments are consistent with existing laws and regulations, and designed to advance a generative AI legal and policy regime. Companies intend these voluntary commitments to remain in effect until regulations covering substantially the same issues come into force. Individual companies may make additional commitments beyond those included here.</i></p><p>Scope: Where commitments mention particular models, they apply only to generative models that are overall more powerful than the current industry frontier (e.g. models that are overall more powerful than any currently released models, including GPT-4, Claude 2, PaLM 2, Titan and, in the case of image generation, DALL-E 2).</p></blockquote><p>&nbsp;</p><blockquote><p>1) Commit to internal and external red-teaming of models or systems in areas including misuse, societal risks, and national security concerns, such as bio, cyber, and other safety areas.</p><p>2) Work toward information sharing among companies and governments regarding trust and safety risks, dangerous or emergent capabilities, and attempts to circumvent safeguards</p><p>3) Invest in cybersecurity and insider threat safeguards to protect proprietary and unreleased model weights</p><p>4) Incent third-party discovery and reporting of issues and vulnerabilities</p><p>5) Develop and deploy mechanisms that enable users to understand if audio or visual content is AI-generated, including robust provenance, watermarking, or both, for AI-generated audio or visual content</p><p>6) Publicly report model or system capabilities, limitations, and domains of appropriate and inappropriate use, including discussion of societal risks, such as effects on fairness and bias</p><p>7) Prioritize research on societal risks posed by AI systems, including on avoiding harmful bias and discrimination, and protecting privacy</p><p>8) Develop and deploy frontier AI systems to help address society\u2019s greatest challenges</p></blockquote>", "parentCommentId": null, "user": {"username": "MJusten"}}, {"_id": "4bJQweFqzLGahDMbQ", "postedAt": "2023-07-24T12:04:25.327Z", "postId": "74CkwGxmXaevwzhNG", "htmlBody": "<p>I'd be very curious if there are historical case studies of how much private corporations stuck to voluntary commitments they made, and how long it took for more binding regulation to replace voluntary commitments</p>", "parentCommentId": null, "user": {"username": "MJusten"}}]