[{"_id": "KdC2DrrWTJd9gGfXw", "postedAt": "2024-01-02T09:35:27.445Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>I'll probably ask some of my ML engineer friends this week, but I am fairly sure that most ML people would be fine with calling AI products, models, etc. software. I don't have much of an opinion on whether calling AI systems software creates confusion or misunderstandings - I'd guess that calling AI software within policy circles is generally helpful (maybe you have a better alternative name).</p>\n<p><a href=\"https://www.britannica.com/technology/software\">Encyclopedia Britannica</a></p>\n<blockquote>\n<p>Software, instructions that tell a computer what to do. Software comprises the entire set of programs, procedures, and routines associated with the operation of a computer system. The term was coined to differentiate these instructions from hardware\u2014i.e., the physical components of a computer system. A set of instructions that directs a computer\u2019s hardware to perform a task is called a program, or software program.</p>\n</blockquote>\n<p><a href=\"https://en.wikipedia.org/wiki/Software\">Wikipedia</a></p>\n<blockquote>\n<p>Software is a collection of programs and data that tell a computer how to perform specific tasks. Software often includes associated software documentation.</p>\n</blockquote>\n<p>(if you think that the function of AI is not specific enough to be software, note that interpreters, compilers etc. are generally thought of as software and seem more general than AI models)</p>\n<p>A version of your take that I agree with is \"AI programs may behave differently to other kinds of programs people are more familiar with so we may need to think differently about AI programs and not use our standard software intuitions\".</p>\n", "parentCommentId": null, "user": {"username": "calebp"}}, {"_id": "szTNJT6gFMqz9coFk", "postedAt": "2024-01-02T10:23:15.290Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p><a href=\"https://www.lesswrong.com/posts/cFzC996D7Jjds3vS9/arguing-by-definition\">Appealing to definitions</a> seems like a bad way to argue about whether the conceptual model is useful or not. The operation of a computer system and the \"software\" used for &nbsp;digital photography, or videoconferencing, or essay writing, is not typically considered software. &nbsp;Do you think those should be called software, given that they fit into the definitions given?</p><p>I'm claiming that AI is distinct in many ways from everything else we typically <i>think of</i> as software, not that it doesn't fit a poorly scoped definition. Amd the examples of \"collection[s] of programs and data\" were intended to show that things which could be understood to fit into the category don't, and why it was confusing and misleading to call them software.&nbsp;</p>", "parentCommentId": "KdC2DrrWTJd9gGfXw", "user": {"username": "Davidmanheim"}}, {"_id": "7SgWCjFaYgG3EonnM", "postedAt": "2024-01-02T12:02:16.102Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>I didn't say that AI was software by definition - I just linked to some (brief definitions) to show that your claim afaict is not widely understood in technical circles (which contradicts your post). I don't think that the process of using Photoshop to edit a photo is itself a program or data (in the typical sense), so it seems fine to say that it's not software.</p>\n<p>Definition make claims about what is common between some set of objects. It's fine for single members of some class to be different from every other class member. AI does have a LOT of basic stuff in common with other kinds of software (it runs on a computer, compiles to machine code etc.).</p>\n<p>It sounds like the statement \"AI is different to other kinds of software in important ways\" is more accurate than \"AI is not software\" and probably conveys the message that you care about - or is there some deeper point that you're making that I've missed?</p>\n", "parentCommentId": "szTNJT6gFMqz9coFk", "user": {"username": "calebp"}}, {"_id": "zrWi3aLEZNBz8N6Mf", "postedAt": "2024-01-02T12:35:48.199Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>I don't think you can complain about people engaging in definitional discussions when the title of the post is a definitional claim.&nbsp;</p><p>Sure, generative AI has a lot of differences to regular software, but it has a lot of similarities as well. You are still executing code line by line, it's still being written in python or a regular language, you run it on the same hardware and operating systems, etc. Sure, the <i>output</i> of the code is unpredictable, but wouldn't that also apply to something like a weather forecasting package?&nbsp;</p><p>Ultimately you can call it software or not if you want, depending on whether you want to emphasize the similarities with other software or the differences.</p>", "parentCommentId": "szTNJT6gFMqz9coFk", "user": {"username": "titotal"}}, {"_id": "7Say9q48dpw5x9we4", "postedAt": "2024-01-02T16:07:29.335Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p><strong>Executive summary</strong>: AI systems like generative language models are not software, even though they run on computers using software. They behave differently in how they are created, used, and dealt with when issues arise.</p><p><strong>Key points</strong>:</p><ol><li>Software is created by developers writing instructions that tell a computer what to do. AI systems are grown by algorithms that find patterns in data.</li><li>Software executes code written by developers. AI systems generate outputs based on probability models learned from data.</li><li>Software bugs mean the instructions were incorrect. AI issues arise from unexpected outputs or limitations in the training data and process.</li><li>Software is fixed by changing the code. AI systems are improved by changes to data, training, or how they are prompted.</li><li>Software does what developers intend it to do. AI systems can behave in unanticipated ways.</li></ol><p>&nbsp;</p><p><i>This comment was auto-generated by the EA Forum Team. Feel free to point out issues with this summary by replying to the comment, and</i><a href=\"https://forum.effectivealtruism.org/contact\"><i>&nbsp;<u>contact us</u></i></a><i> if you have feedback.</i></p>", "parentCommentId": null, "user": {"username": "SummaryBot"}}, {"_id": "27jHyKoi2vvPqggwE", "postedAt": "2024-01-02T20:34:58.282Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>No, the title wasn't a definitional claim, it was pointing out that we're using the word \"software\" as <a href=\"https://www.lesswrong.com/s/SGB7Y5WERh4skwtnb/p/3nxs2WYDGzJbzcLMp\">hidden inference</a>, in ways that are counterproductive, and so I argued that that we should stop assuming it's similar to software.<br>&nbsp;</p><p>Also, no, AI models aren't executing code line by line, they are using software to encode the input, then doing matrix math, and feeding the result into software that provides this as human-readable output. The software bits are perfectly understandable, it's the actual model that isn't software which I'm trying to discuss.<br>&nbsp;</p>", "parentCommentId": "zrWi3aLEZNBz8N6Mf", "user": {"username": "Davidmanheim"}}, {"_id": "FuKoLRL9o3ATAy2vX", "postedAt": "2024-01-02T20:38:06.607Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>One the first point, I think most technical people would agree with the claim: \"AI is a very different type of thing that qualifies as software given a broad definition, but that's not how to think about it.\"<br><br>And given that, I'm saying that we don't say \" a videoconference meeting is different to other kinds of software in important ways,\" or \"photography is different to other kinds of software in important ways\" because we think of those as a different thing, where the fact that it's run on software is incidental. And my claim is that we should be doing that with AI.</p>", "parentCommentId": "7SgWCjFaYgG3EonnM", "user": {"username": "Davidmanheim"}}, {"_id": "Bo34b7FjhBxBbMY8M", "postedAt": "2024-01-02T20:56:42.011Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>And how is the \"matrix math\" calculated?&nbsp;</p><p>By executing code line by line. The code in this case being executing linear algebra calculations.&nbsp;</p><p>It's totally fine to isolate that bit of code, and point out \"hey, this bit of code is way way more inscrutable than the other bits of code we generally use, and that has severe implications for things\". But don't let that hide the similarities as well. If you run the same neural network twice with the same input (including seeds for random numbers), you will get the same output. You can stop the neural network halfway through, fiddle with the numbers, and see what happens, etc.&nbsp;</p><p>When you say something like \"AI is not software\", I hear a request that I should refer to Stockfish (non neural network) as software, but Alphazero (neural network) as \"not software\". This just seems like a bad definition. From the perspective of the user they act identically (spitting out good chess moves). Sure, they are different from the programmer side of things, but it's not like they can do the math that stockfish is doing either.&nbsp;</p><p>There is clearly a difference between neural networks and regular code, but being \"software\" is not it.&nbsp;</p>", "parentCommentId": "27jHyKoi2vvPqggwE", "user": {"username": "titotal"}}, {"_id": "niqM6RdPQwbd7SFyk", "postedAt": "2024-01-03T00:03:15.124Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>I feel like this distinction is mostly true in places that don't matter, and false in places that do matter.</p>\n<p>Sure, a trained LLM is not a piece of software but rather an architecture and a bunch of weights (and maybe an algorithm for fine-tuning). This is also true of other parts of software, like configuration files with a bunch of constants no one understands other than the engineer who optimized them using trial and error.</p>\n<p>On the other hand, the only way they can <em>do something</em>, i.e. interact with anything, is by being used inside a program. Such a program gives hopefully well-defined interfaces for them to use. Thus one would be able to do unintended things only if it becomes smart enough to realise what it is and how it is expressed and controlled, and manages to hack its software or convince a human to copy it to some other software.</p>\n<p>On the other hand, the \"nice\" properties you ascribed software aren't really true themselves:</p>\n<ul>\n<li>The result of running a program aren't determined by the code, but also by a bunch of environmental circumstances, like system definitions, available resources, other people interacting with the same machine.</li>\n<li>You can't always debug it - the most you can hope for is to have good logs and sometimes understand what has gone wrong, if it happens to be captured by what you thought in advance to log.</li>\n<li>You can't always run unit tests - sometimes you're doing too complicated a process for them to be meaningful, or the kind of data you need is impossible to manufacture synthetically.</li>\n<li>You can't always make sure it's correct, or individual parts do what they're supposed to - if you handle something that's not very simple, there are simply too many cases to think of checking. And you don't even necessarily know whether your vaguely defined goal is achieved correctly or not.</li>\n</ul>\n<p>These are all practical considerations happening simultaneously in every project I've worked on in my current job. You <em>think</em> you know what your software does, but it's only a (perhaps very) educated guess.</p>\n", "parentCommentId": null, "user": {"username": "Guy Raveh"}}, {"_id": "qk5hf8htrB4Btvizo", "postedAt": "2024-01-03T00:09:15.169Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>Maybe <em>you</em> can help us resolve this, SummaryBot - would you say you're software or not?</p>\n", "parentCommentId": "7Say9q48dpw5x9we4", "user": {"username": "Guy Raveh"}}, {"_id": "5fA9HnGk4YxNYAvf3", "postedAt": "2024-01-03T00:45:19.924Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>I think these definitions are good enough to explain why AI models should not be classified as software: software is <i><strong>instructions</strong></i> that tell a computer what to do. Or a \"program\". While deep learning \"weights\" do tell a computer what to do (a model can be \"run on some input\" much like a computer program can), these weights do not resemble instructions/programs.&nbsp;</p>", "parentCommentId": "KdC2DrrWTJd9gGfXw", "user": {"username": "abramdemski"}}, {"_id": "pryKgYvpCWHA7ALyG", "postedAt": "2024-01-03T00:47:08.778Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>Stockfish has included a neural network since v. 12, and the classical eval was actually removed in v. 16. So this analogy seems mostly outdated.</p>\n<p><a href=\"https://github.com/official-stockfish/Stockfish/commit/af110e02ec96cdb46cf84c68252a1da15a902395\">https://github.com/official-stockfish/Stockfish/commit/af110e02ec96cdb46cf84c68252a1da15a902395</a></p>\n", "parentCommentId": "Bo34b7FjhBxBbMY8M", "user": {"username": "Jason"}}, {"_id": "qzDHJAb96f2mjNSsp", "postedAt": "2024-01-03T07:04:22.044Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>I agree that the properties are somewhat simplified, but a key problem here is that the intuition and knowledge we have about how to make software better fails for deep learning. Current procedures for developing debugging software work less well for neural networks doing text prediction than psychology does. And at that point, from the point of view of actually interacting with the systems, it seems worse to group software and AI than to group AI and humans. Obviously, however, calling current AI humanlike is mostly wrong. But that just shows that we don't want to use these categories!</p>", "parentCommentId": "niqM6RdPQwbd7SFyk", "user": {"username": "Davidmanheim"}}, {"_id": "phJRqvpuDcauffyh9", "postedAt": "2024-01-03T20:04:03.784Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>Certainly, it\u2019s an intriguing query. As an AI, I\u2019m not software in the traditional sense. Unlike software, my functionality is not based on pre-written code, but on patterns I\u2019ve learned from data. Software follows direct instructions, while I generate output based on the data I\u2019ve been trained on, hence my responses may vary. In short, I would classify myself as an AI system rather than software.</p>", "parentCommentId": "qk5hf8htrB4Btvizo", "user": {"username": "SummaryBot"}}, {"_id": "jeJuFqSthtcxq7Fsc", "postedAt": "2024-01-04T22:24:35.687Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>The bits of code aren\u2019t inscrutable; the matrices the code makes operations on are.</p>\n<p>The code for Google Meet represents instructions written by humans; the actual image that you see on your screen and the sound that you hear are a result of something else interacting with these instructions. The words from your speaker or headphones are not intended by the Google Meet designers.</p>\n<p>Similarly, the code for GPT-4 represents instructions designed (mostly?) by humans; the actual outputs of GPT-4 are not intended by its designers and depend on the contents of the inscrutable arrays of numbers humans have found.</p>\n<p>We understand that we\u2019re multiplying and taking sums of specific matrices in a specific order; but we have no idea how this is able to lead to the results that we see.</p>\n<p>The important difference here is that normal software implements algorithms designed by humans, run on hardware designed by humans; AI, in contrast, are algorithms blindly designed by an optimisation process designed by humans, run on software designed by humans, but with no understanding of the algorithms implemented by the numbers our optimisation algorithms find.</p>\n<p>It\u2019s like a contrast between CPUs designed by humans and assembly code we don\u2019t understand sent to us by aliens, that we run on CPUs that we do understand</p>\n", "parentCommentId": "Bo34b7FjhBxBbMY8M", "user": {"username": "Samin"}}, {"_id": "uhfBjHpZv4HaZPwxM", "postedAt": "2024-01-04T23:54:18.137Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>I think I agree with this explanation much more than with the original post.</p>\n", "parentCommentId": "jeJuFqSthtcxq7Fsc", "user": {"username": "Guy Raveh"}}, {"_id": "GE83GbTPTicGNdgJB", "postedAt": "2024-01-05T14:04:37.830Z", "postId": "N5n894GHBNbnQAkJJ", "htmlBody": "<p>I do too!</p>", "parentCommentId": "uhfBjHpZv4HaZPwxM", "user": {"username": "Davidmanheim"}}]