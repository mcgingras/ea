[{"_id": "rEZBd7YnbaBWTYyXC", "postedAt": "2023-09-19T19:01:11.618Z", "postId": "5NcCWNC3yWdqeaEdH", "htmlBody": "<blockquote>\n<p>There's a flipside to the above, which is that ASI can &gt; be expected to excel in situations where we already &gt; have extremely accurate predictive theories; the &gt;contingencies are already known and incorporated &gt;into the theory...</p>\n</blockquote>\n<p>Even Michael Nielson seems to have a blind spot here, despite all the frankly brilliant and well reasoned arguments prior.</p>\n<p>Why would \"an ASI\" be limited to only reprocessing existing data?</p>\n<p>Humans will, once they have ASI grade tools, use some of those tools to do the kinds of tool use tasks that manufactures more robots and chips.</p>\n<p>This is exponential.</p>\n<p>With realistically a pool of billions of specialized robots, it is a straightforward task to design a prompt to call an ASI instance to analyze existing experiments and rank possible new experiments by a heuristics of predicted knowledge gain/cost, with respect to some end goal.  (\"Best n experiments for increasing rat longevity\")</p>\n<p>Then loop it, perform the highest n value experiments across your robotics pool, update your models based on the results, and so on.</p>\n<p>Hopefully the \"cheap doomsday\" routes Michael is concerned about are too expensive in energy to be practical because if they are not, this kind of experimental loop like above could find it.</p>\n", "parentCommentId": null, "user": {"username": "Gerald Monroe"}}]