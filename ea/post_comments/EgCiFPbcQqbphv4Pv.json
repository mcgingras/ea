[{"_id": "QohG52XzeSWzwdMLE", "postedAt": "2017-12-12T12:16:32.606Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>That\u2019s an awesome selection! I\u2019m also planning to support WASR in 2018 and perhaps longer, and I\u2019m about to donate CHF 5k from my 2018 budget (for tax reasons) to their fundraiser.</p>\n<p>I\u2019m particularly optimistic about the field of welfare biology because it can draw on enormous resources in terms of institutions, biology and ecology research, and scientific methodology to generate break-throughs in an area that has been greatly neglected so far. The situation may be similar to that of medicine in the early days (1800s or so) when the foundations for systematic inquiry into health had finally been laid and then just needed to be applied to generate invaluable new insights.</p>\n<p>Surely many animals in the wild have net positive lives, but so do many humans around the world. I think it\u2019s valuable to research how we can improve the well-being of humans who suffer \u2013 perhaps even to the point of having net negative lives, but not necessarily \u2013 and so I value the same even more for wild animals who are so much more numerous and still live under worse conditions at much higher rates.</p>\n<p>There\u2019s also a <a href=\"https://sentience-politics.org/de/politik/massentierhaltung/\">Sentience Politics initiative going on in Switzerland</a> (<a href=\"https://translate.google.com/translate?hl=en&amp;sl=auto&amp;tl=en&amp;u=https%3A%2F%2Fsentience-politics.org%2Fde%2Fpolitik%2Fmassentierhaltung%2F\">automatic translation</a>) that has a shot at banning factory farming in the whole country via a popular vote. I see this in the same reference class as, for example, the ban on battery cages in California, though on a smaller scale because of the lower population size. Import of factory-farmed products may be more difficult than in the case of California, though, which is a big plus for the initiative. <a href=\"https://www.100-days.net/de/projekt/stopp-massentierhaltung\">And they\u2019re also far short of their fundraising goals.</a></p>\n", "parentCommentId": null, "user": {"username": "Telofy"}}, {"_id": "boyMDukrxNWTzFNN8", "postedAt": "2017-12-12T17:21:19.882Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>I haven't yet gotten around to writing up where I plan on donating in 2018 (I already maxed out my 2017 donations in February), but I've been thinking along the same lines. Recently I've been leaning toward donating to these smaller, riskier organizations because I see a lot of value in helping new orgs grow and learning what they can accomplish--especially because the established charities that I like best have gotten a lot of funding recently and have room to scale up before they start to hit the limits of their funding.</p>\n", "parentCommentId": null, "user": {"username": "MichaelDickens"}}, {"_id": "nRSodGFx85oH6Fcq4", "postedAt": "2017-12-12T18:27:00.704Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<blockquote>\n<p>I think it\u2019s valuable to research how we can improve the well-being of humans who suffer \u2013 perhaps even to the point of having net negative lives, but not necessarily</p>\n</blockquote>\n<p>I agree with this. Just to expand a bit - wild elephants might generally have net positive lives, but there still might be worthwhile interventions, e.g. to ensures some number that would have been killed by predators instead die in their sleep. The most relevant question is not whether wild animals have net positive lives, but how much their welfare could be improved per dollar.</p>\n", "parentCommentId": "QohG52XzeSWzwdMLE", "user": {"username": "avacyn"}}, {"_id": "GPxxbECBddsvBB8Dg", "postedAt": "2017-12-12T21:01:44.199Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>That's a great way of putting it. Thanks for the clarity!</p>\n", "parentCommentId": "nRSodGFx85oH6Fcq4", "user": {"username": "Peter_Hurford"}}, {"_id": "r82fRmCJKqHQ4xv83", "postedAt": "2017-12-12T21:02:25.526Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>Cool! I look forward to seeing your reasoning!</p>\n", "parentCommentId": "boyMDukrxNWTzFNN8", "user": {"username": "Peter_Hurford"}}, {"_id": "NAYLTjcWrMyMTM4cy", "postedAt": "2017-12-13T20:51:41.660Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>Do you have quantitative views on the effectiveness of donating these organizations, that could be compared to other actions? (Or could you point me to any of the links go to something like that?) Sorry if I missed them.</p>\n", "parentCommentId": null, "user": {"username": "Katja_Grace"}}, {"_id": "pqSkWDSk9AYsN5AiZ", "postedAt": "2017-12-13T23:11:01.457Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<blockquote>\n<p>The criteria I used for making these grants was as follows: (1) Have clear \u201croom for more funding\u201d ...\n(2) Have a clear risk of not meeting their funding goal...\n(3) Clear a bar of being \u201cimpactful enough\u201d...represent outstanding opportunities that I think are better than the community average</p>\n</blockquote>\n<blockquote>\n<p>I am very uninformed about organizations... working on existential risk and far future. My impression, however, is that OpenPhil has done a good job filling up the funding gaps in this area and that there are very few organizations that would meet the criteria I\u2019m using for these recommendations.</p>\n</blockquote>\n<p>I think this says about all that needs to be said about whether this kind of search procedure is likely to yield optimal donation targets!</p>\n", "parentCommentId": null, "user": {"username": "inconvenient"}}, {"_id": "GCmEiP8WCskF2jQJ5", "postedAt": "2017-12-14T00:52:06.406Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>I can't tell if this comment is positive or negative toward my criteria. Would you mind elaborating?</p>\n", "parentCommentId": "pqSkWDSk9AYsN5AiZ", "user": {"username": "Peter_Hurford"}}, {"_id": "8LXEucGhy5Anszqbh", "postedAt": "2017-12-14T03:05:09.657Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<blockquote>\n<p>organizations working outside these areas, such as those working on existential risk and far future. My impression, however, is that OpenPhil has done a good job filling up the funding gaps in this area and that there are very few organizations that would meet the criteria I\u2019m using for these recommendations.</p>\n</blockquote>\n<p>[Disclaimers: speaking only for myself, although I do some work for Open Phil.]</p>\n<p>I think that that many EAs are overestimating the degree to which this funding changes the marginal returns of individual donations, for a few reasons:</p>\n<ul>\n<li>In a number of these cases the Open Philanthropy Project grants discuss intentions to take up a percentage of the grantee's budget, and a preference not to exceed half of it; desire to avoid single-donor funding issues creates opportunities for small donors, as I discussed in this <a href=\"http://effective-altruism.com/ea/15g/small_donors_can_plan_to_make_better_bets_than/\">post</a></li>\n<li>If a large donor limits itself to half of the grantee's budget, then not only is there 'room for more funding' left for other donors, but it also implicitly acts as a delayed counterfactual 1:1 matching grant, as each small donor dollar allows for another large donor dollar (less the opportunity cost of Open Philanthropy's 'last dollar' but insofar as one isn't just topping up Open Philanthropy's reserves then presumably one aims to do better than that), which could largely offset diminishing returns  for the marginal donor</li>\n<li>Where 'room for more funding' suggests a steep cliff of diminishing returns, in reality diminishing returns are normally much smoother, as additional funds enable reserves, marginal expenditures, openness to and pursuit of additional expansion, etc; see the <a href=\"https://concepts.effectivealtruism.org/concepts/room-for-more-funding/\">linked articles</a> by Max Dalton and Owen Cotton-Barratt</li>\n<li>Concretely, I think small donors could 'top up' many of the AI grants in the Open Philanthropy <a href=\"https://www.openphilanthropy.org/giving/grants\">grant database</a> and get marginal cost effectiveness within a factor of 2-4 of the average cost-effectiveness of the dollars in the relevant grant</li>\n<li>In cases where the topping up would work better with larger amounts (e.g. $100,000 or $500,000) because of transaction costs (e.g. working with academic labs, or asking for advice on how to do it),  small donors can make use of a <a href=\"http://effective-altruism.com/ea/14d/donor_lotteries_demonstration_and_faq/\">donor lottery</a> to convert their donation into a 1/<em>n</em> chance of a donation <em>n</em> times as great for which the transaction costs are manageable</li>\n</ul>\n<p>In my view the larger shift induced by Open Philanthropy is that the returns to using one's labor, knowledge, and other resources to create opportunities that it will find competitive have gone up (since they are more likely to be able to grow later if successful). That is a boost for several of the organizations you mention, but can also apply to larger organizations whose activity tends to produce those opportunities through other channels than being a new organization (e.g. by building pipelines for new scientists or activists, research that better prioritizes options, demonstrations that technical projects can make progress). </p>\n<p>So I don't think that the arguments in the post are sufficient to establish this:</p>\n<blockquote>\n<p>while I think some organizations may be more impactful per dollar overall, the marginal donation is not as useful as they are highly likely to have been able to fundraise it already with much less effort and there is less at risk (e.g., whether a program happens at all versus whether it is scaled up further).</p>\n</blockquote>\n<p>I agree that CSH looks attractive for a donor who would otherwise give to AMF, that WASR and SI make sense for a donor who might otherwise give to The Humane League (as demonstrated by, e.g. Lewis' EA Funds grants), and that providing access to donation methods for Canadian donors could pay for itself for those donors (with some caveats about distributional details, and due diligence). </p>\n<p>However, I don't think that increased Open Philanthropy funding provides adequate reason to dismiss the cause area of existential risk reduction for marginal funds (and in fact my own view is that the most attractive marginal opportunities lie in that area, directly or indirectly).</p>\n", "parentCommentId": null, "user": {"username": "CarlShulman"}}, {"_id": "ReaN8SDPsmBJNuGae", "postedAt": "2017-12-18T17:17:59.954Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>I focused more on identifying organizations that met the three criteria I outlined and then vetting them individually. Because I was just looking for organizations I felt confident in being &quot;good enough to be considered above average&quot;, I did not take the time to develop quantitative views for them yet. I'm also not sure if such views would be useful.</p>\n<p>For Charity Science Health, I'd rely on <a href=\"http://effective-altruism.com/ea/151/what_is_the_expected_value_of_creating_a_givewell/\">&quot;What is the expected value of creating a GiveWell top charity?&quot;</a>. While published in Dec 2016, I've revisited the underlying numbers in May 2017 and Dec 2017 and found them to still be roughly the same. Notably this estimate is for value of time spent on the project rather than value of marginal funding, but I think the two would be roughly equivalent.</p>\n<p>For the Sentience Institute or the Wild-Animal Suffering Research Institute, I have a rough guess <a href=\"https://www.getguesstimate.com/models/7926\">as to the value of cause prioritization efforts, generally speaking</a> and I think these organizations would fall under that. Again, this estimate is looking at the value of time spent rather than value of marginal funding, but that shouldn't really matter.</p>\n<p>For Rethink Charity, I don't have any quantitative estimates at this time. I tried making one for the Local Effective Altruism Network (LEAN) last year, but was held back by not having any quantitative information about local groups. LEAN has put a lot of time into improving this quantitative situation this year, publishing <a href=\"http://effective-altruism.com/ea/1ic/blah/\">one report</a> and aiming to publish more. This should make constructing a quantitative estimate possible.</p>\n", "parentCommentId": "NAYLTjcWrMyMTM4cy", "user": {"username": "Peter_Hurford"}}, {"_id": "cHEG27cRBhh3jBEZS", "postedAt": "2017-12-18T17:21:22.368Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>Thanks Carl, it's good to know that there are RFMF opportunities in topping up AI grants.</p>\n<p>My reasoning for not donating to AI projects right now is based much less on a RFMF argument and more on not knowing enough about the space. I think I know enough about opportunities in global poverty, animal welfare, and EA community building to recommend projects there with confidence, but not for AI. I expect it would take me a good deal of time to develop the relevant expertise in AI to consider it properly. I have thought about working to develop that expertise, but so far I have not prioritized doing so.</p>\n", "parentCommentId": "8LXEucGhy5Anszqbh", "user": {"username": "Peter_Hurford"}}, {"_id": "DypeTYPQsyGrK4PuZ", "postedAt": "2017-12-18T21:31:14.470Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>I don't understand how that logic leads to thinking it's a good idea to donate to the causes you're thinking of donating to. Donating to a cause area because you can identify good projects within it seems like the <a href=\"https://en.wikipedia.org/wiki/Streetlight_effect\">streetlight effect</a>. </p>\n<p>If you think that AI stuff is plausibly better, shouldn't you either want to learn more about it or enter a donor lottery so that it's more cost-effective for you to learn about it?</p>\n", "parentCommentId": "cHEG27cRBhh3jBEZS", "user": {"username": "Buck"}}, {"_id": "3oSNn4E8c5kthSwg6", "postedAt": "2017-12-18T22:00:36.619Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>Thanks for writing this! This influenced me and my thoughts about donations.</p>\n", "parentCommentId": null, "user": {"username": "zdgroff"}}, {"_id": "pxiuuBvpn7xwuwkpk", "postedAt": "2017-12-18T22:01:34.520Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>My excuses in order of importance:</p>\n<p>1.) While I do think AI as a cause area could be plausibly better than global poverty or animal welfare, I don't think it's so plausibly better that the expected value given my uncertainty dwarfs my current recommendations.</p>\n<p>2a.) I think I'm basically okay with the streetlight effect. I think there's a lot of benefit in donating now to support groups that might not be able to expand at all without my donation, which is what the criteria I outlined here accomplish. Given the entire EA community collaborating as a whole, I think there's less need for me to focus tons of time on making sure my donations are as cost-effective as possible, and more just a need to clear a bar of being &quot;better than average&quot;. I think my recommendations here accomplish that.</p>\n<p>2b.) Insofar as my reasoning in (2a) is some &quot;streetlight effect&quot; bias, I think you could accuse nearly anyone of this, since very few have thoroughly explored every cause area and no one could fully rule out being wrong about a cause area.</p>\n<p>3.) There is still more I could donate later. This money is being saved mainly as a hedge to large financial uncertainty in my immediate future, but could also be used as savings to donate later when I learn more.</p>\n", "parentCommentId": "DypeTYPQsyGrK4PuZ", "user": {"username": "Peter_Hurford"}}, {"_id": "kxnvzyziDFm4AdAhk", "postedAt": "2017-12-19T00:38:18.807Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>[Note: I work on existential risk reduction]</p>\n<p>Although I laud posts like the OP, I'm not sure I understand this approach to uncertainty.</p>\n<p>I think a lot turns on what you mean by the AI cause area being &quot;Plausibly better&quot; than global poverty or animal welfare on EV. The Gretchenfrage seems to be this conditional forecast: &quot;If I spent (lets say) 6 months looking at the AI cause area, would I expect to identify better uses of marginal funding in this cause area than those I find in animal welfare and global poverty?&quot;</p>\n<p>If the answer is &quot;plausibly so, but probably not&quot; (either due to a lower 'prima facie' central estimate, or after pricing in regression to the mean etc.), then I understand the work uncertainty is doing here (modulo the usual points about VoI): one can't carefully look at everything, and one has to make some judgments on what cause areas look most promising to investigate on current margins. </p>\n<p>Yet if the answer is &quot;Probably, yes&quot;, then offering these recommendations simpliciter (i.e. &quot;EA should fully fund this&quot;) seems premature to me. The evaluation is valuable, but should be presented with caveats like, &quot;Conditional on thinking global poverty is the best cause area, fund X; conditional on thinking animal welfare is the best cause area, fund Y (but, FWIW, I believe AI is the best cause area, but I don't know what to fund within it).&quot; It would also lean against making ones own donations to X, Y etc., rather than spending time thinking about it/following the recommendations of someone one trusts to make good picks in the AI cause area. </p>\n", "parentCommentId": "pxiuuBvpn7xwuwkpk", "user": {"username": "Gregory_Lewis"}}, {"_id": "ZdcmvwwioXrnZnqYg", "postedAt": "2017-12-19T02:10:49.494Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<blockquote>\n<p>If the answer is &quot;plausibly so, but probably not&quot; (either due to a lower 'prima facie' central estimate, or after pricing in regression to the mean etc.)</p>\n</blockquote>\n<p>This is what captures my views best right now.</p>\n", "parentCommentId": "kxnvzyziDFm4AdAhk", "user": {"username": "Peter_Hurford"}}, {"_id": "X7A939ekAbNsTi56m", "postedAt": "2017-12-21T23:33:40.152Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<blockquote>\n<p>I still think both LEAN and SHIC have a substantial risk of not being cost-effective, but I\u2019m far more confident that there is sufficient analytical work going on now that failure would be detected and learned from. Given the amount of information they\u2019re generating, I\u2019m confident we\u2019ll all learn something important even if either (or both) projects fail</p>\n</blockquote>\n<p>Could you say more about this? When I look at their metrics, it's a little unclear to me what failure (or success) would look like. In extremis, every group rating LEAN as ineffective (or very effective) would be an update, but it's unclear to me how we would notice smaller changes in feedback and translate that to counterfactual impact on &quot;hit&quot; group members.</p>\n<p>Similarly, for SHIC, if they somehow found a high school student who becomes a top-rated AI safety researcher or something similar that would be a huge update on the benefit of that kind of outreach. But the chances of that seems small, so it's kind of unclear to me what we should expect to learn if they find that students have some moderate changes in their donations but nothing super-high-impact.</p>\n", "parentCommentId": null, "user": {"username": "Ben_West"}}, {"_id": "ZWAMjiEWibTGmCAbK", "postedAt": "2017-12-31T20:19:58.575Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>Ahoy all, first post here super excited!</p>\n<p>Charity Science Health - Do they detail the plans for their RCT? Have the looked at the current research for contexts in which the intervention is more or less effective?</p>\n<p>The RCTs are promising but I would think the cash they are asking for would get them something north of 2k participants (correct me if thats naive).</p>\n<p>Also, is their code open source/do they need some one to code for em? Have they looked at charging clinics a small fee for the repeat customers or would that burn them most likely?</p>\n", "parentCommentId": null, "user": {"username": "VinceB"}}, {"_id": "AhSvPnQ8YbwT8EYWG", "postedAt": "2017-12-31T20:24:13.369Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<blockquote>\n<p>a shot at banning factory farming </p>\n</blockquote>\n<p>What would this entail? should we start a new thread for this? sounds great but small-medium farmers could get their butts whipped if its implemented too broadly no?</p>\n", "parentCommentId": "QohG52XzeSWzwdMLE", "user": {"username": "VinceB"}}, {"_id": "7sfsYnuHB2srcP4Dd", "postedAt": "2017-12-31T20:34:21.744Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>To attempt to complement what Peter already said, </p>\n<blockquote>\n<p>: one can't carefully look at everything, and one has to make some judgments on what cause areas look most promising to investigate on current margins.</p>\n</blockquote>\n<p>This is why EA rarely falls into what can accurately be described as a &quot;streetlight effect&quot;. We aren't looking for one set of keys, we're looking for a bunch of keys (threats to human welfare) and theres a bunch of us drunkards, all with differing abilities and expertise. So I'd argue if its dark somewhere, those with the expertise need to start building streetlights, but if the lights getting brighter in certain areas (RCTs in health) then we need people there too.</p>\n", "parentCommentId": "kxnvzyziDFm4AdAhk", "user": {"username": "VinceB"}}, {"_id": "nci8GPwAnQZh4Hem6", "postedAt": "2017-12-31T20:39:57.568Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>Charity Science Health also featured really good RCTs in their proposal that you can see in their proposal or just google. LMK if I should link them.</p>\n<p>There is also the promise of future data in this arena. JPAL, WHO, and a few other orgs are setting their sails to investigate this as well, so the decent data will be getting much better. If WHO and JPAL are interested theres at the least something big to investigate for sure, and to get that data you need programs to be active.</p>\n", "parentCommentId": "NAYLTjcWrMyMTM4cy", "user": {"username": "VinceB"}}, {"_id": "dNLrMmEHcNcb5MeJE", "postedAt": "2017-12-31T20:41:28.517Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<blockquote>\n<p>I am very uninformed about organizations...</p>\n</blockquote>\n<p>OP wasnt refering to the orgs he was donating to but a seperate problem domain he doesnt have expertise in.</p>\n", "parentCommentId": "pqSkWDSk9AYsN5AiZ", "user": {"username": "VinceB"}}, {"_id": "izwjGY2EHD766d6vv", "postedAt": "2018-01-01T18:32:52.669Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>Congrats on first post.</p>\n<p>You can see our most detailed current plans for the RCT in this <a href=\"https://docs.google.com/document/d/1UpwT1cOHVkuf3K3x4WP9OhF-OejYa8roC7iH2mrTQfI/edit\">concept note</a> or this <a href=\"https://docs.google.com/spreadsheets/d/1WZdr5DPPFfbIBic5EW6H6gTZo7Te2BIrmlYUbGLGu4s/edit#gid=178360181\">spreadsheet</a>. We are still nailing down the partners we are working with and the end line budget we will have, so they are subject to some change. We have considered the existing evidence base fairly carefully and you can see our summary of other studies <a href=\"https://docs.google.com/spreadsheets/d/11eNrNbkSJbIjYsLZTxwgi1g68m7081wTW3JaFnO7WY8/edit#gid=0\">here</a>. </p>\n<p>We have estimates at different sample sizes, but generally we are looking in the 5k-20k range of participants dependent on funding and exact study design.</p>\n<p>Indeed our code is open source and we would love help on it. We are about to put up a volunteering/internship opportunity to help us with it. You can see the code <a href=\"https://github.com/charityscience/csh-sms\">here</a>.</p>\n<p>Sadly clinics would not provide funding for our program, at least not the low income clinics in our target areas. It might be different with private clinics, but they generally target demographics that are less productive to send reminders to (due to having higher baseline vaccination rates)</p>\n", "parentCommentId": "ZWAMjiEWibTGmCAbK", "user": {"username": "Joey"}}, {"_id": "eAvqnNrxX7koQtwoL", "postedAt": "2018-01-04T02:55:20.022Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>That Code link is broken, check it. Would love to star it and take a look :) Im crazy buzy (arent we all?) but it might be worth a look for sure.</p>\n<p>GL on those RCTs! heres to getting 20k samples!</p>\n", "parentCommentId": "izwjGY2EHD766d6vv", "user": {"username": "VinceB"}}, {"_id": "u4L2m7XNhei9hBge8", "postedAt": "2018-01-04T17:08:18.847Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>Fixed now :)</p>\n", "parentCommentId": "eAvqnNrxX7koQtwoL", "user": {"username": "Joey"}}, {"_id": "gsAh4F4qsyMZoyr9m", "postedAt": "2018-01-12T12:01:32.089Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>Sophie and Meret will know more, but from what I\u2019ve heard, they\u2019re pretty much on board with it because it will shift demand toward them. I can point Sophie to this thread if you\u2019d like a more detailed or reliable answer than mine. ;-)</p>\n", "parentCommentId": "AhSvPnQ8YbwT8EYWG", "user": {"username": "Telofy"}}, {"_id": "tySZZeyJbFkCBkCnn", "postedAt": "2018-03-31T12:24:40.771Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>Lewis Bollard is now (March 2018) recommending <a href=\"https://docs.google.com/document/d/1T7erWUkv1wBHhtHk2hY8zAu-DoZR8qTCfOW85L170qA/edit\">additional grants</a> to Wild Animal Suffering Research ($100k) and Sentience Institute ($70k) through the EA Animal Welfare Fund, which may change the room for funding situation for those organizations.</p>\n", "parentCommentId": null, "user": {"username": "AviN"}}, {"_id": "KMiRwegEfHMs3KR5i", "postedAt": "2018-03-31T18:45:14.809Z", "postId": "EgCiFPbcQqbphv4Pv", "htmlBody": "<p>An additional point to take into account when it comes to examining the research on AI as possible space for donations: as a scientific domain the topic of AI risks and safety can easily fall under the public/academic funding, even under the assumption that it is currently underfunded. To this end, individual applicants (precisely those who would be conducting research by means of donations) can apply for individual PhD and postdoc grants. There are numerous opportunities of that kind across EU. Moreover, the funding agencies (e.g. in Germany, Belgium, Netherlands, etc.) will employ expert refereeing system (sometimes even asking the applicant to suggest suitable referees) to assess the project and its effectiveness (which I find very relevant from the perspective of EA). If we take this into account, then a number of other organizations that can't be so easily funded via already existing institutional channels becomes much more urgent.</p>\n<p>P.S. Great post, Peter, only now saw it.</p>\n", "parentCommentId": "kxnvzyziDFm4AdAhk", "user": {"username": "Dunja"}}]