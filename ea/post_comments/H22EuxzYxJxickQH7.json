[{"_id": "ov89gsnFTmoyFBKyq", "postedAt": "2024-01-20T17:55:48.811Z", "postId": "H22EuxzYxJxickQH7", "htmlBody": "<p>I think what this means in part is that we need to also work to create institutions that are actually trustworthy around ai.</p>\n", "parentCommentId": null, "user": {"username": "timunderwood"}}, {"_id": "my96dJgvyyYRcyDKS", "postedAt": "2024-01-20T22:37:10.089Z", "postId": "H22EuxzYxJxickQH7", "htmlBody": "<p>That's definitely important. Though a more extreme take that I might even be agreeable to is that even a poorly run institution, corrupt even, in charge of AI would be better than AI for the masses. Maybe I'm realizing the disagreement on this issue isn't as much about whether you think institutions are frequently corruptible/incompetent, but rather whether that is so off-putting (I grant that there is something almost viscerally repulsive about the idea of a small, secretive, and selfish or incompetent group of individuals in any circumstance, particularly when the stakes are high like in this case) that it's even worse than an even more likely chance of total annihilation. I would say the small group is still better, because I think that while people may not necessarily be altruistic, they don't actively want to harm others if they gain nothing from doing so, and all else equal they'd be happy to help others (except for sociopaths and a few others, who presumably would be screened out by an exclusive board or committee). Feel free to share where you might disagree though!</p>", "parentCommentId": "ov89gsnFTmoyFBKyq", "user": {"username": "another-anon-do-gooder"}}]