[{"_id": "fRTyrv9N6XnKHyi3K", "postedAt": "2023-12-22T22:46:35.332Z", "postId": "Ka6gpToFKtGTTSzXt", "htmlBody": "<p>Thanks for this provocative and timely post.&nbsp;</p><p>I agree that EAs have been far too friendly to AI companies, too eager to get hired within these companies as internal AI safety experts, too willing to give money to support their in-house safety work, and too wary about upsetting AI leaders and developers.&nbsp;</p><p>This has diluted our warnings about extinction risks from AI. I've noticed that on social media like X, ordinary folks get very confused about EA attitudes towards AI. If we really think AI is extraordinarily dangerous, why would we be working with AI companies to advance capabilities, safety-wash their advances, and serve as their PR props to convince the public that they're being cautious and responsible?&nbsp;</p><p>If rapid AI development is really an extinction risk, and EAs want to minimize extinction risks, it's puzzling that we would see the AI industry as our allies rather than our enemies.&nbsp;</p><p>We've talked a lot over the years about the benefits of 'engagement' with the AI industry, 'being in the room' when they make decisions, having insider tracks to monitor and nudge their safety policies, etc. But, as this post points out, the OpenAI debacle might mark the end of that era. The voices for AI safety at OpenAI were decisively pushed out, in favor of maximum-speed commercialization and AGI development.</p><p>So, I think EAs need a new strategy for AI safety that is more confrontational, more political, and savvier about the cynicism, greed, and power of the AI industry. My essay on <a href=\"https://forum.effectivealtruism.org/posts/veR4W92bZsTsGgS3D/a-moral-backlash-against-ai-will-probably-slow-down-agi\">moral stigmatization of AI</a> outlined one possible path. There might be other viable strategies, such as those outlined in this post.</p><p>As I've said many times over the last year or so, it's time to stop playing nice with the AI industry. Especially since, following this recent OpenAI shakeup, they stopped playing nice with us.</p>", "parentCommentId": null, "user": {"username": "geoffreymiller"}}, {"_id": "a8J5mna76hB9bis2c", "postedAt": "2023-12-23T01:19:40.506Z", "postId": "Ka6gpToFKtGTTSzXt", "htmlBody": "<p>I\u2019d think very carefully before pursuing this. Sam is a very experienced political player and two quite senior EA's just got outplayed. In many worlds, I expect our attempts backfire. Don\u2019t pursue this unless you have good reason to believe that you can compete on his level. Otherwise, I'd suggest picking easier fights first.</p>\n<p>Also, some of these don't really seem like gentle pushback, but actually rather aggressive. Maybe we should be aggressive, but if so, we should own it.</p>\n", "parentCommentId": null, "user": {"username": "casebash"}}, {"_id": "JgFKR42Gjbvm7PKpk", "postedAt": "2023-12-23T05:45:18.160Z", "postId": "Ka6gpToFKtGTTSzXt", "htmlBody": "<p>They got outplayed in the context of the internal politics of OpenAI, where there were A LOT of people with profit (Microsoft) or career (the employees) incentives to race ahead. But there seems to be an emerging public consensus in favor of more regulation, so I would expect that e.g. smart, ambitious politicians have quite different incentives.&nbsp;</p>", "parentCommentId": "a8J5mna76hB9bis2c", "user": {"username": "Bluefalcon"}}, {"_id": "u7DoocqrjB6m2h4Pb", "postedAt": "2023-12-23T17:57:28.034Z", "postId": "Ka6gpToFKtGTTSzXt", "htmlBody": "<p>Not to frame everything as the nail my favorite hammer could plant, but I would suggest people to form themselves to conversational techniques (Deep Canvassing, Smart Politics and Street Epistemology). I think that classical argumentation is likely to have only very limited effects if not handled with extremely good rapport and on very long timespans.</p>\n<p>Note that at least one person disagrees with me on this, but I think acting methodically is still better than doing so spontaneously.</p>\n", "parentCommentId": null, "user": {"username": "Camille"}}, {"_id": "rCSS5pKxcFAhPgmeY", "postedAt": "2023-12-25T04:09:46.639Z", "postId": "Ka6gpToFKtGTTSzXt", "htmlBody": "<blockquote>\n<p>Something like the recent Nonlinear post\u2013but focused at Sam\u2013would likely have far, far higher EV.</p>\n</blockquote>\n<p>I felt really uncomfortable reading this</p>\n", "parentCommentId": null, "user": {"username": "SiebeRozendal"}}]