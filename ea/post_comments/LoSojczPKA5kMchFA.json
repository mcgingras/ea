[{"_id": "ERbX4e8uiTzxoeiaX", "postedAt": "2021-11-05T15:44:55.492Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>If you are looking to donate to CEA, the <a href=\"https://forum.effectivealtruism.org/posts/ZhDbbTQs5EAdCGzxt/make-a-usd100-donation-into-usd200-or-more-1\">Every.org donation matching program</a> still has $60K in matching funds available (for a 1:1 match up to $100 [USD]).&nbsp;</p><p>No time like the present to convert 100 USD for CEA into 200 USD! The link to CEA's giving page on Every.org <a href=\"https://www.every.org/effectivealtruism?\">is here</a>.</p>", "parentCommentId": null, "user": {"username": "jared_m"}}, {"_id": "gDaPNHhf8zbinyjBW", "postedAt": "2021-11-05T16:20:19.299Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>What's the argument against CEA being 10x it's current size. IE why is this the right size to stick at?</p>\n<p>Is there research on what the value of HEAs are and why the current amount of money is the right amount to spend finding them?</p>\n", "parentCommentId": null, "user": {"username": "nathan"}}, {"_id": "vuRxDmnhehCDxnyw7", "postedAt": "2021-11-05T16:49:08.673Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>I think you're assuming that we're planning to stick at this size! I think we'll &nbsp;continue to grow at least somewhat beyond this scale, but I'm not yet confident that 10x would still be cost-effective (in terms of aligned labour).</p><p>There is some research on the value of HEAs, but unfortunately it's not mine so I can't share it. Right now, I'm not particularly concerned that the financial costs of CEA aren't repaid via the number of HEAs we help find. I think that the main thing stopping us from creating more HEAs is probably not funding: it's talent and the ability to coordinate that talent without things breaking as we grow. (Funding is helpful for us to diversify our funding base and be more stable.)</p>", "parentCommentId": "gDaPNHhf8zbinyjBW", "user": {"username": "Maxdalton"}}, {"_id": "JAv3DpRkJSnmzBadW", "postedAt": "2021-11-05T19:18:32.758Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>It feels like CEA has been avoiding growing previously and now has started. Am I wrong about that? If not, what changed?</p>\n", "parentCommentId": "vuRxDmnhehCDxnyw7", "user": {"username": "nathan"}}, {"_id": "DikDbiicC5eoXwQSE", "postedAt": "2021-11-05T19:27:50.560Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>You're right that growth was flatter in previous years (though a lot of metrics -e.g. Forum metrics - &nbsp;grew a lot in 2020 too).</p><p>On an organizational level, we consolidated in 2019, figured out our strategy and narrowed our scope in 2020. At the beginning of 2021 we had a clear strategy and we got more data on our impact from OP's survey. That made me confident that we should switch into expansion mode (in terms of headcount).</p><p>More strategically, I think the community is now better set up to accommodate growth - e.g. many more of the core ideas are written up and shared widely, and there are more orgs doing a lot of hiring. So I think we can grow the number of people in the community somewhat quicker at a given quality level than we could in 2018. I don't think the community should grow too quickly, but I think we should grow more quickly than we did in the last couple of years.</p>", "parentCommentId": "JAv3DpRkJSnmzBadW", "user": {"username": "Maxdalton"}}, {"_id": "vEBhZkCzF2cgBz2fq", "postedAt": "2021-11-05T20:51:02.127Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>So I think the thing I don't understand is why you think we shouldn't grow the community too quickly. Why is this the right level?</p>\n<p>And thanks for being so generous with your time here.</p>\n", "parentCommentId": "DikDbiicC5eoXwQSE", "user": {"username": "nathan"}}, {"_id": "8popZtnTPfyQaoY3Q", "postedAt": "2021-11-05T23:08:08.013Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>I'm quite happy to see the progress here. Kudos to everyone at CEA to have been able to scale it, without major problems yet (that we know of). I think I've been pretty impressed by the growth of the community; intuitively I haven't noticed a big drop in average quality, which is obviously the thing to worry about with substantial community growth.</p><p>As I previously discussed in some related comment threads, CEA (and other EA organizations in general) scaling, seems quite positive to me. I prefer this to trying to get tons of tiny orgs, in large part because I think the latter seems much more difficult to do well. That said, I'm not sure how much CEA should try to scale over the next few years; 2x/year is a whole lot to sustain, and over-growth can of course be a serious issue. Maybe, 30%-60%/year feels safe, especially if many members are siloed into distinct units (like seems to be happening).</p><p>Some random things I'm interested in, in the future:</p><ul><li>With so many people, is there a strong management culture? Are managers improving, in part to handle future growth?</li><li>What sorts of pockets of people would make great future hires for CEA, but not so much for other orgs? If there are distinct clusters, I could imagine trying to make projects basically around them. We seem pretty limited for \"senior EA\" talent now, so some of the growth strategy is about identifying other exciting people and figuring out how to best use them.</li><li>With the proliferation of new community groups, how do we do quality control to make sure none turn into cults or have big scandals, like sexual assault? Sadly, poor behavior is quite endemic in many groups, so we might have to be really extra rigorous to reach targets we'd find acceptable. The recent <a href=\"https://www.lesswrong.com/posts/XPwEptSSFRCnfHqFk/zoe-curzi-s-experience-with-leverage-research\">Leverage</a> issues come to mind; personally, I would imagine CEA would be in a good position to investigate that in more detail to make sure that the bad parts of it don't happen again.</li></ul><p>Also, while there's much to like here, I'd flag that the \"Mistakes\" seem pretty minor? I appreciate the inclusion of the section, but for a team with so many people and so many projects, I would have expected more to go wrong. I'm sure you're excluding a lot of things, but am not sure how much is being left out. I could imagine that maybe something like a rating would be more useful, like, \"we rated our project quality 7/10, and an external committee broadly agreed\". Or, \"3 of our main projects were particularly poor, so we're going to work on improving them next time, but it will take a while.\"</p><p>I've heard before a criticism that \"mistakes\" pages can make things less transparent (because they give the illusion of transparency), not more, and that argument comes to mind.</p><p>I don't mean this as anything particularly negative, just something to consider for next time.</p>", "parentCommentId": null, "user": {"username": "oagr"}}, {"_id": "EmCXis75hngPaEG9y", "postedAt": "2021-11-06T06:49:05.548Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>Ah, maybe I was confused because \"level\" sounded like \"total size\" to me, whereas I think you mean \"why is this rate of growth right?\". Is that right?</p><p>My current best guess is that we should be targeting roughly 40% growth, which is quite a bit faster than Ben Todd's estimates for previous years. (This is growth of highly-engaged EAs: I think we could grow top of funnel or effective-giving-style brands more quickly.)</p><p>The main reason that I think we shouldn't grow too much quicker than this is that I think there are some important things (ways of thinking, norms, some of the fuzzier and cutting edge research areas) that are best transferred via apprenticeships of some sort (e.g. taking on a junior role at an org, getting mentorship, doing a series of internships). If you think it takes a couple of years of apprenticeship before people are ready to train up people, then this puts a bit of an upper limit on growth. And if we grow too much faster than that, I worry that some important norms or ways of thinking (e.g. really questioning your beliefs, reasoning transparency, collaborative discussion norms) don't get passed on, which significantly reduces the value of the community's work.</p><p>The main reason that I think, despite that, we should grow at about 40% (which is pretty quick compared to the past) is that if we grow too much slower than this, I just don't see us reaching the sort of scale that we might need to address the problems we're facing (some of which have deadlines, maybe in a decade or two).</p>", "parentCommentId": "vEBhZkCzF2cgBz2fq", "user": {"username": "Maxdalton"}}, {"_id": "nLAb8g5Jg7sKrtRkk", "postedAt": "2021-11-06T07:17:02.580Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>Thanks! Some comments:</p><ul><li>Yeah, I agree 2x is quite a lot! We grew more this year because I think we were catching up with demand for our projects. I expect more like 50% in the future.</li><li>Is there a strong management culture? I think there is: I've managed this set of managers for a long while, and we regularly meet to discuss management conundrums, so I think there's a shared culture. We also have shared <a href=\"https://www.centreforeffectivealtruism.org/team-values#collective-growth\">values</a>, and team retreats to sync up together. But each manager also has their own take, and I think that is leading to different approaches to e.g. project management or goal setting on each team (but not yet to conflict).</li><li>Are managers improving? Broadly, I think they still are! For each of them, there's generally some particular area they're focused on improving via feedback or mentorship. But I also think that we're all just getting extra years of management under our belt, and that helps a lot. I think we're still interested in also bringing in people with management experience or aptitude, to help us keep scaling.</li><li>People who are a good fit for CEA: One thing that I think people haven't fully realized is that we're a<a href=\"https://www.centreforeffectivealtruism.org/careers#do-i-need-to-move\"> remote org first</a>. So if you can't find EA jobs nearby, we might be a good fit. I'm particularly interested in hiring ambitious, agile, user-focused people right now. You can read a lot more on <a href=\"https://www.centreforeffectivealtruism.org/careers\">our careers page</a>.</li><li>I have recently been talking to some people who are interested in setting up new projects that are adjacent to or complementary to our current work, and we're exploring whether some of those could be a part of CEA. So I'm open to that, but the current things are in their early stages. If you are interested in setting up a new thing, and you think it might be better as part of CEA, feel free to get in touch and we can explore that. I think the key reason it might be better at CEA is if it fits in really closely with our current projects, or if there are synergies (e.g. you want to build off Forum tech or do something in the groups space).</li><li>Re cults/scandals at local groups: I agree that this is a risk. We hope that with more group calls we might catch some of this, but ultimately it's hard to vet all local groups. I'd encourage anyone who has concerns about a group or individual to consider reaching out to <a href=\"https://forum.effectivealtruism.org/posts/hYh6jKBsKXH8mWwtc/a-contact-person-for-the-ea-community\">Julia Wise</a>.</li><li>Re mistakes: Those do feel like the biggest ones that directly harmed our outside work. Then I think there were a lot of cases where we could have moved a bit more quickly, or taken on an extra thing that really mattered, or made a slightly better decision. Those really matter too - maybe more than the things that look more like \"mistakes\" - &nbsp;but it's often a bit hard to write them up cleanly. &nbsp;I guess I think that this post overall gives an accurate summary of the balance of successes vs. harm-causing mistakes, but it's not comprehensive about either. And then it might under-weight all of the missed opportunities. &nbsp;(Our <a href=\"https://www.centreforeffectivealtruism.org/our-mistakes\">mistakes page</a> has that disclaimer (\"not comprehensive\") at the top, but I expect people still sometimes see it as comprehensive.)</li></ul>", "parentCommentId": "8popZtnTPfyQaoY3Q", "user": {"username": "Maxdalton"}}, {"_id": "qjhoyLJpKriPYTsLP", "postedAt": "2021-11-06T12:44:02.168Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>Congratulations on this growth, really exciting!</p><p>Have you thought about including randomisation to facilitate evaluation?</p><p>E.g. you could include some randomisation in who invited to events (of those who applied), which universities/cities get organisers (of those on the shortlist) etc. This could also be done with 80k coaching calls, dunno if it has been tried.</p><p>You then track who did and didn't get the treatment, to see what effect it had. &nbsp;This doesn't have to involve denying 'treatment' to people/places - presumably there are more applicants than there are places - you introduce randomisation at the cutoff.</p><p>This would allow some causal inference (RCT/Randomista, &nbsp;<a href=\"https://www.cold-takes.com/does-x-cause-y-an-in-depth-evidence-review/\">does x cause y</a>, etc) as to what effect these treatments are having (vs the control, and null hypothesis of no effect). This could help justify impact to the community and funders. I'm sure people at eg JPAL, Rethink, etc could help with research design.</p>", "parentCommentId": null, "user": {"username": "HaydnBelfield"}}, {"_id": "EFmFuq6xg9mHFJTpk", "postedAt": "2021-11-06T19:36:07.063Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>I support this idea and have mentioned it previously (e.g. <a href=\"https://forum.effectivealtruism.org/posts/TX6aLFsHJrtmwGvYX/does-the-forum-prize-lead-people-to-write-more-posts#bMjsjri3PHrgdsRSw\">here</a> and <a href=\"https://forum.effectivealtruism.org/posts/an9GrNXrdMwBJpHeC/long-term-future-fund-august-2019-grant-recommendations-1#P2YigQY4wAJvzYujd\">here</a>).</p><blockquote><p>This doesn't have to involve denying 'treatment' to people/places - presumably there are more applicants than there are places - you introduce randomisation at the cutoff.</p></blockquote><p>I'm not sure I understand your proposal correctly. To take a concrete example, say 80k gets 500 coaching requests per year and they only have the capacity to coach 250 people. Presumably they select the 250 people they think are most promising, whereas a randomized study would select 250 people randomly and use the remaining 250 as a control. In a sense, this does not involve denying treatment to anyone, since the same number of people (though not the same people) receive coaching, but it does involve a cost in expected impact, which is what matters in this case (and presumably in most other relevant cases\u2014it would be surprising if EA orgs were not prioritizing when they are unable to allocate a resource or service to everyone who requests it). I think the cost is almost certainly justified, given that no randomized studies have been conducted so far and the existing methods of evaluation are often highly speculative, but this doesn't mean that there are no costs. But as noted, I may be misunderstanding you.</p><p>If one is still concerned about the costs, or if randomization is infeasible for other reasons, an alternative is to use a quasi-experimental approach such as a <a href=\"https://en.wikipedia.org/wiki/Regression_discontinuity_design\">regression discontinuity design</a>. Another alternative is to have a series of Metaculus questions on what the results of the experiment <i>would</i> be if it was conducted, which can be informative even if no experiment is ever conducted.</p>", "parentCommentId": "qjhoyLJpKriPYTsLP", "user": {"username": "Pablo_Stafforini"}}, {"_id": "KJtDaZSHdic3pjkHK", "postedAt": "2021-11-07T12:26:19.252Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>Very cool you've previously mentioned it - nice that we've both been thinking about it!</p><p>One proposal is a slight modification. Basically to use your example, you could (a) randomise the entire 250 or (b) you could rank the 500, give the 'treatment' to the top 150 say, then randomise 100 'treatments' to 200 around (100 above and 100 below) the cutoff. I think both proposals, or a RDD, would be good - but would defer to advice from actual EA experts on RCTs.</p>", "parentCommentId": "EFmFuq6xg9mHFJTpk", "user": {"username": "HaydnBelfield"}}, {"_id": "bGbumLoxyvHTxqzLM", "postedAt": "2021-11-07T13:47:59.654Z", "postId": "LoSojczPKA5kMchFA", "htmlBody": "<p>I just want to add, on top of Haydn's comment to your comment, that:</p>\n<ol>\n<li>\n<p>You don't need the treatment and the control group to be of the same size, so you could, for instance, randomize among the top 300 candidates.</p>\n</li>\n<li>\n<p>In my experience, when there isn't a clear metric for ordering, it is extremely hard to make clear judgements. Therefore, I think that in practice, it is very likely that let's say places 100-200 in their ranking seem very similar.</p>\n</li>\n</ol>\n<p>I think that these two factors, combined with Haydn's suggestion to take the top candidates and exclude them from the study, make it very reasonable, and of very low cost.</p>\n", "parentCommentId": "EFmFuq6xg9mHFJTpk", "user": {"username": "shaybenmoshe"}}]